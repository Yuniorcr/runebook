<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="b4b4750e8021650b4da5de07fd1cb495068051c3" translate="yes" xml:space="preserve">
          <source>The logistic regression with One-Vs-Rest is not a multiclass classifier out of the box. As a result it has more trouble in separating class 2 and 3 than the other estimators.</source>
          <target state="translated">Логистическая регрессия с One-Vs-Rest не является многоклассовым классификатором.В результате у него больше проблем с разделением классов 2 и 3,чем у других вычислений.</target>
        </trans-unit>
        <trans-unit id="658bb63624739c29e98c4d11ac78e5bf2f1fae2c" translate="yes" xml:space="preserve">
          <source>The loss function that &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; minimizes is given by</source>
          <target state="translated">Функция потерь, &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; &lt;/a&gt; минимизирует HuberRegressor, определяется выражением</target>
        </trans-unit>
        <trans-unit id="47dc1dfa051244f9df37eb81c616d6773441e3ed" translate="yes" xml:space="preserve">
          <source>The loss function to be used. Defaults to &amp;lsquo;hinge&amp;rsquo;, which gives a linear SVM.</source>
          <target state="translated">Используемая функция потерь. По умолчанию - &amp;laquo;шарнир&amp;raquo;, что дает линейный SVM.</target>
        </trans-unit>
        <trans-unit id="ced89f4970549dd56e97e03e89e06fddefc0d81d" translate="yes" xml:space="preserve">
          <source>The loss function to be used. The possible values are &amp;lsquo;squared_loss&amp;rsquo;, &amp;lsquo;huber&amp;rsquo;, &amp;lsquo;epsilon_insensitive&amp;rsquo;, or &amp;lsquo;squared_epsilon_insensitive&amp;rsquo;</source>
          <target state="translated">Используемая функция потерь. Возможные значения: squared_loss, huber, epsilon_insensitive или squared_epsilon_insensitive.</target>
        </trans-unit>
        <trans-unit id="dcd8a12c459702396e7eec22715d06aed2aee153" translate="yes" xml:space="preserve">
          <source>The loss function to be used: epsilon_insensitive: equivalent to PA-I in the reference paper. squared_epsilon_insensitive: equivalent to PA-II in the reference paper.</source>
          <target state="translated">Используемая функция потерь:epsilon_insensitive:эквивалент PA-I в справочной бумаге.squared_epsilon_insensitive:эквивалент PA-II в справочной бумаге.</target>
        </trans-unit>
        <trans-unit id="4c1d6cfb55920bc5e055d28ac3a6b6a90335ca56" translate="yes" xml:space="preserve">
          <source>The loss function to be used: hinge: equivalent to PA-I in the reference paper. squared_hinge: equivalent to PA-II in the reference paper.</source>
          <target state="translated">Используемая функция потери:шарнир:эквивалент PA-I в справочнике.squared_hinge:эквивалент PA-II в справочнике.</target>
        </trans-unit>
        <trans-unit id="aaa6add3e7cf1ec084105f029a9e3050a4d18bde" translate="yes" xml:space="preserve">
          <source>The loss function to use in the boosting process. &amp;lsquo;binary_crossentropy&amp;rsquo; (also known as logistic loss) is used for binary classification and generalizes to &amp;lsquo;categorical_crossentropy&amp;rsquo; for multiclass classification. &amp;lsquo;auto&amp;rsquo; will automatically choose either loss depending on the nature of the problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d058a2ad82a18d6b6a9ed5c1f1cacf9ddbfdb363" translate="yes" xml:space="preserve">
          <source>The loss function to use in the boosting process. Note that the &amp;ldquo;least squares&amp;rdquo; and &amp;ldquo;poisson&amp;rdquo; losses actually implement &amp;ldquo;half least squares loss&amp;rdquo; and &amp;ldquo;half poisson deviance&amp;rdquo; to simplify the computation of the gradient. Furthermore, &amp;ldquo;poisson&amp;rdquo; loss internally uses a log-link and requires &lt;code&gt;y &amp;gt;= 0&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efb9498c0013e0aa10110f406847617e3f7359e7" translate="yes" xml:space="preserve">
          <source>The loss function to use when updating the weights after each boosting iteration.</source>
          <target state="translated">Функция потерь,используемая при обновлении весов после каждой ускоряющей итерации.</target>
        </trans-unit>
        <trans-unit id="76e41cb6fdfbaf660e2380953e681777b0e6378c" translate="yes" xml:space="preserve">
          <source>The loss function used is binomial deviance. Regularization via shrinkage (&lt;code&gt;learning_rate &amp;lt; 1.0&lt;/code&gt;) improves performance considerably. In combination with shrinkage, stochastic gradient boosting (&lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;) can produce more accurate models by reducing the variance via bagging. Subsampling without shrinkage usually does poorly. Another strategy to reduce the variance is by subsampling the features analogous to the random splits in Random Forests (via the &lt;code&gt;max_features&lt;/code&gt; parameter).</source>
          <target state="translated">Используемая функция потерь - это биномиальное отклонение. Регуляризация за счет сжатия (скорость &lt;code&gt;learning_rate &amp;lt; 1.0&lt;/code&gt; ) значительно улучшает производительность. В сочетании с усадкой повышение стохастического градиента ( &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ) может создавать более точные модели за счет уменьшения дисперсии за счет упаковки в мешки. Подвыборка без усадки обычно не справляется. Другая стратегия уменьшения дисперсии - это субдискретизация признаков, аналогичных случайным разбиениям в случайных лесах (через параметр &lt;code&gt;max_features&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="b776e738f1fc829ad5cd97ce27a8c60ba5e6ea09" translate="yes" xml:space="preserve">
          <source>The low rank part of the profile can be considered the structured signal part of the data while the tail can be considered the noisy part of the data that cannot be summarized by a low number of linear components (singular vectors).</source>
          <target state="translated">Низкая ранговая часть профиля может рассматриваться как структурированная сигнальная часть данных,в то время как хвост можно считать шумной частью данных,которая не может быть обобщена небольшим количеством линейных компонентов (сингулярных векторов).</target>
        </trans-unit>
        <trans-unit id="798401f91692e498e70c4cd9edead7945caa2484" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;alpha&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;alpha&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d36bb18704838afeb9c91e3cf29995f34fe370d6" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;gamma&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;gamma&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="05c76bb31dceb610d87492d4b267252a46764fae" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;length_scale&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;length_scale&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="971e4cf6ca3d178a182a1d45d26bbec9249f02e4" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;noise_level&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;noise_level&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f18d5554a9b373b29b2cfd43681990a3c136384e" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;periodicity&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;periodicity&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c4988467c8a93656299039dfe058cd67baf3941" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &amp;lsquo;sigma_0&amp;rsquo;. If set to &amp;ldquo;fixed&amp;rdquo;, &amp;lsquo;sigma_0&amp;rsquo; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb2363bfa3c4e13746c6b4233da08b1f95f83117" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on &lt;code&gt;constant_value&lt;/code&gt;. If set to &amp;ldquo;fixed&amp;rdquo;, &lt;code&gt;constant_value&lt;/code&gt; cannot be changed during hyperparameter tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eab337b7facddd1f9b82eece11282a55e0039c48" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on alpha</source>
          <target state="translated">Нижняя и верхняя границы на альфа</target>
        </trans-unit>
        <trans-unit id="59acfd562a002dfced1122413eab7f832a55dd1c" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on constant_value</source>
          <target state="translated">Нижняя и верхняя граница по значению константы_значения</target>
        </trans-unit>
        <trans-unit id="3a719a94ceaa10893529e6c7cb2929f1cad3fed1" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on gamma</source>
          <target state="translated">Нижняя и верхняя границы по гамма</target>
        </trans-unit>
        <trans-unit id="1ed15fdef2e92d07e56ad7fd40f1816e9ce5774a" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on l</source>
          <target state="translated">Нижняя и верхняя границы на l</target>
        </trans-unit>
        <trans-unit id="5a4d3b39beb7cd8132b2abe44c4adfccffd03b85" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on length_scale</source>
          <target state="translated">Нижняя и верхняя границы по шкале length_scale</target>
        </trans-unit>
        <trans-unit id="23389af6ff1a664526029d031ba30d8bce5de030" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on noise_level</source>
          <target state="translated">Нижняя и верхняя границы на уровне noise_level</target>
        </trans-unit>
        <trans-unit id="5d396b2f8516f35fa726d028e889486242bc7cef" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on periodicity</source>
          <target state="translated">Нижняя и верхняя граница по периодичности</target>
        </trans-unit>
        <trans-unit id="ca7705b5107aa6db64b47bb244d2b0d4033a135a" translate="yes" xml:space="preserve">
          <source>The lower and upper bound on the parameter. If n_elements&amp;gt;1, a pair of 1d array with n_elements each may be given alternatively. If the string &amp;ldquo;fixed&amp;rdquo; is passed as bounds, the hyperparameter&amp;rsquo;s value cannot be changed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67f0743ba9ff76a5a36032511baa5e62618c04ec" translate="yes" xml:space="preserve">
          <source>The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n &amp;lt;= n &amp;lt;= max_n will be used.</source>
          <target state="translated">Нижняя и верхняя граница диапазона значений n для извлекаемых различных n-граммов. Будут использоваться все значения n, такие что min_n &amp;lt;= n &amp;lt;= max_n.</target>
        </trans-unit>
        <trans-unit id="1a06e2593892f38e2c7f98d2aaf16f88ee8f121a" translate="yes" xml:space="preserve">
          <source>The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n &amp;lt;= n &amp;lt;= max_n will be used. For example an &lt;code&gt;ngram_range&lt;/code&gt; of &lt;code&gt;(1, 1)&lt;/code&gt; means only unigrams, &lt;code&gt;(1, 2)&lt;/code&gt; means unigrams and bigrams, and &lt;code&gt;(2, 2)&lt;/code&gt; means only bigrams. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfc6e4d4438c9aec5ef09350cb9a99015ebb32f0" translate="yes" xml:space="preserve">
          <source>The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n &amp;lt;= n &amp;lt;= max_n will be used. For example an &lt;code&gt;ngram_range&lt;/code&gt; of &lt;code&gt;(1, 1)&lt;/code&gt; means only unigrams, &lt;code&gt;(1, 2)&lt;/code&gt; means unigrams and bigrams, and &lt;code&gt;(2, 2)&lt;/code&gt; means only bigrams. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cf3abbfa7f1a3041db626cf750d4ae3ee4a5f71" translate="yes" xml:space="preserve">
          <source>The lower and upper percentile used create the extreme values for the &lt;code&gt;grid&lt;/code&gt;. Only if &lt;code&gt;X&lt;/code&gt; is not None.</source>
          <target state="translated">Используемые нижний и верхний процентили создают крайние значения для &lt;code&gt;grid&lt;/code&gt; . Только если &lt;code&gt;X&lt;/code&gt; не равно None.</target>
        </trans-unit>
        <trans-unit id="ff88012ee3d2491153687a1e07b6eefe04629c89" translate="yes" xml:space="preserve">
          <source>The lower and upper percentile used to create the extreme values for the PDP axes.</source>
          <target state="translated">Нижний и верхний процентиль используются для создания экстремальных значений для осей PDP.</target>
        </trans-unit>
        <trans-unit id="8e5bebe8622375d11e17f863f40a564811e9afd3" translate="yes" xml:space="preserve">
          <source>The lower and upper percentile used to create the extreme values for the PDP axes. Must be in [0, 1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9186aa58b7ce14e687d5b2e114470d0ce75e6d07" translate="yes" xml:space="preserve">
          <source>The lower and upper percentile used to create the extreme values for the grid. Must be in [0, 1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca509231087e3737e2d90c6b71a37c419327789b" translate="yes" xml:space="preserve">
          <source>The lower left figure plots the pointwise decomposition of the expected mean squared error of a single decision tree. It confirms that the bias term (in blue) is low while the variance is large (in green). It also illustrates the noise part of the error which, as expected, appears to be constant and around &lt;code&gt;0.01&lt;/code&gt;.</source>
          <target state="translated">На нижнем левом рисунке показано точечное разложение ожидаемой среднеквадратичной ошибки одного дерева решений. Это подтверждает, что член смещения (синий) низкий, а дисперсия большая (зеленый). Он также показывает шумовую часть ошибки, которая, как и ожидалось, оказывается постоянной и составляет около &lt;code&gt;0.01&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="caf1b50ddc9e3b679e122c659dff7510d4ed2966" translate="yes" xml:space="preserve">
          <source>The lower the better.</source>
          <target state="translated">Чем ниже,тем лучше.</target>
        </trans-unit>
        <trans-unit id="71c561a637b01dde1b3c6166ce3bd23db956f72f" translate="yes" xml:space="preserve">
          <source>The machine-learning pipeline</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bfd900c27bac872165454194e9ba0284baa1f3aa" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems.</source>
          <target state="translated">Машинная регуляризация точности при расчете диагональных факторов Холесского.Увеличить это для очень плохо обусловленных систем.</target>
        </trans-unit>
        <trans-unit id="d9100545597c68bda47e361ae3fa5acd8ebd846b" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. By default, &lt;code&gt;np.finfo(np.float).eps&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48832baaa50854fed8a3f45f6240f92c4370d802" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Default is &lt;code&gt;np.finfo(np.float64).eps&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69abd1713b39f884bea4ffeed0d502e131117e74" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the &amp;lsquo;tol&amp;rsquo; parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</source>
          <target state="translated">Регуляризация машинной точности при вычислении диагональных множителей Холецкого. Увеличьте это значение для систем с очень плохим состоянием. В отличие от параметра 'tol' в некоторых алгоритмах, основанных на итеративной оптимизации, этот параметр не контролирует допуск оптимизации.</target>
        </trans-unit>
        <trans-unit id="03f1e7333f5d863384674ba69d2200c51c214771" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the &lt;code&gt;tol&lt;/code&gt; parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</source>
          <target state="translated">Регуляризация машинной точности при вычислении диагональных множителей Холецкого. Увеличьте это значение для систем с очень плохим состоянием. В отличие от параметра &lt;code&gt;tol&lt;/code&gt; в некоторых алгоритмах, основанных на итеративной оптимизации, этот параметр не управляет допуском оптимизации.</target>
        </trans-unit>
        <trans-unit id="638a11bb66c553576b68621fdefa92568dded5ac" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the &lt;code&gt;tol&lt;/code&gt; parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization. By default, &lt;code&gt;np.finfo(np.float).eps&lt;/code&gt; is used</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a355ae348914d14284e933a2a39b838c82d13102" translate="yes" xml:space="preserve">
          <source>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the &lt;code&gt;tol&lt;/code&gt; parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization. By default, &lt;code&gt;np.finfo(np.float).eps&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="686cc4307ca584641912f9ca8288a53bb10ce6de" translate="yes" xml:space="preserve">
          <source>The main advantage for Factor Analysis over &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is that it can model the variance in every direction of the input space independently (heteroscedastic noise):</source>
          <target state="translated">Основное преимущество факторного анализа перед &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; заключается в том, что он может независимо моделировать дисперсию во всех направлениях входного пространства (гетероскедастический шум):</target>
        </trans-unit>
        <trans-unit id="c6108525766abe52c974030991b5e8a7ddcb6e28" translate="yes" xml:space="preserve">
          <source>The main difficulty in learning Gaussian mixture models from unlabeled data is that it is one usually doesn&amp;rsquo;t know which points came from which latent component (if one has access to this information it gets very easy to fit a separate Gaussian distribution to each set of points). &lt;a href=&quot;https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm&quot;&gt;Expectation-maximization&lt;/a&gt; is a well-founded statistical algorithm to get around this problem by an iterative process. First one assumes random components (randomly centered on data points, learned from k-means, or even just normally distributed around the origin) and computes for each point a probability of being generated by each component of the model. Then, one tweaks the parameters to maximize the likelihood of the data given those assignments. Repeating this process is guaranteed to always converge to a local optimum.</source>
          <target state="translated">Основная трудность в изучении моделей гауссовой смеси на основе немаркированных данных заключается в том, что обычно не известно, какие точки были получены из какого скрытого компонента (если у кого-то есть доступ к этой информации, становится очень легко подогнать отдельное гауссово распределение для каждого набора точки). &lt;a href=&quot;https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm&quot;&gt;Максимальное ожидание&lt;/a&gt; - это хорошо обоснованный статистический алгоритм, позволяющий обойти эту проблему с помощью итеративного процесса. Первый предполагает случайные компоненты (случайно центрированные по точкам данных, полученные из k-средних или даже просто нормально распределенные вокруг начала координат) и вычисляет для каждой точки вероятность быть сгенерированной каждым компонентом модели. Затем можно настроить параметры, чтобы максимизировать вероятность данных с учетом этих назначений. Повторение этого процесса гарантирует всегда схождение к локальному оптимуму.</target>
        </trans-unit>
        <trans-unit id="d2139f3f89c20ed8a9cf480b63f0750e12fef92b" translate="yes" xml:space="preserve">
          <source>The main documentation. This contains an in-depth description of all algorithms and how to apply them.</source>
          <target state="translated">Основная документация.Она содержит подробное описание всех алгоритмов и способы их применения.</target>
        </trans-unit>
        <trans-unit id="5f94da6f46e5f5e5d800fbb67f1c2ae40caf9c89" translate="yes" xml:space="preserve">
          <source>The main drawback of Affinity Propagation is its complexity. The algorithm has a time complexity of the order \(O(N^2 T)\), where \(N\) is the number of samples and \(T\) is the number of iterations until convergence. Further, the memory complexity is of the order \(O(N^2)\) if a dense similarity matrix is used, but reducible if a sparse similarity matrix is used. This makes Affinity Propagation most appropriate for small to medium sized datasets.</source>
          <target state="translated">Главным недостатком Affinity Propagation является его сложность.Алгоритм имеет временную сложность порядка \(O(N^2 T)\),где \(N\)-количество отсчетов,а \(T\)-количество итераций до сходимости.Далее,сложность памяти имеет порядок \(O(N^2)\),если используется плотная матрица сходства,но сводится к минимуму,если используется разреженная матрица сходства.Это делает Affinity Propagation наиболее подходящим для наборов данных малого и среднего размера.</target>
        </trans-unit>
        <trans-unit id="f23633268affa3b7ac5da4b687edb4096985bac5" translate="yes" xml:space="preserve">
          <source>The main factors that influence the prediction latency are</source>
          <target state="translated">Основными факторами,влияющими на латентность прогноза,являются</target>
        </trans-unit>
        <trans-unit id="26167f635fda3c2035f2a73e215b9329a59f7a43" translate="yes" xml:space="preserve">
          <source>The main observations to make are:</source>
          <target state="translated">Основные замечания:</target>
        </trans-unit>
        <trans-unit id="36a91e6ee1a9ee310e3b9c8a52ba666f014296cb" translate="yes" xml:space="preserve">
          <source>The main parameters to adjust when using these methods is &lt;code&gt;n_estimators&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt;. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are &lt;code&gt;max_features=None&lt;/code&gt; (always considering all features instead of a random subset) for regression problems, and &lt;code&gt;max_features=&quot;sqrt&quot;&lt;/code&gt; (using a random subset of size &lt;code&gt;sqrt(n_features)&lt;/code&gt;) for classification tasks (where &lt;code&gt;n_features&lt;/code&gt; is the number of features in the data). Good results are often achieved when setting &lt;code&gt;max_depth=None&lt;/code&gt; in combination with &lt;code&gt;min_samples_split=2&lt;/code&gt; (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. The best parameter values should always be cross-validated. In addition, note that in random forests, bootstrap samples are used by default (&lt;code&gt;bootstrap=True&lt;/code&gt;) while the default strategy for extra-trees is to use the whole dataset (&lt;code&gt;bootstrap=False&lt;/code&gt;). When using bootstrap sampling the generalization accuracy can be estimated on the left out or out-of-bag samples. This can be enabled by setting &lt;code&gt;oob_score=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5b8962f0fe90f98d375c2c689eb4ed0da37d3b3" translate="yes" xml:space="preserve">
          <source>The main parameters to adjust when using these methods is &lt;code&gt;n_estimators&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt;. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are &lt;code&gt;max_features=n_features&lt;/code&gt; for regression problems, and &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; for classification tasks (where &lt;code&gt;n_features&lt;/code&gt; is the number of features in the data). Good results are often achieved when setting &lt;code&gt;max_depth=None&lt;/code&gt; in combination with &lt;code&gt;min_samples_split=2&lt;/code&gt; (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. The best parameter values should always be cross-validated. In addition, note that in random forests, bootstrap samples are used by default (&lt;code&gt;bootstrap=True&lt;/code&gt;) while the default strategy for extra-trees is to use the whole dataset (&lt;code&gt;bootstrap=False&lt;/code&gt;). When using bootstrap sampling the generalization accuracy can be estimated on the left out or out-of-bag samples. This can be enabled by setting &lt;code&gt;oob_score=True&lt;/code&gt;.</source>
          <target state="translated">Основные параметры, которые необходимо настроить при использовании этих методов, - это &lt;code&gt;n_estimators&lt;/code&gt; и &lt;code&gt;max_features&lt;/code&gt; . Первое - это количество деревьев в лесу. Чем больше, тем лучше, но также тем дольше потребуется вычисление. Кроме того, обратите внимание, что после критического числа деревьев результаты перестанут улучшаться. Последний - это размер случайных подмножеств функций, которые следует учитывать при разделении узла. Чем ниже, тем больше сокращение дисперсии, но также и увеличение смещения. Эмпирические хорошие значения по умолчанию: &lt;code&gt;max_features=n_features&lt;/code&gt; для задач регрессии и &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; для задач классификации (где &lt;code&gt;n_features&lt;/code&gt; количество функций в данных). Хорошие результаты часто достигаются при установке &lt;code&gt;max_depth=None&lt;/code&gt; в сочетании с &lt;code&gt;min_samples_split=2&lt;/code&gt; (т.е. при полной разработке деревьев). Однако имейте в виду, что эти значения обычно не оптимальны и могут привести к моделям, потребляющим много оперативной памяти. Лучшие значения параметров всегда должны подвергаться перекрестной проверке. Кроме того, обратите внимание, что в случайных лесах по умолчанию используются образцы начальной загрузки ( &lt;code&gt;bootstrap=True&lt;/code&gt; ), тогда как стратегия по умолчанию для дополнительных деревьев заключается в использовании всего набора данных ( &lt;code&gt;bootstrap=False&lt;/code&gt; ). При использовании бутстраповой выборки точность обобщения может быть оценена на выборках, не входящих в комплект. Это можно включить, установив &lt;code&gt;oob_score=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="842b51b29e297ee475304c463fec6849d760da97" translate="yes" xml:space="preserve">
          <source>The main purpose of t-SNE is visualization of high-dimensional data. Hence, it works best when the data will be embedded on two or three dimensions.</source>
          <target state="translated">Основным назначением t-SNE является визуализация объемных данных.Следовательно,она лучше всего работает,когда данные встраиваются в два или три измерения.</target>
        </trans-unit>
        <trans-unit id="85533a7e662fe3db2975f7f26edf978cd22f568d" translate="yes" xml:space="preserve">
          <source>The main theoretical result behind the efficiency of random projection is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma (quoting Wikipedia)&lt;/a&gt;:</source>
          <target state="translated">Основным теоретическим результатом эффективности случайной проекции является &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;лемма Джонсона-Линденштрауса (цитируется из Википедии)&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="c6fec5e2fce31198cf0394ae7c6624fc74feba7a" translate="yes" xml:space="preserve">
          <source>The main usage of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.kernel#sklearn.gaussian_process.kernels.Kernel&quot;&gt;&lt;code&gt;Kernel&lt;/code&gt;&lt;/a&gt; is to compute the GP&amp;rsquo;s covariance between datapoints. For this, the method &lt;code&gt;__call__&lt;/code&gt; of the kernel can be called. This method can either be used to compute the &amp;ldquo;auto-covariance&amp;rdquo; of all pairs of datapoints in a 2d array X, or the &amp;ldquo;cross-covariance&amp;rdquo; of all combinations of datapoints of a 2d array X with datapoints in a 2d array Y. The following identity holds true for all kernels k (except for the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.whitekernel#sklearn.gaussian_process.kernels.WhiteKernel&quot;&gt;&lt;code&gt;WhiteKernel&lt;/code&gt;&lt;/a&gt;): &lt;code&gt;k(X) == K(X, Y=X)&lt;/code&gt;</source>
          <target state="translated">Основное использование &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.kernel#sklearn.gaussian_process.kernels.Kernel&quot;&gt; &lt;code&gt;Kernel&lt;/code&gt; &lt;/a&gt; - вычисление ковариации GP между точками данных. Для этого можно вызвать метод &lt;code&gt;__call__&lt;/code&gt; . Этот метод можно использовать либо для вычисления &amp;laquo;автоковариации&amp;raquo; всех пар точек данных в 2-м массиве X, либо &amp;laquo;кросс-ковариации&amp;raquo; всех комбинаций точек данных 2-го массива X с точками данных в 2-м массиве Y. Для всех ядер k (кроме &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.whitekernel#sklearn.gaussian_process.kernels.WhiteKernel&quot;&gt; &lt;code&gt;WhiteKernel&lt;/code&gt; &lt;/a&gt; ) выполняется следующее тождество : &lt;code&gt;k(X) == K(X, Y=X)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4418da68cc8e1590c7a6e820d42fa84b7f1fff49" translate="yes" xml:space="preserve">
          <source>The main use-case of the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.whitekernel#sklearn.gaussian_process.kernels.WhiteKernel&quot;&gt;&lt;code&gt;WhiteKernel&lt;/code&gt;&lt;/a&gt; kernel is as part of a sum-kernel where it explains the noise-component of the signal. Tuning its parameter \(noise\_level\) corresponds to estimating the noise-level. It is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54123ac391766adafa62d20ad77d558f0edc6a11" translate="yes" xml:space="preserve">
          <source>The main use-case of the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.whitekernel#sklearn.gaussian_process.kernels.WhiteKernel&quot;&gt;&lt;code&gt;WhiteKernel&lt;/code&gt;&lt;/a&gt; kernel is as part of a sum-kernel where it explains the noise-component of the signal. Tuning its parameter \(noise\_level\) corresponds to estimating the noise-level. It is defined as:e</source>
          <target state="translated">Основной вариант &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.whitekernel#sklearn.gaussian_process.kernels.WhiteKernel&quot;&gt; &lt;code&gt;WhiteKernel&lt;/code&gt; &lt;/a&gt; ядра WhiteKernel - это часть ядра суммы, где оно объясняет шумовую составляющую сигнала. Настройка его параметра \ (noise \ _level \) соответствует оценке уровня шума. Он определяется как: e</target>
        </trans-unit>
        <trans-unit id="9e4c246aa3bcb240193dfa5bc5ce95df373e50e0" translate="yes" xml:space="preserve">
          <source>The main use-case of this kernel is as part of a sum-kernel where it explains the noise of the signal as independently and identically normally-distributed. The parameter noise_level equals the variance of this noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b785a852cf47604fe35c8c001dbd6b426026b75" translate="yes" xml:space="preserve">
          <source>The main use-case of this kernel is as part of a sum-kernel where it explains the noise-component of the signal. Tuning its parameter corresponds to estimating the noise-level.</source>
          <target state="translated">Основной вариант использования этого ядра как части суммарного ядра,где оно объясняет шумовую составляющую сигнала.Настройка его параметра соответствует оценке уровня шума.</target>
        </trans-unit>
        <trans-unit id="b8d24bce3b0ca4f2f608d76c9973e497dd5a4966" translate="yes" xml:space="preserve">
          <source>The major advantage of SGD is its efficiency, which is basically linear in the number of training examples. If X is a matrix of size (n, p) training has a cost of \(O(k n \bar p)\), where k is the number of iterations (epochs) and \(\bar p\) is the average number of non-zero attributes per sample.</source>
          <target state="translated">Основным преимуществом SGD является его эффективность,которая в основном линейна по количеству обучающих примеров.Если X-матрица размера (n,p),то обучение имеет стоимость \(O(k n \bar p)\),где k-количество итераций (эпох),а \(\bar p\)-среднее количество ненулевых атрибутов на выборку.</target>
        </trans-unit>
        <trans-unit id="c142aa304b117907c4ec82e7c8f2e0e1debc825c" translate="yes" xml:space="preserve">
          <source>The manifold learning implementations available in scikit-learn are summarized below</source>
          <target state="translated">Ниже приводится краткое описание разнообразных методов обучения,доступных в программе &quot;наука-обучение&quot;.</target>
        </trans-unit>
        <trans-unit id="97fe69cbbfc59d33068b7f1700f458b4fb09dc06" translate="yes" xml:space="preserve">
          <source>The mapping from the value \(F_M(x_i)\) to a class or a probability is loss-dependent. For the deviance (or log-loss), the probability that \(x_i\) belongs to the positive class is modeled as \(p(y_i = 1 | x_i) = \sigma(F_M(x_i))\) where \(\sigma\) is the sigmoid function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d450abcdfe5ff938dd90f9482f51850eeea5e6fe" translate="yes" xml:space="preserve">
          <source>The mapping relies on a Monte Carlo approximation to the kernel values. The &lt;code&gt;fit&lt;/code&gt; function performs the Monte Carlo sampling, whereas the &lt;code&gt;transform&lt;/code&gt; method performs the mapping of the data. Because of the inherent randomness of the process, results may vary between different calls to the &lt;code&gt;fit&lt;/code&gt; function.</source>
          <target state="translated">Отображение основывается на приближении Монте-Карло к значениям ядра. Функция &lt;code&gt;fit&lt;/code&gt; выполняет выборку Монте-Карло, тогда как метод &lt;code&gt;transform&lt;/code&gt; выполняет отображение данных. Из-за присущей процессу случайности результаты могут различаться между разными вызовами функции &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1292a72996c3834d41499b1c7abdc4ace6de6204" translate="yes" xml:space="preserve">
          <source>The mask of selected features.</source>
          <target state="translated">Маска выбранных функций.</target>
        </trans-unit>
        <trans-unit id="c45c8ea0546b1c79f5dc6ae49b8b9eba3b94ab9e" translate="yes" xml:space="preserve">
          <source>The mathematical formulation is the following:</source>
          <target state="translated">Математическая формулировка является следующей:</target>
        </trans-unit>
        <trans-unit id="d7ffadc6e201c4cc579f6014a4ba6a553d3e6d97" translate="yes" xml:space="preserve">
          <source>The matrix</source>
          <target state="translated">Матрица</target>
        </trans-unit>
        <trans-unit id="2cec1c9e3ed6a74b7dbd8e5442d20aacdeb523d2" translate="yes" xml:space="preserve">
          <source>The matrix dimension.</source>
          <target state="translated">Размер матрицы.</target>
        </trans-unit>
        <trans-unit id="e194b944fcebb1be4c3463284dee201bd8108680" translate="yes" xml:space="preserve">
          <source>The matrix inverse of the covariance matrix, often called the precision matrix, is proportional to the partial correlation matrix. It gives the partial independence relationship. In other words, if two features are independent conditionally on the others, the corresponding coefficient in the precision matrix will be zero. This is why it makes sense to estimate a sparse precision matrix: the estimation of the covariance matrix is better conditioned by learning independence relations from the data. This is known as &lt;em&gt;covariance selection&lt;/em&gt;.</source>
          <target state="translated">Матрица, обратная ковариационной матрице, часто называемая матрицей точности, пропорциональна матрице частичной корреляции. Это дает частичную независимость отношениям. Другими словами, если два признака независимы друг от друга условно, соответствующий коэффициент в матрице точности будет равен нулю. Вот почему имеет смысл оценивать матрицу разреженной точности: оценка ковариационной матрицы лучше обусловлена ​​изучением отношений независимости от данных. Это называется &lt;em&gt;ковариационным отбором&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="e578a80d83c508825e0e59f2ea21cfd3dab91a77" translate="yes" xml:space="preserve">
          <source>The matrix of features, where NP is the number of polynomial features generated from the combination of inputs.</source>
          <target state="translated">Матрица признаков,где NP-это количество полиномиальных признаков,порожденных комбинацией входов.</target>
        </trans-unit>
        <trans-unit id="64f7c7c3f44e0d1f1fa6c715782355e1f1d2054c" translate="yes" xml:space="preserve">
          <source>The matrix.</source>
          <target state="translated">Матрица.</target>
        </trans-unit>
        <trans-unit id="9e68c52b3ee0713ce10cfb911b2833fc7e9a1df1" translate="yes" xml:space="preserve">
          <source>The maximal number of iterations for the solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3c27fa93df86412f11493765849dd6aeb05082d" translate="yes" xml:space="preserve">
          <source>The maximum depth of each tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.</source>
          <target state="translated">Максимальная глубина каждого дерева.Если None,то узлы расширяются до тех пор,пока все листья не станут чистыми или пока все листья не будут содержать меньше отсчетов min_samples_split.</target>
        </trans-unit>
        <trans-unit id="826fe580f0140d0a1b7e9876f557d09be8bbd041" translate="yes" xml:space="preserve">
          <source>The maximum depth of each tree. The depth of a tree is the number of edges to go from the root to the deepest leaf. Depth isn&amp;rsquo;t constrained by default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52e0ef4a9206a897434b4d55c59a4824cb11d988" translate="yes" xml:space="preserve">
          <source>The maximum depth of the representation. If None, the tree is fully generated.</source>
          <target state="translated">Максимальная глубина представления.Если Нет,то дерево будет полностью сгенерировано.</target>
        </trans-unit>
        <trans-unit id="f5406d9d68ce630037091594fec01e2950e41c42" translate="yes" xml:space="preserve">
          <source>The maximum depth of the tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0ae7481b9fb370fd4191031ea9f70e91832a43a" translate="yes" xml:space="preserve">
          <source>The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.</source>
          <target state="translated">Максимальная глубина дерева.Если None,то узлы расширяются до тех пор,пока все листья не станут чистыми или пока все листья не будут содержать меньше отсчетов min_samples_split.</target>
        </trans-unit>
        <trans-unit id="a55adc01e4f423a3103fea57c0a2cfa41d8471f9" translate="yes" xml:space="preserve">
          <source>The maximum distance between two samples for one to be considered as in the neighborhood of the other. By default it assumes the same value as &lt;code&gt;max_eps&lt;/code&gt;. Used only when &lt;code&gt;cluster_method='dbscan'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2785d22ac4386c9273ddac709630eaca73ae74f0" translate="yes" xml:space="preserve">
          <source>The maximum distance between two samples for one to be considered as in the neighborhood of the other. Default value of &lt;code&gt;np.inf&lt;/code&gt; will identify clusters across all scales; reducing &lt;code&gt;max_eps&lt;/code&gt; will result in shorter run times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86a132d622f603d09919856c8916a271668d069a" translate="yes" xml:space="preserve">
          <source>The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0cec94a1183be1885b8ca965cd0a310a0d6ef03e" translate="yes" xml:space="preserve">
          <source>The maximum distance between two samples for them to be considered as in the same neighborhood.</source>
          <target state="translated">Максимальное расстояние между двумя образцами,чтобы их можно было считать находящимися в одном и том же районе.</target>
        </trans-unit>
        <trans-unit id="2d03a3cd1f8dea91e35b793f66d9300ac80fe58d" translate="yes" xml:space="preserve">
          <source>The maximum number of bins to use for non-missing values. Before training, each feature of the input array &lt;code&gt;X&lt;/code&gt; is binned into integer-valued bins, which allows for a much faster training stage. Features with a small number of unique values may use less than &lt;code&gt;max_bins&lt;/code&gt; bins. In addition to the &lt;code&gt;max_bins&lt;/code&gt; bins, one more bin is always reserved for missing values. Must be no larger than 255.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78f8fd023fb60eb04dc691f81a2e17712a336e66" translate="yes" xml:space="preserve">
          <source>The maximum number of columns in the grid plot. Only active when &lt;code&gt;ax&lt;/code&gt; is a single axes or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78e415aabcf40a1b66551486961973263113520d" translate="yes" xml:space="preserve">
          <source>The maximum number of columns in the grid plot. Only active when &lt;code&gt;ax&lt;/code&gt; is a single axis or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72469eac4bccf834885ed51dab58c805d8cdc971" translate="yes" xml:space="preserve">
          <source>The maximum number of concurrently running jobs, such as the number of Python worker processes when backend=&amp;rdquo;multiprocessing&amp;rdquo; or the size of the thread-pool when backend=&amp;rdquo;threading&amp;rdquo;. If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one are used. None is a marker for &amp;lsquo;unset&amp;rsquo; that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a parallel_backend context manager that sets another value for n_jobs.</source>
          <target state="translated">Максимальное количество одновременно выполняемых заданий, например количество рабочих процессов Python, когда backend = &amp;laquo;multiprocessing&amp;raquo;, или размер пула потоков, когда backend = &amp;laquo;threading&amp;raquo;. Если -1, используются все процессоры. Если задано 1, код параллельных вычислений не используется вообще, что полезно для отладки. Для n_jobs ниже -1 используются (n_cpus + 1 + n_jobs). Таким образом, для n_jobs = -2 используются все ЦП, кроме одного. None - это маркер для &amp;laquo;unset&amp;raquo;, который будет интерпретироваться как n_jobs = 1 (последовательное выполнение), если вызов не выполняется под управлением контекстного менеджера parallel_backend, который устанавливает другое значение для n_jobs.</target>
        </trans-unit>
        <trans-unit id="d68dbcc29192b28b1c0e16950a4955da0229e9e9" translate="yes" xml:space="preserve">
          <source>The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.</source>
          <target state="translated">Максимальное количество оценочных значений,на котором завершение повышения.В случае идеальной подгонки процедура обучения прекращается рано.</target>
        </trans-unit>
        <trans-unit id="0ace226674121a7119418c464f4452694b61318d" translate="yes" xml:space="preserve">
          <source>The maximum number of features selected scoring above &lt;code&gt;threshold&lt;/code&gt;. To disable &lt;code&gt;threshold&lt;/code&gt; and only select based on &lt;code&gt;max_features&lt;/code&gt;, set &lt;code&gt;threshold=-np.inf&lt;/code&gt;.</source>
          <target state="translated">Максимальное количество выбранных функций, превышающих &lt;code&gt;threshold&lt;/code&gt; . Чтобы отключить &lt;code&gt;threshold&lt;/code&gt; и выбирать только на основе &lt;code&gt;max_features&lt;/code&gt; , установите &lt;code&gt;threshold=-np.inf&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="305b61ba0832c48af4c31e220047663d92a85155" translate="yes" xml:space="preserve">
          <source>The maximum number of features to select. To only select based on &lt;code&gt;max_features&lt;/code&gt;, set &lt;code&gt;threshold=-np.inf&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1360fbfbf92ec231e131ca0c0a387fb9e5b6a69f" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations</source>
          <target state="translated">Максимальное количество итераций</target>
        </trans-unit>
        <trans-unit id="07cf3627f06a0c97fd8b5fd02bbb00e02fc4d154" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations in Newton&amp;rsquo;s method for approximating the posterior during predict. Smaller values will reduce computation time at the cost of worse results.</source>
          <target state="translated">Максимальное количество итераций в методе Ньютона для аппроксимации апостериорного значения при прогнозировании. Меньшие значения сократят время вычислений за счет худших результатов.</target>
        </trans-unit>
        <trans-unit id="5ecb214f49e2d4dbf3814aaa5686d1fc9fb18e01" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations is usually high enough and does not need any tuning. The optimization consists of two phases: the early exaggeration phase and the final optimization. During early exaggeration the joint probabilities in the original space will be artificially increased by multiplication with a given factor. Larger factors result in larger gaps between natural clusters in the data. If the factor is too high, the KL divergence could increase during this phase. Usually it does not have to be tuned. A critical parameter is the learning rate. If it is too low gradient descent will get stuck in a bad local minimum. If it is too high the KL divergence will increase during optimization. More tips can be found in Laurens van der Maaten&amp;rsquo;s FAQ (see references). The last parameter, angle, is a tradeoff between performance and accuracy. Larger angles imply that we can approximate larger regions by a single point, leading to better speed but less accurate results.</source>
          <target state="translated">Максимальное количество итераций обычно достаточно велико и не требует настройки. Оптимизация состоит из двух этапов: этапа раннего преувеличения и заключительной оптимизации. Во время раннего преувеличения совместные вероятности в исходном пространстве будут искусственно увеличены путем умножения на заданный коэффициент. Более крупные факторы приводят к большим разрывам между естественными кластерами в данных. Если коэффициент слишком высок, расхождение KL может увеличиться на этом этапе. Обычно его не нужно настраивать. Критическим параметром является скорость обучения. Если он слишком низкий, градиентный спуск застрянет в плохом локальном минимуме. Если оно слишком велико, дивергенция KL увеличится во время оптимизации. Дополнительные советы можно найти в FAQ Лоренса ван дер Маатена (см. Ссылки). Последний параметр, угол, представляет собой компромисс между производительностью и точностью.Большие углы означают, что мы можем аппроксимировать большие области одной точкой, что приводит к более высокой скорости, но менее точным результатам.</target>
        </trans-unit>
        <trans-unit id="ae7ecafb1fbb8659823714d61be48b0de277df78" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations of the boosting process, i.e. the maximum number of trees for binary classification. For multiclass classification, &lt;code&gt;n_classes&lt;/code&gt; trees per iteration are built.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d7badc19d2ae32c74e6847ba0481766700bc0d4" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations of the boosting process, i.e. the maximum number of trees.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a263d39eeb80bbc61890473f9e4f7de61b380fb" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations to be run.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="42a16ed4baf475d1973848504fece7b7ddcdacc6" translate="yes" xml:space="preserve">
          <source>The maximum number of iterations.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="828c8485a088b2e8fca34b650a5b350287a8d14c" translate="yes" xml:space="preserve">
          <source>The maximum number of leaves for each tree. Must be strictly greater than 1. If None, there is no maximum limit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7623dada54053128bc10f5932064e15f34e6e533" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;a href=&quot;#sklearn.linear_model.PassiveAggressiveClassifier.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3d89c5f2bce98870adcd2b6143612a20116ca64" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;a href=&quot;#sklearn.linear_model.Perceptron.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcd0f20b2b6a22d8d1fd2812b58e7d3f318eed78" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;a href=&quot;#sklearn.linear_model.SGDClassifier.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="728ec87f7057b93a5bbf338c5362cf41c1855cde" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;a href=&quot;#sklearn.linear_model.SGDRegressor.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd38afe4aeee3f58ba57bcb27ec36aa15fe40a58" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06bd569f5fc7509f2f4591004e3b0ffe2a685cf9" translate="yes" xml:space="preserve">
          <source>The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the &lt;code&gt;fit&lt;/code&gt; method, and not the &lt;code&gt;partial_fit&lt;/code&gt;. Defaults to 5. Defaults to 1000 from 0.21, or if tol is not None.</source>
          <target state="translated">Максимальное количество проходов по обучающим данным (иначе говоря, эпох). Это влияет только на поведение в методе &lt;code&gt;fit&lt;/code&gt; , но не на &lt;code&gt;partial_fit&lt;/code&gt; . По умолчанию 5. Значение по умолчанию - 1000 от 0,21, или если tol не равно None.</target>
        </trans-unit>
        <trans-unit id="73890f2d8730349939758bb99469c8dd6b7e6151" translate="yes" xml:space="preserve">
          <source>The maximum number of patches per image to extract. If max_patches is a float in (0, 1), it is taken to mean a proportion of the total number of patches.</source>
          <target state="translated">Максимальное количество патчей на изображение для извлечения.Если max_patch является плавающим в (0,1),то это означает долю от общего количества патчей.</target>
        </trans-unit>
        <trans-unit id="52d2f42a039085572a1dcc0b5530d4df0b8b6859" translate="yes" xml:space="preserve">
          <source>The maximum number of patches to extract. If &lt;code&gt;max_patches&lt;/code&gt; is a float between 0 and 1, it is taken to be a proportion of the total number of patches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9914613b7b3d16fc7caab060022c123f66024339" translate="yes" xml:space="preserve">
          <source>The maximum number of patches to extract. If max_patches is a float between 0 and 1, it is taken to be a proportion of the total number of patches.</source>
          <target state="translated">Максимальное количество заплаток для извлечения.Если max_patch-плавающий между 0 и 1,то он принимается как доля от общего числа патчей.</target>
        </trans-unit>
        <trans-unit id="353b6da890fd9a7a3db82e5fc166d25d61607aa3" translate="yes" xml:space="preserve">
          <source>The maximum number of points on the path used to compute the residuals in the cross-validation</source>
          <target state="translated">Максимальное количество точек на пути,используемое для расчета остатков при перекрестном тестировании</target>
        </trans-unit>
        <trans-unit id="36c1ffc6cd6501f0a66093a4a420f28ce4311341" translate="yes" xml:space="preserve">
          <source>The maximum valid value the parameter can take. If None (default) it is implied that the parameter does not have an upper bound.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c53181fb6c1656f1967e529a2fe72fd9bc29ff60" translate="yes" xml:space="preserve">
          <source>The mean and the empirical covariance of the full dataset, which break down as soon as there are outliers in the data set</source>
          <target state="translated">Среднее значение и эмпирическая ковариация полного набора данных,которые ломаются,как только в наборе данных появляются отклонения.</target>
        </trans-unit>
        <trans-unit id="f962fad68fff332002b42ee3dcc1e06f41fcfe6c" translate="yes" xml:space="preserve">
          <source>The mean and the empirical covariance of the observations that are known to be good ones. This can be considered as a &amp;ldquo;perfect&amp;rdquo; MCD estimation, so one can trust our implementation by comparing to this case.</source>
          <target state="translated">Среднее значение и эмпирическая ковариация заведомо хороших наблюдений. Это можно рассматривать как &amp;laquo;идеальную&amp;raquo; оценку MCD, так что можно доверять нашей реализации, сравнивая с этим случаем.</target>
        </trans-unit>
        <trans-unit id="24b29efa5c5ad7917d67d95c19c0b6440c20e3d8" translate="yes" xml:space="preserve">
          <source>The mean claim amount or severity (&lt;code&gt;AvgClaimAmount&lt;/code&gt;) can be empirically shown to follow approximately a Gamma distribution. We fit a GLM model for the severity with the same features as the frequency model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f98043dc9f229ba1c70dcb8021abddb5d793d8af" translate="yes" xml:space="preserve">
          <source>The mean of each mixture component.</source>
          <target state="translated">Среднее значение каждого компонента смеси.</target>
        </trans-unit>
        <trans-unit id="05329e8678ffdabb505c75140f9a49322a5129f1" translate="yes" xml:space="preserve">
          <source>The mean of the multi-dimensional normal distribution. If None then use the origin (0, 0, &amp;hellip;).</source>
          <target state="translated">Среднее значение многомерного нормального распределения. Если None, используйте начало координат (0, 0,&amp;hellip;).</target>
        </trans-unit>
        <trans-unit id="bde1358a0967a15325e4e7cc6fcf95bc7ef0f700" translate="yes" xml:space="preserve">
          <source>The mean over features. Only set if &lt;code&gt;self.whiten&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3598a929d1a64528ce62560f1aa02f9fb9981b30" translate="yes" xml:space="preserve">
          <source>The mean predicted probability in each bin.</source>
          <target state="translated">Средняя предсказанная вероятность в каждом мусорном контейнере.</target>
        </trans-unit>
        <trans-unit id="8aaf5602eb2242bddc9912d47746326b31b0a1d5" translate="yes" xml:space="preserve">
          <source>The mean score and the 95% confidence interval of the score estimate are hence given by:</source>
          <target state="translated">Средний балл и 95% доверительный интервал оценки баллов,таким образом,даны:</target>
        </trans-unit>
        <trans-unit id="fb645170ce6174deae19b9d9f752a59168ce3c91" translate="yes" xml:space="preserve">
          <source>The mean squared error (&lt;code&gt;power=0&lt;/code&gt;) is very sensitive to the prediction difference of the second point,:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94d27e1df24bf9a05c82ae625a1197b415bc3fdc" translate="yes" xml:space="preserve">
          <source>The mean value for each feature in the training set. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_mean=False&lt;/code&gt;.</source>
          <target state="translated">Среднее значение для каждой функции в обучающем наборе. Равно &lt;code&gt;None&lt;/code&gt; , когда &lt;code&gt;with_mean=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b5e7dcb7d882c8689297cb339a998a6e74140e5f" translate="yes" xml:space="preserve">
          <source>The mean, standard error, and &amp;ldquo;worst&amp;rdquo; or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.</source>
          <target state="translated">Среднее значение, стандартная ошибка и &amp;laquo;худшее&amp;raquo; или наибольшее (среднее из трех наибольших значений) этих характеристик были вычислены для каждого изображения, в результате чего было получено 30 функций. Например, поле 3 - это средний радиус, поле 13 - радиус SE, поле 23 - худший радиус.</target>
        </trans-unit>
        <trans-unit id="8d0066f714eed86dea1c0b26b34c2da2cae60854" translate="yes" xml:space="preserve">
          <source>The mean, standard error, and &amp;ldquo;worst&amp;rdquo; or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9952f9f2a02ad0002415a0bd8b6c9bae196d7ee8" translate="yes" xml:space="preserve">
          <source>The measure of normality of an observation given a tree is the depth of the leaf containing this observation, which is equivalent to the number of splittings required to isolate this point. In case of several observations n_left in the leaf, the average path length of a n_left samples isolation tree is added.</source>
          <target state="translated">Мерой нормальности наблюдения за деревом является глубина листа,содержащего это наблюдение,которая эквивалентна количеству расщеплений,необходимых для выделения этой точки.В случае нескольких наблюдений n_left в листе добавляется средняя длина пути дерева изоляции n_left sample.</target>
        </trans-unit>
        <trans-unit id="3ff66cd9c701474c3d9f795cee9d82f5e1659bc8" translate="yes" xml:space="preserve">
          <source>The median absolute deviation to non corrupt new data is used to judge the quality of the prediction.</source>
          <target state="translated">Медианное абсолютное отклонение от некоррумпированных новых данных используется для оценки качества прогноза.</target>
        </trans-unit>
        <trans-unit id="970571bcac487854f4caea3e516e12da8ac34c22" translate="yes" xml:space="preserve">
          <source>The median value for each feature in the training set.</source>
          <target state="translated">Медианное значение для каждого элемента тренировочного набора.</target>
        </trans-unit>
        <trans-unit id="c8bf90a15bbbe280812d1ade2a9f9077adb9d41d" translate="yes" xml:space="preserve">
          <source>The memmapping mode used when loading from cache numpy arrays. See numpy.load for the meaning of the arguments.</source>
          <target state="translated">Режим мемппинга,используемый при загрузке из нумерованных массивов кэша.См.значение аргументов в файле numpy.load.</target>
        </trans-unit>
        <trans-unit id="4971ea4c8c64c5bc8a4bdd1e4563c9705f8166bf" translate="yes" xml:space="preserve">
          <source>The memmapping mode used when loading from cache numpy arrays. See numpy.load for the meaning of the arguments. By default that of the memory object is used.</source>
          <target state="translated">Режим мемппинга,используемый при загрузке из нумерованных массивов кэша.См.значение аргументов в файле numpy.load.По умолчанию используется объект памяти.</target>
        </trans-unit>
        <trans-unit id="85874f620128fa58a2e359ad1c9c828fcfd537bb" translate="yes" xml:space="preserve">
          <source>The memory footprint of randomized &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is also proportional to \(2 \cdot n_{\max} \cdot n_{\mathrm{components}}\) instead of \(n_{\max} \cdot n_{\min}\) for the exact method.</source>
          <target state="translated">Объем памяти рандомизированного &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; также пропорционален \ (2 \ cdot n _ {\ max} \ cdot n _ {\ mathrm {components}} \) вместо \ (n _ {\ max} \ cdot n _ {\ min} \) для точного метода.</target>
        </trans-unit>
        <trans-unit id="ad92e195504975d239e8efd05966b747d9d3adc0" translate="yes" xml:space="preserve">
          <source>The method assumes the inputs come from a binary classifier, and discretize the [0, 1] interval into bins.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fa2b59a5a9d6863d86f91b2a847ac2c39bc204e" translate="yes" xml:space="preserve">
          <source>The method assumes the inputs come from a binary classifier.</source>
          <target state="translated">Метод предполагает,что входы поступают от двоичного классификатора.</target>
        </trans-unit>
        <trans-unit id="ff8ec8205e374ddf520735804ecbfa39550f37bd" translate="yes" xml:space="preserve">
          <source>The method fits the model &lt;code&gt;n_init&lt;/code&gt; times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for &lt;code&gt;max_iter&lt;/code&gt; times until the change of likelihood or lower bound is less than &lt;code&gt;tol&lt;/code&gt;, otherwise, a &lt;code&gt;ConvergenceWarning&lt;/code&gt; is raised. If &lt;code&gt;warm_start&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then &lt;code&gt;n_init&lt;/code&gt; is ignored and a single initialization is performed upon the first call. Upon consecutive calls, training starts where it left off.</source>
          <target state="translated">Метод соответствует модели &lt;code&gt;n_init&lt;/code&gt; раз и устанавливает параметры, при которых модель имеет наибольшее правдоподобие или нижнюю границу. В каждом испытании метод повторяется между E-step и M-step в течение &lt;code&gt;max_iter&lt;/code&gt; раз, пока изменение вероятности или нижней границы не станет меньше, чем &lt;code&gt;tol&lt;/code&gt; , в противном случае возникает &lt;code&gt;ConvergenceWarning&lt;/code&gt; . Если &lt;code&gt;warm_start&lt;/code&gt; имеет значение &lt;code&gt;True&lt;/code&gt; , то &lt;code&gt;n_init&lt;/code&gt; игнорируется, и при первом вызове выполняется однократная инициализация. После последовательных звонков обучение начинается с того места, где оно было остановлено.</target>
        </trans-unit>
        <trans-unit id="64dcb6bda2581c1c56dbef7b8447b61db8e804dd" translate="yes" xml:space="preserve">
          <source>The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for &lt;code&gt;max_iter&lt;/code&gt; times until the change of likelihood or lower bound is less than &lt;code&gt;tol&lt;/code&gt;, otherwise, a &lt;a href=&quot;sklearn.exceptions.convergencewarning#sklearn.exceptions.ConvergenceWarning&quot;&gt;&lt;code&gt;ConvergenceWarning&lt;/code&gt;&lt;/a&gt; is raised. After fitting, it predicts the most probable label for the input data points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aeb4fb178bdd7f679ad7ab31606d57c02d18da8" translate="yes" xml:space="preserve">
          <source>The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for &lt;code&gt;max_iter&lt;/code&gt; times until the change of likelihood or lower bound is less than &lt;code&gt;tol&lt;/code&gt;, otherwise, a &lt;code&gt;ConvergenceWarning&lt;/code&gt; is raised. After fitting, it predicts the most probable label for the input data points.</source>
          <target state="translated">Метод соответствует модели n_init раз и устанавливает параметры, при которых модель имеет наибольшее правдоподобие или нижнюю границу. В каждом испытании метод повторяется между E-step и M-step в течение &lt;code&gt;max_iter&lt;/code&gt; раз, пока изменение вероятности или нижней границы не станет меньше, чем &lt;code&gt;tol&lt;/code&gt; , в противном случае возникает &lt;code&gt;ConvergenceWarning&lt;/code&gt; . После подгонки он предсказывает наиболее вероятную метку для точек входных данных.</target>
        </trans-unit>
        <trans-unit id="02e13e01ea0f52a6e082ed53d9636e409ba7f22e" translate="yes" xml:space="preserve">
          <source>The method gained popularity for initializing deep neural networks with the weights of independent RBMs. This method is known as unsupervised pre-training.</source>
          <target state="translated">Метод получил популярность для инициализации глубоких нейронных сетей с весами независимых РМР.Этот метод известен как неконтролируемая предварительная подготовка.</target>
        </trans-unit>
        <trans-unit id="867b88e44ce337abe62bbd2070ac4235fc6ec53b" translate="yes" xml:space="preserve">
          <source>The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.</source>
          <target state="translated">Метод вспомогательной векторной классификации может быть расширен для решения регрессионных задач.Этот метод называется Support Vector Regression.</target>
        </trans-unit>
        <trans-unit id="0ea5095ab7a2f7c4087eef18fc7667a5380ac2de" translate="yes" xml:space="preserve">
          <source>The method to use for calibration. Can be &amp;lsquo;sigmoid&amp;rsquo; which corresponds to Platt&amp;rsquo;s method (i.e. a logistic regression model) or &amp;lsquo;isotonic&amp;rsquo; which is a non-parametric approach. It is not advised to use isotonic calibration with too few calibration samples &lt;code&gt;(&amp;lt;&amp;lt;1000)&lt;/code&gt; since it tends to overfit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b9b2478ee76aa8f8a62d64db00bfa346a8108cd" translate="yes" xml:space="preserve">
          <source>The method to use for calibration. Can be &amp;lsquo;sigmoid&amp;rsquo; which corresponds to Platt&amp;rsquo;s method or &amp;lsquo;isotonic&amp;rsquo; which is a non-parametric approach. It is not advised to use isotonic calibration with too few calibration samples &lt;code&gt;(&amp;lt;&amp;lt;1000)&lt;/code&gt; since it tends to overfit. Use sigmoids (Platt&amp;rsquo;s calibration) in this case.</source>
          <target state="translated">Метод, используемый для калибровки. Может быть &amp;laquo;сигмовидной&amp;raquo;, что соответствует методу Платта, или &amp;laquo;изотоническим&amp;raquo;, что является непараметрическим подходом. Не рекомендуется использовать изотоническую калибровку при слишком малом количестве калибровочных образцов &lt;code&gt;(&amp;lt;&amp;lt;1000)&lt;/code&gt; , так как она имеет тенденцию к переобучению. В этом случае используйте сигмоиды (калибровка Платта).</target>
        </trans-unit>
        <trans-unit id="1d0e566bfd264bfe0a9882ca94efb92a9385b867" translate="yes" xml:space="preserve">
          <source>The method used by each base estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87ca64fde3cf11f4163bb009ef5ad4abbcdc8e98" translate="yes" xml:space="preserve">
          <source>The method used to calculate the averaged predictions:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21e55011234a7eafaab581faf9cf56cabba5a5c2" translate="yes" xml:space="preserve">
          <source>The method used to initialize the weights, the means and the covariances. Must be one of:</source>
          <target state="translated">Метод,используемый для инициализации весов,средств и ковариаций.Должно быть,один из них:</target>
        </trans-unit>
        <trans-unit id="963cb60032e3efabe5bef9b8ad76de7b8282f830" translate="yes" xml:space="preserve">
          <source>The method used to initialize the weights, the means and the precisions. Must be one of:</source>
          <target state="translated">Метод,используемый для инициализации весов,средств и точности.Должно быть,один из них:</target>
        </trans-unit>
        <trans-unit id="8015d2d76c1dfbbe3de68f3d3f8aa78fbf89dd67" translate="yes" xml:space="preserve">
          <source>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form &lt;code&gt;&amp;lt;component&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; so that it&amp;rsquo;s possible to update each component of a nested object.</source>
          <target state="translated">Этот метод работает как с простыми оценщиками, так и с вложенными объектами (такими как конвейеры). Последние имеют параметры вида &lt;code&gt;&amp;lt;component&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; чтобы можно было обновить каждый компонент вложенного объекта.</target>
        </trans-unit>
        <trans-unit id="5d1673cba254e117532409bf5f2a151ed75e6f39" translate="yes" xml:space="preserve">
          <source>The method works on simple kernels as well as on nested kernels. The latter have parameters of the form &lt;code&gt;&amp;lt;component&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; so that it&amp;rsquo;s possible to update each component of a nested object.</source>
          <target state="translated">Метод работает как с простыми ядрами, так и с вложенными ядрами. Последние имеют параметры вида &lt;code&gt;&amp;lt;component&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; чтобы можно было обновить каждый компонент вложенного объекта.</target>
        </trans-unit>
        <trans-unit id="653c073b67dfbefaf963d2a9e7b682aaf13d10c5" translate="yes" xml:space="preserve">
          <source>The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation.</source>
          <target state="translated">Методы,основанные на F-тесте,оценивают степень линейной зависимости между двумя случайными переменными.С другой стороны,методы на основе взаимной информации могут фиксировать любые виды статистических зависимостей,но,будучи непараметрическими,они требуют большего количества выборок для точной оценки.</target>
        </trans-unit>
        <trans-unit id="86d449abad7d30ccc370e439f66e761a4c276339" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt; for its metric parameter. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;Glossary&lt;/a&gt;, in which case only &amp;ldquo;nonzero&amp;rdquo; elements may be considered neighbors for DBSCAN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9346206e9d06ed06060a101f1e51a8e80f2445f7" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt; for its metric parameter. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42e3e79f7ef752ca5a9bd963af37b6abd9f4c61f" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt; for its metric parameter. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a sparse matrix, in which case only &amp;ldquo;nonzero&amp;rdquo; elements may be considered neighbors for DBSCAN.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой или вызываемой, она должна быть одной из опций, разрешенных &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt; &lt;/a&gt; для ее параметра метрики. Если метрика &amp;laquo;вычисляется заранее&amp;raquo;, X считается матрицей расстояний и должен быть квадратным. X может быть разреженной матрицей, и в этом случае только &amp;laquo;ненулевые&amp;raquo; элементы могут считаться соседями для DBSCAN.</target>
        </trans-unit>
        <trans-unit id="379ba7f47f97569c7bd4b20c4c77667f05344897" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by metrics.pairwise.pairwise_distances for its metric parameter. The centroids for the samples corresponding to each class is the point from which the sum of the distances (according to the metric) of all samples that belong to that particular class are minimized. If the &amp;ldquo;manhattan&amp;rdquo; metric is provided, this centroid is the median and for all other metrics, the centroid is now set to be the mean.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой или вызываемой, она должна быть одной из опций, разрешенных metrics.pairwise.pairwise_distances для ее параметра метрики. Центроиды для выборок, соответствующих каждому классу, - это точка, от которой минимизируется сумма расстояний (согласно метрике) всех выборок, принадлежащих этому конкретному классу. Если указана &amp;laquo;манхэттенская&amp;raquo; метрика, этот центроид является медианой, а для всех других показателей центроид теперь устанавливается как среднее значение.</target>
        </trans-unit>
        <trans-unit id="c83cb22e1c81dc697b4c0637e95b8aeb91bdccce" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by &lt;code&gt;metrics.pairwise.pairwise_distances&lt;/code&gt;. If X is the distance array itself, use &lt;code&gt;metric=&quot;precomputed&quot;&lt;/code&gt;.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой, это должен быть один из вариантов, разрешенных &lt;code&gt;metrics.pairwise.pairwise_distances&lt;/code&gt; . Если X - это сам массив расстояний, используйте &lt;code&gt;metric=&quot;precomputed&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="76b4b37055a409fe2e4e93cf3ad5227beac3187f" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. If X is the distance array itself, use &amp;ldquo;precomputed&amp;rdquo; as the metric.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой, это должен быть один из вариантов, разрешенных &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; . Если X - это сам массив расстояний, используйте &amp;laquo;предварительно вычисленное&amp;raquo; в качестве метрики.</target>
        </trans-unit>
        <trans-unit id="74dc2788261a34d78d8ba4595625c4b4c3a263d6" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. If X is the distance array itself, use &amp;ldquo;precomputed&amp;rdquo; as the metric. Precomputed distance matrices must have 0 along the diagonal.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f209bf70493187675786c136d5f63b20f1b34d" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой, это должна быть одна из опций, разрешенных scipy.spatial.distance.pdist для его параметра метрики, или метрика, указанная в попарно.PAIRWISE_DISTANCE_FUNCTIONS. Если метрика &amp;laquo;вычисляется заранее&amp;raquo;, X считается матрицей расстояний. В качестве альтернативы, если метрика является вызываемой функцией, она вызывается для каждой пары экземпляров (строк) и записывается результирующее значение. Вызываемый объект должен принимать в качестве входных данных два массива из X и возвращать значение, указывающее расстояние между ними.</target>
        </trans-unit>
        <trans-unit id="5d6bfb4b6dd59ce295c63dba458c016e3505d6e2" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them. The default is &amp;ldquo;euclidean&amp;rdquo; which is interpreted as squared euclidean distance.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой, это должна быть одна из опций, разрешенных scipy.spatial.distance.pdist для его параметра метрики, или метрика, указанная в попарно.PAIRWISE_DISTANCE_FUNCTIONS. Если метрика &amp;laquo;вычисляется заранее&amp;raquo;, X считается матрицей расстояний. В качестве альтернативы, если метрика является вызываемой функцией, она вызывается для каждой пары экземпляров (строк) и записывается результирующее значение. Вызываемый объект должен принимать в качестве входных данных два массива из X и возвращать значение, указывающее расстояние между ними. Значение по умолчанию - &amp;laquo;евклидово&amp;raquo;, что интерпретируется как квадрат евклидова расстояния.</target>
        </trans-unit>
        <trans-unit id="1d21e688cc862f7d70c6767af76fb5452c5fdcd0" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options specified in PAIRED_DISTANCES, including &amp;ldquo;euclidean&amp;rdquo;, &amp;ldquo;manhattan&amp;rdquo;, or &amp;ldquo;cosine&amp;rdquo;. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them.</source>
          <target state="translated">Метрика, используемая при вычислении расстояния между экземплярами в массиве объектов. Если метрика является строкой, она должна быть одной из опций, указанных в PAIRED_DISTANCES, включая &amp;laquo;евклидово&amp;raquo;, &amp;laquo;манхэттенское&amp;raquo; или &amp;laquo;косинусное&amp;raquo;. В качестве альтернативы, если метрика является вызываемой функцией, она вызывается для каждой пары экземпляров (строк) и записывается результирующее значение. Вызываемый объект должен принимать в качестве входных данных два массива из X и возвращать значение, указывающее расстояние между ними.</target>
        </trans-unit>
        <trans-unit id="f36b3ebd6c1e0314a19882dfd7c792465ced8cb2" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating kernel between instances in a feature array. If metric is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a kernel matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them.</source>
          <target state="translated">Метрика, используемая при вычислении ядра между экземплярами в массиве функций. Если метрика является строкой, она должна быть одной из метрик в парах .PAIRWISE_KERNEL_FUNCTIONS. Если метрика &amp;laquo;вычисляется заранее&amp;raquo;, предполагается, что X является матрицей ядра. В качестве альтернативы, если метрика является вызываемой функцией, она вызывается для каждой пары экземпляров (строк) и записывается результирующее значение. Вызываемый объект должен принимать в качестве входных данных два массива из X и возвращать значение, указывающее расстояние между ними.</target>
        </trans-unit>
        <trans-unit id="fc294d94430f6d524884c3e3bbe7bf2fd080ba19" translate="yes" xml:space="preserve">
          <source>The metric to use when calculating kernel between instances in a feature array. If metric is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a kernel matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two rows from X as input and return the corresponding kernel value as a single number. This means that callables from &lt;a href=&quot;../classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; are not allowed, as they operate on matrices, not single samples. Use the string identifying the kernel instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4d18e9d9a4e3ba27fc7d43cfc9aa960df294a66" translate="yes" xml:space="preserve">
          <source>The minimal number of components to guarantee with good probability an eps-embedding with n_samples.</source>
          <target state="translated">Минимальное количество компонентов для гарантии с хорошей вероятностью eps-вставки с n_образцами.</target>
        </trans-unit>
        <trans-unit id="bffda997c9866bdeb3072a563a59e0dfd40b41cb" translate="yes" xml:space="preserve">
          <source>The minimization problem becomes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcfd1fcfc3ab5a126126fe7777d3f592dbce3714" translate="yes" xml:space="preserve">
          <source>The minimum consensus score, 0, occurs when all pairs of biclusters are totally dissimilar. The maximum score, 1, occurs when both sets are identical.</source>
          <target state="translated">Минимальный консенсусный балл,0,наступает тогда,когда все пары биклустеров полностью разнятся.Максимальный результат,1,наступает,когда оба сета одинаковы.</target>
        </trans-unit>
        <trans-unit id="546685a327b5ecf09c20bafa81b23b9f31e36223" translate="yes" xml:space="preserve">
          <source>The minimum number of components to guarantee the eps-embedding is given by:</source>
          <target state="translated">Минимальное количество компонентов для гарантии эпс-вставки указано:</target>
        </trans-unit>
        <trans-unit id="d171bb6d353676c30b749e2ca85c8811f4027e78" translate="yes" xml:space="preserve">
          <source>The minimum number of components to guarantees the eps-embedding is given by:</source>
          <target state="translated">Минимальное количество компонентов для гарантии эпс-вставки указано:</target>
        </trans-unit>
        <trans-unit id="78f0aa92767e958a159a7201fe662ff62e3924a6" translate="yes" xml:space="preserve">
          <source>The minimum number of features to be selected. This number of features will always be scored, even if the difference between the original feature count and &lt;code&gt;min_features_to_select&lt;/code&gt; isn&amp;rsquo;t divisible by &lt;code&gt;step&lt;/code&gt;.</source>
          <target state="translated">Минимальное количество выбираемых функций. Это количество функций всегда будет оцениваться, даже если разница между исходным количеством функций и &lt;code&gt;min_features_to_select&lt;/code&gt; не делится на &lt;code&gt;step&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dc2c2ff1c0458b789a8dbc35522b80adbfc0fde6" translate="yes" xml:space="preserve">
          <source>The minimum number of samples per leaf. For small datasets with less than a few hundred samples, it is recommended to lower this value since only very shallow trees would be built.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1db45f422759f4529cb388eaa249fdf3a381a4d3" translate="yes" xml:space="preserve">
          <source>The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least &lt;code&gt;min_samples_leaf&lt;/code&gt; training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.</source>
          <target state="translated">Минимальное количество выборок, которое требуется для конечного узла. Точка разделения на любой глубине будет учитываться только в том случае, если она оставляет не менее &lt;code&gt;min_samples_leaf&lt;/code&gt; обучающих выборок в каждой из левой и правой ветвей. Это может иметь эффект сглаживания модели, особенно при регрессии.</target>
        </trans-unit>
        <trans-unit id="754bd23e1994f02a9f11fc7f2013baebc017ca4d" translate="yes" xml:space="preserve">
          <source>The minimum number of samples required to split an internal node:</source>
          <target state="translated">Минимальное количество образцов,необходимое для разделения внутреннего узла:</target>
        </trans-unit>
        <trans-unit id="28930c1108db91ea501be86c776a39ad33671bd9" translate="yes" xml:space="preserve">
          <source>The minimum score is zero, with lower values indicating better clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cad4521e1577b76d3fbf78851e9af149127ba4db" translate="yes" xml:space="preserve">
          <source>The minimum valid value the parameter can take. If None (default) it is implied that the parameter does not have a lower bound.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34dec0ced4163b0b0c5f6b2dfda2c2ae915251bf" translate="yes" xml:space="preserve">
          <source>The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.</source>
          <target state="translated">Минимальная взвешенная доля от общей суммы весов (всех входных образцов),необходимых для нахождения в узле листа.Образцы имеют равный вес,когда sample_weight не предоставляется.</target>
        </trans-unit>
        <trans-unit id="adbfb8d83e84eef2c959ef548acb01276646831a" translate="yes" xml:space="preserve">
          <source>The missing indicator for input data. The data type of &lt;code&gt;Xt&lt;/code&gt; will be boolean.</source>
          <target state="translated">Отсутствует индикатор входных данных. Тип данных &lt;code&gt;Xt&lt;/code&gt; будет логическим.</target>
        </trans-unit>
        <trans-unit id="2b5249d3ed9eb260ab7aedd15c61af2c7df4b9f1" translate="yes" xml:space="preserve">
          <source>The mixing matrix to be used to initialize the algorithm.</source>
          <target state="translated">Матрица смешивания,используемая для инициализации алгоритма.</target>
        </trans-unit>
        <trans-unit id="bc7bce3b2af118e0efad437caf7d72239aa18a90" translate="yes" xml:space="preserve">
          <source>The mixing matrix.</source>
          <target state="translated">Матрица смешивания.</target>
        </trans-unit>
        <trans-unit id="d9852ae9396dc8e73ffef0a95fb9e0d330c7fbbc" translate="yes" xml:space="preserve">
          <source>The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.</source>
          <target state="translated">Модель соответствует гауссовской плотности для каждого класса,предполагая,что все классы имеют одну и ту же ковариационную матрицу.</target>
        </trans-unit>
        <trans-unit id="c1fbc40d4a13f1c2e80dae47c2199d2a0ef37a24" translate="yes" xml:space="preserve">
          <source>The model fits a Gaussian density to each class.</source>
          <target state="translated">Модель соответствует гауссовской плотности для каждого класса.</target>
        </trans-unit>
        <trans-unit id="c383334c8db0249de2e6de6266d715cf757d0e4f" translate="yes" xml:space="preserve">
          <source>The model learnt is far from being a good model making accurate predictions: this is obvious when looking at the plot above, where good predictions should lie on the red line.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="744fe4c01d7aac1fa2b93515c5b761f9f450f5fc" translate="yes" xml:space="preserve">
          <source>The model makes assumptions regarding the distribution of inputs. At the moment, scikit-learn only provides &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, which assumes the inputs are either binary values or values between 0 and 1, each encoding the probability that the specific feature would be turned on.</source>
          <target state="translated">Модель делает предположения относительно распределения входов. На данный момент scikit-learn предоставляет только &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; , который предполагает, что входными данными являются либо двоичные значения, либо значения от 0 до 1, каждое из которых кодирует вероятность того, что конкретная функция будет включена.</target>
        </trans-unit>
        <trans-unit id="3e7d91224c848a3199f89b8ed290703400860de0" translate="yes" xml:space="preserve">
          <source>The model need to have probability information computed at training time: fit with attribute &lt;code&gt;probability&lt;/code&gt; set to True.</source>
          <target state="translated">Модель должна иметь информацию о вероятности, вычисленную во время обучения: соответствие с &lt;code&gt;probability&lt;/code&gt; атрибута, установленной на True.</target>
        </trans-unit>
        <trans-unit id="f6f2922bb9e8bafadd9354168cde2a4c9535aa4f" translate="yes" xml:space="preserve">
          <source>The model parameters can be accessed through the &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; attributes: &lt;code&gt;coef_&lt;/code&gt; holds the weights \(w\) and &lt;code&gt;intercept_&lt;/code&gt; holds \(b\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="532fcfc5fc4303622a7e9b0379fb5dd6d278b658" translate="yes" xml:space="preserve">
          <source>The model parameters can be accessed through the members &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt;:</source>
          <target state="translated">Доступ к параметрам модели можно получить через члены &lt;code&gt;coef_&lt;/code&gt; и &lt;code&gt;intercept_&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="87fcd2dcd4a9683677aa4a82e264db34c1778c7c" translate="yes" xml:space="preserve">
          <source>The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function for building the model ignores any training data close to the model prediction.</source>
          <target state="translated">Модель,созданная с помощью векторной классификации поддержки (как описано выше),зависит только от подмножества данных об обучении,потому что функция затрат на построение модели не заботится о точках обучения,которые лежат за пределами маржи.Аналогично,модель,построенная с помощью векторной регрессии поддержки,зависит только от подмножества данных по обучению,потому что функция затрат для построения модели игнорирует любые данные по обучению,близкие к предсказанию модели.</target>
        </trans-unit>
        <trans-unit id="14cc80df7b1b8b9f6ebfb922c7e5dfe3e7692df9" translate="yes" xml:space="preserve">
          <source>The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function ignores samples whose prediction is close to their target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4911f4659c5f4e900454be23c5d2d4b6dba06b2b" translate="yes" xml:space="preserve">
          <source>The model will stay unchanged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffaf4f38449ad493c6f07021545ef1cc0f916269" translate="yes" xml:space="preserve">
          <source>The models are ordered from strongest regularized to least regularized. The 4 coefficients of the models are collected and plotted as a &amp;ldquo;regularization path&amp;rdquo;: on the left-hand side of the figure (strong regularizers), all the coefficients are exactly 0. When regularization gets progressively looser, coefficients can get non-zero values one after the other.</source>
          <target state="translated">Модели отсортированы от наиболее упорядоченного до наименее упорядоченного. 4 коэффициента моделей собираются и наносятся на график как &amp;laquo;путь регуляризации&amp;raquo;: в левой части рисунка (сильные регуляризаторы) все коэффициенты равны ровно 0. Когда регуляризация становится все более слабой, коэффициенты могут отличаться от нуля. ценности одно за другим.</target>
        </trans-unit>
        <trans-unit id="41864e959b3c3945768dfd483a7ad2160aff5a56" translate="yes" xml:space="preserve">
          <source>The module &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; includes the popular boosting algorithm AdaBoost, introduced in 1995 by Freund and Schapire &lt;a href=&quot;#fs1995&quot; id=&quot;id9&quot;&gt;[FS1995]&lt;/a&gt;.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; включает популярный алгоритм повышения AdaBoost, представленный в 1995 году Фройндом и &lt;a href=&quot;#fs1995&quot; id=&quot;id9&quot;&gt;Шапиром [FS1995]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1ad1575f52119d57fdeed35bbf3eb9cde06a6188" translate="yes" xml:space="preserve">
          <source>The module &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; provides methods for both classification and regression via gradient boosted decision trees.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06014352d795d21d24d63a43012b2cdda688123a" translate="yes" xml:space="preserve">
          <source>The module &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; provides methods for both classification and regression via gradient boosted regression trees.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; предоставляет методы как для классификации, так и для регрессии с помощью деревьев регрессии с градиентным усилением.</target>
        </trans-unit>
        <trans-unit id="c3b04b84598eb19b700a6f5a28a6ebcc8d4034a0" translate="yes" xml:space="preserve">
          <source>The module &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; also exposes a set of simple functions measuring a prediction error given ground truth and prediction:</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; также предоставляет набор простых функций, измеряющих ошибку предсказания с учетом истинности и предсказания:</target>
        </trans-unit>
        <trans-unit id="a4ba63f9b8e0d9fa0a182e0bb4dc5760121e3e0e" translate="yes" xml:space="preserve">
          <source>The module &lt;code&gt;partial_dependence&lt;/code&gt; provides a convenience function &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.plot_partial_dependence#sklearn.ensemble.partial_dependence.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to create one-way and two-way partial dependence plots. In the below example we show how to create a grid of partial dependence plots: two one-way PDPs for the features &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; and a two-way PDP between the two features:</source>
          <target state="translated">Модуль &lt;code&gt;partial_dependence&lt;/code&gt; предоставляет удобную функцию &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.plot_partial_dependence#sklearn.ensemble.partial_dependence.plot_partial_dependence&quot;&gt; &lt;code&gt;plot_partial_dependence&lt;/code&gt; &lt;/a&gt; для создания односторонних и двусторонних графиков частичной зависимости. В приведенном ниже примере мы показываем, как создать сетку графиков частичной зависимости: два односторонних PDP для функций &lt;code&gt;0&lt;/code&gt; и &lt;code&gt;1&lt;/code&gt; и двусторонний PDP между двумя функциями:</target>
        </trans-unit>
        <trans-unit id="5b2518b0fdafd75a6658a4d2a018bccb79345ce3" translate="yes" xml:space="preserve">
          <source>The module contains the public attributes &lt;code&gt;coefs_&lt;/code&gt; and &lt;code&gt;intercepts_&lt;/code&gt;. &lt;code&gt;coefs_&lt;/code&gt; is a list of weight matrices, where weight matrix at index \(i\) represents the weights between layer \(i\) and layer \(i+1\). &lt;code&gt;intercepts_&lt;/code&gt; is a list of bias vectors, where the vector at index \(i\) represents the bias values added to layer \(i+1\).</source>
          <target state="translated">Модуль содержит общедоступные атрибуты &lt;code&gt;coefs_&lt;/code&gt; и &lt;code&gt;intercepts_&lt;/code&gt; . &lt;code&gt;coefs_&lt;/code&gt; - это список весовых матриц, где весовая матрица с индексом \ (i \) представляет веса между слоем \ (i \) и слоем \ (i + 1 \). &lt;code&gt;intercepts_&lt;/code&gt; - это список векторов смещения, где вектор с индексом \ (i \) представляет значения смещения, добавленные к слою \ (i + 1 \).</target>
        </trans-unit>
        <trans-unit id="b31fa7fd3ac8f2a64f0dd29549e8dd9abb96ee19" translate="yes" xml:space="preserve">
          <source>The module: &lt;code&gt;random_projection&lt;/code&gt; provides several tools for data reduction by random projections. See the relevant section of the documentation: &lt;a href=&quot;random_projection#random-projection&quot;&gt;Random Projection&lt;/a&gt;.</source>
          <target state="translated">Модуль: &lt;code&gt;random_projection&lt;/code&gt; предоставляет несколько инструментов для сокращения данных с помощью случайных проекций. См. Соответствующий раздел документации: &lt;a href=&quot;random_projection#random-projection&quot;&gt;Случайная проекция&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="81f532ac90d157aeffd690ee0c3b7aa6b7bbd149" translate="yes" xml:space="preserve">
          <source>The monitor is called after each iteration with the current iteration, a reference to the estimator and the local variables of &lt;code&gt;_fit_stages&lt;/code&gt; as keyword arguments &lt;code&gt;callable(i, self,
locals())&lt;/code&gt;. If the callable returns &lt;code&gt;True&lt;/code&gt; the fitting procedure is stopped. The monitor can be used for various things such as computing held-out estimates, early stopping, model introspect, and snapshoting.</source>
          <target state="translated">Монитор вызывается после каждой итерации с текущей итерацией, ссылкой на средство оценки и локальные переменные &lt;code&gt;_fit_stages&lt;/code&gt; в качестве аргументов ключевого слова callable &lt;code&gt;callable(i, self, locals())&lt;/code&gt; . Если вызываемый объект возвращает &lt;code&gt;True&lt;/code&gt; , процедура подгонки останавливается. Монитор можно использовать для различных целей, таких как вычисление отложенных оценок, ранняя остановка, самоанализ модели и создание снимков.</target>
        </trans-unit>
        <trans-unit id="52aa15c9df5da45110f63c8c26b8cfa477557d62" translate="yes" xml:space="preserve">
          <source>The most common parameter amenable to this strategy is the parameter encoding the strength of the regularizer. In this case we say that we compute the &lt;strong&gt;regularization path&lt;/strong&gt; of the estimator.</source>
          <target state="translated">Наиболее распространенным параметром, поддающимся этой стратегии, является параметр, кодирующий силу регуляризатора. В этом случае мы говорим, что вычисляем &lt;strong&gt;путь регуляризации&lt;/strong&gt; оценки.</target>
        </trans-unit>
        <trans-unit id="3156312e704bdb91fdff12aa2e110d4f21e21302" translate="yes" xml:space="preserve">
          <source>The most intuitive way to do so is to use a bags of words representation:</source>
          <target state="translated">Самый интуитивный способ сделать это-использовать мешок с изображением слов:</target>
        </trans-unit>
        <trans-unit id="399fde41b63b2ea676c5145583a3950879f6c9fa" translate="yes" xml:space="preserve">
          <source>The motivation to use this scaling include robustness to very small standard deviations of features and preserving zero entries in sparse data.</source>
          <target state="translated">Мотивация к использованию такого масштабирования включает в себя устойчивость к очень малым стандартным отклонениям характеристик и сохранение нулевых записей в разреженных данных.</target>
        </trans-unit>
        <trans-unit id="3ec6281766fab2b8f9e9f9f6e92da7d4704e6316" translate="yes" xml:space="preserve">
          <source>The multi-task lasso allows to fit multiple regression problems jointly enforcing the selected features to be the same across tasks. This example simulates sequential measurements, each task is a time instant, and the relevant features vary in amplitude over time while being the same. The multi-task lasso imposes that features that are selected at one time point are select for all time point. This makes feature selection by the Lasso more stable.</source>
          <target state="translated">Многозадачный лассо позволяет подогнать несколько регрессионных проблем,совместно заставляя выбранные функции быть одинаковыми в разных задачах.В данном примере симулируются последовательные измерения,каждая задача является мгновенной по времени,а соответствующие функции изменяются по амплитуде с течением времени,оставаясь при этом одними и теми же.Многозадачный лассо позволяет выбирать элементы,выбранные в одной временной точке,для всех временных точек.Это делает выбор элемента Лассо более стабильным.</target>
        </trans-unit>
        <trans-unit id="7b55b776834f44186e095c0df9ee2b704ce3630c" translate="yes" xml:space="preserve">
          <source>The multiclass definition here seems the most reasonable extension of the metric used in binary classification, though there is no certain consensus in the literature:</source>
          <target state="translated">Определение мультикласса здесь кажется наиболее разумным расширением метрики,используемой в бинарной классификации,хотя в литературе нет определенного консенсуса:</target>
        </trans-unit>
        <trans-unit id="5fdb408d7bc477f0762da630aa0f3aea39db3f13" translate="yes" xml:space="preserve">
          <source>The multiclass support is handled according to a one-vs-one scheme.</source>
          <target state="translated">Поддержка нескольких классов обрабатывается по схеме &quot;один в один&quot;.</target>
        </trans-unit>
        <trans-unit id="559112a07c580b9f5163f4eaab25d31b6f252bc0" translate="yes" xml:space="preserve">
          <source>The multilabel_confusion_matrix calculates class-wise or sample-wise multilabel confusion matrices, and in multiclass tasks, labels are binarized under a one-vs-rest way; while confusion_matrix calculates one confusion matrix for confusion between every two classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66359e593d021aa5ae2d568f4acc056ec0bf4a32" translate="yes" xml:space="preserve">
          <source>The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.</source>
          <target state="translated">Мультиномиальный классификатор Naive Bayes подходит для классификации с дискретными характеристиками (например,подсчет слов для классификации текста).Многочленное распределение обычно требует подсчета целочисленных признаков.Однако на практике могут также работать и дробные подсчеты,такие как tf-idf.</target>
        </trans-unit>
        <trans-unit id="9fcb660998dc7edb2d34f5dc5854df445bad9a92" translate="yes" xml:space="preserve">
          <source>The multiple metrics can be specified either as a list, tuple or set of predefined scorer names:</source>
          <target state="translated">Несколько метрик могут быть указаны как список,кортеж или набор предопределенных имен счетчиков:</target>
        </trans-unit>
        <trans-unit id="0f55ab2d94390a312af5800dfb617d9ab1f868e3" translate="yes" xml:space="preserve">
          <source>The name of the hyperparameter. Note that a kernel using a hyperparameter with name &amp;ldquo;x&amp;rdquo; must have the attributes self.x and self.x_bounds</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66cdcb45ef3965759b13ccc7a57841383638bd06" translate="yes" xml:space="preserve">
          <source>The name of the parameter to be printed in error messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a09e250651300d47ed9cd74b128d0a12a5aa8e3e" translate="yes" xml:space="preserve">
          <source>The name of the sample image loaded</source>
          <target state="translated">Имя загруженного образца изображения</target>
        </trans-unit>
        <trans-unit id="b853190860f83bcb94f9f4edb130e6f04adf4ae5" translate="yes" xml:space="preserve">
          <source>The names &lt;code&gt;vect&lt;/code&gt;, &lt;code&gt;tfidf&lt;/code&gt; and &lt;code&gt;clf&lt;/code&gt; (classifier) are arbitrary. We will use them to perform grid search for suitable hyperparameters below. We can now train the model with a single command:</source>
          <target state="translated">Имена &lt;code&gt;vect&lt;/code&gt; , &lt;code&gt;tfidf&lt;/code&gt; и &lt;code&gt;clf&lt;/code&gt; (классификатор) произвольны. Мы будем использовать их для поиска подходящих гиперпараметров по сетке ниже. Теперь мы можем обучить модель с помощью одной команды:</target>
        </trans-unit>
        <trans-unit id="37788c74066a15702915a906173e5747b775560c" translate="yes" xml:space="preserve">
          <source>The names of features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a6d82313da18df77f363e5439a6b3ce08c6680a" translate="yes" xml:space="preserve">
          <source>The names of target classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9146e93a1405c3d2cac65e0084d1b1c7a951b3b3" translate="yes" xml:space="preserve">
          <source>The names of the dataset columns</source>
          <target state="translated">Названия столбцов набора данных</target>
        </trans-unit>
        <trans-unit id="9c71b3cc12d889ddb9194bd05e135e431b48c18f" translate="yes" xml:space="preserve">
          <source>The names of the dataset columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e5fcf3b8aec8853bca895bccf214ac28ac4d27e" translate="yes" xml:space="preserve">
          <source>The names of the target columns</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40ffca0689344b78c3e10b40b262e0c45ea9b50f" translate="yes" xml:space="preserve">
          <source>The names of the target columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1942d0e2fca00caa96a5a7573d350784bbfcadf1" translate="yes" xml:space="preserve">
          <source>The new backend can then be selected by passing its name as the backend argument to the Parallel class. Moreover, the default backend can be overwritten globally by setting make_default=True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0fb0e8bf0410fa55523d36fa2a7a49ac4415117" translate="yes" xml:space="preserve">
          <source>The new dtype will be np.float32 or np.float64, depending on the original type. The function can create a copy or modify the argument depending on the argument copy.</source>
          <target state="translated">Новый dtype будет np.float32 или np.float64,в зависимости от оригинального типа.Функция может создать копию или изменить аргумент в зависимости от копии аргумента.</target>
        </trans-unit>
        <trans-unit id="6d7b951e7afa9271dd7834467cb67e175d7e626f" translate="yes" xml:space="preserve">
          <source>The new entry \(d(u,v)\) is computed as follows,</source>
          <target state="translated">Новая запись \(d(u,v)\)рассчитана следующим образом,</target>
        </trans-unit>
        <trans-unit id="c771668f5d4b4d7aa145f31455a67e2ba21af3ce" translate="yes" xml:space="preserve">
          <source>The next figure compares the results obtained for the different type of the weight concentration prior (parameter &lt;code&gt;weight_concentration_prior_type&lt;/code&gt;) for different values of &lt;code&gt;weight_concentration_prior&lt;/code&gt;. Here, we can see the value of the &lt;code&gt;weight_concentration_prior&lt;/code&gt; parameter has a strong impact on the effective number of active components obtained. We can also notice that large values for the concentration weight prior lead to more uniform weights when the type of prior is &amp;lsquo;dirichlet_distribution&amp;rsquo; while this is not necessarily the case for the &amp;lsquo;dirichlet_process&amp;rsquo; type (used by default).</source>
          <target state="translated">На следующем рисунке сравниваются результаты, полученные для другого типа предшествующей весовой концентрации (параметр &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; ) для разных значений &lt;code&gt;weight_concentration_prior&lt;/code&gt; . Здесь мы видим, что значение параметра &lt;code&gt;weight_concentration_prior&lt;/code&gt; оказывает сильное влияние на эффективное количество полученных активных компонентов. Мы также можем заметить, что большие значения для предшествующего веса концентрации приводят к более однородным весам, когда типом Priority является 'dirichlet_distribution', в то время как это не обязательно так для типа 'dirichlet_process' (используется по умолчанию).</target>
        </trans-unit>
        <trans-unit id="c25f5050f6fd3011382e4c50ae76e75315ba1a26" translate="yes" xml:space="preserve">
          <source>The next figure compares the time for fitting and prediction of &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; for different sizes of the training set. Fitting &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; is faster than &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; for medium-sized training sets (less than 1000 samples); however, for larger training sets &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; scales better. With regard to prediction time, &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt; is faster than &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; for all sizes of the training set because of the learned sparse solution. Note that the degree of sparsity and thus the prediction time depends on the parameters \(\epsilon\) and \(C\) of the &lt;a href=&quot;generated/sklearn.svm.svr#sklearn.svm.SVR&quot;&gt;&lt;code&gt;SVR&lt;/code&gt;&lt;/a&gt;; \(\epsilon = 0\) would correspond to a dense model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6d38fd34e131451ba8b974153991556ff8b9398" translate="yes" xml:space="preserve">
          <source>The next figure compares the time for fitting and prediction of &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;SVR&lt;/code&gt; for different sizes of the training set. Fitting &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; is faster than &lt;code&gt;SVR&lt;/code&gt; for medium-sized training sets (less than 1000 samples); however, for larger training sets &lt;code&gt;SVR&lt;/code&gt; scales better. With regard to prediction time, &lt;code&gt;SVR&lt;/code&gt; is faster than &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt;&lt;code&gt;KernelRidge&lt;/code&gt;&lt;/a&gt; for all sizes of the training set because of the learned sparse solution. Note that the degree of sparsity and thus the prediction time depends on the parameters \(\epsilon\) and \(C\) of the &lt;code&gt;SVR&lt;/code&gt;; \(\epsilon = 0\) would correspond to a dense model.</source>
          <target state="translated">На следующем рисунке сравнивается время подгонки и прогнозирования &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt; &lt;code&gt;KernelRidge&lt;/code&gt; &lt;/a&gt; и &lt;code&gt;SVR&lt;/code&gt; для разных размеров обучающего набора. Монтаж &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt; &lt;code&gt;KernelRidge&lt;/code&gt; &lt;/a&gt; быстрее , чем &lt;code&gt;SVR&lt;/code&gt; для средних учебных комплектов (менее 1000 образцов); однако для больших обучающих наборов &lt;code&gt;SVR&lt;/code&gt; масштабируется лучше. Что касается времени предсказания, &lt;code&gt;SVR&lt;/code&gt; быстрее &lt;a href=&quot;generated/sklearn.kernel_ridge.kernelridge#sklearn.kernel_ridge.KernelRidge&quot;&gt; &lt;code&gt;KernelRidge&lt;/code&gt; &lt;/a&gt; для всех размеров обучающего набора из-за изученного разреженного решения. Обратите внимание, что степень разреженности и, следовательно, время прогнозирования зависят от параметров \ (\ epsilon \) и \ (C \) &lt;code&gt;SVR&lt;/code&gt; ; \ (\ epsilon = 0 \) соответствует плотной модели.</target>
        </trans-unit>
        <trans-unit id="7fb8a1fd588ff5df76899e15821355218c8c70df" translate="yes" xml:space="preserve">
          <source>The next figure compares the time for fitting and prediction of KRR and SVR for different sizes of the training set. Fitting KRR is faster than SVR for medium- sized training sets (less than 1000 samples); however, for larger training sets SVR scales better. With regard to prediction time, SVR is faster than KRR for all sizes of the training set because of the learned sparse solution. Note that the degree of sparsity and thus the prediction time depends on the parameters epsilon and C of the SVR.</source>
          <target state="translated">На следующем рисунке сравнивается время подгонки и прогнозирования KRR и SVR для различных размеров тренировочного комплекта.Установка KRR быстрее,чем SVR для тренировочных комплектов средних размеров (менее 1000 проб),но для более крупных тренировочных комплектов весы SVR лучше.Что касается времени прогнозирования,то SVR быстрее,чем KRR для всех размеров тренировочной установки,благодаря выученному разреженному раствору.Отметим,что степень редкости и,следовательно,время прогнозирования зависит от параметров эпсилон и С SVR.</target>
        </trans-unit>
        <trans-unit id="b8b8c72913234ec998c925f50d9fa1a29ef7082f" translate="yes" xml:space="preserve">
          <source>The next image illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).</source>
          <target state="translated">Следующее изображение иллюстрирует,как изменения сигмовидной калибровки предсказывают вероятности для 3-классовой проблемы классификации.Иллюстрируется стандартный 2-симплекс,где три угла соответствуют трем классам.Стрелки указывают от векторов вероятности,предсказанных некалиброванным классификатором,к векторам вероятности,предсказанным тем же классификатором после сигмовидной калибровки на некалиброванном валидационном наборе.Цветами обозначен истинный класс экземпляра (красный:класс 1,зеленый:класс 2,синий:класс 3).</target>
        </trans-unit>
        <trans-unit id="d16a780143f0785e9248e298dec17c9fe8de9d1e" translate="yes" xml:space="preserve">
          <source>The nodes are random variables whose states depend on the state of the other nodes they are connected to. The model is therefore parameterized by the weights of the connections, as well as one intercept (bias) term for each visible and hidden unit, omitted from the image for simplicity.</source>
          <target state="translated">Узлы являются случайными переменными,состояния которых зависят от состояния других узлов,с которыми они соединены.Поэтому модель параметризуется весами связей,а также одним членом перехвата (смещения)для каждой видимой и скрытой единицы,опущенной из изображения для простоты.</target>
        </trans-unit>
        <trans-unit id="55f688a90e745dd5020f6b5c567bbe8f6396fa6e" translate="yes" xml:space="preserve">
          <source>The noise level in the targets can be specified by passing it via the parameter &lt;code&gt;alpha&lt;/code&gt;, either globally as a scalar or per datapoint. Note that a moderate noise level can also be helpful for dealing with numeric issues during fitting as it is effectively implemented as Tikhonov regularization, i.e., by adding it to the diagonal of the kernel matrix. An alternative to specifying the noise level explicitly is to include a WhiteKernel component into the kernel, which can estimate the global noise level from the data (see example below).</source>
          <target state="translated">Уровень шума в целях можно указать, передав его через параметр &lt;code&gt;alpha&lt;/code&gt; либо глобально как скаляр, либо для каждой точки данных. Обратите внимание, что умеренный уровень шума также может быть полезен для решения числовых проблем во время подгонки, поскольку он эффективно реализуется как регуляризация Тихонова, то есть путем добавления его к диагонали матрицы ядра. Альтернативой явному указанию уровня шума является включение в ядро ​​компонента WhiteKernel, который может оценивать глобальный уровень шума на основе данных (см. Пример ниже).</target>
        </trans-unit>
        <trans-unit id="99b58f648d173c7793dc0e913318a8835572f0c2" translate="yes" xml:space="preserve">
          <source>The non-fixed, log-transformed hyperparameters of the kernel</source>
          <target state="translated">Нефиксированные,преобразованные в лог гиперпараметры ядра</target>
        </trans-unit>
        <trans-unit id="8ea3cf8563db967f688cb46c0883a9d020905a15" translate="yes" xml:space="preserve">
          <source>The nonmetric algorithm adds a monotonic regression step before computing the stress.</source>
          <target state="translated">Неметрический алгоритм добавляет шаг монотонной регрессии перед вычислением напряжения.</target>
        </trans-unit>
        <trans-unit id="8cecdfcc92ccd83125ecaa6c4beb7447e43f92cb" translate="yes" xml:space="preserve">
          <source>The norm to use to normalize each non zero sample (or each non-zero feature if axis is 0).</source>
          <target state="translated">Норма,используемая для нормализации каждой ненулевой выборки (или каждой ненулевой выборки,если ось 0).</target>
        </trans-unit>
        <trans-unit id="39e8a7c3ff72c23082d4ee16a84d74279c8584ba" translate="yes" xml:space="preserve">
          <source>The norm to use to normalize each non zero sample.</source>
          <target state="translated">Норма,используемая для нормализации каждого ненулевого образца.</target>
        </trans-unit>
        <trans-unit id="6d3c61aac7334b6f6f54f73be53f19b464b34cbe" translate="yes" xml:space="preserve">
          <source>The norm to use to normalize each non zero sample. If norm=&amp;rsquo;max&amp;rsquo; is used, values will be rescaled by the maximum of the absolute values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4510db24d586496f5cd27e9cd8024ffe16a368e" translate="yes" xml:space="preserve">
          <source>The normalized mutual information is defined as</source>
          <target state="translated">Нормализованная взаимная информация определяется как</target>
        </trans-unit>
        <trans-unit id="ad22e0beb8a3a9f5574d757b3678d39d78057ba3" translate="yes" xml:space="preserve">
          <source>The normalizer instance can then be used on sample vectors as any transformer:</source>
          <target state="translated">В этом случае экземпляр нормализатора может быть использован на образцах векторов,как и любой трансформатор:</target>
        </trans-unit>
        <trans-unit id="82d79be22b3b3fa23f79d393f8a5b628a27ddb08" translate="yes" xml:space="preserve">
          <source>The number k of neighbors considered, (alias parameter n_neighbors) is typically chosen 1) greater than the minimum number of objects a cluster has to contain, so that other objects can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by objects that can potentially be local outliers. In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general. When the proportion of outliers is high (i.e. greater than 10 %, as in the example below), n_neighbors should be greater (n_neighbors=35 in the example below).</source>
          <target state="translated">Число k рассматриваемых соседей (псевдоним параметр n_neighbors)обычно выбирается 1)больше,чем минимальное число объектов,которое должен содержать кластер,так что другие объекты могут быть локальными выбросами относительно этого кластера,и 2)меньше,чем максимальное число близких объектов,которые потенциально могут быть локальными выбросами.На практике такая информация,как правило,недоступна,а выбор n_neighbors=20,похоже,в целом работает хорошо.Когда доля отклонений высока (т.е.больше 10%,как в примере ниже),n_соседей должно быть больше (n_соседей=35 в примере ниже).</target>
        </trans-unit>
        <trans-unit id="9650bdc07aaa5281bfc3be8ecd4292573a8743c6" translate="yes" xml:space="preserve">
          <source>The number of CPUs to use to compute the partial dependences. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a35a9d90f2abd9af864433913570f3dbe7f2765" translate="yes" xml:space="preserve">
          <source>The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество процессоров, используемых для вычисления OVA (один против всех, для задач с несколькими классами). &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="985a6706e191013209fa45542581d0ffa377ae50" translate="yes" xml:space="preserve">
          <source>The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36ae328d3607f79ec631b3fe327da7ed8cf8098b" translate="yes" xml:space="preserve">
          <source>The number of CPUs to use to do the computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество процессоров, которые нужно использовать для вычисления. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="2e29d4d145cd20eb08e9ea5571074f934df7e0d8" translate="yes" xml:space="preserve">
          <source>The number of CPUs to use to do the computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="720879c36f3df22b5ec2b112039efcd8b5ba8b1b" translate="yes" xml:space="preserve">
          <source>The number of EM iterations to perform.</source>
          <target state="translated">Количество выполняемых ЭМ-итераций.</target>
        </trans-unit>
        <trans-unit id="df46ce41d5f6eae9d9abc12693e64e5ffe0f042c" translate="yes" xml:space="preserve">
          <source>The number of OpenMP threads to use for the computation. Parallelism is sample-wise on the main cython loop which assigns each sample to its closest center.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40648db4f1524a67ed66976c14cc75bac6eed386" translate="yes" xml:space="preserve">
          <source>The number of atomic tasks to dispatch at once to each worker. When individual evaluations are very fast, dispatching calls to workers can be slower than sequential computation because of the overhead. Batching fast computations together can mitigate this. The &lt;code&gt;'auto'&lt;/code&gt; strategy keeps track of the time it takes for a batch to complete, and dynamically adjusts the batch size to keep the time on the order of half a second, using a heuristic. The initial batch size is 1. &lt;code&gt;batch_size=&quot;auto&quot;&lt;/code&gt; with &lt;code&gt;backend=&quot;threading&quot;&lt;/code&gt; will dispatch batches of a single task at a time as the threading backend has very little overhead and using larger batch size has not proved to bring any gain in that case.</source>
          <target state="translated">Количество атомарных задач для одновременной отправки каждому исполнителю. Когда отдельные оценки выполняются очень быстро, отправка вызовов работникам может быть медленнее, чем последовательные вычисления из-за накладных расходов. Пакетирование быстрых вычислений может уменьшить это. &lt;code&gt;'auto'&lt;/code&gt; стратегия отслеживает время, необходимое для замеса к полной и динамически регулирует размер пакета , чтобы сохранить время порядка полсекунды, используя эвристические. Начальный размер пакета равен 1. &lt;code&gt;batch_size=&quot;auto&quot;&lt;/code&gt; с &lt;code&gt;backend=&quot;threading&quot;&lt;/code&gt; будет отправлять пакеты одной задачи за раз, так как серверная часть потоковой обработки имеет очень небольшие накладные расходы, и использование большего размера пакета не принесло никакой выгоды в этом кейс.</target>
        </trans-unit>
        <trans-unit id="3ae39cb6a942b138204dbb141781bfb4c75e3760" translate="yes" xml:space="preserve">
          <source>The number of base estimators in the ensemble.</source>
          <target state="translated">Количество базовых оценок в ансамбле.</target>
        </trans-unit>
        <trans-unit id="9fe1c6517ea4c36af295e91a2e2410361ff8432c" translate="yes" xml:space="preserve">
          <source>The number of batches (of tasks) to be pre-dispatched. Default is &amp;lsquo;2*n_jobs&amp;rsquo;. When batch_size=&amp;rdquo;auto&amp;rdquo; this is reasonable default and the workers should never starve.</source>
          <target state="translated">Количество пакетов (задач) для предварительной отправки. По умолчанию &amp;laquo;2 * n_jobs&amp;raquo;. Когда batch_size = &amp;rdquo;auto&amp;rdquo;, это разумное значение по умолчанию, и рабочие никогда не должны голодать.</target>
        </trans-unit>
        <trans-unit id="f9d0a981566d58378881b2cabe57053da9d34fb6" translate="yes" xml:space="preserve">
          <source>The number of biclusters to find.</source>
          <target state="translated">Количество найденных бикластеров.</target>
        </trans-unit>
        <trans-unit id="b9c52ec2125ed0e2339a6eae69fb246b4dc5348e" translate="yes" xml:space="preserve">
          <source>The number of biclusters.</source>
          <target state="translated">Количество блюстеров.</target>
        </trans-unit>
        <trans-unit id="d76125e41f0deb521acf9ed71af5267a484f2d30" translate="yes" xml:space="preserve">
          <source>The number of bins to produce. Raises ValueError if &lt;code&gt;n_bins &amp;lt; 2&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3424019fa75a2f96f62b30f8336ea4cebfa5c4fe" translate="yes" xml:space="preserve">
          <source>The number of bins to produce. The intervals for the bins are determined by the minimum and maximum of the input data. Raises ValueError if &lt;code&gt;n_bins &amp;lt; 2&lt;/code&gt;.</source>
          <target state="translated">Количество бункеров для производства. Интервалы для бинов определяются минимумом и максимумом входных данных. &lt;code&gt;n_bins &amp;lt; 2&lt;/code&gt; ValueError, если n_bins &amp;lt;2 .</target>
        </trans-unit>
        <trans-unit id="b2f078045a64e3b870ff56d7d5abb73dda7d8a43" translate="yes" xml:space="preserve">
          <source>The number of bins used to bin the data is controlled with the &lt;code&gt;max_bins&lt;/code&gt; parameter. Using less bins acts as a form of regularization. It is generally recommended to use as many bins as possible, which is the default.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="016567b86fa6f6a4b4c043763b4e841bd445fc32" translate="yes" xml:space="preserve">
          <source>The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.</source>
          <target state="translated">Количество повышающих ступеней для выполнения.Ускорение градиента достаточно надежно для переподгонки,поэтому большое количество ступеней обычно приводит к лучшей производительности.</target>
        </trans-unit>
        <trans-unit id="d5d9cefb2fff3dbdd417050b8ce7c297d42aaa9f" translate="yes" xml:space="preserve">
          <source>The number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;) is a positive integer (0 included). Thus, this target can be modelled by a Poisson distribution. It is then assumed to be the number of discrete events occuring with a constant rate in a given time interval (&lt;code&gt;Exposure&lt;/code&gt;, in units of years). Here we model the frequency &lt;code&gt;y = ClaimNb / Exposure&lt;/code&gt;, which is still a (scaled) Poisson distribution, and use &lt;code&gt;Exposure&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a186b2a8600030ec87eb172dc6f657942fddfcfb" translate="yes" xml:space="preserve">
          <source>The number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;) is a positive integer that can be modeled as a Poisson distribution. It is then assumed to be the number of discrete events occurring with a constant rate in a given time interval (&lt;code&gt;Exposure&lt;/code&gt;, in units of years).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31e8a7065eae23aeb71500302a31ebb485560ec" translate="yes" xml:space="preserve">
          <source>The number of classes</source>
          <target state="translated">Количество классов</target>
        </trans-unit>
        <trans-unit id="77a0204799f583fccb414a4215d0dc841510a2f7" translate="yes" xml:space="preserve">
          <source>The number of classes (for single output problems), or a list containing the number of classes for each output (for multi-output problems).</source>
          <target state="translated">Количество классов (для одиночных выходных задач),или список,содержащий количество классов для каждого выхода (для многовыходных задач).</target>
        </trans-unit>
        <trans-unit id="221daa93ea83049b71eff667b2da7d0ce3fa89ae" translate="yes" xml:space="preserve">
          <source>The number of classes (or labels) of the classification problem.</source>
          <target state="translated">Количество классов (или меток)проблемы классификации.</target>
        </trans-unit>
        <trans-unit id="7b75bf8cc583f50195e96e51d244ce57f23360a0" translate="yes" xml:space="preserve">
          <source>The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).</source>
          <target state="translated">Количество классов (одна выходная задача),или список,содержащий количество классов для каждого выхода (многовыходная задача).</target>
        </trans-unit>
        <trans-unit id="8b5fc0d622c5abb76da13c6a8f50c84a211eca46" translate="yes" xml:space="preserve">
          <source>The number of classes in the training data</source>
          <target state="translated">Количество занятий в данных по обучению</target>
        </trans-unit>
        <trans-unit id="a096e01744ef01b9d139303dfd4a94a83569986b" translate="yes" xml:space="preserve">
          <source>The number of classes of the classification problem.</source>
          <target state="translated">Количество классов проблемы классификации.</target>
        </trans-unit>
        <trans-unit id="21583bce2023d80fa6dedc801ccace76e8a2445f" translate="yes" xml:space="preserve">
          <source>The number of classes to return.</source>
          <target state="translated">Количество классов,которые нужно вернуть.</target>
        </trans-unit>
        <trans-unit id="7defdc95bb1ddc0580ac0be76fc251278b72fb84" translate="yes" xml:space="preserve">
          <source>The number of classes.</source>
          <target state="translated">Количество классов.</target>
        </trans-unit>
        <trans-unit id="9298de4c7bbca93c3d80fc1d9af6567cb0b29b0a" translate="yes" xml:space="preserve">
          <source>The number of clusters found by the algorithm. If &lt;code&gt;distance_threshold=None&lt;/code&gt;, it will be equal to the given &lt;code&gt;n_clusters&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="062fe5ee9cf896a5c74f9ba057f89b8b6de5fa8a" translate="yes" xml:space="preserve">
          <source>The number of clusters per class.</source>
          <target state="translated">Количество кластеров в классе.</target>
        </trans-unit>
        <trans-unit id="21f23a23e06d5c295fade98ab37ab55d16e621ca" translate="yes" xml:space="preserve">
          <source>The number of clusters to find.</source>
          <target state="translated">Количество кластеров,которые нужно найти.</target>
        </trans-unit>
        <trans-unit id="703c8a00edcb110a0abc7bd2f2de73653cb3b8bc" translate="yes" xml:space="preserve">
          <source>The number of clusters to find. It must be &lt;code&gt;None&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4184f0399110f5f8e690a26513dd6f78511c0a5" translate="yes" xml:space="preserve">
          <source>The number of clusters to form as well as the number of centroids to generate.</source>
          <target state="translated">Количество кластеров,которые необходимо сформировать,а также количество центроидов,которые необходимо сгенерировать.</target>
        </trans-unit>
        <trans-unit id="35d84f4a157603ef94bd9baafa0d524311104205" translate="yes" xml:space="preserve">
          <source>The number of columns in the grid plot (default: 3).</source>
          <target state="translated">Количество столбцов на графике сетки (по умолчанию:3).</target>
        </trans-unit>
        <trans-unit id="1ab9cd0e34ad15344a0623bebcdec3c277a5d196" translate="yes" xml:space="preserve">
          <source>The number of components. It is same as the &lt;code&gt;n_components&lt;/code&gt; parameter if it was given. Otherwise, it will be same as the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25441c707266953707d0c752071de32d0051d235" translate="yes" xml:space="preserve">
          <source>The number of connected components in the graph.</source>
          <target state="translated">Количество подключенных компонентов на графике.</target>
        </trans-unit>
        <trans-unit id="5d17146f816382e55c9752b437d1e0a90ca8e256" translate="yes" xml:space="preserve">
          <source>The number of cross-validation splits (folds/iterations).</source>
          <target state="translated">Количество перекрестных проверок расщеплений (складок/изображений).</target>
        </trans-unit>
        <trans-unit id="4e96a6f0802b675664ce18cac028e5815cdfcfc0" translate="yes" xml:space="preserve">
          <source>The number of data features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa32f92ae0454e6e9ee52207fe93d7eb6600c995" translate="yes" xml:space="preserve">
          <source>The number of degrees of freedom of each components in the model.</source>
          <target state="translated">Количество степеней свободы каждого компонента модели.</target>
        </trans-unit>
        <trans-unit id="b2ef77453518fcb650d3ae2f90fcfda15611a36f" translate="yes" xml:space="preserve">
          <source>The number of duplicated features, drawn randomly from the informative and the redundant features.</source>
          <target state="translated">Количество дублируемых функций,случайным образом заимствованных из информативных и избыточных функций.</target>
        </trans-unit>
        <trans-unit id="81a86627bf928c8685cc6768d089212f83e7a3d6" translate="yes" xml:space="preserve">
          <source>The number of elements of the hyperparameter value. Defaults to 1, which corresponds to a scalar hyperparameter. n_elements &amp;gt; 1 corresponds to a hyperparameter which is vector-valued, such as, e.g., anisotropic length-scales.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3756e321fd8c5762ae8ac31516f2ecb21110717" translate="yes" xml:space="preserve">
          <source>The number of equally spaced points on the &lt;code&gt;grid&lt;/code&gt;.</source>
          <target state="translated">Количество равноотстоящих точек на &lt;code&gt;grid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1ea7fab9bca4ccb2b6b305c06e165e2e51c05101" translate="yes" xml:space="preserve">
          <source>The number of equally spaced points on the axes of the plots, for each target feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29bfd2ea8e3e1682dd4a79d1706f446dfb38a05" translate="yes" xml:space="preserve">
          <source>The number of equally spaced points on the axes.</source>
          <target state="translated">Количество одинаково расположенных точек на осях.</target>
        </trans-unit>
        <trans-unit id="6843d07b6a565b2c9c3cc44410aeae6ef1353131" translate="yes" xml:space="preserve">
          <source>The number of equally spaced points on the grid, for each target feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2df871c8f4e92cb59ed15324ccda38fad42ea75" translate="yes" xml:space="preserve">
          <source>The number of estimators as selected by early stopping (if &lt;code&gt;n_iter_no_change&lt;/code&gt; is specified). Otherwise it is set to &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">Количество оценщиков, выбранное при ранней остановке (если &lt;code&gt;n_iter_no_change&lt;/code&gt; ). В противном случае устанавливается значение &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1c41aa32f1f0f6cf009b98065236eda5fafde67a" translate="yes" xml:space="preserve">
          <source>The number of features (columns) in the output matrices. Small numbers of features are likely to cause hash collisions, but large numbers will cause larger coefficient dimensions in linear learners.</source>
          <target state="translated">Количество функций (столбцов)в выходных матрицах.Небольшое количество признаков может привести к столкновению хэшей,но большое количество приведет к большим размерам коэффициентов у линейных учащихся.</target>
        </trans-unit>
        <trans-unit id="586a175a91db906a71d554d2394ac768c54a011d" translate="yes" xml:space="preserve">
          <source>The number of features for each sample.</source>
          <target state="translated">Количество функций для каждого образца.</target>
        </trans-unit>
        <trans-unit id="7aa2f8ce84af9869f7a766d49383cc26f37d08c4" translate="yes" xml:space="preserve">
          <source>The number of features has to be &amp;gt;= 5.</source>
          <target state="translated">Количество функций должно быть&amp;gt; = 5.</target>
        </trans-unit>
        <trans-unit id="129d21ac97bd672e4633231039dccb80b794a16c" translate="yes" xml:space="preserve">
          <source>The number of features to consider when looking for the best split:</source>
          <target state="translated">Количество функций,которые следует учитывать при поиске лучшего разделения:</target>
        </trans-unit>
        <trans-unit id="c3e18b2792aee2f260136dbfb16e08ac8ac5d9d0" translate="yes" xml:space="preserve">
          <source>The number of features to draw from X to train each base estimator ( without replacement by default, see &lt;code&gt;bootstrap_features&lt;/code&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bfa1c66757d06ac8d59fc4bf744ebce5057ba13" translate="yes" xml:space="preserve">
          <source>The number of features to draw from X to train each base estimator.</source>
          <target state="translated">Количество функций,которые можно отрисовать из X для обучения каждого базового оценщика.</target>
        </trans-unit>
        <trans-unit id="d51bb9401f1843316f34a353f5592cb098582ce3" translate="yes" xml:space="preserve">
          <source>The number of features to select. If &lt;code&gt;None&lt;/code&gt;, half of the features are selected.</source>
          <target state="translated">Количество функций для выбора. Если &lt;code&gt;None&lt;/code&gt; , выбирается половина функций.</target>
        </trans-unit>
        <trans-unit id="9a2e8b8c9f83e59315eadeb30286733009f73579" translate="yes" xml:space="preserve">
          <source>The number of features to use. If None, it will be inferred from the maximum column index occurring in any of the files.</source>
          <target state="translated">Количество используемых функций.Если None,то это будет выведено из максимального индекса столбцов,встречающегося в любом из файлов.</target>
        </trans-unit>
        <trans-unit id="98598b839c3ae52a8bef761a8c292e4971f87fa1" translate="yes" xml:space="preserve">
          <source>The number of features to use. If None, it will be inferred. This argument is useful to load several files that are subsets of a bigger sliced dataset: each subset might not have examples of every feature, hence the inferred shape might vary from one slice to another. n_features is only required if &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed a non-default value.</source>
          <target state="translated">Количество используемых функций. Если None, это будет предполагаться. Этот аргумент полезен для загрузки нескольких файлов, которые являются подмножествами более крупного среза набора данных: каждое подмножество может не иметь примеров каждой функции, поэтому предполагаемая форма может варьироваться от одного фрагмента к другому. n_features требуется только в том случае, если &lt;code&gt;offset&lt;/code&gt; или &lt;code&gt;length&lt;/code&gt; передаются не по умолчанию.</target>
        </trans-unit>
        <trans-unit id="3f0c441872fc889415f948d3a194dda00a747f75" translate="yes" xml:space="preserve">
          <source>The number of features when &lt;a href=&quot;#sklearn.ensemble.BaggingClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65e177587b4163893d6713a7981471e039d2ab1a" translate="yes" xml:space="preserve">
          <source>The number of features when &lt;a href=&quot;#sklearn.ensemble.BaggingRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="deca4fdfd1ca37b7e04bbcf3985c1b98fb8a3a95" translate="yes" xml:space="preserve">
          <source>The number of features when &lt;code&gt;fit&lt;/code&gt; is performed.</source>
          <target state="translated">Количество функций при &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="000ec70bd77b0bf4abd3e711fc085eb14c1166a9" translate="yes" xml:space="preserve">
          <source>The number of features.</source>
          <target state="translated">Количество функций.</target>
        </trans-unit>
        <trans-unit id="9910eba7c229f9255e2c9649c38205ffc855802c" translate="yes" xml:space="preserve">
          <source>The number of features. Should be at least 5.</source>
          <target state="translated">Количество функций.Должно быть не менее 5.</target>
        </trans-unit>
        <trans-unit id="6b858bf37b4f474c4599d32f8587786621c82cda" translate="yes" xml:space="preserve">
          <source>The number of informative features, i.e., the number of features used to build the linear model used to generate the output.</source>
          <target state="translated">Количество информативных признаков,т.е.количество признаков,используемых для построения линейной модели,используемой для генерации выхода.</target>
        </trans-unit>
        <trans-unit id="1a77292033054c608772a804dab5a2e1fdf27c5c" translate="yes" xml:space="preserve">
          <source>The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices of a hypercube in a subspace of dimension &lt;code&gt;n_informative&lt;/code&gt;. For each cluster, informative features are drawn independently from N(0, 1) and then randomly linearly combined within each cluster in order to add covariance. The clusters are then placed on the vertices of the hypercube.</source>
          <target state="translated">Количество информативных функций. Каждый класс состоит из ряда гауссовских кластеров, каждый из которых расположен вокруг вершин гиперкуба в подпространстве размерности &lt;code&gt;n_informative&lt;/code&gt; . Для каждого кластера информативные признаки рисуются независимо от N (0, 1), а затем случайным образом линейно комбинируются внутри каждого кластера для добавления ковариации. Затем кластеры размещаются в вершинах гиперкуба.</target>
        </trans-unit>
        <trans-unit id="8860e037fbe039fe78d5e3c48f8e1848feb12312" translate="yes" xml:space="preserve">
          <source>The number of initializations to perform. The best results are kept.</source>
          <target state="translated">Количество инициализаций,которые необходимо выполнить.Сохраняются лучшие результаты.</target>
        </trans-unit>
        <trans-unit id="51a26d62cae82295bdfa00f11021a221252f4d93" translate="yes" xml:space="preserve">
          <source>The number of initializations to perform. The result with the highest lower bound value on the likelihood is kept.</source>
          <target state="translated">Количество инициализаций,которые необходимо выполнить.Результат с наибольшим значением нижней границы вероятности сохраняется.</target>
        </trans-unit>
        <trans-unit id="38ff309a985e30ab2e29b9afc192f79c8b9a0c6a" translate="yes" xml:space="preserve">
          <source>The number of integer to sample.</source>
          <target state="translated">Количество целых чисел в выборке.</target>
        </trans-unit>
        <trans-unit id="a52a9529854ceea9a883fc2df829925e52c70f47" translate="yes" xml:space="preserve">
          <source>The number of iteration on data batches that has been performed before this call to partial_fit. This is optional: if no number is passed, the memory of the object is used.</source>
          <target state="translated">Номер итерации по пакетам данных,которая была выполнена до этого вызова на partial_fit.Это необязательно:если номер не передан,используется память объекта.</target>
        </trans-unit>
        <trans-unit id="99c30bd94e39fd4b9ed3f7e2a7d5b85b28ed521a" translate="yes" xml:space="preserve">
          <source>The number of iteration on data batches that has been performed before.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a86dc5cbf697553ae74ea1f2c0f3574967cc15f4" translate="yes" xml:space="preserve">
          <source>The number of iterations as selected by early stopping, depending on the &lt;code&gt;early_stopping&lt;/code&gt; parameter. Otherwise it corresponds to max_iter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3bc7b28196b3922c89415e845096f6cf78b8faf" translate="yes" xml:space="preserve">
          <source>The number of iterations corresponding to the best stress. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Количество итераций, соответствующее лучшему напряжению. Возвращается, только если &lt;code&gt;return_n_iter&lt;/code&gt; имеет значение &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="09e334ba47a4a0e3959de08638739eb9eaaab635" translate="yes" xml:space="preserve">
          <source>The number of iterations taken by lars_path to find the grid of alphas for each target.</source>
          <target state="translated">Количество итераций,выполняемых lars_path для нахождения сетки альфов для каждой цели.</target>
        </trans-unit>
        <trans-unit id="b1098a1922ae37c291de7345b0094c64c3a02834" translate="yes" xml:space="preserve">
          <source>The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha.</source>
          <target state="translated">Количество итераций,выполняемых оптимизатором по спуску координат для достижения заданного допуска для каждого альфа.</target>
        </trans-unit>
        <trans-unit id="cb53eef7959113120386cfa7066166d0b269478f" translate="yes" xml:space="preserve">
          <source>The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when &lt;code&gt;return_n_iter&lt;/code&gt; is set to True).</source>
          <target state="translated">Число итераций, выполненных оптимизатором спуска координат для достижения указанного допуска для каждого альфа. (Возвращается, если &lt;code&gt;return_n_iter&lt;/code&gt; имеет значение True).</target>
        </trans-unit>
        <trans-unit id="33de6e55bb60c2bc5ac457a31b105deefc3f996b" translate="yes" xml:space="preserve">
          <source>The number of iterations the solver has ran.</source>
          <target state="translated">Количество итераций,которое провел решатель.</target>
        </trans-unit>
        <trans-unit id="28e3bc9f7f876eba064c747240fb8d2ff652b8df" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel all &lt;code&gt;estimators&lt;/code&gt;&lt;code&gt;fit&lt;/code&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;code&gt;joblib.parallel_backend&lt;/code&gt; context. -1 means using all processors. See Glossary for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2412be87a40770d353886ae29c8c16a95b728197" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for &lt;a href=&quot;#sklearn.multioutput.MultiOutputRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbb843cd2b1d5904ac077f6964fae31def7713e0" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for &lt;code&gt;fit&lt;/code&gt; of all &lt;code&gt;estimators&lt;/code&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;code&gt;joblib.parallel_backend&lt;/code&gt; context. -1 means using all processors. See Glossary for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db80deec4964c14c90bbb2ba0d38dab8d92c99f4" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for &lt;code&gt;fit&lt;/code&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество рабочих мест , работать параллельно для &lt;code&gt;fit&lt;/code&gt; . &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="f140b3227d03089cb6e6210a5db41bedf6b9aa63" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for &lt;code&gt;fit&lt;/code&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9c5c499bb768493660dc4f85003a1f155b88c8c" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for both &lt;a href=&quot;#sklearn.ensemble.BaggingClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.BaggingClassifier.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e98b60a4f63df4b45688240803363e4326e4c3c" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for both &lt;a href=&quot;#sklearn.ensemble.BaggingRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.BaggingRegressor.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="631e50edfdf734f4505b382652be3db79f846fe9" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for both &lt;a href=&quot;#sklearn.ensemble.IsolationForest.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.IsolationForest.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="828e81cc3e32985aa18f25c0aa8cb224a18c0ff7" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for both &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий для параллельного выполнения как для &lt;code&gt;fit&lt;/code&gt; и для &lt;code&gt;predict&lt;/code&gt; . &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="c43ba6eb14ab669b0479493b6caf6c135c124b5c" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel for both &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;. &lt;code&gt;None`&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий для параллельного выполнения как для &lt;code&gt;fit&lt;/code&gt; и для &lt;code&gt;predict&lt;/code&gt; . &lt;code&gt;None`&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="b1734bf8c02c7376c103570d8af07531d90ec5dd" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel. &lt;a href=&quot;#sklearn.ensemble.ExtraTreesClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.ExtraTreesClassifier.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.ExtraTreesClassifier.decision_path&quot;&gt;&lt;code&gt;decision_path&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.ExtraTreesClassifier.apply&quot;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/a&gt; are all parallelized over the trees. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30ff6a93f265905272a4a92b5eefd941a956fb0c" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel. &lt;a href=&quot;#sklearn.ensemble.ExtraTreesRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.ExtraTreesRegressor.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.ExtraTreesRegressor.decision_path&quot;&gt;&lt;code&gt;decision_path&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.ExtraTreesRegressor.apply&quot;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/a&gt; are all parallelized over the trees. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8618a7401b1bd61324e6d152687e714d9dfac99" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel. &lt;a href=&quot;#sklearn.ensemble.RandomForestClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomForestClassifier.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomForestClassifier.decision_path&quot;&gt;&lt;code&gt;decision_path&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.RandomForestClassifier.apply&quot;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/a&gt; are all parallelized over the trees. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c242a688459caf97557bbb76035f6cc722015df4" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel. &lt;a href=&quot;#sklearn.ensemble.RandomForestRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomForestRegressor.predict&quot;&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomForestRegressor.decision_path&quot;&gt;&lt;code&gt;decision_path&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.RandomForestRegressor.apply&quot;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/a&gt; are all parallelized over the trees. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91298d7ca6e21328dab1603b8e897f672cc46e7d" translate="yes" xml:space="preserve">
          <source>The number of jobs to run in parallel. &lt;a href=&quot;#sklearn.ensemble.RandomTreesEmbedding.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomTreesEmbedding.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#sklearn.ensemble.RandomTreesEmbedding.decision_path&quot;&gt;&lt;code&gt;decision_path&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.RandomTreesEmbedding.apply&quot;&gt;&lt;code&gt;apply&lt;/code&gt;&lt;/a&gt; are all parallelized over the trees. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c706846846b90bc0cd14952c05d5f24ee8d014f" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий, используемых для вычисления. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="2f8f980d4703b1ec3df64fe85f466c6c6170bcab" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6833984bce80d83c32632eedfcb38fdab54d1b8b" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. If multiple initializations are used (&lt;code&gt;n_init&lt;/code&gt;), each run of the algorithm is computed in parallel.</source>
          <target state="translated">Количество заданий, используемых для вычисления. Если используется несколько инициализаций ( &lt;code&gt;n_init&lt;/code&gt; ), каждый запуск алгоритма вычисляется параллельно.</target>
        </trans-unit>
        <trans-unit id="6691b8acedaea4810fafdb230140a5bee73c0f13" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. It does each target variable in y in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий, используемых для вычисления. Он выполняет каждую целевую переменную по y параллельно. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="be06d9a31cbe7a4bf21b6f4456cf1df2e9b8ee45" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. It does each target variable in y in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d27815195706836eb73a8c598c8129b01e46ca" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. This will only provide speedup for n_targets &amp;gt; 1 and sufficient large problems. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий, используемых для вычисления. Это обеспечит ускорение только для n_targets&amp;gt; 1 и достаточно больших проблем. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="ba376dc0fa282138bebfa832fa05fd19bdc385f3" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. This will only provide speedup for n_targets &amp;gt; 1 and sufficient large problems. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea0fe9213de8cdb23ff0f2fe182f38ade8bf1a8" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. This works by breaking down the pairwise matrix into n_jobs even slices and computing them in parallel.</source>
          <target state="translated">Количество рабочих мест для расчета.Это работает путем разбиения парной матрицы на n_jobs даже на срезы и вычисления их параллельно.</target>
        </trans-unit>
        <trans-unit id="355b7ccfb662137f73492d9f4ce45fbb16afbbbc" translate="yes" xml:space="preserve">
          <source>The number of jobs to use for the computation. This works by computing each of the n_init runs in parallel.</source>
          <target state="translated">Количество рабочих мест для расчета.Это работает путем параллельного вычисления каждого из n_init.</target>
        </trans-unit>
        <trans-unit id="a5a46de70d97dcbce1cd57e62c5d0b48ff30934b" translate="yes" xml:space="preserve">
          <source>The number of jobs to use in the E-step. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество заданий для использования на E-шаге. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="b51be92d99796ca039296711c164e0b4cf278e0a" translate="yes" xml:space="preserve">
          <source>The number of jobs to use in the E-step. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27ef8dc8b90e4adb5cf60c4b5861107cfc3fcd66" translate="yes" xml:space="preserve">
          <source>The number of leaves in the tree</source>
          <target state="translated">Количество листьев на дереве</target>
        </trans-unit>
        <trans-unit id="aa280d8fa86c4668dcae50e829dc6fe4b82c5c09" translate="yes" xml:space="preserve">
          <source>The number of longitudes (x) and latitudes (y) in the grid</source>
          <target state="translated">Количество долгот (x)и широт (y)в сетке</target>
        </trans-unit>
        <trans-unit id="c1079f8f5554d74d12065ae30d0d0d5ad6da869f" translate="yes" xml:space="preserve">
          <source>The number of mixture components.</source>
          <target state="translated">Количество компонентов смеси.</target>
        </trans-unit>
        <trans-unit id="1b5111fc1060a675cec3a1f3743c5b7235e4d74d" translate="yes" xml:space="preserve">
          <source>The number of mixture components. Depending on the data and the value of the &lt;code&gt;weight_concentration_prior&lt;/code&gt; the model can decide to not use all the components by setting some component &lt;code&gt;weights_&lt;/code&gt; to values very close to zero. The number of effective components is therefore smaller than n_components.</source>
          <target state="translated">Количество компонентов смеси. В зависимости от данных и значения &lt;code&gt;weight_concentration_prior&lt;/code&gt; модель может решить не использовать все компоненты, установив для некоторых компонентов &lt;code&gt;weights_&lt;/code&gt; значения, очень близкие к нулю. Таким образом, количество эффективных компонентов меньше, чем n_components.</target>
        </trans-unit>
        <trans-unit id="add0998b97eff8ce13b181824a749694c3eae657" translate="yes" xml:space="preserve">
          <source>The number of nearest neighbors to return</source>
          <target state="translated">Количество ближайших соседей,которые должны вернуться</target>
        </trans-unit>
        <trans-unit id="15fc684195ef8537dde92583b88b14e2ce9227a5" translate="yes" xml:space="preserve">
          <source>The number of neighbors considered (parameter n_neighbors) is typically set 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by samples that can potentially be local outliers. In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general.</source>
          <target state="translated">Количество рассматриваемых соседей (параметр n_neighbors)обычно устанавливается 1)больше,чем минимальное количество выборок,которое должен содержать кластер,так что другие выборки могут быть локальными отклонениями относительно этого кластера,и 2)меньше,чем максимальное количество близких по выборкам,которые потенциально могут быть локальными отклонениями.На практике такая информация,как правило,недоступна,а выборка n_neighbors=20,похоже,в целом работает хорошо.</target>
        </trans-unit>
        <trans-unit id="acccc5b01db683b034e704a8a9a779e161564526" translate="yes" xml:space="preserve">
          <source>The number of neighbors considered, (parameter n_neighbors) is typically set 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by samples that can potentially be local outliers. In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general.</source>
          <target state="translated">Количество рассматриваемых соседей (параметр n_neighbors)обычно устанавливается 1)больше,чем минимальное количество выборок,которое должен содержать кластер,так что другие выборки могут быть локальными отклонениями относительно этого кластера,и 2)меньше,чем максимальное количество близких по выборкам,которые потенциально могут быть локальными отклонениями.На практике такая информация,как правило,недоступна,а выборка n_neighbors=20,похоже,в целом работает хорошо.</target>
        </trans-unit>
        <trans-unit id="877763fdbf37d108bc07acba2c3c7a43a6b1f5d0" translate="yes" xml:space="preserve">
          <source>The number of occurrences of each label in &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">Количество появлений каждой метки в &lt;code&gt;y_true&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d77e127c483a951faddd4898060a91624b32c7e2" translate="yes" xml:space="preserve">
          <source>The number of outlying points matters, but also how much they are outliers.</source>
          <target state="translated">Количество удаленных точек имеет значение,но также и то,насколько они являются удаленными.</target>
        </trans-unit>
        <trans-unit id="28c74611a0fbfe9d7c9bc15166aba9285108f840" translate="yes" xml:space="preserve">
          <source>The number of outputs when &lt;code&gt;fit&lt;/code&gt; is performed.</source>
          <target state="translated">Количество выходов при &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bb79176b795c17c39b28af054f09df09e008175b" translate="yes" xml:space="preserve">
          <source>The number of outputs.</source>
          <target state="translated">Количество выходов.</target>
        </trans-unit>
        <trans-unit id="b09418506b739dbda708239c423400be69d20b7d" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search.</source>
          <target state="translated">Количество параллельных заданий для поиска соседей.</target>
        </trans-unit>
        <trans-unit id="f8c9b6b47de0b026f28768b5a0afa5c012cbf5fc" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество параллельных заданий, выполняемых для поиска соседей. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="7704c4671581e69d735cac67f4c8350e13fe7ef2" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details. Affects only &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.neighbors.kneighbors_graph#sklearn.neighbors.kneighbors_graph&quot;&gt;&lt;code&gt;kneighbors_graph&lt;/code&gt;&lt;/a&gt; methods.</source>
          <target state="translated">Количество параллельных заданий, выполняемых для поиска соседей. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации. Влияет только на &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;sklearn.neighbors.kneighbors_graph#sklearn.neighbors.kneighbors_graph&quot;&gt; &lt;code&gt;kneighbors_graph&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="361059c7cf2c1088b100ce86f03251d9b9b3606a" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details. Doesn&amp;rsquo;t affect &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">Количество параллельных заданий, выполняемых для поиска соседей. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации. Не влияет на метод &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d88911bb44ab8ec6ef4a44ece33bbbd3a1ce8ce" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details. Doesn&amp;rsquo;t affect &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">Количество параллельных заданий, выполняемых для поиска соседей. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации. Не влияет на метод &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1e03b6a0d6693562cf04d81d449658ec683196ea" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab2a0224fab84a593d45a145e0638371b6911fd8" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details. Doesn&amp;rsquo;t affect &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecd1b3d7da18bb6dc421488bb596e855ecb80e43" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details. Doesn&amp;rsquo;t affect &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f8cf8af9be5d62ff8935fbef652326c9adba1d1" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. If &lt;code&gt;-1&lt;/code&gt;, then the number of jobs is set to the number of CPU cores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e352fe55bf07363046d5192af0f663c879039cfb" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run for neighbors search. This parameter has no impact when &lt;code&gt;metric=&quot;precomputed&quot;&lt;/code&gt; or (&lt;code&gt;metric=&quot;euclidean&quot;&lt;/code&gt; and &lt;code&gt;method=&quot;exact&quot;&lt;/code&gt;). &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92152098131975c56771bce4e909262b46d5eb7d" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">Количество параллельных заданий для запуска. &lt;code&gt;None&lt;/code&gt; означает 1, если только в контексте &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;-1&lt;/code&gt; означает использование всех процессоров. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Глоссарий&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="d31f80403a0bc612aeee728ef96a0071578ad09f" translate="yes" xml:space="preserve">
          <source>The number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99143dd67a79337f4ad9e3dbea2cd1e515a938df" translate="yes" xml:space="preserve">
          <source>The number of passes over the training data (aka epochs). Defaults to None. Deprecated, will be removed in 0.21.</source>
          <target state="translated">Количество проходов по данным тренировок (так называемые эпохи).По умолчанию нет.Исключено,будет удалено в 0.21.</target>
        </trans-unit>
        <trans-unit id="ec5cdfb884714451da411c4ff8cb1db87b4e7636" translate="yes" xml:space="preserve">
          <source>The number of redundant features. These features are generated as random linear combinations of the informative features.</source>
          <target state="translated">Количество избыточных функций.Эти функции генерируются в виде случайных линейных комбинаций информативных признаков.</target>
        </trans-unit>
        <trans-unit id="47b1c5caf88dbd07fabbf6968de5281c23c7d24f" translate="yes" xml:space="preserve">
          <source>The number of regression targets, i.e., the dimension of the y output vector associated with a sample. By default, the output is a scalar.</source>
          <target state="translated">Количество целей регрессии,т.е.размер выходного вектора y,связанного с выборкой.По умолчанию выходной вектор является скаляром.</target>
        </trans-unit>
        <trans-unit id="338ec305a58ac58159822d262713a3e274e16037" translate="yes" xml:space="preserve">
          <source>The number of restarts of the optimizer for finding the kernel&amp;rsquo;s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel&amp;rsquo;s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer == 0 implies that one run is performed.</source>
          <target state="translated">Число перезапусков оптимизатора для нахождения параметров ядра, которые максимизируют предельное логарифмическое правдоподобие. Первый запуск оптимизатора выполняется из начальных параметров ядра, остальные (если есть) из тэта выборки логарифмически равномерно случайным образом из пространства допустимых тета-значений. Если больше 0, все границы должны быть конечными. Обратите внимание, что n_restarts_optimizer == 0 означает, что выполняется один запуск.</target>
        </trans-unit>
        <trans-unit id="a4b3a5a4d2704e96fc904a7b55b3f1c5b2c8d507" translate="yes" xml:space="preserve">
          <source>The number of restarts of the optimizer for finding the kernel&amp;rsquo;s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel&amp;rsquo;s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer=0 implies that one run is performed.</source>
          <target state="translated">Число перезапусков оптимизатора для нахождения параметров ядра, которые максимизируют предельное логарифмическое правдоподобие. Первый запуск оптимизатора выполняется из начальных параметров ядра, остальные (если есть) из тэта выборки логарифмически равномерно случайным образом из пространства допустимых тета-значений. Если больше 0, все границы должны быть конечными. Обратите внимание, что n_restarts_optimizer = 0 означает, что выполняется один запуск.</target>
        </trans-unit>
        <trans-unit id="8f64e7c256c29c0afec3f69dafbe77018e516c64" translate="yes" xml:space="preserve">
          <source>The number of row and column clusters in the checkerboard structure.</source>
          <target state="translated">Количество кластеров строк и столбцов в шахматной доске.</target>
        </trans-unit>
        <trans-unit id="1d47b9ac186fe69411b80e5cb5c0bc35de2b1552" translate="yes" xml:space="preserve">
          <source>The number of row and column clusters.</source>
          <target state="translated">Количество кластеров строк и столбцов.</target>
        </trans-unit>
        <trans-unit id="a93f4e954bb39f85a0cd6723eb5913eb20116e8e" translate="yes" xml:space="preserve">
          <source>The number of sample points on the S curve.</source>
          <target state="translated">Количество точек выборки на кривой S.</target>
        </trans-unit>
        <trans-unit id="e771006aa290a36177ef8a2fd15f85ed45a9f7ce" translate="yes" xml:space="preserve">
          <source>The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.</source>
          <target state="translated">Количество образцов (или общий вес)в окрестностях для точки,которую следует рассматривать как основную точку.Сюда входит и сама точка.</target>
        </trans-unit>
        <trans-unit id="d8023265c3023688c589a292c9dfac5ffedb5a44" translate="yes" xml:space="preserve">
          <source>The number of samples drawn from the Gaussian process</source>
          <target state="translated">Количество образцов,взятых из гауссовского процесса.</target>
        </trans-unit>
        <trans-unit id="c514b9b07551e0f76131a511ab26abfabcd4aa8a" translate="yes" xml:space="preserve">
          <source>The number of samples in a neighborhood for a point to be considered as a core point. Also, up and down steep regions can&amp;rsquo;t have more then &lt;code&gt;min_samples&lt;/code&gt; consecutive non-steep points. Expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9e5e159d14938dc3482cf1b66194258f9217ba8" translate="yes" xml:space="preserve">
          <source>The number of samples in a neighborhood for a point to be considered as a core point. Expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1589955effed900fd5766b276491de7c2d2b9bf4" translate="yes" xml:space="preserve">
          <source>The number of samples processed by the estimator for each feature. If there are not missing samples, the &lt;code&gt;n_samples_seen&lt;/code&gt; will be an integer, otherwise it will be an array. Will be reset on new calls to fit, but increments across &lt;code&gt;partial_fit&lt;/code&gt; calls.</source>
          <target state="translated">Количество выборок, обработанных оценщиком для каждой функции. Если нет отсутствующих образцов, &lt;code&gt;n_samples_seen&lt;/code&gt; будет целым числом, в противном случае это будет массив. Будет сброшен при новых вызовах, чтобы соответствовать, но увеличивается при вызовах &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8b8db8f325de293d35a9c6b4d95ec39fb2cca6ee" translate="yes" xml:space="preserve">
          <source>The number of samples processed by the estimator. It will be reset on new calls to fit, but increments across &lt;code&gt;partial_fit&lt;/code&gt; calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5282c1e1c469ae21abb6fc766981198bf00b68c4" translate="yes" xml:space="preserve">
          <source>The number of samples processed by the estimator. Will be reset on new calls to fit, but increments across &lt;code&gt;partial_fit&lt;/code&gt; calls.</source>
          <target state="translated">Количество выборок, обработанных оценщиком. Будет сброшен при новых вызовах, чтобы соответствовать, но увеличивается при вызовах &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="baac00734c9f0ef53943bb384323fdc39b43973f" translate="yes" xml:space="preserve">
          <source>The number of samples to draw from X to train each base estimator (with replacement by default, see &lt;code&gt;bootstrap&lt;/code&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1793fd9997ff1f0552981d710a775a55fe6d48a0" translate="yes" xml:space="preserve">
          <source>The number of samples to draw from X to train each base estimator.</source>
          <target state="translated">Количество образцов,которые можно взять из Х,чтобы обучить каждого базового оценщика.</target>
        </trans-unit>
        <trans-unit id="bb3a932b7568c921848c0d1cfe6540980845aa8f" translate="yes" xml:space="preserve">
          <source>The number of samples to take in each batch.</source>
          <target state="translated">Количество проб,которые необходимо взять в каждой партии.</target>
        </trans-unit>
        <trans-unit id="45c4c8ec08a2e1d782bf77a47114ec6ebd4dca5e" translate="yes" xml:space="preserve">
          <source>The number of samples to use for each batch. Only used when calling &lt;code&gt;fit&lt;/code&gt;. If &lt;code&gt;batch_size&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, then &lt;code&gt;batch_size&lt;/code&gt; is inferred from the data and set to &lt;code&gt;5 * n_features&lt;/code&gt;, to provide a balance between approximation accuracy and memory consumption.</source>
          <target state="translated">Количество образцов для использования в каждой партии. Используется только при вызове &lt;code&gt;fit&lt;/code&gt; . Если &lt;code&gt;batch_size&lt;/code&gt; равно &lt;code&gt;None&lt;/code&gt; , то &lt;code&gt;batch_size&lt;/code&gt; выводится из данных и устанавливается в &lt;code&gt;5 * n_features&lt;/code&gt; , чтобы обеспечить баланс между точностью аппроксимации и потреблением памяти.</target>
        </trans-unit>
        <trans-unit id="cc9506bec678834c1e3b7d03354e1ff3a3f08ddc" translate="yes" xml:space="preserve">
          <source>The number of samples to use. If not given, all samples are used.</source>
          <target state="translated">Количество используемых образцов.Если не указано,используются все образцы.</target>
        </trans-unit>
        <trans-unit id="06d71b7513bf6cfbd6babc125146f20e54cecd08" translate="yes" xml:space="preserve">
          <source>The number of samples.</source>
          <target state="translated">Количество образцов.</target>
        </trans-unit>
        <trans-unit id="8ed3bb3b4a6145be5f5af9755587163fa8bebbaa" translate="yes" xml:space="preserve">
          <source>The number of seconds contained in delta</source>
          <target state="translated">Количество секунд в дельте</target>
        </trans-unit>
        <trans-unit id="fd2b02981da97aea3b937c6f113a2aa5413af4a0" translate="yes" xml:space="preserve">
          <source>The number of selected features with cross-validation.</source>
          <target state="translated">Количество выбранных функций с перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="f83194da71427b41aa36e9d801ef17814b93c795" translate="yes" xml:space="preserve">
          <source>The number of selected features.</source>
          <target state="translated">Количество выбранных функций.</target>
        </trans-unit>
        <trans-unit id="ecf3b2d99c2ce29bc7f1b5f51d42517d75e68e85" translate="yes" xml:space="preserve">
          <source>The number of stages of the final model is available at the attribute &lt;code&gt;n_estimators_&lt;/code&gt;.</source>
          <target state="translated">Количество этапов финальной модели доступно в атрибуте &lt;code&gt;n_estimators_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d8f394636e1a93d63e3434a6391ec5ef2f73741a" translate="yes" xml:space="preserve">
          <source>The number of threads used by the OpenBLAS, MKL or BLIS libraries can be set via the &lt;code&gt;MKL_NUM_THREADS&lt;/code&gt;, &lt;code&gt;OPENBLAS_NUM_THREADS&lt;/code&gt;, and &lt;code&gt;BLIS_NUM_THREADS&lt;/code&gt; environment variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40db2965d8f58e28ab3da3567d512db3201d5fa4" translate="yes" xml:space="preserve">
          <source>The number of times the grid is refined. Not used if explicit values of alphas are passed.</source>
          <target state="translated">Количество уточнений сетки.Не используется,если передаются явные значения альфов.</target>
        </trans-unit>
        <trans-unit id="642e04b02615d230b9669f1186145c403a47fbce" translate="yes" xml:space="preserve">
          <source>The number of times the grid is refined. Not used if explicit values of alphas are passed. Range is [1, inf).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="089ef760cb35bf7968ad0395345a0886662c0be1" translate="yes" xml:space="preserve">
          <source>The number of tree that are built at each iteration. For regressors, this is always 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20cb5259cf581cee4993b651401d828750438d9c" translate="yes" xml:space="preserve">
          <source>The number of tree that are built at each iteration. This is equal to 1 for binary classification, and to &lt;code&gt;n_classes&lt;/code&gt; for multiclass classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b5e4a652e0296cb387fe06bf82a965799e670b1" translate="yes" xml:space="preserve">
          <source>The number of trees in the forest.</source>
          <target state="translated">Количество деревьев в лесу.</target>
        </trans-unit>
        <trans-unit id="b609a37dc2d7220a5b1e0ac4ad20a19f7617a90e" translate="yes" xml:space="preserve">
          <source>The number of weak learners (i.e. regression trees) is controlled by the parameter &lt;code&gt;n_estimators&lt;/code&gt;; &lt;a href=&quot;#gradient-boosting-tree-size&quot;&gt;The size of each tree&lt;/a&gt; can be controlled either by setting the tree depth via &lt;code&gt;max_depth&lt;/code&gt; or by setting the number of leaf nodes via &lt;code&gt;max_leaf_nodes&lt;/code&gt;. The &lt;code&gt;learning_rate&lt;/code&gt; is a hyper-parameter in the range (0.0, 1.0] that controls overfitting via &lt;a href=&quot;#gradient-boosting-shrinkage&quot;&gt;shrinkage&lt;/a&gt; .</source>
          <target state="translated">Количество слабых учеников (т.е. деревьев регрессии) контролируется параметром &lt;code&gt;n_estimators&lt;/code&gt; ; &lt;a href=&quot;#gradient-boosting-tree-size&quot;&gt;Размер каждого дерева&lt;/a&gt; можно контролировать либо путем установки глубины дерева через &lt;code&gt;max_depth&lt;/code&gt; , либо путем установки количества &lt;code&gt;max_leaf_nodes&lt;/code&gt; узлов через max_leaf_nodes . &lt;code&gt;learning_rate&lt;/code&gt; является гипер-параметр в диапазоне (0,0, 1,0] , который управляет переобучения с помощью &lt;a href=&quot;#gradient-boosting-shrinkage&quot;&gt;усадки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="68e68bbcb31faf3cd13be5ec90f20eecf860f6d7" translate="yes" xml:space="preserve">
          <source>The number of weak learners is controlled by the parameter &lt;code&gt;n_estimators&lt;/code&gt;. The &lt;code&gt;learning_rate&lt;/code&gt; parameter controls the contribution of the weak learners in the final combination. By default, weak learners are decision stumps. Different weak learners can be specified through the &lt;code&gt;base_estimator&lt;/code&gt; parameter. The main parameters to tune to obtain good results are &lt;code&gt;n_estimators&lt;/code&gt; and the complexity of the base estimators (e.g., its depth &lt;code&gt;max_depth&lt;/code&gt; or minimum required number of samples to consider a split &lt;code&gt;min_samples_split&lt;/code&gt;).</source>
          <target state="translated">Количество слабых учеников контролируется параметром &lt;code&gt;n_estimators&lt;/code&gt; . Параметр &lt;code&gt;learning_rate&lt;/code&gt; контролирует вклад слабых учеников в финальную комбинацию. По умолчанию слабые ученики становятся препятствием для принятия решения. С помощью параметра &lt;code&gt;base_estimator&lt;/code&gt; можно указать разных слабых учеников . Основными параметрами, которые нужно настроить для получения хороших результатов, являются &lt;code&gt;n_estimators&lt;/code&gt; и сложность базовых оценок (например, его глубина &lt;code&gt;max_depth&lt;/code&gt; или минимальное необходимое количество выборок для рассмотрения разделения &lt;code&gt;min_samples_split&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="a6d1422bf72f5a61faa255a9a1207169e4a394c6" translate="yes" xml:space="preserve">
          <source>The object solves the same problem as the LassoCV object. However, unlike the LassoCV, it find the relevant alphas values by itself. In general, because of this property, it will be more stable. However, it is more fragile to heavily multicollinear datasets.</source>
          <target state="translated">Объект решает ту же задачу,что и объект LassoCV.Однако,в отличие от LassoCV,он находит соответствующие значения альфатов сам по себе.В целом,благодаря этому свойству,он будет более стабильным.Однако,оно более хрупко для сильно мультиколлинейных наборов данных.</target>
        </trans-unit>
        <trans-unit id="909e016dde1f323cbfe3daf2401dd2bee2829e0c" translate="yes" xml:space="preserve">
          <source>The object to use to fit the data.</source>
          <target state="translated">Объект,который необходимо использовать,чтобы соответствовать данным.</target>
        </trans-unit>
        <trans-unit id="d5c8a5f63b0e142ed66ba0f0aa5318c460719fdf" translate="yes" xml:space="preserve">
          <source>The object&amp;rsquo;s &lt;code&gt;best_score_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; attributes store the best mean score and the parameters setting corresponding to that score:</source>
          <target state="translated">В объекта &lt;code&gt;best_score_&lt;/code&gt; и &lt;code&gt;best_params_&lt;/code&gt; атрибутов хранения лучший средний балл и параметры настройки , соответствующие этому поводу:</target>
        </trans-unit>
        <trans-unit id="512dd720938772db73af76fb4221b6596459608c" translate="yes" xml:space="preserve">
          <source>The objective function is minimized with an alternating minimization of W and H.</source>
          <target state="translated">Объективная функция минимизируется с помощью попеременной минимизации W и H.</target>
        </trans-unit>
        <trans-unit id="f16ae566357b7a1e9f3616f2cbcfd46a6904b9f5" translate="yes" xml:space="preserve">
          <source>The objective function is minimized with an alternating minimization of W and H. If H is given and update_H=False, it solves for W only.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a139874cf1d9e2c13462d6567d8563d658f0907b" translate="yes" xml:space="preserve">
          <source>The objective function is:</source>
          <target state="translated">Объективная функция:</target>
        </trans-unit>
        <trans-unit id="bf56422fecab64934517c1fdfbcaed66ab27df08" translate="yes" xml:space="preserve">
          <source>The objective function to minimize is in this case</source>
          <target state="translated">В этом случае объективная функция заключается в том,чтобы свести к минимуму</target>
        </trans-unit>
        <trans-unit id="e546a5e9110cb4077ff5ab03d80b93cb6429070c" translate="yes" xml:space="preserve">
          <source>The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. Without loss of generality the factors are distributed according to a Gaussian with zero mean and unit covariance. The noise is also zero mean and has an arbitrary diagonal covariance matrix.</source>
          <target state="translated">Предполагается,что наблюдения вызваны линейным преобразованием низкоразмерных латентных факторов и добавлением гауссовского шума.Без потери общности коэффициенты распределены по Гауссу с нулевой средней и единичной ковариацией.Шум также является нулевым средним и имеет произвольную диагональную ковариационную матрицу.</target>
        </trans-unit>
        <trans-unit id="f8b5be5464139b25f15f97e4d9d483501d55af35" translate="yes" xml:space="preserve">
          <source>The observations to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">Наблюдения для кластера.Следует отметить,что данные будут преобразованы в порядок С,что вызовет копирование памяти,если данные не С-сопряжены.</target>
        </trans-unit>
        <trans-unit id="5af240b8e218ff237309779b56f83d5e52d1af7b" translate="yes" xml:space="preserve">
          <source>The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.</source>
          <target state="translated">Наблюдения,расстояния Махаланобиса,которые мы вычисляем.Наблюдения предполагаются из того же распределения,что и данные,использованные в соответствии с ними.</target>
        </trans-unit>
        <trans-unit id="eb71736c8c9acd5b1d75a4e7144f466f3b859a53" translate="yes" xml:space="preserve">
          <source>The obtained score is always strictly greater than 0 and the best value is 1.</source>
          <target state="translated">Полученная оценка всегда строго больше 0,а лучшая-1.</target>
        </trans-unit>
        <trans-unit id="b7dea734e0307eec19c3b5341e6f81839af6082a" translate="yes" xml:space="preserve">
          <source>The one-vs-the-rest meta-classifier also implements a &lt;code&gt;predict_proba&lt;/code&gt; method, so long as such a method is implemented by the base classifier. This method returns probabilities of class membership in both the single label and multilabel case. Note that in the multilabel case, probabilities are the marginal probability that a given sample falls in the given class. As such, in the multilabel case the sum of these probabilities over all possible labels for a given sample &lt;em&gt;will not&lt;/em&gt; sum to unity, as they do in the single label case.</source>
          <target state="translated">Мета-классификатор &amp;laquo;один против остальных&amp;raquo; также реализует метод &lt;code&gt;predict_proba&lt;/code&gt; , если такой метод реализуется базовым классификатором. Этот метод возвращает вероятности членства в классе как в случае с одной меткой, так и в случае с несколькими метками. Обратите внимание, что в случае с несколькими метками вероятности - это предельная вероятность того, что данная выборка попадает в данный класс. Таким образом, в случае с несколькими метками сумма этих вероятностей по всем возможным меткам для данного образца &lt;em&gt;не будет&lt;/em&gt; равна единице, как это происходит в случае с одной меткой.</target>
        </trans-unit>
        <trans-unit id="f36ee9570dbac199195d25256879fa51a751bbaa" translate="yes" xml:space="preserve">
          <source>The opposite LOF of the training samples. The higher, the more normal. Inliers tend to have a LOF score close to 1 (&lt;code&gt;negative_outlier_factor_&lt;/code&gt; close to -1), while outliers tend to have a larger LOF score.</source>
          <target state="translated">Обратный LOF обучающих выборок. Чем выше, тем нормальнее. Выбросы обычно имеют показатель LOF, близкий к 1 ( &lt;code&gt;negative_outlier_factor_&lt;/code&gt; близко к -1), в то время как выбросы имеют более высокий показатель LOF.</target>
        </trans-unit>
        <trans-unit id="df3e454f1090a47509e70dbea510891595829b28" translate="yes" xml:space="preserve">
          <source>The opposite of the Local Outlier Factor of each input samples. The lower, the more abnormal.</source>
          <target state="translated">Противоположность Коэффициента локального выброса каждой входной выборки.Чем ниже,тем более аномальный.</target>
        </trans-unit>
        <trans-unit id="4312ae849a138f7db034f6fd7f5a1ea0b817b171" translate="yes" xml:space="preserve">
          <source>The optimal algorithm for a given dataset is a complicated choice, and depends on a number of factors:</source>
          <target state="translated">Оптимальный алгоритм для данного набора данных является сложным выбором и зависит от ряда факторов:</target>
        </trans-unit>
        <trans-unit id="e994897b226c2495f8cea3f1e46f2c7029c61954" translate="yes" xml:space="preserve">
          <source>The optimal lambda parameter for minimizing skewness is estimated on each feature independently using maximum likelihood.</source>
          <target state="translated">Оптимальный параметр лямбда для минимизации асимметрии оценивается по каждому объекту независимо с максимальной вероятностью.</target>
        </trans-unit>
        <trans-unit id="033713ef73311880bab79fd88513749d67a56824" translate="yes" xml:space="preserve">
          <source>The optimization objective for Lasso is:</source>
          <target state="translated">Целью оптимизации для Лассо является:</target>
        </trans-unit>
        <trans-unit id="64214421bf615c105d2891f743437d06253a6ade" translate="yes" xml:space="preserve">
          <source>The optimization objective for MultiTaskElasticNet is:</source>
          <target state="translated">Цель оптимизации для MultiTaskElasticNet:</target>
        </trans-unit>
        <trans-unit id="f43132c3f7097ed8020d37840c051e421e41e300" translate="yes" xml:space="preserve">
          <source>The optimization objective for MultiTaskLasso is:</source>
          <target state="translated">Целью оптимизации для MultiTaskLasso является:</target>
        </trans-unit>
        <trans-unit id="3bee4ea6ed3cad366ecf4d67dfc05469de43ad46" translate="yes" xml:space="preserve">
          <source>The optimization objective for the case method=&amp;rsquo;lasso&amp;rsquo; is:</source>
          <target state="translated">Целью оптимизации case method = 'lasso' является:</target>
        </trans-unit>
        <trans-unit id="8d89fe15a9f2092d4f8a7ef569d775bf0279d26d" translate="yes" xml:space="preserve">
          <source>The optional extra argument will be appended to the deprecation message and the docstring. Note: to use this with the default value for extra, put in an empty of parentheses:</source>
          <target state="translated">Дополнительный необязательный аргумент будет добавлен к сообщению об истощении и доктрине.Замечание:чтобы использовать его со значением по умолчанию для дополнительных аргументов,поставьте пустые скобки:</target>
        </trans-unit>
        <trans-unit id="0c86ba504c90ec1412c0ccc3d7f0b2f074294dc1" translate="yes" xml:space="preserve">
          <source>The optional parameter &lt;code&gt;whiten=True&lt;/code&gt; makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.</source>
          <target state="translated">Необязательный параметр &lt;code&gt;whiten=True&lt;/code&gt; позволяет проецировать данные на единичное пространство, масштабируя каждый компонент до единичной дисперсии. Это часто бывает полезно, если последующие модели делают строгие предположения об изотропии сигнала: это, например, случай для машин опорных векторов с ядром RBF и алгоритмом кластеризации K-средних.</target>
        </trans-unit>
        <trans-unit id="c77f2b2e59e77aff75fd77a2825914acd9eb1242" translate="yes" xml:space="preserve">
          <source>The order in which the features will be imputed. Possible values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="846ba284e005e0c78a1fd443a812172705bbc8f3" translate="yes" xml:space="preserve">
          <source>The order of labels in the classifier chain.</source>
          <target state="translated">Порядок наклеек в цепочке классификатора.</target>
        </trans-unit>
        <trans-unit id="7b082acdda498538bd71b7e32b0b230c2144c284" translate="yes" xml:space="preserve">
          <source>The order of the chain can be explicitly set by providing a list of integers. For example, for a chain of length 5.:</source>
          <target state="translated">Порядок цепочки может быть явно задан путем предоставления списка целых чисел.Например,для цепочки длиной 5..:</target>
        </trans-unit>
        <trans-unit id="f9d11a930ecaf4c38c05b12592342da86a8c77ff" translate="yes" xml:space="preserve">
          <source>The order of the columns in the transformed feature matrix follows the order of how the columns are specified in the &lt;code&gt;transformers&lt;/code&gt; list. Columns of the original feature matrix that are not specified are dropped from the resulting transformed feature matrix, unless specified in the &lt;code&gt;passthrough&lt;/code&gt; keyword. Those columns specified with &lt;code&gt;passthrough&lt;/code&gt; are added at the right to the output of the transformers.</source>
          <target state="translated">Порядок столбцов в преобразованной матрице признаков соответствует порядку, в котором столбцы указаны в списке &lt;code&gt;transformers&lt;/code&gt; . Столбцы исходной матрицы признаков, которые не указаны, удаляются из результирующей преобразованной матрицы признаков, если только они не указаны в ключевом слове &lt;code&gt;passthrough&lt;/code&gt; . Столбцы, указанные с помощью &lt;code&gt;passthrough&lt;/code&gt; , добавляются справа к выходу трансформаторов.</target>
        </trans-unit>
        <trans-unit id="0b5c0a29228cf2f99af9ecdff2f5b2a0dc08ed2d" translate="yes" xml:space="preserve">
          <source>The original data</source>
          <target state="translated">Оригинальные данные</target>
        </trans-unit>
        <trans-unit id="77422b337aacebf704cab947c2765e7ef78426db" translate="yes" xml:space="preserve">
          <source>The original dataset consisted of 92 x 112, while the version available here consists of 64x64 images.</source>
          <target state="translated">Оригинальный набор данных состоял из 92 x 112,а доступная здесь версия-64x64 изображений.</target>
        </trans-unit>
        <trans-unit id="11407c8a67a7b9eefbd2b65794ca1ecbfa48a97d" translate="yes" xml:space="preserve">
          <source>The original formulation of the hashing trick by Weinberger et al. used two separate hash functions \(h\) and \(\xi\) to determine the column index and sign of a feature, respectively. The present implementation works under the assumption that the sign bit of MurmurHash3 is independent of its other bits.</source>
          <target state="translated">Оригинальная формулировка трюка с хэшированием,выполненная Вайнбергером и др.,использовала две отдельные хэш-функции \(h\)и \(\xi\)для определения индекса столбца и знака признака признака,соответственно.Настоящая реализация работает в предположении,что знаковый бит MurmurHash3 не зависит от других его битов.</target>
        </trans-unit>
        <trans-unit id="62507dafeac3a5da5ac8979b39262545fa83f997" translate="yes" xml:space="preserve">
          <source>The original image data. For color images, the last dimension specifies the channel: a RGB image would have &lt;code&gt;n_channels=3&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8eec938f1b6ddec4315f3fac08b8dc8e8e67d5d5" translate="yes" xml:space="preserve">
          <source>The original images are 250 x 250 pixels, but the default slice and resize arguments reduce them to 62 x 47.</source>
          <target state="translated">Оригинальные изображения имеют размер 250 x 250 пикселей,но аргументы по умолчанию уменьшают их до 62 x 47.</target>
        </trans-unit>
        <trans-unit id="a555f40ab758aba55bcba7bb9ac36af67b065d6a" translate="yes" xml:space="preserve">
          <source>The other kernels</source>
          <target state="translated">Другие ядра</target>
        </trans-unit>
        <trans-unit id="5978e5bbc3d0aa56b4c3321d1d9ccbd8b149a1a9" translate="yes" xml:space="preserve">
          <source>The outer product of the row and column label vectors shows a representation of the checkerboard structure.</source>
          <target state="translated">Внешнее произведение векторов метки строки и столбца показывает представление о структуре шахматной доски.</target>
        </trans-unit>
        <trans-unit id="4e7d9f946f101134a65fd7d38a82dce953516bd7" translate="yes" xml:space="preserve">
          <source>The output &lt;code&gt;y&lt;/code&gt; is created according to the formula:</source>
          <target state="translated">Выход &lt;code&gt;y&lt;/code&gt; создается по формуле:</target>
        </trans-unit>
        <trans-unit id="7348f35a4e7d1a3450461b231ee28ef95517ba57" translate="yes" xml:space="preserve">
          <source>The output is generated by applying a (potentially biased) random linear regression model with &lt;code&gt;n_informative&lt;/code&gt; nonzero regressors to the previously generated input and some gaussian centered noise with some adjustable scale.</source>
          <target state="translated">Выходные данные генерируются путем применения (потенциально смещенной) модели случайной линейной регрессии с &lt;code&gt;n_informative&lt;/code&gt; ненулевых регрессоров к ранее сгенерированным входным данным и некоторого гауссовского центрированного шума с некоторым регулируемым масштабом.</target>
        </trans-unit>
        <trans-unit id="0c62eccd54e33fb989ef31175162303c11637d7c" translate="yes" xml:space="preserve">
          <source>The output of a singular value decomposition is only unique up to a permutation of the signs of the singular vectors. If &lt;code&gt;flip_sign&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, the sign ambiguity is resolved by making the largest loadings for each component in the left singular vectors positive.</source>
          <target state="translated">Результат разложения по сингулярным числам уникален только с точностью до перестановки знаков особых векторов. Если для параметра &lt;code&gt;flip_sign&lt;/code&gt; установлено значение &lt;code&gt;True&lt;/code&gt; , неоднозначность знака устраняется путем установления положительных значений наибольших нагрузок для каждого компонента в левых сингулярных векторах.</target>
        </trans-unit>
        <trans-unit id="ab5b2ab18fdef999b51de35c5e9c33e7d3ac7cc7" translate="yes" xml:space="preserve">
          <source>The output of the 3 models are combined in a 2D graph where nodes represents the stocks and edges the:</source>
          <target state="translated">Вывод 3 моделей объединен в 2D график,где узлы представляют запасы и края:</target>
        </trans-unit>
        <trans-unit id="c9b52f3c910ded5afcb915db265ed0583f446660" translate="yes" xml:space="preserve">
          <source>The output of transform is sometimes referred to as the 1-of-K coding scheme.</source>
          <target state="translated">Выход трансформации иногда называют схемой кодирования 1-of-K.</target>
        </trans-unit>
        <trans-unit id="f172299244e465e38a0859a0349f26df08f75701" translate="yes" xml:space="preserve">
          <source>The output of transform is sometimes referred to by some authors as the 1-of-K coding scheme.</source>
          <target state="translated">Некоторые авторы иногда называют выход преобразования схемой кодирования 1-of-K.</target>
        </trans-unit>
        <trans-unit id="58983c4b722f7fa5c156e992e47b9ca634d33156" translate="yes" xml:space="preserve">
          <source>The output values.</source>
          <target state="translated">Выходные значения.</target>
        </trans-unit>
        <trans-unit id="f348d2a86dcf3bc20a82250a4d5068aa50c67aad" translate="yes" xml:space="preserve">
          <source>The overall complexity of Isomap is \(O[D \log(k) N \log(N)] + O[N^2(k + \log(N))] + O[d N^2]\).</source>
          <target state="translated">Общая сложность Isomap-\(O[D \log(k)N \log(N)]+O[N^2(k+\log(N))]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="9cec4ae56de9cf1cd9cf2f8a0ff2e2e24864f054" translate="yes" xml:space="preserve">
          <source>The overall complexity of MLLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[N (k-D) k^2] + O[d N^2]\).</source>
          <target state="translated">Общая сложность MLLE составляет \(O[D \log(k)N \log(N)]+O[D N k^3]+O[N (k-D)k^2]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="7fa546000c6a79308906d0c040bf81047f6b149e" translate="yes" xml:space="preserve">
          <source>The overall complexity of spectral embedding is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[d N^2]\).</source>
          <target state="translated">Общая сложность спектральной встраивания составляет \(O[D \log(k)N \log(N)]+O[D N k^3]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="808f28c633edaf7537ca8395b6bc52f0086ed496" translate="yes" xml:space="preserve">
          <source>The overall complexity of standard HLLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[N d^6] + O[d N^2]\).</source>
          <target state="translated">Общая сложность стандартной HLLE-\(O[D \log(k)N \log(N)]+O[D N k^3]+O[N d^6]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="63617858af3d41882021a1ab37e78e76cce39983" translate="yes" xml:space="preserve">
          <source>The overall complexity of standard LLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[d N^2]\).</source>
          <target state="translated">Общая сложность стандартной LLE-\(O[D \log(k)N \log(N)]+O[D N k^3]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="b88c53c3806a592f7e00e19aef010a599cfaf4dc" translate="yes" xml:space="preserve">
          <source>The overall complexity of standard LTSA is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[k^2 d] + O[d N^2]\).</source>
          <target state="translated">Общая сложность стандарта LTSA составляет \(O[D \log(k)N \log(N)]+O[D N k^3]+O[k^2 d]+O[d N^2]\).</target>
        </trans-unit>
        <trans-unit id="fc12a97c8a559f9672542a072947ef2eae0adcac" translate="yes" xml:space="preserve">
          <source>The p-value, which approximates the probability that the score would be obtained by chance. This is calculated as:</source>
          <target state="translated">Р-значение,которое аппроксимирует вероятность того,что балл будет получен случайно.Оно рассчитывается как:</target>
        </trans-unit>
        <trans-unit id="7f9aaf22278cea2b541fbd8b88b09de54aad3e99" translate="yes" xml:space="preserve">
          <source>The parallel version of K-Means is broken on OS X when &lt;code&gt;numpy&lt;/code&gt; uses the &lt;code&gt;Accelerate&lt;/code&gt; Framework. This is expected behavior: &lt;code&gt;Accelerate&lt;/code&gt; can be called after a fork but you need to execv the subprocess with the Python binary (which multiprocessing does not do under posix).</source>
          <target state="translated">Параллельная версия K-Means не работает в OS X, когда &lt;code&gt;numpy&lt;/code&gt; использует &lt;code&gt;Accelerate&lt;/code&gt; Framework. Это ожидаемое поведение: &lt;code&gt;Accelerate&lt;/code&gt; может быть вызван после вилки, но вам нужно выполнить подпроцесс с двоичным кодом Python (чего многопроцессорность не выполняет в posix).</target>
        </trans-unit>
        <trans-unit id="6d1486e3a09b61694eecc888bffbc6ccf12d8263" translate="yes" xml:space="preserve">
          <source>The parameter &lt;code&gt;learning_rate&lt;/code&gt; strongly interacts with the parameter &lt;code&gt;n_estimators&lt;/code&gt;, the number of weak learners to fit. Smaller values of &lt;code&gt;learning_rate&lt;/code&gt; require larger numbers of weak learners to maintain a constant training error. Empirical evidence suggests that small values of &lt;code&gt;learning_rate&lt;/code&gt; favor better test error. &lt;a href=&quot;#htf&quot; id=&quot;id20&quot;&gt;[HTF]&lt;/a&gt; recommend to set the learning rate to a small constant (e.g. &lt;code&gt;learning_rate &amp;lt;= 0.1&lt;/code&gt;) and choose &lt;code&gt;n_estimators&lt;/code&gt; by early stopping. For a more detailed discussion of the interaction between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt; see &lt;a href=&quot;#r2007&quot; id=&quot;id21&quot;&gt;[R2007]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26cab4ba2ce5f7f1aa5cff1bedcda88264af63ea" translate="yes" xml:space="preserve">
          <source>The parameter &lt;code&gt;learning_rate&lt;/code&gt; strongly interacts with the parameter &lt;code&gt;n_estimators&lt;/code&gt;, the number of weak learners to fit. Smaller values of &lt;code&gt;learning_rate&lt;/code&gt; require larger numbers of weak learners to maintain a constant training error. Empirical evidence suggests that small values of &lt;code&gt;learning_rate&lt;/code&gt; favor better test error. &lt;a href=&quot;#htf2009&quot; id=&quot;id17&quot;&gt;[HTF2009]&lt;/a&gt; recommend to set the learning rate to a small constant (e.g. &lt;code&gt;learning_rate &amp;lt;= 0.1&lt;/code&gt;) and choose &lt;code&gt;n_estimators&lt;/code&gt; by early stopping. For a more detailed discussion of the interaction between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt; see &lt;a href=&quot;#r2007&quot; id=&quot;id18&quot;&gt;[R2007]&lt;/a&gt;.</source>
          <target state="translated">Параметр &lt;code&gt;learning_rate&lt;/code&gt; сильно взаимодействует с параметром &lt;code&gt;n_estimators&lt;/code&gt; , количеством подходящих слабых учеников. Меньшие значения &lt;code&gt;learning_rate&lt;/code&gt; требуют большего числа слабых учеников для поддержания постоянной ошибки обучения. Эмпирические данные свидетельствуют о том, что небольшие значения &lt;code&gt;learning_rate&lt;/code&gt; способствуют большей ошибке теста. &lt;a href=&quot;#htf2009&quot; id=&quot;id17&quot;&gt;[HTF2009]&lt;/a&gt; рекомендует установить скорость обучения на небольшую константу (например, &lt;code&gt;learning_rate &amp;lt;= 0.1&lt;/code&gt; ) и выбрать &lt;code&gt;n_estimators&lt;/code&gt; путем ранней остановки. Более подробное обсуждение взаимодействия между &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;n_estimators&lt;/code&gt; см. В &lt;a href=&quot;#r2007&quot; id=&quot;id18&quot;&gt;[R2007]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0e6ab9c66156a9d2feae55ed2060a2c6f7d6986c" translate="yes" xml:space="preserve">
          <source>The parameter &lt;code&gt;memory&lt;/code&gt; is needed in order to cache the transformers. &lt;code&gt;memory&lt;/code&gt; can be either a string containing the directory where to cache the transformers or a &lt;a href=&quot;https://pythonhosted.org/joblib/memory.html&quot;&gt;joblib.Memory&lt;/a&gt; object:</source>
          <target state="translated">&lt;code&gt;memory&lt;/code&gt; параметров необходима для кэширования трансформаторов. &lt;code&gt;memory&lt;/code&gt; может быть либо строкой, содержащей каталог, в котором кэшируются преобразователи, либо объектом &lt;a href=&quot;https://pythonhosted.org/joblib/memory.html&quot;&gt;joblib.Memory&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="171048c7012440ddda965396141222fe52434637" translate="yes" xml:space="preserve">
          <source>The parameter &lt;code&gt;normalize&lt;/code&gt; allows to report ratios instead of counts. The confusion matrix can be normalized in 3 different ways: &lt;code&gt;'pred'&lt;/code&gt;, &lt;code&gt;'true'&lt;/code&gt;, and &lt;code&gt;'all'&lt;/code&gt; which will divide the counts by the sum of each columns, rows, or the entire matrix, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a19846a3c7376460662acabedd23579aba492f87" translate="yes" xml:space="preserve">
          <source>The parameter \(\nu\) is also called the &lt;strong&gt;learning rate&lt;/strong&gt; because it scales the step length the gradient descent procedure; it can be set via the &lt;code&gt;learning_rate&lt;/code&gt; parameter.</source>
          <target state="translated">Параметр \ (\ nu \) также называется &lt;strong&gt;скоростью обучения,&lt;/strong&gt; потому что он масштабирует длину шага процедуры градиентного спуска; его можно установить с помощью параметра &lt;code&gt;learning_rate&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="76b14eb14f0e0be16176b9f0182e58f523e33b2d" translate="yes" xml:space="preserve">
          <source>The parameter epsilon controls the number of samples that should be classified as outliers. The smaller the epsilon, the more robust it is to outliers.</source>
          <target state="translated">Параметр epsilon контролирует количество образцов,которые должны быть классифицированы как отклонения.Чем меньше эпсилон,тем он более устойчив к отклонениям.</target>
        </trans-unit>
        <trans-unit id="33a23a95b6f6e50b11cce3982dee22dc3afbeaef" translate="yes" xml:space="preserve">
          <source>The parameter grid to explore, as a dictionary mapping estimator parameters to sequences of allowed values.</source>
          <target state="translated">Сетка параметров для изучения,как словарь отображения параметров оценки последовательности допустимых значений.</target>
        </trans-unit>
        <trans-unit id="95ad4f92539995843fbdd8a8c8263fdd9652cae5" translate="yes" xml:space="preserve">
          <source>The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. More specifically, the optimization objective is:</source>
          <target state="translated">Параметр l1_ratio соответствует альфе в пакете glmnet R,в то время как альфа соответствует параметру лямбда в glmnet.Точнее,цель оптимизации:</target>
        </trans-unit>
        <trans-unit id="444f64a3bffea2bee3d3973fdc03c3dbbbbf54d9" translate="yes" xml:space="preserve">
          <source>The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty. Currently, l1_ratio &amp;lt;= 0.01 is not reliable, unless you supply your own sequence of alpha.</source>
          <target state="translated">Параметр l1_ratio соответствует альфе в пакете glmnet R, а альфа соответствует параметру лямбда в glmnet. В частности, l1_ratio = 1 - штраф за лассо. В настоящее время l1_ratio &amp;lt;= 0,01 не является надежным, если вы не предоставите свою собственную последовательность альфа-канала.</target>
        </trans-unit>
        <trans-unit id="3d75707f4ee017e7f35982b539c7d0e6825a3d30" translate="yes" xml:space="preserve">
          <source>The parameter nu controlling the smoothness of the learned function. The smaller nu, the less smooth the approximated function is. For nu=inf, the kernel becomes equivalent to the RBF kernel and for nu=0.5 to the absolute exponential kernel. Important intermediate values are nu=1.5 (once differentiable functions) and nu=2.5 (twice differentiable functions). Note that values of nu not in [0.5, 1.5, 2.5, inf] incur a considerably higher computational cost (appr. 10 times higher) since they require to evaluate the modified Bessel function. Furthermore, in contrast to l, nu is kept fixed to its initial value and not optimized.</source>
          <target state="translated">Параметр nu,управляющий гладкостью выученной функции.Чем меньше nu,тем менее гладкой является аппроксимируемая функция.Для nu=inf,ядро становится эквивалентным RBF ядру,а для nu=0.5-абсолютному экспоненциальному ядру.Важными промежуточными значениями являются nu=1.5 (одноразовые дифференцируемые функции)и nu=2.5 (двуразовые дифференцируемые функции).Отметим,что значения nu не в [0.5,1.5,2.5,inf]несут значительно большие вычислительные затраты (примерно в 10 раз),так как требуют оценки модифицированной функции Бесселя.Кроме того,в отличие от l,nu удерживается на начальном значении и не оптимизируется.</target>
        </trans-unit>
        <trans-unit id="fa3c09390eafe53f0b58881f0d7db646d5796fe2" translate="yes" xml:space="preserve">
          <source>The parameters \(\sigma_y\) and \(\mu_y\) are estimated using maximum likelihood.</source>
          <target state="translated">Параметры \(\sigma_y\)и \(\mu_y\)оцениваются с максимальной вероятностью.</target>
        </trans-unit>
        <trans-unit id="d8334dfb20de589f58500a915aef89a4fab7377d" translate="yes" xml:space="preserve">
          <source>The parameters \(\theta_y\) is estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:</source>
          <target state="translated">Параметры \(\theta_y\)оцениваются по сглаженной версии максимальной вероятности,т.е.относительного подсчета частоты:</target>
        </trans-unit>
        <trans-unit id="c10d9b59570fee3848efafd20062e78feab2baf1" translate="yes" xml:space="preserve">
          <source>The parameters \(w\), \(\alpha\) and \(\lambda\) are estimated jointly during the fit of the model, the regularization parameters \(\alpha\) and \(\lambda\) being estimated by maximizing the &lt;em&gt;log marginal likelihood&lt;/em&gt;. The scikit-learn implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where the update of the parameters \(\alpha\) and \(\lambda\) is done as suggested in (MacKay, 1992). The initial value of the maximization procedure can be set with the hyperparameters &lt;code&gt;alpha_init&lt;/code&gt; and &lt;code&gt;lambda_init&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="162d2ed9f70c881f87134a87c0c741cb23832c22" translate="yes" xml:space="preserve">
          <source>The parameters implementation of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; class proposes two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.</source>
          <target state="translated">Реализация параметров класса &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; предлагает два типа априорных значений для распределения весов: модель конечной смеси с распределением Дирихле и модель бесконечной смеси с процессом Дирихле. На практике алгоритм вывода процесса Дирихле является приближенным и использует усеченное распределение с фиксированным максимальным числом компонентов (так называемое представление с прерыванием прилипания). Количество фактически используемых компонентов почти всегда зависит от данных.</target>
        </trans-unit>
        <trans-unit id="957eda9a79d6f1f87ea7b634983b57c94627c96b" translate="yes" xml:space="preserve">
          <source>The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.</source>
          <target state="translated">Параметры оценочного средства,используемого для применения этих методов,оптимизируются путем перекрестного сверки по сетке параметров.</target>
        </trans-unit>
        <trans-unit id="6f20d8d61d83d6376fa9caf869f91f4640e0cc5b" translate="yes" xml:space="preserve">
          <source>The parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.</source>
          <target state="translated">Параметры оценочного средства,используемого для применения этих методов,оптимизируются путем перекрестного поиска по параметрам.</target>
        </trans-unit>
        <trans-unit id="1d4a34fa151b21edbbd9fa634476deabc1cb44cf" translate="yes" xml:space="preserve">
          <source>The parameters of the power transformation for the selected features.</source>
          <target state="translated">Параметры преобразования мощности для выбранных функций.</target>
        </trans-unit>
        <trans-unit id="62f294aa209942b08fddf4e74d29c13f78a9e67d" translate="yes" xml:space="preserve">
          <source>The parameters selected are those that maximize the score of the held-out data, according to the scoring parameter.</source>
          <target state="translated">Выбранные параметры-это те,которые максимизируют оценку удерживаемых данных,в соответствии с параметром скоринга.</target>
        </trans-unit>
        <trans-unit id="b6d7555a36c15ae2ffe9751024a0eebcf2421d57" translate="yes" xml:space="preserve">
          <source>The parameters selected are those that maximize the score of the left out data, unless an explicit score is passed in which case it is used instead.</source>
          <target state="translated">Выбранные параметры-это те,которые максимизируют оценку пропущенных данных,если только не передается явная оценка,и в этом случае она используется вместо нее.</target>
        </trans-unit>
        <trans-unit id="34d594dbc00b197d06cf788b61a5dfe36db335bf" translate="yes" xml:space="preserve">
          <source>The parameters that have been evaluated.</source>
          <target state="translated">Параметры,которые были оценены.</target>
        </trans-unit>
        <trans-unit id="f139c5090bf57fe74c58422c7266093265927a67" translate="yes" xml:space="preserve">
          <source>The parent of each node. Only returned when a connectivity matrix is specified, elsewhere &amp;lsquo;None&amp;rsquo; is returned.</source>
          <target state="translated">Родитель каждого узла. Возвращается только в том случае, если указана матрица связности, в другом месте возвращается &amp;laquo;Нет&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="491910df08517ded9cf6622a10e93f79d8d7b51e" translate="yes" xml:space="preserve">
          <source>The partial depdendence curves can be plotted for the multi-layer perceptron. In this case, &lt;code&gt;line_kw&lt;/code&gt; is passed to &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to change the color of the curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89bfd729c83f5c14808628511ada19e6e2b220e5" translate="yes" xml:space="preserve">
          <source>The partial dependence function evaluated on the &lt;code&gt;grid&lt;/code&gt;. For regression and binary classification &lt;code&gt;n_classes==1&lt;/code&gt;.</source>
          <target state="translated">Функция частичной зависимости вычисляется на &lt;code&gt;grid&lt;/code&gt; . Для регрессии и двоичной классификации &lt;code&gt;n_classes==1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="95b5d0f6fa140b6ee1f70868d5a14424c22e2d4c" translate="yes" xml:space="preserve">
          <source>The partial dependence of the response \(f\) at a point \(x_S\) is defined as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="053dbcb3edc2e230ef9a4eff0313b65bae4689ca" translate="yes" xml:space="preserve">
          <source>The passive-aggressive algorithms are a family of algorithms for large-scale learning. They are similar to the Perceptron in that they do not require a learning rate. However, contrary to the Perceptron, they include a regularization parameter &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">Пассивно-агрессивные алгоритмы - это семейство алгоритмов для крупномасштабного обучения. Они похожи на перцептрон в том, что не требуют скорости обучения. Однако, в отличие от перцептрона, они включают в себя параметр регуляризации &lt;code&gt;C&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cf6ba8c5f2e782ae102fc993ff0f91af87853f26" translate="yes" xml:space="preserve">
          <source>The path of the base directory to use as a data store or None. If None is given, no caching is done and the Memory object is completely transparent. This option replaces cachedir since version 0.12.</source>
          <target state="translated">Путь к базовому каталогу для использования в качестве хранилища данных или Нет.Если None задан,кэширование не выполняется,а объект Память полностью прозрачен.Эта опция заменяет кэширование начиная с версии 0.12.</target>
        </trans-unit>
        <trans-unit id="e60c1638cc188f171e30720c51f9233ac8e0591d" translate="yes" xml:space="preserve">
          <source>The path to scikit-learn data dir.</source>
          <target state="translated">Путь к Scikit-learn Data Dir.</target>
        </trans-unit>
        <trans-unit id="d92bdbe34c5616d0c8598712ff33d12e5d0daade" translate="yes" xml:space="preserve">
          <source>The path to the location of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2f9a75941863d91af30a0efa7c5bf671f8aabb3" translate="yes" xml:space="preserve">
          <source>The path to the location of the target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e58c61969eaf91a150b8c119238c04ee82b41f7" translate="yes" xml:space="preserve">
          <source>The penalty (aka regularization term) to be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="780a6be1d44fa6c4bc32e0e6a573d3b4ad24b942" translate="yes" xml:space="preserve">
          <source>The penalty (aka regularization term) to be used. Defaults to &amp;lsquo;l2&amp;rsquo; which is the standard regularizer for linear SVM models. &amp;lsquo;l1&amp;rsquo; and &amp;lsquo;elasticnet&amp;rsquo; might bring sparsity to the model (feature selection) not achievable with &amp;lsquo;l2&amp;rsquo;.</source>
          <target state="translated">Штраф (также известный как термин регуляризации), который необходимо использовать. По умолчанию - l2, который является стандартным регуляризатором для линейных моделей SVM. &amp;laquo;l1&amp;raquo; и &amp;laquo;elasticnet&amp;raquo; могут привести к разреженности модели (выбор функций), недостижимой с &amp;laquo;l2&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="5ec62ab0e251a48390ce125b16975a3fa4c7ca91" translate="yes" xml:space="preserve">
          <source>The penalty (aka regularization term) to be used. Defaults to None.</source>
          <target state="translated">Наказание (так же известное как регуляризационный термин),которое должно быть использовано.По умолчанию нет.</target>
        </trans-unit>
        <trans-unit id="3874ef3081cc70f2fd57e0725f8bff89bf9a04cd" translate="yes" xml:space="preserve">
          <source>The performance is may slightly worse for the randomized search, and is likely due to a noise effect and would not carry over to a held-out test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="195880b4735384ca5f4a3196f2d3109be0fc5155" translate="yes" xml:space="preserve">
          <source>The performance is slightly worse for the randomized search, though this is most likely a noise effect and would not carry over to a held-out test set.</source>
          <target state="translated">Производительность немного хуже для рандомизированного поиска,хотя это,скорее всего,шумовой эффект и не переносится на выдержанный тестовый набор.</target>
        </trans-unit>
        <trans-unit id="66758ccad6c0faa66ee36e2739cca75d7cb80119" translate="yes" xml:space="preserve">
          <source>The performance measure reported by &lt;em&gt;k&lt;/em&gt;-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.</source>
          <target state="translated">Показатель производительности, сообщаемый &lt;em&gt;k-&lt;/em&gt; кратной перекрестной проверкой, тогда является средним значением, вычисленным в цикле. Этот подход может быть дорогостоящим в вычислительном отношении, но при этом не тратится слишком много данных (как в случае фиксации произвольного набора проверки), что является основным преимуществом в таких задачах, как обратный вывод, когда количество выборок очень мало.</target>
        </trans-unit>
        <trans-unit id="773c4b551d63eb1e8cc16b04d1476c48de12db0a" translate="yes" xml:space="preserve">
          <source>The performance of the SAMME and SAMME.R &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt; algorithms are compared. SAMME.R uses the probability estimates to update the additive model, while SAMME uses the classifications only. As the example illustrates, the SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations. The error of each algorithm on the test set after each boosting iteration is shown on the left, the classification error on the test set of each tree is shown in the middle, and the boost weight of each tree is shown on the right. All trees have a weight of one in the SAMME.R algorithm and therefore are not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b50299f6e3a476dff9e3b98d46cee16ed70fcdb" translate="yes" xml:space="preserve">
          <source>The performance of the SAMME and SAMME.R &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; algorithms are compared. SAMME.R uses the probability estimates to update the additive model, while SAMME uses the classifications only. As the example illustrates, the SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations. The error of each algorithm on the test set after each boosting iteration is shown on the left, the classification error on the test set of each tree is shown in the middle, and the boost weight of each tree is shown on the right. All trees have a weight of one in the SAMME.R algorithm and therefore are not shown.</source>
          <target state="translated">Сравнивается производительность алгоритмов SAMME и SAMME.R &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; . SAMME.R использует оценки вероятности для обновления аддитивной модели, в то время как SAMME использует только классификации. Как показывает пример, алгоритм SAMME.R обычно сходится быстрее, чем SAMME, обеспечивая меньшую ошибку теста с меньшим количеством итераций повышения. Ошибка каждого алгоритма в тестовом наборе после каждой итерации повышения отображается слева, ошибка классификации на тестовом наборе каждого дерева показана в середине, а вес повышения каждого дерева показан справа. Все деревья в алгоритме SAMME.R имеют вес, равный единице, и поэтому не отображаются.</target>
        </trans-unit>
        <trans-unit id="54c9475018dc0386efaf6207cbf2038791834d22" translate="yes" xml:space="preserve">
          <source>The performance of the models can be evaluated by their ability to yield well-calibrated predictions and a good ranking.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f1cd52ca3b14d7125644c3724ffbf78c03b2ab3" translate="yes" xml:space="preserve">
          <source>The performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step.</source>
          <target state="translated">Затем производительность выбранных гиперпараметров и тренированной модели измеряется на специальном оценочном наборе,который не использовался на этапе выбора модели.</target>
        </trans-unit>
        <trans-unit id="dd106efb0f7012bff421a0ad8f3697f8283515ed" translate="yes" xml:space="preserve">
          <source>The periodicity of the kernel.</source>
          <target state="translated">Периодичность ядра.</target>
        </trans-unit>
        <trans-unit id="5dce1e0dbd7277c2f73689bcac70f69df5d2fc02" translate="yes" xml:space="preserve">
          <source>The perplexity is defined as \(k=2^{(S)}\) where \(S\) is the Shannon entropy of the conditional probability distribution. The perplexity of a \(k\)-sided die is \(k\), so that \(k\) is effectively the number of nearest neighbors t-SNE considers when generating the conditional probabilities. Larger perplexities lead to more nearest neighbors and less sensitive to small structure. Conversely a lower perplexity considers a smaller number of neighbors, and thus ignores more global information in favour of the local neighborhood. As dataset sizes get larger more points will be required to get a reasonable sample of the local neighborhood, and hence larger perplexities may be required. Similarly noisier datasets will require larger perplexity values to encompass enough local neighbors to see beyond the background noise.</source>
          <target state="translated">Недоумение определяется как \(k=2^{(S)}\),где \(S\)-энтропия Шеннона условного распределения вероятностей.Непонятливость односторонней матрицы \(k\)-\(k\),так что \(k\)-это фактически число ближайших соседей,которое t-SNE учитывает при генерации условных вероятностей.Большие недоумения приводят к появлению более близких соседей и меньшей чувствительности к малой структуре.И наоборот,меньшая растерянность учитывает меньшее число соседей,и таким образом игнорирует более глобальную информацию в пользу локального соседа.По мере того,как размер набора данных будет увеличиваться,потребуется больше точек,чтобы получить разумную выборку локального района,и,следовательно,могут потребоваться большие недоразумения.Точно так же более шумные наборы данных потребуют больших значений недоразумений,чтобы охватить достаточное количество локальных соседей,чтобы видеть за пределами фонового шума.</target>
        </trans-unit>
        <trans-unit id="61a03c034b8bc8a8d92d85436ffe8ab0dc0dda5b" translate="yes" xml:space="preserve">
          <source>The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significanlty different results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08299376158415917838ffdf1e208cdfe76446d4" translate="yes" xml:space="preserve">
          <source>The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. The choice is not extremely critical since t-SNE is quite insensitive to this parameter.</source>
          <target state="translated">Недоумение связано с количеством ближайших соседей,которое используется в других разнообразных алгоритмах обучения.Более крупные наборы данных обычно требуют большей недоуменности.Рассмотрим вариант выбора значения от 5 до 50.Выбор не очень критичен,так как t-SNE достаточно нечувствителен к этому параметру.</target>
        </trans-unit>
        <trans-unit id="042f3b8255d615a1ffcd846018bae060090b690e" translate="yes" xml:space="preserve">
          <source>The physical location of boston csv dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0881df888192122fb3f0dbde6c8cd7ff6f0357c" translate="yes" xml:space="preserve">
          <source>The pipeline below extracts the subject and body from each post using &lt;code&gt;SubjectBodyExtractor&lt;/code&gt;, producing a (n_samples, 2) array. This array is then used to compute standard bag-of-words features for the subject and body as well as text length and number of sentences on the body, using &lt;code&gt;ColumnTransformer&lt;/code&gt;. We combine them, with weights, then train a classifier on the combined set of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d1257b149fa9d88b1966c8dbdc55bf21ea6a0db" translate="yes" xml:space="preserve">
          <source>The placeholder for the missing values. All occurrences of &lt;code&gt;missing_values&lt;/code&gt; will be imputed.</source>
          <target state="translated">Заполнитель для отсутствующих значений. Будут условно исчислены все вхождения &lt;code&gt;missing_values&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9c95ae315d785709e445ae217c5567fb1ce65f07" translate="yes" xml:space="preserve">
          <source>The placeholder for the missing values. All occurrences of &lt;code&gt;missing_values&lt;/code&gt; will be imputed. For missing values encoded as np.nan, use the string value &amp;ldquo;NaN&amp;rdquo;.</source>
          <target state="translated">Заполнитель для отсутствующих значений. Будут условно исчислены все вхождения &lt;code&gt;missing_values&lt;/code&gt; . Для пропущенных значений, закодированных как np.nan, используйте строковое значение &amp;laquo;NaN&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="7d178852ef63f5a60aca24eb2ef7cd366b0501af" translate="yes" xml:space="preserve">
          <source>The placeholder for the missing values. All occurrences of &lt;code&gt;missing_values&lt;/code&gt; will be imputed. For pandas&amp;rsquo; dataframes with nullable integer dtypes with missing values, &lt;code&gt;missing_values&lt;/code&gt; should be set to &lt;code&gt;np.nan&lt;/code&gt;, since &lt;code&gt;pd.NA&lt;/code&gt; will be converted to &lt;code&gt;np.nan&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="182f79373d80c85b96a18c9f29af644fec99f0de" translate="yes" xml:space="preserve">
          <source>The plot above tells us about dependencies between a specific feature and the target when all other features remain constant, i.e., &lt;strong&gt;conditional dependencies&lt;/strong&gt;. An increase of the AGE will induce a decrease of the WAGE when all other features remain constant. On the contrary, an increase of the EXPERIENCE will induce an increase of the WAGE when all other features remain constant. Also, AGE, EXPERIENCE and EDUCATION are the three variables that most influence the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50d8f581357d70f0923b3a8bf25734f11fbbdc88" translate="yes" xml:space="preserve">
          <source>The plot represents the learning curve of the classifier: the evolution of classification accuracy over the course of the mini-batches. Accuracy is measured on the first 1000 samples, held out as a validation set.</source>
          <target state="translated">На графике представлена кривая обучения классификатора:эволюция точности классификации по ходу мини-серий.Точность измеряется на первых 1000 выборках,проводимых в виде валидационного набора.</target>
        </trans-unit>
        <trans-unit id="2108780ce5e305bd6eefeccab3f1f12e712db7ba" translate="yes" xml:space="preserve">
          <source>The plot shows decision boundaries for Linear Discriminant Analysis and Quadratic Discriminant Analysis. The bottom row demonstrates that Linear Discriminant Analysis can only learn linear boundaries, while Quadratic Discriminant Analysis can learn quadratic boundaries and is therefore more flexible.</source>
          <target state="translated">На графике показаны границы решений для линейного анализа дискриминантов и квадратичного анализа дискриминантов.В нижней строке показано,что линейный анализ дискриминанта может изучать только линейные границы,в то время как квадратичный анализ дискриминанта может изучать квадратичные границы и,следовательно,является более гибким.</target>
        </trans-unit>
        <trans-unit id="b078f7cb7ea97d6d1e43a3acd4d110579a0862d7" translate="yes" xml:space="preserve">
          <source>The plot shows decision boundaries for Nearest Neighbor Classification and Neighborhood Components Analysis classification on the iris dataset, when training and scoring on only two features, for visualisation purposes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f022b1b904616a8feb650bfceadf60a7908c45" translate="yes" xml:space="preserve">
          <source>The plot shows four one-way and one two-way partial dependence plots. The target variables for the one-way PDP are: median income (&lt;code&gt;MedInc&lt;/code&gt;), avg. occupants per household (&lt;code&gt;AvgOccup&lt;/code&gt;), median house age (&lt;code&gt;HouseAge&lt;/code&gt;), and avg. rooms per household (&lt;code&gt;AveRooms&lt;/code&gt;).</source>
          <target state="translated">На графике показаны четыре односторонних и один двусторонний график частичной зависимости. Целевыми переменными для одностороннего PDP являются: средний доход ( &lt;code&gt;MedInc&lt;/code&gt; ), ср. жильцов на домохозяйство ( &lt;code&gt;AvgOccup&lt;/code&gt; ), средний возраст дома ( &lt;code&gt;HouseAge&lt;/code&gt; ) и средн. комнат на семью ( &lt;code&gt;AveRooms&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="d1f9d8f4302df476eee3089e3160330e3191c729" translate="yes" xml:space="preserve">
          <source>The plot shows the regions where the discretized encoding is constant.</source>
          <target state="translated">На рисунке показаны области,в которых дискретная кодировка является постоянной.</target>
        </trans-unit>
        <trans-unit id="a1523290796b6a8ba4024eaf4b48817249c66e13" translate="yes" xml:space="preserve">
          <source>The plots below illustrate the effect the parameter &lt;code&gt;C&lt;/code&gt; has on the separation line. A large value of &lt;code&gt;C&lt;/code&gt; basically tells our model that we do not have that much faith in our data&amp;rsquo;s distribution, and will only consider points close to line of separation.</source>
          <target state="translated">На графиках ниже показано влияние параметра &lt;code&gt;C&lt;/code&gt; на разделительную линию. Большое значение &lt;code&gt;C&lt;/code&gt; в основном говорит нашей модели, что мы не очень верим в распределение наших данных и будем рассматривать только точки, близкие к линии разделения.</target>
        </trans-unit>
        <trans-unit id="faaabc25a5f9dd9badc9ef9f18d9770e507882de" translate="yes" xml:space="preserve">
          <source>The plots display firstly what a K-means algorithm would yield using three clusters. It is then shown what the effect of a bad initialization is on the classification process: By setting n_init to only 1 (default is 10), the amount of times that the algorithm will be run with different centroid seeds is reduced. The next plot displays what using eight clusters would deliver and finally the ground truth.</source>
          <target state="translated">На графиках в первую очередь показано,что даст алгоритм K-среднего с использованием трех кластеров.Затем показано,какое влияние оказывает плохая инициализация на процесс классификации:Устанавливая n_init только в 1 (по умолчанию 10),уменьшается количество раз,которое алгоритм будет выполняться с разными семенами центроида.На следующем рисунке показано,что даст использование восьми кластеров,и,наконец,грунтовая истина.</target>
        </trans-unit>
        <trans-unit id="3ad47df403d87eb821e2edd090b9e74720bc0be8" translate="yes" xml:space="preserve">
          <source>The plots represent the distribution of the prediction latency as a boxplot.</source>
          <target state="translated">Графики представляют собой распределение латентности прогноза в виде боп-групп.</target>
        </trans-unit>
        <trans-unit id="9d34744e2f178eb734dfa28bde9ee7e67cdcc28f" translate="yes" xml:space="preserve">
          <source>The plots show four 1-way and two 1-way partial dependence plots (omitted for &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; due to computation time). The target variables for the one-way PDP are: median income (&lt;code&gt;MedInc&lt;/code&gt;), average occupants per household (&lt;code&gt;AvgOccup&lt;/code&gt;), median house age (&lt;code&gt;HouseAge&lt;/code&gt;), and average rooms per household (&lt;code&gt;AveRooms&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee583f2ef106ae04159c6d135c18b8bf01049699" translate="yes" xml:space="preserve">
          <source>The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set.</source>
          <target state="translated">Графики показывают учебные точки сплошным цветом,а испытательные точки-полупрозрачными.В нижнем правом углу показана точность классификации на наборе тестов.</target>
        </trans-unit>
        <trans-unit id="a10b5c6300ecb650c0782e5a6bff1ffc576100bb" translate="yes" xml:space="preserve">
          <source>The point cloud spanned by the observations above is very flat in one direction: one of the three univariate features can almost be exactly computed using the other two. PCA finds the directions in which the data is not &lt;em&gt;flat&lt;/em&gt;</source>
          <target state="translated">Облако точек, охваченное наблюдениями выше, очень плоское в одном направлении: один из трех одномерных объектов может быть почти точно вычислен с использованием двух других. PCA находит направления, в которых данные не &lt;em&gt;плоские&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="9874b880b8ee39ca50e864dab01006b5213a2351" translate="yes" xml:space="preserve">
          <source>The points.</source>
          <target state="translated">Очков.</target>
        </trans-unit>
        <trans-unit id="0cdbbfd6a3924811880d5b83f6e26dafaaff0147" translate="yes" xml:space="preserve">
          <source>The polynomial kernel is defined as:</source>
          <target state="translated">Полиномиальное ядро определяется как:</target>
        </trans-unit>
        <trans-unit id="8b34b53d18875cd269c1341b177c3bcbb9230141" translate="yes" xml:space="preserve">
          <source>The pooled values for each feature cluster.</source>
          <target state="translated">Обобщенные значения для каждого тематического кластера.</target>
        </trans-unit>
        <trans-unit id="6285f4c6cbbb9a8676e04ca09291d710e5d4992f" translate="yes" xml:space="preserve">
          <source>The possible options are &amp;lsquo;hinge&amp;rsquo;, &amp;lsquo;log&amp;rsquo;, &amp;lsquo;modified_huber&amp;rsquo;, &amp;lsquo;squared_hinge&amp;rsquo;, &amp;lsquo;perceptron&amp;rsquo;, or a regression loss: &amp;lsquo;squared_loss&amp;rsquo;, &amp;lsquo;huber&amp;rsquo;, &amp;lsquo;epsilon_insensitive&amp;rsquo;, or &amp;lsquo;squared_epsilon_insensitive&amp;rsquo;.</source>
          <target state="translated">Возможные варианты: &amp;laquo;шарнир&amp;raquo;, &amp;laquo;журнал&amp;raquo;, &amp;laquo;модифицированный_убер&amp;raquo;, &amp;laquo;квадрат_хинджа&amp;raquo;, &amp;laquo;перцептрон&amp;raquo; или потеря регрессии: &amp;laquo;квадрат_потерянности&amp;raquo;, &amp;laquo;хубер&amp;raquo;, &amp;laquo;эпсилон-нечувствительность&amp;raquo; или &amp;laquo;квадрат_псилон-нечувствительность&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="6a0542e47ae26fdcd6f04cfe1be082ea4e8e2319" translate="yes" xml:space="preserve">
          <source>The power determines the underlying target distribution according to the following table:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a756ae9d1d42224e6a27c29b135c093bd570bbe" translate="yes" xml:space="preserve">
          <source>The power of the Minkowski metric to be used to calculate distance between points.</source>
          <target state="translated">Мощность метрики Минковского,которая будет использоваться для вычисления расстояния между точками.</target>
        </trans-unit>
        <trans-unit id="581738f7dfe64a35233afe8207a1e82379bfb8cd" translate="yes" xml:space="preserve">
          <source>The power transform is useful as a transformation in modeling problems where homoscedasticity and normality are desired. Below are examples of Box-Cox and Yeo-Johnwon applied to six different probability distributions: Lognormal, Chi-squared, Weibull, Gaussian, Uniform, and Bimodal.</source>
          <target state="translated">Преобразование силы полезно как преобразование в задачах моделирования,где желательны гомоскедастичность и нормальность.Ниже приведены примеры Box-Cox и Yeo-Johnwon,применяемые к шести различным распределениям вероятностей:Lognormal,Chi-квадрат,Weibull,Gaussian,Uniform и Bimodal.</target>
        </trans-unit>
        <trans-unit id="837e2e1ea652ea6696a91670a638bda69523a446" translate="yes" xml:space="preserve">
          <source>The power transform method. Available methods are:</source>
          <target state="translated">Метод преобразования энергии.Доступны следующие методы:</target>
        </trans-unit>
        <trans-unit id="1605256f2d1d73782f41770777e3757d50960cf1" translate="yes" xml:space="preserve">
          <source>The power transform method. Currently, &amp;lsquo;box-cox&amp;rsquo; (Box-Cox transform) is the only option available.</source>
          <target state="translated">Метод степенного преобразования. В настоящее время доступен только &amp;laquo;бокс-Кокс&amp;raquo; (преобразование Бокса-Кокса).</target>
        </trans-unit>
        <trans-unit id="9e3ef4e072a07501cd2ec598f0a1011b6178f209" translate="yes" xml:space="preserve">
          <source>The precision is the ratio &lt;code&gt;tp / (tp + fp)&lt;/code&gt; where &lt;code&gt;tp&lt;/code&gt; is the number of true positives and &lt;code&gt;fp&lt;/code&gt; the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.</source>
          <target state="translated">Точность - это отношение &lt;code&gt;tp / (tp + fp)&lt;/code&gt; где &lt;code&gt;tp&lt;/code&gt; - количество истинных срабатываний, а &lt;code&gt;fp&lt;/code&gt; - количество ложных срабатываний. Точность - это интуитивно понятная способность классификатора не помечать отрицательный образец как положительный.</target>
        </trans-unit>
        <trans-unit id="5e318fd9419ebb0c7685cd2fcf271eb0864ec5bb" translate="yes" xml:space="preserve">
          <source>The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on &lt;code&gt;covariance_type&lt;/code&gt;:</source>
          <target state="translated">Матрицы точности для каждого компонента в смеси. Матрица точности - это обратная матрица ковариации. Ковариационная матрица является симметричной положительно определенной, поэтому смесь гауссовских значений может быть эквивалентно параметризована матрицами точности. Сохранение матриц точности вместо ковариационных матриц делает более эффективным вычисление логарифмической вероятности появления новых выборок во время тестирования. Форма зависит от &lt;code&gt;covariance_type&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="027e42693446de348f6d01928068eb7453ef8a97" translate="yes" xml:space="preserve">
          <source>The precision matrix associated to the current covariance object.</source>
          <target state="translated">Матрица точности,связанная с текущим ковариационным объектом.</target>
        </trans-unit>
        <trans-unit id="d78de957c617714f761992022534f1c5cbc37dc0" translate="yes" xml:space="preserve">
          <source>The precision of each components on the mean distribution (Gaussian).</source>
          <target state="translated">Точность каждого компонента по среднему распределению (Гаусс).</target>
        </trans-unit>
        <trans-unit id="208aaa08d6ec7d945a950063ea09933d0bd5ac66" translate="yes" xml:space="preserve">
          <source>The precision prior on the mean distribution (Gaussian). Controls the extend to where means can be placed. Smaller values concentrate the means of each clusters around &lt;code&gt;mean_prior&lt;/code&gt;.</source>
          <target state="translated">Априорная точность среднего распределения (по Гауссу). Управляет расширением, где могут быть размещены средства. Меньшие значения концентрируют средние значения каждого кластера вокруг &lt;code&gt;mean_prior&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b72296dd4015be0343e22e7dc45bdf0f7e18f582" translate="yes" xml:space="preserve">
          <source>The precision prior on the mean distribution (Gaussian). Controls the extend to where means can be placed. Smaller values concentrate the means of each clusters around &lt;code&gt;mean_prior&lt;/code&gt;. The value of the parameter must be greater than 0. If it is None, it&amp;rsquo;s set to 1.</source>
          <target state="translated">Априорная точность среднего распределения (по Гауссу). Управляет расширением, где могут быть размещены средства. Меньшие значения концентрируют средние значения каждого кластера вокруг &lt;code&gt;mean_prior&lt;/code&gt; . Значение параметра должно быть больше 0. Если нет, устанавливается значение 1.</target>
        </trans-unit>
        <trans-unit id="99b687233f264a106cecce1d5b60aee20c688782" translate="yes" xml:space="preserve">
          <source>The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around &lt;code&gt;mean_prior&lt;/code&gt;. If mean_precision_prior is set to None, &lt;code&gt;mean_precision_prior_&lt;/code&gt; is set to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88b322c6c16cb10f58188170d43f7d8832a9357f" translate="yes" xml:space="preserve">
          <source>The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around &lt;code&gt;mean_prior&lt;/code&gt;. The value of the parameter must be greater than 0. If it is None, it is set to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d920e00078b8bd9b4faa0b1aa14a8c65b257bb" translate="yes" xml:space="preserve">
          <source>The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</source>
          <target state="translated">Кривая &quot;точность-вызов&quot; показывает компромисс между точностью и вызовом для разных пороговых значений.Высокая область под кривой представляет собой как высокий коэффициент вызова,так и высокую точность,где высокая точность относится к низкому коэффициенту ложноположительных срабатываний,а высокий коэффициент вызова относится к низкому коэффициенту ложно-отрицательных срабатываний.Высокие оценки для обоих показывают,что классификатор возвращает точные результаты (высокая точность),а также возвращает большую часть всех положительных результатов (высокая степень отзыва).</target>
        </trans-unit>
        <trans-unit id="b03d17dd4f0a50b42b8760dd1442678e73495423" translate="yes" xml:space="preserve">
          <source>The predicted class C for each sample in X is returned.</source>
          <target state="translated">Возвращается прогнозируемый класс С для каждого образца в Х.</target>
        </trans-unit>
        <trans-unit id="bfeb54e7bff0bb15dd098a7327cddb86a1801899" translate="yes" xml:space="preserve">
          <source>The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.</source>
          <target state="translated">Прогнозируемые классовые вероятности входной выборки вычисляются как журнал средних прогнозных классовых вероятностей базовых оценщиков в ансамбле.</target>
        </trans-unit>
        <trans-unit id="cd67555dc49cf41a5e5df91097299e3752772d2d" translate="yes" xml:space="preserve">
          <source>The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the trees in the forest.</source>
          <target state="translated">Прогнозные классовые вероятности бревен входной выборки вычисляются как бревно среднепрогнозных классовых вероятностей деревьев в лесу.</target>
        </trans-unit>
        <trans-unit id="eab6e37cbb9069ff9afad75097cea6fc5d34926b" translate="yes" xml:space="preserve">
          <source>The predicted class log-probabilities of an input sample is computed as the weighted mean predicted class log-probabilities of the classifiers in the ensemble.</source>
          <target state="translated">Прогнозируемые вероятности лог-файлов класса входной выборки вычисляются как средневзвешенные вероятности лог-файлов класса классификаторов в ансамбле.</target>
        </trans-unit>
        <trans-unit id="47d729548b0a8e226d9e4c530c0297fbe0f5665f" translate="yes" xml:space="preserve">
          <source>The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.</source>
          <target state="translated">Прогнозируемый класс входной выборки-это голос деревьев в лесу,взвешенный по их вероятностным оценкам.То есть,класс прогнозирования-это класс с самой высокой средней оценкой вероятности по деревьям.</target>
        </trans-unit>
        <trans-unit id="228bf14c189aaaaad2dc0e65c7c1dff58773904b" translate="yes" xml:space="preserve">
          <source>The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a &lt;code&gt;predict_proba&lt;/code&gt; method, then it resorts to voting.</source>
          <target state="translated">Прогнозируемый класс входной выборки вычисляется как класс с наивысшей средней предсказанной вероятностью. Если базовые оценщики не реализуют метод &lt;code&gt;predict_proba&lt;/code&gt; , они прибегают к голосованию.</target>
        </trans-unit>
        <trans-unit id="8652ca51db9ef5a2b15410ff134f217292f6ef55" translate="yes" xml:space="preserve">
          <source>The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.</source>
          <target state="translated">Прогнозируемый класс входной выборки вычисляется как средневзвешенное предсказание классификаторов в ансамбле.</target>
        </trans-unit>
        <trans-unit id="46c6bfcd5571fcbc8ac1e94c5ec5ef7b9ca3bcfc" translate="yes" xml:space="preserve">
          <source>The predicted class probabilities of an input sample are computed as the mean predicted class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same class in a leaf.</source>
          <target state="translated">Прогнозные классовые вероятности входной выборки вычисляются как средние прогнозные классовые вероятности деревьев в лесу.Классовая вероятность одного дерева-это доля выборки одного и того же класса в листе.</target>
        </trans-unit>
        <trans-unit id="90e3cd15b2277da446a86ed04d9b97d9385dbcbd" translate="yes" xml:space="preserve">
          <source>The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a &lt;code&gt;predict_proba&lt;/code&gt; method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.</source>
          <target state="translated">Вероятности предсказанных классов входной выборки вычисляются как средние вероятности предсказанных классов базовых оценщиков в ансамбле. Если базовые оценщики не реализуют метод &lt;code&gt;predict_proba&lt;/code&gt; , тогда он прибегает к голосованию, и вероятности предсказанных классов входной выборки представляют долю оценщиков, предсказывающих каждый класс.</target>
        </trans-unit>
        <trans-unit id="f43014d849d28fe556560f6e74f971c02171e223" translate="yes" xml:space="preserve">
          <source>The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.</source>
          <target state="translated">Прогнозируемые классовые вероятности входной выборки вычисляются как средневзвешенные прогнозные классовые вероятности классификаторов в ансамбле.</target>
        </trans-unit>
        <trans-unit id="232fb255d370f3424586a7b0c3f74d049bd6d607" translate="yes" xml:space="preserve">
          <source>The predicted class probability is the fraction of samples of the same class in a leaf.</source>
          <target state="translated">Прогнозируемая вероятность класса-это доля образцов одного и того же класса в листе.</target>
        </trans-unit>
        <trans-unit id="45d2cef0bd7682bfccc693d1957f2c12cdb9bae8" translate="yes" xml:space="preserve">
          <source>The predicted class.</source>
          <target state="translated">Предсказанный класс.</target>
        </trans-unit>
        <trans-unit id="d01b8d940e0e34c3c7942798bc90fe03e260970d" translate="yes" xml:space="preserve">
          <source>The predicted classes, or the predict values.</source>
          <target state="translated">Прогнозируемые классы,или прогнозируемые значения.</target>
        </trans-unit>
        <trans-unit id="b68f3b27cbad35418e1a35aab9bbe1837a195e37" translate="yes" xml:space="preserve">
          <source>The predicted classes.</source>
          <target state="translated">Предсказанные занятия.</target>
        </trans-unit>
        <trans-unit id="f9c849804a5f2e4c77a6bd9f1a72aeb60a174b11" translate="yes" xml:space="preserve">
          <source>The predicted log-probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;. Equivalent to log(predict_proba(X))</source>
          <target state="translated">Прогнозируемая логарифмическая вероятность выборки для каждого класса в модели, где классы упорядочены так же, как в &lt;code&gt;self.classes_&lt;/code&gt; . Эквивалент журнала (pred_proba (X))</target>
        </trans-unit>
        <trans-unit id="b73f981e520b253c83fbe81831bba280a3db569a" translate="yes" xml:space="preserve">
          <source>The predicted probability of the sample for each class in the model, where classes are ordered as they are in &lt;code&gt;self.classes_&lt;/code&gt;.</source>
          <target state="translated">Прогнозируемая вероятность выборки для каждого класса в модели, где классы упорядочены так же, как и в &lt;code&gt;self.classes_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a286cd68d524dde2fbaba23c990f981ec35b78f3" translate="yes" xml:space="preserve">
          <source>The predicted probas.</source>
          <target state="translated">Прогнозируемые зонды.</target>
        </trans-unit>
        <trans-unit id="53b10e885ebd4a72b834dc0bd6649d47d09469b6" translate="yes" xml:space="preserve">
          <source>The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.</source>
          <target state="translated">Прогнозируемая цель регрессии входной выборки вычисляется как средние прогнозируемые цели регрессии оценщиков в ансамбле.</target>
        </trans-unit>
        <trans-unit id="d575d8b045eb46db33f9cbaec364a954b218830a" translate="yes" xml:space="preserve">
          <source>The predicted regression target of an input sample is computed as the mean predicted regression targets of the trees in the forest.</source>
          <target state="translated">Прогнозируемая цель регрессии входной выборки вычисляется как среднепрогнозируемые цели регрессии деревьев в лесу.</target>
        </trans-unit>
        <trans-unit id="21875214f30fbe829fb7e391b984beb01fcc0748" translate="yes" xml:space="preserve">
          <source>The predicted regression value of an input sample is computed as the weighted median prediction of the classifiers in the ensemble.</source>
          <target state="translated">Прогнозируемое значение регрессии входной выборки вычисляется как средневзвешенное предсказание классификаторов в ансамбле.</target>
        </trans-unit>
        <trans-unit id="d728cdaebb39fe6a42651804a843b92d06b095fc" translate="yes" xml:space="preserve">
          <source>The predicted regression values.</source>
          <target state="translated">Прогнозируемые значения регрессии.</target>
        </trans-unit>
        <trans-unit id="eb2e0fb384bae49f48977b71692091d27df9ee48" translate="yes" xml:space="preserve">
          <source>The predicted target values.</source>
          <target state="translated">Прогнозируемые целевые значения.</target>
        </trans-unit>
        <trans-unit id="16c2ec05bdd825f5e946bffd1661391a4efc1866" translate="yes" xml:space="preserve">
          <source>The predicted value of the input samples.</source>
          <target state="translated">Прогнозируемое значение входных выборок.</target>
        </trans-unit>
        <trans-unit id="71f7a8826bad533ae16d312cbce730009c206751" translate="yes" xml:space="preserve">
          <source>The predicted values.</source>
          <target state="translated">Прогнозируемые значения.</target>
        </trans-unit>
        <trans-unit id="d3f70f498146a996702d8957eebe13ff93b2e60c" translate="yes" xml:space="preserve">
          <source>The prediction interpolates the observations (at least for regular kernels).</source>
          <target state="translated">Прогноз интерполирует наблюдения (по крайней мере,для обычных ядер).</target>
        </trans-unit>
        <trans-unit id="0a5a460e70a5f18f6e563f520727c4e907b64c8a" translate="yes" xml:space="preserve">
          <source>The prediction is probabilistic (Gaussian) so that one can compute empirical confidence intervals and decide based on those if one should refit (online fitting, adaptive fitting) the prediction in some region of interest.</source>
          <target state="translated">Прогноз вероятностный (гауссовский),так что можно вычислить эмпирические доверительные интервалы и на их основе принять решение о том,следует ли переделать (онлайн-подгонка,адаптивная подгонка)прогноз в какой-то интересующей области.</target>
        </trans-unit>
        <trans-unit id="888b741b5759a3600a521b02ebf591af7172583e" translate="yes" xml:space="preserve">
          <source>The prediction is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92250eb4257ffd9737b8e4be4f65018174b8c07a" translate="yes" xml:space="preserve">
          <source>The predictions for all the points in the grid, averaged over all samples in X (or over the training data if &lt;code&gt;method&lt;/code&gt; is &amp;lsquo;recursion&amp;rsquo;). &lt;code&gt;n_outputs&lt;/code&gt; corresponds to the number of classes in a multi-class setting, or to the number of tasks for multi-output regression. For classical regression and binary classification &lt;code&gt;n_outputs==1&lt;/code&gt;. &lt;code&gt;n_values_feature_j&lt;/code&gt; corresponds to the size &lt;code&gt;values[j]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f4304f9d52554d908e981e82f60b25cc189525a" translate="yes" xml:space="preserve">
          <source>The present version of SpectralClustering requires the number of clusters to be specified in advance. It works well for a small number of clusters, but is not advised for many clusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22369282bb204be005e939800f6b06d8c430453c" translate="yes" xml:space="preserve">
          <source>The previously introduced metrics are &lt;strong&gt;not normalized with regards to random labeling&lt;/strong&gt;: this means that depending on the number of samples, clusters and ground truth classes, a completely random labeling will not always yield the same values for homogeneity, completeness and hence v-measure. In particular &lt;strong&gt;random labeling won&amp;rsquo;t yield zero scores especially when the number of clusters is large&lt;/strong&gt;.</source>
          <target state="translated">Ранее введенные метрики &lt;strong&gt;не нормализованы в отношении случайной маркировки&lt;/strong&gt; : это означает, что в зависимости от количества выборок, кластеров и основных классов истинности полностью случайная маркировка не всегда будет давать одни и те же значения для однородности, полноты и, следовательно, v-меры. В частности, &lt;strong&gt;случайная маркировка не даст нулевых оценок, особенно при большом количестве кластеров&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="b298c69bd549b9b894cc39801befe9de3ee0bc57" translate="yes" xml:space="preserve">
          <source>The primal problem can be equivalently formulated as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd0e1bbfb34ee27f92c4a3d8c327812d7edee1f8" translate="yes" xml:space="preserve">
          <source>The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as &lt;em&gt;non-generalizing&lt;/em&gt; machine learning methods, since they simply &amp;ldquo;remember&amp;rdquo; all of its training data (possibly transformed into a fast indexing structure such as a &lt;a href=&quot;#ball-tree&quot;&gt;Ball Tree&lt;/a&gt; or &lt;a href=&quot;#kd-tree&quot;&gt;KD Tree&lt;/a&gt;).</source>
          <target state="translated">Принцип, лежащий в основе методов ближайшего соседа, состоит в том, чтобы найти предопределенное количество обучающих выборок, ближайших по расстоянию к новой точке, и предсказать метку по ним. Количество выборок может быть заданной пользователем константой (обучение k-ближайшего соседа) или изменяться в зависимости от локальной плотности точек (обучение соседей на основе радиуса). Расстояние, как правило, может быть любой метрической мерой: стандартное евклидово расстояние является наиболее распространенным выбором. Соседи на основе методов известны как &lt;em&gt;не-обобщающего&lt;/em&gt; машины методы обучения, так как они просто &amp;laquo;вспомнить&amp;raquo; все его подготовки данных (возможно , превращается в быструю индексной структуры , такие как &lt;a href=&quot;#ball-tree&quot;&gt;Tree мячем&lt;/a&gt; или &lt;a href=&quot;#kd-tree&quot;&gt;KD Tree&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="947ce8b8522668844673470c4e6efaad3bb4bafb" translate="yes" xml:space="preserve">
          <source>The prior and posterior of a GP resulting from a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt;&lt;code&gt;RationalQuadratic&lt;/code&gt;&lt;/a&gt; kernel are shown in the following figure:</source>
          <target state="translated">На следующем рисунке показаны предшествующий и последующий GP, являющийся результатом ядра &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt; &lt;code&gt;RationalQuadratic&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="43f31a8e2502a5518bdd46434b1800e86463052e" translate="yes" xml:space="preserve">
          <source>The prior and posterior of a GP resulting from an ExpSineSquared kernel are shown in the following figure:</source>
          <target state="translated">Предшествующее и последующее GP в результате работы ядра ExpSineSquared показано на следующем рисунке:</target>
        </trans-unit>
        <trans-unit id="f92d48b9507eee6a0b35b438f1fb3d6ff89e93fd" translate="yes" xml:space="preserve">
          <source>The prior of the number of degrees of freedom on the covariance distributions (Wishart).</source>
          <target state="translated">Предварительное число степеней свободы на ковариационных распределениях (Wishart).</target>
        </trans-unit>
        <trans-unit id="f920ca641ad93ad7a821ae4139b67430b9eddb8f" translate="yes" xml:space="preserve">
          <source>The prior of the number of degrees of freedom on the covariance distributions (Wishart). If it is None, it&amp;rsquo;s set to &lt;code&gt;n_features&lt;/code&gt;.</source>
          <target state="translated">Априор числа степеней свободы ковариационных распределений (Wishart). Если это None, он установлен в &lt;code&gt;n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cf6f1da4c11f5b6aa97c72a194e67d10417600f3" translate="yes" xml:space="preserve">
          <source>The prior on the covariance distribution (Wishart). If it is None, the emiprical covariance prior is initialized using the covariance of X. The shape depends on &lt;code&gt;covariance_type&lt;/code&gt;:</source>
          <target state="translated">Априор о ковариационном распределении (Wishart). Если он равен None, предварительная эмиприческая ковариация инициализируется с использованием ковариации X. Форма зависит от &lt;code&gt;covariance_type&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="449bf6ea1f50ae651db1aabfda8187878d697851" translate="yes" xml:space="preserve">
          <source>The prior on the covariance distribution (Wishart). The shape depends on &lt;code&gt;covariance_type&lt;/code&gt;:</source>
          <target state="translated">Априор о ковариационном распределении (Wishart). Форма зависит от &lt;code&gt;covariance_type&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="a7d0d50e2fe2007735b69660533329d841055128" translate="yes" xml:space="preserve">
          <source>The prior on the mean distribution (Gaussian).</source>
          <target state="translated">Предыдущий по среднему распределению (Гаусс).</target>
        </trans-unit>
        <trans-unit id="330376751a07bab7a9ae7af5823384716a02e1f4" translate="yes" xml:space="preserve">
          <source>The prior on the mean distribution (Gaussian). If it is None, it is set to the mean of X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70a81456bc5946b8879a5b610e7810c1053668bd" translate="yes" xml:space="preserve">
          <source>The prior on the mean distribution (Gaussian). If it is None, it&amp;rsquo;s set to the mean of X.</source>
          <target state="translated">Априор по среднему распределению (гауссову). Если это None, то устанавливается среднее значение X.</target>
        </trans-unit>
        <trans-unit id="0c84abbb5dade5fc9d4b47758b34408cb97bc08f" translate="yes" xml:space="preserve">
          <source>The priors over \(\alpha\) and \(\lambda\) are chosen to be &lt;a href=&quot;https://en.wikipedia.org/wiki/Gamma_distribution&quot;&gt;gamma distributions&lt;/a&gt;, the conjugate prior for the precision of the Gaussian.</source>
          <target state="translated">Априорные значения над \ (\ alpha \) и \ (\ lambda \) выбираются как &lt;a href=&quot;https://en.wikipedia.org/wiki/Gamma_distribution&quot;&gt;гамма-распределения&lt;/a&gt; , сопряженные априорные для точности гауссовского.</target>
        </trans-unit>
        <trans-unit id="4f2acfb8ac15388ba72cc76c4859e9942703930f" translate="yes" xml:space="preserve">
          <source>The priors over \(\alpha\) and \(\lambda\) are chosen to be &lt;a href=&quot;https://en.wikipedia.org/wiki/Gamma_distribution&quot;&gt;gamma distributions&lt;/a&gt;, the conjugate prior for the precision of the Gaussian. The resulting model is called &lt;em&gt;Bayesian Ridge Regression&lt;/em&gt;, and is similar to the classical &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69c3bd38e0a5cd7a1c6a9d7a1b4382f7891ca245" translate="yes" xml:space="preserve">
          <source>The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.</source>
          <target state="translated">Вероятностная модель создается с использованием перекрестной валидации,поэтому результаты могут несколько отличаться от результатов,полученных с помощью предсказания.Кроме того,она будет давать бессмысленные результаты на очень маленьких наборах данных.</target>
        </trans-unit>
        <trans-unit id="a6cf9fb7eddd86de2e07f31468eef83947604765" translate="yes" xml:space="preserve">
          <source>The probability of category \(t\) in feature \(i\) given class \(c\) is estimated as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a547056b7368b638d698d05d3f24b68fc3e86df" translate="yes" xml:space="preserve">
          <source>The probability of each class being drawn. Only returned if &lt;code&gt;return_distributions=True&lt;/code&gt;.</source>
          <target state="translated">Вероятность выпадения каждого класса. Возвращается, только если &lt;code&gt;return_distributions=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91c6b31a68e2490c2f85bd0b221deab07bc16086" translate="yes" xml:space="preserve">
          <source>The probability of each feature being drawn given each class. Only returned if &lt;code&gt;return_distributions=True&lt;/code&gt;.</source>
          <target state="translated">Вероятность рисования каждого объекта для каждого класса. Возвращается, только если &lt;code&gt;return_distributions=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e0b4e863c306f0bcfef6f345210b44e3fb52ffa9" translate="yes" xml:space="preserve">
          <source>The probability that a coefficient is zero (see notes). Larger values enforce more sparsity.</source>
          <target state="translated">Вероятность того,что коэффициент равен нулю (см.примечания).Большие значения обеспечивают большую редкость.</target>
        </trans-unit>
        <trans-unit id="f5e975aa46dbf2f661a2bf284eb823b950bfb65a" translate="yes" xml:space="preserve">
          <source>The problem of correlated variables</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4678dc803cddccad6a08944794f2a1c194908b2a" translate="yes" xml:space="preserve">
          <source>The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.</source>
          <target state="translated">Известно,что проблема изучения оптимального дерева решений является NP-завершенной по нескольким аспектам оптимальности и даже по простым понятиям.Следовательно,практические алгоритмы изучения дерева решений основаны на эвристических алгоритмах,таких как алгоритм жадности,в котором на каждом узле принимаются локально оптимальные решения.Такие алгоритмы не могут гарантировать возврат глобально оптимального дерева решений.Это можно смягчить,обучив несколько деревьев в ансамбле учащегося,где характеристики и выборки случайным образом выбираются с заменой.</target>
        </trans-unit>
        <trans-unit id="6c819ed9fb97cd33099d0eff9842389e345641fd" translate="yes" xml:space="preserve">
          <source>The problem solved in clustering</source>
          <target state="translated">Проблема,решенная в кластеризации</target>
        </trans-unit>
        <trans-unit id="2c5b556d82e8f03aa8505b7b204354187717fb43" translate="yes" xml:space="preserve">
          <source>The problem solved in supervised learning</source>
          <target state="translated">Проблема решена в обучении под наблюдением</target>
        </trans-unit>
        <trans-unit id="ab484ff296e26d980b5f93762f848e40818065e8" translate="yes" xml:space="preserve">
          <source>The progress meter: the higher the value of &lt;code&gt;verbose&lt;/code&gt;, the more messages:</source>
          <target state="translated">Индикатор выполнения: чем выше значение &lt;code&gt;verbose&lt;/code&gt; , тем больше сообщений:</target>
        </trans-unit>
        <trans-unit id="4163ad4952f27df98667c245d9d8133cfc5f4bae" translate="yes" xml:space="preserve">
          <source>The project mailing list</source>
          <target state="translated">Список рассылки проекта</target>
        </trans-unit>
        <trans-unit id="c7689a2c8d3ddf3814b537c25de9417bcceff1dc" translate="yes" xml:space="preserve">
          <source>The projected data.</source>
          <target state="translated">Прогнозируемые данные.</target>
        </trans-unit>
        <trans-unit id="8bfacd813c2539118e4e65b3f249a31e3f90cba3" translate="yes" xml:space="preserve">
          <source>The proportion of points to be included in the support of the raw MCD estimate. Default is None, which implies that the minimum value of support_fraction will be used within the algorithm: &lt;code&gt;(n_sample + n_features + 1) / 2&lt;/code&gt;. The parameter must be in the range (0, 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1179732ddee68f2a030de922cca4a7f3acc9e816" translate="yes" xml:space="preserve">
          <source>The proportion of points to be included in the support of the raw MCD estimate. Default is None, which implies that the minimum value of support_fraction will be used within the algorithm: [n_sample + n_features + 1] / 2</source>
          <target state="translated">Доля пунктов,которые должны быть включены в поддержку необработанной оценки ВЧР.По умолчанию None,что означает,что в алгоритме будет использовано минимальное значение support_fraction:[n_sample+n_features+1]/2</target>
        </trans-unit>
        <trans-unit id="5f706b185c5fa578abf1be5586afd62f084c2356" translate="yes" xml:space="preserve">
          <source>The proportion of points to be included in the support of the raw MCD estimate. If None, the minimum value of support_fraction will be used within the algorithm: &lt;code&gt;[n_sample + n_features + 1] / 2&lt;/code&gt;.</source>
          <target state="translated">Доля точек, которые будут включены в поддержку необработанной оценки MCD. Если None, в алгоритме будет использоваться минимальное значение support_fraction: &lt;code&gt;[n_sample + n_features + 1] / 2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2ecaf585d98315eb2e879bcbfec7a3d49600f7b8" translate="yes" xml:space="preserve">
          <source>The proportion of points to be included in the support of the raw MCD estimate. If None, the minimum value of support_fraction will be used within the algorithm: &lt;code&gt;[n_sample + n_features + 1] / 2&lt;/code&gt;. Range is (0, 1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd542c4196f5720eadadf90803a23b09f997f270" translate="yes" xml:space="preserve">
          <source>The proportion of samples whose class is the positive class, in each bin (fraction of positives).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6be8a7dea2b475115d00cec72a7cea2ea475dbdd" translate="yes" xml:space="preserve">
          <source>The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if &lt;code&gt;early_stopping&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5ef332af0dc668a636cc813bd9c0d699622c033" translate="yes" xml:space="preserve">
          <source>The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if &lt;code&gt;n_iter_no_change&lt;/code&gt; is set to an integer.</source>
          <target state="translated">Доля обучающих данных, которые нужно отложить в качестве проверочного набора для ранней остановки. Должен быть от 0 до 1. Используется только в том случае, если для &lt;code&gt;n_iter_no_change&lt;/code&gt; установлено целое число.</target>
        </trans-unit>
        <trans-unit id="e7040634736e41a179ebec81405480b75c6b1afc" translate="yes" xml:space="preserve">
          <source>The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True</source>
          <target state="translated">Доля данных об обучении,которая должна быть зарезервирована в качестве подтверждения,установлена для ранней остановки.Должно быть между 0 и 1.Используется только в том случае,если значение параметра early_stopping равно True.</target>
        </trans-unit>
        <trans-unit id="22eea34be82cd504d8c4cf88134dfff15444db48" translate="yes" xml:space="preserve">
          <source>The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.</source>
          <target state="translated">Доля данных об обучении,которая должна быть зарезервирована в качестве подтверждения,установлена для ранней остановки.Должно быть от 0 до 1.Используется только в том случае,если значение параметра early_stopping равно True.</target>
        </trans-unit>
        <trans-unit id="3b21c544ac1d6b2edc3be7d45619235a28b43e4c" translate="yes" xml:space="preserve">
          <source>The proportions of samples assigned to each class. If None, then classes are balanced. Note that if &lt;code&gt;len(weights) == n_classes - 1&lt;/code&gt;, then the last class weight is automatically inferred. More than &lt;code&gt;n_samples&lt;/code&gt; samples may be returned if the sum of &lt;code&gt;weights&lt;/code&gt; exceeds 1.</source>
          <target state="translated">Пропорции образцов отнесены к каждому классу. Если Нет, то классы сбалансированы. Обратите внимание, что если &lt;code&gt;len(weights) == n_classes - 1&lt;/code&gt; , то автоматически выводится вес последнего класса. Может быть возвращено более &lt;code&gt;n_samples&lt;/code&gt; выборок, если сумма &lt;code&gt;weights&lt;/code&gt; превышает 1.</target>
        </trans-unit>
        <trans-unit id="e063e4585132e12e4e3b8bc3e0e5f8f9333735ee" translate="yes" xml:space="preserve">
          <source>The pseudo-inverse of &lt;code&gt;components_&lt;/code&gt;. It is the linear operator that maps independent sources to the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b5cae22ba8a7c5a2306b5698bd81974f62f5c35" translate="yes" xml:space="preserve">
          <source>The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a &amp;lsquo;__&amp;rsquo;, as in the example below. A step&amp;rsquo;s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to &amp;lsquo;passthrough&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="824b6a86b9524b4fdb9e2919749fc7db8e534162" translate="yes" xml:space="preserve">
          <source>The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a &amp;lsquo;__&amp;rsquo;, as in the example below. A step&amp;rsquo;s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting to None.</source>
          <target state="translated">Цель конвейера состоит в том, чтобы собрать несколько шагов, которые могут быть проверены вместе при установке различных параметров. Для этого он позволяет устанавливать параметры различных шагов, используя их имена и имена параметров, разделенные символом &amp;laquo;__&amp;raquo;, как в примере ниже. Оценщик шага можно полностью заменить, установив параметр с его именем на другой оценщик, или преобразователь можно удалить, установив значение Нет.</target>
        </trans-unit>
        <trans-unit id="7aabe2d97cf9256a5a6bd2e4c38d95ce8f939f1c" translate="yes" xml:space="preserve">
          <source>The purpose of these two sources of randomness is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd8f7005fb1918c1319c0b334e68b25127992a8d" translate="yes" xml:space="preserve">
          <source>The python source code used to generate the model</source>
          <target state="translated">Исходный код питона,использованный для генерации модели</target>
        </trans-unit>
        <trans-unit id="a971c90794b3ab81f6079922073a4f8be4eaa91d" translate="yes" xml:space="preserve">
          <source>The qualitative difference between these models can also be visualized by comparing the histogram of observed target values with that of predicted values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7347085b6a9f16c7df450dca9dbc878bc14f5cc" translate="yes" xml:space="preserve">
          <source>The quantile to predict using the &amp;ldquo;quantile&amp;rdquo; strategy. A quantile of 0.5 corresponds to the median, while 0.0 to the minimum and 1.0 to the maximum.</source>
          <target state="translated">Квантиль для прогнозирования с использованием стратегии &amp;laquo;квантиль&amp;raquo;. Квантиль 0,5 соответствует медиане, 0,0 - минимуму, а 1,0 - максимуму.</target>
        </trans-unit>
        <trans-unit id="eabfb5a10c049cb3056c46f05114ad3228125c8e" translate="yes" xml:space="preserve">
          <source>The quantity \(\left[ \frac{\partial l(y_i, F(x_i))}{\partial F(x_i)} \right]_{F=F_{m - 1}}\) is the derivative of the loss with respect to its second parameter, evaluated at \(F_{m-1}(x)\). It is easy to compute for any given \(F_{m - 1}(x_i)\) in a closed form since the loss is differentiable. We will denote it by \(g_i\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38be089aaf53753add8a6e12d9d6e104537de3bf" translate="yes" xml:space="preserve">
          <source>The quantity that we use is the daily variation in quote price: quotes that are linked tend to cofluctuate during a day.</source>
          <target state="translated">Количество,которое мы используем является ежедневным изменением цены котировки:котировки,которые связаны имеют тенденцию коллидироваться в течение дня.</target>
        </trans-unit>
        <trans-unit id="96cf03fa14346bfc08bd6f97110fef23b56f72d1" translate="yes" xml:space="preserve">
          <source>The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.</source>
          <target state="translated">Точка или точки запроса.Если это не предусмотрено,возвращаются соседи каждой проиндексированной точки.В этом случае точка-запрос не считается собственной соседкой.</target>
        </trans-unit>
        <trans-unit id="30a7cdee7bb9697635b16e9d03b7cdd4b400cabd" translate="yes" xml:space="preserve">
          <source>The query sample or samples to compute the Local Outlier Factor w.r.t. the training samples.</source>
          <target state="translated">Образец запроса или образцы для вычисления локального коэффициента выброса (Local Outlier Factor w.r.t.)в обучающих образцах.</target>
        </trans-unit>
        <trans-unit id="e9edc4411fbea590103c5860156a749b07db92a2" translate="yes" xml:space="preserve">
          <source>The query sample or samples to compute the Local Outlier Factor w.r.t. to the training samples.</source>
          <target state="translated">Образец запроса или образцы для расчета локального коэффициента выброса для учебных образцов.</target>
        </trans-unit>
        <trans-unit id="2f63e59d1f59e9a5989ccb3ba903c403d9c311f4" translate="yes" xml:space="preserve">
          <source>The radius of the subcluster obtained by merging a new sample and the closest subcluster should be lesser than the threshold. Otherwise a new subcluster is started. Setting this value to be very low promotes splitting and vice-versa.</source>
          <target state="translated">Радиус подкластера,полученный при слиянии нового образца и ближайшего подкластера,должен быть меньше порогового значения.В противном случае запускается новый подкластер.Установка этого значения на очень низкий уровень способствует расщеплению и наоборот.</target>
        </trans-unit>
        <trans-unit id="c1fb03bbf68de1d40f0cd10af0722ed019408483" translate="yes" xml:space="preserve">
          <source>The random forest regressor will only ever predict values within the range of observations or closer to zero for each of the targets. As a result the predictions are biased towards the centre of the circle.</source>
          <target state="translated">Случайный лесной регрессор будет предсказывать значения только в пределах диапазона наблюдений или ближе к нулю для каждого из целевых показателей.В результате прогнозы смещены в сторону центра круга.</target>
        </trans-unit>
        <trans-unit id="ff0bc6a79a727353502babbe6e55a993a0f80508" translate="yes" xml:space="preserve">
          <source>The random number generator is used to generate random chain orders.</source>
          <target state="translated">Генератор случайных чисел используется для генерации случайных цепочек.</target>
        </trans-unit>
        <trans-unit id="31617e37a4673ca35baf50a5963330e598289ccc" translate="yes" xml:space="preserve">
          <source>The random symmetric, positive-definite matrix.</source>
          <target state="translated">Случайная симметричная,позитивно-определенная матрица.</target>
        </trans-unit>
        <trans-unit id="0ae670050b82bcbccc27a159ae39c91afa76e218" translate="yes" xml:space="preserve">
          <source>The randomized search and the grid search explore exactly the same space of parameters. The result in parameter settings is quite similar, while the run time for randomized search is drastically lower.</source>
          <target state="translated">Рандомизированный поиск и поиск по сетке исследуют точно такое же пространство параметров.Результат в настройках параметров достаточно схож,в то время как время выполнения рандомизированного поиска значительно меньше.</target>
        </trans-unit>
        <trans-unit id="6f118fa702c125f64290c65f38abc4f6dddff279" translate="yes" xml:space="preserve">
          <source>The raw (unadjusted) Rand index is then given by:</source>
          <target state="translated">Затем дается необработанный (нескорректированный)индекс Rand:</target>
        </trans-unit>
        <trans-unit id="6b2fe9bd420d4a6948923a1a40e37c6224028547" translate="yes" xml:space="preserve">
          <source>The raw RI score is then &amp;ldquo;adjusted for chance&amp;rdquo; into the ARI score using the following scheme:</source>
          <target state="translated">Затем исходный показатель RI &amp;laquo;корректируется на случайность&amp;raquo; в показатель ARI по следующей схеме:</target>
        </trans-unit>
        <trans-unit id="c2c7c9eff2c5366f7dc8bd26b18e5e786e16eeff" translate="yes" xml:space="preserve">
          <source>The raw image data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31fb3fd5063abf3dc0c0004645bb280ed7e9b6d1" translate="yes" xml:space="preserve">
          <source>The raw predicted values (i.e. the sum of the trees leaves) for each sample. n_trees_per_iteration is equal to the number of classes in multiclass classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="884b3f9d013732b636db9c9b452d7d3559d50f2d" translate="yes" xml:space="preserve">
          <source>The raw robust estimated covariance before correction and re-weighting.</source>
          <target state="translated">Сырая надежная оценка ковариантности до коррекции и повторного взвешивания.</target>
        </trans-unit>
        <trans-unit id="70b59f0ad9598471a02599d6a34b12e103ef557b" translate="yes" xml:space="preserve">
          <source>The raw robust estimated location before correction and re-weighting.</source>
          <target state="translated">Исходное надежное оценочное местоположение до корректировки и повторного взвешивания.</target>
        </trans-unit>
        <trans-unit id="246acb046d6b9bd62c3702633fac1169a8d836d0" translate="yes" xml:space="preserve">
          <source>The real data lies in the &lt;code&gt;filenames&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; attributes. The target attribute is the integer index of the category:</source>
          <target state="translated">Настоящие данные заключаются в &lt;code&gt;filenames&lt;/code&gt; и &lt;code&gt;target&lt;/code&gt; атрибутах. Целевой атрибут - это целочисленный индекс категории:</target>
        </trans-unit>
        <trans-unit id="480e842bb5c6e42d98f06aa4f6c096c0c7aba356" translate="yes" xml:space="preserve">
          <source>The recall is the ratio &lt;code&gt;tp / (tp + fn)&lt;/code&gt; where &lt;code&gt;tp&lt;/code&gt; is the number of true positives and &lt;code&gt;fn&lt;/code&gt; the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.</source>
          <target state="translated">Отзыв - это отношение &lt;code&gt;tp / (tp + fn)&lt;/code&gt; где &lt;code&gt;tp&lt;/code&gt; - количество истинных положительных результатов, а &lt;code&gt;fn&lt;/code&gt; - количество ложных отрицательных результатов. Отзыв - это интуитивно понятная способность классификатора находить все положительные образцы.</target>
        </trans-unit>
        <trans-unit id="6f99b6066a1cdf81f95a9e89b923c52bb3877c2c" translate="yes" xml:space="preserve">
          <source>The reconstructed image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65f6a86aee18eed07b01f195c73d746d5f2ca909" translate="yes" xml:space="preserve">
          <source>The reconstructed points using the metric MDS and non metric MDS are slightly shifted to avoid overlapping.</source>
          <target state="translated">Воссозданные точки с использованием метрической MDS и неметрической MDS немного смещены во избежание перекрытия.</target>
        </trans-unit>
        <trans-unit id="cefc093c3489c62b159a3ce090f6d8b10ecaa3b1" translate="yes" xml:space="preserve">
          <source>The reconstruction error computed by each routine can be used to choose the optimal output dimension. For a \(d\)-dimensional manifold embedded in a \(D\)-dimensional parameter space, the reconstruction error will decrease as &lt;code&gt;n_components&lt;/code&gt; is increased until &lt;code&gt;n_components == d&lt;/code&gt;.</source>
          <target state="translated">Ошибка реконструкции, вычисленная каждой программой, может использоваться для выбора оптимального размера вывода. Для \ (D \) - мерное многообразие вкладывается в \ (D \) - мерном пространстве параметров, ошибка восстановления будет уменьшаться по мере &lt;code&gt;n_components&lt;/code&gt; увеличивается до &lt;code&gt;n_components == d&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cd5de02ec688b7a05331073a7d6e7032a5c96c24" translate="yes" xml:space="preserve">
          <source>The reconstruction with L1 penalization gives a result with zero error (all pixels are successfully labeled with 0 or 1), even if noise was added to the projections. In comparison, an L2 penalization (&lt;a href=&quot;../../modules/generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt;&lt;/a&gt;) produces a large number of labeling errors for the pixels. Important artifacts are observed on the reconstructed image, contrary to the L1 penalization. Note in particular the circular artifact separating the pixels in the corners, that have contributed to fewer projections than the central disk.</source>
          <target state="translated">Реконструкция со штрафом L1 дает результат с нулевой ошибкой (все пиксели успешно помечены 0 или 1), даже если к проекциям был добавлен шум. Для сравнения, &lt;a href=&quot;../../modules/generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; &lt;/a&gt; L2 ( sklearn.linear_model.Ridge ) приводит к большому количеству ошибок маркировки пикселей. На восстановленном изображении наблюдаются важные артефакты, в отличие от штрафных санкций L1. В частности, обратите внимание на круговой артефакт, разделяющий пиксели в углах, который способствовал меньшему количеству выступов, чем центральный диск.</target>
        </trans-unit>
        <trans-unit id="cc89055f829a16401789a0501b3aaaa652548713" translate="yes" xml:space="preserve">
          <source>The reduced distance, defined for some metrics, is a computationally more efficient measure which preserves the rank of the true distance. For example, in the Euclidean distance metric, the reduced distance is the squared-euclidean distance.</source>
          <target state="translated">Уменьшенное расстояние,определенное для некоторых метрик,является более эффективной с вычислительной точки зрения мерой,которая сохраняет ранг истинного расстояния.Например,в метрике Евклидового расстояния уменьшенное расстояние является квадратно-евклидовым расстоянием.</target>
        </trans-unit>
        <trans-unit id="d3411437239f8f2dc8ee2706670c4e4a91db1791" translate="yes" xml:space="preserve">
          <source>The reduced samples.</source>
          <target state="translated">Сокращенные образцы.</target>
        </trans-unit>
        <trans-unit id="67c2217cec61f41257c896a393db0ce694f3f635" translate="yes" xml:space="preserve">
          <source>The refitted estimator is made available at the &lt;code&gt;best_estimator_&lt;/code&gt; attribute and permits using &lt;code&gt;predict&lt;/code&gt; directly on this &lt;code&gt;GridSearchCV&lt;/code&gt; instance.</source>
          <target state="translated">Переоборудованы оценщик становится доступным в &lt;code&gt;best_estimator_&lt;/code&gt; атрибута и позволяет использовать &lt;code&gt;predict&lt;/code&gt; непосредственно на этой &lt;code&gt;GridSearchCV&lt;/code&gt; инстанции.</target>
        </trans-unit>
        <trans-unit id="1178e040e21448dfc3d87635a64add70ee2fc71f" translate="yes" xml:space="preserve">
          <source>The refitted estimator is made available at the &lt;code&gt;best_estimator_&lt;/code&gt; attribute and permits using &lt;code&gt;predict&lt;/code&gt; directly on this &lt;code&gt;RandomizedSearchCV&lt;/code&gt; instance.</source>
          <target state="translated">Переоборудованы оценщик становится доступным в &lt;code&gt;best_estimator_&lt;/code&gt; атрибута и позволяет использовать &lt;code&gt;predict&lt;/code&gt; непосредственно на этой &lt;code&gt;RandomizedSearchCV&lt;/code&gt; инстанции.</target>
        </trans-unit>
        <trans-unit id="d35d9dbef92f31bfc55b28e05410d9f2634f5c0d" translate="yes" xml:space="preserve">
          <source>The regression target for each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb2b5c40285ce2a0d935c8174b2b1df487e2e554" translate="yes" xml:space="preserve">
          <source>The regression target or classification labels, if applicable. Dtype is float if numeric, and object if categorical.</source>
          <target state="translated">Цель регрессии или классификационные метки,если это применимо.D-тип является плавающим,если он числовой,и объектом,если он категоричный.</target>
        </trans-unit>
        <trans-unit id="f49726f7b2ee9ab1b3928455718be0471fabc15a" translate="yes" xml:space="preserve">
          <source>The regression target or classification labels, if applicable. Dtype is float if numeric, and object if categorical. If &lt;code&gt;as_frame&lt;/code&gt; is True, &lt;code&gt;target&lt;/code&gt; is a pandas object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3833ac2bfe2b88ee813e1c7e696adf8c3874fe96" translate="yes" xml:space="preserve">
          <source>The regression target.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b42b60d45f4e29bdab4ac89a5e2270a5774add83" translate="yes" xml:space="preserve">
          <source>The regression target. If &lt;code&gt;as_frame=True&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt; will be a pandas Series.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c39a60b37913113f18fb812e5aaafb85e77ce6aa" translate="yes" xml:space="preserve">
          <source>The regression targets. If &lt;code&gt;as_frame=True&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt; will be a pandas DataFrame.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="444eaf2365e5ec07e25a0ed19fde31ede0366773" translate="yes" xml:space="preserve">
          <source>The regressor is used to predict and the &lt;code&gt;inverse_func&lt;/code&gt; or &lt;code&gt;inverse_transform&lt;/code&gt; is applied before returning the prediction.</source>
          <target state="translated">Регрессор используется для прогнозирования, а &lt;code&gt;inverse_func&lt;/code&gt; или &lt;code&gt;inverse_transform&lt;/code&gt; применяются перед возвратом прогноза.</target>
        </trans-unit>
        <trans-unit id="edcb36e5cf0943282d84be3c17128a4f09595f3b" translate="yes" xml:space="preserve">
          <source>The regressor that is used for calibration depends on the &lt;code&gt;method&lt;/code&gt; parameter. &lt;code&gt;'sigmoid'&lt;/code&gt; corresponds to a parametric approach based on Platt&amp;rsquo;s logistic model &lt;a href=&quot;#id8&quot; id=&quot;id4&quot;&gt;3&lt;/a&gt;, i.e. \(p(y_i = 1 | f_i)\) is modeled as \(\sigma(A f_i + B)\) where \(\sigma\) is the logistic function, and \(A\) and \(B\) are real numbers to be determined when fitting the regressor via maximum likelihood. &lt;code&gt;'isotonic'&lt;/code&gt; will instead fit a non-parametric isotonic regressor, which outputs a step-wise non-decreasing function (see &lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ab5d35ab966f753794908f22950ec4d3c66e8fc" translate="yes" xml:space="preserve">
          <source>The regressor to stacked the base estimators fitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f20e2edcb6e4e7d6bdbe8de69b9b24c7725d7e1" translate="yes" xml:space="preserve">
          <source>The regularised covariance is:</source>
          <target state="translated">Урегулированный ковариационный:</target>
        </trans-unit>
        <trans-unit id="4dfecc4cc3d2dd0e68757701d8e0aef7bde77c4d" translate="yes" xml:space="preserve">
          <source>The regularization mixing parameter, with 0 &amp;lt;= l1_ratio &amp;lt;= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 &amp;lt; l1_ratio &amp;lt; 1, the penalty is a combination of L1 and L2.</source>
          <target state="translated">Параметр смешивания регуляризации с 0 &amp;lt;= l1_ratio &amp;lt;= 1. Для l1_ratio = 0 штрафом является поэлементный штраф L2 (также известный как норма Фробениуса). При l1_ratio = 1 это поэлементный штраф L1. Для 0 &amp;lt;l1_ratio &amp;lt;1 штраф представляет собой комбинацию L1 и L2.</target>
        </trans-unit>
        <trans-unit id="f1711bca786b8ddb98e81cd17b706bc6925eee44" translate="yes" xml:space="preserve">
          <source>The regularization parameter C in the LogisticRegression. When C is an array, fit will take each regularization parameter in C one by one for LogisticRegression and store results for each one in &lt;code&gt;all_scores_&lt;/code&gt;, where columns and rows represent corresponding reg_parameters and features.</source>
          <target state="translated">Параметр регуляризации C в LogisticRegression. Когда C является массивом, функция fit будет принимать каждый параметр регуляризации в C один за другим для LogisticRegression и сохранять результаты для каждого из них в &lt;code&gt;all_scores_&lt;/code&gt; , где столбцы и строки представляют соответствующие параметры reg_parameters и функции.</target>
        </trans-unit>
        <trans-unit id="7865779166b38ce9dcfe2e41f3eba5295cbd3874" translate="yes" xml:space="preserve">
          <source>The regularization parameter alpha parameter in the Lasso. Warning: this is not the alpha parameter in the stability selection article which is scaling.</source>
          <target state="translated">Параметр регуляризации альфа-параметр в Лассо.Предупреждение:в статье выбора стабильности,в которой выполняется масштабирование,альфа-параметр не является альфа-параметром.</target>
        </trans-unit>
        <trans-unit id="0ed37f5cbd4d43ac0f2b6fe6eac86f942c91256a" translate="yes" xml:space="preserve">
          <source>The regularization parameter: the higher alpha, the more regularization, the sparser the inverse covariance.</source>
          <target state="translated">Параметр регуляризации:чем выше альфа,тем больше регуляризация,тем меньше обратная ковариация.</target>
        </trans-unit>
        <trans-unit id="e124bf83498b6636f4567895eaf37c151f534f9f" translate="yes" xml:space="preserve">
          <source>The regularization parameter: the higher alpha, the more regularization, the sparser the inverse covariance. Range is (0, inf].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="688891a69c745428fa6d147d1a8f3e33c50a1bf6" translate="yes" xml:space="preserve">
          <source>The regularization reduces the influence of correlated variables on the model because the weight is shared between the two predictive variables, so neither alone would have strong weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a1b8c0c02e4613adc42b58f49402bda71930b51" translate="yes" xml:space="preserve">
          <source>The regularized (shrunk) covariance is given by:</source>
          <target state="translated">Регуляризованная (укороченная)ковариация дается:</target>
        </trans-unit>
        <trans-unit id="0a5a9291b6a07681a32efc9a88d6f2d7eab96435" translate="yes" xml:space="preserve">
          <source>The regularized (shrunk) covariance is:</source>
          <target state="translated">Регуляризованная (сокращенная)ковариация:</target>
        </trans-unit>
        <trans-unit id="5061099398d935daccb5dfd0421b959c5f17fce1" translate="yes" xml:space="preserve">
          <source>The regularized covariance is given by:</source>
          <target state="translated">Ковариативность регуляризации дается:</target>
        </trans-unit>
        <trans-unit id="bba73ee876f52c89494b029f9c7d24e1239abc01" translate="yes" xml:space="preserve">
          <source>The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.</source>
          <target state="translated">Регулятор-это штраф,добавляемый к функции потерь,который уменьшает параметры модели к нулевому вектору,используя либо квадратную эвклидовую норму L2,либо абсолютную норму L1,либо комбинацию обоих (Elastic Net).Если обновление параметров пересекает значение 0,0 из-за регулятора,обновление усекается до 0,0,чтобы позволить изучать разреженные модели и достичь онлайн-выбора функций.</target>
        </trans-unit>
        <trans-unit id="dccfd8ff5de1af25843574f310f33b70fd7f2fcc" translate="yes" xml:space="preserve">
          <source>The relationship between recall and precision can be observed in the stairstep area of the plot - at the edges of these steps a small change in the threshold considerably reduces precision, with only a minor gain in recall.</source>
          <target state="translated">Взаимосвязь между вспоминанием и точностью можно наблюдать на лестничной площадке участка-по краям этих ступеней небольшое изменение порога значительно снижает точность,с небольшим выигрышем в вспоминании.</target>
        </trans-unit>
        <trans-unit id="e4d930448408dd13aba80cfbcc12949bce572769" translate="yes" xml:space="preserve">
          <source>The relative importance of the fat noisy tail of the singular values profile if &lt;code&gt;effective_rank&lt;/code&gt; is not None.</source>
          <target state="translated">Относительная важность жирного зашумленного хвоста профиля сингулярных значений, если значение &lt;code&gt;effective_rank&lt;/code&gt; не равно None.</target>
        </trans-unit>
        <trans-unit id="5b4ee2ad411363b437ce1738486767191903cc20" translate="yes" xml:space="preserve">
          <source>The relative importance of the fat noisy tail of the singular values profile.</source>
          <target state="translated">Относительная важность жирно-шумного хвоста сингулярного профиля значений.</target>
        </trans-unit>
        <trans-unit id="1bf8ab4629789502195bd390130a1b2aa7e78e4e" translate="yes" xml:space="preserve">
          <source>The relative increment in the results before declaring convergence.</source>
          <target state="translated">Относительный прирост результатов до декларирования сходимости.</target>
        </trans-unit>
        <trans-unit id="ae073568b2b2b27a72266212b55fc2cb2d4cd169" translate="yes" xml:space="preserve">
          <source>The relative rank (i.e. depth) of a feature used as a decision node in a tree can be used to assess the relative importance of that feature with respect to the predictability of the target variable. Features used at the top of the tree contribute to the final prediction decision of a larger fraction of the input samples. The &lt;strong&gt;expected fraction of the samples&lt;/strong&gt; they contribute to can thus be used as an estimate of the &lt;strong&gt;relative importance of the features&lt;/strong&gt;. In scikit-learn, the fraction of samples a feature contributes to is combined with the decrease in impurity from splitting them to create a normalized estimate of the predictive power of that feature.</source>
          <target state="translated">Относительный ранг (то есть глубина) признака, используемого в качестве узла принятия решения в дереве, может использоваться для оценки относительной важности этого признака по отношению к предсказуемости целевой переменной. Элементы, используемые в верхней части дерева, участвуют в окончательном решении прогнозирования большей части входных выборок. Таким образом, &lt;strong&gt;ожидаемая доля выборок, в которые&lt;/strong&gt; они вносят вклад, может использоваться как оценка &lt;strong&gt;относительной важности характеристик&lt;/strong&gt; . В scikit-learn доля выборок, в которую вносит свой вклад функция, сочетается с уменьшением примесей от их разделения для создания нормализованной оценки предсказательной силы этой функции.</target>
        </trans-unit>
        <trans-unit id="81bcb12f84ef974910f69bd2abe477a2b6a71621" translate="yes" xml:space="preserve">
          <source>The remaining columns can be used to predict the frequency of claim events. Those columns are very heterogeneous with a mix of categorical and numeric variables with different scales, possibly very unevenly distributed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fc6d12d2c584bef7c5a793374c798219700e42f" translate="yes" xml:space="preserve">
          <source>The remaining singular values&amp;rsquo; tail is fat, decreasing as:</source>
          <target state="translated">Остальные сингулярные значения толстые, уменьшающиеся как:</target>
        </trans-unit>
        <trans-unit id="ec1c6c51e9847818ba009f4ace94e61e7f83ab56" translate="yes" xml:space="preserve">
          <source>The reported averages include macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label), and sample average (only for multilabel classification). Micro average (averaging the total true positives, false negatives and false positives) is only shown for multi-label or multi-class with a subset of classes, because it corresponds to accuracy otherwise. See also &lt;a href=&quot;sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt; for more details on averages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="006806051caab55f94063393a09eaea2afaeb022" translate="yes" xml:space="preserve">
          <source>The reported averages include micro average (averaging the total true positives, false negatives and false positives), macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label) and sample average (only for multilabel classification). See also &lt;a href=&quot;sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt; for more details on averages.</source>
          <target state="translated">Сообщаемые средние значения включают микро-среднее (усреднение общего количества истинно-положительных, ложноотрицательных и ложноположительных результатов), макросреднее (усреднение невзвешенного среднего для каждой метки), средневзвешенное (усреднение взвешенного по поддержке среднего значения для каждой метки) и выборочное среднее (только для нескольких меток). классификация). См. Также &lt;a href=&quot;sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt; &lt;code&gt;precision_recall_fscore_support&lt;/code&gt; &lt;/a&gt; для получения дополнительных сведений о средних значениях.</target>
        </trans-unit>
        <trans-unit id="8f7b2580f38f68e2972536327271d77d45324cd3" translate="yes" xml:space="preserve">
          <source>The residual matrix of X (Xk+1) block is obtained by the deflation on the current X score: x_score.</source>
          <target state="translated">Остаточная матрица блока X (Xk+1)получается путем дефляции при текущем значении X:x_score.</target>
        </trans-unit>
        <trans-unit id="18a2377c2d81e0ebb00644fcb1d33204e8d98249" translate="yes" xml:space="preserve">
          <source>The residual matrix of Y (Yk+1) block is obtained by deflation on the current X score. This performs the PLS regression known as PLS2. This mode is prediction oriented.</source>
          <target state="translated">Остаточная матрица блока Y (Yk+1)получается путем дефляции при текущей оценке X.При этом выполняется регрессия PLS,известная как PLS2.Этот режим является расчетным и прогнозным.</target>
        </trans-unit>
        <trans-unit id="953a5ab9533846fbfb5f76815143b2efa25824fa" translate="yes" xml:space="preserve">
          <source>The residual matrix of Y (Yk+1) block is obtained by deflation on the current Y score.</source>
          <target state="translated">Остаточная матрица блока Y (Yk+1)получается путем дефляции при текущей оценке Y.</target>
        </trans-unit>
        <trans-unit id="4786c768ceb1dac6ca78b9b9b4bd8e26183b7ef9" translate="yes" xml:space="preserve">
          <source>The residual matrix of Y (Yk+1) block is obtained by deflation on the current Y score. This performs a canonical symmetric version of the PLS regression. But slightly different than the CCA. This is mostly used for modeling.</source>
          <target state="translated">Остаточная матрица блока Y (Yk+1)получается путем дефляции при текущей оценке Y.При этом выполняется каноническая симметричная версия регрессии PLS.Но немного отличается от CCA.В основном это используется для моделирования.</target>
        </trans-unit>
        <trans-unit id="f3c685007c5e417136c9d43a236103e7a7414e81" translate="yes" xml:space="preserve">
          <source>The result is quite similar to the non-normalized case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3050c2e87895e094a17bdbd4ce41119b71fa1e6b" translate="yes" xml:space="preserve">
          <source>The result of &lt;a href=&quot;../../modules/linear_model#least-angle-regression&quot;&gt;Least Angle Regression&lt;/a&gt; is much more strongly biased: the difference is reminiscent of the local intensity value of the original image.</source>
          <target state="translated">Результат &lt;a href=&quot;../../modules/linear_model#least-angle-regression&quot;&gt;регрессии&lt;/a&gt; по наименьшему углу смещен гораздо сильнее: разница напоминает локальное значение интенсивности исходного изображения.</target>
        </trans-unit>
        <trans-unit id="2844a2c76b7226f0533d494b8e60503f59b9c4e8" translate="yes" xml:space="preserve">
          <source>The result of &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; may be different from those obtained using &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; as the elements are grouped in different ways. The function &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; takes an average over cross-validation folds, whereas &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; simply returns the labels (or probabilities) from several distinct models undistinguished. Thus, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; is not an appropriate measure of generalisation error.</source>
          <target state="translated">Результат &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt; &lt;code&gt;cross_val_predict&lt;/code&gt; &lt;/a&gt; может отличаться от результата, полученного с помощью &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; ,&lt;/a&gt; поскольку элементы сгруппированы по-разному. Функция &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; берет среднее значение по сверткам перекрестной проверки, тогда как &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt; &lt;code&gt;cross_val_predict&lt;/code&gt; &lt;/a&gt; просто возвращает метки (или вероятности) из нескольких различных моделей без различия. Таким образом, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt; &lt;code&gt;cross_val_predict&lt;/code&gt; &lt;/a&gt; не является подходящей мерой ошибки обобщения.</target>
        </trans-unit>
        <trans-unit id="a51791cdd2f13d5121648ef37a39961811acb402" translate="yes" xml:space="preserve">
          <source>The result of calling &lt;code&gt;fit&lt;/code&gt; on a &lt;code&gt;GridSearchCV&lt;/code&gt; object is a classifier that we can use to &lt;code&gt;predict&lt;/code&gt;:</source>
          <target state="translated">Результатом вызова &lt;code&gt;fit&lt;/code&gt; для объекта &lt;code&gt;GridSearchCV&lt;/code&gt; является классификатор, который мы можем использовать для &lt;code&gt;predict&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="88a0848975f5bdc5b1a985f762b1245644b8930f" translate="yes" xml:space="preserve">
          <source>The result of this method is identical to &lt;code&gt;np.diag(self(X))&lt;/code&gt;; however, it can be evaluated more efficiently since only the diagonal is evaluated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0c66fbb583b621a3ed191db16f52e8d9fa96072" translate="yes" xml:space="preserve">
          <source>The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.</source>
          <target state="translated">Результат этого метода идентичен np.diag(self(X));однако,он может быть оценен более эффективно,так как оценивается только диагональ.</target>
        </trans-unit>
        <trans-unit id="629d23e2107cca0c4a5d2061641bb34723082f2c" translate="yes" xml:space="preserve">
          <source>The result points are &lt;em&gt;not&lt;/em&gt; necessarily sorted by distance to their query point.</source>
          <target state="translated">Точки результатов &lt;em&gt;не&lt;/em&gt; обязательно отсортированы по расстоянию до точки запроса.</target>
        </trans-unit>
        <trans-unit id="97bd456bf5cbdca967559f8f3d5ed5bef7911efc" translate="yes" xml:space="preserve">
          <source>The resulting Calinski-Harabasz score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc861dceeba49e88611e2b04a0b3ec8cf37af89c" translate="yes" xml:space="preserve">
          <source>The resulting Calinski-Harabaz score.</source>
          <target state="translated">В результате счет Калински-Харабаз.</target>
        </trans-unit>
        <trans-unit id="91d97654f948931244cdd794d37fd9ac58fe871c" translate="yes" xml:space="preserve">
          <source>The resulting Davies-Bouldin score.</source>
          <target state="translated">В результате Дэвис-Болдин забил.</target>
        </trans-unit>
        <trans-unit id="cfd8b506a89d0c11900fefa11e6003ff64d7a508" translate="yes" xml:space="preserve">
          <source>The resulting Fowlkes-Mallows score.</source>
          <target state="translated">Итоговый результат &quot;Фаулкс-Маллоус&quot;.</target>
        </trans-unit>
        <trans-unit id="82343548ff27f39a450415f81d355404a35e8f50" translate="yes" xml:space="preserve">
          <source>The resulting bicluster structure is block-diagonal, since each row and each column belongs to exactly one bicluster.</source>
          <target state="translated">Полученная структура билюстра является блочно-диагональной,так как каждый ряд и каждый столбец принадлежит ровно одному билюстру.</target>
        </trans-unit>
        <trans-unit id="a10cedad8ec8047b7f7badb13dd314c46b9b1d6c" translate="yes" xml:space="preserve">
          <source>The resulting counts are normalized using &lt;a href=&quot;sklearn.preprocessing.normalize#sklearn.preprocessing.normalize&quot;&gt;&lt;code&gt;sklearn.preprocessing.normalize&lt;/code&gt;&lt;/a&gt; unless normalize is set to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af7844c7ade28bb6e966130c36de65d0b613a4b9" translate="yes" xml:space="preserve">
          <source>The resulting dataset contains ordinal attributes which can be further used in a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Результирующий набор данных содержит порядковые атрибуты, которые в дальнейшем можно использовать в &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2b9ee0d5d80ffdad0cbeed5368095411cec46727" translate="yes" xml:space="preserve">
          <source>The resulting kernel is defined as k_exp(X, Y) = k(X, Y) ** exponent</source>
          <target state="translated">Результирующее ядро определяется как k_exp(X,Y)=k(X,Y)**экспонента</target>
        </trans-unit>
        <trans-unit id="5f2e205585c93945d55d6e2cae73c2d9f60e4b99" translate="yes" xml:space="preserve">
          <source>The resulting kernel is defined as k_prod(X, Y) = k1(X, Y) * k2(X, Y)</source>
          <target state="translated">Результирующее ядро определяется как k_prod(X,Y)=k1(X,Y)*k2(X,Y)</target>
        </trans-unit>
        <trans-unit id="65c4e9abf2f65b5e239efef34833d44fb903de78" translate="yes" xml:space="preserve">
          <source>The resulting kernel is defined as k_sum(X, Y) = k1(X, Y) + k2(X, Y)</source>
          <target state="translated">Результирующее ядро определяется как k_sum(X,Y)=k1(X,Y)+k2(X,Y)</target>
        </trans-unit>
        <trans-unit id="fb9ca9651a528caa2f6deb96ee39233de0fa48d4" translate="yes" xml:space="preserve">
          <source>The resulting model is called &lt;em&gt;Bayesian Ridge Regression&lt;/em&gt;, and is similar to the classical &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt;. The parameters \(w\), \(\alpha\) and \(\lambda\) are estimated jointly during the fit of the model. The remaining hyperparameters are the parameters of the gamma priors over \(\alpha\) and \(\lambda\). These are usually chosen to be &lt;em&gt;non-informative&lt;/em&gt;. The parameters are estimated by maximizing the &lt;em&gt;marginal log likelihood&lt;/em&gt;.</source>
          <target state="translated">В результате чего модель называется &lt;em&gt;байесовской Ридж регрессии&lt;/em&gt; , и аналогичен классическому &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; . Параметры \ (w \), \ (\ alpha \) и \ (\ lambda \) оцениваются совместно во время подбора модели. Остальные гиперпараметры - это параметры гамма-априорных значений над \ (\ alpha \) и \ (\ lambda \). Обычно они выбираются как &lt;em&gt;неинформативные&lt;/em&gt; . Параметры оцениваются путем максимизации &lt;em&gt;предельного логарифмического правдоподобия&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="2ff5ad65586245c919e0a8e1ef11c4948b5606a5" translate="yes" xml:space="preserve">
          <source>The resulting patches are allocated in a dedicated array.</source>
          <target state="translated">Полученные патчи выделяются в специальный массив.</target>
        </trans-unit>
        <trans-unit id="64dfac2f5dc0c167f2eb731c8522fdbbf80022e7" translate="yes" xml:space="preserve">
          <source>The resulting transformer has then learned a supervised, sparse, high-dimensional categorical embedding of the data.</source>
          <target state="translated">Получившийся трансформатор затем научился контролируемому,разреженному,высокоразмерному категоричному встраиванию данных.</target>
        </trans-unit>
        <trans-unit id="52f668ebefc79801d78ca36ee52d3c9f5a955a8d" translate="yes" xml:space="preserve">
          <source>The results from OPTICS &lt;code&gt;cluster_optics_dbscan&lt;/code&gt; method and DBSCAN are very similar, but not always identical; specifically, labeling of periphery and noise points. This is in part because the first samples of each dense area processed by OPTICS have a large reachability value while being close to other points in their area, and will thus sometimes be marked as noise rather than periphery. This affects adjacent points when they are considered as candidates for being marked as either periphery or noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f9dd224b05fada5edc12dcb7a4c8d5421d61c2d" translate="yes" xml:space="preserve">
          <source>The return value is a cross-validator which generates the train/test splits via the &lt;code&gt;split&lt;/code&gt; method.</source>
          <target state="translated">Возвращаемое значение - это кросс-валидатор, который генерирует &lt;code&gt;split&lt;/code&gt; поездов / тестов с помощью метода разделения .</target>
        </trans-unit>
        <trans-unit id="63a7df0fd8542a7b486adfe1466de16955c3587a" translate="yes" xml:space="preserve">
          <source>The returned dataset is a &lt;code&gt;scikit-learn&lt;/code&gt; &amp;ldquo;bunch&amp;rdquo;: a simple holder object with fields that can be both accessed as python &lt;code&gt;dict&lt;/code&gt; keys or &lt;code&gt;object&lt;/code&gt; attributes for convenience, for instance the &lt;code&gt;target_names&lt;/code&gt; holds the list of the requested category names:</source>
          <target state="translated">&lt;code&gt;scikit-learn&lt;/code&gt; набор данных представляет собой &amp;laquo;набор&amp;raquo; scikit-learn : простой объект-держатель с полями, к которым для удобства можно обращаться как в виде ключей Python &lt;code&gt;dict&lt;/code&gt; ,так и атрибутов &lt;code&gt;object&lt;/code&gt; , например &lt;code&gt;target_names&lt;/code&gt; содержит список запрошенных имен категорий:</target>
        </trans-unit>
        <trans-unit id="c5d262a3b65ccb350b8a1d10b0eaf6eba41fc62d" translate="yes" xml:space="preserve">
          <source>The returned estimates for all classes are ordered by label of classes.</source>
          <target state="translated">Возвращаемые оценки по всем классам упорядочены по меткам классов.</target>
        </trans-unit>
        <trans-unit id="8520c10c8edb7f58383ef36900c902f5398bf785" translate="yes" xml:space="preserve">
          <source>The returned estimates for all classes are ordered by the label of classes.</source>
          <target state="translated">Возвращаемые оценки по всем классам упорядочены по метке классов.</target>
        </trans-unit>
        <trans-unit id="9fa1a308376d0d44aa58fe9b54fd102c1f0b956a" translate="yes" xml:space="preserve">
          <source>The returned object is a MemorizedFunc object, that is callable (behaves like a function), but offers extra methods for cache lookup and management. See the documentation for &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/memory.html#joblib.memory.MemorizedFunc&quot;&gt;&lt;code&gt;joblib.memory.MemorizedFunc&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Возвращаемый объект - это объект MemorizedFunc, который вызывается (ведет себя как функция), но предлагает дополнительные методы для поиска и управления кешем. См. Документацию для &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/memory.html#joblib.memory.MemorizedFunc&quot;&gt; &lt;code&gt;joblib.memory.MemorizedFunc&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4a1e44716730f4f771067bf0b441674e2034e883" translate="yes" xml:space="preserve">
          <source>The richer dictionary on the right is not larger in size, heavier subsampling is performed in order to stay on the same order of magnitude.</source>
          <target state="translated">Более богатый словарь справа невелик по размеру,более тяжелая субдискретизация выполняется для того,чтобы остаться на том же порядке величины.</target>
        </trans-unit>
        <trans-unit id="6f396634dd18eef11c3d60404319f2831b13040b" translate="yes" xml:space="preserve">
          <source>The right figures correspond to the same plots but using instead a bagging ensemble of decision trees. In both figures, we can observe that the bias term is larger than in the previous case. In the upper right figure, the difference between the average prediction (in cyan) and the best possible model is larger (e.g., notice the offset around &lt;code&gt;x=2&lt;/code&gt;). In the lower right figure, the bias curve is also slightly higher than in the lower left figure. In terms of variance however, the beam of predictions is narrower, which suggests that the variance is lower. Indeed, as the lower right figure confirms, the variance term (in green) is lower than for single decision trees. Overall, the bias- variance decomposition is therefore no longer the same. The tradeoff is better for bagging: averaging several decision trees fit on bootstrap copies of the dataset slightly increases the bias term but allows for a larger reduction of the variance, which results in a lower overall mean squared error (compare the red curves int the lower figures). The script output also confirms this intuition. The total error of the bagging ensemble is lower than the total error of a single decision tree, and this difference indeed mainly stems from a reduced variance.</source>
          <target state="translated">Правые рисунки соответствуют тем же графикам, но вместо них используется ансамбль деревьев решений. На обоих рисунках мы можем видеть, что член смещения больше, чем в предыдущем случае. На верхнем правом рисунке разница между средним прогнозом (голубым цветом) и наилучшей возможной моделью больше (например, обратите внимание на смещение около &lt;code&gt;x=2&lt;/code&gt; ). На нижнем правом рисунке кривая смещения также немного выше, чем на нижнем левом рисунке. Однако с точки зрения дисперсии диапазон прогнозов уже, что предполагает меньшую дисперсию. Действительно, как подтверждает нижний правый рисунок, член дисперсии (выделенный зеленым цветом) ниже, чем для отдельных деревьев решений. В целом, разложение отклонения-отклонения уже не то же самое. Компромисс лучше подходит для упаковки: усреднение нескольких деревьев решений, подходящих для загрузочных копий набора данных, немного увеличивает член смещения, но допускает большее уменьшение дисперсии, что приводит к более низкой общей среднеквадратической ошибке (сравните красные кривые с нижним цифры). Вывод сценария также подтверждает эту интуицию. Суммарная ошибка ансамбля мешков ниже, чем общая ошибка одного дерева решений,и эта разница действительно в основном связана с уменьшением дисперсии.</target>
        </trans-unit>
        <trans-unit id="4281560832d700a912bb9768ad9253748f3986db" translate="yes" xml:space="preserve">
          <source>The right plot shows the mean squared error between the coefficients found by the model and the chosen vector w. Less regularised models retrieve the exact coefficients (error is equal to 0), stronger regularised models increase the error.</source>
          <target state="translated">На правом графике показана средняя квадратная ошибка между коэффициентами,найденными моделью и выбранным вектором w.Менее регулярные модели получают точные коэффициенты (погрешность равна 0),более сильные регулярные модели увеличивают погрешность.</target>
        </trans-unit>
        <trans-unit id="e91440f2fdf83c048c6ec145aa4ba8b2408d7a77" translate="yes" xml:space="preserve">
          <source>The robust MCD, that has a low error provided \(n_\text{samples} &amp;gt; 5n_\text{features}\)</source>
          <target state="translated">Надежный MCD с низким уровнем ошибок \ (n_ \ text {samples}&amp;gt; 5n_ \ text {features} \)</target>
        </trans-unit>
        <trans-unit id="ba79522dd51eaaef6a47e20f449051b56df7c07d" translate="yes" xml:space="preserve">
          <source>The roc curve requires either the probabilities or the non-thresholded decision values from the estimator. Since the logistic regression provides a decision function, we will use it to plot the roc curve:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f09e161fdb50b4bf88ea2669cf0485f026fd48" translate="yes" xml:space="preserve">
          <source>The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.</source>
          <target state="translated">Строки-это образцы,а колонки-это колонки:Длина лепестка,Ширина лепестка,Длина лепестка и Ширина лепестка.</target>
        </trans-unit>
        <trans-unit id="075c19426795ecca36fadcd5142db0c818eae0c2" translate="yes" xml:space="preserve">
          <source>The s parameter used to randomly scale the penalty of different features. Should be between 0 and 1.</source>
          <target state="translated">Параметр s используется для случайного масштабирования штрафов за различные функции.Должен быть между 0 и 1.</target>
        </trans-unit>
        <trans-unit id="04a6b9de3c4814c0e0ce533f438ce9705b113ee4" translate="yes" xml:space="preserve">
          <source>The same as the min_samples given to OPTICS. Up and down steep regions can&amp;rsquo;t have more then &lt;code&gt;min_samples&lt;/code&gt; consecutive non-steep points. Expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e103a284fd35ca6afde93378ca71e413fedf538" translate="yes" xml:space="preserve">
          <source>The same group will not appear in two different folds (the number of distinct groups has to be at least equal to the number of folds).</source>
          <target state="translated">Одна и та же группа не появится в двух разных сгибах (количество разных групп должно быть как минимум равным количеству складок).</target>
        </trans-unit>
        <trans-unit id="0bd48a9cd63a739602e7de633cedbe34c0721a4f" translate="yes" xml:space="preserve">
          <source>The same instance of the transformer can then be applied to some new test data unseen during the fit call: the same scaling and shifting operations will be applied to be consistent with the transformation performed on the train data:</source>
          <target state="translated">Тот же экземпляр трансформатора может быть применен к некоторым новым испытательным данным,невидимым во время подгонки:те же самые операции масштабирования и сдвига будут применяться,чтобы быть согласованными с преобразованием,выполненным в данных поезда:</target>
        </trans-unit>
        <trans-unit id="9b63d107562f8bc53dcee73bc223f241497e945e" translate="yes" xml:space="preserve">
          <source>The same parameter &lt;code&gt;target&lt;/code&gt; is used to specify the target in multi-output regression settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4fc830eaa32e3715aa0bbc8cdaaf20cd8fc44d0" translate="yes" xml:space="preserve">
          <source>The same probability calibration procedure is available for all estimators via the &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;calibration#calibration&quot;&gt;Probability calibration&lt;/a&gt;). In the case of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;, this procedure is builtin in &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; which is used under the hood, so it does not rely on scikit-learn&amp;rsquo;s &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c16a50cac2b1dc1101733e88917cf565ad0ad55a" translate="yes" xml:space="preserve">
          <source>The sample counts that are shown are weighted with any sample_weights that might be present.</source>
          <target state="translated">Показанные значения sample_weights взвешиваются с учетом любых весов sample_weights,которые могут присутствовать.</target>
        </trans-unit>
        <trans-unit id="da56cc1e3278be97e394d14d7afaac125d975593" translate="yes" xml:space="preserve">
          <source>The sample weighting rescales the C parameter, which means that the classifier puts more emphasis on getting these points right. The effect might often be subtle. To emphasize the effect here, we particularly weight outliers, making the deformation of the decision boundary very visible.</source>
          <target state="translated">Пример взвешивания перепродает параметр C,что означает,что классификатор делает больший акцент на правильном определении этих баллов.Эффект часто может быть тонким.Чтобы подчеркнуть эффект здесь,мы особенно взвешиваем отклонения,делая деформацию границы решения очень заметной.</target>
        </trans-unit>
        <trans-unit id="67f0f1888d07b20765c25e213bac379b2147854b" translate="yes" xml:space="preserve">
          <source>The sampled subsets of integer. The subset of selected integer might not be randomized, see the method argument.</source>
          <target state="translated">Выборочные подмножества целых чисел.Подмножество выбранных целых чисел может быть не рандомизировано,см.аргумент метода.</target>
        </trans-unit>
        <trans-unit id="582c77a6e6e223c6a451ff779c949c2d01a1e4b1" translate="yes" xml:space="preserve">
          <source>The samples in this dataset correspond to 30&amp;times;30m patches of forest in the US, collected for the task of predicting each patch&amp;rsquo;s cover type, i.e. the dominant species of tree. There are seven covertypes, making this a multiclass classification problem. Each sample has 54 features, described on the &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Covertype&quot;&gt;dataset&amp;rsquo;s homepage&lt;/a&gt;. Some of the features are boolean indicators, while others are discrete or continuous measurements.</source>
          <target state="translated">Образцы в этом наборе данных соответствуют участкам леса 30 &amp;times; 30 м в США, собранным для задачи прогнозирования типа покрытия каждого участка, т. Е. Доминирующих видов деревьев. Существует семь типов обложек, что делает эту задачу классификационной мультиклассовой. Каждый образец имеет 54 функции, описанные на &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Covertype&quot;&gt;домашней странице набора данных&lt;/a&gt; . Некоторые из функций являются логическими индикаторами, а другие - дискретными или непрерывными измерениями.</target>
        </trans-unit>
        <trans-unit id="5425b30895b660513d41a7b82e02c9858a9f43c3" translate="yes" xml:space="preserve">
          <source>The samples in this dataset correspond to 30&amp;times;30m patches of forest in the US, collected for the task of predicting each patch&amp;rsquo;s cover type, i.e. the dominant species of tree. There are seven covertypes, making this a multiclass classification problem. Each sample has 54 features, described on the &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Covertype&quot;&gt;dataset&amp;rsquo;s homepage&lt;/a&gt;. Some of the features are boolean indicators, while others are discrete or continuous measurements.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5340a26524629a68efc3f526b09b13eeae9b4043" translate="yes" xml:space="preserve">
          <source>The samples that are used to train the calibrator should not be used to train the target classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3faf112740a094590f64233617c65a5fa097ee8f" translate="yes" xml:space="preserve">
          <source>The samples.</source>
          <target state="translated">Образцы.</target>
        </trans-unit>
        <trans-unit id="7217248266c27250d74fa132fb5cef7e3435697a" translate="yes" xml:space="preserve">
          <source>The scalar parameter to validate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1aa98782517735bf609d139ad8030ba79e53e38f" translate="yes" xml:space="preserve">
          <source>The scaler instance can then be used on new data to transform it the same way it did on the training set:</source>
          <target state="translated">Затем экземпляр скалера может быть использован на новых данных,чтобы преобразовать их так же,как это было сделано на обучающем множестве:</target>
        </trans-unit>
        <trans-unit id="fae25cf01c011421f9b169e383c16cc5b0e7dc5d" translate="yes" xml:space="preserve">
          <source>The scikit-learn project provides a set of machine learning tools that can be used both for novelty or outlier detection. This strategy is implemented with objects learning in an unsupervised way from the data:</source>
          <target state="translated">Проект &quot;Scikit-learn&quot; предоставляет набор станков для обучения,которые можно использовать как для обнаружения новизны,так и для обнаружения отклонений от нормы.Эта стратегия реализуется при обучении с помощью объектов без контроля на основе данных:</target>
        </trans-unit>
        <trans-unit id="b2bcbd53d39d84e38eaccf61f40a5b7e3d9f1072" translate="yes" xml:space="preserve">
          <source>The scikit-learn provides an object &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt; that fits a robust covariance estimate to the data, and thus fits an ellipse to the central data points, ignoring points outside the central mode.</source>
          <target state="translated">Scikit-learn предоставляет объектную &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; которая подгоняет надежную оценку ковариации к данным и, таким образом, подгоняет эллипс к центральным точкам данных, игнорируя точки за пределами центрального режима.</target>
        </trans-unit>
        <trans-unit id="c6f20ecec2f178819b742529ff67a9012c4e74b9" translate="yes" xml:space="preserve">
          <source>The score above which features should be selected.</source>
          <target state="translated">Счет,выше которого должны быть выбраны характеристики.</target>
        </trans-unit>
        <trans-unit id="fbc2c7bdd77bdb62a30109845f32d883a40f3289" translate="yes" xml:space="preserve">
          <source>The score array for test scores on each cv split.</source>
          <target state="translated">Массив баллов для тестов на каждом cv-разрыве.</target>
        </trans-unit>
        <trans-unit id="a1547f496d2e14d7ede805b073598361b82ebf35" translate="yes" xml:space="preserve">
          <source>The score array for test scores on each cv split. Suffix &lt;code&gt;_score&lt;/code&gt; in &lt;code&gt;test_score&lt;/code&gt; changes to a specific metric like &lt;code&gt;test_r2&lt;/code&gt; or &lt;code&gt;test_auc&lt;/code&gt; if there are multiple scoring metrics in the scoring parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e1ecd73a82717f9c044c3e124c2c92104db3c6b" translate="yes" xml:space="preserve">
          <source>The score array for train scores on each cv split. Suffix &lt;code&gt;_score&lt;/code&gt; in &lt;code&gt;train_score&lt;/code&gt; changes to a specific metric like &lt;code&gt;train_r2&lt;/code&gt; or &lt;code&gt;train_auc&lt;/code&gt; if there are multiple scoring metrics in the scoring parameter. This is available only if &lt;code&gt;return_train_score&lt;/code&gt; parameter is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21374122c0da50ea660a65ea3274fa15ca9abbe5" translate="yes" xml:space="preserve">
          <source>The score array for train scores on each cv split. This is available only if &lt;code&gt;return_train_score&lt;/code&gt; parameter is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Массив очков для оценок поездов по каждому разделению резюме. Это доступно, только если параметр &lt;code&gt;return_train_score&lt;/code&gt; имеет значение &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f9f0e8fbf15571f500f19345d44e98db663f1949" translate="yes" xml:space="preserve">
          <source>The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters.</source>
          <target state="translated">Счетчик ограничен между -1 для неправильной кластеризации и +1 для очень плотной кластеризации.Баллы около нуля указывают на перекрытие кластеров.</target>
        </trans-unit>
        <trans-unit id="10419dac5247bd799d768931a57ece7edc36ff14" translate="yes" xml:space="preserve">
          <source>The score is defined as ratio between the within-cluster dispersion and the between-cluster dispersion.</source>
          <target state="translated">Счет определяется как соотношение между дисперсией внутри кластера и дисперсией между кластерами.</target>
        </trans-unit>
        <trans-unit id="24504b3de92e08246a270b0dc2b57eafc2174bab" translate="yes" xml:space="preserve">
          <source>The score is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances. Thus, clusters which are farther apart and less dispersed will result in a better score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5fc2e46656049d91b95dd6363e2ef13687eb710" translate="yes" xml:space="preserve">
          <source>The score is defined as the ratio of within-cluster distances to between-cluster distances.</source>
          <target state="translated">Балл определяется как отношение расстояний внутри кластера к межкластерным расстояниям.</target>
        </trans-unit>
        <trans-unit id="a9ccc42adfd31440d43d06c5c4aab96f5e8222f0" translate="yes" xml:space="preserve">
          <source>The score is fast to compute</source>
          <target state="translated">Счет быстро вычисляется</target>
        </trans-unit>
        <trans-unit id="ef88d78d9d28409ef934e001658916bd55503917" translate="yes" xml:space="preserve">
          <source>The score is fast to compute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="298450881e1d83a617f17a47cba5b823081f8332" translate="yes" xml:space="preserve">
          <source>The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.</source>
          <target state="translated">Балл выше,когда кластеры плотно и хорошо разделены,что относится к стандартной концепции кластера.</target>
        </trans-unit>
        <trans-unit id="8ebec04d9506729ea096f793265427e501ac6359" translate="yes" xml:space="preserve">
          <source>The score ranges from 0 to 1, or when &lt;code&gt;adjusted=True&lt;/code&gt; is used, it rescaled to the range \(\frac{1}{1 - \text{n\_classes}}\) to 1, inclusive, with performance at random scoring 0.</source>
          <target state="translated">Оценка находится в диапазоне от 0 до 1, или, если используется параметр Adjust &lt;code&gt;adjusted=True&lt;/code&gt; , масштаб изменяется в диапазоне от \ (\ frac {1} {1 - \ text {n \ _classes}}} до 1 включительно, с производительностью случайным образом. оценка 0.</target>
        </trans-unit>
        <trans-unit id="f66ce641ead1aaeebf85e08eeb401e8169ff494e" translate="yes" xml:space="preserve">
          <source>The score ranges from 0 to 1, or when &lt;code&gt;adjusted=True&lt;/code&gt; is used, it rescaled to the range \(\frac{1}{1 - n\_classes}\) to 1, inclusive, with performance at random scoring 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99f201771620c880cb8fcf0a4290517d17eb61e7" translate="yes" xml:space="preserve">
          <source>The score ranges from 0 to 1. A high value indicates a good similarity between two clusters.</source>
          <target state="translated">Счет колеблется от 0 до 1.Высокое значение указывает на хорошее сходство между двумя кластерами.</target>
        </trans-unit>
        <trans-unit id="67703aed8c056d27307c0c36c3685d8f65de746b" translate="yes" xml:space="preserve">
          <source>The scorer callable object / function must have its signature as &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;.</source>
          <target state="translated">Вызываемый объект / функция счетчика должен иметь свою подпись как &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5e77d6fe812bc8f046068c5fa078dda3a1146e44" translate="yes" xml:space="preserve">
          <source>The scorer.</source>
          <target state="translated">Счетчик.</target>
        </trans-unit>
        <trans-unit id="97894cb494476d0c2ed229f8ae81e55aa78ff1c3" translate="yes" xml:space="preserve">
          <source>The scores at each iteration on the held-out validation data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the &lt;code&gt;scoring&lt;/code&gt; parameter. Empty if no early stopping or if &lt;code&gt;validation_fraction&lt;/code&gt; is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04400e5c44d656378bb2e0f77c0e1b05794d2b51" translate="yes" xml:space="preserve">
          <source>The scores at each iteration on the training data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the &lt;code&gt;scoring&lt;/code&gt; parameter. If &lt;code&gt;scoring&lt;/code&gt; is not &amp;lsquo;loss&amp;rsquo;, scores are computed on a subset of at most 10 000 samples. Empty if no early stopping.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd1c18a79b397962bdc5e0312d35f12a484f084a" translate="yes" xml:space="preserve">
          <source>The scores for each feature along the path.</source>
          <target state="translated">Оценки за каждую функцию на пути.</target>
        </trans-unit>
        <trans-unit id="81a1b1406082100f034b3df6c2ec24562a123854" translate="yes" xml:space="preserve">
          <source>The scores obtained for each permutations.</source>
          <target state="translated">Полученные баллы за каждую перестановку.</target>
        </trans-unit>
        <trans-unit id="12753b21f50efe6accfab886a283f46c3614c6fe" translate="yes" xml:space="preserve">
          <source>The scores of HuberRegressor may not be compared directly to both TheilSen and RANSAC because it does not attempt to completely filter the outliers but lessen their effect.</source>
          <target state="translated">Оценки HuberRegressor нельзя напрямую сравнивать как с TheilSen,так и с RANSAC,так как он не пытается полностью отфильтровать отклонения,а снижает их эффект.</target>
        </trans-unit>
        <trans-unit id="48d352a6767e745c328aec9195da7218a62bd613" translate="yes" xml:space="preserve">
          <source>The scores of all the scorers are available in the &lt;code&gt;cv_results_&lt;/code&gt; dict at keys ending in &lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt; (&lt;code&gt;'mean_test_precision'&lt;/code&gt;, &lt;code&gt;'rank_test_precision'&lt;/code&gt;, etc&amp;hellip;)</source>
          <target state="translated">Оценки всех &lt;code&gt;cv_results_&lt;/code&gt; доступны в cv_results_ dict в ключах, оканчивающихся на &lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt; ( &lt;code&gt;'mean_test_precision'&lt;/code&gt; , &lt;code&gt;'rank_test_precision'&lt;/code&gt; и т. Д.)</target>
        </trans-unit>
        <trans-unit id="1676248dcc2b8fd0688c9d8da4bc193152185788" translate="yes" xml:space="preserve">
          <source>The search for the optimal penalization parameter (alpha) is done on an iteratively refined grid: first the cross-validated scores on a grid are computed, then a new refined grid is centered around the maximum, and so on.</source>
          <target state="translated">Поиск оптимального параметра пенализации (альфа)производится на итеративно уточнённой сетке:сначала вычисляются перекрёстные оценки на сетке,затем новая уточнённая сетка центрируется вокруг максимума,и так далее.</target>
        </trans-unit>
        <trans-unit id="929b69ae47a09aabafb756d8ff0633d79e90c985" translate="yes" xml:space="preserve">
          <source>The searched parameter.</source>
          <target state="translated">Поисковый параметр.</target>
        </trans-unit>
        <trans-unit id="0d9a4b24aef1596fe1105c7b9e28ffdd6e589d45" translate="yes" xml:space="preserve">
          <source>The second base-kernel of the product-kernel</source>
          <target state="translated">Второе базовое ядро продукта-ядро</target>
        </trans-unit>
        <trans-unit id="2d0afedea31e6e04d617f4edd60a150835c5916d" translate="yes" xml:space="preserve">
          <source>The second base-kernel of the sum-kernel</source>
          <target state="translated">Второе базовое ядро суммарного ядра</target>
        </trans-unit>
        <trans-unit id="544eb81771c23c2f620b00755dbcd12f00cacc66" translate="yes" xml:space="preserve">
          <source>The second example shows the ability of the Minimum Covariance Determinant robust estimator of covariance to concentrate on the main mode of the data distribution: the location seems to be well estimated, although the covariance is hard to estimate due to the banana-shaped distribution. Anyway, we can get rid of some outlying observations. The One-Class SVM is able to capture the real data structure, but the difficulty is to adjust its kernel bandwidth parameter so as to obtain a good compromise between the shape of the data scatter matrix and the risk of over-fitting the data.</source>
          <target state="translated">Во втором примере показана способность робастного оценщика минимальной ковариативности ковариаций сконцентрироваться на основном режиме распределения данных:кажется,что местоположение хорошо оценено,хотя ковариацию трудно оценить из-за банановидного распределения.В любом случае,мы можем избавиться от некоторых отдаленных наблюдений.One-Class SVM способен захватить реальную структуру данных,но сложность заключается в настройке параметра полосы пропускания ядра,чтобы получить хороший компромисс между формой матрицы рассеяния данных и риском переподгонки данных.</target>
        </trans-unit>
        <trans-unit id="5a46c67db9268b64cb76670e9e1b845e906b608f" translate="yes" xml:space="preserve">
          <source>The second figure shows the calibration curve of a linear support-vector classifier (LinearSVC). LinearSVC shows the opposite behavior as Gaussian naive Bayes: the calibration curve has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">На втором рисунке показана калибровочная кривая линейного векторного классификатора поддержки (LinearSVC).LinearSVC показывает обратное поведение,как Гауссов наивный Байес:калибровочная кривая имеет сигмовидную кривую,что типично для классификатора с недостаточной степенью уверенности.В случае LinearSVC это вызвано свойством margin margin loss шарнира,что позволяет модели ориентироваться на твердые образцы,находящиеся вблизи границы решения (векторы поддержки).</target>
        </trans-unit>
        <trans-unit id="e56142dda4889d67d8f5448567e56cb678c48e3c" translate="yes" xml:space="preserve">
          <source>The second figure shows the log-marginal-likelihood for different choices of the kernel&amp;rsquo;s hyperparameters, highlighting the two choices of the hyperparameters used in the first figure by black dots.</source>
          <target state="translated">На втором рисунке показана предельная логарифмическая вероятность для различных вариантов выбора гиперпараметров ядра, при этом два варианта гиперпараметров, использованных на первом рисунке, выделены черными точками.</target>
        </trans-unit>
        <trans-unit id="69a6b8988bb4a9da22ae7a8129c60d4bfa19ab9d" translate="yes" xml:space="preserve">
          <source>The second loader is typically used for the face verification task: each sample is a pair of two picture belonging or not to the same person:</source>
          <target state="translated">Второй загрузчик обычно используется для задачи проверки лица:каждый образец представляет собой пару двух картинок,принадлежащих или не принадлежащих одному и тому же человеку:</target>
        </trans-unit>
        <trans-unit id="80a536b57ba05b05dbab01bd549517eccd6caab7" translate="yes" xml:space="preserve">
          <source>The second model is a Bayesian Gaussian Mixture Model with a Dirichlet process prior fit with variational inference. The low value of the concentration prior makes the model favor a lower number of active components. This models &amp;ldquo;decides&amp;rdquo; to focus its modeling power on the big picture of the structure of the dataset: groups of points with alternating directions modeled by non-diagonal covariance matrices. Those alternating directions roughly capture the alternating nature of the original sine signal.</source>
          <target state="translated">Вторая модель - это модель байесовской гауссовой смеси с предварительным подбором процесса Дирихле и вариационным выводом. Низкое значение априорной концентрации заставляет модель отдавать предпочтение меньшему количеству активных компонентов. Эта модель &amp;laquo;решает&amp;raquo; сфокусировать свои возможности моделирования на общей картине структуры набора данных: группы точек с чередующимися направлениями, моделируемые недиагональными ковариационными матрицами. Эти чередующиеся направления примерно отражают переменную природу исходного синусоидального сигнала.</target>
        </trans-unit>
        <trans-unit id="ce63f012cd3f9d5ba6717aef4dc1ee5e80e67c9d" translate="yes" xml:space="preserve">
          <source>The second one has a smaller noise level and shorter length scale, which explains most of the variation by the noise-free functional relationship. The second model has a higher likelihood; however, depending on the initial value for the hyperparameters, the gradient-based optimization might also converge to the high-noise solution. It is thus important to repeat the optimization several times for different initializations.</source>
          <target state="translated">Второй имеет меньший уровень шума и более короткую шкалу длины,что объясняет большую часть вариаций бесшумной функциональной зависимостью.Вторая модель имеет более высокую вероятность;однако,в зависимости от исходного значения для гиперпараметров,градиентная оптимизация может также сойтись с высокошумным решением.Поэтому важно несколько раз повторить оптимизацию для различных инициализаций.</target>
        </trans-unit>
        <trans-unit id="d5dcf1b11e556ea9365934aae9c750b0508ecb89" translate="yes" xml:space="preserve">
          <source>The second plot demonstrate one single run of the &lt;code&gt;MiniBatchKMeans&lt;/code&gt; estimator using a &lt;code&gt;init=&quot;random&quot;&lt;/code&gt; and &lt;code&gt;n_init=1&lt;/code&gt;. This run leads to a bad convergence (local optimum) with estimated centers stuck between ground truth clusters.</source>
          <target state="translated">Второй график демонстрирует один прогон &lt;code&gt;MiniBatchKMeans&lt;/code&gt; оценки MiniBatchKMeans с использованием &lt;code&gt;init=&quot;random&quot;&lt;/code&gt; и &lt;code&gt;n_init=1&lt;/code&gt; . Этот прогон приводит к плохой сходимости (локальный оптимум) с предполагаемыми центрами, застрявшими между наземными кластерами истинности.</target>
        </trans-unit>
        <trans-unit id="41338f596d871499307d96f69f697b91afdfa1c4" translate="yes" xml:space="preserve">
          <source>The second plot is a heatmap of the classifier&amp;rsquo;s cross-validation accuracy as a function of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. For this example we explore a relatively large grid for illustration purposes. In practice, a logarithmic grid from \(10^{-3}\) to \(10^3\) is usually sufficient. If the best parameters lie on the boundaries of the grid, it can be extended in that direction in a subsequent search.</source>
          <target state="translated">Второй график - это тепловая карта точности перекрестной проверки классификатора в зависимости от &lt;code&gt;C&lt;/code&gt; и &lt;code&gt;gamma&lt;/code&gt; . В этом примере мы исследуем относительно большую сетку в целях иллюстрации. На практике обычно достаточно логарифмической сетки от \ (10 ​​^ {- 3} \) до \ (10 ​​^ 3 \). Если наилучшие параметры лежат на границах сетки, ее можно расширить в этом направлении при последующем поиске.</target>
        </trans-unit>
        <trans-unit id="57fb8e025f7ec94b6d1e30748cbff5561f1e9901" translate="yes" xml:space="preserve">
          <source>The second plot shows that an increase of the admissible distortion &lt;code&gt;eps&lt;/code&gt; allows to reduce drastically the minimal number of dimensions &lt;code&gt;n_components&lt;/code&gt; for a given number of samples &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">Второй график показывает, что увеличение допустимого искажения &lt;code&gt;eps&lt;/code&gt; позволяет резко уменьшить минимальное количество измерений &lt;code&gt;n_components&lt;/code&gt; для заданного количества отсчетов &lt;code&gt;n_samples&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9c6c0ec72e2e2da2def0a20a979b162b66b4f25f" translate="yes" xml:space="preserve">
          <source>The second plot visualized the decision surfaces of the RBF kernel SVM and the linear SVM with approximate kernel maps. The plot shows decision surfaces of the classifiers projected onto the first two principal components of the data. This visualization should be taken with a grain of salt since it is just an interesting slice through the decision surface in 64 dimensions. In particular note that a datapoint (represented as a dot) does not necessarily be classified into the region it is lying in, since it will not lie on the plane that the first two principal components span.</source>
          <target state="translated">На втором графике были визуализированы поверхности принятия решений ядра RBF SVM и линейные SVM с приблизительными картами ядра.На графике показаны поверхности принятия решений классификаторов,проецируемые на первые две основные составляющие данных.Эта визуализация должна быть выполнена с использованием зерна соли,так как это всего лишь интересный срез через поверхность принятия решений в 64 измерениях.В частности,обратите внимание,что точка данных (представленная в виде точки)не обязательно должна быть классифицирована на область,в которой она лежит,так как она не будет лежать на плоскости,которая простирается на первые две главные компоненты.</target>
        </trans-unit>
        <trans-unit id="0b0b4cc48e44d58bc4674ef40664981912a3f333" translate="yes" xml:space="preserve">
          <source>The second plot visualized the decision surfaces of the RBF kernel SVM and the linear SVM with approximate kernel maps. The plot shows decision surfaces of the classifiers projected onto the first two principal components of the data. This visualization should be taken with a grain of salt since it is just an interesting slice through the decision surface in 64 dimensions. In particular note that a datapoint (represented as a dot) does not necessarily be classified into the region it is lying in, since it will not lie on the plane that the first two principal components span. The usage of &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; is described in detail in &lt;a href=&quot;../../modules/kernel_approximation#kernel-approximation&quot;&gt;Kernel Approximation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7aa029b23a556153d8e76aebf5393705fc5a931" translate="yes" xml:space="preserve">
          <source>The second use case is to build a completely custom scorer object from a simple python function using &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt;, which can take several parameters:</source>
          <target state="translated">Второй вариант использования - создание полностью настраиваемого объекта &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; из простой функции Python с использованием make_scorer , который может принимать несколько параметров:</target>
        </trans-unit>
        <trans-unit id="c00cf63770db0bb2225569e421e3076426129a55" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator for adding small noise to continuous variables in order to remove repeated values. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел для добавления небольшого шума к непрерывным переменным с целью удаления повторяющихся значений. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="06cdf003d2aac9179d5700a91f249ff0a94d6f8e" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator that selects a random feature to update. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;selection&lt;/code&gt; == &amp;lsquo;random&amp;rsquo;</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел, который выбирает случайную функцию для обновления. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется при &lt;code&gt;selection&lt;/code&gt; == 'random'</target>
        </trans-unit>
        <trans-unit id="0bc2f2e46810cbdc913e04d68694f60b2b83e0d8" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator that selects a random feature to update. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;selection&lt;/code&gt; == &amp;lsquo;random&amp;rsquo;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел, который выбирает случайную функцию для обновления. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется при &lt;code&gt;selection&lt;/code&gt; == 'random'.</target>
        </trans-unit>
        <trans-unit id="fceac838e81f76b0b51f388983ff2416b1824960" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator that selects a random feature to update. Used when &lt;code&gt;selection&lt;/code&gt; == &amp;lsquo;random&amp;rsquo;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9b5b4205f687d2590f4c80ac04919e87b2e36db" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use when shuffling the data for the dual coordinate descent (if &lt;code&gt;dual=True&lt;/code&gt;). When &lt;code&gt;dual=False&lt;/code&gt; the underlying implementation of &lt;a href=&quot;#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; is not random and &lt;code&gt;random_state&lt;/code&gt; has no effect on the results. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел для использования при перетасовке данных для двойного координатного спуска (если &lt;code&gt;dual=True&lt;/code&gt; ). Когда &lt;code&gt;dual=False&lt;/code&gt; , базовая реализация &lt;a href=&quot;#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; не является случайной, и &lt;code&gt;random_state&lt;/code&gt; не влияет на результаты. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="213c180fc69b83cb51964cde95f090b02ff40db1" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use when shuffling the data, i.e. getting the random vectors to initialize the algorithm. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f24e839d9f0c07b405eb078c6f50d58ca84b7fe6" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел для использования при перетасовке данных. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="58318e33f8140e9303ba15931c5e93b11c5df63e" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел для использования при перетасовке данных. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;solver&lt;/code&gt; == 'sag' или 'liblinear'.</target>
        </trans-unit>
        <trans-unit id="1e64edd7c479eb06717df1495b4d044bfaa961d0" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo;.</source>
          <target state="translated">Начальное значение генератора псевдослучайных чисел для использования при перетасовке данных. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;solver&lt;/code&gt; == 'sag'.</target>
        </trans-unit>
        <trans-unit id="3a35c2036466dbf3b68131c5150065896eadbbdd" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator to use. Randomizes selection of estimator features if n_nearest_features is not None, the &lt;code&gt;imputation_order&lt;/code&gt; if &lt;code&gt;random&lt;/code&gt;, and the sampling from posterior if &lt;code&gt;sample_posterior&lt;/code&gt; is True. Use an integer for determinism. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db7139d208134a3c43811feaafd4124e4ee369a8" translate="yes" xml:space="preserve">
          <source>The seed of the pseudo random number generator used when shuffling the data for probability estimates. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Начальное число генератора псевдослучайных чисел, используемого при перетасовке данных для оценок вероятности. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f1665069fc9c4c9d9dabb36f1931e17db4945528" translate="yes" xml:space="preserve">
          <source>The set of F values.</source>
          <target state="translated">Набор значений F.</target>
        </trans-unit>
        <trans-unit id="d03a062cac2973dfcc9173b5fc93f7520db21987" translate="yes" xml:space="preserve">
          <source>The set of labels can be different for each output variable. For instance, a sample could be assigned &amp;ldquo;pear&amp;rdquo; for an output variable that takes possible values in a finite set of species such as &amp;ldquo;pear&amp;rdquo;, &amp;ldquo;apple&amp;rdquo;; and &amp;ldquo;blue&amp;rdquo; or &amp;ldquo;green&amp;rdquo; for a second output variable that takes possible values in a finite set of colors such as &amp;ldquo;green&amp;rdquo;, &amp;ldquo;red&amp;rdquo;, &amp;ldquo;blue&amp;rdquo;, &amp;ldquo;yellow&amp;rdquo;&amp;hellip;</source>
          <target state="translated">Набор меток может быть разным для каждой выходной переменной. Например, образцу может быть присвоено значение &amp;laquo;груша&amp;raquo; для выходной переменной, которая принимает возможные значения в конечном наборе видов, таких как &amp;laquo;груша&amp;raquo;, &amp;laquo;яблоко&amp;raquo;; и &amp;laquo;синий&amp;raquo; или &amp;laquo;зеленый&amp;raquo; для второй выходной переменной, которая принимает возможные значения в конечном наборе цветов, таких как &amp;laquo;зеленый&amp;raquo;, &amp;laquo;красный&amp;raquo;, &amp;laquo;синий&amp;raquo;, &amp;laquo;желтый&amp;raquo;&amp;hellip;</target>
        </trans-unit>
        <trans-unit id="143c46009e14705cc3449ca19bc2f349662d5283" translate="yes" xml:space="preserve">
          <source>The set of labels for each sample such that &lt;code&gt;y[i]&lt;/code&gt; consists of &lt;code&gt;classes_[j]&lt;/code&gt; for each &lt;code&gt;yt[i, j] == 1&lt;/code&gt;.</source>
          <target state="translated">Набор меток для каждой выборки такой, что &lt;code&gt;y[i]&lt;/code&gt; состоит из &lt;code&gt;classes_[j]&lt;/code&gt; для каждого &lt;code&gt;yt[i, j] == 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2d10d69a1c09af3eb9fb75910b7cd4ebd942ac2e" translate="yes" xml:space="preserve">
          <source>The set of labels to include when &lt;code&gt;average != 'binary'&lt;/code&gt;, and their order if &lt;code&gt;average is None&lt;/code&gt;. Labels present in the data can be excluded, for example to calculate a multiclass average ignoring a majority negative class, while labels not present in the data will result in 0 components in a macro average. For multilabel targets, labels are column indices. By default, all labels in &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; are used in sorted order.</source>
          <target state="translated">Набор меток, которые нужно включить, если &lt;code&gt;average != 'binary'&lt;/code&gt; , и их порядок, если &lt;code&gt;average is None&lt;/code&gt; . Ярлыки, присутствующие в данных, могут быть исключены, например, для расчета среднего многокласса, игнорируя большинство отрицательных классов, в то время как ярлыки, отсутствующие в данных, приведут к 0 компонентам в среднем макросе. Для целей с несколькими метками метки являются индексами столбцов. По умолчанию все метки в &lt;code&gt;y_true&lt;/code&gt; и &lt;code&gt;y_pred&lt;/code&gt; используются в отсортированном порядке.</target>
        </trans-unit>
        <trans-unit id="fc018ce1a1ad3dcbb813a9b943d602142a80bfe5" translate="yes" xml:space="preserve">
          <source>The set of p-values.</source>
          <target state="translated">Набор р-значений.</target>
        </trans-unit>
        <trans-unit id="ae935a83c454932c18aabaf5527bf9d40a05884a" translate="yes" xml:space="preserve">
          <source>The set of regressors that will be tested sequentially.</source>
          <target state="translated">Набор регрессоров,которые будут тестироваться последовательно.</target>
        </trans-unit>
        <trans-unit id="418cd7fd5c32b01bfeb33989472034a267c4e833" translate="yes" xml:space="preserve">
          <source>The shape (Nx, Ny) array of pairwise distances between points in X and Y.</source>
          <target state="translated">Форма (Nx,Ny)массива парных расстояний между точками по X и Y.</target>
        </trans-unit>
        <trans-unit id="313d9c9325eeb4a6e4291910f1f9fa2e1a31f92e" translate="yes" xml:space="preserve">
          <source>The shape of &lt;code&gt;dual_coef_&lt;/code&gt; is &lt;code&gt;(n_classes-1, n_SV)&lt;/code&gt; with a somewhat hard to grasp layout. The columns correspond to the support vectors involved in any of the &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; &amp;ldquo;one-vs-one&amp;rdquo; classifiers. Each of the support vectors is used in &lt;code&gt;n_classes - 1&lt;/code&gt; classifiers. The &lt;code&gt;n_classes - 1&lt;/code&gt; entries in each row correspond to the dual coefficients for these classifiers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be8e19650b3e56af8959e9d1bdb9305ca252ca97" translate="yes" xml:space="preserve">
          <source>The shape of &lt;code&gt;dual_coef_&lt;/code&gt; is &lt;code&gt;[n_class-1, n_SV]&lt;/code&gt; with a somewhat hard to grasp layout. The columns correspond to the support vectors involved in any of the &lt;code&gt;n_class * (n_class - 1) / 2&lt;/code&gt; &amp;ldquo;one-vs-one&amp;rdquo; classifiers. Each of the support vectors is used in &lt;code&gt;n_class - 1&lt;/code&gt; classifiers. The &lt;code&gt;n_class - 1&lt;/code&gt; entries in each row correspond to the dual coefficients for these classifiers.</source>
          <target state="translated">Форма &lt;code&gt;dual_coef_&lt;/code&gt; - &lt;code&gt;[n_class-1, n_SV]&lt;/code&gt; с довольно сложной компоновкой. Столбцы соответствуют опорным векторам, участвующим в любом из &lt;code&gt;n_class * (n_class - 1) / 2&lt;/code&gt; &amp;laquo;один на один&amp;raquo;. Каждый из опорных векторов используется в классификаторах &lt;code&gt;n_class - 1&lt;/code&gt; . &lt;code&gt;n_class - 1&lt;/code&gt; записи в каждой строке соответствует двойственным коэффициентам для этих классификаторов.</target>
        </trans-unit>
        <trans-unit id="79705c107a83df8d45ef47d82375b7c707f4d5ae" translate="yes" xml:space="preserve">
          <source>The shape of the result.</source>
          <target state="translated">Форма результата.</target>
        </trans-unit>
        <trans-unit id="770a88634d7b4928209cc52a1f8aea4bce68a8e8" translate="yes" xml:space="preserve">
          <source>The shift offset allows a zero threshold for being an outlier. Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point.</source>
          <target state="translated">Смещение сдвига допускает нулевой порог выброса. Доступно только для обнаружения новизны (когда для новизны установлено значение True). Предполагается, что аргумент X содержит &lt;em&gt;новые данные&lt;/em&gt; : если X содержит точку из обучения, он рассматривает более позднюю в своей собственной окрестности. Кроме того, образцы в X не рассматриваются в окрестности какой-либо точки.</target>
        </trans-unit>
        <trans-unit id="fd58d8b5ba5725b529e01c853ef09676528984ae" translate="yes" xml:space="preserve">
          <source>The shifted opposite of the Local Outlier Factor of each input samples. The lower, the more abnormal. Negative scores represent outliers, positive scores represent inliers.</source>
          <target state="translated">Смещенный напротив Коэффициента локального выброса каждой входной выборки.Чем ниже,тем более аномальный.Отрицательные оценки представляют отклонения,положительные-отклонения.</target>
        </trans-unit>
        <trans-unit id="432ee6647b81dbc5a7cbb417e7251dacced20941" translate="yes" xml:space="preserve">
          <source>The signed distance to the hyperplane (computed as the dot product between the coefficients and the input sample, plus the intercept) is given by &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13c37fa5739748416ca3f9521f51dec2de533ef6" translate="yes" xml:space="preserve">
          <source>The similarity of two sets of biclusters.</source>
          <target state="translated">Сходство двух наборов бикластеров.</target>
        </trans-unit>
        <trans-unit id="7becf18fe4f5e5f9bf982cb2425cc3a834e0c404" translate="yes" xml:space="preserve">
          <source>The simplest metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; model, called &lt;em&gt;absolute MDS&lt;/em&gt;, disparities are defined by \(\hat{d}_{ij} = S_{ij}\). With absolute MDS, the value \(S_{ij}\) should then correspond exactly to the distance between point \(i\) and \(j\) in the embedding point.</source>
          <target state="translated">Простейшая метрическая модель &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt; , называемая &lt;em&gt;абсолютной MDS&lt;/em&gt; , различия определяются как \ (\ hat {d} _ {ij} = S_ {ij} \). При абсолютном MDS значение \ (S_ {ij} \) должно тогда точно соответствовать расстоянию между точкой \ (i \) и \ (j \) в точке встраивания.</target>
        </trans-unit>
        <trans-unit id="1d805d3b9d3166d024fed65dbe7dc1ddecd0fb40" translate="yes" xml:space="preserve">
          <source>The simplest possible classifier is the &lt;a href=&quot;https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm&quot;&gt;nearest neighbor&lt;/a&gt;: given a new observation &lt;code&gt;X_test&lt;/code&gt;, find in the training set (i.e. the data used to train the estimator) the observation with the closest feature vector. (Please see the &lt;a href=&quot;../../modules/neighbors#neighbors&quot;&gt;Nearest Neighbors section&lt;/a&gt; of the online Scikit-learn documentation for more information about this type of classifier.)</source>
          <target state="translated">Самый простой возможный классификатор - это &lt;a href=&quot;https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm&quot;&gt;ближайший сосед&lt;/a&gt; : учитывая новое наблюдение &lt;code&gt;X_test&lt;/code&gt; , найдите в обучающем наборе (т.е. данных, используемых для обучения оценщика) наблюдение с ближайшим вектором признаков. ( Дополнительную информацию об этом типе классификатора см. В разделе &amp;laquo; &lt;a href=&quot;../../modules/neighbors#neighbors&quot;&gt;Ближайшие соседи&amp;raquo;&lt;/a&gt; интерактивной документации Scikit-learn.)</target>
        </trans-unit>
        <trans-unit id="1fac5c5ae1360f0509b6fb6c9bee7a89fd16eea5" translate="yes" xml:space="preserve">
          <source>The simplest way to accomplish this dimensionality reduction is by taking a random projection of the data. Though this allows some degree of visualization of the data structure, the randomness of the choice leaves much to be desired. In a random projection, it is likely that the more interesting structure within the data will be lost.</source>
          <target state="translated">Самый простой способ уменьшить эту размерность-это случайный проецирование данных.Хотя это позволяет в некоторой степени визуализировать структуру данных,случайность выбора оставляет желать лучшего.В случайной проекции,скорее всего,будет потеряна более интересная структура внутри данных.</target>
        </trans-unit>
        <trans-unit id="a8c7e68caf35057fba3785bb16a14da344816784" translate="yes" xml:space="preserve">
          <source>The simplest way to use cross-validation is to call the &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; helper function on the estimator and the dataset.</source>
          <target state="translated">Самый простой способ использовать перекрестную проверку - вызвать вспомогательную функцию &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; для оценщика и набора данных.</target>
        </trans-unit>
        <trans-unit id="6b61610397fd4bcbb9699a5ba6221c6a9dfd8212" translate="yes" xml:space="preserve">
          <source>The singular value decomposition, \(A_n = U \Sigma V^\top\), provides the partitions of the rows and columns of \(A\). A subset of the left singular vectors gives the row partitions, and a subset of the right singular vectors gives the column partitions.</source>
          <target state="translated">Разложение по единственному значению,\(A_n=U \Sigma V^\top\),представляет собой разделы строк и столбцов \(A\).Подмножество левых единственных векторов дает простенки строк,а подмножество правых единственных векторов дает простенки столбцов.</target>
        </trans-unit>
        <trans-unit id="f785df3fd21ed481c16151f3b91e613616eec382" translate="yes" xml:space="preserve">
          <source>The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the &lt;code&gt;n_components&lt;/code&gt; variables in the lower-dimensional space.</source>
          <target state="translated">Особые значения, соответствующие каждому из выбранных компонентов. Сингулярные значения равны 2-нормам переменных &lt;code&gt;n_components&lt;/code&gt; в пространстве меньшей размерности.</target>
        </trans-unit>
        <trans-unit id="fda37f3c2ceb4ddf1d93860ac5de12a5ffc950e8" translate="yes" xml:space="preserve">
          <source>The size of &lt;code&gt;grid_scores_&lt;/code&gt; is equal to &lt;code&gt;ceil((n_features - min_features_to_select) / step) + 1&lt;/code&gt;, where step is the number of features removed at each iteration.</source>
          <target state="translated">Размер &lt;code&gt;grid_scores_&lt;/code&gt; равен &lt;code&gt;ceil((n_features - min_features_to_select) / step) + 1&lt;/code&gt; , где step - это количество функций, удаляемых на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="2f08a32d3411460a5643fb826528c94534f8d8f2" translate="yes" xml:space="preserve">
          <source>The size of the image that will be reconstructed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9867bd15789365ba5d58a7dbdcd5815e87ddbf26" translate="yes" xml:space="preserve">
          <source>The size of the model with the default parameters is \(O( M * N * log (N) )\), where \(M\) is the number of trees and \(N\) is the number of samples. In order to reduce the size of the model, you can change these parameters: &lt;code&gt;min_samples_split&lt;/code&gt;, &lt;code&gt;max_leaf_nodes&lt;/code&gt;, &lt;code&gt;max_depth&lt;/code&gt; and &lt;code&gt;min_samples_leaf&lt;/code&gt;.</source>
          <target state="translated">Размер модели с параметрами по умолчанию равен \ (O (M * N * log (N)) \), где \ (M \) - количество деревьев, а \ (N \) - количество выборок. Чтобы уменьшить размер модели, вы можете изменить эти параметры: &lt;code&gt;min_samples_split&lt;/code&gt; , &lt;code&gt;max_leaf_nodes&lt;/code&gt; , &lt;code&gt;max_depth&lt;/code&gt; и &lt;code&gt;min_samples_leaf&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1f17f4e69474d346e8934f03ff8be8d8add88c9f" translate="yes" xml:space="preserve">
          <source>The size of the random matrix to generate.</source>
          <target state="translated">Размер генерируемой случайной матрицы.</target>
        </trans-unit>
        <trans-unit id="b31452681b2b7098990045ccc11256312f76473c" translate="yes" xml:space="preserve">
          <source>The size of the regression tree base learners defines the level of variable interactions that can be captured by the gradient boosting model. In general, a tree of depth &lt;code&gt;h&lt;/code&gt; can capture interactions of order &lt;code&gt;h&lt;/code&gt; . There are two ways in which the size of the individual regression trees can be controlled.</source>
          <target state="translated">Размер учащихся базы дерева регрессии определяет уровень взаимодействия переменных, который может быть зафиксирован моделью повышения градиента. В общем, дерево глубины &lt;code&gt;h&lt;/code&gt; может фиксировать взаимодействия порядка &lt;code&gt;h&lt;/code&gt; . Существует два способа управления размером отдельных деревьев регрессии.</target>
        </trans-unit>
        <trans-unit id="eb0fc3f910e5dcbfcfe6af4540bbfd0a452530ef" translate="yes" xml:space="preserve">
          <source>The size of the sample to use when computing the Silhouette Coefficient on a random subset of the data. If &lt;code&gt;sample_size is None&lt;/code&gt;, no sampling is used.</source>
          <target state="translated">Размер выборки, используемой при вычислении коэффициента силуэта для случайного подмножества данных. Если &lt;code&gt;sample_size is None&lt;/code&gt; , выборка не используется.</target>
        </trans-unit>
        <trans-unit id="b3605bfba06cab15c1207c4102bf5bbb9eee0a53" translate="yes" xml:space="preserve">
          <source>The size of the set to sample from.</source>
          <target state="translated">Размер набора для выборки из.</target>
        </trans-unit>
        <trans-unit id="bec91be0bb08923b4b038e4efb20c2c584713078" translate="yes" xml:space="preserve">
          <source>The size of the trees can be controlled through the &lt;code&gt;max_leaf_nodes&lt;/code&gt;, &lt;code&gt;max_depth&lt;/code&gt;, and &lt;code&gt;min_samples_leaf&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5051ed3b169b87ed97be7e20bda0cdf9d82ecae" translate="yes" xml:space="preserve">
          <source>The size, the distance and the shape of clusters may vary upon initialization, perplexity values and does not always convey a meaning.</source>
          <target state="translated">Размер,расстояние и форма кластеров могут меняться при инициализации,значения недоумения и не всегда передают смысл.</target>
        </trans-unit>
        <trans-unit id="6830208b16eb851287384293d35fab1e64fb8f9a" translate="yes" xml:space="preserve">
          <source>The skewed chi squared kernel is given by:</source>
          <target state="translated">Перекошенное ядро ци в квадрате дано:</target>
        </trans-unit>
        <trans-unit id="b37812e3809837f255e9952013df77f9cb7868cc" translate="yes" xml:space="preserve">
          <source>The smaller the Brier score, the better, hence the naming with &amp;ldquo;loss&amp;rdquo;. Across all items in a set N predictions, the Brier score measures the mean squared difference between (1) the predicted probability assigned to the possible outcomes for item i, and (2) the actual outcome. Therefore, the lower the Brier score is for a set of predictions, the better the predictions are calibrated. Note that the Brier score always takes on a value between zero and one, since this is the largest possible difference between a predicted probability (which must be between zero and one) and the actual outcome (which can take on values of only 0 and 1). The Brier loss is composed of refinement loss and calibration loss. The Brier score is appropriate for binary and categorical outcomes that can be structured as true or false, but is inappropriate for ordinal variables which can take on three or more values (this is because the Brier score assumes that all possible outcomes are equivalently &amp;ldquo;distant&amp;rdquo; from one another). Which label is considered to be the positive label is controlled via the parameter pos_label, which defaults to 1. Read more in the &lt;a href=&quot;../calibration#calibration&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdf0bd9101d435249fe017ac2196fd5049ca1688" translate="yes" xml:space="preserve">
          <source>The smoothing priors \(\alpha \ge 0\) accounts for features not present in the learning samples and prevents zero probabilities in further computations. Setting \(\alpha = 1\) is called Laplace smoothing, while \(\alpha &amp;lt; 1\) is called Lidstone smoothing.</source>
          <target state="translated">Априоры сглаживания \ (\ alpha \ ge 0 \) учитывают особенности, отсутствующие в обучающих выборках, и предотвращают нулевые вероятности в дальнейших вычислениях. Установка \ (\ alpha = 1 \) называется сглаживанием Лапласа, а \ (\ alpha &amp;lt;1 \) - сглаживанием Лидстоуна.</target>
        </trans-unit>
        <trans-unit id="4842d9fce84143997f4f4321a8717acf3b670822" translate="yes" xml:space="preserve">
          <source>The solver &amp;ldquo;liblinear&amp;rdquo; uses a coordinate descent (CD) algorithm, and relies on the excellent C++ &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;LIBLINEAR library&lt;/a&gt;, which is shipped with scikit-learn. However, the CD algorithm implemented in liblinear cannot learn a true multinomial (multiclass) model; instead, the optimization problem is decomposed in a &amp;ldquo;one-vs-rest&amp;rdquo; fashion so separate binary classifiers are trained for all classes. This happens under the hood, so &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; instances using this solver behave as multiclass classifiers. For L1 penalization &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt;&lt;/a&gt; allows to calculate the lower bound for C in order to get a non &amp;ldquo;null&amp;rdquo; (all feature weights to zero) model.</source>
          <target state="translated">Решатель liblinear использует алгоритм координатного спуска (CD) и полагается на превосходную &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;библиотеку&lt;/a&gt; C ++ LIBLINEAR , которая поставляется с scikit-learn. Однако алгоритм CD, реализованный в liblinear, не может изучить истинную полиномиальную (мультиклассовую) модель; вместо этого проблема оптимизации декомпозируется по принципу &amp;laquo;один против остальных&amp;raquo;, поэтому отдельные двоичные классификаторы обучаются для всех классов. Это происходит под капотом, поэтому экземпляры &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; ,&lt;/a&gt; использующие этот решатель, ведут себя как мультиклассовые классификаторы. Для &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt; &lt;/a&gt; L1 sklearn.svm.l1_min_c позволяет вычислить нижнюю границу для C, чтобы получить ненулевую (все веса функций равны нулю) модель.</target>
        </trans-unit>
        <trans-unit id="26f79d036c2795565ba6a21b798f1790f5f71dab" translate="yes" xml:space="preserve">
          <source>The solver &amp;ldquo;liblinear&amp;rdquo; uses a coordinate descent (CD) algorithm, and relies on the excellent C++ &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;LIBLINEAR library&lt;/a&gt;, which is shipped with scikit-learn. However, the CD algorithm implemented in liblinear cannot learn a true multinomial (multiclass) model; instead, the optimization problem is decomposed in a &amp;ldquo;one-vs-rest&amp;rdquo; fashion so separate binary classifiers are trained for all classes. This happens under the hood, so &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; instances using this solver behave as multiclass classifiers. For \(\ell_1\) regularization &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt;&lt;/a&gt; allows to calculate the lower bound for C in order to get a non &amp;ldquo;null&amp;rdquo; (all feature weights to zero) model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed7150245f4b6e455142137cba3f8af716071c7a" translate="yes" xml:space="preserve">
          <source>The solver for weight optimization.</source>
          <target state="translated">Решение для оптимизации веса.</target>
        </trans-unit>
        <trans-unit id="7622dc087d4f210bd1e051afc82030dfdfb796a8" translate="yes" xml:space="preserve">
          <source>The solver is selected by a default policy based on &lt;code&gt;X.shape&lt;/code&gt; and &lt;code&gt;n_components&lt;/code&gt;: if the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient &amp;lsquo;randomized&amp;rsquo; method is enabled. Otherwise the exact full SVD is computed and optionally truncated afterwards.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7be0c6e2677e69b218f8a95f391cfbcac99c36a1" translate="yes" xml:space="preserve">
          <source>The solvers implemented in the class &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; are &amp;ldquo;liblinear&amp;rdquo;, &amp;ldquo;newton-cg&amp;rdquo;, &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;saga&amp;rdquo;:</source>
          <target state="translated">В классе &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; реализованы решатели &amp;laquo;liblinear&amp;raquo;, &amp;laquo;newton-cg&amp;raquo;, &amp;laquo;lbfgs&amp;raquo;, &amp;laquo;sag&amp;raquo; и &amp;laquo;saga&amp;raquo;:</target>
        </trans-unit>
        <trans-unit id="2562620e10231c5093b1e84475f4d077e3e41917" translate="yes" xml:space="preserve">
          <source>The sought maximum memory for temporary distance matrix chunks. When None (default), the value of &lt;code&gt;sklearn.get_config()['working_memory']&lt;/code&gt; is used.</source>
          <target state="translated">Искомая максимальная память для временных фрагментов матрицы расстояний. Когда Нет (по умолчанию), используется значение &lt;code&gt;sklearn.get_config()['working_memory']&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d35f1b775d7d16bbabc524099db10f7048897e6d" translate="yes" xml:space="preserve">
          <source>The source can also be found &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/tree/master/doc/tutorial/text_analytics&quot;&gt;on Github&lt;/a&gt;.</source>
          <target state="translated">Источник также можно найти &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/tree/master/doc/tutorial/text_analytics&quot;&gt;на Github&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="351456aed7b7d0fc1d0034839135c70dde192f05" translate="yes" xml:space="preserve">
          <source>The source of this tutorial can be found within your scikit-learn folder:</source>
          <target state="translated">Источник данного руководства можно найти в вашей папке scikit-learn:</target>
        </trans-unit>
        <trans-unit id="aa3459bc05f5ce02810c5dff6ad6cfbeb1ca9a04" translate="yes" xml:space="preserve">
          <source>The spacing between points of the grid, in degrees</source>
          <target state="translated">Расстояние между точками сетки,в градусах...</target>
        </trans-unit>
        <trans-unit id="464028094b69433f3db44d7a263916deccf86cb6" translate="yes" xml:space="preserve">
          <source>The sparse code factor in the matrix factorization.</source>
          <target state="translated">Разреженный коэффициент кода в матричной факторизации.</target>
        </trans-unit>
        <trans-unit id="f9d9c0a7d6ff3b6246478d922234360e15ed6ab9" translate="yes" xml:space="preserve">
          <source>The sparse code such that each column of this matrix has exactly n_nonzero_coefs non-zero items (X).</source>
          <target state="translated">Разреженный код такой,что каждый столбец этой матрицы имеет ровно n_nonzero_coefs ненулевых элементов (X).</target>
        </trans-unit>
        <trans-unit id="ee7d500960f94d10a937d21e436dcc2adbbc9a2a" translate="yes" xml:space="preserve">
          <source>The sparse codes</source>
          <target state="translated">Разрозненные коды</target>
        </trans-unit>
        <trans-unit id="98979bbd88c557cc69074b91f3080d6fb357dded" translate="yes" xml:space="preserve">
          <source>The sparse implementation produces slightly different results from the dense implementation, due to a shrunk learning rate for the intercept. See &lt;a href=&quot;#implementation-details&quot;&gt;Implementation details&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e1ce62165b4e0dbd0b6b1199e83c88e1c88959d" translate="yes" xml:space="preserve">
          <source>The sparse implementation produces slightly different results than the dense implementation due to a shrunk learning rate for the intercept.</source>
          <target state="translated">Скудная реализация дает несколько иные результаты,чем плотная из-за снижения скорости обучения при перехвате.</target>
        </trans-unit>
        <trans-unit id="e4890de0c56a0e7645deea9088355f84adac629f" translate="yes" xml:space="preserve">
          <source>The sparse vector</source>
          <target state="translated">Разреженный вектор</target>
        </trans-unit>
        <trans-unit id="df0fd56f5b70016c4466d03cfc8859f7c3ea7663" translate="yes" xml:space="preserve">
          <source>The sparsity is actually imposed on the cholesky factor of the matrix. Thus alpha does not translate directly into the filling fraction of the matrix itself.</source>
          <target state="translated">Спарсивность фактически накладывается на фактор холески матрицы.При этом альфа не транслируется непосредственно в заполняющую фракцию самой матрицы.</target>
        </trans-unit>
        <trans-unit id="56d99fb198a4da207bde97c2ceeeb3653451f496" translate="yes" xml:space="preserve">
          <source>The sparsity-inducing \(\ell_1\) norm also prevents learning components from noise when few training samples are available. The degree of penalization (and thus sparsity) can be adjusted through the hyperparameter &lt;code&gt;alpha&lt;/code&gt;. Small values lead to a gently regularized factorization, while larger values shrink many coefficients to zero.</source>
          <target state="translated">Норма \ (\ ell_1 \), вызывающая разреженность, также предохраняет обучающие компоненты от шума, когда доступно несколько обучающих выборок. Степень пенализации (и, следовательно, разреженность) можно отрегулировать с помощью гиперпараметра &lt;code&gt;alpha&lt;/code&gt; . Маленькие значения приводят к мягко регуляризованной факторизации, в то время как большие значения уменьшают многие коэффициенты до нуля.</target>
        </trans-unit>
        <trans-unit id="1e3f3420100e85d456b50524681a1e1c7bbc338a" translate="yes" xml:space="preserve">
          <source>The split code for a single sample has length &lt;code&gt;2 * n_components&lt;/code&gt; and is constructed using the following rule: First, the regular code of length &lt;code&gt;n_components&lt;/code&gt; is computed. Then, the first &lt;code&gt;n_components&lt;/code&gt; entries of the &lt;code&gt;split_code&lt;/code&gt; are filled with the positive part of the regular code vector. The second half of the split code is filled with the negative part of the code vector, only with a positive sign. Therefore, the split_code is non-negative.</source>
          <target state="translated">Код разделения для одной выборки имеет длину &lt;code&gt;2 * n_components&lt;/code&gt; и строится с использованием следующего правила: сначала вычисляется обычный код длины &lt;code&gt;n_components&lt;/code&gt; . Затем первые &lt;code&gt;n_components&lt;/code&gt; записей &lt;code&gt;split_code&lt;/code&gt; заполняются положительной частью вектора обычного кода. Вторая половина кода разделения заполняется отрицательной частью вектора кода, только с положительным знаком. Следовательно, split_code неотрицателен.</target>
        </trans-unit>
        <trans-unit id="c55afca5a7a433d8d42b73a1df4af26f8dc38160" translate="yes" xml:space="preserve">
          <source>The stacked regressor will combine the strengths of the different regressors. However, we also see that training the stacked regressor is much more computationally expensive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="619ea10ad996c929a97e389d99c020b2211157d4" translate="yes" xml:space="preserve">
          <source>The standard LLE algorithm comprises three stages:</source>
          <target state="translated">Стандартный алгоритм LLE состоит из трех этапов:</target>
        </trans-unit>
        <trans-unit id="a5bdc246aecc7e3bec9121428d3f9c450814299f" translate="yes" xml:space="preserve">
          <source>The standard deviation of the clusters.</source>
          <target state="translated">Стандартное отклонение кластеров.</target>
        </trans-unit>
        <trans-unit id="b61516300476f785958503bfbc63e8e96de11d18" translate="yes" xml:space="preserve">
          <source>The standard deviation of the gaussian noise applied to the output.</source>
          <target state="translated">Стандартное отклонение гауссового шума на выходе.</target>
        </trans-unit>
        <trans-unit id="e5c05e9131e22b6718043e99a2bae1b92b538981" translate="yes" xml:space="preserve">
          <source>The standard deviation of the gaussian noise.</source>
          <target state="translated">Стандартное отклонение гауссова шума.</target>
        </trans-unit>
        <trans-unit id="0d973eb25a07dcdadcaeac90be3869c3ac64dae0" translate="yes" xml:space="preserve">
          <source>The standard score of a sample &lt;code&gt;x&lt;/code&gt; is calculated as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3689d32cff3e62dded279fb6b657e94942cdc7dc" translate="yes" xml:space="preserve">
          <source>The stepwise interpolating function that covers the input domain &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Ступенчато интерполированием функция , которая охватывает входной домен &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a2cf8fe1dea678ae31186ca36392deb4d997cfe8" translate="yes" xml:space="preserve">
          <source>The stopping criterion. If it is not None, the iterations will stop when (loss &amp;gt; previous_loss - tol).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d8cf8d82bcb0bc25727f81a7a8d626fa0a70639" translate="yes" xml:space="preserve">
          <source>The stopping criterion. If it is not None, the iterations will stop when (loss &amp;gt; previous_loss - tol). Defaults to None. Defaults to 1e-3 from 0.21.</source>
          <target state="translated">Критерий остановки. Если это не None, итерации остановятся, когда (loss&amp;gt; previous_loss - tol). По умолчанию Нет. По умолчанию 1e-3 от 0,21.</target>
        </trans-unit>
        <trans-unit id="b0435766401c2c671f3d0dbc7668ffa0a2dc3aba" translate="yes" xml:space="preserve">
          <source>The stopping criterion. If it is not None, training will stop when (loss &amp;gt; best_loss - tol) for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba1aa4a75fb51f2479b447aa001f5e6386a1f799" translate="yes" xml:space="preserve">
          <source>The strategy to use to assign labels in the embedding space. There are two ways to assign labels after the laplacian embedding. k-means can be applied and is a popular choice. But it can also be sensitive to initialization. Discretization is another approach which is less sensitive to random initialization.</source>
          <target state="translated">Стратегия назначения меток в пространстве встраивания.Есть два способа назначения меток после лацканского встраивания.k-средства могут быть применены и являются популярным выбором.Но он также может быть чувствителен к инициализации.Дискритизация-это другой подход,который менее чувствителен к случайной инициализации.</target>
        </trans-unit>
        <trans-unit id="0a02a9e0399d776c0fdc23972d432af0d079552e" translate="yes" xml:space="preserve">
          <source>The strategy to use to assign labels in the embedding space. There are two ways to assign labels after the laplacian embedding. k-means can be applied and is a popular choice. But it can also be sensitive to initialization. Discretization is another approach which is less sensitive to random initialization. See the &amp;lsquo;Multiclass spectral clustering&amp;rsquo; paper referenced below for more details on the discretization approach.</source>
          <target state="translated">Стратегия, используемая для присвоения меток в пространстве для встраивания. Есть два способа присвоить метки после вложения лапласиана. k-средства могут применяться, и это популярный выбор. Но он также может быть чувствителен к инициализации. Дискретизация - это еще один подход, который менее чувствителен к случайной инициализации. См. Статью &amp;laquo;Мультиклассовая спектральная кластеризация&amp;raquo;, на которую ссылаются ниже, для получения более подробной информации о подходе дискретизации.</target>
        </trans-unit>
        <trans-unit id="067b32fbfa4aafe8139a50a2cd0dc62d48f6ce7c" translate="yes" xml:space="preserve">
          <source>The strategy used to choose the split at each node. Supported strategies are &amp;ldquo;best&amp;rdquo; to choose the best split and &amp;ldquo;random&amp;rdquo; to choose the best random split.</source>
          <target state="translated">Стратегия, используемая для выбора разделения на каждом узле. Поддерживаемые стратегии являются &amp;laquo;лучшими&amp;raquo; для выбора наилучшего разделения и &amp;laquo;случайными&amp;raquo; для выбора лучшего случайного разделения.</target>
        </trans-unit>
        <trans-unit id="e4b87188ae01dfb2ea23e8aa9287a121677cbc35" translate="yes" xml:space="preserve">
          <source>The strength of recall versus precision in the F-score.</source>
          <target state="translated">Сила отзыва по сравнению с точностью в F-диапазоне.</target>
        </trans-unit>
        <trans-unit id="9380c762fbcadf9826438d5ff503ef39938c2642" translate="yes" xml:space="preserve">
          <source>The strength of the LOF algorithm is that it takes both local and global properties of datasets into consideration: it can perform well even in datasets where abnormal samples have different underlying densities. The question is not, how isolated the sample is, but how isolated it is with respect to the surrounding neighborhood.</source>
          <target state="translated">Сила алгоритма LOF заключается в том,что он учитывает как локальные,так и глобальные свойства наборов данных:он может хорошо работать даже в наборах данных,где аномальные выборки имеют различную базовую плотность.Вопрос не в том,насколько изолирована выборка,а в том,насколько изолирована она по отношению к окружающей местности.</target>
        </trans-unit>
        <trans-unit id="ef559a266ab9339add9416970528df4288b9fe07" translate="yes" xml:space="preserve">
          <source>The string to decode</source>
          <target state="translated">Строка для декодирования</target>
        </trans-unit>
        <trans-unit id="3b937bbc7005ed347df9fefe128290b88cb139ff" translate="yes" xml:space="preserve">
          <source>The string to decode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71af025de90c113777cd083adeb4a7dc41c643ae" translate="yes" xml:space="preserve">
          <source>The string value &amp;ldquo;auto&amp;rdquo; determines whether y should increase or decrease based on the Spearman correlation estimate&amp;rsquo;s sign.</source>
          <target state="translated">Строковое значение &amp;laquo;auto&amp;raquo; определяет, должно ли y увеличиваться или уменьшаться на основе знака оценки корреляции Спирмена.</target>
        </trans-unit>
        <trans-unit id="68913ceeaf791c0f89f5da0e6ea267a6c64604e5" translate="yes" xml:space="preserve">
          <source>The submatrix corresponding to bicluster i.</source>
          <target state="translated">Подматрица,соответствующая билюстру i.</target>
        </trans-unit>
        <trans-unit id="a10436d8ac7a1230da5ccfb4c02351e0bfbb4701" translate="yes" xml:space="preserve">
          <source>The subset of drawn features for each base estimator.</source>
          <target state="translated">Подмножество нарисованных признаков для каждого базового оценщика.</target>
        </trans-unit>
        <trans-unit id="57675bd8615ef838a99f713d239feb9810e82664" translate="yes" xml:space="preserve">
          <source>The subset of drawn samples for each base estimator.</source>
          <target state="translated">Подмножество отрисованных выборок для каждого базового оценщика.</target>
        </trans-unit>
        <trans-unit id="fce75057d74e03086c8b482c64f0a007dbeb6ebe" translate="yes" xml:space="preserve">
          <source>The sum of all predictions also confirms the calibration issue of the &lt;code&gt;Ridge&lt;/code&gt; model: it under-estimates by more than 3% the total number of claims in the test set while the other three models can approximately recover the total number of claims of the test portfolio.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58b06737b1ee81d6af2156c3790929db0bc0c464" translate="yes" xml:space="preserve">
          <source>The sum of the features (number of words if documents) is drawn from a Poisson distribution with this expected value.</source>
          <target state="translated">Сумма характеристик (количество слов в документах)берется из дистрибутива Пуассона с этим ожидаемым значением.</target>
        </trans-unit>
        <trans-unit id="690aa5752a21a529c84a7d2bed72d6956dfbf2f1" translate="yes" xml:space="preserve">
          <source>The support is the number of occurrences of each class in &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">Поддержка - это количество вхождений каждого класса в &lt;code&gt;y_true&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b8f29f24bf343b8a8c6a9702bbb3373c30b3886a" translate="yes" xml:space="preserve">
          <source>The support vector machines in scikit-learn support both dense (&lt;code&gt;numpy.ndarray&lt;/code&gt; and convertible to that by &lt;code&gt;numpy.asarray&lt;/code&gt;) and sparse (any &lt;code&gt;scipy.sparse&lt;/code&gt;) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered &lt;code&gt;numpy.ndarray&lt;/code&gt; (dense) or &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; (sparse) with &lt;code&gt;dtype=float64&lt;/code&gt;.</source>
          <target state="translated">Машины векторов поддержки в scikit-learn поддерживают как плотные ( &lt;code&gt;numpy.ndarray&lt;/code&gt; и конвертируемые в &lt;code&gt;numpy.asarray&lt;/code&gt; ), так и разреженные (любые &lt;code&gt;scipy.sparse&lt;/code&gt; ) образцы векторов в качестве входных данных. Однако, чтобы использовать SVM для прогнозирования разреженных данных, он должен соответствовать таким данным. Для оптимальной производительности используйте упорядоченный в C &lt;code&gt;numpy.ndarray&lt;/code&gt; (плотный) или &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; (разреженный) с &lt;code&gt;dtype=float64&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b8e93494175fc764f9336519319d2c72af2d3469" translate="yes" xml:space="preserve">
          <source>The target features for which the partial dependecy should be computed (size should be smaller than 3 for visual renderings).</source>
          <target state="translated">Целевые характеристики,для которых должна быть рассчитана частичная зависимость (размер должен быть меньше 3 для визуального рендеринга).</target>
        </trans-unit>
        <trans-unit id="1676d735c85e09d0307a407a6c8fc0482ea454c1" translate="yes" xml:space="preserve">
          <source>The target features for which to create the PDPs. If features[i] is an int or a string, a one-way PDP is created; if features[i] is a tuple, a two-way PDP is created. Each tuple must be of size 2. if any entry is a string, then it must be in &lt;code&gt;feature_names&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6694d34ee3bb1ae73f71f475a9064ea6bb5aa61" translate="yes" xml:space="preserve">
          <source>The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set.</source>
          <target state="translated">Объект прогнозируется путем локальной интерполяции целей,связанных с ближайшими соседями в обучающем наборе.</target>
        </trans-unit>
        <trans-unit id="fd8f31b4b903aeb83268043a3b52655fbcfeb540" translate="yes" xml:space="preserve">
          <source>The target labels (integer index).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9040adccd40d7354a58b523dff53abedde8f2d61" translate="yes" xml:space="preserve">
          <source>The target labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="836251639a1d2dd67d806e7910ad6656af016095" translate="yes" xml:space="preserve">
          <source>The target values (class labels in classification, real numbers in regression).</source>
          <target state="translated">Целевые значения (метки классов в классификации,реальные числа в регрессии).</target>
        </trans-unit>
        <trans-unit id="581ab16d01401b52de3a8a770522ae3215b0d2a3" translate="yes" xml:space="preserve">
          <source>The target values (class labels) as integers or strings.</source>
          <target state="translated">Целевые значения (метки класса)в виде целых чисел или строк.</target>
        </trans-unit>
        <trans-unit id="c42151a6b9abff52d7ec8ba07a5200409a48a3c6" translate="yes" xml:space="preserve">
          <source>The target values (class labels).</source>
          <target state="translated">Целевые значения (метки класса).</target>
        </trans-unit>
        <trans-unit id="af111c076ceef9b210aa6e236368271feda238ba" translate="yes" xml:space="preserve">
          <source>The target values (integers that correspond to classes in classification, real numbers in regression).</source>
          <target state="translated">Целевые значения (целые числа,соответствующие классам в классификации,вещественные числа в регрессии).</target>
        </trans-unit>
        <trans-unit id="94e263fd180ba7303394b0318de33e42ec7bd528" translate="yes" xml:space="preserve">
          <source>The target values (real numbers).</source>
          <target state="translated">Целевые значения (реальные числа).</target>
        </trans-unit>
        <trans-unit id="4f52bd7c58bfce68aafb35b3e2f5dd531ddc572f" translate="yes" xml:space="preserve">
          <source>The target values (real numbers). Use &lt;code&gt;dtype=np.float64&lt;/code&gt; and &lt;code&gt;order='C'&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Целевые значения (действительные числа). Используйте &lt;code&gt;dtype=np.float64&lt;/code&gt; и &lt;code&gt;order='C'&lt;/code&gt; для максимальной эффективности.</target>
        </trans-unit>
        <trans-unit id="53a447e32fbe96637e9d7be27a641b24353eba6e" translate="yes" xml:space="preserve">
          <source>The target values.</source>
          <target state="translated">Целевые значения.</target>
        </trans-unit>
        <trans-unit id="863f0df40c91ba7090e8eb769163050f217d7bc5" translate="yes" xml:space="preserve">
          <source>The target variable for supervised learning problems.</source>
          <target state="translated">Целевая переменная для контролируемых проблем обучения.</target>
        </trans-unit>
        <trans-unit id="f60efda845afa3f0dc7adc040cd9b2450fbcc2aa" translate="yes" xml:space="preserve">
          <source>The target variable for supervised learning problems. Stratification is done based on the y labels.</source>
          <target state="translated">Целевая переменная для контролируемых проблем обучения.Стратификация осуществляется на основе y-маркировки.</target>
        </trans-unit>
        <trans-unit id="aa20ad6bc67663b59dda9b76a4a065ca1f86af8f" translate="yes" xml:space="preserve">
          <source>The target variable is the median house value for California districts.</source>
          <target state="translated">Целевая переменная-медианное значение дома для районов Калифорнии.</target>
        </trans-unit>
        <trans-unit id="40a696d29fc2e13fd302babe7b309a6f769a208a" translate="yes" xml:space="preserve">
          <source>The target variable to try to predict in the case of supervised learning.</source>
          <target state="translated">Целевая переменная,которую можно попытаться предсказать в случае обучения под наблюдением.</target>
        </trans-unit>
        <trans-unit id="a34872d2673c11b79098f51c73d69310c6a49da3" translate="yes" xml:space="preserve">
          <source>The task at hand is to predict disease progression from physiological variables.</source>
          <target state="translated">Задача состоит в том,чтобы предсказать прогрессирование болезни на основе физиологических переменных.</target>
        </trans-unit>
        <trans-unit id="609ac3008273ee503e4809fb5a54a64b3f8be85d" translate="yes" xml:space="preserve">
          <source>The ten features are standard independent Gaussian and the target &lt;code&gt;y&lt;/code&gt; is defined by:</source>
          <target state="translated">Десять функций являются стандартными независимыми гауссовскими характеристиками, а целевой &lt;code&gt;y&lt;/code&gt; определяется следующим образом:</target>
        </trans-unit>
        <trans-unit id="b7581ec7a4d469cfac096612cf94e3958274d6aa" translate="yes" xml:space="preserve">
          <source>The term &amp;ldquo;discrete features&amp;rdquo; is used instead of naming them &amp;ldquo;categorical&amp;rdquo;, because it describes the essence more accurately. For example, pixel intensities of an image are discrete features (but hardly categorical) and you will get better results if mark them as such. Also note, that treating a continuous variable as discrete and vice versa will usually give incorrect results, so be attentive about that.</source>
          <target state="translated">Термин &amp;laquo;дискретные признаки&amp;raquo; используется вместо того, чтобы называть их &amp;laquo;категориальными&amp;raquo;, поскольку он более точно описывает суть. Например, интенсивности пикселей изображения являются дискретными характеристиками (но вряд ли категориальными), и вы получите лучшие результаты, если пометите их как таковые. Также обратите внимание, что обработка непрерывной переменной как дискретной и наоборот обычно дает неправильные результаты, поэтому будьте внимательны.</target>
        </trans-unit>
        <trans-unit id="2014676021228002e8224c1f06ee12bb4596d24b" translate="yes" xml:space="preserve">
          <source>The term \((x-\mu_k)^t \Sigma^{-1} (x-\mu_k)\) corresponds to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mahalanobis_distance&quot;&gt;Mahalanobis Distance&lt;/a&gt; between the sample \(x\) and the mean \(\mu_k\). The Mahalanobis distance tells how close \(x\) is from \(\mu_k\), while also accounting for the variance of each feature. We can thus interpret LDA as assigning \(x\) to the class whose mean is the closest in terms of Mahalanobis distance, while also accounting for the class prior probabilities.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1748689c159b7c280435a293a84c60a8fa11ddf6" translate="yes" xml:space="preserve">
          <source>The test points for the data. Same format as the training data.</source>
          <target state="translated">Контрольные точки для данных.Тот же формат,что и для данных тренинга.</target>
        </trans-unit>
        <trans-unit id="c4412981e13c1e09172f9e595c07a27a82a32abb" translate="yes" xml:space="preserve">
          <source>The testing set indices for that split.</source>
          <target state="translated">Тестовые наборы индексов для этого сплита.</target>
        </trans-unit>
        <trans-unit id="c079148b8f468ab34a1c911c5b93e7fb1e4fbf43" translate="yes" xml:space="preserve">
          <source>The text feature extractors in scikit-learn know how to decode text files, but only if you tell them what encoding the files are in. The &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; takes an &lt;code&gt;encoding&lt;/code&gt; parameter for this purpose. For modern text files, the correct encoding is probably UTF-8, which is therefore the default (&lt;code&gt;encoding=&quot;utf-8&quot;&lt;/code&gt;).</source>
          <target state="translated">Экстракторы текстовых функций в scikit-learn знают, как декодировать текстовые файлы, но только если вы сообщите им, в какой кодировке находятся файлы. &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; принимает для этой цели параметр &lt;code&gt;encoding&lt;/code&gt; . Для современных текстовых файлов правильная кодировка, вероятно, UTF-8, поэтому она используется по умолчанию ( &lt;code&gt;encoding=&quot;utf-8&quot;&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="5da204cc914d9d1b370d2a7e3d3f9fed2399ad38" translate="yes" xml:space="preserve">
          <source>The theory says that in order to achieve prediction consistency, the penalty parameter should be kept constant as the number of samples grow.</source>
          <target state="translated">Теория гласит,что для достижения согласованности прогноза,параметр &quot;пенальти&quot; должен поддерживаться постоянным по мере роста количества выборок.</target>
        </trans-unit>
        <trans-unit id="ed8c4048d538066672a56cef623687584e4d51a1" translate="yes" xml:space="preserve">
          <source>The third figure compares kernel density estimates for a distribution of 100 samples in 1 dimension. Though this example uses 1D distributions, kernel density estimation is easily and efficiently extensible to higher dimensions as well.</source>
          <target state="translated">На третьем рисунке сравниваются оценки ядерной плотности для распределения 100 образцов в 1 измерении.Несмотря на то,что в этом примере используются 1D-распределения,ядерная оценка плотности легко и эффективно распространяется и на более высокие измерения.</target>
        </trans-unit>
        <trans-unit id="0742a25a1bc73abd7670f1b33a5e8f933c99aa55" translate="yes" xml:space="preserve">
          <source>The third model is also a Bayesian Gaussian mixture model with a Dirichlet process prior but this time the value of the concentration prior is higher giving the model more liberty to model the fine-grained structure of the data. The result is a mixture with a larger number of active components that is similar to the first model where we arbitrarily decided to fix the number of components to 10.</source>
          <target state="translated">Третья модель также является моделью байесовской гауссовской смеси с предыдущим процессом Дирихлета,но на этот раз значение предыдущей концентрации выше,что дает модели больше свободы для моделирования мелкозернистой структуры данных.В результате получается смесь с большим количеством активных компонентов,аналогичная первой модели,в которой мы произвольно решили закрепить количество компонентов за 10.</target>
        </trans-unit>
        <trans-unit id="f1f7cd9ed7ac82273a71a8430edb1e09f61b8cab" translate="yes" xml:space="preserve">
          <source>The threshold value to use for feature selection. Features whose importance is greater or equal are kept while the others are discarded. If &amp;ldquo;median&amp;rdquo; (resp. &amp;ldquo;mean&amp;rdquo;), then the &lt;code&gt;threshold&lt;/code&gt; value is the median (resp. the mean) of the feature importances. A scaling factor (e.g., &amp;ldquo;1.25*mean&amp;rdquo;) may also be used. If None and if the estimator has a parameter penalty set to l1, either explicitly or implicitly (e.g, Lasso), the threshold used is 1e-5. Otherwise, &amp;ldquo;mean&amp;rdquo; is used by default.</source>
          <target state="translated">Пороговое значение, используемое для выбора функции. Функции, чья важность больше или равна, сохраняются, а другие отбрасываются. Если &amp;laquo;медиана&amp;raquo; (соотв. &amp;laquo;Среднее&amp;raquo;), то &lt;code&gt;threshold&lt;/code&gt; значение - это медиана (соотв. Среднее) значимости характеристики. Также можно использовать масштабный коэффициент (например, &amp;laquo;1,25 * среднее&amp;raquo;). Если None и если для средства оценки установлен штраф за параметр, равный l1, явно или неявно (например, Lasso), используется порог 1e-5. В противном случае по умолчанию используется &amp;laquo;среднее&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="91a1a785c1bc7a11d4e20e6e119c885bf4142111" translate="yes" xml:space="preserve">
          <source>The threshold value used for feature selection.</source>
          <target state="translated">Пороговое значение,используемое для выбора функции.</target>
        </trans-unit>
        <trans-unit id="5a48126d50b83afd18e220a4fcf0cc7ffc7180d9" translate="yes" xml:space="preserve">
          <source>The time complexity of this implementation is &lt;code&gt;O(d ** 2)&lt;/code&gt; assuming d ~ n_features ~ n_components.</source>
          <target state="translated">Временная сложность этой реализации составляет &lt;code&gt;O(d ** 2)&lt;/code&gt; при условии, что d ~ n_features ~ n_components.</target>
        </trans-unit>
        <trans-unit id="ff8097e0ec52614ae168c4cd444f04e3f78b14e2" translate="yes" xml:space="preserve">
          <source>The time for fitting the estimator on the train set for each cv split.</source>
          <target state="translated">Время для установки оценочного прибора в поездной установке для каждого разделения треугольников.</target>
        </trans-unit>
        <trans-unit id="dc0535c66e14595ad26a449dc475b0e83c5091ba" translate="yes" xml:space="preserve">
          <source>The time for scoring the estimator on the test set for each cv split. (Note time for scoring on the train set is not included even if &lt;code&gt;return_train_score&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">Время для оценки оценщика на тестовом наборе для каждого разделения резюме. (Обратите внимание, время для подсчета очков в наборе поездов не включается, даже если &lt;code&gt;return_train_score&lt;/code&gt; имеет значение &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1cd8d7a025bee860396ab665c8f7316a009f2f5a" translate="yes" xml:space="preserve">
          <source>The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=&amp;rsquo;cd&amp;rsquo;.</source>
          <target state="translated">Допуск для решателя эластичной сети, используемого для расчета направления спуска. Этот параметр контролирует точность направления поиска для данного обновления столбца, а не общую оценку параметра. Используется только для mode = 'cd'.</target>
        </trans-unit>
        <trans-unit id="1c748ca3956e12feeccc0881efb2e7b986b52b0e" translate="yes" xml:space="preserve">
          <source>The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=&amp;rsquo;cd&amp;rsquo;. Range is (0, inf].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54800ee92ded7e21b226653650e94d2e245f5dc0" translate="yes" xml:space="preserve">
          <source>The tolerance for the optimization: if the updates are smaller than &lt;code&gt;tol&lt;/code&gt;, the optimization code checks the dual gap for optimality and continues until it is smaller than &lt;code&gt;tol&lt;/code&gt;.</source>
          <target state="translated">Допуск для оптимизации: если обновления меньше, чем &lt;code&gt;tol&lt;/code&gt; , код оптимизации проверяет двойной пробел на оптимальность и продолжает работу, пока он не станет меньше, чем &lt;code&gt;tol&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7abdf76511114d1a589dafaf8c3b9fea94410d4e" translate="yes" xml:space="preserve">
          <source>The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped.</source>
          <target state="translated">Допуск на объявление схождения:если двойной зазор опускается ниже этого значения,итерации прекращаются.</target>
        </trans-unit>
        <trans-unit id="c8679f3dc5795753fd4b3924c7477d6451516504" translate="yes" xml:space="preserve">
          <source>The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped. Range is (0, inf].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1174cbfc6c5cd8bb9e51e269de526360c060c73a" translate="yes" xml:space="preserve">
          <source>The tomography projection operation is a linear transformation. In addition to the data-fidelity term corresponding to a linear regression, we penalize the L1 norm of the image to account for its sparsity. The resulting optimization problem is called the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;. We use the class &lt;a href=&quot;../../modules/generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;sklearn.linear_model.Lasso&lt;/code&gt;&lt;/a&gt;, that uses the coordinate descent algorithm. Importantly, this implementation is more computationally efficient on a sparse matrix, than the projection operator used here.</source>
          <target state="translated">Операция проекции томографии представляет собой линейное преобразование. В дополнение к критерию достоверности данных, соответствующему линейной регрессии, мы штрафуем L1-норму изображения, чтобы учесть его разреженность. Результирующая задача оптимизации называется &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;лассо&lt;/a&gt; . Мы используем класс &lt;a href=&quot;../../modules/generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt; &lt;code&gt;sklearn.linear_model.Lasso&lt;/code&gt; &lt;/a&gt; , который использует алгоритм координатного спуска. Важно отметить, что эта реализация более эффективна с точки зрения вычислений для разреженной матрицы, чем используемый здесь оператор проекции.</target>
        </trans-unit>
        <trans-unit id="6067d7bbaca20238e188da5c4c1f4f9b915cbe46" translate="yes" xml:space="preserve">
          <source>The total number of features.</source>
          <target state="translated">Общее количество функций.</target>
        </trans-unit>
        <trans-unit id="52b059ac9ef2b76cd7b57a438578db960faf18a1" translate="yes" xml:space="preserve">
          <source>The total number of features. These comprise &lt;code&gt;n_informative&lt;/code&gt; informative features, &lt;code&gt;n_redundant&lt;/code&gt; redundant features, &lt;code&gt;n_repeated&lt;/code&gt; duplicated features and &lt;code&gt;n_features-n_informative-n_redundant-n_repeated&lt;/code&gt; useless features drawn at random.</source>
          <target state="translated">Общее количество функций. Они включают в себя &lt;code&gt;n_informative&lt;/code&gt; информативных информативных функций, &lt;code&gt;n_redundant&lt;/code&gt; избыточных избыточных функций, &lt;code&gt;n_repeated&lt;/code&gt; повторяющихся дублированных функций и &lt;code&gt;n_features-n_informative-n_redundant-n_repeated&lt;/code&gt; бесполезных функций, нарисованных случайным образом.</target>
        </trans-unit>
        <trans-unit id="1b95194d002b1fa90370f5ac460e11ae527d46c4" translate="yes" xml:space="preserve">
          <source>The total number of input features.</source>
          <target state="translated">Общее количество функций ввода.</target>
        </trans-unit>
        <trans-unit id="75f4c14304ea0320f6751402bd1abbcf764fb2d4" translate="yes" xml:space="preserve">
          <source>The total number of points equally divided among classes.</source>
          <target state="translated">Общее количество баллов,равномерно распределенное между классами.</target>
        </trans-unit>
        <trans-unit id="6fd1a66b2c352f2c105828a73ec9201a20677da3" translate="yes" xml:space="preserve">
          <source>The total number of points generated.</source>
          <target state="translated">Общее количество сгенерированных баллов.</target>
        </trans-unit>
        <trans-unit id="b463685bc7194f4e1bd9c9e9566855d8af2442c3" translate="yes" xml:space="preserve">
          <source>The total number of points generated. If odd, the inner circle will have one point more than the outer circle.</source>
          <target state="translated">Общее количество сгенерированных баллов.В случае нечетности,внутренняя окружность будет иметь на одну точку больше,чем внешняя.</target>
        </trans-unit>
        <trans-unit id="30df1d74b9688e22831b35a50354a3af5ea3a9b9" translate="yes" xml:space="preserve">
          <source>The total number of polynomial output features. The number of output features is computed by iterating over all suitably sized combinations of input features.</source>
          <target state="translated">Общее количество полиномиальных выходных характеристик.Количество выходных признаков вычисляется путем итерации по всем подходящим по размеру комбинациям входных признаков.</target>
        </trans-unit>
        <trans-unit id="2341cd15b4f720c4e4ca39627124f453602ba043" translate="yes" xml:space="preserve">
          <source>The traditional way to compute the principal eigenvector is to use the power iteration method:</source>
          <target state="translated">Традиционный способ вычисления основного собственного вектора заключается в использовании метода итерации мощности:</target>
        </trans-unit>
        <trans-unit id="486bc8b3be25b906a521777296790c0e7db3392b" translate="yes" xml:space="preserve">
          <source>The training algorithm implemented in &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt; is known as Stochastic Maximum Likelihood (SML) or Persistent Contrastive Divergence (PCD). Optimizing maximum likelihood directly is infeasible because of the form of the data likelihood:</source>
          <target state="translated">Алгоритм обучения, реализованный в &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; , известен как стохастическая максимальная вероятность (SML) или стойкая контрастная дивергенция (PCD). Непосредственная оптимизация максимальной вероятности невозможна из-за формы вероятности данных:</target>
        </trans-unit>
        <trans-unit id="03936b9df8c7a04402a186159fb53bde128b3907" translate="yes" xml:space="preserve">
          <source>The training data</source>
          <target state="translated">Данные тренинга</target>
        </trans-unit>
        <trans-unit id="a7dac9ee1d012d3a04e96a076bd4bb0255f4fa3a" translate="yes" xml:space="preserve">
          <source>The training data contains outliers which are defined as observations that are far from the others. Outlier detection estimators thus try to fit the regions where the training data is the most concentrated, ignoring the deviant observations.</source>
          <target state="translated">Данные обучения содержат исключения,которые определяются как наблюдения,далекие от других.Таким образом,оценщики по выявлению отклонений стараются соответствовать регионам,где обучающие данные наиболее концентрированы,игнорируя наблюдения с отклонениями.</target>
        </trans-unit>
        <trans-unit id="58b640148d7ae1e7f191ee9d800aaef902a6aef0" translate="yes" xml:space="preserve">
          <source>The training data is not polluted by outliers and we are interested in detecting whether a &lt;strong&gt;new&lt;/strong&gt; observation is an outlier. In this context an outlier is also called a novelty.</source>
          <target state="translated">Данные обучения не загрязняются выбросами, и мы заинтересованы в том, чтобы определить, является ли &lt;strong&gt;новое&lt;/strong&gt; наблюдение выбросом. В этом контексте выброс также называется новинкой.</target>
        </trans-unit>
        <trans-unit id="431a9d8e158a3b53d56cef19b322f4a781297a84" translate="yes" xml:space="preserve">
          <source>The training data, e.g. a reference to an immutable snapshot</source>
          <target state="translated">Данные тренировки,например,ссылка на непреложный снимок.</target>
        </trans-unit>
        <trans-unit id="44e706b0239b6ac2fad3df8ff059d735dbfbf296" translate="yes" xml:space="preserve">
          <source>The training input samples.</source>
          <target state="translated">Обучающие входные пробы.</target>
        </trans-unit>
        <trans-unit id="92c6c3d94fd9608db44f0ede45f9bbe4de664d1d" translate="yes" xml:space="preserve">
          <source>The training input samples. Internally, it will be converted to &lt;code&gt;dtype=np.float32&lt;/code&gt; and if a sparse matrix is provided to a sparse &lt;code&gt;csc_matrix&lt;/code&gt;.</source>
          <target state="translated">Обучающие входные образцы. Внутренне он будет преобразован в &lt;code&gt;dtype=np.float32&lt;/code&gt; , а если разреженная матрица будет предоставлена ​​в разреженную &lt;code&gt;csc_matrix&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fdce812a7f2c7f82334342af14e6e75d01b61ef1" translate="yes" xml:space="preserve">
          <source>The training input samples. Internally, its dtype will be converted to &lt;code&gt;dtype=np.float32&lt;/code&gt;. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csc_matrix&lt;/code&gt;.</source>
          <target state="translated">Обучающие входные образцы. Внутренне его dtype будет преобразован в &lt;code&gt;dtype=np.float32&lt;/code&gt; . Если предоставляется разреженная матрица, она будет преобразована в разреженную &lt;code&gt;csc_matrix&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="549582a79c03c6cf3a88a3f5ae8ab3477fe6f4f0" translate="yes" xml:space="preserve">
          <source>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</source>
          <target state="translated">Обучающие входные пробы.Раздельные матрицы принимаются только в том случае,если они поддерживаются базовым оценщиком.</target>
        </trans-unit>
        <trans-unit id="cc9cba55947c2b2da5cd927ed2d1f239e6fce1e8" translate="yes" xml:space="preserve">
          <source>The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed9fac6749e01b46bdd0e4eebbecd7ed42fc3bac" translate="yes" xml:space="preserve">
          <source>The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. DOK and LIL are converted to CSR.</source>
          <target state="translated">Обучающие входные пробы.Разделительная матрица может быть CSC,CSR,COO,DOK или LIL.DOK и LIL преобразуются в CSR.</target>
        </trans-unit>
        <trans-unit id="dba95905d10a3a6d61cb924560b16f35840a95de" translate="yes" xml:space="preserve">
          <source>The training points for the data. Each point has three fields:</source>
          <target state="translated">Точки обучения данных.Каждый пункт имеет три поля:</target>
        </trans-unit>
        <trans-unit id="768a232e21b799d7ab4a21a202aa20c0c2da04e0" translate="yes" xml:space="preserve">
          <source>The training samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49afe52f19d67077f586b0d86a3a80bb7b9051b3" translate="yes" xml:space="preserve">
          <source>The training set has size &lt;code&gt;i * n_samples // (n_splits + 1)
+ n_samples % (n_splits + 1)&lt;/code&gt; in the &lt;code&gt;i``th split,
with a test set of size ``n_samples//(n_splits + 1)&lt;/code&gt;, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples.</source>
          <target state="translated">Обучающий набор имеет размер &lt;code&gt;i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1)&lt;/code&gt; в &lt;code&gt;i``th split, with a test set of size ``n_samples//(n_splits + 1)&lt;/code&gt; , где &lt;code&gt;n_samples&lt;/code&gt; количество образцов.</target>
        </trans-unit>
        <trans-unit id="7d0d65f5b4df90d39c92efe2c541dfa70477a3f3" translate="yes" xml:space="preserve">
          <source>The training set indices for that split.</source>
          <target state="translated">Обучение установило индексы для этого дробления.</target>
        </trans-unit>
        <trans-unit id="1fe1c9ebc66c3c60358a4b7d7ce6958b71f5be6a" translate="yes" xml:space="preserve">
          <source>The transformation can be triggered by setting either &lt;code&gt;transformer&lt;/code&gt; or the pair of functions &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt;. However, setting both options will raise an error.</source>
          <target state="translated">Преобразование может быть инициировано установкой либо &lt;code&gt;transformer&lt;/code&gt; либо пары функций &lt;code&gt;func&lt;/code&gt; и &lt;code&gt;inverse_func&lt;/code&gt; . Однако установка обоих параметров вызовет ошибку.</target>
        </trans-unit>
        <trans-unit id="cb596196fe310821d43e26f57899432a8af2c024" translate="yes" xml:space="preserve">
          <source>The transformation is applied on each feature independently. First an estimate of the cumulative distribution function of a feature is used to map the original values to a uniform distribution. The obtained values are then mapped to the desired output distribution using the associated quantile function. Features values of new/unseen data that fall below or above the fitted range will be mapped to the bounds of the output distribution. Note that this transform is non-linear. It may distort linear correlations between variables measured at the same scale but renders variables measured at different scales more directly comparable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1ce2cd56f04ea729576a873f5ef18af794ea62c" translate="yes" xml:space="preserve">
          <source>The transformation is applied on each feature independently. The cumulative density function of a feature is used to project the original values. Features values of new/unseen data that fall below or above the fitted range will be mapped to the bounds of the output distribution. Note that this transform is non-linear. It may distort linear correlations between variables measured at the same scale but renders variables measured at different scales more directly comparable.</source>
          <target state="translated">Трансформация применяется к каждой функции независимо друг от друга.Функция кумулятивной плотности объекта используется для проектирования исходных значений.Значения признаков новых/невидимых данных,которые попадают ниже или выше установленного диапазона,будут нанесены на границы выходного распределения.Обратите внимание,что это преобразование является нелинейным.Оно может искажать линейные корреляции между переменными,измеренными на одном и том же масштабе,но делает переменные,измеренные на разных масштабах,более непосредственно сопоставимыми.</target>
        </trans-unit>
        <trans-unit id="019c47d3f3ad8207e8989b103cc42bdf22c099af" translate="yes" xml:space="preserve">
          <source>The transformation is calculated as (when &lt;code&gt;axis=0&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac658687b2a734f60273ed8ccd4ce7f47f7a43fa" translate="yes" xml:space="preserve">
          <source>The transformation is given by (when &lt;code&gt;axis=0&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddd72b82186574150d900e6dfd8721345fa62073" translate="yes" xml:space="preserve">
          <source>The transformation is given by:</source>
          <target state="translated">Преобразование дается:</target>
        </trans-unit>
        <trans-unit id="1db1e441acce63afd6d696933447c0b2d453bb8c" translate="yes" xml:space="preserve">
          <source>The transformed data</source>
          <target state="translated">преобразованные данные</target>
        </trans-unit>
        <trans-unit id="f7cd2d51dfcb247e9b3665d7843f0082b5c854bd" translate="yes" xml:space="preserve">
          <source>The transformed data is a sparse graph as returned by kneighbors_graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e2ab39a27e391675e94304e8d0476203d9b90e4" translate="yes" xml:space="preserve">
          <source>The transformed data is a sparse graph as returned by radius_neighbors_graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a52b9359f518099e81b711eeaccc5e0c7c17eb0" translate="yes" xml:space="preserve">
          <source>The transformed data is then used to train a naive Bayes classifier, and a clear difference in prediction accuracies is observed wherein the dataset which is scaled before PCA vastly outperforms the unscaled version.</source>
          <target state="translated">Затем преобразованные данные используются для обучения наивного классификатора Бейеса,и наблюдается явная разница в точности предсказания,когда набор данных,который масштабируется перед PCA,значительно превосходит не масштабированную версию.</target>
        </trans-unit>
        <trans-unit id="80e852f03673351dd5ee00932a57dc4a209cdf2d" translate="yes" xml:space="preserve">
          <source>The transformed data.</source>
          <target state="translated">Трансформированные данные.</target>
        </trans-unit>
        <trans-unit id="831c10597508e086776cd00760f56c708f8d2bba" translate="yes" xml:space="preserve">
          <source>The tree algorithm to use. Valid options are [&amp;lsquo;kd_tree&amp;rsquo;|&amp;rsquo;ball_tree&amp;rsquo;|&amp;rsquo;auto&amp;rsquo;]. Default is &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">Используемый древовидный алгоритм. Допустимые варианты: ['kd_tree' | 'ball_tree' | 'auto']. По умолчанию установлено &amp;laquo;авто&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="d745501ed4c4af3a67688bd307560f44fb29c904" translate="yes" xml:space="preserve">
          <source>The tree data structure consists of nodes with each node consisting of a number of subclusters. The maximum number of subclusters in a node is determined by the branching factor. Each subcluster maintains a linear sum, squared sum and the number of samples in that subcluster. In addition, each subcluster can also have a node as its child, if the subcluster is not a member of a leaf node.</source>
          <target state="translated">Древовидная структура данных состоит из узлов,каждый из которых состоит из ряда подкластеров.Максимальное количество подкластеров в узле определяется коэффициентом ветвления.Каждый подкластер поддерживает линейную сумму,квадратную сумму и количество отсчетов в этом подкластере.Кроме того,каждый подкластер может иметь в качестве дочернего узел,если подкластер не является членом узла листа.</target>
        </trans-unit>
        <trans-unit id="e124a1b9cc4902e35946b8c1931bf2b92e9cefc7" translate="yes" xml:space="preserve">
          <source>The tree-based model is significantly better at ranking policyholders by risk while the two linear models perform similarly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbc6ef1abc08faa2debda525a78475d34850618e" translate="yes" xml:space="preserve">
          <source>The true probability in each bin (fraction of positives).</source>
          <target state="translated">Истинная вероятность в каждом бине (доля положительных значений).</target>
        </trans-unit>
        <trans-unit id="89aec1004fa9767eced66561c3ed3161000c45a1" translate="yes" xml:space="preserve">
          <source>The true score without permuting targets.</source>
          <target state="translated">Истинный счет без прослушивания мишеней.</target>
        </trans-unit>
        <trans-unit id="78ab726a9fdf47809b691c3859f0df06c5754377" translate="yes" xml:space="preserve">
          <source>The trustworthiness is within [0, 1]. It is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="311da69a1a719737450cc586668ba277c4bde011" translate="yes" xml:space="preserve">
          <source>The tutorial folder should contain the following sub-folders:</source>
          <target state="translated">Папка учебника должна содержать следующие вложенные папки:</target>
        </trans-unit>
        <trans-unit id="2e8b6623a8185bbb598cfdf6b3f71f1ee2c2a837" translate="yes" xml:space="preserve">
          <source>The two figures below plot the values of &lt;code&gt;C&lt;/code&gt; on the &lt;code&gt;x-axis&lt;/code&gt; and the corresponding cross-validation scores on the &lt;code&gt;y-axis&lt;/code&gt;, for several different fractions of a generated data-set.</source>
          <target state="translated">На двух рисунках ниже показаны значения &lt;code&gt;C&lt;/code&gt; на &lt;code&gt;x-axis&lt;/code&gt; и соответствующие баллы перекрестной проверки на &lt;code&gt;y-axis&lt;/code&gt; для нескольких различных фракций сгенерированного набора данных.</target>
        </trans-unit>
        <trans-unit id="726ed01e2c2e9b244f4346dd4c7877757cc3867c" translate="yes" xml:space="preserve">
          <source>The two linear regressors &lt;a href=&quot;../../modules/generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.elasticnet#sklearn.linear_model.ElasticNet&quot;&gt;&lt;code&gt;ElasticNet&lt;/code&gt;&lt;/a&gt; now support sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85a91cdcd45557b2849d30b64bc99a3236c9a910" translate="yes" xml:space="preserve">
          <source>The two plots differ only in the area in the middle where the classes are tied. If &lt;code&gt;break_ties=False&lt;/code&gt;, all input in that area would be classified as one class, whereas if &lt;code&gt;break_ties=True&lt;/code&gt;, the tie-breaking mechanism will create a non-convex decision boundary in that area.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a77900ed6f82fb8a154b287d08593a39a5648c" translate="yes" xml:space="preserve">
          <source>The two sample image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ed5804ea6261422d9ec471fffa8f8a41a307d64" translate="yes" xml:space="preserve">
          <source>The two species are:</source>
          <target state="translated">Эти два вида:</target>
        </trans-unit>
        <trans-unit id="4aa36c5d8992165f7895075f7b16a37f9864b092" translate="yes" xml:space="preserve">
          <source>The type of criterion to use.</source>
          <target state="translated">Тип используемого критерия.</target>
        </trans-unit>
        <trans-unit id="6bc8093d847369045cfca5abe49cd94f035f902d" translate="yes" xml:space="preserve">
          <source>The type of feature values. Passed to Numpy array/scipy.sparse matrix constructors as the dtype argument.</source>
          <target state="translated">Тип значений характеристик.В качестве аргумента типа d передается в конструкторы матрицы Numpy array/scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="51cef5c60b8823e16a67a0821a4b5311abdcd5ed" translate="yes" xml:space="preserve">
          <source>The type of feature values. Passed to scipy.sparse matrix constructors as the dtype argument. Do not set this to bool, np.boolean or any unsigned integer type.</source>
          <target state="translated">Тип значений характеристик.Передано в конструкторы матрицы scipy.sparse в качестве аргумента типа d.Не устанавливать в качестве аргумента bool,np.boolean или любой беззнаковый целочисленный тип.</target>
        </trans-unit>
        <trans-unit id="25d83e9ee3b7a100418b9b6d2bb7936470b09825" translate="yes" xml:space="preserve">
          <source>The type of norm used to compute the error. Available error types: - &amp;lsquo;frobenius&amp;rsquo; (default): sqrt(tr(A^t.A)) - &amp;lsquo;spectral&amp;rsquo;: sqrt(max(eigenvalues(A^t.A)) where A is the error &lt;code&gt;(comp_cov - self.covariance_)&lt;/code&gt;.</source>
          <target state="translated">Тип нормы, используемой для вычисления ошибки. Доступные типы ошибок: - 'frobenius' (по умолчанию): sqrt (tr (A ^ tA)) - 'spectral': sqrt (max (eigenvalues ​​(A ^ tA)), где A - ошибка &lt;code&gt;(comp_cov - self.covariance_)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8b60d3555697082fbd56cd614358874d006ccd25" translate="yes" xml:space="preserve">
          <source>The type of the hyperparameter. Currently, only &amp;ldquo;numeric&amp;rdquo; hyperparameters are supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0b5e941b7e074477ab9a734aa8fbc101aeb347c" translate="yes" xml:space="preserve">
          <source>The unchanged dictionary atoms</source>
          <target state="translated">Неизменные атомы по словарю</target>
        </trans-unit>
        <trans-unit id="17cd05cd0020cc8838dc1f102077fa8c28f81758" translate="yes" xml:space="preserve">
          <source>The underlying &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implementation uses a random number generator to select features when fitting the model with a dual coordinate descent (i.e when &lt;code&gt;dual&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;). It is thus not uncommon to have slightly different results for the same input data. If that happens, try with a smaller &lt;code&gt;tol&lt;/code&gt; parameter. This randomness can also be controlled with the &lt;code&gt;random_state&lt;/code&gt; parameter. When &lt;code&gt;dual&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; the underlying implementation of &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; is not random and &lt;code&gt;random_state&lt;/code&gt; has no effect on the results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="776a52daee9321c0497d40c79109e87f34af6b7e" translate="yes" xml:space="preserve">
          <source>The underlying &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implementation uses a random number generator to select features when fitting the model with a dual coordinate descent (i.e when &lt;code&gt;dual&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;). It is thus not uncommon, to have slightly different results for the same input data. If that happens, try with a smaller tol parameter. This randomness can also be controlled with the &lt;code&gt;random_state&lt;/code&gt; parameter. When &lt;code&gt;dual&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; the underlying implementation of &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; is not random and &lt;code&gt;random_state&lt;/code&gt; has no effect on the results.</source>
          <target state="translated">Базовый &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; реализация использует генератор случайных чисел для выбора функций при установке модели с двойным координатным спуском (т.е. когда &lt;code&gt;dual&lt;/code&gt; установлено в значении &lt;code&gt;True&lt;/code&gt; ). Таким образом, нередки случаи, когда для одних и тех же входных данных результаты могут немного отличаться. Если это произойдет, попробуйте использовать меньший параметр tol. Этой случайностью также можно управлять с &lt;code&gt;random_state&lt;/code&gt; параметра random_state . Если для параметра &lt;code&gt;dual&lt;/code&gt; установлено значение &lt;code&gt;False&lt;/code&gt; , основная реализация &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; не является случайной, и &lt;code&gt;random_state&lt;/code&gt; не влияет на результаты.</target>
        </trans-unit>
        <trans-unit id="68c40938fee4ae1976f2ebe09bc5c5a404f12d37" translate="yes" xml:space="preserve">
          <source>The underlying C implementation uses a random number generator to select features when fitting the model. It is thus not uncommon to have slightly different results for the same input data. If that happens, try with a smaller &lt;code&gt;tol&lt;/code&gt; parameter.</source>
          <target state="translated">Базовая реализация C использует генератор случайных чисел для выбора функций при подборе модели. Таким образом, для одних и тех же входных данных нередко могут быть несколько разные результаты. Если это произойдет, попробуйте использовать меньший параметр &lt;code&gt;tol&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f30e1e8a65635cf877334fb55d57ec3cedb0460" translate="yes" xml:space="preserve">
          <source>The underlying C implementation uses a random number generator to select features when fitting the model. It is thus not uncommon, to have slightly different results for the same input data. If that happens, try with a smaller tol parameter.</source>
          <target state="translated">Базовая реализация C использует генератор случайных чисел для выбора функций при подгонке модели.Таким образом,нередки случаи,когда для одних и тех же входных данных получаются несколько разные результаты.Если такое случается,попробуйте с меньшим параметром tol.</target>
        </trans-unit>
        <trans-unit id="4ed849766bc74a6b6038e401c289ce378db99dcc" translate="yes" xml:space="preserve">
          <source>The underlying Tree object. Please refer to &lt;code&gt;help(sklearn.tree._tree.Tree)&lt;/code&gt; for attributes of Tree object and &lt;a href=&quot;../../auto_examples/tree/plot_unveil_tree_structure#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py&quot;&gt;Understanding the decision tree structure&lt;/a&gt; for basic usage of these attributes.</source>
          <target state="translated">Базовый объект Tree. Пожалуйста, обратитесь к &lt;code&gt;help(sklearn.tree._tree.Tree)&lt;/code&gt; для атрибутов объекта Tree и &lt;a href=&quot;../../auto_examples/tree/plot_unveil_tree_structure#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py&quot;&gt;Общие сведения о структуре дерева решений&lt;/a&gt; для базового использования этих атрибутов.</target>
        </trans-unit>
        <trans-unit id="eaa9f70240ca573ce446579a8e3077ce3fd3b2de" translate="yes" xml:space="preserve">
          <source>The underlying implementation is MurmurHash3_x86_32 generating low latency 32bits hash suitable for implementing lookup tables, Bloom filters, count min sketch or feature hashing.</source>
          <target state="translated">В основе реализации лежит MurmurHash3_x86_32,генерирующий 32-битный хэш с низкой латентностью,подходящий для реализации таблиц поиска,фильтров Bloom,count min sketch или хэширования функций.</target>
        </trans-unit>
        <trans-unit id="8b27403493b3e1cf67d088cabd49f20f60beabb5" translate="yes" xml:space="preserve">
          <source>The underlying implementation, liblinear, uses a sparse internal representation for the data that will incur a memory copy.</source>
          <target state="translated">Базовая реализация,liblinear,использует разреженное внутреннее представление для данных,которые будут нести в себе копию памяти.</target>
        </trans-unit>
        <trans-unit id="7c5718e72f8aabec82565a4976b3e3b79f8616d0" translate="yes" xml:space="preserve">
          <source>The unique classes labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22bad6cd0a0fca07f198954a6d755d20a0363412" translate="yes" xml:space="preserve">
          <source>The univariate position of the sample according to the main dimension of the points in the manifold.</source>
          <target state="translated">Одномерное положение образца в соответствии с основным размером точек в коллекторе.</target>
        </trans-unit>
        <trans-unit id="e1bff9cf5ae34029868daf8dfe6afee04fc2666d" translate="yes" xml:space="preserve">
          <source>The unmixing matrix.</source>
          <target state="translated">Несмешивающаяся матрица.</target>
        </trans-unit>
        <trans-unit id="4c5425dc309e3cab0153df4bbf4dcfe21bae1aa0" translate="yes" xml:space="preserve">
          <source>The unsupervised data reduction and the supervised estimator can be chained in one step. See &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline: chaining estimators&lt;/a&gt;.</source>
          <target state="translated">Обработка неконтролируемых данных и контролируемая оценка могут быть связаны за один шаг. Смотрите &lt;a href=&quot;compose#pipeline&quot;&gt;конвейер: цепочки оценок&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="fca2372915cd9dbf5bde8febd27812d65a387223" translate="yes" xml:space="preserve">
          <source>The upper left figure illustrates the predictions (in dark red) of a single decision tree trained over a random dataset LS (the blue dots) of a toy 1d regression problem. It also illustrates the predictions (in light red) of other single decision trees trained over other (and different) randomly drawn instances LS of the problem. Intuitively, the variance term here corresponds to the width of the beam of predictions (in light red) of the individual estimators. The larger the variance, the more sensitive are the predictions for &lt;code&gt;x&lt;/code&gt; to small changes in the training set. The bias term corresponds to the difference between the average prediction of the estimator (in cyan) and the best possible model (in dark blue). On this problem, we can thus observe that the bias is quite low (both the cyan and the blue curves are close to each other) while the variance is large (the red beam is rather wide).</source>
          <target state="translated">Верхний левый рисунок иллюстрирует предсказания (темно-красным) одного дерева решений, обученного на случайном наборе данных LS (синие точки) игрушечной задачи регрессии 1d. Он также иллюстрирует предсказания (светло-красным) других отдельных деревьев решений, обученных на других (и различных) случайно выбранных экземплярах LS задачи. Интуитивно термин дисперсии здесь соответствует ширине луча прогнозов (выделено красным цветом) отдельных оценщиков. Чем больше дисперсия, тем более чувствительны прогнозы для &lt;code&gt;x&lt;/code&gt; на небольшие изменения в обучающей выборке. Член смещения соответствует разнице между средним прогнозом оценки (голубым) и наилучшей возможной моделью (темно-синим). Таким образом, в этой проблеме мы можем заметить, что смещение довольно низкое (и голубая, и синяя кривые близки друг к другу), тогда как дисперсия велика (красный луч довольно широкий).</target>
        </trans-unit>
        <trans-unit id="30828e1dddfa129352e0424777c8d521d86c8855" translate="yes" xml:space="preserve">
          <source>The usage and the parameters of &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are described below. The 2 most important parameters of these estimators are &lt;code&gt;n_estimators&lt;/code&gt; and &lt;code&gt;learning_rate&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1125be6cb70e3f587339b27b5931d4f81c0d0d9b" translate="yes" xml:space="preserve">
          <source>The usage of &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; is described in detail in &lt;a href=&quot;../modules/kernel_approximation#kernel-approximation&quot;&gt;Kernel Approximation&lt;/a&gt;.</source>
          <target state="translated">Использование &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; подробно описано в &lt;a href=&quot;../modules/kernel_approximation#kernel-approximation&quot;&gt;Приближении ядра&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7012369902c9ebdfcf4a40c832356073db31ae9a" translate="yes" xml:space="preserve">
          <source>The usage of centroid distance limits the distance metric to Euclidean space.</source>
          <target state="translated">Использование расстояния до центроида ограничивает метрическое расстояние до евклидового пространства.</target>
        </trans-unit>
        <trans-unit id="4f2ed911398b7e07d993b089b964fc574c420c21" translate="yes" xml:space="preserve">
          <source>The usage of the &lt;a href=&quot;generated/sklearn.kernel_approximation.skewedchi2sampler#sklearn.kernel_approximation.SkewedChi2Sampler&quot;&gt;&lt;code&gt;SkewedChi2Sampler&lt;/code&gt;&lt;/a&gt; is the same as the usage described above for the &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt;. The only difference is in the free parameter, that is called \(c\). For a motivation for this mapping and the mathematical details see &lt;a href=&quot;#ls2010&quot; id=&quot;id7&quot;&gt;[LS2010]&lt;/a&gt;.</source>
          <target state="translated">Использование &lt;a href=&quot;generated/sklearn.kernel_approximation.skewedchi2sampler#sklearn.kernel_approximation.SkewedChi2Sampler&quot;&gt; &lt;code&gt;SkewedChi2Sampler&lt;/code&gt; &lt;/a&gt; такое же, как описано выше для &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; . Единственное отличие заключается в свободном параметре, который называется \ (c \). О мотивации для этого отображения и математических деталях см. &lt;a href=&quot;#ls2010&quot; id=&quot;id7&quot;&gt;[LS2010]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e4fafa67af5e9d647520b3a289f2e58cae35673f" translate="yes" xml:space="preserve">
          <source>The use of multi-output nearest neighbors for regression is demonstrated in &lt;a href=&quot;../auto_examples/miscellaneous/plot_multioutput_face_completion#sphx-glr-auto-examples-miscellaneous-plot-multioutput-face-completion-py&quot;&gt;Face completion with a multi-output estimators&lt;/a&gt;. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fabe9be99adc410c1907ea1daa7576972e4b19e8" translate="yes" xml:space="preserve">
          <source>The use of multi-output nearest neighbors for regression is demonstrated in &lt;a href=&quot;../auto_examples/plot_multioutput_face_completion#sphx-glr-auto-examples-plot-multioutput-face-completion-py&quot;&gt;Face completion with a multi-output estimators&lt;/a&gt;. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.</source>
          <target state="translated">Использование ближайших соседей с несколькими выходами для регрессии демонстрируется в &lt;a href=&quot;../auto_examples/plot_multioutput_face_completion#sphx-glr-auto-examples-plot-multioutput-face-completion-py&quot;&gt;завершении Face с оценками с несколькими выходами&lt;/a&gt; . В этом примере входы X - это пиксели верхней половины граней, а выходы Y - пиксели нижней половины этих граней.</target>
        </trans-unit>
        <trans-unit id="810478c2cd15f9d623ca524c5ee19e348c649a7e" translate="yes" xml:space="preserve">
          <source>The use of multi-output trees for classification is demonstrated in &lt;a href=&quot;../auto_examples/miscellaneous/plot_multioutput_face_completion#sphx-glr-auto-examples-miscellaneous-plot-multioutput-face-completion-py&quot;&gt;Face completion with a multi-output estimators&lt;/a&gt;. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adaab44ae672254ed2b0f1474d8d83b9d0ff364a" translate="yes" xml:space="preserve">
          <source>The use of multi-output trees for classification is demonstrated in &lt;a href=&quot;../auto_examples/plot_multioutput_face_completion#sphx-glr-auto-examples-plot-multioutput-face-completion-py&quot;&gt;Face completion with a multi-output estimators&lt;/a&gt;. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.</source>
          <target state="translated">Использование деревьев с несколькими выходами для классификации продемонстрировано в &lt;a href=&quot;../auto_examples/plot_multioutput_face_completion#sphx-glr-auto-examples-plot-multioutput-face-completion-py&quot;&gt;разделе Завершение лица с помощью оценок с несколькими выходами&lt;/a&gt; . В этом примере входы X - это пиксели верхней половины граней, а выходы Y - пиксели нижней половины этих граней.</target>
        </trans-unit>
        <trans-unit id="e18a96fd5f8412fd8540943bfa9bb84448ef6eef" translate="yes" xml:space="preserve">
          <source>The use of multi-output trees for regression is demonstrated in &lt;a href=&quot;../auto_examples/tree/plot_tree_regression_multioutput#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py&quot;&gt;Multi-output Decision Tree Regression&lt;/a&gt;. In this example, the input X is a single real value and the outputs Y are the sine and cosine of X.</source>
          <target state="translated">Использование деревьев с несколькими выходами для регрессии продемонстрировано в &lt;a href=&quot;../auto_examples/tree/plot_tree_regression_multioutput#sphx-glr-auto-examples-tree-plot-tree-regression-multioutput-py&quot;&gt;разделе &amp;laquo;Регрессия дерева решений с несколькими выходами&amp;raquo;&lt;/a&gt; . В этом примере вход X - это единственное действительное значение, а выходы Y - синус и косинус X.</target>
        </trans-unit>
        <trans-unit id="6d9188616eccce81f2896ac591395f1642a23655" translate="yes" xml:space="preserve">
          <source>The used categories can be found in the &lt;code&gt;categories_&lt;/code&gt; attribute.</source>
          <target state="translated">Использованные категории могут быть найдены в &lt;code&gt;categories_&lt;/code&gt; атрибута.</target>
        </trans-unit>
        <trans-unit id="ada4ba90a5864aca46a2fd4279e91da24ee2ef32" translate="yes" xml:space="preserve">
          <source>The user-provided initial means, defaults to None, If it None, means are initialized using the &lt;code&gt;init_params&lt;/code&gt; method.</source>
          <target state="translated">Предоставленные пользователем начальные средства по умолчанию равны Нет, если нет, то средства инициализируются с использованием метода &lt;code&gt;init_params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a1cbbec0505b4f4802950c392df8579b38a3220d" translate="yes" xml:space="preserve">
          <source>The user-provided initial precisions (inverse of the covariance matrices), defaults to None. If it None, precisions are initialized using the &amp;lsquo;init_params&amp;rsquo; method. The shape depends on &amp;lsquo;covariance_type&amp;rsquo;:</source>
          <target state="translated">Предоставленная пользователем начальная точность (инверсия ковариационных матриц) по умолчанию равна Нет. Если нет, точность инициализируется с помощью метода init_params. Форма зависит от 'covariance_type':</target>
        </trans-unit>
        <trans-unit id="930a8f090bbd3f5ab357e6a55436cb80968a37a5" translate="yes" xml:space="preserve">
          <source>The user-provided initial weights, defaults to None. If it None, weights are initialized using the &lt;code&gt;init_params&lt;/code&gt; method.</source>
          <target state="translated">Пользовательские начальные веса, по умолчанию None. Если нет, веса инициализируются с &lt;code&gt;init_params&lt;/code&gt; метода init_params .</target>
        </trans-unit>
        <trans-unit id="845cdaf2c42f719deb3141928cabec5996b4eedb" translate="yes" xml:space="preserve">
          <source>The usual covariance maximum likelihood estimate can be regularized using shrinkage. Ledoit and Wolf proposed a close formula to compute the asymptotically optimal shrinkage parameter (minimizing a MSE criterion), yielding the Ledoit-Wolf covariance estimate.</source>
          <target state="translated">Обычная оценка максимальной вероятности ковариаций может быть упорядочена с помощью усадки.Ледойт и Вульф предложили близкую формулу для расчета асимптотически оптимального параметра усадки (минимизация критерия МШЭ),что позволило получить оценку ковариаций Ледойта и Вульфа.</target>
        </trans-unit>
        <trans-unit id="5d9f8abe9cd1fbb176b951540baae1f3defa7962" translate="yes" xml:space="preserve">
          <source>The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set. In such a case, it would be better to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set.</source>
          <target state="translated">Обычная ковариационная оценка максимального правдоподобия очень чувствительна к наличию выбросов в наборе данных. В таком случае было бы лучше использовать надежную оценку ковариации, чтобы гарантировать устойчивость оценки к &amp;laquo;ошибочным&amp;raquo; наблюдениям в наборе данных.</target>
        </trans-unit>
        <trans-unit id="b7108164734a4610e8bf46680745d5c565a5fe9c" translate="yes" xml:space="preserve">
          <source>The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set. In such a case, it would be better to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set. &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;#id5&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf61b06542d3e7e313e8463ad6cb36679683eb16" translate="yes" xml:space="preserve">
          <source>The utility function &lt;a href=&quot;generated/sklearn.pipeline.make_pipeline#sklearn.pipeline.make_pipeline&quot;&gt;&lt;code&gt;make_pipeline&lt;/code&gt;&lt;/a&gt; is a shorthand for constructing pipelines; it takes a variable number of estimators and returns a pipeline, filling in the names automatically:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.pipeline.make_pipeline#sklearn.pipeline.make_pipeline&quot;&gt; &lt;code&gt;make_pipeline&lt;/code&gt; &lt;/a&gt; функция make_pipeline - это сокращение для построения конвейеров; он принимает переменное количество оценщиков и возвращает конвейер, автоматически заполняя имена:</target>
        </trans-unit>
        <trans-unit id="e6fa170ec90d321cecf4d3db13ca13c99c71342b" translate="yes" xml:space="preserve">
          <source>The valid distance metrics, and the function they map to, are:</source>
          <target state="translated">Действительные метрики расстояния и функция,к которой они привязаны:</target>
        </trans-unit>
        <trans-unit id="7aae4519886038a4fe27266a449c263068305fb0" translate="yes" xml:space="preserve">
          <source>The value 2 has the highest score: it appears twice with weights of 1.5 and 2: the sum of these is 3.</source>
          <target state="translated">Значение 2 имеет наивысший балл:оно появляется дважды с весами 1,5 и 2:их сумма равна 3.</target>
        </trans-unit>
        <trans-unit id="1614b1f299556b57f6975870b8797f657adfc906" translate="yes" xml:space="preserve">
          <source>The value 2 has the highest score: it appears twice with weights of 1.5 and 2: the sum of these is 3.5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf2aaa6a69c13c7a1da598bbc487a099c24264e9" translate="yes" xml:space="preserve">
          <source>The value 4 appears three times: with uniform weights, the result is simply the mode of the distribution.</source>
          <target state="translated">Значение 4 появляется трижды:при равномерных весах в результате получается просто режим распределения.</target>
        </trans-unit>
        <trans-unit id="ee4d7bc4aea75382ac7c13c2d3ccdb7c85b05695" translate="yes" xml:space="preserve">
          <source>The value by which &lt;code&gt;|y - X'w - c|&lt;/code&gt; is scaled down.</source>
          <target state="translated">Значение, на которое &lt;code&gt;|y - X'w - c|&lt;/code&gt; уменьшается в масштабе.</target>
        </trans-unit>
        <trans-unit id="208f4b20d150446e32489b5141e41ca0c231e069" translate="yes" xml:space="preserve">
          <source>The value of the inertia criterion associated with the chosen partition (if compute_labels is set to True). The inertia is defined as the sum of square distances of samples to their nearest neighbor.</source>
          <target state="translated">Значение критерия инерции,связанного с выбранным простенком (если значение переменной compute_labels установлено в True).Инерция определяется как сумма квадратных расстояний выборки до ближайшего соседа.</target>
        </trans-unit>
        <trans-unit id="605e5e84334ac11a6b1bcf93811952a1f4c93232" translate="yes" xml:space="preserve">
          <source>The value of the information criteria (&amp;lsquo;aic&amp;rsquo;, &amp;lsquo;bic&amp;rsquo;) across all alphas. The alpha which has the smallest information criterion is chosen. This value is larger by a factor of &lt;code&gt;n_samples&lt;/code&gt; compared to Eqns. 2.15 and 2.16 in (Zou et al, 2007).</source>
          <target state="translated">Значение информационных критериев ('aic', 'bic') по всем альфа-каналам. Выбирается альфа, имеющая наименьший информационный критерий. Это значение больше в &lt;code&gt;n_samples&lt;/code&gt; по сравнению с уравнениями. 2.15 и 2.16 в (Zou et al, 2007).</target>
        </trans-unit>
        <trans-unit id="31a3294fc25a32d76657f5de9f45e5deb67968f8" translate="yes" xml:space="preserve">
          <source>The value of the largest coefficient.</source>
          <target state="translated">Значение наибольшего коэффициента.</target>
        </trans-unit>
        <trans-unit id="35a39b75c4cf1051868175c0eb7c4d08a5d8c4c6" translate="yes" xml:space="preserve">
          <source>The value of the smallest coefficient.</source>
          <target state="translated">Значение наименьшего коэффициента.</target>
        </trans-unit>
        <trans-unit id="77ad2ae374f9b7e58f24db15820679db8e02f6eb" translate="yes" xml:space="preserve">
          <source>The values at which the partial dependence should be evaluated are directly generated from &lt;code&gt;X&lt;/code&gt;. For 2-way partial dependence, a 2D-grid of values is generated. The &lt;code&gt;values&lt;/code&gt; field returned by &lt;a href=&quot;generated/sklearn.inspection.partial_dependence#sklearn.inspection.partial_dependence&quot;&gt;&lt;code&gt;sklearn.inspection.partial_dependence&lt;/code&gt;&lt;/a&gt; gives the actual values used in the grid for each target feature. They also correspond to the axis of the plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d764819e9c8551a1ae19a24b5d4cd3ac77d8b2aa" translate="yes" xml:space="preserve">
          <source>The values corresponding the quantiles of reference.</source>
          <target state="translated">Значения,соответствующие квантилям ссылки.</target>
        </trans-unit>
        <trans-unit id="e64c591fdc6bfea9ce8a9d182cdb9d3354d8a90b" translate="yes" xml:space="preserve">
          <source>The values listed by the ValueError exception correspond to the functions measuring prediction accuracy described in the following sections. The scorer objects for those functions are stored in the dictionary &lt;code&gt;sklearn.metrics.SCORERS&lt;/code&gt;.</source>
          <target state="translated">Значения, перечисленные в исключении ValueError, соответствуют функциям измерения точности предсказания, описанным в следующих разделах. Объекты &lt;code&gt;sklearn.metrics.SCORERS&lt;/code&gt; для этих функций хранятся в словаре sklearn.metrics.SCORERS .</target>
        </trans-unit>
        <trans-unit id="ad8b80eff2782593fcb8941c5fc504eacc683633" translate="yes" xml:space="preserve">
          <source>The values of the parameter that will be evaluated.</source>
          <target state="translated">Значения параметра,который будет оцениваться.</target>
        </trans-unit>
        <trans-unit id="380d80dd5b496982ade02999d670873884707a35" translate="yes" xml:space="preserve">
          <source>The values of this array sum to 1, unless all trees are single node trees consisting of only the root node, in which case it will be an array of zeros.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="896e61b11bd1cccb5014a25cacfbd49baded2da1" translate="yes" xml:space="preserve">
          <source>The values to be assigned to each cluster of samples</source>
          <target state="translated">Значения,которые должны быть присвоены каждому кластеру образцов</target>
        </trans-unit>
        <trans-unit id="15b198c6985fde1d17e7089abe8db26ba2c88b68" translate="yes" xml:space="preserve">
          <source>The values with which the grid has been created. The generated grid is a cartesian product of the arrays in &lt;code&gt;values&lt;/code&gt;. &lt;code&gt;len(values) ==
len(features)&lt;/code&gt;. The size of each array &lt;code&gt;values[j]&lt;/code&gt; is either &lt;code&gt;grid_resolution&lt;/code&gt;, or the number of unique values in &lt;code&gt;X[:, j]&lt;/code&gt;, whichever is smaller.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de1379c1aa59c6a0f9d415d70cec6205d70e58b1" translate="yes" xml:space="preserve">
          <source>The variance for each feature in the training set. Used to compute &lt;code&gt;scale_&lt;/code&gt;. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">Дисперсия для каждой функции в обучающем наборе. Используется для вычисления &lt;code&gt;scale_&lt;/code&gt; . Равно &lt;code&gt;None&lt;/code&gt; , когда &lt;code&gt;with_std=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6909f327165fbbe5fe9d7a24773b9839e3b76030" translate="yes" xml:space="preserve">
          <source>The variance of the training samples transformed by a projection to each component.</source>
          <target state="translated">Разница в количестве учебных образцов,преобразованных проекцией на каждый компонент.</target>
        </trans-unit>
        <trans-unit id="73778e0f44de95a7d306fdc5c4bc68ceb4bf8f71" translate="yes" xml:space="preserve">
          <source>The varying values of the coefficients along the path. It is not present if the &lt;code&gt;fit_path&lt;/code&gt; parameter is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">Различные значения коэффициентов по пути. Его нет, если параметр &lt;code&gt;fit_path&lt;/code&gt; равен &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f193fe45abdd49c251c120544e6bc124439f7f88" translate="yes" xml:space="preserve">
          <source>The vector \(h_i\) is called &amp;ldquo;latent&amp;rdquo; because it is unobserved. \(\epsilon\) is considered a noise term distributed according to a Gaussian with mean 0 and covariance \(\Psi\) (i.e. \(\epsilon \sim \mathcal{N}(0, \Psi)\)), \(\mu\) is some arbitrary offset vector. Such a model is called &amp;ldquo;generative&amp;rdquo; as it describes how \(x_i\) is generated from \(h_i\). If we use all the \(x_i\)&amp;lsquo;s as columns to form a matrix \(\mathbf{X}\) and all the \(h_i\)&amp;lsquo;s as columns of a matrix \(\mathbf{H}\) then we can write (with suitably defined \(\mathbf{M}\) and \(\mathbf{E}\)):</source>
          <target state="translated">Вектор \ (h_i \) называется &amp;laquo;скрытым&amp;raquo;, потому что он не наблюдается. \ (\ epsilon \) считается шумовым термином, распределенным в соответствии с гауссианом со средним 0 и ковариацией \ (\ Psi \) (т.е. \ (\ epsilon \ sim \ mathcal {N} (0, \ Psi) \)), \ (\ mu \) - произвольный вектор смещения. Такая модель называется &amp;laquo;генеративной&amp;raquo;, поскольку она описывает, как \ (x_i \) генерируется из \ (h_i \). Если мы используем все \ (x_i \) в качестве столбцов для формирования матрицы \ (\ mathbf {X} \) и все \ (h_i \) в качестве столбцов матрицы \ (\ mathbf {H} \ ), то мы можем написать (с подходящим образом определенными \ (\ mathbf {M} \) и \ (\ mathbf {E} \)):</target>
        </trans-unit>
        <trans-unit id="928beebc49e69bf6a914c81639fd968b851e773a" translate="yes" xml:space="preserve">
          <source>The vector \(h_i\) is called &amp;ldquo;latent&amp;rdquo; because it is unobserved. \(\epsilon\) is considered a noise term distributed according to a Gaussian with mean 0 and covariance \(\Psi\) (i.e. \(\epsilon \sim \mathcal{N}(0, \Psi)\)), \(\mu\) is some arbitrary offset vector. Such a model is called &amp;ldquo;generative&amp;rdquo; as it describes how \(x_i\) is generated from \(h_i\). If we use all the \(x_i\)&amp;rsquo;s as columns to form a matrix \(\mathbf{X}\) and all the \(h_i\)&amp;rsquo;s as columns of a matrix \(\mathbf{H}\) then we can write (with suitably defined \(\mathbf{M}\) and \(\mathbf{E}\)):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4545cfee48c8d7d2034c72caee40a8d82cfcf4ce" translate="yes" xml:space="preserve">
          <source>The verbose setting on the MiniBatchKMeans enables us to see that some clusters are reassigned during the successive calls to partial-fit. This is because the number of patches that they represent has become too low, and it is better to choose a random new cluster.</source>
          <target state="translated">Многословная настройка на MiniBatchKMeans позволяет нам видеть,что некоторые кластеры переназначаются во время последовательных вызовов на частичное соответствие.Это происходит потому,что количество патчей,которые они представляют,стало слишком низким,и лучше выбрать случайный новый кластер.</target>
        </trans-unit>
        <trans-unit id="e4c09c360935c392206a8639f0a0b8f4c48b519d" translate="yes" xml:space="preserve">
          <source>The verbosity level</source>
          <target state="translated">Уровень глаголов</target>
        </trans-unit>
        <trans-unit id="4b4be8a44f0a986b95a00a99e1db7cc81cee43d8" translate="yes" xml:space="preserve">
          <source>The verbosity level.</source>
          <target state="translated">Уровень глаголов.</target>
        </trans-unit>
        <trans-unit id="d073e4bf5a007c3a6f9ea54d0f642d54d81c6316" translate="yes" xml:space="preserve">
          <source>The verbosity level. If not zero, print some information about the fitting process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bca220a25d0b85cbc18bcc37bc0c66babd623c39" translate="yes" xml:space="preserve">
          <source>The verbosity level. The default, zero, means silent mode.</source>
          <target state="translated">Уровень глаголов.По умолчанию,ноль,означает бесшумный режим.</target>
        </trans-unit>
        <trans-unit id="b790263c39903969cb477edb620406690c93cb40" translate="yes" xml:space="preserve">
          <source>The verbosity level: if non zero, progress messages are printed. Above 50, the output is sent to stdout. The frequency of the messages increases with the verbosity level. If it more than 10, all iterations are reported.</source>
          <target state="translated">Уровень глаголов:если не равен нулю,выводятся сообщения о прогрессе.Выше 50,вывод отправляется в stdout.Частота сообщений увеличивается с увеличением уровня глаголовкости.Если она превышает 10,сообщается обо всех итерациях.</target>
        </trans-unit>
        <trans-unit id="ac67f0eccad920e701e068f47d28e090c55e23b1" translate="yes" xml:space="preserve">
          <source>The verbosity mode of the function. By default that of the memory object is used.</source>
          <target state="translated">Глагольный режим функции.По умолчанию используется режим объекта памяти.</target>
        </trans-unit>
        <trans-unit id="31fbaba32a3bec24c49d9ccad5d6e7edcbc904dc" translate="yes" xml:space="preserve">
          <source>The versions of scikit-learn and its dependencies</source>
          <target state="translated">Версии научно-обученного и его зависимости</target>
        </trans-unit>
        <trans-unit id="588dcf117cf46b2a6deec167a78bc5c1266a3688" translate="yes" xml:space="preserve">
          <source>The visualization is fit automatically to the size of the axis. Use the &lt;code&gt;figsize&lt;/code&gt; or &lt;code&gt;dpi&lt;/code&gt; arguments of &lt;code&gt;plt.figure&lt;/code&gt; to control the size of the rendering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a1686cc9631522f215a91033f5d185a9b750f85" translate="yes" xml:space="preserve">
          <source>The vocabulary extracted by this vectorizer is hence much bigger and can now resolve ambiguities encoded in local positioning patterns:</source>
          <target state="translated">Следовательно,словарь,извлекаемый этим векторизатором,намного больше и теперь может разрешать двусмысленности,закодированные в локальных шаблонах позиционирования:</target>
        </trans-unit>
        <trans-unit id="16d6455593e440b1ece6b5d9b609b990b16728ff" translate="yes" xml:space="preserve">
          <source>The weighted average probabilities for a sample would then be calculated as follows:</source>
          <target state="translated">Затем средневзвешенные вероятности для выборки будут рассчитаны следующим образом:</target>
        </trans-unit>
        <trans-unit id="cf3727918257ef88c9160136d7b98b7188c886ca" translate="yes" xml:space="preserve">
          <source>The weighted impurity decrease equation is the following:</source>
          <target state="translated">Уравнение уменьшения взвешенных примесей следующее:</target>
        </trans-unit>
        <trans-unit id="b71363fa16752021c27a44ccc8c03e740b0054e3" translate="yes" xml:space="preserve">
          <source>The weights \(w\) of the model can be access:</source>
          <target state="translated">Доступна информация о весах модели \(w\):</target>
        </trans-unit>
        <trans-unit id="dff6c2479ef55aa391ea0314f017ab45501554fd" translate="yes" xml:space="preserve">
          <source>The weights for each observation in X. If None, all observations are assigned equal weight</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd37cf293f530a725eccba4fc386300500a89671" translate="yes" xml:space="preserve">
          <source>The weights for each observation in X. If None, all observations are assigned equal weight (default: None)</source>
          <target state="translated">Веса для каждого наблюдения в X.Если Нет,то всем наблюдениям присваивается равный вес (по умолчанию:Нет).</target>
        </trans-unit>
        <trans-unit id="89b091775b7b9350f3e527eec283b3139c887c00" translate="yes" xml:space="preserve">
          <source>The weights for each observation in X. If None, all observations are assigned equal weight (default: None).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cdf718f4170abd3f842260826cc1d9da2bb111a" translate="yes" xml:space="preserve">
          <source>The weights for each observation in X. If None, all observations are assigned equal weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fd9c75eb2401f4a1ca174b965b1602b9d82941e" translate="yes" xml:space="preserve">
          <source>The weights of each feature computed by the &lt;code&gt;fit&lt;/code&gt; method call are stored in a model attribute:</source>
          <target state="translated">Веса каждого объекта, вычисленные вызовом метода &lt;code&gt;fit&lt;/code&gt; , хранятся в атрибуте модели:</target>
        </trans-unit>
        <trans-unit id="44235eb4c2d368f2a7e225131bb791a1dc59a457" translate="yes" xml:space="preserve">
          <source>The weights of each mixture components.</source>
          <target state="translated">Вес каждого компонента смеси.</target>
        </trans-unit>
        <trans-unit id="dd426f25816730ede96a98b838186f9fc1553a50" translate="yes" xml:space="preserve">
          <source>The wine dataset is a classic and very easy multi-class classification dataset.</source>
          <target state="translated">Набор данных по винам является классическим и очень простым набором классификационных данных по нескольким классам.</target>
        </trans-unit>
        <trans-unit id="9f15574c628488edf549f3131c3e1a8bfce37b9c" translate="yes" xml:space="preserve">
          <source>The word &amp;ldquo;article&amp;rdquo; is a significant feature, based on how often people quote previous posts like this: &amp;ldquo;In article [article ID], [name] &amp;lt;[e-mail address]&amp;gt; wrote:&amp;rdquo;</source>
          <target state="translated">Слово &amp;laquo;статья&amp;raquo; - важная особенность, основанная на том, как часто люди цитируют предыдущие сообщения, например: &amp;laquo;В статье [идентификатор статьи], [имя] &amp;lt;[адрес электронной почты]&amp;gt; написал:&amp;raquo;</target>
        </trans-unit>
        <trans-unit id="364df8b6c4c1dfcb405abf5ac32289b3f8338a10" translate="yes" xml:space="preserve">
          <source>The word &lt;em&gt;restricted&lt;/em&gt; refers to the bipartite structure of the model, which prohibits direct interaction between hidden units, or between visible units. This means that the following conditional independencies are assumed:</source>
          <target state="translated">Слово &amp;laquo; &lt;em&gt;ограниченный&amp;raquo;&lt;/em&gt; относится к двудольной структуре модели, которая запрещает прямое взаимодействие между скрытыми или видимыми элементами. Это означает, что предполагаются следующие условные зависимости:</target>
        </trans-unit>
        <trans-unit id="92b782ef9bfc8a9813d7ea0d8efb9106d8f1896e" translate="yes" xml:space="preserve">
          <source>The word boundaries-aware variant &lt;code&gt;char_wb&lt;/code&gt; is especially interesting for languages that use white-spaces for word separation as it generates significantly less noisy features than the raw &lt;code&gt;char&lt;/code&gt; variant in that case. For such languages it can increase both the predictive accuracy and convergence speed of classifiers trained using such features while retaining the robustness with regards to misspellings and word derivations.</source>
          <target state="translated">Границы слов, известно , вариант &lt;code&gt;char_wb&lt;/code&gt; особенно интересен для языков , которые используют белые-пространства для разделения слов , как он генерирует значительно меньше , чем шумные функции исходного &lt;code&gt;char&lt;/code&gt; вариант в этом случае. Для таких языков это может повысить как точность прогнозов, так и скорость сходимости классификаторов, обученных с использованием таких функций, при сохранении устойчивости в отношении орфографических ошибок и производных слов.</target>
        </trans-unit>
        <trans-unit id="8e8bd120180a9cd30000d6c7bc4b945e5f585fc6" translate="yes" xml:space="preserve">
          <source>The worst case complexity is given by O(n^(k+2/p)) with n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii, &amp;lsquo;How slow is the k-means method?&amp;rsquo; SoCG2006)</source>
          <target state="translated">Сложность наихудшего случая определяется как O (n ^ (k + 2 / p)) с n = n_samples, p = n_features. (Д. Артур и С. Васильвицкий, &amp;laquo;Насколько медленен метод k-средних?&amp;raquo;, SoCG2006)</target>
        </trans-unit>
        <trans-unit id="08b4bc51642b52ec53b43a5b2dca7586d296a859" translate="yes" xml:space="preserve">
          <source>Theil-Sen Estimator: robust multivariate regression model.</source>
          <target state="translated">Theil-Sen Estimator:робастная многомерная модель регрессии.</target>
        </trans-unit>
        <trans-unit id="26357ed7a886288385aec0522bda7ee91031a5a9" translate="yes" xml:space="preserve">
          <source>Theil-Sen Estimators in a Multiple Linear Regression Model, 2009 Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&lt;/a&gt;</source>
          <target state="translated">Оценки Тейла-Сена в модели множественной линейной регрессии, 2009 г. Синь Данг, Ханьсян Пэн, Сюэцинь Ван и Хэпин Чжан &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bfbe9912c49db3d4af2258ea17cbacd11611139b" translate="yes" xml:space="preserve">
          <source>Theil-Sen Regression</source>
          <target state="translated">регрессия Тейл-Сена</target>
        </trans-unit>
        <trans-unit id="43407a9ed591c227c94e72cd0fbe8ae10a8a282d" translate="yes" xml:space="preserve">
          <source>TheilSen is good for small outliers, both in direction X and y, but has a break point above which it performs worse than OLS.</source>
          <target state="translated">TheilSen хорошо подходит для небольших отклонений,как в направлении X,так и y,но имеет точку перелома,выше которой он работает хуже,чем OLS.</target>
        </trans-unit>
        <trans-unit id="bae71614b2af83560543a8e9bca47722a78d80c8" translate="yes" xml:space="preserve">
          <source>Their harmonic mean called &lt;strong&gt;V-measure&lt;/strong&gt; is computed by &lt;a href=&quot;generated/sklearn.metrics.v_measure_score#sklearn.metrics.v_measure_score&quot;&gt;&lt;code&gt;v_measure_score&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Их среднее гармоническое значение, называемое &lt;strong&gt;V-мерой&lt;/strong&gt; , вычисляется с помощью &lt;a href=&quot;generated/sklearn.metrics.v_measure_score#sklearn.metrics.v_measure_score&quot;&gt; &lt;code&gt;v_measure_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="de0b6ab722b9ec4be95cb7086fea273ea373e1de" translate="yes" xml:space="preserve">
          <source>Then fire an ipython shell and run the work-in-progress script with:</source>
          <target state="translated">Затем запустите оболочку ipython и запустите рабочий скрипт:</target>
        </trans-unit>
        <trans-unit id="8f78bb6cc31961e9507c2d8e418f53fe822a9ecd" translate="yes" xml:space="preserve">
          <source>Then one can show that to classify a data point after scaling is equivalent to finding the estimated class mean \(\mu^*_k\) which is closest to the data point in the Euclidean distance. But this can be done just as well after projecting on the \(K-1\) affine subspace \(H_K\) generated by all the \(\mu^*_k\) for all classes. This shows that, implicit in the LDA classifier, there is a dimensionality reduction by linear projection onto a \(K-1\) dimensional space.</source>
          <target state="translated">Тогда можно показать,что классификация точки данных после масштабирования эквивалентна нахождению среднего оценочного класса \(\mu^*_k\),который наиболее близок к точке данных на евклидовом расстоянии.Но это можно сделать так же хорошо после проектирования на \(K-1\)аффинировать подпространство \(H_K\),сгенерированное всеми \(\mu^*_k\)для всех классов.Это показывает,что,неявно в классификаторе LDA,есть уменьшение размерности линейной проекцией на размерное пространство \(K-1\).</target>
        </trans-unit>
        <trans-unit id="37e493a483dcc9fefbfec81c47f8c835f7340e3f" translate="yes" xml:space="preserve">
          <source>Then the Davies-Bouldin index is defined as:</source>
          <target state="translated">Затем определяется индекс Дэвиса-Болдин:</target>
        </trans-unit>
        <trans-unit id="54059dffef3b64a1ba00cd6fbe5ba85d85229195" translate="yes" xml:space="preserve">
          <source>Then the metrics are defined as:</source>
          <target state="translated">Затем определяются метрики как:</target>
        </trans-unit>
        <trans-unit id="8da3ae858e8aee4768b456c38c7b9a98b999a912" translate="yes" xml:space="preserve">
          <source>Then the multiclass MCC is defined as:</source>
          <target state="translated">Затем определяется многоклассный MCC:</target>
        </trans-unit>
        <trans-unit id="826d143749061228ef1caa51bd344b5a543a3ad8" translate="yes" xml:space="preserve">
          <source>Then the rows of \(Z\) are clustered using &lt;a href=&quot;clustering#k-means&quot;&gt;k-means&lt;/a&gt;. The first &lt;code&gt;n_rows&lt;/code&gt; labels provide the row partitioning, and the remaining &lt;code&gt;n_columns&lt;/code&gt; labels provide the column partitioning.</source>
          <target state="translated">Затем строки \ (Z \) группируются с использованием &lt;a href=&quot;clustering#k-means&quot;&gt;k-средних&lt;/a&gt; . Первые метки &lt;code&gt;n_rows&lt;/code&gt; обеспечивают разделение строк, а оставшиеся метки &lt;code&gt;n_columns&lt;/code&gt; обеспечивают разделение столбцов.</target>
        </trans-unit>
        <trans-unit id="35fd57830f62bfb9e9a1c9481c01f75fad3f7e92" translate="yes" xml:space="preserve">
          <source>Then we check the performance of the computed model plotting its predictions on the test set and computing, for example, the median absolute error of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04ebdc92c95e8a854e544219afce2fe077f07d46" translate="yes" xml:space="preserve">
          <source>Then we check the quality of the predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7548beecedd6ae525f17db272cd47fef5592b2e" translate="yes" xml:space="preserve">
          <source>Then, applying the Euclidean (L2) norm, we obtain the following tf-idfs for document 1:</source>
          <target state="translated">Затем,применяя норму Евклидана (L2),получаем следующие tf-idfs для документа 1:</target>
        </trans-unit>
        <trans-unit id="743e0b74d42270bf2752b1121cf66d48c177b1df" translate="yes" xml:space="preserve">
          <source>Then, the &lt;code&gt;raw_X&lt;/code&gt; to be fed to &lt;code&gt;FeatureHasher.transform&lt;/code&gt; can be constructed using:</source>
          <target state="translated">Затем &lt;code&gt;raw_X&lt;/code&gt; для передачи в &lt;code&gt;FeatureHasher.transform&lt;/code&gt; может быть сконструирован с использованием:</target>
        </trans-unit>
        <trans-unit id="36e93c1a3cbd0ad36880c0132d911de26dc0ca83" translate="yes" xml:space="preserve">
          <source>Then, we identify features &lt;code&gt;X&lt;/code&gt; and targets &lt;code&gt;y&lt;/code&gt;: the column WAGE is our target variable (i.e., the variable which we want to predict).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2abd121a4ed8d06cf0817807518539ab09e24fe" translate="yes" xml:space="preserve">
          <source>Then, we introspect the information regarding each column data type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4665e6f004c55fa84e60f1409a5b03c15037dd8c" translate="yes" xml:space="preserve">
          <source>Theoretical bounds</source>
          <target state="translated">Теоретические рамки</target>
        </trans-unit>
        <trans-unit id="3ebe4a41a0b35192395aac8a80293b4ff462a23b" translate="yes" xml:space="preserve">
          <source>There are 3 different APIs for evaluating the quality of a model&amp;rsquo;s predictions:</source>
          <target state="translated">Есть 3 разных API для оценки качества прогнозов модели:</target>
        </trans-unit>
        <trans-unit id="96e1915039a69b2e8b64f25478a0431f9e517cc9" translate="yes" xml:space="preserve">
          <source>There are \(K\) topics in the corpus.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa910de5e10f2b04644e63996efaedb310779ee6" translate="yes" xml:space="preserve">
          <source>There are a number of ways to convert between a distance metric and a similarity measure, such as a kernel. Let &lt;code&gt;D&lt;/code&gt; be the distance, and &lt;code&gt;S&lt;/code&gt; be the kernel:</source>
          <target state="translated">Существует несколько способов преобразования между метрикой расстояния и мерой сходства, например ядром. Пусть &lt;code&gt;D&lt;/code&gt; - расстояние, а &lt;code&gt;S&lt;/code&gt; - ядро:</target>
        </trans-unit>
        <trans-unit id="daf4e822cec5d40489080bfb83cea014bb21271c" translate="yes" xml:space="preserve">
          <source>There are also a couple of cons (vs using a CountVectorizer with an in-memory vocabulary):</source>
          <target state="translated">Есть также пара &quot;против&quot; (против использования CountVectorizer со словарным запасом in-memory):</target>
        </trans-unit>
        <trans-unit id="17151dd0dcece68b8abecb55a500335bd2f90b73" translate="yes" xml:space="preserve">
          <source>There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.</source>
          <target state="translated">Есть понятия,которые трудно усвоить,потому что деревья решений не выражают их легко,такие как XOR,четность или проблемы с мультиплексором.</target>
        </trans-unit>
        <trans-unit id="fbd19b439fe6ba80531cd23629fc7a9a883a8dcf" translate="yes" xml:space="preserve">
          <source>There are different things to keep in mind when dealing with data corrupted by outliers:</source>
          <target state="translated">Есть разные вещи,о которых следует помнить,когда имеешь дело с данными,поврежденными посторонними лицами:</target>
        </trans-unit>
        <trans-unit id="8e7f48473f9869b2775936845c434aa7ef66ad5e" translate="yes" xml:space="preserve">
          <source>There are four more hyperparameters, \(\alpha_1\), \(\alpha_2\), \(\lambda_1\) and \(\lambda_2\) of the gamma prior distributions over \(\alpha\) and \(\lambda\). These are usually chosen to be &lt;em&gt;non-informative&lt;/em&gt;. By default \(\alpha_1 = \alpha_2 = \lambda_1 = \lambda_2 = 10^{-6}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcc62fa36cf231416a60ac162100095676c743b" translate="yes" xml:space="preserve">
          <source>There are many learning routines which rely on nearest neighbors at their core. One example is &lt;a href=&quot;density#kernel-density&quot;&gt;kernel density estimation&lt;/a&gt;, discussed in the &lt;a href=&quot;density#density-estimation&quot;&gt;density estimation&lt;/a&gt; section.</source>
          <target state="translated">Есть много программ обучения, которые в своей основе полагаются на ближайших соседей. Одним из примеров является &lt;a href=&quot;density#kernel-density&quot;&gt;оценка плотности ядра&lt;/a&gt; , обсуждаемая в разделе &lt;a href=&quot;density#density-estimation&quot;&gt;оценки плотности&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="de49a8d62debf6dd1584d9f929c607a2c0abdd42" translate="yes" xml:space="preserve">
          <source>There are many well-established imputation packages in the R data science ecosystem: Amelia, mi, mice, missForest, etc. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See &lt;a href=&quot;../auto_examples/impute/plot_iterative_imputer_variants_comparison#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py&quot;&gt;Imputing missing values with variants of IterativeImputer&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afc5c09497df5828bed5e53fb9ba7340fbd12b56" translate="yes" xml:space="preserve">
          <source>There are several known issues in our provided &amp;lsquo;english&amp;rsquo; stop word list. It does not aim to be a general, &amp;lsquo;one-size-fits-all&amp;rsquo; solution as some tasks may require a more custom solution. See &lt;a href=&quot;#nqy18&quot; id=&quot;id5&quot;&gt;[NQY18]&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84513801465c2346e62e2a9ecaecce1cb0c3994b" translate="yes" xml:space="preserve">
          <source>There are several known issues in our provided &amp;lsquo;english&amp;rsquo; stop word list. See &lt;a href=&quot;#nqy18&quot; id=&quot;id5&quot;&gt;[NQY18]&lt;/a&gt;.</source>
          <target state="translated">В предоставленном нами списке стоп-слов для английского языка есть несколько известных проблем. См. &lt;a href=&quot;#nqy18&quot; id=&quot;id5&quot;&gt;[NQY18]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="69da86c48a6fab38a24a0a096ce607f0a2966cc1" translate="yes" xml:space="preserve">
          <source>There are several possibilities to do that, two of which are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87d60889b216a9f6a8543438325d8902e749b92a" translate="yes" xml:space="preserve">
          <source>There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</source>
          <target state="translated">Существует десять различных изображений каждого из 40 различных предметов.Для некоторых объектов изображения были сделаны в разное время,варьируя освещение,мимику (открытые/закрытые глаза,улыбающиеся/неулыбающиеся)и детали лица (очки/без очков).Все снимки были сделаны на темном однородном фоне,с объектами в вертикальном,фронтальном положении (с допуском на некоторые боковые движения).</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
