<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="b70db829e86f8b0b87ee4b4ea9165e2800cb135e" translate="yes" xml:space="preserve">
          <source>In particular the interrogative form &amp;ldquo;Is this&amp;rdquo; is only present in the last document:</source>
          <target state="translated">В частности, вопросительная форма Is this присутствует только в последнем документе:</target>
        </trans-unit>
        <trans-unit id="48a72aaef5f57348c3c02ddfbd84f34663c56133" translate="yes" xml:space="preserve">
          <source>In particular we name:</source>
          <target state="translated">В частности,мы называем:</target>
        </trans-unit>
        <trans-unit id="32bae48b70c29501503578b88b61dfab45b0637c" translate="yes" xml:space="preserve">
          <source>In particular, \(\nu = 3/2\):</source>
          <target state="translated">В частности,\(\nu=3/2\):</target>
        </trans-unit>
        <trans-unit id="ff34c019cd4067dd0b8a1a6d1536db31ff351b58" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">В частности,усеченный SVD работает на матрицах count/tf-idf сроков,возвращаемых векторизаторами в sklearn.feature_extraction.text.В этом контексте он известен как латентный семантический анализ (LSA).</target>
        </trans-unit>
        <trans-unit id="74d856933005d819af2a4b7d2ce24317b5186453" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plan.</source>
          <target state="translated">На практике Spectral Clustering (спектральная кластеризация)очень полезна,когда структура отдельных кластеров сильно не сгущается или,в более общем плане,когда мера центра и распространения кластера не является подходящим описанием полного кластера.Например,когда кластеры вложены в круги на 2D плане.</target>
        </trans-unit>
        <trans-unit id="5662b7bb73c6d21ae298513382716bd3fe526ba2" translate="yes" xml:space="preserve">
          <source>In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of his k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.</source>
          <target state="translated">На практике локальная плотность получается у k-самых близких соседей.Показатель LOF наблюдения равен соотношению средней локальной плотности его k-крестных соседей и его собственной локальной плотности:ожидается,что нормальный экземпляр будет иметь локальную плотность,аналогичную плотности его соседей,в то время как аномальные данные будут иметь гораздо меньшую локальную плотность.</target>
        </trans-unit>
        <trans-unit id="7ab811a62d63edef5c9695fca6cafd8cc266404c" translate="yes" xml:space="preserve">
          <source>In practice those estimates are stored as an attribute named &lt;code&gt;feature_importances_&lt;/code&gt; on the fitted model. This is an array with shape &lt;code&gt;(n_features,)&lt;/code&gt; whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.</source>
          <target state="translated">На практике эти оценки сохраняются как атрибут с именем &lt;code&gt;feature_importances_&lt;/code&gt; в подобранной модели. Это массив с формой &lt;code&gt;(n_features,)&lt;/code&gt; , значения которой положительны и в сумме равны 1.0. Чем выше значение, тем важнее вклад функции сопоставления в функцию прогнозирования.</target>
        </trans-unit>
        <trans-unit id="2f91c327e74b19930bc0b8d2d9c2f5d99fe44af7" translate="yes" xml:space="preserve">
          <source>In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.</source>
          <target state="translated">На практике мы часто игнорируем форму распределения и просто преобразовываем данные в центр,удаляя среднее значение каждого признака,а затем масштабируем его,разделяя неконстантные признаки на их стандартное отклонение.</target>
        </trans-unit>
        <trans-unit id="4c632dd9d37d8e850afe2fbbbdbddfedb108d119" translate="yes" xml:space="preserve">
          <source>In practice, \(\mu\) and \(\Sigma\) are replaced by some estimates. The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set and therefor, the corresponding Mahalanobis distances are. One would better have to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set and that the associated Mahalanobis distances accurately reflect the true organisation of the observations.</source>
          <target state="translated">На практике \ (\ mu \) и \ (\ Sigma \) заменяются некоторыми оценками. Обычная ковариационная оценка максимального правдоподобия очень чувствительна к наличию выбросов в наборе данных и, следовательно, соответствующих расстояний Махаланобиса. Лучше было бы использовать надежную оценку ковариации, чтобы гарантировать, что оценка устойчива к &amp;laquo;ошибочным&amp;raquo; наблюдениям в наборе данных и что соответствующие расстояния Махаланобиса точно отражают истинную организацию наблюдений.</target>
        </trans-unit>
        <trans-unit id="7f19bfe5f66f3783151b8147191d95599d9b587d" translate="yes" xml:space="preserve">
          <source>In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That&amp;rsquo;s why it can be useful to restart it several times.</source>
          <target state="translated">На практике алгоритм k-средних очень быстр (один из самых быстрых доступных алгоритмов кластеризации), но он попадает в локальные минимумы. Вот почему может быть полезно перезапустить его несколько раз.</target>
        </trans-unit>
        <trans-unit id="a9809378b0338436bd7bbe8f2e2070a6272b570d" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples keywords &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">В задачах, где желательно придать большее значение определенным классам или определенным отдельным образцам, можно использовать ключевые слова &lt;code&gt;class_weight&lt;/code&gt; и &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cae7f41bfdb577edc832687cbceee9865d3220c5" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.</source>
          <target state="translated">В случайных лесах (см. &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt; ) каждое дерево в ансамбле строится из выборки, взятой с заменой (т. Е. Выборки начальной загрузки) из обучающего набора. Кроме того, при разделении узла во время построения дерева выбранное разделение больше не является лучшим разделением среди всех функций. Вместо этого выбранное разбиение является лучшим разбиением среди случайного подмножества функций. В результате этой случайности смещение леса обычно немного увеличивается (по сравнению с смещением одного неслучайного дерева), но из-за усреднения его дисперсия также уменьшается, обычно более чем компенсируя увеличение смещения, следовательно, дает в целом лучшую модель.</target>
        </trans-unit>
        <trans-unit id="eee63fdeeb00f1867cdf7e3f336a4276e1d12ae2" translate="yes" xml:space="preserve">
          <source>In regression, the expected mean squared error of an estimator can be decomposed in terms of bias, variance and noise. On average over datasets of the regression problem, the bias term measures the average amount by which the predictions of the estimator differ from the predictions of the best possible estimator for the problem (i.e., the Bayes model). The variance term measures the variability of the predictions of the estimator when fit over different instances LS of the problem. Finally, the noise measures the irreducible part of the error which is due the variability in the data.</source>
          <target state="translated">В регрессии ожидаемая средняя квадратная ошибка оценщика может быть разложена в терминах смещения,дисперсии и шума.В среднем по наборам данных задачи регрессии,член смещения измеряет среднюю величину,на которую предсказания оценщика отличаются от предсказаний лучшего из возможных оценщиков задачи (т.е.модели Байеса).Дисперсионный член измеряет изменчивость предсказаний оценщика,когда подгоняется под различные экземпляры LS задачи.Наконец,шум измеряет неисчерпаемую часть ошибки,которая обусловлена изменчивостью данных.</target>
        </trans-unit>
        <trans-unit id="3eae88b0a075df5d4090eee16e911849fedcc7b3" translate="yes" xml:space="preserve">
          <source>In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.</source>
          <target state="translated">В регрессии выход остается в виде \(f(x)\);поэтому выходная функция активации является лишь идентификационной функцией.</target>
        </trans-unit>
        <trans-unit id="253be6f032627aec5a3b2c4240659e2190b9fba2" translate="yes" xml:space="preserve">
          <source>In scikit-learn a random split into training and test sets can be quickly computed with the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; helper function. Let&amp;rsquo;s load the iris data set to fit a linear support vector machine on it:</source>
          <target state="translated">В scikit-learn случайное разбиение на обучающие и тестовые наборы можно быстро вычислить с &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt; вспомогательной функции train_test_split . Давайте загрузим набор данных радужной оболочки, чтобы он соответствовал машине линейных опорных векторов:</target>
        </trans-unit>
        <trans-unit id="bdcdb5bf0b220e10633a04e3b3d7b23fb832fcf9" translate="yes" xml:space="preserve">
          <source>In scikit-learn, an estimator for classification is a Python object that implements the methods &lt;code&gt;fit(X, y)&lt;/code&gt; and &lt;code&gt;predict(T)&lt;/code&gt;.</source>
          <target state="translated">В scikit-learn оценщик для классификации - это объект Python, который реализует методы &lt;code&gt;fit(X, y)&lt;/code&gt; и &lt;code&gt;predict(T)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a15700735758e7e1606b13cd4f276e5fe1e0ef96" translate="yes" xml:space="preserve">
          <source>In scikit-learn, bagging methods are offered as a unified &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt;&lt;code&gt;BaggingClassifier&lt;/code&gt;&lt;/a&gt; meta-estimator (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt;&lt;code&gt;BaggingRegressor&lt;/code&gt;&lt;/a&gt;), taking as input a user-specified base estimator along with parameters specifying the strategy to draw random subsets. In particular, &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt; control the size of the subsets (in terms of samples and features), while &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;bootstrap_features&lt;/code&gt; control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting &lt;code&gt;oob_score=True&lt;/code&gt;. As an example, the snippet below illustrates how to instantiate a bagging ensemble of &lt;code&gt;KNeighborsClassifier&lt;/code&gt; base estimators, each built on random subsets of 50% of the samples and 50% of the features.</source>
          <target state="translated">В scikit-learn методы &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt; &lt;code&gt;BaggingClassifier&lt;/code&gt; &lt;/a&gt; предлагаются в виде унифицированного метаоценки BaggingClassifier (соответственно, &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt; &lt;code&gt;BaggingRegressor&lt;/code&gt; &lt;/a&gt; ), принимающего в качестве входных данных указанную пользователем базовую оценку вместе с параметрами, определяющими стратегию рисования случайных подмножеств. В частности, &lt;code&gt;max_samples&lt;/code&gt; и &lt;code&gt;max_features&lt;/code&gt; управляют размером подмножеств (с точки зрения образцов и функций), в то время как &lt;code&gt;bootstrap&lt;/code&gt; и &lt;code&gt;bootstrap_features&lt;/code&gt; контролируют, отрисовываются ли образцы и функции с заменой или без нее. При использовании подмножества доступных образцов точность обобщения можно оценить с помощью образцов вне пакета, установив &lt;code&gt;oob_score=True&lt;/code&gt; . В качестве примера приведенный ниже фрагмент иллюстрирует, как создать экземпляр ансамбля &lt;code&gt;KNeighborsClassifier&lt;/code&gt; базовых оценщиков KNeighborsClassifier , каждый из которых построен на случайных подмножествах из 50% выборок и 50% функций.</target>
        </trans-unit>
        <trans-unit id="0848ab34fddbc88dcbfdd395d0519986e8d182eb" translate="yes" xml:space="preserve">
          <source>In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt;&lt;code&gt;shrunk_covariance&lt;/code&gt;&lt;/a&gt; method. Also, a shrunk estimator of the covariance can be fitted to data with a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object and its &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt;&lt;code&gt;ShrunkCovariance.fit&lt;/code&gt;&lt;/a&gt; method. Again, results depend on whether the data are centered, so one may want to use the &lt;code&gt;assume_centered&lt;/code&gt; parameter accurately.</source>
          <target state="translated">В scikit-learn это преобразование (с определяемым пользователем коэффициентом усадки) можно напрямую применить к предварительно вычисленной ковариации с &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt; &lt;code&gt;shrunk_covariance&lt;/code&gt; &lt;/a&gt; метода shrunk_covariance . Кроме того, сжатую оценку ковариации можно &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; к данным с помощью объекта ShrunkCovariance и его метода &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt; &lt;code&gt;ShrunkCovariance.fit&lt;/code&gt; &lt;/a&gt; . Опять же, результаты зависят от того, центрированы ли данные, поэтому можно точно использовать параметр &lt;code&gt;assume_centered&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="77c9e3634b9d256acc307751b68c900b0b833a29" translate="yes" xml:space="preserve">
          <source>In single precision, &lt;code&gt;mean&lt;/code&gt; can be inaccurate:</source>
          <target state="translated">При одинарной точности &lt;code&gt;mean&lt;/code&gt; может быть неточным:</target>
        </trans-unit>
        <trans-unit id="640c5c337251b299605fe0c1704cd43d50fcda84" translate="yes" xml:space="preserve">
          <source>In some cases it&amp;rsquo;s not necessary to include higher powers of any single feature, but only the so-called &lt;em&gt;interaction features&lt;/em&gt; that multiply together at most \(d\) distinct features. These can be gotten from &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;.</source>
          <target state="translated">В некоторых случаях необязательно включать более высокие степени какой-либо отдельной функции, а только так называемые &lt;em&gt;функции взаимодействия,&lt;/em&gt; которые умножаются вместе не более чем на \ (d \) различных функций. Их можно получить из &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt; с установкой &lt;code&gt;interaction_only=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4976a8ab8df4ced9a6ceb9c8368b484dbc953550" translate="yes" xml:space="preserve">
          <source>In some cases, only interaction terms among features are required, and it can be gotten with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;:</source>
          <target state="translated">В некоторых случаях требуются только условия взаимодействия между функциями, и это может быть получено с помощью параметра &lt;code&gt;interaction_only=True&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1b40a5cc0ca592bd5c1306138f251a81fe534579" translate="yes" xml:space="preserve">
          <source>In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)</source>
          <target state="translated">Несмотря на свои,казалось бы,чрезмерно упрощенные допущения,наивные классификаторы Бейеса неплохо сработали во многих реальных ситуациях,известных как классификация документов и фильтрация спама.Они требуют небольшого количества обучающих данных для оценки необходимых параметров.(По теоретическим причинам,почему наивный Бэйес работает хорошо,и на какие типы данных он работает,см.ссылки ниже).</target>
        </trans-unit>
        <trans-unit id="389828ed3005eb646a2fbe827835555cbdc74437" translate="yes" xml:space="preserve">
          <source>In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.</source>
          <target state="translated">С точки зрения точности LOO часто приводит к высокой дисперсии в качестве оценочного показателя ошибки теста.Интуитивно,так как для построения каждой модели используются образцы \(n-1\),то модели,построенные из складок,практически идентичны друг другу и модели,построенные из всего обучающего набора.</target>
        </trans-unit>
        <trans-unit id="36132aafc76511f4279f2a1765dcbaeb9d7a44b1" translate="yes" xml:space="preserve">
          <source>In terms of time and space complexity, Theil-Sen scales according to</source>
          <target state="translated">С точки зрения пространственно-временной сложности,шкала Тейл-Зена в соответствии с</target>
        </trans-unit>
        <trans-unit id="8cac8320893acecd46013a1cd740f5237cabb213" translate="yes" xml:space="preserve">
          <source>In that case, the model with 2 components and full covariance (which corresponds to the true generative model) is selected.</source>
          <target state="translated">В этом случае выбирается модель с 2 компонентами и полной ковариацией (что соответствует истинной генеративной модели).</target>
        </trans-unit>
        <trans-unit id="df23be83a828beae97b01644c9cebfd6ec568f81" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;smooth_idf=False&lt;/code&gt;, the &amp;ldquo;1&amp;rdquo; count is added to the idf instead of the idf&amp;rsquo;s denominator:</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;smooth_idf=False&lt;/code&gt; счетчик &amp;laquo;1&amp;raquo; добавляется к idf вместо знаменателя idf:</target>
        </trans-unit>
        <trans-unit id="5bd53e1aa867b99daf4cb138797f33e24d9cfda1" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren&amp;rsquo;t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; все единицы являются стохастическими двоичными единицами. Это означает, что входные данные должны быть либо двоичными, либо с действительными значениями от 0 до 1, что означает вероятность того, что видимый блок включится или выключится. Это хорошая модель для распознавания символов, когда интересует, какие пиксели активны, а какие нет. Для изображений естественных сцен он больше не подходит из-за фона, глубины и тенденции соседних пикселей принимать одинаковые значения.</target>
        </trans-unit>
        <trans-unit id="729860dcb0b5963ed7d873f5d8718ecbded39d56" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; case, theory says that prediction consistency (i.e. that under given hypothesis, the estimator learned predicts as well as a model knowing the true distribution) is not possible because of the bias of the &lt;code&gt;l1&lt;/code&gt;. It does say, however, that model consistency, in terms of finding the right set of non-zero parameters as well as their signs, can be achieved by scaling &lt;code&gt;C1&lt;/code&gt;.</source>
          <target state="translated">В случае &lt;code&gt;l1&lt;/code&gt; теория утверждает, что непротиворечивость предсказания (то есть, что при данной гипотезе оценщик, обученный, предсказывает, а также модель, знающая истинное распределение) невозможна из-за смещения &lt;code&gt;l1&lt;/code&gt; . Однако в нем говорится, что согласованность модели с точки зрения нахождения правильного набора ненулевых параметров, а также их знаков может быть достигнута путем масштабирования &lt;code&gt;C1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3ac113ba1d5ea8579f40e00fa885b5d980c4ba43" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; penalty case, the cross-validation-error correlates best with the test-error, when scaling our &lt;code&gt;C&lt;/code&gt; with the number of samples, &lt;code&gt;n&lt;/code&gt;, which can be seen in the first figure.</source>
          <target state="translated">В случае штрафа &lt;code&gt;l1&lt;/code&gt; ошибка перекрестной проверки лучше всего коррелирует с ошибкой теста при масштабировании нашего &lt;code&gt;C&lt;/code&gt; с количеством выборок &lt;code&gt;n&lt;/code&gt; , что можно увидеть на первом рисунке.</target>
        </trans-unit>
        <trans-unit id="4495b7082e60ec7cb3a7d3cf1946536697a0e6b3" translate="yes" xml:space="preserve">
          <source>In the above case, the classifier is fit on a 1d array of multiclass labels and the &lt;code&gt;predict()&lt;/code&gt; method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:</source>
          <target state="translated">В приведенном выше случае классификатор помещается в 1d-массив мультиклассовых меток, и поэтому метод &lt;code&gt;predict()&lt;/code&gt; обеспечивает соответствующие многоклассовые предсказания. Также возможно разместить на 2-м массиве бинарных индикаторов меток:</target>
        </trans-unit>
        <trans-unit id="41d2181ce120b72b14a943b5e6f5608fe64d404d" translate="yes" xml:space="preserve">
          <source>In the above example, &lt;code&gt;char_wb&lt;/code&gt; analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The &lt;code&gt;char&lt;/code&gt; analyzer, alternatively, creates n-grams that span across words:</source>
          <target state="translated">В приведенном выше примере &lt;code&gt;char_wb&lt;/code&gt; анализатор char_wb , который создает н-граммы только из символов внутри границ слова (с пробелами с каждой стороны). В качестве альтернативы анализатор &lt;code&gt;char&lt;/code&gt; создает n-граммы, охватывающие слова:</target>
        </trans-unit>
        <trans-unit id="02dd6b844a6f6c7bb7b63318a0172b18e25d4984" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'city'&lt;/code&gt;). However, other transformers generally expect 2D data, and in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">В приведенном выше примере &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; ожидает в качестве входных данных одномерный массив, поэтому столбцы были указаны как строка ( &lt;code&gt;'city'&lt;/code&gt; ). Однако другие преобразователи обычно ожидают 2D-данных, и в этом случае вам нужно указать столбец как список строк ( &lt;code&gt;['city']&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="8be3ffb93abc4e32a08a3f61b709f6ed3e6124c4" translate="yes" xml:space="preserve">
          <source>In the above example-code, we firstly use the &lt;code&gt;fit(..)&lt;/code&gt; method to fit our estimator to the data and secondly the &lt;code&gt;transform(..)&lt;/code&gt; method to transform our count-matrix to a tf-idf representation. These two steps can be combined to achieve the same end result faster by skipping redundant processing. This is done through using the &lt;code&gt;fit_transform(..)&lt;/code&gt; method as shown below, and as mentioned in the note in the previous section:</source>
          <target state="translated">В приведенном выше примере кода мы, во-первых, используем метод &lt;code&gt;fit(..)&lt;/code&gt; чтобы подогнать нашу оценку к данным, и, во-вторых, метод &lt;code&gt;transform(..)&lt;/code&gt; для преобразования нашей матрицы-счетчика в представление tf-idf. Эти два шага можно объединить, чтобы быстрее достичь того же конечного результата, пропустив избыточную обработку. Это делается с помощью метода &lt;code&gt;fit_transform(..)&lt;/code&gt; как показано ниже и как указано в примечании в предыдущем разделе:</target>
        </trans-unit>
        <trans-unit id="fc1fc9feffcc3ab7062a5968abf403f994be456d" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is more than 2, and that the document length is never zero. Likewise, we reject classes which have already been chosen. The documents that are assigned to both classes are plotted surrounded by two colored circles.</source>
          <target state="translated">В описанном выше процессе выборка отказов используется для того,чтобы убедиться,что n больше 2,а длина документа никогда не будет равна нулю.Точно так же мы отвергаем уже выбранные классы.Документы,которые назначены обоим классам,построены в окружении двух цветных кругов.</target>
        </trans-unit>
        <trans-unit id="35ac86e1f976c024d854c94dc1a07d9250df373b" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is never zero or more than &lt;code&gt;n_classes&lt;/code&gt;, and that the document length is never zero. Likewise, we reject classes which have already been chosen.</source>
          <target state="translated">В приведенном выше процессе выборка отклонения используется, чтобы убедиться, что n никогда не равно нулю или больше &lt;code&gt;n_classes&lt;/code&gt; , и что длина документа никогда не равна нулю. Точно так же мы отклоняем уже выбранные классы.</target>
        </trans-unit>
        <trans-unit id="35b3eed71c5956697e4e941c9abda7fa7875d908" translate="yes" xml:space="preserve">
          <source>In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as</source>
          <target state="translated">В двоичном (двухклассовом)случае,\(tp\),\(tn\),\(fp\)и \(fn\),соответственно,число истинных положительных результатов,истинных отрицательных результатов,ложных положительных результатов и ложных отрицательных результатов,MCC определяется,как</target>
        </trans-unit>
        <trans-unit id="8cf754386b9e93bff61012cc7eebd891fe098125" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores.</source>
          <target state="translated">В двоичном случае сбалансированная точность равна среднему арифметическому &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;чувствительности&lt;/a&gt; (истинно положительный показатель) и &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;специфичности&lt;/a&gt; (истинно отрицательный показатель) или площади под кривой ROC с двоичными прогнозами, а не баллами.</target>
        </trans-unit>
        <trans-unit id="a998ef5238ae7921fe9486295ae64f00deab3566" translate="yes" xml:space="preserve">
          <source>In the binary case, we can extract true positives, etc as follows:</source>
          <target state="translated">В бинарном случае мы можем извлечь истинные положительные результаты и т.д.следующим образом:</target>
        </trans-unit>
        <trans-unit id="2482e7f51309cef70ec85538824011f95f0813b1" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of having a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; and &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">В случае &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; &amp;laquo;один на один&amp;raquo; компоновка атрибутов немного сложнее. В случае линейного ядра атрибуты &lt;code&gt;coef_&lt;/code&gt; и &lt;code&gt;intercept_&lt;/code&gt; имеют форму &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; и &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; соответственно. Это похоже на схему для &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; ,&lt;/a&gt; описанную выше, где каждая строка теперь соответствует двоичному классификатору. Порядок для классов от 0 до n следующий: &amp;laquo;0 против 1&amp;raquo;, &amp;laquo;0 против 2&amp;raquo;,&amp;hellip; &amp;laquo;0 против n&amp;raquo;, &amp;laquo;1 против 2&amp;raquo;, &amp;laquo;1 против 3&amp;raquo;, &amp;laquo;1 против n&amp;raquo;,. . . &amp;laquo;П-1 против п&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="7befa9fe69dc29e17ce8c14ce1f24dcd596f25dc" translate="yes" xml:space="preserve">
          <source>In the case of Gaussian process classification, &amp;ldquo;one_vs_one&amp;rdquo; might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates but only plain predictions. Moreover, note that &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.</source>
          <target state="translated">В случае классификации гауссовского процесса &amp;laquo;one_vs_one&amp;raquo; может быть дешевле с вычислительной точки зрения, поскольку он должен решать многие проблемы, включающие только подмножество всего обучающего набора, а не меньшее количество проблем во всем наборе данных. Поскольку классификация процессов по Гауссу кубически масштабируется в зависимости от размера набора данных, это может быть значительно быстрее. Однако обратите внимание, что &amp;laquo;one_vs_one&amp;raquo; не поддерживает прогнозирование оценок вероятности, а только простые прогнозы. Кроме того, обратите внимание, что &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; (пока) не реализует истинное мультиклассовое приближение Лапласа внутри, но, как обсуждалось выше, основано на решении нескольких внутренних задач двоичной классификации, которые комбинируются с использованием одного против остальных или одного против одного.</target>
        </trans-unit>
        <trans-unit id="35a5ada3d16c18d2778299b423e5960182d45740" translate="yes" xml:space="preserve">
          <source>In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios \(\log[P(y=k | X) / P(y=l | X)]\):</source>
          <target state="translated">В случае LDA предполагается,что гаусси для каждого класса имеют одну и ту же ковариационную матрицу:\(\Sigma_k=\Sigma\)для всех \(k\).Это приводит к линейным поверхностям принятия решений,что можно увидеть,сравнивая лог-вероятностные соотношения \(\log[P(y=k | X)/P(y=l | X)]\):</target>
        </trans-unit>
        <trans-unit id="9191afe7181654f4c123a5274615786e30f48b2b" translate="yes" xml:space="preserve">
          <source>In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">В случае QDA нет никаких предположений относительно ковариационных матриц \ (\ Sigma_k \) гауссианов, приводящих к квадратичным решающим поверхностям. См. &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="be50ffb98df62eb79c354d934aa76c5587bf8cba" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of &lt;code&gt;shape=[n_classes]&lt;/code&gt;. The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">В случае мультиклассовой классификации &lt;code&gt;coef_&lt;/code&gt; - это двумерный массив &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; а &lt;code&gt;intercept_&lt;/code&gt; - одномерный массив &lt;code&gt;shape=[n_classes]&lt;/code&gt; . I-я строка &lt;code&gt;coef_&lt;/code&gt; содержит весовой вектор классификатора OVA для i-го класса; классы индексируются в порядке возрастания (см. атрибут &lt;code&gt;classes_&lt;/code&gt; ). Обратите внимание, что в принципе, поскольку они позволяют создать модель вероятности, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; и &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; больше подходят для классификации &quot;один против всех&quot;.</target>
        </trans-unit>
        <trans-unit id="e1959581346965192dc91c946ef9926bceb1c51a" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.</source>
          <target state="translated">В случае классификации по нескольким классам возвращается средняя лог-маржинальная вероятность классификации по принципу &quot;один против одного&quot;.</target>
        </trans-unit>
        <trans-unit id="a45d03e82085c1e194b2b19d0700767439a7ac42" translate="yes" xml:space="preserve">
          <source>In the case of one-hot/one-of-K coding, the constructed feature names and values are returned rather than the original ones.</source>
          <target state="translated">В случае одноразового/одноразового кодирования возвращаются не оригинальные,а построенные имена и значения признаков.</target>
        </trans-unit>
        <trans-unit id="108b9e0576d5a78538771fb415a46ae76d1a6e26" translate="yes" xml:space="preserve">
          <source>In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. &lt;code&gt;BernoulliNB&lt;/code&gt; might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.</source>
          <target state="translated">В случае классификации текста для обучения и использования этого классификатора могут использоваться векторы появления слов (а не векторы подсчета слов). &lt;code&gt;BernoulliNB&lt;/code&gt; может лучше работать с некоторыми наборами данных, особенно с более короткими документами. Желательно оценить обе модели, если позволяет время.</target>
        </trans-unit>
        <trans-unit id="1ee37ddaa2e2b7fb0103fdddd162d9ad76a8f2dd" translate="yes" xml:space="preserve">
          <source>In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we &lt;em&gt;fit&lt;/em&gt; an &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimator&lt;/a&gt; to be able to &lt;em&gt;predict&lt;/em&gt; the classes to which unseen samples belong.</source>
          <target state="translated">В случае набора данных цифр задача состоит в том, чтобы по изображению предсказать, какую цифру оно представляет. Мы приведены образцы каждого из 10 возможных классов (цифры от нуля до девяти) , на котором мы &lt;em&gt;подходят&lt;/em&gt; к &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;оценщик&lt;/a&gt; , чтобы быть в состоянии &lt;em&gt;предсказать&lt;/em&gt; классы , к которым невидимые образцы принадлежат.</target>
        </trans-unit>
        <trans-unit id="0484e6facaecfeba6a4ff8e0552fa9a5ac1c52dd" translate="yes" xml:space="preserve">
          <source>In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if &lt;code&gt;method&lt;/code&gt; produces columns per class, as in {&amp;lsquo;decision_function&amp;rsquo;, &amp;lsquo;predict_proba&amp;rsquo;, &amp;lsquo;predict_log_proba&amp;rsquo;}. For &lt;code&gt;predict_proba&lt;/code&gt; this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.</source>
          <target state="translated">В случае, если один или несколько классов отсутствуют в обучающей части, оценка по умолчанию должна быть назначена всем экземплярам для этого класса, если &lt;code&gt;method&lt;/code&gt; создает столбцы для каждого класса, как в {'solution_function', 'pred_proba', 'pred_log_proba'} . Для &lt;code&gt;predict_proba&lt;/code&gt; это значение равно 0. Чтобы гарантировать конечный результат, мы аппроксимируем отрицательную бесконечность минимальным конечным значением с плавающей запятой для dtype в других случаях.</target>
        </trans-unit>
        <trans-unit id="74ff5bfdda6b3e93f59169f7c22fc2d68fa3fcf3" translate="yes" xml:space="preserve">
          <source>In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model&amp;rsquo;s decision_function method directly as the input of inverse_transform.</source>
          <target state="translated">В случае, когда двоичные метки дробные (вероятностные), inverse_transform выбирает класс с наибольшим значением. Как правило, это позволяет использовать выходные данные метода линейной модели solution_function непосредственно в качестве входных данных inverse_transform.</target>
        </trans-unit>
        <trans-unit id="2d852af4ac330c07eec96a31a9559a88b3b70655" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;code&gt;VotingClassifier&lt;/code&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">В случае ничьей &lt;code&gt;VotingClassifier&lt;/code&gt; выберет класс в порядке возрастания. Например, в следующем сценарии</target>
        </trans-unit>
        <trans-unit id="84352a0fa93e8d3c09e63ba562819b09bff22e0e" translate="yes" xml:space="preserve">
          <source>In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:</source>
          <target state="translated">В случае шахматной доски каждая строка принадлежит всем кластерам столбцов,и каждый столбец принадлежит всем кластерам строк.Приведем пример такой структуры,где дисперсия значений внутри каждого билюстра невелика:</target>
        </trans-unit>
        <trans-unit id="6a06bacf0f95acd504bad8493dc228833ae72576" translate="yes" xml:space="preserve">
          <source>In the event that the 95% confidence interval based on Fisher transform spans zero, a warning is raised.</source>
          <target state="translated">В случае,если доверительный интервал 95%,основанный на преобразовании Фишера,охватывает ноль,повышается предупреждение.</target>
        </trans-unit>
        <trans-unit id="2da0fe066fd806cee05903c8f41b8c38bb726d66" translate="yes" xml:space="preserve">
          <source>In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.</source>
          <target state="translated">В приведенном ниже примере использование небольшого усадочного порога увеличивает точность модели с 0,81 до 0,82.</target>
        </trans-unit>
        <trans-unit id="ae3527cc8009043f3459062f8b3ac5f4c7cdc080" translate="yes" xml:space="preserve">
          <source>In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.</source>
          <target state="translated">На рисунке ниже цвет обозначает принадлежность к кластерам,а большие кружки указывают на найденные алгоритмом образцы ядра.Маленькие круги-это неосновные образцы,которые все еще являются частью кластера.Более того,отклонения обозначаются черными точками внизу.</target>
        </trans-unit>
        <trans-unit id="a915ebedbc9fc712ae336eb7409727fc370425dc" translate="yes" xml:space="preserve">
          <source>In the first row, the classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.</source>
          <target state="translated">В первом ряду классификаторы построены с использованием только ширины чашелистики и длины чашелистики,во втором ряду только с использованием длины лепестка и длины чашелистики,а в третьем ряду только с использованием ширины лепестка и длины лепестка.</target>
        </trans-unit>
        <trans-unit id="bd9366b471cf174a5dc26260b1ee3e4775bd8a95" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1, 1, 1]:</source>
          <target state="translated">В следующем примере мы создаем класс NeighborsClassifier из массива, представляющего наш набор данных, и спрашиваем, кто ближайшая точка к [1, 1, 1]:</target>
        </trans-unit>
        <trans-unit id="f873541d5e32ccd97b454877a7265b9e862eeb9a" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">В следующем примере мы создаем класс NeighborsClassifier из массива, представляющего наш набор данных, и спрашиваем, кто ближайшая точка к [1,1,1]</target>
        </trans-unit>
        <trans-unit id="65f9f2f58e8b0fd298381aa88835a40b1607c17f" translate="yes" xml:space="preserve">
          <source>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</source>
          <target state="translated">На следующем рисунке из бимодального распределения взято 100 точек,а для трех вариантов ядра показаны оценки плотности:</target>
        </trans-unit>
        <trans-unit id="24263a7351535bc4435386a661d4637b721eb5a0" translate="yes" xml:space="preserve">
          <source>In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).</source>
          <target state="translated">На следующем рисунке мы видим функцию \(f(x)=\cos (\frac{3}{2}\pi x)\)и некоторые шумные примеры из этой функции.Для подгонки функции мы используем три различных оценочных параметра:линейную регрессию с полиномиальными признаками степени 1,4 и 15.Мы видим,что первый оценщик в лучшем случае может обеспечить только плохое соответствие выборки и истинной функции,так как она слишком проста (большое смещение),второй оценщик аппроксимирует ее почти идеально,а последний оценщик аппроксимирует тренировочные данные идеально,но не очень хорошо подходит к истинной функции,т.е.очень чувствительна к различным тренировочным данным (высокая дисперсия).</target>
        </trans-unit>
        <trans-unit id="de54ef0bf525631d31eb0623dcd55f8a9ddc120b" translate="yes" xml:space="preserve">
          <source>In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.</source>
          <target state="translated">В следующих подразделах мы опишем каждую из этих функций,чему предшествуют некоторые заметки об общем API и метрическом определении.</target>
        </trans-unit>
        <trans-unit id="7549668dfe247eb9e0e172cc89f620a63604992b" translate="yes" xml:space="preserve">
          <source>In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; function by pointing it to the &lt;code&gt;20news-bydate-train&lt;/code&gt; sub-folder of the uncompressed archive folder.</source>
          <target state="translated">Далее мы будем использовать встроенный загрузчик набора данных для 20 групп новостей из scikit-learn. В качестве альтернативы можно загрузить набор данных вручную с веб-сайта и использовать функцию &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; , указав ее в &lt;code&gt;20news-bydate-train&lt;/code&gt; папки несжатого архива.</target>
        </trans-unit>
        <trans-unit id="2cb0b9817ecf09ea4893bb9df9d328ce75ef2d1b" translate="yes" xml:space="preserve">
          <source>In the following, &amp;ldquo;city&amp;rdquo; is a categorical attribute while &amp;ldquo;temperature&amp;rdquo; is a traditional numerical feature:</source>
          <target state="translated">В дальнейшем &amp;laquo;город&amp;raquo; - это категориальный атрибут, а &amp;laquo;температура&amp;raquo; - это традиционный числовой показатель:</target>
        </trans-unit>
        <trans-unit id="3e019b4cbe3ce7f1554fa08ce08898c560cb8a3b" translate="yes" xml:space="preserve">
          <source>In the following, we start a Python interpreter from our shell and then load the &lt;code&gt;iris&lt;/code&gt; and &lt;code&gt;digits&lt;/code&gt; datasets. Our notational convention is that &lt;code&gt;$&lt;/code&gt; denotes the shell prompt while &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denotes the Python interpreter prompt:</source>
          <target state="translated">Далее мы запускаем интерпретатор Python из нашей оболочки, а затем загружаем наборы данных &lt;code&gt;iris&lt;/code&gt; и &lt;code&gt;digits&lt;/code&gt; . Наше условное обозначение таково, что &lt;code&gt;$&lt;/code&gt; обозначает приглашение оболочки, а &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; обозначает приглашение интерпретатора Python:</target>
        </trans-unit>
        <trans-unit id="fe30ab8cfcc104ee94b5fb01793274570a377034" translate="yes" xml:space="preserve">
          <source>In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:</source>
          <target state="translated">В приведенной выше формуле \(\mathbf{b}\)и \(\mathbf{c}\)являются векторами перехвата для видимого и скрытого слоев соответственно.Совместная вероятность модели определяется с точки зрения энергии:</target>
        </trans-unit>
        <trans-unit id="66070e8da21856ec34fc0b507e5d723e9475a567" translate="yes" xml:space="preserve">
          <source>In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">В случае с несколькими классами и несколькими метками это средний балл F1 каждого класса с взвешиванием, зависящим от &lt;code&gt;average&lt;/code&gt; параметра.</target>
        </trans-unit>
        <trans-unit id="47604d7ff8f733fb868ecbca5a77b859a57fe5aa" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the Matthews correlation coefficient can be &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;defined&lt;/a&gt; in terms of a &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt;\(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:</source>
          <target state="translated">В случае мультикласса коэффициент корреляции Мэтьюза может быть &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;определен&lt;/a&gt; в терминах &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; \ (C \) для классов \ (K \). Чтобы упростить определение, рассмотрим следующие промежуточные переменные:</target>
        </trans-unit>
        <trans-unit id="b8d01a57cb617acafda7dfb6fdd570d7cb46be7c" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross- entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">В случае мультикласса алгоритм обучения использует схему one-vs-rest (OvR), если опция multi_class установлена ​​на ovr, и использует потерю кросс-энтропии, если опция multi_class установлена ​​на multinomial '. (В настоящее время опция 'multinomial' поддерживается только решателями 'lbfgs', 'sag' и 'newton-cg'.)</target>
        </trans-unit>
        <trans-unit id="0fc004eb44e3b89b80f2b6796f35d04551e921cc" translate="yes" xml:space="preserve">
          <source>In the multiclass case:</source>
          <target state="translated">В случае мультикласса:</target>
        </trans-unit>
        <trans-unit id="d77598124fa8bad46b51e89decd127c4c83bc1e3" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators, where the first label set [0,1] has an error:</source>
          <target state="translated">В случае с многомаркировочными индикаторами бинарных этикеток,где первый набор этикеток [0,1]имеет ошибку:</target>
        </trans-unit>
        <trans-unit id="4557110f167a92f3d0af48823270c458eb95839b" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators:</source>
          <target state="translated">В многомаркировочном корпусе с индикаторами бинарных этикеток:</target>
        </trans-unit>
        <trans-unit id="3dbb497f0422701e359a6bab16a477019a81aa92" translate="yes" xml:space="preserve">
          <source>In the multilabel learning literature, OvR is also known as the binary relevance method.</source>
          <target state="translated">В учебной литературе по многомаркировке OvR также известен как метод двоичной релевантности.</target>
        </trans-unit>
        <trans-unit id="b098a0ed402e179dee6b5de05c6210f893507735" translate="yes" xml:space="preserve">
          <source>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by &lt;code&gt;transform&lt;/code&gt; will typically be dense.</source>
          <target state="translated">В новом пространстве каждое измерение - это расстояние до центров кластеров. Обратите внимание, что даже если X является разреженным, массив, возвращаемый &lt;code&gt;transform&lt;/code&gt; , обычно будет плотным.</target>
        </trans-unit>
        <trans-unit id="a90aa674a36fbb7c4f65ac18f5e6a5a0eb4c7bc3" translate="yes" xml:space="preserve">
          <source>In the official &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; this task is described as the &amp;ldquo;Restricted&amp;rdquo; task. As I am not sure as to implement the &amp;ldquo;Unrestricted&amp;rdquo; variant correctly, I left it as unsupported for now.</source>
          <target state="translated">В официальном &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; эта задача описана как &amp;laquo;Ограниченная&amp;raquo;. Поскольку я не уверен, что правильно реализую вариант &amp;laquo;Без ограничений&amp;raquo;, я оставил его как неподдерживаемый на данный момент.</target>
        </trans-unit>
        <trans-unit id="901c760a214576d30b4ced7bbcce771984b42233" translate="yes" xml:space="preserve">
          <source>In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.</source>
          <target state="translated">В простой одномерной задаче,которую мы видели в примере,легко увидеть,страдает ли оценщик от смещения или дисперсии.Однако в высокоразмерных пространствах модели могут стать очень трудно визуализируемыми.По этой причине часто бывает полезно использовать инструменты,описанные ниже.</target>
        </trans-unit>
        <trans-unit id="bada0a0c8458a65354b2c23e7134e865cc4bf85c" translate="yes" xml:space="preserve">
          <source>In the single label multiclass case, the rows of the returned matrix sum to 1.</source>
          <target state="translated">В случае с одной этикеткой мультикласса,строки возвращаемой матрицы складываются в 1.</target>
        </trans-unit>
        <trans-unit id="696912c12d134eed0fdc2e472302634288905dc5" translate="yes" xml:space="preserve">
          <source>In the small-samples situation, in which &lt;code&gt;n_samples&lt;/code&gt; is on the order of &lt;code&gt;n_features&lt;/code&gt; or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.</source>
          <target state="translated">В ситуации с малыми выборками, когда &lt;code&gt;n_samples&lt;/code&gt; имеет порядок &lt;code&gt;n_features&lt;/code&gt; или меньше, разреженные оценки обратной ковариации, как правило, работают лучше, чем оценки сжатой ковариации. Однако в противоположной ситуации или для сильно коррелированных данных они могут быть численно нестабильными. Кроме того, в отличие от оценщиков усадки, разреженные оценщики способны восстанавливать недиагональную структуру.</target>
        </trans-unit>
        <trans-unit id="d5f33dda5b96ece3c041650e9fa8db02e62bfd46" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">В конкретном случае scikit-learn может быть лучше использовать замену pickle в &lt;code&gt;joblib.dump&lt;/code&gt; ( joblib.dump &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), которая более эффективна для объектов, которые несут большие массивы numpy внутри, как это часто бывает для встроенных scikit- выучить оценщики, но можно копировать только на диск, а не на строку:</target>
        </trans-unit>
        <trans-unit id="4d7c6f4a78fb7d42f5b6b076760e4c0fb27e052c" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be more interesting to use joblib&amp;rsquo;s replacement for pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on big data but it can only pickle to the disk and not to a string:</source>
          <target state="translated">В конкретном случае scikit-learn может быть более интересным использовать замену joblib для pickle ( &lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt; ), которая более эффективна для больших данных, но может обрабатывать только диск, а не строку :</target>
        </trans-unit>
        <trans-unit id="4e8940d2e745f9a24bd23b0a1547dcf715a870bb" translate="yes" xml:space="preserve">
          <source>In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification.</source>
          <target state="translated">В общем наборе функций значимы только 4 первых.Мы видим,что они набрали наибольшее количество баллов при одномерном выборе функций.SVM присваивает большой вес одной из этих функций,но также выбирает многие из неинформативных функций.Применение одномерного выделения функций до SVM увеличивает вес SVM,присваиваемый значимым функциям,и,таким образом,улучшает классификацию.</target>
        </trans-unit>
        <trans-unit id="a3dd53135ff49dbe7e421a248bf614a3ea8f0d5e" translate="yes" xml:space="preserve">
          <source>In the vector quantization literature, &lt;code&gt;cluster_centers_&lt;/code&gt; is called the code book and each value returned by &lt;code&gt;predict&lt;/code&gt; is the index of the closest code in the code book.</source>
          <target state="translated">В литературе по векторному квантованию &lt;code&gt;cluster_centers_&lt;/code&gt; называется кодовой книгой, и каждое значение, возвращаемое &lt;code&gt;predict&lt;/code&gt; является индексом ближайшего кода в кодовой книге.</target>
        </trans-unit>
        <trans-unit id="9a63d5086bf9614df56a7612405271e0122a8145" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">В своей статье 2004 г. &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; О. Ледуа и М. Вольф предлагают формулу для вычисления оптимального коэффициента усадки \ (\ alpha \), который минимизирует среднеквадратичную ошибку между оцененной и реальной ковариационной матрицей.</target>
        </trans-unit>
        <trans-unit id="ee9767309b3df05ebf7c392a0bb4e8915eee3d46" translate="yes" xml:space="preserve">
          <source>In these settings, the &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; approach solves the problem know as &amp;lsquo;normalized graph cuts&amp;rsquo;: the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</source>
          <target state="translated">В этих настройках подход &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;спектральной кластеризации&lt;/a&gt; решает проблему, известную как &amp;laquo;нормализованные разрезы графа&amp;raquo;: изображение рассматривается как граф связанных вокселей, а алгоритм спектральной кластеризации сводится к выбору разрезов графа, определяющих области, при минимизации соотношения градиента вдоль разрез, и объем области.</target>
        </trans-unit>
        <trans-unit id="e2e4475ec0999dd975ba681e19179d817d6681ae" translate="yes" xml:space="preserve">
          <source>In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.</source>
          <target state="translated">В этом случае нам хотелось бы знать,хорошо ли обобщена модель,обученная по определенному набору групп,к невидимым группам.Чтобы измерить это,мы должны убедиться,что все образцы в папке валидации пришли из групп,которые вообще не представлены в парной тренировочной папке.</target>
        </trans-unit>
        <trans-unit id="8e6586aaac37d3a887b7276aee6797fdd6471b11" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features:</source>
          <target state="translated">В этом случае &lt;code&gt;X_train&lt;/code&gt; и &lt;code&gt;X_test&lt;/code&gt; гарантированно имеют одинаковое количество функций. Другой способ добиться того же результата - исправить ряд функций:</target>
        </trans-unit>
        <trans-unit id="c94c921d6a6a8582b29da8ef5a3a44fe1ea80a89" translate="yes" xml:space="preserve">
          <source>In this case, the classifier is fit upon instances each assigned multiple labels. The &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; is used to binarize the 2d array of multilabels to &lt;code&gt;fit&lt;/code&gt; upon. As a result, &lt;code&gt;predict()&lt;/code&gt; returns a 2d array with multiple predicted labels for each instance.</source>
          <target state="translated">В этом случае классификатор подходит для экземпляров, каждому из которых присвоено несколько меток. &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; используется для бинаризации в 2d массива multilabels в &lt;code&gt;fit&lt;/code&gt; после. В результате прогноз &lt;code&gt;predict()&lt;/code&gt; возвращает двумерный массив с несколькими предсказанными метками для каждого экземпляра.</target>
        </trans-unit>
        <trans-unit id="4367a423584d0b6ba622189fa17b21bb3e206f2c" translate="yes" xml:space="preserve">
          <source>In this case, the cross-validation retained the same ratio of classes across each CV split. Next we&amp;rsquo;ll visualize this behavior for a number of CV iterators.</source>
          <target state="translated">В этом случае перекрестная проверка сохранила одинаковое соотношение классов по каждому разделению резюме. Далее мы визуализируем это поведение для ряда итераторов CV.</target>
        </trans-unit>
        <trans-unit id="d121f450bc55250670235f93c8cd2083eb40a561" translate="yes" xml:space="preserve">
          <source>In this context, we can define the notions of precision, recall and F-measure:</source>
          <target state="translated">В этом контексте мы можем определить понятия точности,вспоминания и F-измерения:</target>
        </trans-unit>
        <trans-unit id="6b7e5d4a758a26d1b659ba54387246d5cebcf12f" translate="yes" xml:space="preserve">
          <source>In this example the dependent variable Y is set as a function of the input features: y = X*w + c. The coefficient vector w is randomly sampled from a normal distribution, whereas the bias term c is set to a constant.</source>
          <target state="translated">В данном примере зависимая переменная Y задается как функция входных признаков:y=X*w+c.Вектор коэффициента w случайным образом выбирается из нормального распределения,а член смещения c задается константой.</target>
        </trans-unit>
        <trans-unit id="5d530c717737ac885c81ddc70c9c4fe51f2f2e42" translate="yes" xml:space="preserve">
          <source>In this example the silhouette analysis is used to choose an optimal value for &lt;code&gt;n_clusters&lt;/code&gt;. The silhouette plot shows that the &lt;code&gt;n_clusters&lt;/code&gt; value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.</source>
          <target state="translated">В этом примере анализ силуэта используется для выбора оптимального значения для &lt;code&gt;n_clusters&lt;/code&gt; . График силуэта показывает, что значения &lt;code&gt;n_clusters&lt;/code&gt; 3, 5 и 6 - плохой выбор для данных данных из-за наличия кластеров с оценками силуэта ниже среднего, а также из-за значительных колебаний в размере графиков силуэтов. Анализ силуэта более неоднозначен при выборе между 2 и 4.</target>
        </trans-unit>
        <trans-unit id="550c896ceafe31d2e76547c4031642097a79581f" translate="yes" xml:space="preserve">
          <source>In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.</source>
          <target state="translated">В данном примере мы сравниваем различные стратегии инициализации K-средних по времени исполнения и качеству результатов.</target>
        </trans-unit>
        <trans-unit id="d9bed364e1f96090d42e72d8ad4e31b8f81dfc1d" translate="yes" xml:space="preserve">
          <source>In this example we prefer the &lt;code&gt;elasticnet&lt;/code&gt; penalty as it is often a good compromise between model compactness and prediction power. One can also further tune the &lt;code&gt;l1_ratio&lt;/code&gt; parameter (in combination with the regularization strength &lt;code&gt;alpha&lt;/code&gt;) to control this tradeoff.</source>
          <target state="translated">В этом примере мы предпочитаем штраф за &lt;code&gt;elasticnet&lt;/code&gt; поскольку это часто является хорошим компромиссом между компактностью модели и мощностью прогнозирования. Можно также дополнительно настроить параметр &lt;code&gt;l1_ratio&lt;/code&gt; (в сочетании с силой регуляризации &lt;code&gt;alpha&lt;/code&gt; ), чтобы контролировать этот компромисс.</target>
        </trans-unit>
        <trans-unit id="5f4ca84332e1fc2168e90c43c86e1d784ebd5f8c" translate="yes" xml:space="preserve">
          <source>In this example we see how to robustly fit a linear model to faulty data using the RANSAC algorithm.</source>
          <target state="translated">В данном примере мы видим,как с помощью алгоритма RANSAC надежно подогнать линейную модель к ошибочным данным.</target>
        </trans-unit>
        <trans-unit id="38fc37287fc51222e73dd7c83e6c92e563107ff6" translate="yes" xml:space="preserve">
          <source>In this example you might try to:</source>
          <target state="translated">В этом примере вы можете попытаться:</target>
        </trans-unit>
        <trans-unit id="8a61e0fa0737723bbfe9d0174ce3aad285419f4d" translate="yes" xml:space="preserve">
          <source>In this example, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;float32&lt;/code&gt;, which is cast to &lt;code&gt;float64&lt;/code&gt; by &lt;code&gt;fit_transform(X)&lt;/code&gt;.</source>
          <target state="translated">В этом примере &lt;code&gt;X&lt;/code&gt; - это &lt;code&gt;float32&lt;/code&gt; , который приводится к &lt;code&gt;float64&lt;/code&gt; с помощью &lt;code&gt;fit_transform(X)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2812da8873763c11175cae962f9ab9000ab381c4" translate="yes" xml:space="preserve">
          <source>In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.</source>
          <target state="translated">В этом примере генерируется изображение с соединенными окружностями,а для разделения окружностей используется спектральная кластеризация.</target>
        </trans-unit>
        <trans-unit id="69af0b849be70a0524a821dde21a609feb16811a" translate="yes" xml:space="preserve">
          <source>In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.</source>
          <target state="translated">В данном примере пиксели представлены в 3D-пространстве,а K-средние используются для поиска 64 цветовых кластеров.В литературе по обработке изображений кодовая книга,полученная из К-средних (кластерные центры),называется цветовой палитрой.С помощью одного байта можно адресовать до 256 цветов,в то время как для кодирования RGB требуется 3 байта на пиксел.Формат GIF-файлов,например,использует такую палитру.</target>
        </trans-unit>
        <trans-unit id="2f0fb947da0f2bfc5faf32b771a3cb10ff049eda" translate="yes" xml:space="preserve">
          <source>In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category (&lt;code&gt;'missing'&lt;/code&gt;).</source>
          <target state="translated">В этом примере числовые данные стандартно масштабируются после вменения среднего значения, в то время как категориальные данные кодируются в горячем режиме после вменения отсутствующих значений в новую категорию ( &lt;code&gt;'missing'&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="d88656bc2e040320cf9595554acac12be98f916c" translate="yes" xml:space="preserve">
          <source>In this example, we compare the estimation errors that are made when using various types of location and covariance estimates on contaminated Gaussian distributed data sets:</source>
          <target state="translated">В этом примере мы сравниваем ошибки оценки,которые делаются при использовании различных типов оценок местоположения и ковариаций на загрязненных гауссовских распределенных наборах данных:</target>
        </trans-unit>
        <trans-unit id="2b7bcaf87ef3b0730f7083836942b0b038810927" translate="yes" xml:space="preserve">
          <source>In this example, we give an overview of the &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt;&lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt;&lt;/a&gt;. Two examples illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Boston housing data set.</source>
          <target state="translated">В этом примере мы даем обзор &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt; &lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt; &lt;/a&gt; . Два примера демонстрируют преимущества преобразования целей перед изучением модели линейной регрессии. В первом примере используются синтетические данные, а во втором примере - набор данных о жилищном строительстве в Бостоне.</target>
        </trans-unit>
        <trans-unit id="fd9410f53a0f1d1aa2f5ff77c7bafaf9751d4c08" translate="yes" xml:space="preserve">
          <source>In this example, we set the value of &lt;code&gt;gamma&lt;/code&gt; manually. To find good values for these parameters, we can use tools such as &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; and &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;.</source>
          <target state="translated">В этом примере мы устанавливаем значение &lt;code&gt;gamma&lt;/code&gt; вручную. Чтобы найти подходящие значения для этих параметров, мы можем использовать такие инструменты, как &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;поиск по сетке&lt;/a&gt; и &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;перекрестная проверка&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9e0782ea6d7859077c07d60aaa0a30b1c4373f50" translate="yes" xml:space="preserve">
          <source>In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.</source>
          <target state="translated">На этом графике вы можете увидеть обучающие и проверочные оценки SVM для различных значений гамма-параметра ядра.Для очень низких значений гаммы,вы можете видеть,что и оценка обучения и оценка валидации низкие.Это называется подгонкой.Средние значения гаммы приведут к высоким значениям для обоих баллов,т.е.классификатор работает достаточно хорошо.Если гамма слишком высока,то классификатор будет переоснащаться,что означает,что тренировочный балл хороший,а валидационный балл плохой.</target>
        </trans-unit>
        <trans-unit id="2c39a03080473177a8509645110953edafebbd76" translate="yes" xml:space="preserve">
          <source>In this scheme, features and samples are defined as follows:</source>
          <target state="translated">В этой схеме особенности и образцы определяются следующим образом:</target>
        </trans-unit>
        <trans-unit id="5941fbb58c226f551ff80660bcd51a84bcc2bae1" translate="yes" xml:space="preserve">
          <source>In this section we will see how to:</source>
          <target state="translated">В этом разделе мы посмотрим,как это сделать:</target>
        </trans-unit>
        <trans-unit id="6ce5845b6414a0cfccffc603f3efdd4b47c7ce4b" translate="yes" xml:space="preserve">
          <source>In this section, we introduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; vocabulary that we use throughout scikit-learn and give a simple learning example.</source>
          <target state="translated">В этом разделе мы познакомим вас со словарем &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;машинного обучения,&lt;/a&gt; который мы используем в scikit-learn, и дадим простой обучающий пример.</target>
        </trans-unit>
        <trans-unit id="e7b54ae8e73f20fa370a273bbb52814367b82582" translate="yes" xml:space="preserve">
          <source>In this snippet we make use of a &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt; coupled with &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; to evaluate feature importances and select the most relevant features. Then, a &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt;&lt;/a&gt; is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt; examples for more details.</source>
          <target state="translated">В этом фрагменте мы используем &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; в&lt;/a&gt; сочетании с &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; для оценки важности функций и выбора наиболее важных функций. Затем &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt; &lt;/a&gt; обучается на преобразованном выходе, то есть с использованием только соответствующих функций. Вы можете выполнять аналогичные операции с другими методами выбора функций, а также с классификаторами, которые, конечно, предоставляют способ оценки важности функций. См. Примеры &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="87aee0924ee2a28e2d573efd8e050c2a5c1632a3" translate="yes" xml:space="preserve">
          <source>In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple &lt;code&gt;continuous latent variable&lt;/code&gt; model for \(X\) is</source>
          <target state="translated">При обучении без учителя у нас есть только набор данных \ (X = \ {x_1, x_2, \ dots, x_n \} \). Как можно математически описать этот набор данных? Очень простая модель &lt;code&gt;continuous latent variable&lt;/code&gt; для \ (X \) - это</target>
        </trans-unit>
        <trans-unit id="c89a6ca6f29b888687c7afd577a282b5b95a2be5" translate="yes" xml:space="preserve">
          <source>Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as &lt;em&gt;data leakage&lt;/em&gt;), for example in the case of scalers or imputing missing values.</source>
          <target state="translated">Включение статистики из тестовых данных в препроцессоры делает результаты перекрестной проверки ненадежными (известными как &lt;em&gt;утечка данных&lt;/em&gt; ), например, в случае масштабаторов или вменения пропущенных значений.</target>
        </trans-unit>
        <trans-unit id="4c33f1e1286c254eaae3fbe03197d5578f08f56a" translate="yes" xml:space="preserve">
          <source>Increasing &lt;code&gt;max_depth&lt;/code&gt; for AdaBoost lowers the standard deviation of the scores (but the average score does not improve).</source>
          <target state="translated">Увеличение &lt;code&gt;max_depth&lt;/code&gt; для AdaBoost снижает стандартное отклонение оценок (но средний балл не улучшается).</target>
        </trans-unit>
        <trans-unit id="e79b1358981354168a853701629e2643ba45bf93" translate="yes" xml:space="preserve">
          <source>Increasing false positive rates such that element i is the false positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Увеличение количества ложных срабатываний, так что элемент i является показателем ложных срабатываний прогнозов с оценкой&amp;gt; = пороговые значения [i].</target>
        </trans-unit>
        <trans-unit id="3ca08d3a2216068596512fa76cc1f85e2464a3a8" translate="yes" xml:space="preserve">
          <source>Increasing thresholds on the decision function used to compute precision and recall.</source>
          <target state="translated">Увеличение пороговых значений функции принятия решений,используемой для расчета точности и вызова.</target>
        </trans-unit>
        <trans-unit id="7ae5f53b337e575381bac1d47d2d4a4d2e4839b6" translate="yes" xml:space="preserve">
          <source>Increasing true positive rates such that element i is the true positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">Увеличение истинно положительных показателей, так что элемент i является истинно положительным показателем прогнозов с оценкой&amp;gt; = пороговые значения [i].</target>
        </trans-unit>
        <trans-unit id="54206634ab03f8962d59d7c24e12c85ebd45b5e1" translate="yes" xml:space="preserve">
          <source>Incremental PCA</source>
          <target state="translated">Инкрементальный PCA</target>
        </trans-unit>
        <trans-unit id="acaf3165fc4e0ddec759b9648ee12eed48089691" translate="yes" xml:space="preserve">
          <source>Incremental fit on a batch of samples.</source>
          <target state="translated">Инкрементная посадка на партию образцов.</target>
        </trans-unit>
        <trans-unit id="a79a34aec33f8c8b084e4316cf8e243a4d6601e6" translate="yes" xml:space="preserve">
          <source>Incremental fit with X.</source>
          <target state="translated">Инкрементальная посадка с Х.</target>
        </trans-unit>
        <trans-unit id="87210470540ea5af2ee40f330fdeea4017f1c0aa" translate="yes" xml:space="preserve">
          <source>Incremental fit with X. All of X is processed as a single batch.</source>
          <target state="translated">Инкрементная посадка с Х.Все Х обрабатывается как одна партия.</target>
        </trans-unit>
        <trans-unit id="5b9d567927b0a80924b0a28fdea6cf19b23d2e57" translate="yes" xml:space="preserve">
          <source>Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.</source>
          <target state="translated">Инкрементный анализ основных компонентов (IPCA)обычно используется в качестве замены анализа основных компонентов (PCA),когда разлагаемый набор данных слишком велик,чтобы поместиться в память.IPCA строит низкоуровневую аппроксимацию для входных данных,используя объем памяти,который не зависит от количества образцов входных данных.Она все еще зависит от особенностей входных данных,но изменение размера партии позволяет контролировать использование памяти.</target>
        </trans-unit>
        <trans-unit id="66088e706ece2d903ed2071fa2d42be9315774b6" translate="yes" xml:space="preserve">
          <source>Incremental principal components analysis (IPCA).</source>
          <target state="translated">Инкрементальный анализ основных компонентов (IPCA).</target>
        </trans-unit>
        <trans-unit id="ef7722207a6c2343d08e45f401cd00ccd19381c7" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data.</source>
          <target state="translated">Инкрементально подогнать модель под данные.</target>
        </trans-unit>
        <trans-unit id="505bf67b8aa7cec37d64a9ce9b03d73f70b38b8b" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">Инкрементально подогнать модель под данные.Подгоните отдельную модель для каждой выходной переменной.</target>
        </trans-unit>
        <trans-unit id="9e12e704fa3eb16be83d58c2167c9c4f83379a1d" translate="yes" xml:space="preserve">
          <source>Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.</source>
          <target state="translated">Действительно,многие оценщики разрабатываются исходя из предположения,что каждый элемент принимает значения,близкие к нулю,или,что более важно,что все элементы различаются на сопоставимых шкалах.В частности,оценщики на основе метрик и градиентов часто предполагают приблизительно стандартизированные данные (центрированные характеристики с отклонениями в единицах).Заметным исключением являются оценки на основе дерева решений,которые устойчивы к произвольному масштабированию данных.</target>
        </trans-unit>
        <trans-unit id="7933c6d72de999f40e22d3286d9c782fd636305b" translate="yes" xml:space="preserve">
          <source>Independent Component Analysis: ICA</source>
          <target state="translated">Независимый компонентный анализ:ICA</target>
        </trans-unit>
        <trans-unit id="d170598045cdc9e2df037718a96d1706ed03e640" translate="yes" xml:space="preserve">
          <source>Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;Fast ICA&lt;/code&gt;&lt;/a&gt; algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.</source>
          <target state="translated">Независимый компонентный анализ разделяет многомерный сигнал на аддитивные подкомпоненты, которые максимально независимы. Это реализовано в scikit-learn с использованием алгоритма &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;Fast ICA&lt;/code&gt; &lt;/a&gt; . Обычно ICA используется не для уменьшения размерности, а для разделения наложенных сигналов. Поскольку модель ICA не включает термин &amp;laquo;шум&amp;raquo;, для того, чтобы модель была правильной, необходимо применить отбеливание. Это можно сделать внутренне, используя аргумент whiten, или вручную, используя один из вариантов PCA.</target>
        </trans-unit>
        <trans-unit id="420bdf88d0c37e0c49c684e7be83be0c3065749b" translate="yes" xml:space="preserve">
          <source>Independent component analysis, a latent variable model with non-Gaussian latent variables.</source>
          <target state="translated">Независимый компонентный анализ,модель латентных переменных с негауссовыми латентными переменными.</target>
        </trans-unit>
        <trans-unit id="e81fd2ba1ed4351b51becec6b3e044be03272d29" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel.</source>
          <target state="translated">Независимый параметр в поли/сигмоидном ядре.</target>
        </trans-unit>
        <trans-unit id="75b2e172573134b992419919380eaa4d379125c8" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel. 0 by default.</source>
          <target state="translated">Независимый параметр в поли/сигмоидном ядре.0 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="93ccb8f475af3ead0828a4d704d80fd7c1bcca2a" translate="yes" xml:space="preserve">
          <source>Independent term in decision function.</source>
          <target state="translated">Независимый срок в функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="d60b4ce63cb13d9b546e71bb468305b122e1ff12" translate="yes" xml:space="preserve">
          <source>Independent term in decision function. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">Независимый член в функции принятия решения. Установите 0,0, если &lt;code&gt;fit_intercept = False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="62ca36e367478a373b265bf6692ac1dd0b87c736" translate="yes" xml:space="preserve">
          <source>Independent term in kernel function. It is only significant in &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">Независимый член в функции ядра. Он имеет значение только в &amp;laquo;поли&amp;raquo; и &amp;laquo;сигмовиде&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="498514c5789196d4e7f38be6d2ccefad9084f660" translate="yes" xml:space="preserve">
          <source>Independent term in poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Независимый термин в поли-и сигмовидных ядрах.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="c818388cffefe0c1449b9099e6b8c434f2466b05" translate="yes" xml:space="preserve">
          <source>Independent term in the decision function.</source>
          <target state="translated">Независимый срок в функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="b8069da00c91cf6e966b739b57f9cbe347e859d2" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model.</source>
          <target state="translated">Независимый термин в линейной модели.</target>
        </trans-unit>
        <trans-unit id="5c78017fad7dc4be13e21b61b07a09cb5931df33" translate="yes" xml:space="preserve">
          <source>Index of the cluster each sample belongs to.</source>
          <target state="translated">Индекс кластера,к которому принадлежит каждая выборка.</target>
        </trans-unit>
        <trans-unit id="79bbc01c7afbd569e88078c06011f6a142dc18ba" translate="yes" xml:space="preserve">
          <source>Index of the column of X to be swapped.</source>
          <target state="translated">Индекс столбца X для замены.</target>
        </trans-unit>
        <trans-unit id="ed1d58c02de7a13d74564b832a9effc7dd7512f7" translate="yes" xml:space="preserve">
          <source>Index of the row of X to be swapped.</source>
          <target state="translated">Индекс строки X,которую нужно поменять.</target>
        </trans-unit>
        <trans-unit id="ec76f2d92b2be403363a104dc4a87849c9c331a9" translate="yes" xml:space="preserve">
          <source>Indexable data-structures can be arrays, lists, dataframes or scipy sparse matrices with consistent first dimension.</source>
          <target state="translated">Индексируемыми структурами данных могут быть массивы,списки,кадры данных или научные разрозненные матрицы с последовательным первым измерением.</target>
        </trans-unit>
        <trans-unit id="436737ead6b730ec05aa4979d3ab186eb46b0b4a" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above.</source>
          <target state="translated">Индексирует данные на своей второй оси. Целые числа интерпретируются как позиционные столбцы, а строки могут ссылаться на столбцы DataFrame по имени. Скалярная строка или int должна использоваться там, где &lt;code&gt;transformer&lt;/code&gt; ожидает, что X будет 1d массивом (вектором), иначе 2d массив будет передан преобразователю. Вызываемому объекту передаются входные данные &lt;code&gt;X&lt;/code&gt; , и он может возвращать любые из вышеперечисленных.</target>
        </trans-unit>
        <trans-unit id="33324894ea0a98c1ef1f880dc97967e00c913318" translate="yes" xml:space="preserve">
          <source>Indicate that func accepts a sparse matrix as input. If validate is False, this has no effect. Otherwise, if accept_sparse is false, sparse matrix inputs will cause an exception to be raised.</source>
          <target state="translated">Укажите,что эта функция принимает на вход разреженную матрицу.Если валидная-False,то это не имеет никакого эффекта.Иначе,если accept_sparse будет ложным,то разреженные входные данные матрицы вызовут исключение.</target>
        </trans-unit>
        <trans-unit id="eb7cd0d8cb7fae1e80a3e28d3771772ae8884b48" translate="yes" xml:space="preserve">
          <source>Indicate that the input X array should be checked before calling &lt;code&gt;func&lt;/code&gt;. The possibilities are:</source>
          <target state="translated">Укажите, что входной массив X должен быть проверен перед вызовом &lt;code&gt;func&lt;/code&gt; . Возможности:</target>
        </trans-unit>
        <trans-unit id="ae286e88bfa268243cfd38132ccb40e58428bfed" translate="yes" xml:space="preserve">
          <source>Indicate that transform should forward the y argument to the inner callable.</source>
          <target state="translated">Укажите,что преобразование должно перенаправить аргумент y во внутренний вызываемый.</target>
        </trans-unit>
        <trans-unit id="9d241566a403a6506d3449cf17d407da2b6e2613" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels</source>
          <target state="translated">Указывает на заказ этикеток класса</target>
        </trans-unit>
        <trans-unit id="9f992c130abda366b807271662ae2ae17c7305e7" translate="yes" xml:space="preserve">
          <source>Indices according to which X will be subsampled.</source>
          <target state="translated">Индексы,в соответствии с которыми Х будет подвергаться субдискретизации.</target>
        </trans-unit>
        <trans-unit id="13d9e5d82e7cab8325fb7843fa12831d259a69f1" translate="yes" xml:space="preserve">
          <source>Indices of &lt;code&gt;components_&lt;/code&gt; in the training set.</source>
          <target state="translated">Индексы &lt;code&gt;components_&lt;/code&gt; в обучающей выборке.</target>
        </trans-unit>
        <trans-unit id="eeb5984b85169d88759ac10f7fe9d10f5246bc74" translate="yes" xml:space="preserve">
          <source>Indices of active variables at the end of the path.</source>
          <target state="translated">Индексы активных переменных в конце пути.</target>
        </trans-unit>
        <trans-unit id="fff8cc57ffbca371ebcb1bd938597e8d339ff509" translate="yes" xml:space="preserve">
          <source>Indices of cluster centers</source>
          <target state="translated">Индексы кластерных центров</target>
        </trans-unit>
        <trans-unit id="2c68ceeb78b6311d290c266259420efe85138435" translate="yes" xml:space="preserve">
          <source>Indices of columns in the dataset that belong to the bicluster.</source>
          <target state="translated">Индексы колонок в наборе данных,которые принадлежат билюстрам.</target>
        </trans-unit>
        <trans-unit id="d4d2ad6637f8190da67b396b7e452baac4f7558f" translate="yes" xml:space="preserve">
          <source>Indices of core samples.</source>
          <target state="translated">Индексы образцов керна.</target>
        </trans-unit>
        <trans-unit id="c71c298055da26ecac09942b9115f5fc73f7640d" translate="yes" xml:space="preserve">
          <source>Indices of rows in the dataset that belong to the bicluster.</source>
          <target state="translated">Индексы строк в наборе данных,которые принадлежат билюстрам.</target>
        </trans-unit>
        <trans-unit id="a5ecd973c55633f90c97a971f74a80fe11af3310" translate="yes" xml:space="preserve">
          <source>Indices of support vectors.</source>
          <target state="translated">Индексы векторов поддержки.</target>
        </trans-unit>
        <trans-unit id="9ccd80ce2c5e0529264583d000f7c9651892271d" translate="yes" xml:space="preserve">
          <source>Indices of the approximate nearest points in the population matrix.</source>
          <target state="translated">Индексы приблизительных ближайших точек в матрице населения.</target>
        </trans-unit>
        <trans-unit id="94147abfa5127a12fe3c3b0c7153a32b171d401a" translate="yes" xml:space="preserve">
          <source>Indices of the nearest points in the population matrix.</source>
          <target state="translated">Индексы ближайших точек в матрице населения.</target>
        </trans-unit>
        <trans-unit id="3db97f5586a1b88a52d6998bdcb68ce6424bd44e" translate="yes" xml:space="preserve">
          <source>Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.</source>
          <target state="translated">Отдельные деревья решений можно легко интерпретировать,просто визуализируя структуру дерева.Модели с градиентным увеличением,однако,состоят из сотен деревьев регрессии,поэтому они не могут быть легко интерпретированы визуальным осмотром отдельных деревьев.К счастью,был предложен ряд методик для обобщения и интерпретации моделей повышения градиента.</target>
        </trans-unit>
        <trans-unit id="dda28c621b6ebb6a75808a25ba823af15c148423" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">Отдельные деревья решений по сути выполняют выбор функций путем выбора соответствующих точек разделения. Эта информация может использоваться для измерения важности каждой функции; Основная идея такова: чем чаще функция используется в точках разделения дерева, тем важнее эта функция. Это понятие важности может быть распространено на ансамбли деревьев решений путем простого усреднения важности характеристик каждого дерева (подробнее см. В разделе &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Оценка важности&lt;/a&gt; характеристик).</target>
        </trans-unit>
        <trans-unit id="e3bee3019e098ad6b65e2ff793a0e712b529b8f1" translate="yes" xml:space="preserve">
          <source>Individual samples are assumed to be files stored a two levels folder structure such as the following:</source>
          <target state="translated">Предполагается,что отдельными примерами являются файлы,хранящиеся в двухуровневой структуре папок,как,например,следующее:</target>
        </trans-unit>
        <trans-unit id="c0fc01010c6e24d626cecdd62fd33ec75c0c929c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">Отдельные шаги также можно заменить как параметры, а нефинальные шаги можно игнорировать, установив для них значение &lt;code&gt;None&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="1005c12f11beba0f3b6f9dd6a7112c31b922588d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample</source>
          <target state="translated">Индивидуальные веса для каждого образца</target>
        </trans-unit>
        <trans-unit id="1fda26bba39629c5adc019bfeebf23b6ea1cae92" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample raises error if sample_weight is passed and base_estimator fit method does not support it.</source>
          <target state="translated">Индивидуальные веса для каждого примера повышают ошибку,если передан sample_weight и метод подгонки base_estimator не поддерживает его.</target>
        </trans-unit>
        <trans-unit id="fa75f1e4d13933a19ded3aa860129fc7cab3ed7d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample, ignored if None is passed.</source>
          <target state="translated">Индивидуальные веса для каждого образца,игнорируются,если Никто не пройден.</target>
        </trans-unit>
        <trans-unit id="718e842694bb04faf5cc021c83e29c576f98c12d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">Индивидуальные веса для каждого образца. Если sample_weight не равно None и solver = 'auto', решатель будет установлен на 'cholesky'.</target>
        </trans-unit>
        <trans-unit id="f221e5d04a99f60098722e2605a369c8541e6c9c" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">Инерция - это не нормализованная метрика: мы просто знаем, что более низкие значения лучше, а ноль - оптимально. Но в очень многомерных пространствах евклидовы расстояния имеют тенденцию становиться завышенными (это пример так называемого &amp;laquo;проклятия размерности&amp;raquo;). Запуск алгоритма уменьшения размерности, такого как &lt;a href=&quot;pca&quot;&gt;PCA,&lt;/a&gt; перед кластеризацией k-средних может облегчить эту проблему и ускорить вычисления.</target>
        </trans-unit>
        <trans-unit id="e010b0c9058bbaf9975d3f14818f3861029f83a1" translate="yes" xml:space="preserve">
          <source>Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</source>
          <target state="translated">Инерция делает допущение,что кластеры выпуклые и изотропные,что не всегда так.Она плохо реагирует на вытянутые кластеры или коллекторы неправильной формы.</target>
        </trans-unit>
        <trans-unit id="2d57b1c4d1f958efe3710f23677dd552a8a1384c" translate="yes" xml:space="preserve">
          <source>Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">Инерция,или внутрикластерный критерий суммы квадратов,может быть признан как мера того,насколько внутренне когерентны кластеры.Она страдает от различных недостатков:</target>
        </trans-unit>
        <trans-unit id="1b9b7d4cd56309d7954eee8c5d88a8d58559a22d" translate="yes" xml:space="preserve">
          <source>Inference of the model can be time consuming.</source>
          <target state="translated">Вывод модели может занять много времени.</target>
        </trans-unit>
        <trans-unit id="8f5d2c4b74b9f6de8f1a369f5793fd5ad3db1bd0" translate="yes" xml:space="preserve">
          <source>Influence of outliers on location and covariance estimates</source>
          <target state="translated">Влияние отклонений на оценку местоположения и ковариаций</target>
        </trans-unit>
        <trans-unit id="b8c700f6663aab653644d35fb6aa9a0e53919c01" translate="yes" xml:space="preserve">
          <source>Information on how to contribute. This also contains useful information for advanced users, for example how to build their own estimators.</source>
          <target state="translated">Информация о том,как внести свой вклад.Она также содержит полезную информацию для продвинутых пользователей,например,о том,как строить свои собственные оценки.</target>
        </trans-unit>
        <trans-unit id="c4fbdb7aab44015fbed39936864f9255a99074c1" translate="yes" xml:space="preserve">
          <source>Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">Выбор модели на основе информационных критериев очень быстр,но он основывается на правильной оценке степеней свободы,выводится для больших выборок (асимптотических результатов)и предполагает,что модель корректна,т.е.данные реально генерируются этой моделью.Они также имеют тенденцию ломаться,когда проблема плохо решена (больше признаков,чем выборки).</target>
        </trans-unit>
        <trans-unit id="168bf67b39abe0e5515698a4ec915c75e07ca524" translate="yes" xml:space="preserve">
          <source>Initial value for the dictionary for warm restart scenarios.</source>
          <target state="translated">Начальное значение для словаря для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="64b2b9f72c239478fc1b9e586ac8147218ca87bd" translate="yes" xml:space="preserve">
          <source>Initial value for the sparse code for warm restart scenarios.</source>
          <target state="translated">Начальное значение для разреженного кода для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="1a6282c9a9baf1c9231fe6132d9510c0860835e2" translate="yes" xml:space="preserve">
          <source>Initial values for the components for warm restart scenarios.</source>
          <target state="translated">Начальные значения для компонентов для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="ff1f0a80e07dd6cd648bd3a5e935a909ec2cb299" translate="yes" xml:space="preserve">
          <source>Initial values for the loadings for warm restart scenarios.</source>
          <target state="translated">Начальные значения нагрузок для сценариев теплого рестарта.</target>
        </trans-unit>
        <trans-unit id="e597ad1e68022a1929058718fd92959e281b3619" translate="yes" xml:space="preserve">
          <source>Initialization of embedding. Possible options are &amp;lsquo;random&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.</source>
          <target state="translated">Инициализация встраивания. Возможные варианты: 'random', 'pca' и массив формы numpy (n_samples, n_components). Инициализация PCA не может использоваться с предварительно вычисленными расстояниями и обычно более стабильна в глобальном масштабе, чем случайная инициализация.</target>
        </trans-unit>
        <trans-unit id="e644154875d3e41452e4b87177ec7a98e4e47540" translate="yes" xml:space="preserve">
          <source>Initialization value for coefficients of logistic regression. Useless for liblinear solver.</source>
          <target state="translated">Значение инициализации для коэффициентов логистической регрессии.Бесполезно для литологического решателя.</target>
        </trans-unit>
        <trans-unit id="ed7011971816dd0f1903ad54a411facedaee4ded" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Значение инициализации разреженных кодов. Используется, только если &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5f66672d1a211feccb2663e524389cc7bbdc9544" translate="yes" xml:space="preserve">
          <source>Initialize self. See help(type(self)) for accurate signature.</source>
          <target state="translated">Инициализируй себя.См.справку(type(self))для точной подписи.</target>
        </trans-unit>
        <trans-unit id="f4694fddfebcd07057574f3bedbe073aecef8cbe" translate="yes" xml:space="preserve">
          <source>Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the &lt;code&gt;score_samples&lt;/code&gt; method, while the threshold can be controlled by the &lt;code&gt;contamination&lt;/code&gt; parameter.</source>
          <target state="translated">Выбросы помечены как 1, а выбросы - как -1. В методе прогнозирования используется порог необработанной функции оценки, вычисляемый оценщиком. Эта функция оценки доступна через метод &lt;code&gt;score_samples&lt;/code&gt; , в то время как порог может контролироваться параметром &lt;code&gt;contamination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2495be2cc170e277a5d9d5dd99a3f779ff0175c9" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Внутренняя статистика,которая поддерживается алгоритмом.Передача их при инициализации полезна в онлайн-настройках,чтобы не потерять историю эволюции.A (n_components,n_components)-ковариационная матрица словаря.B (n_features,n_components)-матрица аппроксимации данных.</target>
        </trans-unit>
        <trans-unit id="4cb705151cf2a5dcfea8029a0e74d39c67469fa5" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSC/CSR matrix.</source>
          <target state="translated">Масштабирование столбцов матрицы CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="15ad21d3f40808b965488683b0faaff07ad4b5e9" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSR matrix.</source>
          <target state="translated">Введите масштабирование столбца матрицы CSR.</target>
        </trans-unit>
        <trans-unit id="75290bdbc975498c98c7572ec067e43ddceb0c68" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l1 norm</source>
          <target state="translated">Ввод строк нормализуется по норме l1.</target>
        </trans-unit>
        <trans-unit id="bc0180825da8415aba8c76f27c29d7e471b70c2a" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l2 norm</source>
          <target state="translated">Ввод строки нормализуется с помощью нормы l2</target>
        </trans-unit>
        <trans-unit id="d91ae689358e283ef6d343e24e55244f1fb1cad2" translate="yes" xml:space="preserve">
          <source>Inplace row scaling of a CSR or CSC matrix.</source>
          <target state="translated">Введите масштабирование строк матрицы CSR или CSC.</target>
        </trans-unit>
        <trans-unit id="16ca749420dd58126c1f3f4ccf95ce2fc49387c9" translate="yes" xml:space="preserve">
          <source>Input array.</source>
          <target state="translated">Входной массив.</target>
        </trans-unit>
        <trans-unit id="f6fcca00499ce6b21e6114d56b450f6d3d43ccb2" translate="yes" xml:space="preserve">
          <source>Input checker utility for building a cross-validator</source>
          <target state="translated">Утилита проверки входа для построения перекрёстного валидатора</target>
        </trans-unit>
        <trans-unit id="3f43a2e4863dbf39da8cfbd5e4e557f3052ec269" translate="yes" xml:space="preserve">
          <source>Input data</source>
          <target state="translated">Исходные данные</target>
        </trans-unit>
        <trans-unit id="41aa04ac5754100b497c803419573444b7e1d42b" translate="yes" xml:space="preserve">
          <source>Input data representation and sparsity</source>
          <target state="translated">Представление входных данных и редкость</target>
        </trans-unit>
        <trans-unit id="66a8a4e34fe15bd5eafb5d984d77b9c0e3866728" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed.</source>
          <target state="translated">Вводите данные,которые будут преобразованы.</target>
        </trans-unit>
        <trans-unit id="fbb05f66a147e8520f226c078931507f60d0caac" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed. It cannot be sparse.</source>
          <target state="translated">Вводите данные,которые будут преобразованы.Они не могут быть скудными.</target>
        </trans-unit>
        <trans-unit id="1e3e0a570b83c9cbe639106afeb9bedd23e3fcfd" translate="yes" xml:space="preserve">
          <source>Input data to be transformed.</source>
          <target state="translated">Входные данные для преобразования.</target>
        </trans-unit>
        <trans-unit id="071feefe9143dba47a473de169ba49367bfce443" translate="yes" xml:space="preserve">
          <source>Input data to be transformed. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency. Sparse matrices are also supported, use sparse &lt;code&gt;csr_matrix&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Входные данные для преобразования. Используйте &lt;code&gt;dtype=np.float32&lt;/code&gt; для максимальной эффективности. Также поддерживаются разреженные матрицы, используйте разреженные &lt;code&gt;csr_matrix&lt;/code&gt; для максимальной эффективности.</target>
        </trans-unit>
        <trans-unit id="688f24dc1e25fac1dc510cf29e6e51a5cdee42ba" translate="yes" xml:space="preserve">
          <source>Input data used to build forests. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">Исходные данные, используемые для построения лесов. Используйте &lt;code&gt;dtype=np.float32&lt;/code&gt; для максимальной эффективности.</target>
        </trans-unit>
        <trans-unit id="ece9df27fcdc2d8935842ef4ed6ac1e8d53f8b6c" translate="yes" xml:space="preserve">
          <source>Input data, of which specified subsets are used to fit the transformers.</source>
          <target state="translated">Входные данные,из которых заданные подмножества используются для подгонки трансформаторов.</target>
        </trans-unit>
        <trans-unit id="8c020a67c0398f86d112987222d02c36283701ba" translate="yes" xml:space="preserve">
          <source>Input data, target values.</source>
          <target state="translated">Входные данные,целевые значения.</target>
        </trans-unit>
        <trans-unit id="0d15fc28721eb2bcf2d53de59215da674d786463" translate="yes" xml:space="preserve">
          <source>Input data, used to fit transformers.</source>
          <target state="translated">Входные данные,используемые для подгонки трансформаторов.</target>
        </trans-unit>
        <trans-unit id="aee2f5203193bb3069f6e2f7b08e833e91d53841" translate="yes" xml:space="preserve">
          <source>Input data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">Входные данные, где &lt;code&gt;n_samples&lt;/code&gt; - количество выборок, а &lt;code&gt;n_features&lt;/code&gt; - количество функций.</target>
        </trans-unit>
        <trans-unit id="8f9c683e36e31c7c38c7e8d6a2daeccf181d4c94" translate="yes" xml:space="preserve">
          <source>Input data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Входные данные,где n_samples-количество примеров,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="260753716624ad2077f13f38ada17a33c0f48cba" translate="yes" xml:space="preserve">
          <source>Input data.</source>
          <target state="translated">Вводите данные.</target>
        </trans-unit>
        <trans-unit id="c414149f534c72aa4d2016c93404604f17aa41fd" translate="yes" xml:space="preserve">
          <source>Input data. Columns are assumed to have unit norm.</source>
          <target state="translated">Вводите данные.Считается,что столбцы имеют единичную норму.</target>
        </trans-unit>
        <trans-unit id="fc921091c020b61d18864b21129c4eb989ef6d69" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;None&lt;/code&gt;, the output will be the pairwise similarities between all samples in &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">Входные данные. Если &lt;code&gt;None&lt;/code&gt; , то выход будет попарные сходство между всеми образцами в &lt;code&gt;X&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="afaf08d18a1423dc1a78bf3492e5ce0eb50d8638" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt;, the input should be the dissimilarity matrix.</source>
          <target state="translated">Входные данные. Если &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt; , входными данными должна быть матрица несходства.</target>
        </trans-unit>
        <trans-unit id="c7e2acaca5145e47486c9c2928ab5532aee98fd4" translate="yes" xml:space="preserve">
          <source>Input data. If X is not provided, only the global clustering step is done.</source>
          <target state="translated">Вводите данные.Если X не предоставляется,то выполняется только глобальный шаг кластеризации.</target>
        </trans-unit>
        <trans-unit id="d39fe8b9c923e952612de77f70ad5aff60c34542" translate="yes" xml:space="preserve">
          <source>Input object to check / convert.</source>
          <target state="translated">Ввод объекта для проверки/преобразования.</target>
        </trans-unit>
        <trans-unit id="ca7fd27e447d5e335b2e80d1b2bb1406dceac239" translate="yes" xml:space="preserve">
          <source>Input object to check / convert. Must be two-dimensional and square, otherwise a ValueError will be raised.</source>
          <target state="translated">Ввод объекта для проверки/преобразования.Должен быть двумерным и квадратным,иначе будет поднят ValueError.</target>
        </trans-unit>
        <trans-unit id="f24bf584af83fad1f47a5035ff05cdc62fd1daef" translate="yes" xml:space="preserve">
          <source>Input points.</source>
          <target state="translated">Точки входа.</target>
        </trans-unit>
        <trans-unit id="71b2d21e1f2e71c0dcf88bd09dfe9ef6fd499ea3" translate="yes" xml:space="preserve">
          <source>Input targets</source>
          <target state="translated">Входные цели</target>
        </trans-unit>
        <trans-unit id="b58e4bce1b7ebb41f970a06dbe933522f9ad2c46" translate="yes" xml:space="preserve">
          <source>Input targets multiplied by X: X.T * y</source>
          <target state="translated">Входные цели,умноженные на X:X.T*y</target>
        </trans-unit>
        <trans-unit id="69a0e9f3a009e8ccbba64367545e9fbe88306b19" translate="yes" xml:space="preserve">
          <source>Input targets.</source>
          <target state="translated">Входные цели.</target>
        </trans-unit>
        <trans-unit id="51c9f9fb1fac83429c51404b5e9b2caee57cc2f2" translate="yes" xml:space="preserve">
          <source>Input validation for standard estimators.</source>
          <target state="translated">Проверка входных данных для стандартных оценщиков.</target>
        </trans-unit>
        <trans-unit id="346da7aa7d7e4eb884706a35a69404b7d3fc9daa" translate="yes" xml:space="preserve">
          <source>Input validation on an array, list, sparse matrix or similar.</source>
          <target state="translated">Входная проверка на массив,список,разреженную матрицу или подобное.</target>
        </trans-unit>
        <trans-unit id="8344beaf285df55c120907e8b74a9a1f87253895" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are 4 independent features uniformly distributed on the intervals:</source>
          <target state="translated">Входы &lt;code&gt;X&lt;/code&gt; - это 4 независимых объекта, равномерно распределенных по интервалам:</target>
        </trans-unit>
        <trans-unit id="bcbcb56a88ddeef69ce01bcc9a78a456071e2cf0" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are independent features uniformly distributed on the interval [0, 1]. The output &lt;code&gt;y&lt;/code&gt; is created according to the formula:</source>
          <target state="translated">Входы &lt;code&gt;X&lt;/code&gt; - это независимые признаки, равномерно распределенные на интервале [0, 1]. Выход &lt;code&gt;y&lt;/code&gt; создается по формуле:</target>
        </trans-unit>
        <trans-unit id="fffa8f8e3b740ecfc583b9bf477ffcbdb298b533" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest.</source>
          <target state="translated">Вставляет новые данные в уже установленный LSH Forest.</target>
        </trans-unit>
        <trans-unit id="e78cacac23222d74508b7d4b79fbb8a5cb79c6fc" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest. Cost is proportional to new total size, so additions should be batched.</source>
          <target state="translated">Вставляет новые данные в уже установленный LSH Forest.Стоимость пропорциональна новому общему размеру,поэтому дополнения должны быть согласованы.</target>
        </trans-unit>
        <trans-unit id="58768f013d8600aed4da42a9f67c30c0b0e7f2be" translate="yes" xml:space="preserve">
          <source>Instead of computing with a set of cardinality &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples (at least number of features), consider only a stochastic subpopulation of a given maximal size if &amp;lsquo;n choose k&amp;rsquo; is larger than max_subpopulation. For other than small problem sizes this parameter will determine memory usage and runtime if n_subsamples is not changed.</source>
          <target state="translated">Вместо вычислений с набором мощности n choose k, где n - количество выборок, а k - количество подвыборок (по крайней мере, количество характеристик), рассмотрите только стохастическую подгруппу заданного максимального размера, если n choose k 'больше, чем max_subpopulation. Для задач, отличных от небольших, этот параметр будет определять использование памяти и время выполнения, если n_subsamples не изменяется.</target>
        </trans-unit>
        <trans-unit id="ce6171dee8019fcd810326710a2a425d2ef2e21c" translate="yes" xml:space="preserve">
          <source>Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the L1 norm of the parameter vector. The full coefficients path is stored in the array &lt;code&gt;coef_path_&lt;/code&gt;, which has size (n_features, max_features+1). The first column is always zero.</source>
          <target state="translated">Вместо того чтобы давать векторный результат, решение LARS состоит из кривой, обозначающей решение для каждого значения нормы L1 вектора параметров. Полный путь коэффициентов хранится в массиве &lt;code&gt;coef_path_&lt;/code&gt; , который имеет размер (n_features, max_features + 1). Первый столбец всегда равен нулю.</target>
        </trans-unit>
        <trans-unit id="1c47d2e573aac76a94273f4c46c066cf6f2a8ad1" translate="yes" xml:space="preserve">
          <source>Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. We try out all classifiers on either words or bigrams, with or without idf, and with a penalty parameter of either 0.01 or 0.001 for the linear SVM:</source>
          <target state="translated">Вместо того,чтобы подстраивать параметры различных составляющих цепочки,можно провести исчерпывающий поиск наилучших параметров по сетке возможных значений.Мы опробуем все классификаторы либо на словах,либо на биграммах,с idf или без,и с параметром штрафных санкций 0.01 или 0.001 для линейного SVM:</target>
        </trans-unit>
        <trans-unit id="db33f6d449a5c5c7a074dd03bb12ec7fc077641c" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_centering=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSR matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">Вместо этого ожидается, что вызывающий либо явно установит &lt;code&gt;with_centering=False&lt;/code&gt; (в этом случае для функций матрицы CSR будет выполняться только масштабирование дисперсии), либо вызовет &lt;code&gt;X.toarray()&lt;/code&gt; если он / она ожидает, что материализованный плотный массив будет соответствовать в памяти.</target>
        </trans-unit>
        <trans-unit id="f080b277d95a6b1142abd6eb9ea11a07abcb1917" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_mean=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSC matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">Вместо этого ожидается, что вызывающий либо явно установит &lt;code&gt;with_mean=False&lt;/code&gt; (в этом случае для функций матрицы CSC будет выполняться только масштабирование дисперсии), либо вызовет &lt;code&gt;X.toarray()&lt;/code&gt; если он / она ожидает, что материализованный плотный массив будет соответствовать в памяти.</target>
        </trans-unit>
        <trans-unit id="b11f1ba476938b01d18dd66d0c3826617a20151e" translate="yes" xml:space="preserve">
          <source>Instead, the distribution over \(w\) is assumed to be an axis-parallel, elliptical Gaussian distribution.</source>
          <target state="translated">Вместо этого предполагается,что распределение по адресу \(w\)является осево-параллельным,эллиптическим гауссовым распределением.</target>
        </trans-unit>
        <trans-unit id="33a2873657f7cc53fbafced5857dd217868f1368" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. By default, it is &amp;lsquo;strict&amp;rsquo;, meaning that a UnicodeDecodeError will be raised. Other values are &amp;lsquo;ignore&amp;rsquo; and &amp;lsquo;replace&amp;rsquo;.</source>
          <target state="translated">Инструкция, что делать, если на анализ дана последовательность байтов, содержащая символы не заданной &lt;code&gt;encoding&lt;/code&gt; . По умолчанию он &amp;laquo;строгий&amp;raquo;, что означает, что будет вызвана ошибка UnicodeDecodeError. Другие значения - &amp;laquo;игнорировать&amp;raquo; и &amp;laquo;заменить&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="d22b7ba366228e805a5817961de5812cf7af3a5e" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. Passed as keyword argument &amp;lsquo;errors&amp;rsquo; to bytes.decode.</source>
          <target state="translated">Инструкция, что делать, если на анализ дана последовательность байтов, содержащая символы не заданной &lt;code&gt;encoding&lt;/code&gt; . Передается в качестве аргумента ключевого слова &amp;laquo;errors&amp;raquo; в bytes.decode.</target>
        </trans-unit>
        <trans-unit id="98ae123013fca86e4cc21f01a470888e055215cc" translate="yes" xml:space="preserve">
          <source>Integer array of labels. If not provided, labels will be inferred from y_true and y_pred.</source>
          <target state="translated">Целочисленный массив этикеток.Если это не предусмотрено,то метки будут выведены из y_true и y_pred.</target>
        </trans-unit>
        <trans-unit id="fb86aae8ca1d5ea8c3a2f0216a09b115ca2c4371" translate="yes" xml:space="preserve">
          <source>Intercept (a.k.a. bias) added to the decision function.</source>
          <target state="translated">Перехват (так же известный как предвзятость),добавленный к функции принятия решения.</target>
        </trans-unit>
        <trans-unit id="02c60e7ce23b1ba7da9aadaca682e74dd23bd987" translate="yes" xml:space="preserve">
          <source>Intercept term.</source>
          <target state="translated">Срок перехвата.</target>
        </trans-unit>
        <trans-unit id="077392291decf12f1b024c471b5bea6bcd10e56c" translate="yes" xml:space="preserve">
          <source>Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid loosing the history of the evolution, but they shouldn&amp;rsquo;t have any use for the end user. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Внутренняя достаточная статистика, которая хранится алгоритмом. Их полезно хранить в онлайн-настройках, чтобы не потерять историю эволюции, но они не должны иметь никакого смысла для конечного пользователя. A (n_components, n_components) - это ковариационная матрица словаря. B (n_features, n_components) - матрица аппроксимации данных</target>
        </trans-unit>
        <trans-unit id="14f5f43f255d2aa36ff5598f3fb3ace3d6d04389" translate="yes" xml:space="preserve">
          <source>Internally, the Laplace approximation is used for approximating the non-Gaussian posterior by a Gaussian.</source>
          <target state="translated">Внутренняя аппроксимация Лапласа используется для аппроксимации гауссовым апостериором не гауссового апостериорного.</target>
        </trans-unit>
        <trans-unit id="0b925a293764508f95547bba83dbd960f81b58e6" translate="yes" xml:space="preserve">
          <source>Internally, the target &lt;code&gt;y&lt;/code&gt; is always converted into a 2-dimensional array to be used by scikit-learn transformers. At the time of prediction, the output will be reshaped to a have the same number of dimensions as &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Внутренне целевой &lt;code&gt;y&lt;/code&gt; всегда преобразуется в двумерный массив, который будет использоваться преобразователями scikit-learn. Во время прогнозирования результат будет изменен, чтобы иметь то же количество измерений, что и &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a6c7ce41d2f8fb06b74993c6b6972d365c014219" translate="yes" xml:space="preserve">
          <source>Internally, we use &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; to handle all computations. These libraries are wrapped using C and Cython.</source>
          <target state="translated">Внутри мы используем &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; и &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; для обработки всех вычислений. Эти библиотеки обернуты с использованием C и Cython.</target>
        </trans-unit>
        <trans-unit id="a2d983855292bfa7e006da9cc5e0020136bdcd0e" translate="yes" xml:space="preserve">
          <source>Interruption of multiprocesses jobs with &amp;lsquo;Ctrl-C&amp;rsquo;</source>
          <target state="translated">Прерывание многопроцессных заданий с помощью Ctrl-C</target>
        </trans-unit>
        <trans-unit id="c8666d7061618ff72086e37218ea77619df4e168" translate="yes" xml:space="preserve">
          <source>Intuitive interpretation: clustering with bad V-measure can be &lt;strong&gt;qualitatively analyzed in terms of homogeneity and completeness&lt;/strong&gt; to better feel what &amp;lsquo;kind&amp;rsquo; of mistakes is done by the assignment.</source>
          <target state="translated">Интуитивная интерпретация: кластеризацию с плохой V-мерой можно &lt;strong&gt;качественно проанализировать с точки зрения однородности и полноты,&lt;/strong&gt; чтобы лучше понять, какие &amp;laquo;ошибки&amp;raquo; допущены при задании.</target>
        </trans-unit>
        <trans-unit id="b3bf13a5a75c5bcae60f4d54f651f7f504b37960" translate="yes" xml:space="preserve">
          <source>Intuitively, &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;precision&lt;/a&gt; is the ability of the classifier not to label as positive a sample that is negative, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;recall&lt;/a&gt; is the ability of the classifier to find all the positive samples.</source>
          <target state="translated">Интуитивно, &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;точность&lt;/a&gt; - это способность классификатора не маркировать как положительный образец, который является отрицательным, а &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;отзыв&lt;/a&gt; - это способность классификатора находить все положительные образцы.</target>
        </trans-unit>
        <trans-unit id="d7d0867c1bea54b1fdaded0f6d4a137c7b95792e" translate="yes" xml:space="preserve">
          <source>Intuitively, one can also think of a histogram as a stack of blocks, one block per point. By stacking the blocks in the appropriate grid space, we recover the histogram. But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location? This idea leads to the lower-left visualization. It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data.</source>
          <target state="translated">Интуитивно,можно также думать о гистограмме,как о стопке блоков,по одному блоку на точку.Укладывая блоки в соответствующее пространство сетки,мы восстанавливаем гистограмму.Но что,если вместо того,чтобы укладывать блоки на обычную сетку,мы центрируем каждый блок по точке,которую он представляет,и суммируем общую высоту в каждой точке? Эта идея приведет к визуализации в левом нижнем углу.Возможно,она не так чиста,как гистограмма,но тот факт,что данные приводят к расположению блоков,означает,что это гораздо лучшее представление исходных данных.</target>
        </trans-unit>
        <trans-unit id="a413ab311fb3ee6ba0089ad38e522b4769b873e8" translate="yes" xml:space="preserve">
          <source>Intuitively, the &lt;code&gt;gamma&lt;/code&gt; parameter defines how far the influence of a single training example reaches, with low values meaning &amp;lsquo;far&amp;rsquo; and high values meaning &amp;lsquo;close&amp;rsquo;. The &lt;code&gt;gamma&lt;/code&gt; parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.</source>
          <target state="translated">Интуитивно параметр &lt;code&gt;gamma&lt;/code&gt; определяет, насколько далеко распространяется влияние одного обучающего примера, при этом низкие значения означают &amp;laquo;далеко&amp;raquo;, а высокие значения - &amp;laquo;близко&amp;raquo;. Параметры &lt;code&gt;gamma&lt;/code&gt; можно рассматривать как обратную величину радиуса влияния образцов, выбранных моделью в качестве опорных векторов.</target>
        </trans-unit>
        <trans-unit id="0af317bc827b64b57bcc63f42ad5928a61b8cb1f" translate="yes" xml:space="preserve">
          <source>Intuitively, this matrix can be interpreted as a matrix of pseudo features (the points raised to some power). The matrix is akin to (but different from) the matrix induced by a polynomial kernel.</source>
          <target state="translated">Интуитивно эту матрицу можно интерпретировать как матрицу псевдофункций (пунктов,поднятых до некоторой степени).Матрица сродни (но отличается от)матрицы,индуцированной полиномиальным ядром.</target>
        </trans-unit>
        <trans-unit id="20dc7b25181635b005eb94a34d79a1d1ef88f5eb" translate="yes" xml:space="preserve">
          <source>Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.</source>
          <target state="translated">Обратная сила регуляризации;должен быть положительный поплавок.Как и в векторных машинах поддержки,меньшие значения указывают более сильную регуляризацию.</target>
        </trans-unit>
        <trans-unit id="33bf667eeef9f8f87ba0b221f0610de05f350c0d" translate="yes" xml:space="preserve">
          <source>Inverse the transformation.</source>
          <target state="translated">Обратное преобразование.</target>
        </trans-unit>
        <trans-unit id="c6d1024dc4c416573a81f58d53b390ce79e27d74" translate="yes" xml:space="preserve">
          <source>Inverse the transformation. Return a vector of size nb_features with the values of Xred assigned to each group of features</source>
          <target state="translated">Обратное преобразование.Возвращает вектор размера nb_features со значениями Xred,присвоенными каждой группе признаков</target>
        </trans-unit>
        <trans-unit id="68776e7556a932d7c1772f163bcd0ea5d3036f2f" translate="yes" xml:space="preserve">
          <source>Inverse transform matrix. Only available when &lt;code&gt;fit_inverse_transform&lt;/code&gt; is True.</source>
          <target state="translated">Матрица обратного преобразования. Доступно, только когда &lt;code&gt;fit_inverse_transform&lt;/code&gt; имеет значение True.</target>
        </trans-unit>
        <trans-unit id="a53229d5506328691d3b32e8898ac28b845cf1d2" translate="yes" xml:space="preserve">
          <source>Inverse transformed array.</source>
          <target state="translated">Обратный преобразованный массив.</target>
        </trans-unit>
        <trans-unit id="6d0db9202e10d4b2a1eb16356a668a8027a929fc" translate="yes" xml:space="preserve">
          <source>Invokes the passed method name of the passed estimator. For method=&amp;rsquo;predict_proba&amp;rsquo;, the columns correspond to the classes in sorted order.</source>
          <target state="translated">Вызывает переданное имя метода переданного оценщика. Для method = 'pred_proba' столбцы соответствуют классам в отсортированном порядке.</target>
        </trans-unit>
        <trans-unit id="d37270b3f9f32ae673296712eb4a194d52812d8f" translate="yes" xml:space="preserve">
          <source>Invoking the &lt;code&gt;fit&lt;/code&gt; method on the &lt;code&gt;VotingClassifier&lt;/code&gt; will fit clones of those original estimators that will be stored in the class attribute &lt;code&gt;self.estimators_&lt;/code&gt;. An estimator can be set to &lt;code&gt;None&lt;/code&gt; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="translated">Вызов метода &lt;code&gt;fit&lt;/code&gt; в &lt;code&gt;VotingClassifier&lt;/code&gt; подберет клоны тех исходных оценщиков, которые будут храниться в атрибуте класса &lt;code&gt;self.estimators_&lt;/code&gt; . Для оценщика можно установить значение &lt;code&gt;None&lt;/code&gt; с помощью &lt;code&gt;set_params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="42b4a555867c758d3e1c4078b74a325ea5729a8f" translate="yes" xml:space="preserve">
          <source>Iris-Setosa</source>
          <target state="translated">Iris-Setosa</target>
        </trans-unit>
        <trans-unit id="0e4a66fb06fc31fa26bb267122a303163869bd83" translate="yes" xml:space="preserve">
          <source>Iris-Versicolour</source>
          <target state="translated">Iris-Versicolour</target>
        </trans-unit>
        <trans-unit id="c11352543468838c7f536aa067f758dd5cf065cc" translate="yes" xml:space="preserve">
          <source>Iris-Virginica</source>
          <target state="translated">Iris-Virginica</target>
        </trans-unit>
        <trans-unit id="bb0f5655f4fe0f8adc1a787c53ae1e836f4be186" translate="yes" xml:space="preserve">
          <source>Iso-probability lines for Gaussian Processes classification (GPC)</source>
          <target state="translated">Линии прозо-вероятности для Гауссовской классификации процессов (GPC)</target>
        </trans-unit>
        <trans-unit id="2b50512539d0e21a6687a0e4968f704ff8cc80fe" translate="yes" xml:space="preserve">
          <source>Isolation Forest Algorithm</source>
          <target state="translated">алгоритм изоляции леса</target>
        </trans-unit>
        <trans-unit id="00617c131e78d4c4ef41c400773154d235217731" translate="yes" xml:space="preserve">
          <source>IsolationForest example</source>
          <target state="translated">пример IsolationForest</target>
        </trans-unit>
        <trans-unit id="3a2755971bbebbe11d424139f5382799c401f262" translate="yes" xml:space="preserve">
          <source>Isomap Embedding</source>
          <target state="translated">Isomap Embedding</target>
        </trans-unit>
        <trans-unit id="fe769adce6faebe1974c95ecc576637486cbe643" translate="yes" xml:space="preserve">
          <source>Isotone Optimization in R : Pool-Adjacent-Violators Algorithm (PAVA) and Active Set Methods Leeuw, Hornik, Mair Journal of Statistical Software 2009</source>
          <target state="translated">Оптимизация изотонов в R:Алгоритм пула-аджакента-виолятора (PAVA)и методы активных множеств Leeuw,Hornik,Журнал статистического программного обеспечения Mair за 2009 год</target>
        </trans-unit>
        <trans-unit id="906c68921cb26d68c13066c88efbe4d7d97d1205" translate="yes" xml:space="preserve">
          <source>Isotonic Median Regression: A Linear Programming Approach Nilotpal Chakravarti Mathematics of Operations Research Vol. 14, No. 2 (May, 1989), pp. 303-308</source>
          <target state="translated">Изотоническая Медианная Регрессия:Линейный программный подход Nilotpal Chakravarti Математика исследования операций Том 14,No.2 (май 1989 г.),стр.303-308</target>
        </trans-unit>
        <trans-unit id="73b36c35655a3846d59943ac16d2df052178f43b" translate="yes" xml:space="preserve">
          <source>Isotonic Regression</source>
          <target state="translated">изотоническая регрессия</target>
        </trans-unit>
        <trans-unit id="c214056f848cd4e39c52f175df94ac0d422815da" translate="yes" xml:space="preserve">
          <source>Isotonic fit of y.</source>
          <target state="translated">Изотонический припадок.</target>
        </trans-unit>
        <trans-unit id="350a83a6eea9b1b3e9903b81e34485a4ebed4999" translate="yes" xml:space="preserve">
          <source>Isotonic regression model.</source>
          <target state="translated">Изотоническая регрессионная модель.</target>
        </trans-unit>
        <trans-unit id="7c5ae8804283297e052b100d9986cbd5cd009701" translate="yes" xml:space="preserve">
          <source>Issue a warning when the function is called/the class is instantiated and adds a warning to the docstring.</source>
          <target state="translated">Выдача предупреждения при вызове функции/класса и добавление предупреждения в стыковочную строку.</target>
        </trans-unit>
        <trans-unit id="4de98053a0f4264ca5362b17521388fcee7300ef" translate="yes" xml:space="preserve">
          <source>It adapts to the data at hand.</source>
          <target state="translated">Он адаптируется к имеющимся данным.</target>
        </trans-unit>
        <trans-unit id="d00cd2eb4ac76616c412b13d0e3140cdba7905a2" translate="yes" xml:space="preserve">
          <source>It allows specifying multiple metrics for evaluation.</source>
          <target state="translated">Она позволяет задавать несколько метрик для оценки.</target>
        </trans-unit>
        <trans-unit id="f7ac040f9311efb440d25da16c027a81ab8e3ad5" translate="yes" xml:space="preserve">
          <source>It also can be expressed in set cardinality formulation:</source>
          <target state="translated">Она также может быть выражена в установленной формулировке кардинальности:</target>
        </trans-unit>
        <trans-unit id="aedad5338d2a0edf1701c1d5c20ad5954bfd8c84" translate="yes" xml:space="preserve">
          <source>It can also be directly used as the &lt;code&gt;kernel&lt;/code&gt; argument:</source>
          <target state="translated">Его также можно напрямую использовать как аргумент &lt;code&gt;kernel&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="9678c3fa14b59b03394b92e8e0080149cf3f64c8" translate="yes" xml:space="preserve">
          <source>It can also be used as a pre-processing step for estimators that consider boolean random variables (e.g. modelled using the Bernoulli distribution in a Bayesian setting).</source>
          <target state="translated">Она также может быть использована в качестве этапа предварительной обработки для оценщиков,которые рассматривают булевы случайные переменные (например,смоделированные с использованием распределения Бернулли в байесовской установке).</target>
        </trans-unit>
        <trans-unit id="94554b8e34efbb328f639daf4ccda2adc301f69d" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.</source>
          <target state="translated">Она также может быть использована для преобразования нецифровых меток (при условии,что они являются хэшируемыми и сопоставимыми)с числовыми метками.</target>
        </trans-unit>
        <trans-unit id="f96e6d208d3d13906cbf9cd9c045b4122e99a4e4" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels:</source>
          <target state="translated">Она также может быть использована для преобразования нецифровых меток (при условии,что они являются хэшируемыми и сопоставимыми)с числовыми метками:</target>
        </trans-unit>
        <trans-unit id="52f6dad43e1775ee0bbb04be9ef515bae958e0a2" translate="yes" xml:space="preserve">
          <source>It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.</source>
          <target state="translated">Он также может иметь регуляризационный термин,добавленный к функции потерь,который сокращает параметры модели,чтобы предотвратить переподгонку.</target>
        </trans-unit>
        <trans-unit id="998bd5d13863b9f1e85f5a6708bf38f625d563b0" translate="yes" xml:space="preserve">
          <source>It can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD.</source>
          <target state="translated">Он также может использовать scipy.sparse.linalg ARPACK реализацию усеченного SVD.</target>
        </trans-unit>
        <trans-unit id="a5f9c7ba1af0aaff84e6645b602de8095311d995" translate="yes" xml:space="preserve">
          <source>It can be called with parameters &lt;code&gt;(estimator, X, y)&lt;/code&gt;, where &lt;code&gt;estimator&lt;/code&gt; is the model that should be evaluated, &lt;code&gt;X&lt;/code&gt; is validation data, and &lt;code&gt;y&lt;/code&gt; is the ground truth target for &lt;code&gt;X&lt;/code&gt; (in the supervised case) or &lt;code&gt;None&lt;/code&gt; (in the unsupervised case).</source>
          <target state="translated">Его можно вызвать с параметрами &lt;code&gt;(estimator, X, y)&lt;/code&gt; , где &lt;code&gt;estimator&lt;/code&gt; - это модель, которая должна быть оценена, &lt;code&gt;X&lt;/code&gt; - данные валидации, а &lt;code&gt;y&lt;/code&gt; - основная истинная цель для &lt;code&gt;X&lt;/code&gt; (в контролируемом случае) или &lt;code&gt;None&lt;/code&gt; (в неконтролируемом случае). кейс).</target>
        </trans-unit>
        <trans-unit id="9a6afc7a825a539f282e6908ea3004d59da105e7" translate="yes" xml:space="preserve">
          <source>It can be downloaded/loaded using the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">Его можно скачать / загрузить с &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt; &lt;/a&gt; функции sklearn.datasets.fetch_california_housing .</target>
        </trans-unit>
        <trans-unit id="afe5a10e4cd1db3d3b82e37290c3a4b0be9670c8" translate="yes" xml:space="preserve">
          <source>It can be interpreted as a weighted difference per entry.</source>
          <target state="translated">Это может быть интерпретировано как взвешенная разница на запись.</target>
        </trans-unit>
        <trans-unit id="d898e853ebb8a8ce7531765c1307531f5ab826e6" translate="yes" xml:space="preserve">
          <source>It can be noted that k-means (and minibatch k-means) are very sensitive to feature scaling and that in this case the IDF weighting helps improve the quality of the clustering by quite a lot as measured against the &amp;ldquo;ground truth&amp;rdquo; provided by the class label assignments of the 20 newsgroups dataset.</source>
          <target state="translated">Можно отметить, что k-средние (и k-средние мини-пакета) очень чувствительны к масштабированию признаков, и что в этом случае взвешивание IDF помогает значительно улучшить качество кластеризации по сравнению с &amp;laquo;наземной истиной&amp;raquo;, предоставленной присвоения меток класса для набора данных 20 групп новостей.</target>
        </trans-unit>
        <trans-unit id="074f1a9d1908eeea94dd9624b8e4e74f70971f1f" translate="yes" xml:space="preserve">
          <source>It can be seen from the plots that the results of &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt; with two non-zero coefficients is a bit less biased than when keeping only one (the edges look less prominent). It is in addition closer from the ground truth in Frobenius norm.</source>
          <target state="translated">Из графиков видно, что результаты &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;поиска ортогонального соответствия (OMP)&lt;/a&gt; с двумя ненулевыми коэффициентами немного менее смещены, чем при сохранении только одного (края выглядят менее заметными). Вдобавок это ближе к истине в норме Фробениуса.</target>
        </trans-unit>
        <trans-unit id="0cf8fb702abea7c91fd29d6847c4f9bb34be57f9" translate="yes" xml:space="preserve">
          <source>It can be shown that the \(\nu\)-SVC formulation is a reparameterization of the \(C\)-SVC and therefore mathematically equivalent.</source>
          <target state="translated">Можно показать,что формулировка \(\nu\)-SVC является репараметризацией \(C\)-SVC и,следовательно,математически эквивалентна.</target>
        </trans-unit>
        <trans-unit id="157aa7190191e4be1be236c86eabe4e67d5e1efd" translate="yes" xml:space="preserve">
          <source>It can be used for univariate features selection, read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Его можно использовать для одномерного выбора функций, подробнее читайте в &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;Руководстве пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="711c50760d4f6c264d6b8a92b5297202a600fa0b" translate="yes" xml:space="preserve">
          <source>It can be used to include regularization parameters in the estimation procedure.</source>
          <target state="translated">Его можно использовать для включения параметров регуляризации в процедуру оценки.</target>
        </trans-unit>
        <trans-unit id="e52b5bc871c7db656a1b43abcce93011714c74d2" translate="yes" xml:space="preserve">
          <source>It does not require a learning rate.</source>
          <target state="translated">Для этого не требуется скорость обучения.</target>
        </trans-unit>
        <trans-unit id="4d19424efe5e9e20338f3273e68fb2ccbb132c12" translate="yes" xml:space="preserve">
          <source>It doesn&amp;rsquo;t give a single metric to use as an objective for clustering optimisation.</source>
          <target state="translated">Он не дает ни одной метрики для использования в качестве цели для оптимизации кластеризации.</target>
        </trans-unit>
        <trans-unit id="0a46e66645323d1f8dad68441e68b478eacb85f4" translate="yes" xml:space="preserve">
          <source>It has been observed in [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; that, when carefully constrained, &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; can produce a parts-based representation of the dataset, resulting in interpretable models. The following example displays 16 sparse components found by &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; from the images in the Olivetti faces dataset, in comparison with the PCA eigenfaces.</source>
          <target state="translated">В [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; было замечено, что при тщательном ограничении &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; может создавать представление набора данных на основе частей, что приводит к интерпретируемым моделям. В следующем примере показаны 16 разреженных компонентов, найденных &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; из изображений в наборе данных Olivetti Faces, в сравнении с собственными лицами PCA.</target>
        </trans-unit>
        <trans-unit id="8dcb00db48002a7fdf6f8f4ffd6c64f833e7dfb1" translate="yes" xml:space="preserve">
          <source>It has properties that are similar to the exponentiated chi squared kernel often used in computer vision, but allows for a simple Monte Carlo approximation of the feature map.</source>
          <target state="translated">Он обладает свойствами,схожими с экспоненциальным квадратным ядром chi,часто используемым в компьютерном зрении,но позволяет простое аппроксимационное изображение карты характеристик Монте-Карло.</target>
        </trans-unit>
        <trans-unit id="37dc8b6f979214e286ace27e5272dd91d61126bc" translate="yes" xml:space="preserve">
          <source>It has proven useful in ML applied to noiseless data. See e.g. &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Machine learning for quantum mechanics in a nutshell&lt;/a&gt;.</source>
          <target state="translated">Это оказалось полезным в машинном обучении применительно к бесшумным данным. См., Например, &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Машинное обучение для квантовой механики в двух словах&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e3ea912466304dbf8e7c52052ad02a2c286c1ad1" translate="yes" xml:space="preserve">
          <source>It implements a variant of Random Kitchen Sinks.[1]</source>
          <target state="translated">Он реализует вариант Случайных кухонных раковин.[1].</target>
        </trans-unit>
        <trans-unit id="74d404b8e11acc4d9a6402146bf70c71d78d2e94" translate="yes" xml:space="preserve">
          <source>It is a Linear Model trained with an L1 prior as regularizer.</source>
          <target state="translated">Это линейная модель,тренированная с L1 в качестве регулятора.</target>
        </trans-unit>
        <trans-unit id="971eff281c404ac7ff23799c2f2e17c93f769de1" translate="yes" xml:space="preserve">
          <source>It is a memory-efficient, online-learning algorithm provided as an alternative to &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt;. It constructs a tree data structure with the cluster centroids being read off the leaf. These can be either the final cluster centroids or can be provided as input to another clustering algorithm such as &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это эффективный с точки зрения памяти алгоритм онлайн-обучения, предоставляемый в качестве альтернативы &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; . Он создает древовидную структуру данных, центроиды кластера считываются с листа. Это могут быть либо конечные центроиды кластера, либо они могут быть предоставлены в качестве входных данных для другого алгоритма кластеризации, такого как &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1a9933b24a1c1c056c0577574d6613078e271127" translate="yes" xml:space="preserve">
          <source>It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is &lt;code&gt;n_samples&lt;/code&gt;, the update method is same as batch learning. In the literature, this is called kappa.</source>
          <target state="translated">Это параметр, который контролирует скорость обучения в методе онлайн-обучения. Значение должно быть установлено в диапазоне (0,5, 1,0], чтобы гарантировать асимптотическую сходимость. Когда значение равно 0,0, а размер batch_size равен &lt;code&gt;n_samples&lt;/code&gt; , метод обновления аналогичен пакетному обучению. В литературе это называется каппа.</target>
        </trans-unit>
        <trans-unit id="15f125826dc7be5a6512e2415a2ab7dc87afbdb7" translate="yes" xml:space="preserve">
          <source>It is advised to set the parameter &lt;code&gt;epsilon&lt;/code&gt; to 1.35 to achieve 95% statistical efficiency.</source>
          <target state="translated">Рекомендуется установить параметр &lt;code&gt;epsilon&lt;/code&gt; на 1,35 для достижения 95% статистической эффективности.</target>
        </trans-unit>
        <trans-unit id="542f7392581e6c4610879b36a37978fc74650959" translate="yes" xml:space="preserve">
          <source>It is also common among the text processing community to use binary feature values (probably to simplify the probabilistic reasoning) even if normalized counts (a.k.a. term frequencies) or TF-IDF valued features often perform slightly better in practice.</source>
          <target state="translated">В сообществе,занимающемся обработкой текстов,также распространено использование двоичных значений признаков (вероятно,для упрощения вероятностных рассуждений),даже если нормализованные значения (так называемые терминологические частоты)или значения TF-IDF признаков часто работают несколько лучше на практике.</target>
        </trans-unit>
        <trans-unit id="005dab4eb22b6ead110b29a8850c3898f552d977" translate="yes" xml:space="preserve">
          <source>It is also known as the Variance Ratio Criterion.</source>
          <target state="translated">Он также известен как Критерий соотношения вариаций.</target>
        </trans-unit>
        <trans-unit id="4221678f503b8b29e4ba191986027706279048ac" translate="yes" xml:space="preserve">
          <source>It is also possible to constrain the dictionary and/or code to be positive to match constraints that may be present in the data. Below are the faces with different positivity constraints applied. Red indicates negative values, blue indicates positive values, and white represents zeros.</source>
          <target state="translated">Также возможно ограничить словарь и/или код,чтобы они соответствовали ограничениям,которые могут присутствовать в данных.Ниже приведены грани с различными ограничениями позитивности.Красный-отрицательные значения,синий-положительные,белый-нули.</target>
        </trans-unit>
        <trans-unit id="cd4e94997f77b01819c6451ba1d9a9d98a78db7c" translate="yes" xml:space="preserve">
          <source>It is also possible to efficiently produce a sparse graph showing the connections between neighboring points:</source>
          <target state="translated">Также можно эффективно построить разреженный график,показывающий связи между соседними точками:</target>
        </trans-unit>
        <trans-unit id="e5cc911e1a3213d4a6ea82327423c6b7195a9251" translate="yes" xml:space="preserve">
          <source>It is also possible to map data to a normal distribution using &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; by setting &lt;code&gt;output_distribution='normal'&lt;/code&gt;. Using the earlier example with the iris dataset:</source>
          <target state="translated">Также можно отобразить данные к нормальному распределению с помощью &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; , установив &lt;code&gt;output_distribution='normal'&lt;/code&gt; . Используя предыдущий пример с набором данных iris:</target>
        </trans-unit>
        <trans-unit id="f35eb3fdcbe153523a6b78440df1aad8edf3b026" translate="yes" xml:space="preserve">
          <source>It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:</source>
          <target state="translated">Можно также использовать и другие стратегии перекрестной валидации,например,передав итератор перекрестной валидации:</target>
        </trans-unit>
        <trans-unit id="c62a692f1bef88aa9ea1dc55b02f68e6ac2b429f" translate="yes" xml:space="preserve">
          <source>It is classically used to separate mixed signals (a problem known as &lt;em&gt;blind source separation&lt;/em&gt;), as in the example below:</source>
          <target state="translated">Он обычно используется для разделения смешанных сигналов (проблема, известная как &lt;em&gt;слепое разделение источников&lt;/em&gt; ), как в примере ниже:</target>
        </trans-unit>
        <trans-unit id="579f13cf2a54010546e31ecfaa7ced83f4da4e12" translate="yes" xml:space="preserve">
          <source>It is computationally just as fast as forward selection and has the same order of complexity as an ordinary least squares.</source>
          <target state="translated">Он вычисляется так же быстро,как и прямая селекция,и имеет такой же порядок сложности,как и обычные наименьшие квадраты.</target>
        </trans-unit>
        <trans-unit id="2a0b5a3028e23e8f66ba4845cf98605a35e74ca3" translate="yes" xml:space="preserve">
          <source>It is converted to an F score then to a p-value.</source>
          <target state="translated">Он преобразуется в F,а затем в p-значение.</target>
        </trans-unit>
        <trans-unit id="9da4ca4cacbca0baec3287f1b2124c4dcd00df7a" translate="yes" xml:space="preserve">
          <source>It is easily modified to produce solutions for other estimators, like the Lasso.</source>
          <target state="translated">Он легко модифицируется для создания решений для других оценщиков,таких как Лассо.</target>
        </trans-unit>
        <trans-unit id="a180f7cced602efdc3c3224733570427c990972f" translate="yes" xml:space="preserve">
          <source>It is easy for a classifier to overfit on particular things that appear in the 20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very high F-scores, but their results would not generalize to other documents that aren&amp;rsquo;t from this window of time.</source>
          <target state="translated">Классификатору легко приспособиться к конкретным вещам, которые появляются в данных 20 групп новостей, например, к заголовкам групп новостей. Многие классификаторы достигают очень высоких оценок F, но их результаты не могут быть обобщены на другие документы, выходящие за пределы этого временного окна.</target>
        </trans-unit>
        <trans-unit id="2e5aa329cff0eb3a121eaf66246e864cad7413ee" translate="yes" xml:space="preserve">
          <source>It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples. For more tips see Laurens van der Maaten&amp;rsquo;s FAQ [2].</source>
          <target state="translated">Настоятельно рекомендуется использовать другой метод уменьшения размерности (например, PCA для плотных данных или TruncatedSVD для разреженных данных), чтобы уменьшить количество измерений до разумного количества (например, 50), если количество функций очень велико. Это подавит некоторый шум и ускорит вычисление попарных расстояний между выборками. Дополнительные советы см. В FAQ Лоренса ван дер Маатена [2].</target>
        </trans-unit>
        <trans-unit id="4c694641d1b1cd9e68259bd2f7aabf747615adda" translate="yes" xml:space="preserve">
          <source>It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the &lt;code&gt;fit&lt;/code&gt; method. The identifier that this implementation uses is the integer value \(-1\).</source>
          <target state="translated">Важно , чтобы назначить идентификатор немеченых точек вместе с мечеными данными при подготовке модели с &lt;code&gt;fit&lt;/code&gt; методом. Идентификатор, который использует эта реализация, - это целочисленное значение \ (- 1 \).</target>
        </trans-unit>
        <trans-unit id="a067b4f8fd8c4002a8fc9abd7aa015e146d303ad" translate="yes" xml:space="preserve">
          <source>It is important to note that when the number of samples is much larger than the number of features, one would expect that no shrinkage would be necessary. The intuition behind this is that if the population covariance is full rank, when the number of sample grows, the sample covariance will also become positive definite. As a result, no shrinkage would necessary and the method should automatically do this.</source>
          <target state="translated">Важно отметить,что когда количество образцов значительно превышает количество характеристик,можно ожидать,что усадки не потребуется.Интуиция,лежащая в основе этого,заключается в том,что при полном ранге ковариативности популяции,когда количество выборки растет,ковариативность выборки также становится положительной.В результате,усадка не потребуется,и метод должен делать это автоматически.</target>
        </trans-unit>
        <trans-unit id="d9e45bb570908f10d72f7b51c91c236b78670a3c" translate="yes" xml:space="preserve">
          <source>It is made of 150 observations of irises, each described by 4 features: their sepal and petal length and width, as detailed in &lt;code&gt;iris.DESCR&lt;/code&gt;.</source>
          <target state="translated">Он состоит из 150 наблюдений ирисов, каждое из которых описывается четырьмя характеристиками: длиной и шириной чашелистиков и лепестков, как указано в &lt;code&gt;iris.DESCR&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1856ef8269f110a1ccc7c37c9db810b8176fc5f8" translate="yes" xml:space="preserve">
          <source>It is more efficient than the LassoCV if only a small number of features are selected compared to the total number, for instance if there are very few samples compared to the number of features.</source>
          <target state="translated">Он более эффективен,чем LassoCV,если по сравнению с общим количеством выбрано лишь небольшое количество функций,например,если по сравнению с количеством функций выбрано очень мало выборок.</target>
        </trans-unit>
        <trans-unit id="1d58fe1839ae301f10f6b9aaac159ed67a9eabfe" translate="yes" xml:space="preserve">
          <source>It is not appropriate to pass these predictions into an evaluation metric. Use &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; to measure generalization error.</source>
          <target state="translated">Передавать эти прогнозы в метрику оценки нецелесообразно. Используйте &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt; для измерения ошибки обобщения.</target>
        </trans-unit>
        <trans-unit id="9af2e9f8fa22ff915f29e1a168987ff536812b91" translate="yes" xml:space="preserve">
          <source>It is not recommended to hard-code the backend name in a call to Parallel in a library. Instead it is recommended to set soft hints (prefer) or hard constraints (require) so as to make it possible for library users to change the backend from the outside using the parallel_backend context manager.</source>
          <target state="translated">Не рекомендуется жестко кодировать имя бэкэнда при вызове Parallel в библиотеке.Вместо этого рекомендуется задавать мягкие подсказки (предпочитают)или жесткие ограничения (требуют),чтобы пользователи библиотеки могли изменять бекенд извне с помощью контекстного менеджера параллельного_бекенда.</target>
        </trans-unit>
        <trans-unit id="b26cf025ddad5c1f883715bf24d85887eccade22" translate="yes" xml:space="preserve">
          <source>It is not regularized (penalized).</source>
          <target state="translated">Она не легализована (наказана).</target>
        </trans-unit>
        <trans-unit id="f18c5e38092754d2adb7bb6eb5c0799854e297b3" translate="yes" xml:space="preserve">
          <source>It is numerically efficient in contexts where p &amp;gt;&amp;gt; n (i.e., when the number of dimensions is significantly greater than the number of points)</source>
          <target state="translated">Он численно эффективен в контекстах, где p &amp;gt;&amp;gt; n (т. Е. Когда количество измерений значительно превышает количество точек)</target>
        </trans-unit>
        <trans-unit id="8c7122bd43c891f087ca247f2fcde5236f637b0c" translate="yes" xml:space="preserve">
          <source>It is often interesting to project data to a lower-dimensional space that preserves most of the variance, by dropping the singular vector of components associated with lower singular values.</source>
          <target state="translated">Часто бывает интересно проецировать данные на меньшее по размеру пространство,сохраняющее большую часть дисперсии,путем опускания сингулярного вектора компонентов,связанных с меньшими сингулярными значениями.</target>
        </trans-unit>
        <trans-unit id="5ed0af274291a2311daa7ee05d7bd79f85fc7e49" translate="yes" xml:space="preserve">
          <source>It is possible and recommended to search the hyper-parameter space for the best &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt; score.</source>
          <target state="translated">Можно и рекомендуется поискать в пространстве гиперпараметров лучший результат &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;перекрестной проверки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="19b21329d1ba1e2fd90b4634d03905cf0f5e7826" translate="yes" xml:space="preserve">
          <source>It is possible to adjust the threshold of the binarizer:</source>
          <target state="translated">Можно настроить порог бинаризатора:</target>
        </trans-unit>
        <trans-unit id="5fdc4b2c9af36a36fca156373f6cb7c574f550b3" translate="yes" xml:space="preserve">
          <source>It is possible to compute per-label precisions, recalls, F1-scores and supports instead of averaging:</source>
          <target state="translated">Вместо усреднения можно вычислять точность на метку,вспоминания,F1-обновления и поддержки:</target>
        </trans-unit>
        <trans-unit id="c890fcaf4f6baafc6ccf39a67fce7daf92b8b950" translate="yes" xml:space="preserve">
          <source>It is possible to control the randomness for reproducibility of the results by explicitly seeding the &lt;code&gt;random_state&lt;/code&gt; pseudo random number generator.</source>
          <target state="translated">Можно контролировать случайность для воспроизводимости результатов, явно &lt;code&gt;random_state&lt;/code&gt; генератора псевдослучайных чисел random_state .</target>
        </trans-unit>
        <trans-unit id="8c436001d07579c89b669f127dbaf0c3bd65de34" translate="yes" xml:space="preserve">
          <source>It is possible to customize the behavior by passing a callable to the vectorizer constructor:</source>
          <target state="translated">Можно настроить поведение,передав вызываемый конструктор векторизатора:</target>
        </trans-unit>
        <trans-unit id="0839b4d3a34db46e778e581b781425b62631583b" translate="yes" xml:space="preserve">
          <source>It is possible to disable either centering or scaling by either passing &lt;code&gt;with_mean=False&lt;/code&gt; or &lt;code&gt;with_std=False&lt;/code&gt; to the constructor of &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Можно отключить центрирование или масштабирование, передав &lt;code&gt;with_mean=False&lt;/code&gt; или &lt;code&gt;with_std=False&lt;/code&gt; конструктору &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="85a1eed4b8a0f5199be27070848fbc013f8f8638" translate="yes" xml:space="preserve">
          <source>It is possible to get back the category names as follows:</source>
          <target state="translated">Названия категорий можно получить обратно следующим образом:</target>
        </trans-unit>
        <trans-unit id="6b11842b410c7ed9014abd60118219965dd51782" translate="yes" xml:space="preserve">
          <source>It is possible to introspect the scaler attributes to find about the exact nature of the transformation learned on the training data:</source>
          <target state="translated">Можно провести интроспекцию атрибутов скалера,чтобы узнать точную природу трансформации,усвоенную на тренинговых данных:</target>
        </trans-unit>
        <trans-unit id="d994dbf018869cdf387e647211852d55a08f6930" translate="yes" xml:space="preserve">
          <source>It is possible to load only a sub-selection of the categories by passing the list of the categories to load to the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Можно загрузить только подвыбор категорий, передав список категорий для загрузки в функцию &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="03749a52f5e2e7e976928d01767369407c7307c4" translate="yes" xml:space="preserve">
          <source>It is possible to mix sparse and dense arrays in the same run:</source>
          <target state="translated">Возможно смешивать разреженные и плотные массивы в одном прогоне:</target>
        </trans-unit>
        <trans-unit id="be16ce674bae3bf54f6cdc3d4d41c5990ca746b6" translate="yes" xml:space="preserve">
          <source>It is possible to overcome those limitations by combining the &amp;ldquo;hashing trick&amp;rdquo; (&lt;a href=&quot;#feature-hashing&quot;&gt;Feature hashing&lt;/a&gt;) implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt;&lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt;&lt;/a&gt; class and the text preprocessing and tokenization features of the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Эти ограничения можно преодолеть, объединив &amp;laquo;трюк с хешированием&amp;raquo; ( &lt;a href=&quot;#feature-hashing&quot;&gt;хеширование функций&lt;/a&gt; ), реализованный классом &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt; &lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt; &lt;/a&gt; и функциями предварительной обработки текста и токенизации &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="737f1fd475d1dc22b14b4896563d476e36ccb4e8" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Можно сохранить модель в scikit-learn, используя встроенную в Python модель сохраняемости, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="1d319918af937e7b588f1bdf4ba0c9bc1d2e6a8f" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, namely &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Можно сохранить модель в scikit-learn, используя встроенную модель персистентности Python, а именно &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="33bdca276514e666ea92e40ef8d9c04e5206a96b" translate="yes" xml:space="preserve">
          <source>It is possible to specify this explicitly using the parameter &lt;code&gt;categories&lt;/code&gt;. There are two genders, four possible continents and four web browsers in our dataset:</source>
          <target state="translated">Это можно указать явно с помощью &lt;code&gt;categories&lt;/code&gt; параметров . В нашем наборе данных есть два пола, четыре возможных континента и четыре веб-браузера:</target>
        </trans-unit>
        <trans-unit id="cbfa3a3539d1ad40958cd50540686b2891b5e349" translate="yes" xml:space="preserve">
          <source>It is sometimes not enough to center and scale the features independently, since a downstream model can further make some assumption on the linear independence of the features.</source>
          <target state="translated">Иногда бывает недостаточно самостоятельно центрировать и масштабировать черты,так как нисходящая модель может в дальнейшем сделать некоторое предположение о линейной независимости черт.</target>
        </trans-unit>
        <trans-unit id="311a1593daf1f1187805481bab88c0d399c3cecf" translate="yes" xml:space="preserve">
          <source>It is sometimes worthwhile storing the state of a specific transformer since it could be used again. Using a pipeline in &lt;code&gt;GridSearchCV&lt;/code&gt; triggers such situations. Therefore, we use the argument &lt;code&gt;memory&lt;/code&gt; to enable caching.</source>
          <target state="translated">Иногда имеет смысл сохранить состояние конкретного трансформатора, поскольку его можно использовать снова. Использование конвейера в &lt;code&gt;GridSearchCV&lt;/code&gt; вызывает такие ситуации. Поэтому мы используем &lt;code&gt;memory&lt;/code&gt; аргументов, чтобы включить кеширование.</target>
        </trans-unit>
        <trans-unit id="ba51434e495bfdf85ff2401c563345468fae8389" translate="yes" xml:space="preserve">
          <source>It is the fastest algorithm for learning mixture models</source>
          <target state="translated">Это самый быстрый алгоритм для изучения моделей смеси.</target>
        </trans-unit>
        <trans-unit id="5c9cedaa4c291702a05bee05d8b7517536cf8c97" translate="yes" xml:space="preserve">
          <source>It is the opposite as as bigger is better, i.e. large values correspond to inliers.</source>
          <target state="translated">Все наоборот,так как чем больше,тем лучше,т.е.большие значения соответствуют инсайдерам.</target>
        </trans-unit>
        <trans-unit id="b0c456c256349cc53ca134d105c8be601465dd39" translate="yes" xml:space="preserve">
          <source>It is worth noting that RandomForests and ExtraTrees can be fitted in parallel on many cores as each tree is built independently of the others. AdaBoost&amp;rsquo;s samples are built sequentially and so do not use multiple cores.</source>
          <target state="translated">Стоит отметить, что RandomForests и ExtraTrees могут быть установлены параллельно на многих ядрах, поскольку каждое дерево строится независимо от других. Образцы AdaBoost создаются последовательно и поэтому не используют несколько ядер.</target>
        </trans-unit>
        <trans-unit id="a4029704b1c865bc18db0f7f71b472d5421882ac" translate="yes" xml:space="preserve">
          <source>It produces a full piecewise linear solution path, which is useful in cross-validation or similar attempts to tune the model.</source>
          <target state="translated">Она создает полный кусочно-линейный путь решения,что полезно при перекрестной проверке или подобных попытках настройки модели.</target>
        </trans-unit>
        <trans-unit id="a4dee1947755b5fe4ca1a29e0b9b0f0b85817660" translate="yes" xml:space="preserve">
          <source>It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.</source>
          <target state="translated">В дополнение к результатам теста он возвращает надпись,содержащую время,необходимое для тренировки,баллы (и,по желанию,оценки тренировок,а также подогнанные оценочные баллы).</target>
        </trans-unit>
        <trans-unit id="be2089f68dcca4fd6c2250f878425dd499fc444a" translate="yes" xml:space="preserve">
          <source>It returns a dictionary-like object, with the following attributes:</source>
          <target state="translated">Он возвращает словарный объект со следующими атрибутами:</target>
        </trans-unit>
        <trans-unit id="6f65f619abd94296c7075a4b5d91a76ac1e641bc" translate="yes" xml:space="preserve">
          <source>It returns a floating point number that quantifies the &lt;code&gt;estimator&lt;/code&gt; prediction quality on &lt;code&gt;X&lt;/code&gt;, with reference to &lt;code&gt;y&lt;/code&gt;. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.</source>
          <target state="translated">Он возвращает число с плавающей запятой, которое количественно определяет качество предсказания &lt;code&gt;estimator&lt;/code&gt; по &lt;code&gt;X&lt;/code&gt; со ссылкой на &lt;code&gt;y&lt;/code&gt; . Опять же, по соглашению, более высокие числа лучше, поэтому, если ваш секретарь сообщает о проигрыше, это значение следует отрицать.</target>
        </trans-unit>
        <trans-unit id="58c0c1b9288f5ba70bfdf3e509c8376ea38265d4" translate="yes" xml:space="preserve">
          <source>It should be noted that Johnson-Lindenstrauss lemma can yield very conservative estimated of the required number of components as it makes no assumption on the structure of the dataset.</source>
          <target state="translated">Следует отметить,что лемма Джонсона-Линденстрауса может дать очень консервативную оценку требуемого количества компонентов,так как не делает никаких предположений о структуре набора данных.</target>
        </trans-unit>
        <trans-unit id="5bcecde02163a3a6b9fb69b7700a66c21be36347" translate="yes" xml:space="preserve">
          <source>It shows how to use &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; to approximate the feature map of an RBF kernel for classification with an SVM on the digits dataset. Results using a linear SVM in the original space, a linear SVM using the approximate mappings and using a kernelized SVM are compared. Timings and accuracy for varying amounts of Monte Carlo samplings (in the case of &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt;, which uses random Fourier features) and different sized subsets of the training set (for &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;) for the approximate mapping are shown.</source>
          <target state="translated">В нем показано, как использовать &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; для аппроксимации карты характеристик ядра RBF для классификации с помощью SVM в наборе данных цифр. Сравниваются результаты с использованием линейной SVM в исходном пространстве, линейной SVM, использующей приблизительные отображения и использующей ядро ​​SVM. Показаны сроки и точность для различного количества выборок Монте-Карло (в случае &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; , который использует случайные функции Фурье) и подмножества обучающего набора разного размера (для &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; ) для приблизительного отображения.</target>
        </trans-unit>
        <trans-unit id="45249c231a1e8d583e28deb277d22f5fe88e16b7" translate="yes" xml:space="preserve">
          <source>It turns a collection of text documents into a scipy.sparse matrix holding token occurrence counts (or binary occurrence information), possibly normalized as token frequencies if norm=&amp;rsquo;l1&amp;rsquo; or projected on the euclidean unit sphere if norm=&amp;rsquo;l2&amp;rsquo;.</source>
          <target state="translated">Он превращает набор текстовых документов в матрицу scipy.sparse, содержащую количество вхождений токенов (или двоичную информацию вхождений), возможно, нормализованные как частоты токенов, если norm = 'l1', или проецируемые на евклидову единичную сферу, если norm = 'l2'.</target>
        </trans-unit>
        <trans-unit id="9b65a724f589693294d8b39fded9beef68bf84ef" translate="yes" xml:space="preserve">
          <source>It updates its model only on mistakes.</source>
          <target state="translated">Он обновляет свою модель только на ошибки.</target>
        </trans-unit>
        <trans-unit id="4ef1ebaa3d2757730ff62ab1b50211fc95aec89a" translate="yes" xml:space="preserve">
          <source>It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.</source>
          <target state="translated">Он использует LAPACK реализацию полного SVD или рандомизированного усеченного SVD методом Halko и др.2009,в зависимости от формы входных данных и количества компонентов для извлечения.</target>
        </trans-unit>
        <trans-unit id="eb35f7366145b28ea8e69aba84c19929cb4fd162" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s also possible for almost all of these function to constrain the output to be a tuple containing only the data and the target, by setting the &lt;code&gt;return_X_y&lt;/code&gt; parameter to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Также для почти всех этих функций возможно ограничить вывод как кортеж, содержащий только данные и цель, установив для параметра &lt;code&gt;return_X_y&lt;/code&gt; значение &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="522ad20a1aa12ab3e8e796322f388a9318be6368" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s clear how the kernel shape affects the smoothness of the resulting distribution. The scikit-learn kernel density estimator can be used as follows:</source>
          <target state="translated">Понятно, как форма ядра влияет на гладкость полученного распределения. Оценщик плотности ядра scikit-learn можно использовать следующим образом:</target>
        </trans-unit>
        <trans-unit id="262f72bd253b7e8f886f3645ecd5afaaf624d7fc" translate="yes" xml:space="preserve">
          <source>Iterate 2 and 3 until convergence.</source>
          <target state="translated">Итерация 2 и 3 до конвергенции.</target>
        </trans-unit>
        <trans-unit id="f2f172891cc8c1241e8513ed23c4f46ceb939f0f" translate="yes" xml:space="preserve">
          <source>Iterative procedure to maximize the evidence</source>
          <target state="translated">Итеративная процедура для максимизации доказательств</target>
        </trans-unit>
        <trans-unit id="1e87dcaf344d15783f1af4ad18b162b497d772d4" translate="yes" xml:space="preserve">
          <source>Its dual is</source>
          <target state="translated">Его двойственность заключается в том,что</target>
        </trans-unit>
        <trans-unit id="4ba292a3729a3ffa6797e98ae7a24bba4f0e087f" translate="yes" xml:space="preserve">
          <source>J. Davis, M. Goadrich, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;The Relationship Between Precision-Recall and ROC Curves&lt;/a&gt;, ICML 2006.</source>
          <target state="translated">Дж. Дэвис, М. Гоадрич, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;Взаимосвязь между&lt;/a&gt; точным воспроизведением и кривыми ROC , ICML 2006.</target>
        </trans-unit>
        <trans-unit id="9f9ca6a90c561398be254053aedc4a945c9160d7" translate="yes" xml:space="preserve">
          <source>J. Friedman, &amp;ldquo;Multivariate adaptive regression splines&amp;rdquo;, The Annals of Statistics 19 (1), pages 1-67, 1991.</source>
          <target state="translated">Дж. Фридман, &amp;laquo;Сплайны многомерной адаптивной регрессии&amp;raquo;, &amp;laquo;Анналы статистики&amp;raquo; 19 (1), страницы 1-67, 1991.</target>
        </trans-unit>
        <trans-unit id="f3a4e2abf1b3937c134504328e857f33b32a50ea" translate="yes" xml:space="preserve">
          <source>J. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</source>
          <target state="translated">J.Фридман,Приближение Жадных Функций:Машина градиентной стимуляции,Летопись статистики,Том 29,№ 5,2001.</target>
        </trans-unit>
        <trans-unit id="37cd6f13ac969b2cba8a5a7a242580515d06793b" translate="yes" xml:space="preserve">
          <source>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (&lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt;)</source>
          <target state="translated">Дж. Майрал, Ф. Бах, Дж. Понсе, Дж. Сапиро, 2009: изучение онлайн-словарей для разреженного кодирования ( &lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="d67bb0042b556d1819c5bcf6e551c8393e0d921f" translate="yes" xml:space="preserve">
          <source>J. Nothman, H. Qin and R. Yurchak (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&amp;ldquo;Stop Word Lists in Free Open-source Software Packages&amp;rdquo;&lt;/a&gt;. In &lt;em&gt;Proc. Workshop for NLP Open Source Software&lt;/em&gt;.</source>
          <target state="translated">Дж. Нотман, Х. Цинь и Р. Юрчак (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&amp;laquo;Списки стоп-слов в бесплатных пакетах программного обеспечения с открытым исходным кодом&amp;raquo;&lt;/a&gt; . В &lt;em&gt;Proc. Практикум по НЛП с открытым исходным кодом&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="692e866d29ab5ac27b12eb939942a283756e56c6" translate="yes" xml:space="preserve">
          <source>J. Zhu, H. Zou, S. Rosset, T. Hastie. &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Дж. Чжу, Х. Цзоу, С. Россет, Т. Хасти. &amp;laquo;Мульти-класс AdaBoost&amp;raquo;, 2009 г.</target>
        </trans-unit>
        <trans-unit id="5d92020b429e9c336d3ae7d33c4ba163d63036bb" translate="yes" xml:space="preserve">
          <source>J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.</source>
          <target state="translated">Джей-Ар Куинлан.C4.5:программы для машинного обучения.Морган Кауфманн,1993.</target>
        </trans-unit>
        <trans-unit id="b259e0488f66e10ad76098d33440aa4c5f23c876" translate="yes" xml:space="preserve">
          <source>JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case&lt;/a&gt;</source>
          <target state="translated">JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;Обзор методов частичных наименьших квадратов (PLS) с упором на двухблочный случай&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="89591613ce2ead27076b0dd7b68b18da1f4e31d9" translate="yes" xml:space="preserve">
          <source>Jaccard similarity coefficient score</source>
          <target state="translated">балл коэффициента сходства Jaccard</target>
        </trans-unit>
        <trans-unit id="3dd35b446a7d3de6ee5688cfabde9bb7cc55f61a" translate="yes" xml:space="preserve">
          <source>JaccardDistance</source>
          <target state="translated">JaccardDistance</target>
        </trans-unit>
        <trans-unit id="493395686693db33a59d5eea00e82ad6c02c5742" translate="yes" xml:space="preserve">
          <source>Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case. Technical Report 371, Department of Statistics, University of Washington, Seattle, 2000.</source>
          <target state="translated">Джейкоб А.Уэгелин.Опрос методов наименьших частичных квадратов (PLS)с акцентом на двухблочный случай.Технический доклад 371,факультет статистики,Вашингтонский университет,Сиэтл,2000 год.</target>
        </trans-unit>
        <trans-unit id="80af07b09c2acb231d89e62f1382b88433574f92" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank,</source>
          <target state="translated">Джесси Рид,Бернхард Пфаринджер,Джефф Холмс,Ю Фрэнк,</target>
        </trans-unit>
        <trans-unit id="6f9c9a3eee3a8f7459d68946df6ef289f22fee94" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, &amp;ldquo;Classifier Chains for Multi-label Classification&amp;rdquo;, 2009.</source>
          <target state="translated">Джесси Рид, Бернхард Пфарингер, Джефф Холмс, Эйбе Франк, &amp;laquo;Цепочки классификаторов для многокомпонентной классификации&amp;raquo;, 2009 г.</target>
        </trans-unit>
        <trans-unit id="2da78ef6529cd970b51628e985f5f2ea249ac134" translate="yes" xml:space="preserve">
          <source>Johanna Hardin, David M Rocke. The distribution of robust distances. Journal of Computational and Graphical Statistics. December 1, 2005, 14(4): 928-946.</source>
          <target state="translated">Джоанна Хардин,Дэвид М.Рокк.Распределение прочных расстояний.Журнал вычислительной и графической статистики.1 декабря 2005,14(4):928-946.</target>
        </trans-unit>
        <trans-unit id="f669c43cc07002b0d2c74696c2e577f06e2f830d" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;.</source>
          <target state="translated">Джон. Д. Келлехер, Брайан Мак Нейми, Аойф Д'Арси, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Основы машинного обучения для прогнозной аналитики данных: алгоритмы, рабочие примеры и тематические исследования&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7aafef76ed32e6bfff8b0b682dc86da3ac5a13fa" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;, 2015.</source>
          <target state="translated">Джон. Д. Келлехер, Брайан Мак Нейме, Аойф Д'Арси, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Основы машинного обучения для прогнозного анализа данных: алгоритмы, отработанные примеры и тематические исследования&lt;/a&gt; , 2015 г.</target>
        </trans-unit>
        <trans-unit id="19e6bf8efc7133dd97d0abbd89569a0495139bdc" translate="yes" xml:space="preserve">
          <source>Joint feature selection with multi-task Lasso</source>
          <target state="translated">Выбор совместной функции с многозадачным Лассо</target>
        </trans-unit>
        <trans-unit id="6e210d8e33bded6f565ddf30568ce6ee46546dcb" translate="yes" xml:space="preserve">
          <source>Joint parameter selection</source>
          <target state="translated">Совместный выбор параметров</target>
        </trans-unit>
        <trans-unit id="5dcd2dd79faa568a08732dcdc7a1c5d001632db6" translate="yes" xml:space="preserve">
          <source>Journal of Machine Learning Research 15(Oct):3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</source>
          <target state="translated">Journal of Machine Learning Research 15 (октябрь): 3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6689749f561220cbe925de6f0809b1dc75c6258d" translate="yes" xml:space="preserve">
          <source>July, 1988</source>
          <target state="translated">июль 1988 года</target>
        </trans-unit>
        <trans-unit id="854e66ede1ccc0e35f92ec3068666dcad934aaf9" translate="yes" xml:space="preserve">
          <source>July; 1998</source>
          <target state="translated">июль 1998 года</target>
        </trans-unit>
        <trans-unit id="a2a7da9b458fe4f43b31552673f0b66352445d61" translate="yes" xml:space="preserve">
          <source>Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN Error Measures in MultiClass Prediction</source>
          <target state="translated">Юрман,Риккадонна,Фурланелло,(2012).Сравнение мер по ошибкам MCC и CEN в многоклассовом прогнозировании.</target>
        </trans-unit>
        <trans-unit id="a8dcc7a6052d083397dd89c88efdae4d16610c1e" translate="yes" xml:space="preserve">
          <source>Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;data transformations&lt;/a&gt; similarly should be learnt from a training set and applied to held-out data for prediction:</source>
          <target state="translated">Так же, как важно протестировать предсказатель на данных, полученных в результате обучения, предварительная обработка (например, стандартизация, выбор функций и т. Д.) И аналогичные &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;преобразования данных&lt;/a&gt; аналогичным образом должны быть изучены из обучающего набора и применены к удерживаемым данным для прогнозирования. :</target>
        </trans-unit>
        <trans-unit id="19ba747b37c5ad6ac1cc4689022bdfff83622716" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a in b), but with a nicer default message.</source>
          <target state="translated">Так же как и self.assertTrue(a в b),но с более приятным сообщением по умолчанию.</target>
        </trans-unit>
        <trans-unit id="a7abce2837c2684f6308e0a3abb93654038ccc5f" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a not in b), but with a nicer default message.</source>
          <target state="translated">Так же как и self.assertTrue(a не в b),но с более приятным сообщением по умолчанию.</target>
        </trans-unit>
        <trans-unit id="57113affe2edb0e21a97719d086746970040c08f" translate="yes" xml:space="preserve">
          <source>K&amp;auml;rkk&amp;auml;inen and S. &amp;Auml;yr&amp;auml;m&amp;ouml;: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;On Computation of Spatial Median for Robust Data Mining.&lt;/a&gt;</source>
          <target state="translated">Кярккяйнен и С. Эйрамё: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;О вычислении пространственной&lt;/a&gt; медианы для надежного интеллектуального анализа данных.</target>
        </trans-unit>
        <trans-unit id="7c859ded2bd8aa408f6c0369beaf2c2cf3f0ddde" translate="yes" xml:space="preserve">
          <source>K(X, Y) = &amp;lt;X, Y&amp;gt; / (||X||*||Y||)</source>
          <target state="translated">K (X, Y) = &amp;lt;X, Y&amp;gt; / (|| X || * || Y ||)</target>
        </trans-unit>
        <trans-unit id="86beb78a3bdf4132202cbc165378339bb7f278e3" translate="yes" xml:space="preserve">
          <source>K-Folds cross-validator</source>
          <target state="translated">перекрёстный валидатор K-Fold</target>
        </trans-unit>
        <trans-unit id="66e29f0aeaaf6f3b77934175874c79014b658ea2" translate="yes" xml:space="preserve">
          <source>K-Means</source>
          <target state="translated">K-Means</target>
        </trans-unit>
        <trans-unit id="bc6e2dbca5eeaca5cfd908f6085c13e70dbbe207" translate="yes" xml:space="preserve">
          <source>K-Means clustering</source>
          <target state="translated">кластеризация Кей-Минов</target>
        </trans-unit>
        <trans-unit id="c532c5671424d23a3a3bc85d7cee5f6f8a964404" translate="yes" xml:space="preserve">
          <source>K-fold iterator variant with non-overlapping groups.</source>
          <target state="translated">Вариант К-образного итератора с неперекрывающимися группами.</target>
        </trans-unit>
        <trans-unit id="8434c9f312099287fd33427192dcba6bdae1583b" translate="yes" xml:space="preserve">
          <source>K-means Clustering</source>
          <target state="translated">кластеризация K-средних</target>
        </trans-unit>
        <trans-unit id="16176fa529a1e6d30521129cdc8f04353aaff22e" translate="yes" xml:space="preserve">
          <source>K-means algorithm to use. The classical EM-style algorithm is &amp;ldquo;full&amp;rdquo;. The &amp;ldquo;elkan&amp;rdquo; variation is more efficient by using the triangle inequality, but currently doesn&amp;rsquo;t support sparse data. &amp;ldquo;auto&amp;rdquo; chooses &amp;ldquo;elkan&amp;rdquo; for dense data and &amp;ldquo;full&amp;rdquo; for sparse data.</source>
          <target state="translated">Используемый алгоритм K-средних. Классический алгоритм EM-стиля - &amp;laquo;полный&amp;raquo;. Вариант &amp;laquo;elkan&amp;raquo; более эффективен при использовании неравенства треугольника, но в настоящее время не поддерживает разреженные данные. &amp;laquo;Auto&amp;raquo; выбирает &amp;laquo;elkan&amp;raquo; для плотных данных и &amp;laquo;full&amp;raquo; для разреженных данных.</target>
        </trans-unit>
        <trans-unit id="848dff73d6f69d92cd5b01b40f76a731abde9743" translate="yes" xml:space="preserve">
          <source>K-means can be used for vector quantization. This is achieved using the transform method of a trained model of &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">K-средства могут использоваться для векторного квантования. Это достигается с помощью метода преобразования обученной модели &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ba78203e9e9f38ce3f7e015938283eb704622fc1" translate="yes" xml:space="preserve">
          <source>K-means clustering</source>
          <target state="translated">K-средняя кластеризация</target>
        </trans-unit>
        <trans-unit id="4c31918fe250fba32eafec9c8bd2408d0665baa0" translate="yes" xml:space="preserve">
          <source>K-means clustering algorithm.</source>
          <target state="translated">Алгоритм кластеризации К-средства.</target>
        </trans-unit>
        <trans-unit id="3f9399be9d9993e05f4712a210efb7bcf391430f" translate="yes" xml:space="preserve">
          <source>K-means is equivalent to the expectation-maximization algorithm with a small, all-equal, diagonal covariance matrix.</source>
          <target state="translated">К-средние эквивалентно алгоритму матожидания-максимизации с маленькой,полностью равной,диагональной ковариационной матрицей.</target>
        </trans-unit>
        <trans-unit id="f931e58c5b02fb6c60e80955646f359bee6ac7ee" translate="yes" xml:space="preserve">
          <source>K-means is often referred to as Lloyd&amp;rsquo;s algorithm. In basic terms, the algorithm has three steps. The first step chooses the initial centroids, with the most basic method being to choose \(k\) samples from the dataset \(X\). After initialization, K-means consists of looping between the two other steps. The first step assigns each sample to its nearest centroid. The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids are computed and the algorithm repeats these last two steps until this value is less than a threshold. In other words, it repeats until the centroids do not move significantly.</source>
          <target state="translated">K-средних часто называют алгоритмом Ллойда. В основном алгоритм состоит из трех шагов. На первом этапе выбираются начальные центроиды, при этом самый простой метод - выбрать \ (k \) выборки из набора данных \ (X \). После инициализации K-means состоит из цикла между двумя другими шагами. На первом этапе каждой выборке присваивается ближайший центроид. На втором этапе создаются новые центроиды, взяв среднее значение всех выборок, назначенных каждому предыдущему центроиду. Вычисляется разница между старым и новым центроидами, и алгоритм повторяет эти последние два шага, пока это значение не станет меньше порогового значения. Другими словами, это повторяется до тех пор, пока центроиды не переместятся значительно.</target>
        </trans-unit>
        <trans-unit id="c91b0be65ee9c7db25b71aa279369cca08edc7ca" translate="yes" xml:space="preserve">
          <source>K-means quantization</source>
          <target state="translated">квантование K-средних</target>
        </trans-unit>
        <trans-unit id="5cf295fcd230ab825b1fa5bcf82b9dac494d126c" translate="yes" xml:space="preserve">
          <source>KDTree for fast generalized N-point problems</source>
          <target state="translated">Дерево KDTree для быстрых обобщенных проблем с N точками</target>
        </trans-unit>
        <trans-unit id="34d74f913e8bd68fa4a9d1c4d3966f34ca72fc15" translate="yes" xml:space="preserve">
          <source>KDTree(X, leaf_size=40, metric=&amp;rsquo;minkowski&amp;rsquo;, **kwargs)</source>
          <target state="translated">KDTree (X, лист_размер = 40, метрика = 'минковски', ** kwargs)</target>
        </trans-unit>
        <trans-unit id="8a130d990c735953536ce43a1c5cf50c4989bca1" translate="yes" xml:space="preserve">
          <source>Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators.</source>
          <target state="translated">Оценки Kappa могут быть вычислены для двоичных или многоклассовых задач,но не для многомаркировочных задач (за исключением ручного вычисления оценки на метку)и не более чем для двух аннотаторов.</target>
        </trans-unit>
        <trans-unit id="992bd2f88020b43ae9d881f8a8ecb43504cd4a74" translate="yes" xml:space="preserve">
          <source>Keep the 3 RGB channels instead of averaging them to a single gray level channel. If color is True the shape of the data has one more dimension than the shape with color = False.</source>
          <target state="translated">Держите 3 канала RGB вместо того,чтобы усреднять их до одного канала уровня серого.Если цвет равен True,то форма данных имеет на одно измерение больше,чем форма с цветом=False.</target>
        </trans-unit>
        <trans-unit id="e85b73c38883acb129e419e1a2f1719d75a444c5" translate="yes" xml:space="preserve">
          <source>Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.</source>
          <target state="translated">Кен Тан и Поннутхурай Н.Шугантан и Си Яо и А.Кай Цинь.Уменьшение линейной размерности с использованием релевантной взвешенной LDA.Школа электрической и электронной техники Наньаньского технологического университета.2005.</target>
        </trans-unit>
        <trans-unit id="4ac337776123607052d628758806e2172a140241" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimate of Species Distributions</source>
          <target state="translated">Оценка ядерной плотности распределения видов</target>
        </trans-unit>
        <trans-unit id="1794dd0445cf0665650fb5446983f4ef8a3519d3" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimation</source>
          <target state="translated">оценка зерновой плотности</target>
        </trans-unit>
        <trans-unit id="3bd4b1d4f074cf6b0f30ea849b2a75ad1d3777d9" translate="yes" xml:space="preserve">
          <source>Kernel PCA</source>
          <target state="translated">PCA Кернел</target>
        </trans-unit>
        <trans-unit id="e5cb129fc99d7ba99fe28de6d8de36380920334b" translate="yes" xml:space="preserve">
          <source>Kernel PCA was introduced in:</source>
          <target state="translated">Кернел PCA был представлен в:</target>
        </trans-unit>
        <trans-unit id="ba5a4a64bda1b4288aa7730d4a3cc2a5a99cf5dc" translate="yes" xml:space="preserve">
          <source>Kernel Principal component analysis (KPCA)</source>
          <target state="translated">Анализ основных компонентов ядра (KPCA)</target>
        </trans-unit>
        <trans-unit id="f9f3967ca79560e0b7bba219989bbd17450e2f6e" translate="yes" xml:space="preserve">
          <source>Kernel bandwidth.</source>
          <target state="translated">Полоса пропускания ядра.</target>
        </trans-unit>
        <trans-unit id="8f8874978483d89d1eb3e15131193d11bfd798e3" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">Коэффициент ядра для 'rbf', 'poly' и 'sigmoid'.</target>
        </trans-unit>
        <trans-unit id="97392135d656893f41c86b28ea3abd0d9e018bae" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf kernel.</source>
          <target state="translated">Коэффициент ядра для ядра rbf.</target>
        </trans-unit>
        <trans-unit id="0ae546d11d3317bcab299286e34e2f35ebfa8832" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Коэффициент ядра для rbf,поли и сигмовидных ядер.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="4a5a36cb73b6fa8cb90e406a9b203038f766b3f9" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels. Ignored for &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt;.</source>
          <target state="translated">Коэффициент ядра для ядер rbf, poly, sigmoid, laplacian и chi2. Игнорируется для &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ed139f80ae0f25db98c92c5cce6311e8435271b" translate="yes" xml:space="preserve">
          <source>Kernel density estimation in scikit-learn is implemented in the &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator, which uses the Ball Tree or KD Tree for efficient queries (see &lt;a href=&quot;neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; for a discussion of these). Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions.</source>
          <target state="translated">Оценка плотности ядра в scikit-learn реализована в &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; , который использует Ball Tree или KD Tree для эффективных запросов ( обсуждение этих вопросов см. В разделе &amp;laquo; &lt;a href=&quot;neighbors#neighbors&quot;&gt;Ближайшие соседи&amp;raquo;&lt;/a&gt; ). Хотя в приведенном выше примере для простоты используется набор одномерных данных, оценка плотности ядра может быть выполнена в любом количестве измерений, хотя на практике проклятие размерности приводит к ухудшению его производительности в больших измерениях.</target>
        </trans-unit>
        <trans-unit id="55e8fbe20e17e26ae0f3d4e88a1aeba0651c9393" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Гиперпараметры ядра, для которых оценивается предельное логарифмическое правдоподобие. Если None, возвращается предварительно вычисленное значение log_marginal_likelihood для &lt;code&gt;self.kernel_.theta&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aef459d7999942524bf342d4727b96b71e8fe80a" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. In the case of multi-class classification, theta may be the hyperparameters of the compound kernel or of an individual kernel. In the latter case, all individual kernel get assigned the same theta values. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Гиперпараметры ядра, для которых оценивается предельное логарифмическое правдоподобие. В случае многоклассовой классификации тета может быть гиперпараметрами составного ядра или отдельного ядра. В последнем случае всем индивидуальным ядрам присваиваются одинаковые значения тета. Если None, возвращается предварительно вычисленное значение log_marginal_likelihood для &lt;code&gt;self.kernel_.theta&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e5fe7d4b4a2b4b1f4287c0408af092681ae17306" translate="yes" xml:space="preserve">
          <source>Kernel k(X, Y)</source>
          <target state="translated">Ядро k(X,Y)</target>
        </trans-unit>
        <trans-unit id="3ec24bca52509370dd13e99805241c7649952db1" translate="yes" xml:space="preserve">
          <source>Kernel map to be approximated. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number.</source>
          <target state="translated">Карта ядра должна быть аппроксимирована.Вызываемый объект должен принимать два аргумента и аргументы ключевого слова,переданные этому объекту как kernel_params,и должен возвращать номер с плавающей точкой.</target>
        </trans-unit>
        <trans-unit id="819d0e343c77a54a44f85a514be1d98b92643c33" translate="yes" xml:space="preserve">
          <source>Kernel mapping used internally. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number. Set to &amp;ldquo;precomputed&amp;rdquo; in order to pass a precomputed kernel matrix to the estimator methods instead of samples.</source>
          <target state="translated">Отображение ядра для внутреннего использования. Вызываемый объект должен принимать два аргумента и аргументы ключевого слова, переданные этому объекту как kernel_params, и должен возвращать число с плавающей запятой. Установите значение &amp;laquo;предварительно вычислено&amp;raquo;, чтобы передать предварительно вычисленную матрицу ядра методам оценки вместо выборок.</target>
        </trans-unit>
        <trans-unit id="5470105c2039f2210b1a2c9d8e55edfd818f2e42" translate="yes" xml:space="preserve">
          <source>Kernel matrix.</source>
          <target state="translated">Матрица ядра.</target>
        </trans-unit>
        <trans-unit id="839a7f66845e964bf2afbaec5611c3402217b903" translate="yes" xml:space="preserve">
          <source>Kernel methods like support vector machines or kernelized PCA rely on a property of reproducing kernel Hilbert spaces. For any positive definite kernel function \(k\) (a so called Mercer kernel), it is guaranteed that there exists a mapping \(\phi\) into a Hilbert space \(\mathcal{H}\), such that</source>
          <target state="translated">Методы ядра,такие как поддерживающие векторные машины или ядро PCA,полагаются на свойство воспроизведения пространств ядра Гильберта.Для любой положительной определенной функции ядра \(k\)(так называемое ядро Мерсера)гарантируется,что существует отображение \(\phi\)в пространство Гильберта \(\mathcal{H}\),такое,что</target>
        </trans-unit>
        <trans-unit id="a3bb404582c234b1b5161269097e65342126edc8" translate="yes" xml:space="preserve">
          <source>Kernel methods to project data into alternate dimensional spaces</source>
          <target state="translated">Методы ядра для проектирования данных в альтернативные размерные пространства</target>
        </trans-unit>
        <trans-unit id="7853e504e205e94517ed94484ade6d5285c25255" translate="yes" xml:space="preserve">
          <source>Kernel operators take one or two base kernels and combine them into a new kernel. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{sum}(X, Y) = k1(X, Y) + k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{product}(X, Y) = k1(X, Y) * k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt;&lt;code&gt;Exponentiation&lt;/code&gt;&lt;/a&gt; kernel takes one base kernel and a scalar parameter \(exponent\) and combines them via \(k_{exp}(X, Y) = k(X, Y)^\text{exponent}\).</source>
          <target state="translated">Операторы ядра берут одно или два базовых ядра и объединяют их в новое ядро. &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt; ядро имеет два ядра \ (k1 \) и \ (k2 \) и объединяет их с помощью \ (k_ {сумма} (X, Y) = k1 (X, Y) + k2 (X, Y) \). &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; &lt;/a&gt; Ядро имеет два ядра \ (k1 \) и \ (k2 \) и объединяет их с помощью \ (k_ {произведение} (X, Y) = k1 (X, Y) * k2 (X, Y) \). &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt; &lt;code&gt;Exponentiation&lt;/code&gt; &lt;/a&gt; ядро занимает одно базовое ядро и скалярный параметр \ (экспоненту \) и объединяет их с помощью \ (k_ {ехр} (X, Y) = к (X, Y) = \ текст {показатель} \).</target>
        </trans-unit>
        <trans-unit id="9dc320ddac29ab60da57cafc47693079e4b6b082" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; combines &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;Ridge Regression&lt;/a&gt; (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">Регрессия гребня ядра (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; сочетает в себе &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;регрессию&lt;/a&gt; гребня (линейный метод наименьших квадратов с регуляризацией по l2-норме) с уловкой ядра. Таким образом, он изучает линейную функцию в пространстве, индуцированную соответствующим ядром и данными. Для нелинейных ядер это соответствует нелинейной функции в исходном пространстве.</target>
        </trans-unit>
        <trans-unit id="7d585be11bb912be319b898c908d63ce568dd8c0" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">Регрессия гребня ядра (KRR)сочетает регрессию гребня (линейные наименьшие квадраты с регуляризацией l2-формы)с трюком ядра.Таким образом,она узнает линейную функцию в пространстве,индуцированном соответствующим ядром и данными.Для нелинейных ядер это соответствует нелинейной функции в исходном пространстве.</target>
        </trans-unit>
        <trans-unit id="262cee695a2ed79939315817b4a3a26823167afe" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression combines ridge regression with the kernel trick</source>
          <target state="translated">Регрессия гребня ядра сочетает в себе регрессию гребня с трюком ядра</target>
        </trans-unit>
        <trans-unit id="589ad014b6254add975c198ac204f9560e253ac1" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression.</source>
          <target state="translated">Кернел-хребетная регрессия.</target>
        </trans-unit>
        <trans-unit id="a797077c9a6730a652ad75f039a934d138c2b41f" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed.</source>
          <target state="translated">Ядро для использования в модели:линейное,полиномиальное,RBF,сигмовидное или предварительно рассчитанное.</target>
        </trans-unit>
        <trans-unit id="407ab400408caf91955e34873fdbfe1f6ae14b07" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed. &amp;lsquo;rbf&amp;rsquo; by default.</source>
          <target state="translated">Ядро для использования в модели: линейное, полиномиальное, RBF, сигмовидное или предварительно вычисленное. По умолчанию 'rbf'.</target>
        </trans-unit>
        <trans-unit id="716837a63a81bd1da24c9f2580ff0581777fc381" translate="yes" xml:space="preserve">
          <source>Kernel which is composed of a set of other kernels.</source>
          <target state="translated">Ядро,которое состоит из набора других ядер.</target>
        </trans-unit>
        <trans-unit id="a170413f32a293189023e0700b83d22ea6042972" translate="yes" xml:space="preserve">
          <source>Kernel. Default=&amp;rdquo;linear&amp;rdquo;.</source>
          <target state="translated">Ядро. По умолчанию = &amp;laquo;линейный&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="e3cb275740ef8ee4f25f4b8b1bb2cb56094f01c1" translate="yes" xml:space="preserve">
          <source>Kernels (also called &amp;ldquo;covariance functions&amp;rdquo; in the context of GPs) are a crucial ingredient of GPs which determine the shape of prior and posterior of the GP. They encode the assumptions on the function being learned by defining the &amp;ldquo;similarity&amp;rdquo; of two datapoints combined with the assumption that similar datapoints should have similar target values. Two categories of kernels can be distinguished: stationary kernels depend only on the distance of two datapoints and not on their absolute values \(k(x_i, x_j)= k(d(x_i, x_j))\) and are thus invariant to translations in the input space, while non-stationary kernels depend also on the specific values of the datapoints. Stationary kernels can further be subdivided into isotropic and anisotropic kernels, where isotropic kernels are also invariant to rotations in the input space. For more details, we refer to Chapter 4 of &lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">Ядра (также называемые &amp;laquo;ковариационными функциями&amp;raquo; в контексте GP) являются важнейшим компонентом GP, которые определяют форму предшествующих и апостериорных функций GP. Они кодируют предположения об изучаемой функции, определяя &amp;laquo;сходство&amp;raquo; двух точек данных в сочетании с предположением, что аналогичные точки данных должны иметь похожие целевые значения. Можно выделить две категории ядер: стационарные ядра зависят только от расстояния до двух точек данных, а не от их абсолютных значений \ (k (x_i, x_j) = k (d (x_i, x_j)) \) и, таким образом, инвариантны к трансляциям. во входном пространстве, в то время как нестационарные ядра зависят также от конкретных значений точек данных. Стационарные ядра могут быть далее подразделены на изотропные и анизотропные ядра, где изотропные ядра также инвариантны к поворотам во входном пространстве. Больше подробностей,мы ссылаемся на главу 4&lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0ad8dd8fec70a9d46c4f724f1ce47b4b45810363" translate="yes" xml:space="preserve">
          <source>Kernels are measures of similarity, i.e. &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; if objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are considered &amp;ldquo;more similar&amp;rdquo; than objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt;. A kernel must also be positive semi-definite.</source>
          <target state="translated">Ядра - это меры сходства, то есть &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; если объекты &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;b&lt;/code&gt; считаются &amp;laquo;более похожими&amp;raquo;, чем объекты &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;c&lt;/code&gt; . Ядро также должно быть положительно полуопределенным.</target>
        </trans-unit>
        <trans-unit id="cd28143394596209b24bd87df6806973641c2997" translate="yes" xml:space="preserve">
          <source>Kernels are parameterized by a vector \(\theta\) of hyperparameters. These hyperparameters can for instance control length-scales or periodicity of a kernel (see below). All kernels support computing analytic gradients of of the kernel&amp;rsquo;s auto-covariance with respect to \(\theta\) via setting &lt;code&gt;eval_gradient=True&lt;/code&gt; in the &lt;code&gt;__call__&lt;/code&gt; method. This gradient is used by the Gaussian process (both regressor and classifier) in computing the gradient of the log-marginal-likelihood, which in turn is used to determine the value of \(\theta\), which maximizes the log-marginal-likelihood, via gradient ascent. For each hyperparameter, the initial value and the bounds need to be specified when creating an instance of the kernel. The current value of \(\theta\) can be get and set via the property &lt;code&gt;theta&lt;/code&gt; of the kernel object. Moreover, the bounds of the hyperparameters can be accessed by the property &lt;code&gt;bounds&lt;/code&gt; of the kernel. Note that both properties (theta and bounds) return log-transformed values of the internally used values since those are typically more amenable to gradient-based optimization. The specification of each hyperparameter is stored in the form of an instance of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt;&lt;code&gt;Hyperparameter&lt;/code&gt;&lt;/a&gt; in the respective kernel. Note that a kernel using a hyperparameter with name &amp;ldquo;x&amp;rdquo; must have the attributes self.x and self.x_bounds.</source>
          <target state="translated">Ядра параметризованы вектором \ (\ theta \) гиперпараметров. Эти гиперпараметры могут, например, управлять масштабами длины или периодичностью ядра (см. Ниже). Все ядра поддерживают вычисление аналитических градиентов &lt;code&gt;eval_gradient=True&lt;/code&gt; ядра по отношению к \ (\ theta \) посредством установки eval_gradient = True в методе &lt;code&gt;__call__&lt;/code&gt; . Этот градиент используется гауссовским процессом (как регрессором, так и классификатором) при вычислении градиента логарифмического предельного правдоподобия, который, в свою очередь, используется для определения значения \ (\ theta \), которое максимизирует логарифмически маржинальное правдоподобие. вероятность, через градиентный подъем. Для каждого гиперпараметра необходимо указать начальное значение и границы при создании экземпляра ядра. Текущее значение \ (\ theta \) можно получить и установить через свойство &lt;code&gt;theta&lt;/code&gt; объекта ядра. Более того, границы гиперпараметров могут быть доступны по &lt;code&gt;bounds&lt;/code&gt; свойств ядра. Обратите внимание, что оба свойства (тета и границы) возвращают логарифмически преобразованные значения внутренних значений, поскольку они обычно более поддаются оптимизации на основе градиента. Спецификация каждого гиперпараметра хранится в форме экземпляра &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt; &lt;code&gt;Hyperparameter&lt;/code&gt; &lt;/a&gt; в соответствующем ядре. Обратите внимание, что ядро, использующее гиперпараметр с именем &amp;laquo;x&amp;raquo;, должно иметь атрибуты self.x и self.x_bounds.</target>
        </trans-unit>
        <trans-unit id="2a754d09a87b01a5043bf319d676ca0f6cb6a853" translate="yes" xml:space="preserve">
          <source>Kernels:</source>
          <target state="translated">Kernels:</target>
        </trans-unit>
        <trans-unit id="c3b9fc0d0d17c07a841795715ed044ed9e710926" translate="yes" xml:space="preserve">
          <source>Kevin P. Murphy &amp;ldquo;Machine Learning: A Probabilistic Perspective&amp;rdquo;, The MIT Press chapter 14.4.3, pp. 492-493</source>
          <target state="translated">Кевин П. Мерфи &amp;laquo;Машинное обучение: вероятностная перспектива&amp;raquo;, MIT Press, глава 14.4.3, стр. 492-493</target>
        </trans-unit>
        <trans-unit id="1ebff3fd3bf929976eef25f0da78c334d18a2c1d" translate="yes" xml:space="preserve">
          <source>Keys are parameter names that can be passed to &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Ключи - это имена параметров, которые можно передать в &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c16cf0c8b95cb6641127d4ecde39c2d13ee54107" translate="yes" xml:space="preserve">
          <source>Keyword arguments allow to adapt these defaults to specific data sets (see parameters &lt;code&gt;target_name&lt;/code&gt;, &lt;code&gt;data_name&lt;/code&gt;, &lt;code&gt;transpose_data&lt;/code&gt;, and the examples below).</source>
          <target state="translated">Аргументы ключевых слов позволяют адаптировать эти значения по умолчанию к конкретным наборам данных (см. Параметры &lt;code&gt;target_name&lt;/code&gt; , &lt;code&gt;data_name&lt;/code&gt; , &lt;code&gt;transpose_data&lt;/code&gt; и примеры ниже).</target>
        </trans-unit>
        <trans-unit id="bd2209e677c2e2331711a5337dc06706ac2ee537" translate="yes" xml:space="preserve">
          <source>Keyword arguments to pass to specified metric function.</source>
          <target state="translated">Ключевые аргументы для передачи в указанную метрическую функцию.</target>
        </trans-unit>
        <trans-unit id="b6574be8c6baa963e814d600a049a18b07924f05" translate="yes" xml:space="preserve">
          <source>Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola and Josh Attenberg (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Feature hashing for large scale multitask learning&lt;/a&gt;. Proc. ICML.</source>
          <target state="translated">Килиан Вайнбергер, Анирбан Дасгупта, Джон Лэнгфорд, Алекс Смола и Джош Аттенберг (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Функция хеширования для крупномасштабного многозадачного обучения&lt;/a&gt; . Proc. ICML.</target>
        </trans-unit>
        <trans-unit id="35a95e3949c1091022c84b09bdfaee477e2ca247" translate="yes" xml:space="preserve">
          <source>Kingma, Diederik, and Jimmy Ba. &amp;ldquo;Adam: A method for stochastic</source>
          <target state="translated">Кингма, Дидерик и Джимми Ба. &amp;laquo;Адам: метод стохастического</target>
        </trans-unit>
        <trans-unit id="7bf0d4f9044d36fbabdb373fe028824c8f48b797" translate="yes" xml:space="preserve">
          <source>Kluger, Y., Basri, R., Chang, J. T., &amp;amp; Gerstein, M. (2003). Spectral biclustering of microarray data: coclustering genes and conditions. Genome research, 13(4), 703-716.</source>
          <target state="translated">Клугер, Ю., Басри, Р., Чанг, Дж. Т., и Герштейн, М. (2003). Спектральная бикластеризация данных микрочипов: гены и условия совместной кластеризации. Исследование генома, 13 (4), 703-716.</target>
        </trans-unit>
        <trans-unit id="454573718b795c598350a3ed3c4e500004992423" translate="yes" xml:space="preserve">
          <source>Kluger, Yuval, et. al., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Spectral biclustering of microarray data: coclustering genes and conditions&lt;/a&gt;.</source>
          <target state="translated">Kluger, Yuval, et. др., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Спектральная бикластеризация данных микрочипов: гены и условия совместной кластеризации&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c956cdb3811d15bc82b9ab562e4744234449e302" translate="yes" xml:space="preserve">
          <source>Knowing only the number of samples, the &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt;&lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;&lt;/a&gt; estimates conservatively the minimal size of the random subspace to guarantee a bounded distortion introduced by the random projection:</source>
          <target state="translated">Зная только количество выборок, &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt; &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt; &lt;/a&gt; консервативно оценивает минимальный размер случайного подпространства, чтобы гарантировать ограниченное искажение , вносимое случайной проекцией:</target>
        </trans-unit>
        <trans-unit id="dc8be79b794b57340c1a9b2bf6e67594910f3213" translate="yes" xml:space="preserve">
          <source>Koby Crammer, Yoram Singer. On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines. Journal of Machine Learning Research 2, (2001), 265-292</source>
          <target state="translated">Коби Краммер,Йорам Сингер.Об алгоритмической реализации многоклассных векторных машин на основе ядра.Журнал исследований в области обучения работе с машинами 2,(2001),265-292.</target>
        </trans-unit>
        <trans-unit id="5c3682641cb862b7b72f47a7d095c9e12f698d72" translate="yes" xml:space="preserve">
          <source>Kullback-Leibler divergence after optimization.</source>
          <target state="translated">Расхождение Куллбек-Лейблера после оптимизации.</target>
        </trans-unit>
        <trans-unit id="58f9065948558949c0307af59f2acaf3f9203c82" translate="yes" xml:space="preserve">
          <source>KulsinskiDistance</source>
          <target state="translated">KulsinskiDistance</target>
        </trans-unit>
        <trans-unit id="cb6565437657bdf8e9b94faf7a832064c7b5f242" translate="yes" xml:space="preserve">
          <source>L-BFGS is a solver that approximates the Hessian matrix which represents the second-order partial derivative of a function. Further it approximates the inverse of the Hessian matrix to perform parameter updates. The implementation uses the Scipy version of &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt;.</source>
          <target state="translated">L-BFGS - это решающая программа, которая аппроксимирует матрицу Гессе, которая представляет собой частную производную второго порядка функции. Кроме того, он аппроксимирует обратную матрицу Гессе для обновления параметров. В реализации используется Scipy-версия &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a9d5151f1c406ba9642eb6d20ad7472462d4b8c9" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning 24, pages 123-140, 1996.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Предикторы упаковки&amp;raquo;, Машинное обучение 24, страницы 123&amp;ndash;140, 1996.</target>
        </trans-unit>
        <trans-unit id="05401786a74b32c74f5aaf77879ff5fe2a1ce4dc" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning, 24(2), 123-140, 1996.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Предикторы упаковки&amp;raquo;, Машинное обучение, 24 (2), 123-140, 1996.</target>
        </trans-unit>
        <trans-unit id="ae813a657051355d781d3ca7a4417546370b5fb0" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Pasting small votes for classification in large databases and on-line&amp;rdquo;, Machine Learning, 36(1), 85-103, 1999.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Вставка небольших голосов для классификации в больших базах данных и в Интернете&amp;raquo;, Машинное обучение, 36 (1), 85-103, 1999.</target>
        </trans-unit>
        <trans-unit id="93aaad4c8bcdef78f99bc463e879b251fb063491" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone, &amp;ldquo;Classification and Regression Trees&amp;rdquo;, Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">Л. Брейман, Дж. Фридман, Р. Олшен и К. Стоун, &amp;laquo;Деревья классификации и регрессии&amp;raquo;, Уодсворт, Белмонт, Калифорния, 1984.</target>
        </trans-unit>
        <trans-unit id="728ad1a9616394c8f19b0d53311780e8eed780ec" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">L.Брейман,Джей Фридман,Р.Ольшен и Си Стоун.Деревья классификации и регрессии.Уодсворт,Белмонт,Калифорния,1984.</target>
        </trans-unit>
        <trans-unit id="26e831dbfd841f8bca5cddecddc5d95f765adc3b" translate="yes" xml:space="preserve">
          <source>L. Breiman, P. Spector &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Submodel selection and evaluation in regression: The X-random case&lt;/a&gt;, International Statistical Review 1992;</source>
          <target state="translated">Л. Брейман, П. Спектор &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Выбор подмоделей и оценка в регрессии: случай X&lt;/a&gt; , Международный статистический обзор 1992;</target>
        </trans-unit>
        <trans-unit id="da524759b928a0c6c0410a2ba55315d0723efbf9" translate="yes" xml:space="preserve">
          <source>L. Breiman, and A. Cutler, &amp;ldquo;Random Forests&amp;rdquo;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</source>
          <target state="translated">Л. Брейман и А. Катлер, &amp;laquo;Случайные леса&amp;raquo;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="27e9c034667fd587e63afe1b6bd9ac5dd761c4eb" translate="yes" xml:space="preserve">
          <source>L1 AND L2 Regularization for Multiclass Hinge Loss Models by Robert C. Moore, John DeNero.</source>
          <target state="translated">Регуляризация L1 и L2 для многоклассных моделей потери шарниров Робертом К.Муром,Джоном Денеро.</target>
        </trans-unit>
        <trans-unit id="739dce23f089e2bc4737d849cf6e6812aaac6b25" translate="yes" xml:space="preserve">
          <source>L1 Penalty and Sparsity in Logistic Regression</source>
          <target state="translated">L1 Штраф и спартантизм в логистической регрессии</target>
        </trans-unit>
        <trans-unit id="8d79d7e84774c8797e94aafbcec78896f21a814d" translate="yes" xml:space="preserve">
          <source>L1 norm: \(R(w) := \sum_{i=1}^{n} |w_i|\), which leads to sparse solutions.</source>
          <target state="translated">Норма L1:\(R(w):=\sum_{i=1}^{n}|w_i|\),что приводит к разреженным решениям.</target>
        </trans-unit>
        <trans-unit id="ae8ca0f194d88f499adeb94f8b5c01af62268b9f" translate="yes" xml:space="preserve">
          <source>L2 norm: \(R(w) := \frac{1}{2} \sum_{i=1}^{n} w_i^2\),</source>
          <target state="translated">Норма L2:\(R(w):=\frac{1}{2}\sum_{i=1}^{n}w_i^2\),</target>
        </trans-unit>
        <trans-unit id="e55996560b375d2b1311657b3550d521d2224094" translate="yes" xml:space="preserve">
          <source>L2 penalty (regularization term) parameter.</source>
          <target state="translated">L2 штрафной параметр (срок регуляризации).</target>
        </trans-unit>
        <trans-unit id="7d7eb4b58ee70885659f8b6dfa6b739d18b840b6" translate="yes" xml:space="preserve">
          <source>LIBLINEAR &amp;ndash; A Library for Large Linear Classification</source>
          <target state="translated">LIBLINEAR - библиотека для большой линейной классификации</target>
        </trans-unit>
        <trans-unit id="23f600324ae930d885bf27049a430c382dc77087" translate="yes" xml:space="preserve">
          <source>LIBLINEAR: A Library for Large Linear Classification</source>
          <target state="translated">ЛИБЛИНАРА:Библиотека для Большой Линейной Классификации</target>
        </trans-unit>
        <trans-unit id="2f7204b5759b40e38407ab9bdcb1553f2d733475" translate="yes" xml:space="preserve">
          <source>LSA is also known as latent semantic indexing, LSI, though strictly that refers to its use in persistent indexes for information retrieval purposes.</source>
          <target state="translated">LSA также известен как скрытое семантическое индексирование,LSI,хотя строго говоря,это относится к его использованию в постоянных индексах для целей информационного поиска.</target>
        </trans-unit>
        <trans-unit id="f4a5095ae748443324845cf5a2f1b28d147ed2ca" translate="yes" xml:space="preserve">
          <source>LSH Forest being an approximate method, some true neighbors from the indexed dataset might be missing from the results.</source>
          <target state="translated">Поскольку LSH Forest является приблизительным методом,некоторые истинные соседи из индексированного набора данных могут отсутствовать в результатах.</target>
        </trans-unit>
        <trans-unit id="afceea8d4c81422ac802414c94f3f49075a51ec4" translate="yes" xml:space="preserve">
          <source>LSH Forest: Locality Sensitive Hashing forest [1] is an alternative method for vanilla approximate nearest neighbor search methods. LSH forest data structure has been implemented using sorted arrays and binary search and 32 bit fixed-length hashes. Random projection is used as the hash family which approximates cosine distance.</source>
          <target state="translated">ЛШХ Лес:Locality Sensitive Hashing Forest [1]-альтернативный метод для поиска ванили,приближенной к ближайшему соседу.Структура данных леса LSH была реализована с использованием отсортированных массивов и бинарного поиска и 32-битных хэшей фиксированной длины.В качестве семейства хэшей используется случайная проекция,которая аппроксимирует косинусное расстояние.</target>
        </trans-unit>
        <trans-unit id="497cbd9196f20980eefacbc5b295901fb0a6c25f" translate="yes" xml:space="preserve">
          <source>LSTAT % lower status of the population</source>
          <target state="translated">ЗАКЛЮЧИТЕЛЬНЫЙ % более низкий статус населения</target>
        </trans-unit>
        <trans-unit id="10e8ec7cf1b34af007bc1d6b016abc85aa0b454d" translate="yes" xml:space="preserve">
          <source>Label Propagation classifier</source>
          <target state="translated">Классификатор размножения этикеток</target>
        </trans-unit>
        <trans-unit id="abaf5a09ed6812e5734e77c1313bb44d953f5d5d" translate="yes" xml:space="preserve">
          <source>Label Propagation digits active learning</source>
          <target state="translated">Цифры этикетки Пропаганда активное обучение</target>
        </trans-unit>
        <trans-unit id="a45a75b5c87b437cf487b153831ce5b94e5322d0" translate="yes" xml:space="preserve">
          <source>Label Propagation digits: Demonstrating performance</source>
          <target state="translated">Цифры этикетки &quot;Пропаганда&quot;:Демонстрационная производительность</target>
        </trans-unit>
        <trans-unit id="f15baf6416f92a52b1527f1d28d49a335fe3d388" translate="yes" xml:space="preserve">
          <source>Label Propagation learning a complex structure</source>
          <target state="translated">Label Propagation изучение сложной структуры</target>
        </trans-unit>
        <trans-unit id="5f24cba3626113f57fbd8f2c1a1dac90f055831d" translate="yes" xml:space="preserve">
          <source>Label assigned to each item via the transduction.</source>
          <target state="translated">Метка,присваиваемая каждому изделию через трансляцию.</target>
        </trans-unit>
        <trans-unit id="0154541a5d5e8e0b2444f876377737f91ad447a9" translate="yes" xml:space="preserve">
          <source>Label considered as positive and others are considered negative.</source>
          <target state="translated">Этикетка считается положительной,а другие-отрицательной.</target>
        </trans-unit>
        <trans-unit id="e1c383c45e91a1b41ae4aea8504e1ff71ada889a" translate="yes" xml:space="preserve">
          <source>Label is 1 for an inlier and -1 for an outlier according to the LOF score and the contamination parameter.</source>
          <target state="translated">Метка 1 для входа и -1 для выхода в зависимости от балла LOF и параметра загрязнения.</target>
        </trans-unit>
        <trans-unit id="4a4a633c5d3b5ebf2a9c4453fb41f8475e350bc9" translate="yes" xml:space="preserve">
          <source>Label of the positive class. If None, the maximum label is used as positive class</source>
          <target state="translated">Ярлык положительного класса.Если Нет,то максимальная метка используется как положительный класс.</target>
        </trans-unit>
        <trans-unit id="91ed314c98998b774c857769b601470c2a4233d0" translate="yes" xml:space="preserve">
          <source>Label propagation denotes a few variations of semi-supervised graph inference algorithms.</source>
          <target state="translated">Распространение меток обозначает несколько вариаций полууправляемых алгоритмов вывода графов.</target>
        </trans-unit>
        <trans-unit id="3a4c36d2f1914cbaa6f86d2f3e759e05f747e6f8" translate="yes" xml:space="preserve">
          <source>Label propagation models have two built-in kernel methods. Choice of kernel effects both scalability and performance of the algorithms. The following are available:</source>
          <target state="translated">Модели распространения этикеток имеют два встроенных метода ядра.Выбор эффектов от ядра,как масштабируемости,так и производительности алгоритмов.Доступны следующие варианты:</target>
        </trans-unit>
        <trans-unit id="d9c8943fba1565dfa00ecc788417147c59e84b5a" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) averages over the samples the answer to the following question: for each ground truth label, what fraction of higher-ranked labels were true labels? This performance measure will be higher if you are able to give better rank to the labels associated with each sample. The obtained score is always strictly greater than 0, and the best value is 1. If there is exactly one relevant label per sample, label ranking average precision is equivalent to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;mean reciprocal rank&lt;/a&gt;.</source>
          <target state="translated">Средняя точность ранжирования меток (LRAP) усредняет по выборкам ответ на следующий вопрос: для каждой основной метки истинности какая доля меток с более высоким рейтингом была истинной? Этот показатель эффективности будет выше, если вы сможете лучше ранжировать метки, связанные с каждым образцом. Полученная оценка всегда строго больше 0, а наилучшее значение равно 1. Если имеется ровно одна релевантная метка для каждой выборки, средняя точность ранжирования меток эквивалентна &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;среднему обратному рангу&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="12d27d4c8cd4504c7079d27029449977fea3fa44" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) is the average over each ground truth label assigned to each sample, of the ratio of true vs. total labels with lower score.</source>
          <target state="translated">Средняя точность ранжирования меток (LRAP)-это среднее значение по каждой наземной истине,присвоенной каждой выборке,соотношения истинного и общего количества меток с более низкой оценкой.</target>
        </trans-unit>
        <trans-unit id="57882529b52287495d04cf4c6bba559a970b02d4" translate="yes" xml:space="preserve">
          <source>Label, which is given for outlier samples (samples with no neighbors on given radius). If set to None, ValueError is raised, when outlier is detected.</source>
          <target state="translated">Ярлык,который дается для исходных образцов (образцов без соседей по заданному радиусу).Если установлено значение None,то ValueError повышается при обнаружении отклонений.</target>
        </trans-unit>
        <trans-unit id="a3ea7d5af24c9f7706e04a90b4cc006ad64537bf" translate="yes" xml:space="preserve">
          <source>LabelSpreading model for semi-supervised learning</source>
          <target state="translated">Модель LabelSpreading для полууправляемого обучения</target>
        </trans-unit>
        <trans-unit id="82b6583f37d4a090f2277f71261de91f41eff15e" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not always pure, hence penalized:</source>
          <target state="translated">Наклейки,которые назначают всех членов классов на одни и те же кластеры,не всегда являются чистыми,а следовательно,подлежат наказанию:</target>
        </trans-unit>
        <trans-unit id="a59d28cce33bc578e32e7790445917276a69fe16" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not homogeneous, hence penalized:</source>
          <target state="translated">Маркировки,которые присваивают всем классам членов одного и того же кластера,не являются однородными и,следовательно,подлежат наказанию:</target>
        </trans-unit>
        <trans-unit id="2625047637f13a503b1aa26353d53ce007980d47" translate="yes" xml:space="preserve">
          <source>Labelings that have pure clusters with members coming from the same classes are homogeneous but un-necessary splits harms completeness and thus penalize V-measure as well:</source>
          <target state="translated">Маркировки,которые имеют чистые кластеры с членами,пришедшими из одних и тех же классов,однородны,но ненужные расщепления наносят вред полноте и,таким образом,наказывают также и V-меру:</target>
        </trans-unit>
        <trans-unit id="040e8af7f9faa240f939c7eb15dd2f3691882d68" translate="yes" xml:space="preserve">
          <source>Labelled data.</source>
          <target state="translated">Металлические данные.</target>
        </trans-unit>
        <trans-unit id="a8a910f7e8e66128e5f0f93a7ebe3b1d5812067b" translate="yes" xml:space="preserve">
          <source>Labelling a new sample is performed by finding the nearest centroid for a given sample.</source>
          <target state="translated">Пометка нового образца выполняется путем нахождения ближайшего центроида для данного образца.</target>
        </trans-unit>
        <trans-unit id="47fc9fa69e29f326a363aa6376f6761fa85e0797" translate="yes" xml:space="preserve">
          <source>Labels assigned by the first annotator.</source>
          <target state="translated">Ярлыки,присвоенные первым аннотатором.</target>
        </trans-unit>
        <trans-unit id="bdb7346e56bb733f97e8f0b9d11cce2ffadf9042" translate="yes" xml:space="preserve">
          <source>Labels assigned by the second annotator. The kappa statistic is symmetric, so swapping &lt;code&gt;y1&lt;/code&gt; and &lt;code&gt;y2&lt;/code&gt; doesn&amp;rsquo;t change the value.</source>
          <target state="translated">Ярлыки, присвоенные вторым аннотатором. Статистика каппа симметрична, поэтому замена &lt;code&gt;y1&lt;/code&gt; и &lt;code&gt;y2&lt;/code&gt; не меняет значения.</target>
        </trans-unit>
        <trans-unit id="202396c3dbc4d15cb0462523b4fd7f2f49834479" translate="yes" xml:space="preserve">
          <source>Labels assigned to the centroids of the subclusters after they are clustered globally.</source>
          <target state="translated">Ярлыки,присваиваемые центроидам подкластеров после того,как они сгруппированы по всему миру.</target>
        </trans-unit>
        <trans-unit id="86a5303314971b15773b1ad8460967a7978fc1e6" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels are ranging from 0-39 and correspond to the Subject IDs.</source>
          <target state="translated">Ярлыки,связанные с каждым изображением лица.Эти метки варьируются от 0 до 39 и соответствуют идентификаторам субъектов.</target>
        </trans-unit>
        <trans-unit id="b8a8237c586e7a43e02e7a221af16786bca65b16" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels range from 0-5748 and correspond to the person IDs.</source>
          <target state="translated">Ярлыки,связанные с каждым изображением лица.Эти ярлыки варьируются в диапазоне 0-5748 и соответствуют идентификаторам лиц.</target>
        </trans-unit>
        <trans-unit id="639c7a5f12221be9fa16d4184a91d960ee8d5fb6" translate="yes" xml:space="preserve">
          <source>Labels associated to each pair of images. The two label values being different persons or the same person.</source>
          <target state="translated">Ярлыки,связанные с каждой парой изображений.Два значения этикетки-разные люди или один и тот же человек.</target>
        </trans-unit>
        <trans-unit id="dd9359ae6e29bf7b087516560ad1a2e91d10cfb0" translate="yes" xml:space="preserve">
          <source>Labels for X.</source>
          <target state="translated">Ярлыки для Икс.</target>
        </trans-unit>
        <trans-unit id="0b53b6571e9267409e85ff23873e0a0824df02a7" translate="yes" xml:space="preserve">
          <source>Labels of each point</source>
          <target state="translated">Метки каждой точки</target>
        </trans-unit>
        <trans-unit id="4350a7104cda6c17ed013efe2d00ebaae03eeb73" translate="yes" xml:space="preserve">
          <source>Labels of each point (if compute_labels is set to True).</source>
          <target state="translated">Метки каждой точки (если значение переменной compute_labels установлено в True).</target>
        </trans-unit>
        <trans-unit id="8c76fdcbe4be61c2bbf79d2e67413441e31eb988" translate="yes" xml:space="preserve">
          <source>Labels of each point.</source>
          <target state="translated">Ярлыки каждой точки.</target>
        </trans-unit>
        <trans-unit id="9caa2dbfb17c8c2f4ae17aa6bab878223c8520e3" translate="yes" xml:space="preserve">
          <source>Labels to constrain permutation within groups, i.e. &lt;code&gt;y&lt;/code&gt; values are permuted among samples with the same group identifier. When not specified, &lt;code&gt;y&lt;/code&gt; values are permuted among all samples.</source>
          <target state="translated">Метки для ограничения перестановки внутри групп, т. &lt;code&gt;y&lt;/code&gt; Значения y переставляются среди выборок с одним и тем же идентификатором группы. Если не указано иное, значения &lt;code&gt;y&lt;/code&gt; переставляются среди всех выборок.</target>
        </trans-unit>
        <trans-unit id="c21c4f0b2fc516030c767721367e1d2fba51e007" translate="yes" xml:space="preserve">
          <source>Labels.</source>
          <target state="translated">Labels.</target>
        </trans-unit>
        <trans-unit id="45efe9972f3bf7c62e3db1678d501faf12d10c1b" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_clusters&lt;/code&gt; and &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">Большие &lt;code&gt;n_clusters&lt;/code&gt; и &lt;code&gt;n_samples&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="28e08fa26129e68210c4b016ca6da1b08a1a37e9" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Большие &lt;code&gt;n_samples&lt;/code&gt; и &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d40959dcecc27d1d44b2e4cffa59a304e9a052a1" translate="yes" xml:space="preserve">
          <source>Large dataset, outlier removal, data reduction.</source>
          <target state="translated">Большой набор данных,удаление отклонений,уменьшение данных.</target>
        </trans-unit>
        <trans-unit id="8f1784e927c9c4e578edb46d860596eed4a90b35" translate="yes" xml:space="preserve">
          <source>Large outliers</source>
          <target state="translated">Большие отклонения</target>
        </trans-unit>
        <trans-unit id="20dfcd03ef69fe3c6c6e8549019c43956f87d5db" translate="yes" xml:space="preserve">
          <source>Lars computes a path solution only for each kink in the path. As a result, it is very efficient when there are only of few kinks, which is the case if there are few features or samples. Also, it is able to compute the full path without setting any meta parameter. On the opposite, coordinate descent compute the path points on a pre-specified grid (here we use the default). Thus it is more efficient if the number of grid points is smaller than the number of kinks in the path. Such a strategy can be interesting if the number of features is really large and there are enough samples to select a large amount. In terms of numerical errors, for heavily correlated variables, Lars will accumulate more errors, while the coordinate descent algorithm will only sample the path on a grid.</source>
          <target state="translated">Ларс вычисляет решение пути только для каждого перегиба в пути.В результате,оно очень эффективно,когда есть только несколько перегибов,что бывает в случае,если есть несколько особенностей или примеров.Кроме того,он может вычислить полный путь,не задавая никаких мета-параметров.Напротив,координатный спуск вычисляет точки пути на заранее заданной сетке (здесь мы используем значение по умолчанию).Таким образом,это более эффективно,если количество точек сетки меньше,чем количество перегибов на пути.Такая стратегия может быть интересна,если количество объектов действительно велико,а выборки достаточно велики.С точки зрения числовых ошибок,для сильнокоррелированных переменных Ларс будет накапливать больше ошибок,в то время как алгоритм координатного спуска будет сэмплировать путь только на сетке.</target>
        </trans-unit>
        <trans-unit id="fafbf93538200568ab2506c2a63168c161506b4f" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net</source>
          <target state="translated">Лассо и эластичная сеть</target>
        </trans-unit>
        <trans-unit id="64045413f4cce0f6cc0a64e33254b9beab1142d8" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net for Sparse Signals</source>
          <target state="translated">Лассо и эластичная сеть для разделения сигналов</target>
        </trans-unit>
        <trans-unit id="02b3c1dbfc5f6c26007e2282ba4be10a77581a65" translate="yes" xml:space="preserve">
          <source>Lasso and elastic net (L1 and L2 penalisation) implemented using a coordinate descent.</source>
          <target state="translated">Лассо и эластичная сетка (наказание L1 и L2),реализованная с использованием координатного спуска.</target>
        </trans-unit>
        <trans-unit id="721bb6d50a67145009b7e81abd6add7dc9980ff6" translate="yes" xml:space="preserve">
          <source>Lasso computed by least-angle regression</source>
          <target state="translated">Лассо вычислен по регрессии наименьшего угла</target>
        </trans-unit>
        <trans-unit id="c805258f4c266592bbe9892ca4c6fe8fe41525e3" translate="yes" xml:space="preserve">
          <source>Lasso linear model with iterative fitting along a regularization path</source>
          <target state="translated">Линейная модель Лассо с итерационной подгонкой по пути регуляризации</target>
        </trans-unit>
        <trans-unit id="af3dece2cf6ae684f46dbebc7279e4f62e00335d" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Lars using BIC or AIC for model selection</source>
          <target state="translated">Модель Lasso подходит к Ларсу,используя BIC или AIC для выбора модели.</target>
        </trans-unit>
        <trans-unit id="050a0d126029facc258b43169ac1e55a978389bf" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a.</source>
          <target state="translated">Модель Лассо подходит с регрессией по методу наименьшего угла.</target>
        </trans-unit>
        <trans-unit id="9cd5532bfae0b1e27ef3555196bbd1195b2078fe" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a. Lars</source>
          <target state="translated">Модель Лассо подходит с регрессией наименьшего угла,так же известной как Ларс.</target>
        </trans-unit>
        <trans-unit id="7cbdf91f396ae23c8822ab30bdd340882655aa26" translate="yes" xml:space="preserve">
          <source>Lasso model selection: Cross-Validation / AIC / BIC</source>
          <target state="translated">Выбор модели Лассо:Перекрестная проверка/AIC/BIC</target>
        </trans-unit>
        <trans-unit id="51c5bc73e17f640c8a180ee453dbdca923d8c408" translate="yes" xml:space="preserve">
          <source>Lasso on dense and sparse data</source>
          <target state="translated">Лассо по плотным и редким данным</target>
        </trans-unit>
        <trans-unit id="4222e17e965145615293d33dd92e1394e71c2b5b" translate="yes" xml:space="preserve">
          <source>Lasso path using LARS</source>
          <target state="translated">путь Лассо с помощью ЛАРС</target>
        </trans-unit>
        <trans-unit id="1acac83cf58491df993404acd51caed4c4458648" translate="yes" xml:space="preserve">
          <source>Lasso using coordinate descent (&lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;)</source>
          <target state="translated">Лассо с использованием координатного спуска ( &lt;a href=&quot;linear_model#lasso&quot;&gt;Лассо&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="e33c33e9d593ce188f7d437b3dd829993a23358f" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation is a generative probabilistic model for collections of discrete dataset such as text corpora. It is also a topic model that is used for discovering abstract topics from a collection of documents.</source>
          <target state="translated">Latent Dirichlet Allocation является генеративной вероятностной моделью для коллекций дискретных наборов данных,таких как текстовые корпуса.Это также тематическая модель,которая используется для открытия абстрактных тем из коллекции документов.</target>
        </trans-unit>
        <trans-unit id="b259b9fed25933f3361602dc71394efbeb9d0882" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation with online variational Bayes algorithm</source>
          <target state="translated">Скрытое распределение Дирихлета с онлайн вариационным алгоритмом Байеса</target>
        </trans-unit>
        <trans-unit id="691257140e4ed31a708c6cf301cec44aee34c69f" translate="yes" xml:space="preserve">
          <source>Latent representations of the data.</source>
          <target state="translated">Скрытое представление данных.</target>
        </trans-unit>
        <trans-unit id="7972223ce1d5a83652f334b349de24d196516da5" translate="yes" xml:space="preserve">
          <source>Later you can load back the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Позже вы можете загрузить обратно маринованную модель (возможно,в другом процессе на Python)с помощью:</target>
        </trans-unit>
        <trans-unit id="af705669290f66a0c593b0deebc97c8dff7d4996" translate="yes" xml:space="preserve">
          <source>Later, you can reload the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Позже вы можете перезагрузить маринованную модель (возможно,в другом процессе на Python)с помощью:</target>
        </trans-unit>
        <trans-unit id="87b4154b3c380b9ca1fa8f1419dd8e2c1d34065a" translate="yes" xml:space="preserve">
          <source>Latitude house block latitude</source>
          <target state="translated">Широта квартала дома широты</target>
        </trans-unit>
        <trans-unit id="5d6517da9252e690b07eb861ecaf7b79646512be" translate="yes" xml:space="preserve">
          <source>Leaf size passed to &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt;. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передан в &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; или&lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; . Это может повлиять на скорость построения и запроса, а также на объем памяти, необходимый для хранения дерева. Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="adfd1a5c3117b99a14c45a4ae06038fd4593b137" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передается в BallTree или KDTree.Это может повлиять на скорость построения и запроса,а также на память,необходимую для хранения дерева.Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="2f4f4f9d9992d30c454ebca3af5182554c5dd5d3" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or cKDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передается в BallTree или cKDTree.Это может повлиять на скорость построения и запроса,а также на память,необходимую для хранения дерева.Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="31743e5f5ee8b348cb24154ab26179446399d075" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X and returns the transformed data.</source>
          <target state="translated">Изучите модель NMF для данных X и верните преобразованные данные.</target>
        </trans-unit>
        <trans-unit id="a49199fe15b3d192e2f8e78d2cfcc004b5bb592f" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X.</source>
          <target state="translated">Изучите модель NMF для данных X.</target>
        </trans-unit>
        <trans-unit id="f28a5a2a8197ba712162f1642134c8c32dff12de" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings and transform X.</source>
          <target state="translated">Изучите список имен функций -&amp;gt; сопоставления индексов и преобразуйте X.</target>
        </trans-unit>
        <trans-unit id="8c410f4ecac33d5545793d5deb3e8b1121157db0" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings.</source>
          <target state="translated">Изучите список названий функций -&amp;gt; сопоставления индексов.</target>
        </trans-unit>
        <trans-unit id="a753afaf1f2a5a0c1c19f381e2c844f4e69ccf16" translate="yes" xml:space="preserve">
          <source>Learn a vocabulary dictionary of all tokens in the raw documents.</source>
          <target state="translated">Изучите словарь всех жетонов в исходных документах.</target>
        </trans-unit>
        <trans-unit id="d9349583a45dc48570d0d3236e8faf8ecfef570b" translate="yes" xml:space="preserve">
          <source>Learn and apply the dimension reduction on the train data.</source>
          <target state="translated">Изучите и применяйте уменьшение размеров к данным поезда.</target>
        </trans-unit>
        <trans-unit id="c8e9cfdd99f37695b9bb2a2cf234f653fe10a376" translate="yes" xml:space="preserve">
          <source>Learn empirical variances from X.</source>
          <target state="translated">Узнайте об эмпирических изменениях из X.</target>
        </trans-unit>
        <trans-unit id="650a6ae9c550e7f32470024973e3b36aee2841fa" translate="yes" xml:space="preserve">
          <source>Learn model for the data X with variational Bayes method.</source>
          <target state="translated">Изучите модель для данных X с помощью вариационного метода Байеса.</target>
        </trans-unit>
        <trans-unit id="dacb80f7c7ce4a5db80b953f259da8b386886101" translate="yes" xml:space="preserve">
          <source>Learn the idf vector (global term weights)</source>
          <target state="translated">Изучите вектор idf (глобальные терминологические веса).</target>
        </trans-unit>
        <trans-unit id="b331e0a3149fc26c2099c41ac3e9655d530c7a47" translate="yes" xml:space="preserve">
          <source>Learn the inverse transform for non-precomputed kernels. (i.e. learn to find the pre-image of a point)</source>
          <target state="translated">Изучите обратное преобразование для неперечисленных ядер.(т.е.научиться находить предварительное изображение точки).</target>
        </trans-unit>
        <trans-unit id="ee96e1f94ac61b3bff29cbb75afd2fdb8a437bed" translate="yes" xml:space="preserve">
          <source>Learn the vocabulary dictionary and return term-document matrix.</source>
          <target state="translated">Изучите словарь терминов и верните матрицу терминологических документов.</target>
        </trans-unit>
        <trans-unit id="65adc2e107d7d619d7107cf14005ab5e9c9cd5ef" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf from training set.</source>
          <target state="translated">Изучайте словарный запас и idf из учебного набора.</target>
        </trans-unit>
        <trans-unit id="d9ba5b6f4cc6cff1198de21973fdc3c62d64336f" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf, return term-document matrix.</source>
          <target state="translated">Изучайте лексику и idf,возвращайте матрицу терминологического документа.</target>
        </trans-unit>
        <trans-unit id="5b86400dde56a045e486ecc10d7618c7daf0f573" translate="yes" xml:space="preserve">
          <source>Learning a graph structure</source>
          <target state="translated">Изучение графической структуры</target>
        </trans-unit>
        <trans-unit id="f89176d3f1741099f1479699aa585a0c6906b634" translate="yes" xml:space="preserve">
          <source>Learning and predicting</source>
          <target state="translated">Обучение и прогнозирование</target>
        </trans-unit>
        <trans-unit id="5087c606edcdf30c07ac8bd6a14c9b96c0975b25" translate="yes" xml:space="preserve">
          <source>Learning curve.</source>
          <target state="translated">Кривая обучения.</target>
        </trans-unit>
        <trans-unit id="af86142d107ea3e7d568509ca68cbef348748b05" translate="yes" xml:space="preserve">
          <source>Learning problems fall into a few categories:</source>
          <target state="translated">Проблемы с обучением делятся на несколько категорий:</target>
        </trans-unit>
        <trans-unit id="213b18cf4e4c891522544c2231435e470a8853a1" translate="yes" xml:space="preserve">
          <source>Learning rate schedule for weight updates.</source>
          <target state="translated">График обучения для обновления веса.</target>
        </trans-unit>
        <trans-unit id="ad3970bc51aa8e2c82bc13dcb9d4922e01a06590" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each classifier by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">Скорость обучения уменьшает вклад каждого классификатора на &lt;code&gt;learning_rate&lt;/code&gt; . Существует компромисс между &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cc055e36b16b7ea8669e5252649d8e3ee1af0b11" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each regressor by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">Скорость обучения уменьшает вклад каждого регрессора на &lt;code&gt;learning_rate&lt;/code&gt; . Существует компромисс между &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8982fb177d3b5a895540d84670a324c9b8376572" translate="yes" xml:space="preserve">
          <source>Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called &lt;strong&gt;overfitting&lt;/strong&gt;. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a &lt;strong&gt;test set&lt;/strong&gt;&lt;code&gt;X_test, y_test&lt;/code&gt;. Note that the word &amp;ldquo;experiment&amp;rdquo; is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally.</source>
          <target state="translated">Изучение параметров функции прогнозирования и тестирование ее на одних и тех же данных является методологической ошибкой: модель, которая будет просто повторять метки образцов, которые она только что увидела, будет иметь идеальную оценку, но не сможет еще предсказать что-либо полезное. невидимые данные. Такая ситуация называется &lt;strong&gt;переобучением&lt;/strong&gt; . Чтобы этого избежать, при проведении (контролируемого) эксперимента с машинным обучением распространена практика хранения части доступных данных в виде &lt;strong&gt;тестового набора &lt;/strong&gt; &lt;code&gt;X_test, y_test&lt;/code&gt; . Обратите внимание, что слово &amp;laquo;эксперимент&amp;raquo; не предназначено для обозначения только академического использования, потому что даже в коммерческих условиях машинное обучение обычно начинается экспериментально.</target>
        </trans-unit>
        <trans-unit id="93c3e1794e48ba7d8637b32d813e97686cf36d4f" translate="yes" xml:space="preserve">
          <source>Learns each output independently rather than chaining.</source>
          <target state="translated">Изучает каждый выход самостоятельно,а не приковывает цепь.</target>
        </trans-unit>
        <trans-unit id="5fce8b00092369b98dfb920b76a7ee0efe5e00b1" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a.</source>
          <target state="translated">Модель регрессии по методу наименьшего угла,так же известная как...</target>
        </trans-unit>
        <trans-unit id="3b28e26eb21f16fdbdefabf1ed5ad375edeafb8b" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a. LAR</source>
          <target state="translated">Модель регрессии по методу наименьшего угла,также известная как LAR.</target>
        </trans-unit>
        <trans-unit id="b8ab306ac662259fba4aa6725b193c75be140b61" translate="yes" xml:space="preserve">
          <source>Least Squares projection of the data onto the sparse components.</source>
          <target state="translated">Проекция данных в виде наименьших квадратов на разреженные компоненты.</target>
        </trans-unit>
        <trans-unit id="2c3aa035aea93ac3dc79ecee5528b7c8dcfba4ab" translate="yes" xml:space="preserve">
          <source>Least absolute deviation (&lt;code&gt;'lad'&lt;/code&gt;): A robust loss function for regression. The initial model is given by the median of the target values.</source>
          <target state="translated">Наименьшее абсолютное отклонение ( &lt;code&gt;'lad'&lt;/code&gt; ): надежная функция потерь для регрессии. Исходная модель задается медианой целевых значений.</target>
        </trans-unit>
        <trans-unit id="3aeaacb76e6b5d496047f324133ddd0747e1d2c6" translate="yes" xml:space="preserve">
          <source>Least squares (&lt;code&gt;'ls'&lt;/code&gt;): The natural choice for regression due to its superior computational properties. The initial model is given by the mean of the target values.</source>
          <target state="translated">Метод наименьших квадратов ( &lt;code&gt;'ls'&lt;/code&gt; ): естественный выбор для регрессии из-за его превосходных вычислительных свойств. Исходная модель представлена ​​средним целевым значением.</target>
        </trans-unit>
        <trans-unit id="7963186b092849241b779637d34ce64214b0375a" translate="yes" xml:space="preserve">
          <source>Least-Squares: Ridge Regression.</source>
          <target state="translated">Меньше квадратов:Регрессия хребта.</target>
        </trans-unit>
        <trans-unit id="acf6db0396d489bb160af474285d57fb823df68a" translate="yes" xml:space="preserve">
          <source>Least-angle regression (&lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;Least Angle Regression&lt;/a&gt;)</source>
          <target state="translated">Регрессия &lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;наименьшего угла&lt;/a&gt; ( наименьшая угловая регрессия )</target>
        </trans-unit>
        <trans-unit id="818f02ffe71d576f8833c06d3318f5d50790be37" translate="yes" xml:space="preserve">
          <source>Least-angle regression (LARS) is a regression algorithm for high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. LARS is similar to forward stepwise regression. At each step, it finds the predictor most correlated with the response. When there are multiple predictors having equal correlation, instead of continuing along the same predictor, it proceeds in a direction equiangular between the predictors.</source>
          <target state="translated">Регрессия по методу наименьшего угла (LARS)-это алгоритм регрессии для высокоразмерных данных,разработанный Брэдли Эфроном,Тревором Хасти,Иеном Джонстоуном и Робертом Тибширани.LARS похож на прогрессивную регрессию в прямом направлении.На каждом шаге он находит предиктор,наиболее коррелированный с ответом.При наличии множества предикторов,имеющих равную корреляцию,вместо того,чтобы продолжать по одному и тому же предиктору,он движется в направлении,равностороннем между предикторами.</target>
        </trans-unit>
        <trans-unit id="5cc9936fd171dfb4c941611970a01e31c9182cee" translate="yes" xml:space="preserve">
          <source>Leave One Group Out cross-validator</source>
          <target state="translated">Оставьте одну группу вне перекрёстного валидатора.</target>
        </trans-unit>
        <trans-unit id="708b3ff9ed12b2c6f3635d37f516d672f76ad26e" translate="yes" xml:space="preserve">
          <source>Leave P Group(s) Out cross-validator</source>
          <target state="translated">Оставить П-группу (группы)Вне перекрестного валидатора</target>
        </trans-unit>
        <trans-unit id="b1d423c90dfa79c0db1cf2e91d8b80c110d2debb" translate="yes" xml:space="preserve">
          <source>Leave P groups out.</source>
          <target state="translated">Оставьте &quot;П&quot; группы вне игры.</target>
        </trans-unit>
        <trans-unit id="2e788c12c63436d5bbf2b3d54792d07b4ad5906d" translate="yes" xml:space="preserve">
          <source>Leave P observations out.</source>
          <target state="translated">Оставьте наблюдения &quot;П&quot;.</target>
        </trans-unit>
        <trans-unit id="23a4dfbb0e55172e2c29fa75763519463b465b57" translate="yes" xml:space="preserve">
          <source>Leave one observation out.</source>
          <target state="translated">Оставьте одно наблюдение.</target>
        </trans-unit>
        <trans-unit id="96e7c056605d5580183d915f0e8250d81cc4028b" translate="yes" xml:space="preserve">
          <source>Leave-One-Out cross-validator</source>
          <target state="translated">Перекрёстный валидатор &quot;оставил-не оставил-не оставил&quot;.</target>
        </trans-unit>
        <trans-unit id="a3d5fb094bf6540a5945dfebfc612a40422d0970" translate="yes" xml:space="preserve">
          <source>Leave-P-Out cross-validator</source>
          <target state="translated">Перекрестный валидатор Leave-P-Out</target>
        </trans-unit>
        <trans-unit id="7fa92633d7eb4070a1a9e7f3ffd6a6dd808d5514" translate="yes" xml:space="preserve">
          <source>Ledoit O, Wolf M. Honey, I Shrunk the Sample Covariance Matrix. The Journal of Portfolio Management 30(4), 110-119, 2004.</source>
          <target state="translated">Ледуард О,Вульф М.Дорогой,я забиваю ковариационную матрицу образца.Журнал управления портфелями 30(4),110-119,2004.</target>
        </trans-unit>
        <trans-unit id="b6a08e295c1dafc447ef93ac82d0e6a70b01528e" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient is computed using O. Ledoit and M. Wolf&amp;rsquo;s formula as described in &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Ledoit and Wolf, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">Ледуа-Вольф - это особая форма усадки, где коэффициент усадки вычисляется с использованием формулы О. Ледуа и М. Вольфа, как описано в &amp;laquo;Хорошо обусловленная оценка для матриц большой размерной ковариации&amp;raquo;, Ледуа и Вольф, Журнал многомерного анализа , Том 88, выпуск 2, февраль 2004 г., страницы 365-411.</target>
        </trans-unit>
        <trans-unit id="b450ff5574aa7547a2d2804a59fde9043d1f11e3" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf vs OAS estimation</source>
          <target state="translated">Оценка Ledoit-Wolf против OAS</target>
        </trans-unit>
        <trans-unit id="74b56641357b357e1a04f8ba20caa0211258f1b9" translate="yes" xml:space="preserve">
          <source>LedoitWolf Estimator</source>
          <target state="translated">LedoitWolf Estimator</target>
        </trans-unit>
        <trans-unit id="a7127a921977497178bbe9d19b374d5b3660e695" translate="yes" xml:space="preserve">
          <source>Left argument of the returned kernel k(X, Y)</source>
          <target state="translated">Левый аргумент возвращаемого ядра k(X,Y)</target>
        </trans-unit>
        <trans-unit id="75bf879e9683d8e42f9cdbce4ac2378477aafa4c" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</source>
          <target state="translated">Длина пути. &lt;code&gt;eps=1e-3&lt;/code&gt; означает, что &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c25fd55e85b58584519914fbcbbc8e0b71dacb4b" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;.</source>
          <target state="translated">Длина пути. &lt;code&gt;eps=1e-3&lt;/code&gt; означает, что &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="820f47ab7dc5f77aa60df5d42cf3669d7140be19" translate="yes" xml:space="preserve">
          <source>Less sensitivity to the number of parameters:</source>
          <target state="translated">Меньше чувствительности к количеству параметров:</target>
        </trans-unit>
        <trans-unit id="650648dcfa58ca5d69540fc9d7c76c71c03cdd8d" translate="yes" xml:space="preserve">
          <source>Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a function mapping x to a Hilbert space. KernelCenterer centers (i.e., normalize to have zero mean) the data without explicitly computing phi(x). It is equivalent to centering phi(x) with sklearn.preprocessing.StandardScaler(with_std=False).</source>
          <target state="translated">Пусть K(x,z)-это ядро,определенное phi(x)^T phi(z),где phi-это функция,отображающая x в пространство Гильберта.Центры KernelCenterer (т.е.нормализуют к нулевому среднему значению)данные без явного вычисления phi(x).Это эквивалентно центрированию фи(x)с помощью sklearn.preproprocessing.StandardScaler(with_std=False).</target>
        </trans-unit>
        <trans-unit id="4d3e4f22e7563805ce13fd93e247765bb5c10653" translate="yes" xml:space="preserve">
          <source>Let \(S\) be the similarity matrix, and \(X\) the coordinates of the \(n\) input points. Disparities \(\hat{d}_{ij}\) are transformation of the similarities chosen in some optimal ways. The objective, called the stress, is then defined by \(sum_{i &amp;lt; j} d_{ij}(X) - \hat{d}_{ij}(X)\)</source>
          <target state="translated">Пусть \ (S \) - матрица подобия, а \ (X \) - координаты входных точек \ (n \). Неравенства \ (\ hat {d} _ {ij} \) - это преобразование подобий, выбранных некоторыми оптимальными способами. Затем цель, называемая напряжением, определяется как \ (sum_ {i &amp;lt;j} d_ {ij} (X) - \ hat {d} _ {ij} (X) \)</target>
        </trans-unit>
        <trans-unit id="c0a7cf3804b0fab7efc2f61eebe3b5930a870c77" translate="yes" xml:space="preserve">
          <source>Let the data at node \(m\) be represented by \(Q\). For each candidate split \(\theta = (j, t_m)\) consisting of a feature \(j\) and threshold \(t_m\), partition the data into \(Q_{left}(\theta)\) and \(Q_{right}(\theta)\) subsets</source>
          <target state="translated">Пусть данные на узле \(m\)будут представлены \(Q\).Для каждого кандидата разбить \(\theta=(j,t_m)\)на подмножества \(j\)и порог \(t_m\),разделить данные на подмножества \(Q_{left}(\theta)\)и \(Q_{right}(\theta)\).</target>
        </trans-unit>
        <trans-unit id="0eec5761b9ded7fa59a47d01c0fcb2883cae7dd4" translate="yes" xml:space="preserve">
          <source>Let us now try to reconstruct the original image from the patches by averaging on overlapping areas:</source>
          <target state="translated">Теперь попробуем воссоздать исходное изображение по патчам,усредняя по областям перекрытия:</target>
        </trans-unit>
        <trans-unit id="106ecb5f7c6bb4669d70caeae32d17518696e61b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s print the first lines of the first loaded file:</source>
          <target state="translated">Напечатаем первые строки первого загруженного файла:</target>
        </trans-unit>
        <trans-unit id="bcd495b6fedeb570ab62363e5dbb308b08a2e969" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 25, and 50, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 25 и 50 и вы хотите узнать название их класса.</target>
        </trans-unit>
        <trans-unit id="65595eba1f80a7173dc24674f2afc2d5837968b2" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 50, and 85, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 50 и 85 и вы хотите узнать имя их класса.</target>
        </trans-unit>
        <trans-unit id="fb46983e946ca9f3803c9b6fd00931719bb67d7b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 80, and 140, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 80 и 140 и вы хотите узнать имя их класса.</target>
        </trans-unit>
        <trans-unit id="36ae1b66774b74a6fe504ba4aa0655c5c58c7d06" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how it looks for the &lt;code&gt;KFold&lt;/code&gt; cross-validation object:</source>
          <target state="translated">Посмотрим, как это выглядит для &lt;code&gt;KFold&lt;/code&gt; перекрестной проверки KFold :</target>
        </trans-unit>
        <trans-unit id="9c035fe2592c35e4264add67f9ea318300cfbf19" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take a look at what the most informative features are:</source>
          <target state="translated">Давайте посмотрим, какие функции наиболее информативны:</target>
        </trans-unit>
        <trans-unit id="fc26adc7a4427a7251d50d414ace6a50d7fbe76d" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take an example with the following counts. The first term is present 100% of the time hence not very interesting. The two other features only in less than 50% of the time hence probably more representative of the content of the documents:</source>
          <target state="translated">Давайте рассмотрим пример со следующими подсчетами. Первый член присутствует 100% времени, поэтому не очень интересен. Две другие функции используются менее чем в 50% случаев, следовательно, вероятно, более репрезентативны для содержания документов:</target>
        </trans-unit>
        <trans-unit id="2f95c182cf5fa2e13ce2622defe8af992d765313" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s try again with the default setting:</source>
          <target state="translated">Попробуем еще раз с настройкой по умолчанию:</target>
        </trans-unit>
        <trans-unit id="c3a6b9996c4370e6a8670703084aa093c6face20" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s use it to tokenize and count the word occurrences of a minimalistic corpus of text documents:</source>
          <target state="translated">Давайте воспользуемся им для токенизации и подсчета вхождений слов в минималистичном корпусе текстовых документов:</target>
        </trans-unit>
        <trans-unit id="c77ba9dd4a1f63d6e3e47c6ccfdd6637c48fa284" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s visually compare the cross validation behavior for many scikit-learn cross-validation objects. Below we will loop through several common cross-validation objects, visualizing the behavior of each.</source>
          <target state="translated">Давайте визуально сравним поведение перекрестной проверки для многих объектов перекрестной проверки scikit-learn. Ниже мы переберем несколько общих объектов перекрестной проверки, визуализируя поведение каждого из них.</target>
        </trans-unit>
        <trans-unit id="6c69807d4e78cfb8da9f8e8c21f378d88124782a" translate="yes" xml:space="preserve">
          <source>Level of verbosity.</source>
          <target state="translated">Уровень глаголов.</target>
        </trans-unit>
        <trans-unit id="ee9267aef527ceaeed70f092da783571e1b2536d" translate="yes" xml:space="preserve">
          <source>Libsvm GUI</source>
          <target state="translated">Либсвм ГУИ</target>
        </trans-unit>
        <trans-unit id="538c09161b8497f998404cafc34964ed3a445575" translate="yes" xml:space="preserve">
          <source>Licensed under the 3-clause BSD License.</source>
          <target state="translated">Лицензия BSD 3-clause License.</target>
        </trans-unit>
        <trans-unit id="d119b02c417272fad54f56fb5c480a5a866c4e2e" translate="yes" xml:space="preserve">
          <source>Lichman, M. (2013). UCI Machine Learning Repository [&lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt;]. Irvine, CA: University of California, School of Information and Computer Science.</source>
          <target state="translated">Личман, М. (2013). Репозиторий машинного обучения UCI [ &lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt; ]. Ирвин, Калифорния: Калифорнийский университет, Школа информационных и компьютерных наук.</target>
        </trans-unit>
        <trans-unit id="4a2cabe35d47f4d173451a3dc4bce594fc9e8434" translate="yes" xml:space="preserve">
          <source>Like &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;, forests of trees also extend to &lt;a href=&quot;tree#tree-multioutput&quot;&gt;multi-output problems&lt;/a&gt; (if Y is an array of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt;).</source>
          <target state="translated">Подобно &lt;a href=&quot;tree#tree&quot;&gt;деревьям решений&lt;/a&gt; , леса деревьев также распространяются на &lt;a href=&quot;tree#tree-multioutput&quot;&gt;задачи&lt;/a&gt; с несколькими выходами (если Y является массивом размера &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="f8c94a1d14fd76e50a18d8c5112493b7c41a75b8" translate="yes" xml:space="preserve">
          <source>Like &lt;code&gt;Pipeline&lt;/code&gt;, individual steps may be replaced using &lt;code&gt;set_params&lt;/code&gt;, and ignored by setting to &lt;code&gt;'drop'&lt;/code&gt;:</source>
          <target state="translated">Как и в случае с &lt;code&gt;Pipeline&lt;/code&gt; , отдельные шаги можно заменить с помощью &lt;code&gt;set_params&lt;/code&gt; и игнорировать, установив значение &lt;code&gt;'drop'&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="09c07eeb7023cd495f9b67aa8c5832e9de0a3634" translate="yes" xml:space="preserve">
          <source>Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.</source>
          <target state="translated">Как и MultinomialNB,этот классификатор подходит для дискретных данных.Разница заключается в том,что в то время как MultinomialNB работает со счетами вхождений,BernoulliNB предназначен для двоичных/булевых функций.</target>
        </trans-unit>
        <trans-unit id="33e640491ab99ccee8501c0c94b8deb9f93a420b" translate="yes" xml:space="preserve">
          <source>Like fit(X) followed by transform(X), but does not require materializing X in memory.</source>
          <target state="translated">Подобно fit(X)с последующим преобразованием(X),но не требует материализации X в памяти.</target>
        </trans-unit>
        <trans-unit id="07a7d71492c9370f4c5f214183352ca2f48a9590" translate="yes" xml:space="preserve">
          <source>Like in Pipeline and FeatureUnion, this allows the transformer and its parameters to be set using &lt;code&gt;set_params&lt;/code&gt; and searched in grid search.</source>
          <target state="translated">Как и в Pipeline и FeatureUnion, это позволяет настраивать преобразователь и его параметры с помощью &lt;code&gt;set_params&lt;/code&gt; и выполнять поиск в поиске по сетке.</target>
        </trans-unit>
        <trans-unit id="ace16ab25f8f0e2cb278ad02989604150a81258c" translate="yes" xml:space="preserve">
          <source>Like pipelines, feature unions have a shorthand constructor called &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt;&lt;code&gt;make_union&lt;/code&gt;&lt;/a&gt; that does not require explicit naming of the components.</source>
          <target state="translated">Как и конвейеры, объединения функций имеют сокращенный конструктор &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt; &lt;code&gt;make_union&lt;/code&gt; &lt;/a&gt; , который не требует явного именования компонентов.</target>
        </trans-unit>
        <trans-unit id="29685b73b0fbefa3dc8a3378779801b7f7266cf2" translate="yes" xml:space="preserve">
          <source>Like scalers, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; puts all features into the same, known range or distribution. However, by performing a rank transformation, it smooths out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features.</source>
          <target state="translated">Как и скейлеры, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; помещает все функции в один и тот же известный диапазон или распределение. Однако, выполняя преобразование ранга, он сглаживает необычные распределения и меньше подвержен влиянию выбросов, чем методы масштабирования. Однако это искажает корреляции и расстояния внутри и между объектами.</target>
        </trans-unit>
        <trans-unit id="0ae4ed5af04ee97eab148462e283fb7149bd9d04" translate="yes" xml:space="preserve">
          <source>Limit in bytes of the size of the cache.</source>
          <target state="translated">Ограничение в байтах размера кэша.</target>
        </trans-unit>
        <trans-unit id="bbd76c46a461ce6867ca433ec8697501cc65b137" translate="yes" xml:space="preserve">
          <source>Limiting distance of neighbors to return. (default is the value passed to the constructor).</source>
          <target state="translated">Ограничение расстояния до соседей,чтобы вернуться.(по умолчанию-значение,переданное конструктору).</target>
        </trans-unit>
        <trans-unit id="62c917554a7197d63486db913ca90de577c0bfe0" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis</source>
          <target state="translated">Линейный анализ дискриминанта</target>
        </trans-unit>
        <trans-unit id="719a12bbe391db4f9a1b1f0f22d958d133e79356" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) are two classic classifiers, with, as their names suggest, a linear and a quadratic decision surface, respectively.</source>
          <target state="translated">Линейный дискриминантный анализ ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) и квадратичный дискриминантный анализ ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) - это два классических классификатора с, как следует из их названия, линейной и квадратичной поверхностью принятия решений соответственно.</target>
        </trans-unit>
        <trans-unit id="e36f5257c349ab3d8389a5027fa29765ef7a78a4" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance &lt;em&gt;between classes&lt;/em&gt;. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.</source>
          <target state="translated">Линейный дискриминантный анализ (LDA) пытается определить атрибуты, на которые приходится наибольшая разница &lt;em&gt;между классами&lt;/em&gt; . В частности, LDA, в отличие от PCA, является контролируемым методом, использующим известные метки классов.</target>
        </trans-unit>
        <trans-unit id="02924b985796944d65c857ba377ee96748a5fefe" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis and Quadratic Discriminant Analysis</source>
          <target state="translated">Линейный анализ дискриминантов и квадратичный анализ дискриминантов</target>
        </trans-unit>
        <trans-unit id="fe99070400d8a366d4438afb34b3817ed643e76c" translate="yes" xml:space="preserve">
          <source>Linear Model trained with L1 prior as regularizer (aka the Lasso)</source>
          <target state="translated">Линейная модель,прошедшая обучение с L1 в качестве регулятора (он же Лассо).</target>
        </trans-unit>
        <trans-unit id="b4819d272193c458d14d3c2a02b6439edb693339" translate="yes" xml:space="preserve">
          <source>Linear Regression Example</source>
          <target state="translated">Пример линейной регрессии</target>
        </trans-unit>
        <trans-unit id="85494d31f5cd31cf05c6e37284f8e968283c0002" translate="yes" xml:space="preserve">
          <source>Linear SVC is not a probabilistic classifier by default but it has a built-in calibration option enabled in this example (&lt;code&gt;probability=True&lt;/code&gt;).</source>
          <target state="translated">Линейный SVC по умолчанию не является вероятностным классификатором, но в этом примере для него включена встроенная опция калибровки ( &lt;code&gt;probability=True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e97d7a71e4408e1f570cb8d2ee92b68f661724af" translate="yes" xml:space="preserve">
          <source>Linear SVMs</source>
          <target state="translated">Линейные СВМ</target>
        </trans-unit>
        <trans-unit id="73af0f0fe2656e7c704e9d2782f72d490054905e" translate="yes" xml:space="preserve">
          <source>Linear Sum - A n-dimensional vector holding the sum of all samples</source>
          <target state="translated">Линейная сумма-n-мерный вектор,содержащий сумму всех образцов</target>
        </trans-unit>
        <trans-unit id="1cd7978197df4491cb006d18687f0ce787689e06" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification (&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt;) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">Классификация линейных опорных &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; ( LinearSVC ) показывает еще более сигмовидную кривую, чем RandomForestClassifier, что типично для методов с максимальной маржой (сравните Никулеску-Мизил и Каруана &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; ), которые сосредоточены на жестких выборках, которые близки к границе решения ( опорные векторы).</target>
        </trans-unit>
        <trans-unit id="88aaad048f30298d89bc0519c1e6f4cfbb7c20ea" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification.</source>
          <target state="translated">Векторная классификация линейной поддержки.</target>
        </trans-unit>
        <trans-unit id="4669e7bb12c975a34b6d592ccfe985850a9e31eb" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Regression.</source>
          <target state="translated">Векторная регрессия линейной поддержки.</target>
        </trans-unit>
        <trans-unit id="299f04ebeb7ad11bec6b5498c6b639ccade4023d" translate="yes" xml:space="preserve">
          <source>Linear and Quadratic Discriminant Analysis with covariance ellipsoid</source>
          <target state="translated">Линейный и квадратичный анализ дискриминанта с ковариантным эллипсоидом</target>
        </trans-unit>
        <trans-unit id="c0463594ed874e4d015c682e8a6395a05e3fbd8b" translate="yes" xml:space="preserve">
          <source>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</source>
          <target state="translated">Линейные классификаторы (SVM,логистическая регрессия,a.o.)с обучением SGD.</target>
        </trans-unit>
        <trans-unit id="fa82faf2d530b479b3e87ec39c80fc313d729e93" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of centered data, keeping only the most significant singular vectors to project the data to a lower dimensional space.</source>
          <target state="translated">Линейное уменьшение размерности с помощью Singular Value Decomposition из централизованных данных,сохраняя только наиболее значимые сингулярные векторы для проецирования данных в меньшее размерное пространство.</target>
        </trans-unit>
        <trans-unit id="9db7130b75e27bc47e2764b6ec7d1ce03bb7f92f" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.</source>
          <target state="translated">Уменьшение линейной размерности с помощью Singular Value Decomposition данных для проецирования их на меньшее размерное пространство.</target>
        </trans-unit>
        <trans-unit id="212b70af3cba5b501136f7c4f46821ce9f54ad31" translate="yes" xml:space="preserve">
          <source>Linear kernel (&lt;code&gt;kernel = 'linear'&lt;/code&gt;)</source>
          <target state="translated">Линейное ядро ​​( &lt;code&gt;kernel = 'linear'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="1196f0388e6edcd3bda2236746717385556b159a" translate="yes" xml:space="preserve">
          <source>Linear least squares with l2 regularization.</source>
          <target state="translated">Линейные наименьшие квадраты с регуляризацией l2.</target>
        </trans-unit>
        <trans-unit id="0663410286eb390a6a91a4885ecdb0348930bc50" translate="yes" xml:space="preserve">
          <source>Linear model fitted by minimizing a regularized empirical loss with SGD</source>
          <target state="translated">Линейная модель,подогнанная путем минимизации регулярных эмпирических потерь с помощью SGD</target>
        </trans-unit>
        <trans-unit id="8d6556caff9af87efd1e0ccffe2463b6a45189f7" translate="yes" xml:space="preserve">
          <source>Linear model for testing the individual effect of each of many regressors. This is a scoring function to be used in a feature selection procedure, not a free standing feature selection procedure.</source>
          <target state="translated">Линейная модель для тестирования индивидуального эффекта каждого из многих регрессоров.Это функция подсчета очков,которая будет использоваться в процедуре выбора функции,а не в процедуре свободного выбора функции.</target>
        </trans-unit>
        <trans-unit id="8f05719b5c26a33c08ae54e21caa15631a4bbbf1" translate="yes" xml:space="preserve">
          <source>Linear model: from regression to sparsity</source>
          <target state="translated">Линейная модель:от регрессии к спарсителю</target>
        </trans-unit>
        <trans-unit id="2c94cc16a66b49675f2acef482a0fbcd40d606ee" translate="yes" xml:space="preserve">
          <source>Linear models: \(y = X\beta + \epsilon\)</source>
          <target state="translated">Линейные модели:\(y=X\beta+\epsilon\).</target>
        </trans-unit>
        <trans-unit id="b501f602569674c31fc384f2cd7a29bcf6c1ce1f" translate="yes" xml:space="preserve">
          <source>Linear regression</source>
          <target state="translated">Линейная регрессия</target>
        </trans-unit>
        <trans-unit id="d8f88b232d41c327138bbda59458fa5fc4086fff" translate="yes" xml:space="preserve">
          <source>Linear regression model that is robust to outliers.</source>
          <target state="translated">Модель линейной регрессии,устойчивая к отклонениям.</target>
        </trans-unit>
        <trans-unit id="597ff76dcbb7bc322f194ba001977a736c193c2d" translate="yes" xml:space="preserve">
          <source>Linear regression with combined L1 and L2 priors as regularizer.</source>
          <target state="translated">Линейная регрессия с комбинированными L1 и L2 приорами в качестве регулятора.</target>
        </trans-unit>
        <trans-unit id="0a2d386e0774637a1788b00b4abdb8b2c6c38c74" translate="yes" xml:space="preserve">
          <source>Linear ridge regression.</source>
          <target state="translated">Регрессия линейного гребня.</target>
        </trans-unit>
        <trans-unit id="c7ed3fbb6680836b95c3db482cfaf054c37a8419" translate="yes" xml:space="preserve">
          <source>List containing train-test split of inputs.</source>
          <target state="translated">Список,содержащий тестовое разделение входов.</target>
        </trans-unit>
        <trans-unit id="7946c78611ea79ca25491c94f60dac5182c68016" translate="yes" xml:space="preserve">
          <source>List of (name, class), where &lt;code&gt;name&lt;/code&gt; is the class name as string and &lt;code&gt;class&lt;/code&gt; is the actuall type of the class.</source>
          <target state="translated">Список (имя, класс), где &lt;code&gt;name&lt;/code&gt; - это имя класса в виде строки, а &lt;code&gt;class&lt;/code&gt; - это актуальный тип класса.</target>
        </trans-unit>
        <trans-unit id="01f72260e79a828ac37c6e1b27f0158a5c017639" translate="yes" xml:space="preserve">
          <source>List of (name, transform) tuples (implementing fit/transform) that are chained, in the order in which they are chained, with the last object an estimator.</source>
          <target state="translated">Список кортежей (имя,преобразование)(реализующие подгонку/преобразование),которые цепочечно,в порядке их цепочки,с последним объектом-оценщиком.</target>
        </trans-unit>
        <trans-unit id="da3552a00ac25869a883c68bd3a0b9b483a759ac" translate="yes" xml:space="preserve">
          <source>List of (name, transformer, column(s)) tuples specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="translated">Список кортежей (имя,трансформатор,столбец(ы))с указанием объектов трансформатора,которые должны применяться к подмножествам данных.</target>
        </trans-unit>
        <trans-unit id="9ce9067b559ab6542ebc584f224960b4d8e01fb3" translate="yes" xml:space="preserve">
          <source>List of &lt;code&gt;n_features&lt;/code&gt;-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Список &lt;code&gt;n_features&lt;/code&gt; -мерных точек данных. Каждая строка соответствует одной точке данных.</target>
        </trans-unit>
        <trans-unit id="5f38bb9ffb369276ed25fb7c04fb0e0e029823d8" translate="yes" xml:space="preserve">
          <source>List of all the classes that can possibly appear in the y vector.</source>
          <target state="translated">Список всех классов,которые могут появиться в y векторе.</target>
        </trans-unit>
        <trans-unit id="7cd6d854280958549421b40e7d622e1782f63df4" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If &lt;code&gt;None&lt;/code&gt; alphas are set automatically</source>
          <target state="translated">Список альфа, где вычислять модели. Если &lt;code&gt;None&lt;/code&gt; альфа устанавливается автоматически</target>
        </trans-unit>
        <trans-unit id="917b5a956108e84a4893edaf20f4507c6507d0e2" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If None alphas are set automatically</source>
          <target state="translated">Список альфов,где можно рассчитать модели.Если ни один альфа-фаз не установлен автоматически</target>
        </trans-unit>
        <trans-unit id="d057f35a68cef6d291f5ea686ce0f4438a6a2951" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If not provided, set automatically.</source>
          <target state="translated">Список альфов,где можно рассчитать модели.Если он не предусмотрен,установите его автоматически.</target>
        </trans-unit>
        <trans-unit id="fb8d4641f5ca2701f801733b19cf7bb77974f371" translate="yes" xml:space="preserve">
          <source>List of arrays of terms.</source>
          <target state="translated">Список массивов терминов.</target>
        </trans-unit>
        <trans-unit id="6ecedd8bbbc6137125014e8bb7a429cbcef11be8" translate="yes" xml:space="preserve">
          <source>List of built-in kernels.</source>
          <target state="translated">Список встроенных ядер.</target>
        </trans-unit>
        <trans-unit id="36c7ba17f19f78b4b0b98a1a27cecbfd22dc65e4" translate="yes" xml:space="preserve">
          <source>List of coefficients for the Logistic Regression model. If fit_intercept is set to True then the second dimension will be n_features + 1, where the last item represents the intercept. For &lt;code&gt;multiclass='multinomial'&lt;/code&gt;, the shape is (n_classes, n_cs, n_features) or (n_classes, n_cs, n_features + 1).</source>
          <target state="translated">Список коэффициентов модели логистической регрессии. Если для fit_intercept установлено значение True, тогда второе измерение будет n_features + 1, где последний элемент представляет точку пересечения. Для &lt;code&gt;multiclass='multinomial'&lt;/code&gt; форма имеет вид (n_classes, n_cs, n_features) или (n_classes, n_cs, n_features + 1).</target>
        </trans-unit>
        <trans-unit id="568d5fc554d78a8c3f420990686843b1d52522c9" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to reorder or select a subset of labels. If none is given, those that appear at least once in &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; are used in sorted order.</source>
          <target state="translated">Список меток для индексации матрицы. Это можно использовать для изменения порядка или выбора подмножества этикеток. Если ничего не указано, те, которые появляются хотя бы один раз в &lt;code&gt;y_true&lt;/code&gt; или &lt;code&gt;y_pred&lt;/code&gt; , используются в отсортированном порядке.</target>
        </trans-unit>
        <trans-unit id="4904457db6e3ad315971a386c35727cdd591b70f" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to select a subset of labels. If None, all labels that appear at least once in &lt;code&gt;y1&lt;/code&gt; or &lt;code&gt;y2&lt;/code&gt; are used.</source>
          <target state="translated">Список меток для индексации матрицы. Это может быть использовано для выбора подмножества меток. Если нет, используются все метки, которые появляются хотя бы один раз в &lt;code&gt;y1&lt;/code&gt; или &lt;code&gt;y2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b841f355bd90388eac15a6584a26192e6c900c97" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Список n_features-мерных точек данных.Каждая строка соответствует одной точке данных.</target>
        </trans-unit>
        <trans-unit id="af1051d092002bc2f98d27cb1ada3b5cc2dacea1" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single query.</source>
          <target state="translated">Список n_features-мерных точек данных.Каждая строка соответствует одному запросу.</target>
        </trans-unit>
        <trans-unit id="85e7a2833a6b5505d28e95f0c1116dee51aa01e1" translate="yes" xml:space="preserve">
          <source>List of objects to ensure sliceability.</source>
          <target state="translated">Список объектов для обеспечения разрезаемости.</target>
        </trans-unit>
        <trans-unit id="5538dc428bf1dd702d4666daf2c6801367c4f065" translate="yes" xml:space="preserve">
          <source>List of sample weights attached to the data X.</source>
          <target state="translated">Список весов образцов,приложенных к данным X.</target>
        </trans-unit>
        <trans-unit id="af4d88e1f955adfe14752a1cab15db410dc25046" translate="yes" xml:space="preserve">
          <source>List of samples.</source>
          <target state="translated">Список образцов.</target>
        </trans-unit>
        <trans-unit id="9fa149a90ccae2cfe066dfb859bf8a7c95ef01ca" translate="yes" xml:space="preserve">
          <source>List of transformer objects to be applied to the data. The first half of each tuple is the name of the transformer.</source>
          <target state="translated">Список объектов трансформатора,которые необходимо применить к данным.Первая половина каждого кортежа-это название трансформатора.</target>
        </trans-unit>
        <trans-unit id="f2f499a9d9cf5fba3b5aa16bff4e7ad9f538a51f" translate="yes" xml:space="preserve">
          <source>List of values for the regularization parameter or integer specifying the number of regularization parameters that should be used. In this case, the parameters will be chosen in a logarithmic scale between 1e-4 and 1e4.</source>
          <target state="translated">Список значений для параметра регуляризации или целое число,указывающее количество используемых параметров регуляризации.В этом случае параметры будут выбираться в логарифмической шкале от 1e-4 до 1e4.</target>
        </trans-unit>
        <trans-unit id="d742bd356ab53d1131907c9ca41e9f89956bc677" translate="yes" xml:space="preserve">
          <source>List of weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="translated">Список типов весов для расчета баллов. Нет означает отсутствие взвешивания; &amp;laquo;Линейный&amp;raquo; означает линейно взвешенный; &amp;laquo;Квадратичный&amp;raquo; означает квадратично взвешенный.</target>
        </trans-unit>
        <trans-unit id="ccaadae3fd2b8d525242b8298319bebc15b1d7f7" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation forest.&amp;rdquo; Data Mining, 2008. ICDM&amp;lsquo;08. Eighth IEEE International Conference on.</source>
          <target state="translated">Лю, Фэй Тони, Тин, Кай Мин и Чжоу, Чжи-Хуа. &amp;laquo;Изолированный лес&amp;raquo;. Data Mining, 2008. ICDM'08. Восьмая международная конференция IEEE по.</target>
        </trans-unit>
        <trans-unit id="8d858831be3c025b5261ad0994fdd43e36106d2f" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation-based anomaly detection.&amp;rdquo; ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): 3.</source>
          <target state="translated">Лю, Фэй Тони, Тин, Кай Мин и Чжоу, Чжи-Хуа. &amp;laquo;Обнаружение аномалий на основе изоляции&amp;raquo;. Транзакции ACM при обнаружении знаний из данных (TKDD) 6.1 (2012 г.): 3.</target>
        </trans-unit>
        <trans-unit id="bc1c89a3655919cbe107b23bf70fdaef2d59b7e4" translate="yes" xml:space="preserve">
          <source>Load a datasets as downloaded from &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</source>
          <target state="translated">Загрузите наборы данных, загруженные с &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10fbb828ccf5ef978744b601a27eefff85b82acd" translate="yes" xml:space="preserve">
          <source>Load and return the boston house-prices dataset (regression).</source>
          <target state="translated">Загрузите и верните Бостону набор данных о ценах на жилье (регрессия).</target>
        </trans-unit>
        <trans-unit id="f0b03288037dddab02ba1bf0d814f5cc8cf63088" translate="yes" xml:space="preserve">
          <source>Load and return the breast cancer wisconsin dataset (classification).</source>
          <target state="translated">Загрузите и верните набор данных по раку молочной железы (классификация).</target>
        </trans-unit>
        <trans-unit id="fb9c782009d54032f572c4b8eb05f6ff3c69b6ee" translate="yes" xml:space="preserve">
          <source>Load and return the diabetes dataset (regression).</source>
          <target state="translated">Загрузить и вернуть набор данных по диабету (регрессия).</target>
        </trans-unit>
        <trans-unit id="5ee0c3f160bd1db558fab50ff07fd2d60e875939" translate="yes" xml:space="preserve">
          <source>Load and return the digits dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор цифр (классификация).</target>
        </trans-unit>
        <trans-unit id="91627f9a236f04bf8e67f696e6012e55dde096ca" translate="yes" xml:space="preserve">
          <source>Load and return the iris dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор данных по радужной оболочке глаза (классификация).</target>
        </trans-unit>
        <trans-unit id="08308ecd69078eb0533ddcbcb38611925dd58ae7" translate="yes" xml:space="preserve">
          <source>Load and return the linnerud dataset (multivariate regression).</source>
          <target state="translated">Загрузить и вернуть набор данных linnerud (многомерная регрессия).</target>
        </trans-unit>
        <trans-unit id="0a61d81b3e38cd33952ad8e4ab4da4e0afb0ac23" translate="yes" xml:space="preserve">
          <source>Load and return the wine dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор данных о вине (классификация).</target>
        </trans-unit>
        <trans-unit id="907ca9fec180a2f563a6eb0b2c208dd89483dfe5" translate="yes" xml:space="preserve">
          <source>Load dataset from multiple files in SVMlight format</source>
          <target state="translated">Загрузка набора данных из нескольких файлов в формате SVMlight</target>
        </trans-unit>
        <trans-unit id="e0287d019fcfe4320ef71958ec3623d393a07d68" translate="yes" xml:space="preserve">
          <source>Load datasets in the svmlight / libsvm format into sparse CSR matrix</source>
          <target state="translated">Загрузить наборы данных в формате svmlight/libsvm в разреженную CSR матрицу</target>
        </trans-unit>
        <trans-unit id="15df99bbc404778e529956fb3833b1f8b300577d" translate="yes" xml:space="preserve">
          <source>Load sample images for image manipulation.</source>
          <target state="translated">Загружайте образцы изображений для работы с ними.</target>
        </trans-unit>
        <trans-unit id="93b606a5680687306536f14272c219f02caf9a74" translate="yes" xml:space="preserve">
          <source>Load text files with categories as subfolder names.</source>
          <target state="translated">Загружайте текстовые файлы с категориями в качестве имен вложенных папок.</target>
        </trans-unit>
        <trans-unit id="ada1ba97e9c53b7b56715b1a2824f0ae676a78c6" translate="yes" xml:space="preserve">
          <source>Load the 20 newsgroups dataset and vectorize it into token counts (classification).</source>
          <target state="translated">Загрузите набор данных 20 новостных групп и векторизуйте его в подсчет маркеров (классификация).</target>
        </trans-unit>
        <trans-unit id="4f7a062fa00aaafd76d451b474abbba6455b18d1" translate="yes" xml:space="preserve">
          <source>Load the California housing dataset (regression).</source>
          <target state="translated">Загрузите калифорнийский набор данных по жилью (регрессия).</target>
        </trans-unit>
        <trans-unit id="d369acbb02d6ae84bdcebcaf52c16540c4d5f177" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).</source>
          <target state="translated">Загрузить набор данных (классификация)маркированных лиц в парах диких (LFW).</target>
        </trans-unit>
        <trans-unit id="fdf290fe8f8a97ef39a92df3e1f665ba9f5137b7" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) people dataset (classification).</source>
          <target state="translated">Загрузить набор данных (классификация)людей с метками в дикой природе (LFW).</target>
        </trans-unit>
        <trans-unit id="c1d9dfefbd2137b268a0489f71dee7b704510f30" translate="yes" xml:space="preserve">
          <source>Load the Olivetti faces data-set from AT&amp;amp;T (classification).</source>
          <target state="translated">Загрузите набор данных лиц Olivetti от AT&amp;amp;T (классификация).</target>
        </trans-unit>
        <trans-unit id="2772bcfa51d7f467cdc1ff56dd2a38098daf99c8" translate="yes" xml:space="preserve">
          <source>Load the RCV1 multilabel dataset (classification).</source>
          <target state="translated">Загрузить многомаркировочный набор данных RCV1 (классификация).</target>
        </trans-unit>
        <trans-unit id="b34ac8eb475e3d0c92e532ea1f16cafea2826dba" translate="yes" xml:space="preserve">
          <source>Load the covertype dataset (classification).</source>
          <target state="translated">Загрузите набор данных covertype (классификация).</target>
        </trans-unit>
        <trans-unit id="54322fa6d75ea033036ee5315e01f5a9e265e0ca" translate="yes" xml:space="preserve">
          <source>Load the filenames and data from the 20 newsgroups dataset (classification).</source>
          <target state="translated">Загрузить имена файлов и данные из набора данных 20 групп новостей (классификация).</target>
        </trans-unit>
        <trans-unit id="ae3c786b5593f01e176137f6a4960d769f8b9d22" translate="yes" xml:space="preserve">
          <source>Load the kddcup99 dataset (classification).</source>
          <target state="translated">Загрузите набор данных kddcup99 (классификация).</target>
        </trans-unit>
        <trans-unit id="820329ef76c355bc57213e87e726caebf3ec8e17" translate="yes" xml:space="preserve">
          <source>Load the numpy array of a single sample image</source>
          <target state="translated">Загрузите числовой массив одного образца изображения.</target>
        </trans-unit>
        <trans-unit id="6565057c8bbe701655d34466bc255155c3ea2c6e" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et.</source>
          <target state="translated">Загрузчик для набора данных о распределении видов от Филлипса и др.</target>
        </trans-unit>
        <trans-unit id="00912c83de18e685a34ddbd42e1354c697eb14e0" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et. al. (2006)</source>
          <target state="translated">Загрузчик для набора данных о распределении видов от Филлипса и др.(2006)</target>
        </trans-unit>
        <trans-unit id="4f514b04ed6b877534da140af8e12cab5016f713" translate="yes" xml:space="preserve">
          <source>Loaders</source>
          <target state="translated">Loaders</target>
        </trans-unit>
        <trans-unit id="1d603b233f1badee343cd4d051b0c74346bf8ab5" translate="yes" xml:space="preserve">
          <source>Loading an example dataset</source>
          <target state="translated">Загрузка набора данных примера</target>
        </trans-unit>
        <trans-unit id="afb9453c6f5c0750a61be0390918061037ab3605" translate="yes" xml:space="preserve">
          <source>Loading from external datasets</source>
          <target state="translated">Загрузка из внешних наборов данных</target>
        </trans-unit>
        <trans-unit id="b4240e57d982043f1f905f33f107714b1056ff0f" translate="yes" xml:space="preserve">
          <source>Loading the 20 newsgroups dataset</source>
          <target state="translated">Загрузка набора данных 20 новостных групп</target>
        </trans-unit>
        <trans-unit id="bf453b7e00694519c6d048cddce89c9acdc80f61" translate="yes" xml:space="preserve">
          <source>Loads both, &lt;code&gt;china&lt;/code&gt; and &lt;code&gt;flower&lt;/code&gt;.</source>
          <target state="translated">Грузы и &lt;code&gt;china&lt;/code&gt; и &lt;code&gt;flower&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5a8b86a7fef7215f7de926bc65cb224b10c3ccba" translate="yes" xml:space="preserve">
          <source>Locally Linear Embedding</source>
          <target state="translated">Локальное линейное ограждение</target>
        </trans-unit>
        <trans-unit id="f71746cee5cf3673e7e527aaea93ab0ac960ab66" translate="yes" xml:space="preserve">
          <source>Locally linear embedding (LLE) seeks a lower-dimensional projection of the data which preserves distances within local neighborhoods. It can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding.</source>
          <target state="translated">Локально-линейное встраивание (LLE)ищет нижнемерную проекцию данных,которая сохраняет расстояния в пределах локальных окрестностей.Его можно рассматривать как серию локальных анализов основных компонентов,которые глобально сравниваются для поиска наилучшего нелинейного встраивания.</target>
        </trans-unit>
        <trans-unit id="ba721026e6725be51f569c81e87377b42c664dd5" translate="yes" xml:space="preserve">
          <source>Locally linear embedding can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Локально линейное встраивание может быть выполнено с помощью функции &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="120996393a2755aae459a0342f6a159574a0420b" translate="yes" xml:space="preserve">
          <source>Log likelihood of the Gaussian mixture given X.</source>
          <target state="translated">Вероятность бревна гауссовской смеси с учетом X.</target>
        </trans-unit>
        <trans-unit id="10dac5cbd2ef695e498b42bff8cc166d8d6c8a26" translate="yes" xml:space="preserve">
          <source>Log loss is undefined for p=0 or p=1, so probabilities are clipped to max(eps, min(1 - eps, p)).</source>
          <target state="translated">Потеря лога не определена для p=0 или p=1,поэтому вероятности обрезаются до max(eps,min(1-eps,p)).</target>
        </trans-unit>
        <trans-unit id="8742f15984971d3e598576d7cde59958d4df18a1" translate="yes" xml:space="preserve">
          <source>Log loss, aka logistic loss or cross-entropy loss.</source>
          <target state="translated">Потеря журнала,также известная как логистическая потеря или потеря кросс-энтропии.</target>
        </trans-unit>
        <trans-unit id="3332ed47adb99d618a3191081bd1b56f7df887fc" translate="yes" xml:space="preserve">
          <source>Log loss, also called logistic regression loss or cross-entropy loss, is defined on probability estimates. It is commonly used in (multinomial) logistic regression and neural networks, as well as in some variants of expectation-maximization, and can be used to evaluate the probability outputs (&lt;code&gt;predict_proba&lt;/code&gt;) of a classifier instead of its discrete predictions.</source>
          <target state="translated">Потери журнала, также называемые потерями логистической регрессии или кросс-энтропийными потерями, определяются на основе оценок вероятности. Он обычно используется в (полиномиальной) логистической регрессии и нейронных сетях, а также в некоторых вариантах максимизации ожидания и может использоваться для оценки вероятностных выходов ( &lt;code&gt;predict_proba&lt;/code&gt; ) классификатора вместо его дискретных прогнозов.</target>
        </trans-unit>
        <trans-unit id="f8ceba0d5dd7df5e53e4d9ba0bfe4881369ef7f1" translate="yes" xml:space="preserve">
          <source>Log of probability estimates.</source>
          <target state="translated">Журнал вероятностных оценок.</target>
        </trans-unit>
        <trans-unit id="b2dede1f561914a3bc83cf7a3f85dcff6bab8c76" translate="yes" xml:space="preserve">
          <source>Log probabilities of each data point in X.</source>
          <target state="translated">Вероятности журнала каждой точки данных в X.</target>
        </trans-unit>
        <trans-unit id="ce21bba36fd356086ab08edfbf5461d606fc0046" translate="yes" xml:space="preserve">
          <source>Log probability of each class (smoothed).</source>
          <target state="translated">Вероятность записи в журнал каждого класса (сглаженная).</target>
        </trans-unit>
        <trans-unit id="10521a3daec9ae1f69d9eb092c8ffd785e7a6414" translate="yes" xml:space="preserve">
          <source>Log-likelihood of each sample under the current model</source>
          <target state="translated">Вероятность записи в журнал каждой выборки в рамках текущей модели</target>
        </trans-unit>
        <trans-unit id="9c1e8dc95e554810186fcd38490e4f1fe6e53c32" translate="yes" xml:space="preserve">
          <source>Log-likelihood score on left-out data across folds.</source>
          <target state="translated">Вероятность записи в журнал по пропущенным данным по сгибам.</target>
        </trans-unit>
        <trans-unit id="af6fc4d4c535e2fcc7787b2d2b354e641a5cdf07" translate="yes" xml:space="preserve">
          <source>Log-marginal likelihood of theta for training data.</source>
          <target state="translated">Журнал-маржинальная вероятность тэты для тренировочных данных.</target>
        </trans-unit>
        <trans-unit id="a79f6e0f430c7ecad68ae2bba39688851de03cfd" translate="yes" xml:space="preserve">
          <source>Log: Logistic Regression.</source>
          <target state="translated">Бревно:Логистическая регрессия.</target>
        </trans-unit>
        <trans-unit id="667a374e42016ea0491009bae949bbc3eb5a98fe" translate="yes" xml:space="preserve">
          <source>Logistic Regression (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Классификатор логистической регрессии (также известный как logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="7553fecbacc2ab6c754b732dd2a40625b016efa3" translate="yes" xml:space="preserve">
          <source>Logistic Regression 3-class Classifier</source>
          <target state="translated">Классификатор логистической регрессии 3 класса</target>
        </trans-unit>
        <trans-unit id="67b9d1bed8ce4778bb74ee8f32cf37a9f88e56b4" translate="yes" xml:space="preserve">
          <source>Logistic Regression CV (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Классификатор логистической регрессии CV (он же logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="4c4251ffdad99c44ab6ab03dc44e767ed73a387b" translate="yes" xml:space="preserve">
          <source>Logistic function</source>
          <target state="translated">Логистическая функция</target>
        </trans-unit>
        <trans-unit id="2c0f1438d10823ae208574adad9979316ecf1f7d" translate="yes" xml:space="preserve">
          <source>Logistic regression on raw pixel values is presented for comparison. The example shows that the features extracted by the BernoulliRBM help improve the classification accuracy.</source>
          <target state="translated">Для сравнения представлена логистическая регрессия по значениям необработанных пикселей.Пример показывает,что особенности,извлеченные из BernoulliRBM,помогают повысить точность классификации.</target>
        </trans-unit>
        <trans-unit id="f05fe21aed88fc82a5a0513559ae877673e205fc" translate="yes" xml:space="preserve">
          <source>Logistic regression with built-in cross validation</source>
          <target state="translated">Логистическая регрессия со встроенной перекрестной проверкой</target>
        </trans-unit>
        <trans-unit id="d3b2957f5500f497ec4678d49dfe4396dcf43781" translate="yes" xml:space="preserve">
          <source>Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;logistic function&lt;/a&gt;.</source>
          <target state="translated">Логистическая регрессия, несмотря на свое название, представляет собой скорее линейную модель классификации, чем регрессию. Логистическая регрессия также известна в литературе как логит-регрессия, классификация максимальной энтропии (MaxEnt) или лог-линейный классификатор. В этой модели вероятности, описывающие возможные результаты одного испытания, моделируются с использованием &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;логистической функции&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="de456a9443564fc60f026f7b3757765c6c521491" translate="yes" xml:space="preserve">
          <source>LogisticRegression returns well calibrated predictions as it directly optimizes log-loss. In contrast, the other methods return biased probabilities, with different biases per method:</source>
          <target state="translated">LogisticRegression возвращает хорошо откалиброванные прогнозы,так как она непосредственно оптимизирует потери каротажа.Другие методы,напротив,возвращают смещенные вероятности,с разными смещениями для каждого метода:</target>
        </trans-unit>
        <trans-unit id="83ec89bbbb1925d31612bf071115de8d555d9924" translate="yes" xml:space="preserve">
          <source>Longitude house block longitude</source>
          <target state="translated">Долгота блока домов долготы</target>
        </trans-unit>
        <trans-unit id="f2ebf0012d7d593bf1ef0d0a316102397c08a9f0" translate="yes" xml:space="preserve">
          <source>Low-level methods</source>
          <target state="translated">Низкоуровневые методы</target>
        </trans-unit>
        <trans-unit id="ea609f61be1ccbae7413cc55d9401ee01dff16e3" translate="yes" xml:space="preserve">
          <source>Lower bound value on the likelihood (of the training data with respect to the model) of the best fit of inference.</source>
          <target state="translated">Нижняя граница значения вероятности (данных об обучении по отношению к модели)наилучшего подведения итогов.</target>
        </trans-unit>
        <trans-unit id="af301438554e0ee8815f3548a50754545e52e051" translate="yes" xml:space="preserve">
          <source>Lower bound value on the log-likelihood (of the training data with respect to the model) of the best fit of EM.</source>
          <target state="translated">Нижняя граница значения вероятности (данных обучения по отношению к модели)наилучшего соответствия ЭМ.</target>
        </trans-unit>
        <trans-unit id="4ada54abc98e483baeab7ae15def52027a7aae96" translate="yes" xml:space="preserve">
          <source>Lower-triangular Cholesky decomposition of the kernel in &lt;code&gt;X_train_&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;X_train_&lt;/code&gt; разложение ядра Холецкого в X_train_</target>
        </trans-unit>
        <trans-unit id="b93b2eafc7fea724b9bcb08bb1fb9109b8d1d561" translate="yes" xml:space="preserve">
          <source>M. Bawa, T. Condie and P. Ganesan, &amp;ldquo;LSH Forest: Self-Tuning Indexes for Similarity Search&amp;rdquo;, WWW &amp;lsquo;05 Proceedings of the 14th international conference on World Wide Web, 651-660, 2005.</source>
          <target state="translated">М. Бава, Т. Конди и П. Ганесан, &amp;laquo;Лес LSH: самонастраивающиеся индексы для поиска сходства&amp;raquo;, WWW '05 Труды 14-й международной конференции по World Wide Web, 651-660, 2005.</target>
        </trans-unit>
        <trans-unit id="e8445854a0cf4ad63f8ee64cb2fc2359051f4c85" translate="yes" xml:space="preserve">
          <source>M. Dumont et al, &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Fast multi-class image annotation with random subwindows and multiple output randomized trees&lt;/a&gt;, International Conference on Computer Vision Theory and Applications 2009</source>
          <target state="translated">М. Дюмон и др., &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Быстрая мультиклассовая аннотация изображений со случайными подокнами и множественными выходными рандомизированными деревьями&lt;/a&gt; , Международная конференция по теории и приложениям компьютерного зрения, 2009 г.</target>
        </trans-unit>
        <trans-unit id="2422710e8cdc4f555670a3606a875134eadd99fe" translate="yes" xml:space="preserve">
          <source>M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;The Pascal Visual Object Classes (VOC) Challenge&lt;/a&gt;, IJCV 2010.</source>
          <target state="translated">М. Эверингем, Л. Ван Гул, CKI Уильямс, Дж. Винн, А. Зиссерман, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Задача классов визуальных объектов Pascal (VOC)&lt;/a&gt; , IJCV 2010.</target>
        </trans-unit>
        <trans-unit id="aa09c5b3704d1cab7c2f9d80f35ab989ea05cba1" translate="yes" xml:space="preserve">
          <source>MAE output is non-negative floating point. The best value is 0.0.</source>
          <target state="translated">Выход MAE-неотрицательная плавающая запятая.Лучшее значение-0.0.</target>
        </trans-unit>
        <trans-unit id="f4d1d18b18dbadb43dc94aafefb0919124514bb4" translate="yes" xml:space="preserve">
          <source>MEDV Median value of owner-occupied homes in $1000&amp;rsquo;s</source>
          <target state="translated">MEDV Средняя стоимость частных домов в 1000 долларов</target>
        </trans-unit>
        <trans-unit id="33379c640ef1bcb7b4dbc3ceb61d0f9854342e44" translate="yes" xml:space="preserve">
          <source>MKL</source>
          <target state="translated">MKL</target>
        </trans-unit>
        <trans-unit id="a8e1fd8b99167af6d3e02ac86d0a101dabaf0e42" translate="yes" xml:space="preserve">
          <source>MLP can fit a non-linear model to the training data. &lt;code&gt;clf.coefs_&lt;/code&gt; contains the weight matrices that constitute the model parameters:</source>
          <target state="translated">MLP может подогнать нелинейную модель к обучающим данным. &lt;code&gt;clf.coefs_&lt;/code&gt; содержит весовые матрицы, составляющие параметры модели:</target>
        </trans-unit>
        <trans-unit id="7fc5f2a7a15f6ccd1641b37c2fb96c6ce75018c2" translate="yes" xml:space="preserve">
          <source>MLP is sensitive to feature scaling.</source>
          <target state="translated">MLP чувствителен к масштабированию функций.</target>
        </trans-unit>
        <trans-unit id="08431dee59de79a71b4718dbf6ee28e75fee38c3" translate="yes" xml:space="preserve">
          <source>MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.</source>
          <target state="translated">MLP требует настройки ряда гиперпараметров,таких как количество скрытых нейронов,слоев и итераций.</target>
        </trans-unit>
        <trans-unit id="e82dbcf8b443c94c79e54d7d53faa6f5db46762a" translate="yes" xml:space="preserve">
          <source>MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples:</source>
          <target state="translated">MLP тренируется на двух массивах:массиве X размера (n_samples,n_features),в котором обучающие выборки представлены в виде векторов признаков с плавающей точкой;и массиве y размера (n_samples,),в котором хранятся целевые значения (метки классов)для обучающих выборок:</target>
        </trans-unit>
        <trans-unit id="f0c27305c85163e665d40daa0f2ca2e458a2e63e" translate="yes" xml:space="preserve">
          <source>MLP trains using &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt;, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt;. Stochastic Gradient Descent (SGD) updates parameters using the gradient of the loss function with respect to a parameter that needs adaptation, i.e.</source>
          <target state="translated">MLP тренирует с использованием &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;стохастического градиентного спуска&lt;/a&gt; , &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Адама&lt;/a&gt; или &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt; . Стохастический градиентный спуск (SGD) обновляет параметры, используя градиент функции потерь по отношению к параметру, который требует адаптации, т. Е.</target>
        </trans-unit>
        <trans-unit id="f27922032032bfc1325082b9b33d5f3a9228ddf6" translate="yes" xml:space="preserve">
          <source>MLP trains using Backpropagation. More precisely, it trains using some form of gradient descent and the gradients are calculated using Backpropagation. For classification, it minimizes the Cross-Entropy loss function, giving a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">Поезда MLP с помощью Backpropagation.Точнее,он движется поездам,использующим ту или иную форму спуска с уклоном,а уклоны рассчитываются с помощью Backpropagation.Для классификации она минимизирует функцию Cross-Entropy loss,давая вектор вероятностных оценок \(P(y|x)\)на выборку \(x\):</target>
        </trans-unit>
        <trans-unit id="c8c1d3b7c59691465cb0496f22bcb3604bca5a60" translate="yes" xml:space="preserve">
          <source>MLP uses different loss functions depending on the problem type. The loss function for classification is Cross-Entropy, which in binary case is given as,</source>
          <target state="translated">MLP использует различные функции потерь в зависимости от типа проблемы.Функция потерь для классификации является Cross-Entropy,которая в двоичном случае дается как,</target>
        </trans-unit>
        <trans-unit id="d03f0b750d6ad970862b8ceab4b82a667eb1bc44" translate="yes" xml:space="preserve">
          <source>MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.</source>
          <target state="translated">MLP со скрытыми слоями имеют функцию несверхностных потерь,где существует более одного локального минимума.Поэтому различные случайные весовые инициализации могут привести к различной точности проверки.</target>
        </trans-unit>
        <trans-unit id="14160d0f2e53b28f2f5c2a7702cb0510220c29b8" translate="yes" xml:space="preserve">
          <source>MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">MLPClassifier тренируется итеративно,так как на каждом шаге вычисляются частичные производные функции потерь относительно параметров модели для обновления параметров.</target>
        </trans-unit>
        <trans-unit id="8b27d0c0c6a8a44ae6f32f660e2bfb892d109024" translate="yes" xml:space="preserve">
          <source>MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">MLPRegressor тренируется итеративно,так как на каждом шаге вычисляются частичные производные функции потерь относительно параметров модели для обновления параметров.</target>
        </trans-unit>
        <trans-unit id="8e70290c1fc16432a8f4b616e4fd6fbaa4abfbea" translate="yes" xml:space="preserve">
          <source>MNIST classfification using multinomial logistic + L1</source>
          <target state="translated">Классификация MNIST с использованием мультиномиальной логистики+L1</target>
        </trans-unit>
        <trans-unit id="25845da185fe3a02cb60c18fcf84202e8f31d1e7" translate="yes" xml:space="preserve">
          <source>Machine learning algorithms need data. Go to each &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; sub-folder and run the &lt;code&gt;fetch_data.py&lt;/code&gt; script from there (after having read them first).</source>
          <target state="translated">Алгоритмам машинного обучения нужны данные. Перейдите в каждую подпапку &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; и запустите &lt;code&gt;fetch_data.py&lt;/code&gt; скрипт fetch_data.py (предварительно прочитав их).</target>
        </trans-unit>
        <trans-unit id="45f2bd27f62f0226a5b3177e6a59d79cc23fea68" translate="yes" xml:space="preserve">
          <source>Machine learning is about learning some properties of a data set and then testing those properties against another data set. A common practice in machine learning is to evaluate an algorithm by splitting a data set into two. We call one of those sets the &lt;strong&gt;training set&lt;/strong&gt;, on which we learn some properties; we call the other set the &lt;strong&gt;testing set&lt;/strong&gt;, on which we test the learned properties.</source>
          <target state="translated">Машинное обучение - это изучение некоторых свойств набора данных и последующее тестирование этих свойств на другом наборе данных. Обычной практикой в ​​машинном обучении является оценка алгоритма путем разделения набора данных на два. Мы называем один из этих наборов &lt;strong&gt;обучающим набором&lt;/strong&gt; , на котором мы изучаем некоторые свойства; мы называем другой набор набором для &lt;strong&gt;тестирования&lt;/strong&gt; , на котором мы проверяем изученные свойства.</target>
        </trans-unit>
        <trans-unit id="17dc705c260bdc393406dc006335656d8788b655" translate="yes" xml:space="preserve">
          <source>Machine learning: the problem setting</source>
          <target state="translated">Машинное обучение:постановка задачи</target>
        </trans-unit>
        <trans-unit id="e6a69273199992ddfe41f469dda4cc1f6b79ceb0" translate="yes" xml:space="preserve">
          <source>Magnesium</source>
          <target state="translated">Magnesium</target>
        </trans-unit>
        <trans-unit id="2bb08573261ae718ebb52db49951821b64f9a80c" translate="yes" xml:space="preserve">
          <source>Magnesium:</source>
          <target state="translated">Magnesium:</target>
        </trans-unit>
        <trans-unit id="91059cae8d3b76142d7879b78c0a2ccaab268e7d" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances of the training set (on which &lt;code&gt;fit&lt;/code&gt; is called) observations.</source>
          <target state="translated">Дистанции Махаланобиса обучающей выборки (на которой называется &lt;code&gt;fit&lt;/code&gt; ) наблюдений.</target>
        </trans-unit>
        <trans-unit id="d469f730cc4a1b58c5ef61209e446f59013c3c80" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances to centers</source>
          <target state="translated">Махаланобис расстояния до центров</target>
        </trans-unit>
        <trans-unit id="6f98cc22ed52c0a1e40fae778fadcd35627c25b5" translate="yes" xml:space="preserve">
          <source>MahalanobisDistance</source>
          <target state="translated">MahalanobisDistance</target>
        </trans-unit>
        <trans-unit id="62bce9422ff2d14f69ab80a154510232fc8a9afd" translate="yes" xml:space="preserve">
          <source>Main</source>
          <target state="translated">Main</target>
        </trans-unit>
        <trans-unit id="8d6381188443dad8aa5d016fb4ec69dd96237200" translate="yes" xml:space="preserve">
          <source>Make a copy of input data.</source>
          <target state="translated">Сделайте копию входных данных.</target>
        </trans-unit>
        <trans-unit id="f11963f5d19078a49cfab3cc41da5922accd3330" translate="yes" xml:space="preserve">
          <source>Make a large circle containing a smaller circle in 2d.</source>
          <target state="translated">Сделайте большой круг,содержащий меньший круг в 2d.</target>
        </trans-unit>
        <trans-unit id="1cce5fef6c99c293eee32e22f026e768f4b5d892" translate="yes" xml:space="preserve">
          <source>Make a scorer from a performance metric or loss function.</source>
          <target state="translated">Сделайте счетчик из метрики производительности или потери функции.</target>
        </trans-unit>
        <trans-unit id="bdd3abd6a5ef3ffb2c4167fd4f1b6dc60d7a55bd" translate="yes" xml:space="preserve">
          <source>Make arrays indexable for cross-validation.</source>
          <target state="translated">Сделайте массивы индексируемыми для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="2d28cad808149ac4eb3c924434a0979417f24a68" translate="yes" xml:space="preserve">
          <source>Make sure that X has a minimum number of samples in its first axis (rows for a 2D array).</source>
          <target state="translated">Убедитесь,что X имеет минимальное количество отсчетов по первой оси (строк для 2D массива).</target>
        </trans-unit>
        <trans-unit id="b2b1ee415b35f3ec33d28dbc91a8479edeb8d71e" translate="yes" xml:space="preserve">
          <source>Make sure that array is 2D, square and symmetric.</source>
          <target state="translated">Убедитесь,что массив 2D,квадратный и симметричный.</target>
        </trans-unit>
        <trans-unit id="6885424e5e7bfa46a7e7c7cb1bd5d6e804bbccd9" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when X has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь, что 2D-массив имеет минимальное количество функций (столбцов). Значение по умолчанию 1 отклоняет пустые наборы данных. Эта проверка применяется только тогда, когда X фактически имеет 2 измерения или изначально является 1D и &lt;code&gt;ensure_2d&lt;/code&gt; имеет значение True. Установка на 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="37a276f69711964822e7fcec88111a5f6d2f84a0" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when the input data has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь, что 2D-массив имеет минимальное количество функций (столбцов). Значение по умолчанию 1 отклоняет пустые наборы данных. Эта проверка выполняется только в том случае, если входные данные имеют фактически 2 измерения или изначально являются 1D и &lt;code&gt;ensure_2d&lt;/code&gt; имеет значение True. Установка на 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="c24d8a1e4fcddcfde73957adfbe65fb40c76c786" translate="yes" xml:space="preserve">
          <source>Make sure that the array has a minimum number of samples in its first axis (rows for a 2D array). Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь,что в первой оси массива есть минимальное количество сэмплов (строк для 2D массива).Установка в 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="fdc3084b2db3fff3561874bdbe81f2954a4b0ffc" translate="yes" xml:space="preserve">
          <source>Make sure the same scale is used over all features. Because manifold learning methods are based on a nearest-neighbor search, the algorithm may perform poorly otherwise. See &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; for convenient ways of scaling heterogeneous data.</source>
          <target state="translated">Убедитесь, что для всех функций используется один и тот же масштаб. Поскольку разнообразные методы обучения основаны на поиске ближайшего соседа, в противном случае алгоритм может работать плохо. См. &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; для удобных способов масштабирования разнородных данных.</target>
        </trans-unit>
        <trans-unit id="7f7e62e13bb8885a4df4d0d5a8e1dba7c3c65c15" translate="yes" xml:space="preserve">
          <source>Make sure you permute (shuffle) your training data before fitting the model or use &lt;code&gt;shuffle=True&lt;/code&gt; to shuffle after each iteration.</source>
          <target state="translated">Убедитесь, что вы переставляете (перемешиваете) свои обучающие данные перед подгонкой модели или используете &lt;code&gt;shuffle=True&lt;/code&gt; для перемешивания после каждой итерации.</target>
        </trans-unit>
        <trans-unit id="f48f3a474378f962985a41275dc98355541c63d2" translate="yes" xml:space="preserve">
          <source>Make two interleaving half circles</source>
          <target state="translated">Сделайте два чередовавшихся полуокружности</target>
        </trans-unit>
        <trans-unit id="0a0a9871e0af603535e4f6104cfca3266e203a87" translate="yes" xml:space="preserve">
          <source>Malic Acid:</source>
          <target state="translated">Малиновая кислота:</target>
        </trans-unit>
        <trans-unit id="245748b8f3a70aaac9759204b7d3978b9d337db8" translate="yes" xml:space="preserve">
          <source>Malic acid</source>
          <target state="translated">яблочная кислота</target>
        </trans-unit>
        <trans-unit id="a81a721fb7e702ed0a37d056ec4a9d2f925e70b0" translate="yes" xml:space="preserve">
          <source>ManhattanDistance</source>
          <target state="translated">ManhattanDistance</target>
        </trans-unit>
        <trans-unit id="ccbe2127be70aaa7c3514b3155dd29902fae6143" translate="yes" xml:space="preserve">
          <source>Manifold Learning can be thought of as an attempt to generalize linear frameworks like PCA to be sensitive to non-linear structure in data. Though supervised variants exist, the typical manifold learning problem is unsupervised: it learns the high-dimensional structure of the data from the data itself, without the use of predetermined classifications.</source>
          <target state="translated">Manifold Learning можно рассматривать как попытку обобщить линейные структуры,такие как PCA,чтобы быть чувствительными к нелинейным структурам в данных.Несмотря на то,что существуют контролируемые варианты,типичная проблема многогранного обучения остается без внимания:она узнает высокоразмерную структуру данных из самих данных,без использования заранее определенных классификаций.</target>
        </trans-unit>
        <trans-unit id="7a0e60acb472080022463866637a1ea7c0251335" translate="yes" xml:space="preserve">
          <source>Manifold Learning methods on a severed sphere</source>
          <target state="translated">Манифольдовые методы обучения на разорванной сфере</target>
        </trans-unit>
        <trans-unit id="aca365adba00c10f7a3cc50cff4a88afd0947dd9" translate="yes" xml:space="preserve">
          <source>Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.</source>
          <target state="translated">Обучение манифестациям-это подход к нелинейному уменьшению размерности.Алгоритмы для этой задачи основаны на идее,что размерность многих наборов данных только искусственно завышена.</target>
        </trans-unit>
        <trans-unit id="1e718f0bccbec4566b4c8536fdd24c184318a8a9" translate="yes" xml:space="preserve">
          <source>Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;</source>
          <target state="translated">Обучение многообразию рукописных цифр: локально линейное встраивание, Isomap&amp;hellip;</target>
        </trans-unit>
        <trans-unit id="0d3695eb907329bab9f0e9752d7ff00d200420c9" translate="yes" xml:space="preserve">
          <source>Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations (it is an &lt;em&gt;inlier&lt;/em&gt;), or should be considered as different (it is an &lt;em&gt;outlier&lt;/em&gt;). Often, this ability is used to clean real data sets. Two important distinctions must be made:</source>
          <target state="translated">Многие приложения требуют наличия возможности решить, принадлежит ли новое наблюдение к тому же распределению, что и существующие наблюдения (это &lt;em&gt;промежуточный результат&lt;/em&gt; ), или его следует рассматривать как другое (это &lt;em&gt;выброс&lt;/em&gt; ). Часто эта возможность используется для очистки реальных наборов данных. Необходимо сделать два важных различия:</target>
        </trans-unit>
        <trans-unit id="626f0980ad5cd6d2b6f18a99ff094a7bf141dc9a" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints</source>
          <target state="translated">Многие кластеры,возможно,ограничения связи</target>
        </trans-unit>
        <trans-unit id="9d1190903d42ddc70f3db2311f157c56b6260b92" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints, non Euclidean distances</source>
          <target state="translated">Многие кластеры,возможно,ограничения связи,не евклидовые расстояния</target>
        </trans-unit>
        <trans-unit id="ac65e2f8a158fa7cc404d708906171f5ea9f26fd" translate="yes" xml:space="preserve">
          <source>Many clusters, uneven cluster size, non-flat geometry</source>
          <target state="translated">Множество кластеров,неравномерный размер кластера,не плоская геометрия</target>
        </trans-unit>
        <trans-unit id="241eda779a46dbe514b8b7f2a96e98aed4d935af" translate="yes" xml:space="preserve">
          <source>Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. Often it is easiest to preprocess data before applying scikit-learn methods, for example using &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;. Processing your data before passing it to scikit-learn might be problematic for one of the following reasons:</source>
          <target state="translated">Многие наборы данных содержат объекты разных типов, например текст, числа с плавающей запятой и даты, где каждый тип объекта требует отдельных шагов предварительной обработки или извлечения признаков. Часто проще всего предварительно обработать данные перед применением методов scikit-learn, например, с помощью &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; . Обработка ваших данных перед их передачей в scikit-learn может быть проблематичной по одной из следующих причин:</target>
        </trans-unit>
        <trans-unit id="192c25a6ed904d1327958fde4c93098505cb86b8" translate="yes" xml:space="preserve">
          <source>Many metrics are not given names to be used as &lt;code&gt;scoring&lt;/code&gt; values, sometimes because they require additional parameters, such as &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;. In such cases, you need to generate an appropriate scoring object. The simplest way to generate a callable object for scoring is by using &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt;. That function converts metrics into callables that can be used for model evaluation.</source>
          <target state="translated">Многие показатели не дают имена , которые будут использоваться в качестве &lt;code&gt;scoring&lt;/code&gt; значений, иногда потому , что они требуют дополнительных параметров, таких как &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; . В таких случаях вам необходимо создать соответствующий объект оценки. Самый простой способ сгенерировать вызываемый объект для скоринга - использовать &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; . Эта функция преобразует метрики в вызываемые объекты, которые можно использовать для оценки модели.</target>
        </trans-unit>
        <trans-unit id="dacd10610ea3bac36f91971d47d3019273ca964d" translate="yes" xml:space="preserve">
          <source>Many statistical problems require the estimation of a population&amp;rsquo;s covariance matrix, which can be seen as an estimation of data set scatter plot shape. Most of the time, such an estimation has to be done on a sample whose properties (size, structure, homogeneity) have a large influence on the estimation&amp;rsquo;s quality. The &lt;code&gt;sklearn.covariance&lt;/code&gt; package provides tools for accurately estimating a population&amp;rsquo;s covariance matrix under various settings.</source>
          <target state="translated">Многие статистические задачи требуют оценки ковариационной матрицы совокупности, которую можно рассматривать как оценку формы диаграммы разброса набора данных. В большинстве случаев такую ​​оценку приходится проводить на выборке, свойства которой (размер, структура, однородность) имеют большое влияние на качество оценки. Пакет &lt;code&gt;sklearn.covariance&lt;/code&gt; предоставляет инструменты для точной оценки ковариационной матрицы популяции при различных настройках.</target>
        </trans-unit>
        <trans-unit id="be7bf3b7e371f4bec9a03a7522f6dcf31d112a68" translate="yes" xml:space="preserve">
          <source>Many, many more &amp;hellip;</source>
          <target state="translated">Многие, многие другие&amp;hellip;</target>
        </trans-unit>
        <trans-unit id="01a4f781a04bf81d6d3609180ff5b158082bf232" translate="yes" xml:space="preserve">
          <source>Map data to a normal distribution</source>
          <target state="translated">Карта данных для нормального распределения</target>
        </trans-unit>
        <trans-unit id="16409bc40b2df043ac11786860ad0f327aa511b9" translate="yes" xml:space="preserve">
          <source>Maps data to a normal distribution using a power transformation.</source>
          <target state="translated">Картирование данных в нормальное распределение с помощью преобразования мощности.</target>
        </trans-unit>
        <trans-unit id="05aecccd2b32722fa423ccbd7840d48763834385" translate="yes" xml:space="preserve">
          <source>Maps data to a standard normal distribution with the parameter &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Сопоставляет данные со стандартным нормальным распределением с параметром &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2546740d19a0cb39e3dfa40dd82138fa02a22968" translate="yes" xml:space="preserve">
          <source>Maps each categorical feature name to a list of values, such that the value encoded as i is ith in the list.</source>
          <target state="translated">Сопоставляет имя каждого категориального элемента со списком значений,таким образом,чтобы значение,закодированное как i,было ith в списке.</target>
        </trans-unit>
        <trans-unit id="601b228138151f5d614818578f5a990f06465ee3" translate="yes" xml:space="preserve">
          <source>Marginal distribution for the transformed data. The choices are &amp;lsquo;uniform&amp;rsquo; (default) or &amp;lsquo;normal&amp;rsquo;.</source>
          <target state="translated">Маржинальное распределение для преобразованных данных. Возможные варианты: &amp;laquo;равномерный&amp;raquo; (по умолчанию) или &amp;laquo;нормальный&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="32cec489ab51eb304acc5d56c34e0b5894817af1" translate="yes" xml:space="preserve">
          <source>Mark Schmidt, Nicolas Le Roux, and Francis Bach: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;Minimizing Finite Sums with the Stochastic Average Gradient.&lt;/a&gt;</source>
          <target state="translated">Марк Шмидт, Николя Ле Ру и Фрэнсис Бах: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;минимизация конечных сумм с помощью стохастического среднего градиента.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b66f191d027329ba9273c4c5f9be765f9b3745f5" translate="yes" xml:space="preserve">
          <source>Mask to be used on X.</source>
          <target state="translated">Маска для X.</target>
        </trans-unit>
        <trans-unit id="54a21a4d94fa24c6c092fd6e4c2ec05359c76c09" translate="yes" xml:space="preserve">
          <source>MatchingDistance</source>
          <target state="translated">MatchingDistance</target>
        </trans-unit>
        <trans-unit id="38c6b835ca8294e13538ac219d64ae1244beb7fc" translate="yes" xml:space="preserve">
          <source>Matern kernel.</source>
          <target state="translated">Материнское ядро.</target>
        </trans-unit>
        <trans-unit id="c2846fd5b2a8440131137c07fea40912afc701b7" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with \(\ell_1\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,прошедшей обучение по адресу \(\ell_1\)в качестве регулятора.Объективная функция для минимизации является:</target>
        </trans-unit>
        <trans-unit id="bf1818d1c45b1997515a16368907c8cf902bab56" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior and \(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,подготовленной со смешанной \(\ell__1\)\(\ell__2\)предыдущей и \(\ell__2\)предыдущей в качестве регулятора.Объективная функция,чтобы минимизировать является:</target>
        </trans-unit>
        <trans-unit id="1d9fe275a9038555cabcfe46b4a675067788d84f" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,подготовленной со смешанной \(\ell_1\)\(\ell__2\)до этого в качестве регулятора.Объективная функция для минимизации является:</target>
        </trans-unit>
        <trans-unit id="461064fec990b9f56bd78c5da4699263962dc67b" translate="yes" xml:space="preserve">
          <source>Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the l2-penalized Maximum Likelihood Estimator of the covariance matrix. In practice, shrinkage boils down to a simple a convex transformation : \(\Sigma_{\rm shrunk} = (1-\alpha)\hat{\Sigma} + \alpha\frac{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).</source>
          <target state="translated">Математически эта усадка заключается в уменьшении соотношения между наименьшими и наибольшими собственными значениями эмпирической ковариационной матрицы.Это может быть сделано путем простого смещения каждого собственного значения в соответствии с заданным смещением,что эквивалентно нахождению l2-пеналлизованного Оценщика максимального правдоподобия ковариационной матрицы.На практике усадка сводится к простому выпуклому преобразованию:\(\Sigma_{\rm shrunk}=(1-\alpha)\hat{\Sigma}+\alpha\frac{{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).</target>
        </trans-unit>
        <trans-unit id="7f2fa948973686599d9719cd22bf9c261bdbf5a5" translate="yes" xml:space="preserve">
          <source>Mathematically, truncated SVD applied to training samples \(X\) produces a low-rank approximation \(X\):</source>
          <target state="translated">Математически усеченное SVD,применяемое к учебным образцам \(X\),производит низкоуровневое приближение \(X\):</target>
        </trans-unit>
        <trans-unit id="b8c6141893596b10260b39727bf4a66986a56a95" translate="yes" xml:space="preserve">
          <source>Matrices:</source>
          <target state="translated">Matrices:</target>
        </trans-unit>
        <trans-unit id="878abbe8708b2c0d949ede6590fbf80f3b3ca712" translate="yes" xml:space="preserve">
          <source>Matrix \(C\) such that \(C_{i, j}\) is the number of samples in true class \(i\) and in predicted class \(j\). If &lt;code&gt;eps is None&lt;/code&gt;, the dtype of this array will be integer. If &lt;code&gt;eps&lt;/code&gt; is given, the dtype will be float. Will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; if &lt;code&gt;sparse=True&lt;/code&gt;.</source>
          <target state="translated">Матрица \ (C \) такая, что \ (C_ {i, j} \) - это количество выборок в истинном классе \ (i \) и в предсказанном классе \ (j \). Если &lt;code&gt;eps is None&lt;/code&gt; , dtype этого массива будет целым. Если задано &lt;code&gt;eps&lt;/code&gt; , dtype будет плавающим. Будет &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; , если &lt;code&gt;sparse=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a9d3bf25623c95ec103c9ba9ebefafc39b31e10" translate="yes" xml:space="preserve">
          <source>Matrix of similarities between points</source>
          <target state="translated">Матрица сходства между точками</target>
        </trans-unit>
        <trans-unit id="fe09cc11ed56c787dbf583e1d3c86930e73d13b7" translate="yes" xml:space="preserve">
          <source>Matrix to be scaled.</source>
          <target state="translated">Матрица должна быть масштабирована.</target>
        </trans-unit>
        <trans-unit id="f581a8973d13aee9e6d301f776c7ac0aca9937df" translate="yes" xml:space="preserve">
          <source>Matrix to decompose</source>
          <target state="translated">Матрица для разложения</target>
        </trans-unit>
        <trans-unit id="64c58969af0dfb121c9b8582a353fed07f3ae81a" translate="yes" xml:space="preserve">
          <source>Matrix to normalize using the variance of the features.</source>
          <target state="translated">Матрица для нормализации с использованием дисперсии функций.</target>
        </trans-unit>
        <trans-unit id="dc67599b55e21aadb81c15a2c42c0d243f238c7f" translate="yes" xml:space="preserve">
          <source>Matrix whose two columns are to be swapped.</source>
          <target state="translated">Матрица,две колонки которой должны быть заменены.</target>
        </trans-unit>
        <trans-unit id="2ea8698954891f702cc6556af5a70f4a4777910c" translate="yes" xml:space="preserve">
          <source>Matrix whose two rows are to be swapped.</source>
          <target state="translated">Матрица,два ряда которой должны быть заменены.</target>
        </trans-unit>
        <trans-unit id="91c27cd36373d9f3e97d3e8652e4d5420038195e" translate="yes" xml:space="preserve">
          <source>Max number of iterations for updating document topic distribution in the E-step.</source>
          <target state="translated">Максимальное количество итераций для обновления распространения темы документа в E-шаге.</target>
        </trans-unit>
        <trans-unit id="00c71f39eb3784f568496e9b201bef34cf1fba1e" translate="yes" xml:space="preserve">
          <source>MaxAbsScaler</source>
          <target state="translated">MaxAbsScaler</target>
        </trans-unit>
        <trans-unit id="b19f6ae06ce0301b0f2f115ace4b151976f71361" translate="yes" xml:space="preserve">
          <source>Maximizing ELBO is equivalent to minimizing the Kullback-Leibler(KL) divergence between \(q(z,\theta,\beta)\) and the true posterior \(p(z, \theta, \beta |w, \alpha, \eta)\).</source>
          <target state="translated">Максимизация ELBO эквивалентна минимизации расхождения Kullback-Leibler(KL)между \(q(z,\theta,\beta)\)и истинным апостериорным \(p(z,\theta,\beta |w,\alpha,\eta)\).</target>
        </trans-unit>
        <trans-unit id="c7118c6c94bd33474c6bd73b2a0ef4d05bd61b9a" translate="yes" xml:space="preserve">
          <source>Maximizing the log-marginal-likelihood after subtracting the target&amp;rsquo;s mean yields the following kernel with an LML of -83.214:</source>
          <target state="translated">Максимизация логарифма маржинального правдоподобия после вычитания целевого среднего дает следующее ядро ​​с LML -83,214:</target>
        </trans-unit>
        <trans-unit id="3cc68e53e734e045e272d9b61d6ce440314a7c5a" translate="yes" xml:space="preserve">
          <source>Maximum distortion rate as defined by the Johnson-Lindenstrauss lemma. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">Максимальная скорость искажений,определенная леммой Джонсона-Линденстрауса.Если задан массив,то он вычислит безопасное количество компонентов массива.</target>
        </trans-unit>
        <trans-unit id="2648af65469bf6064127630edb239d63fa9087cb" translate="yes" xml:space="preserve">
          <source>Maximum likelihood covariance estimator</source>
          <target state="translated">Оценщик максимальной вероятности ковариаций</target>
        </trans-unit>
        <trans-unit id="c549d82a160dc50758b33cda113fa1dc7a80727c" translate="yes" xml:space="preserve">
          <source>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</source>
          <target state="translated">Максимальная норма остатка.Если нет None,переопределяет n_nonzero_coefs.</target>
        </trans-unit>
        <trans-unit id="c4d8a154588727ab7c620ef2088eb03d03fdb2cd" translate="yes" xml:space="preserve">
          <source>Maximum number of CF subclusters in each node. If a new samples enters such that the number of subclusters exceed the branching_factor then that node is split into two nodes with the subclusters redistributed in each. The parent subcluster of that node is removed and two new subclusters are added as parents of the 2 split nodes.</source>
          <target state="translated">Максимальное количество подкластеров CF в каждом узле.Если новые выборки поступают так,что количество подкластеров превышает коэффициент ветвления,то эта вершина делится на две вершины,в каждой из которых перераспределяются подкластеры.Родительский подкластер этого узла удаляется,и два новых подкластера добавляются как родители 2-х разделенных узлов.</target>
        </trans-unit>
        <trans-unit id="ffcbfb393ae9341f5e6cf4dea80093dbb65c654d" translate="yes" xml:space="preserve">
          <source>Maximum number of epochs to not meet &lt;code&gt;tol&lt;/code&gt; improvement. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Максимальное количество эпох не соответствует &lt;code&gt;tol&lt;/code&gt; улучшения. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="2d31095f21fc709b8362fbfbc8701ee49bed43f4" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations</source>
          <target state="translated">Максимальное количество итераций</target>
        </trans-unit>
        <trans-unit id="8d0f629c611a546c50fbd29c0a5c09d14523502f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations before timing out.</source>
          <target state="translated">Максимальное количество итераций до тайминга.</target>
        </trans-unit>
        <trans-unit id="e5ab15aeae2ebd19c6cc8dd9b722001d143407e7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations during fit.</source>
          <target state="translated">Максимальное количество итераций во время посадки.</target>
        </trans-unit>
        <trans-unit id="4bd775e3e4801f1199d0d4b78f5390120406b7db" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for arpack. If None, optimal value will be chosen by arpack.</source>
          <target state="translated">Максимальное количество итераций для арпака.Если Нет,то оптимальное значение будет выбрано арпакетом.</target>
        </trans-unit>
        <trans-unit id="f374a3956c9375a530255caa54ee43ca08273ef7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; solver, the default value is 1000.</source>
          <target state="translated">Максимальное количество итераций для решателя сопряженных градиентов. Для решателей 'sparse_cg' и 'lsqr' значение по умолчанию определяется scipy.sparse.linalg. Для решателя &amp;laquo;провисания&amp;raquo; значение по умолчанию - 1000.</target>
        </trans-unit>
        <trans-unit id="11f341e8f36dbf9c1af7cfa8e66dcc9686e34f6b" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For the &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; and saga solver, the default value is 1000.</source>
          <target state="translated">Максимальное количество итераций для решателя сопряженных градиентов. Для решателей 'sparse_cg' и 'lsqr' значение по умолчанию определяется scipy.sparse.linalg. Для решателя sag и saga значение по умолчанию - 1000.</target>
        </trans-unit>
        <trans-unit id="c5354ceb6cfff4ad460f2a35427697293dda616c" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.</source>
          <target state="translated">Максимальное количество итераций для сопряженного градиентного решателя.Значение по умолчанию определяется с помощью scipy.sparse.linalg.</target>
        </trans-unit>
        <trans-unit id="1e7dfd80e629f3bb34ea64892d98c69b612b79e1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for random sample selection.</source>
          <target state="translated">Максимальное количество итераций для случайной выборки.</target>
        </trans-unit>
        <trans-unit id="ecd130d87b8a2f3d02f709f684a50be372cae2c9" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the arpack solver. not used if eigen_solver == &amp;lsquo;dense&amp;rsquo;.</source>
          <target state="translated">Максимальное количество итераций для решателя arpack. не используется, если eigen_solver == 'density'.</target>
        </trans-unit>
        <trans-unit id="9de38c6ff2395ad8506cb6d44f0cafffcf62c788" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the calculation of spatial median.</source>
          <target state="translated">Максимальное количество итераций для расчета пространственной медианы.</target>
        </trans-unit>
        <trans-unit id="07f904d8faecfe25c803428c8e7a88d0070e3e3e" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the optimization. Should be at least 250.</source>
          <target state="translated">Максимальное количество итераций для оптимизации.Должно быть не менее 250.</target>
        </trans-unit>
        <trans-unit id="dce17045503a4e7dfc48c40d90d1aeae843b7e1f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the solver.</source>
          <target state="translated">Максимальное количество итераций для решателя.</target>
        </trans-unit>
        <trans-unit id="e1c1739cc631f47e83bf7484461b685fd99cca3d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the SMACOF algorithm for a single run.</source>
          <target state="translated">Максимальное количество итераций алгоритма SMACOF за один прогон.</target>
        </trans-unit>
        <trans-unit id="7f1e71a3c23990192b71291657a3bae2f490d4ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm for a single run.</source>
          <target state="translated">Максимальное количество итераций алгоритма k-среднего за один прогон.</target>
        </trans-unit>
        <trans-unit id="f0e6e9653318c3bc8385e39576298e438fdcd759" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm to run.</source>
          <target state="translated">Максимальное количество итераций алгоритма k-средних для запуска.</target>
        </trans-unit>
        <trans-unit id="368dd40a437636dbd3f559d65e7725494d2a9fb1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the optimization algorithm.</source>
          <target state="translated">Максимальное количество итераций алгоритма оптимизации.</target>
        </trans-unit>
        <trans-unit id="63c06831f070b2a52428ee45e49cb4b88ea5a09d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.</source>
          <target state="translated">Максимальное количество итераций по всему набору данных до остановки независимо от любой эвристики раннего критерия остановки.</target>
        </trans-unit>
        <trans-unit id="7899fd5b3a78738f0401cfc3b35e8ce4d2309778" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that can be skipped due to finding zero inliers or invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt; or invalid models defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">Максимальное количество итераций, которые можно пропустить из-за обнаружения нулевых меток или недопустимых данных, определенных &lt;code&gt;is_data_valid&lt;/code&gt; , или недопустимых моделей, определенных &lt;code&gt;is_model_valid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7fba252520d1990cf2d4eb5716def2f32bbae99" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that scipy.optimize.fmin_l_bfgs_b should run for.</source>
          <target state="translated">Максимальное количество итераций,которое должен выполнить scipy.optim.fmin_l_bfgs_b.</target>
        </trans-unit>
        <trans-unit id="4e1098501827a192b62ebb4f1cab51c2d422cf00" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Максимальное количество итераций для выполнения, если &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aa990833ac4f020e2d41da9d6169624866ecf0ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform in the Lars algorithm.</source>
          <target state="translated">Максимальное количество итераций для выполнения в алгоритме Ларса.</target>
        </trans-unit>
        <trans-unit id="d0f4ce7794b613699161c8c6e0e45882e1e59e63" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform, set to infinity for no limit.</source>
          <target state="translated">Максимальное количество выполняемых итераций,установлено на бесконечность без ограничения.</target>
        </trans-unit>
        <trans-unit id="6484f135db2cde17daa0042bcd9839216d734460" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="db2ca83257c5e157920232d66349b60febf20184" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform. Can be used for early stopping.</source>
          <target state="translated">Максимальное количество итераций.Может использоваться для ранней остановки.</target>
        </trans-unit>
        <trans-unit id="3ae0883a212da2486dca35b829a405dbbd2b8c29" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations without progress before we abort the optimization, used after 250 initial iterations with early exaggeration. Note that progress is only checked every 50 iterations so this value is rounded to the next multiple of 50.</source>
          <target state="translated">Максимальное количество итераций без прогресса перед прерыванием оптимизации,используемое после 250 начальных итераций с ранним преувеличением.Обратите внимание,что прогресс проверяется только каждые 50 итераций,поэтому это значение округляется до следующего кратного числа 50.</target>
        </trans-unit>
        <trans-unit id="5919ba2c46521b64537304f167c62803da4391df" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations, per seed point before the clustering operation terminates (for that seed point), if has not converged yet.</source>
          <target state="translated">Максимальное количество итераций на точку посадки до окончания кластеризации (для этой точки посадки),если она еще не сошла воедино.</target>
        </trans-unit>
        <trans-unit id="3fcea6ff6580050eb63d7142d23e7d7896de7626" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="2bd71b5c83b9f5da0d4a94baa31a035271906ce7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300</source>
          <target state="translated">Максимальное количество итераций.По умолчанию 300</target>
        </trans-unit>
        <trans-unit id="6740f9eed55c5399b0f5fe47513d42802b2d72aa" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300.</source>
          <target state="translated">Максимальное количество итераций.По умолчанию 300.</target>
        </trans-unit>
        <trans-unit id="1d3427b734648d0ef9c00f4282011f095b732bba" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;) or this number of iterations. For stochastic solvers (&amp;lsquo;sgd&amp;rsquo;, &amp;lsquo;adam&amp;rsquo;), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.</source>
          <target state="translated">Максимальное количество итераций. Решающая программа выполняет итерацию до сходимости (определяемой параметром &amp;laquo;tol&amp;raquo;) или до этого количества итераций. Для стохастических решателей ('sgd', 'adam') обратите внимание, что это определяет количество эпох (сколько раз будет использоваться каждая точка данных), а не количество шагов градиента.</target>
        </trans-unit>
        <trans-unit id="647156dc0e4267e82660e321d855d0ab57ee6ce8" translate="yes" xml:space="preserve">
          <source>Maximum number of samples used to estimate the quantiles for computational efficiency. Note that the subsampling procedure may differ for value-identical sparse and dense matrices.</source>
          <target state="translated">Максимальное количество выборок,используемых для оценки квантилей для вычислительной эффективности.Обратите внимание,что процедура субсэмплинга может отличаться для среднеквадратичных разреженных и плотных матриц.</target>
        </trans-unit>
        <trans-unit id="415a2ec1c451656db8760ffe077b89b191d3a2b3" translate="yes" xml:space="preserve">
          <source>Maximum numbers of iterations to perform, therefore maximum features to include. 10% of &lt;code&gt;n_features&lt;/code&gt; but at least 5 if available.</source>
          <target state="translated">Максимальное количество выполняемых итераций, следовательно, максимальное количество функций, которые необходимо включить. 10% &lt;code&gt;n_features&lt;/code&gt; , но не менее 5, если доступно.</target>
        </trans-unit>
        <trans-unit id="631012abffd401f8346d1251260aa1bdd321bf8a" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt; or the number of nodes in the path with &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; , либо количество узлов в пути с &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="705f01a5b973480d43f7edb8b4f1d8b46afffacc" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt;, or the number of nodes in the path with correlation greater than &lt;code&gt;alpha&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; , либо количество узлов в пути с корреляцией больше &lt;code&gt;alpha&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="62989d4a3b259ca439d6192faa2834aa0e75a2e0" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;n_nonzero_coefs&lt;/code&gt; or &lt;code&gt;n_features&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;n_nonzero_coefs&lt;/code&gt; , либо &lt;code&gt;n_features&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="e56eb85aade57d415023e1a3a8ae03f5b942a0cd" translate="yes" xml:space="preserve">
          <source>Maximum residual for a data sample to be classified as an inlier. By default the threshold is chosen as the MAD (median absolute deviation) of the target values &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Максимальный остаток для выборки данных, которая должна быть классифицирована как вставка. По умолчанию порог выбирается как MAD (среднее абсолютное отклонение) целевых значений &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6dd6334c9c1bb29cde2ace0d7ca9c039e7de14bd" translate="yes" xml:space="preserve">
          <source>Maximum size for a single training set.</source>
          <target state="translated">Максимальный размер для одного тренировочного комплекта.</target>
        </trans-unit>
        <trans-unit id="3feffec2bfb871f0142dbd2d75d410b437245309" translate="yes" xml:space="preserve">
          <source>Maximum squared sum of X over samples. Used only in SAG solver. If None, it will be computed, going through all the samples. The value should be precomputed to speed up cross validation.</source>
          <target state="translated">Максимальная квадратная сумма Х по образцам.Используется только в SAG solver.Если None,он будет вычислен,проходя через все сэмплы.Значение должно быть предварительно вычислено,чтобы ускорить перекрестную проверку.</target>
        </trans-unit>
        <trans-unit id="229948f9503f6467f2a53d61f4254093e7ca3738" translate="yes" xml:space="preserve">
          <source>Maximum step size (regularization). Defaults to 1.0.</source>
          <target state="translated">Максимальный размер шага (регуляризация).По умолчанию 1.0.</target>
        </trans-unit>
        <trans-unit id="843c61e3ff0f74449c911dbb02faa43821e29850" translate="yes" xml:space="preserve">
          <source>Maximum value of a bicluster.</source>
          <target state="translated">Максимальное значение билюстра.</target>
        </trans-unit>
        <trans-unit id="ce9a39e13a20e687ebff9fcf4496175bdfa0afbb" translate="yes" xml:space="preserve">
          <source>Maximum value of input array &lt;code&gt;X_&lt;/code&gt; for right bound.</source>
          <target state="translated">Максимальное значение входного массива &lt;code&gt;X_&lt;/code&gt; для правой границы.</target>
        </trans-unit>
        <trans-unit id="9fa80bb15d05b082522b43fcb83b05beb6f022c6" translate="yes" xml:space="preserve">
          <source>May be the string &amp;ldquo;jaccard&amp;rdquo; to use the Jaccard coefficient, or any function that takes four arguments, each of which is a 1d indicator vector: (a_rows, a_columns, b_rows, b_columns).</source>
          <target state="translated">Это может быть строка &amp;laquo;jaccard&amp;raquo; для использования коэффициента Жаккара или любая функция, которая принимает четыре аргумента, каждый из которых является 1d вектором индикатора: (a_rows, a_columns, b_rows, b_columns).</target>
        </trans-unit>
        <trans-unit id="4fad1e9d11d435bd5f0db307b217272d94f19197" translate="yes" xml:space="preserve">
          <source>May contain any subset of (&amp;lsquo;headers&amp;rsquo;, &amp;lsquo;footers&amp;rsquo;, &amp;lsquo;quotes&amp;rsquo;). Each of these are kinds of text that will be detected and removed from the newsgroup posts, preventing classifiers from overfitting on metadata.</source>
          <target state="translated">Может содержать любое подмножество (&amp;laquo;заголовки&amp;raquo;, &amp;laquo;нижние колонтитулы&amp;raquo;, &amp;laquo;кавычки&amp;raquo;). Каждый из этих типов текста будет обнаруживаться и удаляться из сообщений группы новостей, предотвращая переоснащение классификаторами метаданных.</target>
        </trans-unit>
        <trans-unit id="4f0935dfe9ab3f30e90c245d2338ed727682177f" translate="yes" xml:space="preserve">
          <source>Mean Absolute Error:</source>
          <target state="translated">Средняя Абсолютная Ошибка:</target>
        </trans-unit>
        <trans-unit id="007ffde203dd83c4c710b22da1cbe0b3700a98d1" translate="yes" xml:space="preserve">
          <source>Mean Silhouette Coefficient for all samples.</source>
          <target state="translated">Коэффициент среднего силуэта для всех образцов.</target>
        </trans-unit>
        <trans-unit id="2762f10f75116f5e4a70c10eb14cf5f478eb498f" translate="yes" xml:space="preserve">
          <source>Mean Squared Error:</source>
          <target state="translated">Средняя квадратичная ошибка:</target>
        </trans-unit>
        <trans-unit id="43559adecf21dbddbbe17afba52b16b4a67e4402" translate="yes" xml:space="preserve">
          <source>Mean absolute error regression loss</source>
          <target state="translated">Средняя потеря регрессии абсолютной погрешности</target>
        </trans-unit>
        <trans-unit id="ec9517dd8574c2a6b45d6a307e2a503f5e6d275d" translate="yes" xml:space="preserve">
          <source>Mean accuracy of self.predict(X) wrt. y.</source>
          <target state="translated">Средняя точность самопредсказания(X)не...y.</target>
        </trans-unit>
        <trans-unit id="7493a61b1729d0e0247689ac97555930f03706df" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator</source>
          <target state="translated">Средний перекрёстный балл best_estimator</target>
        </trans-unit>
        <trans-unit id="140100875ffefa42eddb6a75afe4c55e05443030" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator.</source>
          <target state="translated">Средний перекрестный балл best_estimator.</target>
        </trans-unit>
        <trans-unit id="dd2a669704ec2ab03a0e4ca8e2abc9c2d42f71c6" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution a query points</source>
          <target state="translated">Среднее предсказывающее распределение точек запроса</target>
        </trans-unit>
        <trans-unit id="b609d0f7d96a7b9c8e60baf85298ffc173cbc6f7" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution of query points.</source>
          <target state="translated">Среднее предсказывающее распределение точек запроса.</target>
        </trans-unit>
        <trans-unit id="e7f5a133eabd3f3a470b8b7cb54eeb045b64973a" translate="yes" xml:space="preserve">
          <source>Mean or median or quantile of the training targets or constant value given by the user.</source>
          <target state="translated">Среднее или медианное или квантильное значение учебных целей или постоянное значение,заданное пользователем.</target>
        </trans-unit>
        <trans-unit id="9ede03e41402c8eec43dd01264f8f822af5fb92b" translate="yes" xml:space="preserve">
          <source>Mean shift clustering aims to discover &amp;ldquo;blobs&amp;rdquo; in a smooth density of samples. It is a centroid-based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids.</source>
          <target state="translated">Кластеризация среднего сдвига направлена ​​на обнаружение &amp;laquo;пятен&amp;raquo; в сглаженной плотности выборок. Это алгоритм на основе центроидов, который работает, обновляя кандидатов в центроиды, чтобы они были средними точками в данном регионе. Затем эти кандидаты фильтруются на этапе постобработки, чтобы исключить почти дубликаты и сформировать окончательный набор центроидов.</target>
        </trans-unit>
        <trans-unit id="08b2e6d37eec1f5ceae1376ffba9071609b6547f" translate="yes" xml:space="preserve">
          <source>Mean shift clustering using a flat kernel.</source>
          <target state="translated">Средняя кластеризация сдвига с помощью плоского ядра.</target>
        </trans-unit>
        <trans-unit id="4484f1a9abfaeee06549ff0a6b75712b44fd35f2" translate="yes" xml:space="preserve">
          <source>Mean square error for the test set on each fold, varying l1_ratio and alpha.</source>
          <target state="translated">Средняя квадратная погрешность для тестового набора на каждой сгибе,изменяющаяся в соотношении l1_ratio и alpha.</target>
        </trans-unit>
        <trans-unit id="4a0031a2d59450a58aeaa638a064cb2e2c9a0da5" translate="yes" xml:space="preserve">
          <source>Mean squared error regression loss</source>
          <target state="translated">Потеря регрессии средней квадратной ошибки</target>
        </trans-unit>
        <trans-unit id="831bfb250ab69b773c25fae60f230a00bfdc7239" translate="yes" xml:space="preserve">
          <source>Mean squared logarithmic error regression loss</source>
          <target state="translated">Средняя квадратичная логарифмическая ошибка потери регрессии</target>
        </trans-unit>
        <trans-unit id="2db7f6881ab1082c632822482db18fa9fc34ed90" translate="yes" xml:space="preserve">
          <source>Mean-shift</source>
          <target state="translated">Mean-shift</target>
        </trans-unit>
        <trans-unit id="df21241945c8fd60618f888d81f315be3f7af674" translate="yes" xml:space="preserve">
          <source>Measure the similarity of two clusterings of a set of points.</source>
          <target state="translated">Измерьте схожесть двух скоплений набора точек.</target>
        </trans-unit>
        <trans-unit id="e49da6a85d81735a7b28ef79fc256dec989d2443" translate="yes" xml:space="preserve">
          <source>Measurement errors in X</source>
          <target state="translated">Погрешности измерения в Х</target>
        </trans-unit>
        <trans-unit id="471fba4dfe2d4f61d0ae5efc77acb722551abb7b" translate="yes" xml:space="preserve">
          <source>Measurement errors in y</source>
          <target state="translated">Погрешности измерения в y</target>
        </trans-unit>
        <trans-unit id="d59aa4a9911bb1573c0ba0a2779ea96a4989f27f" translate="yes" xml:space="preserve">
          <source>MedInc median income in block</source>
          <target state="translated">MedInc средний доход в блоке</target>
        </trans-unit>
        <trans-unit id="bb82014fc42479d50d7886c5d05c20bd8db97f56" translate="yes" xml:space="preserve">
          <source>Median absolute error regression loss</source>
          <target state="translated">Медианная потеря абсолютной погрешности регрессии</target>
        </trans-unit>
        <trans-unit id="9e7082d8eb8f2409deaa71605e5d6dbf5b190217" translate="yes" xml:space="preserve">
          <source>Medium &lt;code&gt;n_samples&lt;/code&gt;, small &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Средних &lt;code&gt;n_samples&lt;/code&gt; , маленьких &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="da13fe6da16d1b0d3601ee1416010215c9da2b3d" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;coef_&lt;/code&gt; holds the weights \(w\)</source>
          <target state="translated">Член &lt;code&gt;coef_&lt;/code&gt; содержит веса \ (w \)</target>
        </trans-unit>
        <trans-unit id="b26ca7073281a8f4da3f64aafb4932ce0dc723cc" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds \(b\)</source>
          <target state="translated">Элемент &lt;code&gt;intercept_&lt;/code&gt; содержит \ (b \)</target>
        </trans-unit>
        <trans-unit id="8e7e4ea63f467ef992e1b5515c3662fd092327fd" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds the intercept (aka offset or bias):</source>
          <target state="translated">Член &lt;code&gt;intercept_&lt;/code&gt; содержит перехват (также известный как смещение или смещение):</target>
        </trans-unit>
        <trans-unit id="b6ef7f0fdf735583a61dbfc359227479e43bf842" translate="yes" xml:space="preserve">
          <source>Memmapping mode for numpy arrays passed to workers. See &amp;lsquo;max_nbytes&amp;rsquo; parameter documentation for more details.</source>
          <target state="translated">Режим Memmapping для массивов numpy передан рабочим. См. Дополнительную информацию в документации по параметру max_nbytes.</target>
        </trans-unit>
        <trans-unit id="424b610ebd2af23e4bb8a29dcabbc0551e9c3d87" translate="yes" xml:space="preserve">
          <source>Memory consumption for large sample sizes</source>
          <target state="translated">Расход памяти для больших размеров образцов</target>
        </trans-unit>
        <trans-unit id="5418f36b831a9c825f5d841c5ee3b1bdb2dd3e28" translate="yes" xml:space="preserve">
          <source>Meta-estimator to regress on a transformed target.</source>
          <target state="translated">Мета-стимулятор для регресса по преобразованной цели.</target>
        </trans-unit>
        <trans-unit id="79599678d3d5e2500fd2a7f727461a2dac0b6cd4" translate="yes" xml:space="preserve">
          <source>Meta-estimators for building composite models with transformers</source>
          <target state="translated">Мета-оценщики для построения композитных моделей с трансформаторами</target>
        </trans-unit>
        <trans-unit id="d5a7b3579e10eeaa00ced1884380b174708caebd" translate="yes" xml:space="preserve">
          <source>Meta-transformer for selecting features based on importance weights.</source>
          <target state="translated">Мета-трансформатор для выбора функций на основе весов важности.</target>
        </trans-unit>
        <trans-unit id="88306943fea7e76f9cd57cae0ea6d8b32d2e8434" translate="yes" xml:space="preserve">
          <source>Method</source>
          <target state="translated">Method</target>
        </trans-unit>
        <trans-unit id="3dad9226be4bd937f8a455ee0badad4ee6cceff1" translate="yes" xml:space="preserve">
          <source>Method for initialization of k-means algorithm; defaults to &amp;lsquo;k-means++&amp;rsquo;.</source>
          <target state="translated">Метод инициализации алгоритма k-средних; по умолчанию &quot;k-means ++&quot;.</target>
        </trans-unit>
        <trans-unit id="2c3f3dc3ba37d9b2f1af18176cea15628b89a09c" translate="yes" xml:space="preserve">
          <source>Method for initialization, default to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">Метод инициализации, по умолчанию k-means ++:</target>
        </trans-unit>
        <trans-unit id="62b8a3dc56fc8229948d624cc5b38920d22e2365" translate="yes" xml:space="preserve">
          <source>Method for initialization, defaults to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">Метод инициализации, по умолчанию k-means ++:</target>
        </trans-unit>
        <trans-unit id="3b1389e0e832a05337d6ccb31e50ea1425ca91a8" translate="yes" xml:space="preserve">
          <source>Method name</source>
          <target state="translated">Название метода</target>
        </trans-unit>
        <trans-unit id="b78ea13fd7ce3e01d82dac91ffffedca9d6a516f" translate="yes" xml:space="preserve">
          <source>Method of normalizing and converting singular vectors into biclusters. May be one of &amp;lsquo;scale&amp;rsquo;, &amp;lsquo;bistochastic&amp;rsquo;, or &amp;lsquo;log&amp;rsquo;. The authors recommend using &amp;lsquo;log&amp;rsquo;. If the data is sparse, however, log normalization will not work, which is why the default is &amp;lsquo;bistochastic&amp;rsquo;. CAUTION: if &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt;, the data must not be sparse.</source>
          <target state="translated">Метод нормализации и преобразования сингулярных векторов в бикластеры. Может быть &amp;laquo;масштаб&amp;raquo;, &amp;laquo;бистохастический&amp;raquo; или &amp;laquo;журнал&amp;raquo;. Авторы рекомендуют использовать log. Однако, если данные немногочисленны, нормализация журнала не будет работать, поэтому значение по умолчанию - &amp;laquo;бистохастический&amp;raquo;. ВНИМАНИЕ: если &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt; , данные не должны быть разреженными.</target>
        </trans-unit>
        <trans-unit id="7e7b59d1db0b41f1f7de6a768474fa98a959edfd" translate="yes" xml:space="preserve">
          <source>Method to use in finding shortest path.</source>
          <target state="translated">Метод поиска кратчайшего пути.</target>
        </trans-unit>
        <trans-unit id="46674c498c855af96974ed544b15ae6396d6f74f" translate="yes" xml:space="preserve">
          <source>Method used to encode the transformed result.</source>
          <target state="translated">Метод,используемый для кодирования преобразованного результата.</target>
        </trans-unit>
        <trans-unit id="155758829048f282b684f453070e5e32e8a3b098" translate="yes" xml:space="preserve">
          <source>Method used to initialize the procedure. Default: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise random. Valid options:</source>
          <target state="translated">Метод, используемый для инициализации процедуры. По умолчанию: 'nndsvd', если n_components &amp;lt;n_features, в противном случае - случайный. Допустимые варианты:</target>
        </trans-unit>
        <trans-unit id="2c32a8fabfe7118c5a18a023b129a09f5774d869" translate="yes" xml:space="preserve">
          <source>Method used to update &lt;code&gt;_component&lt;/code&gt;. Only used in &lt;code&gt;fit&lt;/code&gt; method. In general, if the data size is large, the online update will be much faster than the batch update.</source>
          <target state="translated">Метод, используемый для обновления &lt;code&gt;_component&lt;/code&gt; . Используется только в &lt;code&gt;fit&lt;/code&gt; методе. В целом, если размер данных большой, онлайн-обновление будет намного быстрее, чем пакетное обновление.</target>
        </trans-unit>
        <trans-unit id="7e4ac6803c9159c694f63d089cb06b2519c16aba" translate="yes" xml:space="preserve">
          <source>Methods</source>
          <target state="translated">Methods</target>
        </trans-unit>
        <trans-unit id="ef01ecfb88c8d650a45a85cec9ebc18d89f4ecbc" translate="yes" xml:space="preserve">
          <source>Metric used to compute the linkage. Can be &amp;ldquo;euclidean&amp;rdquo;, &amp;ldquo;l1&amp;rdquo;, &amp;ldquo;l2&amp;rdquo;, &amp;ldquo;manhattan&amp;rdquo;, &amp;ldquo;cosine&amp;rdquo;, or &amp;lsquo;precomputed&amp;rsquo;. If linkage is &amp;ldquo;ward&amp;rdquo;, only &amp;ldquo;euclidean&amp;rdquo; is accepted.</source>
          <target state="translated">Метрика, используемая для вычисления связи. Может быть &amp;laquo;евклидовым&amp;raquo;, &amp;laquo;l1&amp;raquo;, &amp;laquo;l2&amp;raquo;, &amp;laquo;манхэттенским&amp;raquo;, &amp;laquo;косинусным&amp;raquo; или &amp;laquo;предварительно вычисленным&amp;raquo;. Если связь &amp;laquo;подопечная&amp;raquo;, принимается только &amp;laquo;евклидова&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="b996dbf9b464efe667f55d3c7b947b9e2ffb345f" translate="yes" xml:space="preserve">
          <source>Metrics available for various machine learning tasks are detailed in sections below.</source>
          <target state="translated">Метрики,доступные для различных задач машинного обучения,подробно описаны в разделах ниже.</target>
        </trans-unit>
        <trans-unit id="276b36ad13c4507935dcfa6095085df1bf048be3" translate="yes" xml:space="preserve">
          <source>Michael E. Tipping: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;Sparse Bayesian Learning and the Relevance Vector Machine&lt;/a&gt;</source>
          <target state="translated">Майкл Е. Типпинг: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;разреженное байесовское обучение и вектор релевантности&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ee22c86ee428b82d33b13bdebced2deed71d63a1" translate="yes" xml:space="preserve">
          <source>Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</source>
          <target state="translated">Майкл Маршалл (MARSHALL%PLU@io.arc.nasa.gov)</target>
        </trans-unit>
        <trans-unit id="f33a348553a7d85d27424bb525b1eca4fb8a5155" translate="yes" xml:space="preserve">
          <source>MinMaxScaler</source>
          <target state="translated">MinMaxScaler</target>
        </trans-unit>
        <trans-unit id="6fad9f3e5fbaefddf87807ab8e89f2398827a6e0" translate="yes" xml:space="preserve">
          <source>Mini-Batch K-Means clustering</source>
          <target state="translated">Мини-группа К-Минов кластеризация</target>
        </trans-unit>
        <trans-unit id="8a7343b748199980306d06faf24494c5fb233c16" translate="yes" xml:space="preserve">
          <source>Mini-batch Sparse Principal Components Analysis</source>
          <target state="translated">Миниатюрный анализ по разделению основных компонентов</target>
        </trans-unit>
        <trans-unit id="4a04231399e807603297c55fa730ae6cac785e8b" translate="yes" xml:space="preserve">
          <source>Mini-batch dictionary learning</source>
          <target state="translated">Обучение мини-словарям</target>
        </trans-unit>
        <trans-unit id="b36d4bb746673223e9f3eddf90497433b367472a" translate="yes" xml:space="preserve">
          <source>Mini-batch sparse PCA (&lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt;) is a variant of &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt;&lt;code&gt;SparsePCA&lt;/code&gt;&lt;/a&gt; that is faster but less accurate. The increased speed is reached by iterating over small chunks of the set of features, for a given number of iterations.</source>
          <target state="translated">Мини-пакетный разреженный PCA ( &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; ) - это вариант &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt; &lt;code&gt;SparsePCA&lt;/code&gt; ,&lt;/a&gt; который работает быстрее, но менее точен. Повышенная скорость достигается путем повторения небольших фрагментов набора функций в течение заданного количества итераций.</target>
        </trans-unit>
        <trans-unit id="338b69eb058f4b8de205ae0e6a0b364261aebe7e" translate="yes" xml:space="preserve">
          <source>Minimizes the objective function:</source>
          <target state="translated">Минимизирует объективную функцию:</target>
        </trans-unit>
        <trans-unit id="84c971787220fb3e13d325cba22644ed7cfc6396" translate="yes" xml:space="preserve">
          <source>Minimizing Finite Sums with the Stochastic Average Gradient &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</source>
          <target state="translated">Минимизация конечных сумм с помощью среднего стохастического градиента &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="40d428add0b0bb2b15690324c7a65b1e95d21444" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant (MCD): robust estimator of covariance.</source>
          <target state="translated">Детерминант минимальной ковариативности (MCD):робастный оценщик ковариаций.</target>
        </trans-unit>
        <trans-unit id="f0d923ebaec99475dba3ff68622a8b582426df2b" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant Estimator</source>
          <target state="translated">Минимальный ковариационный детерминантный оценщик</target>
        </trans-unit>
        <trans-unit id="acdf76216ef7494ca3a405d1a4760970f1dcb045" translate="yes" xml:space="preserve">
          <source>Minimum correlation along the path. It corresponds to the regularization parameter alpha parameter in the Lasso.</source>
          <target state="translated">Минимальная корреляция по пути.Соответствует параметру регуляризации альфа-параметра в Лассо.</target>
        </trans-unit>
        <trans-unit id="45261c0e2275ffe7c782578b7e04c16d232cec64" translate="yes" xml:space="preserve">
          <source>Minimum number of candidates evaluated per estimator, assuming enough items meet the &lt;code&gt;min_hash_match&lt;/code&gt; constraint.</source>
          <target state="translated">Минимальное количество кандидатов, оцениваемых &lt;code&gt;min_hash_match&lt;/code&gt; оценщиком, при условии, что достаточное количество элементов соответствует ограничению min_hash_match .</target>
        </trans-unit>
        <trans-unit id="1f6032c543b0bedd4ef1a29303943c7332e81e08" translate="yes" xml:space="preserve">
          <source>Minimum number of samples chosen randomly from original data. Treated as an absolute number of samples for &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt;, treated as a relative number &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt;) for &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt;. This is typically chosen as the minimal number of samples necessary to estimate the given &lt;code&gt;base_estimator&lt;/code&gt;. By default a &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; estimator is assumed and &lt;code&gt;min_samples&lt;/code&gt; is chosen as &lt;code&gt;X.shape[1] + 1&lt;/code&gt;.</source>
          <target state="translated">Минимальное количество выборок, выбранных случайным образом из исходных данных. Рассматривается как абсолютное количество выборок для &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt; , обрабатывается как относительное число &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt; ) для &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt; . Обычно это выбирается как минимальное количество выборок, необходимое для оценки данного &lt;code&gt;base_estimator&lt;/code&gt; . По умолчанию предполагается &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; а &lt;code&gt;min_samples&lt;/code&gt; выбирается как &lt;code&gt;X.shape[1] + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3a6bb55043794a0a93e8ff0524f08e79cbc35225" translate="yes" xml:space="preserve">
          <source>Minimum value of a bicluster.</source>
          <target state="translated">Минимальное значение билюстра.</target>
        </trans-unit>
        <trans-unit id="59e81ca4cbc76e95e029c93b9fa76bb8c2828a22" translate="yes" xml:space="preserve">
          <source>Minimum value of input array &lt;code&gt;X_&lt;/code&gt; for left bound.</source>
          <target state="translated">Минимальное значение входного массива &lt;code&gt;X_&lt;/code&gt; для левой границы.</target>
        </trans-unit>
        <trans-unit id="2b5d457149fe5be167ed99387c99dd4725835fe8" translate="yes" xml:space="preserve">
          <source>MinkowskiDistance</source>
          <target state="translated">MinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="f3547bc4550b1de5a83615a3b3bc38cc23770ce0" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;class_log_prior_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Зеркала &lt;code&gt;class_log_prior_&lt;/code&gt; для интерпретации MultinomialNB как линейной модели.</target>
        </trans-unit>
        <trans-unit id="7814bd45bfd54f380e5f0cd3f0461e627752ef7b" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;feature_log_prob_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Зеркала &lt;code&gt;feature_log_prob_&lt;/code&gt; для интерпретации MultinomialNB как линейной модели.</target>
        </trans-unit>
        <trans-unit id="e446df504bb1a7ba9afc2f86aa7e483abdbc1937" translate="yes" xml:space="preserve">
          <source>Missing Attribute Values:</source>
          <target state="translated">Пропущенные значения атрибутов:</target>
        </trans-unit>
        <trans-unit id="391b82fea55e1ed8699fe6e91400e8d6055ab0df" translate="yes" xml:space="preserve">
          <source>Missing values can be replaced by the mean, the median or the most frequent value using the basic &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt;. The median is a more robust estimator for data with high magnitude variables which could dominate results (otherwise known as a &amp;lsquo;long tail&amp;rsquo;).</source>
          <target state="translated">Пропущенные значения могут быть заменены средним, медианным или наиболее частым значением с помощью базового &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt; &lt;/a&gt; . Медиана является более надежной оценкой для данных с переменными высокой величины, которые могут доминировать в результатах (также известная как &amp;laquo;длинный хвост&amp;raquo;).</target>
        </trans-unit>
        <trans-unit id="7657a2d6545adb4955b10f53c4131bc5602e90eb" translate="yes" xml:space="preserve">
          <source>Missing values in the &amp;lsquo;data&amp;rsquo; are represented as NaN&amp;rsquo;s. Missing values in &amp;lsquo;target&amp;rsquo; are represented as NaN&amp;rsquo;s (numerical target) or None (categorical target)</source>
          <target state="translated">Отсутствующие значения в &amp;laquo;данных&amp;raquo; представлены как NaN. Отсутствующие значения в 'target' представлены как NaN (числовая цель) или None (категориальная цель)</target>
        </trans-unit>
        <trans-unit id="6a6932c856f91eed3dd44780fa6b9fe69490c4b8" translate="yes" xml:space="preserve">
          <source>Mixin class for all bicluster estimators in scikit-learn</source>
          <target state="translated">Класс микшина для всех оценщиков библлюстра в наушниках.</target>
        </trans-unit>
        <trans-unit id="2c10e3ce37d297d342507e753914a98859330d14" translate="yes" xml:space="preserve">
          <source>Mixin class for all classifiers in scikit-learn.</source>
          <target state="translated">Класс микшина для всех классификаторов в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="5fa39e3354bc95759f1ac752182b15d93d7771cd" translate="yes" xml:space="preserve">
          <source>Mixin class for all cluster estimators in scikit-learn.</source>
          <target state="translated">Класс микшина для всех кластерных оценок в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="eb8addc65b16d7fa21479da43bfb0ac745b8fd54" translate="yes" xml:space="preserve">
          <source>Mixin class for all density estimators in scikit-learn.</source>
          <target state="translated">Класс смешивания для всех оценщиков плотности в наукографе.</target>
        </trans-unit>
        <trans-unit id="6ac045bb154d5d0dbd1cc9d29eba911e1ea2781a" translate="yes" xml:space="preserve">
          <source>Mixin class for all regression estimators in scikit-learn.</source>
          <target state="translated">Класс Mixin для всех регрессионных оценок в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="f73bd7177b7212616f9ae4cd764e784bac6a7ce1" translate="yes" xml:space="preserve">
          <source>Mixin class for all transformers in scikit-learn.</source>
          <target state="translated">Класс микшина для всех трансформаторов в наукоемких исследованиях.</target>
        </trans-unit>
        <trans-unit id="4d9a44acff48ccb4a2b026d4835ebe86a95495fc" translate="yes" xml:space="preserve">
          <source>Model Complexity Influence</source>
          <target state="translated">Влияние сложности модели</target>
        </trans-unit>
        <trans-unit id="7d5e06ce8e5a0fb1e8e99aee47dbf3426de865fe" translate="yes" xml:space="preserve">
          <source>Model Selection Interface</source>
          <target state="translated">Интерфейс выбора модели</target>
        </trans-unit>
        <trans-unit id="d9b7f2bb0f8fc0d29940e1aefd1565fcc5b449f7" translate="yes" xml:space="preserve">
          <source>Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods.</source>
          <target state="translated">Смешивание моделей:когда предсказания одного контролируемого оценщика используются для обучения другого оценщика ансамблевым методам.</target>
        </trans-unit>
        <trans-unit id="c3b027b1bc55171725d0853107d2cd63b70cf1b0" translate="yes" xml:space="preserve">
          <source>Model complexity</source>
          <target state="translated">Сложность модели</target>
        </trans-unit>
        <trans-unit id="088cfdc97cd06f5c2647d7bc4d07170997a1804d" translate="yes" xml:space="preserve">
          <source>Model compression in scikit-learn only concerns linear models for the moment. In this context it means that we want to control the model sparsity (i.e. the number of non-zero coordinates in the model vectors). It is generally a good idea to combine model sparsity with sparse input data representation.</source>
          <target state="translated">Сжатие модели в Scikit-learn на данный момент относится только к линейным моделям.В этом контексте это означает,что мы хотим контролировать спектральность модели (т.е.количество ненулевых координат в векторах модели).Обычно хорошей идеей является сочетание ломкости модели с разреженным представлением входных данных.</target>
        </trans-unit>
        <trans-unit id="12cb4d758358636a28aab0195639a05c4c6adf09" translate="yes" xml:space="preserve">
          <source>Model persistence</source>
          <target state="translated">Сохранность модели</target>
        </trans-unit>
        <trans-unit id="c38101ec23202ddb2bcf9ed4925ad6d1c9181511" translate="yes" xml:space="preserve">
          <source>Model reshaping consists in selecting only a portion of the available features to fit a model. In other words, if a model discards features during the learning phase we can then strip those from the input. This has several benefits. Firstly it reduces memory (and therefore time) overhead of the model itself. It also allows to discard explicit feature selection components in a pipeline once we know which features to keep from a previous run. Finally, it can help reduce processing time and I/O usage upstream in the data access and feature extraction layers by not collecting and building features that are discarded by the model. For instance if the raw data come from a database, it can make it possible to write simpler and faster queries or reduce I/O usage by making the queries return lighter records. At the moment, reshaping needs to be performed manually in scikit-learn. In the case of sparse input (particularly in &lt;code&gt;CSR&lt;/code&gt; format), it is generally sufficient to not generate the relevant features, leaving their columns empty.</source>
          <target state="translated">Изменение формы модели заключается в выборе только части доступных функций для соответствия модели. Другими словами, если модель отбрасывает функции на этапе обучения, мы можем удалить их из входных данных. Это дает несколько преимуществ. Во-первых, это уменьшает накладные расходы на память (и, следовательно, время) самой модели. Это также позволяет отказаться от компонентов явного выбора функций в конвейере, если мы знаем, какие функции следует сохранить из предыдущего запуска. Наконец, это может помочь сократить время обработки и использование ввода-вывода в восходящем направлении на уровнях доступа к данным и извлечения признаков, поскольку не собирает и не создает объекты, которые отбрасываются моделью. Например, если необработанные данные поступают из базы данных, это может дать возможность писать более простые и быстрые запросы или уменьшить использование ввода-вывода, заставляя запросы возвращать более легкие записи. В данный момент,изменение формы необходимо выполнять вручную в scikit-learn. В случае разреженного ввода (особенно в &lt;code&gt;CSR&lt;/code&gt; Формат CSR ), как правило, достаточно не генерировать соответствующие функции, оставив их столбцы пустыми.</target>
        </trans-unit>
        <trans-unit id="12aba00cd9b6d07b68e1c4795de07ac9d7b738d7" translate="yes" xml:space="preserve">
          <source>Model selection and evaluation using tools, such as &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;model_selection.cross_val_score&lt;/code&gt;&lt;/a&gt;, take a &lt;code&gt;scoring&lt;/code&gt; parameter that controls what metric they apply to the estimators evaluated.</source>
          <target state="translated">Выбор и оценка модели с использованием таких инструментов, как &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;model_selection.cross_val_score&lt;/code&gt; &lt;/a&gt; , принимают параметр &lt;code&gt;scoring&lt;/code&gt; который контролирует, какую метрику они применяют к оцениваемым оценщикам.</target>
        </trans-unit>
        <trans-unit id="855cd5c7a76f661266d80a6648a2f964caf6a19e" translate="yes" xml:space="preserve">
          <source>Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to &amp;ldquo;train&amp;rdquo; the parameters of the grid.</source>
          <target state="translated">Выбор модели путем оценки различных настроек параметров можно рассматривать как способ использования помеченных данных для &amp;laquo;обучения&amp;raquo; параметров сетки.</target>
        </trans-unit>
        <trans-unit id="89917070f2baaaaf3d7a4bc37b23fe9e19c05135" translate="yes" xml:space="preserve">
          <source>Model selection with Probabilistic PCA and Factor Analysis (FA)</source>
          <target state="translated">Выбор модели с вероятностным РСА и факторным анализом (ФА)</target>
        </trans-unit>
        <trans-unit id="9c731d5ab6adf4a98df3f1383f23cf8f7eed3338" translate="yes" xml:space="preserve">
          <source>Model selection without nested CV uses the same data to tune model parameters and evaluate model performance. Information may thus &amp;ldquo;leak&amp;rdquo; into the model and overfit the data. The magnitude of this effect is primarily dependent on the size of the dataset and the stability of the model. See Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; for an analysis of these issues.</source>
          <target state="translated">Выбор модели без вложенного CV использует те же данные для настройки параметров модели и оценки производительности модели. Таким образом, информация может &amp;laquo;просочиться&amp;raquo; в модель и не соответствовать данным. Величина этого эффекта в первую очередь зависит от размера набора данных и стабильности модели. См. Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; для анализа этих вопросов.</target>
        </trans-unit>
        <trans-unit id="74392d3518eac75d4c193fc75b5f4945cf9be3f9" translate="yes" xml:space="preserve">
          <source>Model selection: choosing estimators and their parameters</source>
          <target state="translated">Выбор модели:выбор оценщиков и их параметров</target>
        </trans-unit>
        <trans-unit id="ad79a801df8015a66d5501cf36f7ffcd2a41ddf8" translate="yes" xml:space="preserve">
          <source>Model validation</source>
          <target state="translated">Проверка модели</target>
        </trans-unit>
        <trans-unit id="04c7998384d3cc95ade6e27711f83c95af26806e" translate="yes" xml:space="preserve">
          <source>Modeling species&amp;rsquo; geographic distributions is an important problem in conservation biology. In this example we model the geographic distribution of two south american mammals given past observations and 14 environmental variables. Since we have only positive examples (there are no unsuccessful observations), we cast this problem as a density estimation problem and use the &lt;code&gt;OneClassSVM&lt;/code&gt; provided by the package &lt;code&gt;sklearn.svm&lt;/code&gt; as our modeling tool. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Моделирование географического распределения видов - важная проблема природоохранной биологии. В этом примере мы моделируем географическое распределение двух южноамериканских млекопитающих с учетом прошлых наблюдений и 14 переменных окружающей среды. Поскольку у нас есть только положительные примеры (нет неудачных наблюдений), мы рассматриваем эту проблему как проблему оценки плотности и используем &lt;code&gt;OneClassSVM&lt;/code&gt; , предоставляемый пакетом &lt;code&gt;sklearn.svm&lt;/code&gt; ,в качестве инструмента моделирования. Набор данных предоставлен Phillips et. al. (2006). Если возможно, в примере используется &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;базовая карта&lt;/a&gt; для построения береговых линий и национальных границ Южной Америки.</target>
        </trans-unit>
        <trans-unit id="41be465b762359b2fa053c297894959404d2b4b5" translate="yes" xml:space="preserve">
          <source>Module &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt;&lt;code&gt;sklearn.kernel_ridge&lt;/code&gt;&lt;/a&gt; implements kernel ridge regression.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt; &lt;code&gt;sklearn.kernel_ridge&lt;/code&gt; &lt;/a&gt; реализует регрессию гребня ядра.</target>
        </trans-unit>
        <trans-unit id="7c19bb73223842069c348f5ce2be56f6bdc47336" translate="yes" xml:space="preserve">
          <source>Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">Импульс для обновления градиентного спуска. Должно быть от 0 до 1. Используется только когда solver = 'sgd'.</target>
        </trans-unit>
        <trans-unit id="afdb29f8a2a5c8088f948d58228ab92ec4b8dbc8" translate="yes" xml:space="preserve">
          <source>Moosmann, F. and Triggs, B. and Jurie, F. &amp;ldquo;Fast discriminative visual codebooks using randomized clustering forests&amp;rdquo; NIPS 2007</source>
          <target state="translated">Моосманн, Ф., Триггс, Б. и Джури, Ф. &amp;laquo;Быстрые дискриминативные визуальные кодовые книги с использованием рандомизированных лесов кластеризации&amp;raquo; NIPS 2007</target>
        </trans-unit>
        <trans-unit id="ea951c164724999b1e82491617fa7550c41c4ea4" translate="yes" xml:space="preserve">
          <source>More details can be found in the article &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Bayesian Interpolation&lt;/a&gt; by MacKay, David J. C.</source>
          <target state="translated">Более подробную информацию можно найти в статье &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Байесовская интерполяция&lt;/a&gt; Маккея, Дэвида Дж. К.</target>
        </trans-unit>
        <trans-unit id="5be68ba5f49b8c23c2004cef7b8f1738816fd7ff" translate="yes" xml:space="preserve">
          <source>More details can be found in the documentation of &lt;a href=&quot;sgd&quot;&gt;SGD&lt;/a&gt;</source>
          <target state="translated">Более подробную информацию можно найти в документации &lt;a href=&quot;sgd&quot;&gt;SGD.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eeddded239db4ba79d40ed239189aa60eea25acb" translate="yes" xml:space="preserve">
          <source>More details on tools available for model selection can be found in the sections on &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; and &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">Более подробную информацию об инструментах, доступных для выбора модели, можно найти в разделах &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Перекрестная проверка: оценка производительности оценщика&lt;/a&gt; и &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Настройка гиперпараметров оценщика&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d431b615f9733586de025b4f9872bf1a8badc9bd" translate="yes" xml:space="preserve">
          <source>More formally, the responsibility of a sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Более формально,ответственность за образец \(k\)как за образец \(i\)возложена на него:</target>
        </trans-unit>
        <trans-unit id="e5fcb8eb05185b2ae6a7561ecfd54e7e78d1825d" translate="yes" xml:space="preserve">
          <source>More formally, we define a core sample as being a sample in the dataset such that there exist &lt;code&gt;min_samples&lt;/code&gt; other samples within a distance of &lt;code&gt;eps&lt;/code&gt;, which are defined as &lt;em&gt;neighbors&lt;/em&gt; of the core sample. This tells us that the core sample is in a dense area of the vector space. A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of &lt;em&gt;their&lt;/em&gt; neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.</source>
          <target state="translated">Более формально, мы определяем образец керна как образец в наборе данных, так что существуют &lt;code&gt;min_samples&lt;/code&gt; другие образцы на расстоянии &lt;code&gt;eps&lt;/code&gt; , которые определены как &lt;em&gt;соседи&lt;/em&gt; с образцом керна. Это говорит нам о том, что основной образец находится в плотной области векторного пространства. Кластер - это набор образцов керна, который может быть создан путем рекурсивного взятия образца керна, поиска всех его соседей, которые являются образцами керна, поиска всех &lt;em&gt;их&lt;/em&gt; соседей, которые являются образцами керна, и так далее. Кластер также имеет набор неосновных выборок, которые представляют собой выборки, которые являются соседями керновой выборки в кластере, но не являются сами по себе образцами керна. Интуитивно эти образцы находятся на периферии кластера.</target>
        </trans-unit>
        <trans-unit id="39d3fe53d51c5218d78f036015830e2502c27f2b" translate="yes" xml:space="preserve">
          <source>More generally, when the accuracy of a classifier is too close to random, it probably means that something went wrong: features are not helpful, a hyperparameter is not correctly tuned, the classifier is suffering from class imbalance, etc&amp;hellip;</source>
          <target state="translated">В более общем плане, когда точность классификатора слишком близка к случайной, это, вероятно, означает, что что-то пошло не так: функции бесполезны, гиперпараметр настроен неправильно, классификатор страдает от дисбаланса классов и т. Д.</target>
        </trans-unit>
        <trans-unit id="63b4a4241c78c35e803f9a1e6a808d1813f2fb30" translate="yes" xml:space="preserve">
          <source>More information can be found on the &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;Scipy install page&lt;/a&gt; and in this &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;blog post&lt;/a&gt; from Daniel Nouri which has some nice step by step install instructions for Debian / Ubuntu.</source>
          <target state="translated">Дополнительную информацию можно найти на &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;странице установки Scipy&lt;/a&gt; и в этом &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;сообщении&lt;/a&gt; в блоге Даниэля Нури, в котором есть несколько хороших пошаговых инструкций по установке для Debian / Ubuntu.</target>
        </trans-unit>
        <trans-unit id="5d4e98f0a8d8595ea60691c38a1427dece6499fb" translate="yes" xml:space="preserve">
          <source>More metadata from OpenML</source>
          <target state="translated">Больше метаданных из OpenML</target>
        </trans-unit>
        <trans-unit id="12db8232292ca8d1cf35bc6b9168f2c8b63d47ca" translate="yes" xml:space="preserve">
          <source>More precisely its the expectation of the target response after accounting for the initial model; partial dependence plots do not include the &lt;code&gt;init&lt;/code&gt; model.</source>
          <target state="translated">Точнее, это ожидание целевого отклика после учета исходной модели; графики частичных зависимостей не включают модель &lt;code&gt;init&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="73794f226fb348eb5da6ad63afeb16cb41727d95" translate="yes" xml:space="preserve">
          <source>More readable code, in particular since it avoids constructing list of arguments.</source>
          <target state="translated">Более читабельный код,в частности,поскольку он позволяет избежать построения списка аргументов.</target>
        </trans-unit>
        <trans-unit id="a22dda2285328f04695cb396d42b64909dfc0d90" translate="yes" xml:space="preserve">
          <source>More specifically, for linear and quadratic discriminant analysis, \(P(X|y)\) is modeled as a multivariate Gaussian distribution with density:</source>
          <target state="translated">Точнее,для линейного и квадратичного дискриминантного анализа \(P(X|y)\)смоделировано многомерное гауссово распределение с плотностью:</target>
        </trans-unit>
        <trans-unit id="79ecb6d9275fdfeccdbd69d6aa3919b92952032e" translate="yes" xml:space="preserve">
          <source>Most commonly, disparities are set to \(\hat{d}_{ij} = b S_{ij}\).</source>
          <target state="translated">Чаще всего диспропорции устанавливаются по адресу \(\hat{d}_{ij}=b S_{ij}\).</target>
        </trans-unit>
        <trans-unit id="13411f05832555677b503d8db5e64b4930c99086" translate="yes" xml:space="preserve">
          <source>Most of the variance can be explained by a bell-shaped curve of width effective_rank: the low rank part of the singular values profile is:</source>
          <target state="translated">Большую часть дисперсии можно объяснить колоколообразной кривой ширины effective_rank:низкая ранговая часть профиля единичных значений:</target>
        </trans-unit>
        <trans-unit id="9a311c70d6fa85e99fb6533c84253a4d2c760cf7" translate="yes" xml:space="preserve">
          <source>Most scikit-learn models are usually pretty fast as they are implemented either with compiled Cython extensions or optimized computing libraries. On the other hand, in many real world applications the feature extraction process (i.e. turning raw data like database rows or network packets into numpy arrays) governs the overall prediction time. For example on the Reuters text classification task the whole preparation (reading and parsing SGML files, tokenizing the text and hashing it into a common vector space) is taking 100 to 500 times more time than the actual prediction code, depending on the chosen model.</source>
          <target state="translated">Большинство scikit-learn моделей обычно довольно быстры,так как они реализованы либо скомпилированными расширениями Cython,либо оптимизированными вычислительными библиотеками.С другой стороны,во многих реальных приложениях процесс извлечения функций (т.е.превращение необработанных данных,таких как строки базы данных или сетевые пакеты,в нумерованные массивы)управляет общим временем прогнозирования.Например,по задаче классификации текста Reuters вся подготовка (чтение и разбор SGML-файлов,токенирование текста и хэширование его в общее векторное пространство)занимает в 100-500 раз больше времени,чем реальный код прогнозирования,в зависимости от выбранной модели.</target>
        </trans-unit>
        <trans-unit id="1f57c7d2294fbf421c865e0ff805433c9e9164a6" translate="yes" xml:space="preserve">
          <source>Most treatments of LSA in the natural language processing (NLP) and information retrieval (IR) literature swap the axes of the matrix \(X\) so that it has shape &lt;code&gt;n_features&lt;/code&gt; &amp;times; &lt;code&gt;n_samples&lt;/code&gt;. We present LSA in a different way that matches the scikit-learn API better, but the singular values found are the same.</source>
          <target state="translated">В большинстве трактовок LSA в литературе по обработке естественного языка (NLP) и информационному поиску (IR) оси матрицы \ (X \) &lt;code&gt;n_features&lt;/code&gt; &lt;code&gt;n_samples&lt;/code&gt; так что она имеет форму n_features &amp;times; n_samples . Мы представляем LSA другим способом, который лучше соответствует API scikit-learn, но найденные единичные значения такие же.</target>
        </trans-unit>
        <trans-unit id="56ac69cc3d5e8e713d723baf0656a6eefef8f81b" translate="yes" xml:space="preserve">
          <source>Multi target classification</source>
          <target state="translated">Многоцелевая классификация</target>
        </trans-unit>
        <trans-unit id="b9b406b23aa7207ecf1f2aef41fc5c5ad0ba0c31" translate="yes" xml:space="preserve">
          <source>Multi target regression</source>
          <target state="translated">Многоцелевая регрессия</target>
        </trans-unit>
        <trans-unit id="332c064d1606c8de1a2522f9e4ee668dee56478e" translate="yes" xml:space="preserve">
          <source>Multi-class AdaBoosted Decision Trees</source>
          <target state="translated">Многоклассные AdaBoosted деревья принятия решений</target>
        </trans-unit>
        <trans-unit id="d384b7095ac166d1b587c1dafb0cadad28beb4c2" translate="yes" xml:space="preserve">
          <source>Multi-class targets.</source>
          <target state="translated">Многоклассные цели.</target>
        </trans-unit>
        <trans-unit id="3243798e9c1a783043187bb0ea60ba4b8d0dfc62" translate="yes" xml:space="preserve">
          <source>Multi-class targets. An indicator matrix turns on multilabel classification.</source>
          <target state="translated">Многоклассные цели.Матрица индикаторов включает многомаркировочную классификацию.</target>
        </trans-unit>
        <trans-unit id="552ba9a8fb8ef0b9cf8d9ea68e7f0c182ae9af5e" translate="yes" xml:space="preserve">
          <source>Multi-dimensional scaling</source>
          <target state="translated">Многомерное масштабирование</target>
        </trans-unit>
        <trans-unit id="9815dac6e8971893d838904dc7e1cfe16372af94" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron classifier.</source>
          <target state="translated">Многослойный перцептронный классификатор.</target>
        </trans-unit>
        <trans-unit id="b994a134c1a31489af71fc772bdcadb38a217ddf" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the &lt;em&gt;same&lt;/em&gt; scaling to the test set for meaningful results. You can use &lt;code&gt;StandardScaler&lt;/code&gt; for standardization.</source>
          <target state="translated">Многослойный персептрон чувствителен к масштабированию функций, поэтому настоятельно рекомендуется масштабировать ваши данные. Например, масштабируйте каждый атрибут во входном векторе X до [0, 1] или [-1, +1] или стандартизируйте его, чтобы иметь среднее значение 0 и дисперсию 1. Обратите внимание, что вы должны применить такое &lt;em&gt;же&lt;/em&gt; масштабирование к набору тестов для значимые результаты. Вы можете использовать &lt;code&gt;StandardScaler&lt;/code&gt; для стандартизации.</target>
        </trans-unit>
        <trans-unit id="8b22895cdf3840f5acfe1ac32cbc8961e8fd336a" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron regressor.</source>
          <target state="translated">Многослойный перцептронный регрессор.</target>
        </trans-unit>
        <trans-unit id="dc72474a07afc8bb8057ac9bf6d8fbc65e56a63e" translate="yes" xml:space="preserve">
          <source>Multi-output Decision Tree Regression</source>
          <target state="translated">Регрессия дерева решений с несколькими выходами</target>
        </trans-unit>
        <trans-unit id="2627f8f7a5d9294ea8dcfe47a04508977edd8f7c" translate="yes" xml:space="preserve">
          <source>Multi-output targets predicted across multiple predictors. Note: Separate models are generated for each predictor.</source>
          <target state="translated">Множественные цели,предсказанные с помощью нескольких предикторов.Примечание:Для каждого предиктора создаются отдельные модели.</target>
        </trans-unit>
        <trans-unit id="4da1e42d60732d934b60458ac859ed1253e6bfbd" translate="yes" xml:space="preserve">
          <source>Multi-output targets.</source>
          <target state="translated">Многоцелевые цели.</target>
        </trans-unit>
        <trans-unit id="d25d7d780166f0481648cccd463a78a5e417f6f3" translate="yes" xml:space="preserve">
          <source>Multi-output targets. An indicator matrix turns on multilabel estimation.</source>
          <target state="translated">Многоцелевые цели.Матрица индикаторов включает многомаркировочную оценку.</target>
        </trans-unit>
        <trans-unit id="775030d60513b2f729789206b06d021b6661e16d" translate="yes" xml:space="preserve">
          <source>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Многозадачная модель ElasticNet,обученная с L1/L2 смешанной формой как регуляризатор</target>
        </trans-unit>
        <trans-unit id="7259143bf01ac8062e2b5725644f1e005f808315" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 ElasticNet with built-in cross-validation.</source>
          <target state="translated">Многозадачная L1/L2 ElasticNet со встроенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="5c1ad40e838b03e514631adae1736168414d6605" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation</source>
          <target state="translated">Многозадачный L1/L2 Лассо со встроенной кросс-проверкой</target>
        </trans-unit>
        <trans-unit id="a743aa48cf046a15087b0f4886f436159c359dd5" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation.</source>
          <target state="translated">Многозадачный L1/L2 Lasso со встроенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="6377873684d0ac47f9792cf0130c074e6b5d5c8f" translate="yes" xml:space="preserve">
          <source>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Многозадачная модель Лассо,обученная с L1/L2 смешанной формы в качестве регулятора</target>
        </trans-unit>
        <trans-unit id="669e809a0e7044a9302d0da3188c44feddafe180" translate="yes" xml:space="preserve">
          <source>Multiclass and multilabel classification strategies</source>
          <target state="translated">Стратегии классификации по нескольким классам и многомаркировке</target>
        </trans-unit>
        <trans-unit id="957cc5ae23e389ffa9c767fc16d7ac37036b0153" translate="yes" xml:space="preserve">
          <source>Multiclass classification</source>
          <target state="translated">Классификация по нескольким классам</target>
        </trans-unit>
        <trans-unit id="f43fb647f0e5eccf5a3760b6eafe5e21b79a50a6" translate="yes" xml:space="preserve">
          <source>Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan.</source>
          <target state="translated">Многоклассные вероятностные оценки получены из бинарных (однопроцентных)оценок путем простой нормализации,как рекомендуют Задрозный и Элкан.</target>
        </trans-unit>
        <trans-unit id="3debc5753cd55840fa65a540929e237591ad2faf" translate="yes" xml:space="preserve">
          <source>Multiclass settings</source>
          <target state="translated">Многоклассовые настройки</target>
        </trans-unit>
        <trans-unit id="e3f8736465f26b4a50bfa9739f8adbcfb24ccc56" translate="yes" xml:space="preserve">
          <source>Multiclass sparse logisitic regression on newgroups20</source>
          <target state="translated">Многоклассная разреженная логистическая регрессия на новых группах20</target>
        </trans-unit>
        <trans-unit id="38a70920d0cd2001f4ef8f9ee41dfa6b122f018c" translate="yes" xml:space="preserve">
          <source>Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</source>
          <target state="translated">Мультиклассовая спектральная кластеризация, 2003 г. Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c5d0b14c4e8dd95e44e1cd37847a8b6674049750" translate="yes" xml:space="preserve">
          <source>Multiclass vs. multilabel fitting</source>
          <target state="translated">Фитинг мультикласса против многомаркировочного фитинга</target>
        </trans-unit>
        <trans-unit id="dbc4079d7d6495ef3cfc4fdaba01141075b60d89" translate="yes" xml:space="preserve">
          <source>Multidimensional scaling</source>
          <target state="translated">Многомерное масштабирование</target>
        </trans-unit>
        <trans-unit id="7c33b81ffc3ca04c62af4f5074ba33e510028ebd" translate="yes" xml:space="preserve">
          <source>Multilabel classification</source>
          <target state="translated">Многомаркировочная классификация</target>
        </trans-unit>
        <trans-unit id="c720ba81272f13af125e464e56bd5648c8146ada" translate="yes" xml:space="preserve">
          <source>Multilabel ranking metrics</source>
          <target state="translated">Многомаркировочные метрики ранга</target>
        </trans-unit>
        <trans-unit id="b6031d58e46d313eca93045d9598faea168256f9" translate="yes" xml:space="preserve">
          <source>Multimetric scoring can either be specified as a list of strings of predefined scores names or a dict mapping the scorer name to the scorer function and/or the predefined scorer name(s). See &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Using multiple metric evaluation&lt;/a&gt; for more details.</source>
          <target state="translated">Мультиметрическая оценка может быть указана либо в виде списка строк с предварительно определенными именами оценок, либо в виде словаря, сопоставляющего имя счетчика с функцией счетчика и / или предварительно определенным именем (именами) счетчика. Дополнительные сведения см. В разделе &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Использование множественной метрической оценки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="71e5ed6f7fb13f64a7d1e47fd6ffef12dfd5580e" translate="yes" xml:space="preserve">
          <source>Multinomial + L1 penalty</source>
          <target state="translated">Мультиномиальный+L1 штраф</target>
        </trans-unit>
        <trans-unit id="82d79c421161a2e0a31300a79127c9804ae62ed5" translate="yes" xml:space="preserve">
          <source>Multinomial + L2 penalty</source>
          <target state="translated">Мультиномиальный+L2 штраф</target>
        </trans-unit>
        <trans-unit id="efccef2252a812759badf849dd9e2acd4cd7eb95" translate="yes" xml:space="preserve">
          <source>Multinomial deviance (&lt;code&gt;'deviance'&lt;/code&gt;): The negative multinomial log-likelihood loss function for multi-class classification with &lt;code&gt;n_classes&lt;/code&gt; mutually exclusive classes. It provides probability estimates. The initial model is given by the prior probability of each class. At each iteration &lt;code&gt;n_classes&lt;/code&gt; regression trees have to be constructed which makes GBRT rather inefficient for data sets with a large number of classes.</source>
          <target state="translated">Полиномиальное отклонение ( &lt;code&gt;'deviance'&lt;/code&gt; ): отрицательная полиномиальная функция потерь логарифма правдоподобия для мультиклассовой классификации с &lt;code&gt;n_classes&lt;/code&gt; взаимоисключающими классами. Он предоставляет оценки вероятности. Исходная модель задается априорной вероятностью каждого класса. На каждой итерации должны быть построены деревья регрессии &lt;code&gt;n_classes&lt;/code&gt; , что делает GBRT довольно неэффективным для наборов данных с большим количеством классов.</target>
        </trans-unit>
        <trans-unit id="313293589005fec34a4137f7e7a462e44753a91e" translate="yes" xml:space="preserve">
          <source>Multioutput classification support can be added to any classifier with &lt;code&gt;MultiOutputClassifier&lt;/code&gt;. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3&amp;hellip;,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3&amp;hellip;,yn).</source>
          <target state="translated">Поддержка классификации с несколькими выходами может быть добавлена ​​к любому классификатору с помощью &lt;code&gt;MultiOutputClassifier&lt;/code&gt; . Эта стратегия состоит из подбора одного классификатора для каждой цели. Это позволяет несколько классификаций целевых переменных. Цель этого класса - расширить оценщики, чтобы иметь возможность оценивать серию целевых функций (f1, f2, f3&amp;hellip;, fn), которые обучаются на одной матрице предикторов X для прогнозирования серии ответов (y1, y2, y3 &amp;hellip;, Уп).</target>
        </trans-unit>
        <trans-unit id="086b68ade408f93caaac80f71e1eabb4cc44f3fd" translate="yes" xml:space="preserve">
          <source>Multioutput regression support can be added to any regressor with &lt;code&gt;MultiOutputRegressor&lt;/code&gt;. This strategy consists of fitting one regressor per target. Since each target is represented by exactly one regressor it is possible to gain knowledge about the target by inspecting its corresponding regressor. As &lt;code&gt;MultiOutputRegressor&lt;/code&gt; fits one regressor per target it can not take advantage of correlations between targets.</source>
          <target state="translated">Поддержка множественной регрессии может быть добавлена ​​к любому регрессору с помощью &lt;code&gt;MultiOutputRegressor&lt;/code&gt; . Эта стратегия состоит из подбора одного регрессора для каждой цели. Поскольку каждая цель представлена ​​ровно одним регрессором, можно получить информацию о цели, проверив соответствующий регрессор. Поскольку &lt;code&gt;MultiOutputRegressor&lt;/code&gt; соответствует одному регрессору для каждой цели, он не может использовать преимущества корреляции между целями.</target>
        </trans-unit>
        <trans-unit id="96e252b1f2ecf6cba5d585af259eddb308663e2e" translate="yes" xml:space="preserve">
          <source>Multiple metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt; (please refer the &lt;code&gt;scoring&lt;/code&gt; parameter doc for more information)</source>
          <target state="translated">Оценка множественных показателей с использованием &lt;code&gt;cross_validate&lt;/code&gt; ( дополнительную информацию см. В документации по параметрам &lt;code&gt;scoring&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="629b6c06ee9b92eec539c00c0d5b033d1b11a26d" translate="yes" xml:space="preserve">
          <source>Multiple metric parameter search can be done by setting the &lt;code&gt;scoring&lt;/code&gt; parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables.</source>
          <target state="translated">Поиск по нескольким параметрам метрики может быть выполнен путем установки параметра &lt;code&gt;scoring&lt;/code&gt; в список имен счетчиков метрик или словаря, сопоставляющего имена счетчиков с вызываемыми счетчиками.</target>
        </trans-unit>
        <trans-unit id="85ae0fa16a20d62aa04d6b821cea2aa9547567a2" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. Keys are transformer names, values the weights.</source>
          <target state="translated">Мультипликативный вес для каждого трансформатора.Ключи-это названия трансформаторов,значения весов.</target>
        </trans-unit>
        <trans-unit id="0634d761605b2ffdac7cc3b47cb937d2911bb7fc" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. The output of the transformer is multiplied by these weights. Keys are transformer names, values the weights.</source>
          <target state="translated">Мультипликативный вес для каждого трансформатора.Выходная мощность трансформатора умножается на эти веса.Ключами являются названия трансформаторов,значения весов.</target>
        </trans-unit>
        <trans-unit id="7f4f1f6c0e0110908215d6d402a5fd0376794171" translate="yes" xml:space="preserve">
          <source>Multiply features by the specified value. If None, then features are scaled by a random value drawn in [1, 100]. Note that scaling happens after shifting.</source>
          <target state="translated">Умножьте характеристики на указанное значение.Если Нет,то функции масштабируются на случайное значение,записанное в [1,100].Обратите внимание,что масштабирование происходит после сдвига.</target>
        </trans-unit>
        <trans-unit id="773db00cec71fc706de69e832dff6b23a68d6b97" translate="yes" xml:space="preserve">
          <source>Multithreaded BLAS libraries sometimes conflict with Python&amp;rsquo;s &lt;code&gt;multiprocessing&lt;/code&gt; module, which is used by e.g. &lt;code&gt;GridSearchCV&lt;/code&gt; and most other estimators that take an &lt;code&gt;n_jobs&lt;/code&gt; argument (with the exception of &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;SGDRegressor&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; and tree-based methods such as random forests). This is true of Apple&amp;rsquo;s Accelerate and OpenBLAS when built with OpenMP support.</source>
          <target state="translated">Многопоточные библиотеки BLAS иногда конфликтуют с модулем &lt;code&gt;multiprocessing&lt;/code&gt; Python , который используется, например, &lt;code&gt;GridSearchCV&lt;/code&gt; и большинством других оценщиков, принимающих аргумент &lt;code&gt;n_jobs&lt;/code&gt; (за исключением &lt;code&gt;SGDClassifier&lt;/code&gt; , &lt;code&gt;SGDRegressor&lt;/code&gt; , &lt;code&gt;Perceptron&lt;/code&gt; , &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; и древовидных методов, таких как случайные леса). Это верно для Apple Accelerate и OpenBLAS, когда они созданы с поддержкой OpenMP.</target>
        </trans-unit>
        <trans-unit id="425dc1fa519b0f6261993bae28e1ad51c131bb66" translate="yes" xml:space="preserve">
          <source>Must be provided at the first call to partial_fit, can be omitted in subsequent calls.</source>
          <target state="translated">Должен предоставляться при первом вызове на partial_fit,может быть опущен при последующих вызовах.</target>
        </trans-unit>
        <trans-unit id="b6845c300d4f945b800f2e50de745703cc5cc891" translate="yes" xml:space="preserve">
          <source>Must fulfill the input assumptions of the underlying estimator.</source>
          <target state="translated">Должны соответствовать исходным допущениям базового оценщика.</target>
        </trans-unit>
        <trans-unit id="214188886e4a84a8788bdd82b6f8744f5146fead" translate="yes" xml:space="preserve">
          <source>Mutual Information (not adjusted for chance)</source>
          <target state="translated">Взаимная информация (не скорректированная с учетом случайности)</target>
        </trans-unit>
        <trans-unit id="16b7cc0e7a5234ba809ed1e09a3a8960dff39693" translate="yes" xml:space="preserve">
          <source>Mutual Information between two clusterings.</source>
          <target state="translated">Взаимная информация между двумя кластерами.</target>
        </trans-unit>
        <trans-unit id="81e08bee8a8968c08bd07aed8cef44d9fb7a13f3" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">Взаимная информация (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; между двумя случайными величинами - это неотрицательное значение, которое измеряет зависимость между переменными. Он равен нулю тогда и только тогда, когда две случайные величины независимы, а более высокие значения означают более высокую зависимость.</target>
        </trans-unit>
        <trans-unit id="92d0e5dc6672a19ad8c5b9523b6a6d1a9b82c89e" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">Взаимная информация (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; между двумя случайными величинами - это неотрицательное значение, которое измеряет зависимость между переменными. Он равен нулю тогда и только тогда, когда две случайные величины независимы, а более высокие значения означают более высокую зависимость.</target>
        </trans-unit>
        <trans-unit id="4276bd70be44db9c6fb9548906a97ab826aba297" translate="yes" xml:space="preserve">
          <source>Mutual information between features and the target.</source>
          <target state="translated">Взаимная информация между функциями и целью.</target>
        </trans-unit>
        <trans-unit id="33ca9360bf5453bcb4bf9aed03e658f161f23932" translate="yes" xml:space="preserve">
          <source>Mutual information for a continuous target.</source>
          <target state="translated">Взаимная информация для постоянной цели.</target>
        </trans-unit>
        <trans-unit id="aa199ad103c044c23c4e2e0edbe572bad088827c" translate="yes" xml:space="preserve">
          <source>Mutual information for a contnuous target.</source>
          <target state="translated">Взаимная информация для совместной цели.</target>
        </trans-unit>
        <trans-unit id="ef9610a089a978dd0d661be292e2bde712e413d1" translate="yes" xml:space="preserve">
          <source>Mutual information for a discrete target.</source>
          <target state="translated">Взаимная информация для дискретной цели.</target>
        </trans-unit>
        <trans-unit id="2555b04ef28112b324874c1cc2f3bf2b5b5c384e" translate="yes" xml:space="preserve">
          <source>Mutual information, a non-negative value</source>
          <target state="translated">Взаимная информация,неотрицательная ценность</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="4e1221dedd7ee34eb6931a44dc15d9a84ca69a81" translate="yes" xml:space="preserve">
          <source>N : number of dimensions</source>
          <target state="translated">N:количество размеров</target>
        </trans-unit>
        <trans-unit id="8daf5ce04352d841160e980446540ca50cce58e4" translate="yes" xml:space="preserve">
          <source>N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.</source>
          <target state="translated">Н-бабушки на помощь! Вместо того,чтобы строить простую коллекцию униграмм (n=1),можно было бы предпочесть коллекцию биграмм (n=2),в которой подсчитываются вхождения пар последовательных слов.</target>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF:количество димов,в которых оба значения являются Ложными.</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT:количество димов,в которых первое значение-False,второе-True.</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMF лучше всего использовать с методом &lt;code&gt;fit_transform&lt;/code&gt; , который возвращает матрицу W. Матрица H сохраняется в подобранной модели в атрибуте &lt;code&gt;components_&lt;/code&gt; ; &lt;code&gt;transform&lt;/code&gt; метода разложит новую матрицу X_new на основе этих сохраненных компонентов:</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">NMI и MI не приспособлены к случайностям.</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ/(NNEQ+0,5*NTT)</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ/(NTT+NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ/N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ/NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ:количество неравных размеров,NNEQ=NTF+NFT</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ/N</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ:количество ненулевых размеров,NNZ=NTF+NFT+NTT</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">Заметьте,что при использовании пользовательских счетчиков,каждый счетчик должен возвращать одно значение.Метрические функции,возвращающие список/массив значений,могут быть обернуты в несколько баллов,которые возвращают по одному значению каждому.</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">концентрация окислов азота NOX (частей на 10 миллионов)</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF:количество димов,в которых первое значение равно True,второе-False</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT:количество димов,в которых оба значения True</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">NaNs игнорируются в алгоритме.</target>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">NaNs рассматриваются как отсутствующие значения:игнорируются при подгонке и сохраняются при трансформации.</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">NaNs считаются пропущенными значениями:игнорируются при вычислении статистики и сохраняются во время преобразования данных.</target>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">Классификатор Naive Bayes для мультиномиальных моделей</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">Классификатор Naive Bayes для многомерных моделей Бернулли.</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">Учащиеся и классификаторы Naive Bayes могут быть чрезвычайно быстрыми по сравнению с более сложными методами.Развязка распределений условных признаков класса означает,что каждое распределение может быть независимо оценено как одномерное.Это,в свою очередь,помогает смягчить проблемы,связанные с проклятием размерности.</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">Наивные методы Байеса - это набор алгоритмов обучения с учителем, основанных на применении теоремы Байеса с &amp;laquo;наивным&amp;raquo; предположением об условной независимости между каждой парой характеристик с учетом значения переменной класса. Теорема Байеса утверждает следующее отношение, учитывая переменную класса \ (y \) и зависимый вектор признаков с \ (x_1 \) через \ (x_n \),:</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">Наивные байесовские модели могут использоваться для решения крупномасштабных задач классификации, для которых полный обучающий набор может не поместиться в памяти. Чтобы справиться с этим случаем, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt; предоставляют метод &lt;code&gt;partial_fit&lt;/code&gt; , который можно использовать постепенно, как это делается с другими классификаторами, как показано в разделе&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt; Классификация текстовых документов вне ядра&lt;/a&gt; . Все наивные байесовские классификаторы поддерживают взвешивание выборки.</target>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">Название набора данных</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">Имя каждого объекта;feature_names[i]содержит имя объекта с индексом i.</target>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">Название набора данных на mldata.org, например: &amp;laquo;leukemia&amp;raquo;, &amp;laquo;Whistler Daily Snowfall&amp;raquo; и т. Д. Необработанное имя автоматически преобразуется в URL-адрес mldata.org.</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">Имя функции активации выхода.</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">Имя параметра,который будет изменяться.</target>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">Наименование или индекс столбца,содержащего данные.</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">Название или индекс столбца,содержащего целевые значения.</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">Именованные функции,не встречающиеся во время подгонки или fit_transform будут беззвучно проигнорированы.</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">Имена каждой из функций.</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">Имена каждого из целевых классов в возрастающем числовом порядке. Актуально только для классификации и не поддерживается для нескольких выходов. Если &lt;code&gt;True&lt;/code&gt; , показывает символическое представление имени класса.</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">Имена каждой цели (RCV1 тем),в порядке,указанном в dataset.target.</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">Названия элементов,полученных в результате трансформации.</target>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">Естественная обработка данных смешанного типа (=гетерогенные характеристики)</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">Ближайшая центроидная классификация</target>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">Классификация ближайших соседей</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">Регрессия ближайших соседей</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">Ближайший центроидный классификатор.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
