<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="translated">Образец матрицы.</target>
        </trans-unit>
        <trans-unit id="04c4511b91c525e2da2ef7db41615c6ca0a3fd2e" translate="yes" xml:space="preserve">
          <source>Sample output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="translated">Пробный конвейер для извлечения и оценки текстовых элементов</target>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">Пример использования классификации &quot;Ближайший центроид&quot;.Будет построена граница решения для каждого класса.</target>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">Пример использования классификации &quot;Ближайшие соседи&quot;.Будет построена граница решения для каждого класса.</target>
        </trans-unit>
        <trans-unit id="c4ad00c210ac74869e557ad5117f0c17f5204222" translate="yes" xml:space="preserve">
          <source>Sample usage of Neighborhood Components Analysis for dimensionality reduction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="translated">Примеры векторов,из которых можно вычислять отклонения.</target>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="translated">Векторы образцов.</target>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="translated">Вес образца</target>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="translated">Вес образца.</target>
        </trans-unit>
        <trans-unit id="b0d17c86dbd02471ac25031f76f6b9e62870f2a0" translate="yes" xml:space="preserve">
          <source>Sample weights</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="translated">Пробные веса.</target>
        </trans-unit>
        <trans-unit id="f828cc5ffdb9cf591696bfda2177ba993eb46afe" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, all samples are given the same weight.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="translated">Пробные веса.Если нет,то веса образца инициализируются в 1/n_образцы.</target>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="translated">Вес образца. Если None, веса выборки инициализируются как &lt;code&gt;1 / n_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.</target>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Обратите внимание,что это поддерживается только в том случае,если все основные оценщики поддерживают веса выборки.</target>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Обратите внимание,что это поддерживается только в том случае,если базовый оценщик поддерживает взвешивание образцов.</target>
        </trans-unit>
        <trans-unit id="44004435db67a9bbea489a279598bbde7cadacd2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying classifier supports sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Поддерживается только в том случае,если базовый регрессор поддерживает вес выборки.</target>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Дроби,которые создадут дочерние узлы с нулевым или отрицательным весом нетто,игнорируются при поиске дроби в каждом узле.</target>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Дроби,которые создадут дочерние узлы с нулевым или отрицательным весом нетто,игнорируются при поиске дроби в каждом узле.В случае классификации,дроби также игнорируются,если они приведут к тому,что любой из классов будет иметь отрицательный вес в любой из дочерних узлов.</target>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">Пробные веса.Если нет,то образцы имеют одинаковый вес.Дроби,которые создадут дочерние узлы с нулевым или отрицательным весом нетто,игнорируются при поиске дроби в каждом узле.Деления также игнорируются,если они приведут к созданию одного класса с отрицательным весом в любой из дочерних узлов.</target>
        </trans-unit>
        <trans-unit id="a6e78b9afd27497df49aade34a36635be33138ac" translate="yes" xml:space="preserve">
          <source>Sample-weight support for Lasso and ElasticNet</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="translated">Примеряет подмножество учебных точек,вычисляет ядро по ним и вычисляет матрицу нормализации.</target>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="translated">Генератор проб</target>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">Образцы могут иметь несколько ярлыков (см. &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;Http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="4d0b8d7411b8018b991a89ec2a4d88914d35dbf8" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="translated">Образцы по классам</target>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="translated">Образцы случайной проекции в соответствии с n_функциями.</target>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="translated">Образцы на скопление.</target>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="translated">Общее количество образцов</target>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="translated">Образцы.Каждый образец должен быть текстовым документом (байт или строка в юникоде,имя файла или объект файла в зависимости от аргумента конструктора),который будет токенирован и хэширован.</target>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="translated">Образцы.Каждый образец должен быть итерабельным (например,список или кортеж),содержащим/генерирующим имена элементов (и,опционально,значения,см.аргумент input_type конструктора),которые будут хэшироваться.raw_X не обязательно должна поддерживать функцию len,поэтому она может быть результатом работы генератора;n_образцы определяются &quot;на лету&quot;.</target>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="translated">Образцы. Если ядро ​​== &amp;laquo;предварительно вычислено&amp;raquo;, это вместо этого предварительно вычисленная матрица ядра, shape = [n_samples, n_samples_fitted], где n_samples_fitted - это количество выборок, используемых при подгонке для этой оценки.</target>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="translated">Интервал выборки.Должен быть указан,когда sample_steps не в {1,2,3}.</target>
        </trans-unit>
        <trans-unit id="fb8efe38000470eaaa9cdd2c1e100fa22c387ba8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">Очевидно, что выборка большего количества измерений приводит к лучшим результатам классификации, но требует больших затрат. Это означает, что существует компромисс между временем выполнения и точностью, заданный параметром n_components. Обратите внимание, что решение линейной SVM, а также приближенной SVM ядра можно значительно ускорить, используя стохастический градиентный спуск через &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; . Это не просто возможно в случае ядра SVM.</target>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="translated">Санджой Дасгупта и Анупам Гупта, 1999, &amp;laquo;Элементарное доказательство леммы Джонсона-Линденштрауса&amp;raquo;. &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="translated">Санджой Дасгупта и Анупам Гупта, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Элементарное доказательство леммы Джонсона-Линденштрауса.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">Санджой Дасгупта. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Эксперименты со случайной проекцией. &lt;/a&gt;В материалах шестнадцатой конференции по неопределенности в искусственном интеллекте (UAI'00), Craig Boutilier и Mois&amp;eacute;s Goldszmidt (Eds.). Морган Кауфманн Паблишерс Инк., Сан-Франциско, Калифорния, США, 143&amp;ndash;151.</target>
        </trans-unit>
        <trans-unit id="2894bd12dff71a351f3ecafd27a1d2a6b0bda89e" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;https://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;rsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="translated">Сохраняйте подогнанную модель как лучшую,если количество образцов в рационе максимальное.В случае,если текущая оценочная модель имеет такое же количество инсайдеров,она считается лучшей только в том случае,если она имеет лучший балл.</target>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="461b60146605d928fa9b9a5fb416ca167c84c880" translate="yes" xml:space="preserve">
          <source>Scalability and stability improvements to KMeans</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="translated">Масштабируемость можно увеличить,используя меньшее количество семян,например,используя большее значение min_bin_freq в функции get_bin_seeds.</target>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="translated">Масштабируемость,в связи с последовательным характером форсирования,вряд ли может быть распараллелена.</target>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="translated">Масштабируемый векторный станок с линейной поддержкой для классификации,реализованный с использованием Liblinear.См.также раздел LinearSVC для получения дополнительной информации об элементе сравнения.</target>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="translated">Масштабируемый векторный станок с линейной поддержкой для регрессии,реализованный с использованием Liblinear.</target>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="translated">Масштабируемый линейный опорный векторный станок для классификации с использованием блестящих линий.</target>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="translated">Масштабирование данных до исходного представления</target>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="translated">Масштабировать каждый элемент по его максимальному абсолютному значению.</target>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">Масштабировать каждую особенность матрицы данных,умножая на определенную шкалу,предоставляемую вызывающим абонентом,предполагая (n_samples,n_features)форму.</target>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="translated">Масштабируйте каждую функцию до диапазона [-1,1],не нарушая при этом ломкость.</target>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="translated">Масштабировать каждую не нулевую строку X до единичной нормы.</target>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">Масштабировать каждую строку матрицы данных путем умножения на определенную шкалу,предоставленную вызывающим абонентом,предполагая (n_samples,n_features)форму.</target>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="translated">Масштабный коэффициент между внутренней и внешней окружностью.</target>
        </trans-unit>
        <trans-unit id="c9aadd325b03483aa8cbb4258dd4942f088c00d2" translate="yes" xml:space="preserve">
          <source>Scale features of X according to feature_range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="translated">Функция масштабирования с использованием статистики,которая устойчива к отклонениям.</target>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="translated">Масштабируйте входные векторы по отдельности в соответствии с единичной нормой (длина вектора).</target>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="translated">Параметр &quot;Масштабная смесь</target>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="translated">Масштабировать данные</target>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="translated">Масштабируемые данные имеют нулевое среднее значение и дисперсию в единицах измерения:</target>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="translated">Масштабировщики являются линейными (или точнее аффинированными)трансформаторами и отличаются друг от друга способом оценки параметров,используемых для сдвига и масштабирования каждого элемента.</target>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="translated">Масштабирование 1D-массива</target>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="translated">Масштабирование характеристик X в соответствии с диапазоном feature_range.</target>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="translated">Масштабирование входов до единичных норм является обычной операцией,например,для классификации текста или кластеризации.Например,точечный продукт двух l2-нормированных векторов TF-IDF является косинусным сходством векторов и является базовой метрикой сходства для векторной пространственной модели,обычно используемой сообществом Information Retrieval.</target>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="translated">Масштабирование характеристик в пространстве,охваченном классом центроидов.</target>
        </trans-unit>
        <trans-unit id="b5c5a5ab3639fcbfa287bfb00c2baa97d840c68a" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids. Only available for &amp;lsquo;svd&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="translated">Параметр масштабирования ядра chi2.</target>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="translated">Масштабирование параметра регуляризации для SVC</target>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="translated">Масштабирование против отбеливания</target>
        </trans-unit>
        <trans-unit id="02ba5e6e4d2072a725717b83a0dcd2c4ccfb8e6e" translate="yes" xml:space="preserve">
          <source>Sch&amp;ouml;lkopf et. al &lt;a href=&quot;https://www.stat.purdue.edu/~yuzhu/stat598m3/Papers/NewSVM.pdf&quot;&gt;New Support Vector Algorithms&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f575a7be2bbae52450cf10acab0f42ab527bed47" translate="yes" xml:space="preserve">
          <source>Schubert, E., Sander, J., Ester, M., Kriegel, H. P., &amp;amp; Xu, X. (2017). DBSCAN revisited, revisited: why and how you should (still) use DBSCAN. ACM Transactions on Database Systems (TODS), 42(3), 19.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b3e8e65e06fb91614a9faf2b4d8410e9e9072a" translate="yes" xml:space="preserve">
          <source>Schubert, Erich, Michael Gertz. &amp;ldquo;Improving the Cluster Structure Extracted from OPTICS Plots.&amp;rdquo; Proc. of the Conference &amp;ldquo;Lernen, Wissen, Daten, Analysen&amp;rdquo; (LWDA) (2018): 318-329.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ac4d036f5e40e9fc63fcd2b4959a2b29e290cfe" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduced two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id24&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb84d52fa4915e02b24a271ab0aad024c4056d13" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduces two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id14&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learn также встраивает пару образцов изображений в формате JPEG,опубликованных их авторами по лицензии Creative Commons.Эти изображения могут быть полезны для тестирования алгоритмов и передачи 2D-данных.</target>
        </trans-unit>
        <trans-unit id="aad0f03512858b9b99ff0fe8b0c0fddc5ad0d78e" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those images can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="translated">Scikit-learn также позволяет оценивать несколько метрик в &lt;code&gt;GridSearchCV&lt;/code&gt; , &lt;code&gt;RandomizedSearchCV&lt;/code&gt; и &lt;code&gt;cross_validate&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="translated">Scikit-learn занимается изучением информации из одного или нескольких наборов данных, представленных в виде 2D-массивов. Их можно понимать как список многомерных наблюдений. Мы говорим, что первая ось этих массивов - это ось &lt;strong&gt;образцов&lt;/strong&gt; , а вторая - ось &lt;strong&gt;признаков&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="f9977ec0fe68c8f9bbc6588808c28cd22800a19b" translate="yes" xml:space="preserve">
          <source>Scikit-learn defines a simple API for creating visualizations for machine learning. The key features of this API is to allow for quick plotting and visual adjustments without recalculation. In this example, we will demonstrate how to use the visualization API by comparing ROC curves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="translated">Scikit-learn выполняет некоторую проверку данных, что увеличивает накладные расходы на вызов для &lt;code&gt;predict&lt;/code&gt; и подобных функций. В частности, проверка того, что функции являются конечными (не NaN или бесконечными), включает полный проход по данным. Если вы уверены, что ваши данные приемлемы, вы можете подавить проверку на конечность, установив для переменной среды &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; непустую строку перед импортом scikit-learn или настроив ее в Python с помощью &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; . Для большего контроля, чем эти глобальные настройки, &lt;code&gt;config_context&lt;/code&gt; позволяет вам установить эту конфигурацию в указанном контексте:</target>
        </trans-unit>
        <trans-unit id="56e4295ba33d7d0b066dcb5a29b6f828761a1e6b" translate="yes" xml:space="preserve">
          <source>Scikit-learn generally relies on the &lt;code&gt;loky&lt;/code&gt; backend, which is joblib&amp;rsquo;s default backend. Loky is a multi-processing backend. When doing multi-processing, in order to avoid duplicating the memory in each process (which isn&amp;rsquo;t reasonable with big datasets), joblib will create a &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html&quot;&gt;memmap&lt;/a&gt; that all processes can share, when the data is bigger than 1MB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="translated">Scikit-learn имеет коллекцию классов,которые могут быть использованы для создания списков индексов поездов/тестов для популярных стратегий перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="translated">Scikit-learn реализует различные классы для оценки моделей смеси Гаусса,которые соответствуют различным стратегиям оценки,подробно описанным ниже.</target>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="translated">Scikit-learn реализует эффективную оценку плотности ядра с использованием структуры Ball Tree или KD Tree через оценщик &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; . Доступные ядра показаны на втором рисунке этого примера.</target>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn - это модуль Python, объединяющий классические алгоритмы машинного обучения в сплоченном мире научных пакетов Python ( &lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt; , &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt; , &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="8efe5ffe4058ee23f32fcb7e77b39f35cffa4409" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;https://www.numpy.org/&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;https://scipy.org/&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;https://matplotlib.org/&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="translated">Scikit-learn предлагает более эффективное внедрение для строительства деревьев принятия решений.Наивная реализация (как описано выше)позволит пересчитывать гистограммы метки класса (для классификации)или средства (для регрессии)для каждой новой точки разделения вдоль данной особенности.Представление признака по всем соответствующим выборкам и сохранение бегущего количества меток уменьшит сложность на каждом узле до \(O(n_{features}\log(n_{samples}))\),в результате чего общая стоимость \(O(n_{features}n_{samples}\log(n_{samples}))\).Это опция для всех алгоритмов на основе дерева.По умолчанию она включена для повышения градиента,где в целом обучение происходит быстрее,но отключена для всех остальных алгоритмов,так как имеет тенденцию замедлять обучение при обучении глубоких деревьев.</target>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="translated">Scikit-learn предоставляет 3 надежных средства оценки регрессии: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; , &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; и &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="54ef66758fb920f45dd137b20e476f9003566169" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf6e9e896240b0867bdae025d2a37105852d3491" translate="yes" xml:space="preserve">
          <source>Scikit-learn relies heavily on NumPy and SciPy, which internally call multi-threaded linear algebra routines implemented in libraries such as MKL, OpenBLAS or BLIS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="translated">Scikit-learn использует библиотеку &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib,&lt;/a&gt; чтобы обеспечить параллельные вычисления внутри своих оценщиков. См. Документацию joblib, чтобы узнать о переключателях для управления параллельными вычислениями.</target>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipy предоставляет структуры данных с разреженными матрицами, которые оптимизированы для хранения разреженных данных. Основная особенность разреженных форматов заключается в том, что вы не храните нули, поэтому, если ваши данные разрежены, вы используете гораздо меньше памяти. Ненулевое значение в разреженном ( &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR или CSC&lt;/a&gt; ) представлении займет в среднем только одну 32-битную целочисленную позицию + 64-битное значение с плавающей запятой + дополнительные 32 бита на строку или столбец в матрице. Использование разреженных входных данных в плотной (или разреженной) линейной модели может значительно ускорить прогнозирование, поскольку только ненулевые характеристики влияют на скалярное произведение и, следовательно, на прогнозы модели. Следовательно, если у вас есть 100 ненулевых единиц в пространстве измерений 1e6, вам потребуется только операция умножения и сложения 100 вместо 1e6.</target>
        </trans-unit>
        <trans-unit id="41590fea612397630e8b90182fcd88974e84be1f" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="translated">Документация по форматам матриц</target>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">Функция оценки (или функция потерь) с сигнатурой &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e8a42d4da772627d057fecc9d05d1c5e0de456df" translate="yes" xml:space="preserve">
          <source>Score of base estimator with best alpha.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="translated">Степень уверенности в себе.Предсказать...</target>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="translated">Степень предсказания.</target>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="translated">Оценка набора данных для обучения,полученного с использованием оценки вне сумки.</target>
        </trans-unit>
        <trans-unit id="d47762b2bcf100a0eee50ed9f7a0b022146b7037" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when &lt;code&gt;oob_score&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a728e01859e5aacfa8054e6c7ac1cbc91bfd77d" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given test split.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="translated">Оценка этого параметра на данном тренинге/тестовом разделе.</target>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="translated">Очки и перекрёстные оценки</target>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="translated">Функция Scorer,используемая на выведенных данных для выбора наилучших параметров модели.</target>
        </trans-unit>
        <trans-unit id="2d120255d84deeb73e3a5484f87eef4818f21119" translate="yes" xml:space="preserve">
          <source>Scorer to use. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="translated">Показатели всех выходов усредняются равномерным весом.</target>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="translated">Показатели всех выходов усредняются,взвешиваются по отклонениям каждого отдельного выхода.</target>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="translated">Множество возможностей.</target>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="translated">Показатели на тестовом наборе.</target>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="translated">Баллы на тренировочных площадках.</target>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="1d35080d3b512f65a9672a3ec57c49c5c7d18fa7" translate="yes" xml:space="preserve">
          <source>Scoring parameter to use for early stopping. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used. If &lt;code&gt;scoring='loss'&lt;/code&gt;, early stopping is checked w.r.t the loss value. Only used if early stopping is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="translated">Второй пример</target>
        </trans-unit>
        <trans-unit id="01969fb763d816468d958ddf55fbcfeb6492bbfe" translate="yes" xml:space="preserve">
          <source>Second, precomputing the graph can give finer control on the nearest neighbors estimation, for instance enabling multiprocessing though the parameter &lt;code&gt;n_jobs&lt;/code&gt;, which might not be available in all estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="translated">Во-вторых,при использовании матрицы подключения,одиночные,средние и полные связи нестабильны и,как правило,создают несколько кластеров,которые растут очень быстро.Действительно,среднее и полное связывание борется с таким поведением при слиянии,учитывая все расстояния между двумя кластерами (в то время как единое связывание преувеличивает поведение,учитывая только кратчайшие расстояния между кластерами).График связности нарушает этот механизм средней и полной связности,делая их похожими на более хрупкие одиночные связки.Этот эффект более выражен для очень разреженных графов (попробуйте уменьшить количество соседей в kneighbors_graph)и при полной связи.В частности,наличие очень малого числа соседей на графе накладывает геометрию,близкую к одиночной связи,которая,как известно,обладает такой нестабильностью перколяции.</target>
        </trans-unit>
        <trans-unit id="d90e68437e39bd56831ac8f750d7707399d6fbb2" translate="yes" xml:space="preserve">
          <source>Secondly, the squared loss function is replaced by the unit deviance \(d\) of a distribution in the exponential family (or more precisely, a reproductive exponential dispersion model (EDM) &lt;a href=&quot;#id34&quot; id=&quot;id32&quot;&gt;11&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="translated">Секунды,использованные для переоснащения лучшей модели по всему набору данных.</target>
        </trans-unit>
        <trans-unit id="a31532b7821dad04a81b3f8844e44fc4c4735bbf" translate="yes" xml:space="preserve">
          <source>Section 3.3 in Christopher M. Bishop: Pattern Recognition and Machine Learning, 2006</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="translated">Раздел 5.4.4,стр.252-253.</target>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="translated">Содержание раздела</target>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="translated">См. &amp;laquo;Случайные функции для крупномасштабных ядерных машин&amp;raquo; А. Рахими и Бенджамина Рехта.</target>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="translated">См. &amp;laquo;Случайные приближения Фурье для ядер мультипликативных гистограмм с перекосом&amp;raquo; Фусин Ли, Каталин Ионеску и Кристиан Сминчисеску.</target>
        </trans-unit>
        <trans-unit id="03ac02c3ddabaad90ce0d4962bc965c10cba4eeb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#r95f74c4622c1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, Chapter 4, Section 4.2, for further details regarding the DotProduct kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">См. &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt; , pp84 для получения дополнительной информации о различных вариантах ядра Mat&amp;eacute;rn.</target>
        </trans-unit>
        <trans-unit id="dc2d327bd01f6b4c26633dc7230267bf2994fc43" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id7&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="translated">См. &amp;laquo; &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Математическая формулировка&amp;raquo;&lt;/a&gt; для полного описания решающей функции.</target>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="translated">См. &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;Примеры / compose / plot_transformed_target.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="translated">См. &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Примеры / linear_model / plot_polynomial_interpolation.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="translated">См. &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;Примеры / model_selection / plot_learning_curve.py&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="translated">См. &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Построение кривых проверки&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">Дополнительную информацию о регрессоре см. В разделе &amp;laquo; &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Регрессия Байесовского хребта&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Оценка Тейла-Сена: оценка на основе обобщенной медианы&lt;/a&gt; для получения дополнительной информации о регрессоре.</target>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">См. &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Модели Гауссовой смеси&lt;/a&gt; для получения дополнительной информации об оценке.</target>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">См. &lt;a href=&quot;../../modules/tree#tree&quot;&gt;Дерево решений&lt;/a&gt; для получения дополнительной информации об оценщике.</target>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Моделирование распределения видов&lt;/a&gt; пример использования ROC для моделирования распределения видов.</target>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Калибровка вероятности классификаторов&amp;raquo;,&lt;/a&gt; где приведен пример использования потерь по шкале Бриера для выполнения калибровки вероятности классификаторов.</target>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Распознавание рукописных цифр&lt;/a&gt; пример использования отчета о классификации рукописных цифр.</target>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Распознавание рукописных цифр&lt;/a&gt; пример использования матрицы неточностей для классификации рукописных цифр.</target>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Оценка ковариации усадки: LedoitWolf против OAS и максимальное правдоподобие&lt;/a&gt; пример того, как подогнать объект &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt; к данным и для визуализации характеристик оценки Ледуа-Вольфа с точки зрения вероятности.</target>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Оценка ковариации усадки: LedoitWolf против OAS и максимальное правдоподобие&lt;/a&gt; пример того, как подогнать объект &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt; к данным.</target>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Оценка ковариации усадки: LedoitWolf против OAS и максимальное правдоподобие&lt;/a&gt; пример того, как подогнать объект &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; к данным.</target>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Оценка ковариации усадки: LedoitWolf против OAS и максимальное правдоподобие&lt;/a&gt; пример того, как подобрать объект &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; к данным.</target>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf против оценки OAS,&lt;/a&gt; чтобы визуализировать разницу &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt; ошибок между LedoitWolf и оценкой &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt; ковариации.</target>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Оценка робастной ковариации&amp;raquo; и &amp;laquo;Релевантность расстояний Махаланобиса&amp;raquo;&lt;/a&gt; для иллюстрации разницы между использованием стандартной ( &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; ) или надежной оценки ( &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;covariance.MinCovDet&lt;/code&gt; &lt;/a&gt; ) местоположения и ковариации для оценки степени удаленности наблюдения.</target>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Робастная оценка ковариации&amp;raquo; и &amp;laquo;Релевантность расстояний Махаланобиса&amp;raquo;,&lt;/a&gt; чтобы визуализировать разницу между &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt; ковариации &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; и MinCovDet с точки зрения расстояния Махаланобиса (чтобы получить более точную оценку матрицы точности).</target>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="translated">См. В разделе &amp;laquo; &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Робастная оценка эмпирической ковариации&amp;raquo;&lt;/a&gt; пример того, как подогнать объект &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; &lt;/a&gt; к данным, и увидеть, как оценка остается точной, несмотря на наличие выбросов.</target>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Регрессия&lt;/a&gt; повышения градиента пример использования среднеквадратичной ошибки для оценки регрессии повышения градиента.</target>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;Пример IsolationForest&lt;/a&gt; для иллюстрации использования IsolationForest.</target>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Проверка с перестановками значимости классификационной оценки&lt;/a&gt; пример использования показателя точности с использованием перестановок набора данных.</target>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Рекурсивное исключение функции с перекрестной проверкой&amp;raquo;,&lt;/a&gt; где приведен пример использования нулевой потери для выполнения рекурсивного исключения функции с перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="translated">См. В разделе &amp;laquo; &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Лассо и эластичная сеть для разреженных сигналов&amp;raquo;&lt;/a&gt; приведен пример использования показателя R&amp;sup2; для оценки лассо и эластичной сети для разреженных сигналов.</target>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Полиномиальная интерполяция&lt;/a&gt; для регрессии Риджа с использованием созданных полиномиальных функций.</target>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Сравнение методов обучения многообразию&lt;/a&gt; для примера уменьшения размерности на наборе данных игрушечной &amp;laquo;S-образной кривой&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Обучение многообразию на рукописных цифрах: локально линейное вложение, изокарта&amp;hellip;&amp;raquo;&lt;/a&gt; для примера уменьшения размерности рукописных цифр.</target>
        </trans-unit>
        <trans-unit id="2a32db7a757930b4f797df7e8d06a3cd21abcff6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43f0e98d020880753d56a5cecd019501b6cb864a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="add8ccecfab3f9c846b3f2682673366366734b83" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cee09c79ab5ccf2f8ea1b726ccad8beb5f01cbf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="translated">См &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;концентрации перед Тип Анализ вариации байесовской гауссовой смеси&lt;/a&gt; для примера построения доверительных эллипсоидов для &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; с различными &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; для различных значений параметра &lt;code&gt;weight_concentration_prior&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Эллипсоиды модели гауссовой смеси&lt;/a&gt; пример построения доверительных эллипсоидов для &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;Ковариации GMM&lt;/a&gt; пример использования гауссовой смеси для кластеризации набора данных радужной оболочки.</target>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Оценка плотности гауссовой смеси&lt;/a&gt; пример построения графика оценки плотности.</target>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Выбор модели гауссовой смеси&lt;/a&gt; пример выбора модели, выполненный с использованием классической гауссовой смеси.</target>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Пример конвейера для извлечения и оценки текстовых признаков,&lt;/a&gt; где приведен пример параметров связывания Grid Search из экстрактора признаков текстовых документов (векторизатор подсчета n-граммов и преобразователь TF-IDF) с классификатором (здесь линейная SVM, обученная с помощью SGD с любой эластичной сеткой). или штраф L2) с использованием экземпляра &lt;code&gt;pipeline.Pipeline&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Матрица&lt;/a&gt; неточностей пример использования матрицы неточностей для оценки качества выходных данных классификатора.</target>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Оценка параметров с использованием поиска по сетке с перекрестной проверкой&amp;raquo;,&lt;/a&gt; где приведен пример использования &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt; для оценки параметров с помощью поиска по сетке с вложенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Оценка параметров с использованием поиска по сетке с перекрестной проверкой&amp;raquo;,&lt;/a&gt; где приведен пример вычисления поиска по сетке для набора данных цифр.</target>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Оценка параметров с использованием поиска по сетке с перекрестной проверкой,&lt;/a&gt; где приведен пример использования отчета классификации для поиска по сетке с вложенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="588e2a7cc51b06cfa971b7f26bd8bf4053207cf1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_refit_callable#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py&quot;&gt;Balance model complexity and cross-validated score&lt;/a&gt; for an example of using &lt;code&gt;refit=callable&lt;/code&gt; interface in &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. The example shows how this interface adds certain amount of flexibility in identifying the &amp;ldquo;best&amp;rdquo; estimator. This interface can also be used in multiple metrics evaluation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Демонстрацию оценки нескольких показателей в cross_val_score и GridSearchCV,&lt;/a&gt; где показан пример использования &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; для одновременной оценки нескольких показателей.</target>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="translated">См. Пример использования в разделе &amp;laquo; &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Демонстрация оценки нескольких показателей на cross_val_score и GridSearchCV&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Вложенная и не вложенная перекрестная проверка&lt;/a&gt; для примера поиска по сетке в цикле перекрестной проверки для набора данных радужной оболочки глаза. Это лучший метод оценки производительности модели с поиском по сетке.</target>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="translated">См. В разделе &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; пример использования &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; для оценки качества вывода классификатора.</target>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="translated">См. В разделе &amp;laquo; &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Рабочие характеристики приемника&amp;raquo; (ROC)&lt;/a&gt; пример использования ROC для оценки качества выходных данных классификатора.</target>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="translated">См. В разделе &amp;laquo; &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Рабочие характеристики приемника&amp;raquo; (ROC) с перекрестной проверкой&lt;/a&gt; пример использования ROC для оценки качества выходных данных классификатора с помощью перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Обнаружение выбросов с помощью локального фактора выброса (LOF)&lt;/a&gt; для иллюстрации использования &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Сравнение алгоритмов обнаружения аномалий для обнаружения выбросов в наборах данных игрушек&lt;/a&gt; для сравнения &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; с &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; , svm.OneClassSVM (настроен на работу как метод обнаружения выбросов) и обнаружения выбросов на основе &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; с covariance.EllipticEnvelope .</target>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Сравнение алгоритмов обнаружения аномалий для обнаружения выбросов в наборах данных игрушек&lt;/a&gt; для сравнения &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Сравнение алгоритмов обнаружения аномалий для обнаружения выбросов в наборах данных игрушек&lt;/a&gt; для сравнения с другими методами обнаружения аномалий.</target>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">Теоретическое объяснение леммы Джонсона-Линденштрауса и эмпирическую проверку с использованием разреженных случайных матриц см. &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;В&lt;/a&gt; разделе Граница Джонсона-Линденштрауса для вложения со случайными проекциями .</target>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">См. &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;Одноклассная SVM с нелинейным ядром (RBF)&lt;/a&gt; для визуализации границ, изученных вокруг некоторых данных с помощью объекта &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Классификация текстовых документов с использованием разреженных функций&lt;/a&gt; для примера использования &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; для классификации текстовых документов.</target>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Классификация текстовых документов с использованием разреженных функций,&lt;/a&gt; где приведен пример использования отчета о классификации для текстовых документов.</target>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Классификация текстовых документов с использованием разреженных функций,&lt;/a&gt; где приведен пример использования матрицы неточностей для классификации текстовых документов.</target>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="translated">См. Пример в разделе &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Определение нескольких показателей для оценки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="translated">См. &amp;laquo; &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Ближайшие соседи&amp;raquo;&lt;/a&gt; в онлайн-документации для обсуждения выбора &lt;code&gt;algorithm&lt;/code&gt; и &lt;code&gt;leaf_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91bb5f21ad92edefb7cd46dcdff8e31af1c98298" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on the pruning process.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="translated">См. Раздел &amp;laquo; &lt;a href=&quot;compose#combining-estimators&quot;&gt;Трубопроводы и составные оценщики&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Загрузка функций из dicts,&lt;/a&gt; чтобы узнать о категориальных функциях, которые представлены как dict, а не как скаляры.</target>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">См. &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;Здесь&lt;/a&gt; для получения дополнительной информации об этом наборе данных.</target>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">См. &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;Http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="translated">См. &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;laquo;Эффективные аддитивные ядра с помощью явных карт функций&amp;raquo;&lt;/a&gt; А. Ведальди и А. Зиссерман, Анализ шаблонов и машинный интеллект, 2011 г.</target>
        </trans-unit>
        <trans-unit id="8ccf3f09b07311e149a69a4c5ed81e792cfab2aa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="translated">См. &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;Здесь&lt;/a&gt; для получения дополнительной информации об этом наборе данных.</target>
        </trans-unit>
        <trans-unit id="eb3a5aff676c4d5166ca0015430772938f3b0abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee1e742783ffe82079419a7f74e91fb7300f9192" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="translated">Подробнее см. &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;Параметр оценки: определение правил оценки модели&lt;/a&gt; . В случае набора данных Iris выборки сбалансированы по целевым классам, поэтому точность и оценка F1 почти равны.</target>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="translated">См. Раздел &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Обнаружение&lt;/a&gt; новинок и выбросов для описания и использования OneClassSVM.</target>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="translated">См. &lt;code&gt;predict_proba&lt;/code&gt; для подробностей.</target>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="translated">См. Параметр &lt;code&gt;refit&lt;/code&gt; для получения дополнительной информации о допустимых значениях.</target>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="translated">См. Параметр &lt;code&gt;scoring&lt;/code&gt; чтобы узнать больше об оценке нескольких показателей.</target>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="translated">См.также:</target>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="translated">Подробнее о различных вариантах материнского ядра см.Расмуссен и Вильямс 2006,стр.84.</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">См.также</target>
        </trans-unit>
        <trans-unit id="319ca132af6f206834626d4c0565d67f882f0bf4" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;../../modules/tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on pruning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eddd8dfbe32e6e27a2f2d9692940c76ecde49164" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;neighbors#nca-dim-reduction&quot;&gt;Dimensionality reduction&lt;/a&gt; for dimensionality reduction with Neighborhood Components Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16d6db1c15da7e05f275e12f2b52c16bcc8dc1f7" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_permutation_importance#sphx-glr-auto-examples-inspection-plot-permutation-importance-py&quot;&gt;Permutation Importance vs Random Forest Feature Importance (MDI)&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="translated">См. Также &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Рекурсивное устранение признаков с перекрестной проверкой.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9232d9babf570066106c095c7f9e14cb2421acee" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_roc_curve_visualization_api#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py&quot;&gt;ROC Curve with Visualization API&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">См.также:</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="translated">См. Также: 1988 MLC Proceedings, 54-64. Концептуальная система кластеризации AUTOCLASS II Чизмана и др. Находит в данных 3 класса.</target>
        </trans-unit>
        <trans-unit id="96949ffbfe0e5b8e858a6b32bba0567fa5dcf8f9" translate="yes" xml:space="preserve">
          <source>See glossary entry for &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cross-validation-estimator&quot;&gt;cross-validation estimator&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ce8930e7f553fab96c5eb4cdba6059705f0a1b9" translate="yes" xml:space="preserve">
          <source>See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="translated">Полный список параметров см.в sklearn.svm.предсказать.</target>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="translated">См. &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;Графический интерфейс SVM,&lt;/a&gt; чтобы загрузить &lt;code&gt;svm_gui.py&lt;/code&gt; ; добавить точки данных обоих классов с помощью правой и левой кнопок, подогнать под модель и изменить параметры и данные.</target>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;сведения&lt;/a&gt; см. В разделе &amp;laquo;Оценка бикластеризации &amp;raquo; в руководстве пользователя.</target>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Оценка производительности кластеризации&amp;raquo;&lt;/a&gt; руководства пользователя.</target>
        </trans-unit>
        <trans-unit id="32e5d32ee9a61e6d932c5ca6a73a2f56a975703b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://scikit-learn.org/0.23/visualizations.html#visualizations&quot;&gt;Visualizations&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные &lt;a href=&quot;metrics#metrics&quot;&gt;сведения&lt;/a&gt; см. В разделе &amp;laquo; Парные метрики, сходства и ядра &amp;raquo; в руководстве пользователя.</target>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Метрики классификации&lt;/a&gt; &amp;raquo; руководства пользователя.</target>
        </trans-unit>
        <trans-unit id="a370028df0ac77d50f24c414c79435536844962d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Оценка модели: количественная оценка качества прогнозов&lt;/a&gt; &amp;raquo; и в разделе &amp;laquo; &lt;a href=&quot;metrics#metrics&quot;&gt;Парные метрики, сходства и ядра&lt;/a&gt; &amp;raquo; руководства пользователя.</target>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Метрики ранжирования Multilabel&lt;/a&gt; &amp;raquo; в руководстве пользователя.</target>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Метрики регрессии&lt;/a&gt; &amp;raquo; в руководстве пользователя.</target>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">Дополнительные сведения см. &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;В&lt;/a&gt; разделе &amp;laquo; Параметр оценки: определение правил оценки модели &amp;raquo; в руководстве пользователя.</target>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="translated">См. Вывод консоли для получения дополнительных сведений о каждой модели.</target>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="translated">Список доступных метрик см.в документации к DistanceMetric.</target>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="translated">Подробнее об этих метриках см.документацию по scipy.spatial.distance.</target>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">См. Документацию по scipy.spatial.distance для получения подробной информации об этих показателях: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="26decb2493981e4fa0291aaddd53d2d9f9052651" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">См. Примеры ниже и строку документации &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt; для получения дополнительной информации.</target>
        </trans-unit>
        <trans-unit id="21e6c58453c3a42f9380294c0c23f1e8e3252a3a" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3733f36a35b17995708cf55601d9baf4bb2149b" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="translated">См.примеры ниже для получения дополнительной информации.</target>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="translated">См.примеры такого применения.</target>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Видеть. &amp;laquo;Распознавание образов и машинное обучение&amp;raquo; К. Бишопа, 12.2.1 с. 574 или &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="translated">Посевной материал для генератора случайных чисел,используемый для оценки вероятности.0 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="translated">Посев осуществляется с использованием техники отбивания для масштабирования.</target>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="translated">Семена,используемые для инициализации ядер.Если параметр не установлен,семена вычисляются по методу clustering.get_bin_seeds с шириной полосы пропускания в качестве размера сетки и значениями по умолчанию для других параметров.</target>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="translated">Сегментирование изображения греческих монет в регионах</target>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="translated">Выберите случайные выборки &lt;code&gt;min_samples&lt;/code&gt; из исходных данных и проверьте, действителен ли набор данных (см. &lt;code&gt;is_data_valid&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="translated">Выберите собачий розгалик.Если n_компоненты намного меньше,чем количество тренировочных образцов,то арпак может быть более эффективным,чем плотный собачий рогалик.</target>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="translated">Выбирайте функции в соответствии с процентилем самых высоких баллов.</target>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="translated">Выбирайте функции в соответствии с k высшими баллами.</target>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="translated">Выберите функции на основе теста с ложноположительным результатом.</target>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="translated">Выбирайте функции на основе оценочного коэффициента ложного обнаружения.</target>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="translated">Выбирайте функции на основе семейного коэффициента ошибок.</target>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="translated">Выбирайте функции,основываясь на процентиле самых высоких баллов.</target>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="translated">Выбирайте функции на основе k самых высоких баллов.</target>
        </trans-unit>
        <trans-unit id="d3166439a7b0a709dd15d8647b0a1e23526bb82a" translate="yes" xml:space="preserve">
          <source>Select from the model features with the higest score</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="translated">Выберите n_samples integers из набора [0,n_population]без замены.</target>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="translated">Выберите алгоритм для решения двойной или основной задачи оптимизации. Предпочитать dual = False, когда n_samples&amp;gt; n_features.</target>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="translated">Выберите набор данных для загрузки: &amp;laquo;train&amp;raquo; для набора для обучения разработки, &amp;laquo;test&amp;raquo; для набора для тестирования для разработки и &amp;laquo;10_folds&amp;raquo; для официального оценочного набора, который предназначен для использования с 10-кратной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="translated">Выберите набор данных для загрузки: &amp;laquo;train&amp;raquo; для обучающего набора (23149 выборок), &amp;laquo;test&amp;raquo; для тестового набора (781265 образцов), &amp;laquo;all&amp;raquo; для обоих, с обучающими выборками в первую очередь, если shuffle имеет значение False. Это следует за официальным хронологическим разделением LYRL2004.</target>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="translated">Выберите набор данных для загрузки: &amp;laquo;обучение&amp;raquo; для обучающего набора, &amp;laquo;тест&amp;raquo; для набора тестов, &amp;laquo;все&amp;raquo; для обоих, с произвольным порядком.</target>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="translated">Выберите параметры,которые минимизируют примесь</target>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="translated">Выберите порцию для загрузки: &quot;поезд&quot;, &quot;тест&quot; или &quot;сырой&quot;.</target>
        </trans-unit>
        <trans-unit id="b97f498920dc9d14793f9ec22705c51c7828c05e" translate="yes" xml:space="preserve">
          <source>Select whether the regularization affects the components (H), the transformation (W), both or none of them.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="translated">Если выбрать &lt;code&gt;average=None&lt;/code&gt; будет возвращен массив с оценками для каждого класса.</target>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="translated">Выбор уменьшения размеров с помощью Трубопровода и GridSearchCV</target>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="translated">Выбор количества кластеров с анализом силуэтов на кластеризации KMeans</target>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">Выбирает алгоритм поиска сингулярных векторов. Может быть &quot;рандомизировано&quot; или &quot;arpack&quot;. Если &quot;рандомизировано&quot;, используйте &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; &lt;/a&gt; , что может быть быстрее для больших матриц. Если &amp;laquo;arpack&amp;raquo;, используйте &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt; &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; &lt;/a&gt; , который более точен, но, возможно, в некоторых случаях медленнее.</target>
        </trans-unit>
        <trans-unit id="fc3d3604d35f10ba0398acd746e6c18250ce369b" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">Выбирает алгоритм поиска сингулярных векторов. Может быть &quot;рандомизировано&quot; или &quot;arpack&quot;. Если &quot;рандомизировано&quot;, использует &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; , что может быть быстрее для больших матриц. Если 'arpack', использует &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; , который более точен, но, возможно, в некоторых случаях медленнее.</target>
        </trans-unit>
        <trans-unit id="90a62864642c982296e3e801c0e34e5e7f5e23e4" translate="yes" xml:space="preserve">
          <source>Semi Supervised Classification</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="translated">Длина спала</target>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="translated">Ширина спала</target>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="translated">Отделение линеек от линеек с помощью расстояния Махаланобиса</target>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="translated">Разделительная плоскость, описанная выше, была получена с использованием дерева методов с несколькими поверхностями (MSM-T) [Беннетт К.П., &amp;laquo;Построение дерева решений с помощью линейного программирования&amp;raquo;. Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], метод классификации, который использует линейное программирование для построения дерева решений. Релевантные объекты были отобраны путем исчерпывающего поиска в пространстве из 1-4 объектов и 1-3 разделяющих плоскостей.</target>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="translated">Строка-разделитель,используемая при построении новых функций для одноразового кодирования.</target>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="translated">Последовательность целочисленных меток или многомаркировочных данных для кодирования.</target>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">Последовательность передискретированных копий коллекций.Оригинальные массивы не пострадали.</target>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">Последовательность перетасовок копий коллекций.Оригинальные массивы не пострадали.</target>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">Последовательность весов ( &lt;code&gt;float&lt;/code&gt; или &lt;code&gt;int&lt;/code&gt; ) для взвешивания вхождений предсказанных меток классов ( &lt;code&gt;hard&lt;/code&gt; голосование) или вероятностей классов перед усреднением ( &lt;code&gt;soft&lt;/code&gt; голосование). Использование единых весов , если &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1b2a96243ee03211fb7854a57171cf92c85f5687" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted values before averaging. Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="translated">Последовательно применяйте список преобразований и окончательную оценку. Промежуточные этапы конвейера должны быть &amp;laquo;преобразованиями&amp;raquo;, то есть они должны реализовывать методы подгонки и преобразования. Окончательному оценщику нужно только реализовать подгонку. Трансформаторы в конвейере можно кэшировать с помощью аргумента &lt;code&gt;memory&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="translated">Установите &lt;code&gt;kernel='precomputed'&lt;/code&gt; и передайте матрицу Грама вместо X в методе подбора. На данный момент должны быть предоставлены значения ядра между &lt;em&gt;всеми&lt;/em&gt; обучающими векторами и тестовыми векторами.</target>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="translated">Установите для &lt;code&gt;n_clusters&lt;/code&gt; необходимое значение, используя &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="translated">Установите начальную начальную конфигурацию,случайным образом или нет.</target>
        </trans-unit>
        <trans-unit id="acdb8317b38cc1be24a0a9627d99a9301a5b666a" translate="yes" xml:space="preserve">
          <source>Set and validate the parameters of estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="translated">Установить глобальную научную конфигурацию</target>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Набор примеров,где n_samples-количество примеров,а n_features-количество функций.</target>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Установите для параметра C класса i значение &lt;code&gt;class_weight[i]*C&lt;/code&gt; для SVC. Если не указано иное, все классы должны иметь вес один. &amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов во входных данных как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="291ade590fbb6a8638dd1afb8f1376626f33f6ea" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Установите для параметра C класса i значение class_weight [i] * C для SVC. Если не указано иное, все классы должны иметь вес один. &amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">Установите для параметра C класса i значение class_weight [i] * C для SVC. Если не указано иное, все классы должны иметь вес один. &amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов во входных данных как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="translated">Установить параметры</target>
        </trans-unit>
        <trans-unit id="3f30532fe6a7a61216e1f94a622dfc009651d7c9" translate="yes" xml:space="preserve">
          <source>Set the parameters of an estimator from the ensemble.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="translated">Задайте параметры этой оценки.</target>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="translated">Задайте параметры этого ядра.</target>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="translated">Установите значение False для выполнения вычислений на месте во время преобразования.</target>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="translated">Установить в False для выполнения вычислений на месте.</target>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Установите значение False,чтобы выполнить нормализацию строк на месте и избежать копирования (если вход уже является массивом numpy).</target>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Установите значение False,чтобы выполнить масштабирование на месте и избежать копирования (если вход уже является нумерованным массивом).</target>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Установите значение False,чтобы выполнить трансформацию на месте и избежать копирования (если вход уже является массивом numpy).</target>
        </trans-unit>
        <trans-unit id="bbfbd49ae916b95e446b3c89c15541e5023cd4ad" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array). If True, a copy of &lt;code&gt;X&lt;/code&gt; is transformed, leaving the original &lt;code&gt;X&lt;/code&gt; unchanged</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="translated">Установите значение True,чтобы применить к преобразованному выходу нормализацию нулевого значения единичной величины.</target>
        </trans-unit>
        <trans-unit id="31263c2a03fef7d2c1e558ffe5e1f7ce22d5913e" translate="yes" xml:space="preserve">
          <source>Set to True, both W and H will be estimated from initial guesses. Set to False, only W will be estimated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="translated">Установите значение true,если выходной двоичный массив желателен в формате CSR с разрежением</target>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Устанавливает значение по умолчанию для &lt;code&gt;assume_finite&lt;/code&gt; аргумента &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Устанавливает значение по умолчанию для &lt;code&gt;working_memory&lt;/code&gt; аргумента &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="translated">Устанавливает семена глобального генератора случайных чисел при проведении испытаний для воспроизводимости.</target>
        </trans-unit>
        <trans-unit id="75bad9ccfc79ab0c0bbe60c8449ed7b0c754d17f" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division, i.e. when all predictions and labels are negative. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5785bcff96fce8eedf96c87581cbc35bae5756d5" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e057cbf5e19c7dcf916bf2fe2aa47295c10430c1" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="translated">Устанавливает количество глаголов</target>
        </trans-unit>
        <trans-unit id="0f757b166230d0f61e44fc2003ab4f4a4d10043d" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;generate_only=True&lt;/code&gt; returns a generator that yields (estimator, check) tuples where the check can be called independently from each other, i.e. &lt;code&gt;check(estimator)&lt;/code&gt;. This allows all checks to be run independently and report the checks that are failing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="translated">Установка значения True приводит к получению различных классификаторов и параметров классификаторов.</target>
        </trans-unit>
        <trans-unit id="924da9eef84794e1bcb0c0c5d50e7650f0dfc881" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e750c0ef44cf143b57f79a94939ea31cd10193d" translate="yes" xml:space="preserve">
          <source>Setting print_changed_only to True will alternate the representation of estimators to only show the parameters that have been set to non-default values. This can be used to have more compact representations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="translated">Задание параметра путем перекрестного подтверждения вероятности по трем сгибам в соответствии с сеткой параметров потенциальной усадки.</target>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="translated">Настройка параметров голосующего классификатора</target>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="translated">Несколько оценщиков в scikit-learn могут использовать информацию о связи между функциями или образцами. Например, кластеризация Уорда ( &lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;иерархическая кластеризация&lt;/a&gt; ) может кластеризовать вместе только соседние пиксели изображения, образуя таким образом непрерывные участки:</target>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="translated">Несколько функций позволяют анализировать точность,отзыв и оценку F-мер:</target>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="translated">Было разработано несколько методов для сравнения двух наборов бикластеров. В настоящее время только &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt; &lt;code&gt;consensus_score&lt;/code&gt; &lt;/a&gt; (.. Hochreiter и др, 2010) доступен:</target>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="translated">Несколько алгоритмов регрессии и бинарной классификации доступны в Scikit-learn.Простой способ расширить эти алгоритмы до многоклассового классификационного случая-использовать так называемую схему &quot;один-на-всех&quot;.</target>
        </trans-unit>
        <trans-unit id="0ac410486b823defe3030785e8a86edcf2b2b7e4" translate="yes" xml:space="preserve">
          <source>Severity Model - Gamma distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="translated">Форма массивов данных</target>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">Форма i-го бикластера.</target>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="translated">Форма будет [n_samples,1]для двоичных проблем.</target>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="translated">Сдвинуть функции на указанное значение.Если None,то функции сдвигаются на случайное значение,рисуемое в [-class_sep,class_sep].</target>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Смещен напротив коэффициента локального выброса X.</target>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="translated">Следует использовать,когда память неэффективна для обработки всех данных.Кусочки данных могут передаваться в несколько итераций,где при первом вызове должен быть массив всех целевых переменных.</target>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="translated">Следует использовать,когда память неэффективна для обработки всех данных.Кусочки данных можно передавать за несколько итераций.</target>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="translated">Ниже показаны границы решения классификаторов логистической регрессии по первым двум измерениям (длина и ширина чашелистика) набора данных &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;радужной оболочки глаза&lt;/a&gt; . Точки данных окрашены в соответствии с их метками.</target>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="translated">На графике показано,как логистическая регрессия в этом синтетическом наборе данных будет классифицировать значения как 0 или 1,т.е.класс один или два,используя логистическую кривую.</target>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="translated">Показывает,как усадка улучшает классификацию.</target>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="translated">Показывает, как использовать преобразователь функций в конвейере. Если вы знаете, что основной компонент вашего набора данных не имеет отношения к задаче классификации, вы можете использовать FunctionTransformer для выбора всех, кроме первого столбца преобразованных данных PCA.</target>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="translated">Показывает эффект коллинеарности в коэффициентах оценщика.</target>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="translated">Усадка и скудость с логистической регрессией</target>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="translated">Оценка ковариаций усадки:LedoitWolf против OAS и максимальная вероятность</target>
        </trans-unit>
        <trans-unit id="2e2068ed5693c53cc14ed41dc7c2ee819779a1f5" translate="yes" xml:space="preserve">
          <source>Shrinkage is a form of regularization used to improve the estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator, and shrinkage helps improving the generalization performance of the classifier. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id6&quot; id=&quot;id4&quot;&gt;2&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">Сжатие - это инструмент для улучшения оценки ковариационных матриц в ситуациях, когда количество обучающих выборок мало по сравнению с количеством функций. В этом сценарии ковариация эмпирической выборки является плохой оценкой. LDA усадки можно использовать, установив для параметра &lt;code&gt;shrinkage&lt;/code&gt; класса &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; значение &amp;laquo;auto&amp;raquo;. Это автоматически определяет оптимальный параметр усадки аналитическим способом, следуя лемме, введенной Ледуа и Вольфом &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; . Обратите внимание, что в настоящее время сжатие работает только при установке для параметра &lt;code&gt;solver&lt;/code&gt; &amp;laquo;lsqr&amp;raquo; или &amp;laquo;eigen&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="translated">Параметр усадки,возможные значения:</target>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="translated">Ковариант &quot;Шранк&quot;.</target>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="translated">последовательно перемешивать массивы или разрозненные матрицы</target>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="translated">Перетасуйте образцы и особенности.</target>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="translated">Перетасуйте образцы.</target>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="translated">Итератор перекрестной проверки в тасках</target>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="translated">Знаковое расстояние является положительным для коэффициента усиления и отрицательным для коэффициента усиления.</target>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="translated">Подписанное расстояние до разделяющей гиперплоскости.</target>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="translated">Коэффициент силуэта для каждого образца.</target>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="translated">Анализ силуэта может быть использован для изучения расстояния между полученными кластерами.Силуэт-график показывает,насколько близко каждая точка в одном кластере к точкам в соседних кластерах,и,таким образом,дает возможность визуально оценить такие параметры,как количество кластеров.Эта мера имеет диапазон [-1,1].</target>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="translated">Коэффициенты силуэта (как эти значения называются)вблизи +1 указывают на то,что выборка находится далеко от соседних кластеров.Значение 0 означает,что выборка находится на границе принятия решения между двумя соседними кластерами или очень близко к ней,а отрицательные значения указывают на то,что эти выборки могли быть назначены не тому кластеру.</target>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="translated">Аналогичные экстракторы функций должны быть созданы для других типов неструктурированных данных, таких как изображения, аудио, видео и т. Д.</target>
        </trans-unit>
        <trans-unit id="9be20d5d3cad647d5b5693ebaedd1ee1a23948cc" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; but only a single metric is permitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="translated">Аналогично AgglomerativeClustering,но рекурсивно объединяет свойства вместо образцов.</target>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="translated">Аналогично NuSVC,для регрессии используется параметр nu для управления количеством векторов поддержки.Однако,в отличие от NuSVC,где nu заменяет C,здесь nu заменяет параметр epsilon epsilon-SVR.</target>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="translated">Аналогично SVC,но использует параметр для управления количеством векторов поддержки.</target>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">Подобен SVC с параметром kernel = 'linear', но реализован в терминах liblinear, а не libsvm, поэтому он имеет большую гибкость в выборе функций штрафов и потерь и должен лучше масштабироваться для большого количества выборок.</target>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">Подобен SVR с параметром kernel = 'linear', но реализован в терминах liblinear, а не libsvm, поэтому он имеет большую гибкость в выборе функций штрафов и потерь и должен лучше масштабироваться для большого количества выборок.</target>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="translated">Как и другие алгоритмы форсирования,GBRT строит аддитивную модель поэтапно:</target>
        </trans-unit>
        <trans-unit id="76a1a1878f09aac58b35d999b125160a70440000" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms, a GBRT is built in a greedy fashion:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="translated">Вычисляется сходство между отдельными библъюстерами.Затем с помощью венгерского алгоритма найдено наилучшее совпадение между сетами.Окончательный результат представляет собой сумму сходств,разделенную на размер большего множества.</target>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="translated">Счетчик сходства между -1.0 и 1.0.Случайные обозначения имеют ARI близкий к 0.0.1.0 означает идеальное совпадение.</target>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">Точно так же &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt; &lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt; &lt;/a&gt; повторяет стратифицированный K-Fold n раз с разной рандомизацией в каждом повторении.</target>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="translated">Аналогичным образом,регуляризованная логистическая регрессия L1 решает следующую задачу оптимизации</target>
        </trans-unit>
        <trans-unit id="904046bd05dcb9fe24c66e7942e9a89936649854" translate="yes" xml:space="preserve">
          <source>Similarly, \(\ell_1\) regularized logistic regression solves the following optimization problem:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8ee1f0c1cff57e37c89253984120399103de69b" translate="yes" xml:space="preserve">
          <source>Similarly, a negative monotonic constraint is of the form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="translated">Аналогичным образом,метки,не присутствующие в выборке данных,могут быть учтены в макроусреднении.</target>
        </trans-unit>
        <trans-unit id="de3a0306d5f9d4f628a86437bd31f501c79f2495" translate="yes" xml:space="preserve">
          <source>Similarly, the precision recall curve can be plotted using &lt;code&gt;y_score&lt;/code&gt; from the prevision sections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="translated">Простая 1D оценка ядерной плотности</target>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="translated">Просто понять и интерпретировать.Деревья можно визуализировать.</target>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="translated">Простое использование Конвейера,который последовательно запускает одномерное выделение функций с помощью anova,а затем C-SVM выделенных функций.</target>
        </trans-unit>
        <trans-unit id="e7766eb7ad8cfdfa67609d5277fb9ac991ed77ce" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a SVM of the selected features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="translated">Простое использование вспомогательных векторных машин для классификации образца.Она построит диаграмму поверхности принятия решения и векторов поддержки.</target>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="translated">Простое использование различных алгоритмов перекрестной декомпозиции:-PLSCanonical-PLSRegression,с многомерным ответом,a.k.a.PLS2-PLSRegression,с одномерным ответом,a.k.a.PLS1-CCA</target>
        </trans-unit>
        <trans-unit id="da21ac2a81c42a0cc34c3a8c8243f3f710d2f668" translate="yes" xml:space="preserve">
          <source>SimpleImputer</source>
          <target state="translated">SimpleImputer</target>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="translated">Просто выполните svd для матрицы кросс-ковариации: X'Y Здесь нет итеративного дефляции.</target>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="translated">Так как \(P(x_1,\dots,x_n)\)является константой при входе,то можно использовать следующее правило классификации:</target>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="translated">Поскольку внутреннее представление модели может отличаться на двух разных архитектурах,демпинг модели на одной архитектуре и ее загрузка на другую архитектуру не поддерживается.</target>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="translated">Поскольку для преобразования хеш-функции в индекс столбца используется простой модуль по модулю, рекомендуется использовать степень двойки в качестве параметра &lt;code&gt;n_features&lt;/code&gt; ; в противном случае элементы не будут отображаться равномерно по столбцам.</target>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">Поскольку он требует соответствия &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; , этот метод обычно медленнее, чем один против остальных, из-за его сложности O (n_classes ^ 2). Однако этот метод может быть &lt;code&gt;n_samples&lt;/code&gt; для таких алгоритмов, как алгоритмы ядра, которые плохо масштабируются с n_samples . Это связано с тем, что каждая отдельная задача обучения включает в себя только небольшое подмножество данных, тогда как при использовании одного по сравнению с остальными весь набор данных используется &lt;code&gt;n_classes&lt;/code&gt; раз.</target>
        </trans-unit>
        <trans-unit id="d70a1912c85de6341311b3ee0902966d17cafa41" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times. The decision function is the result of a monotonic transformation of the one-versus-one classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="translated">Так как наша функция потерь зависит от количества образцов, последний будет влиять на выбранное значение &lt;code&gt;C&lt;/code&gt; . Возникает вопрос: &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="translated">Так как рекурсивное разбиение может быть представлено древовидной структурой,то количество разбиений,необходимое для изоляции выборки,эквивалентно длине пути от корневого до конечного узла.</target>
        </trans-unit>
        <trans-unit id="e0effd5f72f2afc7c618332a9b819d624a406e57" translate="yes" xml:space="preserve">
          <source>Since the L1 norm promotes sparsity of features we might be interested in selecting only a subset of the most interesting features from the dataset. This example shows how to select two the most interesting features from the diabetes dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53564a374f656b4eebc264b9099b9cd10a25ad1a" translate="yes" xml:space="preserve">
          <source>Since the Poisson regressor internally models the log of the expected target value instead of the expected value directly (log vs identity link function), the relationship between X and y is not exactly linear anymore. Therefore the Poisson regressor is called a Generalized Linear Model (GLM) rather than a vanilla linear model as is the case for Ridge regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="translated">Поскольку хеш-функция может вызвать конфликты между (несвязанными) функциями, используется хеш-функция со знаком, и знак значения хеш-функции определяет знак значения, хранящегося в выходной матрице для функции. Таким образом, коллизии, скорее всего, будут отменять, а не накапливать ошибку, и ожидаемое среднее значение любого выходного значения функции равно нулю. Этот механизм включен по умолчанию с помощью &lt;code&gt;alternate_sign=True&lt;/code&gt; и особенно полезен для небольших размеров хэш-таблиц ( &lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt; ). Для больших размеров хэш-таблиц его можно отключить, чтобы выходные данные передавались в средства оценки, такие как &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt; &lt;/a&gt; селекторам функций, которые ожидают неотрицательные входные данные.</target>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="translated">Так как ядро,которое должно быть аппроксимировано,является аддитивным,компоненты входных векторов могут быть обработаны отдельно.Каждая запись в исходном пространстве преобразуется в 2*sample_steps+1 признак,где sample_steps является параметром метода.Типичные значения sample_steps включают 1,2 и 3.</target>
        </trans-unit>
        <trans-unit id="eab55792648442f25c33ef137afa5ea98f14550a" translate="yes" xml:space="preserve">
          <source>Since the linear predictor \(Xw\) can be negative and Poisson, Gamma and Inverse Gaussian distributions don&amp;rsquo;t support negative values, it is necessary to apply an inverse link function that guarantees the non-negativeness. For example with &lt;code&gt;link='log'&lt;/code&gt;, the inverse link function becomes \(h(Xw)=\exp(Xw)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="translated">Поскольку апостериор неразрешим,вариационный байесовский метод использует более простое распределение \(q(z,\theta,\beta | \lambda,\phi,\gamma)\)для аппроксимации,и эти вариационные параметры \(\lambda\),\(\phi\),\(\gamma\)оптимизированы,чтобы максимизировать Evidence Lower Bound (ELBO):</target>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="translated">Поскольку пороговые значения отсортированы от низких до высоких значений, они меняются местами при возврате, чтобы гарантировать, что они соответствуют как &lt;code&gt;fpr&lt;/code&gt; ,так и &lt;code&gt;tpr&lt;/code&gt; , которые сортируются в обратном порядке во время их расчета.</target>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="translated">Так как эмпирической работы по примерным встраиваниям было мало,желательно по возможности сравнивать результаты с точными методами ядра.</target>
        </trans-unit>
        <trans-unit id="181ed345f14e5249ac33bd9934643c4f9dd72c8f" translate="yes" xml:space="preserve">
          <source>Since v0.21, if &lt;code&gt;input&lt;/code&gt; is &lt;code&gt;filename&lt;/code&gt; or &lt;code&gt;file&lt;/code&gt;, the data is first read from the file and then passed to the given callable analyzer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="translated">Одиночная оценка по сравнению с мешковиной:разложение по смещению-изменению</target>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="translated">Оценка единой метрики с использованием &lt;code&gt;cross_validate&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="translated">Одиночная, средняя и полная связь может использоваться с различными расстояниями (или сходствами), в частности евклидовым расстоянием ( &lt;em&gt;l2&lt;/em&gt; ), манхэттенским расстоянием (или Cityblock, или &lt;em&gt;l1&lt;/em&gt; ), косинусным расстоянием или любой предварительно вычисленной матрицей аффинности.</target>
        </trans-unit>
        <trans-unit id="b1a526a4c2ab5cc879cbcf97bbdfc6e58be65f64" translate="yes" xml:space="preserve">
          <source>Singular values of &lt;code&gt;X&lt;/code&gt;. Only available when &lt;code&gt;X&lt;/code&gt; is dense.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="409f99dea48046b433f18bebd495f19a0bb51787" translate="yes" xml:space="preserve">
          <source>Singularities</source>
          <target state="translated">Singularities</target>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="translated">Размер мини-пакетов для стохастических оптимизаторов. Если решателем является lbfgs, классификатор не будет использовать мини-пакет. Когда установлено значение &amp;laquo;auto&amp;raquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7241ed1ae94944f10d565b9b8502a2569d69bebc" translate="yes" xml:space="preserve">
          <source>Size of text font. If None, determined automatically to fit figure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">Размер блоков,на которые будет разделена ковариационная матрица во время ее оценки Ледойт-Вульф.Это чисто оптимизация памяти и не влияет на результаты.</target>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">Размер блоков,на которые будет разделена ковариационная матрица.Это чисто оптимизация памяти и не влияет на результаты.</target>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="translated">Размер мини-партий.</target>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="translated">Размер возвращаемого массива</target>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="translated">Размер тестовых наборов.</target>
        </trans-unit>
        <trans-unit id="3ede3a7d9dde54c062e45da23a9dc65bbb39cbbf" translate="yes" xml:space="preserve">
          <source>Size of the test sets. Must be strictly less than the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="translated">Пропустить проверки подтверждения входа,включая матрицу Грама при условии,что она обрабатывается вызывающим абонентом при check_input=False.</target>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="translated">Слайды,объясняющие PLS</target>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="translated">Небольшие отклонения</target>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">Небольшие положительные значения альфа улучшают обусловленность проблемы и уменьшают дисперсию оценок. Альфа соответствует &lt;code&gt;(2*C)^-1&lt;/code&gt; в других линейных моделях, таких как LogisticRegression или LinearSVC. Если передан массив, предполагается, что штрафы зависят от целей. Следовательно, они должны совпадать по количеству.</target>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="translated">Меньшие значения приводят к лучшему встраиванию и большему количеству размеров (n_компонент)в целевое проекционное пространство.</target>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="translated">Наименьшее из рассмотренных значений альфа/альфа_макса</target>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="translated">Гладкий idf вес,добавив один к частоте документа,как если бы дополнительный документ был виден,содержащий каждый термин в коллекции ровно один раз.Предотвращает нулевое деление.</target>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="translated">Сглаженная эмпирическая вероятность журнала для каждого класса.</target>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="translated">Сглаженная эмпирическая вероятность журнала для каждого класса.Используется только в крайнем случае с одним классом в тренировочном комплекте.</target>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="translated">Классификатор &quot;мягкого&quot; голосования/правило большинства для неподходящих оценок.</target>
        </trans-unit>
        <trans-unit id="3c16977f20db1a9e128b2062c246165103dd7921" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="translated">Мягкая подсказка для выбора серверной части по умолчанию, если с помощью контекстного менеджера parallel_backend не была выбрана конкретная внутренняя часть. Бэкэнд на основе процессов по умолчанию - &amp;laquo;локальный&amp;raquo;, а бэкэнд на основе потоков по умолчанию - &amp;laquo;потоки&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="7472593b6d35821b7f5c4104f85f3418ec74c28e" translate="yes" xml:space="preserve">
          <source>Solution to the non-negative least squares problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Решение: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Решение: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8dc243287f9af0458afdd79c7e208cb930e6e9d1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/91f0cd01beb5b964a5e1ece5bdd15499/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5a155c549be47525e0ef469c6ede18a502d5bc6" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/bfcebce45024b267e8546d6914acfedc/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="908bab59b18307a14acc0f3d3e00d2c36c09b88e" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="translated">Разрешите модель изотонической регрессии:</target>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="translated">Решить уравнение гребня методом нормальных уравнений.</target>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="translated">Решение для использования в вычислительных рутинах:</target>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="translated">Решение для использования,возможные значения:</target>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="translated">Решает задачу факторизации матрицы обучения словарю в режиме онлайн.</target>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="translated">Решает задачу факторизации матрицы обучения словарю.</target>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="translated">Решает задачи ортогонального поиска соответствия n_targets,используя только грамм-матрицу X.T*X и продукт X.T*y.</target>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="translated">Решает задачи ортогонального поиска соответствия n_targets.Экземпляр проблемы имеет форму:</target>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="translated">Решает задачу оптимизации:</target>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="translated">Некоторые преимущества деревьев принятия решений:</target>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="translated">Некоторые также работают в многомаркировочном корпусе:</target>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="translated">Некоторые вычисления, реализованные с использованием стандартных векторных операций numpy, включают использование большого количества временной памяти. Это может потенциально исчерпать системную память. В тех случаях, когда вычисления могут выполняться в блоках с фиксированной памятью, мы пытаемся это сделать и позволяем пользователю &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt; максимальный размер этой рабочей памяти (по умолчанию 1 ГБ) с помощью sklearn.set_config или &lt;code&gt;config_context&lt;/code&gt; . Ниже предлагается ограничить временную рабочую память до 128 МБ:</target>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="translated">Некоторые проблемы классификации могут показывать большой дисбаланс в распределении целевых классов: например, отрицательных проб может быть в несколько раз больше, чем положительных. В таких случаях рекомендуется использовать стратифицированную выборку, реализованную в &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt; &lt;code&gt;StratifiedShuffleSplit&lt;/code&gt; ,&lt;/a&gt; чтобы гарантировать, что относительная частота классов приблизительно сохраняется в каждой последовательности и валидации.</target>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="translated">Некоторые итераторы перекрестной проверки, такие как &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; , имеют встроенную возможность перетасовать индексы данных перед их разделением. Обратите внимание, что:</target>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="translated">Некоторые оценщики предоставляют метод &lt;code&gt;transform&lt;/code&gt; , например, для уменьшения размерности набора данных.</target>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">В некоторой литературе предлагаются альтернативные определения сбалансированной точности. Наше определение эквивалентно &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; со сбалансированными по классам весами выборки и разделяет желаемые свойства с двоичным регистром. См. &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;Руководство пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="translated">Некоторые метрики по существу определены для задач двоичной классификации (например, &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; ). В этих случаях по умолчанию оценивается только положительная метка, предполагая по умолчанию, что положительный класс помечен как &lt;code&gt;1&lt;/code&gt; (хотя это можно настроить с помощью параметра &lt;code&gt;pos_label&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="translated">Некоторые модели допускают специализированные, эффективные стратегии поиска параметров, &lt;a href=&quot;#alternative-cv&quot;&gt;описанные ниже&lt;/a&gt; . В scikit-learn представлены два общих подхода к выборке кандидатов для поиска: для заданных значений &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; исчерпывающе рассматривает все комбинации параметров, а &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; может выполнять выборку заданного количества кандидатов из пространства параметров с указанным распределением. После описания этих инструментов мы подробно рассмотрим &lt;a href=&quot;#grid-search-tips&quot;&gt;передовой опыт,&lt;/a&gt; применимый к обоим подходам.</target>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="translated">Некоторые модели также имеют &lt;code&gt;row_labels_&lt;/code&gt; и &lt;code&gt;column_labels_&lt;/code&gt; . Эти модели разделяют строки и столбцы, например, в блочно-диагональных и бикластерных структурах шахматной доски.</target>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="translated">Некоторые модели могут подбирать данные для диапазона значений некоторого параметра почти так же эффективно,как и подбирать оценочное устройство для одного значения параметра.Эту функцию можно использовать для более эффективной перекрестной проверки,используемой для выбора модели этого параметра.</target>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="translated">Некоторые модели могут предложить информационно-теоретическую замкнутую формулу оптимальной оценки параметра регуляризации путем вычисления одного пути регуляризации (а не нескольких при использовании перекрестной проверки).</target>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="translated">Некоторые из кластеров,изученные без ограничений по подключению,не учитывают структуру швейцарского валика и простираются через различные складки коллекторов.Напротив,при противоположных ограничениях связности,кластеры образуют красивую парцелляцию швейцарского валика.</target>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="translated">Некоторые из них ограничены случаем бинарной классификации:</target>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="translated">Некоторые другие классификаторы лучше справляются с этой более сложной версией задачи. Попробуйте запустить &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;пример конвейера для извлечения и оценки текстовых функций&lt;/a&gt; с параметром &lt;code&gt;--filter&lt;/code&gt; и без него, чтобы сравнить результаты.</target>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="translated">Некоторые настройки параметров могут привести к невозможности &lt;code&gt;fit&lt;/code&gt; одну или несколько складок данных. По умолчанию это приведет к сбою всего поиска, даже если некоторые настройки параметров могут быть полностью оценены. Установка &lt;code&gt;error_score=0&lt;/code&gt; (или &lt;code&gt;=np.NaN&lt;/code&gt; ) сделает процедуру устойчивой к такому отказу, выдаст предупреждение и установит счет для этой свертки на 0 (или &lt;code&gt;NaN&lt;/code&gt; ), но завершит поиск.</target>
        </trans-unit>
        <trans-unit id="2f1168d7fab23533f7c212613fc87fe5fb99b1b4" translate="yes" xml:space="preserve">
          <source>Some scikit-learn estimators and utilities can parallelize costly operations using multiple CPU cores, thanks to the following components:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="translated">Несколько советов и хитростей:</target>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="translated">Иногда может быть полезно преобразовать данные обратно в исходное пространство функций. Функция &lt;code&gt;inverse_transform&lt;/code&gt; преобразует объединенные данные в исходное пространство признаков. Каждое значение будет равно среднему значению двух краев бина.</target>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="translated">Иногда рассмотрение изученных коэффициентов нейронной сети может дать представление об учебном поведении.Например,если веса выглядят неструктурированными,может быть,некоторые из них вообще не использовались,или если существуют очень большие коэффициенты,может быть,регуляризация была слишком низкой или скорость обучения слишком высокой.</target>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">Исходный URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8173b56b5b02e6dc31d6c2059fb643537f89144d" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">Источники,где n_samples-количество отсчетов,а n_components-количество компонентов.</target>
        </trans-unit>
        <trans-unit id="3af0ce95ad1f86c8c1749c4ae38a0dba87aebcff" translate="yes" xml:space="preserve">
          <source>Sparse Principal Component Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="translated">Анализ разделения основных компонентов (SparsePCA)</target>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="translated">Раздельное кодирование</target>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="translated">Раздельное кодирование с предварительно составленным словарем</target>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="translated">Извлеченные из данных отдельные компоненты.</target>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="translated">Раздельный ввод</target>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="translated">Обратная ковариационная оценка разделения</target>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="translated">Раздельная оценка обратных ковариаций с l1-пенализированной оценкой.</target>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="translated">Раздельная обратная ковариация ж/перекрёстное подтверждение выбора штрафа l1</target>
        </trans-unit>
        <trans-unit id="0113e7df66bdaa38179e1b6944e6cd1aa2f5ffce" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="translated">Разделение основных компонентов дает более скупое,интерпретируемое представление,четко подчеркивая,какие из исходных особенностей способствуют различиям между выборками.</target>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">Раздельные случайные матрицы являются альтернативой плотной гауссовской матрице случайной проекции,которая гарантирует аналогичное качество встраивания при гораздо более эффективном использовании памяти и позволяет быстрее вычислять проектируемые данные.</target>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">Раздельная случайная матрица является альтернативой плотной случайной проекционной матрице,которая гарантирует аналогичное качество встраивания при гораздо более эффективном использовании памяти и позволяет быстрее вычислять проектируемые данные.</target>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="translated">Пример скупости:Устанавливаются только функции 1 и 2</target>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="translated">Контрольный параметр Спарсити.</target>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="translated">Контрольный параметр Спарсити.Более высокие значения приводят к образованию редкостных компонентов.</target>
        </trans-unit>
        <trans-unit id="49f74e244eb107a1663f4aabb4f4ff9cbf7f050c" translate="yes" xml:space="preserve">
          <source>Spatial indexing trees are used to avoid calculating the full distance matrix, and allow for efficient memory usage on large sets of samples. Different distance metrics can be supplied via the &lt;code&gt;metric&lt;/code&gt; keyword.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="translated">Моделирование распределения видов</target>
        </trans-unit>
        <trans-unit id="57d730dfe1585d0d57e966c58e133370714f1563" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. &lt;code&gt;set_params(parameter_name=new_value)&lt;/code&gt;. In addition, to setting the parameters of the stacking estimator, the individual estimator of the stacking estimators can also be set, or can be removed by setting them to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="translated">Конкретные параметры с использованием, например, set_params (parameter_name = new_value) В дополнение к настройке параметров &lt;code&gt;VotingClassifier&lt;/code&gt; , отдельные классификаторы &lt;code&gt;VotingClassifier&lt;/code&gt; также могут быть установлены или заменены, установив для них значение None.</target>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="translated">Каждому классификатору можно присвоить определенные веса с помощью параметра &lt;code&gt;weights&lt;/code&gt; . Когда предоставляются веса, прогнозируемые вероятности классов для каждого классификатора собираются, умножаются на вес классификатора и усредняются. Затем последняя метка класса получается из метки класса с наивысшей средней вероятностью.</target>
        </trans-unit>
        <trans-unit id="68354cd532978d44f7b8a2998caa562af7db6244" translate="yes" xml:space="preserve">
          <source>Specifically, here the input variables are some gene sequences stored as variable-length strings consisting of letters &amp;lsquo;A&amp;rsquo;, &amp;lsquo;T&amp;rsquo;, &amp;lsquo;C&amp;rsquo;, and &amp;lsquo;G&amp;rsquo;, while the output variables are floating point numbers and True/False labels in the regression and classification tasks, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40c186465110b1329791125cf6cae8eb6f471442" translate="yes" xml:space="preserve">
          <source>Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into a neural network or an unregularized regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="translated">Определяет, как решаются проблемы классификации нескольких классов. Поддерживаются &amp;laquo;one_vs_rest&amp;raquo; и &amp;laquo;one_vs_one&amp;raquo;. В &amp;laquo;one_vs_rest&amp;raquo; для каждого класса установлен один двоичный гауссовский классификатор процессов, который обучен отделить этот класс от остальных. В &amp;laquo;one_vs_one&amp;raquo; для каждой пары классов устанавливается один двоичный гауссовский классификатор процессов, который обучен разделять эти два класса. Прогнозы этих двоичных предикторов объединяются в многоклассовые предсказания. Обратите внимание, что &amp;laquo;one_vs_one&amp;raquo; не поддерживает прогнозирование оценок вероятности.</target>
        </trans-unit>
        <trans-unit id="e7bd9f102fbfd80a2ad8d309cf0a9504bc2caee0" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;lsquo;one_vs_rest&amp;rsquo; and &amp;lsquo;one_vs_one&amp;rsquo;. In &amp;lsquo;one_vs_rest&amp;rsquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;lsquo;one_vs_one&amp;rsquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;lsquo;one_vs_one&amp;rsquo; does not support predicting probability estimates.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="translated">Указывает,следует ли добавлять к функции принятия решения константу (так же известную как смещение или перехват).</target>
        </trans-unit>
        <trans-unit id="9cc5cb93f212cfc9a20617982597c3fd3b14a01a" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor (X @ coef + intercept).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="translated">Указывает,хранится ли оценочная точность.</target>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="translated">Указывает,должен ли перехватчик быть установлен на модели.Он должен соответствовать параметру метода fit().</target>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="translated">Задает тип ядра, который будет использоваться в алгоритме. Он должен быть одним из &quot;linear&quot;, &quot;poly&quot;, &quot;rbf&quot;, &quot;sigmoid&quot;, &quot;precomputed&quot; или вызываемый. Если ничего не указано, будет использоваться rbf. Если задан вызываемый объект, он используется для предварительного вычисления матрицы ядра из матриц данных; эта матрица должна быть массивом формы &lt;code&gt;(n_samples, n_samples)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="translated">Задает тип ядра, который будет использоваться в алгоритме. Он должен быть одним из &quot;linear&quot;, &quot;poly&quot;, &quot;rbf&quot;, &quot;sigmoid&quot;, &quot;precomputed&quot; или вызываемый. Если ничего не указано, будет использоваться rbf. Если задан вызываемый объект, он используется для предварительного вычисления матрицы ядра.</target>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="translated">Задает функцию потерь. &amp;laquo;шарнир&amp;raquo; - это стандартные потери SVM (используемые, например, классом SVC), а &amp;laquo;squared_hinge&amp;raquo; - это квадрат потерь в шарнирах.</target>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="translated">Задает функцию потерь. Нечувствительные к эпсилону потери (стандартный SVR) - это потери L1, тогда как квадратные нечувствительные к эпсилону потери ('squared_epsilon_insensitive') - это потери L2.</target>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="translated">Задает функцию потерь. С &quot;squared_hinge&quot; это квадрат шарнира потери (также известный как потеря L2). В случае &amp;laquo;журнала&amp;raquo; это потеря моделей логистической регрессии.</target>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="translated">Задает норму, используемую при наложении штрафов. Штраф &amp;laquo;l2&amp;raquo; - это стандарт, используемый в SVC. 'L1' приводит к &lt;code&gt;coef_&lt;/code&gt; векторам coef_ .</target>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="translated">Задает возвращаемую модель. Выберите &lt;code&gt;'lar'&lt;/code&gt; для регрессии наименьшего угла, &lt;code&gt;'lasso'&lt;/code&gt; для лассо.</target>
        </trans-unit>
        <trans-unit id="ef557ab8128f60634f92721dd7b48ce0309e1238" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. For regressors this parameter is ignored and the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. By default, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and we revert to &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; if it doesn&amp;rsquo;t exist. If &lt;code&gt;method&lt;/code&gt; is &amp;lsquo;recursion&amp;rsquo;, the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4eb03b762d72883fa3052fd37abd9dd63a6ceb00" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. If set to &amp;lsquo;auto&amp;rsquo;, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and if it does not exist &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; is tried next.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Укажите папку для загрузки и кеширования наборов данных. Если None, все данные scikit-learn хранятся в подпапках '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Укажите папку для загрузки и кеширования наборов данных. Если Нет, все данные scikit-learn хранятся в подпапках '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Укажите другую папку для загрузки и кеширования наборов данных. По умолчанию все данные scikit-learn хранятся в подпапках '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">Укажите другую папку для загрузки и кеширования наборов данных. По умолчанию все данные scikit-learn хранятся в подпапках '~ / scikit_learn_data'.</target>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="translated">Укажите другую папку для загрузки и кеширования наборов данных. По умолчанию все данные scikit-learn хранятся в подпапках '~ / scikit_learn_data'. .. добавлена ​​версия :: 0.19</target>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="translated">Укажите,хранится ли оценочная точность</target>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="translated">Укажите,хранится ли оценочная точность.</target>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="translated">Укажите имя столбца в данных для использования в качестве цели. Если &quot;default-target&quot;, используется стандартный целевой столбец a, хранящийся на сервере. Если &lt;code&gt;None&lt;/code&gt; , все столбцы возвращаются как данные, а цель - &lt;code&gt;None&lt;/code&gt; . Если список (строк), все столбцы с этими именами возвращаются как многоцелевые (Примечание: не все классификаторы scikit-learn могут обрабатывать все типы комбинаций с несколькими выходами)</target>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="translated">Укажите желаемый относительный и абсолютный допуск результата. Если истинный результат - K_true, то возвращаемый результат K_ret удовлетворяет &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; По умолчанию для обоих используется ноль (то есть машинная точность).</target>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="translated">Укажите размер листа лежащего в основе дерева. См. &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; для подробностей. По умолчанию 40.</target>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="translated">Укажите реализацию бэкэнда распараллеливания.Поддерживаются бэкэнды:</target>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="translated">Укажите размер кэша ядра (в мегабайтах).</target>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="translated">Укажите,какие функции рассматриваются как категорические.</target>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="translated">Укажите,должны ли существовать все или любой из данных атрибутов.</target>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="translated">Указание того, как следует выбирать параметры, выполняется с помощью словаря, очень похоже на указание параметров для &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; . Кроме того, бюджет вычислений, являющийся количеством выбранных кандидатов или итераций выборки, указывается с &lt;code&gt;n_iter&lt;/code&gt; параметра n_iter . Для каждого параметра можно указать либо распределение по возможным значениям, либо список дискретных вариантов (которые будут выбираться равномерно):</target>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="translated">Указание набора данных по имени &amp;laquo;iris&amp;raquo; дает самую низкую версию, версию 1, с &lt;code&gt;data_id&lt;/code&gt; 61. Чтобы всегда получать именно этот набор данных, безопаснее всего указать его с помощью набора данных &lt;code&gt;data_id&lt;/code&gt; . Другой набор данных с &lt;code&gt;data_id&lt;/code&gt; 969 - это версия 3 (версия 2 стала неактивной) и содержит бинаризованную версию данных:</target>
        </trans-unit>
        <trans-unit id="a7781532fac864d69f63a26a8d414fddcb049d3b" translate="yes" xml:space="preserve">
          <source>Specifying the value of the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; attribute will trigger the use of cross-validation with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;, for example &lt;code&gt;cv=10&lt;/code&gt; for 10-fold cross-validation, rather than Generalized Cross-Validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="translated">Спектральную кластеризацию также можно использовать для кластеризации графов путем их спектральных вложений. В этом случае матрица аффинности является матрицей смежности графа, а SpectralClustering инициализируется с &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="e698832cd5821ea0f1db5828f5b72aad63c46c00" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to partition graphs via their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity='precomputed'&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="translated">Алгоритм спектрального со-клестера (Дхиллон,2001).</target>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="translated">Спектральное вложение (Laplacian Eigenmaps)наиболее полезно,когда граф имеет один подключенный компонент.Если граф имеет много компонентов,то первые несколько собственных векторов просто обнаружат подключенные компоненты графа.</target>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Спектральное вложение - это подход к вычислению нелинейного вложения. Scikit-learn реализует лапласианские собственные карты, которые находят низкоразмерное представление данных с использованием спектрального разложения лапласиана графа. Сгенерированный граф можно рассматривать как дискретную аппроксимацию многообразия низкой размерности в пространстве высокой размерности. Минимизация функции стоимости на основе графика гарантирует, что точки, близкие друг к другу на многообразии, отображаются близко друг к другу в низкоразмерном пространстве, сохраняя локальные расстояния. Спектральное вложение может быть выполнено с помощью функции &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt; &lt;code&gt;spectral_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt; &lt;code&gt;SpectralEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="translated">Спектральная билюстрация (Клюгер,2003).</target>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="translated">Спектральные алгоритмы билюстрации.</target>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="translated">Спектральная кластеризация</target>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="translated">Спектральная кластеризация для сегментации изображений</target>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="translated">Спектральное встраивание для нелинейного уменьшения размерности.</target>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="translated">Спектральное встраивание матрицы обучения.</target>
        </trans-unit>
        <trans-unit id="2d2cb022bc3d26bd1407c4aa787d5e46e1ad4c3b" translate="yes" xml:space="preserve">
          <source>Speed</source>
          <target state="translated">Speed</target>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="translated">Разделение массивов или матриц на случайные подмножества поездов и тестовых подмножеств</target>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="translated">Разделяет на складки К,поезда на К-1,а затем тесты на выезде.</target>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="translated">Сплиттер-классы</target>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="translated">Функции сплиттера</target>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="translated">Квадратные L2 нормы линий y.Требуется,если толерант нет Нет.</target>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="translated">Площадь махаланобиса расстояния наблюдений.</target>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="translated">Квадрат Сум-Сумма квадрата L2 нормы всех образцов.</target>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="translated">Квадратная норма центроидов.</target>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="translated">Путь стабильности на основе рандомизированных оценок Лассо</target>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="translated">Выбор стабильности Николай Мейнсхаузен,журнал Петера Бюльмана Королевского статистического общества:Серия B Том 72,выпуск 4,страницы 417-473,сентябрь 2010 г.ДОИ:10.1111/j.1467-9868.2010.00740.x</target>
        </trans-unit>
        <trans-unit id="24ab98f7d3b4687c560036182f11b4e7733b1d68" translate="yes" xml:space="preserve">
          <source>Stack Exchange</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b2c903e12bff4f98c474e759faf1146ab6ad92" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8433d8b247979d86acd74f4143c89bb21831f7b9" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a568e00cb92ef139342d099c3bf8234421058e98" translate="yes" xml:space="preserve">
          <source>Stack of predictors on a single data set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8781e517c304621291a3255c93ced28430f5c0bd" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f5f44a8c7d7cd4102991a0e07afa77f83e823da" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d83774fb1981a771cc887192522bcd1ee8713fc" translate="yes" xml:space="preserve">
          <source>Stacked generalization is a method for combining estimators to reduce their biases &lt;a href=&quot;#w1992&quot; id=&quot;id32&quot;&gt;[W1992]&lt;/a&gt;&lt;a href=&quot;#htf&quot; id=&quot;id33&quot;&gt;[HTF]&lt;/a&gt;. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93dcc7ee10b4f7f50030c1b93ea7e60ca7979cd4" translate="yes" xml:space="preserve">
          <source>Stacking Classifier and Regressor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a37a65ea2247a4c331699e362c23755d1370e615" translate="yes" xml:space="preserve">
          <source>Stacking refers to a method to blend estimators. In this strategy, some estimators are individually fitted on some training data while a final estimator is trained using the stacked predictions of these base estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="translated">Стандартное отклонение гауссовского шума,добавленное к данным.</target>
        </trans-unit>
        <trans-unit id="a17025349c0cc77d7292705f3e0aace21538f53e" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when &lt;code&gt;return_std&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="translated">Стандартное отклонение прогнозируемого распределения в точках запроса.Возвращается только в том случае,если return_std имеет значение True.</target>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="translated">Стандартное отклонение прогнозируемого распределения точек запроса.</target>
        </trans-unit>
        <trans-unit id="c37a2551fc59b4216e7ebb6941b4c543d13c64ce" translate="yes" xml:space="preserve">
          <source>Standard deviation over &lt;code&gt;n_repeats&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="translated">Стандартизация набора данных является общим требованием для многих учебных машинных смет.Как правило,это достигается путем удаления среднего значения и масштабирования до единицы дисперсии.Однако часто отклонения могут отрицательно влиять на среднее значение выборки/дисперсию.В таких случаях медиана и интерквартильный диапазон часто дают лучшие результаты.</target>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="translated">Стандартизация набора данных является общим требованием для многих машинных учебных смет:они могут вести себя плохо,если отдельные особенности не более или менее похожи на стандартные нормально распределенные данные (например,гауссовские с 0 средней и единичной дисперсией).</target>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="translated">Стандартизировать набор данных по любой оси</target>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="translated">Стандартизация функций путем удаления среднего значения и масштабирования до единичной дисперсии.</target>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="translated">Начни указывать на все листья.</target>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">Начало настройки встраивания для инициализации алгоритма SMACOF.По умолчанию алгоритм инициализируется случайно выбранным массивом.</target>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">Начало настройки встраивания для инициализации алгоритма.По умолчанию алгоритм инициализируется случайно выбранным массивом.</target>
        </trans-unit>
        <trans-unit id="08977c4568e04a737e6b3a87f7b6021573de1b1c" translate="yes" xml:space="preserve">
          <source>Starting from &lt;code&gt;joblib &amp;gt;= 0.14&lt;/code&gt;, when the &lt;code&gt;loky&lt;/code&gt; backend is used (which is the default), joblib will tell its child &lt;strong&gt;processes&lt;/strong&gt; to limit the number of threads they can use, so as to avoid oversubscription. In practice the heuristic that joblib uses is to tell the processes to use &lt;code&gt;max_threads
= n_cpus // n_jobs&lt;/code&gt;, via their corresponding environment variable. Back to our example from above, since the joblib backend of &lt;code&gt;GridSearchCV&lt;/code&gt; is &lt;code&gt;loky&lt;/code&gt;, each process will only be able to use 1 thread instead of 8, thus mitigating the oversubscription issue.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="translated">Начиная с исходных случайных весов,многослойный перцептрон (MLP)минимизирует функцию потерь,многократно обновляя эти веса.После вычисления потерь,обратный проход передает их с выходного слоя на предыдущие слои,предоставляя каждому весовому параметру значение обновления,предназначенного для уменьшения потерь.</target>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="translated">Начальный узел пути</target>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="translated">Стат-Эсс,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="translated">статистическое обучение</target>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="translated">Статистическое обучение:установка и объект оценивания в науке.</target>
        </trans-unit>
        <trans-unit id="904a41f7fbe4f76d9e16b8a6416dab74831246a2" translate="yes" xml:space="preserve">
          <source>Stef van Buuren, Karin Groothuis-Oudshoorn (2011). &amp;ldquo;mice: Multivariate Imputation by Chained Equations in R&amp;rdquo;. Journal of Statistical Software 45: 1-67.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="translated">Все еще эффективен в случаях,когда количество размеров превышает количество образцов.</target>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="translated">Стохастический градиентный спуск</target>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="translated">Stochastic Gradient Descent-это техника оптимизации,которая минимизирует функцию потерь стохастической моды,выполняя шаг спуска градиента по образцу.В частности,это очень эффективный метод для подгонки линейных моделей.</target>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="translated">Стохастический градиентный спуск чувствителен к масштабированию функций, поэтому настоятельно рекомендуется масштабировать ваши данные. Например, масштабируйте каждый атрибут во входном векторе X до [0,1] или [-1, + 1] или стандартизируйте его так, чтобы он имел среднее значение 0 и дисперсию 1. Обратите внимание, что такое &lt;em&gt;же&lt;/em&gt; масштабирование должно быть применено к проверочному вектору, чтобы получить значимые результаты. Это легко сделать с помощью &lt;code&gt;StandardScaler&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="translated">Стохастическое повышение градиента позволяет вычислять нестандартные оценки отклонения теста путем вычисления улучшения отклонения на примерах, которые не включены в выборку начальной загрузки (т. Е. В нестандартных примерах). Улучшения хранятся в атрибуте &lt;code&gt;oob_improvement_&lt;/code&gt; . &lt;code&gt;oob_improvement_[i]&lt;/code&gt; содержит улучшение с точки зрения потерь в выборках OOB, если вы добавите i-й этап к текущим прогнозам. Оценки вне пакета можно использовать для выбора модели, например, для определения оптимального количества итераций. Оценки OOB обычно очень пессимистичны, поэтому мы рекомендуем вместо этого использовать перекрестную проверку и использовать OOB только в том случае, если перекрестная проверка занимает слишком много времени.</target>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="translated">Стохастический градиентный спуск - это простой, но очень эффективный подход для подбора линейных моделей. Это особенно полезно, когда количество образцов (и количество функций) очень велико. Метод &lt;code&gt;partial_fit&lt;/code&gt; позволяет обучаться в режиме онлайн / вне ядра.</target>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="translated">Стохастический градиентный спуск-метод оптимизации для неограниченных задач оптимизации.В отличие от (пакетного)градиентного спуска,SGD аппроксимирует истинный градиент \(E(w,b)\),рассматривая один учебный пример за раз.</target>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">Остановите раннее строительство дерева на n_clusters.Это полезно для уменьшения времени вычислений,если количество кластеров невелико по сравнению с количеством особенностей.Эта опция полезна только при указании матрицы связности.Обратите также внимание,что при варьировании числа кластеров и использовании кэширования может быть выгодно вычислить полное дерево.</target>
        </trans-unit>
        <trans-unit id="27fa813a99ee0ee872f0a0fdd316cf176619503c" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="translated">Досрочно остановить построение дерева в n_clusters. Это полезно для уменьшения времени вычислений, если количество кластеров невелико по сравнению с количеством выборок. В этом случае полное дерево не вычисляется, поэтому вывод &amp;laquo;дочерних элементов&amp;raquo; имеет ограниченное использование, а вывод &amp;laquo;родителей&amp;raquo; следует использовать. Эта опция действительна только при указании матрицы связи.</target>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">Остановите раннее строительство дерева на n_clusters.Это полезно для уменьшения времени вычислений,если количество кластеров не мало по сравнению с количеством сэмплов.Эта опция полезна только при указании матрицы связности.Обратите также внимание,что при варьировании числа кластеров и использовании кэширования может быть выгодно вычислить полное дерево.</target>
        </trans-unit>
        <trans-unit id="cec77383bf3b11f332bd0e653f87f2dc409b1dee" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="translated">Остановите итерацию,если найдено хотя бы это количество линеек.</target>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="translated">Остановить итерацию,если балл больше этого порога.</target>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="translated">Остановите solver после этого множества итераций независимо от точности (XXX В настоящее время нет API,чтобы знать,если этот лягнул)-1 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="356700453d0a0d54f3f7d4b7b513913c4b6ecef8" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="translated">Остановите алгоритм,если w сошлись.По умолчанию 1.e-3.</target>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="translated">Стоп-слова - это такие слова, как &amp;laquo;и&amp;raquo;, &amp;laquo;тот&amp;raquo;, &amp;laquo;он&amp;raquo;, которые считаются неинформативными при представлении содержания текста и которые могут быть удалены, чтобы не рассматривать их как сигнал для предсказания. Однако иногда похожие слова полезны для предсказаний, например, для классификации стиля письма или личности.</target>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="translated">Критерии остановки.</target>
        </trans-unit>
        <trans-unit id="2eda661dab2cf19600424ed9df7c9d0563861dff" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when &lt;code&gt;eigen_solver='arpack'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="translated">Критерий останова при использовании arpack eigen_solver для эйгендекомпозиции лаплацианской матрицы.</target>
        </trans-unit>
        <trans-unit id="a798cb65fb942fe2386149a92d6481d384d3e392" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the lbfgs solver, the iteration will stop when &lt;code&gt;max{|g_j|, j = 1, ..., d} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_j&lt;/code&gt; is the j-th component of the gradient (derivative) of the objective function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="translated">Критерий остановки. Для решателей newton-cg и lbfgs итерация остановится, когда &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; где &lt;code&gt;g_i&lt;/code&gt; - i-я компонента градиента.</target>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="translated">Останавливающая допуск для ЭМ алгоритма.</target>
        </trans-unit>
        <trans-unit id="54709da56f5bb7c428a618dd7d85fb0e4421bcb5" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for log-likelihood increase.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="translated">Ограничение допуска для обновления распространения темы документа на E-шаге.</target>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="translated">Храните n выходных значений в листьях вместо 1;</target>
        </trans-unit>
        <trans-unit id="0fac441919e9594e005f5d0571a0bfbc255133fa" translate="yes" xml:space="preserve">
          <source>Stored sampling interval. Specified as a parameter if sample_steps not in {1,2,3}.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="translated">Хранит ближайший сосед,включая BallTree или KDtree,если применимо.</target>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">Сохраняет матрицу аффинности, используемую в &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="translated">Хранит встраиваемые векторы</target>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="translated">Хранит встраиваемые векторы.</target>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="translated">Хранит геодезическую матрицу расстояний тренировочных данных.</target>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="translated">Хранит позицию набора данных в пространстве встраивания.</target>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="translated">Хранит данные тренировок.</target>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="translated">Стратегия использования для создания прогнозов.</target>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="translated">Стратегия,используемая для определения ширины бункеров.</target>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="translated">Перекрестный валидатор стратифицированных K-Folds</target>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="translated">Стратифицированный перекрестный валидатор ShuffleSplit</target>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="translated">Штрел, Александр и Джойдип Гош (2002). &amp;laquo;Кластерные ансамбли - структура повторного использования знаний для объединения нескольких разделов&amp;raquo;. Журнал исследований машинного обучения 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;DOI: 10,1162 / 153244303321897735&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="738d614dd3bdb5fdb2eecf8a98b676a349ac24fe" translate="yes" xml:space="preserve">
          <source>Strictly speaking, SGD is merely an optimization technique and does not correspond to a specific family of machine learning models. It is only a &lt;em&gt;way&lt;/em&gt; to train a model. Often, an instance of &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; will have an equivalent estimator in the scikit-learn API, potentially using a different optimization technique. For example, using &lt;code&gt;SGDClassifier(loss='log')&lt;/code&gt; results in logistic regression, i.e. a model equivalent to &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; which is fitted via SGD instead of being fitted by one of the other solvers in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;. Similarly, &lt;code&gt;SGDRegressor(loss='squared_loss', penalty='l2')&lt;/code&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; solve the same optimization problem, via different means.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="translated">Строка,описывающая тип используемых ковариационных параметров.Должно быть,один из них:</target>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="translated">Строка,описывающая тип концентрации веса до этого.Должно быть,одна из них:</target>
        </trans-unit>
        <trans-unit id="8c721819e7f297061a3852981915f8763538ca5d" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape (n_samples, n_features), and return a (n_samples, n_samples) shaped weight matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="translated">Строковый идентификатор используемой функции ядра или самой функции ядра. Допустимыми входными данными являются только строки &amp;laquo;rbf&amp;raquo; и &amp;laquo;knn&amp;raquo;. Переданная функция должна принимать два входа, каждый из которых имеет форму [n_samples, n_features], и возвращать матрицу весов в форме [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="translated">Строковый идентификатор используемой функции ядра или самой функции ядра. Допустимыми входными данными являются только строки &amp;laquo;rbf&amp;raquo; и &amp;laquo;knn&amp;raquo;. Переданная функция должна принимать два входа, каждый из которых имеет форму [n_samples, n_features], и возвращать матрицу весов в форме [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="translated">Строковый идентификатор набора данных.Обратите внимание,что OpenML может иметь несколько наборов данных с одним и тем же именем.</target>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="translated">Поддерживаются строковые входы, &amp;laquo;absolute_loss&amp;raquo; и &amp;laquo;squared_loss&amp;raquo;, которые находят, соответственно, абсолютные потери и квадраты потерь на выборку.</target>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="translated">Строка должна быть в {'frobenius', 'kullback-leibler', 'itakura-saito'}. Бета-расхождение необходимо минимизировать, измеряя расстояние между X и скалярным произведением WH. Обратите внимание, что значения, отличные от &amp;laquo;frobenius&amp;raquo; (или 2) и &amp;laquo;kullback-leibler&amp;raquo; (или 1), приводят к значительно более медленным подборам. Обратите внимание, что для beta_loss &amp;lt;= 0 (или 'itakura-saito') входная матрица X не может содержать нулей. Используется только в решателе &quot;mu&quot;.</target>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="translated">Имена строк для функций ввода, если они доступны. По умолчанию используются &amp;laquo;x0&amp;raquo;, &amp;laquo;x1&amp;raquo;,&amp;hellip; &amp;laquo;xn_features&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="translated">Строковое представление входного дерева в точечном формате GraphViz. Возвращается, только если &lt;code&gt;out_file&lt;/code&gt; равен None.</target>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="translated">Строка [s], представляющая разрешенные форматы разреженных матриц, такие как 'csc', 'csr' и т. Д. Если входные данные являются разреженными, но не в разрешенном формате, они будут преобразованы в первый из перечисленных форматов. True позволяет вводить любой формат. Ложь означает, что ввод разреженной матрицы вызовет ошибку.</target>
        </trans-unit>
        <trans-unit id="5110c05a58c323fc1a90d8e9c2d4e3215bf368fd" translate="yes" xml:space="preserve">
          <source>Strings can reference columns if the input is a DataFrame, integers are always interpreted as the positional columns.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="translated">Впоследствии объект создается как:</target>
        </trans-unit>
        <trans-unit id="858f5a05f03a44bd2c0d7ffef4c39076939797fb" translate="yes" xml:space="preserve">
          <source>Subset of X on axis 0 or 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="translated">Поднаборка X по первой оси</target>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="translated">Поднаборка целевых значений</target>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="translated">Поднаборка целевых значений</target>
        </trans-unit>
        <trans-unit id="b6f57836197cd859fcd7456747a897dac9249a7c" translate="yes" xml:space="preserve">
          <source>Subset of the target values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="translated">Поднаборка данных об обучении</target>
        </trans-unit>
        <trans-unit id="a36f00d869bab77d370e6340b596e76174606ee7" translate="yes" xml:space="preserve">
          <source>Subset of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="translated">Поднаборка данных по обучению</target>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="translated">Подмножество учебных точек,используемых для построения карты объекта.</target>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="translated">Такая группировка данных является доменной спецификой.Примером может служить случай,когда медицинские данные собираются от нескольких пациентов,причем от каждого пациента отбирается несколько проб.И такие данные,скорее всего,будут зависеть от конкретной группы.В нашем примере идентификатор пациента для каждой выборки будет являться ее идентификатором группы.</target>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="translated">Такое целочисленное представление,однако,не может быть использовано непосредственно со всеми научно-обученными оценщиками,так как они ожидают непрерывного ввода,и будет интерпретировать категории как упорядоченные,что часто не желательно (т.е.набор браузеров был упорядочен произвольно).</target>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="translated">Сумма квадратных расстояний образцов до ближайшего центра кластера.</target>
        </trans-unit>
        <trans-unit id="854e30e5027349dd68053e9c07e26612b753dfb3" translate="yes" xml:space="preserve">
          <source>Sum of the impurities of the subtree leaves for the corresponding alpha value in &lt;code&gt;ccp_alphas&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d0794742200525b0f1825276d5e113f8014eaee" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c895953cca3a7be3ad68f35cb10044d9d62303c" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount. Then divide by the best possible score (Ideal DCG, obtained for a perfect ranking) to obtain a score between 0 and 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="translated">Сум-ядро k1+k2 двух ядер k1 и k2.</target>
        </trans-unit>
        <trans-unit id="bb594232250fde950a53bc755dc305c05d6d4d31" translate="yes" xml:space="preserve">
          <source>Summary Statistics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="translated">Сводная статистика:</target>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="translated">Контролируемые алгоритмы обучения потребуют обозначения категорий для каждого документа в учебном наборе.В этом случае категория-это название группы новостей,которая также является названием папки,в которой хранятся отдельные документы.</target>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="translated">Обучение под наблюдением:прогнозирование выходной переменной по результатам высокоразмерных наблюдений.</target>
        </trans-unit>
        <trans-unit id="a3f901fb4e96c309b27de60d3fa05a2f6c90ddfd" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">Классификация опорных векторов (SVC) показывает еще более сигмовидную кривую, чем RandomForestClassifier, что типично для методов с максимальной маржой (сравните Никулеску-Мизил и Каруана &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt; ), которые сосредоточены на жестких выборках, которые близки к границе решения ( опорные векторы).</target>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">Алгоритмы машины опорных векторов не масштабируются, поэтому &lt;strong&gt;настоятельно рекомендуется масштабировать ваши данные&lt;/strong&gt; . Например, масштабируйте каждый атрибут во входном векторе X до [0,1] или [-1, + 1] или стандартизируйте его так, чтобы он имел среднее значение 0 и дисперсию 1. Обратите внимание, что такое &lt;em&gt;же&lt;/em&gt; масштабирование должно быть применено к проверочному вектору, чтобы получить значимые результаты. См. Раздел &amp;laquo; &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Предварительная обработка данных&amp;raquo;&lt;/a&gt; для получения более подробной информации о масштабировании и нормализации.</target>
        </trans-unit>
        <trans-unit id="6759d5fe5cd02546f72e19999514f8d8dd0c2afc" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="translated">Поддержка векторной машины для регрессии,реализованная с помощью libsvm.</target>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="translated">Поддержка Vector Machine для классификации реализована с помощью libsvm с параметром для управления количеством поддерживаемых векторов.</target>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="translated">Поддержка Vector Machine для классификации с помощью libsvm.</target>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="translated">Поддержка Vector Machine для регрессии реализована с помощью libsvm с помощью параметра для управления количеством поддерживаемых векторов.</target>
        </trans-unit>
        <trans-unit id="0e9e942139034d62a386d593445cc7ca0b8119c8" translate="yes" xml:space="preserve">
          <source>Support Vector Machines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09b4534def5c091569acb02092fe6cf8bbcb767a" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">Машины опорных векторов - мощные инструменты, но их требования к вычислениям и хранению быстро растут с увеличением количества обучающих векторов. Ядром SVM является задача квадратичного программирования (QP), отделяющая опорные векторы от остальных обучающих данных. Решатель QP, используемый этой &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;реализацией на&lt;/a&gt; основе libsvm, масштабируется между \ (O (n_ {features} \ times n_ {samples} ^ 2) \) и \ (O (n_ {features} \ times n_ {samples} ^ 3) \ ) в зависимости от того, насколько эффективно &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;используется&lt;/a&gt; кеш libsvm на практике (зависит от набора данных). Если данные очень разреженные, \ (n_ {features} \) следует заменить средним числом ненулевых функций в векторной выборке.</target>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="translated">Поддержка векторной регрессии (SVR)с использованием линейных и нелинейных ядер</target>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="translated">Поддержка векторной регрессии,реализованная с помощью libsvm.</target>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="translated">Векторные машины поддержки (SVM)</target>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="translated">Векторы поддержки.</target>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="translated">Поддерживает редкие матрицы,если они не являются негативными.</target>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="translated">Предположим,есть \(n\)учебные образцы,\(m\)особенности,\(k\)скрытые слои,каждый из которых содержит \(h\)нейроны-для простоты,и \(o\)выходные нейроны.Временная сложность обратного распространения-\(O(n\cdot m \cdot h^k \cdot o \cdot i)\),где \(i\)-количество итераций.Так как обратное прорастание имеет высокую временную сложность,то для обучения желательно начинать с меньшего количества скрытых нейронов и нескольких скрытых слоев.</target>
        </trans-unit>
        <trans-unit id="cd4ffcedd7e0903b657852f1e48effcf51cd6dba" translate="yes" xml:space="preserve">
          <source>Suppose you have a machine with 8 CPUs. Consider a case where you&amp;rsquo;re running a &lt;code&gt;GridSearchCV&lt;/code&gt; (parallelized with joblib) with &lt;code&gt;n_jobs=8&lt;/code&gt; over a &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; (parallelized with OpenMP). Each instance of &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; will spawn 8 threads (since you have 8 CPUs). That&amp;rsquo;s a total of &lt;code&gt;8 * 8 = 64&lt;/code&gt; threads, which leads to oversubscription of physical CPU resources and to scheduling overhead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="translated">Меняет местами две колонки матрицы CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="translated">Меняет местами два ряда матрицы CSC/CSR.</target>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="translated">Снижение швейцарского ролля с LLE</target>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="translated">Симметричный вариант входного массива,т.е.среднее значение array и array.transpose().Если они разрежены,то сначала суммируются дубликаты,а затем удаляются нули.</target>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="translated">Симметрия:d(x,y)=d(y,x)</target>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="translated">Синтетический пример</target>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="translated">Т. Калински и Дж. Харабас, 1974. &amp;laquo;Дендритный метод для кластерного анализа&amp;raquo;. Коммуникации в статистике</target>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Т. Хасти, Р. Тибширани и Дж. Фридман, &amp;laquo;Элементы статистического обучения. Ред. 2 &amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="translated">Т. Хасти, Р. Тибширани и Дж. Фридман, &amp;laquo;Элементы статистического обучения. Ред. 2 &amp;rdquo;, стр. 592-593, Springer, 2009 г.</target>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Т. Хасти, Р. Тибширани и Дж. Фридман, &amp;laquo;Элементы статистического обучения&amp;raquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="1a36ad5ec8c80f7993b9fd82eb2686d2da21883a" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn//&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Second Edition, Section 10.13.2, Springer, 2009.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Т. Хасти, Р. Тибширани и Дж. Фридман. &amp;laquo;Элементы статистического обучения&amp;raquo;, Springer, 2009 г.</target>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="translated">T.Хасти,Р.Тибширани и Дж.Фридман.Элементы статистического обучения изд.2,Спрингер,2009.</target>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="translated">T.Хасти,Р.Тибширани и Дж.Фридман.Элементы статистического обучения,Спрингер,2009.</target>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="translated">Т. Хасти, Р. Тибширани, Дж. Фридман, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;Элементы статистического обучения&lt;/a&gt; , Springer 2009 г.</target>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="translated">Т. Хо, &amp;laquo;Метод случайных подпространств для построения лесов решений&amp;raquo;, Анализ шаблонов и машинный интеллект, 20 (8), 832-844, 1998.</target>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="translated">Т. Янг, Ю. Ли, М. Махдави, Р. Джин и З. Чжоу &amp;laquo;Метод Нистрома против случайных характеристик Фурье: теоретическое и эмпирическое сравнение&amp;raquo;, Достижения в системах обработки нейронной информации 2012</target>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="translated">Налог на недвижимость на полную стоимость за 10 000 долл.</target>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="translated">TF-IDF векторы текстовых документов,выползенных из сети.</target>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="translated">TODO:осуществить загрузку набора данных zip тоже.</target>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="translated">Принимает групповой массив для групповых наблюдений.</target>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="translated">Учитывает информацию о группах,чтобы избежать построения складок с несбалансированным распределением классов (для задач бинарной или мультиклассификационной классификации).</target>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="translated">Данные лекции,наборы слайдов и другая информация,относящаяся к научному предмету.</target>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="27a0909e2e214e16b84c188da9b6e36fbb24a75c" translate="yes" xml:space="preserve">
          <source>Target Domain</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0810f8f564f353b71a4c98cca217fcf1b526a4f" translate="yes" xml:space="preserve">
          <source>Target cardinality</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a92a80f8cb5657b9d712fa7c0bc7d1998153a6b8" translate="yes" xml:space="preserve">
          <source>Target names used for plotting. By default, &lt;code&gt;labels&lt;/code&gt; will be used if it is defined, otherwise the unique labels of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; will be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="translated">Целевое количество ненулевых коэффициентов. Используйте &lt;code&gt;np.inf&lt;/code&gt; без ограничений.</target>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="translated">Цель относительно Х для классификации или регрессии;Нет для неконтролируемого обучения.</target>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">Целевые баллы могут быть либо оценками вероятности положительного класса, либо значениями достоверности, либо мерой решений без пороговых значений (возвращаемой функцией &amp;laquo;solution_function&amp;raquo; для некоторых классификаторов).</target>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="translated">Целевые баллы могут быть либо оценками вероятности положительного класса, либо значениями достоверности, либо мерой решений без пороговых значений (возвращаемой функцией &amp;laquo;solution_function&amp;raquo; для некоторых классификаторов). Для двоичного y_true y_score должен быть оценкой класса с большей меткой.</target>
        </trans-unit>
        <trans-unit id="e311afc7eeab469d8890dd7eea87d765736badbd" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b0d9d264d1c088751e6e40c1e8e25db9f44f02f" translate="yes" xml:space="preserve">
          <source>Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by &lt;code&gt;decision_function&lt;/code&gt; on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of &lt;code&gt;labels&lt;/code&gt;, if provided, or else to the numerical or lexicographical order of the labels in &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="translated">Целевые значения</target>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="translated">Целевые значения (метки классов в классификации,вещественные числа в регрессии)</target>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="translated">Целевые значения (целые числа для классификации,вещественные числа для регрессии).</target>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="translated">Целевые значения (целые числа)</target>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Целевые значения (целые числа). При необходимости будет преобразован в dtype X</target>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="translated">Целевые значения (строки или целые числа в классификации,вещественные числа в регрессии)Для классификации метки должны соответствовать классам.</target>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="translated">Целевые значения в учебных данных (также необходимы для прогнозирования)</target>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="translated">Целевые значения формы=[n_образцы]или [n_образцы,n_выходы].</target>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="translated">Целевые значения,массив значений с плавающей запятой,форма=[n_samples].</target>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="translated">Целевые значения,должны быть двоичными</target>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="translated">Целевые значения.</target>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="translated">Целевые значения.Все разреженные матрицы преобразуются в CSR перед инверсным преобразованием.</target>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="translated">Целевые значения.Метки классов должны быть целочисленными или с плавающей точкой,или массивовидными объектами целочисленных или с плавающей точкой для многомаркировочных классификаций.</target>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="translated">Целевые значения.Матрица 2-d должна содержать только 0 и 1,представляет собой многомаркировочную классификацию.</target>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="translated">Целевые значения.Матрица 2-d должна содержать только 0 и 1,представляет собой многомаркировочную классификацию.Разделительная матрица может быть CSR,CSC,COO,DOK или LIL.</target>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Целевые значения. При необходимости будет преобразован в dtype X</target>
        </trans-unit>
        <trans-unit id="26a7504c7e3fd5624ea9f7504b20b691f54baa64" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="translated">Вектор цели (метки класса).</target>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="translated">Вектор цели относительно X</target>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="translated">Вектор цели относительно X.</target>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="translated">Вектор цели.</target>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="translated">Целевые векторы,где n_samples-количество отсчетов,а n_targets-количество переменных ответа.</target>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">Target. При необходимости будет преобразован в dtype X</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="translated">Цели для входных данных.</target>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="translated">Цели для обучения под наблюдением.</target>
        </trans-unit>
        <trans-unit id="135d4c14ef59d437ba9b3977ff9548aa96a57252" translate="yes" xml:space="preserve">
          <source>Targets for supervised or &lt;code&gt;None&lt;/code&gt; for unsupervised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">Цели,используемые для подсчета очков.Должны соответствовать требованиям по маркировке для всех этапов трубопровода.</target>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="translated">Технически модель Lasso оптимизирует ту же целевую функцию, что и Elastic Net, с &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (без штрафа L2).</target>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">Десять базовых переменных,возраст,пол,индекс массы тела,среднее артериальное давление,и шесть измерений сыворотки крови были получены для каждого из n=442 больных сахарным диабетом,а также ответ интереса,количественная мера прогрессирования заболевания через год после базового уровня.</target>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="translated">Tenenbaum, JB; De Silva, V .; И Лэнгфорд, Дж. К. Глобальная геометрическая основа для нелинейного уменьшения размерности. Наука 290 (5500)</target>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">Тененхаус,М.(1998).PLS регрессия:теория и практика.Париж:Издания Technic.</target>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="translated">Условия,которые были проигнорированы,потому что они тоже:</target>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="translated">Тестовые данные,из которых мы вычисляем вероятность,где n_образцы-это количество отсчетов,а n_функции-это количество признаков.X_test предполагается получить из того же распределения,что и данные,используемые в fit (включая центрирование).</target>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="translated">Тестовые данные,которые должны быть преобразованы,должны иметь такое же количество характеристик,как и данные,используемые для обучения модели.</target>
        </trans-unit>
        <trans-unit id="65eaa1a409cbf0736a7b1da17a35a153fc9af91f" translate="yes" xml:space="preserve">
          <source>Test samples</source>
          <target state="translated">Тестовые образцы</target>
        </trans-unit>
        <trans-unit id="29446ed524d3e237184352cbcf6e1c5aaeb464e4" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator. Passing None as test samples gives the same result as passing real test samples, since DummyRegressor operates independently of the sampled observations.</source>
          <target state="translated">Тестовые примеры с формой=(n_образцы,n_функции)или None.Для некоторых оценок это может быть предварительно вычисленная матрица кернела,вместо нее shape=(n_samples,n_samples_fitted],где n_samples_fitted-это количество примеров,используемых в подгонке для оценщика.Прохождение None в качестве тестовых отсчетов дает тот же результат,что и прохождение реальных тестовых отсчетов,поскольку DummyRegressor работает независимо от выборочных наблюдений.</target>
        </trans-unit>
        <trans-unit id="12cad09d9d4837878fb37fd506e5f7fb71a801c9" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. Passing None as test samples gives the same result as passing real test samples, since DummyClassifier operates independently of the sampled observations.</source>
          <target state="translated">Тестовые примеры с формой=(n_образцы,n_функции)или None.Прохождение None в качестве тестовых образцов дает тот же результат,что и прохождение реальных тестовых образцов,поскольку DummyClassifier работает независимо от выборочных наблюдений.</target>
        </trans-unit>
        <trans-unit id="0c1d5bbb82f5cfc66b7e35e84179b02f4b13f8b1" translate="yes" xml:space="preserve">
          <source>Test samples.</source>
          <target state="translated">Тестовые образцы.</target>
        </trans-unit>
        <trans-unit id="bdec5057d32ebe97bd4c525fff2435009f4be0a0" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="translated">Тестовые образцы.Для некоторых оценок это может быть предварительно вычисленная матрица кернела,вместо нее shape=(n_samples,n_samples_fitted],где n_samples_fitted-количество примеров,используемых в подгонке под оценивающее устройство.</target>
        </trans-unit>
        <trans-unit id="a3c0fad25d001ac0a0589946fd03f6f0be795bec" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead, shape = (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f9baccc70399290d29568f9812594e6335c4ae0" translate="yes" xml:space="preserve">
          <source>Test with permutations the significance of a classification score</source>
          <target state="translated">Тест с перестановками значение классификационной оценки</target>
        </trans-unit>
        <trans-unit id="c67f73aee0c3dc1034cba236cfe8c8526d7a9123" translate="yes" xml:space="preserve">
          <source>Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.</source>
          <target state="translated">Текстовый анализ является основной областью применения алгоритмов машинного обучения.Однако необработанные данные,последовательность символов не может быть подана непосредственно в сами алгоритмы,так как большинство из них ожидают числовых характерных векторов с фиксированным размером,а не исходных текстовых документов с переменной длиной.</target>
        </trans-unit>
        <trans-unit id="990226708ed5e3f7319c13e5c3e22d22fd438346" translate="yes" xml:space="preserve">
          <source>Text is made of characters, but files are made of bytes. These bytes represent characters according to some &lt;em&gt;encoding&lt;/em&gt;. To work with text files in Python, their bytes must be &lt;em&gt;decoded&lt;/em&gt; to a character set called Unicode. Common encodings are ASCII, Latin-1 (Western Europe), KOI8-R (Russian) and the universal encodings UTF-8 and UTF-16. Many others exist.</source>
          <target state="translated">Текст состоит из символов, а файлы состоят из байтов. Эти байты представляют символы в соответствии с некоторой &lt;em&gt;кодировкой&lt;/em&gt; . Для работы с текстовыми файлами в Python их байты должны быть &lt;em&gt;декодированы&lt;/em&gt; в кодировку Unicode. Распространенными кодировками являются ASCII, Latin-1 (Западная Европа), KOI8-R (Русский) и универсальные кодировки UTF-8 и UTF-16. Многие другие существуют.</target>
        </trans-unit>
        <trans-unit id="2a2f9f7e298485c4a85bf6b791046a1b63087cf9" translate="yes" xml:space="preserve">
          <source>Text preprocessing, tokenizing and filtering of stopwords are all included in &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;, which builds a dictionary of features and transforms documents to feature vectors:</source>
          <target state="translated">Предварительная обработка текста, токенизация и фильтрация игнорируемых слов включены в &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; , который создает словарь функций и преобразует документы в векторы функций:</target>
        </trans-unit>
        <trans-unit id="81ed5011593c32dbca614ea281c1292f374dff62" translate="yes" xml:space="preserve">
          <source>Text summary of all the rules in the decision tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79142cb36f8945e4d341c82cf5dc060dc02c8f0f" translate="yes" xml:space="preserve">
          <source>Text summary of the precision, recall, F1 score for each class. Dictionary returned if output_dict is True. Dictionary has the following structure:</source>
          <target state="translated">Текстовое обобщение точности,отзыв,оценка F1 для каждого класса.Возвращается словарь,если output_dict равен True.Словарь имеет следующую структуру:</target>
        </trans-unit>
        <trans-unit id="f042ff208f7aff2fdebc20ebdcfe3611681222ed" translate="yes" xml:space="preserve">
          <source>Tf is &amp;ldquo;n&amp;rdquo; (natural) by default, &amp;ldquo;l&amp;rdquo; (logarithmic) when &lt;code&gt;sublinear_tf=True&lt;/code&gt;. Idf is &amp;ldquo;t&amp;rdquo; when use_idf is given, &amp;ldquo;n&amp;rdquo; (none) otherwise. Normalization is &amp;ldquo;c&amp;rdquo; (cosine) when &lt;code&gt;norm='l2'&lt;/code&gt;, &amp;ldquo;n&amp;rdquo; (none) when &lt;code&gt;norm=None&lt;/code&gt;.</source>
          <target state="translated">Tf - &amp;laquo;n&amp;raquo; (натуральный) по умолчанию, &amp;laquo;l&amp;raquo; (логарифмический), когда &lt;code&gt;sublinear_tf=True&lt;/code&gt; . Idf - это &amp;laquo;t&amp;raquo;, если указано use_idf, в противном случае - &amp;laquo;n&amp;raquo; (нет). Нормализация - это &amp;laquo;c&amp;raquo; (косинус), когда &lt;code&gt;norm='l2'&lt;/code&gt; , &amp;laquo;n&amp;raquo; (нет), когда &lt;code&gt;norm=None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="97730bbab5383bbe19dd65de91be719c29295304" translate="yes" xml:space="preserve">
          <source>Tf means &lt;strong&gt;term-frequency&lt;/strong&gt; while tf&amp;ndash;idf means term-frequency times &lt;strong&gt;inverse document-frequency&lt;/strong&gt;: \(\text{tf-idf(t,d)}=\text{tf(t,d)} \times \text{idf(t)}\).</source>
          <target state="translated">Tf означает &lt;strong&gt;частоту термина,&lt;/strong&gt; а tf &amp;ndash; idf означает частоту термина, умноженную на &lt;strong&gt;обратную&lt;/strong&gt; частоту &lt;strong&gt;документа&lt;/strong&gt; : \ (\ text {tf-idf (t, d)} = \ text {tf (t, d)} \ times \ text {idf (t)} \).</target>
        </trans-unit>
        <trans-unit id="f1cc0d39fa695e88ce231644990ae2b503602ddb" translate="yes" xml:space="preserve">
          <source>Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.</source>
          <target state="translated">Tf означает периодичность,в то время как tf-idf означает периодичность,обратная периодичности документа.Это распространенная схема взвешивания терминов при поиске информации,которая также нашла хорошее применение в классификации документов.</target>
        </trans-unit>
        <trans-unit id="771178a448f62a1d367a9045d97d08b26eb6869c" translate="yes" xml:space="preserve">
          <source>Tf-idf-weighted document-term matrix.</source>
          <target state="translated">Полу-взвешенная матрица документооборота.</target>
        </trans-unit>
        <trans-unit id="daaa1c74bc4f107e3ab2cba2520cc29b4809af00" translate="yes" xml:space="preserve">
          <source>TfidfVectorizer uses a in-memory vocabulary (a python dict) to map the most frequent words to features indices and hence compute a word occurrence frequency (sparse) matrix. The word frequencies are then reweighted using the Inverse Document Frequency (IDF) vector collected feature-wise over the corpus.</source>
          <target state="translated">TfidfVectorizer использует словарь in-memory (надпись на питоне)для сопоставления наиболее часто встречающихся слов с индексами и,следовательно,вычисления матрицы частоты встречаемости слов (разреженной).Частота встречаемости слов затем повторно взвешивается с помощью вектора Inverse Document Frequency (IDF),собранного функцией по всему телу.</target>
        </trans-unit>
        <trans-unit id="2c1e749a66bcce49e10daf1b4a981af3bebb9284" translate="yes" xml:space="preserve">
          <source>That this function takes time at least quadratic in n_samples. For large datasets, it&amp;rsquo;s wise to set that parameter to a small value.</source>
          <target state="translated">Эта функция требует как минимум квадратичного времени в n_samples. Для больших наборов данных целесообразно установить для этого параметра небольшое значение.</target>
        </trans-unit>
        <trans-unit id="fb20b5f965f5eb1a2ab7f1c1219e1e8adbfdfc00" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; heuristic is inspired by Logistic Regression in Rare Events Data, King, Zen, 2001.</source>
          <target state="translated">&amp;laquo;Сбалансированная&amp;raquo; эвристика основана на работе &amp;laquo;Логистическая регрессия в данных о редких событиях&amp;raquo;, King, Zen, 2001.</target>
        </trans-unit>
        <trans-unit id="f4d692dace6b9f963c8a80ff6fb54e77b0936bf5" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">&amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов во входных данных как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ef34b0ee7fbdfc2770447dcdf0759da38193f229" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">&amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов во входных данных как &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="66610aa2288acbb0ecf69897c27cb9799d361b2f" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data: &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">&amp;laquo;Сбалансированный&amp;raquo; режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам классов во входных данных: &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ef1bbf84c17d648e39cb34085672c6faaeb47082" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced_subsample&amp;rdquo; mode is the same as &amp;ldquo;balanced&amp;rdquo; except that weights are computed based on the bootstrap sample for every tree grown.</source>
          <target state="translated">Режим &amp;laquo;balance_subsample&amp;raquo; аналогичен &amp;laquo;сбалансированному&amp;raquo; за исключением того, что веса вычисляются на основе выборки начальной загрузки для каждого выращенного дерева.</target>
        </trans-unit>
        <trans-unit id="ed963145b52986c215cb0664e22ee6755071701e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; is an optimization algorithm that approximates the Broyden&amp;ndash;Fletcher&amp;ndash;Goldfarb&amp;ndash;Shanno algorithm &lt;a href=&quot;#id28&quot; id=&quot;id23&quot;&gt;8&lt;/a&gt;, which belongs to quasi-Newton methods. The &amp;ldquo;lbfgs&amp;rdquo; solver is recommended for use for small data-sets but for larger datasets its performance suffers. &lt;a href=&quot;#id29&quot; id=&quot;id24&quot;&gt;9&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd9d2df3102671da4d90b6a16223e62bcf13a40d" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; solver is used by default for its robustness. For large datasets the &amp;ldquo;saga&amp;rdquo; solver is usually faster. For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss, which might be even faster but requires more tuning.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9570d1ba54b75e486c6a8fe70ab0af402d1567cc" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support L2 penalization and are found to converge faster for some high dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="translated">Решатели &amp;laquo;lbfgs&amp;raquo;, &amp;laquo;sag&amp;raquo; и &amp;laquo;newton-cg&amp;raquo; поддерживают только штрафы L2 и, как обнаружено, сходятся быстрее для некоторых данных большой размерности. Установка &lt;code&gt;multi_class&lt;/code&gt; на &amp;laquo;полиномиальный&amp;raquo; с помощью этих решателей позволяет изучить истинную полиномиальную модель логистической регрессии &lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]&lt;/a&gt; , что означает, что ее оценки вероятности должны быть лучше откалиброваны, чем настройка по умолчанию &amp;laquo;один против остальных&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="5921538cf9d0b305a04fb55e5723f201454da417" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support \(\ell_2\) regularization or no regularization, and are found to converge faster for some high-dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id25&quot; id=&quot;id20&quot;&gt;5&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c76cf618fdea0e603c8990092e5d960628df7c0c" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;new&amp;rdquo; data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model.</source>
          <target state="translated">&amp;laquo;Новые&amp;raquo; данные состоят из линейных комбинаций входных данных с вероятностными весами с учетом модели KDE.</target>
        </trans-unit>
        <trans-unit id="6e028a15cea05a7ec04768381b1c3e0f7d725291" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses Stochastic Average Gradient descent &lt;a href=&quot;#id26&quot; id=&quot;id21&quot;&gt;6&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="420229f24d72cfc948f72b9aaf53e46dfcb25b62" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses a Stochastic Average Gradient descent &lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="translated">Решатель &amp;laquo;провисания&amp;raquo; использует спуск среднего стохастического градиента &lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt; . Это быстрее, чем другие решатели для больших наборов данных, когда и количество выборок, и количество объектов велико.</target>
        </trans-unit>
        <trans-unit id="2dbe4d8b05b25b3ecc8447f4c7fa6494b583e905" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id27&quot; id=&quot;id22&quot;&gt;7&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt;. This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports &lt;code&gt;penalty=&quot;elasticnet&quot;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf55bf4220bbf6e5ad8c38b76c827b53a1e3f193" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; option. This is therefore the solver of choice for sparse multinomial logistic regression.</source>
          <target state="translated">Решатель &amp;laquo;saga&amp;raquo; &lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt; представляет собой вариант &amp;laquo;sag&amp;raquo;, который также поддерживает параметр non-smooth &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; . Таким образом, это предпочтительный решатель для разреженной полиномиальной логистической регрессии.</target>
        </trans-unit>
        <trans-unit id="77bf2f7306c562160b3a78c9199a57470ad6395e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver is often the best choice. The &amp;ldquo;liblinear&amp;rdquo; solver is used by default for historical reasons.</source>
          <target state="translated">Решающая программа &amp;laquo;саги&amp;raquo; часто оказывается лучшим выбором. &amp;laquo;Liblinear&amp;raquo; решатель используется по умолчанию по историческим причинам.</target>
        </trans-unit>
        <trans-unit id="068bc43bd479e1422a1e2139866c2ca587dbb3ad" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;steepness&amp;rdquo; of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.</source>
          <target state="translated">&amp;laquo;Крутизна&amp;raquo; кривых ROC также важна, поскольку она идеальна для максимизации частоты истинных положительных результатов при минимизации частоты ложных положительных результатов.</target>
        </trans-unit>
        <trans-unit id="0eb5d5532023d8acbeeebff557bc347056c3c6a7" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;target&amp;rdquo; for this database is an integer from 0 to 39 indicating the identity of the person pictured; however, with only 10 examples per class, this relatively small dataset is more interesting from an unsupervised or semi-supervised perspective.</source>
          <target state="translated">&amp;laquo;Цель&amp;raquo; для этой базы данных - это целое число от 0 до 39, указывающее личность изображенного человека; однако, имея только 10 примеров на класс, этот относительно небольшой набор данных более интересен с точки зрения неконтролируемого или полууправляемого обучения.</target>
        </trans-unit>
        <trans-unit id="457f2fe1e264c1b033671c931911858da10508e3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending on the shape of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6893a2ecba3f5b3ceba43b94c7037a23940a0678" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending upon the shape and format of the training data.</source>
          <target state="translated">&amp;laquo;Автоматический&amp;raquo; режим используется по умолчанию и предназначен для выбора более дешевого варианта из двух в зависимости от формы и формата данных обучения.</target>
        </trans-unit>
        <trans-unit id="c686d2e453ba3e5377730ccb9178f9e3372548ba" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;brute&amp;rsquo; method is a generic method that works with any estimator. It approximates the above integral by computing an average over the data &lt;code&gt;X&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f80449b3a36a9645d51b541d6ac4415080a7df2" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;cd&amp;rsquo; solver can only optimize the Frobenius norm. Due to the underlying non-convexity of NMF, the different solvers may converge to different minima, even when optimizing the same distance function.</source>
          <target state="translated">Решатель cd может только оптимизировать норму Фробениуса. Из-за лежащей в основе невыпуклости NMF разные решатели могут сходиться к разным минимумам, даже при оптимизации одной и той же функции расстояния.</target>
        </trans-unit>
        <trans-unit id="370b11b6ae177f24cc2d42a049dda5c0d7e30775" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;eigen&amp;rsquo; solver is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classification and transform, and it supports shrinkage. However, the &amp;lsquo;eigen&amp;rsquo; solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.</source>
          <target state="translated">&amp;laquo;Собственный&amp;raquo; решатель основан на оптимизации разброса между классами до коэффициента разброса внутри классов. Его можно использовать как для классификации, так и для преобразования, и он поддерживает сжатие. Однако &amp;laquo;собственный&amp;raquo; решатель должен вычислять ковариационную матрицу, поэтому он может не подходить для ситуаций с большим количеством функций.</target>
        </trans-unit>
        <trans-unit id="969c56b312ffc26d2c3d7a44ecbd20546b358e11" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see &lt;a href=&quot;sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; for a description.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccda076fda793672987d7568e3ca12c3047fb684" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see SGDRegressor for a description.</source>
          <target state="translated">&amp;laquo;Журнал&amp;raquo; потерь дает логистическую регрессию, вероятностный классификатор. &amp;laquo;Modified_huber&amp;raquo; - еще одна плавная потеря, обеспечивающая устойчивость к выбросам, а также к оценкам вероятности. &quot;squared_hinge&quot; похоже на шарнир, но штрафуется квадратично. &amp;laquo;перцептрон&amp;raquo; - это линейные потери, используемые алгоритмом перцептрона. Другие потери предназначены для регрессии, но также могут быть полезны при классификации; см. SGDRegressor для описания.</target>
        </trans-unit>
        <trans-unit id="960f213c3988b3643a9995192d8dbe5d183a7506" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It needs to explicitly compute the covariance matrix \(\Sigma\), and supports shrinkage. This solver computes the coefficients \(\omega_k = \Sigma^{-1}\mu_k\) by solving for \(\Sigma \omega = \mu_k\), thus avoiding the explicit computation of the inverse \(\Sigma^{-1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5302138e8a256151a982f3c737747f8db1fec2f7" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It supports shrinkage.</source>
          <target state="translated">Решатель lsqr - эффективный алгоритм, который работает только для классификации. Поддерживает усадку.</target>
        </trans-unit>
        <trans-unit id="920a5500dd530a18d71ed258f87f05c8340a0987" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation, or no regularization. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e2a91334301a1b93c477cd479a707ce044fefdf3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">Решатели newton-cg, sag и lbfgs поддерживают только регуляризацию L2 с первичной формулировкой. &amp;laquo;Либлинейный&amp;raquo; решатель поддерживает регуляризацию как L1, так и L2, с двойной формулировкой только для штрафа L2.</target>
        </trans-unit>
        <trans-unit id="f2d81bdc600d48b918368b0b02059bc57b808de5" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;recursion&amp;rsquo; method is faster than the &amp;lsquo;brute&amp;rsquo; method, but it is only supported by some tree-based estimators. It is computed as follows. For a given point \(x_S\), a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed; otherwise both branches are followed, each branch being weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all the visited leaves values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ade2e6c6872bcfb8e63408411f739881d7395764" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;squared_loss&amp;rsquo; refers to the ordinary least squares fit. &amp;lsquo;huber&amp;rsquo; modifies &amp;lsquo;squared_loss&amp;rsquo; to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. &amp;lsquo;epsilon_insensitive&amp;rsquo; ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. &amp;lsquo;squared_epsilon_insensitive&amp;rsquo; is the same but becomes squared loss past a tolerance of epsilon.</source>
          <target state="translated">&amp;laquo;Squared_loss&amp;raquo; относится к обычному методу наименьших квадратов. 'huber' изменяет 'squared_loss', чтобы меньше фокусироваться на исправлении выбросов, переключаясь с квадрата на линейные потери на расстоянии эпсилон. 'epsilon_insensitive' игнорирует ошибки, меньшие чем epsilon, и линейно после этого; это функция потерь, используемая в SVR. &quot;squared_epsilon_insensitive&quot; то же самое, но становится квадратом потерь сверх допуска эпсилон.</target>
        </trans-unit>
        <trans-unit id="d846a2b9506766851ba4d72a28fde6b068825be1" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;svd&amp;rsquo; solver is the default solver used for &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;, and it is the only available solver for &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;. It can perform both classification and transform (for LDA). As it does not rely on the calculation of the covariance matrix, the &amp;lsquo;svd&amp;rsquo; solver may be preferable in situations where the number of features is large. The &amp;lsquo;svd&amp;rsquo; solver cannot be used with shrinkage. For QDA, the use of the SVD solver relies on the fact that the covariance matrix \(\Sigma_k\) is, by definition, equal to \(\frac{1}{n - 1} X_k^tX_k = V S^2 V^t\) where \(V\) comes from the SVD of the (centered) matrix: \(X_k = U S V^t\). It turns out that we can compute the log-posterior above without having to explictly compute \(\Sigma\): computing \(S\) and \(V\) via the SVD of \(X\) is enough. For LDA, two SVDs are computed: the SVD of the centered input matrix \(X\) and the SVD of the class-wise mean vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="388443bd992c152f7c80a788085a15982e280e0a" translate="yes" xml:space="preserve">
          <source>The (scaled) interquartile range for each feature in the training set.</source>
          <target state="translated">(масштабированный)интерквартильный диапазон для каждого элемента тренировочного комплекта.</target>
        </trans-unit>
        <trans-unit id="1db16517be9cf545f06172e2c55188fa78cfa7fa" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new set of features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3533a4edec1fdb05f12a2a421dc320606ca77c6" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new variable</source>
          <target state="translated">Наблюдение (иногда удивительное) заключается в том, что это &lt;em&gt;все еще линейная модель&lt;/em&gt; : чтобы убедиться в этом, представьте, что создаете новую переменную.</target>
        </trans-unit>
        <trans-unit id="ae37fbc1863417aba870f086fd7dcb7d12932667" translate="yes" xml:space="preserve">
          <source>The (x,y) position of the lower-left corner, in degrees</source>
          <target state="translated">Положение (x,y)нижнего левого угла,в градусах...</target>
        </trans-unit>
        <trans-unit id="bcd6ca42c3472afbe27069a62710b5c531496d9b" translate="yes" xml:space="preserve">
          <source>The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper &amp;ldquo;Newsweeder: Learning to filter netnews,&amp;rdquo; though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.</source>
          <target state="translated">Набор данных 20 групп новостей представляет собой набор примерно из 20 000 документов групп новостей, разделенных (почти) равномерно по 20 различным группам новостей. Насколько нам известно, первоначально он был собран Кеном Лэнгом, вероятно, для его статьи &amp;laquo;Newsweeder: обучение фильтрации сетевых новостей&amp;raquo;, хотя он явно не упоминает эту коллекцию. Коллекция 20 групп новостей стала популярным набором данных для экспериментов в текстовых приложениях методов машинного обучения, таких как классификация текста и кластеризация текста.</target>
        </trans-unit>
        <trans-unit id="4b2a042059fffe007deb9ebabf02d8062c1e6bda" translate="yes" xml:space="preserve">
          <source>The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.</source>
          <target state="translated">Набор данных 20 новостных групп включает около 18000 сообщений по 20 темам,разделенных на две подгруппы:одна для обучения (или развития)и другая для тестирования (или оценки эффективности).Разделение между учебным и тестовым набором основано на сообщениях,размещенных до и после определенной даты.</target>
        </trans-unit>
        <trans-unit id="6f66371b5ad2b199bde3ecde676da8dfe31ce717" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#ht2001&quot; id=&quot;id25&quot;&gt;[HT2001]&lt;/a&gt; multiclass AUC metric can be extended to be weighted by the prevalence:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c380ecdb017c04631da3ca1753b6ddf07ce8267f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.cluster&quot;&gt;&lt;code&gt;sklearn.cluster&lt;/code&gt;&lt;/a&gt; module gathers popular unsupervised clustering algorithms.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.cluster&quot;&gt; &lt;code&gt;sklearn.cluster&lt;/code&gt; &lt;/a&gt; собирает популярные алгоритмы неконтролируемой кластеризации.</target>
        </trans-unit>
        <trans-unit id="6a798b177e574d6ff4ac12be7b93e3b8f8d74b71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.covariance&quot;&gt;&lt;code&gt;sklearn.covariance&lt;/code&gt;&lt;/a&gt; module includes methods and algorithms to robustly estimate the covariance of features given a set of points. The precision matrix defined as the inverse of the covariance is also estimated. Covariance estimation is closely related to the theory of Gaussian Graphical Models.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.covariance&quot;&gt; &lt;code&gt;sklearn.covariance&lt;/code&gt; &lt;/a&gt; включает в себя методы и алгоритмы для надежной оценки ковариации признаков по набору точек. Также оценивается матрица точности, определяемая как инверсия ковариации. Оценка ковариации тесно связана с теорией гауссовских графических моделей.</target>
        </trans-unit>
        <trans-unit id="d1230decfda989b60168bc88df7b70ef79122b2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.datasets&quot;&gt;&lt;code&gt;sklearn.datasets&lt;/code&gt;&lt;/a&gt; module includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.datasets&quot;&gt; &lt;code&gt;sklearn.datasets&lt;/code&gt; &lt;/a&gt; включает в себя утилиты для загрузки наборов данных, включая методы для загрузки и получения популярных справочных наборов данных. Он также имеет несколько генераторов искусственных данных.</target>
        </trans-unit>
        <trans-unit id="94bdb0abc615359801b0dde8f5ed432fa774aae6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; module includes matrix decomposition algorithms, including among others PCA, NMF or ICA. Most of the algorithms of this module can be regarded as dimensionality reduction techniques.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt; включает алгоритмы разложения матриц, в том числе, среди прочего, PCA, NMF или ICA. Большинство алгоритмов этого модуля можно рассматривать как методы уменьшения размерности.</target>
        </trans-unit>
        <trans-unit id="cce83af2900332bbe995457713d2e3977e6cea91" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes ensemble-based methods for classification, regression and anomaly detection.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; включает основанные на ансамбле методы классификации, регрессии и обнаружения аномалий.</target>
        </trans-unit>
        <trans-unit id="a3b34965d608c8571221686c4eaa7dd2128cda34" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.exceptions&quot;&gt;&lt;code&gt;sklearn.exceptions&lt;/code&gt;&lt;/a&gt; module includes all custom warnings and error classes used across scikit-learn.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.exceptions&quot;&gt; &lt;code&gt;sklearn.exceptions&lt;/code&gt; &lt;/a&gt; включает все настраиваемые предупреждения и классы ошибок, используемые в scikit-learn.</target>
        </trans-unit>
        <trans-unit id="88149e0dc35a9af4a24d012611fba0cc883c2d66" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.experimental&quot;&gt;&lt;code&gt;sklearn.experimental&lt;/code&gt;&lt;/a&gt; module provides importable modules that enable the use of experimental features or estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="953e85b8304fe86126d3f8d4d49e2c347def818a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module deals with feature extraction from raw data. It currently includes methods to extract features from text and images.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; занимается извлечением функций из необработанных данных. В настоящее время он включает методы для извлечения функций из текста и изображений.</target>
        </trans-unit>
        <trans-unit id="2ff97b1fa019f5f400e3468860cd96aea04f63dc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt;&lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to extract features from images.</source>
          <target state="translated">В &lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt; &lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt; &lt;/a&gt; подмодуль собирает утилиты для извлечения функций из образов.</target>
        </trans-unit>
        <trans-unit id="5fb7f21374928a29d973d39c8eed205507941559" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to build feature vectors from text documents.</source>
          <target state="translated">В &lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; &lt;/a&gt; подмодуль собирает утилиты для построения векторов признаков из текстовых документов.</target>
        </trans-unit>
        <trans-unit id="f8894b12541a4b0b591ccbf9c1c5e42bf4d0c13b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt;&lt;code&gt;sklearn.feature_selection&lt;/code&gt;&lt;/a&gt; module implements feature selection algorithms. It currently includes univariate filter selection methods and the recursive feature elimination algorithm.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt; &lt;code&gt;sklearn.feature_selection&lt;/code&gt; &lt;/a&gt; реализует алгоритмы выбора признаков. В настоящее время он включает методы выбора одномерного фильтра и алгоритм исключения рекурсивных признаков.</target>
        </trans-unit>
        <trans-unit id="af392a06a08e896e0c1f9a845ceba81c0151ed14" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt;&lt;code&gt;sklearn.gaussian_process&lt;/code&gt;&lt;/a&gt; module implements Gaussian Process based regression and classification.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt; &lt;code&gt;sklearn.gaussian_process&lt;/code&gt; &lt;/a&gt; реализует регрессию и классификацию на основе гауссовского процесса.</target>
        </trans-unit>
        <trans-unit id="385213737ec5d4067fe933c56afb4e9039eb2d7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module includes tools for model inspection.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25959a779b184ae02a906c2808f68686c73aab5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt;&lt;code&gt;sklearn.kernel_approximation&lt;/code&gt;&lt;/a&gt; module implements several approximate kernel feature maps base on Fourier transforms.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt; &lt;code&gt;sklearn.kernel_approximation&lt;/code&gt; &lt;/a&gt; реализует несколько приблизительных карт функций ядра на основе преобразований Фурье.</target>
        </trans-unit>
        <trans-unit id="311a58f7516f87097f4b239ae388620a5fb8155d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements a variety of linear models.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf3dc31fd9ef458aef6de4af32bf51a7e61106a1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements generalized linear models. It includes Ridge regression, Bayesian Regression, Lasso and Elastic Net estimators computed with Least Angle Regression and coordinate descent. It also implements Stochastic Gradient Descent related algorithms.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; &lt;/a&gt; реализует обобщенные линейные модели. Он включает оценки хребтовой регрессии, байесовской регрессии, лассо и эластичной сети, рассчитанные с помощью регрессии наименьшего угла и координатного спуска. Он также реализует алгоритмы, связанные со стохастическим градиентным спуском.</target>
        </trans-unit>
        <trans-unit id="75e43c84de91a4a1d643ca88db0beef9e86494b8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.manifold&quot;&gt;&lt;code&gt;sklearn.manifold&lt;/code&gt;&lt;/a&gt; module implements data embedding techniques.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.manifold&quot;&gt; &lt;code&gt;sklearn.manifold&lt;/code&gt; &lt;/a&gt; реализует методы встраивания данных.</target>
        </trans-unit>
        <trans-unit id="f55aa3d6c230d41fe62ec5929fa59e00645b5d62" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module includes score functions, performance metrics and pairwise metrics and distance computations.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; включает в себя функции оценки, метрики производительности, парные метрики и вычисления расстояния.</target>
        </trans-unit>
        <trans-unit id="90553131dabe004a613ea2c87be35b6b6db9a1ae" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt;&lt;code&gt;sklearn.metrics.cluster&lt;/code&gt;&lt;/a&gt; submodule contains evaluation metrics for cluster analysis results. There are two forms of evaluation:</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt; &lt;code&gt;sklearn.metrics.cluster&lt;/code&gt; &lt;/a&gt; подмодуль содержит показатели для оценки результатов кластерного анализа. Есть две формы оценки:</target>
        </trans-unit>
        <trans-unit id="537333336506a029d4e76c0c5320f3e14636c908" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.mixture&quot;&gt;&lt;code&gt;sklearn.mixture&lt;/code&gt;&lt;/a&gt; module implements mixture modeling algorithms.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.mixture&quot;&gt; &lt;code&gt;sklearn.mixture&lt;/code&gt; &lt;/a&gt; реализует алгоритмы моделирования смеси.</target>
        </trans-unit>
        <trans-unit id="1b9bcfe9136ee1328197e574e66457c49aa39ded" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt;&lt;code&gt;sklearn.naive_bayes&lt;/code&gt;&lt;/a&gt; module implements Naive Bayes algorithms. These are supervised learning methods based on applying Bayes&amp;rsquo; theorem with strong (naive) feature independence assumptions.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt; &lt;code&gt;sklearn.naive_bayes&lt;/code&gt; &lt;/a&gt; реализует наивные байесовские алгоритмы. Это контролируемые методы обучения, основанные на применении теоремы Байеса с сильными (наивными) предположениями о независимости функций.</target>
        </trans-unit>
        <trans-unit id="31da4b6c2407f749b7e6e441bc1101265b243a97" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; module implements the k-nearest neighbors algorithm.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt; реализует алгоритм k-ближайших соседей.</target>
        </trans-unit>
        <trans-unit id="637db5b82af4c4775ad8c11b2cc086c407ac4adc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neural_network&quot;&gt;&lt;code&gt;sklearn.neural_network&lt;/code&gt;&lt;/a&gt; module includes models based on neural networks.</source>
          <target state="translated">В модуль &lt;a href=&quot;#module-sklearn.neural_network&quot;&gt; &lt;code&gt;sklearn.neural_network&lt;/code&gt; &lt;/a&gt; входят модели на основе нейронных сетей.</target>
        </trans-unit>
        <trans-unit id="97c84f48ddcbce9eff5bb423de61ca9bed7742a5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline&lt;/code&gt;&lt;/a&gt; module implements utilities to build a composite estimator, as a chain of transforms and estimators.</source>
          <target state="translated">В модуле &lt;a href=&quot;#module-sklearn.pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline&lt;/code&gt; &lt;/a&gt; реализованы утилиты для построения составного оценщика в виде цепочки преобразований и оценщиков.</target>
        </trans-unit>
        <trans-unit id="3e4a3abf94a63259dfe9d5546d6b613a02821c2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization and imputation methods.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt; &lt;code&gt;sklearn.preprocessing&lt;/code&gt; &lt;/a&gt; включает методы масштабирования, центрирования, нормализации, бинаризации и вменения.</target>
        </trans-unit>
        <trans-unit id="f8f509d37a71bbf7a86f10aff8bf2d2fdd437066" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fd91efb13a21a364a66a195be3f60dbc3429cc3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt;&lt;code&gt;sklearn.semi_supervised&lt;/code&gt;&lt;/a&gt; module implements semi-supervised learning algorithms. These algorithms utilized small amounts of labeled data and large amounts of unlabeled data for classification tasks. This module includes Label Propagation.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt; &lt;code&gt;sklearn.semi_supervised&lt;/code&gt; &lt;/a&gt; реализует полууправляемые алгоритмы обучения. Эти алгоритмы использовали небольшие объемы помеченных данных и большие объемы немаркированных данных для задач классификации. Этот модуль включает распространение меток.</target>
        </trans-unit>
        <trans-unit id="6b1e5de562db4c7ae4499c2a4fcb3f75a3027318" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; module includes Support Vector Machine algorithms.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt; включает алгоритмы машины опорных векторов .</target>
        </trans-unit>
        <trans-unit id="ef3c16856f883650f7c10c3b8b62a045804fc7da" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module includes decision tree-based models for classification and regression.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt; включает модели на основе дерева решений для классификации и регрессии.</target>
        </trans-unit>
        <trans-unit id="fd392963cb16a5b60813f22af8246fa4065eb565" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.utils&quot;&gt;&lt;code&gt;sklearn.utils&lt;/code&gt;&lt;/a&gt; module includes various utilities.</source>
          <target state="translated">В модуль &lt;a href=&quot;#module-sklearn.utils&quot;&gt; &lt;code&gt;sklearn.utils&lt;/code&gt; &lt;/a&gt; входят различные утилиты.</target>
        </trans-unit>
        <trans-unit id="9c614be243d558a71ca4ede548ecf4767e4adc7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;simple example on this dataset&lt;/a&gt; illustrates how starting from the original problem one can shape the data for consumption in scikit-learn.</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Простой пример этого набора данных&lt;/a&gt; показывает , как начиная с исходной задачей можно формировать данные для потребления в scikit учиться.</target>
        </trans-unit>
        <trans-unit id="1173339ea4209f3d2d9f369da23b0882a1bab947" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; estimator was entirely re-worked, and it is now significantly faster and more stable. In addition, the Elkan algorithm is now compatible with sparse matrices. The estimator uses OpenMP based parallelism instead of relying on joblib, so the &lt;code&gt;n_jobs&lt;/code&gt; parameter has no effect anymore. For more details on how to control the number of threads, please refer to our &lt;a href=&quot;../../modules/computing#parallelism&quot;&gt;Parallelism&lt;/a&gt; notes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30870f8f1c3b8d652d87325d159164cb4897186f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; now have native support for missing values (NaNs). This means that there is no need for imputing data when training or predicting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d52c41feb33f6dcb3543db8b050b747b486d3d88" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; class is very flexible - it can be used with a variety of estimators to do round-robin regression, treating every variable as an output in turn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20080456681e7e51efd596990b6fe9c5442d5451" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; can be used to get an estimate of the importance of each feature, for any fitted estimator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32ce39f7d5e0bf9b7a13f0705f1c0e1a4677070b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; function returns a &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay&quot;&gt;&lt;code&gt;PartialDependenceDisplay&lt;/code&gt;&lt;/a&gt; object that can be used for plotting without needing to recalculate the partial dependence. In this example, we show how to plot partial dependence plots and how to quickly customize the plot with the visualization API.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa56488b2914a0f1ce166cbc607c029c9e711d0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;sklearn.metrics.mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; depends on a &lt;code&gt;power&lt;/code&gt; parameter. As we do not know the true value of the &lt;code&gt;power&lt;/code&gt; parameter, we here compute the mean deviances for a grid of possible values, and compare the models side by side, i.e. we compare them at identical values of &lt;code&gt;power&lt;/code&gt;. Ideally, we hope that one model will be consistently better than the other, regardless of &lt;code&gt;power&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14b4e05e10f859ded14445d95cdfc3e13fffcfe1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;sklearn.metrics.roc_auc_score&lt;/code&gt;&lt;/a&gt; function can be used for multi-class classification. The multi-class One-vs-One scheme compares every unique pairwise combination of classes. In this section, we calculate the AUC using the OvR and OvO schemes. We report a macro average, and a prevalence-weighted average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f876970ad7209ceedd7d12cc65c7506766be528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; is known to be sensitive to outliers and thus does not perform very well for outlier detection. This estimator is best suited for novelty detection when the training set is not contaminated by outliers. That said, outlier detection in high-dimension, or without any assumptions on the distribution of the inlying data is very challenging, and a One-class SVM might give useful results in these situations depending on the value of its hyperparameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a4f7d548c6a3daf45cbc9aca2408b6479c48a9f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; provides parameters such as &lt;code&gt;min_samples_leaf&lt;/code&gt; and &lt;code&gt;max_depth&lt;/code&gt; to prevent a tree from overfiting. Cost complexity pruning provides another option to control the size of a tree. In &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, this pruning technique is parameterized by the cost complexity parameter, &lt;code&gt;ccp_alpha&lt;/code&gt;. Greater values of &lt;code&gt;ccp_alpha&lt;/code&gt; increase the number of nodes pruned. Here we only show the effect of &lt;code&gt;ccp_alpha&lt;/code&gt; on regularizing the trees and how to choose a &lt;code&gt;ccp_alpha&lt;/code&gt; based on validation scores.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="424aa7402b9869b036306a671e3630b4177e36b0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to fit a sine curve with addition noisy observation. As a result, it learns local linear regressions approximating the sine curve.</source>
          <target state="translated">В &lt;a href=&quot;../../modules/tree#tree&quot;&gt;дереве решений&lt;/a&gt; используются , чтобы соответствовать синусоиде с наблюдением добавления шумного. В результате он изучает локальные линейные регрессии, аппроксимирующие синусоидальную кривую.</target>
        </trans-unit>
        <trans-unit id="eb2cbae46431d84a4889d55d659950b594e78664" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to predict simultaneously the noisy x and y observations of a circle given a single underlying feature. As a result, it learns local linear regressions approximating the circle.</source>
          <target state="translated">В &lt;a href=&quot;../../modules/tree#tree&quot;&gt;деревья решений&lt;/a&gt; используется для прогнозирования одновременно с помехами х и у наблюдений окружности заданной одной основной функцией. В результате он изучает локальные линейные регрессии, аппроксимирующие круг.</target>
        </trans-unit>
        <trans-unit id="4ea0ad8f51ec5bec92f088b272fa90a6ac2d5b55" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function is a data fetching / caching functions that downloads the data archive from the original &lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;20 newsgroups website&lt;/a&gt;, extracts the archive contents in the &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; folder and calls the &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; on either the training or testing set folder, or both of them:</source>
          <target state="translated">Функция &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; - это функция выборки / кэширования данных, которая загружает архив данных с исходного &lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;веб-сайта 20 групп новостей&lt;/a&gt; , извлекает содержимое архива в папке &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; и вызывает &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt; на любом из учебных или папку набора тестов, или оба:</target>
        </trans-unit>
        <trans-unit id="26c038b3ea935758dab579b3237ee5588d78f251" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt;&lt;/a&gt; datasets is subdivided into 3 subsets: the development &lt;code&gt;train&lt;/code&gt; set, the development &lt;code&gt;test&lt;/code&gt; set and an evaluation &lt;code&gt;10_folds&lt;/code&gt; set meant to compute performance metrics using a 10-folds cross validation scheme.</source>
          <target state="translated">В &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt; &lt;/a&gt; наборы данных подразделяются на 3 подмножество: развитие &lt;code&gt;train&lt;/code&gt; набор, разработка &lt;code&gt;test&lt;/code&gt; набор и оценка &lt;code&gt;10_folds&lt;/code&gt; набора предназначены для вычислений метрик производительности с использованием 10-складывает перекрестную схему , проверки.</target>
        </trans-unit>
        <trans-unit id="d14958ad2582740fd909337c2882b7ba18717e2a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes two averaging algorithms based on randomized &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;: the RandomForest algorithm and the Extra-Trees method. Both algorithms are perturb-and-combine techniques &lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998]&lt;/a&gt; specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; включает два алгоритма усреднения на основе рандомизированных &lt;a href=&quot;tree#tree&quot;&gt;деревьев решений&lt;/a&gt; : алгоритм RandomForest и метод Extra-Trees. Оба алгоритма представляют собой методы &amp;laquo;возмущать и комбинировать&amp;raquo; &lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998],&lt;/a&gt; специально разработанные для деревьев. Это означает, что разнообразный набор классификаторов создается путем введения случайности в конструкцию классификатора. Прогноз для ансамбля дается как усредненный прогноз отдельных классификаторов.</target>
        </trans-unit>
        <trans-unit id="fbeef59e0313a7e281a500dd36152abed677fa2e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt; можно использовать для извлечения функций в формате, поддерживаемом алгоритмами машинного обучения, из наборов данных, состоящих из таких форматов, как текст и изображение.</target>
        </trans-unit>
        <trans-unit id="ff270d1b4e640c5be645e763d862de5cbdc56019" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module provides a convenience function &lt;a href=&quot;generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to create one-way and two-way partial dependence plots. In the below example we show how to create a grid of partial dependence plots: two one-way PDPs for the features &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; and a two-way PDP between the two features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="565412031e53246181e593ab56b9ab7f3accb362" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure classification performance. Some metrics might require probability estimates of the positive class, confidence values, or binary decisions values. Most implementations allow each sample to provide a weighted contribution to the overall score, through the &lt;code&gt;sample_weight&lt;/code&gt; parameter.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; реализует несколько функций потерь, оценки и полезности для измерения эффективности классификации. Некоторые метрики могут потребовать оценок вероятности положительного класса, значений достоверности или значений двоичных решений. Большинство реализаций позволяют каждой выборке обеспечивать взвешенный вклад в общую оценку с &lt;code&gt;sample_weight&lt;/code&gt; параметра sample_weight .</target>
        </trans-unit>
        <trans-unit id="6986be647f522d4ad92a86deccdacfb4588f163b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure regression performance. Some of those have been enhanced to handle the multioutput case: &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; реализует несколько функций потерь, оценки и полезности для измерения производительности регрессии. Некоторые из них были расширены , чтобы обработать случай multioutput: &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e3af9dc32993fb04e5c47da4dea690da48a6baa4" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions. For more information see the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section for instance clustering, and &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; for biclustering.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; реализует несколько функций потерь, оценки и полезности. Для получения дополнительной информации см. Раздел &amp;laquo; &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Оценка производительности кластеризации&lt;/a&gt; &amp;raquo; для кластеризации экземпляров и &amp;laquo; &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Оценка бикластеризации&amp;raquo;&lt;/a&gt; для бикластеризации.</target>
        </trans-unit>
        <trans-unit id="095cb4e1ad7cf586616a563cdbf95404fbb2310e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; submodule implements utilities to evaluate pairwise distances or affinity of sets of samples.</source>
          <target state="translated">В &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; подмодуль реализует утилиты для оценки попарных расстояний или сродства наборов образцов.</target>
        </trans-unit>
        <trans-unit id="8e4a825968b52124826a5f75996abc15ec7f1a2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. &lt;code&gt;multioutput&lt;/code&gt; regression is also supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f0063776d96ccddba5880841f7defdb7f0d5d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. Multitarget regression is also supported.</source>
          <target state="translated">В &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; &lt;/a&gt; модуль реализует &lt;em&gt;мету-оценку&lt;/em&gt; для решения &lt;code&gt;multiclass&lt;/code&gt; и &lt;code&gt;multilabel&lt;/code&gt; задач классификации, разлагая такие проблемы в бинарные задачи классификации. Также поддерживается многоцелевой регресс.</target>
        </trans-unit>
        <trans-unit id="8db5d205727541fd60809b9d143967244bf8e79b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt;&lt;code&gt;sklearn.random_projection&lt;/code&gt;&lt;/a&gt; module implements a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes. This module implements two types of unstructured random matrix: &lt;a href=&quot;#gaussian-random-matrix&quot;&gt;Gaussian random matrix&lt;/a&gt; and &lt;a href=&quot;#sparse-random-matrix&quot;&gt;sparse random matrix&lt;/a&gt;.</source>
          <target state="translated">Модуль &lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt; &lt;code&gt;sklearn.random_projection&lt;/code&gt; &lt;/a&gt; реализует простой и эффективный с вычислительной точки зрения способ уменьшить размерность данных, торгуя контролируемой точностью (в качестве дополнительной дисперсии) для более быстрой обработки и меньших размеров модели. Этот модуль реализует два типа неструктурированной случайной матрицы: &lt;a href=&quot;#gaussian-random-matrix&quot;&gt;гауссову матрицу случайных чисел&lt;/a&gt; и &lt;a href=&quot;#sparse-random-matrix&quot;&gt;разреженную матрицу случайных чисел&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a34e8e8e9bf3ccf9c2fa51aff7ed58e5e45bbffa" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; class is used to calibrate a classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaa03339275413a44471cce8ed9110742f7e29fb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt; object performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. The linkage criteria determines the metric used for the merge strategy:</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; выполняет иерархическую кластеризацию, используя восходящий подход: каждое наблюдение начинается в своем собственном кластере, и кластеры последовательно объединяются вместе. Критерии связывания определяют метрику, используемую для стратегии слияния:</target>
        </trans-unit>
        <trans-unit id="913b5a9805377fabb258d2653b5b70e8adeffb2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt;&lt;code&gt;SpectralBiclustering&lt;/code&gt;&lt;/a&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt; &lt;code&gt;SpectralBiclustering&lt;/code&gt; &lt;/a&gt; алгоритм предполагает , что матрица входных данных имеет скрытую структуру шахматной доски. Строки и столбцы матрицы с этой структурой могут быть разделены таким образом, чтобы элементы любого бикластера в декартовом произведении кластеров строк и кластеров столбцов были приблизительно постоянными. Например, если есть два раздела строки и три раздела столбца, каждая строка будет принадлежать трем бикластерам, а каждый столбец будет принадлежать двум бикластерам.</target>
        </trans-unit>
        <trans-unit id="96812a842015efa920168397038c120e6e957561" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt;&lt;code&gt;SpectralCoclustering&lt;/code&gt;&lt;/a&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt; &lt;code&gt;SpectralCoclustering&lt;/code&gt; &lt;/a&gt; алгоритм находит biclusters со значениями выше , чем в других соответствующих строках и столбцах. Каждая строка и каждый столбец принадлежат ровно одному бикластеру, поэтому перестановка строк и столбцов для обеспечения непрерывности разделов показывает эти высокие значения по диагонали:</target>
        </trans-unit>
        <trans-unit id="9debcd56df8be7e32ea091b79dc8e313d63ea1d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Characteristic Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Characteristic Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Characteristic Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt; &lt;code&gt;Birch&lt;/code&gt; &lt;/a&gt; строит дерево называется Характерная черта дерево (CFT) для приведенных данных. Данные по существу сжимаются с потерями до набора узлов характеристик (узлов CF). Узлы CF имеют ряд подкластеров, называемых подкластерами характеристических признаков (подкластеры CF), и эти подкластеры CF, расположенные в нетерминальных узлах CF, могут иметь узлы CF в качестве дочерних.</target>
        </trans-unit>
        <trans-unit id="5792059d2ce9d3e99380df43abdafaacd52cf188" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Clustering Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Clustering Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Clustering Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8b115edebda7f7bf86445503d0ce08900b4f8de" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm views clusters as areas of high density separated by areas of low density. Due to this rather generic view, clusters found by DBSCAN can be any shape, as opposed to k-means which assumes that clusters are convex shaped. The central component to the DBSCAN is the concept of &lt;em&gt;core samples&lt;/em&gt;, which are samples that are in areas of high density. A cluster is therefore a set of core samples, each close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples). There are two parameters to the algorithm, &lt;code&gt;min_samples&lt;/code&gt; and &lt;code&gt;eps&lt;/code&gt;, which define formally what we mean when we say &lt;em&gt;dense&lt;/em&gt;. Higher &lt;code&gt;min_samples&lt;/code&gt; or lower &lt;code&gt;eps&lt;/code&gt; indicate higher density necessary to form a cluster.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt; алгоритм рассматривает кластеры , как районы высокой плотности , разделенных районах с низкой плотностью. Из-за этого довольно общего представления кластеры, найденные с помощью DBSCAN, могут иметь любую форму, в отличие от k-средних, которое предполагает, что кластеры имеют выпуклую форму. Центральным компонентом DBSCAN является концепция &lt;em&gt;образцов керна&lt;/em&gt; , то есть образцов, находящихся в областях с высокой плотностью. Таким образом, кластер представляет собой набор образцов керна, каждый из которых находится близко друг к другу (измеряется с помощью некоторого расстояния), и набор образцов, не относящихся к керну, которые близки к образцу керна (но сами не являются образцами керна). У алгоритма есть два параметра, &lt;code&gt;min_samples&lt;/code&gt; и &lt;code&gt;eps&lt;/code&gt; , которые формально определяют, что мы имеем в виду, когда говорим &amp;laquo; &lt;em&gt;плотный&amp;raquo;&lt;/em&gt; . Высшее &lt;code&gt;min_samples&lt;/code&gt; или меньшие &lt;code&gt;eps&lt;/code&gt; указывают на более высокую плотность, необходимую для формирования кластера.</target>
        </trans-unit>
        <trans-unit id="844222980d29de5ed47698200091f13bdd09a284" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; uses agglomerative clustering to group together features that look very similar, thus decreasing the number of features. It is a dimensionality reduction tool, see &lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;Unsupervised dimensionality reduction&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;FeatureAgglomeration&lt;/code&gt; &lt;/a&gt; использует агломерационную кластеризацию группироваться функциями , которые очень похоже, тем самым уменьшая количество функций. Это инструмент уменьшения размерности, см. &amp;laquo; &lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;Уменьшение размерности без учителя&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="3ccd68ae912b5d8e7b609345a756782aaea1f1b3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;a href=&quot;inertia&quot;&gt;inertia&lt;/a&gt; or within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; алгоритм данных кластеров, пытаясь в отдельные образцы п групп одинаковой дисперсии, сводя к минимуму критерия , известный как &lt;a href=&quot;inertia&quot;&gt;инерция&lt;/a&gt; или внутри-кластера сумм квадратов. Этот алгоритм требует указания количества кластеров. Он хорошо масштабируется для большого количества образцов и используется в широком диапазоне областей применения во многих различных областях.</target>
        </trans-unit>
        <trans-unit id="1ffab773fe637da04ea4c04490bc4a37e92e75f6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;em&gt;inertia&lt;/em&gt; or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8f9ba49e304c2e7e84cbf4122c9838a65e0d463" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; is a variant of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm which uses mini-batches to reduce the computation time, while still attempting to optimise the same objective function. Mini-batches are subsets of the input data, randomly sampled in each training iteration. These mini-batches drastically reduce the amount of computation required to converge to a local solution. In contrast to other algorithms that reduce the convergence time of k-means, mini-batch k-means produces results that are generally only slightly worse than the standard algorithm.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; является вариант &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; алгоритма , который использует мини-серий для уменьшения времени вычислений, в то же время пытается оптимизировать ту же целевую функцию. Мини-пакеты - это подмножества входных данных, которые выбираются случайным образом на каждой итерации обучения. Эти мини-пакеты резко сокращают объем вычислений, необходимых для сходимости к локальному решению. В отличие от других алгоритмов, которые сокращают время сходимости k-средних, мини-пакетные k-средние дают результаты, которые обычно лишь немного хуже, чем стандартный алгоритм.</target>
        </trans-unit>
        <trans-unit id="13f492ae552c222beb8a78a6fea9613c4b7f22e2" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt;&lt;code&gt;OPTICS&lt;/code&gt;&lt;/a&gt; algorithm shares many similarities with the &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm, and can be considered a generalization of DBSCAN that relaxes the &lt;code&gt;eps&lt;/code&gt; requirement from a single value to a value range. The key difference between DBSCAN and OPTICS is that the OPTICS algorithm builds a &lt;em&gt;reachability&lt;/em&gt; graph, which assigns each sample both a &lt;code&gt;reachability_&lt;/code&gt; distance, and a spot within the cluster &lt;code&gt;ordering_&lt;/code&gt; attribute; these two attributes are assigned when the model is fitted, and are used to determine cluster membership. If OPTICS is run with the default value of &lt;em&gt;inf&lt;/em&gt; set for &lt;code&gt;max_eps&lt;/code&gt;, then DBSCAN style cluster extraction can be performed repeatedly in linear time for any given &lt;code&gt;eps&lt;/code&gt; value using the &lt;code&gt;cluster_optics_dbscan&lt;/code&gt; method. Setting &lt;code&gt;max_eps&lt;/code&gt; to a lower value will result in shorter run times, and can be thought of as the maximum neighborhood radius from each point to find other potential reachable points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="381def8c4d001638003d40e7acf9264b0a49ea0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; помогает выполнять различные преобразования для разных столбцов данных, в пределах &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; , который является безопасным от утечки данных и которые могут быть параметризованы. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; работает с массивами, разреженными матрицами и &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;пандами DataFrames&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d5b3cf1eea0426995e81b4c182953586d3dd6af5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37d727244bb97826f98eb0365b95bf6cd4afb239" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; class is experimental and the API is subject to change.</source>
          <target state="translated">Класс &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; является экспериментальным, и API может быть изменен.</target>
        </trans-unit>
        <trans-unit id="36f50b6d2de06293da3e162b3eb7e342568ccd05" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.make_column_transformer#sklearn.compose.make_column_transformer&quot;&gt;&lt;code&gt;make_column_transformer&lt;/code&gt;&lt;/a&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83e5137b54932bec66ccc36542bace6834598b69" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt; estimator uses an l1 penalty to enforce sparsity on the precision matrix: the higher its &lt;code&gt;alpha&lt;/code&gt; parameter, the more sparse the precision matrix. The corresponding &lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt;&lt;code&gt;GraphicalLassoCV&lt;/code&gt;&lt;/a&gt; object uses cross-validation to automatically set the &lt;code&gt;alpha&lt;/code&gt; parameter.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt; &lt;code&gt;GraphicalLasso&lt;/code&gt; &lt;/a&gt; оценщик использует l1 штраф для обеспечения разреженности на высокоточной матрице: чем выше его &lt;code&gt;alpha&lt;/code&gt; - параметр, тем более разреженная точность матрица. Соответствующий объект &lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt; &lt;code&gt;GraphicalLassoCV&lt;/code&gt; &lt;/a&gt; использует перекрестную проверку для автоматической установки &lt;code&gt;alpha&lt;/code&gt; параметра.</target>
        </trans-unit>
        <trans-unit id="4d547fe6e0c2b8c31056c1efceecbd9d17b8cbf1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-score&quot;&gt;score&lt;/a&gt; method that can be used in cross-validation:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9447390bf3cfd368da76e6282f132428b32dfff8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;code&gt;score&lt;/code&gt; method that can be used in cross-validation:</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; также обеспечивает вероятностную интерпретацию PCA, которая может дать вероятность данных на основе величины объясняемой дисперсии. Таким образом, он реализует метод &lt;code&gt;score&lt;/code&gt; который можно использовать при перекрестной проверке:</target>
        </trans-unit>
        <trans-unit id="de1125bcd2177e15b5b35e281621b5bbf18681e1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object is very useful, but has certain limitations for large datasets. The biggest limitation is that &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; only supports batch processing, which means all of the data to be processed must fit in main memory. The &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; object uses a different form of processing and allows for partial computations which almost exactly match the results of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; while processing the data in a minibatch fashion. &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; makes it possible to implement out-of-core Principal Component Analysis either by:</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; очень полезен, но имеет определенные ограничения для больших наборов данных. Самым большим ограничением является то, что &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; поддерживает только пакетную обработку, что означает, что все обрабатываемые данные должны умещаться в основной памяти. Объект &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; &lt;/a&gt; использует другую форму обработки и позволяет выполнять частичные вычисления, которые почти точно соответствуют результатам &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; ,&lt;/a&gt; при обработке данных мини-пакетной обработкой. &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; &lt;/a&gt; позволяет реализовать анализ основных компонентов вне ядра посредством:</target>
        </trans-unit>
        <trans-unit id="ecd6b33d3bd2199aadcf263cff0e5246cde4bd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;SparseCoder&lt;/code&gt;&lt;/a&gt; object is an estimator that can be used to transform signals into sparse linear combination of atoms from a fixed, precomputed dictionary such as a discrete wavelet basis. This object therefore does not implement a &lt;code&gt;fit&lt;/code&gt; method. The transformation amounts to a sparse coding problem: finding a representation of the data as a linear combination of as few dictionary atoms as possible. All variations of dictionary learning implement the following transform methods, controllable via the &lt;code&gt;transform_method&lt;/code&gt; initialization parameter:</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;SparseCoder&lt;/code&gt; &lt;/a&gt; - это средство оценки, которое можно использовать для преобразования сигналов в разреженную линейную комбинацию атомов из фиксированного предварительно вычисленного словаря, такого как базис дискретных вейвлетов. Таким образом, этот объект не реализует метод &lt;code&gt;fit&lt;/code&gt; . Преобразование сводится к проблеме разреженного кодирования: поиск представления данных в виде линейной комбинации как можно меньшего количества атомов словаря. Все варианты обучения словарю реализуют следующие методы преобразования, которыми можно управлять с помощью параметра инициализации &lt;code&gt;transform_method&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="e3da78a60195e1f6e094f14916e2b477c6f8356b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; supports &lt;code&gt;warm_start=True&lt;/code&gt; which allows you to add more trees to an already fitted model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="541c2e4d790ae9e327bfbba2dc5bd507a6c1e503" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt; provide such strategies which can be applied to classification and regression problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8482134b0c48ad8bcdfc22624a585a7b569b1ee" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; can also be used together with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51b760d25143490b212d3dce7b63a475beffe57d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt; function extracts patches from an image stored as a two-dimensional array, or three-dimensional with color information along the third axis. For rebuilding an image from all its patches, use &lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt;&lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt;&lt;/a&gt;. For example let use generate a 4x4 pixel picture with 3 color channels (e.g. in RGB format):</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt; извлекает участки из изображения, хранящегося в виде двухмерного массива, или трехмерного с информацией о цвете по третьей оси. Для восстановления образа из всех его патчей используйте &lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt; &lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt; &lt;/a&gt; . Например, позвольте использовать создание изображения 4x4 пикселя с 3 цветовыми каналами (например, в формате RGB):</target>
        </trans-unit>
        <trans-unit id="13de12da96c62cdbe967814b1ded04e8c85eef13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt;&lt;code&gt;PatchExtractor&lt;/code&gt;&lt;/a&gt; class works in the same way as &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt;, only it supports multiple images as input. It is implemented as an estimator, so it can be used in pipelines. See:</source>
          <target state="translated">Класс &lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt; &lt;code&gt;PatchExtractor&lt;/code&gt; &lt;/a&gt; работает так же, как &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt; , только поддерживает несколько изображений в качестве входных. Он реализован как оценщик, поэтому его можно использовать в конвейерах. Видеть:</target>
        </trans-unit>
        <trans-unit id="5f1d9b11617dc21530d4a8e947334af50d14c144" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; also comes with the following limitations:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt; также поставляется со следующими ограничениями:</target>
        </trans-unit>
        <trans-unit id="dec1e79879a530cf5d8d2ea5bf189d8118bb1961" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for classification purposes, more specifically for probabilistic classification, where test predictions take the form of class probabilities. GaussianProcessClassifier places a GP prior on a latent function \(f\), which is then squashed through a link function to obtain the probabilistic classification. The latent function \(f\) is a so-called nuisance function, whose values are not observed and are not relevant by themselves. Its purpose is to allow a convenient formulation of the model, and \(f\) is removed (integrated out) during prediction. GaussianProcessClassifier implements the logistic link function, for which the integral cannot be computed analytically but is easily approximated in the binary case.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt; реализует гауссовские процессы (GP) для целей классификации, более конкретно для вероятностной классификации, где тест предсказания принимают форму класса вероятностей. GaussianProcessClassifier помещает GP перед скрытой функцией \ (f \), которая затем сжимается с помощью функции ссылки для получения вероятностной классификации. Скрытая функция \ (f \) - это так называемая мешающая функция, значения которой не наблюдаются и не имеют значения сами по себе. Его цель состоит в том, чтобы обеспечить удобную формулировку модели, а \ (f \) удаляется (интегрируется) во время прогнозирования. GaussianProcessClassifier реализует функцию логистической связи, для которой интеграл не может быть вычислен аналитически, но легко аппроксимируется в двоичном случае.</target>
        </trans-unit>
        <trans-unit id="2a70b80f4163a2c6bfd08f3c8b84b458a9627cc7" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by a passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt; &lt;code&gt;GaussianProcessRegressor&lt;/code&gt; &lt;/a&gt; реализует гауссовских процессов (GP) для целей регрессии. Для этого необходимо указать предшествующего врача. Предполагается, что предыдущее среднее значение является постоянным и нулевым (для &lt;code&gt;normalize_y=False&lt;/code&gt; ) или средним значением обучающих данных (для &lt;code&gt;normalize_y=True&lt;/code&gt; ). Ковариация предшествующего уровня определяется передачей объекта &lt;a href=&quot;#gp-kernels&quot;&gt;ядра&lt;/a&gt; . Гиперпараметры ядра оптимизируются во время подгонки GaussianProcessRegressor путем максимизации логарифмического предельного правдоподобия (LML) на основе переданного &lt;code&gt;optimizer&lt;/code&gt; . Поскольку LML может иметь несколько локальных оптимизаторов, оптимизатор можно запускать повторно, указав &lt;code&gt;n_restarts_optimizer&lt;/code&gt; . Первый запуск всегда выполняется, начиная с начальных значений гиперпараметров ядра; последующие прогоны проводятся на основе значений гиперпараметров, выбранных случайным образом из диапазона допустимых значений. Если исходные гиперпараметры следует оставить фиксированными, &lt;code&gt;None&lt;/code&gt; можно передать в качестве оптимизатора.</target>
        </trans-unit>
        <trans-unit id="cef90bbcd0a36066d60f0a9fa46fd7add704859a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a013933edad2184a36ef1d15fcbf21a794c0c7f5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt;&lt;code&gt;ConstantKernel&lt;/code&gt;&lt;/a&gt; kernel can be used as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel where it scales the magnitude of the other factor (kernel) or as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel, where it modifies the mean of the Gaussian process. It depends on a parameter \(constant\_value\). It is defined as:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt; &lt;code&gt;ConstantKernel&lt;/code&gt; &lt;/a&gt; ядро может быть использовано как часть &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; &lt;/a&gt; ядра , где он масштабирует величину других фактора (ядра) или как часть &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt; ядра, где она изменяет среднее значение гауссовского процесса. Это зависит от параметра \ (константа \ _value \). Это определяется как:</target>
        </trans-unit>
        <trans-unit id="a1a78e3b1d5985ce1973c8989ff0075d7d078b79" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is commonly combined with exponentiation. An example with exponent 2 is shown in the following figure:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; ядро обычно сочетается с потенцированием. Пример с показателем степени 2 показан на следующем рисунке:</target>
        </trans-unit>
        <trans-unit id="299194d50f816028e01666a91e5aaf031d88d5c0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter \(\sigma_0^2\). For \(\sigma_0^2 = 0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; ядро нестационарное и может быть получена из линейной регрессии, полагая \ (N (0, 1) \) априорные на коэффициенты \ (x_d (д = 1,..., D) , \) и до из \ (N (0, \ sigma_0 ^ 2) \) по смещению. &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt; ядро инвариантно к вращению координат вокруг начала координат, но не переводы. Параметризуется параметром \ (\ sigma_0 ^ 2 \). Для \ (\ sigma_0 ^ 2 = 0 \) ядро ​​называется однородным линейным ядром, иначе оно неоднородно. Ядро дается формулой</target>
        </trans-unit>
        <trans-unit id="9b254fd92e2584b8ca8c7f30ca756b0bac24ec2b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt;&lt;code&gt;ExpSineSquared&lt;/code&gt;&lt;/a&gt; kernel allows modeling periodic functions. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a periodicity parameter \(p&amp;gt;0\). Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt; &lt;code&gt;ExpSineSquared&lt;/code&gt; &lt;/a&gt; ядро позволяет моделировать периодические функции. Он параметризуется параметром масштаба длины \ (l&amp;gt; 0 \) и параметром периодичности \ (p&amp;gt; 0 \). На данный момент поддерживается только изотропный вариант, где \ (l \) - скаляр. Ядро выдается:</target>
        </trans-unit>
        <trans-unit id="4fa9c3925ee31fe17ddb7d4f95d9aa563f446e7b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt;&lt;code&gt;Matern&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel and a generalization of the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel. It has an additional parameter \(\nu\) which controls the smoothness of the resulting function. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt; &lt;code&gt;Matern&lt;/code&gt; &lt;/a&gt; ядро представляет собой стационарное ядро и обобщение &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; ядра. У него есть дополнительный параметр \ (\ nu \), который контролирует гладкость результирующей функции. Он параметризуется параметром масштаба длины \ (l&amp;gt; 0 \), который может быть либо скаляром (изотропный вариант ядра), либо вектором с тем же числом измерений, что и входы \ (x \) (анизотропный вариант ядра). Ядро выдается:</target>
        </trans-unit>
        <trans-unit id="9cc391d0a3f24c35e3e834b704611ffc08dfc23c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt;&lt;code&gt;RationalQuadratic&lt;/code&gt;&lt;/a&gt; kernel can be seen as a scale mixture (an infinite sum) of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernels with different characteristic length-scales. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a scale mixture parameter \(\alpha&amp;gt;0\) Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt; &lt;code&gt;RationalQuadratic&lt;/code&gt; &lt;/a&gt; ядро может рассматриваться в качестве шкалы смеси (бесконечная сумма) &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; ядер с различной характерной длиной чешуей. Он параметризован параметром масштаба длины \ (l&amp;gt; 0 \) и параметром смеси масштабов \ (\ alpha&amp;gt; 0 \) В настоящее время поддерживается только изотропный вариант, где \ (l \) - скаляр. Ядро выдается:</target>
        </trans-unit>
        <trans-unit id="a0d4e8e5df8534d7f797dec945fa5951797b46d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel. It is also known as the &amp;ldquo;squared exponential&amp;rdquo; kernel. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt; ядра является стационарным ядром. Это также известно как &amp;laquo;квадрат экспоненциального ядра&amp;raquo;. Он параметризуется параметром масштаба длины \ (l&amp;gt; 0 \), который может быть либо скаляром (изотропный вариант ядра), либо вектором с тем же числом измерений, что и входы \ (x \) (анизотропный вариант ядра). Ядро выдается:</target>
        </trans-unit>
        <trans-unit id="82f3fd9dd57bf0bc3cf4c6bc458ae2db6dc1ab71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.knnimputer#sklearn.impute.KNNImputer&quot;&gt;&lt;code&gt;KNNImputer&lt;/code&gt;&lt;/a&gt; class provides imputation for filling in missing values using the k-Nearest Neighbors approach. By default, a euclidean distance metric that supports missing values, &lt;code&gt;nan_euclidean_distances&lt;/code&gt;, is used to find the nearest neighbors. Each missing feature is imputed using values from &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. If a sample has more than one feature missing, then the neighbors for that sample can be different depending on the particular feature being imputed. When the number of available neighbors is less than &lt;code&gt;n_neighbors&lt;/code&gt; and there are no defined distances to the training set, the training set average for that feature is used during imputation. If there is at least one neighbor with a defined distance, the weighted or unweighted average of the remaining neighbors will be used during imputation. If a feature is always missing in training, it is removed during &lt;code&gt;transform&lt;/code&gt;. For more information on the methodology, see ref. &lt;a href=&quot;#ol2001&quot; id=&quot;id5&quot;&gt;[OL2001]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f4b1aa7c1e397df865fdc8d1fd65546b5eaaf2f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative.</source>
          <target state="translated">Преобразователь &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt; полезен для преобразования набора данных в соответствующую двоичную матрицу, указывающую на наличие отсутствующих значений в наборе данных. Это преобразование полезно в сочетании с вменением. При использовании вменения сохранение информации о пропущенных значениях может быть информативным.</target>
        </trans-unit>
        <trans-unit id="a7157e982e0dbd339518050ff3330356266a7d9d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative. Note that both the &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; have the boolean parameter &lt;code&gt;add_indicator&lt;/code&gt; (&lt;code&gt;False&lt;/code&gt; by default) which when set to &lt;code&gt;True&lt;/code&gt; provides a convenient way of stacking the output of the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer with the output of the imputer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c9736c8ad276e3deabee46eb181026e0204e8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports categorical data represented as string values or pandas categoricals when using the &lt;code&gt;'most_frequent'&lt;/code&gt; or &lt;code&gt;'constant'&lt;/code&gt; strategy:</source>
          <target state="translated">Класс &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; также поддерживает категориальные данные, представленные в виде строковых значений или категорий pandas при использовании &lt;code&gt;'most_frequent'&lt;/code&gt; или &lt;code&gt;'constant'&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="4d17103c250c5ab6ac126fd9a857f81de53fed6f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports sparse matrices:</source>
          <target state="translated">Класс &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; также поддерживает разреженные матрицы:</target>
        </trans-unit>
        <trans-unit id="618df5d6360d655fcf582933900e1cb3bcf02379" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. This class also allows for different missing values encodings.</source>
          <target state="translated">Класс &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt; предоставляет базовые стратегии для вменения пропущенных значений. Пропущенные значения могут быть вменены с использованием предоставленного постоянного значения или с использованием статистики (среднего, медианного или наиболее частого) каждого столбца, в котором находятся отсутствующие значения. Этот класс также допускает различные кодировки пропущенных значений.</target>
        </trans-unit>
        <trans-unit id="68b4ceed0ca0d6a56ff0860f4ead39fbe0f8312e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt; function calculates the feature importance of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt; for a given dataset. The &lt;code&gt;n_repeats&lt;/code&gt; parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f59968771d1dbbd03a744853045d3c0b7aa414b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; constructs an approximate mapping for the radial basis function kernel, also known as &lt;em&gt;Random Kitchen Sinks&lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007]&lt;/a&gt;. This transformation can be used to explicitly model a kernel map, prior to applying a linear algorithm, for example a linear SVM:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; строит приближенное отображение для радиальной базисной функции ядра, также известный как &lt;em&gt;Random кухонные раковины &lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007]&lt;/a&gt; . Это преобразование можно использовать для явного моделирования карты ядра перед применением линейного алгоритма, например линейной SVM:</target>
        </trans-unit>
        <trans-unit id="44948166b7a6695399209dd8e1e1f1af0b0058e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; differs from using &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; with loss set to &lt;code&gt;huber&lt;/code&gt; in the following ways.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; &lt;/a&gt; отличается от использования &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt; &lt;code&gt;SGDRegressor&lt;/code&gt; &lt;/a&gt; с множеством потерь для &lt;code&gt;huber&lt;/code&gt; следующих способов.</target>
        </trans-unit>
        <trans-unit id="7ab9e90f2b3f808e98761c90cab46994be6820bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; is different to &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; because it applies a linear loss to samples that are classified as outliers. A sample is classified as an inlier if the absolute error of that sample is lesser than a certain threshold. It differs from &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt;&lt;code&gt;RANSACRegressor&lt;/code&gt;&lt;/a&gt; because it does not ignore the effect of the outliers but gives a lesser weight to them.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; &lt;/a&gt; отличается от &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; , поскольку он применяет линейную потерю для образцов, которые классифицируются как выбросы. Выборка классифицируется как промежуточная, если абсолютная ошибка этой выборки меньше определенного порога. Он отличается от &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt; &lt;code&gt;RANSACRegressor&lt;/code&gt; ,&lt;/a&gt; потому что он не игнорирует влияние выбросов, но придает им меньший вес.</target>
        </trans-unit>
        <trans-unit id="6c9667130f9758bb96a7c943daf0a6616eced1f9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70ef4a25a40856b26fd987533d68c36540345c20" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent. For this reason, the Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero weights (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt; &lt;code&gt;Lasso&lt;/code&gt; &lt;/a&gt; представляет собой линейную модель , которая оценивает разреженные коэффициенты. Это полезно в некоторых контекстах из-за своей тенденции отдавать предпочтение решениям с меньшим количеством значений параметров, эффективно уменьшая количество переменных, от которых зависит данное решение. По этой причине лассо и его варианты являются основополагающими в области восприятия сжатых данных. При определенных условиях он может восстановить точный набор ненулевых весов (см. &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Компрессионное зондирование: реконструкция томографии с предварительным L1 (лассо)&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="eec44edb57da642e68d30eaaa1191346c0a6b209" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c1095adf7bd87312f73373efdee9c54e778b1be" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt; &lt;code&gt;MultiTaskElasticNet&lt;/code&gt; &lt;/a&gt; представляет собой эластичную-чистая модель , которая оценивает разреженные коэффициенты для нескольких задач регрессии совместно: &lt;code&gt;Y&lt;/code&gt; представляет собой 2D массив, по форме &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; . Ограничение заключается в том, что выбранные функции одинаковы для всех задач регрессии, также называемых задачами.</target>
        </trans-unit>
        <trans-unit id="0855f24dbbabd45aa8775e800911f6fb3f3411c3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt;&lt;code&gt;MultiTaskLasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt; &lt;code&gt;MultiTaskLasso&lt;/code&gt; &lt;/a&gt; представляет собой линейную модель , которая оценивает разреженные коэффициенты для нескольких задач регрессии совместно: &lt;code&gt;y&lt;/code&gt; представляет собой 2D массив, по форме &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; . Ограничение заключается в том, что выбранные функции одинаковы для всех задач регрессии, также называемых задачами.</target>
        </trans-unit>
        <trans-unit id="d927ce91bac1b6df649580c487bdf34ce5f21e13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt;&lt;code&gt;Perceptron&lt;/code&gt;&lt;/a&gt; is another simple classification algorithm suitable for large scale learning. By default:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt; &lt;code&gt;Perceptron&lt;/code&gt; &lt;/a&gt; другой простой алгоритм классификации подходит для крупномасштабного обучения. По умолчанию:</target>
        </trans-unit>
        <trans-unit id="114bd6c0908df3918d68db503a6c5b185beb59c6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; regressor has a classifier variant: &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt;. This classifier first converts binary targets to &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task, optimizing the same objective as above. The predicted class corresponds to the sign of the regressor&amp;rsquo;s prediction. For multiclass classification, the problem is treated as multi-output regression, and the predicted class corresponds to the output with the highest value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97c2977337c286541956e3848f1e0d89e23d036d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt; can be significantly faster than e.g. &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with a high number of classes, because it is able to compute the projection matrix \((X^T X)^{-1} X^T\) only once.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc6941408ce5829c04ee30dacb5eec313120d42e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It looses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; &lt;/a&gt; оценка использует обобщение медианы в нескольких измерениях. Таким образом, он устойчив к многомерным выбросам. Однако обратите внимание, что надежность оценки быстро снижается с увеличением размерности проблемы. Он теряет свои свойства устойчивости и становится не лучше, чем обычный метод наименьших квадратов в большой размерности.</target>
        </trans-unit>
        <trans-unit id="6c80a0d39e7d7595f1867b8a38b3ed5fa33131bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It loses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="497dd0db8e84137ac4b140cff3317a3423c09e22" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;accuracy&lt;/a&gt;, either the fraction (default) or the count (normalize=False) of correct predictions.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; функция вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;точность&lt;/a&gt; , либо фракции ( по умолчанию) или количество (нормализует = False) правильных предсказаний.</target>
        </trans-unit>
        <trans-unit id="734b9a83298cb0e5bb404a0eb951bb89a38c30c1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;среднюю точность&lt;/a&gt; (AP) на основе оценок прогнозов. Значение от 0 до 1 и выше - лучше. AP определяется как</target>
        </trans-unit>
        <trans-unit id="e82eb3ff042c4b3a5e1b920dfccc7718db2306b1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c1e547613cb8b25282a0a1d2e2d0fa8b86fab4a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt;&lt;code&gt;balanced_accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;balanced accuracy&lt;/a&gt;, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt; &lt;code&gt;balanced_accuracy_score&lt;/code&gt; &lt;/a&gt; функция вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;взвешенную точность&lt;/a&gt; , что позволяет избежать завышенных оценок производительности на несбалансированных данных. Это среднее макросреднее оценок отзыва по классу или, что то же самое, грубая точность, где каждая выборка взвешивается в соответствии с обратной распространенностью ее истинного класса. Таким образом, для сбалансированных наборов данных оценка равна точности.</target>
        </trans-unit>
        <trans-unit id="6c29a08df4ccee7316d3d3b84f8a1be99122d005" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;brier_score_loss&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;Brier score&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt; &lt;code&gt;brier_score_loss&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;оценку Brier&lt;/a&gt; для двоичных классов. Цитата из Википедии:</target>
        </trans-unit>
        <trans-unit id="446d2ff4c24d7bf4bbe8a92416191f1e2b3de72b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;sklearn.metrics.brier_score_loss&lt;/code&gt;&lt;/a&gt; may be used to evaluate how well a classifier is calibrated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80ef899573ebb3be6112621f7df5aadf4a0d99d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt;&lt;code&gt;classification_report&lt;/code&gt;&lt;/a&gt; function builds a text report showing the main classification metrics. Here is a small example with custom &lt;code&gt;target_names&lt;/code&gt; and inferred labels:</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt; &lt;code&gt;classification_report&lt;/code&gt; &lt;/a&gt; строит текстовый отчет, показывающий основные показатели классификации. Вот небольшой пример с настраиваемыми &lt;code&gt;target_names&lt;/code&gt; и предполагаемыми ярлыками:</target>
        </trans-unit>
        <trans-unit id="297cbd08a7b9d6cdee2db0fac772b51c60ecb158" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion matrix&lt;/a&gt; with each row corresponding to the true class (Wikipedia and other references may use different convention for axes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="646495d784f725b3203da7b1895753c47a46c957" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the confusion matrix with each row corresponding to the true class &amp;lt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt;&amp;gt;`_. (Wikipedia and other references may use different convention for axes.)</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; оценивает точность классификации путем вычисления матрицы путаницы, в которой каждая строка соответствует истинному классу &amp;lt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt; &amp;gt; `_. (Википедия и другие источники могут использовать другое соглашение для осей.)</target>
        </trans-unit>
        <trans-unit id="627c762ce2611d603b6cf9dd93706bacfe9a64ab" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt;&lt;code&gt;coverage_error&lt;/code&gt;&lt;/a&gt; function computes the average number of labels that have to be included in the final prediction such that all true labels are predicted. This is useful if you want to know how many top-scored-labels you have to predict in average without missing any true one. The best value of this metrics is thus the average number of true labels.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt; &lt;code&gt;coverage_error&lt;/code&gt; &lt;/a&gt; функция вычисляет среднее число меток , которые должны быть включены в окончательном предсказании таким образом, что все истинные метки предсказанные. Это полезно, если вы хотите знать, сколько меток с наивысшими баллами вам нужно предсказать в среднем, не пропуская ни одной истинной. Таким образом, наилучшее значение этого показателя - среднее количество истинных ярлыков.</target>
        </trans-unit>
        <trans-unit id="365c5eb64f0dc2e33be205a551210f568e81546d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;explained variance regression score&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;объясненной дисперсии регрессии балл&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="16accfb21d784810c328541c85b1894b818cde8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt;&lt;code&gt;hamming_loss&lt;/code&gt;&lt;/a&gt; computes the average Hamming loss or &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;Hamming distance&lt;/a&gt; between two sets of samples.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt; &lt;code&gt;hamming_loss&lt;/code&gt; &lt;/a&gt; вычисляет среднюю потерю Хэмминга или &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;расстояние Хемминга&lt;/a&gt; между двумя наборами образцов.</target>
        </trans-unit>
        <trans-unit id="6d1238c9791f472ba1850e50c0898d87bebfa2d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function computes the average distance between the model and the data using &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;hinge loss&lt;/a&gt;, a one-sided metric that considers only prediction errors. (Hinge loss is used in maximal margin classifiers such as support vector machines.)</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; вычисляет среднее расстояние между моделью и данными, используя &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;потери на шарнирах&lt;/a&gt; , одностороннюю метрику, которая учитывает только ошибки прогнозирования. (Потери на шарнирах используются в классификаторах максимальной маржи, таких как опорные векторные машины.)</target>
        </trans-unit>
        <trans-unit id="8897c326f42ba94a97047f2763d3dfdfd57b8bb8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_score#sklearn.metrics.jaccard_score&quot;&gt;&lt;code&gt;jaccard_score&lt;/code&gt;&lt;/a&gt; function computes the average of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29930da8eb2c0b1ff7129cc1cbfbb0416883031e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt;&lt;code&gt;jaccard_similarity_score&lt;/code&gt;&lt;/a&gt; function computes the average (default) or sum of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt; &lt;code&gt;jaccard_similarity_score&lt;/code&gt; &lt;/a&gt; вычисляет среднее (по умолчанию) или сумму &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;коэффициентов сходства Жаккара&lt;/a&gt; , также называемых индексом Жаккара, между парами наборов меток.</target>
        </trans-unit>
        <trans-unit id="cbf6f35f94b93c090ec2e48a35d245f91dcfca65" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt;&lt;code&gt;label_ranking_average_precision_score&lt;/code&gt;&lt;/a&gt; function implements label ranking average precision (LRAP). This metric is linked to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function, but is based on the notion of label ranking instead of precision and recall.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt; &lt;code&gt;label_ranking_average_precision_score&lt;/code&gt; &lt;/a&gt; реализует среднюю точность ранжирования меток (LRAP). Эта метрика связана с функцией &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt; , но основана на понятии ранжирования меток, а не на точности и отзыве.</target>
        </trans-unit>
        <trans-unit id="79620a85c10a9be19922ad33cc7395bed79c9e4e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt;&lt;code&gt;label_ranking_loss&lt;/code&gt;&lt;/a&gt; function computes the ranking loss which averages over the samples the number of label pairs that are incorrectly ordered, i.e. true labels have a lower score than false labels, weighted by the inverse of the number of ordered pairs of false and true labels. The lowest achievable ranking loss is zero.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt; &lt;code&gt;label_ranking_loss&lt;/code&gt; &lt;/a&gt; вычисляет потерю ранжирования, которая усредняет по выборкам количество неправильно упорядоченных пар меток, т. Е. Истинные метки имеют более низкий балл, чем ложные метки, взвешенные по величине, обратной количеству упорядоченных пар ложных и истинных меток. Наименьшая возможная потеря рейтинга равна нулю.</target>
        </trans-unit>
        <trans-unit id="4b0810d3cef1ca02b990e21053d774c24a0e430b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt;&lt;code&gt;log_loss&lt;/code&gt;&lt;/a&gt; function computes log loss given a list of ground-truth labels and a probability matrix, as returned by an estimator&amp;rsquo;s &lt;code&gt;predict_proba&lt;/code&gt; method.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt; &lt;code&gt;log_loss&lt;/code&gt; &lt;/a&gt; вычисляет потерю журнала с учетом списка меток истинности и матрицы вероятностей, возвращаемых методом оценки &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3661b0b19cd7cbd747b2bf1ce7b4a383102a7abe" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;Matthew&amp;rsquo;s correlation coefficient (MCC)&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;коэффициент корреляции Мэтью (MCC)&lt;/a&gt; для двоичных классов. Цитата из Википедии:</target>
        </trans-unit>
        <trans-unit id="61afc8dcca66cd062b78b06b9f6f1f6a381f8368" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d67557cc032f22cb8c3e56bc9812e04ade8f8ad" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; function computes the maximum &lt;a href=&quot;https://en.wikipedia.org/wiki/Errors_and_residuals&quot;&gt;residual error&lt;/a&gt; , a metric that captures the worst case error between the predicted value and the true value. In a perfectly fitted single output regression model, &lt;code&gt;max_error&lt;/code&gt; would be &lt;code&gt;0&lt;/code&gt; on the training set and though this would be highly unlikely in the real world, this metric shows the extent of error that the model had when it was fitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8af6e2db7d7843522a3d6755e0b8d1e9cbd1e8f1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean absolute error&lt;/a&gt;, a risk metric corresponding to the expected value of the absolute error loss or \(l1\)-norm loss.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;среднюю абсолютную ошибку&lt;/a&gt; , метрику риска, соответствующую ожидаемому значению потери абсолютной ошибки или \ (l1 \) - потери нормы.</target>
        </trans-unit>
        <trans-unit id="798074cb4600d0906a9ad4975942309f6067f034" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean square error&lt;/a&gt;, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; вычисляет &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;среднеквадратичную ошибку&lt;/a&gt; , метрику риска, соответствующую ожидаемому значению квадратичной (квадратичной) ошибки или убытка.</target>
        </trans-unit>
        <trans-unit id="e4bbccf6d12a691e935e91e2611be809f1bb4329" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; &lt;/a&gt; вычисляет показатель риска, соответствующий ожидаемому значению возведенной в квадрат логарифмической (квадратичной) ошибки или убытка.</target>
        </trans-unit>
        <trans-unit id="9206d6989b69732d0750b8f7b0f0cca35f16a502" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance&quot;&gt;mean Tweedie deviance error&lt;/a&gt; with a &lt;code&gt;power&lt;/code&gt; parameter (\(p\)). This is a metric that elicits predicted expectation values of regression targets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39f48c0bbd67ae6ad01f06368c176486b0da9e3b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; не поддерживает multioutput.</target>
        </trans-unit>
        <trans-unit id="4c03eab2aa446025510f65f3a7e796a70c97a820" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; особенно интересен тем , что он является устойчивым к выбросам. Убыток рассчитывается путем взятия медианы всех абсолютных различий между целью и прогнозом.</target>
        </trans-unit>
        <trans-unit id="9e08c2b58ff3ad56580920cccb403426006e1ddc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function computes class-wise (default) or sample-wise (samplewise=True) multilabel confusion matrix to evaluate the accuracy of a classification. multilabel_confusion_matrix also treats multiclass data as if it were multilabel, as this is a transformation commonly applied to evaluate multiclass problems with binary classification metrics (such as precision, recall, etc.).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f5631acff2238ea5bcb79376fef6d2e143756a6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; computes a precision-recall curve from the ground truth label and a score given by the classifier by varying a decision threshold.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt; вычисляет прецизионной отзыв кривой от этикетки подспутниковой и оценка дается классификатором путем изменения порога принятия решения.</target>
        </trans-unit>
        <trans-unit id="d16f1c84f45a895677960253a6c6c45cf8b671e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; accept an additional value &lt;code&gt;'variance_weighted'&lt;/code&gt; for the &lt;code&gt;multioutput&lt;/code&gt; parameter. This option leads to a weighting of each individual score by the variance of the corresponding target variable. This setting quantifies the globally captured unscaled variance. If the target variables are of different scale, then this score puts more importance on well explaining the higher variance variables. &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; is the default value for &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; for backward compatibility. This will be changed to &lt;code&gt;uniform_average&lt;/code&gt; in the future.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; принять дополнительное значение &lt;code&gt;'variance_weighted'&lt;/code&gt; для &lt;code&gt;multioutput&lt;/code&gt; параметра. Эта опция приводит к взвешиванию каждой отдельной оценки по дисперсии соответствующей целевой переменной. Этот параметр позволяет количественно оценить глобально зафиксированную немасштабированную дисперсию. Если целевые переменные имеют разную шкалу, то этот балл придает большее значение хорошему объяснению переменных с более высокой дисперсией. &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; - значение по умолчанию для &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; для обратной совместимости. В будущем это будет изменено на &lt;code&gt;uniform_average&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="093b69e0a2a3ccbb33c0abc5ad459d307bcf6553" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes R&amp;sup2;, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;. It provides a measure of how well future samples are likely to be predicted by the model. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; вычисляет R&amp;sup2;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;коэффициент детерминации&lt;/a&gt; . Он дает меру того, насколько хорошо будущие образцы могут быть предсказаны моделью. Наилучшая возможная оценка - 1,0, и она может быть отрицательной (потому что модель может быть произвольно хуже). Постоянная модель, которая всегда предсказывает ожидаемое значение y, без учета входных характеристик, получит оценку R ^ 2 равную 0,0.</target>
        </trans-unit>
        <trans-unit id="38084709322f1f775abaac153e1595951318cede" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;, usually denoted as R&amp;sup2;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fdc4c3e65c0a2a9ffbf753fef92ef0300417867" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function can also be used in multi-class classification. Two averaging strategies are currently supported: the one-vs-one algorithm computes the average of the pairwise ROC AUC scores, and the one-vs-rest algorithm computes the average of the ROC AUC scores for each class against all other classes. In both cases, the predicted labels are provided in an array with values from 0 to &lt;code&gt;n_classes&lt;/code&gt;, and the scores correspond to the probability estimates that a sample belongs to a particular class. The OvO and OvR algorithms support weighting uniformly (&lt;code&gt;average='macro'&lt;/code&gt;) and by prevalence (&lt;code&gt;average='weighted'&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cdf15299db25ef1f3b3628cdbe3b0de1b0d0ab3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function computes the area under the receiver operating characteristic (ROC) curve, which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number. For more information see the &lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;Wikipedia article on AUC&lt;/a&gt;.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt; вычисляет площадь под кривой рабочей характеристики приемника (ROC), которая также обозначается AUC или AUROC. При вычислении площади под кривой roc информация о кривой суммируется в одном номере. Для получения дополнительной информации см. &lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;Статью&lt;/a&gt; в Википедии о AUC .</target>
        </trans-unit>
        <trans-unit id="fbc2259a8dc85fa7ed24780d0f0e2ac678fbcad9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; function computes the sum or the average of the 0-1 classification loss (\(L_{0-1}\)) over \(n_{\text{samples}}\). By default, the function normalizes over the sample. To get the sum of the \(L_{0-1}\), set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">Функция &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt; вычисляет сумму или среднее значение потери классификации 0-1 (\ (L_ {0-1} \)) по \ (n _ {\ text {samples}} \). По умолчанию функция нормализуется по выборке. Чтобы получить сумму \ (L_ {0-1} \), установите &lt;code&gt;normalize&lt;/code&gt; в &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0ce78ef531a28f4df4b9620cf7454901e00bf965" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; object implements a variant of the Gaussian mixture model with variational inference algorithms. The API is similar as the one defined by &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; &lt;/a&gt; реализует вариант модели гауссовой смеси с алгоритмами вариационного вывода. API аналогичен API, определенному &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7755b185d3bd9567bc77a31c3d84e8be2c332f90" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; comes with different options to constrain the covariance of the difference classes estimated: spherical, diagonal, tied or full covariance.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; поставляется с различными вариантами , чтобы ограничить ковариации разностных классов оцениваются: сферические, диагональные, привязанным или полные ковариации.</target>
        </trans-unit>
        <trans-unit id="9cb1ef419e28ff804b54eef9fc18747641996ac9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; object implements the &lt;a href=&quot;#expectation-maximization&quot;&gt;expectation-maximization&lt;/a&gt; (EM) algorithm for fitting mixture-of-Gaussian models. It can also draw confidence ellipsoids for multivariate models, and compute the Bayesian Information Criterion to assess the number of clusters in the data. A &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt;&lt;code&gt;GaussianMixture.fit&lt;/code&gt;&lt;/a&gt; method is provided that learns a Gaussian Mixture Model from train data. Given test data, it can assign to each sample the Gaussian it mostly probably belong to using the &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt;&lt;code&gt;GaussianMixture.predict&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">Объект &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt; реализует алгоритм &lt;a href=&quot;#expectation-maximization&quot;&gt;максимизации ожидания&lt;/a&gt; (EM) для подбора смеси гауссовых моделей. Он также может рисовать эллипсоиды уверенности для многомерных моделей и вычислять байесовский информационный критерий для оценки количества кластеров в данных. Предоставляется метод &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt; &lt;code&gt;GaussianMixture.fit&lt;/code&gt; ,&lt;/a&gt; который изучает модель гауссовой смеси на основе данных поезда. Учитывая тестовые данные, он может присвоить каждому образцу значение Гаусса, которому он, скорее всего, принадлежит, используя метод &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt; &lt;code&gt;GaussianMixture.predict&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0716de4b023c33cd11d454f2784cb63c7a79bbcc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; function differs from &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; in two ways:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0de55d1a8cabbad74e59064d298db364a4949211" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; instance implements the usual estimator API: when &amp;ldquo;fitting&amp;rdquo; it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained.</source>
          <target state="translated">В &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; экземпляра реализует обычный API оценки: когда &amp;laquo;уместно&amp;raquo; его на наборе данных все возможные комбинации значений параметров оцениваются и наилучшее сочетание сохраняется.</target>
        </trans-unit>
        <trans-unit id="45a8a9b77f54ed1a1a49e1eebdf058e73c1ad33a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator behaves as a combination of &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;, and generates a sequence of randomized partitions in which a subset of groups are held out for each split.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; &lt;/a&gt; итератор ведет себя как комбинация &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt; , и генерирует последовательность рандомизированных групп , в которых подмножество групп проводятся для каждого раскола.</target>
        </trans-unit>
        <trans-unit id="ec15ef26f9a075815cd5139e68468c23802a4936" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; итератор будет генерировать определенный пользователь число независимых поезда / тестовые наборы данных разделений. Образцы сначала перемешиваются, а затем разделяются на пару наборов поездов и тестов.</target>
        </trans-unit>
        <trans-unit id="9d19931407bdaf26c2091f0ff552c9705b61d84b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; (LOF) algorithm computes a score (called local outlier factor) reflecting the degree of abnormality of the observations. It measures the local density deviation of a given data point with respect to its neighbors. The idea is to detect the samples that have a substantially lower density than their neighbors.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; алгоритм (МВА) вычисляет оценку ( так называемой локальным фактором отклоняющихся значений) , что отражает степень ненормальности наблюдений. Он измеряет локальное отклонение плотности данной точки данных по отношению к ее соседям. Идея состоит в том, чтобы обнаружить образцы, которые имеют значительно меньшую плотность, чем их соседи.</target>
        </trans-unit>
        <trans-unit id="7ee66eef276fb6deecd16d4b6508f3c8417f58ed" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier has a &lt;code&gt;shrink_threshold&lt;/code&gt; parameter, which implements the nearest shrunken centroid classifier. In effect, the value of each feature for each centroid is divided by the within-class variance of that feature. The feature values are then reduced by &lt;code&gt;shrink_threshold&lt;/code&gt;. Most notably, if a particular feature value crosses zero, it is set to zero. In effect, this removes the feature from affecting the classification. This is useful, for example, for removing noisy features.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; классификатор имеет &lt;code&gt;shrink_threshold&lt;/code&gt; параметра, который реализует ближайшую сморщенные медианы классификатора. Фактически, значение каждого объекта для каждого центроида делится на внутриклассовое отклонение этого объекта. Затем значения характеристик уменьшаются на &lt;code&gt;shrink_threshold&lt;/code&gt; . В частности, если значение конкретной функции пересекает ноль, оно устанавливается на ноль. Фактически, это исключает влияние функции на классификацию. Это полезно, например, для удаления шумных элементов.</target>
        </trans-unit>
        <trans-unit id="80f0d0589fbf3ca83c23f0b6ee7bc1939986e528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;sklearn.cluster.KMeans&lt;/code&gt;&lt;/a&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43771e48f74cd166aa989881024956f81686fd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;code&gt;sklearn.KMeans&lt;/code&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; классификатор представляет собой простой алгоритм , который представляет каждый класс, центр тяжести его членов. По сути, это делает его похожим на фазу обновления &lt;code&gt;sklearn.KMeans&lt;/code&gt; алгоритма sklearn.KMeans . У него также нет параметров для выбора, что делает его хорошим базовым классификатором. Однако он страдает от невыпуклых классов, а также когда классы имеют резко различающиеся дисперсии, поскольку предполагается одинаковая дисперсия во всех измерениях. См. Раздел &amp;laquo;Линейный дискриминантный анализ&amp;raquo; ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) и квадратичный дискриминантный анализ ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) для получения более сложных методов, которые не делают этого предположения. Использование по умолчанию &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt; просто:</target>
        </trans-unit>
        <trans-unit id="39bfe25102ea45948a285842eddb73a441e962a3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; is built using a list of &lt;code&gt;(key, value)&lt;/code&gt; pairs, where the &lt;code&gt;key&lt;/code&gt; is a string containing the name you want to give this step and &lt;code&gt;value&lt;/code&gt; is an estimator object:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; построен с использованием списка &lt;code&gt;(key, value)&lt;/code&gt; пар, где &lt;code&gt;key&lt;/code&gt; является строка , содержащая имя , которое вы хотите дать этот шаг и &lt;code&gt;value&lt;/code&gt; является объектом оценки:</target>
        </trans-unit>
        <trans-unit id="c923ad3a865326ec6c72af48e5305bcc89674896" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space on a randomly generated matrix where components are drawn from the following distribution \(N(0, \frac{1}{n_{components}})\).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt; &lt;/a&gt; уменьшает размерность путем проецирования исходного входного пространства на случайно сгенерированную матрице , в которой компоненты взяты из распределения следующей \ (N (0, \ гидроразрыва {1} {N_ {компонента}}) \).</target>
        </trans-unit>
        <trans-unit id="bf402b0deb2f6872588357c0d1a4ee6663793993" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space using a sparse random matrix.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt; &lt;/a&gt; уменьшает размерность путем проецирования исходного входного пространства с помощью разреженной матрицы случайной.</target>
        </trans-unit>
        <trans-unit id="bfc6d74a43acae56b2f26724a2d5ae8338eaf262" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter also supports a variety of aesthetic options, including coloring nodes by their class (or value for regression) and using explicit variable and class names if desired. Jupyter notebooks also render these plots inline automatically:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt; экспортер также поддерживает множество эстетических вариантов, в том числе окраски узлов их класс (или значение регрессии) и используя явные имена переменных и классов , если это необходимо. Блокноты Jupyter также автоматически отображают эти графики встроенными:</target>
        </trans-unit>
        <trans-unit id="7c175b2e5f3e3958b57eb43bc3177612df200e71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/%20Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a15d0b16a3ea1ca7d8280fbccb678c643c12770" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F-measure&lt;/a&gt; (\(F_\beta\) and \(F_1\) measures) can be interpreted as a weighted harmonic mean of the precision and recall. A \(F_\beta\) measure reaches its best value at 1 and its worst score at 0. With \(\beta = 1\), \(F_\beta\) and \(F_1\) are equivalent, and the recall and the precision are equally important.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F-мера&lt;/a&gt; (\ (Р- \ бета \) и \ (F_1 \) меры) можно интерпретировать как взвешенное среднее гармоническое точности и отзыва. Показатель \ (F_ \ beta \) достигает своего наилучшего значения при 1 и худшего результата при 0. При \ (\ beta = 1 \), \ (F_ \ beta \) и \ (F_1 \) эквивалентны, а отзыв и точность одинаково важны.</target>
        </trans-unit>
        <trans-unit id="88cf2fa597f50207550c56a5d725499fc42ad462" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Джонсон-Линденштраусс лемма&lt;/a&gt; утверждает , что любая высокая размерная набор данных может быть случайным образом проецируется в нижнем евклидовом пространстве, контролируя искажение попарных расстояний.</target>
        </trans-unit>
        <trans-unit id="6b941988cfc8d08eb5daa76d4a5974b4197ff783" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; is required to be a fitted estimator. &lt;code&gt;X&lt;/code&gt; can be the data set used to train the estimator or a hold-out set. The permutation importance of a feature is calculated as follows. First, a baseline metric, defined by &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scoring&quot;&gt;scoring&lt;/a&gt;, is evaluated on a (potentially different) dataset defined by the &lt;code&gt;X&lt;/code&gt;. Next, a feature column from the validation set is permuted and the metric is evaluated again. The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96678c00449216bcbe65a0961a8b25b8baf7a396" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class can adapt its number of mixture components automatically. The parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt; has a direct link with the resulting number of components with non-zero weights. Specifying a low value for the concentration prior will make the model put most of the weight on few components set the remaining components weights very close to zero. High values of the concentration prior will allow a larger number of components to be active in the mixture.</source>
          <target state="translated">Класс &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; может автоматически изменять количество компонентов смеси. Параметр &lt;code&gt;weight_concentration_prior&lt;/code&gt; имеет прямую связь с результирующим количеством компонентов с ненулевым весом. Задание низкого значения для предшествующей концентрации заставит модель возложить большую часть веса на несколько компонентов, а вес остальных компонентов будет очень близок к нулю. Высокие значения предварительной концентрации позволят большему количеству компонентов быть активными в смеси.</target>
        </trans-unit>
        <trans-unit id="c17c439e95320993d0276d174b035cd14b7ce3b3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter controls the amount of regularization in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; object: a large value for &lt;code&gt;C&lt;/code&gt; results in less regularization. &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; gives &lt;a href=&quot;#shrinkage&quot;&gt;Shrinkage&lt;/a&gt; (i.e. non-sparse coefficients), while &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; gives &lt;a href=&quot;#sparsity&quot;&gt;Sparsity&lt;/a&gt;.</source>
          <target state="translated">Параметр &lt;code&gt;C&lt;/code&gt; управляет степенью регуляризации в объекте &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; : большее значение &lt;code&gt;C&lt;/code&gt; приводит к меньшей регуляризации. &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; дает &lt;a href=&quot;#shrinkage&quot;&gt;усадку&lt;/a&gt; (т. е. не разреженные коэффициенты), а &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; дает &lt;a href=&quot;#sparsity&quot;&gt;разреженность&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9164d9a9144eaecf5fe284f2e40277e82f0b8068" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter trades off correct classification of training examples against maximization of the decision function&amp;rsquo;s margin. For larger values of &lt;code&gt;C&lt;/code&gt;, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower &lt;code&gt;C&lt;/code&gt; will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words``C`` behaves as a regularization parameter in the SVM.</source>
          <target state="translated">Параметр &lt;code&gt;C&lt;/code&gt; жертвует правильной классификацией обучающих примеров и максимизацией запаса функции принятия решений. Для больших значений &lt;code&gt;C&lt;/code&gt; будет допустим меньший запас, если функция принятия решения лучше правильно классифицирует все обучающие точки. Более низкий &lt;code&gt;C&lt;/code&gt; будет способствовать увеличению запаса, следовательно, более простой функции принятия решений за счет точности обучения. Другими словами, `` C '' ведет себя как параметр регуляризации в SVM.</target>
        </trans-unit>
        <trans-unit id="9aa2de3f6ced8022ed53d959fe2e18d24e70ecf1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DESCR&lt;/code&gt; contains a free-text description of the data, while &lt;code&gt;details&lt;/code&gt; contains a dictionary of meta-data stored by openml, like the dataset id. For more details, see the &lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;OpenML documentation&lt;/a&gt; The &lt;code&gt;data_id&lt;/code&gt; of the mice protein dataset is 40966, and you can use this (or the name) to get more information on the dataset on the openml website:</source>
          <target state="translated">&lt;code&gt;DESCR&lt;/code&gt; содержит свободный текст описания данных, в то время как &lt;code&gt;details&lt;/code&gt; содержит словарь мета-данных , которые хранятся openml, как набор данных ид. Дополнительные сведения см. В &lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;документации OpenML&lt;/a&gt; . &lt;code&gt;data_id&lt;/code&gt; набора данных белка мышей - 40966, и вы можете использовать это (или имя), чтобы получить дополнительную информацию о наборе данных на веб-сайте openml:</target>
        </trans-unit>
        <trans-unit id="388bd8e84c98bb0ce4ff6564cc35fb4e0e8f41db" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; estimator has the most flexibility and is able to predict higher expected values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="81a0037eca65e4ed69e2a49ca4871b0ce138bc10" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Normalizer&lt;/code&gt; rescales the vector for each sample to have unit norm, independently of the distribution of the samples. It can be seen on both figures below where all samples are mapped onto the unit circle. In our example the two selected features have only positive values; therefore the transformed data only lie in the positive quadrant. This would not be the case if some original features had a mix of positive and negative values.</source>
          <target state="translated">&lt;code&gt;Normalizer&lt;/code&gt; перемасштабирует вектор для каждого образца , чтобы иметь единичную норму, независимо от распределения образцов. Это можно увидеть на обоих рисунках ниже, где все образцы нанесены на единичный круг. В нашем примере две выбранные функции имеют только положительные значения; поэтому преобразованные данные лежат только в положительном квадранте. Этого не было бы, если бы некоторые исходные характеристики имели сочетание положительных и отрицательных значений.</target>
        </trans-unit>
        <trans-unit id="c108938c180fba7834742cb26f12054acc7a2184" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;PCA&lt;/code&gt; fitting is only computed at the evaluation of the first configuration of the &lt;code&gt;C&lt;/code&gt; parameter of the &lt;code&gt;LinearSVC&lt;/code&gt; classifier. The other configurations of &lt;code&gt;C&lt;/code&gt; will trigger the loading of the cached &lt;code&gt;PCA&lt;/code&gt; estimator data, leading to save processing time. Therefore, the use of caching the pipeline using &lt;code&gt;memory&lt;/code&gt; is highly beneficial when fitting a transformer is costly.</source>
          <target state="translated">&lt;code&gt;PCA&lt;/code&gt; фитинг вычисляется только при оценке первой конфигурации &lt;code&gt;C&lt;/code&gt; параметра &lt;code&gt;LinearSVC&lt;/code&gt; классификатора. Другие конфигурации &lt;code&gt;C&lt;/code&gt; запускают загрузку кэшированных данных оценщика &lt;code&gt;PCA&lt;/code&gt; , что позволяет сэкономить время обработки. Следовательно, использование кэширования конвейера с использованием &lt;code&gt;memory&lt;/code&gt; очень выгодно, когда установка трансформатора является дорогостоящей.</target>
        </trans-unit>
        <trans-unit id="c287f0a262d74ac1807987cdaae52227ef4012e1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Product&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a3cb6faf35a31966ca4f91d6d7c341a997f291b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17baab07595bc9a1b9010bf52fc5ebb7c1555943" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;RandomForestClassifier&lt;/code&gt; обучаются с использованием &lt;em&gt;агрегации начальной загрузки&lt;/em&gt; , где каждое новое дерево подходит из образца начальной загрузки учебных наблюдений \ (z_i = (x_i, y_i) \). &lt;em&gt;Вне мешка&lt;/em&gt; (OOB) ошибка средней ошибки для каждого \ в соответствующей выборке начальной загрузки (z_i \) вычисляется с использованием предсказания с деревьев , которые не содержат \ (z_i \). Это позволяет &lt;code&gt;RandomForestClassifier&lt;/code&gt; соответствовать и проверять во время обучения &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b88cefdaf9f96b3cdafb06bfae8af6e9f9c7d591" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Ridge&lt;/code&gt; regression model can predict very low expected frequencies that do not match the data. It can therefore severly under-estimate the risk for some policyholders.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fcb1f40315317ee430343ccf6429ac412e1cf20" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralBiclustering&lt;/code&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d62b9583d10d4cdba8ebe8ca76f4a0cc3bafcf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralCoclustering&lt;/code&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2977d18fbb46e84c7bb310b8e5bfcc96a3f259f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Sum&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="093b9af7ff877738a1c191bf8fe58f666ce1b93c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;VotingClassifier&lt;/code&gt; can also be used together with &lt;code&gt;GridSearch&lt;/code&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="translated">&lt;code&gt;VotingClassifier&lt;/code&gt; также может быть использован вместе с &lt;code&gt;GridSearch&lt;/code&gt; для того , чтобы настроиться на гиперпараметрах индивидуальных оценок:</target>
        </trans-unit>
        <trans-unit id="a92f24d7703ca3728952e82f17755a0b7604fe2c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the coefficients estimated.</source>
          <target state="translated">Параметр &lt;code&gt;alpha&lt;/code&gt; управляет степенью разреженности оцениваемых коэффициентов.</target>
        </trans-unit>
        <trans-unit id="315ca80415fed5e99f9417365418d048de6cb5f9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the estimated coefficients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d22b7c9a5ce685adf8551f77a733c13cab8fe2d4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;best_estimator_&lt;/code&gt;, &lt;code&gt;best_index_&lt;/code&gt;, &lt;code&gt;best_score_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; correspond to the scorer (key) that is set to the &lt;code&gt;refit&lt;/code&gt; attribute.</source>
          <target state="translated">&lt;code&gt;best_estimator_&lt;/code&gt; , &lt;code&gt;best_index_&lt;/code&gt; , &lt;code&gt;best_score_&lt;/code&gt; и &lt;code&gt;best_params_&lt;/code&gt; соответствуют (ключу) бомбардира , который установлен в &lt;code&gt;refit&lt;/code&gt; атрибута.</target>
        </trans-unit>
        <trans-unit id="ea04fcbf02a8de4070a990d8e4f932cdf0278b0d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of precision in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; only recall).</source>
          <target state="translated">Параметр &lt;code&gt;beta&lt;/code&gt; определяет вес точности в объединенной оценке. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; придает больший вес точности, тогда как &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; способствует отзыву ( &lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; учитывает только точность, &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; только отзыв).</target>
        </trans-unit>
        <trans-unit id="baaa5bd4c537184b8165bf82e50573a6954bd1a3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of recall in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; +inf&lt;/code&gt; only recall).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cbc8f71751f51b8523a564fa7c56816a950df46" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;clf&lt;/code&gt; (for classifier) estimator instance is first fitted to the model; that is, it must &lt;em&gt;learn&lt;/em&gt; from the model. This is done by passing our training set to the &lt;code&gt;fit&lt;/code&gt; method. For the training set, we&amp;rsquo;ll use all the images from our dataset, except for the last image, which we&amp;rsquo;ll reserve for our predicting. We select the training set with the &lt;code&gt;[:-1]&lt;/code&gt; Python syntax, which produces a new array that contains all but the last item from &lt;code&gt;digits.data&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;clf&lt;/code&gt; (для классификаторов) экземпляра оценивани сначала устанавливается на модели; то есть он должен &lt;em&gt;учиться&lt;/em&gt; на модели. Это делается путем передачи нашего обучающего набора методу &lt;code&gt;fit&lt;/code&gt; . Для обучающего набора мы будем использовать все изображения из нашего набора данных, за исключением последнего изображения, которое мы зарезервируем для нашего прогнозирования. Мы выбираем обучающий набор с помощью синтаксиса Python &lt;code&gt;[:-1]&lt;/code&gt; , который создает новый массив, содержащий все, кроме последнего элемента из &lt;code&gt;digits.data&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="0655de3e2b717fc73c590188fdaa9881c37414a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cross_validate&lt;/code&gt; function differs from &lt;code&gt;cross_val_score&lt;/code&gt; in two ways -</source>
          <target state="translated">Функция &lt;code&gt;cross_validate&lt;/code&gt; отличается от &lt;code&gt;cross_val_score&lt;/code&gt; двумя способами:</target>
        </trans-unit>
        <trans-unit id="f3aad90428722c87b3422d97c1856aa8204966ed" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cv_results_&lt;/code&gt; parameter can be easily imported into pandas as a &lt;code&gt;DataFrame&lt;/code&gt; for further inspection.</source>
          <target state="translated">Параметр &lt;code&gt;cv_results_&lt;/code&gt; можно легко импортировать в pandas как &lt;code&gt;DataFrame&lt;/code&gt; для дальнейшей проверки.</target>
        </trans-unit>
        <trans-unit id="6d0144f231c5dfa868fda545c176e4a6eca95147" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;data_id&lt;/code&gt; also uniquely identifies a dataset from OpenML:</source>
          <target state="translated">&lt;code&gt;data_id&lt;/code&gt; также уникально идентифицирует набор данных из OpenML:</target>
        </trans-unit>
        <trans-unit id="7bfd5d978dedbc7159d3a401f357dd25ad25428a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers:</source>
          <target state="translated">&lt;code&gt;decision_function&lt;/code&gt; метод также определяются из функции подсчета очков, таким образом , что отрицательные значения являются выбросы и неотрицательных из них являются inliers:</target>
        </trans-unit>
        <trans-unit id="bc22b4069c85e3e1ecbf3c942877625aea87d185" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling &lt;a href=&quot;#id11&quot; id=&quot;id2&quot;&gt;9&lt;/a&gt;: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per &lt;a href=&quot;#id12&quot; id=&quot;id3&quot;&gt;10&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62eacbcbc4132ef1f5317a0a939d640165e31df3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per Wu et al. (2004).</source>
          <target state="translated">&lt;code&gt;decision_function&lt;/code&gt; метод &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; дает по классам баллов для каждого образца (или единого показателя на образец в двоичном случае). Когда &lt;code&gt;probability&lt;/code&gt; параметра конструктора установлена ​​в значение &lt;code&gt;True&lt;/code&gt; , оценки вероятности членства в классе (из методов &lt;code&gt;predict_proba&lt;/code&gt; и &lt;code&gt;predict_log_proba&lt;/code&gt; ) включены. В двоичном случае вероятности калибруются с использованием шкалы Платта: логистическая регрессия по оценкам SVM, согласованная с помощью дополнительной перекрестной проверки данных обучения. В случае мультикласса это расширено согласно Wu et al. (2004).</target>
        </trans-unit>
        <trans-unit id="cacd73f2ee1bdb21ccf547bfa27f031af8d1c84f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;estimators&lt;/code&gt; parameter corresponds to the list of the estimators which are stacked together in parallel on the input data. It should be given as a list of names and estimators:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="912eed5f20931cd928be8a8b3c3891f77622f73b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to return all features whether or not they contain missing values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac9899847d23144b2277382b5ec5bf6360733941" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to returned all features whether or not they contain missing values:</source>
          <target state="translated">Для параметра &lt;code&gt;features&lt;/code&gt; можно установить значение &lt;code&gt;'all'&lt;/code&gt; чтобы возвращались все функции, независимо от того, содержат ли они отсутствующие значения:</target>
        </trans-unit>
        <trans-unit id="0e29ac108f496200ac17f2eb1912fca379623586" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter is used to choose the features for which the mask is constructed. By default, it is &lt;code&gt;'missing-only'&lt;/code&gt; which returns the imputer mask of the features containing missing values at &lt;code&gt;fit&lt;/code&gt; time:</source>
          <target state="translated">Параметр &lt;code&gt;features&lt;/code&gt; используется для выбора функций, для которых создается маска. По умолчанию это &lt;code&gt;'missing-only'&lt;/code&gt; что возвращает маску импутера функций, содержащих пропущенные значения во время &lt;code&gt;fit&lt;/code&gt; времени:</target>
        </trans-unit>
        <trans-unit id="9c67ef88019a1b7e1168b9363c0a3a8856eb06c6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;final_estimator&lt;/code&gt; will use the predictions of the &lt;code&gt;estimators&lt;/code&gt; as input. It needs to be a classifier or a regressor when using &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt;, respectively:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b06298ca8347e48ebdf3df08a4c5d05e9d2dcbb" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;fit&lt;/code&gt; function takes two arguments: &lt;code&gt;n_components&lt;/code&gt;, which is the target dimensionality of the feature transform, and &lt;code&gt;gamma&lt;/code&gt;, the parameter of the RBF-kernel. A higher &lt;code&gt;n_components&lt;/code&gt; will result in a better approximation of the kernel and will yield results more similar to those produced by a kernel SVM. Note that &amp;ldquo;fitting&amp;rdquo; the feature function does not actually depend on the data given to the &lt;code&gt;fit&lt;/code&gt; function. Only the dimensionality of the data is used. Details on the method can be found in &lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; функция принимает два аргумента: &lt;code&gt;n_components&lt;/code&gt; , что является целевой мерность функции преобразования и &lt;code&gt;gamma&lt;/code&gt; , параметр в RBF-ядра. Более высокое значение &lt;code&gt;n_components&lt;/code&gt; приведет к лучшему приближению ядра и даст результаты, более похожие на результаты, полученные с помощью SVM ядра. Обратите внимание , что &amp;laquo;установка&amp;raquo; функция функции фактически не зависит от данных , приведенных в &lt;code&gt;fit&lt;/code&gt; функции. Используется только размерность данных. Подробную информацию о методе можно найти в &lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="24f4fe27df1296a0eb0115a0bb0e2832f2225923" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;id&lt;/code&gt; of each check is set to be a pprint version of the estimator and the name of the check with its keyword arguments. This allows to use &lt;code&gt;pytest -k&lt;/code&gt; to specify which tests to run:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8f8ea902ec10f43c9cca575477617a393bf1406" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;increasing&lt;/code&gt; parameter changes the constraint to \(\hat{y}_i \ge \hat{y}_j\) whenever \(X_i \le X_j\). Setting it to &amp;lsquo;auto&amp;rsquo; will automatically choose the constraint based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&quot;&gt;Spearman&amp;rsquo;s rank correlation coefficient&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f460a2e1f3d0337b4c58660913081d08e87c0f52" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;4&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="759d68cbc1b0e0c960b6f5234a5fe3b985174684" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="translated">&lt;code&gt;init&lt;/code&gt; атрибутов определяет метод инициализации применяется, который имеет большое влияние на производительность способа. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; реализует метод &amp;laquo;Разложение на неотрицательное двойное сингулярное значение&amp;raquo;. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt; основан на двух процессах SVD, один из которых аппроксимирует матрицу данных, а другой аппроксимирует положительные части результирующих частных коэффициентов SVD, используя алгебраическое свойство матриц единичного ранга. Базовый алгоритм NNDSVD лучше подходит для разреженной факторизации. Его варианты NNDSVDa (в котором все нули установлены равными среднему значению всех элементов данных) и NNDSVDar (в котором нули установлены для случайных возмущений, меньших, чем среднее значение данных, деленное на 100) рекомендуются в плотном кейс.</target>
        </trans-unit>
        <trans-unit id="dae4c344a8a96bf6754b4ff3002f4e9350562dbc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; attribute holds the intercept (aka offset or bias):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aaf2ff68858d9c24eece58235794e4a322e1ce9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; member is not converted.</source>
          <target state="translated">&lt;code&gt;intercept_&lt;/code&gt; член не преобразуется.</target>
        </trans-unit>
        <trans-unit id="0e6b2b935d052640da205c359a0d82666ebb9942" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; functions allow to identify and reject degenerate combinations of random sub-samples. If the estimated model is not needed for identifying degenerate cases, &lt;code&gt;is_data_valid&lt;/code&gt; should be used as it is called prior to fitting the model and thus leading to better computational performance.</source>
          <target state="translated">Функции &lt;code&gt;is_data_valid&lt;/code&gt; и &lt;code&gt;is_model_valid&lt;/code&gt; позволяют идентифицировать и отклонять вырожденные комбинации случайных подвыборок. Если оценочная модель не требуется для выявления вырожденных случаев, следует использовать &lt;code&gt;is_data_valid&lt;/code&gt; , поскольку он вызывается до подгонки модели и, таким образом, приводит к повышению производительности вычислений.</target>
        </trans-unit>
        <trans-unit id="dee80932cbc9425c512fa33535be444f8c4ddfa6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;l2_regularization&lt;/code&gt; parameter is a regularizer on the loss function and corresponds to \(\lambda\) in equation (2) of &lt;a href=&quot;#xgboost&quot; id=&quot;id26&quot;&gt;[XGBoost]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1aa8bc8d7f393abce9beb6161257c50a1665624" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots.</source>
          <target state="translated">В &lt;code&gt;len(features)&lt;/code&gt; участки расположены в сетке с &lt;code&gt;n_cols&lt;/code&gt; колоннами. Графики двусторонней частичной зависимости построены в виде изолиний.</target>
        </trans-unit>
        <trans-unit id="da451cbcbf87abb0e9a3cde3e39db4fedec8991d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots. The deciles of the feature values will be shown with tick marks on the x-axes for one-way plots, and on both axes for two-way plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d39915194cee376ca662b61de9924274942d60a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;make_columntransformer&lt;/code&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="translated">Функция &lt;code&gt;make_columntransformer&lt;/code&gt; доступна для более простого создания объекта &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt; . В частности, имена будут даны автоматически. Эквивалент для приведенного выше примера:</target>
        </trans-unit>
        <trans-unit id="e3ab7886f45f0e5bcfcb494c5dda13f6aee54058" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_fit_time&lt;/code&gt;, &lt;code&gt;std_fit_time&lt;/code&gt;, &lt;code&gt;mean_score_time&lt;/code&gt; and &lt;code&gt;std_score_time&lt;/code&gt; are all in seconds.</source>
          <target state="translated">Значения &lt;code&gt;mean_fit_time&lt;/code&gt; , &lt;code&gt;std_fit_time&lt;/code&gt; , &lt;code&gt;mean_score_time&lt;/code&gt; и &lt;code&gt;std_score_time&lt;/code&gt; указаны в секундах.</target>
        </trans-unit>
        <trans-unit id="5067a7dbb7441ffa442bc35298e784d3bbb5d81c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;out_of_bounds&lt;/code&gt; parameter handles how &lt;code&gt;X&lt;/code&gt; values outside of the training domain are handled. When set to &amp;ldquo;nan&amp;rdquo;, predictions will be NaN. When set to &amp;ldquo;clip&amp;rdquo;, predictions will be set to the value corresponding to the nearest train interval endpoint. When set to &amp;ldquo;raise&amp;rdquo; a &lt;code&gt;ValueError&lt;/code&gt; is raised.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dc710fdb008b124893854b1db0d772123e2f23c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;out_of_bounds&lt;/code&gt; parameter handles how x-values outside of the training domain are handled. When set to &amp;ldquo;nan&amp;rdquo;, predicted y-values will be NaN. When set to &amp;ldquo;clip&amp;rdquo;, predicted y-values will be set to the value corresponding to the nearest train interval endpoint. When set to &amp;ldquo;raise&amp;rdquo;, allow &lt;code&gt;interp1d&lt;/code&gt; to throw ValueError.</source>
          <target state="translated">Параметр &lt;code&gt;out_of_bounds&lt;/code&gt; управляет тем, как обрабатываются значения x вне области обучения. Если установлено значение &amp;laquo;nan&amp;raquo;, прогнозируемые значения y будут NaN. Если установлено значение &amp;laquo;clip&amp;raquo;, прогнозируемые значения y будут установлены на значение, соответствующее ближайшей конечной точке интервала поезда. Если установлено значение &amp;laquo;raise&amp;raquo;, разрешить &lt;code&gt;interp1d&lt;/code&gt; выбросить ValueError.</target>
        </trans-unit>
        <trans-unit id="3c0e73047db48d9d2c7fabbdd5b52d96e2b806a9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;partial_fit&lt;/code&gt; method call of naive Bayes models introduces some computational overhead. It is recommended to use data chunk sizes that are as large as possible, that is as the available RAM allows.</source>
          <target state="translated">&lt;code&gt;partial_fit&lt;/code&gt; вызов метода наивных моделей Байеса представляет некоторую вычислительную нагрузку. Рекомендуется использовать как можно больший размер блоков данных, т.е. насколько позволяет доступная оперативная память.</target>
        </trans-unit>
        <trans-unit id="12fb3214c445789e7d1fb007eb13c0f9c87b3271" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;penalty&lt;/code&gt; parameter determines the regularization to be used (see description above in the classification section).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c075895944959b3ce70972d2605db496c74ee36b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;preprocessing&lt;/code&gt; module further provides a utility class &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt;&lt;code&gt;Normalizer&lt;/code&gt;&lt;/a&gt; that implements the same operation using the &lt;code&gt;Transformer&lt;/code&gt; API (even though the &lt;code&gt;fit&lt;/code&gt; method is useless in this case: the class is stateless as this operation treats samples independently).</source>
          <target state="translated">Модуль &lt;code&gt;preprocessing&lt;/code&gt; также предоставляет служебный класс &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt; &lt;code&gt;Normalizer&lt;/code&gt; ,&lt;/a&gt; который реализует ту же операцию с использованием &lt;code&gt;Transformer&lt;/code&gt; API (даже несмотря на то, что в этом случае метод &lt;code&gt;fit&lt;/code&gt; бесполезен: класс не имеет состояния, поскольку эта операция обрабатывает образцы независимо).</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
