<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="a344504140059db6f88458066c961354f795c6a7" translate="yes" xml:space="preserve">
          <source>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">Этот метод имеет некоторые накладные расходы на производительность,поэтому для сокрытия накладных расходов лучше вызвать функцию partial_fit на максимально больших кусках данных (до тех пор,пока они подгоняются под бюджет памяти).</target>
        </trans-unit>
        <trans-unit id="ceeeb1e178fb9959d4ffe786c9917a8fc68013bb" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity than an &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">Этот метод имеет тот же порядок сложности, что и &lt;a href=&quot;#ordinary-least-squares&quot;&gt;обычный&lt;/a&gt; метод наименьших квадратов .</target>
        </trans-unit>
        <trans-unit id="8149d43c4db3023940e20ddee18dfd4caaeb24b1" translate="yes" xml:space="preserve">
          <source>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</source>
          <target state="translated">Предполагается,что этот метод будет вызываться несколько раз подряд на различных участках массива данных,чтобы реализовать внеядерное или онлайн-обучение.</target>
        </trans-unit>
        <trans-unit id="7914e16bc2009e2d4fc76b2006a65a031a42eb76" translate="yes" xml:space="preserve">
          <source>This method is just there to implement the usual API and hence work in pipelines.</source>
          <target state="translated">Этот метод как раз и используется для реализации обычного API и,следовательно,для работы в трубопроводах.</target>
        </trans-unit>
        <trans-unit id="53a4e9f6af590018ff1a37b6f68db2405dd79282" translate="yes" xml:space="preserve">
          <source>This method is just there to mark the fact that this transformer can work in a streaming setup.</source>
          <target state="translated">Этот метод предназначен только для того,чтобы отметить тот факт,что этот трансформатор может работать в потоковой установке.</target>
        </trans-unit>
        <trans-unit id="1ad1f3e2c791502dcf55d0ea0c930c86843ade76" translate="yes" xml:space="preserve">
          <source>This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.</source>
          <target state="translated">Этот метод предназначен для одновременного вызова многопроцессорного обратного вызова.Мы полагаемся на потокобезопасность send_one_batch для защиты от одновременного потребления незащищенного итератора.</target>
        </trans-unit>
        <trans-unit id="4e81340dab29281a8d6b3bd99833383bb408f46c" translate="yes" xml:space="preserve">
          <source>This method is not deterministic: it computes a quantity called the free energy on X, then on a randomly corrupted version of X, and returns the log of the logistic function of the difference.</source>
          <target state="translated">Этот метод не детерминирован:он вычисляет величину,называемую свободной энергией по Х,затем по случайно испорченной версии Х,и возвращает журнал логистической функции разницы.</target>
        </trans-unit>
        <trans-unit id="483c17ab697933f17e74386d9739e36cf3fc93e7" translate="yes" xml:space="preserve">
          <source>This method is only available for log loss and modified Huber loss.</source>
          <target state="translated">Этот метод доступен только для потерь журнала и модифицированных потерь Huber.</target>
        </trans-unit>
        <trans-unit id="d7475ebc10f647671bee9a4be7afee1b81279276" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Этот метод обеспечивает безопасный способ взять на вход матрицу расстояний,сохраняя при этом совместимость со многими другими алгоритмами,которые берут векторный массив.</target>
        </trans-unit>
        <trans-unit id="b5d8e2fef5ebecb0c66f96f2926a64438412f355" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a kernel matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">Этот метод обеспечивает безопасный способ взять на вход матрицу кернела,сохраняя при этом совместимость со многими другими алгоритмами,которые берут векторный массив.</target>
        </trans-unit>
        <trans-unit id="0fc2db598aaa9c1a0947d8f73a1238d30285a532" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed. If the input is a distances matrix, it is returned instead.</source>
          <target state="translated">Этот метод принимает либо векторный массив,либо матрицу расстояний и возвращает матрицу расстояний.Если на входе находится векторный массив,то вычисляются расстояния.Если входной сигнал является матрицей расстояний,то он возвращается.</target>
        </trans-unit>
        <trans-unit id="924736c0bae89c3f4376281e6a105fa549739eb4" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a kernel matrix, and returns a kernel matrix. If the input is a vector array, the kernels are computed. If the input is a kernel matrix, it is returned instead.</source>
          <target state="translated">Этот метод берет либо векторный массив,либо матрицу кернела и возвращает матрицу кернела.Если на входе находится векторный массив,то вычисляются кернелы.Если входной сигнал является матрицей кернела,то он возвращается.</target>
        </trans-unit>
        <trans-unit id="b80df7fbbffdde8aff9c30af4a5bee17e602075b" translate="yes" xml:space="preserve">
          <source>This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.</source>
          <target state="translated">Этот метод преобразует характеристики,чтобы следовать равномерному или нормальному распределению.Таким образом,для данного признака это преобразование имеет тенденцию распределять наиболее часто встречающиеся значения.Оно также уменьшает влияние (предельных)отклонений:таким образом,это надежная схема предварительной обработки.</target>
        </trans-unit>
        <trans-unit id="4a6448f2646e45809baed97b35289a513191212b" translate="yes" xml:space="preserve">
          <source>This method works similarly to the builtin &lt;code&gt;apply&lt;/code&gt;, except that the function is called only if the cache is not up to date.</source>
          <target state="translated">Этот метод работает аналогично встроенной функции &lt;code&gt;apply&lt;/code&gt; , за исключением того, что функция вызывается только в том случае, если кеш не обновлен.</target>
        </trans-unit>
        <trans-unit id="3b270b097c02b54b15c6706faba2a05992e48391" translate="yes" xml:space="preserve">
          <source>This metric is furthermore symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.</source>
          <target state="translated">Более того, эта метрика симметрична: переключение &lt;code&gt;label_true&lt;/code&gt; на &lt;code&gt;label_pred&lt;/code&gt; вернет то же значение оценки. Это может быть полезно для измерения соответствия двух независимых стратегий присвоения меток одному и тому же набору данных, когда истинная достоверность неизвестна.</target>
        </trans-unit>
        <trans-unit id="b8da4b4fabd4786b82c03e2c15a17659173e15c8" translate="yes" xml:space="preserve">
          <source>This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score value in any way.</source>
          <target state="translated">Эта метрика не зависит от абсолютных значений меток: перестановка значений метки класса или кластера никоим образом не изменит значение оценки.</target>
        </trans-unit>
        <trans-unit id="bfbb6fef2be45da43d1153172735208301268ab3" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Этот показатель не является симметричным: переключение &lt;code&gt;label_true&lt;/code&gt; с &lt;code&gt;label_pred&lt;/code&gt; возвратит &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; , который будет отличаться в целом.</target>
        </trans-unit>
        <trans-unit id="d6ecae2ce63387462768b5daf2f548b32eba4de4" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">Этот показатель не является симметричным: переключение &lt;code&gt;label_true&lt;/code&gt; с &lt;code&gt;label_pred&lt;/code&gt; возвратит &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; , который будет отличаться в целом.</target>
        </trans-unit>
        <trans-unit id="e3d29b108d9b9b14881da7a1115d336ab614cf19" translate="yes" xml:space="preserve">
          <source>This metric is used in multilabel ranking problem, where the goal is to give better rank to the labels associated to each sample.</source>
          <target state="translated">Эта метрика используется в многомаркировочном ранге,где цель состоит в том,чтобы присвоить более высокий ранг меткам,связанным с каждой выборкой.</target>
        </trans-unit>
        <trans-unit id="70091de439c388c847d5db9bb63c11ef6af9aff3" translate="yes" xml:space="preserve">
          <source>This might be made more clear by an example:</source>
          <target state="translated">Это можно прояснить на примере:</target>
        </trans-unit>
        <trans-unit id="87c35466b9ea86a2466ad7ff0fff224c499553d9" translate="yes" xml:space="preserve">
          <source>This model has many parameters, however the default values are quite reasonable (please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details):</source>
          <target state="translated">Эта модель имеет множество параметров, однако значения по умолчанию вполне разумны (подробности см. В &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;справочной документации&lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="a96824cdb923fbde7424d806cedfbff3d185c97a" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">Эта модель является расширением последовательного преобразования Карунена-Лоэва из: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; См. &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;Http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5eaf31e8c5d94894f814f950dadb507546a62c7a" translate="yes" xml:space="preserve">
          <source>This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</source>
          <target state="translated">Данная модель аналогична базовому алгоритму Label Propagation,но использует матрицу аффинити,основанную на нормализованном графе Laplacian и мягком зажиме поперек этикеток.</target>
        </trans-unit>
        <trans-unit id="31cfc2556e1a899818d23b9328ee0744c892d322" translate="yes" xml:space="preserve">
          <source>This model optimizes the log-loss function using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Эта модель оптимизирует функцию потери логов с помощью LBFGS или стохастического градиентного спуска.</target>
        </trans-unit>
        <trans-unit id="a4064d8d27531f23ac21cbcbd5928e344df2525d" translate="yes" xml:space="preserve">
          <source>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.</source>
          <target state="translated">Эта модель оптимизирует квадратный убыток с помощью LBFGS или стохастического градиента спуска.</target>
        </trans-unit>
        <trans-unit id="5745ffae87fdf8e03232a3372f515cd928402ef0" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">Эта модель решает регрессионную модель,где функция потерь является линейной функцией наименьших квадратов,а регуляризация дается l2-нормой.Также известна как регрессия хребта или регуляризация Тихонова.Этот оценщик имеет встроенную поддержку многомерной регрессии (т.е.когда y-это 2d-массив формы [n_samples,n_targets]).</target>
        </trans-unit>
        <trans-unit id="f19c01936c0bc27e43d782c2c60b0838b0f4894d" translate="yes" xml:space="preserve">
          <source>This module contains both distance metrics and kernels. A brief summary is given on the two here.</source>
          <target state="translated">Данный модуль содержит как метрики расстояния,так и ядра.Краткая информация по этим двум параметрам приведена здесь.</target>
        </trans-unit>
        <trans-unit id="ea7156035377b3d98062532f66578932992ce326" translate="yes" xml:space="preserve">
          <source>This module contains two loaders. The first one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt;, returns a list of the raw texts that can be fed to text feature extractors such as &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; with custom parameters so as to extract feature vectors. The second one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt;&lt;/a&gt;, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.</source>
          <target state="translated">Этот модуль содержит два загрузчика. Первый, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; , возвращает список необработанных текстов, которые могут быть переданы в экстракторы текстовых функций, такие как &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; ,&lt;/a&gt; с настраиваемыми параметрами для извлечения векторов признаков. Второй, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt; &lt;/a&gt; , возвращает готовые к использованию функции, т. Е. Нет необходимости использовать средство извлечения признаков.</target>
        </trans-unit>
        <trans-unit id="e5dbda685e3f3b6ebc21c265d6368ea8386c5f03" translate="yes" xml:space="preserve">
          <source>This module implements multiclass learning algorithms:</source>
          <target state="translated">В этом модуле реализованы многоклассные алгоритмы обучения:</target>
        </trans-unit>
        <trans-unit id="40fee252ae7de928b5fc80e9416986beafe64ef4" translate="yes" xml:space="preserve">
          <source>This module implements multioutput regression and classification.</source>
          <target state="translated">В этом модуле реализована многовыходная регрессия и классификация.</target>
        </trans-unit>
        <trans-unit id="f4b5a1fcc345642615c5317116147407ee22511b" translate="yes" xml:space="preserve">
          <source>This module offers support for multi-output problems by implementing this strategy in both &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt;&lt;code&gt;DecisionTreeRegressor&lt;/code&gt;&lt;/a&gt;. If a decision tree is fit on an output array Y of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; then the resulting estimator will:</source>
          <target state="translated">Этот модуль предлагает поддержку задач с несколькими выходами путем реализации этой стратегии как в &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; ,так&lt;/a&gt; и в &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt; &lt;code&gt;DecisionTreeRegressor&lt;/code&gt; &lt;/a&gt; . Если дерево решений помещается в выходной массив Y размера &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; то итоговая оценка будет:</target>
        </trans-unit>
        <trans-unit id="69b4d83c7d3d58178d932db005c229bef475361e" translate="yes" xml:space="preserve">
          <source>This normalization is implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; class:</source>
          <target state="translated">Эта нормализация реализуется классом &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="36bde3d3011eb8df53f7587f509f261b5588364f" translate="yes" xml:space="preserve">
          <source>This object uses workers to compute in parallel the application of a function to many different arguments. The main functionality it brings in addition to using the raw multiprocessing or concurrent.futures API are (see examples for details):</source>
          <target state="translated">Этот объект использует рабочих для параллельного вычисления применения функции к множеству различных аргументов.Основной функционал,который он приносит в дополнение к использованию raw multiprocessing или concurrent.futures API (см.примеры для подробностей):</target>
        </trans-unit>
        <trans-unit id="43f85d31a1122b5ce913b6ac1587dc97b9fac8c9" translate="yes" xml:space="preserve">
          <source>This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the &amp;lsquo;real world&amp;rsquo;.</source>
          <target state="translated">В этом пакете также есть помощники для получения больших наборов данных, которые обычно используются сообществом машинного обучения для тестирования алгоритмов на данных, поступающих из &amp;laquo;реального мира&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="f678792533c8ea573ae326139ccc463721df5e43" translate="yes" xml:space="preserve">
          <source>This parameter has been renamed to n_components and will be removed in version 0.21. .. deprecated:: 0.19</source>
          <target state="translated">Этот параметр был переименован в n_components и будет удален в версии 0.21....deprecated::0.19</target>
        </trans-unit>
        <trans-unit id="2008376a104f1f0d722babab4554d9900556a331" translate="yes" xml:space="preserve">
          <source>This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">Этот параметр игнорируется,если словарь не None.</target>
        </trans-unit>
        <trans-unit id="4896edc233b2b945e9bfe76cd7c644f9b147f395" translate="yes" xml:space="preserve">
          <source>This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Этот параметр игнорируется, если для &lt;code&gt;fit_intercept&lt;/code&gt; установлено значение False. Если True, регрессоры X будут нормализованы перед регрессией путем вычитания среднего и деления на l2-норму. Если вы хотите стандартизировать, пожалуйста, используйте &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt; перед вызовом &lt;code&gt;fit&lt;/code&gt; воценщике с &lt;code&gt;normalize=False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="18c6fb9267c5496a0a4415bd237b294d4f877c13" translate="yes" xml:space="preserve">
          <source>This parameter is required for multiclass/multilabel targets. If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">Этот параметр необходим для целей с несколькими классами / метками. Если &lt;code&gt;None&lt;/code&gt; , возвращаются оценки для каждого класса. В противном случае это определяет тип усреднения, выполняемого для данных:</target>
        </trans-unit>
        <trans-unit id="4b54c5323e385131687ecd8fe6362000ef5ec12b" translate="yes" xml:space="preserve">
          <source>This parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\) :</source>
          <target state="translated">К этим параметрам можно получить доступ через элементы &lt;code&gt;dual_coef_&lt;/code&gt; , которые содержат продукт \ (y_i \ alpha_i \), &lt;code&gt;support_vectors_&lt;/code&gt; , которые содержат опорные векторы, и &lt;code&gt;intercept_&lt;/code&gt; , который содержит независимый член \ (\ rho \):</target>
        </trans-unit>
        <trans-unit id="f0e92a41ff311d2df395e780ee2f06d2a63e9cbc" translate="yes" xml:space="preserve">
          <source>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.</source>
          <target state="translated">Эта длина пути,усредненная по лесу таких случайных деревьев,является мерой нормальности и нашей функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="80dec09fc285dd6f9c561fc2931162bad1982cdb" translate="yes" xml:space="preserve">
          <source>This plot compares the decision surfaces learned by a decision tree classifier (first column), by a random forest classifier (second column), by an extra- trees classifier (third column) and by an AdaBoost classifier (fourth column).</source>
          <target state="translated">На данном рисунке сравниваются поверхности принятия решений,полученные с помощью классификатора деревьев принятия решений (первая колонка),случайного классификатора леса (вторая колонка),экстра-деревянного классификатора (третья колонка)и классификатора AdaBoost (четвертая колонка).</target>
        </trans-unit>
        <trans-unit id="8e05dc7c1a0ec44a96abb884d1ce621cca93db4e" translate="yes" xml:space="preserve">
          <source>This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. &lt;strong&gt;For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&lt;/strong&gt;.</source>
          <target state="translated">Эту проблему можно смело игнорировать, если количество выборок превышает тысячу, а количество кластеров меньше 10. &lt;strong&gt;Для меньших размеров выборки или большего количества кластеров безопаснее использовать скорректированный индекс, такой как Скорректированный индекс ранда ( ARI)&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="fcd7e110cbbcbd004685bcd45cf928dd3da1b5b1" translate="yes" xml:space="preserve">
          <source>This procedure (spectral clustering on an image) is an efficient approximate solution for finding normalized graph cuts.</source>
          <target state="translated">Эта процедура (спектральная кластеризация на изображении)является эффективным приблизительным решением для нахождения нормализованных графовых разрезов.</target>
        </trans-unit>
        <trans-unit id="7a8651d966c336f363771d222433438f229cb5c2" translate="yes" xml:space="preserve">
          <source>This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.</source>
          <target state="translated">Этот регрессор полезен в качестве простого базиса для сравнения с другими (реальными)регрессорами.Не используйте его для реальных проблем.</target>
        </trans-unit>
        <trans-unit id="566769fe300350777b617d7ceed39620171814da" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices by passing &lt;code&gt;with_mean=False&lt;/code&gt; to avoid breaking the sparsity structure of the data.</source>
          <target state="translated">Этот масштабатор также можно применить к разреженным матрицам CSR или CSC, передав &lt;code&gt;with_mean=False&lt;/code&gt; , чтобы не нарушать разреженную структуру данных.</target>
        </trans-unit>
        <trans-unit id="bf350412f5695ebe05a62d114269ff308d8edf9f" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices.</source>
          <target state="translated">Этот скалер также может быть применен к разреженным матрицам CSR или CSC.</target>
        </trans-unit>
        <trans-unit id="096cae15373bbc176ca80052b34794345347f334" translate="yes" xml:space="preserve">
          <source>This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.</source>
          <target state="translated">Эта оценка может быть использована для выбора характеристик n_features с наибольшими значениями для тестовой статистики хи-квадрат от X,которая должна содержать только неотрицательные характеристики,такие как булеан или частоты (например,количество терминов в классификации документов),по отношению к классам.</target>
        </trans-unit>
        <trans-unit id="bc67f7a4c884a57cb8d65e3051862bc296a2adb5" translate="yes" xml:space="preserve">
          <source>This score is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;'arithmetic'&lt;/code&gt; option for averaging.</source>
          <target state="translated">Эта оценка идентична &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;'arithmetic'&lt;/code&gt; опцией для усреднения.</target>
        </trans-unit>
        <trans-unit id="81b377dd4306b3470c7efb10edcaa8d55b57210b" translate="yes" xml:space="preserve">
          <source>This section illustrates the use of a &lt;code&gt;Pipeline&lt;/code&gt; with &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">В этом разделе показано использование &lt;code&gt;Pipeline&lt;/code&gt; с &lt;code&gt;GridSearchCV&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="929a45e65dc1a0cd0b685d6194be9ae4708eb857" translate="yes" xml:space="preserve">
          <source>This should make it possible to check that the cross-validation score is in the same range as before.</source>
          <target state="translated">Это должно позволить проверить,что результат перекрестного тестирования находится в том же диапазоне,что и раньше.</target>
        </trans-unit>
        <trans-unit id="08af461e03baea2ad13f22a738ff3dde29c2a50f" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Здесь показан пример запроса на основе соседей (в частности, оценка плотности ядра) для геопространственных данных с использованием дерева шариков, построенного на основе метрики расстояния Гаверсина, то есть расстояний по точкам по широте / долготе. Набор данных предоставлен Phillips et. al. (2006). Если возможно, в примере используется &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;базовая карта&lt;/a&gt; для построения береговых линий и национальных границ Южной Америки.</target>
        </trans-unit>
        <trans-unit id="38716491ad409e2f991bc1db8f7b1d944921bf99" translate="yes" xml:space="preserve">
          <source>This sort of preprocessing can be streamlined with the &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; tools. A single object representing a simple polynomial regression can be created and used as follows:</source>
          <target state="translated">Такого рода предварительную обработку можно упростить с помощью инструментов &lt;a href=&quot;compose#pipeline&quot;&gt;конвейера&lt;/a&gt; . Один объект, представляющий простую полиномиальную регрессию, может быть создан и использован следующим образом:</target>
        </trans-unit>
        <trans-unit id="4e6050ab2083fb67a848ffe7f83ae292a8f60f62" translate="yes" xml:space="preserve">
          <source>This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.</source>
          <target state="translated">Эта стратегия также может быть использована для изучения многоэлементных этикеток,где классификатор используется для предсказания нескольких этикеток,например,путем подгонки к 2-d матрице,в которой ячейка [i,j]равна 1,если образец i имеет этикетку j,и 0 в противном случае.</target>
        </trans-unit>
        <trans-unit id="8cd6a64f79d725ef1cdd342315685305aab51887" translate="yes" xml:space="preserve">
          <source>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">Эта стратегия заключается в подборе одного классификатора на пару классов. Во время прогнозирования выбирается класс, получивший наибольшее количество голосов. Поскольку он требует соответствия &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; , этот метод обычно медленнее, чем один против остальных, из-за его сложности O (n_classes ^ 2). Однако этот метод может быть &lt;code&gt;n_samples&lt;/code&gt; для таких алгоритмов, как алгоритмы ядра, которые плохо масштабируются с n_samples . Это связано с тем, что каждая отдельная задача обучения включает в себя только небольшое подмножество данных, тогда как при использовании одного против остальных полный набор данных используется &lt;code&gt;n_classes&lt;/code&gt; раз.</target>
        </trans-unit>
        <trans-unit id="de640b51f281cc0046c1a9e652c58d4e96ebef0b" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification</source>
          <target state="translated">Эта стратегия состоит в том,чтобы подогнать один классификатор под каждую цель.Это простая стратегия для расширения классификаторов,которые не поддерживают классификацию по нескольким целям.</target>
        </trans-unit>
        <trans-unit id="7d6fb6c6a7f2b79b31f4627b09bbb93dcc2f3bc4" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.</source>
          <target state="translated">Эта стратегия состоит в подборе одного регрессора на каждую цель.Это простая стратегия для расширения регрессоров,которые не поддерживают многоцелевую регрессию.</target>
        </trans-unit>
        <trans-unit id="27cbaceed22a6f90d5ae07c700825d27bfca1f78" translate="yes" xml:space="preserve">
          <source>This strategy has several advantages:</source>
          <target state="translated">Эта стратегия имеет ряд преимуществ:</target>
        </trans-unit>
        <trans-unit id="91d49a77db9793bc904e6dbf1c0dda029b6c110b" translate="yes" xml:space="preserve">
          <source>This strategy is illustrated below.</source>
          <target state="translated">Эта стратегия проиллюстрирована ниже.</target>
        </trans-unit>
        <trans-unit id="02849272fb07ed52ea9b00f7ccc02a748c971372" translate="yes" xml:space="preserve">
          <source>This strategy, also known as &lt;strong&gt;one-vs-all&lt;/strong&gt;, is implemented in &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;OneVsRestClassifier&lt;/code&gt;&lt;/a&gt;. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.</source>
          <target state="translated">Эта стратегия, также известная как &amp;laquo; &lt;strong&gt;один против всех&amp;raquo;&lt;/strong&gt; , реализована в &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;OneVsRestClassifier&lt;/code&gt; &lt;/a&gt; . Стратегия заключается в подборе одного классификатора на класс. Для каждого классификатора класс сопоставляется со всеми другими классами. В дополнение к его вычислительной эффективности (необходимы только классификаторы &lt;code&gt;n_classes&lt;/code&gt; ), одним из преимуществ этого подхода является его интерпретируемость. Поскольку каждый класс представлен одним и только одним классификатором, можно получить информацию о классе, проверив соответствующий классификатор. Это наиболее часто используемая стратегия и справедливый выбор по умолчанию.</target>
        </trans-unit>
        <trans-unit id="27ac94ab878e8b852843daf6fdc6644656d86a0e" translate="yes" xml:space="preserve">
          <source>This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see &lt;a href=&quot;svm#svm&quot;&gt;Support Vector Machines&lt;/a&gt;). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.</source>
          <target state="translated">Этот подмодуль содержит функции, которые аппроксимируют сопоставления функций, которые соответствуют определенным ядрам, поскольку они используются, например, в машинах опорных векторов (см. &lt;a href=&quot;svm#svm&quot;&gt;Машины&lt;/a&gt; опорных векторов ). Следующие функции функций выполняют нелинейные преобразования входных данных, которые могут служить основой для линейной классификации или других алгоритмов.</target>
        </trans-unit>
        <trans-unit id="fcbae9cfcf0bd03c252edbce0ec54b00175fa149" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options.</source>
          <target state="translated">Этот тест может быть применен к классам или экземплярам.Классы в настоящее время имеют некоторые дополнительные тесты,которые связаны с построением,в то время как прохождение экземпляров позволяет проверить несколько вариантов.</target>
        </trans-unit>
        <trans-unit id="fe4512e0330ee3f9d4d908b10acadfb35dcb4b46" translate="yes" xml:space="preserve">
          <source>This text vectorizer implementation uses the hashing trick to find the token string name to feature integer index mapping.</source>
          <target state="translated">Эта реализация текстового векторизатора использует трюк хэширования для поиска имени строки токена для отображения целочисленного индекса.</target>
        </trans-unit>
        <trans-unit id="90704510327932a48fb3c52155398163f97475e2" translate="yes" xml:space="preserve">
          <source>This transformation is often used as an alternative to zero mean, unit variance scaling.</source>
          <target state="translated">Это преобразование часто используется в качестве альтернативы масштабированию нулевого среднего,дисперсии в единицах измерения.</target>
        </trans-unit>
        <trans-unit id="2f720ce11fea82f150f2e1314efc3b6e74d2aa65" translate="yes" xml:space="preserve">
          <source>This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).</source>
          <target state="translated">Этот трансформатор способен работать как с плотными нумерованными массивами,так и с матрицей scipy.sparse (используйте CSR формат,если хотите избежать нагрузки,связанной с копированием/преобразованием).</target>
        </trans-unit>
        <trans-unit id="22f51ce5936d304512713b7c2d6420a9339ed07c" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.</source>
          <target state="translated">Этот трансформатор выполняет линейное уменьшение размерности посредством усеченного разложения сингулярных величин (SVD).В отличие от СПС,этот оценщик не центрирует данные до расчета сингулярного разложения.Это означает,что он может эффективно работать с матрицами scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="c058bdf39166834e7b3e02bee2a3dc32df1bea5c" translate="yes" xml:space="preserve">
          <source>This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.</source>
          <target state="translated">Этот трансформатор превращает списки отображений (dict-подобных объектов)имен элементов в значения элементов в массивы Numpy или scipy.sparse матрицы для использования с scikit-learn оценщиками.</target>
        </trans-unit>
        <trans-unit id="6fa17f9065133747f6dee2c04fd6c387874c04ab" translate="yes" xml:space="preserve">
          <source>This tutorial will explore &lt;em&gt;statistical learning&lt;/em&gt;, the use of machine learning techniques with the goal of &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;statistical inference&lt;/a&gt;: drawing conclusions on the data at hand.</source>
          <target state="translated">В этом руководстве будет изучено &lt;em&gt;статистическое обучение&lt;/em&gt; , использование методов машинного обучения с целью &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;статистического вывода&lt;/a&gt; : выводы на основе имеющихся данных.</target>
        </trans-unit>
        <trans-unit id="d770164eec068c2686e18d9f67f7678a7fe3d2ab" translate="yes" xml:space="preserve">
          <source>This uses the Benjamini-Hochberg procedure. &lt;code&gt;alpha&lt;/code&gt; is an upper bound on the expected false discovery rate.</source>
          <target state="translated">Здесь используется процедура Бенджамини-Хохберга. &lt;code&gt;alpha&lt;/code&gt; - это верхняя граница ожидаемого уровня ложного обнаружения.</target>
        </trans-unit>
        <trans-unit id="25630de50e6415b67bb72ea47abf6e457ed32d31" translate="yes" xml:space="preserve">
          <source>This uses the score defined by &lt;code&gt;scoring&lt;/code&gt; where provided, and the &lt;code&gt;best_estimator_.score&lt;/code&gt; method otherwise.</source>
          <target state="translated">При этом используется оценка, определенная путем &lt;code&gt;scoring&lt;/code&gt; если она предоставлена, и метод &lt;code&gt;best_estimator_.score&lt;/code&gt; в противном случае.</target>
        </trans-unit>
        <trans-unit id="57e78bad29e459afb6f7e8e9a46e0b5e6e5f4fa9" translate="yes" xml:space="preserve">
          <source>This value is valid if class_weight parameter in fit() is not set.</source>
          <target state="translated">Это значение действует,если параметр class_weight в функции fit()не установлен.</target>
        </trans-unit>
        <trans-unit id="0973d55bbbd406d7d050b325e278935eae6a368e" translate="yes" xml:space="preserve">
          <source>This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of &amp;ldquo;mutual information&amp;rdquo; between the label assignments.</source>
          <target state="translated">Это значение взаимной информации, а также нормализованного варианта не скорректировано на случайность и будет иметь тенденцию к увеличению по мере увеличения количества различных меток (кластеров), независимо от фактического количества &amp;laquo;взаимной информации&amp;raquo; между назначениями меток.</target>
        </trans-unit>
        <trans-unit id="ec27c204380d1bf1bec671104c4e5cc563667983" translate="yes" xml:space="preserve">
          <source>This visualization is an example of a &lt;em&gt;kernel density estimation&lt;/em&gt;, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</source>
          <target state="translated">Эта визуализация является примером &lt;em&gt;оценки плотности ядра&lt;/em&gt; , в данном случае с ядром в форме цилиндра (то есть квадратным блоком в каждой точке). Мы можем восстановить более плавное распределение, используя более гладкое ядро. На нижнем правом графике показана оценка плотности ядра Гаусса, в которой каждая точка вносит свой вклад в общую кривую Гаусса. В результате получается гладкая оценка плотности, которая выводится из данных и функционирует как мощная непараметрическая модель распределения точек.</target>
        </trans-unit>
        <trans-unit id="1cad85e71e9b226b43b5778c8058de4fe70516a7" translate="yes" xml:space="preserve">
          <source>This warning is used to notify the user that BLAS was not used for dot operation and hence the efficiency may be affected.</source>
          <target state="translated">Это предупреждение используется для уведомления пользователя о том,что BLAS не использовался для работы с точками и,следовательно,эффективность может быть снижена.</target>
        </trans-unit>
        <trans-unit id="7b4c8162b5298ba9d922a2200274b38ddddf44e8" translate="yes" xml:space="preserve">
          <source>This warning notifies the user that the efficiency may not be optimal due to some reason which may be included as a part of the warning message. This may be subclassed into a more specific Warning class.</source>
          <target state="translated">Это предупреждение уведомляет пользователя о том,что эффективность может быть не оптимальной по какой-то причине,которая может быть включена в предупреждающее сообщение.Оно может быть подразделено на более конкретный класс предупреждения.</target>
        </trans-unit>
        <trans-unit id="ec79da6e5e29f4afd0662e82ec298c39ed6dbabd" translate="yes" xml:space="preserve">
          <source>This warning occurs when some input data needs to be converted or interpreted in a way that may not match the user&amp;rsquo;s expectations.</source>
          <target state="translated">Это предупреждение появляется, когда некоторые входные данные необходимо преобразовать или интерпретировать таким образом, который может не соответствовать ожиданиям пользователя.</target>
        </trans-unit>
        <trans-unit id="14994b75958434504d6803fa4be46a86d6219fc9" translate="yes" xml:space="preserve">
          <source>This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.</source>
          <target state="translated">Первоначально это была схема взвешивания терминов,разработанная для поиска информации (как функция ранжирования результатов в поисковых системах),которая также нашла хорошее применение в классификации документов и кластеризации.</target>
        </trans-unit>
        <trans-unit id="90d00e9f85af52e63288d2fca3d9f513dce9de12" translate="yes" xml:space="preserve">
          <source>This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.</source>
          <target state="translated">Это,однако,не случай в процедуре Ледойт-Вульф когда коварианс населенности случается быть множественным из матрицы тождественности.В этом случае оценка усадки Ледойт-Вульф приближается к 1 по мере увеличения количества образцов.Это указывает на то,что оптимальная оценка матрицы ковариаций в смысле Ледойт-Вульф кратна идентичности.Так как ковариация популяции уже кратна матрице идентичности,решение Ледуарда-Вольфа действительно является разумной оценкой.</target>
        </trans-unit>
        <trans-unit id="e911226999d28ae4c4eb95cef049955b008548cf" translate="yes" xml:space="preserve">
          <source>Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score values in any way.</source>
          <target state="translated">Эти 3 метрики не зависят от абсолютных значений меток: перестановка значений метки класса или кластера никоим образом не изменит значения оценки.</target>
        </trans-unit>
        <trans-unit id="a17151aff3f6e79d6bfb3bc3e7c5d30ff3b77b7d" translate="yes" xml:space="preserve">
          <source>Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</source>
          <target state="translated">Эти метрики основаны на нормализованных условных энтропийных мерах маркировки кластеризации для того чтобы оценить дано знание наземной истины ярлыков класса тех же самых образцов.</target>
        </trans-unit>
        <trans-unit id="831e093286e91d34e1415d38600e7c8277f14a07" translate="yes" xml:space="preserve">
          <source>Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'ltsa'&lt;/code&gt;.</source>
          <target state="translated">Хотя технически это не вариант LLE, локальное выравнивание касательного пространства (LTSA) алгоритмически достаточно похоже на LLE, чтобы его можно было отнести к этой категории. Вместо того, чтобы сосредоточиться на сохранении расстояний между соседями, как в LLE, LTSA стремится охарактеризовать локальную геометрию в каждой окрестности через его касательное пространство и выполняет глобальную оптимизацию для выравнивания этих локальных касательных пространств для изучения встраивания. LTSA может выполняться с помощью функции &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; с ключевым словом &lt;code&gt;method = 'ltsa'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3dcfc8b5bdf930c1b66451c5dc30f486901100ee" translate="yes" xml:space="preserve">
          <source>Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially useful when the data-points are not linearly separable.</source>
          <target state="translated">Ниже отображаются три различных типа SVM-ядер.Полиномы и RBF особенно полезны,когда точки данных не разделяются линейно.</target>
        </trans-unit>
        <trans-unit id="2eb0d5d5e8d716a06a5bc42a652c1781cf721343" translate="yes" xml:space="preserve">
          <source>Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.</source>
          <target state="translated">Порог для бинаризации (отображения в булеан)особенностей выборки.Если Нет,то предполагается,что вход уже состоит из бинарных векторов.</target>
        </trans-unit>
        <trans-unit id="ac359cd376aaf3163dffdc564a92f8f55ebdbfe9" translate="yes" xml:space="preserve">
          <source>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</source>
          <target state="translated">Порог для ранней остановки роста деревьев.Узел расколется,если его примесь окажется выше порога,иначе это лист.</target>
        </trans-unit>
        <trans-unit id="d2dde1e4fd07fa9e4ff99bf50a843f5c394281b4" translate="yes" xml:space="preserve">
          <source>Threshold for shrinking centroids to remove features.</source>
          <target state="translated">Порог для сжимания центроидов для удаления функций.</target>
        </trans-unit>
        <trans-unit id="5b50eca69565a6240c9cb586697767c09ac4525e" translate="yes" xml:space="preserve">
          <source>Threshold on the size of arrays passed to the workers that triggers automated memory mapping in temp_folder. Can be an int in Bytes, or a human-readable string, e.g., &amp;lsquo;1M&amp;rsquo; for 1 megabyte. Use None to disable memmapping of large arrays. Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">Порог размера массивов, передаваемых рабочим, который запускает автоматическое отображение памяти в temp_folder. Может быть int в байтах или удобочитаемой строкой, например, &amp;laquo;1M&amp;raquo; для 1 мегабайта. Используйте None, чтобы отключить отображение больших массивов. Активен, только когда backend = &quot;loky&quot; или &quot;multiprocessing&quot;.</target>
        </trans-unit>
        <trans-unit id="3bf722c4ec04176f091be4d50fbd629d5b754a20" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation in SVD solver.</source>
          <target state="translated">Порог,используемый для оценки ранга в SVD solver.</target>
        </trans-unit>
        <trans-unit id="0168a115989469a76c56e8c46c0d56b1a01f88c6" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation.</source>
          <target state="translated">Порог,используемый для оценки ранга.</target>
        </trans-unit>
        <trans-unit id="558232b0add0e7cf1e4001c15b7a509781ecfb59" translate="yes" xml:space="preserve">
          <source>Threshold used in the binary and multi-label cases.</source>
          <target state="translated">Порог,используемый в бинарных и мульти-маркировочных случаях.</target>
        </trans-unit>
        <trans-unit id="d260a173cc06214ee3d2352996ea165371c17c29" translate="yes" xml:space="preserve">
          <source>Thresholding</source>
          <target state="translated">Thresholding</target>
        </trans-unit>
        <trans-unit id="8265a18b28c2cb3c5a28ceb45384d9a49c2f7715" translate="yes" xml:space="preserve">
          <source>Thresholding is clearly not useful for denoising, but it is here to show that it can produce a suggestive output with very high speed, and thus be useful for other tasks such as object classification, where performance is not necessarily related to visualisation.</source>
          <target state="translated">Очевидно,что пороговый тон не полезен для размывания,но он здесь для того,чтобы показать,что он может производить внушающий результат с очень высокой скоростью,и,таким образом,быть полезным для других задач,таких как классификация объектов,где производительность не обязательно связана с визуализацией.</target>
        </trans-unit>
        <trans-unit id="c4d29a75003891e7d5c5dbb3dea7166bf19f4ab9" translate="yes" xml:space="preserve">
          <source>Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.</source>
          <target state="translated">Порог очень быстрый,но не дает точных реконструкций.Они были показаны в литературе,полезной для классификационных задач.Для задач реконструкции изображений,поиск ортогонального соответствия дает наиболее точную,объективную реконструкцию.</target>
        </trans-unit>
        <trans-unit id="3904c870d9e800cc53a98ecb8acef59d010fad3d" translate="yes" xml:space="preserve">
          <source>Throw a ValueError if X contains NaN or infinity.</source>
          <target state="translated">Бросьте ValueError,если X содержит NaN или бесконечность.</target>
        </trans-unit>
        <trans-unit id="8b8612c016401dc529cb09be5ddd6996fe872d9c" translate="yes" xml:space="preserve">
          <source>Thus in binary classification, the count of true negatives is \(C_{0,0}\), false negatives is \(C_{1,0}\), true positives is \(C_{1,1}\) and false positives is \(C_{0,1}\).</source>
          <target state="translated">Таким образом,в бинарной классификации количество истинных отрицательных значений равно \(C_{0,0}\),ложных отрицательных значений-\(C_{1,0}\),истинных значений-\(C_{1,1}\),а ложных значений-\(C_{0,1}\).</target>
        </trans-unit>
        <trans-unit id="877864e25b035038afd6bbe5a72ca90fb8e0741e" translate="yes" xml:space="preserve">
          <source>Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input&amp;rsquo;s minimum and maximum &amp;mdash; corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively &amp;mdash; do not become infinite under the transformation.</source>
          <target state="translated">Таким образом, медиана входных данных становится средним значением выходных данных с центром в 0. Нормальный выход обрезается так, чтобы минимум и максимум входного сигнала, соответствующие квантилям 1e-7 и 1 - 1e-7 соответственно, не становились бесконечными при преобразование.</target>
        </trans-unit>
        <trans-unit id="0808b4cdf67452766c8c5389635c6458f9990f5b" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015</source>
          <target state="translated">Таким образом,большая часть целевого сигнала (34,4 п.п.)объясняется долгосрочной тенденцией роста (по шкале длины 41,8 года).Периодическая составляющая имеет амплитуду 3,27 промилле,время распада 180 лет и шкалу длины 1,44.Длительное время распада указывает на то,что мы имеем локально очень близкую к периодической сезонной составляющей.Коррелированный шум имеет амплитуду 0.197ppm при шкале длины 0.138 лет и вклад белого шума 0.197ppm.Таким образом,общий уровень шума очень мал,что указывает на то,что данные могут быть очень хорошо объяснены моделью.Рисунок также показывает,что модель делает очень уверенные прогнозы до примерно 2015 г.</target>
        </trans-unit>
        <trans-unit id="4ab3c0245825ab663f7197647adadf073e4b3e64" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015.</source>
          <target state="translated">Таким образом,большая часть целевого сигнала (34,4 п.п.)объясняется долгосрочной тенденцией роста (по шкале длины 41,8 года).Периодическая составляющая имеет амплитуду 3,27 промилле,время распада 180 лет и шкалу длины 1,44.Длительное время распада указывает на то,что мы имеем локально очень близкую к периодической сезонной составляющей.Коррелированный шум имеет амплитуду 0.197ppm при шкале длины 0.138 лет и вклад белого шума 0.197ppm.Таким образом,общий уровень шума очень мал,что указывает на то,что данные могут быть очень хорошо объяснены моделью.Рисунок также показывает,что модель делает очень уверенные прогнозы до примерно 2015 года.</target>
        </trans-unit>
        <trans-unit id="af16f18f91308907d1dd8226e54112fa0bd29044" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">Тиан Чжан, Рагху Рамакришнан, Марон Ливни БЕРЕЗА: эффективный метод кластеризации данных для больших баз данных. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d53cad37906f55db18b858cf86bfeef9ad9688eb" translate="yes" xml:space="preserve">
          <source>Tibshirani, R., Hastie, T., Narasimhan, B., &amp;amp; Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.</source>
          <target state="translated">Тибширани, Р., Хасти, Т., Нарасимхан, Б., и Чу, Г. (2002). Диагностика нескольких типов рака по уменьшенным центроидам экспрессии генов. Proceedings of the National Academy of Sciences of the United States of America, 99 (10), 6567-6572. Национальная академия наук.</target>
        </trans-unit>
        <trans-unit id="a297f524f28779281bb4e53d7b6af672dcac3672" translate="yes" xml:space="preserve">
          <source>Ties are broken using the secondary method from Leeuw, 1977.</source>
          <target state="translated">Связи разрываются с помощью вторичного метода из Leeuw,1977.</target>
        </trans-unit>
        <trans-unit id="59976e05663a4d82c80a3273030c2c2f87094f4d" translate="yes" xml:space="preserve">
          <source>Ties between features with equal scores will be broken in an unspecified way.</source>
          <target state="translated">Связи между функциями с одинаковым количеством баллов будут нарушены неуказанным образом.</target>
        </trans-unit>
        <trans-unit id="c41dd9e78b42392c90f4c6ddfb54f7863f5482f1" translate="yes" xml:space="preserve">
          <source>Ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">Связи в &lt;code&gt;y_scores&lt;/code&gt; разрываются путем присвоения максимального ранга, который был бы присвоен всем связанным значениям.</target>
        </trans-unit>
        <trans-unit id="ba73dffe02601a1abd345b6200b276334877401b" translate="yes" xml:space="preserve">
          <source>Time Series cross-validator</source>
          <target state="translated">Кросс-валидатор временных рядов</target>
        </trans-unit>
        <trans-unit id="bbad16d201e3f82cae87bba42e6286ebcef9d190" translate="yes" xml:space="preserve">
          <source>Time series data is characterised by the correlation between observations that are near in time (&lt;em&gt;autocorrelation&lt;/em&gt;). However, classical cross-validation techniques such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the &amp;ldquo;future&amp;rdquo; observations least like those that are used to train the model. To achieve this, one solution is provided by &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt;&lt;code&gt;TimeSeriesSplit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Данные временных рядов характеризуются корреляцией между близкими по времени наблюдениями ( &lt;em&gt;автокорреляция&lt;/em&gt; ). Однако классические методы перекрестной проверки, такие как &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; ,&lt;/a&gt; предполагают, что выборки независимы и одинаково распределены, что приведет к необоснованной корреляции между обучающими и тестовыми экземплярами (что дает плохие оценки ошибки обобщения) данных временных рядов. Следовательно, очень важно оценивать нашу модель для данных временных рядов по &amp;laquo;будущим&amp;raquo; наблюдениям, в меньшей степени, чем те, которые используются для обучения модели. Для этого &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt; &lt;code&gt;TimeSeriesSplit&lt;/code&gt; &lt;/a&gt; предоставляет одно решение .</target>
        </trans-unit>
        <trans-unit id="a6268d75d578276d37dec9fce6dea804677e6b49" translate="yes" xml:space="preserve">
          <source>Timeout limit for each task to complete. If any task takes longer a TimeOutError will be raised. Only applied when n_jobs != 1</source>
          <target state="translated">Ограничение по времени выполнения каждой задачи.Если какая-либо задача занимает больше времени,будет поднята ошибка TimeOutError.Применяется только при n_jobs !=1.</target>
        </trans-unit>
        <trans-unit id="8879146d32620a1e603bf26a188c9426e79a5ed0" translate="yes" xml:space="preserve">
          <source>To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, &lt;em&gt;without having to explicitly calculate their distance&lt;/em&gt;. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).</source>
          <target state="translated">Для решения проблемы вычислительной неэффективности подхода грубой силы были изобретены различные древовидные структуры данных. В общем, эти структуры пытаются уменьшить необходимое количество вычислений расстояния путем эффективного кодирования совокупной информации о расстоянии для выборки. Основная идея состоит в том, что если точка \ (A \) очень удалена от точки \ (B \), а точка \ (B \) очень близко к точке \ (C \), то мы знаем, что точки \ (A \ ) и \ (C \) очень далеки, &lt;em&gt;без необходимости явно вычислять их расстояние&lt;/em&gt; . Таким образом, вычислительные затраты на поиск ближайших соседей могут быть уменьшены до \ (O [DN \ log (N)] \) или лучше. Это значительное улучшение по сравнению с перебором для больших \ (N \).</target>
        </trans-unit>
        <trans-unit id="81ec528524d941df99755c9bb7fceaf80c6a8752" translate="yes" xml:space="preserve">
          <source>To address the inefficiencies of KD Trees in higher dimensions, the &lt;em&gt;ball tree&lt;/em&gt; data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.</source>
          <target state="translated">Чтобы устранить неэффективность KD Trees в более высоких измерениях, была разработана структура данных &lt;em&gt;дерева шара&lt;/em&gt; . Если деревья KD разделяют данные по декартовым осям, то шаровые деревья разделяют данные на ряд вложенных гипер-сфер. Это делает построение дерева более дорогостоящим, чем построение дерева KD, но приводит к структуре данных, которая может быть очень эффективной для сильно структурированных данных даже в очень больших измерениях.</target>
        </trans-unit>
        <trans-unit id="a11d5f0b5df4ea3ced24dc7521fb6d9f97740ba3" translate="yes" xml:space="preserve">
          <source>To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an &amp;ldquo;interesting&amp;rdquo; linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.</source>
          <target state="translated">Для решения этой проблемы был разработан ряд контролируемых и неконтролируемых структур снижения линейной размерности, таких как анализ главных компонентов (PCA), независимый компонентный анализ, линейный дискриминантный анализ и другие. Эти алгоритмы определяют конкретные рубрики для выбора &amp;laquo;интересной&amp;raquo; линейной проекции данных. Эти методы могут быть мощными, но часто упускают важную нелинейную структуру данных.</target>
        </trans-unit>
        <trans-unit id="c134b5f4c4fa3b034f915a1c4077d9f58401c669" translate="yes" xml:space="preserve">
          <source>To address this issue you can use &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;whiten=True&lt;/code&gt; to further remove the linear correlation across features.</source>
          <target state="translated">Чтобы решить эту проблему, вы можете использовать &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt; с whiten &lt;code&gt;whiten=True&lt;/code&gt; чтобы дополнительно удалить линейную корреляцию между функциями.</target>
        </trans-unit>
        <trans-unit id="5dfb268e42cc748904256c70f6b80b2da01edce9" translate="yes" xml:space="preserve">
          <source>To also transform a test set \(X\), we multiply it with \(V_k\):</source>
          <target state="translated">Чтобы преобразовать тестовый набор \(X\),мы умножаем его на \(V_k\):</target>
        </trans-unit>
        <trans-unit id="8ef7600ab8e39fc13b7dc9585804325c8072844d" translate="yes" xml:space="preserve">
          <source>To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the &lt;code&gt;ridge_alpha&lt;/code&gt; parameter.</source>
          <target state="translated">Чтобы избежать проблем с нестабильностью в случае, если система недостаточно определена, можно применить регуляризацию (регрессия гребня) с помощью параметра &lt;code&gt;ridge_alpha&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="622754a0a375aafa66f9d8336ffd00fcfc0a1948" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSC matrix.</source>
          <target state="translated">Чтобы избежать копирования памяти,звонящий должен пройти CSC матрицу.</target>
        </trans-unit>
        <trans-unit id="21a05d95ccb73f51d245c302b02e9a8f32df0276" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSR matrix.</source>
          <target state="translated">Чтобы избежать копирования памяти,звонящий должен передать CSR-матрицу.</target>
        </trans-unit>
        <trans-unit id="e5ab0a4f687079cc593610e8d8c0f15b79824d4d" translate="yes" xml:space="preserve">
          <source>To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.</source>
          <target state="translated">Чтобы избежать перераспределения памяти,рекомендуется выделять исходные данные в памяти непосредственно с использованием этого формата.</target>
        </trans-unit>
        <trans-unit id="ee93c7e2ac06e08c1567b0ca209ad480ea5f1b80" translate="yes" xml:space="preserve">
          <source>To avoid the computation of global clustering, for every call of &lt;code&gt;partial_fit&lt;/code&gt; the user is advised</source>
          <target state="translated">Чтобы избежать вычисления глобальной кластеризации, для каждого вызова &lt;code&gt;partial_fit&lt;/code&gt; пользователю рекомендуется</target>
        </trans-unit>
        <trans-unit id="e81cbf7353acbc69eeae43ca8cf143e58e658d10" translate="yes" xml:space="preserve">
          <source>To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called &lt;code&gt;tf&lt;/code&gt; for Term Frequencies.</source>
          <target state="translated">Чтобы избежать этих возможных расхождений, достаточно разделить количество вхождений каждого слова в документе на общее количество слов в документе: эти новые функции называются &lt;code&gt;tf&lt;/code&gt; для Term Frequencies.</target>
        </trans-unit>
        <trans-unit id="39f01dfdcdf5847fd1935ba52ba9be2bfc80430b" translate="yes" xml:space="preserve">
          <source>To avoid this problem, nested CV effectively uses a series of train/validation/test set splits. In the inner loop (here executed by &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;), the score is approximately maximized by fitting a model to each training set, and then directly maximized in selecting (hyper)parameters over the validation set. In the outer loop (here in &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;), generalization error is estimated by averaging test set scores over several dataset splits.</source>
          <target state="translated">Чтобы избежать этой проблемы, вложенное резюме эффективно использует серию разделений на обучение / проверку / набор тестов. Во внутреннем цикле (здесь выполняется &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; ) оценка приблизительно максимизируется путем подбора модели для каждого обучающего набора, а затем напрямую максимизируется при выборе (гипер) параметров по набору проверки. Во внешнем цикле (здесь в &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; ) ошибка обобщения оценивается путем усреднения результатов набора тестов по нескольким разбиениям набора данных.</target>
        </trans-unit>
        <trans-unit id="a37b39aad5fcf98e98548e781cdec5193cfe7b97" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.</source>
          <target state="translated">Чтобы избежать ненужного дублирования памяти,аргумент X метода fit должен передаваться непосредственно в виде массива нумерации,граничащего с Fortran.</target>
        </trans-unit>
        <trans-unit id="d9c2f7485084c926a2f68d8587d615406cc01649" translate="yes" xml:space="preserve">
          <source>To be in favorable recovery conditions, we sample the data from a model with a sparse inverse covariance matrix. In addition, we ensure that the data is not too much correlated (limiting the largest coefficient of the precision matrix) and that there a no small coefficients in the precision matrix that cannot be recovered. In addition, with a small number of observations, it is easier to recover a correlation matrix rather than a covariance, thus we scale the time series.</source>
          <target state="translated">Для того чтобы быть в благоприятных условиях восстановления,мы берем данные из модели с разреженной обратной ковариационной матрицей.Кроме того,мы гарантируем,что данные не слишком сильно коррелируют (ограничивая наибольший коэффициент матрицы прецизионности)и что в матрице прецизионности нет малых коэффициентов,которые не могут быть восстановлены.Кроме того,при небольшом количестве наблюдений легче восстановить матрицу корреляции,чем ковариацию,поэтому мы масштабируем временной ряд.</target>
        </trans-unit>
        <trans-unit id="f7fd313aae703eaa110952d34fbc2e74f81a873c" translate="yes" xml:space="preserve">
          <source>To be removed in 0.21</source>
          <target state="translated">Удаляется через 0.21</target>
        </trans-unit>
        <trans-unit id="b656a9f4366f6cbcc5b1e6914e7bc1a8d099ee57" translate="yes" xml:space="preserve">
          <source>To be removed in 0.22</source>
          <target state="translated">Удаляется через 0.22</target>
        </trans-unit>
        <trans-unit id="bc387423485c5a73576ae6f9089ec34a8b143ae6" translate="yes" xml:space="preserve">
          <source>To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:</source>
          <target state="translated">Для начала все значения для \(r\)и \(a\)устанавливаются на ноль,а расчет каждого итерата до сходимости.Как обсуждалось выше,чтобы избежать численных колебаний при обновлении сообщений,в итерационный процесс вводится коэффициент демпфирования \(\lambda\):</target>
        </trans-unit>
        <trans-unit id="ebc5cb56aa5d3da850d595b902c1384fa4142906" translate="yes" xml:space="preserve">
          <source>To begin, we&amp;rsquo;ll visualize our data.</source>
          <target state="translated">Для начала визуализируем наши данные.</target>
        </trans-unit>
        <trans-unit id="57e47e513e200b11a216f9768279c1f81e7b3157" translate="yes" xml:space="preserve">
          <source>To benchmark different estimators for your case you can simply change the &lt;code&gt;n_features&lt;/code&gt; parameter in this example: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;. This should give you an estimate of the order of magnitude of the prediction latency.</source>
          <target state="translated">Чтобы сравнить различные оценщики в вашем случае, вы можете просто изменить параметр &lt;code&gt;n_features&lt;/code&gt; в этом примере: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt; . Это должно дать вам оценку порядка величины задержки предсказания.</target>
        </trans-unit>
        <trans-unit id="892d831a9e807296347eacb2e8474830ca349663" translate="yes" xml:space="preserve">
          <source>To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.</source>
          <target state="translated">Чтобы сравнить набор найденных биоклустеров с набором истинных биоклустеров,необходимы две меры сходства:мера сходства для отдельных биоклустеров и способ объединить эти индивидуальные сходства в общий балл.</target>
        </trans-unit>
        <trans-unit id="f0ff37a06cd777b22ebe208ab3110388f720b201" translate="yes" xml:space="preserve">
          <source>To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:</source>
          <target state="translated">Для сравнения отдельных билюстеров было использовано несколько мер.На данный момент реализован только индекс Jaccard:</target>
        </trans-unit>
        <trans-unit id="30a2aa60dabe3d1d8b8497c6228442c6c55454f4" translate="yes" xml:space="preserve">
          <source>To control display of warnings.</source>
          <target state="translated">Для управления отображением предупреждений.</target>
        </trans-unit>
        <trans-unit id="6c3d05eecff544d238db6888c87daeb42794f44b" translate="yes" xml:space="preserve">
          <source>To control the verbosity of the procedure.</source>
          <target state="translated">Чтобы контролировать многословие процедуры.</target>
        </trans-unit>
        <trans-unit id="d66f891ca7bde7537002ad52d27fc9dd62dd5881" translate="yes" xml:space="preserve">
          <source>To convert categorical features to such integer codes, we can use the &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):</source>
          <target state="translated">Чтобы преобразовать категориальные признаки в такие целочисленные коды, мы можем использовать &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt; . Этот оценщик преобразует каждую категориальную характеристику в одну новую характеристику целых чисел (от 0 до n_categories - 1):</target>
        </trans-unit>
        <trans-unit id="693e8d8ca1982fe1e279b5869b2b710976d06558" translate="yes" xml:space="preserve">
          <source>To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:</source>
          <target state="translated">Для борьбы с этим эффектом мы можем дисконтировать ожидаемый RI \(E[\text{RI}]\)случайных меток,определив скорректированный индекс Rand следующим образом:</target>
        </trans-unit>
        <trans-unit id="2ccfac714af4138a2df70ede11b2ff4e1963a414" translate="yes" xml:space="preserve">
          <source>To create positive examples click the left mouse button; to create negative examples click the right button.</source>
          <target state="translated">Для создания положительных примеров нажмите левую кнопку мыши,для создания отрицательных-правую.</target>
        </trans-unit>
        <trans-unit id="d0bfc36f728f01d8f998e7e774b5cc731a5652d7" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on inertia, set max_no_improvement to None.</source>
          <target state="translated">Чтобы отключить обнаружение сходимости по инерции,установите max_no_improvement равным None.</target>
        </trans-unit>
        <trans-unit id="644ea86209186f0b63818c18611416bf68aa348b" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</source>
          <target state="translated">Чтобы отключить обнаружение сходимости на основе нормализованного изменения центра,установите допуск на 0.0 (по умолчанию).</target>
        </trans-unit>
        <trans-unit id="8f49411326bd4f684fb56ae33f90d4fd9150ab8c" translate="yes" xml:space="preserve">
          <source>To do the exercises, copy the content of the &amp;lsquo;skeletons&amp;rsquo; folder as a new folder named &amp;lsquo;workspace&amp;rsquo;:</source>
          <target state="translated">Для выполнения упражнений скопируйте содержимое папки &amp;laquo;скелеты&amp;raquo; в новую папку с именем &amp;laquo;рабочая область&amp;raquo;:</target>
        </trans-unit>
        <trans-unit id="79cf44a84fa8878b10f291a31335b47430451015" translate="yes" xml:space="preserve">
          <source>To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:</source>
          <target state="translated">К каждой колонке можно применить различные преобразования,такие как препроцессирование или метод извлечения специфических признаков:</target>
        </trans-unit>
        <trans-unit id="a0a5ce85df1e1aafd2ebf61b7efd7098beb62d7b" translate="yes" xml:space="preserve">
          <source>To estimate a probabilistic model (e.g. a Gaussian model), estimating the precision matrix, that is the inverse covariance matrix, is as important as estimating the covariance matrix. Indeed a Gaussian model is parametrized by the precision matrix.</source>
          <target state="translated">Для оценки вероятностной модели (например,гауссовской модели)оценка матрицы точности,т.е.обратной ковариационной матрицы,так же важна,как и оценка ковариационной матрицы.Действительно,гауссовская модель параметризуется матрицей точности.</target>
        </trans-unit>
        <trans-unit id="06985e50b51113b200d13cecad3eedd2a07fa798" translate="yes" xml:space="preserve">
          <source>To evaluate the impact of the scale of the dataset (&lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_features&lt;/code&gt;) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.</source>
          <target state="translated">Чтобы оценить влияние масштаба набора данных ( &lt;code&gt;n_samples&lt;/code&gt; и &lt;code&gt;n_features&lt;/code&gt; ) при контроле статистических свойств данных (обычно корреляции и информативности функций), также можно сгенерировать синтетические данные.</target>
        </trans-unit>
        <trans-unit id="8b81da86f6a51388bf88e8748866dfbc1da10ddb" translate="yes" xml:space="preserve">
          <source>To fully specify a dataset, you need to provide a name and a version, though the version is optional, see &lt;a href=&quot;#openml-versions&quot;&gt;Dataset Versions&lt;/a&gt; below. The dataset contains a total of 1080 examples belonging to 8 different classes:</source>
          <target state="translated">Чтобы полностью указать набор данных, вам необходимо указать имя и версию, хотя версия не является обязательной, см. &amp;laquo; &lt;a href=&quot;#openml-versions&quot;&gt;Версии набора данных&amp;raquo;&lt;/a&gt; ниже. Набор данных содержит в общей сложности 1080 примеров, относящихся к 8 различным классам:</target>
        </trans-unit>
        <trans-unit id="eddbe44ecc236b178d14592239180b4231c2f462" translate="yes" xml:space="preserve">
          <source>To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in &lt;em&gt;folds&lt;/em&gt; that we use for training and testing:</source>
          <target state="translated">Чтобы получить лучшую меру точности предсказания (которую мы можем использовать в качестве прокси для оценки соответствия модели), мы можем последовательно разделить данные на &lt;em&gt;складки,&lt;/em&gt; которые мы используем для обучения и тестирования:</target>
        </trans-unit>
        <trans-unit id="8f2c7c86e5d1b0f8592203b4a46517414e54ce05" translate="yes" xml:space="preserve">
          <source>To get identical results for each split, set &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">Чтобы получить идентичные результаты для каждого разделения, установите &lt;code&gt;random_state&lt;/code&gt; в целое число.</target>
        </trans-unit>
        <trans-unit id="0228140936e0aced4eaa7c77d90637025c4d0909" translate="yes" xml:space="preserve">
          <source>To get started with this tutorial, you must first install &lt;em&gt;scikit-learn&lt;/em&gt; and all of its required dependencies.</source>
          <target state="translated">Чтобы начать работу с этим руководством, вы должны сначала установить &lt;em&gt;scikit-learn&lt;/em&gt; и все его необходимые зависимости.</target>
        </trans-unit>
        <trans-unit id="8d91bad777aec839541c338ab9f11be081ee54c6" translate="yes" xml:space="preserve">
          <source>To get the signed distance to the hyperplane use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Чтобы получить расстояние со &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt; &lt;code&gt;SGDClassifier.decision_function&lt;/code&gt; &lt;/a&gt; до гиперплоскости, используйте SGDClassifier.decision_function :</target>
        </trans-unit>
        <trans-unit id="6ae2612052e54b7be6598947088a287fffd01403" translate="yes" xml:space="preserve">
          <source>To illustrate &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt;, first let&amp;rsquo;s create an imbalanced dataset:</source>
          <target state="translated">Чтобы проиллюстрировать &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; , сначала давайте создадим несбалансированный набор данных:</target>
        </trans-unit>
        <trans-unit id="e7a02a8f3e922c68cd6ce64dca33ce54683ffb1b" translate="yes" xml:space="preserve">
          <source>To illustrate this with a simple example, let&amp;rsquo;s assume we have 3 classifiers and a 3-class classification problems where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.</source>
          <target state="translated">Чтобы проиллюстрировать это на простом примере, предположим, что у нас есть 3 классификатора и 3 задачи классификации, в которых мы присваиваем всем классификаторам одинаковые веса: w1 = 1, w2 = 1, w3 = 1.</target>
        </trans-unit>
        <trans-unit id="27fe4060cc8aa9166cda2609863b9fdd12999baf" translate="yes" xml:space="preserve">
          <source>To illustrate this, PCA is performed comparing the use of data with &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.</source>
          <target state="translated">Чтобы проиллюстрировать это, PCA сравнивает использование данных с примененным &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; с немасштабированными данными. Результаты визуализируются, и отмечается четкая разница. Виден 1-й главный компонент немасштабированного набора. Можно видеть, что объект № 13 доминирует над направлением, будучи на два порядка выше остальных объектов. Это контрастирует при наблюдении за главным компонентом масштабированной версии данных. В масштабированной версии порядки величины для всех функций примерно одинаковы.</target>
        </trans-unit>
        <trans-unit id="952f60109f87198cc4767d483a08ad921abb5966" translate="yes" xml:space="preserve">
          <source>To improve the conditioning of the problem (i.e. mitigating the &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The curse of dimensionality&lt;/a&gt;), it would be interesting to select only the informative features and set non-informative ones, like feature 2 to 0. Ridge regression will decrease their contribution, but not set them to zero. Another penalization approach, called &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (least absolute shrinkage and selection operator), can set some coefficients to zero. Such methods are called &lt;strong&gt;sparse method&lt;/strong&gt; and sparsity can be seen as an application of Occam&amp;rsquo;s razor: &lt;em&gt;prefer simpler models&lt;/em&gt;.</source>
          <target state="translated">Чтобы улучшить обусловленность проблемы (т.е. смягчить &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;проклятие размерности&lt;/a&gt; ), было бы интересно выбрать только информативные функции и установить неинформативные, например, функцию 2 равной 0. Риджевая регрессия уменьшит их вклад, но не установит. их к нулю. Другой подход к наказанию, называемый &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;лассо&lt;/a&gt; (оператор наименьшего абсолютного сжатия и выбора), может устанавливать некоторые коэффициенты равными нулю. Такие методы называются &lt;strong&gt;разреженными методами,&lt;/strong&gt; а разреженность можно рассматривать как применение бритвы Оккама: &lt;em&gt;предпочитайте более простые модели&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="f028c20036ea78694db90136b8cb3004f099e0bf" translate="yes" xml:space="preserve">
          <source>To limit the memory consumption, we queue examples up to a fixed amount before feeding them to the learner.</source>
          <target state="translated">Чтобы ограничить потребление памяти,мы ставим примеры в очередь до фиксированного количества перед подачей ученику.</target>
        </trans-unit>
        <trans-unit id="61f860c325e06c4f97b9f4c7ced3d5279054856d" translate="yes" xml:space="preserve">
          <source>To load from an external dataset, please refer to &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;loading external datasets&lt;/a&gt;.</source>
          <target state="translated">Чтобы загрузить из внешнего набора данных, обратитесь к &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;разделу Загрузка внешних наборов данных&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d787fd22509da728f07846c2b5d3ecac1d6b4105" translate="yes" xml:space="preserve">
          <source>To load the data and visualize the images:</source>
          <target state="translated">Для загрузки данных и визуализации изображений:</target>
        </trans-unit>
        <trans-unit id="b4be4dde535adc435619c6f0e295e0ce05bad72b" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance.</source>
          <target state="translated">Чтобы заставить пример работать быстрее,мы используем очень мало скрытых единиц,и тренируемся только в течение очень короткого времени.Более длительные тренировки привели бы к тому,что веса стали бы намного более плавными в пространстве.</target>
        </trans-unit>
        <trans-unit id="96ba992a3c5af68caa74d107191c5a3c32806c93" translate="yes" xml:space="preserve">
          <source>To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the &lt;code&gt;build_preprocessor&lt;/code&gt;, &lt;code&gt;build_tokenizer&lt;/code&gt; and &lt;code&gt;build_analyzer&lt;/code&gt; factory methods instead of passing custom functions.</source>
          <target state="translated">Чтобы препроцессор, токенизатор и анализаторы знали параметры модели, можно &lt;code&gt;build_preprocessor&lt;/code&gt; от класса и переопределить фабричные методы build_preprocessor , &lt;code&gt;build_tokenizer&lt;/code&gt; и &lt;code&gt;build_analyzer&lt;/code&gt; вместо передачи пользовательских функций.</target>
        </trans-unit>
        <trans-unit id="c0f08b8475e4b67e5147698ce9ccb818f0394d27" translate="yes" xml:space="preserve">
          <source>To make this more explicit, consider the following notation:</source>
          <target state="translated">Чтобы сделать это более понятным,рассмотрим следующую нотацию:</target>
        </trans-unit>
        <trans-unit id="8ada09feb86f8f3751dffbeeaba0e1e4f69156a7" translate="yes" xml:space="preserve">
          <source>To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):</source>
          <target state="translated">Для получения полностью вероятностной модели предполагается,что выход \(y\)будет гауссовским,распространяемым по адресу \(X w\):</target>
        </trans-unit>
        <trans-unit id="65178eef58b048e690e1c210520e38da80789880" translate="yes" xml:space="preserve">
          <source>To perform classification with generalized linear models, see &lt;a href=&quot;#logistic-regression&quot;&gt;Logistic regression&lt;/a&gt;.</source>
          <target state="translated">Чтобы выполнить классификацию с помощью обобщенных линейных моделей, см. &lt;a href=&quot;#logistic-regression&quot;&gt;Логистическая регрессия&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="72dc32b7225454e8d7c0ec26f14d95b55df2c79a" translate="yes" xml:space="preserve">
          <source>To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates.</source>
          <target state="translated">Для количественной оценки погрешности оценки строится вероятность невидимых данных для различных значений параметра усадки.Мы также показываем выбор путем перекрестной проверки или с помощью оценок LedoitWolf и OAS.</target>
        </trans-unit>
        <trans-unit id="397393d3de29d9ed57b4f231bd553afc264bafab" translate="yes" xml:space="preserve">
          <source>To return the corresponding classical subsets of kddcup 99. If None, return the entire kddcup 99 dataset.</source>
          <target state="translated">Вернуть соответствующие классические подмножества kddcup 99.Если Нет,вернуть весь набор данных kddcup 99.</target>
        </trans-unit>
        <trans-unit id="b0e502baa68f0434bb574994337b41db58fa07c4" translate="yes" xml:space="preserve">
          <source>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</source>
          <target state="translated">Для проведения перекрестной проверки по нескольким показателям,а также для возврата очков поезда,времени посадки и времени очков.</target>
        </trans-unit>
        <trans-unit id="2d79b95a40b4d1ea2f276f13509aebc984e2d932" translate="yes" xml:space="preserve">
          <source>To see how this generalizes the binary log loss given above, note that in the binary case, \(p_{i,0} = 1 - p_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.</source>
          <target state="translated">Чтобы посмотреть,как это обобщает приведенный выше двоичный лог-потерь,обратите внимание,что в двоичном случае \(p_{i,0}=1-p_{i,1}\)и \(y_{i,0}=1-y_{i,1}\),таким образом расширяя внутреннюю сумму над \(y_{i,k}\in \{0,1\}\)дает двоичный лог-потерь.</target>
        </trans-unit>
        <trans-unit id="25684d8b1766d360b665e8498a44a626b2b5bd13" translate="yes" xml:space="preserve">
          <source>To set &lt;code&gt;n_clusters=None&lt;/code&gt; initially</source>
          <target state="translated">Чтобы изначально установить &lt;code&gt;n_clusters=None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="78f293aec6a6c458449c6dc3bcd71b696525a449" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.</source>
          <target state="translated">Чтобы ускорить работу алгоритма,в качестве семян принимайте только те бункеры,в которых есть хотя бы мин_бин_фрек.</target>
        </trans-unit>
        <trans-unit id="e1dfcbed698085a7ab462cf760bf24e65a9e8400" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds. If not defined, set to 1.</source>
          <target state="translated">Чтобы ускорить работу алгоритма,в качестве семян принимайте только те бункеры,в которых есть хотя бы мин_бин_фрек.Если не определено,установите значение 1.</target>
        </trans-unit>
        <trans-unit id="fd2f04d7c6e080a2cce0d2e7339e598ba17acac5" translate="yes" xml:space="preserve">
          <source>To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call &lt;code&gt;transform&lt;/code&gt; instead of &lt;code&gt;fit_transform&lt;/code&gt; on the transformers, since they have already been fit to the training set:</source>
          <target state="translated">Чтобы попытаться предсказать результат для нового документа, нам нужно извлечь признаки, используя почти ту же цепочку извлечения признаков, что и раньше. Разница в том, что мы вызываем &lt;code&gt;transform&lt;/code&gt; вместо &lt;code&gt;fit_transform&lt;/code&gt; для трансформаторов, поскольку они уже соответствуют обучающему набору:</target>
        </trans-unit>
        <trans-unit id="5da67914dc5314b6125944bb748e1a3d6c08f736" translate="yes" xml:space="preserve">
          <source>To understand the use of LDA in dimensionality reduction, it is useful to start with a geometric reformulation of the LDA classification rule explained above. We write \(K\) for the total number of target classes. Since in LDA we assume that all classes have the same estimated covariance \(\Sigma\), we can rescale the data so that this covariance is the identity:</source>
          <target state="translated">Чтобы понять использование LDA в сокращении размерности,полезно начать с геометрического переосмысления правила классификации LDA,объясненного выше.Для общего количества целевых классов мы пишем \(K\).Поскольку в LDA мы предполагаем,что все классы имеют одну и ту же оценочную ковариацию \(\Sigma\),мы можем перемасштабировать данные таким образом,чтобы эта ковариация была идентична:</target>
        </trans-unit>
        <trans-unit id="6df5e0eab0e1e02def9ae99e68c6ddf1a841d6d1" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator:</source>
          <target state="translated">Чтобы использовать &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt; для обнаружения новизны, т. Е. Прогнозирования меток или вычисления оценки отклонения от нормы новых невидимых данных, вам необходимо создать экземпляр оценщика с параметром &lt;code&gt;novelty&lt;/code&gt; установленным на &lt;code&gt;True&lt;/code&gt; , перед подгонкой оценщика:</target>
        </trans-unit>
        <trans-unit id="011ed6ad19bc2f123579a7e50ff8b4dad33bf360" translate="yes" xml:space="preserve">
          <source>To use joblib.Memory to cache the svmlight file:</source>
          <target state="translated">Использовать joblib.Memory для кэширования файла svmlight:</target>
        </trans-unit>
        <trans-unit id="e11936ea84de206f18d8b708b6f4eca9fb6c8b59" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">Чтобы использовать текстовые файлы в алгоритме классификации или кластеризации scikit-learn, вам нужно будет использовать модуль &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; для создания преобразователя извлечения функций, который подходит для вашей задачи.</target>
        </trans-unit>
        <trans-unit id="c7aa2d2ef894f356c354736ecb4235681bee95b2" translate="yes" xml:space="preserve">
          <source>To use this dataset with scikit-learn, we transform each 8x8 image into a feature vector of length 64</source>
          <target state="translated">Чтобы использовать этот набор данных с scikit-learn,мы преобразовываем каждое изображение 8x8 в функциональный вектор длиной 64</target>
        </trans-unit>
        <trans-unit id="f5d271c927cff9ea25de07089e51938b7e86a2a7" translate="yes" xml:space="preserve">
          <source>To use this model as a classifier, we just need to estimate from the training data the class priors \(P(y=k)\) (by the proportion of instances of class \(k\)), the class means \(\mu_k\) (by the empirical sample class means) and the covariance matrices (either by the empirical sample class covariance matrices, or by a regularized estimator: see the section on shrinkage below).</source>
          <target state="translated">Для использования этой модели в качестве классификатора достаточно оценить по учебным данным классы-приоры \(P(y=k)\)(по доле экземпляров класса \(k\)),класс означает \(\mu_k\)(по средствам эмпирической выборки класса)и ковариационные матрицы (либо по ковариационным матрицам класса эмпирической выборки,либо по регуляризованной оценке:см.раздел &quot;Усадка&quot; ниже).</target>
        </trans-unit>
        <trans-unit id="5d015bfb570917361c4b4abaaa59f5e623d8c463" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">Для проверки модели нам нужна функция &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;оценки&lt;/a&gt; (см. Оценка модели: количественная оценка качества прогнозов ), например, точность для классификаторов. Правильный способ выбора нескольких гиперпараметров оценщика - это, конечно, поиск по сетке или аналогичные методы (см. &lt;a href=&quot;grid_search#grid-search&quot;&gt;Настройка&lt;/a&gt; гиперпараметров оценщика ), которые выбирают гиперпараметр с максимальной оценкой на наборе проверки или нескольких наборах проверки. Обратите внимание, что если мы оптимизировали гиперпараметры на основе оценки валидации, оценка валидации будет смещена и больше не будет хорошей оценкой обобщения. Чтобы получить правильную оценку обобщения, мы должны вычислить оценку на другом наборе тестов.</target>
        </trans-unit>
        <trans-unit id="baa10199f999bc30e58b0035ac2f6e51132399ed" translate="yes" xml:space="preserve">
          <source>To visualize the probability weighting, we fit each classifier on the training set and plot the predicted class probabilities for the first sample in this example dataset.</source>
          <target state="translated">Чтобы визуализировать взвешивание вероятностей,мы подгоняем каждый классификатор к обучающему набору и строим прогнозные классовые вероятности для первой выборки в этом примере набора данных.</target>
        </trans-unit>
        <trans-unit id="ba234a16bb1a2ae4619585ca04988c1afd574060" translate="yes" xml:space="preserve">
          <source>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</source>
          <target state="translated">Токенирование документов и подсчёт случаев токена и возврат их в разрежённую матрицу</target>
        </trans-unit>
        <trans-unit id="e89caeb25fc24a274e225b242d49cc6fb7ddfa72" translate="yes" xml:space="preserve">
          <source>Tokenizing text with &lt;code&gt;scikit-learn&lt;/code&gt;</source>
          <target state="translated">Токенизация текста с помощью &lt;code&gt;scikit-learn&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="45d4a0ebe499a5d042ac0f7bc4284501d3667758" translate="yes" xml:space="preserve">
          <source>Tolerance for &amp;lsquo;arpack&amp;rsquo; method Not used if eigen_solver==&amp;rsquo;dense&amp;rsquo;.</source>
          <target state="translated">Допуск для метода 'arpack' Не используется, если eigen_solver == 'density'.</target>
        </trans-unit>
        <trans-unit id="318dfc593e0123f93a8fe309f411532f48eea756" translate="yes" xml:space="preserve">
          <source>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.</source>
          <target state="translated">Толерантность к ARPACK.0 означает точность станка.Игнорируется рандомизированным SVD solver.</target>
        </trans-unit>
        <trans-unit id="13511570864a98fa2d61f43da929b11b4894937f" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if &lt;code&gt;method == 'hessian'&lt;/code&gt;</source>
          <target state="translated">Допуск для метода отображения собственных значений Гессе. Используется только если &lt;code&gt;method == 'hessian'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e4c877ba267607a99e62c8b31f7891feda117cf7" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if method == &amp;lsquo;hessian&amp;rsquo;</source>
          <target state="translated">Допуск для метода отображения собственных значений Гессе. Используется только если method == 'hessian'</target>
        </trans-unit>
        <trans-unit id="aeb25ea9c0101939a4336136b4e11db71f1bb1be" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if &lt;code&gt;method == 'modified'&lt;/code&gt;</source>
          <target state="translated">Допуск для модифицированного метода LLE. Используется только если &lt;code&gt;method == 'modified'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b6502cfb6f414093cd5faf0376953824eae5e86f" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if method == &amp;lsquo;modified&amp;rsquo;</source>
          <target state="translated">Допуск для модифицированного метода LLE. Используется только если метод == 'изменен'</target>
        </trans-unit>
        <trans-unit id="40eaf2d9a188116c07595886d4a67c9121557ecf" translate="yes" xml:space="preserve">
          <source>Tolerance for singular values computed by svd_solver == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">Допуск для сингулярных значений, вычисленных svd_solver == 'arpack'.</target>
        </trans-unit>
        <trans-unit id="a495f50d68c5f0d21905244c442ac1ec46831c6d" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criteria.</source>
          <target state="translated">Толерантность к критериям остановки.</target>
        </trans-unit>
        <trans-unit id="1f900b2be351c5e1d6397b25c9a2e6c5e5c36343" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criterion.</source>
          <target state="translated">Толерантность к критерию остановки.</target>
        </trans-unit>
        <trans-unit id="4d73abe23fd3517118aa70ae58840719c14ae6a0" translate="yes" xml:space="preserve">
          <source>Tolerance for the early stopping. When the loss is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations (if set to a number), the training stops.</source>
          <target state="translated">Допуск к преждевременной остановке. Когда потери не улучшаются по крайней мере на tol для итераций &lt;code&gt;n_iter_no_change&lt;/code&gt; (если установлено число), обучение прекращается.</target>
        </trans-unit>
        <trans-unit id="334a1d6597d473e85cc8725e20828e0c9824ea02" translate="yes" xml:space="preserve">
          <source>Tolerance for the optimization. When the loss or score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive iterations, unless &lt;code&gt;learning_rate&lt;/code&gt; is set to &amp;lsquo;adaptive&amp;rsquo;, convergence is considered to be reached and training stops.</source>
          <target state="translated">Допуск на оптимизацию. Когда потеря или оценка не улучшаются по крайней мере на &lt;code&gt;tol&lt;/code&gt; для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных итераций, если только &lt;code&gt;learning_rate&lt;/code&gt; не установлено на &amp;laquo;адаптивное&amp;raquo;, сходимость считается достигнутой, и обучение прекращается.</target>
        </trans-unit>
        <trans-unit id="6938a4dcb29969d15aaa6cafefb8f09b830ed305" translate="yes" xml:space="preserve">
          <source>Tolerance for the stopping condition.</source>
          <target state="translated">Толерантность к состоянию остановки.</target>
        </trans-unit>
        <trans-unit id="3a49445cc3e76e8c0deab47f4b10c5bd7dc33960" translate="yes" xml:space="preserve">
          <source>Tolerance of the stopping condition.</source>
          <target state="translated">Толерантность к состоянию остановки.</target>
        </trans-unit>
        <trans-unit id="48a48ded1ae1ed29a7ddaed19c15db301472918d" translate="yes" xml:space="preserve">
          <source>Tolerance on update at each iteration.</source>
          <target state="translated">Допуск на обновление на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="a2223ba588ac8a94dc6928512bbe1ae559b46f6b" translate="yes" xml:space="preserve">
          <source>Tolerance used in the iterative algorithm default 1e-06.</source>
          <target state="translated">Допуск,используемый в итерационном алгоритме по умолчанию 1e-06.</target>
        </trans-unit>
        <trans-unit id="20a2955c412dcae35aa2ef964ce8c2d4b1c07dcb" translate="yes" xml:space="preserve">
          <source>Tolerance when calculating spatial median.</source>
          <target state="translated">Толерантность при расчете пространственной медианы.</target>
        </trans-unit>
        <trans-unit id="f3d0c54c4b7882f5280f0492c26f2bf33d35d2a2" translate="yes" xml:space="preserve">
          <source>Tony Blair</source>
          <target state="translated">Тони Блэр</target>
        </trans-unit>
        <trans-unit id="e1781cb6d03ccb2216639c1d54de7540b9fc2c2b" translate="yes" xml:space="preserve">
          <source>Tools for imputing missing values are discussed at &lt;a href=&quot;impute#impute&quot;&gt;Imputation of missing values&lt;/a&gt;.</source>
          <target state="translated">Инструменты для вменения пропущенных значений обсуждаются в &lt;a href=&quot;impute#impute&quot;&gt;разделе &amp;laquo;Вменение пропущенных значений&amp;raquo;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0d184ce2992ee425b9d4cc3d528da94fb4da399d" translate="yes" xml:space="preserve">
          <source>Tophat kernel (&lt;code&gt;kernel = 'tophat'&lt;/code&gt;)</source>
          <target state="translated">Ядро Tophat ( &lt;code&gt;kernel = 'tophat'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="0954aa60533f43dc3b2b9a9cbdee11a74f79eada" translate="yes" xml:space="preserve">
          <source>Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</source>
          <target state="translated">Тематическое извлечение с помощью факторно-отрицательной матрицы и латентного дирихлетного выделения</target>
        </trans-unit>
        <trans-unit id="97129616afbfcb01d33b44619c8bf267194395ac" translate="yes" xml:space="preserve">
          <source>Total Phenols:</source>
          <target state="translated">Полные Фенолы:</target>
        </trans-unit>
        <trans-unit id="24a9e81269d05c734577a89440230faee238f7b2" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X.</source>
          <target state="translated">Общая лог-вероятность данных в X.</target>
        </trans-unit>
        <trans-unit id="4055747cee4593e58e4a6dcbfa7d6ccc61845cf0" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">Общее количество документов. Используется только в методе &lt;code&gt;partial_fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aed40ed5719d059f29eba1177189a60b01059871" translate="yes" xml:space="preserve">
          <source>Total phenols</source>
          <target state="translated">Всего фенолов</target>
        </trans-unit>
        <trans-unit id="babba0bc0e9a3e36ce98f362a62519c8eacb94cb" translate="yes" xml:space="preserve">
          <source>Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</source>
          <target state="translated">На пути к оптимальному предварительно обусловленному собственному вычислителю: локально оптимальный блочный предварительно обусловленный метод сопряженного градиента Андрей В. Князев &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3ae1e8d052cc2d0c25bbda7e5d0370ec624b1e8" translate="yes" xml:space="preserve">
          <source>Toy example of 1D regression using linear, polynomial and RBF kernels.</source>
          <target state="translated">Игрушечный пример 1D регрессии с использованием линейных,полиномиальных и RBF ядер.</target>
        </trans-unit>
        <trans-unit id="264fa08a131d6382d6715d8c951f2b5bea1c373c" translate="yes" xml:space="preserve">
          <source>Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process:</source>
          <target state="translated">В примере трассировки обратите внимание на то,как указывается строка ошибки,а также на значения параметра,переданного функции,которая спровоцировала исключение,даже если трассировка происходит в дочернем процессе:</target>
        </trans-unit>
        <trans-unit id="8718fa41b5577d15733c0d074d4e6ea2d5f88486" translate="yes" xml:space="preserve">
          <source>Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.</source>
          <target state="translated">Отслеживание,Международный журнал компьютерного зрения,том 77,выпуск 1-3,стр.125-141,май 2008.</target>
        </trans-unit>
        <trans-unit id="6e4826fce9da6f5f03d1b11115df13e0bc514c4a" translate="yes" xml:space="preserve">
          <source>Train all data by multiple calls to partial_fit.</source>
          <target state="translated">Обучение всех данных по нескольким вызовам на функцию partial_fit.</target>
        </trans-unit>
        <trans-unit id="bd98708380c7e60a9c0a687f254abca8478a36f8" translate="yes" xml:space="preserve">
          <source>Train and test sizes may be different in each fold, with a difference of at most &lt;code&gt;n_classes&lt;/code&gt;.</source>
          <target state="translated">Размеры &lt;code&gt;n_classes&lt;/code&gt; и тестов могут быть разными в каждом сгибе, с разницей не более n_classes .</target>
        </trans-unit>
        <trans-unit id="1c08c1bee3835bcafdb50e8cdda68c68d71fa67e" translate="yes" xml:space="preserve">
          <source>Train error vs Test error</source>
          <target state="translated">Ошибка поезда vs Ошибка теста</target>
        </trans-unit>
        <trans-unit id="357c94d50b669e3c60f0758a6140ed17dc81af61" translate="yes" xml:space="preserve">
          <source>Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.</source>
          <target state="translated">Поезд l1-пенализованных логистических регрессионных моделей по двоичной проблеме классификации,полученной из набора данных Iris.</target>
        </trans-unit>
        <trans-unit id="0cfcb0c276264df865da734aa7faab6c6b43fed6" translate="yes" xml:space="preserve">
          <source>Train the model using libsvm (low-level method)</source>
          <target state="translated">Обучение модели с помощью libsvm (низкоуровневый метод)</target>
        </trans-unit>
        <trans-unit id="ff5331ad7dc89bf5a9dd23c31ab738af7815c499" translate="yes" xml:space="preserve">
          <source>Training a classifier</source>
          <target state="translated">Обучение классификатору</target>
        </trans-unit>
        <trans-unit id="0f0630eb2ecfdd0ed6f7defc6642e6c0143bcbf3" translate="yes" xml:space="preserve">
          <source>Training data</source>
          <target state="translated">Данные тренинга</target>
        </trans-unit>
        <trans-unit id="6c7c988c62ce8a65ab6394bf4f62bdef696bbe60" translate="yes" xml:space="preserve">
          <source>Training data, requires length = n_samples</source>
          <target state="translated">Данные тренировки,требуется длина=n_образец</target>
        </trans-unit>
        <trans-unit id="70fa8e3174eef9a1ccfc0bda8b38c7cfbf09ffd6" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие данные,где n_образцов в количестве образцов и n_функций-это количество функций.</target>
        </trans-unit>
        <trans-unit id="1d999bb02f6364cf15c69e5533af993a3fc0fdd8" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие данные,где n_образцы-количество образцов,а n_функции-количество функций.</target>
        </trans-unit>
        <trans-unit id="f12731d4ed32a02266da09997a2bf0e000555cf6" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Данные обучения, которые также необходимы для прогнозирования. Если ядро ​​== &amp;laquo;предварительно вычислено&amp;raquo;, это вместо предварительно вычисленной обучающей матрицы, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="c5441fed149296831061b9151bd71d563327dc0d" translate="yes" xml:space="preserve">
          <source>Training data.</source>
          <target state="translated">Данные по обучению.</target>
        </trans-unit>
        <trans-unit id="4319dec91a5574f9382b1b679ba9c82bf44c0f15" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, shape [n_samples, n_features], or [n_samples, n_samples] if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Данные обучения. Если массив или матрица, форма [n_samples, n_features] или [n_samples, n_samples], если metric = 'precomputed'.</target>
        </trans-unit>
        <trans-unit id="3cc715a75ede17772899f7cc9ab69882475a79bc" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">Данные обучения. Если ядро ​​== &amp;laquo;предварительно вычислено&amp;raquo;, это вместо этого предварительно вычисленная матрица ядра, shape = [n_samples, n_samples].</target>
        </trans-unit>
        <trans-unit id="b12ede4c226e6e2f235813d30bce55744269c03f" translate="yes" xml:space="preserve">
          <source>Training data. Must fulfill input requirements of first step of the pipeline.</source>
          <target state="translated">Данные по обучению.Должны соответствовать входным требованиям первой ступени трубопровода.</target>
        </trans-unit>
        <trans-unit id="d5044fd4a2ac02d5a0b137f2f3b7fd6b8f65a006" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If &lt;code&gt;y&lt;/code&gt; is mono-output then &lt;code&gt;X&lt;/code&gt; can be sparse.</source>
          <target state="translated">Данные обучения. Передайте данные напрямую как непрерывные данные Fortran, чтобы избежать ненужного дублирования памяти. Если &lt;code&gt;y&lt;/code&gt; моно-вывод, то &lt;code&gt;X&lt;/code&gt; может быть разреженным.</target>
        </trans-unit>
        <trans-unit id="8ed7855d8da328d2505a0bcd1c3302665b72cb3d" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.</source>
          <target state="translated">Данные по обучению.Передавайте данные непосредственно в формате Fortran,чтобы избежать ненужного дублирования памяти.Если y-моно-выпуск,то X может быть разреженным.</target>
        </trans-unit>
        <trans-unit id="4c004afef287030c2dcb4a937f43adb06e1cdf0e" translate="yes" xml:space="preserve">
          <source>Training data. Shape [n_samples, n_features], or [n_samples, n_samples] if affinity==&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">Данные обучения. Форма [n_samples, n_features] или [n_samples, n_samples], если affinity == 'precomputed'.</target>
        </trans-unit>
        <trans-unit id="be8959fb1d08ac2482d5adecb9cc6d42cd3487ff" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">Учебные примеры для кластера.Следует отметить,что данные будут преобразованы в C-заказ,что вызовет копирование памяти,если данные не являются C-сопряженными.</target>
        </trans-unit>
        <trans-unit id="1fb973e1446d09c43085a14e14217bfa82f35fac" translate="yes" xml:space="preserve">
          <source>Training set and testing set</source>
          <target state="translated">Учебный и испытательный набор</target>
        </trans-unit>
        <trans-unit id="ea59a824d416e7ea0dc63df33b1afa59cdb64566" translate="yes" xml:space="preserve">
          <source>Training set.</source>
          <target state="translated">Тренировочный набор.</target>
        </trans-unit>
        <trans-unit id="3c518c488676e60e90ca53bcc0aa7271b669fe4d" translate="yes" xml:space="preserve">
          <source>Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.</source>
          <target state="translated">Учебный набор:только форма используется для нахождения оптимальных случайных размеров матрицы на основе теории,упомянутой в вышеупомянутых работах.</target>
        </trans-unit>
        <trans-unit id="68d52cda6c0756d21c2527d22eda07d7e45f55d9" translate="yes" xml:space="preserve">
          <source>Training target.</source>
          <target state="translated">Тренировочная цель.</target>
        </trans-unit>
        <trans-unit id="32e48bd3169f82f98b7879700514da5daba97549" translate="yes" xml:space="preserve">
          <source>Training targets. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">Учебные цели.Должны соответствовать требованиям по маркировке для всех этапов трубопровода.</target>
        </trans-unit>
        <trans-unit id="bc89d708a926da60c1e855065f294a150e4844da" translate="yes" xml:space="preserve">
          <source>Training vector, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the total number of features.</source>
          <target state="translated">Вектор обучения, где &lt;code&gt;n_samples&lt;/code&gt; - это количество выборок, а &lt;code&gt;n_features&lt;/code&gt; - общее количество функций.</target>
        </trans-unit>
        <trans-unit id="325dc392b957558d0accbc4c288eabf85d0d476c" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">Вектор обучения,где n_образцов в количестве сэмплов и n_функций-это количество признаков.</target>
        </trans-unit>
        <trans-unit id="01000b19ae19a1d02ea4ceb374852ca509745c92" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">Вектор обучения,где n_образцов в количестве сэмплов и n_функций-это количество признаков.Обратите внимание,что центроидная усадка не может использоваться с разреженными матрицами.</target>
        </trans-unit>
        <trans-unit id="6a8354ff2f178d04d8fd18ac8502cba6a9d2e53e" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Вектор обучения,где n_samples-количество сэмплов,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="66e0bce9861c05444da85a9795d5edcc3de5cb5e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">Обучающие векторы,где n_samples-количество сэмплов,а n_features-количество признаков.</target>
        </trans-unit>
        <trans-unit id="f64b8abd734d5648613b346b4bb3c97a56c66bbf" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples, n_samples).</source>
          <target state="translated">Обучающие векторы, где n_samples - это количество выборок, а n_features - количество функций. Для kernel = &quot;precomputed&quot; ожидаемая форма X будет (n_samples, n_samples).</target>
        </trans-unit>
        <trans-unit id="ee5e82a19ba6d9a5b4fc8f431028f4e0ae5cae2a" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of predictors.</source>
          <target state="translated">Обучающие векторы,где n_образцы-количество сэмплов,а n_функции-количество предикторов.</target>
        </trans-unit>
        <trans-unit id="3dbb8cbc3c8d093280069e8e889d1e0c62e1afde" translate="yes" xml:space="preserve">
          <source>Transform X back to its original space.</source>
          <target state="translated">Трансформируйте Х обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="dbfeebba6e53c937056143e8cf1258378ae1c26d" translate="yes" xml:space="preserve">
          <source>Transform X back to original space.</source>
          <target state="translated">Трансформируйте Х обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="2fcdcd20eec681f04cc400d1e7a3d3a35f46ced9" translate="yes" xml:space="preserve">
          <source>Transform X into subcluster centroids dimension.</source>
          <target state="translated">Преобразовать Х в подкластерные центроиды.</target>
        </trans-unit>
        <trans-unit id="da3379264043ea94358e5b4b01ce80967c41f1a5" translate="yes" xml:space="preserve">
          <source>Transform X separately by each transformer, concatenate results.</source>
          <target state="translated">Трансформируйте Х по отдельности для каждого трансформатора,а затем согласуйте результаты.</target>
        </trans-unit>
        <trans-unit id="054e9dc484301382a53ef7807c44414f413c3b43" translate="yes" xml:space="preserve">
          <source>Transform X to a cluster-distance space.</source>
          <target state="translated">Трансформируйте Х в кластерно-дистанционное пространство.</target>
        </trans-unit>
        <trans-unit id="9340d4e978871cfc2faf3772609beb4370b76837" translate="yes" xml:space="preserve">
          <source>Transform X to ordinal codes.</source>
          <target state="translated">Трансформируйте Х в ординарные коды.</target>
        </trans-unit>
        <trans-unit id="d750cda6e828d45a370fec4538601ee99b5443be" translate="yes" xml:space="preserve">
          <source>Transform X using one-hot encoding.</source>
          <target state="translated">Преобразование X с использованием одноразрядной кодировки.</target>
        </trans-unit>
        <trans-unit id="f9e88a65d85f54852f98655b3f250fdbf7750c92" translate="yes" xml:space="preserve">
          <source>Transform X using the forward function.</source>
          <target state="translated">Трансформируйте X с помощью функции перемотки вперед.</target>
        </trans-unit>
        <trans-unit id="fb06535ce9222390887b51d0862f28eec382f495" translate="yes" xml:space="preserve">
          <source>Transform X using the inverse function.</source>
          <target state="translated">Трансформируйте Х с помощью обратной функции.</target>
        </trans-unit>
        <trans-unit id="55b2dc92fd17631d37a113cafae1257246c63b9f" translate="yes" xml:space="preserve">
          <source>Transform X.</source>
          <target state="translated">Трансформируй Х.</target>
        </trans-unit>
        <trans-unit id="df5b966033d10ab5ffd4498c25f3563581fac3a4" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a normalized tf or tf-idf representation</source>
          <target state="translated">Преобразование счетной матрицы в нормализованное представление tf или tf-idf</target>
        </trans-unit>
        <trans-unit id="c6579300b554475d257c93a2551d1e7ac8d00f29" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a tf or tf-idf representation</source>
          <target state="translated">Преобразование счетной матрицы в представление tf или tf-idf</target>
        </trans-unit>
        <trans-unit id="cfe77beec60d283a1ae2557849fffc568b20c2b6" translate="yes" xml:space="preserve">
          <source>Transform a new matrix using the built clustering</source>
          <target state="translated">Преобразование новой матрицы с помощью построенной кластеризации</target>
        </trans-unit>
        <trans-unit id="eb758f2f9f4d3b4a21a0f5aa711d86b7f433cb44" translate="yes" xml:space="preserve">
          <source>Transform a sequence of documents to a document-term matrix.</source>
          <target state="translated">Преобразование последовательности документов в документ-матрицу.</target>
        </trans-unit>
        <trans-unit id="90d7961623626a54873e65ae75f5e5aedaf80a7d" translate="yes" xml:space="preserve">
          <source>Transform a sequence of instances to a scipy.sparse matrix.</source>
          <target state="translated">Преобразовать последовательность инстансов в матрицу scipy.sparse.</target>
        </trans-unit>
        <trans-unit id="482237f55f57c5ab1436ea9ad6e0ca3a5497f2c8" translate="yes" xml:space="preserve">
          <source>Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt;&lt;/a&gt; estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.</source>
          <target state="translated">Преобразуйте сигнал как разреженную комбинацию вейвлетов Рикера. В этом примере визуально сравниваются различные методы разреженного кодирования с помощью &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt; &lt;/a&gt; . Риккер (также известный как мексиканская шляпа или вторая производная от гауссианы) не особенно хорошее ядро ​​для представления кусочно-постоянных сигналов, подобных этому. Таким образом, можно увидеть, насколько важно добавление атомов разной ширины и, следовательно, мотивирует изучение словаря, чтобы он наилучшим образом соответствовал вашему типу сигналов.</target>
        </trans-unit>
        <trans-unit id="3c3158f9e95a76dac9ab046600d246dc683b1322" translate="yes" xml:space="preserve">
          <source>Transform array or sparse matrix X back to feature mappings.</source>
          <target state="translated">Преобразование массива или разреженной матрицы X обратно в сопоставления функций.</target>
        </trans-unit>
        <trans-unit id="43aed443a30ff04a0a7d38cae0c2e3f2c765ad45" translate="yes" xml:space="preserve">
          <source>Transform between iterable of iterables and a multilabel format</source>
          <target state="translated">Преобразование между итерабельными итерабельными и многоячеистым форматом</target>
        </trans-unit>
        <trans-unit id="8428b18b095eb02611727f6a1283e0146f4aea18" translate="yes" xml:space="preserve">
          <source>Transform binary labels back to multi-class labels</source>
          <target state="translated">Преобразование бинарных этикеток обратно в многоклассные этикетки</target>
        </trans-unit>
        <trans-unit id="2d5fb2d774241a80b97c22822072a1cd5822cad7" translate="yes" xml:space="preserve">
          <source>Transform data X according to the fitted model.</source>
          <target state="translated">Преобразование данных Х в соответствии с установленной моделью.</target>
        </trans-unit>
        <trans-unit id="e993947ab9336eb409d6a8eb55c55e2b5b858d46" translate="yes" xml:space="preserve">
          <source>Transform data back to its original space.</source>
          <target state="translated">Трансформируйте данные обратно в исходное пространство.</target>
        </trans-unit>
        <trans-unit id="b922af176e5b4295d0d766cd496f7523d4754428" translate="yes" xml:space="preserve">
          <source>Transform data to polynomial features</source>
          <target state="translated">Преобразование данных в полиномы</target>
        </trans-unit>
        <trans-unit id="f1a4a6b05048c3643e26b0d505b52199b7895296" translate="yes" xml:space="preserve">
          <source>Transform dataset.</source>
          <target state="translated">Трансформируй набор данных.</target>
        </trans-unit>
        <trans-unit id="0146265304f248a8c03f040ea5d584981839ec0b" translate="yes" xml:space="preserve">
          <source>Transform documents to document-term matrix.</source>
          <target state="translated">Преобразование документов в матрицу документов.</target>
        </trans-unit>
        <trans-unit id="778e7579ae52504e167839efee081ba3167de93f" translate="yes" xml:space="preserve">
          <source>Transform feature-&amp;gt;value dicts to array or sparse matrix.</source>
          <target state="translated">Функция преобразования-&amp;gt; значение указывает на массив или разреженную матрицу.</target>
        </trans-unit>
        <trans-unit id="c8f4f5c3bee4bfd8c782321e0d4eb227c2d3191b" translate="yes" xml:space="preserve">
          <source>Transform features using quantiles information.</source>
          <target state="translated">Функции преобразования с использованием информации квантилей.</target>
        </trans-unit>
        <trans-unit id="ace4ae2489dd9688eddb3a58e732664d39d28a92" translate="yes" xml:space="preserve">
          <source>Transform labels back to original encoding.</source>
          <target state="translated">Преобразуйте метки обратно в исходную кодировку.</target>
        </trans-unit>
        <trans-unit id="76c682df30bb4975f2641f2e89f16cc0b5f2d625" translate="yes" xml:space="preserve">
          <source>Transform labels to normalized encoding.</source>
          <target state="translated">Преобразование этикеток в нормализованную кодировку.</target>
        </trans-unit>
        <trans-unit id="e6d8f7568400d53b2f444fa6cbf018c08b09552e" translate="yes" xml:space="preserve">
          <source>Transform multi-class labels to binary labels</source>
          <target state="translated">Преобразование многоклассных этикеток в двоичные этикетки</target>
        </trans-unit>
        <trans-unit id="ec1f3a72d306387b537de1b3b116fbdf51b17550" translate="yes" xml:space="preserve">
          <source>Transform new data by linear interpolation</source>
          <target state="translated">Преобразование новых данных путем линейной интерполяции</target>
        </trans-unit>
        <trans-unit id="7e25dbc81754715628745ec728c6c249ac9d1737" translate="yes" xml:space="preserve">
          <source>Transform new points into embedding space.</source>
          <target state="translated">Преобразовывать новые точки во встраиваемое пространство.</target>
        </trans-unit>
        <trans-unit id="17e15b65d999776fc7cb047cfc38d87f9b340eec" translate="yes" xml:space="preserve">
          <source>Transform the data X according to the fitted NMF model</source>
          <target state="translated">Преобразование данных X в соответствии с установленной моделью NMF.</target>
        </trans-unit>
        <trans-unit id="28a4737ac1d13b4e451237dc699b89c49f7fb862" translate="yes" xml:space="preserve">
          <source>Transform the given indicator matrix into label sets</source>
          <target state="translated">Преобразовать данную индикаторную матрицу в наборы этикеток</target>
        </trans-unit>
        <trans-unit id="38739bda11e07f48ac023acb8323ed328f115bd5" translate="yes" xml:space="preserve">
          <source>Transform the given label sets</source>
          <target state="translated">Преобразовать данные наборы этикеток</target>
        </trans-unit>
        <trans-unit id="92a052e88a019f5aca9bb96a9137d202560617b4" translate="yes" xml:space="preserve">
          <source>Transform the sources back to the mixed data (apply mixing matrix).</source>
          <target state="translated">Преобразование источников обратно в смешанные данные (применить матрицу смешивания).</target>
        </trans-unit>
        <trans-unit id="6414c408546f181e607c3ec28647dd72e64872ea" translate="yes" xml:space="preserve">
          <source>Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.</source>
          <target state="translated">Превратите свои особенности в более компактное и скудное пространство.Затем подготовьте линейную модель по этим характеристикам.</target>
        </trans-unit>
        <trans-unit id="d3709f378c935401f6b259df9cce5a50135da098" translate="yes" xml:space="preserve">
          <source>Transformed array.</source>
          <target state="translated">Преобразованный массив.</target>
        </trans-unit>
        <trans-unit id="4a8a97e010ec7ac27b50257ef7ee542c13ba8846" translate="yes" xml:space="preserve">
          <source>Transformed data</source>
          <target state="translated">преобразованные данные</target>
        </trans-unit>
        <trans-unit id="d460e113769e190612a2b959c1c729d7e8676439" translate="yes" xml:space="preserve">
          <source>Transformed data in the binned space.</source>
          <target state="translated">Преобразованные данные в мусорном пространстве.</target>
        </trans-unit>
        <trans-unit id="14642329121567cf9f5775d8a6512d3b978fccd2" translate="yes" xml:space="preserve">
          <source>Transformed data matrix</source>
          <target state="translated">преобразованная матрица данных</target>
        </trans-unit>
        <trans-unit id="0d3a338b719647431757293955a1513d13c572f4" translate="yes" xml:space="preserve">
          <source>Transformed data.</source>
          <target state="translated">Преобразованные данные.</target>
        </trans-unit>
        <trans-unit id="08b12f8aaa8632b66a6a22bc4de550a469c3cc9c" translate="yes" xml:space="preserve">
          <source>Transformed dataset.</source>
          <target state="translated">Преобразованный набор данных.</target>
        </trans-unit>
        <trans-unit id="eeb85e59603c1cea29acb31c92a29204737376ea" translate="yes" xml:space="preserve">
          <source>Transformed input.</source>
          <target state="translated">Преобразованный вход.</target>
        </trans-unit>
        <trans-unit id="0a6145f06a4913811002ff339bc5284d2892e790" translate="yes" xml:space="preserve">
          <source>Transformed samples</source>
          <target state="translated">Преобразованные образцы</target>
        </trans-unit>
        <trans-unit id="6d517e36599e67ec967c7be2afac6d7777579d1a" translate="yes" xml:space="preserve">
          <source>Transformer used in &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Трансформатор используется в &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="43471a7ace97310a9577002aa9803e00d83e6192" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">Преобразователи обычно комбинируются с классификаторами, регрессорами или другими оценщиками для построения составного оценщика. Самый распространенный инструмент - &lt;a href=&quot;#pipeline&quot;&gt;конвейер&lt;/a&gt; . Конвейер часто используется в сочетании с &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion,&lt;/a&gt; который объединяет выходные данные преобразователей в составное пространство функций. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; занимается преобразованием &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;цели&lt;/a&gt; (т. Е. Логарифмическим преобразованием &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt; ). Напротив, конвейеры преобразуют только наблюдаемые данные ( &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="b69fe15775501662a569d2ed632ddbe970e558ef" translate="yes" xml:space="preserve">
          <source>Transformers for missing value imputation</source>
          <target state="translated">Трансформаторы для вменения пропущенных значений</target>
        </trans-unit>
        <trans-unit id="4804df5ca1652cab2567ab10e41eae2d30b7e99a" translate="yes" xml:space="preserve">
          <source>Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</source>
          <target state="translated">Преобразование оценок классификатора в точные оценки вероятности нескольких классов, Б. Задрозный и К. Элкан (KDD 2002)</target>
        </trans-unit>
        <trans-unit id="74f517360774a680819178109aa2b52b87d4fd99" translate="yes" xml:space="preserve">
          <source>Transforming distance to well-behaved similarities</source>
          <target state="translated">Преобразование расстояния до хорошо сохранившегося сходства</target>
        </trans-unit>
        <trans-unit id="dfe17b4b683a10ef2eafef30897d9c629bf96dd6" translate="yes" xml:space="preserve">
          <source>Transforms discretized data back to original feature space.</source>
          <target state="translated">Преобразовывает дискретизированные данные обратно в оригинальное функциональное пространство.</target>
        </trans-unit>
        <trans-unit id="5bd7a9a7032f01002afe1d21dc1635e87bd5dbc6" translate="yes" xml:space="preserve">
          <source>Transforms features by scaling each feature to a given range.</source>
          <target state="translated">Преобразование элементов путем масштабирования каждого элемента до заданного диапазона.</target>
        </trans-unit>
        <trans-unit id="45675a7235910659531092f94ca2cac1226cb6a9" translate="yes" xml:space="preserve">
          <source>Transforms lists of feature-value mappings to vectors.</source>
          <target state="translated">Преобразование списков отображений признаков в векторы.</target>
        </trans-unit>
        <trans-unit id="ff596a653686d4986dda1851c66682d846f4bf4d" translate="yes" xml:space="preserve">
          <source>Transforms the image samples in X into a matrix of patch data.</source>
          <target state="translated">Преобразовывает образцы изображений в X в матрицу патч-данных.</target>
        </trans-unit>
        <trans-unit id="d6a25d0e3691aa7e7e60fcc1d61ee6046c7d09b3" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt; основе дерева (см. Модуль sklearn.tree и лес деревьев в модуле &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; ) могут использоваться для вычисления значимости функций, которые, в свою очередь, могут использоваться для отбрасывания нерелевантных функций (в сочетании с &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt; мета-преобразователь):</target>
        </trans-unit>
        <trans-unit id="81d8ac0c0739336d0bbd6f8053b2fde8039cdb1c" translate="yes" xml:space="preserve">
          <source>Triangle Inequality: d(x, y) + d(y, z) &amp;gt;= d(x, z)</source>
          <target state="translated">Неравенство треугольника: d (x, y) + d (y, z)&amp;gt; = d (x, z)</target>
        </trans-unit>
        <trans-unit id="331d2c199452ae22aa8941c5bcbe6a7fe41c68b5" translate="yes" xml:space="preserve">
          <source>Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Relevance Vector Machines explained&lt;/a&gt;</source>
          <target state="translated">Тристан Флетчер: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Объяснение машин вектора релевантности&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b19d80cd81c13647ace615b9d73da08b4d8c61b" translate="yes" xml:space="preserve">
          <source>True : always precompute distances</source>
          <target state="translated">Правда:всегда предварительные расчеты расстояний</target>
        </trans-unit>
        <trans-unit id="ebac1d7d68472a848a069828ba36b6b2dd6227bb" translate="yes" xml:space="preserve">
          <source>True binary labels in binary indicator format.</source>
          <target state="translated">Истинные двоичные метки в двоичном формате индикатора.</target>
        </trans-unit>
        <trans-unit id="94ad072572f1b0d8a6896ff3fd5d5269c3006cce" translate="yes" xml:space="preserve">
          <source>True binary labels or binary label indicators.</source>
          <target state="translated">Истинные двоичные этикетки или двоичные индикаторы.</target>
        </trans-unit>
        <trans-unit id="173029937373f6d16ed7438491b1a8131b2bc4cb" translate="yes" xml:space="preserve">
          <source>True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.</source>
          <target state="translated">Истинные двоичные этикетки.Если метки не являются {-1,1}или {0,1},то следует явно указать pos_label.</target>
        </trans-unit>
        <trans-unit id="cba1cd7ae39f91f6d0e2908d3956200bdf94de07" translate="yes" xml:space="preserve">
          <source>True if estimator is a classifier and False otherwise.</source>
          <target state="translated">Верно,если оценщик является классификатором,и неверно.</target>
        </trans-unit>
        <trans-unit id="7e34070b9f977933411df9b814860396cade02bb" translate="yes" xml:space="preserve">
          <source>True if estimator is a regressor and False otherwise.</source>
          <target state="translated">Верно,если оценщик является регрессором,и неверно.</target>
        </trans-unit>
        <trans-unit id="d039a95b006860b5b92d23f84015c0458d6fdb1a" translate="yes" xml:space="preserve">
          <source>True if the array returned from predict is to be in sparse CSC format. Is automatically set to True if the input y is passed in sparse format.</source>
          <target state="translated">Правда,если массив,возвращаемый из предсказания,должен быть в разреженном формате CSC.Автоматически устанавливается значение True,если вход y передан в разреженном формате.</target>
        </trans-unit>
        <trans-unit id="018f28ffd2c7241c63be51b46bba3e8aa528d907" translate="yes" xml:space="preserve">
          <source>True if the input data to transform is given as a sparse matrix, False otherwise.</source>
          <target state="translated">Правда,если входные данные для преобразования даны в виде разреженной матрицы,Ложно иначе.</target>
        </trans-unit>
        <trans-unit id="06236e43536e8bd62b7d950e36ddd9dca022a999" translate="yes" xml:space="preserve">
          <source>True if the output at fit is 2d, else false.</source>
          <target state="translated">Верно,если выход при подгонке 2d,иначе ложь.</target>
        </trans-unit>
        <trans-unit id="abda54d00232aa3c71419926e38966e372a6e200" translate="yes" xml:space="preserve">
          <source>True if the returned array from transform is desired to be in sparse CSR format.</source>
          <target state="translated">Правда,если возвращаемый массив из преобразования должен быть в разреженном формате CSR.</target>
        </trans-unit>
        <trans-unit id="b3f5d1c4b9aeea8d97315ada02d3f0f3b6e0dbc5" translate="yes" xml:space="preserve">
          <source>True labels for X.</source>
          <target state="translated">Истинные ярлыки для Икс.</target>
        </trans-unit>
        <trans-unit id="24a7816a0ae25d0715f83e367246b56738200fc8" translate="yes" xml:space="preserve">
          <source>True mutual information can&amp;rsquo;t be negative. If its estimate turns out to be negative, it is replaced by zero.</source>
          <target state="translated">Истинная взаимная информация не может быть отрицательной. Если его оценка оказывается отрицательной, она заменяется нулем.</target>
        </trans-unit>
        <trans-unit id="e857c90bead41164c28f265fe201e3c7a69f5d75" translate="yes" xml:space="preserve">
          <source>True target, consisting of integers of two values. The positive label must be greater than the negative label.</source>
          <target state="translated">Истинная цель,состоящая из целых чисел двух значений.Положительная метка должна быть больше отрицательной.</target>
        </trans-unit>
        <trans-unit id="5f6f5563a268706baa91536cfcd1565c453cd8e7" translate="yes" xml:space="preserve">
          <source>True targets of binary classification in range {-1, 1} or {0, 1}.</source>
          <target state="translated">Истинные мишени бинарной классификации в диапазоне {-1,1}или {0,1}.</target>
        </trans-unit>
        <trans-unit id="6e2bbfc40bf0e63b31fb5b0351be961b49cc74be" translate="yes" xml:space="preserve">
          <source>True targets.</source>
          <target state="translated">Истинные цели.</target>
        </trans-unit>
        <trans-unit id="18dd5ee40d70767a2f6629e8ff8969a87290115e" translate="yes" xml:space="preserve">
          <source>True values for X</source>
          <target state="translated">Истинные значения для X</target>
        </trans-unit>
        <trans-unit id="81e3774c236b4c61a22388a1a822b3e69fb3e5a6" translate="yes" xml:space="preserve">
          <source>True values for X.</source>
          <target state="translated">Истинные значения для X.</target>
        </trans-unit>
        <trans-unit id="0d7ce48badf2f0a91a36bec7511768633417749f" translate="yes" xml:space="preserve">
          <source>True when convergence was reached in fit(), False otherwise.</source>
          <target state="translated">Верно,когда конвергенция была достигнута в функции fit(),неверно,в противном случае.</target>
        </trans-unit>
        <trans-unit id="d333cd18e174fe06286d776d55b1b9eaf760ce1b" translate="yes" xml:space="preserve">
          <source>True: Force all values of X to be finite.</source>
          <target state="translated">Правда:Заставить все значения X быть конечными.</target>
        </trans-unit>
        <trans-unit id="260b9ffda14105c1fd2ffa31d36eae7c83268ddd" translate="yes" xml:space="preserve">
          <source>True: the results is casted to an unsigned int</source>
          <target state="translated">Правда:результат кастится на неподписанный int</target>
        </trans-unit>
        <trans-unit id="00b6f6ebc7b7070cf35772b16b427811573346a1" translate="yes" xml:space="preserve">
          <source>Try classifying classes 1 and 2 from the iris dataset with SVMs, with the 2 first features. Leave out 10% of each class and test prediction performance on these observations.</source>
          <target state="translated">Попробуйте классифицировать классы 1 и 2 из набора данных по радужной оболочке глаза с помощью SVM,с двумя первыми функциями.Оставьте 10% от каждого класса и протестируйте производительность прогнозирования по этим наблюдениям.</target>
        </trans-unit>
        <trans-unit id="5449ae93c54cf3f8e79ab0ee95bb4ee118bd4f84" translate="yes" xml:space="preserve">
          <source>Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations.</source>
          <target state="translated">Попробуйте классифицировать набор цифр с ближайшими соседями и линейную модель.Оставьте последние 10% и проверьте эффективность прогнозирования по этим наблюдениям.</target>
        </trans-unit>
        <trans-unit id="7a783eca4388b1c7b8c830f476caa080328ba3c3" translate="yes" xml:space="preserve">
          <source>Try playing around with the &lt;code&gt;analyzer&lt;/code&gt; and &lt;code&gt;token normalisation&lt;/code&gt; under &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Попробуйте поиграть с &lt;code&gt;analyzer&lt;/code&gt; и &lt;code&gt;token normalisation&lt;/code&gt; в &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b7e468fa3f6cfdfb33fa6bf28dcdf3165bf89507" translate="yes" xml:space="preserve">
          <source>Try to differentiate the two first classes of the iris data</source>
          <target state="translated">Попробуйте дифференцировать два первых класса данных по радужной оболочке глаза.</target>
        </trans-unit>
        <trans-unit id="1bc09af6523c25787ea3631aac8c3f52f8bc29dc" translate="yes" xml:space="preserve">
          <source>Try using &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; for &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;latent semantic analysis&lt;/a&gt;.</source>
          <target state="translated">Попробуйте использовать &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; для &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;скрытого семантического анализа&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="126c548fa4d4a4c65c7759b8f0eb82ce5677dab5" translate="yes" xml:space="preserve">
          <source>Tsoumakas, G., Katakis, I., &amp;amp; Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</source>
          <target state="translated">Цумакас, Г., Катакис, И., и Влахавас, И. (2010). Майнинг данных с несколькими метками. В справочнике по интеллектуальному анализу данных и открытию знаний (стр. 667-685). Springer США.</target>
        </trans-unit>
        <trans-unit id="0d016a3ee3141a6ebd01b9c31169fb6ec8d37fd6" translate="yes" xml:space="preserve">
          <source>Tuning the hyper-parameters of an estimator</source>
          <target state="translated">Настройка гиперпараметров оценщика</target>
        </trans-unit>
        <trans-unit id="2e926727653886b165b872a4b6b2a62bf90f0bd1" translate="yes" xml:space="preserve">
          <source>Tuple of row and column indicators for a set of biclusters.</source>
          <target state="translated">Кортеж индикаторов ряда и столбца для набора бикластеров.</target>
        </trans-unit>
        <trans-unit id="c054700312acf34cbacbc98d115120c76da3a6d5" translate="yes" xml:space="preserve">
          <source>Turn seed into a np.random.RandomState instance</source>
          <target state="translated">Превратите семя в np.random.RandomState экземпляр.</target>
        </trans-unit>
        <trans-unit id="007a671747688cedb01751baca6545483f05de7a" translate="yes" xml:space="preserve">
          <source>Tutorial setup</source>
          <target state="translated">учебная установка</target>
        </trans-unit>
        <trans-unit id="025f75efad84ed2b985f2818a53e81aa77abca7c" translate="yes" xml:space="preserve">
          <source>Tutorial: A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">Учебное пособие:Учебное пособие по статистике для обработки научных данных.</target>
        </trans-unit>
        <trans-unit id="e7df3b5ebbaf2fd3b4b4579edbd7ce42f46db699" translate="yes" xml:space="preserve">
          <source>Tutorial: An introduction to machine learning with scikit-learn</source>
          <target state="translated">Учебное пособие:Введение в машинное обучение с помощью научно-обученного.</target>
        </trans-unit>
        <trans-unit id="8682fb6c27e32858369b74e47f829fad6c8d3a68" translate="yes" xml:space="preserve">
          <source>Tutorial: Choosing the right estimator</source>
          <target state="translated">Учебное пособие:Выбор правильного оценщика</target>
        </trans-unit>
        <trans-unit id="2865c0d93493065de0c34da92792e35a845226d3" translate="yes" xml:space="preserve">
          <source>Tutorial: Model selection</source>
          <target state="translated">Учебное пособие:Выбор модели</target>
        </trans-unit>
        <trans-unit id="b7709b919b68974b71489ceb95a00ef31c4eda72" translate="yes" xml:space="preserve">
          <source>Tutorial: Putting it all together</source>
          <target state="translated">Учебное пособие:Складывая все вместе</target>
        </trans-unit>
        <trans-unit id="b0b3bc4bbf4e62230750bf24baeb122d7a994298" translate="yes" xml:space="preserve">
          <source>Tutorial: Statistical learning</source>
          <target state="translated">Учебное пособие:статистическое обучение</target>
        </trans-unit>
        <trans-unit id="a149365421f01d98250256737c350c42a4cd4b82" translate="yes" xml:space="preserve">
          <source>Tutorial: Supervised learning</source>
          <target state="translated">Учебное пособие:контролируемое обучение</target>
        </trans-unit>
        <trans-unit id="4353f067a68843e09ae0691ab9f9c44ef2e6db23" translate="yes" xml:space="preserve">
          <source>Tutorial: Unsupervised learning</source>
          <target state="translated">Учебное пособие:Неконтролируемое обучение</target>
        </trans-unit>
        <trans-unit id="206fac7baeed5ee14f8990630b6607a7c33e8644" translate="yes" xml:space="preserve">
          <source>Tutorial: Working With Text Data</source>
          <target state="translated">Учебное пособие:Работа с текстовыми данными</target>
        </trans-unit>
        <trans-unit id="b919de3c63710fd07133db7062fb5a1fbffa0bfe" translate="yes" xml:space="preserve">
          <source>Tutorial: scikit-learn Tutorials</source>
          <target state="translated">Учебное пособие:Уроки фантастического обучения</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="995550b74403db560a3a2ea8d3906cd56b901336" translate="yes" xml:space="preserve">
          <source>Two algorithms are demoed: ordinary k-means and its more scalable cousin minibatch k-means.</source>
          <target state="translated">Демонстрируются два алгоритма:обычный к-средний и его более масштабируемый двоюродный мини-пакет к-средний.</target>
        </trans-unit>
        <trans-unit id="3b934d458351995534fed7d234de7b14c38f4cd4" translate="yes" xml:space="preserve">
          <source>Two approaches for performing calibration of probabilistic predictions are provided: a parametric approach based on Platt&amp;rsquo;s sigmoid model and a non-parametric approach based on isotonic regression (&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;). Probability calibration should be done on new data not used for model fitting. The class &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; uses a cross-validation generator and estimates for each split the model parameter on the train samples and the calibration of the test samples. The probabilities predicted for the folds are then averaged. Already fitted classifiers can be calibrated by &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; via the parameter cv=&amp;rdquo;prefit&amp;rdquo;. In this case, the user has to take care manually that data for model fitting and calibration are disjoint.</source>
          <target state="translated">Предлагаются два подхода к выполнению калибровки вероятностных прогнозов: параметрический подход, основанный на сигмовидной модели Платта, и непараметрический подход, основанный на изотонической регрессии ( &lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt; &lt;code&gt;sklearn.isotonic&lt;/code&gt; &lt;/a&gt; ). Калибровку вероятности следует проводить на новых данных, не используемых для подгонки модели. Класс &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; использует генератор перекрестной проверки и оценки для каждого разделения параметра модели на образцах поездов и калибровки тестовых образцов. Вероятности, предсказанные для складок, затем усредняются. Уже установленные классификаторы могут быть откалиброваны с помощью &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; через параметр cv = &quot;prefit&quot;. В этом случае пользователь должен вручную следить за тем, чтобы данные для подгонки модели и калибровки не пересекались.</target>
        </trans-unit>
        <trans-unit id="de7e8d6ad699213a292d0c528c5ddad33bca14ae" translate="yes" xml:space="preserve">
          <source>Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster.</source>
          <target state="translated">Можно заметить два последствия навязывания связи.Первая кластеризация с матрицей соединений происходит гораздо быстрее.</target>
        </trans-unit>
        <trans-unit id="73ece4ca1e1779fbf5110031e848f2313deac958" translate="yes" xml:space="preserve">
          <source>Two cross-validation loops are performed in parallel: one by the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; estimator to set &lt;code&gt;gamma&lt;/code&gt; and the other one by &lt;code&gt;cross_val_score&lt;/code&gt; to measure the prediction performance of the estimator. The resulting scores are unbiased estimates of the prediction score on new data.</source>
          <target state="translated">Два &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; перекрестной проверки выполняются параллельно: один оценщиком GridSearchCV для установки &lt;code&gt;gamma&lt;/code&gt; а другой с помощью &lt;code&gt;cross_val_score&lt;/code&gt; для измерения производительности прогнозирования оценщика. Результирующие оценки представляют собой объективные оценки оценки прогноза на основе новых данных.</target>
        </trans-unit>
        <trans-unit id="d467efdd44bf60415fc895b8589d9d81d46d02ec" translate="yes" xml:space="preserve">
          <source>Two families of ensemble methods are usually distinguished:</source>
          <target state="translated">Обычно различают два семейства ансамблевых методов:</target>
        </trans-unit>
        <trans-unit id="e8ac95de27d48015555c5b981483208d51b8f268" translate="yes" xml:space="preserve">
          <source>Two feature extraction methods can be used in this example:</source>
          <target state="translated">В этом примере можно использовать два метода извлечения признаков:</target>
        </trans-unit>
        <trans-unit id="ebb2ce8305b879c94bfe5ff4f307e7a35d679e99" translate="yes" xml:space="preserve">
          <source>Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the side of the scatter plot.</source>
          <target state="translated">Для каждого скалера/нормализатора/трансформатора будут показаны два графика.На левом рисунке будет показан график рассеяния полного набора данных,в то время как на правом рисунке будут исключены экстремальные значения,учитывающие только 99% набора данных,исключая предельные отклонения.Кроме того,предельные распределения для каждой характеристики будут показаны на боковой стороне диаграммы рассеяния.</target>
        </trans-unit>
        <trans-unit id="348f286c4d7d6b276984cd38d102dc527023a237" translate="yes" xml:space="preserve">
          <source>Two separate datasets are used for the two different plots. The reason behind this is the &lt;code&gt;l1&lt;/code&gt; case works better on sparse data, while &lt;code&gt;l2&lt;/code&gt; is better suited to the non-sparse case.</source>
          <target state="translated">Для двух разных графиков используются два отдельных набора данных. Причина этого в том, что случай &lt;code&gt;l1&lt;/code&gt; лучше работает с разреженными данными, тогда как &lt;code&gt;l2&lt;/code&gt; лучше подходит для не разреженного случая.</target>
        </trans-unit>
        <trans-unit id="32895c2e5eacd1283051e2d5a4f1fd3f826fb6ed" translate="yes" xml:space="preserve">
          <source>Two-class AdaBoost</source>
          <target state="translated">Двухклассный АдаБост</target>
        </trans-unit>
        <trans-unit id="b8fde32df7d701e50fc79883cdf21005c9469e51" translate="yes" xml:space="preserve">
          <source>Type casting</source>
          <target state="translated">Типовое литьё</target>
        </trans-unit>
        <trans-unit id="7b90464c9a3a0593a486a1facdfd06e25cac2162" translate="yes" xml:space="preserve">
          <source>Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR</source>
          <target state="translated">Тип SVM:C SVC,ню SVC,один класс,эпсилон SVR,ню SVR</target>
        </trans-unit>
        <trans-unit id="fb24034e0a15fdb11753c4c561fec377a847eca1" translate="yes" xml:space="preserve">
          <source>Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR respectively. 0 by default.</source>
          <target state="translated">Тип SVM:C_SVC,NuSVC,OneClassSVM,EpsilonSVR или NuSVR соответственно.0 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="05734831eef4f60aabd73eed1535149e1780b49e" translate="yes" xml:space="preserve">
          <source>Type of kernel.</source>
          <target state="translated">Тип ядра.</target>
        </trans-unit>
        <trans-unit id="7784bde958a1d323776ea14d0478698cc397c040" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, and &amp;lsquo;distance&amp;rsquo; will return the distances between neighbors according to the given metric.</source>
          <target state="translated">Тип возвращаемой матрицы: &amp;laquo;связность&amp;raquo; вернет матрицу связности с единицами и нулями, а &amp;laquo;расстояние&amp;raquo; вернет расстояния между соседями в соответствии с заданной метрикой.</target>
        </trans-unit>
        <trans-unit id="029a83801426f186d4049ef92d5f3d3590b1d125" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, in &amp;lsquo;distance&amp;rsquo; the edges are Euclidean distance between points.</source>
          <target state="translated">Тип возвращаемой матрицы: &amp;laquo;связность&amp;raquo; вернет матрицу связности с единицами и нулями, в &amp;laquo;расстоянии&amp;raquo; края - это евклидово расстояние между точками.</target>
        </trans-unit>
        <trans-unit id="e2af4c36790c9137ba49cdb815accc60f6f75311" translate="yes" xml:space="preserve">
          <source>Type of store backend for reading/writing cache files. Default: &amp;lsquo;local&amp;rsquo;. The &amp;lsquo;local&amp;rsquo; backend is using regular filesystem operations to manipulate data (open, mv, etc) in the backend.</source>
          <target state="translated">Тип хранилища для чтения / записи файлов кеша. По умолчанию: &amp;laquo;местный&amp;raquo;. &amp;laquo;Локальный&amp;raquo; бэкэнд использует обычные операции файловой системы для управления данными (open, mv и т. Д.) В бэкэнде.</target>
        </trans-unit>
        <trans-unit id="858cba7a97e85950fd69a9661ce88f3dff1bf729" translate="yes" xml:space="preserve">
          <source>Type of the matrix returned by fit_transform() or transform().</source>
          <target state="translated">Тип матрицы,возвращаемой функциями fit_transform()или transform().</target>
        </trans-unit>
        <trans-unit id="b6e792a3d08a7bd144dac10e42edb461fd3dd2e3" translate="yes" xml:space="preserve">
          <source>Type to use in computing the mean. For integer inputs, the default is &lt;code&gt;float64&lt;/code&gt;; for floating point inputs, it is the same as the input dtype.</source>
          <target state="translated">Тип для использования при вычислении среднего. Для целочисленных входов значение по умолчанию - &lt;code&gt;float64&lt;/code&gt; ; для входных данных с плавающей запятой это то же самое, что и входной dtype.</target>
        </trans-unit>
        <trans-unit id="f77afa338a167babd59a76b7f498d6550ba586ff" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">Предполагая, что данные распределены по Гауссу, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; вывели формулу, направленную на выбор коэффициента усадки, который дает меньшую среднеквадратичную ошибку, чем та, которая дается формулой Ледуа и Вольфа. Результирующая оценка известна как оценка ковариации Oracle Shrinkage Approximating.</target>
        </trans-unit>
        <trans-unit id="b57ce0246b95ca0ff3d95c499722ea513c24180d" translate="yes" xml:space="preserve">
          <source>Underfitting vs. Overfitting</source>
          <target state="translated">Переоснащение против переоснащения</target>
        </trans-unit>
        <trans-unit id="10dab5fb240281c20bb10ad043cbba82ec3b0bd6" translate="yes" xml:space="preserve">
          <source>Understanding the decision tree structure</source>
          <target state="translated">Понимание структуры дерева решений</target>
        </trans-unit>
        <trans-unit id="a381b476a1bdd0042346ffd8d02655a7131aa344" translate="yes" xml:space="preserve">
          <source>Undo the scaling of X according to feature_range.</source>
          <target state="translated">Отменить масштабирование X в соответствии с диапазоном feature_range.</target>
        </trans-unit>
        <trans-unit id="11b4a2e4a2b6531b9e75ad23f03f25fd4f8ecde0" translate="yes" xml:space="preserve">
          <source>Uniform weights are used by default.</source>
          <target state="translated">По умолчанию используются унифицированные веса.</target>
        </trans-unit>
        <trans-unit id="9421754583ed6d327fe582bef2d0e2d0f17ba0c4" translate="yes" xml:space="preserve">
          <source>Unique class labels.</source>
          <target state="translated">Уникальные этикетки класса.</target>
        </trans-unit>
        <trans-unit id="6efd4cf40567c19c24a13e3421a6d1109a47da44" translate="yes" xml:space="preserve">
          <source>Uniquely holds the label for each class.</source>
          <target state="translated">Уникально держит этикетку для каждого класса.</target>
        </trans-unit>
        <trans-unit id="15f758514c6db2ef9033ee5636e4d09d40ce9747" translate="yes" xml:space="preserve">
          <source>Univariate Feature Selection</source>
          <target state="translated">Выбор одномерной характеристики</target>
        </trans-unit>
        <trans-unit id="820dda4dd874419c514343cc2737763cc18b33d1" translate="yes" xml:space="preserve">
          <source>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">Одномерный выбор функций работает путем выбора лучших функций на основе одномерных статистических тестов. Это можно рассматривать как этап предварительной обработки оценщика. Scikit-learn предоставляет процедуры выбора функций как объекты, реализующие метод &lt;code&gt;transform&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b943e7c2ae0f248f889b02c7d797d243c0d56e6a" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable mode.</source>
          <target state="translated">Селектор однопараметрических функций с настраиваемым режимом.</target>
        </trans-unit>
        <trans-unit id="05b44ce5dcc153b8702db1e0eab0c9af1fb62f9c" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable strategy.</source>
          <target state="translated">Одномерный селектор функций с настраиваемой стратегией.</target>
        </trans-unit>
        <trans-unit id="d9b7ebeeb7d99a7c69a9087085473be1721215ee" translate="yes" xml:space="preserve">
          <source>Univariate linear regression tests.</source>
          <target state="translated">Одномерные тесты линейной регрессии.</target>
        </trans-unit>
        <trans-unit id="833fdc74927caa030c0f5f51bade98d55541b93d" translate="yes" xml:space="preserve">
          <source>Unlabeled entries in &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">Записи без метки в &lt;code&gt;y&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d5f2b47c1710490958929f8f01f5858025c133e1" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, input will be cast to &lt;code&gt;float64&lt;/code&gt;:</source>
          <target state="translated">Если не указано иное, ввод будет &lt;code&gt;float64&lt;/code&gt; в float64 :</target>
        </trans-unit>
        <trans-unit id="6027b38892a9b0df12f36988c98a41a4655ff464" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.</source>
          <target state="translated">В отличие от &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; , представление вектора получается аддитивным способом, путем наложения компонентов без вычитания. Такие аддитивные модели эффективны для представления изображений и текста.</target>
        </trans-unit>
        <trans-unit id="f73d55c7488edaa74f7dc85966062a8a5be2b94b" translate="yes" xml:space="preserve">
          <source>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</source>
          <target state="translated">В отличие от большинства других оценок,оценка R^2 может быть отрицательной (на самом деле она не обязательно должна быть квадратом количества R).</target>
        </trans-unit>
        <trans-unit id="fb0dd07f15380472f302743b85f6d7c3f60efb9d" translate="yes" xml:space="preserve">
          <source>Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).</source>
          <target state="translated">В отличие от предыдущих сканеров,статистика центрирования и масштабирования этого скалера основана на процентилях и поэтому не подвержена влиянию нескольких очень больших маргинальных отклонений.Следовательно,результирующий диапазон преобразованных значений признаков больше,чем у предыдущих шкалеров,и,что более важно,примерно одинаков:для обоих признаков большая часть преобразованных значений лежит в диапазоне [-2,3],как видно из приближенного к масштабу рисунка.Обратите внимание,что сами отклонения все еще присутствуют в преобразованных данных.Если желателен отдельный обрезок выбросов,то требуется нелинейное преобразование (см.ниже).</target>
        </trans-unit>
        <trans-unit id="be4091e1f0941887f57bdebf1b1a9b607356f1f1" translate="yes" xml:space="preserve">
          <source>Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.</source>
          <target state="translated">В отличие от предыдущих преобразований,нормализация относится к преобразованию на выборку,а не к преобразованию на объект.</target>
        </trans-unit>
        <trans-unit id="d6efdeaf0fd8663d7b74628a841a2a21988919e0" translate="yes" xml:space="preserve">
          <source>Unregularized graph based semi-supervised learning</source>
          <target state="translated">Нерегулируемое обучение на основе полууправляемых графиков</target>
        </trans-unit>
        <trans-unit id="27bee227769f6c4dd6bbb550e3dab104adba94bb" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</source>
          <target state="translated">Обнаружение неконтролируемых выбросов с помощью локального коэффициента выброса (LOF).</target>
        </trans-unit>
        <trans-unit id="7b5353048e77b9864be0e146d8fe78c3034a09d3" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection.</source>
          <target state="translated">Неконтролируемое обнаружение внешних воздействий.</target>
        </trans-unit>
        <trans-unit id="091dbb252c60dafbec16ee540eb9588c7d736a5b" translate="yes" xml:space="preserve">
          <source>Unsupervised learner for implementing neighbor searches.</source>
          <target state="translated">Неконтролируемый ученик для осуществления поиска соседей.</target>
        </trans-unit>
        <trans-unit id="336bcbb510eed89e13ba021c352635cdc0677016" translate="yes" xml:space="preserve">
          <source>Unsupervised learning: seeking representations of the data</source>
          <target state="translated">Неконтролируемое обучение:поиск представлений данных</target>
        </trans-unit>
        <trans-unit id="568c5820f9e5362ca266c9125e695403019435a8" translate="yes" xml:space="preserve">
          <source>Unused parameter.</source>
          <target state="translated">Неиспользуемый параметр.</target>
        </trans-unit>
        <trans-unit id="207a5be036cc811b3313bce86d86c7d5b4302176" translate="yes" xml:space="preserve">
          <source>Update k means estimate on a single mini-batch X.</source>
          <target state="translated">Обновление k означает оценку на одну мини-группу X.</target>
        </trans-unit>
        <trans-unit id="718430f889e80a3494a47ee7bec5ca3329673e5e" translate="yes" xml:space="preserve">
          <source>Updated feature-wise means.</source>
          <target state="translated">Обновленные функциональные средства.</target>
        </trans-unit>
        <trans-unit id="4f10d24907ba29eca99bd941c7ead98539a4f5b4" translate="yes" xml:space="preserve">
          <source>Updated feature-wise variances.</source>
          <target state="translated">Обновленные функциональные изменения.</target>
        </trans-unit>
        <trans-unit id="693a7de21c7466734e7ffa03c5ae997209e7997d" translate="yes" xml:space="preserve">
          <source>Updated number of seen samples.</source>
          <target state="translated">Обновленное количество просмотренных образцов.</target>
        </trans-unit>
        <trans-unit id="410e0e09369f3d862bca36022b47e478be0933f7" translate="yes" xml:space="preserve">
          <source>Updates the model using the data in X as a mini-batch.</source>
          <target state="translated">Обновление модели с использованием данных в X в виде мини-партии.</target>
        </trans-unit>
        <trans-unit id="48b5dd5eaa54e931a34dd1d6396ec1c9d66da80b" translate="yes" xml:space="preserve">
          <source>Urbanowicz R.J., Moore, J.H. &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: description and evaluation of a scalable learning classifier system&lt;/a&gt;, Evol. Intel. (2015) 8: 89.</source>
          <target state="translated">Urbanowicz RJ, Moore, JH &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: описание и оценка масштабируемой системы классификаторов обучения&lt;/a&gt; , Evol. Intel. (2015) 8:89.</target>
        </trans-unit>
        <trans-unit id="173610cb31251b28e80fadc258036215d99d7128" translate="yes" xml:space="preserve">
          <source>Usage examples:</source>
          <target state="translated">Примеры использования:</target>
        </trans-unit>
        <trans-unit id="272998fc40498f57127bf4e7cf71805cd53c9500" translate="yes" xml:space="preserve">
          <source>Use 0 when &lt;code&gt;Y&lt;/code&gt; contains the output of decision_function (classifier). Use 0.5 when &lt;code&gt;Y&lt;/code&gt; contains the output of predict_proba.</source>
          <target state="translated">Используйте 0, когда &lt;code&gt;Y&lt;/code&gt; содержит вывод функции решения (классификатора). Используйте 0.5, если &lt;code&gt;Y&lt;/code&gt; содержит вывод pred_proba.</target>
        </trans-unit>
        <trans-unit id="e620712d1a8872ff21d8a3d8ca61cf7867c4f8c8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;min_samples_split&lt;/code&gt; or &lt;code&gt;min_samples_leaf&lt;/code&gt; to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try &lt;code&gt;min_samples_leaf=5&lt;/code&gt; as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While &lt;code&gt;min_samples_split&lt;/code&gt; can create arbitrarily small leaves, &lt;code&gt;min_samples_leaf&lt;/code&gt; guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; is often the best choice.</source>
          <target state="translated">Используйте &lt;code&gt;min_samples_split&lt;/code&gt; или &lt;code&gt;min_samples_leaf&lt;/code&gt; , чтобы гарантировать, что несколько выборок сообщают каждому решению в дереве, контролируя, какие разделения будут учитываться. Очень маленькое число обычно означает, что дерево будет переоснащаться, тогда как большое число не позволит дереву изучить данные. Попробуйте &lt;code&gt;min_samples_leaf=5&lt;/code&gt; в качестве начального значения. Если размер выборки сильно различается, в этих двух параметрах можно использовать число с плавающей запятой в процентах. В то время как &lt;code&gt;min_samples_split&lt;/code&gt; может создавать произвольно маленькие листья, &lt;code&gt;min_samples_leaf&lt;/code&gt; гарантирует, что каждый лист имеет минимальный размер, избегая низкоразмерных, чрезмерно подходящих конечных узлов в задачах регрессии. Для классификации с несколькими классами &lt;code&gt;min_samples_leaf=1&lt;/code&gt; часто лучший выбор.</target>
        </trans-unit>
        <trans-unit id="3429b333ce93c8bae91a85fe794f080132090825" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</source>
          <target state="translated">Используйте &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7760fd58346bed0a2b559e055012bd8a21868552" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.</source>
          <target state="translated">Используйте SelectFromModel мета-трансформатор вместе с Lasso,чтобы выбрать лучшую пару функций из Бостонского набора данных.</target>
        </trans-unit>
        <trans-unit id="71685d673fcc400f8aa4ec7ef3e4a61bf3bbf5f7" translate="yes" xml:space="preserve">
          <source>Use approximate bound as score.</source>
          <target state="translated">Используйте в качестве балла приблизительный результат.</target>
        </trans-unit>
        <trans-unit id="400d526bc775314ded26ebb1519045ccc0979588" translate="yes" xml:space="preserve">
          <source>Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.</source>
          <target state="translated">Используйте плотность=1/3,0,если вы хотите воспроизвести результаты Achlioptas,2001.</target>
        </trans-unit>
        <trans-unit id="38fb3c866f165060e0d95ec1a873c702ff2c91dc" translate="yes" xml:space="preserve">
          <source>Use only on new data</source>
          <target state="translated">Использовать только для новых данных</target>
        </trans-unit>
        <trans-unit id="0eb6d7f6360fc3b257840e6d0ece909142d961e3" translate="yes" xml:space="preserve">
          <source>Use splitting criteria that compute the average reduction across all n outputs.</source>
          <target state="translated">Используйте критерии разделения,которые вычисляют среднее снижение по всем n выводам.</target>
        </trans-unit>
        <trans-unit id="d4a5711bd46bd2a4542a66497bb7f3342ea23a7f" translate="yes" xml:space="preserve">
          <source>Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; estimator.</source>
          <target state="translated">Используйте информационный критерий Акаике (AIC), информационный критерий Байеса (BIC) и перекрестную проверку, чтобы выбрать оптимальное значение параметра регуляризации альфа для оценки &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Лассо&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="35f6c244b8fd2da4794beb17214246bc1c30610f" translate="yes" xml:space="preserve">
          <source>Usecase</source>
          <target state="translated">Usecase</target>
        </trans-unit>
        <trans-unit id="2d6d1bb4bf090f9031a078f80f81b5cfa346c5fb" translate="yes" xml:space="preserve">
          <source>Used for internal caching. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Используется для внутреннего кэширования.По умолчанию кэширование не выполняется.Если задана строка,то это путь к каталогу кэширования.</target>
        </trans-unit>
        <trans-unit id="a659f5ae4cfedf0686976ca2f311fa3c53dbc2ce" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">Используется для рандомизации разложения по сингулярным числам и инициализации k-средних. Используйте int, чтобы сделать случайность детерминированной. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="04206996c9eca941c8da97d474cf5a147f4b8713" translate="yes" xml:space="preserve">
          <source>Used to cache the fitted transformers of the pipeline. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute &lt;code&gt;named_steps&lt;/code&gt; or &lt;code&gt;steps&lt;/code&gt; to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.</source>
          <target state="translated">Используется для кэширования установленных трансформаторов трубопровода. По умолчанию кэширование не выполняется. Если дана строка, это путь к каталогу кеширования. Включение кэширования запускает клонирование трансформаторов перед установкой. Следовательно, экземпляр трансформатора, переданный в трубопровод, нельзя проверить напрямую. Используйте атрибут &lt;code&gt;named_steps&lt;/code&gt; или &lt;code&gt;steps&lt;/code&gt; для проверки оценщиков в конвейере. Кэширование трансформаторов выгодно, если установка требует много времени.</target>
        </trans-unit>
        <trans-unit id="b831b0ccc618367ad6990c063d4f6b68c21b54a0" translate="yes" xml:space="preserve">
          <source>Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">Используется для кэширования результатов вычисления дерева.По умолчанию кэширование не производится.Если задана строка,то это путь к каталогу кэширования.</target>
        </trans-unit>
        <trans-unit id="ec2d1021c796c8396406488bdd5b004de6014166" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties.</source>
          <target state="translated">Используется для указания нормы, применяемой при наложении штрафов. Решатели newton-cg, sag и lbfgs поддерживают только l2 штрафов.</target>
        </trans-unit>
        <trans-unit id="5a789f5832dbb34972e6ab11f85f2125e32dddce" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">Полезно для применения нелинейного преобразования в задачах регрессии. Это преобразование может быть задано как преобразователь, например QuantileTransformer, или как функция и ее обратная функция, например &lt;code&gt;log&lt;/code&gt; и &lt;code&gt;exp&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="665be16622d5dce4c265443eced33f5309efed0f" translate="yes" xml:space="preserve">
          <source>Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.</source>
          <target state="translated">Полезно только для ньютон-кг,sag и lbfgs solvers.Максимальное количество итераций,необходимое для конвергенции решателей.</target>
        </trans-unit>
        <trans-unit id="1f7081fc6e8837c157dbcac4dfe150624d77daa3" translate="yes" xml:space="preserve">
          <source>Useful only when the solver &amp;lsquo;liblinear&amp;rsquo; is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt;.</source>
          <target state="translated">Полезно, только если используется решатель liblinear и для self.fit_intercept установлено значение True. В этом случае x становится [x, self.intercept_scaling], т.е. &amp;laquo;синтетическая&amp;raquo; функция с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cb4f9242d2c5bef801309a7b11564e9f2917779f" translate="yes" xml:space="preserve">
          <source>Useful tutorials for developing a feel for some of scikit-learn's applications in the machine learning field.</source>
          <target state="translated">Полезные обучающие материалы для развития навыков работы с некоторыми приложениями Scikit-learn в области машинного обучения.</target>
        </trans-unit>
        <trans-unit id="bec249e659662f7d5947bf09a1ea1d4a552885b0" translate="yes" xml:space="preserve">
          <source>User Guide</source>
          <target state="translated">руководство пользователя</target>
        </trans-unit>
        <trans-unit id="32b4edc9350cb6d93cc0316d635ce26e35fa63d2" translate="yes" xml:space="preserve">
          <source>Uses BLAS GEMM as replacement for numpy.dot where possible to avoid unnecessary copies.</source>
          <target state="translated">Использует BLAS GEMM в качестве замены для numpy.dot там,где это возможно,чтобы избежать ненужных копий.</target>
        </trans-unit>
        <trans-unit id="ac4bd4f4f631e790604905794abbd6ed09d66803" translate="yes" xml:space="preserve">
          <source>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</source>
          <target state="translated">Использует подмножество обучающих точек в функции принятия решений (так называемые поддерживающие векторы),поэтому он также эффективен с точки зрения памяти.</target>
        </trans-unit>
        <trans-unit id="4a4b56e0bea50fff706430a1a94289a4e5e03040" translate="yes" xml:space="preserve">
          <source>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</source>
          <target state="translated">Использует модель белой коробки.Если заданная ситуация наблюдается в модели,то объяснение условия легко объяснить с помощью булевой логики.Напротив,в модели &quot;черного ящика&quot; (например,в искусственной нейронной сети)результаты могут быть сложнее интерпретированы.</target>
        </trans-unit>
        <trans-unit id="ced5d25baa7aaf39837296d764096d52eb67f5ca" translate="yes" xml:space="preserve">
          <source>Uses sampling the fourier transform of the kernel characteristic at regular intervals.</source>
          <target state="translated">Использует выборку преобразования фурье характеристики ядра через регулярные промежутки времени.</target>
        </trans-unit>
        <trans-unit id="2c633fc259072170ae02b4cf8b2266258b09ddc5" translate="yes" xml:space="preserve">
          <source>Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).</source>
          <target state="translated">Использует словарный запас и частоты документов (df)узнал по мере необходимости (или fit_transform).</target>
        </trans-unit>
        <trans-unit id="cdea6e25f0fe24b03bf907dbf26253d4f40a11df" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; or &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; enables the &lt;code&gt;predict_proba&lt;/code&gt; method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">Использование &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; или &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; включает метод &lt;code&gt;predict_proba&lt;/code&gt; , который дает вектор оценок вероятности \ (P (y | x) \) на выборку \ (x \):</target>
        </trans-unit>
        <trans-unit id="4072d118d17ebbe341d060ec8f347bb287543668" translate="yes" xml:space="preserve">
          <source>Using FunctionTransformer to select columns</source>
          <target state="translated">Использование FunctionTransformer для выбора столбцов</target>
        </trans-unit>
        <trans-unit id="af570039f4e6335c176e5a0ced20f61ade37ec58" translate="yes" xml:space="preserve">
          <source>Using KBinsDiscretizer to discretize continuous features</source>
          <target state="translated">Использование KBinsDiscretizer для дискретизации непрерывных функций</target>
        </trans-unit>
        <trans-unit id="58dd6560cd1dd1ff16a956c31444ffff4530a294" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more feature are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Использование &lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; L1, предоставляемых LinearSVC (потеря = 'l2', штраф = 'l1', dual = False), дает разреженное решение, то есть только подмножество весов характеристик отличается от нуля и вносит вклад в функцию принятия решения. Увеличение &lt;code&gt;C&lt;/code&gt; дает более сложную модель (выбирается больше функций). Значение &lt;code&gt;C&lt;/code&gt; , которое дает &amp;laquo;нулевую&amp;raquo; модель (все веса равны нулю), может быть вычислено с помощью &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0033ecf2999fee9c8f71baf5ea186698e26a6aa1" translate="yes" xml:space="preserve">
          <source>Using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; without cache enabled, it is possible to inspect the original instance such as:</source>
          <target state="translated">Используя &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; без включенного кеша, можно проверить исходный экземпляр, например:</target>
        </trans-unit>
        <trans-unit id="4b38a6f3576ed137cc4e9a9f59798fb707d4dde4" translate="yes" xml:space="preserve">
          <source>Using a single underlying feature the model learns both the x and y coordinate as output.</source>
          <target state="translated">Используя единственную базовую функцию,модель получает на выходе координаты x и y.</target>
        </trans-unit>
        <trans-unit id="6d5ea28ea8efb863c08e76177dc50acce9324f64" translate="yes" xml:space="preserve">
          <source>Using a small &lt;code&gt;max_features&lt;/code&gt; value can significantly decrease the runtime.</source>
          <target state="translated">Использование небольшого значения &lt;code&gt;max_features&lt;/code&gt; может значительно сократить время выполнения.</target>
        </trans-unit>
        <trans-unit id="03c1a9468c05dba06aec630e70cb3912379c2cb0" translate="yes" xml:space="preserve">
          <source>Using its &lt;code&gt;partial_fit&lt;/code&gt; method on chunks of data fetched sequentially from the local hard drive or a network database.</source>
          <target state="translated">Использование его метода &lt;code&gt;partial_fit&lt;/code&gt; для фрагментов данных, последовательно извлекаемых с локального жесткого диска или сетевой базы данных.</target>
        </trans-unit>
        <trans-unit id="ee5e8e298a940fdf98e8e52d2f16edd9327907f7" translate="yes" xml:space="preserve">
          <source>Using kernels</source>
          <target state="translated">Использование ядер</target>
        </trans-unit>
        <trans-unit id="9cfba89ca182507cccdcf4094af12bc5a4c62801" translate="yes" xml:space="preserve">
          <source>Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary</source>
          <target state="translated">Использование ортогонального поиска соответствия для восстановления разреженного сигнала от шумного измерения,закодированного в словаре.</target>
        </trans-unit>
        <trans-unit id="24a0ae926e510d4f01c040899e37f954b1d9b717" translate="yes" xml:space="preserve">
          <source>Using pre_dispatch in a producer/consumer situation, where the data is generated on the fly. Note how the producer is first called 3 times before the parallel loop is initiated, and then called to generate new data on the fly:</source>
          <target state="translated">Использование pre_dispatch в ситуации производитель/потребитель,где данные генерируются на лету.Обратите внимание,как производитель сначала вызывается 3 раза перед началом параллельного цикла,а затем вызывается для генерации новых данных &quot;на лету&quot;:</target>
        </trans-unit>
        <trans-unit id="efd1182f39233190c4734b5ce34b9cfcf1bbe0bb" translate="yes" xml:space="preserve">
          <source>Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.</source>
          <target state="translated">Используя t-SNE.Журнал исследований в области обучения на станках 9:2579-2605,2008.</target>
        </trans-unit>
        <trans-unit id="52758be5ab8f6ab028b2bf9ad6db5d2b69896663" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TfidfTransformer&lt;/code&gt;&amp;rsquo;s default settings, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as</source>
          <target state="translated">Использование &lt;code&gt;TfidfTransformer&lt;/code&gt; &amp;laquo;настройки s по умолчанию, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; термин частота, число раз термин встречается в данном документе, умножается на IDF компонент, который вычисляется как</target>
        </trans-unit>
        <trans-unit id="95d62a973e97428e1fb3d7b86f3a392143b00b8c" translate="yes" xml:space="preserve">
          <source>Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.</source>
          <target state="translated">Использование оценочного прибора GraphicalLasso для изучения ковариаций и разреженной точности на небольшом количестве образцов.</target>
        </trans-unit>
        <trans-unit id="f9e94a3c6c72e38b7c72fe500879db6b6bb31872" translate="yes" xml:space="preserve">
          <source>Using the Iris dataset, we can construct a tree as follows:</source>
          <target state="translated">Используя набор данных Iris,мы можем построить дерево следующим образом:</target>
        </trans-unit>
        <trans-unit id="f990799abb31a15673ef02f50b5506399075290a" translate="yes" xml:space="preserve">
          <source>Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:</source>
          <target state="translated">Используя ожидаемое значение,скорректированная взаимная информация может быть рассчитана в той же форме,что и скорректированный индекс Rand:</target>
        </trans-unit>
        <trans-unit id="525fdffa79943fda791ea83f2bc571cbb29e45c1" translate="yes" xml:space="preserve">
          <source>Using the naive conditional independence assumption that</source>
          <target state="translated">Используя наивное условное предположение о независимости,что</target>
        </trans-unit>
        <trans-unit id="ded2353583b49d229cc248063161251fcd75da59" translate="yes" xml:space="preserve">
          <source>Using the prediction pipeline in a grid search</source>
          <target state="translated">Использование конвейера прогнозирования при поиске по сетке</target>
        </trans-unit>
        <trans-unit id="4b65de55e2dd198ac6e2aecd67614d2f3e1d68d9" translate="yes" xml:space="preserve">
          <source>Using the results of the previous exercises and the &lt;code&gt;cPickle&lt;/code&gt; module of the standard library, write a command line utility that detects the language of some text provided on &lt;code&gt;stdin&lt;/code&gt; and estimate the polarity (positive or negative) if the text is written in English.</source>
          <target state="translated">Используя результаты предыдущих упражнений и модуль &lt;code&gt;cPickle&lt;/code&gt; стандартной библиотеки, напишите утилиту командной строки, которая определяет язык некоторого текста, предоставленного на &lt;code&gt;stdin&lt;/code&gt; , и оценивает полярность (положительную или отрицательную), если текст написан на английском языке.</target>
        </trans-unit>
        <trans-unit id="271df6087c1c40487d3dd610dcce2afcb5a005f8" translate="yes" xml:space="preserve">
          <source>Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:</source>
          <target state="translated">Используя это изменение,tf-idf третьего срока в документе 1 изменяется на 1.8473:</target>
        </trans-unit>
        <trans-unit id="35033b7b1c0300bd76803da2e755fdbe07a7c28b" translate="yes" xml:space="preserve">
          <source>Utilities from joblib:</source>
          <target state="translated">Коммунальные услуги от joblib:</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="8d1950c14bc870de437b37f806aaa51c635a9ec3" translate="yes" xml:space="preserve">
          <source>V measure</source>
          <target state="translated">V мера</target>
        </trans-unit>
        <trans-unit id="a6ed7787c295565530f8c589d9ab12370f5f5b3d" translate="yes" xml:space="preserve">
          <source>V or VI</source>
          <target state="translated">V или VI</target>
        </trans-unit>
        <trans-unit id="e659ac0cd03fda8c2776727471548e055d6ecaa7" translate="yes" xml:space="preserve">
          <source>V-Measure (NMI with arithmetic mean option.)</source>
          <target state="translated">V-Measure (NMI с опцией среднего арифметического).</target>
        </trans-unit>
        <trans-unit id="893c35d89ea6a5c89935fd8eeed462af4410524f" translate="yes" xml:space="preserve">
          <source>V-Measure is furthermore symmetric: swapping &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;label_pred&lt;/code&gt; will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the arithmetic averaging method.</source>
          <target state="translated">Кроме того, V-Measure является симметричным: замена &lt;code&gt;labels_true&lt;/code&gt; и &lt;code&gt;label_pred&lt;/code&gt; даст одинаковый результат. Это не относится к однородности и полноте. V-Measure идентичен &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; с методом арифметического усреднения.</target>
        </trans-unit>
        <trans-unit id="47faeee4990a814efec079e593cccd036ad6778a" translate="yes" xml:space="preserve">
          <source>V-measure cluster labeling given a ground truth.</source>
          <target state="translated">Кластерная маркировка V-измерений,дающая основание для истины.</target>
        </trans-unit>
        <trans-unit id="a4fd517acce42be80ab9791260ae88f5cbdf1a52" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Spam filtering with Naive Bayes &amp;ndash; Which Naive Bayes?&lt;/a&gt; 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">В. Метсис, И. Андроутсопулос и Г. Палиурас (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Фильтрация спама с помощью наивного байесовского метода - какой наивный байесовский метод? &lt;/a&gt;3-я конф. по электронной почте и защите от спама (CEAS).</target>
        </trans-unit>
        <trans-unit id="942786415758a60976a047b84669d53dbc12ecc2" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes &amp;ndash; Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">В. Метсис, И. Андроутсопулос и Г. Палиурас (2006). Фильтрация спама с помощью наивного Байеса - Какой наивный Байес? 3-я конф. по электронной почте и защите от спама (CEAS).</target>
        </trans-unit>
        <trans-unit id="ca4c1a38268237e7698432accf1a9a5a48b6fb08" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_distances.</source>
          <target state="translated">Действительные метрики для парных_расстояний.</target>
        </trans-unit>
        <trans-unit id="26700c8a25eea6fd902a0bb4963f14783c982650" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_kernels</source>
          <target state="translated">Действительные метрики для парных_ядер</target>
        </trans-unit>
        <trans-unit id="850c962c3f063b586578621ee12bbb84d6f38bb7" translate="yes" xml:space="preserve">
          <source>Valid options:</source>
          <target state="translated">Действительные варианты:</target>
        </trans-unit>
        <trans-unit id="493108de26f61e3b76acfe363b14fa409e1fdc9a" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with &lt;code&gt;get_params()&lt;/code&gt;.</source>
          <target state="translated">Допустимые ключи параметров могут быть перечислены с помощью &lt;code&gt;get_params()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1a791ec45bdf21e7b9592679ed5472b3c5ab8093" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with get_params().</source>
          <target state="translated">С помощью функции get_params()можно перечислить действительные ключи параметров.</target>
        </trans-unit>
        <trans-unit id="90d9fefcb561047bbbd742b13c3608c6fcf1e657" translate="yes" xml:space="preserve">
          <source>Valid values for metric are:</source>
          <target state="translated">Действительные значения для метрики:</target>
        </trans-unit>
        <trans-unit id="47edea5ff3c24dcb16dc15647447ec5c4a9d77c2" translate="yes" xml:space="preserve">
          <source>Valid values for metric are::</source>
          <target state="translated">Действительными значениями для метрики являются:..:</target>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">Кривая проверки.</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">Значение,добавленное к диагонали матрицы кернела при подгонке.Большие значения соответствуют повышенному уровню шума в наблюдениях.Это также может предотвратить потенциальную числовую проблему во время подгонки,гарантируя,что вычисленные значения образуют положительную определенную матрицу.Если передаётся массив,то он должен иметь то же количество записей,что и данные,используемые для подгонки,и использоваться как уровень шума,зависящий от точки отсчёта.Обратите внимание,что это эквивалентно добавлению WhiteKernel с c=alpha.Разрешение задавать уровень шума непосредственно в качестве параметра в основном для удобства и согласованности с Ridge.</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Значение числовой устойчивости в адаме. Используется только когда solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">Значение псевдо-вероятности (прокси-сервер для вероятности).</target>
        </trans-unit>
        <trans-unit id="7c9f9f5dcfc8aebd4eea110198ededa32c4b1278" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Значение, присваиваемое баллу, если при подгонке оценщика возникает ошибка. Если установлено значение &amp;laquo;поднять&amp;raquo;, возникает ошибка. Если задано числовое значение, возникает FitFailedWarning. Этот параметр не влияет на этап переоборудования, который всегда вызывает ошибку. По умолчанию - &amp;laquo;поднять&amp;raquo;, но с версии 0.22 он изменится на np.nan.</target>
        </trans-unit>
        <trans-unit id="51fe27463b1bbffac6c175b98fff3a09a8ef007a" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If set to &amp;lsquo;raise-deprecating&amp;rsquo;, a FutureWarning is printed before the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise-deprecating&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Значение, присваиваемое оценке, если при подборе оценщика возникает ошибка. Если установлено значение &amp;laquo;поднять&amp;raquo;, возникает ошибка. Если установлено значение &amp;laquo;raise-deprecating&amp;raquo;, FutureWarning печатается до возникновения ошибки. Если задано числовое значение, возникает FitFailedWarning. Этот параметр не влияет на этап переоборудования, который всегда вызывает ошибку. По умолчанию это &quot;повышение-устаревшее&quot;, но с версии 0.22 оно изменится на np.nan.</target>
        </trans-unit>
        <trans-unit id="402a4cfb84a22d3670431b1576518e6587de93b8" translate="yes" xml:space="preserve">
          <source>Value to use for the dummy feature.</source>
          <target state="translated">Значение для использования функции манекена.</target>
        </trans-unit>
        <trans-unit id="82321dd8f607145fb8d2875c3e367d82d45dfc71" translate="yes" xml:space="preserve">
          <source>Value with which negative labels must be encoded.</source>
          <target state="translated">Значение,с которым должны быть закодированы отрицательные метки.</target>
        </trans-unit>
        <trans-unit id="4e0758fceaa4f106e89501aa7c196eea7d1ad1c2" translate="yes" xml:space="preserve">
          <source>Value with which positive labels must be encoded.</source>
          <target state="translated">Значение,с которым должны быть закодированы положительные метки.</target>
        </trans-unit>
        <trans-unit id="6a7ed2e67e56dace630120ac5c7bd01e4d032523" translate="yes" xml:space="preserve">
          <source>Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0. With the default threshold of 0, only positive values map to 1.</source>
          <target state="translated">Значения больше карты порога до 1,а значения меньше или равны карте порога до 0.При пороге по умолчанию 0,только положительные значения карты до 1.</target>
        </trans-unit>
        <trans-unit id="0a659f48fb09b2c2dd949774cc3bd6b7ffd6fd87" translate="yes" xml:space="preserve">
          <source>Values in each bin have the same nearest center of a 1D k-means cluster.</source>
          <target state="translated">Значения в каждом мусорном контейнере имеют один и тот же ближайший центр кластера 1D к-средних.</target>
        </trans-unit>
        <trans-unit id="c67d763b94a97115ba7ee9d49115a272cb508cf6" translate="yes" xml:space="preserve">
          <source>Values of n_samples samples drawn from Gaussian process and evaluated at query points.</source>
          <target state="translated">Значения образцов n_samples,взятых из Гауссовского процесса и вычисленных в точках запроса.</target>
        </trans-unit>
        <trans-unit id="1cd1b62dfd3b6a63572d1bf631789bd088451d1d" translate="yes" xml:space="preserve">
          <source>Values of the visible layer after one Gibbs step.</source>
          <target state="translated">Значения видимого слоя после одного шага Гиббса.</target>
        </trans-unit>
        <trans-unit id="c9500aef779ad4ab4355590ca05b9c0de0aa083a" translate="yes" xml:space="preserve">
          <source>Values of the visible layer to start from.</source>
          <target state="translated">Значения видимого слоя для начала.</target>
        </trans-unit>
        <trans-unit id="d9ca5115511a5b00d878e1de5b9daa8f530b632c" translate="yes" xml:space="preserve">
          <source>Values of the visible layer. Must be all-boolean (not checked).</source>
          <target state="translated">Значения видимого слоя.Должно быть,все булевые (не проверено).</target>
        </trans-unit>
        <trans-unit id="445d09e482944669dc8a6e893591f45bda28254b" translate="yes" xml:space="preserve">
          <source>Vanschoren, van Rijn, Bischl and Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;OpenML: networked science in machine learning&amp;rdquo;&lt;/a&gt;, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014.</source>
          <target state="translated">Ваншорен, ван Рейн, Бишл и Торго &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;laquo;OpenML: сетевая наука в машинном обучении&amp;raquo;&lt;/a&gt; , ACM SIGKDD Explorations Newsletter, 15 (2), 49-60, 2014.</target>
        </trans-unit>
        <trans-unit id="ba47c39bbafea14cc75438e6420272a547d1a3e3" translate="yes" xml:space="preserve">
          <source>Variance explained by each of the selected components.</source>
          <target state="translated">Различия объясняются каждым из выбранных компонентов.</target>
        </trans-unit>
        <trans-unit id="17b5cb397e6ad9830d59b5fc66bebb45024c7ef4" translate="yes" xml:space="preserve">
          <source>Variances of individual features.</source>
          <target state="translated">Варианты индивидуальных особенностей.</target>
        </trans-unit>
        <trans-unit id="7933f72bf76c6cfbc1dde87498522f5e833878e6" translate="yes" xml:space="preserve">
          <source>Variational Bayesian estimation of a Gaussian mixture.</source>
          <target state="translated">Вариационная байесовская оценка гауссовской смеси.</target>
        </trans-unit>
        <trans-unit id="e459652719d6e0edf38bb3c9f14dba040888c62f" translate="yes" xml:space="preserve">
          <source>Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.</source>
          <target state="translated">Вариационный вывод является продолжением матожидания-максимизации,максимизирующим нижний предел на модельных доказательствах (включая приоры)вместо вероятности данных.Принцип,лежащий в основе вариационных методов,тот же,что и в случае с матожиданием-максимизацией (т.е.итерационные алгоритмы,которые чередуются между поиском вероятностей для каждой точки,генерируемой каждой смесью,и подгонкой смеси под эти заданные точки),но вариационные методы добавляют регуляризацию,интегрируя информацию из предыдущих распределений.Это позволяет избежать сингулярностей,часто встречающихся в решениях по матожиданию-максимизации,но привносит в модель некоторые тонкие смещения.Выводы часто бывают заметно медленнее,но,как правило,не настолько,чтобы сделать использование непрактичным.</target>
        </trans-unit>
        <trans-unit id="009e019794c4b5a288d65b8e0eabe9064e298c81" translate="yes" xml:space="preserve">
          <source>Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the &amp;ldquo;true&amp;rdquo; number of components, affects only algorithmic complexity, not the actual number of components used).</source>
          <target state="translated">Методы вариационного вывода для процесса Дирихле по-прежнему работают с конечным приближением к этой модели бесконечной смеси, но вместо того, чтобы заранее указывать, сколько компонентов нужно использовать, нужно просто указать параметр концентрации и верхнюю границу количества смеси. компонентов (эта верхняя граница, если предполагается, что она превышает &amp;laquo;истинное&amp;raquo; количество компонентов, влияет только на алгоритмическую сложность, а не на фактическое количество используемых компонентов).</target>
        </trans-unit>
        <trans-unit id="bfc42eb1bb86ce5f62b086e9ffd3c67a080b0730" translate="yes" xml:space="preserve">
          <source>Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, &lt;code&gt;components_[i, j]&lt;/code&gt; can be viewed as pseudocount that represents the number of times word &lt;code&gt;j&lt;/code&gt; was assigned to topic &lt;code&gt;i&lt;/code&gt;. It can also be viewed as distribution over the words for each topic after normalization: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt;.</source>
          <target state="translated">Вариационные параметры распределения тематических слов. Поскольку полное условие для распределения тематических слов - это Дирихле, &lt;code&gt;components_[i, j]&lt;/code&gt; можно рассматривать как псевдосчет, который представляет количество раз, когда слово &lt;code&gt;j&lt;/code&gt; было присвоено теме &lt;code&gt;i&lt;/code&gt; . Его также можно рассматривать как распределение по словам для каждой темы после нормализации: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65cb8d21f19957f8f56d7ec3aeccadf0c1efbc6f" translate="yes" xml:space="preserve">
          <source>Various Agglomerative Clustering on a 2D embedding of digits</source>
          <target state="translated">Различная агломеративная кластеризация на 2D-встраивании цифр</target>
        </trans-unit>
        <trans-unit id="b1e276370580ceeca94d9a25d3b75abf89a69938" translate="yes" xml:space="preserve">
          <source>Varying regularization in Multi-layer Perceptron</source>
          <target state="translated">Варьирующаяся регуляризация в многослойном Perceptron</target>
        </trans-unit>
        <trans-unit id="1e178759402bc070ae202c1ae1b1666da0dd6a9c" translate="yes" xml:space="preserve">
          <source>Vector Quantization Example</source>
          <target state="translated">Пример векторного квантования</target>
        </trans-unit>
        <trans-unit id="ba8b3829eecac2c5ad85a64a161b0e7f2fae54cf" translate="yes" xml:space="preserve">
          <source>Vector of errors at each iteration.</source>
          <target state="translated">Вектор ошибок на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="93c6f0903309fd539ceb7d4710cf07f7db8cb1d8" translate="yes" xml:space="preserve">
          <source>Verbose mode when fitting the model.</source>
          <target state="translated">Вербозный режим при установке модели.</target>
        </trans-unit>
        <trans-unit id="eeb343db47ab9124ef417c41d9bdb92839772dc0" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations. Defaults to 0.</source>
          <target state="translated">Обратный вывод во время вычислений PD.По умолчанию 0.</target>
        </trans-unit>
        <trans-unit id="65d3f9d357c8217e4b4161cc31c9983e755e9511" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated.</source>
          <target state="translated">Флаг Verbosity,управляет отладочными сообщениями,которые выдаются как функции оцениваются.</target>
        </trans-unit>
        <trans-unit id="a606460a9db19f2456900341e545d542d386dcd0" translate="yes" xml:space="preserve">
          <source>Verbosity level.</source>
          <target state="translated">Уровень вербозности.</target>
        </trans-unit>
        <trans-unit id="9cadb350a887ea26b759cec53fba259b94be0b70" translate="yes" xml:space="preserve">
          <source>Verbosity level. Setting verbose &amp;gt; 0 will display additional information depending on the solver used.</source>
          <target state="translated">Уровень детализации. Установка подробного&amp;gt; 0 отобразит дополнительную информацию в зависимости от используемого решателя.</target>
        </trans-unit>
        <trans-unit id="c09635f4883cd7798a06597eead68509e08bef52" translate="yes" xml:space="preserve">
          <source>Verbosity mode.</source>
          <target state="translated">Режим вербозности.</target>
        </trans-unit>
        <trans-unit id="4ee9c427e0cc678ca91bc7294708dc43db03512b" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#gp-kernels&quot;&gt;kernels&lt;/a&gt; can be specified. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Универсальность: можно указать разные &lt;a href=&quot;#gp-kernels&quot;&gt;ядра&lt;/a&gt; . Предоставляются общие ядра, но также можно указать собственные ядра.</target>
        </trans-unit>
        <trans-unit id="4b16fac84e3102257e26d97dc6bcc2775a76c275" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Универсальность: для функции принятия решения могут быть указаны различные &lt;a href=&quot;#svm-kernels&quot;&gt;функции ядра&lt;/a&gt; . Предоставляются общие ядра, но также можно указать собственные ядра.</target>
        </trans-unit>
        <trans-unit id="102caab3d934ebf62d9240e41edbdfb96ec830ff" translate="yes" xml:space="preserve">
          <source>Version of the dataset. Can only be provided if also &lt;code&gt;name&lt;/code&gt; is given. If &amp;lsquo;active&amp;rsquo; the oldest version that&amp;rsquo;s still active is used. Since there may be more than one active version of a dataset, and those versions may fundamentally be different from one another, setting an exact version is highly recommended.</source>
          <target state="translated">Версия набора данных. Может быть предоставлено, только если также указано &lt;code&gt;name&lt;/code&gt; . Если активна, то используется самая старая версия, которая все еще активна. Поскольку может быть несколько активных версий набора данных, и эти версии могут существенно отличаться друг от друга, настоятельно рекомендуется установить точную версию.</target>
        </trans-unit>
        <trans-unit id="2d0ab9e3d9a896817cdfc684c77fbf9f0c4f1aac" translate="yes" xml:space="preserve">
          <source>Version: RCV1-v2, vectors, full sets, topics multilabels.</source>
          <target state="translated">Версия:RCV1-v2,векторы,полные наборы,темы многомаркировки.</target>
        </trans-unit>
        <trans-unit id="3496b8ff284f2499d5b89bafe815a9579d5a779b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Очень большие &lt;code&gt;n_samples&lt;/code&gt; , средние &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90edfe52a065a045edbdd25bf2f2316a234658ac" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch code&lt;/a&gt;</source>
          <target state="translated">Очень большие &lt;code&gt;n_samples&lt;/code&gt; , средние &lt;code&gt;n_clusters&lt;/code&gt; с &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;кодом MiniBatch&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56b71e89fb1079caaadefd0889e9a22e8b0560e3" translate="yes" xml:space="preserve">
          <source>Videos</source>
          <target state="translated">Videos</target>
        </trans-unit>
        <trans-unit id="f74a22805e87ed187a5bf75da0c74d88f9fc4e05" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh et al. (2010) назвали варианты NMI и AMI методом их усреднения [VEB2010]. Их средние &quot;sqrt&quot; и &quot;sum&quot; являются средними геометрическими и арифметическими; мы используем эти более общие имена.</target>
        </trans-unit>
        <trans-unit id="40fdfddfc4699e8e891d021e6ce4e4252243f9c7" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR</source>
          <target state="translated">Винь,Эппс и Бейли,(2010).Информационно-теоретические меры для сравнения кластеров:Варианты,Свойства,Нормализация и коррекция для шансов,JMLR</target>
        </trans-unit>
        <trans-unit id="64eeb8915eff8290b0627c8aa96dd46ee4bda6f1" translate="yes" xml:space="preserve">
          <source>Visualise your tree as you are training by using the &lt;code&gt;export&lt;/code&gt; function. Use &lt;code&gt;max_depth=3&lt;/code&gt; as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.</source>
          <target state="translated">Визуализируйте свое дерево во время обучения с помощью функции &lt;code&gt;export&lt;/code&gt; . Используйте &lt;code&gt;max_depth=3&lt;/code&gt; в качестве начальной глубины дерева, чтобы понять, насколько дерево соответствует вашим данным, а затем увеличьте глубину.</target>
        </trans-unit>
        <trans-unit id="d175985b87dd9f620aa960059c730b4a35e3bcb5" translate="yes" xml:space="preserve">
          <source>Visualization</source>
          <target state="translated">Visualization</target>
        </trans-unit>
        <trans-unit id="38623835e09f3cd243cdf966707dad9de4ecfeda" translate="yes" xml:space="preserve">
          <source>Visualization of MLP weights on MNIST</source>
          <target state="translated">Визуализация весов MLP на MNIST</target>
        </trans-unit>
        <trans-unit id="a291ff40a157c9afd67fb01fd3c6b6d368d78978" translate="yes" xml:space="preserve">
          <source>Visualization of predictions obtained from different models.</source>
          <target state="translated">Визуализация прогнозов,полученных из различных моделей.</target>
        </trans-unit>
        <trans-unit id="a6c65fa336dc53edc04e670583358fb288a99997" translate="yes" xml:space="preserve">
          <source>Visualize cross-validation indices for many CV objects</source>
          <target state="translated">Визуализируйте перекрестные проверочные индексы для многих объектов CV</target>
        </trans-unit>
        <trans-unit id="4a2bddc914855cb9100c33fc5e346e89e1926136" translate="yes" xml:space="preserve">
          <source>Visualize our data</source>
          <target state="translated">Визуализируйте наши данные</target>
        </trans-unit>
        <trans-unit id="28ba2de8813583360eb0588f62cb6dc19a1f4072" translate="yes" xml:space="preserve">
          <source>Visualize the resulting regions</source>
          <target state="translated">Визуализируйте результирующие регионы</target>
        </trans-unit>
        <trans-unit id="b77da1f257213eacf5971ec98d2f34c8fe910374" translate="yes" xml:space="preserve">
          <source>Visualizing cross-validation behavior in scikit-learn</source>
          <target state="translated">Визуализация перекрёстно-проверочного поведения в наукографе.</target>
        </trans-unit>
        <trans-unit id="e6614e53d3137ea4329f7b88a52f014060c402bb" translate="yes" xml:space="preserve">
          <source>Visualizing the stock market structure</source>
          <target state="translated">Визуализация структуры фондового рынка</target>
        </trans-unit>
        <trans-unit id="3e1e0ef10e7a115946f530e934380438421c5b34" translate="yes" xml:space="preserve">
          <source>Vocabulary: classification and regression</source>
          <target state="translated">Словарь:классификация и регрессия</target>
        </trans-unit>
        <trans-unit id="dd7b37acd93acaf11b82a9ebbc3eea819b85e0ef" translate="yes" xml:space="preserve">
          <source>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.</source>
          <target state="translated">У.Х.Вольберг,У.Н.Стрит и О.Л.Мангасарян.Машинное обучение методам диагностики рака молочной железы от аспиратов с тонкой иголкой.Раковые письма 77 (1994)163-171.</target>
        </trans-unit>
        <trans-unit id="985d7c09beb3a8622b6c063b009de9296fdb89ed" translate="yes" xml:space="preserve">
          <source>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</source>
          <target state="translated">WN Street, WH Wolberg и OL Mangasarian. Извлечение ядерных признаков для диагностики опухолей молочной железы. IS &amp;amp; T / SPIE 1993 Международный симпозиум по электронной визуализации: наука и технология, том 1905, страницы 861-870, Сан-Хосе, Калифорния, 1993.</target>
        </trans-unit>
        <trans-unit id="0525374f4c7331dc5d256feba32a265d327160ed" translate="yes" xml:space="preserve">
          <source>WDBC-Benign</source>
          <target state="translated">WDBC-Benign</target>
        </trans-unit>
        <trans-unit id="fd630df285b07b6076d3b38d88445f6031d3902e" translate="yes" xml:space="preserve">
          <source>WDBC-Malignant</source>
          <target state="translated">WDBC-Malignant</target>
        </trans-unit>
        <trans-unit id="9b852a8108b3e892136da9e7da9f0a5bb56540ea" translate="yes" xml:space="preserve">
          <source>WMinkowskiDistance</source>
          <target state="translated">WMinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="4e8ee595c7db5dd5f284f8fb603cc66c6c8287ae" translate="yes" xml:space="preserve">
          <source>Ward clustering based on a Feature matrix.</source>
          <target state="translated">Кластеризация палат на основе матрицы функций.</target>
        </trans-unit>
        <trans-unit id="1af684513cf70467c9307765e01677f8970cff6e" translate="yes" xml:space="preserve">
          <source>Ward hierarchical clustering</source>
          <target state="translated">Иерархическая кластеризация палат</target>
        </trans-unit>
        <trans-unit id="d2173ac976f5809b703436c0de33dab1598b674c" translate="yes" xml:space="preserve">
          <source>Ward is the most effective method for noisy data.</source>
          <target state="translated">Уорд является наиболее эффективным методом для шумных данных.</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="44d79cfceaac3d6c963709a9f443a7578dfdd3fa" translate="yes" xml:space="preserve">
          <source>Warning class used if there is an error while fitting the estimator.</source>
          <target state="translated">Класс предупреждения,используемый в случае ошибки при установке оценочного устройства.</target>
        </trans-unit>
        <trans-unit id="c56f46b7e83e71f0bcaf54dacd8cfc15c71ef274" translate="yes" xml:space="preserve">
          <source>Warning class used to notify the user of any change in the behavior.</source>
          <target state="translated">Предупреждающий класс,используемый для оповещения пользователя о любых изменениях в поведении.</target>
        </trans-unit>
        <trans-unit id="43a2ad1c4144ef567b3006486da55db4df5bcce7" translate="yes" xml:space="preserve">
          <source>Warning used to notify implicit data conversions happening in the code.</source>
          <target state="translated">Предупреждение,используемое для уведомления о неявном преобразовании данных,происходящем в коде.</target>
        </trans-unit>
        <trans-unit id="69bb37448a64e3ca58327c210b042b57b19259a7" translate="yes" xml:space="preserve">
          <source>Warning used to notify the user of inefficient computation.</source>
          <target state="translated">Предупреждение,используемое для уведомления пользователя о неэффективности вычислений.</target>
        </trans-unit>
        <trans-unit id="95fde5bcc048210bdd2da0e9628c10dadee1ce1e" translate="yes" xml:space="preserve">
          <source>Warning used when the dot operation does not use BLAS.</source>
          <target state="translated">Предупреждение,используемое,когда точка операция не использует BLAS.</target>
        </trans-unit>
        <trans-unit id="77d4a9d6a0a46436c153d66828a62d378a7e1f5d" translate="yes" xml:space="preserve">
          <source>Warning used when the metric is invalid</source>
          <target state="translated">Предупреждение,используемое,когда метрика недействительна</target>
        </trans-unit>
        <trans-unit id="d0aaba5d13d0d7235d440530a46ccfa6343b56ff" translate="yes" xml:space="preserve">
          <source>Warning: Extra-trees should only be used within ensemble methods.</source>
          <target state="translated">Внимание:Дополнительные деревья должны использоваться только в ансамблевых методах.</target>
        </trans-unit>
        <trans-unit id="c2eb6fdf9d13ab34884681ef0c66f41e16b52aad" translate="yes" xml:space="preserve">
          <source>Warning: this function is experimental and subject to change in a future version of joblib.</source>
          <target state="translated">Предупреждение:эта функция является экспериментальной и может быть изменена в будущей версии joblib.</target>
        </trans-unit>
        <trans-unit id="b33d3bb4e4bfe5e80c2407f4ead429c7fa466ef0" translate="yes" xml:space="preserve">
          <source>We achieved 83.5% accuracy. Let&amp;rsquo;s see if we can do better with a linear &lt;a href=&quot;../../modules/svm#svm&quot;&gt;support vector machine (SVM)&lt;/a&gt;, which is widely regarded as one of the best text classification algorithms (although it&amp;rsquo;s also a bit slower than na&amp;iuml;ve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:</source>
          <target state="translated">Мы достигли точности 83,5%. Посмотрим, сможем ли мы добиться большего успеха с помощью линейной &lt;a href=&quot;../../modules/svm#svm&quot;&gt;машины опорных векторов (SVM)&lt;/a&gt; , которая широко считается одним из лучших алгоритмов классификации текста (хотя она также немного медленнее, чем наивный байесовский алгоритм). Мы можем изменить учащегося, просто подключив другой объект классификатора к нашему конвейеру:</target>
        </trans-unit>
        <trans-unit id="5e4234559a6f8eb7829d45ed1528d4d2b014e858" translate="yes" xml:space="preserve">
          <source>We achieved 91.3% accuracy using the SVM. &lt;code&gt;scikit-learn&lt;/code&gt; provides further utilities for more detailed performance analysis of the results:</source>
          <target state="translated">Мы достигли точности 91,3% с помощью SVM. &lt;code&gt;scikit-learn&lt;/code&gt; предоставляет дополнительные утилиты для более подробного анализа результатов:</target>
        </trans-unit>
        <trans-unit id="4073bf855ec3741a8d17116f66549a3127ee1b52" translate="yes" xml:space="preserve">
          <source>We add observation noise to these waveforms. We generate very sparse noise: only 6% of the time points contain noise. As a result, the l1 norm of this noise (ie &amp;ldquo;cityblock&amp;rdquo; distance) is much smaller than it&amp;rsquo;s l2 norm (&amp;ldquo;euclidean&amp;rdquo; distance). This can be seen on the inter-class distance matrices: the values on the diagonal, that characterize the spread of the class, are much bigger for the Euclidean distance than for the cityblock distance.</source>
          <target state="translated">Мы добавляем к этим сигналам шум наблюдения. Мы генерируем очень разреженный шум: только 6% временных точек содержат шум. В результате норма этого шума l1 (то есть расстояние &amp;laquo;городской квартал&amp;raquo;) намного меньше его нормы l2 (&amp;laquo;евклидово&amp;raquo; расстояние). Это можно увидеть на матрицах межклассовых расстояний: значения на диагонали, которые характеризуют разброс класса, намного больше для евклидова расстояния, чем для расстояния между кварталами города.</target>
        </trans-unit>
        <trans-unit id="5fc281c3e8b120a8bce90f392d5367731bdfa8e6" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for ARD for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">Мы также построим прогнозы и неопределенности для ARD для одномерной регрессии,используя расширение полиномиальных признаков.Обратите внимание,что неопределенности начинают расти в правой части графика.Это связано с тем,что эти тестовые образцы находятся за пределами диапазона тренировочных образцов.</target>
        </trans-unit>
        <trans-unit id="bda5a1ba58eab4f9acd36ef763104051f247918e" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for Bayesian Ridge Regression for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">Мы также построим прогнозы и неопределенности для Байесовской хребтовой регрессии для одномерной регрессии с использованием разложения полиномиальных признаков.Обратите внимание,что неопределенности начинают расти в правой части графика.Это связано с тем,что эти тестовые образцы находятся за пределами диапазона тренировочных образцов.</target>
        </trans-unit>
        <trans-unit id="b29f4bff482ccd99c1af96e146d78b516ea318aa" translate="yes" xml:space="preserve">
          <source>We also use warm_start=True which means that the coefficients of the models are reused to initialize the next model fit to speed-up the computation of the full-path.</source>
          <target state="translated">Мы также используем параметр warm_start=True,что означает,что коэффициенты моделей используются повторно для инициализации подгонки следующей модели,чтобы ускорить вычисление полного пути.</target>
        </trans-unit>
        <trans-unit id="0f24896ee5efd7713cddd30b90821fa31665d4c0" translate="yes" xml:space="preserve">
          <source>We assume that the observations are independent and identically distributed (i.i.d.).</source>
          <target state="translated">Мы предполагаем,что наблюдения независимы и одинаково распределены (i.i.d.).</target>
        </trans-unit>
        <trans-unit id="b19a456f973e90e2b4e21cdba9f00b15173fd0ef" translate="yes" xml:space="preserve">
          <source>We call &lt;strong&gt;vectorization&lt;/strong&gt; the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the &lt;strong&gt;Bag of Words&lt;/strong&gt; or &amp;ldquo;Bag of n-grams&amp;rdquo; representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</source>
          <target state="translated">Мы называем &lt;strong&gt;векторизацией&lt;/strong&gt; общий процесс превращения набора текстовых документов в числовые векторы признаков. Эта конкретная стратегия (токенизация, подсчет и нормализация) называется представлением &amp;laquo; &lt;strong&gt;Мешок слов&amp;raquo;&lt;/strong&gt; или &amp;laquo;Мешок н-грамм&amp;raquo;. Документы описываются по вхождению слов при полном игнорировании информации об относительном положении слов в документе.</target>
        </trans-unit>
        <trans-unit id="096029ae48dbb08bf7baa8066a510ed0e5cf55ab" translate="yes" xml:space="preserve">
          <source>We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.</source>
          <target state="translated">Мы также можем предсказать на основе неподготовленной модели,используя GP prior.В дополнение к среднему значению предсказывающего распределения,также можно предсказать его стандартное отклонение (return_std=True)или ковариацию (return_cov=True).Обратите внимание,что в большинстве случаев может быть запрошено одно из этих двух.</target>
        </trans-unit>
        <trans-unit id="7f60df7f123136fa11f4ddf222fab31a6a72d17d" translate="yes" xml:space="preserve">
          <source>We can choose &lt;code&gt;alpha&lt;/code&gt; to minimize left out error, this time using the diabetes dataset rather than our synthetic data:</source>
          <target state="translated">Мы можем выбрать &lt;code&gt;alpha&lt;/code&gt; чтобы минимизировать пропущенную ошибку, на этот раз используя набор данных о диабете, а не наши синтетические данные:</target>
        </trans-unit>
        <trans-unit id="469d4e6eabf44c56eec1620cbb6087744c30d3f6" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the avg. occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">Мы ясно видим,что медианная цена дома показывает линейную связь с медианным доходом (вверху слева),и что цена дома падает,когда авг.человек на домохозяйство увеличивается (вверху посередине).Верхний правый участок показывает,что возраст дома в районе не оказывает сильного влияния на цену дома (медиана);так же как и средние комнаты на домохозяйство.Галочки на оси x представляют собой децили значений характеристик в данных обучения.</target>
        </trans-unit>
        <trans-unit id="c32b4a200d58f731852c3f4a8eefb32ef18f31ed" translate="yes" xml:space="preserve">
          <source>We can keep the remaining rating columns by setting &lt;code&gt;remainder='passthrough'&lt;/code&gt;. The values are appended to the end of the transformation:</source>
          <target state="translated">Мы можем сохранить оставшиеся столбцы рейтинга, установив &lt;code&gt;remainder='passthrough'&lt;/code&gt; . Значения добавляются в конец преобразования:</target>
        </trans-unit>
        <trans-unit id="a59ff6e4288992e31a9513b51da5a036927e8ec8" translate="yes" xml:space="preserve">
          <source>We can now load the list of files matching those categories as follows:</source>
          <target state="translated">Теперь мы можем загрузить список файлов,соответствующих этим категориям следующим образом:</target>
        </trans-unit>
        <trans-unit id="f1f864cfbdff004081b5667459fd9c49d8fcf703" translate="yes" xml:space="preserve">
          <source>We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:</source>
          <target state="translated">Теперь мы можем быстро отбирать набор для обучения,при этом удерживая 40% данных для тестирования (оценки)нашего классификатора:</target>
        </trans-unit>
        <trans-unit id="850dcea5aea59348ecbdc161cc86fe56ad9b64b5" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">Мы можем уменьшить размерность еще больше до выбранного \ (L \), проецируя на линейное подпространство \ (H_L \), которое максимизирует дисперсию \ (\ mu ^ * _ k \) после проецирования (фактически, мы делают форму PCA для преобразованных средств класса \ (\ mu ^ * _ k \)). Этот \ (L \) соответствует параметру &lt;code&gt;n_components&lt;/code&gt; , используемому в методе &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt; . См. &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="bee45302ee9842b9e6d2e72404b6369d8b7e97cc" translate="yes" xml:space="preserve">
          <source>We can see that for low values of &lt;code&gt;n_components&lt;/code&gt; the distribution is wide with many distorted pairs and a skewed distribution (due to the hard limit of zero ratio on the left as distances are always positives) while for larger values of n_components the distortion is controlled and the distances are well preserved by the random projection.</source>
          <target state="translated">Мы можем видеть, что для низких значений &lt;code&gt;n_components&lt;/code&gt; распределение широкое с большим количеством искаженных пар и перекосом (из-за жесткого ограничения нулевого отношения слева, поскольку расстояния всегда положительны), в то время как для больших значений n_components искажение контролируется и расстояния хорошо сохраняются случайной проекцией.</target>
        </trans-unit>
        <trans-unit id="d51b2a4e76fb7eb99807202c5234812c15585e4c" translate="yes" xml:space="preserve">
          <source>We can see that if the maximum depth of the tree (controlled by the &lt;code&gt;max_depth&lt;/code&gt; parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.</source>
          <target state="translated">Мы можем видеть, что если максимальная глубина дерева (управляемая параметром &lt;code&gt;max_depth&lt;/code&gt; ) установлена ​​слишком высокой, деревья решений узнают слишком мелкие детали обучающих данных и учатся на шуме, то есть они переоснащаются.</target>
        </trans-unit>
        <trans-unit id="5bc27bfd8c709ab5505734b2124db3dbd09e7af4" translate="yes" xml:space="preserve">
          <source>We can see that, although feature 2 has a strong coefficient on the full model, it conveys little information on &lt;code&gt;y&lt;/code&gt; when considered with feature 1.</source>
          <target state="translated">Мы можем видеть, что, хотя характеристика 2 имеет сильный коэффициент для полной модели, она дает мало информации о &lt;code&gt;y&lt;/code&gt; при рассмотрении с функцией 1.</target>
        </trans-unit>
        <trans-unit id="208e5f1f40787dd5dcd62a253128bd90d5a3414b" translate="yes" xml:space="preserve">
          <source>We can turn those concept as scores &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt;. Both are bounded below by 0.0 and above by 1.0 (higher is better):</source>
          <target state="translated">Мы можем преобразовать эти концепции в оценки &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; . Оба ограничены снизу 0,0 и выше 1,0 (чем выше, тем лучше):</target>
        </trans-unit>
        <trans-unit id="592289b1a6fdac7a6256bbd4a62b88701d16e505" translate="yes" xml:space="preserve">
          <source>We can use the function &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt;&lt;code&gt;learning_curve&lt;/code&gt;&lt;/a&gt; to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):</source>
          <target state="translated">Мы можем использовать функцию &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt; &lt;code&gt;learning_curve&lt;/code&gt; &lt;/a&gt; для генерации значений, необходимых для построения такой кривой обучения (количество использованных образцов, средние баллы на обучающих наборах и средние баллы на проверочных наборах):</target>
        </trans-unit>
        <trans-unit id="3c55a99ecafce9d11edefa5f7981438b525c546b" translate="yes" xml:space="preserve">
          <source>We classify 8x8 images of digits into two classes: 0-4 against 5-9. The visualization shows coefficients of the models for varying C.</source>
          <target state="translated">Мы классифицируем 8х8 изображений цифр на два класса:0-4 против 5-9.Визуализация показывает коэффициенты моделей для различных C.</target>
        </trans-unit>
        <trans-unit id="4c2ceff57e3b51d317fe78664f4ea8312ed35966" translate="yes" xml:space="preserve">
          <source>We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the target depends on them as follows:</source>
          <target state="translated">Рассмотрим 3 особенности x_1,x_2,x_3,равномерно распределенных по [0,1],от них зависит цель:</target>
        </trans-unit>
        <trans-unit id="8b738423194ebf355d81c34c5848e446f6f25c86" translate="yes" xml:space="preserve">
          <source>We create a multi-label dataset, to illustrate the precision-recall in multi-label settings</source>
          <target state="translated">Мы создаем набор данных для нескольких этикеток,чтобы проиллюстрировать точность вызова в настройках нескольких этикеток.</target>
        </trans-unit>
        <trans-unit id="7df3a30efca0a13e3a362147c9be1fa02a3e02fd" translate="yes" xml:space="preserve">
          <source>We don&amp;rsquo;t allow:</source>
          <target state="translated">Мы не разрешаем:</target>
        </trans-unit>
        <trans-unit id="c17cba12ad6e5c2f931d1de0fcadd712e7bb0a0a" translate="yes" xml:space="preserve">
          <source>We first find the separating plane with a plain SVC and then plot (dashed) the separating hyperplane with automatically correction for unbalanced classes.</source>
          <target state="translated">Сначала мы находим разделительную плоскость с простым SVC,а затем рисуем (пунктиром)разделительную гиперплоскость с автоматической коррекцией для несбалансированных классов.</target>
        </trans-unit>
        <trans-unit id="916afde7457af1caed530318ff87e1a7a139918e" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">Мы обнаружили, что &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; дает сопоставимые результаты с &lt;code&gt;max_depth=k-1&lt;/code&gt; , но обучение проходит значительно быстрее за счет немного большей ошибки обучения. Параметр &lt;code&gt;max_leaf_nodes&lt;/code&gt; соответствует переменной &lt;code&gt;J&lt;/code&gt; в главе о повышении градиента в &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; и связан с параметром &lt;code&gt;interaction.depth&lt;/code&gt; в пакете R gbm, где &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="72f7189dc223c470430f67b7332d9ced78363339" translate="yes" xml:space="preserve">
          <source>We found that Averaged SGD works best with a larger number of features and a higher eta0</source>
          <target state="translated">Мы обнаружили,что Averaged SGD лучше всего работает с большим количеством функций и более высоким показателем eta0.</target>
        </trans-unit>
        <trans-unit id="ecc641e4f0c3be544f8ba1b6978d12b64c778e22" translate="yes" xml:space="preserve">
          <source>We generate data from three groups of waveforms. Two of the waveforms (waveform 1 and waveform 2) are proportional one to the other. The cosine distance is invariant to a scaling of the data, as a result, it cannot distinguish these two waveforms. Thus even with no noise, clustering using this distance will not separate out waveform 1 and 2.</source>
          <target state="translated">Мы генерируем данные из трех групп волновых форм.Две формы волны (форма волны 1 и форма волны 2)пропорциональны друг другу.Косинусное расстояние инвариантно масштабированию данных,в результате,оно не может различать эти две формы волн.Таким образом,даже при отсутствии шума кластеризация с использованием этого расстояния не сможет отделить кривые 1 и 2.</target>
        </trans-unit>
        <trans-unit id="03835cacd7901d07f747c14f209b80543758c4fd" translate="yes" xml:space="preserve">
          <source>We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators:</source>
          <target state="translated">Мы видели,что некоторые оценщики могут преобразовывать данные,а некоторые-предсказывать переменные.Мы также можем создавать комбинированные оценки:</target>
        </trans-unit>
        <trans-unit id="996013b3c282443801da622c65fee1deca3cef01" translate="yes" xml:space="preserve">
          <source>We have seen that sparsity could be used to mitigate the curse of dimensionality, &lt;em&gt;i.e&lt;/em&gt; an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: &lt;strong&gt;feature agglomeration&lt;/strong&gt;. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data.</source>
          <target state="translated">Мы видели, что разреженность может быть использована для смягчения проклятия размерности, &lt;em&gt;то&lt;/em&gt; есть недостаточного количества наблюдений по сравнению с количеством функций. Другой подход - объединить похожие функции: &lt;strong&gt;агломерация признаков&lt;/strong&gt; . Этот подход может быть реализован путем кластеризации в направлении признаков, другими словами кластеризации транспонированных данных.</target>
        </trans-unit>
        <trans-unit id="f70b46435230cf70b0b3d749ceef620b9bcdee9d" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">Мы специально воздержались от оптимизации, используемой авторами обеих статей, QR-разложения, используемого в определенных ситуациях для уменьшения алгоритмической сложности SVD. Источник для этой техники - &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt; . Этот метод был опущен, потому что он &lt;code&gt;n_samples&lt;/code&gt; только при разложении матрицы с n_samples (строки)&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; (столбцы) и ухудшает читабельность реализованного алгоритма. Это будет хорошей возможностью для будущей оптимизации, если она будет сочтена необходимой.</target>
        </trans-unit>
        <trans-unit id="db298eced453f06f8efed43be73a03415c98ca01" translate="yes" xml:space="preserve">
          <source>We have to reconstruct model and parameters to make sure we stay in sync with the python object.</source>
          <target state="translated">Мы должны реконструировать модель и параметры,чтобы убедиться,что мы синхронизированы с объектом питона.</target>
        </trans-unit>
        <trans-unit id="f2683785e1f3e3ccb40d3941fed7d5fa67a33cfc" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) which controls the number of support vectors and training errors. The parameter \(\nu \in (0, 1]\) is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</source>
          <target state="translated">Мы вводим новый параметр \(\nu\),который контролирует количество векторов поддержки и ошибок обучения.Параметр \(\nu \in (0,1]\)-это верхняя граница доли обучающих ошибок и нижняя граница доли поддерживающих векторов.</target>
        </trans-unit>
        <trans-unit id="284f00654c2880797bacd24e85e3bc2f5ec8be8d" translate="yes" xml:space="preserve">
          <source>We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.</source>
          <target state="translated">Мы больше не получаем столкновений,но это происходит за счет гораздо большей размерности выходного пространства.Конечно,другие термины,кроме 19,используемые здесь,все еще могут сталкиваться друг с другом.</target>
        </trans-unit>
        <trans-unit id="0e7a6d4d2e128e719f76bf1799c4515162612bfb" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the preplexity value increases.</source>
          <target state="translated">Мы наблюдаем тенденцию к более четким формам по мере увеличения значения докомплексности.</target>
        </trans-unit>
        <trans-unit id="b4e7d2188aa62b346706f6bd2a1ae94095756883" translate="yes" xml:space="preserve">
          <source>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</source>
          <target state="translated">Мы строим предсказанные метки как на тренинге,так и на тестовых данных,используя различные ковариационные типы GMM на наборе данных по радужной оболочке глаза.Мы сравниваем GMM со сферическими,диагональными,полными и связанными ковариационными матрицами в порядке возрастания производительности.Хотя можно было бы ожидать,что полная ковариация будет работать лучше всего в целом,она склонна к переподгонке на небольших наборах данных и не обобщает хорошо проведенных тестовых данных.</target>
        </trans-unit>
        <trans-unit id="8a444360e57dc0870f14b3c959a7b626922e7571" translate="yes" xml:space="preserve">
          <source>We see that &lt;code&gt;SVC&lt;/code&gt; doesn&amp;rsquo;t do much better than a dummy classifier. Now, let&amp;rsquo;s change the kernel:</source>
          <target state="translated">Мы видим, что &lt;code&gt;SVC&lt;/code&gt; не намного лучше, чем фиктивный классификатор. Теперь изменим ядро:</target>
        </trans-unit>
        <trans-unit id="9619f66671fbeb88bbee2c1b3d850c22bdb6ab25" translate="yes" xml:space="preserve">
          <source>We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt; section for details.</source>
          <target state="translated">Мы видим, что точность увеличена почти до 100%. Рекомендуется стратегия перекрестной проверки для лучшей оценки точности, если она не требует слишком больших затрат на ЦП. Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Перекрестная проверка: оценка производительности средства оценки&lt;/a&gt; &amp;raquo;. Более того, если вы хотите оптимизировать пространство параметров, настоятельно рекомендуется использовать соответствующую методологию; подробности см. в разделе &amp;laquo; &lt;a href=&quot;grid_search#grid-search&quot;&gt;Настройка гиперпараметров оценщика&lt;/a&gt; &amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="d680bb4e5101fe3a9df93911d26cfa982767e679" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we&amp;rsquo;d considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">Мы видим, что полученная &lt;em&gt;полиномиальная регрессия&lt;/em&gt; относится к тому же классу линейных моделей, который мы рассматривали выше (т.е. модель линейна по \ (w \)) и может быть решена с помощью тех же методов. Рассматривая линейные соответствия в многомерном пространстве, построенном с помощью этих базисных функций, модель обладает гибкостью, позволяющей соответствовать гораздо более широкому диапазону данных.</target>
        </trans-unit>
        <trans-unit id="1a0e7af8231b7a460dcfd9acf44c6323ad1ea844" translate="yes" xml:space="preserve">
          <source>We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.</source>
          <target state="translated">Мы выбрали два набора двух переменных из набора данных по корпусу в Бостоне в качестве иллюстрации того,какой анализ может быть выполнен с помощью нескольких инструментов обнаружения отклонений.Для визуализации мы работаем с двумерными примерами,но следует помнить,что,как будет указано,в высоком измерении вещи не так тривиальны.</target>
        </trans-unit>
        <trans-unit id="940e7a9289cb117779f9b0e089fc6f41ec456057" translate="yes" xml:space="preserve">
          <source>We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations &lt;code&gt;n_splits&lt;/code&gt; at the expense of compute time. Increasing the value number of &lt;code&gt;C_range&lt;/code&gt; and &lt;code&gt;gamma_range&lt;/code&gt; steps will increase the resolution of the hyper-parameter heat map.</source>
          <target state="translated">Мы также должны отметить, что небольшие различия в оценках являются результатом случайного разделения процедуры перекрестной проверки. Эти ложные вариации можно сгладить, увеличив количество итераций CV &lt;code&gt;n_splits&lt;/code&gt; за счет времени вычислений. Увеличение числа &lt;code&gt;C_range&lt;/code&gt; шагов C_range и &lt;code&gt;gamma_range&lt;/code&gt; увеличит разрешение тепловой карты гиперпараметров.</target>
        </trans-unit>
        <trans-unit id="1cbc5d306e08afa1d68b1045fc6a567611cf26d2" translate="yes" xml:space="preserve">
          <source>We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.</source>
          <target state="translated">Мы показываем,что linear_model.Lasso дает одинаковые результаты для плотных и разреженных данных и что в случае разреженных данных скорость улучшается.</target>
        </trans-unit>
        <trans-unit id="efbf964638e7ca0fbdc3e1bd2a5029a9cbed6b8c" translate="yes" xml:space="preserve">
          <source>We start by training a label propagation model with only 10 labeled points, then we select the top five most uncertain points to label. Next, we train with 15 labeled points (original 10 + 5 new ones). We repeat this process four times to have a model trained with 30 labeled examples. Note you can increase this to label more than 30 by changing &lt;code&gt;max_iterations&lt;/code&gt;. Labeling more than 30 can be useful to get a sense for the speed of convergence of this active learning technique.</source>
          <target state="translated">Мы начинаем с обучения модели распространения меток только с 10 помеченными точками, а затем выбираем пять наиболее неопределенных точек для маркировки. Далее мы тренируемся с 15 отмеченными точками (исходные 10 + 5 новых). Мы повторяем этот процесс четыре раза, чтобы обучить модель с 30 помеченными примерами. Обратите внимание, что вы можете увеличить это значение до более 30, изменив &lt;code&gt;max_iterations&lt;/code&gt; . Присвоение более 30 баллов может быть полезно для понимания скорости конвергенции этой техники активного обучения.</target>
        </trans-unit>
        <trans-unit id="b926aa4a7c89ca684b4dc714781356e70fac60ed" translate="yes" xml:space="preserve">
          <source>We thus transform the KDD Data set into two different data sets: SA and SF.</source>
          <target state="translated">Таким образом,мы преобразуем набор данных KDD в два различных набора данных:SA и SF.</target>
        </trans-unit>
        <trans-unit id="13122bf873819e99a4ec7d32c926bbee95474f9b" translate="yes" xml:space="preserve">
          <source>We use a GridSearchCV to set the dimensionality of the PCA</source>
          <target state="translated">Мы используем GridSearchCV для определения размерности СПС</target>
        </trans-unit>
        <trans-unit id="83c28baded6fcaa48849ef740f04075945b33344" translate="yes" xml:space="preserve">
          <source>We use clustering to group together quotes that behave similarly. Here, amongst the &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;various clustering techniques&lt;/a&gt; available in the scikit-learn, we use &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation&lt;/a&gt; as it does not enforce equal-size clusters, and it can choose automatically the number of clusters from the data.</source>
          <target state="translated">Мы используем кластеризацию, чтобы группировать цитаты, которые ведут себя одинаково. Здесь, среди &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;различных методов кластеризации,&lt;/a&gt; доступных в scikit-learn, мы используем &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation, так&lt;/a&gt; как он не требует кластеров одинакового размера и может автоматически выбирать количество кластеров из данных.</target>
        </trans-unit>
        <trans-unit id="78d7bc0e66fad92fa188a5bbaa0a7aaa581101c6" translate="yes" xml:space="preserve">
          <source>We use sparse inverse covariance estimation to find which quotes are correlated conditionally on the others. Specifically, sparse inverse covariance gives us a graph, that is a list of connection. For each symbol, the symbols that it is connected too are those useful to explain its fluctuations.</source>
          <target state="translated">Мы используем разреженную обратную ковариационную оценку,чтобы найти,какие котировки коррелируют условно с другими.В частности,разреженная обратная ковариация дает нам график,то есть список связей.Для каждого символа,символы,с которыми он связан,также являются теми,которые полезны для объяснения его флуктуаций.</target>
        </trans-unit>
        <trans-unit id="4e3f49993eefd3c100d45584ffc552355d0d52e7" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the digits dataset or on the 20 newsgroups text document (TF-IDF word frequencies) dataset:</source>
          <target state="translated">Мы подтверждаем вышеперечисленные границы в наборе цифровых данных или в текстовом документе 20 новостных групп (TF-IDF word frequencyencies):</target>
        </trans-unit>
        <trans-unit id="4bd2e73735072e414ab7c853666f3b851cc359c1" translate="yes" xml:space="preserve">
          <source>We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;).</source>
          <target state="translated">Мы хотим сравнить производительность MiniBatchKMeans и KMeans: MiniBatchKMeans быстрее, но дает немного разные результаты (см. &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Мини-пакетные K-средние&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="b8ae1ec8b6dd301757e7e59be0a9aeff645f7f18" translate="yes" xml:space="preserve">
          <source>We will cluster a set of data, first with KMeans and then with MiniBatchKMeans, and plot the results. We will also plot the points that are labelled differently between the two algorithms.</source>
          <target state="translated">Мы сконцентрируем набор данных сначала с KMeans,а затем с MiniBatchKMeans,и построим график результатов.Мы также построим графики точек,которые помечены по-разному между двумя алгоритмами.</target>
        </trans-unit>
        <trans-unit id="b4cfcf9a2f9d6095c0707be11ca996fe9017bf9d" translate="yes" xml:space="preserve">
          <source>We will probably have to use an estimator or a parametrization of the current estimator that can learn more complex concepts (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.</source>
          <target state="translated">Вероятно,нам придется использовать вычислитель или параметризацию текущей вычислительной системы,которая сможет изучить более сложные понятия (т.е.имеет меньший смещение).Если оценка обучения намного больше,чем оценка валидации для максимального количества обучающих выборок,то добавление большего количества обучающих выборок,скорее всего,увеличит обобщение.На следующем рисунке видно,что SVM может выиграть от большего количества учебных примеров.</target>
        </trans-unit>
        <trans-unit id="3f09acb611dde4d0822059b7dd910a6bf0d4be22" translate="yes" xml:space="preserve">
          <source>We will review here the orders of magnitude you can expect from a number of scikit-learn estimators in different contexts and provide some tips and tricks for overcoming performance bottlenecks.</source>
          <target state="translated">Мы рассмотрим здесь порядки величин,которые вы можете ожидать от ряда научно-обученных оценщиков в различных контекстах,и дадим некоторые советы и уловки для преодоления узких мест в производительности.</target>
        </trans-unit>
        <trans-unit id="5ab95440492dec088ab7d086a3622b86acadc7e7" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ll define a function that lets us visualize the behavior of each cross-validation object. We&amp;rsquo;ll perform 4 splits of the data. On each split, we&amp;rsquo;ll visualize the indices chosen for the training set (in blue) and the test set (in red).</source>
          <target state="translated">Мы определим функцию, которая позволит нам визуализировать поведение каждого объекта перекрестной проверки. Мы выполним 4 разделения данных. На каждом сплите мы визуализируем индексы, выбранные для обучающего набора (синим цветом) и тестового набора (красным).</target>
        </trans-unit>
        <trans-unit id="70c023ae490fc71ae664cdd80527ab708a5db4b9" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ve already encountered some parameters such as &lt;code&gt;use_idf&lt;/code&gt; in the &lt;code&gt;TfidfTransformer&lt;/code&gt;. Classifiers tend to have many parameters as well; e.g., &lt;code&gt;MultinomialNB&lt;/code&gt; includes a smoothing parameter &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;SGDClassifier&lt;/code&gt; has a penalty parameter &lt;code&gt;alpha&lt;/code&gt; and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python &lt;code&gt;help&lt;/code&gt; function to get a description of these).</source>
          <target state="translated">Мы уже встречались с некоторыми параметрами, такими как &lt;code&gt;use_idf&lt;/code&gt; , в &lt;code&gt;TfidfTransformer&lt;/code&gt; . Классификаторы также имеют много параметров; например, &lt;code&gt;MultinomialNB&lt;/code&gt; включает параметр сглаживания &lt;code&gt;alpha&lt;/code&gt; а &lt;code&gt;SGDClassifier&lt;/code&gt; имеет параметр штрафа &lt;code&gt;alpha&lt;/code&gt; и настраиваемые параметры потерь и штрафа в целевой функции (см. документацию модуля или используйте функцию &lt;code&gt;help&lt;/code&gt; Python, чтобы получить их описание).</target>
        </trans-unit>
        <trans-unit id="96df76d7fa199e301349be570d5ef4d0bb6a7f3d" translate="yes" xml:space="preserve">
          <source>Weight given to each sample.</source>
          <target state="translated">Вес,присвоенный каждому образцу.</target>
        </trans-unit>
        <trans-unit id="a7a3ce3e7a16ef99378bfef64690454462da25e9" translate="yes" xml:space="preserve">
          <source>Weight matrix, where n_features in the number of visible units and n_components is the number of hidden units.</source>
          <target state="translated">Весовая матрица,где n_функции в количестве видимых единиц и n_компонент-количество скрытых единиц.</target>
        </trans-unit>
        <trans-unit id="d0664e46a183d0a2a2e3afcbc3b6c5ba30a9d4ef" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">Вес каждого образца, так что образец с весом не менее &lt;code&gt;min_samples&lt;/code&gt; сам по себе является образцом керна; образец с отрицательным весом может препятствовать тому, чтобы его eps-сосед был ядром. Обратите внимание, что веса являются абсолютными и по умолчанию равны 1.</target>
        </trans-unit>
        <trans-unit id="5cc536fd8cf249ec4c2e295665e0070f1b9cec67" translate="yes" xml:space="preserve">
          <source>Weight of precision in harmonic mean.</source>
          <target state="translated">Вес точности в гармоническом средстве.</target>
        </trans-unit>
        <trans-unit id="6cd90e03c276712f974984f65620519bcea49500" translate="yes" xml:space="preserve">
          <source>Weight vector(s).</source>
          <target state="translated">Весовой вектор(ы).</target>
        </trans-unit>
        <trans-unit id="ac0d2c9a738f9c54a5d208ddac8f22019ff9c627" translate="yes" xml:space="preserve">
          <source>Weight, Waist and Pulse.</source>
          <target state="translated">Вес,талия и пульс.</target>
        </trans-unit>
        <trans-unit id="c74e4e7c5caf95682fb65872b5814741f06c7fac" translate="yes" xml:space="preserve">
          <source>Weighted average</source>
          <target state="translated">Средневзвешенное значение</target>
        </trans-unit>
        <trans-unit id="39392047d0260b6fc1e042825fdae9116d630e28" translate="yes" xml:space="preserve">
          <source>Weighted average probability for each class per sample.</source>
          <target state="translated">Средневзвешенная вероятность для каждого класса на выборку.</target>
        </trans-unit>
        <trans-unit id="9a702ae7f12a23bf0cde9786ae821e6b340d4991" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples (1. for unweighted).</source>
          <target state="translated">Веса,применяемые к отдельным образцам (1.для не взвешенных).</target>
        </trans-unit>
        <trans-unit id="0c68217fe30f051f7b997da07ad569653cfdb104" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed.</source>
          <target state="translated">Веса,применяемые к отдельным образцам.Если это не указано,то предполагается,что речь идет об однородных весах.</target>
        </trans-unit>
        <trans-unit id="3070fe087be2b6fbe15f65d4db644297c1112686" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified</source>
          <target state="translated">Веса,применяемые к отдельным образцам.Если это не указано,то предполагается,что речь идет об однородных весах.Эти веса будут умножены на class_weight (передаются через конструктор),если указан class_weight</target>
        </trans-unit>
        <trans-unit id="86b1d5826d4836f8e129b6346c9e9e60976aafee" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</source>
          <target state="translated">Веса,присвоенные признакам (коэффициенты в основной задаче).Это доступно только в случае линейного ядра.</target>
        </trans-unit>
        <trans-unit id="4b149f5e057b5bff95048ebeff46bfac0e7a368d" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features.</source>
          <target state="translated">Веса,присвоенные функциям.</target>
        </trans-unit>
        <trans-unit id="8064bf8d5d6b0c15f7ed813823cc0da43a8bc7e6" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Веса, связанные с классами в форме &lt;code&gt;{class_label: weight}&lt;/code&gt; . Если не указано иное, все классы должны иметь вес один.</target>
        </trans-unit>
        <trans-unit id="96f3238c530c2df09403ab213fee9515feb36c99" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">Веса, связанные с классами в форме &lt;code&gt;{class_label: weight}&lt;/code&gt; . Если не указано иное, все классы должны иметь вес один. Для задач с несколькими выходами список dicts может быть предоставлен в том же порядке, что и столбцы y.</target>
        </trans-unit>
        <trans-unit id="4a87f3dd4dfb432aa1a51752552e165c9cc23301" translate="yes" xml:space="preserve">
          <source>Weights associated with classes. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Веса,связанные с классами.Если не указано,то все классы должны иметь вес один.</target>
        </trans-unit>
        <trans-unit id="4837ab63e8195a91fca82bbd82590df1bbe7fcc4" translate="yes" xml:space="preserve">
          <source>Weights for each estimator in the boosted ensemble.</source>
          <target state="translated">Веса для каждого оценщика в усиленном ансамбле.</target>
        </trans-unit>
        <trans-unit id="55ddc90a49d39d4b40d722b720afa82441019829" translate="yes" xml:space="preserve">
          <source>Weights on each point of the regression. If None, weight is set to 1 (equal weights).</source>
          <target state="translated">Веса на каждой точке регрессии.Если None,то вес устанавливается равным 1 (равные веса).</target>
        </trans-unit>
        <trans-unit id="0946f675292deb36a2ff9f4a33806ccd9e9e1833" translate="yes" xml:space="preserve">
          <source>Weights. If set to None, all weights will be set to 1 (equal weights).</source>
          <target state="translated">Весы.Если установлено значение None,то все веса будут установлены на 1 (равные веса).</target>
        </trans-unit>
        <trans-unit id="c1f521c553b00dab458900dd1fb3f949a6ba99ab" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class.</source>
          <target state="translated">Хорошо откалиброванные классификаторы являются вероятностными классификаторами,для которых выход метода predict_proba может быть непосредственно интерпретирован как уровень доверия.Например,хорошо откалиброванный (бинарный)классификатор должен классифицировать выборки таким образом,чтобы среди выборок,для которых он дал значение предсказания_пробы близкое к 0.8,примерно 80% действительно принадлежали к положительному классу.</target>
        </trans-unit>
        <trans-unit id="6db2509535d857954c618d97c17994b5d42574ae" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:</source>
          <target state="translated">Хорошо откалиброванные классификаторы являются вероятностными классификаторами,для которых выход метода predict_proba может быть непосредственно интерпретирован как уровень доверия.Например,хорошо откалиброванный (бинарный)классификатор должен классифицировать выборки таким образом,чтобы среди выборок,для которых он дал значение предсказания_пробы близкое к 0.8,примерно 80% действительно принадлежали к положительному классу.Следующий график сравнивает,насколько хорошо откалиброваны вероятностные прогнозы различных классификаторов:</target>
        </trans-unit>
        <trans-unit id="830bc34728ca0799f710b4883d58631c6dfded76" translate="yes" xml:space="preserve">
          <source>Wether to include meta-estimators that are somehow special and can not be default-constructed sensibly. These are currently Pipeline, FeatureUnion and GridSearchCV</source>
          <target state="translated">Не следует включать метаоценщики,которые каким-то образом являются особенными и не могут быть разумно построены по умолчанию.В настоящее время это &quot;Трубопровод&quot;,&quot;Характеристика&quot; и &quot;Сеть поиска&quot;.</target>
        </trans-unit>
        <trans-unit id="d4f157bc9962e4b0dc2a197ed14e50902555d749" translate="yes" xml:space="preserve">
          <source>What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?</source>
          <target state="translated">Каковы различные алгоритмы дерева решений и чем они отличаются друг от друга? Какой из них реализован в наукоёмких исследованиях?</target>
        </trans-unit>
        <trans-unit id="a1f5f9cd3d06157b8582b1ca4000a5bc395e765a" translate="yes" xml:space="preserve">
          <source>What this example shows us is the behavior &amp;ldquo;rich getting richer&amp;rdquo; of agglomerative clustering that tends to create uneven cluster sizes. This behavior is pronounced for the average linkage strategy, that ends up with a couple of singleton clusters, while in the case of single linkage we get a single central cluster with all other clusters being drawn from noise points around the fringes.</source>
          <target state="translated">Этот пример показывает нам поведение агломеративной кластеризации &amp;laquo;богатый становится еще богаче&amp;raquo;, которая имеет тенденцию создавать кластеры неравномерного размера. Такое поведение ярко выражено для стратегии усредненного связывания, которая заканчивается парой одноэлементных кластеров, в то время как в случае одиночного связывания мы получаем один центральный кластер, а все остальные кластеры выводятся из точек шума по краям.</target>
        </trans-unit>
        <trans-unit id="32580ac608fcdadc1c2050695a6c24cae1fcef1f" translate="yes" xml:space="preserve">
          <source>What we can see that:</source>
          <target state="translated">То,что мы видим:</target>
        </trans-unit>
        <trans-unit id="bd10ebd98b3e733be938ffeb72efbd3793589a2c" translate="yes" xml:space="preserve">
          <source>When &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; is applied on a &amp;ldquo;document-term&amp;rdquo; matrix, the matrix will be decomposed into a &amp;ldquo;topic-term&amp;rdquo; matrix and a &amp;ldquo;document-topic&amp;rdquo; matrix. While &amp;ldquo;topic-term&amp;rdquo; matrix is stored as &lt;code&gt;components_&lt;/code&gt; in the model, &amp;ldquo;document-topic&amp;rdquo; matrix can be calculated from &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">Когда &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt; применяется к матрице &amp;laquo;документ-термин&amp;raquo;, матрица будет разложена на матрицу &amp;laquo;тема-термин&amp;raquo; и матрица &amp;laquo;документ-тема&amp;raquo;. В то время как матрица &amp;laquo;тема-термин&amp;raquo; хранится в модели как &lt;code&gt;components_&lt;/code&gt; , матрица &amp;laquo;документ-тема&amp;raquo; может быть вычислена методом &lt;code&gt;transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d35c02f0322e905eb57e225a27ca83f7c5f6cc47" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=0&lt;/code&gt;, columns which only contained missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">Когда &lt;code&gt;axis=0&lt;/code&gt; , столбцы, которые содержат только недостающие значения при &lt;code&gt;fit&lt;/code&gt; , отбрасываются при &lt;code&gt;transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cf98e7188203ecb0d30e3564b161d5393433799" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=1&lt;/code&gt;, an exception is raised if there are rows for which it is not possible to fill in the missing values (e.g., because they only contain missing values).</source>
          <target state="translated">Когда &lt;code&gt;axis=1&lt;/code&gt; , возникает исключение, если есть строки, для которых невозможно заполнить отсутствующие значения (например, потому что они содержат только отсутствующие значения).</target>
        </trans-unit>
        <trans-unit id="4bce6b6fbd4b9fe79bfc7468f7df9f938d3ce841" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;fit&lt;/code&gt; does not converge, &lt;code&gt;cluster_centers_&lt;/code&gt; becomes an empty array and all training samples will be labelled as &lt;code&gt;-1&lt;/code&gt;. In addition, &lt;code&gt;predict&lt;/code&gt; will then label every sample as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">Когда &lt;code&gt;fit&lt;/code&gt; не сходится, &lt;code&gt;cluster_centers_&lt;/code&gt; становится пустым массивом, и все обучающие выборки будут помечены как &lt;code&gt;-1&lt;/code&gt; . Кроме того, &lt;code&gt;predict&lt;/code&gt; , будет маркировать каждую выборку , как &lt;code&gt;-1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f7c77c5939a6b7b3a7ed9ce47827d49725522a57" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;gamma&lt;/code&gt; is very small, the model is too constrained and cannot capture the complexity or &amp;ldquo;shape&amp;rdquo; of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.</source>
          <target state="translated">Когда &lt;code&gt;gamma&lt;/code&gt; очень мала, модель слишком ограничена и не может уловить сложность или &amp;laquo;форму&amp;raquo; данных. Область влияния любого выбранного вектора поддержки будет включать в себя весь комплекс подготовки. Результирующая модель будет вести себя аналогично линейной модели с набором гиперплоскостей, разделяющих центры высокой плотности любой пары из двух классов.</target>
        </trans-unit>
        <trans-unit id="6579a89bba02e2aa5596acf0a356de3285b5831f" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;learning_method&lt;/code&gt; is &amp;lsquo;online&amp;rsquo;, use mini-batch update. Otherwise, use batch update.</source>
          <target state="translated">Когда &lt;code&gt;learning_method&lt;/code&gt; находится в режиме онлайн, используйте мини-пакетное обновление. В противном случае используйте пакетное обновление.</target>
        </trans-unit>
        <trans-unit id="1789662661fe322dc45828ec3c3eb62749643034" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;novelty&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; be aware that you must only use &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; on new unseen data and not on the training samples as this would lead to wrong results. The scores of abnormality of the training samples are always accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">Когда &lt;code&gt;novelty&lt;/code&gt; устанавливается в &lt;code&gt;True&lt;/code&gt; , иметь в виду , что вы должны использовать только &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; и &lt;code&gt;score_samples&lt;/code&gt; на новом невидимом данных , а не на учебных образцов , так как это привело бы к ошибочным результатам. Оценки отклонений обучающих выборок всегда доступны через атрибут &lt;code&gt;negative_outlier_factor_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f3329fe0cead2a208482794593628ff4dce53789" translate="yes" xml:space="preserve">
          <source>When False, either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; being sparse will yield sparse output. When True, output will always be an array.</source>
          <target state="translated">Если задано значение False, то либо &lt;code&gt;a&lt;/code&gt; , либо &lt;code&gt;b&lt;/code&gt; являются разреженными, результат будет разреженным. Когда True, вывод всегда будет массивом.</target>
        </trans-unit>
        <trans-unit id="0baad85c0e4d647371baa109869739d44cb0f600" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are divided by &lt;code&gt;n_samples&lt;/code&gt; times &lt;code&gt;components_&lt;/code&gt; to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Когда True (по умолчанию False), векторы &lt;code&gt;components_&lt;/code&gt; делятся на &lt;code&gt;n_samples&lt;/code&gt; , умноженные на &lt;code&gt;components_&lt;/code&gt; , чтобы гарантировать некоррелированные выходы с единичными покомпонентными дисперсиями.</target>
        </trans-unit>
        <trans-unit id="3eaa2881688032030c765cb871d4c787aff03fe7" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Когда True (по умолчанию False), векторы &lt;code&gt;components_&lt;/code&gt; умножаются на квадратный корень из n_samples, а затем делятся на сингулярные значения, чтобы гарантировать некоррелированные выходы с единичными покомпонентными дисперсиями.</target>
        </trans-unit>
        <trans-unit id="afb8087ad0f4a499dd14f72be9807792c351ecd8" translate="yes" xml:space="preserve">
          <source>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</source>
          <target state="translated">При значении True к матрице свойств применяется абсолютное значение до ее возврата.При использовании в сочетании с переменной alternate_sign=True это значительно снижает внутреннее свойство сохранения продукта.</target>
        </trans-unit>
        <trans-unit id="204d5c48d22bd9cd74d36182840231c3ecac4f55" translate="yes" xml:space="preserve">
          <source>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</source>
          <target state="translated">Когда параметр True,к характеристикам добавляется переменный знак для того,чтобы приблизительно сохранить внутренний продукт в хэш-памяти даже при небольших n_функциях.Такой подход аналогичен разреженной случайной проекции.</target>
        </trans-unit>
        <trans-unit id="e08ec276d8bba6d4be8a6e677715ca1a35d4dd15" translate="yes" xml:space="preserve">
          <source>When a grouped cross-validator is used, the group labels are also passed on to the &lt;code&gt;split&lt;/code&gt; method of the cross-validator. The cross-validator uses them for grouping the samples while splitting the dataset into train/test set.</source>
          <target state="translated">Когда используется сгруппированный кросс-валидатор, групповые метки также передаются в метод &lt;code&gt;split&lt;/code&gt; кросс-валидатора. Кросс-валидатор использует их для группировки выборок при разделении набора данных на набор для обучения / тестирования.</target>
        </trans-unit>
        <trans-unit id="6c0f90cdc44694d62adb6ac9bccd5513d6bf148f" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, &lt;code&gt;fit&lt;/code&gt; will result in a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Когда все обучающие выборки имеют одинаковое сходство и одинаковые предпочтения, назначение центров кластеров и меток зависит от предпочтения. Если предпочтение меньше, чем сходство, &lt;code&gt;fit&lt;/code&gt; приведет к единственному центру кластера и метке &lt;code&gt;0&lt;/code&gt; для каждой выборки. В противном случае каждая обучающая выборка становится собственным центром кластера и получает уникальную метку.</target>
        </trans-unit>
        <trans-unit id="c440a8e563c9cc7b9752f14072284d81697bdfcd" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample will be returned. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Когда все обучающие выборки имеют одинаковое сходство и одинаковые предпочтения, назначение центров кластеров и меток зависит от предпочтения. Если предпочтение меньше, чем сходство, будет возвращен единый центр кластера и метка &lt;code&gt;0&lt;/code&gt; для каждого образца. В противном случае каждая обучающая выборка становится собственным центром кластера и получает уникальную метку.</target>
        </trans-unit>
        <trans-unit id="2494d11b03713922afdad3fa1bc52bb7064577b4" translate="yes" xml:space="preserve">
          <source>When alpha is very large, the regularization effect dominates the squared loss function and the coefficients tend to zero. At the end of the path, as alpha tends toward zero and the solution tends towards the ordinary least squares, coefficients exhibit big oscillations. In practise it is necessary to tune alpha in such a way that a balance is maintained between both.</source>
          <target state="translated">Когда альфа очень большой,эффект регуляризации доминирует над квадратной функцией потерь,а коэффициенты стремятся к нулю.В конце пути,когда альфа стремится к нулю,а решение стремится к обычным наименьшим квадратам,коэффициенты проявляют большие колебания.На практике необходимо настраивать альфа так,чтобы поддерживался баланс между ними.</target>
        </trans-unit>
        <trans-unit id="e93a4fdf68d407dc869190eca6cd7dfaf57ad986" translate="yes" xml:space="preserve">
          <source>When applying LOF for outlier detection, there are no &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods but only a &lt;code&gt;fit_predict&lt;/code&gt; method. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute. Note that &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; can be used on new unseen data when LOF is applied for novelty detection, i.e. when the &lt;code&gt;novelty&lt;/code&gt; parameter is set to &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;#novelty-with-lof&quot;&gt;Novelty detection with Local Outlier Factor&lt;/a&gt;.</source>
          <target state="translated">При применении LOF для обнаружения выбросов не &lt;code&gt;score_samples&lt;/code&gt; методы &lt;code&gt;predict&lt;/code&gt; , функция &lt;code&gt;decision_function&lt;/code&gt; и оценка_выборки, а есть только метод &lt;code&gt;fit_predict&lt;/code&gt; . Оценки отклонений от нормы обучающих выборок доступны через атрибут &lt;code&gt;negative_outlier_factor_&lt;/code&gt; . Обратите внимание , что &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; и &lt;code&gt;score_samples&lt;/code&gt; могут быть использованы на новых невидимых данных , когда LOF применяется для детекции новизны, то есть , когда &lt;code&gt;novelty&lt;/code&gt; параметр установлен в значение &lt;code&gt;True&lt;/code&gt; . См. &lt;a href=&quot;#novelty-with-lof&quot;&gt;Обнаружение новинок с помощью локального выброса&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="869141a5ff3e1444543cdaec8c9968684d76b66e" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">При построении словаря игнорируйте термины,которые имеют частоту документа строго выше заданного порога (стоп-слова по корпусу).Если параметр float,то он представляет собой пропорцию документов,целочисленные абсолютные числа.Этот параметр игнорируется,если в словаре нет None.</target>
        </trans-unit>
        <trans-unit id="1f13ad80586b74ad6fdc521fde036c051cf6e0e7" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">При построении словаря игнорируйте термины,которые имеют частоту документа строго ниже заданного порога.В литературе это значение также называется отсечением.Если float,то параметр представляет собой пропорцию документов,целочисленные абсолютные числа.Этот параметр игнорируется,если словарь не None.</target>
        </trans-unit>
        <trans-unit id="8ed788b8f95069d89dcb15b1bea5b5e7da9a9648" translate="yes" xml:space="preserve">
          <source>When calling &lt;code&gt;fit&lt;/code&gt;, an affinity matrix is constructed using either kernel function such the Gaussian (aka RBF) kernel of the euclidean distanced &lt;code&gt;d(X, X)&lt;/code&gt;:</source>
          <target state="translated">При вызове &lt;code&gt;fit&lt;/code&gt; строится матрица аффинности с использованием любой функции ядра, такой как гауссово (также известное как RBF) ядро ​​евклидова удаленного &lt;code&gt;d(X, X)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="da9c4333516559f145c3dcae1d1fd9f5e0da891d" translate="yes" xml:space="preserve">
          <source>When doing classification in scikit-learn, &lt;code&gt;y&lt;/code&gt; is a vector of integers or strings.</source>
          <target state="translated">При выполнении классификации в scikit-learn &lt;code&gt;y&lt;/code&gt; - это вектор целых чисел или строк.</target>
        </trans-unit>
        <trans-unit id="fb08dbb1ad477236e66b72b0cef9bccfd1ceec61" translate="yes" xml:space="preserve">
          <source>When doing supervised learning, a simple sanity check consists of comparing one&amp;rsquo;s estimator against simple rules of thumb. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt; implements several such simple strategies for classification:</source>
          <target state="translated">При обучении с учителем простая проверка работоспособности состоит из сравнения своей оценки с простыми практическими правилами. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; реализует несколько таких простых стратегий классификации:</target>
        </trans-unit>
        <trans-unit id="3bf9748662d1dbe365a15ba24b002d016f11408b" translate="yes" xml:space="preserve">
          <source>When evaluating different settings (&amp;ldquo;hyperparameters&amp;rdquo;) for estimators, such as the &lt;code&gt;C&lt;/code&gt; setting that must be manually set for an SVM, there is still a risk of overfitting &lt;em&gt;on the test set&lt;/em&gt; because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can &amp;ldquo;leak&amp;rdquo; into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called &amp;ldquo;validation set&amp;rdquo;: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.</source>
          <target state="translated">При оценке различных настроек (&amp;laquo;гиперпараметров&amp;raquo;) для оценщиков, таких как настройка &lt;code&gt;C&lt;/code&gt; , которая должна быть установлена ​​вручную для SVM, все еще существует риск переобучения &lt;em&gt;на тестовом наборе,&lt;/em&gt; поскольку параметры можно настраивать до тех пор, пока оценщик не будет работать оптимально. Таким образом, знания о наборе тестов могут &amp;laquo;просочиться&amp;raquo; в модель, а показатели оценки больше не будут сообщать о производительности обобщения. Чтобы решить эту проблему, еще одна часть набора данных может быть представлена ​​как так называемый &amp;laquo;набор для проверки&amp;raquo;: обучение продолжается на обучающем наборе, после чего выполняется оценка на проверочном наборе, и когда эксперимент кажется успешным. , окончательную оценку можно провести на тестовом наборе.</target>
        </trans-unit>
        <trans-unit id="b6d52e3adfb55f9048c5ef57545d77d640ae7db4" translate="yes" xml:space="preserve">
          <source>When evaluating text classifiers on the 20 Newsgroups data, you should strip newsgroup-related metadata. In scikit-learn, you can do this by setting &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt;. The F-score will be lower because it is more realistic.</source>
          <target state="translated">При оценке текстовых классификаторов для данных 20 групп новостей следует удалить метаданные, относящиеся к группам новостей. В scikit-learn вы можете сделать это, установив &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt; . F-оценка будет ниже, потому что это более реалистично.</target>
        </trans-unit>
        <trans-unit id="b44ace677df67ec762b5f7d213266d4181953b1c" translate="yes" xml:space="preserve">
          <source>When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a &lt;strong&gt;development set&lt;/strong&gt; (to be fed to the &lt;code&gt;GridSearchCV&lt;/code&gt; instance) and an &lt;strong&gt;evaluation set&lt;/strong&gt; to compute performance metrics.</source>
          <target state="translated">При оценке полученной модели важно делать это на удерживаемых выборках, которые не были замечены в процессе поиска по сетке: рекомендуется разделить данные на &lt;strong&gt;набор&lt;/strong&gt; для &lt;strong&gt;разработки&lt;/strong&gt; (для &lt;code&gt;GridSearchCV&lt;/code&gt; экземпляр GridSearchCV ) и &lt;strong&gt;набор для оценки.&lt;/strong&gt; для вычисления показателей производительности.</target>
        </trans-unit>
        <trans-unit id="1a86b5b9ee94c593acad1b7968fd00ab3b487df9" translate="yes" xml:space="preserve">
          <source>When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature &amp;ldquo;f&amp;rdquo; that can take on the values &amp;ldquo;ham&amp;rdquo; and &amp;ldquo;spam&amp;rdquo; will become two features in the output, one signifying &amp;ldquo;f=ham&amp;rdquo;, the other &amp;ldquo;f=spam&amp;rdquo;.</source>
          <target state="translated">Когда значения функции являются строками, этот преобразователь будет выполнять двоичное кодирование по принципу &amp;laquo;одноразовое&amp;raquo; (также известное как &amp;laquo;один из K&amp;raquo;): для каждого из возможных строковых значений, которые может принимать функция, создается одна функция с логическим значением. Например, функция &amp;laquo;f&amp;raquo;, которая может принимать значения &amp;laquo;ветчина&amp;raquo; и &amp;laquo;спам&amp;raquo;, станет двумя функциями на выходе, одна из которых будет означать &amp;laquo;f = ветчина&amp;raquo;, а другая &amp;laquo;f = спам&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="e3d8c3576d6baaf6f77dc4e34223e91a48a8c662" translate="yes" xml:space="preserve">
          <source>When fitting a model to a matrix X_train and evaluating it against a matrix X_test, it is essential that X_train and X_test have the same number of features (X_train.shape[1] == X_test.shape[1]). This may not be the case if you load the files individually with load_svmlight_file.</source>
          <target state="translated">При подгонке модели к матрице X_train и ее оценке в сравнении с матрицей X_test необходимо,чтобы X_train и X_test имели одинаковое количество признаков (X_train.shape[1]==X_test.shape[1]).Этого может не произойти,если загружать файлы по отдельности файлом load_svmlight_file.</target>
        </trans-unit>
        <trans-unit id="618912ddd6add9bc398f8cf8343e255bb5f0ac59" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</source>
          <target state="translated">В случае сомнений используйте &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7ebc317e66e94c9c3ce7d1b975021eefa97b880b" translate="yes" xml:space="preserve">
          <source>When individual estimators are fast to train or predict using &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; can result in slower performance due to the overhead of spawning processes.</source>
          <target state="translated">Когда отдельные оценщики быстро обучаются или предсказывают, используя &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; ,это может привести к снижению производительности из-за накладных расходов на процессы порождения.</target>
        </trans-unit>
        <trans-unit id="5223d409a8ec7650bd8559a52e22ddb32a950ada" translate="yes" xml:space="preserve">
          <source>When loss=&amp;rdquo;modified_huber&amp;rdquo;, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.</source>
          <target state="translated">Когда loss = &quot;modified_huber&quot;, оценки вероятности могут быть точными нулями и единицами, поэтому логарифмирование невозможно.</target>
        </trans-unit>
        <trans-unit id="63fb46936ec9f0c71e69b897d1f9d91941d422e3" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics:</source>
          <target state="translated">При моделировании текстовой корпорации модель предполагает следующий генеративный процесс для корпуса с документами \(D\)и темами \(K\):</target>
        </trans-unit>
        <trans-unit id="744347c999c68da3080dd50ae1b985e4b97e385e" translate="yes" xml:space="preserve">
          <source>When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.</source>
          <target state="translated">При недостаточном количестве точек на смесь оценка ковариационных матриц становится затруднительной,а алгоритм,как известно,расходится и находит решения с бесконечной вероятностью,если только ковариарии искусственно не легализуются.</target>
        </trans-unit>
        <trans-unit id="e24f09e860711fd3a63a21415134601f90e4efc0" translate="yes" xml:space="preserve">
          <source>When parametrized by error using the parameter &lt;code&gt;tol&lt;/code&gt;: argmin ||gamma||_0 subject to ||y - Xgamma||^2 &amp;lt;= tol</source>
          <target state="translated">При параметризации по ошибке с использованием параметра &lt;code&gt;tol&lt;/code&gt; : argmin || gamma || _0 при условии || y - Xgamma || ^ 2 &amp;lt;= tol</target>
        </trans-unit>
        <trans-unit id="70b3334d846e26366c45a04fb1a4a39af8e3ec45" translate="yes" xml:space="preserve">
          <source>When parametrized by the number of non-zero coefficients using &lt;code&gt;n_nonzero_coefs&lt;/code&gt;: argmin ||y - Xgamma||^2 subject to ||gamma||_0 &amp;lt;= n_{nonzero coefs}</source>
          <target state="translated">При параметризации числом ненулевых коэффициентов с использованием &lt;code&gt;n_nonzero_coefs&lt;/code&gt; : argmin || y - Xgamma || ^ 2 при условии || gamma || _0 &amp;lt;= n_ {ненулевые коэффициенты}</target>
        </trans-unit>
        <trans-unit id="10d326cee514d3b967129b254954126bcda90793" translate="yes" xml:space="preserve">
          <source>When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier.</source>
          <target state="translated">При выполнении классификации часто хочется предсказать не только метку класса,но и связанную с ней вероятность.Эта вероятность дает некоторую уверенность в предсказании.Этот пример демонстрирует,как показать,насколько хорошо откалиброваны предсказанные вероятности и как откалибровать некалиброванный классификатор.</target>
        </trans-unit>
        <trans-unit id="533cc79868c5585705042f97bd64dbf9b1c6133f" translate="yes" xml:space="preserve">
          <source>When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.</source>
          <target state="translated">При выполнении классификации часто требуется не только предсказать метку класса,но и получить вероятность соответствующей метки.Эта вероятность дает вам некоторую уверенность в предсказании.Некоторые модели могут дать вам плохие оценки вероятности класса,а некоторые даже не поддерживают предсказание вероятности.Модуль калибровки позволяет Вам лучше калибровать вероятности данной модели или добавить поддержку прогноза вероятности.</target>
        </trans-unit>
        <trans-unit id="ede14543224daf4bd7da97ebebdbcb4bdb8fe514" translate="yes" xml:space="preserve">
          <source>When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&amp;rsquo;s score (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;).</source>
          <target state="translated">При выполнении классификации часто требуется предсказать не только метку класса, но и соответствующую вероятность. Эта вероятность дает вам некоторую уверенность в прогнозе. Однако не все классификаторы обеспечивают хорошо откалиброванные вероятности: некоторые из них слишком уверены, а другие - недостаточно. Таким образом, в качестве постобработки часто желательна отдельная калибровка предсказанных вероятностей. Этот пример иллюстрирует два разных метода этой калибровки и оценивает качество возвращаемых вероятностей с использованием оценки Бриера (см. &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;Https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="e99cb78745b2020137c83400ee3d8d22f37293c0" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.</source>
          <target state="translated">При предварительном вычислении расстояний более точным с числовой точки зрения является выравнивание данных в первую очередь.Если copy_x-True (по умолчанию),то исходные данные не изменяются,что обеспечивает С-сопряжение X.Если False,то исходные данные модифицируются и возвращаются обратно до того,как функция вернётся,но небольшие числовые различия могут быть введены путём вычитания и последующего сложения среднего значения данных,в этом случае также не будет обеспечена С-сопряжённость данных,что может привести к значительному замедлению работы.</target>
        </trans-unit>
        <trans-unit id="55ac178846c6596090a6f8d0133ba62fcd26aebb" translate="yes" xml:space="preserve">
          <source>When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.</source>
          <target state="translated">При предсказании истинные метки будут недоступны.Вместо этого предсказания каждой модели передаются последующим моделям в цепочке для использования в качестве признаков.</target>
        </trans-unit>
        <trans-unit id="441463f4c28b96b4ca0739417ce251a6d1637336" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;.</source>
          <target state="translated">Когда случайные подмножества набора данных рисуются как случайные подмножества признаков, этот метод известен как случайные подпространства &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ed3a388f4c5d9809937b1b2fceecd5d5d41437fc" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;.</source>
          <target state="translated">Когда случайные подмножества набора данных рисуются как случайные подмножества выборок, этот алгоритм известен как Вставка &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f494cf947867cf3181ff2c5eaa996adc8d0ce783" translate="yes" xml:space="preserve">
          <source>When requesting a dataset with a name that is in mock_datasets, this object creates a fake dataset in a StringIO object and returns it. Otherwise, it raises an HTTPError.</source>
          <target state="translated">При запросе набора данных с именем,которое находится в mock_datasets,этот объект создает поддельный набор данных в StringIO-объекте и возвращает его.В противном случае он вызывает HTTPError.</target>
        </trans-unit>
        <trans-unit id="d66c9681351cfa02a7cc3145d8e8cc7e7a3877b3" translate="yes" xml:space="preserve">
          <source>When samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;.</source>
          <target state="translated">Когда образцы &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;отбираются&lt;/a&gt; с заменой, этот метод известен как Bagging [B1996] .</target>
        </trans-unit>
        <trans-unit id="b67d588266cee585b7c0608db5b116728771921f" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt;, i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Когда self.fit_intercept имеет значение True, вектор экземпляра x становится &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt; , т.е. &amp;laquo;синтетический&amp;raquo; объект с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится intercept_scaling * синтетический вес признака. Примечание! синтетический вес признака подлежит регуляризации l1 / l2, как и все другие признаки. Чтобы уменьшить влияние регуляризации на вес синтетических признаков (и, следовательно, на перехват), необходимо увеличить intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="339fba0d20ce2052ad9daa9e3c6cc55589d832bc" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Когда self.fit_intercept имеет значение True, вектор экземпляра x становится [x, self.intercept_scaling], т.е. &amp;laquo;синтетический&amp;raquo; объект с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится intercept_scaling * синтетический вес признака. Примечание! синтетический вес признака подлежит регуляризации l1 / l2, как и все другие признаки. Чтобы уменьшить влияние регуляризации на вес синтетических признаков (и, следовательно, на перехват), необходимо увеличить intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="ad06c0ce7c1fc91387cf888768a953ddfc43c4b6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;False&lt;/code&gt;, ignore special characters for PostScript compatibility.</source>
          <target state="translated">Если установлено значение &lt;code&gt;False&lt;/code&gt; , игнорируйте специальные символы для совместимости с PostScript.</target>
        </trans-unit>
        <trans-unit id="d1b93df55570608a785000a0ebdde0c1a478b680" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, change the display of &amp;lsquo;values&amp;rsquo; and/or &amp;lsquo;samples&amp;rsquo; to be proportions and percentages respectively.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , измените отображение &amp;laquo;значений&amp;raquo; и / или &amp;laquo;образцов&amp;raquo; на пропорции и проценты соответственно.</target>
        </trans-unit>
        <trans-unit id="3843d20a53a1ef3b59460be1fa7cb77d3c2ee1f6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw all leaf nodes at the bottom of the tree.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , нарисуйте все листовые узлы в нижней части дерева.</target>
        </trans-unit>
        <trans-unit id="1dd8441b2d9ea649f69d55eb070005c43dff3ea1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , рисовать блоки узлов с закругленными углами и использовать шрифты Helvetica вместо Times-Roman.</target>
        </trans-unit>
        <trans-unit id="37e5e7c90dcc2881b20280bd58a636a2601aa0c6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, forces the coefficients to be positive.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , коэффициенты будут положительными.</target>
        </trans-unit>
        <trans-unit id="a556178389cf10e9a8f97ab94b5cbc137168d877" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, orient tree left to right rather than top-down.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , ориентировать дерево слева направо, а не сверху вниз.</target>
        </trans-unit>
        <trans-unit id="db2d0a81092e78238cdb916143e482a964d5a789" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , закрашивайте узлы, чтобы указать класс большинства для классификации, крайние значения для регрессии или чистоту узла для множественного вывода.</target>
        </trans-unit>
        <trans-unit id="387704ecb7f5fc4e8c941c08ae18f72e58104663" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы подогнать и добавить больше оценщиков в ансамбль, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e08becb1d7f3dabb059c61e3163efbfc5e9d6bd5" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы подогнать и добавить больше оценщиков в ансамбль, в противном случае просто поместите весь новый лес. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1ddb18c96e1fca0312edb00f224f2db160c80a30" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="303e5cc9af6656c2592224b864d50a2e7f014b54" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the ID number on each node.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , показывать идентификационный номер на каждом узле.</target>
        </trans-unit>
        <trans-unit id="d19057d05dc608969ed0862b9054b2defc3fb482" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the impurity at each node.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , показывать примеси в каждом узле.</target>
        </trans-unit>
        <trans-unit id="0199409f1eeb1aa7581c717d5c23e182af166761" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">Если установлено значение True, вычисляет усредненные веса SGD и сохраняет результат в &lt;code&gt;coef_&lt;/code&gt; . Если установлено значение int больше 1, усреднение начнется, когда общее количество наблюдаемых выборок достигнет среднего. Таким образом, &lt;code&gt;average=10&lt;/code&gt; начнется усреднение после просмотра 10 образцов.</target>
        </trans-unit>
        <trans-unit id="19c4ca669b90d48df2f3aa161b89103ea08c0cbd" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</source>
          <target state="translated">Если установлено значение True, вычисляет усредненные веса SGD и сохраняет результат в &lt;code&gt;coef_&lt;/code&gt; . Если установлено значение int больше 1, усреднение начнется, когда общее количество наблюдаемых выборок достигнет среднего. Таким образом, среднее значение = 10 начнется усреднение после просмотра 10 образцов.</target>
        </trans-unit>
        <trans-unit id="e60b70114bd43f63c876204c608aaaaca2e5c6d2" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение из предыдущего вызова, чтобы подогнать и добавить больше оценщиков к ансамблю, в противном случае просто подгоните полностью новый ансамбль. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0615ecfccfe9c12eea86adfdd92570d0b3a6f9cf" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="869683b3c71be56286e995de01f21c989fc735d8" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. Бесполезен для либлинеарного решателя. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="61362ce0a02977970071e88e9dc71d066251fcde" translate="yes" xml:space="preserve">
          <source>When specifying multiple metrics, the &lt;code&gt;refit&lt;/code&gt; parameter must be set to the metric (string) for which the &lt;code&gt;best_params_&lt;/code&gt; will be found and used to build the &lt;code&gt;best_estimator_&lt;/code&gt; on the whole dataset. If the search should not be refit, set &lt;code&gt;refit=False&lt;/code&gt;. Leaving refit to the default value &lt;code&gt;None&lt;/code&gt; will result in an error when using multiple metrics.</source>
          <target state="translated">При указании нескольких метрик параметр &lt;code&gt;refit&lt;/code&gt; должен быть установлен на метрику (строку), для которой будет найден &lt;code&gt;best_params_&lt;/code&gt; и будет использоваться для построения &lt;code&gt;best_estimator_&lt;/code&gt; для всего набора данных. Если поиск не должен повторяться, установите &lt;code&gt;refit=False&lt;/code&gt; . Если оставить для параметра refit значение по умолчанию &lt;code&gt;None&lt;/code&gt; , при использовании нескольких показателей возникнет ошибка.</target>
        </trans-unit>
        <trans-unit id="765386eefc1dd2e9ed203024ee007c99e07f6618" translate="yes" xml:space="preserve">
          <source>When strategy == &amp;ldquo;constant&amp;rdquo;, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and &amp;ldquo;missing_value&amp;rdquo; for strings or object data types.</source>
          <target state="translated">Когда стратегия == &amp;laquo;константа&amp;raquo;, fill_value используется для замены всех вхождений missing_values. Если оставить значение по умолчанию, fill_value будет равно 0 при подстановке числовых данных и &amp;laquo;missing_value&amp;raquo; для строк или типов данных объекта.</target>
        </trans-unit>
        <trans-unit id="b3973bbeeefced2bd7eb8aaa05fcc0fadc5e600b" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;cv&lt;/code&gt; argument is an integer, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; uses the &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; strategies by default, the latter being used if the estimator derives from &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt;&lt;code&gt;ClassifierMixin&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Если аргумент &lt;code&gt;cv&lt;/code&gt; является целым числом, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; по умолчанию использует стратегии &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; , причем последняя используется, если оценщик является производным от &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt; &lt;code&gt;ClassifierMixin&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c7d238875ff93bafa2620f7a2d7675b937a2183b" translate="yes" xml:space="preserve">
          <source>When the algorithm does not converge, it returns an empty array as &lt;code&gt;cluster_center_indices&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; as label for each training sample.</source>
          <target state="translated">Когда алгоритм не сходится, он возвращает пустой массив как &lt;code&gt;cluster_center_indices&lt;/code&gt; и &lt;code&gt;-1&lt;/code&gt; как метку для каждой обучающей выборки.</target>
        </trans-unit>
        <trans-unit id="b4fdfb364ee084bf57bd04a0f7c8f0c41739edf4" translate="yes" xml:space="preserve">
          <source>When the data is not initially in the &lt;code&gt;(n_samples, n_features)&lt;/code&gt; shape, it needs to be preprocessed in order to be used by scikit-learn.</source>
          <target state="translated">Когда данные изначально не &lt;code&gt;(n_samples, n_features)&lt;/code&gt; форму (n_samples, n_features) , их необходимо предварительно обработать, чтобы использовать scikit-learn.</target>
        </trans-unit>
        <trans-unit id="aaeec02a52e8579f06c37808c9e18fa50d637a08" translate="yes" xml:space="preserve">
          <source>When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground true labels. The maximum value is always +1.</source>
          <target state="translated">При наличии более двух меток значение ЦУД больше не будет находиться в диапазоне от -1 до +1.Вместо этого минимальное значение будет находиться где-то между -1 и 0 в зависимости от количества и распределения заземленных истинных меток.Максимальное значение всегда равно +1.</target>
        </trans-unit>
        <trans-unit id="5c69ffd1e0dc71befa67c00726bc6370582b5df5" translate="yes" xml:space="preserve">
          <source>When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.</source>
          <target state="translated">При отсутствии корреляции между выходами очень простой способ решения такой задачи-построить n независимых моделей,т.е.по одной для каждой из выходов,а затем использовать эти модели для независимого предсказания каждой из n выходов.Однако,поскольку вполне вероятно,что выходные значения,связанные с одним и тем же входом,сами по себе коррелируют,зачастую лучший способ-построить единую модель,способную предсказывать одновременно все n выходов.Во-первых,это требует меньшего времени на обучение,так как строится только один оценщик.Во-вторых,точность обобщения результирующей оценки часто может быть увеличена.</target>
        </trans-unit>
        <trans-unit id="8c7fa59e2b8c1ce3abb542d1d5f76caddd1816f1" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikt-learn and joblib need to be compatible. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">Когда эта переменная окружения установлена в ненулевое значение,scikit-learn использует joblib сайта,а не его обожествленную версию.Следовательно,для работы scikit-learn должен быть установлен joblib.Обратите внимание,что использование библиотеки joblib сайта на ваш страх и риск:версии scikt-learn и joblib должны быть совместимы.Кроме того,дампов с joblib.Memory может быть несовместимым,и вы можете потерять некоторые кэши и будете вынуждены перезагружать некоторые наборы данных.</target>
        </trans-unit>
        <trans-unit id="743d4762d28a3d61488ddf12d10bce762b152657" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, the tests that need network access are skipped.</source>
          <target state="translated">Когда эта переменная окружения установлена на ненулевое значение,тесты,которым необходим доступ к сети,пропускаются.</target>
        </trans-unit>
        <trans-unit id="beb3490e0a85d3bcf9f4888cb75a6b1ea2e1e6a8" translate="yes" xml:space="preserve">
          <source>When training an SVM with the &lt;em&gt;Radial Basis Function&lt;/em&gt; (RBF) kernel, two parameters must be considered: &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. The parameter &lt;code&gt;C&lt;/code&gt;, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low &lt;code&gt;C&lt;/code&gt; makes the decision surface smooth, while a high &lt;code&gt;C&lt;/code&gt; aims at classifying all training examples correctly. &lt;code&gt;gamma&lt;/code&gt; defines how much influence a single training example has. The larger &lt;code&gt;gamma&lt;/code&gt; is, the closer other examples must be to be affected.</source>
          <target state="translated">При обучении SVM с помощью ядра &lt;em&gt;радиальной базовой функции&lt;/em&gt; (RBF) необходимо учитывать два параметра: &lt;code&gt;C&lt;/code&gt; и &lt;code&gt;gamma&lt;/code&gt; . Параметр &lt;code&gt;C&lt;/code&gt; , общий для всех ядер SVM, сводит на нет неправильную классификацию обучающих примеров и простоту поверхности принятия решений. Низкий &lt;code&gt;C&lt;/code&gt; делает поверхность принятия решения гладкой, а высокий &lt;code&gt;C&lt;/code&gt; направлен на правильную классификацию всех обучающих примеров. &lt;code&gt;gamma&lt;/code&gt; определяет, какое влияние имеет один обучающий пример. Чем больше &lt;code&gt;gamma&lt;/code&gt; , тем ближе другие примеры должны быть затронуты.</target>
        </trans-unit>
        <trans-unit id="4f5d7a3d8a7ab119798fbec5ead8471db219e63d" translate="yes" xml:space="preserve">
          <source>When true, the result is adjusted for chance, so that random performance would score 0, and perfect performance scores 1.</source>
          <target state="translated">Если это так,то результат корректируется на случайность,так что случайное исполнение набрало бы 0 баллов,а идеальное исполнение-1.</target>
        </trans-unit>
        <trans-unit id="a756308318fb23f07be0498c8c83a0d088f9279a" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;code&gt;CountVectorizer&lt;/code&gt; or &lt;code&gt;TfidfVectorizer&lt;/code&gt;), this transformation is known as &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">Когда усеченный SVD применяется к матрицам терминов-документов (возвращаемых &lt;code&gt;CountVectorizer&lt;/code&gt; или &lt;code&gt;TfidfVectorizer&lt;/code&gt; ), это преобразование известно как &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;латентный семантический анализ&lt;/a&gt; (LSA), поскольку оно преобразует такие матрицы в &amp;laquo;семантическое&amp;raquo; пространство низкой размерности. В частности, известно, что LSA борется с эффектами синонимии и многозначности (оба из которых примерно означают наличие нескольких значений на слово), из-за которых матрицы терминов-документов становятся слишком разреженными и демонстрируют плохое сходство по таким параметрам, как косинусное сходство.</target>
        </trans-unit>
        <trans-unit id="726430099b436b4edbed2772b4e46aec59296fe0" translate="yes" xml:space="preserve">
          <source>When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.</source>
          <target state="translated">При использовании для классификации текста с векторами tf-idf,этот классификатор также известен как классификатор Роккио.</target>
        </trans-unit>
        <trans-unit id="b1373e66b4937bbac8defef2fa925bed61a8d596" translate="yes" xml:space="preserve">
          <source>When used to &lt;em&gt;transform&lt;/em&gt; data, PCA can reduce the dimensionality of the data by projecting on a principal subspace.</source>
          <target state="translated">При использовании для &lt;em&gt;преобразования&lt;/em&gt; данных PCA может уменьшить размерность данных за счет проецирования на главное подпространство.</target>
        </trans-unit>
        <trans-unit id="93429c223efcd8d6622a4c8e5f0e71f13358e226" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;multiclass classifiers&lt;/code&gt;&lt;/a&gt;, the learning and prediction task that is performed is dependent on the format of the target data fit upon:</source>
          <target state="translated">При использовании &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;multiclass classifiers&lt;/code&gt; &lt;/a&gt; выполняемая задача обучения и прогнозирования зависит от формата целевых данных, соответствующих:</target>
        </trans-unit>
        <trans-unit id="cb56aa339cbb48c9a75d42d2c7bf7e7858b3170b" translate="yes" xml:space="preserve">
          <source>When using ensemble methods base upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.</source>
          <target state="translated">При использовании ансамблевых методов на основе мешков,т.е.при создании новых тренировочных комплектов на основе отбора проб с заменой,часть тренировочного комплекта остается неиспользованной.Для каждого классификатора в ансамбле не используется отдельная часть тренировочного комплекта.</target>
        </trans-unit>
        <trans-unit id="a9696826aefafecc5b32845bc270f3c2cabe6664" translate="yes" xml:space="preserve">
          <source>When using these images, please give credit to AT&amp;amp;T Laboratories Cambridge.</source>
          <target state="translated">При использовании этих изображений, пожалуйста, отдайте должное AT&amp;amp;T Laboratories Cambridge.</target>
        </trans-unit>
        <trans-unit id="5a6f9e7437ff7d6762455e24a46c4771dc2e0a37" translate="yes" xml:space="preserve">
          <source>When using, for example, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;, to set the amount of regularization with &lt;code&gt;C&lt;/code&gt;, there will be a different amount of samples between the main problem and the smaller problems within the folds of the cross validation.</source>
          <target state="translated">При использовании, например, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;перекрестной проверки&lt;/a&gt; , чтобы установить степень регуляризации с помощью &lt;code&gt;C&lt;/code&gt; , будет различное количество выборок между основной проблемой и меньшими проблемами в пределах складок перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="5dae0cb2a4d8c33bb8e68ee9ffd452db73e27eb2" translate="yes" xml:space="preserve">
          <source>When we apply clustering to the data, we find that the clustering reflects what was in the distance matrices. Indeed, for the Euclidean distance, the classes are ill-separated because of the noise, and thus the clustering does not separate the waveforms. For the cityblock distance, the separation is good and the waveform classes are recovered. Finally, the cosine distance does not separate at all waveform 1 and 2, thus the clustering puts them in the same cluster.</source>
          <target state="translated">Когда мы применяем кластеризацию к данным,мы обнаруживаем,что кластеризация отражает то,что было в матрицах расстояний.Действительно,для евклидового расстояния классы плохо разделены из-за шума,и поэтому кластеризация не разделяет формы волн.Для расстояния до ситиблока разделение хорошо,и классы формы волны восстанавливаются.Наконец,косинусоидальное расстояние не разделяет кривые 1 и 2,поэтому кластеризация помещает их в один и тот же кластер.</target>
        </trans-unit>
        <trans-unit id="8975b7dd097c19a6af3c2b4b090f357f96aab52d" translate="yes" xml:space="preserve">
          <source>When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.</source>
          <target state="translated">При работе с оценкой ковариации обычно используется оценка максимального правдоподобия, например &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; . Он несмещен, т. Е. Сходится к истинной (популяционной) ковариации при большом количестве наблюдений. Однако также может быть полезно упорядочить его, чтобы уменьшить его дисперсию; это, в свою очередь, вносит некоторую предвзятость. Этот пример иллюстрирует простую регуляризацию, используемую в &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;оценках Shrunk Covariance&lt;/a&gt; . В частности, он фокусируется на том, как установить степень регуляризации, то есть как выбрать компромисс между смещением и дисперсией.</target>
        </trans-unit>
        <trans-unit id="17b704aa73a46ef6f9edddecff620d33c0b705d7" translate="yes" xml:space="preserve">
          <source>When you want to apply different transformations to each field of the data, see the related class &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;#column-transformer&quot;&gt;user guide&lt;/a&gt;).</source>
          <target state="translated">Если вы хотите применить различные преобразования к каждому полю данных, см. Связанный класс &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; (см. &lt;a href=&quot;#column-transformer&quot;&gt;Руководство пользователя&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="ffd889b6ef09600260c419603787a00c67ae551d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in both the true labels and the predicted labels), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in the true labels and not in the predicted labels) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in the predicted labels and not in the true labels).</source>
          <target state="translated">Где &lt;code&gt;TP&lt;/code&gt; - это количество &lt;strong&gt;истинно положительных&lt;/strong&gt; (т. Е. Количество пар точек, которые принадлежат одним и тем же кластерам как в истинных, так и в предсказанных метках), &lt;code&gt;FP&lt;/code&gt; - это количество &lt;strong&gt;ложных положительных результатов&lt;/strong&gt; (то есть количество пар точек, принадлежащих к одним и тем же кластерам в истинных метках, а не в предсказанных метках), а &lt;code&gt;FN&lt;/code&gt; - это количество &lt;strong&gt;ложных отрицательных&lt;/strong&gt; значений (т. е. количество пар точек, которые принадлежат одним и тем же кластерам в предсказанных метках, а не в истинных метках).</target>
        </trans-unit>
        <trans-unit id="276f699fa82da6208d110c0a23b40d61550922dd" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in both &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt;), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_true&lt;/code&gt; and not in &lt;code&gt;labels_pred&lt;/code&gt;) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_pred&lt;/code&gt; and not in &lt;code&gt;labels_True&lt;/code&gt;).</source>
          <target state="translated">Где &lt;code&gt;TP&lt;/code&gt; это число &lt;strong&gt;истинно положительный&lt;/strong&gt; (т.е. числа пар точек , которая принадлежит в одних и тех же кластерах в обоих &lt;code&gt;labels_true&lt;/code&gt; и &lt;code&gt;labels_pred&lt;/code&gt; ), &lt;code&gt;FP&lt;/code&gt; является числом &lt;strong&gt;ложного положительным&lt;/strong&gt; (т.е. числа пар точек , которая принадлежит в одних и тех же кластерах в &lt;code&gt;labels_true&lt;/code&gt; , а не в &lt;code&gt;labels_pred&lt;/code&gt; ) и &lt;code&gt;FN&lt;/code&gt; является числом &lt;strong&gt;Ложноотрицательного&lt;/strong&gt; (то есть число пар точек , которая принадлежит в одних и тех же кластерах в &lt;code&gt;labels_pred&lt;/code&gt; и не &lt;code&gt;labels_True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e78195e2eb2711f3bb8a0d7f4e3c56eea492c48d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;delta&lt;/code&gt; is a free parameter representing the width of the Gaussian kernel.</source>
          <target state="translated">Где &lt;code&gt;delta&lt;/code&gt; - это свободный параметр, представляющий ширину ядра Гаусса.</target>
        </trans-unit>
        <trans-unit id="6d88fb8179777bb060d39d8e880a1a6ec89efb59" translate="yes" xml:space="preserve">
          <source>Where C is the number of permutations whose score &amp;gt;= the true score.</source>
          <target state="translated">Где C - количество перестановок, оценка которых&amp;gt; = истинная оценка.</target>
        </trans-unit>
        <trans-unit id="0426d1b8d26623c0079356962f68cf2595f6d67a" translate="yes" xml:space="preserve">
          <source>Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:</source>
          <target state="translated">Где D-матрица расстояний для входных данных X,D_fit-матрица расстояний для выходных встраиваемых X_fit,а K-изомапное ядро:</target>
        </trans-unit>
        <trans-unit id="77844a8258430d31f41a5c27fd5c3c817a4c46f5" translate="yes" xml:space="preserve">
          <source>Where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset (without ordering).</source>
          <target state="translated">Где \(C_2^{n_{samples}}\)-общее количество возможных пар в наборе данных (без заказа).</target>
        </trans-unit>
        <trans-unit id="45f9706f8e40bfee3b8f4082279b7c1694d8aead" translate="yes" xml:space="preserve">
          <source>Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R &lt;code&gt;glasso&lt;/code&gt; package.</source>
          <target state="translated">Где \ (K \) - это матрица точности, которую необходимо оценить, а \ (S \) - это выборочная ковариационная матрица. \ (\ | K \ | _1 \) - это сумма абсолютных значений недиагональных коэффициентов \ (K \). Для решения этой проблемы используется алгоритм GLasso из статьи Friedman 2008 Biostatistics. Это тот же алгоритм, что и в пакете R &lt;code&gt;glasso&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="23038cc6fb25ab648004d5485267f6db76cb9eda" translate="yes" xml:space="preserve">
          <source>Where \(N(x_i)\) is the neighborhood of samples within a given distance around \(x_i\) and \(m\) is the &lt;em&gt;mean shift&lt;/em&gt; vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:</source>
          <target state="translated">Где \ (N (x_i) \) - это окрестность выборок на заданном расстоянии вокруг \ (x_i \), а \ (m \) - вектор &lt;em&gt;среднего сдвига,&lt;/em&gt; который вычисляется для каждого центроида, который указывает на область максимального увеличения по плотности точек. Это вычисляется с использованием следующего уравнения, эффективно обновляющего центроид до среднего значения выборок в его окрестности:</target>
        </trans-unit>
        <trans-unit id="c4be16a40b65a723b122e1219966e4db066c1f56" translate="yes" xml:space="preserve">
          <source>Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).</source>
          <target state="translated">Где \(R\)-диагональная матрица с записью \(i\),равной \(\sum_{j}A_{ij}\)и \(C\)-диагональная матрица с записью \(j\),равной \(\sum_{i}A_{ij}\).</target>
        </trans-unit>
        <trans-unit id="06bd15907339a321f45a7707ee037e3bf4bb294c" translate="yes" xml:space="preserve">
          <source>Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.</source>
          <target state="translated">Где \(\langle \cdot,\cdot\)обозначает внутренний продукт в пространстве Гильберта.</target>
        </trans-unit>
        <trans-unit id="b505305e3f68e0055136674f6671623549265da7" translate="yes" xml:space="preserve">
          <source>Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.</source>
          <target state="translated">Где \(\log_e (x)\)означает естественный логарифм \(x\).Этот показатель лучше всего использовать,когда речь идет о целях,имеющих экспоненциальный рост,таких как численность населения,средний объем продаж какого-либо товара за период времени и т.д.Обратите внимание,что данная метрика предусматривает штрафные санкции за недопредставленную оценку,превышающую завышенную оценку.</target>
        </trans-unit>
        <trans-unit id="dc652afd01d2a671ac597240d27fcb8fb6f2cb88" translate="yes" xml:space="preserve">
          <source>Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Где \(s(i,k)\)-это сходство между образцами \(i\)и \(k\).Наличие образца \(k\)является примером образца \(i\):</target>
        </trans-unit>
        <trans-unit id="9fa1e5b532b4ed4720d23061371103281dda3d83" translate="yes" xml:space="preserve">
          <source>Where r is defined per sample, we need to make use of &lt;code&gt;start&lt;/code&gt;:</source>
          <target state="translated">Где r определяется для каждого образца, нам нужно использовать &lt;code&gt;start&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c16b06fa7e959786262fbf5823a1d1a66514be0c" translate="yes" xml:space="preserve">
          <source>Where the step length \(\gamma_m\) is chosen using line search:</source>
          <target state="translated">Где длина шага \(\gamma_m\)выбирается с помощью поиска по строке:</target>
        </trans-unit>
        <trans-unit id="1e4c7785f80a06d28d2e2b965c377764abc1c026" translate="yes" xml:space="preserve">
          <source>Where to from here</source>
          <target state="translated">Куда отсюда</target>
        </trans-unit>
        <trans-unit id="17eb390ca1dec9880beb722610077dafb8edc9ac" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features] and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Где u и v-любые строки,взятые из набора данных формы [n_samples,n_features]и p-это проекция случайной гауссовской N(0,1)матрицы с формой [n_компоненты,n_features](или разреженной ахлиоптасовой матрицы).</target>
        </trans-unit>
        <trans-unit id="c5759c4abe89df832c23e0269eba38e4f1ad0ad7" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features], eps is in ]0, 1[ and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Где u и v-любые строки,взятые из набора данных формы [n_samples,n_features],eps находится в ]0,1[и p-проекция случайной гауссовской N(0,1)матрицы с формой [n_компоненты,n_features](или разреженной ахлиоптасовой матрицей).</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="07f1abf8acdb3dcd49bde3ee8a201c3421831b31" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting. True by default.</source>
          <target state="translated">Будьте &lt;code&gt;feature_names_&lt;/code&gt; и &lt;code&gt;vocabulary_&lt;/code&gt; должны быть отсортированы при установке. Верно по умолчанию.</target>
        </trans-unit>
        <trans-unit id="e61b5eefa6a0d8caaa65c0cf06600523e6eded8c" translate="yes" xml:space="preserve">
          <source>Whether a forced copy will be triggered. If copy=False, a copy might be triggered by a conversion.</source>
          <target state="translated">Сработает ли принудительная копия.Если Copy=False,копия может быть вызвана преобразованием.</target>
        </trans-unit>
        <trans-unit id="6817dee267fec06b200988a35092c9fafdb28df4" translate="yes" xml:space="preserve">
          <source>Whether a prefit model is expected to be passed into the constructor directly or not. If True, &lt;code&gt;transform&lt;/code&gt; must be called directly and SelectFromModel cannot be used with &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;GridSearchCV&lt;/code&gt; and similar utilities that clone the estimator. Otherwise train the model using &lt;code&gt;fit&lt;/code&gt; and then &lt;code&gt;transform&lt;/code&gt; to do feature selection.</source>
          <target state="translated">Ожидается, что предварительная модель будет передана в конструктор напрямую или нет. Если True, &lt;code&gt;transform&lt;/code&gt; должно вызываться напрямую, а SelectFromModel нельзя использовать с &lt;code&gt;cross_val_score&lt;/code&gt; , &lt;code&gt;GridSearchCV&lt;/code&gt; и аналогичными утилитами, которые клонируют оценщик. В противном случае обучите модель, используя &lt;code&gt;fit&lt;/code&gt; а затем &lt;code&gt;transform&lt;/code&gt; чтобы выбрать элементы.</target>
        </trans-unit>
        <trans-unit id="e67f675f1639113224879739e0229eb2671df0d3" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style.</source>
          <target state="translated">Будет ли массив вынужден быть фортран или c-стилем.</target>
        </trans-unit>
        <trans-unit id="57d1f88164d54372295bc307285273118c662089" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style. When order is None (default), then if copy=False, nothing is ensured about the memory layout of the output array; otherwise (copy=True) the memory layout of the returned array is kept as close as possible to the original array.</source>
          <target state="translated">Будет ли массив вынужден быть фортран или c-стилем.Если порядок None (по умолчанию),то если copy=False,то о компоновке памяти выходного массива ничего не известно;в противном случае (copy=True)компоновка памяти возвращаемого массива хранится как можно ближе к исходному массиву.</target>
        </trans-unit>
        <trans-unit id="f6541283616583040ce3e73f070cbb436dbc5da9" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees.</source>
          <target state="translated">Используются ли при строительстве деревьев образцы бутстрап.</target>
        </trans-unit>
        <trans-unit id="344e324f858395af07d0534305d3cd485a522869" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; is passed. If &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to &lt;code&gt;zero_based=True&lt;/code&gt; to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Независимо от того, отсчитываются ли индексы столбцов в f от нуля (True) или от единицы (False). Если индексы столбцов начинаются с единицы, они преобразуются в нулевые, чтобы соответствовать соглашениям Python / NumPy. Если установлено значение &amp;laquo;авто&amp;raquo;, применяется эвристическая проверка, чтобы определить это по содержимому файла. Оба типа файлов встречаются &amp;laquo;в дикой природе&amp;raquo;, но, к сожалению, они не самоидентифицируются. Использование &amp;laquo;auto&amp;raquo; или &amp;laquo;True&amp;raquo; всегда должно быть безопасным, если не передается &lt;code&gt;offset&lt;/code&gt; или &lt;code&gt;length&lt;/code&gt; . Если &lt;code&gt;offset&lt;/code&gt; или &lt;code&gt;length&lt;/code&gt; переданы, режим &amp;laquo;auto&amp;raquo; возвращается к &lt;code&gt;zero_based=True&lt;/code&gt; чтобы избежать получения несогласованных результатов эвристической проверки в разных сегментах файла.</target>
        </trans-unit>
        <trans-unit id="f00bfe1387e4927051573cb3d574287560206c66" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no offset or length is passed. If offset or length are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to zero_based=True to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Независимо от того, отсчитываются ли индексы столбцов в f от нуля (True) или от единицы (False). Если индексы столбцов начинаются с единицы, они преобразуются в нулевые, чтобы соответствовать соглашениям Python / NumPy. Если установлено значение &amp;laquo;авто&amp;raquo;, применяется эвристическая проверка, чтобы определить это по содержимому файла. Оба типа файлов встречаются &amp;laquo;в дикой природе&amp;raquo;, но, к сожалению, они не самоидентифицируются. Использование &amp;laquo;auto&amp;raquo; или &amp;laquo;True&amp;raquo; всегда должно быть безопасным, если не передается смещение или длина. Если смещение или длина переданы, режим &amp;laquo;auto&amp;raquo; возвращается к нулевому_based = True, чтобы избежать получения несогласованных результатов эвристической проверки в разных сегментах файла.</target>
        </trans-unit>
        <trans-unit id="be05ee9a303aba9073e602f5af4606db8dba467c" translate="yes" xml:space="preserve">
          <source>Whether column indices should be written zero-based (True) or one-based (False).</source>
          <target state="translated">Должны ли индексы столбца быть написаны на нулевой основе (True)или на одной основе (False).</target>
        </trans-unit>
        <trans-unit id="426c392bb98aa08b186e867710abfa024378fa01" translate="yes" xml:space="preserve">
          <source>Whether features are drawn with replacement.</source>
          <target state="translated">Отрисовываются ли функции с заменой.</target>
        </trans-unit>
        <trans-unit id="b1153e9c8e50c0d286811aaf218a31fa047ae93d" translate="yes" xml:space="preserve">
          <source>Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.</source>
          <target state="translated">Проводится ли вторая нормализация весов или нет.Поведение по умолчанию зеркально отражает реализации,найденные в Махауте и Веке,которые не следуют полному алгоритму,описанному в таблице 9 статьи.</target>
        </trans-unit>
        <trans-unit id="1500a013d74d8899d6c67c8489e35470d425474d" translate="yes" xml:space="preserve">
          <source>Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter &lt;code&gt;fit_intercept&lt;/code&gt;.</source>
          <target state="translated">Должна ли модель использовать перехват, т. &lt;code&gt;fit_intercept&lt;/code&gt; гиперплоскость, контролируется параметром fit_intercept .</target>
        </trans-unit>
        <trans-unit id="c17699d69c93a1c9674665b22c836f689e7a71a8" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch.</source>
          <target state="translated">Должны ли данные тренировки быть перетасованы после каждой эпохи или нет.</target>
        </trans-unit>
        <trans-unit id="2f96d4cd24a907c94c91a597b369db5ae9d183fe" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch. Defaults to True.</source>
          <target state="translated">Должны ли данные тренировки быть перетасованы после каждой эпохи или нет.По умолчанию установлено значение True.</target>
        </trans-unit>
        <trans-unit id="21e287c040da0ab9f7612eda4a9df397d21447be" translate="yes" xml:space="preserve">
          <source>Whether or not to compute labels for each fit.</source>
          <target state="translated">Рассчитывать ли этикетки для каждого подбора или нет.</target>
        </trans-unit>
        <trans-unit id="ae7627e3aed47d9187a8dde354d4bd8908f66e18" translate="yes" xml:space="preserve">
          <source>Whether or not to consider raw Mahalanobis distances as the decision function. Must be False (default) for compatibility with the others outlier detection tools.</source>
          <target state="translated">Рассматривать или не рассматривать необработанные расстояния Махаланобиса как функцию решения.Должно быть Ложно (по умолчанию)для совместимости с другими инструментами обнаружения отклонений.</target>
        </trans-unit>
        <trans-unit id="d7d36162415efc2dece0359749393df764e8f212" translate="yes" xml:space="preserve">
          <source>Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.</source>
          <target state="translated">Соответствует ли перехват или нет.Это может быть установлено в значение False,если данные уже сосредоточены вокруг источника.</target>
        </trans-unit>
        <trans-unit id="99ecd63bc30b233e173e08d6a58d2b609112b08a" translate="yes" xml:space="preserve">
          <source>Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Сделать или не сделать копию данных.Если установлено значение False,начальные данные будут перезаписаны.</target>
        </trans-unit>
        <trans-unit id="0d8aa347bdbdfa6dd79051c8fee2f95fc5666522" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &lt;code&gt;None&lt;/code&gt;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo; as this will preserve backwards compatibility.</source>
          <target state="translated">Следует ли отмечать каждый образец как первого ближайшего соседа к себе. Если &lt;code&gt;None&lt;/code&gt; , то True используется для mode = 'connectivity' и False для mode = 'distance', так как это сохранит обратную совместимость.</target>
        </trans-unit>
        <trans-unit id="a1d6eb056f01f6a77d40d6f787612d8008f1be4b" translate="yes" xml:space="preserve">
          <source>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</source>
          <target state="translated">Возвращать или не возвращать разреженную матрицу CSR,как поведение по умолчанию,или возвращать плотный массив,совместимый с операторами плотных трубопроводов.</target>
        </trans-unit>
        <trans-unit id="8f592bf838896fb605ecc15c063970bf58250eab" translate="yes" xml:space="preserve">
          <source>Whether or not to return the number of iterations.</source>
          <target state="translated">Вернуть или не вернуть количество итераций.</target>
        </trans-unit>
        <trans-unit id="3433b032133d6a741db0a6ccce9ce8005a84877d" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.</source>
          <target state="translated">Перетасовывать данные перед разбиением или нет.Если shuffle=False,то стратификация должна быть None.</target>
        </trans-unit>
        <trans-unit id="d797771ee8d7ac8a664344b3d1655c54bf4a7c5a" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data: might be important for models that make the assumption that the samples are independent and identically distributed (i.i.d.), such as stochastic gradient descent.</source>
          <target state="translated">Переставлять или не переставлять данные:может быть важно для моделей,которые делают предположение,что образцы независимы и идентично распределены (i.i.d.),например,стохастический градиентный спуск.</target>
        </trans-unit>
        <trans-unit id="169aa17090e9b82766c818a4a09acd1cb51fcb24" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement.</source>
          <target state="translated">Отбираются ли образцы с заменой.</target>
        </trans-unit>
        <trans-unit id="b61c81ce74fc75ce6a90c790bfafe984d14c7994" translate="yes" xml:space="preserve">
          <source>Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.</source>
          <target state="translated">Является ли функция score_func функцией оценки (по умолчанию),означающей,что максимум-это хорошо,или функция потерь,означающая,что минимум-это хорошо.В последнем случае,объект scorer будет означать результат функции score_func.</target>
        </trans-unit>
        <trans-unit id="01c7a3b4947bb7aed2272a78dd753a14b9e24fdc" translate="yes" xml:space="preserve">
          <source>Whether score_func requires predict_proba to get probability estimates out of a classifier.</source>
          <target state="translated">Требуется ли sco_func прогноз_proba,чтобы получить из классификатора вероятностные оценки.</target>
        </trans-unit>
        <trans-unit id="e86601bb1c2db478564381eb9b1a33fc72f3ad69" translate="yes" xml:space="preserve">
          <source>Whether score_func takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method.</source>
          <target state="translated">Принимает ли sco_func непрерывное решение с уверенностью.Это работает только для бинарной классификации с использованием оценщиков,которые имеют либо метод decision_function,либо метод predict_proba.</target>
        </trans-unit>
        <trans-unit id="62e384e32324c7d8c05ac06534cda98d3cbc0def" translate="yes" xml:space="preserve">
          <source>Whether support is a list of indices.</source>
          <target state="translated">Является ли поддержка списком индексов.</target>
        </trans-unit>
        <trans-unit id="970ea0e030e6e4be6469b0282edfb558e0e9066d" translate="yes" xml:space="preserve">
          <source>Whether the algorithm should be applied to M.T instead of M. The result should approximately be the same. The &amp;lsquo;auto&amp;rsquo; mode will trigger the transposition if M.shape[1] &amp;gt; M.shape[0] since this implementation of randomized SVD tend to be a little faster in that case.</source>
          <target state="translated">Следует ли применять алгоритм к МП вместо М. Результат должен быть примерно таким. &amp;laquo;Автоматический&amp;raquo; режим запускает транспонирование, если M.shape [1]&amp;gt; M.shape [0], поскольку эта реализация рандомизированного SVD имеет тенденцию быть немного быстрее в этом случае.</target>
        </trans-unit>
        <trans-unit id="3226951d2ead1297a694651602f8538f5e93757c" translate="yes" xml:space="preserve">
          <source>Whether the covariance vector Xy must be copied by the algorithm. If False, it may be overwritten.</source>
          <target state="translated">Должен ли ковариационный вектор Xy быть скопирован алгоритмом.Если False,то он может быть переписан.</target>
        </trans-unit>
        <trans-unit id="d2b667c3b7746e3e678455d8b2d703997aeb5e60" translate="yes" xml:space="preserve">
          <source>Whether the deflation be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effects</source>
          <target state="translated">Будет ли дефляция сделана на копии. Оставьте значение по умолчанию True, если вас не волнуют побочные эффекты.</target>
        </trans-unit>
        <trans-unit id="1cba92780e42c1ebe55ada467260206516898de8" translate="yes" xml:space="preserve">
          <source>Whether the deflation should be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effect</source>
          <target state="translated">Следует ли производить дефляцию на копии. Оставьте значение по умолчанию True, если вас не волнует побочный эффект.</target>
        </trans-unit>
        <trans-unit id="99f0df0508624fcfafef99671905c951f197a398" translate="yes" xml:space="preserve">
          <source>Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Должна ли матрица проектирования X быть скопирована алгоритмом.Ложное значение полезно только в том случае,если X уже заказана по Fortran,в противном случае копия все равно будет сделана.</target>
        </trans-unit>
        <trans-unit id="f62ef19aafedabcbf9aa2a6c1cbcccaa900e840f" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams.</source>
          <target state="translated">Должна ли эта функция быть сделана из слова или из n-грамм символов.</target>
        </trans-unit>
        <trans-unit id="9c1354d44a66effd212e821b1aba74fe08612248" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">Должен ли признак состоять из словесных или символьных н-граммов. Опция 'char_wb' создает н-граммы символов только из текста внутри границ слова; n-граммы по краям слов заполняются пробелами.</target>
        </trans-unit>
        <trans-unit id="824ad07968fefbc8aa1fba0ade7c849f0d099562" translate="yes" xml:space="preserve">
          <source>Whether the gram matrix must be copied by the algorithm. A false value is only helpful if it is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Должна ли грамматическая матрица быть скопирована алгоритмом.Ложное значение полезно только в том случае,если оно уже заказано Fortran,в противном случае копия все равно будет сделана.</target>
        </trans-unit>
        <trans-unit id="23571fa5c9f0e8d5b2ce0915807aa480e23639d3" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask format should be sparse or dense.</source>
          <target state="translated">Должен ли формат маски принтера быть разреженным или плотным.</target>
        </trans-unit>
        <trans-unit id="b70758cdff0513f8822d9fb7393f16dda3f13af9" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask should represent all or a subset of features.</source>
          <target state="translated">Должна ли маска вмятины представлять все или подмножество возможностей.</target>
        </trans-unit>
        <trans-unit id="11709e37813efd2480c1d891188cf0d8201c8a69" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If &lt;code&gt;False&lt;/code&gt;, the data is assumed to be already centered.</source>
          <target state="translated">Следует ли оценивать перехват или нет. Если &lt;code&gt;False&lt;/code&gt; , предполагается, что данные уже центрированы.</target>
        </trans-unit>
        <trans-unit id="0ccd5f6458ed970eecf03c787120d2831e50f140" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.</source>
          <target state="translated">Должен ли перехват быть оценен или нет.Если Фальшивка,то предполагается,что данные уже центрированы.</target>
        </trans-unit>
        <trans-unit id="2fafec857734808cd372cb104d91a568d25acbf6" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</source>
          <target state="translated">Должен ли перехват быть оценен или нет.Если Фальшивка,то предполагается,что данные уже центрированы.По умолчанию-True.</target>
        </trans-unit>
        <trans-unit id="efe887a2120302f3ddf508ce39115dacb905298c" translate="yes" xml:space="preserve">
          <source>Whether the parameter was found to be a named parameter of the estimator&amp;rsquo;s fit method.</source>
          <target state="translated">Было ли обнаружено, что параметр является именованным параметром метода подбора оценщика.</target>
        </trans-unit>
        <trans-unit id="e3e6070e7b1bf06bd46c63ade906ee83f84569ff" translate="yes" xml:space="preserve">
          <source>Whether the power iterations are normalized with step-by-step QR factorization (the slowest but most accurate), &amp;lsquo;none&amp;rsquo; (the fastest but numerically unstable when &lt;code&gt;n_iter&lt;/code&gt; is large, e.g. typically 5 or larger), or &amp;lsquo;LU&amp;rsquo; factorization (numerically stable but can lose slightly in accuracy). The &amp;lsquo;auto&amp;rsquo; mode applies no normalization if &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 and switches to LU otherwise.</source>
          <target state="translated">Нормализованы ли итерации мощности с помощью пошаговой QR-факторизации (самая медленная, но наиболее точная), &amp;laquo;none&amp;raquo; (самая быстрая, но численно нестабильная, когда &lt;code&gt;n_iter&lt;/code&gt; большое, например, обычно 5 или больше), или факторизация &amp;laquo;LU&amp;raquo; (численно стабильно, но может немного потерять точность). В автоматическом режиме нормализация не применяется, если &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2, в противном случае переключается на LU.</target>
        </trans-unit>
        <trans-unit id="00c2bc5048e0182a905dad0c4dec40740dd521b8" translate="yes" xml:space="preserve">
          <source>Whether the relationship is increasing or decreasing.</source>
          <target state="translated">Увеличиваются ли отношения или уменьшаются.</target>
        </trans-unit>
        <trans-unit id="dc0314689b038e45038d5534e1499b2766f8b916" translate="yes" xml:space="preserve">
          <source>Whether the return value is an array of sparse matrix depends on the type of the input X.</source>
          <target state="translated">Является ли возвращаемое значение массивом разреженной матрицы,зависит от типа входа X.</target>
        </trans-unit>
        <trans-unit id="ed44b1dc96dab239fb6ac2dc375f2ee5fe3ae793" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, i.e., the mean of the observed target values become zero. This parameter should be set to True if the target values&amp;rsquo; mean is expected to differ considerable from zero. When enabled, the normalization effectively modifies the GP&amp;rsquo;s prior based on the data, which contradicts the likelihood principle; normalization is thus disabled per default.</source>
          <target state="translated">Нормализованы ли целевые значения y, т. Е. Среднее из наблюдаемых целевых значений становится нулевым. Для этого параметра следует установить значение True, если ожидается, что среднее целевых значений будет значительно отличаться от нуля. Когда эта функция включена, нормализация эффективно изменяет априорность GP на основе данных, что противоречит принципу правдоподобия; поэтому по умолчанию нормализация отключена.</target>
        </trans-unit>
        <trans-unit id="4d56de522c2f2c8fa83698a0d6921644d35a5428" translate="yes" xml:space="preserve">
          <source>Whether the task is a classification task, in which case stratified KFold will be used.</source>
          <target state="translated">Является ли задача классификационной задачей,в этом случае будет использоваться расслоенный KFold.</target>
        </trans-unit>
        <trans-unit id="6cb255093bce0eff775d5414b35fcd6fbd07931b" translate="yes" xml:space="preserve">
          <source>Whether this is a multilabel classifier</source>
          <target state="translated">Является ли это многоэлементным классификатором</target>
        </trans-unit>
        <trans-unit id="b1be5efdade94da8e67722b4ba2f983efa0225c5" translate="yes" xml:space="preserve">
          <source>Whether to allow 2-d y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">Разрешать ли 2-d y (массив или разреженная матрица).Если false,то y будет проверяться как вектор.y не может иметь np.nan или np.inf значений,если multi_output=True.</target>
        </trans-unit>
        <trans-unit id="8ecc2d4e014d3f2172c25597969963bd34e18f05" translate="yes" xml:space="preserve">
          <source>Whether to allow X.ndim &amp;gt; 2.</source>
          <target state="translated">Разрешить ли X.ndim&amp;gt; 2.</target>
        </trans-unit>
        <trans-unit id="d5dcbf9253f384309cfbc4a594ef7b057c1cb7e6" translate="yes" xml:space="preserve">
          <source>Whether to also return the code U or just the dictionary V.</source>
          <target state="translated">Вернуть ли также код U или просто словарь V.</target>
        </trans-unit>
        <trans-unit id="c6289192e1f815e2a760fe289e8841e73f51c42c" translate="yes" xml:space="preserve">
          <source>Whether to be verbose.</source>
          <target state="translated">Будет ли это многословно.</target>
        </trans-unit>
        <trans-unit id="ccada94fe77cfa7bf4094a2aaa2265ce9f9f4e5f" translate="yes" xml:space="preserve">
          <source>Whether to cache downloaded datasets using joblib.</source>
          <target state="translated">Кэшировать ли загруженные наборы данных с помощью joblib.</target>
        </trans-unit>
        <trans-unit id="86614eccba121d18979d29b5e6a1aceed9dc9343" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение False,то перехват не будет использоваться в расчетах (например,ожидается,что данные уже будут центрированы).</target>
        </trans-unit>
        <trans-unit id="943768cddf06aea5cdead26cd3dff69cb74196ef" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,то перехват не будет использоваться в вычислениях (например,ожидается,что данные уже будут по центру).</target>
        </trans-unit>
        <trans-unit id="27f8a383f138130dd1f45baee7b1d68ad4ce59f4" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,то перехват не будет использоваться в вычислениях (т.е.ожидается,что данные уже будут по центру).</target>
        </trans-unit>
        <trans-unit id="0336ff17d311b84566800e5cf35b415ab2b27f38" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,перехват не будет использоваться в вычислениях.</target>
        </trans-unit>
        <trans-unit id="471ed2aff4494fad57e380482ee0a58232333b20" translate="yes" xml:space="preserve">
          <source>Whether to check that &lt;code&gt;transform&lt;/code&gt; followed by &lt;code&gt;inverse_transform&lt;/code&gt; or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original targets.</source>
          <target state="translated">&lt;code&gt;inverse_transform&lt;/code&gt; ли проверять, что &lt;code&gt;transform&lt;/code&gt; за которым следует inverse_transform, или &lt;code&gt;func&lt;/code&gt; , за которым следует &lt;code&gt;inverse_func&lt;/code&gt; , приводит к исходным целям.</target>
        </trans-unit>
        <trans-unit id="3c61d748141856e990caff79c0b01fd8a4086321" translate="yes" xml:space="preserve">
          <source>Whether to check that or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original inputs. It can be used for a sanity check, raising a warning when the condition is not fulfilled.</source>
          <target state="translated">Проверять ли это или &lt;code&gt;func&lt;/code&gt; , за которым следует &lt;code&gt;inverse_func&lt;/code&gt; , приводит к исходным входным данным. Его можно использовать для проверки работоспособности, выдавая предупреждение, когда условие не выполняется.</target>
        </trans-unit>
        <trans-unit id="50850a0df7fa2328560b0d7ebe31ee1142901517" translate="yes" xml:space="preserve">
          <source>Whether to compute &lt;code&gt;y_&lt;/code&gt; is increasing (if set to True) or decreasing (if set to False)</source>
          <target state="translated">&lt;code&gt;y_&lt;/code&gt; ли вычислять y_ : увеличивается (если установлено значение True) или уменьшается (если установлено значение False)</target>
        </trans-unit>
        <trans-unit id="5fbe7e9ef9385d70942ace9201de11e6cead8f8d" translate="yes" xml:space="preserve">
          <source>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</source>
          <target state="translated">Будь то вычисление нормы квадратной ошибки или нормы ошибки.Если значение True (по умолчанию),возвращается норма ошибки в квадрате.Если False,возвращается норма ошибки.</target>
        </trans-unit>
        <trans-unit id="01086dba4779bb032a62d90a9f9152dc1b833baf" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place computations.</source>
          <target state="translated">Скопировать ли X и Y,или выполнить вычисления на месте.</target>
        </trans-unit>
        <trans-unit id="725302de0fd34aabdbfc0e0affbd4f4fb754127c" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place normalization.</source>
          <target state="translated">Скопировать ли X и Y или выполнить локальную нормализацию.</target>
        </trans-unit>
        <trans-unit id="7462b314a4fe2fff7847f10014abb6b1183fa84f" translate="yes" xml:space="preserve">
          <source>Whether to copy X and operate on the copy or perform in-place operations.</source>
          <target state="translated">Будь то копирование X и работа с копией или выполнение операций на месте.</target>
        </trans-unit>
        <trans-unit id="3692936737114d51a6bb410cb3531454c9ad1d68" translate="yes" xml:space="preserve">
          <source>Whether to copy the precomputed covariance matrix; if False, it may be overwritten.</source>
          <target state="translated">Скопировать ли предварительно вычисленную ковариационную матрицу;если False,то она может быть перезаписана.</target>
        </trans-unit>
        <trans-unit id="324d6fe1307968790ddbb142ded331e1979517da" translate="yes" xml:space="preserve">
          <source>Whether to create a copy of X and operate on it or to perform inplace computation (default behaviour).</source>
          <target state="translated">Создавать ли копию X и работать ли над ней или выполнять вычисления на месте (поведение по умолчанию).</target>
        </trans-unit>
        <trans-unit id="62527ff1b5ed50e080e833b6d4fd94a862b78590" translate="yes" xml:space="preserve">
          <source>Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.</source>
          <target state="translated">Следует ли снижать некоторые неоптимальные пороговые значения,которые не будут отображаться на построенной ROC-кривой.Это полезно для создания более легких УХО-кривых.</target>
        </trans-unit>
        <trans-unit id="9851e7fdf1748b99ff7c24c940b7ce5f334a6a27" translate="yes" xml:space="preserve">
          <source>Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.</source>
          <target state="translated">Неважно,сбросить ли первый собственный вектор.Для спектральной встраивания,это должно быть True,так как первый собственный вектор должен быть постоянным вектором для связанного графика,но для спектральной кластеризации,это должно быть сохранено как False,чтобы сохранить первый собственный вектор.</target>
        </trans-unit>
        <trans-unit id="5f99ffcc1bc3b15acf95363130c37cd5b381a91e" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, and will slow down that method.</source>
          <target state="translated">Следует ли включать оценки вероятности. Это должно быть включено до вызова &lt;code&gt;fit&lt;/code&gt; и замедлит этот метод.</target>
        </trans-unit>
        <trans-unit id="4a4497ffca40d00ae7a4f4bda08e5dece2337700" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the code.</source>
          <target state="translated">Привести ли в исполнение позитивность при нахождении кода.</target>
        </trans-unit>
        <trans-unit id="2920a1115fbc090ce8de93fb299e0d53a98e0404" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary</source>
          <target state="translated">Навязывать ли позитивность при поиске словаря...</target>
        </trans-unit>
        <trans-unit id="cc323427a6369f3d4c345df0c7eab9b613a4b184" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary.</source>
          <target state="translated">Привести ли в исполнение позитивность при поиске словаря.</target>
        </trans-unit>
        <trans-unit id="0c86815e9d15a8d79f49100b7de99ab0894ffb4b" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the encoding.</source>
          <target state="translated">Навязывать ли позитивность при поиске кодировки.</target>
        </trans-unit>
        <trans-unit id="67962e408072673f64867d41053d2df5bd8ffd92" translate="yes" xml:space="preserve">
          <source>Whether to ensure that y has a numeric type. If dtype of y is object, it is converted to float64. Should only be used for regression algorithms.</source>
          <target state="translated">Убедиться,что у вас есть цифровой тип.Если тип y является объектным,то он преобразуется в float64.Должен использоваться только для алгоритмов регрессии.</target>
        </trans-unit>
        <trans-unit id="a89a89f1fbc0cff73f883e4748e4c43034f0361e" translate="yes" xml:space="preserve">
          <source>Whether to filter invalid parameters or not.</source>
          <target state="translated">Фильтрация недействительных параметров или нет.</target>
        </trans-unit>
        <trans-unit id="8bd7eb051fe8793acf6505d7ff57ac8a40be3e89" translate="yes" xml:space="preserve">
          <source>Whether to fit an intercept for the model. In this case the shape of the returned array is (n_cs, n_features + 1).</source>
          <target state="translated">Подогнать ли перехват под модель.В этом случае форма возвращаемого массива будет (n_cs,n_features+1).</target>
        </trans-unit>
        <trans-unit id="8e39ad37924100e174516b8fe05585ae0c11a660" translate="yes" xml:space="preserve">
          <source>Whether to include &amp;ldquo;special&amp;rdquo; label estimator or test processors.</source>
          <target state="translated">Следует ли включать &amp;laquo;специальный&amp;raquo; оценщик этикеток или тестовые процессоры.</target>
        </trans-unit>
        <trans-unit id="84818ba086581abd044063f9dd3c5b2beb12eda7" translate="yes" xml:space="preserve">
          <source>Whether to include meta-estimators that can be constructed using an estimator as their first argument. These are currently BaseEnsemble, OneVsOneClassifier, OutputCodeClassifier, OneVsRestClassifier, RFE, RFECV.</source>
          <target state="translated">Включить ли в качестве первого аргумента метаоценщики,которые могут быть построены с использованием оценочного средства.В настоящее время это BaseEnsemble,OneVsOneClassifier,OutputCodeClassifier,OneVsRestClassifier,RFE,RFECV.</target>
        </trans-unit>
        <trans-unit id="74d7014a87bc3e04b7cb4d5881013af41aaf9d5f" translate="yes" xml:space="preserve">
          <source>Whether to include train scores.</source>
          <target state="translated">Включить ли баллы поезда.</target>
        </trans-unit>
        <trans-unit id="b770fc1f2ccfc02ef3107a2ecac741b2276c37e8" translate="yes" xml:space="preserve">
          <source>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</source>
          <target state="translated">Изучать ли класс предыдущие вероятности или нет.Если это ложь,будет использована единообразная предшествующая.</target>
        </trans-unit>
        <trans-unit id="8606bf192804810fba78c6bd2b8805fda4483156" translate="yes" xml:space="preserve">
          <source>Whether to load only 10 percent of the data.</source>
          <target state="translated">Загружать ли только 10 процентов данных.</target>
        </trans-unit>
        <trans-unit id="3156faf4c491e77c08d3500dd2b8c76947137632" translate="yes" xml:space="preserve">
          <source>Whether to load or not the content of the different files. If true a &amp;lsquo;data&amp;rsquo; attribute containing the text information is present in the data structure returned. If not, a filenames attribute gives the path to the files.</source>
          <target state="translated">Загружать или нет содержимое разных файлов. Если true, в возвращаемой структуре данных присутствует атрибут data, содержащий текстовую информацию. Если нет, атрибут filenames дает путь к файлам.</target>
        </trans-unit>
        <trans-unit id="81f8d6a01f7cffb7f53496e9cfd84f1ce27de740" translate="yes" xml:space="preserve">
          <source>Whether to make X at least 2d.</source>
          <target state="translated">Сделать ли Х как минимум 2d.</target>
        </trans-unit>
        <trans-unit id="2a578215f5e1bceb4eddd518c894532f84a10916" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of X. If &lt;code&gt;False&lt;/code&gt;, the input X gets overwritten during fitting.</source>
          <target state="translated">Делать ли копию X. Если &lt;code&gt;False&lt;/code&gt; , вход X перезаписывается во время подгонки.</target>
        </trans-unit>
        <trans-unit id="e2abdc017941ef25090c0789fe34541086dc5677" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Сделать ли копию данных.Если установлено значение False,начальные данные будут перезаписаны.</target>
        </trans-unit>
        <trans-unit id="df62a350cab30808585d28e267100de2daf97811" translate="yes" xml:space="preserve">
          <source>Whether to normalize the output matrix to make the leading diagonal elements all 1</source>
          <target state="translated">Нормализовать ли выходную матрицу,чтобы сделать ведущие диагональные элементы все 1</target>
        </trans-unit>
        <trans-unit id="ba6415e4db38e5cea33cf7fab1a514fcf5285867" translate="yes" xml:space="preserve">
          <source>Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.</source>
          <target state="translated">Будет ли выполняться пре-вычисление.Улучшает производительность,когда n_targets или n_samples очень большие.</target>
        </trans-unit>
        <trans-unit id="4010b2bff9133aaf08486f7fb645e8e39634583e" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. Auto mode by default will use presorting on dense data and default to normal sorting on sparse data. Setting presort to true on sparse data will raise an error.</source>
          <target state="translated">Предварительная сортировка данных для ускорения поиска наилучшего разделения при монтаже.Автоматический режим по умолчанию будет использовать предварительную сортировку на плотных данных,а по умолчанию-обычную сортировку на разреженных данных.Установка параметра presort в true для разреженных данных приведет к ошибке.</target>
        </trans-unit>
        <trans-unit id="29f75c6794195c888ce8399680c96d5b14e65048" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. For the default settings of a decision tree on large datasets, setting this to true may slow down the training process. When using either a smaller dataset or a restricted depth, this may speed up the training.</source>
          <target state="translated">Предварительная сортировка данных для ускорения поиска наилучшего разделения при монтаже.При настройке по умолчанию дерева решений на больших наборах данных,установка этого значения в true может замедлить тренировочный процесс.При использовании либо меньшего набора данных,либо ограниченной глубины это может ускорить тренировочный процесс.</target>
        </trans-unit>
        <trans-unit id="cc4d3f96c9bc487e50b4fc4701212f323c65bca6" translate="yes" xml:space="preserve">
          <source>Whether to print progress messages to stdout.</source>
          <target state="translated">Следует ли распечатывать сообщения о ходе работы в stdout.</target>
        </trans-unit>
        <trans-unit id="b44ea19ee67df3ef30c54f3be25f24e67c4f3a60" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2d.</source>
          <target state="translated">Следует ли увеличивать ошибку значения,если X не 2d.</target>
        </trans-unit>
        <trans-unit id="b5d06b3c83946e2cd2c05192b834ad6e01c6a1d5" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. The possibilities are:</source>
          <target state="translated">Поднять ли ошибку на np.inf и np.nan в X.Возможности таковы:</target>
        </trans-unit>
        <trans-unit id="eaa329f6263ead71ba810671bba1e6a99379040d" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. This parameter does not influence whether y can have np.inf or np.nan values. The possibilities are:</source>
          <target state="translated">Поднять ли ошибку на np.inf и np.nan в X.Этот параметр не влияет на то,может ли y иметь значения np.inf или np.nan.Возможности таковы:</target>
        </trans-unit>
        <trans-unit id="c551edd4edb4cf1081c3e3d3eb3a36ad8f839a51" translate="yes" xml:space="preserve">
          <source>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to &amp;lsquo;ignore&amp;rsquo; and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.</source>
          <target state="translated">Следует ли выдавать ошибку или игнорировать, если во время преобразования присутствует неизвестная категориальная функция (по умолчанию возникает ошибка). Если для этого параметра задано значение &amp;laquo;игнорировать&amp;raquo; и во время преобразования обнаруживается неизвестная категория, в результирующих столбцах с горячим кодированием для этой функции будут все нули. В обратном преобразовании неизвестная категория будет обозначена как None.</target>
        </trans-unit>
        <trans-unit id="55b5cf4021bca4319afc6cff07e1e1c5a8e21c80" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).</source>
          <target state="translated">Следует ли возвращать функцию принятия решения one-vs-rest ('ovr') формы (n_samples, n_classes), как все другие классификаторы, или исходную функцию принятия решения one-vs-one ('ovo') библиотеки libsvm, которая имеет форму (n_samples , n_классов * (n_classes - 1) / 2).</target>
        </trans-unit>
        <trans-unit id="3e008ca3901c2f4656b69b334cd2bbf88df838cc" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy.</source>
          <target state="translated">Следует ли возвращать функцию принятия решения one-vs-rest ('ovr') формы (n_samples, n_classes), как все другие классификаторы, или исходную функцию принятия решения one-vs-one ('ovo') библиотеки libsvm, которая имеет форму (n_samples , n_классов * (n_classes - 1) / 2). Однако стратегия &amp;laquo;один против одного&amp;raquo; (&amp;laquo;ово&amp;raquo;) всегда используется как мультиклассовая стратегия.</target>
        </trans-unit>
        <trans-unit id="ebccc28d7f21db5d9325894eec5fc9e6d02d15c3" translate="yes" xml:space="preserve">
          <source>Whether to return dense output even when the input is sparse. If &lt;code&gt;False&lt;/code&gt;, the output is sparse if both input arrays are sparse.</source>
          <target state="translated">Следует ли возвращать плотный вывод, даже если ввод разреженный. Если &lt;code&gt;False&lt;/code&gt; , выходные данные будут разреженными, если оба входных массива разрежены.</target>
        </trans-unit>
        <trans-unit id="12da7a3ff0421b885caca94ef2caa65b1b016c5f" translate="yes" xml:space="preserve">
          <source>Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.</source>
          <target state="translated">Следует ли возвращать каждое значение ненулевых коэффициентов на прямом пути.Полезно для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="6a16a084b2e44866fb8e9c04ea892f46ef9407d0" translate="yes" xml:space="preserve">
          <source>Whether to return the estimators fitted on each split.</source>
          <target state="translated">Следует ли возвращать оценочные приборы,установленные на каждом отдельном участке.</target>
        </trans-unit>
        <trans-unit id="642c6fa9e4316671c7770b59f9d72b6641ef628f" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations.</source>
          <target state="translated">Вернуть ли количество итераций.</target>
        </trans-unit>
        <trans-unit id="b549a24da790409f4ec3623e7b38a8b83191c416" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction.</source>
          <target state="translated">Вернуть ли стандартное отклонение апостериорного прогноза.</target>
        </trans-unit>
        <trans-unit id="b33ff2a27948731af021590a907c614a500fc29d" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction. All zeros in this case.</source>
          <target state="translated">Вернуть ли стандартное отклонение апостериорного прогноза.Все нули в этом случае.</target>
        </trans-unit>
        <trans-unit id="ef9a1d5fe208dc604ffba3d0e60394e32f61bdb0" translate="yes" xml:space="preserve">
          <source>Whether to scale X and Y.</source>
          <target state="translated">Будь то шкала X и Y.</target>
        </trans-unit>
        <trans-unit id="06ccde346dfb7273af2d0810793b1fb5e47df0dc" translate="yes" xml:space="preserve">
          <source>Whether to show informative labels for impurity, etc. Options include &amp;lsquo;all&amp;rsquo; to show at every node, &amp;lsquo;root&amp;rsquo; to show only at the top root node, or &amp;lsquo;none&amp;rsquo; to not show at any node.</source>
          <target state="translated">Показывать ли информативные метки для примесей и т. Д. Параметры включают &amp;laquo;все&amp;raquo; для отображения на каждом узле, &amp;laquo;корень&amp;raquo; для отображения только в верхнем корневом узле или &amp;laquo;нет&amp;raquo;, чтобы не отображать ни на одном узле.</target>
        </trans-unit>
        <trans-unit id="bcd035c2f558018eebfd4e5534f5df5bef89069a" translate="yes" xml:space="preserve">
          <source>Whether to shuffle dataset.</source>
          <target state="translated">Перетасовывать ли набор данных.</target>
        </trans-unit>
        <trans-unit id="8704d580bb26c2f6617363a0297f26abfb9fda30" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each stratification of the data before splitting into batches.</source>
          <target state="translated">Следует ли перетасовать каждую стратификацию данных,прежде чем разбивать их на части.</target>
        </trans-unit>
        <trans-unit id="5de7b9303caa771da78304a93ebeac224ba77f9b" translate="yes" xml:space="preserve">
          <source>Whether to shuffle samples in each iteration. Only used when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;.</source>
          <target state="translated">Следует ли перемешивать образцы на каждой итерации. Используется только когда solver = 'sgd' или 'adam'.</target>
        </trans-unit>
        <trans-unit id="3558a0c3a77b9ce3c242cc621a2d776c46a133af" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches.</source>
          <target state="translated">Следует ли перетасовать данные до их разделения на части.</target>
        </trans-unit>
        <trans-unit id="ddc8f26baf73b311e3fd82ce49af7a5449330660" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting it in batches.</source>
          <target state="translated">Следует ли перетасовывать данные,прежде чем разбивать их на части.</target>
        </trans-unit>
        <trans-unit id="f23a63355a4e388bf6ee14cbad5c7c9c8b8c8007" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the samples.</source>
          <target state="translated">Неважно,перетасовывать ли образцы.</target>
        </trans-unit>
        <trans-unit id="a5c75421672ae29d738aa02687f5d9f3ec0cf20c" translate="yes" xml:space="preserve">
          <source>Whether to shuffle training data before taking prefixes of it based on``train_sizes``.</source>
          <target state="translated">Перетасовывать ли тренировочные данные до получения префиксов на основе ``тренировочных размеров``.</target>
        </trans-unit>
        <trans-unit id="ce33fd98a79a5db67d420efb6fcabed70acb96c4" translate="yes" xml:space="preserve">
          <source>Whether to sort x before computing. If False, assume that x must be either monotonic increasing or monotonic decreasing. If True, y is used to break ties when sorting x. Make sure that y has a monotonic relation to x when setting reorder to True.</source>
          <target state="translated">Сортировать ли х перед вычислением.Если False,предположим,что x должен быть либо монотонным увеличивающимся,либо монотонным уменьшающимся.Если True,то y используется для разрыва связей при сортировке x.Убедитесь,что y имеет монотонное отношение к x при установке переупорядочивания в True.</target>
        </trans-unit>
        <trans-unit id="5091491cac888f3972a1197cfef1256978c18b5f" translate="yes" xml:space="preserve">
          <source>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</source>
          <target state="translated">Разделить ли разреженный характерный вектор на конкатенуацию его отрицательной и положительной частей.Это может улучшить производительность последующих классификаторов.</target>
        </trans-unit>
        <trans-unit id="8b58e41338c55eaf50346244bd6082e4f3c1a628" translate="yes" xml:space="preserve">
          <source>Whether to use Nesterov&amp;rsquo;s momentum. Only used when solver=&amp;rsquo;sgd&amp;rsquo; and momentum &amp;gt; 0.</source>
          <target state="translated">Использовать ли импульс Нестерова. Используется только когда solver = 'sgd' и импульс&amp;gt; 0.</target>
        </trans-unit>
        <trans-unit id="d97545296a16ed9ee24e38ded3551b9344d66c64" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;code&gt;n_targets&lt;/code&gt; or &lt;code&gt;n_samples&lt;/code&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама и Xy для ускорения вычислений. Повышает производительность, когда &lt;code&gt;n_targets&lt;/code&gt; или &lt;code&gt;n_samples&lt;/code&gt; очень большие. Обратите внимание: если у вас уже есть такие матрицы, вы можете передать их непосредственно методу fit.</target>
        </trans-unit>
        <trans-unit id="7dc600168d6ae4c500452eb14badcdfddafb11ff" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &amp;lsquo;auto&amp;rsquo; let us decide. The Gram matrix can also be passed as argument, but it will be used only for the selection of parameter alpha, if alpha is &amp;lsquo;aic&amp;rsquo; or &amp;lsquo;bic&amp;rsquo;.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &amp;laquo;авто&amp;raquo;, мы решим. Матрица Грама также может быть передана в качестве аргумента, но она будет использоваться только для выбора параметра alpha, если alpha равно 'aic' или 'bic'.</target>
        </trans-unit>
        <trans-unit id="0057a82fcc5e3ed086a2d1961e27e45b3f58597f" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрица Грама также может быть передана в качестве аргумента.</target>
        </trans-unit>
        <trans-unit id="419f7e60c7c4f4f84360a1078ab4b36ce5bf208a" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрица Грама также может быть передана в качестве аргумента. Для разреженного ввода эта опция всегда имеет значение &lt;code&gt;True&lt;/code&gt; , чтобы сохранить разреженность.</target>
        </trans-unit>
        <trans-unit id="18cfe378dd4d6390fca460de4e70af73f097cdf4" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрицу Грама нельзя передавать в качестве аргумента, поскольку мы будем использовать только подмножества X.</target>
        </trans-unit>
        <trans-unit id="2bc24bd08e69b99e2a7b63ee3e5ac92e16a75bc1" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Матрица Грама также может быть передана в качестве аргумента. Для разреженного ввода эта опция всегда имеет значение &lt;code&gt;True&lt;/code&gt; , чтобы сохранить разреженность.</target>
        </trans-unit>
        <trans-unit id="1efc80d653c0b8715eb15bdf1b19f3becd74a957" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Использовать ли раннюю остановку для прекращения обучения,когда оценка не улучшается.Если установлено значение True,то это автоматически откладывает часть тренировочных данных как валидацию и прекращает обучение,когда результат валидации не улучшается,по крайней мере,на n_iter_no_change последовательных эпох.</target>
        </trans-unit>
        <trans-unit id="9af303ba091050935df1b1843777cae63d69ca4c" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Следует ли использовать раннюю остановку для прекращения обучения, когда оценка валидации не улучшается. Если установлено значение true, он автоматически выделяет 10% обучающих данных в качестве проверки и прекращает обучение, если оценка проверки не улучшается по крайней мере на &lt;code&gt;tol&lt;/code&gt; для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных эпох. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="998484dc55c21823abb36e2b54f5b8f623a0a41f" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Следует ли использовать раннюю остановку для прекращения обучения, когда оценка валидации не улучшается. Если установлено значение true, он автоматически выделяет 10% обучающих данных в качестве проверки и прекращает обучение, если оценка проверки не улучшается по крайней мере на tol для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных эпох. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="cec695b146ca339e70be6934dce1a5005aa741f4" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Использовать ли раннюю остановку для прекращения тренировок при проверке.оценка не улучшается.Если установлено значение True,то это автоматически откладывает часть тренировочных данных как валидацию и прекращает обучение,когда результат валидации не улучшается,по крайней мере,допустимо для n_iter_no_change последовательных эпох.</target>
        </trans-unit>
        <trans-unit id="aad0324e5e5b11eda436b08ef9513e34456be6fd" translate="yes" xml:space="preserve">
          <source>Whether to use mini-batch k-means, which is faster but may get different results.</source>
          <target state="translated">Использовать ли мини-компоненты k-средств,что быстрее,но может дать разные результаты.</target>
        </trans-unit>
        <trans-unit id="098e9f05a9707c21daca2709c375c5f67a6fc326" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">Использовать ли нестандартные выборки для оценки R^2 на невидимых данных.</target>
        </trans-unit>
        <trans-unit id="cf1378e2f07c46392b05b68a8d3fb4a1b87de256" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization accuracy.</source>
          <target state="translated">Использовать ли нестандартные образцы для оценки точности обобщения.</target>
        </trans-unit>
        <trans-unit id="b9d7a8d80bd713aecc3b75a6342d626d4ac28b69" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization error.</source>
          <target state="translated">Использовать ли нестандартные примеры для оценки погрешности обобщения.</target>
        </trans-unit>
        <trans-unit id="3aa24f38e2caae33363ee03e7cecc2915d7b4a6e" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic.</source>
          <target state="translated">Использовать ли сокращающуюся эвристику.</target>
        </trans-unit>
        <trans-unit id="0fcee6cb3493ee9e39e4cf5b70ffc63bc5b7fc72" translate="yes" xml:space="preserve">
          <source>Whether to zip the stored data on disk. If an integer is given, it should be between 1 and 9, and sets the amount of compression. Note that compressed arrays cannot be read by memmapping.</source>
          <target state="translated">Следует ли заархивировать сохраненные на диске данные.Если задано целое число,то оно должно быть между 1 и 9 и задает степень сжатия.Обратите внимание,что сжатые массивы не могут быть прочитаны путем запоминания.</target>
        </trans-unit>
        <trans-unit id="a8c18609d5573425cb13e22e1562611896bad931" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices. True by default.</source>
          <target state="translated">Должна ли трансформация производить scipy.редкие матрицы.По умолчанию верно.</target>
        </trans-unit>
        <trans-unit id="96e3c213b0373954a6f42c2953a288bf58e9c8e1" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not a proper probability. If True, the smallest value in y_prob is mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">Нужно ли нормировать y_prob в бине [0,1],т.е.не является правильной вероятностью.Если True,то наименьшее значение в y_prob отображается на 0,а наибольшее-на 1.</target>
        </trans-unit>
        <trans-unit id="673ccf9c3156ee120e948d124a09a8f79d0986df" translate="yes" xml:space="preserve">
          <source>Which SVD method to use. If &amp;lsquo;lapack&amp;rsquo; use standard SVD from scipy.linalg, if &amp;lsquo;randomized&amp;rsquo; use fast &lt;code&gt;randomized_svd&lt;/code&gt; function. Defaults to &amp;lsquo;randomized&amp;rsquo;. For most applications &amp;lsquo;randomized&amp;rsquo; will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for &lt;code&gt;iterated_power&lt;/code&gt;. If this is not sufficient, for maximum precision you should choose &amp;lsquo;lapack&amp;rsquo;.</source>
          <target state="translated">Какой метод СВД использовать. Если &quot;Lapack&quot; использует стандартный SVD из scipy.linalg, если &quot;randomized&quot;, используйте быструю функцию &lt;code&gt;randomized_svd&lt;/code&gt; . По умолчанию &quot;рандомизировано&quot;. Для большинства приложений &amp;laquo;рандомизация&amp;raquo; будет достаточно точной, но при этом обеспечит значительный прирост скорости. Точность также можно повысить, установив более высокие значения для &lt;code&gt;iterated_power&lt;/code&gt; . Если этого недостаточно, для максимальной точности следует выбрать &amp;laquo;лапак&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="f51286fa5438dabdb2fdc9e6a35c79244bd208d2" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &lt;code&gt;precomputed&lt;/code&gt; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &lt;code&gt;euclidean&lt;/code&gt; uses the negative squared euclidean distance between points.</source>
          <target state="translated">Какое сходство использовать. На данный момент поддерживаются &lt;code&gt;precomputed&lt;/code&gt; и &lt;code&gt;euclidean&lt;/code&gt; . &lt;code&gt;euclidean&lt;/code&gt; использует отрицательный квадрат евклидова расстояния между точками.</target>
        </trans-unit>
        <trans-unit id="0a291d7f5d694ce4dae77d370f938e385f2f41cf" translate="yes" xml:space="preserve">
          <source>Which kind of estimators should be returned. If None, no filter is applied and all estimators are returned. Possible values are &amp;lsquo;classifier&amp;rsquo;, &amp;lsquo;regressor&amp;rsquo;, &amp;lsquo;cluster&amp;rsquo; and &amp;lsquo;transformer&amp;rsquo; to get estimators only of these specific types, or a list of these to get the estimators that fit at least one of the types.</source>
          <target state="translated">Какие оценщики нужно вернуть. Если Нет, фильтр не применяется, и возвращаются все оценки. Возможные значения: &amp;laquo;классификатор&amp;raquo;, &amp;laquo;регрессор&amp;raquo;, &amp;laquo;кластер&amp;raquo; и &amp;laquo;преобразователь&amp;raquo;, чтобы получить оценщики только этих конкретных типов, или их список, чтобы получить оценщики, соответствующие хотя бы одному из типов.</target>
        </trans-unit>
        <trans-unit id="9ab873abc046d5e79c6628d1e73d15a9a8c8a011" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Какой критерий связи использовать.Критерий связи определяет,какое расстояние использовать между наборами функций.Алгоритм объединит пары кластеров,которые минимизируют этот критерий.</target>
        </trans-unit>
        <trans-unit id="17ba6fc895d15866ea1e60a4db791726755dc58f" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Какой критерий связи использовать.Критерий связи определяет,какое расстояние использовать между наборами наблюдений.Алгоритм объединит пары кластеров,которые минимизируют этот критерий.</target>
        </trans-unit>
        <trans-unit id="7ca40022d1c5dcd68056f855d9cb29fbb48c9062" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgement: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">Какая модель является лучшей-это вопрос субъективного суждения:хотим ли мы отдавать предпочтение моделям,которые только захватывают большую картину,чтобы суммировать и объяснить большую часть структуры данных,игнорируя при этом детали,или же мы предпочитаем модели,которые близко следуют за областями высокой плотности сигнала?</target>
        </trans-unit>
        <trans-unit id="e8cddae54ed0b1b16ee030ff58543e83ff547ded" translate="yes" xml:space="preserve">
          <source>While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.</source>
          <target state="translated">В то время как Isomap,LLE и варианты лучше всего подходят для разворачивания одного непрерывного низкоразмерного коллектора,t-SNE сосредоточится на локальной структуре данных и будет стремиться к извлечению кластеризованных локальных групп образцов,как показано на примере S-образной кривой.Такая возможность группировать образцы на основе локальной структуры может быть полезна для визуального разворачивания набора данных,который состоит из нескольких коллекторов одновременно,как это происходит в наборе цифровых данных.</target>
        </trans-unit>
        <trans-unit id="d80a7676bafb31f5f9bcb99f7aed7e1817a9d535" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">В то время как модели SVM, полученные из &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; и &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear,&lt;/a&gt; используют &lt;code&gt;C&lt;/code&gt; в качестве параметра регуляризации, большинство других оценщиков используют &lt;code&gt;alpha&lt;/code&gt; . Точная эквивалентность между степенью регуляризации двух моделей зависит от точной целевой функции, оптимизированной моделью. Например, когда используется &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; регрессии sklearn.linear_model.Ridge , отношение между ними задается как \ (C = \ frac {1} {alpha} \).</target>
        </trans-unit>
        <trans-unit id="c20daeb41107431c48223b43ad4fe138aa4845d5" translate="yes" xml:space="preserve">
          <source>While experimenting with any learning algorithm, it is important not to test the prediction of an estimator on the data used to fit the estimator as this would not be evaluating the performance of the estimator on &lt;strong&gt;new data&lt;/strong&gt;. This is why datasets are often split into &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; data.</source>
          <target state="translated">Экспериментируя с любым алгоритмом обучения, важно не тестировать предсказание оценщика на данных, используемых для соответствия оценщику, так как это не будет оценивать производительность оценщика на &lt;strong&gt;новых данных&lt;/strong&gt; . Вот почему наборы данных часто разделяются на данные для &lt;em&gt;обучения&lt;/em&gt; и &lt;em&gt;тестирования&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="d04cd5b9d0463d9bc89f841d571873fec4953569" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it&amp;rsquo;s safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt; Similarly if we know that the generative process has a group structure (samples from collected from different subjects, experiments, measurement devices) it safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">Хотя данные iid являются распространенным предположением в теории машинного обучения, на практике оно редко выполняется. Если один знает , что образцы были получены с использованием процесса , зависящих от времени, это безопаснее использовать &lt;a href=&quot;#timeseries-cv&quot;&gt;осведомленный схемы кросс-валидации временных рядов&lt;/a&gt; Аналогично , если мы знаем , что порождающий процесс имеет структуру группы (образцы из собраны из разных предметов, экспериментов , измерительные устройства) безопаснее использовать &lt;a href=&quot;#group-cv&quot;&gt;групповую перекрестную проверку&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0526a7a936d1a8c691dcdaa23691304fc8ebc7ef" translate="yes" xml:space="preserve">
          <source>While in the spirit of an online algorithm, the class &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt; does not implement &lt;code&gt;partial_fit&lt;/code&gt; because the algorithm is online along the features direction, not the samples direction.</source>
          <target state="translated">В духе интерактивного алгоритма класс &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; не реализует &lt;code&gt;partial_fit&lt;/code&gt; , потому что алгоритм находится в оперативном режиме по направлению функций, а не по направлению выборки.</target>
        </trans-unit>
        <trans-unit id="c8d4a37562dd2bb8e9910fd82f43df80f682c63a" translate="yes" xml:space="preserve">
          <source>While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the &amp;lsquo;weight&amp;rsquo; axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.</source>
          <target state="translated">Хотя многие алгоритмы (такие как SVM, K-ближайших соседей и логистическая регрессия) требуют нормализации функций, интуитивно мы можем рассматривать анализ основных компонентов (PCA) как яркий пример того, когда важна нормализация. В PCA нас интересуют компоненты, которые увеличивают дисперсию. Если один компонент (например, рост человека) меняется меньше, чем другой (например, вес) из-за их соответствующих масштабов (метры против килограммов), PCA может определить, что направление максимальной дисперсии более точно соответствует оси &amp;laquo;веса&amp;raquo;, если эти характеристики не масштабируются. Поскольку изменение роста на один метр может считаться гораздо более важным, чем изменение веса на один килограмм, это явно неверно.</target>
        </trans-unit>
        <trans-unit id="3e272f5577ff59f34cc0835d41b4f8bd0e7fa207" translate="yes" xml:space="preserve">
          <source>While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.</source>
          <target state="translated">В то время как модели,сохранённые с помощью одной версии scikit-learn,могут загружаться в других версиях,это совершенно не поддерживается и не рекомендуется.Следует также помнить,что операции,выполняемые с такими данными,могут дать разные и неожиданные результаты.</target>
        </trans-unit>
        <trans-unit id="5cdd1c0f02e03a5a1b156076678017404f8561ab" translate="yes" xml:space="preserve">
          <source>While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell &lt;code&gt;[i, j]&lt;/code&gt; has value 1 if sample &lt;code&gt;i&lt;/code&gt; has label &lt;code&gt;j&lt;/code&gt; and value 0 otherwise.</source>
          <target state="translated">В то время как многоклассовые данные предоставляются метрике, как двоичные цели, в виде массива меток классов, данные с несколькими метками указываются как индикаторная матрица, в которой ячейка &lt;code&gt;[i, j]&lt;/code&gt; имеет значение 1, если образец &lt;code&gt;i&lt;/code&gt; имеет метку &lt;code&gt;j&lt;/code&gt; , и значение 0 в противном случае. .</target>
        </trans-unit>
        <trans-unit id="ed422f68a65d31027201e13d55d1a7c59ba06f45" translate="yes" xml:space="preserve">
          <source>While not particularly fast to process, Python&amp;rsquo;s &lt;code&gt;dict&lt;/code&gt; has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.</source>
          <target state="translated">Хотя Python &lt;code&gt;dict&lt;/code&gt; не особенно быстро обрабатывается, он имеет преимущества в том, что он удобен в использовании, является разреженным (отсутствующие функции не нужно сохранять) и хранит имена функций в дополнение к значениям.</target>
        </trans-unit>
        <trans-unit id="6575e62afd8d9d86f5e5759f0c1f4bf12add49e4" translate="yes" xml:space="preserve">
          <source>While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.</source>
          <target state="translated">В то время как некоторая локальная информация о позиционировании может быть сохранена путем извлечения n-грамм вместо отдельных слов,мешок слов и мешок n-грамм разрушают большую часть внутренней структуры документа и,следовательно,большую часть смысла,несущего эту внутреннюю структуру.</target>
        </trans-unit>
        <trans-unit id="f9eb71a899b2efe02a5e86463ae919f1b60ed0f7" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any (sparse) feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">В то время как преобразователь &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; работает с любой (разреженной) матрицей признаков, рекомендуется использовать его для матриц tf &amp;ndash; idf вместо необработанных частотных подсчетов в настройке обработки LSA / документа. В частности, следует включить сублинейное масштабирование и обратную частоту документа ( &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ), чтобы приблизить значения функций к гауссовскому распределению, компенсируя ошибочные предположения LSA о текстовых данных.</target>
        </trans-unit>
        <trans-unit id="29a2650e25fbd5181744282ce886a2b96e4ac93d" translate="yes" xml:space="preserve">
          <source>While the above example sets the &lt;code&gt;standardize&lt;/code&gt; option to &lt;code&gt;False&lt;/code&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; will apply zero-mean, unit-variance normalization to the transformed output by default.</source>
          <target state="translated">В то время как в приведенном выше примере для параметра &lt;code&gt;standardize&lt;/code&gt; значение &lt;code&gt;False&lt;/code&gt; , &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; по умолчанию&lt;/a&gt; применяет нормализацию с нулевым средним и единичной дисперсией к преобразованному результату.</target>
        </trans-unit>
        <trans-unit id="e50cabfff84e84e9590f53c8299406f023e4e46d" translate="yes" xml:space="preserve">
          <source>While the hyperparameters chosen by optimizing LML have a considerable larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad) This undesirable effect is caused by the Laplace approximation used internally by GPC.</source>
          <target state="translated">В то время как гиперпараметры,выбранные при оптимизации LML,имеют значительно больший размер LML,они работают несколько хуже по лог-потере на тестовых данных.Из рисунка видно,что это происходит потому,что они демонстрируют резкое изменение вероятностей класса на границах класса (что хорошо),но предсказывают вероятности вблизи 0.5 расстояния от границ класса (что плохо)Этот нежелательный эффект вызван аппроксимацией Лапласа,используемой внутри GPC.</target>
        </trans-unit>
        <trans-unit id="17e6df329175ba9fee759ed839a4afe469b184fd" translate="yes" xml:space="preserve">
          <source>While the tf&amp;ndash;idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the &lt;code&gt;binary&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. In particular, some estimators such as &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf&amp;ndash;idf values while the binary occurrence info is more stable.</source>
          <target state="translated">Хотя нормализация tf &amp;ndash; idf часто бывает очень полезной, могут быть случаи, когда двоичные маркеры вхождения могут предложить лучшие функции. Этого можно достичь с помощью &lt;code&gt;binary&lt;/code&gt; параметра &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; . В частности, некоторые оценщики, такие как &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes,&lt;/a&gt; явно моделируют дискретные логические случайные величины. Кроме того, очень короткие тексты могут иметь зашумленные значения tf &amp;ndash; idf, тогда как двоичная информация о вхождении более стабильна.</target>
        </trans-unit>
        <trans-unit id="ed181b0221327c005991b804ef6da84808fa6b75" translate="yes" xml:space="preserve">
          <source>While these examples give some intuition about the algorithms, this intuition might not apply to very high dimensional data.</source>
          <target state="translated">Хотя эти примеры дают некоторое представление об алгоритмах,эта интуиция может не относиться к очень объемным данным.</target>
        </trans-unit>
        <trans-unit id="20e141fdf1f5d5d16051f029790d3b9e841c723d" translate="yes" xml:space="preserve">
          <source>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</source>
          <target state="translated">Хотя использование сетки настроек параметров в настоящее время является наиболее широко используемым методом оптимизации параметров, другие методы поиска обладают более благоприятными свойствами. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; реализует рандомизированный поиск по параметрам, где каждый параметр выбирается из распределения по возможным значениям параметров. У этого есть два основных преимущества перед исчерпывающим поиском:</target>
        </trans-unit>
        <trans-unit id="ae7c1638fd1917cb535ca7c68b4bd5f19a47ea30" translate="yes" xml:space="preserve">
          <source>White kernel.</source>
          <target state="translated">Белое ядро.</target>
        </trans-unit>
        <trans-unit id="6eaf9e8193566018ccba0d72a95d7647c23f2585" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.</source>
          <target state="translated">Отбеливание удалит некоторую информацию из преобразованного сигнала (шкалы относительной дисперсии компонентов),но может в какой-то момент улучшить точность прогнозирования последующих оценок,заставив их данные уважать некоторые жестко привязанные предположения.</target>
        </trans-unit>
        <trans-unit id="07aaa00ad7b994406ce70b8bd7598f7e15e6859a" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.</source>
          <target state="translated">Отбеливание удалит некоторую информацию из преобразованного сигнала (шкалы относительной дисперсии компонентов),но иногда может повысить точность прогнозирования последующих оценок,заставляя данные учитывать некоторые жестко установленные допущения.</target>
        </trans-unit>
        <trans-unit id="b5ed864ec9d16ad31c6639d1d4c3bf64e3372001" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Davies-Bouldin index.</source>
          <target state="translated">Запись в Википедии для индекса Дэвиса-Болдин.</target>
        </trans-unit>
        <trans-unit id="a0184957526e21d06d99d8f077fe30eb4aaec4f9" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for contingency matrix</source>
          <target state="translated">Запись в Википедии для матрицы непредвиденных обстоятельств</target>
        </trans-unit>
        <trans-unit id="55a3b17abc1268c1d436ba897c97b456b993b4ea" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the (normalized) Mutual Information</source>
          <target state="translated">Запись в Википедии для (нормализованной)взаимной информации</target>
        </trans-unit>
        <trans-unit id="1f069c9fec7504cb4f8a493de2e1b54ffc547081" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Adjusted Mutual Information</source>
          <target state="translated">Запись в Википедии для скорректированной взаимной информации</target>
        </trans-unit>
        <trans-unit id="ca2fe3eff096e2c0ff94d3c0f6ce61af74cc646f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Brier score.</source>
          <target state="translated">Запись в Википедии очков Брайера.</target>
        </trans-unit>
        <trans-unit id="ffd655e9eb3a21416da69aac696bc5ce043a000f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Cohen&amp;rsquo;s kappa.</source>
          <target state="translated">Запись в Википедии о каппе Коэна.</target>
        </trans-unit>
        <trans-unit id="8d8ae14fc3bcf00321ca2d4b9c37c609195c6275" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the F1-score</source>
          <target state="translated">Запись в Википедии для F1-экрана</target>
        </trans-unit>
        <trans-unit id="0d85777073541b6f8aecb3488f1962f6903fd77c" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Fowlkes-Mallows Index</source>
          <target state="translated">Вход в Википедию для Индекса Фаулкс Допусков</target>
        </trans-unit>
        <trans-unit id="738fb31d9583a6207339f58c0335e89437aa096f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Jaccard index</source>
          <target state="translated">Запись в Википедии для индекса Jaccard</target>
        </trans-unit>
        <trans-unit id="d69dce297a7e32abae3549494346594b424875bc" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Matthews Correlation Coefficient</source>
          <target state="translated">Запись в Википедии о коэффициенте корреляции Матфея</target>
        </trans-unit>
        <trans-unit id="d1c0692994293b3fef98ac5de7dd74e23175c8d1" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Precision and recall</source>
          <target state="translated">Запись в Википедии о Точности и Вспоминании</target>
        </trans-unit>
        <trans-unit id="6c2dd7ccbd3afed766d1ee6ce92b068445c27bbb" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Receiver operating characteristic</source>
          <target state="translated">Запись в Википедии об операционной характеристике приемника</target>
        </trans-unit>
        <trans-unit id="caae1d529b64ebeb0d4804273e9107122a389ac6" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the adjusted Rand index</source>
          <target state="translated">Запись в Википедии для скорректированного индекса Рэнда</target>
        </trans-unit>
        <trans-unit id="af0472efa729237e92d89bb05e9ca0c8e7f37b5f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Coefficient of determination</source>
          <target state="translated">Запись в Википедии о Коэффициенте определения</target>
        </trans-unit>
        <trans-unit id="e345be5719f19335870d8d3a8cdd20b6bd307aa0" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hamming distance</source>
          <target state="translated">Запись в Википедии о расстоянии до Хэмминга</target>
        </trans-unit>
        <trans-unit id="1857fa6b095ad66d104ea60f4be3df45f12529a3" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hinge loss</source>
          <target state="translated">Запись в Википедии о потере шарнира</target>
        </trans-unit>
        <trans-unit id="d4ccd1b47442c7552ebe73794cdd38515c5ffdef" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Lasso</source>
          <target state="translated">Запись в Википедии о Лассо</target>
        </trans-unit>
        <trans-unit id="8751f23b19110bb289e70c6d8c900548f6c9b761" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Least-angle regression</source>
          <target state="translated">Запись в Википедии о регрессии по наименее развитым уголкам</target>
        </trans-unit>
        <trans-unit id="ed8f4a303fe71f9ad0ec1e1b74ef6fe644dad80d" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Silhouette Coefficient</source>
          <target state="translated">Запись в Википедии о коэффициенте силуэта</target>
        </trans-unit>
        <trans-unit id="0b665174747365aef367583fb0c32fb021d06a22" translate="yes" xml:space="preserve">
          <source>Wikipedia principal eigenvector</source>
          <target state="translated">Главный собачий вектор Википедии</target>
        </trans-unit>
        <trans-unit id="713348b23d025b202ea7f033591c046a82a1973b" translate="yes" xml:space="preserve">
          <source>Will be ignored when &lt;code&gt;y_true&lt;/code&gt; is binary.</source>
          <target state="translated">Будет игнорироваться, если &lt;code&gt;y_true&lt;/code&gt; является двоичным.</target>
        </trans-unit>
        <trans-unit id="af498f4dd6f24dbc1f93745e77fe6ed29d0b9d0c" translate="yes" xml:space="preserve">
          <source>Will return sparse matrix if set True else will return an array.</source>
          <target state="translated">Возвращает разреженную матрицу,если установлено значение True else,возвращает массив.</target>
        </trans-unit>
        <trans-unit id="f02c359862a5df44abc185413e06bdb77cfc5770" translate="yes" xml:space="preserve">
          <source>Williams, C.K.I. and Seeger, M. &amp;ldquo;Using the Nystroem method to speed up kernel machines&amp;rdquo;, Advances in neural information processing systems 2001</source>
          <target state="translated">Уильямс, CKI и Сигер, М. &amp;laquo;Использование метода Nystroem для ускорения ядерных машин&amp;raquo;, Успехи в системах обработки нейронной информации 2001</target>
        </trans-unit>
        <trans-unit id="a20af0cf6ba0496377888d152bfba536fcfdefc1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{\text{n\_classes}}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;adjusted=True&lt;/code&gt; , сбалансированная точность сообщает об относительном увеличении от \ (\ texttt {сбалансированная-точность} (y, \ mathbf {0}, w) = \ frac {1} {\ text {n \ _classes}}} \). В двоичном случае это также известно как &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* статистика Юдена *&lt;/a&gt; , или &lt;em&gt;информированность&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="8a7d860e7dc8979710329f97e747eaff0d3415d3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the input data.</source>
          <target state="translated">При &lt;code&gt;early_stopping=False&lt;/code&gt; модель подбирается для всех входных данных, а критерий остановки основан на целевой функции, вычисленной на входных данных.</target>
        </trans-unit>
        <trans-unit id="4ceb9e226f3e04a8a66252e3801eed93f740afd9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">При &lt;code&gt;early_stopping=True&lt;/code&gt; входные данные разделяются на обучающий набор и проверочный набор. Затем модель настраивается на обучающий набор, и критерий остановки основан на оценке прогноза, вычисленной на проверочном наборе. Размер набора проверки можно изменить с помощью параметра &lt;code&gt;validation_fraction&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="318aced6d4dfc924ad223bd54e79ede301143b06" translate="yes" xml:space="preserve">
          <source>With SGD or Adam, training supports online and mini-batch learning.</source>
          <target state="translated">С помощью SGD или Адама обучение поддерживается в режиме онлайн и в мини-группах.</target>
        </trans-unit>
        <trans-unit id="bebfaf6a5f7ee4311c7425773ef87a0b1b61dcc0" translate="yes" xml:space="preserve">
          <source>With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.</source>
          <target state="translated">При использовании SVM и логистической регрессии параметр C управляет редкостью:чем меньше C,тем меньше функций выбрано.С Lasso,чем выше альфа-параметр,тем меньше функций выбрано.</target>
        </trans-unit>
        <trans-unit id="2e07775067fbbb8cee792ed1d4b4b0282fd223be" translate="yes" xml:space="preserve">
          <source>With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:</source>
          <target state="translated">С \(P'(j)=|V_j|/N\).Взаимная информация (MI)между \(U\)и \(V\)рассчитывается по:</target>
        </trans-unit>
        <trans-unit id="5313dd287c9c493fc21b86c81282cea7d0608304" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image:</source>
          <target state="translated">С помощью агломеративной кластеризации можно указать,какие образцы могут быть сгруппированы вместе,предоставив график соединений.Графики в scikit-learn представлены их матрицей связности.Часто используется разреженная матрица.Это может быть полезно,например,для получения связанных областей (иногда также называемых связанными компонентами)при кластеризации изображения:</target>
        </trans-unit>
        <trans-unit id="ebae629f7af13ae26b867ab75161458173d10bdc" translate="yes" xml:space="preserve">
          <source>With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:</source>
          <target state="translated">Что касается деревьев принятия решений,то эта стратегия может быть легко использована для поддержки многопроизводительных задач.Это требует следующих изменений:</target>
        </trans-unit>
        <trans-unit id="d6eab2b8513179355ba20cab88473d0665849027" translate="yes" xml:space="preserve">
          <source>With such an abundance of clues that distinguish newsgroups, the classifiers barely have to identify topics from text at all, and they all perform at the same high level.</source>
          <target state="translated">При таком изобилии подсказок,отличающих новостные группы,классификаторам едва ли удается выделить темы из текста,и все они работают на одном и том же высоком уровне.</target>
        </trans-unit>
        <trans-unit id="ba25a12704b8225df22eb5cee35ebe73afb76c8b" translate="yes" xml:space="preserve">
          <source>With sum_over_features equal to False it returns the componentwise distances.</source>
          <target state="translated">С параметрами sum_over_features равными False он возвращает компонентные расстояния.</target>
        </trans-unit>
        <trans-unit id="03d84c3da120d3c6633bcd8017a1f00e1bb6dad8" translate="yes" xml:space="preserve">
          <source>With this class, the base_estimator is fit on the train set of the cross-validation generator and the test set is used for calibration. The probabilities for each of the folds are then averaged for prediction. In case that cv=&amp;rdquo;prefit&amp;rdquo; is passed to __init__, it is assumed that base_estimator has been fitted already and all data is used for calibration. Note that data for fitting the classifier and for calibrating it must be disjoint.</source>
          <target state="translated">С этим классом base_estimator подходит для набора поездов генератора перекрестной проверки, а набор тестов используется для калибровки. Вероятности для каждой из складок затем усредняются для прогноза. В случае, если cv = &amp;rdquo;prefit&amp;rdquo; передается в __init__, предполагается, что base_estimator уже настроен, и все данные используются для калибровки. Обратите внимание, что данные для подбора классификатора и для его калибровки не должны пересекаться.</target>
        </trans-unit>
        <trans-unit id="07ec442186310e3d4d8de1ef730f033183a12d2a" translate="yes" xml:space="preserve">
          <source>With this re-labeling of the data, our problem can be written</source>
          <target state="translated">При такой перемаркировке данных,наша проблема может быть записана...</target>
        </trans-unit>
        <trans-unit id="bb9dc2936468de0109f9958206c68ba68552df6f" translate="yes" xml:space="preserve">
          <source>With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a &lt;em&gt;KD-tree&lt;/em&gt; in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt;&lt;/a&gt;. Alternatively, the user can work with the &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class directly.</source>
          <target state="translated">При такой настройке одного расчета расстояния между контрольной точкой и центроидом достаточно, чтобы определить нижнюю и верхнюю границы расстояния до всех точек в узле. Из-за сферической геометрии узлов шарового дерева он может превзойти &lt;em&gt;KD-дерево&lt;/em&gt; в больших измерениях, хотя фактическая производительность сильно зависит от структуры обучающих данных. В scikit-learn поиск соседей на основе дерева мячей задается с помощью ключевого слова &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt; и вычисляется с использованием класса &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt; &lt;/a&gt; . В качестве альтернативы пользователь может напрямую работать с классом &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c5b891d6db4b2b53f2c329c62187e665d9759f8a" translate="yes" xml:space="preserve">
          <source>Without any prior information on the sample, the number of projections required to reconstruct the image is of the order of the linear size &lt;code&gt;l&lt;/code&gt; of the image (in pixels). For simplicity we consider here a sparse image, where only pixels on the boundary of objects have a non-zero value. Such data could correspond for example to a cellular material. Note however that most images are sparse in a different basis, such as the Haar wavelets. Only &lt;code&gt;l/7&lt;/code&gt; projections are acquired, therefore it is necessary to use prior information available on the sample (its sparsity): this is an example of &lt;strong&gt;compressive sensing&lt;/strong&gt;.</source>
          <target state="translated">Без какой-либо предварительной информации об образце количество проекций, необходимых для восстановления изображения, порядка линейного размера &lt;code&gt;l&lt;/code&gt; изображения (в пикселях). Для простоты мы рассматриваем здесь разреженное изображение, где только пиксели на границе объектов имеют ненулевое значение. Такие данные могут соответствовать, например, клеточному материалу. Обратите внимание, однако, что большинство изображений разрежены на другой основе, такой как вейвлеты Хаара. Только &lt;code&gt;l/7&lt;/code&gt; проекций приобретаются, поэтому необходимо использовать априорную информацию можно найти на образце (его разреженность): это пример &lt;strong&gt;сжимающего зондирования&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="087783a9ac4373b41b03a4f66d5eaf61d7d47ff1" translate="yes" xml:space="preserve">
          <source>Without reduce_func:</source>
          <target state="translated">Без reduce_func:</target>
        </trans-unit>
        <trans-unit id="e6002e635270be50830b0534ba0aafc304922d8b" translate="yes" xml:space="preserve">
          <source>Without shuffling, &lt;code&gt;X&lt;/code&gt; horizontally stacks features in the following order: the primary &lt;code&gt;n_informative&lt;/code&gt; features, followed by &lt;code&gt;n_redundant&lt;/code&gt; linear combinations of the informative features, followed by &lt;code&gt;n_repeated&lt;/code&gt; duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt;.</source>
          <target state="translated">Без перетасовки &lt;code&gt;X&lt;/code&gt; горизонтально складывает объекты в следующем порядке: первичные &lt;code&gt;n_informative&lt;/code&gt; признаки, за которыми следуют &lt;code&gt;n_redundant&lt;/code&gt; линейных комбинаций информативных признаков, за которыми следуют &lt;code&gt;n_repeated&lt;/code&gt; дубликаты, нарисованные случайным образом с заменой информативных и избыточных признаков. Остальные особенности заполнены случайным шумом. Таким образом, без перемешивания, все полезные функции содержатся в столбцах &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d2a146386973596d64e5c0f348ec45ab36bab658" translate="yes" xml:space="preserve">
          <source>Working With Text Data</source>
          <target state="translated">Работа с текстовыми данными</target>
        </trans-unit>
        <trans-unit id="5b5ef6667bd92ea247084ea267c265251f4aa7de" translate="yes" xml:space="preserve">
          <source>Works with sparse matrices. Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">Работает с разреженными матрицами. Работает только при &lt;code&gt;columns_&lt;/code&gt; атрибутов &lt;code&gt;rows_&lt;/code&gt; и columns_ .</target>
        </trans-unit>
        <trans-unit id="926da419b9cc98b9060a6d00fb8d48cd55be86f9" translate="yes" xml:space="preserve">
          <source>Wrapper for kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">Обертка для ядер в sklearn.metrics.pairwise.</target>
        </trans-unit>
        <trans-unit id="f986c2ac1f7dce99239d5b1ba2c2c97de265f3fa" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline to classify movie reviews as either positive or negative.</source>
          <target state="translated">Напишите текстовый конвейер классификации для классификации отзывов на фильмы как положительные или отрицательные.</target>
        </trans-unit>
        <trans-unit id="c1b32a0493a32a44864910f6b6b9c9398af4b20e" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline using a custom preprocessor and &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; using data from Wikipedia articles as training set.</source>
          <target state="translated">Напишите конвейер классификации текста с помощью настраиваемого препроцессора и &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; , используя данные из статей Википедии в качестве обучающего набора.</target>
        </trans-unit>
        <trans-unit id="c72e193d2469d6cfb2918ba7a00dbc8ed1d451d6" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Ву, Линь и Венг, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;laquo;Оценки вероятности многоклассовой классификации путем попарного связывания&amp;raquo;&lt;/a&gt; , JMLR 5: 975-1005, 2004.</target>
        </trans-unit>
        <trans-unit id="c8c1574205d07b839af62817660ba2b78f320cd0" translate="yes" xml:space="preserve">
          <source>X block loadings vectors.</source>
          <target state="translated">Векторы блокировки нагрузки Х.</target>
        </trans-unit>
        <trans-unit id="b8076ad410e1a569012d16107ff003e5d358439f" translate="yes" xml:space="preserve">
          <source>X block to latents rotations.</source>
          <target state="translated">Х-блок к скрытым вращениям.</target>
        </trans-unit>
        <trans-unit id="a6b8640132f42899bc713ee5acc307439a5b7049" translate="yes" xml:space="preserve">
          <source>X block weights vectors.</source>
          <target state="translated">Векторы веса блока Х.</target>
        </trans-unit>
        <trans-unit id="e6bc2e58339df2a473a9897261f25e31780f738c" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set.</source>
          <target state="translated">X проецируется на первые основные компоненты,ранее извлеченные из учебного набора.</target>
        </trans-unit>
        <trans-unit id="7228d382c859d348525ccb5bce51e5752c38bc04" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;code&gt;transform&lt;/code&gt; needs X to interpolate new input data.</source>
          <target state="translated">X сохраняется для будущего использования, поскольку &lt;code&gt;transform&lt;/code&gt; требуется X для интерполяции новых входных данных.</target>
        </trans-unit>
        <trans-unit id="3074bef8d8da5f206ce501f5438e3d5abb038064" translate="yes" xml:space="preserve">
          <source>X must have been produced by this DictVectorizer&amp;rsquo;s transform or fit_transform method; it may only have passed through transformers that preserve the number of features and their order.</source>
          <target state="translated">X должен быть создан с помощью метода преобразования или fit_transform этого DictVectorizer; он мог пройти только через трансформаторы, сохраняющие количество функций и их порядок.</target>
        </trans-unit>
        <trans-unit id="d0ad8e13f68af13dec8ad59c4f3a6a0df7a4de08" translate="yes" xml:space="preserve">
          <source>X scores.</source>
          <target state="translated">Х баллов.</target>
        </trans-unit>
        <trans-unit id="28a3e4c54c0fde2f1aaa67a11fe405d430c2fe41" translate="yes" xml:space="preserve">
          <source>X transformed in the new space.</source>
          <target state="translated">Икс трансформировался в новом пространстве.</target>
        </trans-unit>
        <trans-unit id="feedfda54d7431e28acb98075b2c2bd9cf8331f2" translate="yes" xml:space="preserve">
          <source>Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</source>
          <target state="translated">Сяоцзинь Чжу и Зубин Гахрамани. Изучение помеченных и немаркированных данных с распространением меток. Технический отчет CMU-CALD-02-107, Университет Карнеги-Меллона, 2002 г. &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5c986ee528dd9bdf7a6c8d0101f77976c47ae9d2" translate="yes" xml:space="preserve">
          <source>Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;Theil-Sen Estimators in a Multiple Linear Regression Model.&lt;/a&gt;</source>
          <target state="translated">Синь Данг, Ханьсян Пэн, Сюэцинь Ван и Хэпин Чжан: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;оценки Тейл-Сен в модели множественной линейной регрессии.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c93217dd923de34853280b8058e56203ef9ee737" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</source>
          <target state="translated">Xy=np.dot(X.T,y),которая может быть предварительно рассчитана.Это полезно только тогда,когда предварительно вычисляется грамм-матрица.</target>
        </trans-unit>
        <trans-unit id="23eb4d3f4155395a74e9d534f97ff4c1908f5aac" translate="yes" xml:space="preserve">
          <source>Y</source>
          <target state="translated">Y</target>
        </trans-unit>
        <trans-unit id="aac13ced89d2b311880e53ba16f36f4513402a98" translate="yes" xml:space="preserve">
          <source>Y block loadings vectors.</source>
          <target state="translated">Векторы блокировки нагрузки Y.</target>
        </trans-unit>
        <trans-unit id="148708c0aec99251158277d2fc4d038d62f32551" translate="yes" xml:space="preserve">
          <source>Y block to latents rotations.</source>
          <target state="translated">Блок Y-скрытые вращения.</target>
        </trans-unit>
        <trans-unit id="8f4ded8aca1a84f4452774f8bc622751045ade48" translate="yes" xml:space="preserve">
          <source>Y block weights vectors.</source>
          <target state="translated">Векторы веса блока Y.</target>
        </trans-unit>
        <trans-unit id="780dd8f1641062cfc0af001d2fcfedba3262be26" translate="yes" xml:space="preserve">
          <source>Y scores.</source>
          <target state="translated">Y баллов.</target>
        </trans-unit>
        <trans-unit id="93b5936ef31b077aecad8b961838c412166e9fd0" translate="yes" xml:space="preserve">
          <source>Y. Freund, R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting&amp;rdquo;, 1995.</source>
          <target state="translated">Ю. Фройнд, Р. Шапайр, &amp;laquo;Теоретико-решающее обобщение онлайн-обучения и его применение для повышения эффективности&amp;raquo;, 1995.</target>
        </trans-unit>
        <trans-unit id="bf931371fe813e68af145bc28f1f0c59ead42876" translate="yes" xml:space="preserve">
          <source>Y. Freund, and R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting&amp;rdquo;, 1997.</source>
          <target state="translated">Ю. Фройнд и Р. Шапайр, &amp;laquo;Теоретико-решающее обобщение онлайн-обучения и приложение для повышения эффективности&amp;raquo;, 1997.</target>
        </trans-unit>
        <trans-unit id="982b5c305af507a5853864a0280fe0330e5fb9d9" translate="yes" xml:space="preserve">
          <source>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</source>
          <target state="translated">Y[argmin[i],:]-это строка в Y,которая наиболее близка к X[i,:].</target>
        </trans-unit>
        <trans-unit id="3526f607bcd4f51ad0bc05f814579a42c2c0ba57" translate="yes" xml:space="preserve">
          <source>Yellow</source>
          <target state="translated">Yellow</target>
        </trans-unit>
        <trans-unit id="44e848b37858df8125129ee3d3911783b05fb21f" translate="yes" xml:space="preserve">
          <source>Yields indices to split data into training and test sets.</source>
          <target state="translated">Индексы урожайности для разделения данных на тренировочные и тестовые наборы.</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e285a8203a02b899c727c909bb971f8a5290d1a9" translate="yes" xml:space="preserve">
          <source>You can &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; over parameters of all estimators in the pipeline at once.</source>
          <target state="translated">Вы можете выполнять &lt;a href=&quot;grid_search#grid-search&quot;&gt;поиск&lt;/a&gt; по сетке сразу по параметрам всех оценщиков в конвейере.</target>
        </trans-unit>
        <trans-unit id="e4f0eb08d1e594cb4ba39dda583b2124c29e8d3e" translate="yes" xml:space="preserve">
          <source>You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them.</source>
          <target state="translated">Вы можете настроить количество категорий,дав их имена загрузчику набора данных или установив их в None,чтобы получить 20 из них.</target>
        </trans-unit>
        <trans-unit id="d6a91645b832623d5d5110588ef04aebdc451880" translate="yes" xml:space="preserve">
          <source>You can already copy the skeletons into a new folder somewhere on your hard-drive named &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; where you will edit your own files for the exercises while keeping the original skeletons intact:</source>
          <target state="translated">Вы уже можете скопировать скелеты в новую папку где-нибудь на вашем жестком диске с именем &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; , где вы будете редактировать свои собственные файлы для упражнений, сохраняя исходные скелеты нетронутыми:</target>
        </trans-unit>
        <trans-unit id="1cf0d94595a131d36f8236532aeafb049eaa6dbc" translate="yes" xml:space="preserve">
          <source>You can also specify both the name and the version, which also uniquely identifies the dataset:</source>
          <target state="translated">Вы также можете указать как имя,так и версию,которая также однозначно идентифицирует набор данных:</target>
        </trans-unit>
        <trans-unit id="ae5f0da778f6ff8c0d5d1c2ccd6f86bebea3d9e0" translate="yes" xml:space="preserve">
          <source>You can also use your own defined kernels by passing a function to the keyword &lt;code&gt;kernel&lt;/code&gt; in the constructor.</source>
          <target state="translated">Вы также можете использовать свои собственные определенные ядра, передав функцию ключевому слову &lt;code&gt;kernel&lt;/code&gt; в конструкторе.</target>
        </trans-unit>
        <trans-unit id="c90fd70bc9584ad72350fadce865213cd8c472be" translate="yes" xml:space="preserve">
          <source>You can combine &lt;code&gt;KBinsDiscretizer&lt;/code&gt; with &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; if you only want to preprocess part of the features.</source>
          <target state="translated">Вы можете комбинировать &lt;code&gt;KBinsDiscretizer&lt;/code&gt; с &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; ,&lt;/a&gt; если вы хотите предварительно обработать только часть функций.</target>
        </trans-unit>
        <trans-unit id="579522a3d8d5bf3b4958e7c2d681266388521dce" translate="yes" xml:space="preserve">
          <source>You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.</source>
          <target state="translated">Вы можете определить свои собственные ядра либо передав кернел в виде питоновой функции,либо предварительно вычислив матрицу Грама.</target>
        </trans-unit>
        <trans-unit id="5a14b3f83e3bd81fa3adef5b677dc7c591d450db" translate="yes" xml:space="preserve">
          <source>You can display the BLAS / LAPACK implementation used by your NumPy / SciPy / scikit-learn install with the following commands:</source>
          <target state="translated">Вы можете отобразить реализацию BLAS/LAPACK,используемую при установке NumPy/SciPy/scikit-learn со следующими командами:</target>
        </trans-unit>
        <trans-unit id="929abd63168ac2d721d4708b8ef8be3cd51b08a0" translate="yes" xml:space="preserve">
          <source>You can ensure that &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt; are the inverse of each other by setting &lt;code&gt;check_inverse=True&lt;/code&gt; and calling &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt;. Please note that a warning is raised and can be turned into an error with a &lt;code&gt;filterwarnings&lt;/code&gt;:</source>
          <target state="translated">Вы можете гарантировать, что &lt;code&gt;func&lt;/code&gt; и &lt;code&gt;inverse_func&lt;/code&gt; являются обратными друг другу, установив &lt;code&gt;check_inverse=True&lt;/code&gt; и вызвав &lt;code&gt;fit&lt;/code&gt; перед &lt;code&gt;transform&lt;/code&gt; . Обратите внимание, что появляется предупреждение, которое может быть преобразовано в ошибку с помощью &lt;code&gt;filterwarnings&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="8fe8cd91261eb27750ae7b2f82fa15c24077f346" translate="yes" xml:space="preserve">
          <source>You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt; factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:</source>
          <target state="translated">Вы можете создавать еще более гибкие модели скоринга, &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; свой собственный скоринговый объект с нуля, без использования фабрики make_scorer . Чтобы вызываемый может быть бомбардиром, он должен соответствовать протоколу, определенному следующими двумя правилами:</target>
        </trans-unit>
        <trans-unit id="cb07d258c61c328d902779de990b642f82ba2beb" translate="yes" xml:space="preserve">
          <source>You can get more information on the dataset by looking at the &lt;code&gt;DESCR&lt;/code&gt; and &lt;code&gt;details&lt;/code&gt; attributes:</source>
          <target state="translated">Вы можете получить дополнительную информацию о наборе данных, просмотрев &lt;code&gt;DESCR&lt;/code&gt; и &lt;code&gt;details&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="316dc294ff0e2890db335b30189c691f1a723809" translate="yes" xml:space="preserve">
          <source>You can now see many things that these features have overfit to:</source>
          <target state="translated">Теперь вы можете видеть много вещей,к которым эти функции имеют переоснащение:</target>
        </trans-unit>
        <trans-unit id="ee86b8b814976ee239ecfc8e86907133be9d3afc" translate="yes" xml:space="preserve">
          <source>You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the &lt;code&gt;n_features&lt;/code&gt; parameter.</source>
          <target state="translated">Вы можете видеть, что в векторных выходных данных было извлечено 16 ненулевых маркеров функций: это меньше, чем 19 ненулевых &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; извлеченных ранее CountVectorizer в том же корпусе игрушек. Несоответствие происходит из-за конфликтов хэш-функций из-за низкого значения параметра &lt;code&gt;n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c31033fd31d22147ea7534b97a7d63f646fe3e48" translate="yes" xml:space="preserve">
          <source>You can then edit the content of the workspace without fear of losing the original exercise instructions.</source>
          <target state="translated">После этого вы можете редактировать содержимое рабочего пространства,не опасаясь потерять исходные инструкции по выполнению упражнений.</target>
        </trans-unit>
        <trans-unit id="e21dcf7dc4d8353d8949b3e6ddc2c35c364a9b4a" translate="yes" xml:space="preserve">
          <source>You cannot nest objects with parallel computing (&lt;code&gt;n_jobs&lt;/code&gt; different than 1).</source>
          <target state="translated">Вы не можете &lt;code&gt;n_jobs&lt;/code&gt; объекты с параллельными вычислениями ( n_jobs отличное от 1).</target>
        </trans-unit>
        <trans-unit id="d086a1b811e8ad563a3cd7d98758c535aff811c7" translate="yes" xml:space="preserve">
          <source>You could try UTF-8 and disregard the errors. You can decode byte strings with &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; to replace all decoding errors with a meaningless character, or set &lt;code&gt;decode_error='replace'&lt;/code&gt; in the vectorizer. This may damage the usefulness of your features.</source>
          <target state="translated">Вы можете попробовать UTF-8 и не обращать внимания на ошибки. Вы можете декодировать байтовые строки с помощью &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; чтобы заменить все ошибки декодирования бессмысленным символом, или установить &lt;code&gt;decode_error='replace'&lt;/code&gt; в векторизаторе. Это может повредить полезности ваших функций.</target>
        </trans-unit>
        <trans-unit id="c0d5a5afa92ed6aa301d13299623473f530c94ba" translate="yes" xml:space="preserve">
          <source>You may also load two (or more) datasets at once:</source>
          <target state="translated">Вы также можете загружать два (или более)набора данных одновременно:</target>
        </trans-unit>
        <trans-unit id="a822ec525f0ce269b9b885feec474e1f8b512e04" translate="yes" xml:space="preserve">
          <source>You may also retain the estimator fitted on each training set by setting &lt;code&gt;return_estimator=True&lt;/code&gt;.</source>
          <target state="translated">Вы также можете сохранить оценщик, установленный на каждом обучающем наборе, установив &lt;code&gt;return_estimator=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c9bcd37e9efb4d07a927274f7ad017afc3f094c8" translate="yes" xml:space="preserve">
          <source>You may be able to find out what kind of encoding it is in general using the UNIX command &lt;code&gt;file&lt;/code&gt;. The Python &lt;code&gt;chardet&lt;/code&gt; module comes with a script called &lt;code&gt;chardetect.py&lt;/code&gt; that will guess the specific encoding, though you cannot rely on its guess being correct.</source>
          <target state="translated">Вы можете узнать, что это за кодировка в целом, с помощью командного &lt;code&gt;file&lt;/code&gt; UNIX . Модуль Python &lt;code&gt;chardet&lt;/code&gt; поставляется со скриптом под названием &lt;code&gt;chardetect.py&lt;/code&gt; , который угадывает конкретную кодировку, хотя вы не можете полагаться на его правильность.</target>
        </trans-unit>
        <trans-unit id="04405b99190799597dab92e2ef615219d1447404" translate="yes" xml:space="preserve">
          <source>You may load a dataset like as follows:</source>
          <target state="translated">Вы можете загрузить набор данных следующим образом:</target>
        </trans-unit>
        <trans-unit id="f9f71500b978e09c529098f893f05269c79caaff" translate="yes" xml:space="preserve">
          <source>You may want to include the parameters of the preprocessors in a &lt;a href=&quot;grid_search#grid-search&quot;&gt;parameter search&lt;/a&gt;.</source>
          <target state="translated">Вы можете включить параметры препроцессоров в &lt;a href=&quot;grid_search#grid-search&quot;&gt;поиск параметров&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4cbe0908270a3a4effe7f03ed10c6fc1b573bdb1" translate="yes" xml:space="preserve">
          <source>You might get slightly different results with the solver liblinear than with the others since this uses LIBLINEAR which penalizes the intercept.</source>
          <target state="translated">Вы можете получить немного другие результаты с solver liblinear,чем с другими,так как это использует LIBLINEAR,который наказывает перехват.</target>
        </trans-unit>
        <trans-unit id="eacc5e93bbce61c3d762f60af9c0b85d6ab90006" translate="yes" xml:space="preserve">
          <source>You might have noticed that the samples were shuffled randomly when we called &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt;: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.</source>
          <target state="translated">Вы могли заметить, что образцы были перемешаны случайным образом, когда мы вызывали &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt; : это полезно, если вы хотите выбрать только подмножество образцов, чтобы быстро обучить модель и получить первую представление результатов перед повторным обучением на полном наборе данных позже.</target>
        </trans-unit>
        <trans-unit id="1c0c1bb33d891f47deca1c516d19aa08bd8443b9" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">Вам нужно только один раз вызвать &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; свои данные, чтобы соответствовать всей последовательности оценщиков.</target>
        </trans-unit>
        <trans-unit id="8f00f0e599f4c3a7b71dcab47e41c43fc685f526" translate="yes" xml:space="preserve">
          <source>You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is split into &lt;em&gt;we&lt;/em&gt; and &lt;em&gt;ve&lt;/em&gt; by CountVectorizer&amp;rsquo;s default tokenizer, so if &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is in &lt;code&gt;stop_words&lt;/code&gt;, but &lt;em&gt;ve&lt;/em&gt; is not, &lt;em&gt;ve&lt;/em&gt; will be retained from &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.</source>
          <target state="translated">Вы также должны убедиться, что в списке стоп-слов была применена такая же предварительная обработка и токенизация, как и в векторизаторе. Слово &lt;em&gt;мы&lt;/em&gt; в расщепляется на &lt;em&gt;мы&lt;/em&gt; и &lt;em&gt;ве&lt;/em&gt; по умолчанию Tokenizer CountVectorizer, поэтому , если &lt;em&gt;мы&lt;/em&gt; в в &lt;code&gt;stop_words&lt;/code&gt; , но &lt;em&gt;ве&lt;/em&gt; не является, &lt;em&gt;ве&lt;/em&gt; будет удерживаться от &lt;em&gt;мы&lt;/em&gt; в в преобразованном тексте. Наши векторизаторы попытаются выявить некоторые несоответствия и предупредить о них.</target>
        </trans-unit>
        <trans-unit id="03e4dbf3891b38cb2bcd04772f91e994b5e9c01b" translate="yes" xml:space="preserve">
          <source>Your dataset consists of heterogeneous data types (e.g. raster images and text captions)</source>
          <target state="translated">Ваш набор данных состоит из разнородных типов данных (например,растровые изображения и текстовые подписи).</target>
        </trans-unit>
        <trans-unit id="7b0a68e70dc900bed821b4c342a07edfa667e451" translate="yes" xml:space="preserve">
          <source>Your dataset is stored in a Pandas DataFrame and different columns require different processing pipelines.</source>
          <target state="translated">Ваш набор данных хранится в фрейме Pandas DataFrame,и различные столбцы требуют различных трубопроводов обработки.</target>
        </trans-unit>
        <trans-unit id="cf246e4fd612425ede440737acf49a3220f42916" translate="yes" xml:space="preserve">
          <source>Your kernel must take as arguments two matrices of shape &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt;, &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; and return a kernel matrix of shape &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt;.</source>
          <target state="translated">Ваше ядро ​​должно принимать в качестве аргументов две матрицы формы &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt; , &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; и возвращать матрицу ядра формы &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a97cec9f16597107c699027a6e02cf1c0426b74a" translate="yes" xml:space="preserve">
          <source>ZN proportion of residential land zoned for lots over 25,000 sq.ft.</source>
          <target state="translated">ZN доля жилой земли,районированной на участки площадью более 25 000 кв.футов.</target>
        </trans-unit>
        <trans-unit id="712d097b167e76a6e9d59b3e5e274cb4dc4edfe4" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;lsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Задрозный и Элькан, &amp;laquo;Преобразование оценок классификатора в оценки вероятности нескольких классов&amp;raquo;, SIGKDD'02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f05a65af97509516c00dcac126500e3f1415b5be" translate="yes" xml:space="preserve">
          <source>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Нулевой коэффициент для полиномиальных и сигмовидных ядер.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="e35caa5ca631cf4323249c1e10ca37b600a29376" translate="yes" xml:space="preserve">
          <source>Zero is the lowest possible score. Values closer to zero indicate a better partition.</source>
          <target state="translated">Ноль-это минимально возможный балл.Значения ближе к нулю указывают на лучшее разделение.</target>
        </trans-unit>
        <trans-unit id="4196df3003bc4705f3359c145eca39ac9042a13b" translate="yes" xml:space="preserve">
          <source>Zero-one classification loss.</source>
          <target state="translated">Нулевая потеря классификации.</target>
        </trans-unit>
        <trans-unit id="ee137211a128584365e4b492f8f1e31e317a831d" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Чжан Дж. И Маршалек М. и Лазебник С. и Шмид К. Локальные особенности и ядра для классификации текстур и категорий объектов: комплексное исследование International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/ ru-ru / um / people / manik / projects / trade-off / paper / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f2ef1b5180fd57b17245a5c505519733d35270d" translate="yes" xml:space="preserve">
          <source>Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Чжу, Х. Цзоу, С. Россет, Т. Хасти, &amp;laquo;Мультиклассовый AdaBoost&amp;raquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="8ce45cc584babf565a133f667c041638840fdfd3" translate="yes" xml:space="preserve">
          <source>Zoubir A., Koivunen V., Chakhchoukh Y. and Muma M. (2012). Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts. IEEE Signal Processing Magazine 29(4), 61-80.</source>
          <target state="translated">Зоубир А.,Койвунен В.,Чахчух Ю.и Мума М.(2012).Надежная оценка при обработке сигналов:Учебно-методическая трактовка фундаментальных понятий.Журнал по обработке сигналов IEEE 29(4),61-80.</target>
        </trans-unit>
        <trans-unit id="cd3417b4282b09dc45879fe7c77bee8859983780" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['rbf', 'сигмоид', 'полином', 'поли', 'линейный', 'косинус']</target>
        </trans-unit>
        <trans-unit id="7c0453b88eaf6a5b1a0ac2faa1dec6c20e0dda6a" translate="yes" xml:space="preserve">
          <source>[1, x_2, x_2 ** 2, x_2 ** 3, &amp;hellip;], &amp;hellip;]</source>
          <target state="translated">[1, x_2, x_2 ** 2, x_2 ** 3,&amp;hellip;],&amp;hellip;]</target>
        </trans-unit>
        <trans-unit id="af237073ca841ce40d3b1c3f9ec3b84ba9e8c1ce" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Online Learning for Latent Dirichlet Allocation&amp;rdquo;, Matthew D. Hoffman,</source>
          <target state="translated">[1] &amp;laquo;Онлайн-обучение скрытому распределению Дирихле&amp;raquo;, Мэтью Д. Хоффман,</target>
        </trans-unit>
        <trans-unit id="a5828c16246e11e0eda2596d27fdd402ee57d009" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">[1] &amp;laquo;Алгоритмы сжатия для оценки ковариации MMSE&amp;raquo; Чен и др., IEEE Trans. на знак. Proc., Volume 58, Issue 10, October 2010.</target>
        </trans-unit>
        <trans-unit id="c5ae55965c66d78c700f954c5d28c9832964e702" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] &amp;laquo;Взвешенные суммы случайных кухонных раковин: замена минимизации рандомизацией в обучении&amp;raquo; А. Рахими и Бенджамина Рехта. ( &lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="851ede0920efe80a8308115ddfdc22058d99b224" translate="yes" xml:space="preserve">
          <source>[1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for</source>
          <target state="translated">[1] Hinton, GE, Osindero, S. и Teh, Y. Алгоритм быстрого обучения для</target>
        </trans-unit>
        <trans-unit id="c4ab6918e1971671fbb440a7f8e61bfcc4315791" translate="yes" xml:space="preserve">
          <source>[1] P. J. Rousseeuw. Least median of squares regression. J. Am</source>
          <target state="translated">[1] PJ Rousseeuw. Наименьшая медиана квадратов регрессии. Варенье</target>
        </trans-unit>
        <trans-unit id="4becf43125cdaf0ec29f63ac1f954b679ab8e6bc" translate="yes" xml:space="preserve">
          <source>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</source>
          <target state="translated">[1] Йошуа Бенжио, Оливье Делалло, Николя Ле Ру. In Semi-Supervised Learning (2006), pp. 193-216.</target>
        </trans-unit>
        <trans-unit id="9a201577697a06c9ac689a946ae70d44d48c0e7c" translate="yes" xml:space="preserve">
          <source>[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data</source>
          <target state="translated">[1] ван дер Маатен, ЛДП; Хинтон, GE Визуализация многомерных данных</target>
        </trans-unit>
        <trans-unit id="8eeff125eef3cfca1ff3f8b3157054b95e0b3509" translate="yes" xml:space="preserve">
          <source>[2] &amp;ldquo;Stochastic Variational Inference&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</source>
          <target state="translated">[2] &amp;laquo;Стохастический вариационный вывод&amp;raquo;, Мэтью Д. Хоффман, Дэвид М. Блей,</target>
        </trans-unit>
        <trans-unit id="ea3c887d7b7624a41f686043b166f388d3617ff3" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Оливье Делалло, Йошуа Бенжио, Николя Ле Ру. Эффективная индукция непараметрических функций при полу-контролируемом обучении. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="390f7912993134abee39b500fe8ff987c558bcc7" translate="yes" xml:space="preserve">
          <source>[2] Tieleman, T. Training Restricted Boltzmann Machines using</source>
          <target state="translated">[2] Тилеман, Т. Тренировка машин Больцмана с ограничениями с использованием</target>
        </trans-unit>
        <trans-unit id="936e8131576c3002ff436671f77d81f6c95e71d7" translate="yes" xml:space="preserve">
          <source>[2] Wilson, E. B., &amp;amp; Hilferty, M. M. (1931). The distribution of chi-square.</source>
          <target state="translated">[2] Уилсон, Э.Б., и Хильферти, М.М. (1931). Распределение хи-квадрат.</target>
        </trans-unit>
        <trans-unit id="5cccbf6c7fe7c1f50410b68e37c12f00b67f9330" translate="yes" xml:space="preserve">
          <source>[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding</source>
          <target state="translated">[2] ван дер Маатен, LJP t-Распределенное стохастическое соседнее вложение.</target>
        </trans-unit>
        <trans-unit id="740947d1c8302c56dc8a9209234aab173f75acad" translate="yes" xml:space="preserve">
          <source>[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.</source>
          <target state="translated">[3] LJP van der Maaten. Ускорение t-SNE с использованием древовидных алгоритмов.</target>
        </trans-unit>
        <trans-unit id="a16dde9090b3c419b1ba6d8027b90785ddf73263" translate="yes" xml:space="preserve">
          <source>[3] Matthew D. Hoffman&amp;rsquo;s onlineldavb code. Link:</source>
          <target state="translated">[3] Онлайн-код Мэтью Д. Хоффмана. Ссылка на сайт:</target>
        </trans-unit>
        <trans-unit id="2091fb37b7afd77ae2e8e60855d4cad2538ba378" translate="yes" xml:space="preserve">
          <source>[B1996]</source>
          <target state="translated">[B1996]</target>
        </trans-unit>
        <trans-unit id="66fa89cedf249bba6f8bbd7ca59a6edba1eb2520" translate="yes" xml:space="preserve">
          <source>[B1998]</source>
          <target state="translated">[B1998]</target>
        </trans-unit>
        <trans-unit id="7665023d9511c3ea5a7a3e7baca06057eba900d6" translate="yes" xml:space="preserve">
          <source>[B1999]</source>
          <target state="translated">[B1999]</target>
        </trans-unit>
        <trans-unit id="5c075f95c1e65a7e49dec5ad30ee36d1fb13b2b6" translate="yes" xml:space="preserve">
          <source>[B2001]</source>
          <target state="translated">[B2001]</target>
        </trans-unit>
        <trans-unit id="04bec92cc809290da2bf608da574e1877293633f" translate="yes" xml:space="preserve">
          <source>[B2011]</source>
          <target state="translated">[B2011]</target>
        </trans-unit>
        <trans-unit id="2b6c9f7f2623b948c281da789073abc37bb7f8fa" translate="yes" xml:space="preserve">
          <source>[ButlerDavies]</source>
          <target state="translated">[ButlerDavies]</target>
        </trans-unit>
        <trans-unit id="1d442f2d1661e89f1bc869a582a8d649d24881e4" translate="yes" xml:space="preserve">
          <source>[D1997]</source>
          <target state="translated">[D1997]</target>
        </trans-unit>
        <trans-unit id="20e70caf2f764d35f0c5f51eb6c2cc52a6f947f2" translate="yes" xml:space="preserve">
          <source>[Davis2006]</source>
          <target state="translated">[Davis2006]</target>
        </trans-unit>
        <trans-unit id="3b0f17e8250c1e7b54512123b77c31bb0899ae7a" translate="yes" xml:space="preserve">
          <source>[Everingham2010]</source>
          <target state="translated">[Everingham2010]</target>
        </trans-unit>
        <trans-unit id="e5ff04dac92d8d5710e2d4ade54a4899d9a01662" translate="yes" xml:space="preserve">
          <source>[F1999]</source>
          <target state="translated">[F1999]</target>
        </trans-unit>
        <trans-unit id="ddfaba8b68f822d387eefcc49dbcf89bee83fcbe" translate="yes" xml:space="preserve">
          <source>[F2001]</source>
          <target state="translated">[F2001]</target>
        </trans-unit>
        <trans-unit id="5712ff07224dea2f09976ad1b5f9060cea098ee8" translate="yes" xml:space="preserve">
          <source>[FS1995]</source>
          <target state="translated">[FS1995]</target>
        </trans-unit>
        <trans-unit id="111b120f6e2f3a7d9723c16133fcfb1ce7b7557b" translate="yes" xml:space="preserve">
          <source>[Flach2015]</source>
          <target state="translated">[Flach2015]</target>
        </trans-unit>
        <trans-unit id="0be1b91bf292e6f295e73f8ba1626aa315ca1709" translate="yes" xml:space="preserve">
          <source>[Guyon2015]</source>
          <target state="translated">[Guyon2015]</target>
        </trans-unit>
        <trans-unit id="16deff704a4f867ca18d98b22e63afcb70ec96d2" translate="yes" xml:space="preserve">
          <source>[H1998]</source>
          <target state="translated">[H1998]</target>
        </trans-unit>
        <trans-unit id="346ddc10d1a23f1ff0ba05ea1da881f4666595c5" translate="yes" xml:space="preserve">
          <source>[HTF2009]</source>
          <target state="translated">[HTF2009]</target>
        </trans-unit>
        <trans-unit id="2b6bce181ae06e6796d39628b4dc12ca65767e20" translate="yes" xml:space="preserve">
          <source>[HTF]</source>
          <target state="translated">[HTF]</target>
        </trans-unit>
        <trans-unit id="8f4756ba18c793a637ad7568fd4450479f47b718" translate="yes" xml:space="preserve">
          <source>[Hubert1985]</source>
          <target state="translated">[Hubert1985]</target>
        </trans-unit>
        <trans-unit id="1c2acae56920363d695dc395b30aa0dac0656aa7" translate="yes" xml:space="preserve">
          <source>[Jen09]</source>
          <target state="translated">[Jen09]</target>
        </trans-unit>
        <trans-unit id="52833f723be6af6645b6622da4d471b65e89d942" translate="yes" xml:space="preserve">
          <source>[Kelleher2015]</source>
          <target state="translated">[Kelleher2015]</target>
        </trans-unit>
        <trans-unit id="8d63f432cd9715591fb04662784fbed01426124f" translate="yes" xml:space="preserve">
          <source>[L2014]</source>
          <target state="translated">[L2014]</target>
        </trans-unit>
        <trans-unit id="e6f810474b9d9bf1966e66d024bfd2d0d9af7983" translate="yes" xml:space="preserve">
          <source>[LG2012]</source>
          <target state="translated">[LG2012]</target>
        </trans-unit>
        <trans-unit id="4108a351bec333bc41371d8be81bbf1f0bd216a0" translate="yes" xml:space="preserve">
          <source>[LS2010]</source>
          <target state="translated">[LS2010]</target>
        </trans-unit>
        <trans-unit id="36c1f9470816b8da81a8ed80471ace8df2456c31" translate="yes" xml:space="preserve">
          <source>[M2012]</source>
          <target state="translated">[M2012]</target>
        </trans-unit>
        <trans-unit id="536dc6f43e65eedbc7dcd92d64ef850b0a7951d3" translate="yes" xml:space="preserve">
          <source>[MRS2008]</source>
          <target state="translated">[MRS2008]</target>
        </trans-unit>
        <trans-unit id="350f14f810397ce0cd7520f35f0fae7d54d72023" translate="yes" xml:space="preserve">
          <source>[Manning2008]</source>
          <target state="translated">[Manning2008]</target>
        </trans-unit>
        <trans-unit id="0cc214a1564fbbf90b4daa0b0972b6f8408e3afc" translate="yes" xml:space="preserve">
          <source>[Mosley2013]</source>
          <target state="translated">[Mosley2013]</target>
        </trans-unit>
        <trans-unit id="73be0b37b87d3c88f49438b3a7ca251dc3d3c1d2" translate="yes" xml:space="preserve">
          <source>[Mrl09]</source>
          <target state="translated">[Mrl09]</target>
        </trans-unit>
        <trans-unit id="690e639d5d468ec30ab9e54cb03287a1d07d286f" translate="yes" xml:space="preserve">
          <source>[NQY18]</source>
          <target state="translated">[NQY18]</target>
        </trans-unit>
        <trans-unit id="95849b59dfe0de62fa4f930bc19ca3b64ad51c5b" translate="yes" xml:space="preserve">
          <source>[R2007]</source>
          <target state="translated">[R2007]</target>
        </trans-unit>
        <trans-unit id="d27f89b25dd2806ef3b69d37ac341ea761b1f775" translate="yes" xml:space="preserve">
          <source>[RR2007]</source>
          <target state="translated">[RR2007]</target>
        </trans-unit>
        <trans-unit id="99aae3a9e5135b3c3c9e6f81c5583f53ea54b161" translate="yes" xml:space="preserve">
          <source>[RVD]</source>
          <target state="translated">[RVD]</target>
        </trans-unit>
        <trans-unit id="7fc4fd0834c6c78f63966f47416f1e672a05b032" translate="yes" xml:space="preserve">
          <source>[RVDriessen]</source>
          <target state="translated">[RVDriessen]</target>
        </trans-unit>
        <trans-unit id="9a3d290ec7e0cf466e2e530b732c430fd93742e5" translate="yes" xml:space="preserve">
          <source>[RW2006]</source>
          <target state="translated">[RW2006]</target>
        </trans-unit>
        <trans-unit id="ab40883d6ce3b576febad86ad20a220ae60fc722" translate="yes" xml:space="preserve">
          <source>[Rouseeuw1984]</source>
          <target state="translated">[Rouseeuw1984]</target>
        </trans-unit>
        <trans-unit id="f4ff5aad65e1461e94ef70a659337011d0c58126" translate="yes" xml:space="preserve">
          <source>[Rousseeuw]</source>
          <target state="translated">[Rousseeuw]</target>
        </trans-unit>
        <trans-unit id="74f2d2c5b044f5dc96afc1e0482d2495c57d5370" translate="yes" xml:space="preserve">
          <source>[Urbanowicz2015]</source>
          <target state="translated">[Urbanowicz2015]</target>
        </trans-unit>
        <trans-unit id="34cb3f1593778c84c25ed6665ee9a323140a68d9" translate="yes" xml:space="preserve">
          <source>[VEB2009] Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">[VEB2009] Винь, Эппс и Бейли, (2009). &amp;laquo;Теоретико-информационные меры для сравнения кластеризации&amp;raquo;. Материалы 26-й ежегодной международной конференции по машинному обучению - ICML '09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;DOI: 10.1145 / 1553374.1553511&lt;/a&gt; . ISBN 9781605585161.</target>
        </trans-unit>
        <trans-unit id="48a5d15f42b24744d500812bf01a83ad55ecae83" translate="yes" xml:space="preserve">
          <source>[VEB2010] Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">[VEB2010] Винь, Эппс и Бейли, (2010). &amp;laquo;Теоретико-информационные меры для сравнения кластеризации: варианты, свойства, нормализация и поправка на случайность&amp;raquo;. JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
