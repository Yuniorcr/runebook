<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="20a9e2ae79f377ec69f0ec221a6bcb99fe892698" translate="yes" xml:space="preserve">
          <source>Inputs: fitted predictive model \(m\), tabular dataset (training or validation) \(D\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fffa8f8e3b740ecfc583b9bf477ffcbdb298b533" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest.</source>
          <target state="translated">Вставляет новые данные в уже установленный LSH Forest.</target>
        </trans-unit>
        <trans-unit id="e78cacac23222d74508b7d4b79fbb8a5cb79c6fc" translate="yes" xml:space="preserve">
          <source>Inserts new data into the already fitted LSH Forest. Cost is proportional to new total size, so additions should be batched.</source>
          <target state="translated">Вставляет новые данные в уже установленный LSH Forest.Стоимость пропорциональна новому общему размеру,поэтому дополнения должны быть согласованы.</target>
        </trans-unit>
        <trans-unit id="aa15440a6446ecaf7603f9c0287316507f4328a1" translate="yes" xml:space="preserve">
          <source>Inspecting coefficients across the folds of a cross-validation loop gives an idea of their stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3ce4618efaae8bf391d0768eaf2c4b834adfb9b" translate="yes" xml:space="preserve">
          <source>Inspection</source>
          <target state="translated">Inspection</target>
        </trans-unit>
        <trans-unit id="4c0fbc7b0ca330086776985f409e7f037b2f9494" translate="yes" xml:space="preserve">
          <source>Instance of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58768f013d8600aed4da42a9f67c30c0b0e7f2be" translate="yes" xml:space="preserve">
          <source>Instead of computing with a set of cardinality &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples (at least number of features), consider only a stochastic subpopulation of a given maximal size if &amp;lsquo;n choose k&amp;rsquo; is larger than max_subpopulation. For other than small problem sizes this parameter will determine memory usage and runtime if n_subsamples is not changed.</source>
          <target state="translated">Вместо вычислений с набором мощности n choose k, где n - количество выборок, а k - количество подвыборок (по крайней мере, количество характеристик), рассмотрите только стохастическую подгруппу заданного максимального размера, если n choose k 'больше, чем max_subpopulation. Для задач, отличных от небольших, этот параметр будет определять использование памяти и время выполнения, если n_subsamples не изменяется.</target>
        </trans-unit>
        <trans-unit id="ce6171dee8019fcd810326710a2a425d2ef2e21c" translate="yes" xml:space="preserve">
          <source>Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the L1 norm of the parameter vector. The full coefficients path is stored in the array &lt;code&gt;coef_path_&lt;/code&gt;, which has size (n_features, max_features+1). The first column is always zero.</source>
          <target state="translated">Вместо того чтобы давать векторный результат, решение LARS состоит из кривой, обозначающей решение для каждого значения нормы L1 вектора параметров. Полный путь коэффициентов хранится в массиве &lt;code&gt;coef_path_&lt;/code&gt; , который имеет размер (n_features, max_features + 1). Первый столбец всегда равен нулю.</target>
        </trans-unit>
        <trans-unit id="848ef7b85f04c1e0179836725b124a8c68948c34" translate="yes" xml:space="preserve">
          <source>Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the \(\ell_1\) norm of the parameter vector. The full coefficients path is stored in the array &lt;code&gt;coef_path_&lt;/code&gt;, which has size (n_features, max_features+1). The first column is always zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c47d2e573aac76a94273f4c46c066cf6f2a8ad1" translate="yes" xml:space="preserve">
          <source>Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. We try out all classifiers on either words or bigrams, with or without idf, and with a penalty parameter of either 0.01 or 0.001 for the linear SVM:</source>
          <target state="translated">Вместо того,чтобы подстраивать параметры различных составляющих цепочки,можно провести исчерпывающий поиск наилучших параметров по сетке возможных значений.Мы опробуем все классификаторы либо на словах,либо на биграммах,с idf или без,и с параметром штрафных санкций 0.01 или 0.001 для линейного SVM:</target>
        </trans-unit>
        <trans-unit id="db33f6d449a5c5c7a074dd03bb12ec7fc077641c" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_centering=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSR matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">Вместо этого ожидается, что вызывающий либо явно установит &lt;code&gt;with_centering=False&lt;/code&gt; (в этом случае для функций матрицы CSR будет выполняться только масштабирование дисперсии), либо вызовет &lt;code&gt;X.toarray()&lt;/code&gt; если он / она ожидает, что материализованный плотный массив будет соответствовать в памяти.</target>
        </trans-unit>
        <trans-unit id="f080b277d95a6b1142abd6eb9ea11a07abcb1917" translate="yes" xml:space="preserve">
          <source>Instead the caller is expected to either set explicitly &lt;code&gt;with_mean=False&lt;/code&gt; (in that case, only variance scaling will be performed on the features of the CSC matrix) or to call &lt;code&gt;X.toarray()&lt;/code&gt; if he/she expects the materialized dense array to fit in memory.</source>
          <target state="translated">Вместо этого ожидается, что вызывающий либо явно установит &lt;code&gt;with_mean=False&lt;/code&gt; (в этом случае для функций матрицы CSC будет выполняться только масштабирование дисперсии), либо вызовет &lt;code&gt;X.toarray()&lt;/code&gt; если он / она ожидает, что материализованный плотный массив будет соответствовать в памяти.</target>
        </trans-unit>
        <trans-unit id="b11f1ba476938b01d18dd66d0c3826617a20151e" translate="yes" xml:space="preserve">
          <source>Instead, the distribution over \(w\) is assumed to be an axis-parallel, elliptical Gaussian distribution.</source>
          <target state="translated">Вместо этого предполагается,что распределение по адресу \(w\)является осево-параллельным,эллиптическим гауссовым распределением.</target>
        </trans-unit>
        <trans-unit id="33a2873657f7cc53fbafced5857dd217868f1368" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. By default, it is &amp;lsquo;strict&amp;rsquo;, meaning that a UnicodeDecodeError will be raised. Other values are &amp;lsquo;ignore&amp;rsquo; and &amp;lsquo;replace&amp;rsquo;.</source>
          <target state="translated">Инструкция, что делать, если на анализ дана последовательность байтов, содержащая символы не заданной &lt;code&gt;encoding&lt;/code&gt; . По умолчанию он &amp;laquo;строгий&amp;raquo;, что означает, что будет вызвана ошибка UnicodeDecodeError. Другие значения - &amp;laquo;игнорировать&amp;raquo; и &amp;laquo;заменить&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="d22b7ba366228e805a5817961de5812cf7af3a5e" translate="yes" xml:space="preserve">
          <source>Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given &lt;code&gt;encoding&lt;/code&gt;. Passed as keyword argument &amp;lsquo;errors&amp;rsquo; to bytes.decode.</source>
          <target state="translated">Инструкция, что делать, если на анализ дана последовательность байтов, содержащая символы не заданной &lt;code&gt;encoding&lt;/code&gt; . Передается в качестве аргумента ключевого слова &amp;laquo;errors&amp;raquo; в bytes.decode.</target>
        </trans-unit>
        <trans-unit id="98ae123013fca86e4cc21f01a470888e055215cc" translate="yes" xml:space="preserve">
          <source>Integer array of labels. If not provided, labels will be inferred from y_true and y_pred.</source>
          <target state="translated">Целочисленный массив этикеток.Если это не предусмотрено,то метки будут выведены из y_true и y_pred.</target>
        </trans-unit>
        <trans-unit id="e031a894709099be1ecbe448974105f94db94157" translate="yes" xml:space="preserve">
          <source>Intercept (a.k.a. bias) added to linear predictor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb86aae8ca1d5ea8c3a2f0216a09b115ca2c4371" translate="yes" xml:space="preserve">
          <source>Intercept (a.k.a. bias) added to the decision function.</source>
          <target state="translated">Перехват (так же известный как предвзятость),добавленный к функции принятия решения.</target>
        </trans-unit>
        <trans-unit id="02c60e7ce23b1ba7da9aadaca682e74dd23bd987" translate="yes" xml:space="preserve">
          <source>Intercept term.</source>
          <target state="translated">Срок перехвата.</target>
        </trans-unit>
        <trans-unit id="077392291decf12f1b024c471b5bea6bcd10e56c" translate="yes" xml:space="preserve">
          <source>Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid loosing the history of the evolution, but they shouldn&amp;rsquo;t have any use for the end user. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">Внутренняя достаточная статистика, которая хранится алгоритмом. Их полезно хранить в онлайн-настройках, чтобы не потерять историю эволюции, но они не должны иметь никакого смысла для конечного пользователя. A (n_components, n_components) - это ковариационная матрица словаря. B (n_features, n_components) - матрица аппроксимации данных</target>
        </trans-unit>
        <trans-unit id="e1895bccbde849f2ce31dc6715c34549e1152575" translate="yes" xml:space="preserve">
          <source>Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid losing the history of the evolution, but they shouldn&amp;rsquo;t have any use for the end user. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14f5f43f255d2aa36ff5598f3fb3ace3d6d04389" translate="yes" xml:space="preserve">
          <source>Internally, the Laplace approximation is used for approximating the non-Gaussian posterior by a Gaussian.</source>
          <target state="translated">Внутренняя аппроксимация Лапласа используется для аппроксимации гауссовым апостериором не гауссового апостериорного.</target>
        </trans-unit>
        <trans-unit id="0b925a293764508f95547bba83dbd960f81b58e6" translate="yes" xml:space="preserve">
          <source>Internally, the target &lt;code&gt;y&lt;/code&gt; is always converted into a 2-dimensional array to be used by scikit-learn transformers. At the time of prediction, the output will be reshaped to a have the same number of dimensions as &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Внутренне целевой &lt;code&gt;y&lt;/code&gt; всегда преобразуется в двумерный массив, который будет использоваться преобразователями scikit-learn. Во время прогнозирования результат будет изменен, чтобы иметь то же количество измерений, что и &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="465a9fa03a440d5f1b8441512ea129ccebe5933c" translate="yes" xml:space="preserve">
          <source>Internally, this method uses &lt;code&gt;max_iter = 1&lt;/code&gt;. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence and early stopping should be handled by the user.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6c7ce41d2f8fb06b74993c6b6972d365c014219" translate="yes" xml:space="preserve">
          <source>Internally, we use &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; to handle all computations. These libraries are wrapped using C and Cython.</source>
          <target state="translated">Внутри мы используем &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; и &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; для обработки всех вычислений. Эти библиотеки обернуты с использованием C и Cython.</target>
        </trans-unit>
        <trans-unit id="921b6b42e9e212246385b90b6e2081ffae4bdd4d" translate="yes" xml:space="preserve">
          <source>Internally, we use &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;&lt;a href=&quot;#id14&quot; id=&quot;id9&quot;&gt;12&lt;/a&gt; and &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;&lt;a href=&quot;#id13&quot; id=&quot;id10&quot;&gt;11&lt;/a&gt; to handle all computations. These libraries are wrapped using C and Cython. For a description of the implementation and details of the algorithms used, please refer to their respective papers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a02157db035ff864370a2c436b6c81a38e8d8a3c" translate="yes" xml:space="preserve">
          <source>Interpreting coefficients: scale matters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2d983855292bfa7e006da9cc5e0020136bdcd0e" translate="yes" xml:space="preserve">
          <source>Interruption of multiprocesses jobs with &amp;lsquo;Ctrl-C&amp;rsquo;</source>
          <target state="translated">Прерывание многопроцессных заданий с помощью Ctrl-C</target>
        </trans-unit>
        <trans-unit id="c8666d7061618ff72086e37218ea77619df4e168" translate="yes" xml:space="preserve">
          <source>Intuitive interpretation: clustering with bad V-measure can be &lt;strong&gt;qualitatively analyzed in terms of homogeneity and completeness&lt;/strong&gt; to better feel what &amp;lsquo;kind&amp;rsquo; of mistakes is done by the assignment.</source>
          <target state="translated">Интуитивная интерпретация: кластеризацию с плохой V-мерой можно &lt;strong&gt;качественно проанализировать с точки зрения однородности и полноты,&lt;/strong&gt; чтобы лучше понять, какие &amp;laquo;ошибки&amp;raquo; допущены при задании.</target>
        </trans-unit>
        <trans-unit id="b3bf13a5a75c5bcae60f4d54f651f7f504b37960" translate="yes" xml:space="preserve">
          <source>Intuitively, &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;precision&lt;/a&gt; is the ability of the classifier not to label as positive a sample that is negative, and &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;recall&lt;/a&gt; is the ability of the classifier to find all the positive samples.</source>
          <target state="translated">Интуитивно, &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Precision&quot;&gt;точность&lt;/a&gt; - это способность классификатора не маркировать как положительный образец, который является отрицательным, а &lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall#Recall&quot;&gt;отзыв&lt;/a&gt; - это способность классификатора находить все положительные образцы.</target>
        </trans-unit>
        <trans-unit id="d7d0867c1bea54b1fdaded0f6d4a137c7b95792e" translate="yes" xml:space="preserve">
          <source>Intuitively, one can also think of a histogram as a stack of blocks, one block per point. By stacking the blocks in the appropriate grid space, we recover the histogram. But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location? This idea leads to the lower-left visualization. It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data.</source>
          <target state="translated">Интуитивно,можно также думать о гистограмме,как о стопке блоков,по одному блоку на точку.Укладывая блоки в соответствующее пространство сетки,мы восстанавливаем гистограмму.Но что,если вместо того,чтобы укладывать блоки на обычную сетку,мы центрируем каждый блок по точке,которую он представляет,и суммируем общую высоту в каждой точке? Эта идея приведет к визуализации в левом нижнем углу.Возможно,она не так чиста,как гистограмма,но тот факт,что данные приводят к расположению блоков,означает,что это гораздо лучшее представление исходных данных.</target>
        </trans-unit>
        <trans-unit id="a413ab311fb3ee6ba0089ad38e522b4769b873e8" translate="yes" xml:space="preserve">
          <source>Intuitively, the &lt;code&gt;gamma&lt;/code&gt; parameter defines how far the influence of a single training example reaches, with low values meaning &amp;lsquo;far&amp;rsquo; and high values meaning &amp;lsquo;close&amp;rsquo;. The &lt;code&gt;gamma&lt;/code&gt; parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.</source>
          <target state="translated">Интуитивно параметр &lt;code&gt;gamma&lt;/code&gt; определяет, насколько далеко распространяется влияние одного обучающего примера, при этом низкие значения означают &amp;laquo;далеко&amp;raquo;, а высокие значения - &amp;laquo;близко&amp;raquo;. Параметры &lt;code&gt;gamma&lt;/code&gt; можно рассматривать как обратную величину радиуса влияния образцов, выбранных моделью в качестве опорных векторов.</target>
        </trans-unit>
        <trans-unit id="0af317bc827b64b57bcc63f42ad5928a61b8cb1f" translate="yes" xml:space="preserve">
          <source>Intuitively, this matrix can be interpreted as a matrix of pseudo features (the points raised to some power). The matrix is akin to (but different from) the matrix induced by a polynomial kernel.</source>
          <target state="translated">Интуитивно эту матрицу можно интерпретировать как матрицу псевдофункций (пунктов,поднятых до некоторой степени).Матрица сродни (но отличается от)матрицы,индуцированной полиномиальным ядром.</target>
        </trans-unit>
        <trans-unit id="d0136f60343b9ddfe4e95ff298a3f11e6a44a13d" translate="yes" xml:space="preserve">
          <source>Intuitively, we&amp;rsquo;re trying to maximize the margin (by minimizing \(||w||^2 = w^Tw\)), while incurring a penalty when a sample is misclassified or within the margin boundary. Ideally, the value \(y_i (w^T \phi (x_i) + b)\) would be \(\geq 1\) for all samples, which indicates a perfect prediction. But problems are usually not always perfectly separable with a hyperplane, so we allow some samples to be at a distance \(\zeta_i\) from their correct margin boundary. The penalty term &lt;code&gt;C&lt;/code&gt; controls the strengh of this penalty, and as a result, acts as an inverse regularization parameter (see note below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcf37d79a0d7f3a40e6e7bdc86aa285b256f5c04" translate="yes" xml:space="preserve">
          <source>Inverse Gaussian</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="20dc7b25181635b005eb94a34d79a1d1ef88f5eb" translate="yes" xml:space="preserve">
          <source>Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.</source>
          <target state="translated">Обратная сила регуляризации;должен быть положительный поплавок.Как и в векторных машинах поддержки,меньшие значения указывают более сильную регуляризацию.</target>
        </trans-unit>
        <trans-unit id="33bf667eeef9f8f87ba0b221f0610de05f350c0d" translate="yes" xml:space="preserve">
          <source>Inverse the transformation.</source>
          <target state="translated">Обратное преобразование.</target>
        </trans-unit>
        <trans-unit id="c6d1024dc4c416573a81f58d53b390ce79e27d74" translate="yes" xml:space="preserve">
          <source>Inverse the transformation. Return a vector of size nb_features with the values of Xred assigned to each group of features</source>
          <target state="translated">Обратное преобразование.Возвращает вектор размера nb_features со значениями Xred,присвоенными каждой группе признаков</target>
        </trans-unit>
        <trans-unit id="68776e7556a932d7c1772f163bcd0ea5d3036f2f" translate="yes" xml:space="preserve">
          <source>Inverse transform matrix. Only available when &lt;code&gt;fit_inverse_transform&lt;/code&gt; is True.</source>
          <target state="translated">Матрица обратного преобразования. Доступно, только когда &lt;code&gt;fit_inverse_transform&lt;/code&gt; имеет значение True.</target>
        </trans-unit>
        <trans-unit id="a53229d5506328691d3b32e8898ac28b845cf1d2" translate="yes" xml:space="preserve">
          <source>Inverse transformed array.</source>
          <target state="translated">Обратный преобразованный массив.</target>
        </trans-unit>
        <trans-unit id="6d0db9202e10d4b2a1eb16356a668a8027a929fc" translate="yes" xml:space="preserve">
          <source>Invokes the passed method name of the passed estimator. For method=&amp;rsquo;predict_proba&amp;rsquo;, the columns correspond to the classes in sorted order.</source>
          <target state="translated">Вызывает переданное имя метода переданного оценщика. Для method = 'pred_proba' столбцы соответствуют классам в отсортированном порядке.</target>
        </trans-unit>
        <trans-unit id="93ce645e781a1eaea74d358c1f7aa54ffb25426b" translate="yes" xml:space="preserve">
          <source>Invoking the &lt;code&gt;fit&lt;/code&gt; method on the &lt;code&gt;VotingClassifier&lt;/code&gt; will fit clones of those original estimators that will be stored in the class attribute &lt;code&gt;self.estimators_&lt;/code&gt;. An estimator can be set to &lt;code&gt;'drop'&lt;/code&gt; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d37270b3f9f32ae673296712eb4a194d52812d8f" translate="yes" xml:space="preserve">
          <source>Invoking the &lt;code&gt;fit&lt;/code&gt; method on the &lt;code&gt;VotingClassifier&lt;/code&gt; will fit clones of those original estimators that will be stored in the class attribute &lt;code&gt;self.estimators_&lt;/code&gt;. An estimator can be set to &lt;code&gt;None&lt;/code&gt; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="translated">Вызов метода &lt;code&gt;fit&lt;/code&gt; в &lt;code&gt;VotingClassifier&lt;/code&gt; подберет клоны тех исходных оценщиков, которые будут храниться в атрибуте класса &lt;code&gt;self.estimators_&lt;/code&gt; . Для оценщика можно установить значение &lt;code&gt;None&lt;/code&gt; с помощью &lt;code&gt;set_params&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0f0eee1c2a0f3878912e931a58a1d92e46d13c5a" translate="yes" xml:space="preserve">
          <source>Invoking the &lt;code&gt;fit&lt;/code&gt; method on the &lt;code&gt;VotingRegressor&lt;/code&gt; will fit clones of those original estimators that will be stored in the class attribute &lt;code&gt;self.estimators_&lt;/code&gt;. An estimator can be set to &lt;code&gt;'drop'&lt;/code&gt; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42b4a555867c758d3e1c4078b74a325ea5729a8f" translate="yes" xml:space="preserve">
          <source>Iris-Setosa</source>
          <target state="translated">Iris-Setosa</target>
        </trans-unit>
        <trans-unit id="0e4a66fb06fc31fa26bb267122a303163869bd83" translate="yes" xml:space="preserve">
          <source>Iris-Versicolour</source>
          <target state="translated">Iris-Versicolour</target>
        </trans-unit>
        <trans-unit id="c11352543468838c7f536aa067f758dd5cf065cc" translate="yes" xml:space="preserve">
          <source>Iris-Virginica</source>
          <target state="translated">Iris-Virginica</target>
        </trans-unit>
        <trans-unit id="bb0f5655f4fe0f8adc1a787c53ae1e836f4be186" translate="yes" xml:space="preserve">
          <source>Iso-probability lines for Gaussian Processes classification (GPC)</source>
          <target state="translated">Линии прозо-вероятности для Гауссовской классификации процессов (GPC)</target>
        </trans-unit>
        <trans-unit id="2b50512539d0e21a6687a0e4968f704ff8cc80fe" translate="yes" xml:space="preserve">
          <source>Isolation Forest Algorithm</source>
          <target state="translated">алгоритм изоляции леса</target>
        </trans-unit>
        <trans-unit id="90b7e1d9dae263e13bf54b6eb5bbce295b25c458" translate="yes" xml:space="preserve">
          <source>Isolation Forest Algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00617c131e78d4c4ef41c400773154d235217731" translate="yes" xml:space="preserve">
          <source>IsolationForest example</source>
          <target state="translated">пример IsolationForest</target>
        </trans-unit>
        <trans-unit id="3a2755971bbebbe11d424139f5382799c401f262" translate="yes" xml:space="preserve">
          <source>Isomap Embedding</source>
          <target state="translated">Isomap Embedding</target>
        </trans-unit>
        <trans-unit id="fe769adce6faebe1974c95ecc576637486cbe643" translate="yes" xml:space="preserve">
          <source>Isotone Optimization in R : Pool-Adjacent-Violators Algorithm (PAVA) and Active Set Methods Leeuw, Hornik, Mair Journal of Statistical Software 2009</source>
          <target state="translated">Оптимизация изотонов в R:Алгоритм пула-аджакента-виолятора (PAVA)и методы активных множеств Leeuw,Hornik,Журнал статистического программного обеспечения Mair за 2009 год</target>
        </trans-unit>
        <trans-unit id="906c68921cb26d68c13066c88efbe4d7d97d1205" translate="yes" xml:space="preserve">
          <source>Isotonic Median Regression: A Linear Programming Approach Nilotpal Chakravarti Mathematics of Operations Research Vol. 14, No. 2 (May, 1989), pp. 303-308</source>
          <target state="translated">Изотоническая Медианная Регрессия:Линейный программный подход Nilotpal Chakravarti Математика исследования операций Том 14,No.2 (май 1989 г.),стр.303-308</target>
        </trans-unit>
        <trans-unit id="73b36c35655a3846d59943ac16d2df052178f43b" translate="yes" xml:space="preserve">
          <source>Isotonic Regression</source>
          <target state="translated">изотоническая регрессия</target>
        </trans-unit>
        <trans-unit id="c214056f848cd4e39c52f175df94ac0d422815da" translate="yes" xml:space="preserve">
          <source>Isotonic fit of y.</source>
          <target state="translated">Изотонический припадок.</target>
        </trans-unit>
        <trans-unit id="350a83a6eea9b1b3e9903b81e34485a4ebed4999" translate="yes" xml:space="preserve">
          <source>Isotonic regression model.</source>
          <target state="translated">Изотоническая регрессионная модель.</target>
        </trans-unit>
        <trans-unit id="7c5ae8804283297e052b100d9986cbd5cd009701" translate="yes" xml:space="preserve">
          <source>Issue a warning when the function is called/the class is instantiated and adds a warning to the docstring.</source>
          <target state="translated">Выдача предупреждения при вызове функции/класса и добавление предупреждения в стыковочную строку.</target>
        </trans-unit>
        <trans-unit id="4de98053a0f4264ca5362b17521388fcee7300ef" translate="yes" xml:space="preserve">
          <source>It adapts to the data at hand.</source>
          <target state="translated">Он адаптируется к имеющимся данным.</target>
        </trans-unit>
        <trans-unit id="d00cd2eb4ac76616c412b13d0e3140cdba7905a2" translate="yes" xml:space="preserve">
          <source>It allows specifying multiple metrics for evaluation.</source>
          <target state="translated">Она позволяет задавать несколько метрик для оценки.</target>
        </trans-unit>
        <trans-unit id="f7ac040f9311efb440d25da16c027a81ab8e3ad5" translate="yes" xml:space="preserve">
          <source>It also can be expressed in set cardinality formulation:</source>
          <target state="translated">Она также может быть выражена в установленной формулировке кардинальности:</target>
        </trans-unit>
        <trans-unit id="aedad5338d2a0edf1701c1d5c20ad5954bfd8c84" translate="yes" xml:space="preserve">
          <source>It can also be directly used as the &lt;code&gt;kernel&lt;/code&gt; argument:</source>
          <target state="translated">Его также можно напрямую использовать как аргумент &lt;code&gt;kernel&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="9678c3fa14b59b03394b92e8e0080149cf3f64c8" translate="yes" xml:space="preserve">
          <source>It can also be used as a pre-processing step for estimators that consider boolean random variables (e.g. modelled using the Bernoulli distribution in a Bayesian setting).</source>
          <target state="translated">Она также может быть использована в качестве этапа предварительной обработки для оценщиков,которые рассматривают булевы случайные переменные (например,смоделированные с использованием распределения Бернулли в байесовской установке).</target>
        </trans-unit>
        <trans-unit id="94554b8e34efbb328f639daf4ccda2adc301f69d" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.</source>
          <target state="translated">Она также может быть использована для преобразования нецифровых меток (при условии,что они являются хэшируемыми и сопоставимыми)с числовыми метками.</target>
        </trans-unit>
        <trans-unit id="f96e6d208d3d13906cbf9cd9c045b4122e99a4e4" translate="yes" xml:space="preserve">
          <source>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels:</source>
          <target state="translated">Она также может быть использована для преобразования нецифровых меток (при условии,что они являются хэшируемыми и сопоставимыми)с числовыми метками:</target>
        </trans-unit>
        <trans-unit id="52f6dad43e1775ee0bbb04be9ef515bae958e0a2" translate="yes" xml:space="preserve">
          <source>It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.</source>
          <target state="translated">Он также может иметь регуляризационный термин,добавленный к функции потерь,который сокращает параметры модели,чтобы предотвратить переподгонку.</target>
        </trans-unit>
        <trans-unit id="998bd5d13863b9f1e85f5a6708bf38f625d563b0" translate="yes" xml:space="preserve">
          <source>It can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD.</source>
          <target state="translated">Он также может использовать scipy.sparse.linalg ARPACK реализацию усеченного SVD.</target>
        </trans-unit>
        <trans-unit id="a5f9c7ba1af0aaff84e6645b602de8095311d995" translate="yes" xml:space="preserve">
          <source>It can be called with parameters &lt;code&gt;(estimator, X, y)&lt;/code&gt;, where &lt;code&gt;estimator&lt;/code&gt; is the model that should be evaluated, &lt;code&gt;X&lt;/code&gt; is validation data, and &lt;code&gt;y&lt;/code&gt; is the ground truth target for &lt;code&gt;X&lt;/code&gt; (in the supervised case) or &lt;code&gt;None&lt;/code&gt; (in the unsupervised case).</source>
          <target state="translated">Его можно вызвать с параметрами &lt;code&gt;(estimator, X, y)&lt;/code&gt; , где &lt;code&gt;estimator&lt;/code&gt; - это модель, которая должна быть оценена, &lt;code&gt;X&lt;/code&gt; - данные валидации, а &lt;code&gt;y&lt;/code&gt; - основная истинная цель для &lt;code&gt;X&lt;/code&gt; (в контролируемом случае) или &lt;code&gt;None&lt;/code&gt; (в неконтролируемом случае). кейс).</target>
        </trans-unit>
        <trans-unit id="9a6afc7a825a539f282e6908ea3004d59da105e7" translate="yes" xml:space="preserve">
          <source>It can be downloaded/loaded using the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt;&lt;/a&gt; function.</source>
          <target state="translated">Его можно скачать / загрузить с &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_california_housing#sklearn.datasets.fetch_california_housing&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_california_housing&lt;/code&gt; &lt;/a&gt; функции sklearn.datasets.fetch_california_housing .</target>
        </trans-unit>
        <trans-unit id="afe5a10e4cd1db3d3b82e37290c3a4b0be9670c8" translate="yes" xml:space="preserve">
          <source>It can be interpreted as a weighted difference per entry.</source>
          <target state="translated">Это может быть интерпретировано как взвешенная разница на запись.</target>
        </trans-unit>
        <trans-unit id="d898e853ebb8a8ce7531765c1307531f5ab826e6" translate="yes" xml:space="preserve">
          <source>It can be noted that k-means (and minibatch k-means) are very sensitive to feature scaling and that in this case the IDF weighting helps improve the quality of the clustering by quite a lot as measured against the &amp;ldquo;ground truth&amp;rdquo; provided by the class label assignments of the 20 newsgroups dataset.</source>
          <target state="translated">Можно отметить, что k-средние (и k-средние мини-пакета) очень чувствительны к масштабированию признаков, и что в этом случае взвешивание IDF помогает значительно улучшить качество кластеризации по сравнению с &amp;laquo;наземной истиной&amp;raquo;, предоставленной присвоения меток класса для набора данных 20 групп новостей.</target>
        </trans-unit>
        <trans-unit id="074f1a9d1908eeea94dd9624b8e4e74f70971f1f" translate="yes" xml:space="preserve">
          <source>It can be seen from the plots that the results of &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt; with two non-zero coefficients is a bit less biased than when keeping only one (the edges look less prominent). It is in addition closer from the ground truth in Frobenius norm.</source>
          <target state="translated">Из графиков видно, что результаты &lt;a href=&quot;../../modules/linear_model#omp&quot;&gt;поиска ортогонального соответствия (OMP)&lt;/a&gt; с двумя ненулевыми коэффициентами немного менее смещены, чем при сохранении только одного (края выглядят менее заметными). Вдобавок это ближе к истине в норме Фробениуса.</target>
        </trans-unit>
        <trans-unit id="0cf8fb702abea7c91fd29d6847c4f9bb34be57f9" translate="yes" xml:space="preserve">
          <source>It can be shown that the \(\nu\)-SVC formulation is a reparameterization of the \(C\)-SVC and therefore mathematically equivalent.</source>
          <target state="translated">Можно показать,что формулировка \(\nu\)-SVC является репараметризацией \(C\)-SVC и,следовательно,математически эквивалентна.</target>
        </trans-unit>
        <trans-unit id="157aa7190191e4be1be236c86eabe4e67d5e1efd" translate="yes" xml:space="preserve">
          <source>It can be used for univariate features selection, read more in the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Его можно использовать для одномерного выбора функций, подробнее читайте в &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;Руководстве пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="711c50760d4f6c264d6b8a92b5297202a600fa0b" translate="yes" xml:space="preserve">
          <source>It can be used to include regularization parameters in the estimation procedure.</source>
          <target state="translated">Его можно использовать для включения параметров регуляризации в процедуру оценки.</target>
        </trans-unit>
        <trans-unit id="e52b5bc871c7db656a1b43abcce93011714c74d2" translate="yes" xml:space="preserve">
          <source>It does not require a learning rate.</source>
          <target state="translated">Для этого не требуется скорость обучения.</target>
        </trans-unit>
        <trans-unit id="4d19424efe5e9e20338f3273e68fb2ccbb132c12" translate="yes" xml:space="preserve">
          <source>It doesn&amp;rsquo;t give a single metric to use as an objective for clustering optimisation.</source>
          <target state="translated">Он не дает ни одной метрики для использования в качестве цели для оптимизации кластеризации.</target>
        </trans-unit>
        <trans-unit id="53127b98db145a1107f55ea45dbcbf9eb40fb387" translate="yes" xml:space="preserve">
          <source>It has been observed in [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;2&lt;/a&gt; that, when carefully constrained, &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; can produce a parts-based representation of the dataset, resulting in interpretable models. The following example displays 16 sparse components found by &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; from the images in the Olivetti faces dataset, in comparison with the PCA eigenfaces.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a46e66645323d1f8dad68441e68b478eacb85f4" translate="yes" xml:space="preserve">
          <source>It has been observed in [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; that, when carefully constrained, &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; can produce a parts-based representation of the dataset, resulting in interpretable models. The following example displays 16 sparse components found by &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; from the images in the Olivetti faces dataset, in comparison with the PCA eigenfaces.</source>
          <target state="translated">В [Hoyer, 2004] &lt;a href=&quot;#id12&quot; id=&quot;id6&quot;&gt;[2]&lt;/a&gt; было замечено, что при тщательном ограничении &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; может создавать представление набора данных на основе частей, что приводит к интерпретируемым моделям. В следующем примере показаны 16 разреженных компонентов, найденных &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt; из изображений в наборе данных Olivetti Faces, в сравнении с собственными лицами PCA.</target>
        </trans-unit>
        <trans-unit id="8dcb00db48002a7fdf6f8f4ffd6c64f833e7dfb1" translate="yes" xml:space="preserve">
          <source>It has properties that are similar to the exponentiated chi squared kernel often used in computer vision, but allows for a simple Monte Carlo approximation of the feature map.</source>
          <target state="translated">Он обладает свойствами,схожими с экспоненциальным квадратным ядром chi,часто используемым в компьютерном зрении,но позволяет простое аппроксимационное изображение карты характеристик Монте-Карло.</target>
        </trans-unit>
        <trans-unit id="37dc8b6f979214e286ace27e5272dd91d61126bc" translate="yes" xml:space="preserve">
          <source>It has proven useful in ML applied to noiseless data. See e.g. &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Machine learning for quantum mechanics in a nutshell&lt;/a&gt;.</source>
          <target state="translated">Это оказалось полезным в машинном обучении применительно к бесшумным данным. См., Например, &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Машинное обучение для квантовой механики в двух словах&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bbe0780585e0153715a866cbcbfa3d1d5e8429c4" translate="yes" xml:space="preserve">
          <source>It has proven useful in ML applied to noiseless data. See e.g. &lt;a href=&quot;https://onlinelibrary.wiley.com/doi/10.1002/qua.24954/abstract/&quot;&gt;Machine learning for quantum mechanics in a nutshell&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3ea912466304dbf8e7c52052ad02a2c286c1ad1" translate="yes" xml:space="preserve">
          <source>It implements a variant of Random Kitchen Sinks.[1]</source>
          <target state="translated">Он реализует вариант Случайных кухонных раковин.[1].</target>
        </trans-unit>
        <trans-unit id="74d404b8e11acc4d9a6402146bf70c71d78d2e94" translate="yes" xml:space="preserve">
          <source>It is a Linear Model trained with an L1 prior as regularizer.</source>
          <target state="translated">Это линейная модель,тренированная с L1 в качестве регулятора.</target>
        </trans-unit>
        <trans-unit id="971eff281c404ac7ff23799c2f2e17c93f769de1" translate="yes" xml:space="preserve">
          <source>It is a memory-efficient, online-learning algorithm provided as an alternative to &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt;. It constructs a tree data structure with the cluster centroids being read off the leaf. These can be either the final cluster centroids or can be provided as input to another clustering algorithm such as &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Это эффективный с точки зрения памяти алгоритм онлайн-обучения, предоставляемый в качестве альтернативы &lt;a href=&quot;sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt; . Он создает древовидную структуру данных, центроиды кластера считываются с листа. Это могут быть либо конечные центроиды кластера, либо они могут быть предоставлены в качестве входных данных для другого алгоритма кластеризации, такого как &lt;a href=&quot;sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1a9933b24a1c1c056c0577574d6613078e271127" translate="yes" xml:space="preserve">
          <source>It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is &lt;code&gt;n_samples&lt;/code&gt;, the update method is same as batch learning. In the literature, this is called kappa.</source>
          <target state="translated">Это параметр, который контролирует скорость обучения в методе онлайн-обучения. Значение должно быть установлено в диапазоне (0,5, 1,0], чтобы гарантировать асимптотическую сходимость. Когда значение равно 0,0, а размер batch_size равен &lt;code&gt;n_samples&lt;/code&gt; , метод обновления аналогичен пакетному обучению. В литературе это называется каппа.</target>
        </trans-unit>
        <trans-unit id="15f125826dc7be5a6512e2415a2ab7dc87afbdb7" translate="yes" xml:space="preserve">
          <source>It is advised to set the parameter &lt;code&gt;epsilon&lt;/code&gt; to 1.35 to achieve 95% statistical efficiency.</source>
          <target state="translated">Рекомендуется установить параметр &lt;code&gt;epsilon&lt;/code&gt; на 1,35 для достижения 95% статистической эффективности.</target>
        </trans-unit>
        <trans-unit id="542f7392581e6c4610879b36a37978fc74650959" translate="yes" xml:space="preserve">
          <source>It is also common among the text processing community to use binary feature values (probably to simplify the probabilistic reasoning) even if normalized counts (a.k.a. term frequencies) or TF-IDF valued features often perform slightly better in practice.</source>
          <target state="translated">В сообществе,занимающемся обработкой текстов,также распространено использование двоичных значений признаков (вероятно,для упрощения вероятностных рассуждений),даже если нормализованные значения (так называемые терминологические частоты)или значения TF-IDF признаков часто работают несколько лучше на практике.</target>
        </trans-unit>
        <trans-unit id="005dab4eb22b6ead110b29a8850c3898f552d977" translate="yes" xml:space="preserve">
          <source>It is also known as the Variance Ratio Criterion.</source>
          <target state="translated">Он также известен как Критерий соотношения вариаций.</target>
        </trans-unit>
        <trans-unit id="657bf821e2dc05fc87b192deecf1d4c429b7d563" translate="yes" xml:space="preserve">
          <source>It is also possible to compute the permutation importances on the training set. This reveals that &lt;code&gt;random_num&lt;/code&gt; gets a significantly higher importance ranking than when computed on the test set. The difference between those two plots is a confirmation that the RF model has enough capacity to use that random numerical feature to overfit. You can further confirm this by re-running this example with constrained RF with min_samples_leaf=10.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4221678f503b8b29e4ba191986027706279048ac" translate="yes" xml:space="preserve">
          <source>It is also possible to constrain the dictionary and/or code to be positive to match constraints that may be present in the data. Below are the faces with different positivity constraints applied. Red indicates negative values, blue indicates positive values, and white represents zeros.</source>
          <target state="translated">Также возможно ограничить словарь и/или код,чтобы они соответствовали ограничениям,которые могут присутствовать в данных.Ниже приведены грани с различными ограничениями позитивности.Красный-отрицательные значения,синий-положительные,белый-нули.</target>
        </trans-unit>
        <trans-unit id="cd4e94997f77b01819c6451ba1d9a9d98a78db7c" translate="yes" xml:space="preserve">
          <source>It is also possible to efficiently produce a sparse graph showing the connections between neighboring points:</source>
          <target state="translated">Также можно эффективно построить разреженный график,показывающий связи между соседними точками:</target>
        </trans-unit>
        <trans-unit id="0396c69b921d6f190c09b79532ebbdc31b35e115" translate="yes" xml:space="preserve">
          <source>It is also possible to encode each column into &lt;code&gt;n_categories - 1&lt;/code&gt; columns instead of &lt;code&gt;n_categories&lt;/code&gt; columns by using the &lt;code&gt;drop&lt;/code&gt; parameter. This parameter allows the user to specify a category for each feature to be dropped. This is useful to avoid co-linearity in the input matrix in some classifiers. Such functionality is useful, for example, when using non-regularized regression (&lt;a href=&quot;generated/sklearn.linear_model.linearregression#sklearn.linear_model.LinearRegression&quot;&gt;&lt;code&gt;LinearRegression&lt;/code&gt;&lt;/a&gt;), since co-linearity would cause the covariance matrix to be non-invertible. When this parameter is not None, &lt;code&gt;handle_unknown&lt;/code&gt; must be set to &lt;code&gt;error&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5cc911e1a3213d4a6ea82327423c6b7195a9251" translate="yes" xml:space="preserve">
          <source>It is also possible to map data to a normal distribution using &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; by setting &lt;code&gt;output_distribution='normal'&lt;/code&gt;. Using the earlier example with the iris dataset:</source>
          <target state="translated">Также можно отобразить данные к нормальному распределению с помощью &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; , установив &lt;code&gt;output_distribution='normal'&lt;/code&gt; . Используя предыдущий пример с набором данных iris:</target>
        </trans-unit>
        <trans-unit id="f35eb3fdcbe153523a6b78440df1aad8edf3b026" translate="yes" xml:space="preserve">
          <source>It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:</source>
          <target state="translated">Можно также использовать и другие стратегии перекрестной валидации,например,передав итератор перекрестной валидации:</target>
        </trans-unit>
        <trans-unit id="c62a692f1bef88aa9ea1dc55b02f68e6ac2b429f" translate="yes" xml:space="preserve">
          <source>It is classically used to separate mixed signals (a problem known as &lt;em&gt;blind source separation&lt;/em&gt;), as in the example below:</source>
          <target state="translated">Он обычно используется для разделения смешанных сигналов (проблема, известная как &lt;em&gt;слепое разделение источников&lt;/em&gt; ), как в примере ниже:</target>
        </trans-unit>
        <trans-unit id="579f13cf2a54010546e31ecfaa7ced83f4da4e12" translate="yes" xml:space="preserve">
          <source>It is computationally just as fast as forward selection and has the same order of complexity as an ordinary least squares.</source>
          <target state="translated">Он вычисляется так же быстро,как и прямая селекция,и имеет такой же порядок сложности,как и обычные наименьшие квадраты.</target>
        </trans-unit>
        <trans-unit id="eaad2537722d5ddb17252eb65683de60a4e9ec00" translate="yes" xml:space="preserve">
          <source>It is computationally just as fast as forward selection and has the same order of complexity as ordinary least squares.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a0b5a3028e23e8f66ba4845cf98605a35e74ca3" translate="yes" xml:space="preserve">
          <source>It is converted to an F score then to a p-value.</source>
          <target state="translated">Он преобразуется в F,а затем в p-значение.</target>
        </trans-unit>
        <trans-unit id="9da4ca4cacbca0baec3287f1b2124c4dcd00df7a" translate="yes" xml:space="preserve">
          <source>It is easily modified to produce solutions for other estimators, like the Lasso.</source>
          <target state="translated">Он легко модифицируется для создания решений для других оценщиков,таких как Лассо.</target>
        </trans-unit>
        <trans-unit id="a180f7cced602efdc3c3224733570427c990972f" translate="yes" xml:space="preserve">
          <source>It is easy for a classifier to overfit on particular things that appear in the 20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very high F-scores, but their results would not generalize to other documents that aren&amp;rsquo;t from this window of time.</source>
          <target state="translated">Классификатору легко приспособиться к конкретным вещам, которые появляются в данных 20 групп новостей, например, к заголовкам групп новостей. Многие классификаторы достигают очень высоких оценок F, но их результаты не могут быть обобщены на другие документы, выходящие за пределы этого временного окна.</target>
        </trans-unit>
        <trans-unit id="f3493e2a2c4e4ad9e265942ad2fd137cc9804a32" translate="yes" xml:space="preserve">
          <source>It is generally recommended to avoid using significantly more processes or threads than the number of CPUs on a machine. Over-subscription happens when a program is running too many threads at the same time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e5aa329cff0eb3a121eaf66246e864cad7413ee" translate="yes" xml:space="preserve">
          <source>It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples. For more tips see Laurens van der Maaten&amp;rsquo;s FAQ [2].</source>
          <target state="translated">Настоятельно рекомендуется использовать другой метод уменьшения размерности (например, PCA для плотных данных или TruncatedSVD для разреженных данных), чтобы уменьшить количество измерений до разумного количества (например, 50), если количество функций очень велико. Это подавит некоторый шум и ускорит вычисление попарных расстояний между выборками. Дополнительные советы см. В FAQ Лоренса ван дер Маатена [2].</target>
        </trans-unit>
        <trans-unit id="4c694641d1b1cd9e68259bd2f7aabf747615adda" translate="yes" xml:space="preserve">
          <source>It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the &lt;code&gt;fit&lt;/code&gt; method. The identifier that this implementation uses is the integer value \(-1\).</source>
          <target state="translated">Важно , чтобы назначить идентификатор немеченых точек вместе с мечеными данными при подготовке модели с &lt;code&gt;fit&lt;/code&gt; методом. Идентификатор, который использует эта реализация, - это целочисленное значение \ (- 1 \).</target>
        </trans-unit>
        <trans-unit id="643f8f6ee250eb138ea3f0ff80df853cb01ed9c1" translate="yes" xml:space="preserve">
          <source>It is important to keep in mind that the coefficients that have been dropped may still be related to the outcome by themselves: the model chose to suppress them because they bring little or no additional information on top of the other features. Additionnaly, this selection is unstable for correlated features, and should be interpreted with caution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a067b4f8fd8c4002a8fc9abd7aa015e146d303ad" translate="yes" xml:space="preserve">
          <source>It is important to note that when the number of samples is much larger than the number of features, one would expect that no shrinkage would be necessary. The intuition behind this is that if the population covariance is full rank, when the number of sample grows, the sample covariance will also become positive definite. As a result, no shrinkage would necessary and the method should automatically do this.</source>
          <target state="translated">Важно отметить,что когда количество образцов значительно превышает количество характеристик,можно ожидать,что усадки не потребуется.Интуиция,лежащая в основе этого,заключается в том,что при полном ранге ковариативности популяции,когда количество выборки растет,ковариативность выборки также становится положительной.В результате,усадка не потребуется,и метод должен делать это автоматически.</target>
        </trans-unit>
        <trans-unit id="d9e45bb570908f10d72f7b51c91c236b78670a3c" translate="yes" xml:space="preserve">
          <source>It is made of 150 observations of irises, each described by 4 features: their sepal and petal length and width, as detailed in &lt;code&gt;iris.DESCR&lt;/code&gt;.</source>
          <target state="translated">Он состоит из 150 наблюдений ирисов, каждое из которых описывается четырьмя характеристиками: длиной и шириной чашелистиков и лепестков, как указано в &lt;code&gt;iris.DESCR&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1856ef8269f110a1ccc7c37c9db810b8176fc5f8" translate="yes" xml:space="preserve">
          <source>It is more efficient than the LassoCV if only a small number of features are selected compared to the total number, for instance if there are very few samples compared to the number of features.</source>
          <target state="translated">Он более эффективен,чем LassoCV,если по сравнению с общим количеством выбрано лишь небольшое количество функций,например,если по сравнению с количеством функций выбрано очень мало выборок.</target>
        </trans-unit>
        <trans-unit id="1d58fe1839ae301f10f6b9aaac159ed67a9eabfe" translate="yes" xml:space="preserve">
          <source>It is not appropriate to pass these predictions into an evaluation metric. Use &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; to measure generalization error.</source>
          <target state="translated">Передавать эти прогнозы в метрику оценки нецелесообразно. Используйте &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt; для измерения ошибки обобщения.</target>
        </trans-unit>
        <trans-unit id="9af2e9f8fa22ff915f29e1a168987ff536812b91" translate="yes" xml:space="preserve">
          <source>It is not recommended to hard-code the backend name in a call to Parallel in a library. Instead it is recommended to set soft hints (prefer) or hard constraints (require) so as to make it possible for library users to change the backend from the outside using the parallel_backend context manager.</source>
          <target state="translated">Не рекомендуется жестко кодировать имя бэкэнда при вызове Parallel в библиотеке.Вместо этого рекомендуется задавать мягкие подсказки (предпочитают)или жесткие ограничения (требуют),чтобы пользователи библиотеки могли изменять бекенд извне с помощью контекстного менеджера параллельного_бекенда.</target>
        </trans-unit>
        <trans-unit id="b26cf025ddad5c1f883715bf24d85887eccade22" translate="yes" xml:space="preserve">
          <source>It is not regularized (penalized).</source>
          <target state="translated">Она не легализована (наказана).</target>
        </trans-unit>
        <trans-unit id="3023247377e7882a0cbda1c2d8280926be6aa8ba" translate="yes" xml:space="preserve">
          <source>It is now possible to prune most tree-based estimators once the trees are built. The pruning is based on minimal cost-complexity. Read more in the &lt;a href=&quot;../../modules/tree#minimal-cost-complexity-pruning&quot;&gt;User Guide&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f18c5e38092754d2adb7bb6eb5c0799854e297b3" translate="yes" xml:space="preserve">
          <source>It is numerically efficient in contexts where p &amp;gt;&amp;gt; n (i.e., when the number of dimensions is significantly greater than the number of points)</source>
          <target state="translated">Он численно эффективен в контекстах, где p &amp;gt;&amp;gt; n (т. Е. Когда количество измерений значительно превышает количество точек)</target>
        </trans-unit>
        <trans-unit id="3387956abcbcbc8c7f2e1b04a07247bbce69a743" translate="yes" xml:space="preserve">
          <source>It is numerically efficient in contexts where the number of features is significantly greater than the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7122bd43c891f087ca247f2fcde5236f637b0c" translate="yes" xml:space="preserve">
          <source>It is often interesting to project data to a lower-dimensional space that preserves most of the variance, by dropping the singular vector of components associated with lower singular values.</source>
          <target state="translated">Часто бывает интересно проецировать данные на меньшее по размеру пространство,сохраняющее большую часть дисперсии,путем опускания сингулярного вектора компонентов,связанных с меньшими сингулярными значениями.</target>
        </trans-unit>
        <trans-unit id="5ed0af274291a2311daa7ee05d7bd79f85fc7e49" translate="yes" xml:space="preserve">
          <source>It is possible and recommended to search the hyper-parameter space for the best &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt; score.</source>
          <target state="translated">Можно и рекомендуется поискать в пространстве гиперпараметров лучший результат &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;перекрестной проверки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="19b21329d1ba1e2fd90b4634d03905cf0f5e7826" translate="yes" xml:space="preserve">
          <source>It is possible to adjust the threshold of the binarizer:</source>
          <target state="translated">Можно настроить порог бинаризатора:</target>
        </trans-unit>
        <trans-unit id="5fdc4b2c9af36a36fca156373f6cb7c574f550b3" translate="yes" xml:space="preserve">
          <source>It is possible to compute per-label precisions, recalls, F1-scores and supports instead of averaging:</source>
          <target state="translated">Вместо усреднения можно вычислять точность на метку,вспоминания,F1-обновления и поддержки:</target>
        </trans-unit>
        <trans-unit id="c890fcaf4f6baafc6ccf39a67fce7daf92b8b950" translate="yes" xml:space="preserve">
          <source>It is possible to control the randomness for reproducibility of the results by explicitly seeding the &lt;code&gt;random_state&lt;/code&gt; pseudo random number generator.</source>
          <target state="translated">Можно контролировать случайность для воспроизводимости результатов, явно &lt;code&gt;random_state&lt;/code&gt; генератора псевдослучайных чисел random_state .</target>
        </trans-unit>
        <trans-unit id="8c436001d07579c89b669f127dbaf0c3bd65de34" translate="yes" xml:space="preserve">
          <source>It is possible to customize the behavior by passing a callable to the vectorizer constructor:</source>
          <target state="translated">Можно настроить поведение,передав вызываемый конструктор векторизатора:</target>
        </trans-unit>
        <trans-unit id="0839b4d3a34db46e778e581b781425b62631583b" translate="yes" xml:space="preserve">
          <source>It is possible to disable either centering or scaling by either passing &lt;code&gt;with_mean=False&lt;/code&gt; or &lt;code&gt;with_std=False&lt;/code&gt; to the constructor of &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Можно отключить центрирование или масштабирование, передав &lt;code&gt;with_mean=False&lt;/code&gt; или &lt;code&gt;with_std=False&lt;/code&gt; конструктору &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="85a1eed4b8a0f5199be27070848fbc013f8f8638" translate="yes" xml:space="preserve">
          <source>It is possible to get back the category names as follows:</source>
          <target state="translated">Названия категорий можно получить обратно следующим образом:</target>
        </trans-unit>
        <trans-unit id="6b11842b410c7ed9014abd60118219965dd51782" translate="yes" xml:space="preserve">
          <source>It is possible to introspect the scaler attributes to find about the exact nature of the transformation learned on the training data:</source>
          <target state="translated">Можно провести интроспекцию атрибутов скалера,чтобы узнать точную природу трансформации,усвоенную на тренинговых данных:</target>
        </trans-unit>
        <trans-unit id="d994dbf018869cdf387e647211852d55a08f6930" translate="yes" xml:space="preserve">
          <source>It is possible to load only a sub-selection of the categories by passing the list of the categories to load to the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Можно загрузить только подвыбор категорий, передав список категорий для загрузки в функцию &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="03749a52f5e2e7e976928d01767369407c7307c4" translate="yes" xml:space="preserve">
          <source>It is possible to mix sparse and dense arrays in the same run:</source>
          <target state="translated">Возможно смешивать разреженные и плотные массивы в одном прогоне:</target>
        </trans-unit>
        <trans-unit id="54adadb321f18cc462f6fa41bc0c4a25f1f6b29d" translate="yes" xml:space="preserve">
          <source>It is possible to obtain the p-values and confidence intervals for coefficients in cases of regression without penalization. The &lt;code&gt;statsmodels
package &amp;lt;https://pypi.org/project/statsmodels/&amp;gt;&lt;/code&gt; natively supports this. Within sklearn, one could use bootstrapping instead as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be16ce674bae3bf54f6cdc3d4d41c5990ca746b6" translate="yes" xml:space="preserve">
          <source>It is possible to overcome those limitations by combining the &amp;ldquo;hashing trick&amp;rdquo; (&lt;a href=&quot;#feature-hashing&quot;&gt;Feature hashing&lt;/a&gt;) implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt;&lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt;&lt;/a&gt; class and the text preprocessing and tokenization features of the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Эти ограничения можно преодолеть, объединив &amp;laquo;трюк с хешированием&amp;raquo; ( &lt;a href=&quot;#feature-hashing&quot;&gt;хеширование функций&lt;/a&gt; ), реализованный классом &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt; &lt;code&gt;sklearn.feature_extraction.FeatureHasher&lt;/code&gt; &lt;/a&gt; и функциями предварительной обработки текста и токенизации &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="737f1fd475d1dc22b14b4896563d476e36ccb4e8" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Можно сохранить модель в scikit-learn, используя встроенную в Python модель сохраняемости, &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="1d319918af937e7b588f1bdf4ba0c9bc1d2e6a8f" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, namely &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="translated">Можно сохранить модель в scikit-learn, используя встроенную модель персистентности Python, а именно &lt;a href=&quot;https://docs.python.org/2/library/pickle.html&quot;&gt;pickle&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="c1dfe5304fca32594b4f7b15a0ed1671355448d1" translate="yes" xml:space="preserve">
          <source>It is possible to save a model in scikit-learn by using Python&amp;rsquo;s built-in persistence model, namely &lt;a href=&quot;https://docs.python.org/3/library/pickle.html&quot;&gt;pickle&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="33bdca276514e666ea92e40ef8d9c04e5206a96b" translate="yes" xml:space="preserve">
          <source>It is possible to specify this explicitly using the parameter &lt;code&gt;categories&lt;/code&gt;. There are two genders, four possible continents and four web browsers in our dataset:</source>
          <target state="translated">Это можно указать явно с помощью &lt;code&gt;categories&lt;/code&gt; параметров . В нашем наборе данных есть два пола, четыре возможных континента и четыре веб-браузера:</target>
        </trans-unit>
        <trans-unit id="7291e604dadcc649d0d77ccb4ebf5e3c457ba713" translate="yes" xml:space="preserve">
          <source>It is recommend to use &lt;a href=&quot;sklearn.metrics.plot_confusion_matrix#sklearn.metrics.plot_confusion_matrix&quot;&gt;&lt;code&gt;plot_confusion_matrix&lt;/code&gt;&lt;/a&gt; to create a &lt;a href=&quot;#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;. All parameters are stored as attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab8a32e7f4d09197b24de455e36e8e5fe3df1e84" translate="yes" xml:space="preserve">
          <source>It is recommend to use &lt;a href=&quot;sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt; to create a visualizer. All parameters are stored as attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80b150a43cd5aba26116528fb4f30933db56b582" translate="yes" xml:space="preserve">
          <source>It is recommend to use &lt;a href=&quot;sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;plot_roc_curve&lt;/code&gt;&lt;/a&gt; to create a visualizer. All parameters are stored as attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f18c0fc60439524a8f745b0ef99ce87a71814897" translate="yes" xml:space="preserve">
          <source>It is recommended to use &lt;a href=&quot;sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to create a &lt;a href=&quot;#sklearn.inspection.PartialDependenceDisplay&quot;&gt;&lt;code&gt;PartialDependenceDisplay&lt;/code&gt;&lt;/a&gt;. All parameters are stored as attributes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbfa3a3539d1ad40958cd50540686b2891b5e349" translate="yes" xml:space="preserve">
          <source>It is sometimes not enough to center and scale the features independently, since a downstream model can further make some assumption on the linear independence of the features.</source>
          <target state="translated">Иногда бывает недостаточно самостоятельно центрировать и масштабировать черты,так как нисходящая модель может в дальнейшем сделать некоторое предположение о линейной независимости черт.</target>
        </trans-unit>
        <trans-unit id="b49f552a6383ab2c79a28eb8ae358eb905c8df59" translate="yes" xml:space="preserve">
          <source>It is sometimes tedious to find the model which will best perform on a given dataset. Stacking provide an alternative by combining the outputs of several learners, without the need to choose a model specifically. The performance of stacking is usually close to the best model and sometimes it can outperform the prediction performance of each individual model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="311a1593daf1f1187805481bab88c0d399c3cecf" translate="yes" xml:space="preserve">
          <source>It is sometimes worthwhile storing the state of a specific transformer since it could be used again. Using a pipeline in &lt;code&gt;GridSearchCV&lt;/code&gt; triggers such situations. Therefore, we use the argument &lt;code&gt;memory&lt;/code&gt; to enable caching.</source>
          <target state="translated">Иногда имеет смысл сохранить состояние конкретного трансформатора, поскольку его можно использовать снова. Использование конвейера в &lt;code&gt;GridSearchCV&lt;/code&gt; вызывает такие ситуации. Поэтому мы используем &lt;code&gt;memory&lt;/code&gt; аргументов, чтобы включить кеширование.</target>
        </trans-unit>
        <trans-unit id="9d1619fcc011ef5a461992b135770b43d5982f12" translate="yes" xml:space="preserve">
          <source>It is still an open problem as to how useful single vs. multiple imputation is in the context of prediction and classification when the user is not interested in measuring uncertainty due to missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba51434e495bfdf85ff2401c563345468fae8389" translate="yes" xml:space="preserve">
          <source>It is the fastest algorithm for learning mixture models</source>
          <target state="translated">Это самый быстрый алгоритм для изучения моделей смеси.</target>
        </trans-unit>
        <trans-unit id="5c9cedaa4c291702a05bee05d8b7517536cf8c97" translate="yes" xml:space="preserve">
          <source>It is the opposite as as bigger is better, i.e. large values correspond to inliers.</source>
          <target state="translated">Все наоборот,так как чем больше,тем лучше,т.е.большие значения соответствуют инсайдерам.</target>
        </trans-unit>
        <trans-unit id="eec2b41e384c85c1e4587a1c1f6fa007f24ac337" translate="yes" xml:space="preserve">
          <source>It is the opposite as bigger is better, i.e. large values correspond to inliers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0c456c256349cc53ca134d105c8be601465dd39" translate="yes" xml:space="preserve">
          <source>It is worth noting that RandomForests and ExtraTrees can be fitted in parallel on many cores as each tree is built independently of the others. AdaBoost&amp;rsquo;s samples are built sequentially and so do not use multiple cores.</source>
          <target state="translated">Стоит отметить, что RandomForests и ExtraTrees могут быть установлены параллельно на многих ядрах, поскольку каждое дерево строится независимо от других. Образцы AdaBoost создаются последовательно и поэтому не используют несколько ядер.</target>
        </trans-unit>
        <trans-unit id="9876d3b6328cf0e41b8f18a6a35d45d86ad7b5f1" translate="yes" xml:space="preserve">
          <source>It is worth noting that more than 93% of policyholders have zero claims. If we were to convert this problem into a binary classification task, it would be significantly imbalanced, and even a simplistic model that would only predict mean can achieve an accuracy of 93%.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86441e9f0bfca4823b62f4a6d4cecce7c1b80a8e" translate="yes" xml:space="preserve">
          <source>It might be possible to trade some accuracy on the training set for a slightly better accuracy on the test set by limiting the capacity of the trees (for instance by setting &lt;code&gt;min_samples_leaf=5&lt;/code&gt; or &lt;code&gt;min_samples_leaf=10&lt;/code&gt;) so as to limit overfitting while not introducing too much underfitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1e3cdc828409a9c2610db18343fc252165aed81" translate="yes" xml:space="preserve">
          <source>It might seem questionable to use a (penalized) Least Squares loss to fit a classification model instead of the more traditional logistic or hinge losses. However in practice all those models can lead to similar cross-validation scores in terms of accuracy or precision/recall, while the penalized least squares loss used by the &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt; allows for a very different choice of the numerical solvers with distinct computational performance profiles.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4029704b1c865bc18db0f7f71b472d5421882ac" translate="yes" xml:space="preserve">
          <source>It produces a full piecewise linear solution path, which is useful in cross-validation or similar attempts to tune the model.</source>
          <target state="translated">Она создает полный кусочно-линейный путь решения,что полезно при перекрестной проверке или подобных попытках настройки модели.</target>
        </trans-unit>
        <trans-unit id="dec67b5f65557893043d8c253cdd2dab65f3a96a" translate="yes" xml:space="preserve">
          <source>It represents the proportion of variance (of y) that has been explained by the independent variables in the model. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4dee1947755b5fe4ca1a29e0b9b0f0b85817660" translate="yes" xml:space="preserve">
          <source>It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.</source>
          <target state="translated">В дополнение к результатам теста он возвращает надпись,содержащую время,необходимое для тренировки,баллы (и,по желанию,оценки тренировок,а также подогнанные оценочные баллы).</target>
        </trans-unit>
        <trans-unit id="be2089f68dcca4fd6c2250f878425dd499fc444a" translate="yes" xml:space="preserve">
          <source>It returns a dictionary-like object, with the following attributes:</source>
          <target state="translated">Он возвращает словарный объект со следующими атрибутами:</target>
        </trans-unit>
        <trans-unit id="6f65f619abd94296c7075a4b5d91a76ac1e641bc" translate="yes" xml:space="preserve">
          <source>It returns a floating point number that quantifies the &lt;code&gt;estimator&lt;/code&gt; prediction quality on &lt;code&gt;X&lt;/code&gt;, with reference to &lt;code&gt;y&lt;/code&gt;. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.</source>
          <target state="translated">Он возвращает число с плавающей запятой, которое количественно определяет качество предсказания &lt;code&gt;estimator&lt;/code&gt; по &lt;code&gt;X&lt;/code&gt; со ссылкой на &lt;code&gt;y&lt;/code&gt; . Опять же, по соглашению, более высокие числа лучше, поэтому, если ваш секретарь сообщает о проигрыше, это значение следует отрицать.</target>
        </trans-unit>
        <trans-unit id="58c0c1b9288f5ba70bfdf3e509c8376ea38265d4" translate="yes" xml:space="preserve">
          <source>It should be noted that Johnson-Lindenstrauss lemma can yield very conservative estimated of the required number of components as it makes no assumption on the structure of the dataset.</source>
          <target state="translated">Следует отметить,что лемма Джонсона-Линденстрауса может дать очень консервативную оценку требуемого количества компонентов,так как не делает никаких предположений о структуре набора данных.</target>
        </trans-unit>
        <trans-unit id="af7347a7c717add0101a2649bad5550dc47a184a" translate="yes" xml:space="preserve">
          <source>It shows how to use &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; to approximate the feature map of an RBF kernel for classification with an SVM on the digits dataset. Results using a linear SVM in the original space, a linear SVM using the approximate mappings and using a kernelized SVM are compared. Timings and accuracy for varying amounts of Monte Carlo samplings (in the case of &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt;, which uses random Fourier features) and different sized subsets of the training set (for &lt;a href=&quot;../../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;) for the approximate mapping are shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bcecde02163a3a6b9fb69b7700a66c21be36347" translate="yes" xml:space="preserve">
          <source>It shows how to use &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt; to approximate the feature map of an RBF kernel for classification with an SVM on the digits dataset. Results using a linear SVM in the original space, a linear SVM using the approximate mappings and using a kernelized SVM are compared. Timings and accuracy for varying amounts of Monte Carlo samplings (in the case of &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt;, which uses random Fourier features) and different sized subsets of the training set (for &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;) for the approximate mapping are shown.</source>
          <target state="translated">В нем показано, как использовать &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; для аппроксимации карты характеристик ядра RBF для классификации с помощью SVM в наборе данных цифр. Сравниваются результаты с использованием линейной SVM в исходном пространстве, линейной SVM, использующей приблизительные отображения и использующей ядро ​​SVM. Показаны сроки и точность для различного количества выборок Монте-Карло (в случае &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; , который использует случайные функции Фурье) и подмножества обучающего набора разного размера (для &lt;a href=&quot;../modules/generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; ) для приблизительного отображения.</target>
        </trans-unit>
        <trans-unit id="45249c231a1e8d583e28deb277d22f5fe88e16b7" translate="yes" xml:space="preserve">
          <source>It turns a collection of text documents into a scipy.sparse matrix holding token occurrence counts (or binary occurrence information), possibly normalized as token frequencies if norm=&amp;rsquo;l1&amp;rsquo; or projected on the euclidean unit sphere if norm=&amp;rsquo;l2&amp;rsquo;.</source>
          <target state="translated">Он превращает набор текстовых документов в матрицу scipy.sparse, содержащую количество вхождений токенов (или двоичную информацию вхождений), возможно, нормализованные как частоты токенов, если norm = 'l1', или проецируемые на евклидову единичную сферу, если norm = 'l2'.</target>
        </trans-unit>
        <trans-unit id="9b65a724f589693294d8b39fded9beef68bf84ef" translate="yes" xml:space="preserve">
          <source>It updates its model only on mistakes.</source>
          <target state="translated">Он обновляет свою модель только на ошибки.</target>
        </trans-unit>
        <trans-unit id="4ef1ebaa3d2757730ff62ab1b50211fc95aec89a" translate="yes" xml:space="preserve">
          <source>It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.</source>
          <target state="translated">Он использует LAPACK реализацию полного SVD или рандомизированного усеченного SVD методом Halko и др.2009,в зависимости от формы входных данных и количества компонентов для извлечения.</target>
        </trans-unit>
        <trans-unit id="74ae47bdcf2723d7a82146ada9f167c02a150388" translate="yes" xml:space="preserve">
          <source>It will plot the class decision boundaries given by a Nearest Neighbors classifier when using the Euclidean distance on the original features, versus using the Euclidean distance after the transformation learned by Neighborhood Components Analysis. The latter aims to find a linear transformation that maximises the (stochastic) nearest neighbor classification accuracy on the training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80b76c72ce07f72ff1bcc8279eceffb68f3a73b2" translate="yes" xml:space="preserve">
          <source>It would be possible to get even higher predictive performance with a larger neural network but the training would also be significantly more expensive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb35f7366145b28ea8e69aba84c19929cb4fd162" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s also possible for almost all of these function to constrain the output to be a tuple containing only the data and the target, by setting the &lt;code&gt;return_X_y&lt;/code&gt; parameter to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Также для почти всех этих функций возможно ограничить вывод как кортеж, содержащий только данные и цель, установив для параметра &lt;code&gt;return_X_y&lt;/code&gt; значение &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="522ad20a1aa12ab3e8e796322f388a9318be6368" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s clear how the kernel shape affects the smoothness of the resulting distribution. The scikit-learn kernel density estimator can be used as follows:</source>
          <target state="translated">Понятно, как форма ядра влияет на гладкость полученного распределения. Оценщик плотности ядра scikit-learn можно использовать следующим образом:</target>
        </trans-unit>
        <trans-unit id="35600165765d17d14f9a53e3a40d6c087a8e15cc" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s possible to visualize the tree representing the hierarchical merging of clusters as a dendrogram. Visual inspection can often be useful for understanding the structure of the data, though more so in the case of small sample sizes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="262f72bd253b7e8f886f3645ecd5afaaf624d7fc" translate="yes" xml:space="preserve">
          <source>Iterate 2 and 3 until convergence.</source>
          <target state="translated">Итерация 2 и 3 до конвергенции.</target>
        </trans-unit>
        <trans-unit id="e39adff24d3659cea88912062bf2425d11890a07" translate="yes" xml:space="preserve">
          <source>Iterative imputation of the missing values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2f172891cc8c1241e8513ed23c4f46ceb939f0f" translate="yes" xml:space="preserve">
          <source>Iterative procedure to maximize the evidence</source>
          <target state="translated">Итеративная процедура для максимизации доказательств</target>
        </trans-unit>
        <trans-unit id="1e87dcaf344d15783f1af4ad18b162b497d772d4" translate="yes" xml:space="preserve">
          <source>Its dual is</source>
          <target state="translated">Его двойственность заключается в том,что</target>
        </trans-unit>
        <trans-unit id="ce6398892ce7bfa57c8075a52d29f534a23469a6" translate="yes" xml:space="preserve">
          <source>Its validation performance, measured via the \(R^2\) score, is significantly larger than the chance level. This makes it possible to use the &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt; function to probe which features are most predictive:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07da5fcab12f57a49e864df0a2dcb43ec8cd118b" translate="yes" xml:space="preserve">
          <source>J&amp;oslash;rgensen, B. (1992). The theory of exponential dispersion models and analysis of deviance. Monografias de matem&amp;aacute;tica, no. 51. See also &lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_dispersion_model&quot;&gt;Exponential dispersion model.&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d7e5d74ebe16b65b422b57dd9089de563aa7d4b5" translate="yes" xml:space="preserve">
          <source>J. Cohen (1960). &amp;ldquo;A coefficient of agreement for nominal scales&amp;rdquo;. Educational and Psychological Measurement 20(1):37-46. doi:10.1177/001316446002000104.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ba292a3729a3ffa6797e98ae7a24bba4f0e087f" translate="yes" xml:space="preserve">
          <source>J. Davis, M. Goadrich, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;The Relationship Between Precision-Recall and ROC Curves&lt;/a&gt;, ICML 2006.</source>
          <target state="translated">Дж. Дэвис, М. Гоадрич, &lt;a href=&quot;http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf&quot;&gt;Взаимосвязь между&lt;/a&gt; точным воспроизведением и кривыми ROC , ICML 2006.</target>
        </trans-unit>
        <trans-unit id="9f9ca6a90c561398be254053aedc4a945c9160d7" translate="yes" xml:space="preserve">
          <source>J. Friedman, &amp;ldquo;Multivariate adaptive regression splines&amp;rdquo;, The Annals of Statistics 19 (1), pages 1-67, 1991.</source>
          <target state="translated">Дж. Фридман, &amp;laquo;Сплайны многомерной адаптивной регрессии&amp;raquo;, &amp;laquo;Анналы статистики&amp;raquo; 19 (1), страницы 1-67, 1991.</target>
        </trans-unit>
        <trans-unit id="f3a4e2abf1b3937c134504328e857f33b32a50ea" translate="yes" xml:space="preserve">
          <source>J. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.</source>
          <target state="translated">J.Фридман,Приближение Жадных Функций:Машина градиентной стимуляции,Летопись статистики,Том 29,№ 5,2001.</target>
        </trans-unit>
        <trans-unit id="f06167e7b529cb39087bd6b97f521b456419a7cd" translate="yes" xml:space="preserve">
          <source>J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov. &amp;ldquo;Neighbourhood Components Analysis&amp;rdquo;. Advances in Neural Information Processing Systems. 17, 513-520, 2005. &lt;a href=&quot;http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf&quot;&gt;http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37cd6f13ac969b2cba8a5a7a242580515d06793b" translate="yes" xml:space="preserve">
          <source>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (&lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt;)</source>
          <target state="translated">Дж. Майрал, Ф. Бах, Дж. Понсе, Дж. Сапиро, 2009: изучение онлайн-словарей для разреженного кодирования ( &lt;a href=&quot;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;http://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="8417a497b98a8d480d1cb9818d1f322bb7565268" translate="yes" xml:space="preserve">
          <source>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (&lt;a href=&quot;https://www.di.ens.fr/sierra/pdfs/icml09.pdf&quot;&gt;https://www.di.ens.fr/sierra/pdfs/icml09.pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d67bb0042b556d1819c5bcf6e551c8393e0d921f" translate="yes" xml:space="preserve">
          <source>J. Nothman, H. Qin and R. Yurchak (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&amp;ldquo;Stop Word Lists in Free Open-source Software Packages&amp;rdquo;&lt;/a&gt;. In &lt;em&gt;Proc. Workshop for NLP Open Source Software&lt;/em&gt;.</source>
          <target state="translated">Дж. Нотман, Х. Цинь и Р. Юрчак (2018). &lt;a href=&quot;http://aclweb.org/anthology/W18-2502&quot;&gt;&amp;laquo;Списки стоп-слов в бесплатных пакетах программного обеспечения с открытым исходным кодом&amp;raquo;&lt;/a&gt; . В &lt;em&gt;Proc. Практикум по НЛП с открытым исходным кодом&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="40bd5fef8dd5af699d79639063d7832cf1e45e49" translate="yes" xml:space="preserve">
          <source>J. Nothman, H. Qin and R. Yurchak (2018). &lt;a href=&quot;https://aclweb.org/anthology/W18-2502&quot;&gt;&amp;ldquo;Stop Word Lists in Free Open-source Software Packages&amp;rdquo;&lt;/a&gt;. In &lt;em&gt;Proc. Workshop for NLP Open Source Software&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="692e866d29ab5ac27b12eb939942a283756e56c6" translate="yes" xml:space="preserve">
          <source>J. Zhu, H. Zou, S. Rosset, T. Hastie. &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Дж. Чжу, Х. Цзоу, С. Россет, Т. Хасти. &amp;laquo;Мульти-класс AdaBoost&amp;raquo;, 2009 г.</target>
        </trans-unit>
        <trans-unit id="5d92020b429e9c336d3ae7d33c4ba163d63036bb" translate="yes" xml:space="preserve">
          <source>J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.</source>
          <target state="translated">Джей-Ар Куинлан.C4.5:программы для машинного обучения.Морган Кауфманн,1993.</target>
        </trans-unit>
        <trans-unit id="b259e0488f66e10ad76098d33440aa4c5f23c876" translate="yes" xml:space="preserve">
          <source>JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case&lt;/a&gt;</source>
          <target state="translated">JA Wegelin &lt;a href=&quot;https://www.stat.washington.edu/research/reports/2000/tr371.pdf&quot;&gt;Обзор методов частичных наименьших квадратов (PLS) с упором на двухблочный случай&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="89591613ce2ead27076b0dd7b68b18da1f4e31d9" translate="yes" xml:space="preserve">
          <source>Jaccard similarity coefficient score</source>
          <target state="translated">балл коэффициента сходства Jaccard</target>
        </trans-unit>
        <trans-unit id="3dd35b446a7d3de6ee5688cfabde9bb7cc55f61a" translate="yes" xml:space="preserve">
          <source>JaccardDistance</source>
          <target state="translated">JaccardDistance</target>
        </trans-unit>
        <trans-unit id="493395686693db33a59d5eea00e82ad6c02c5742" translate="yes" xml:space="preserve">
          <source>Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case. Technical Report 371, Department of Statistics, University of Washington, Seattle, 2000.</source>
          <target state="translated">Джейкоб А.Уэгелин.Опрос методов наименьших частичных квадратов (PLS)с акцентом на двухблочный случай.Технический доклад 371,факультет статистики,Вашингтонский университет,Сиэтл,2000 год.</target>
        </trans-unit>
        <trans-unit id="b9a5b6145a558ec82725430f200fe46fa35f6aac" translate="yes" xml:space="preserve">
          <source>Jarvelin, K., &amp;amp; Kekalainen, J. (2002). Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems (TOIS), 20(4), 422-446.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="80af07b09c2acb231d89e62f1382b88433574f92" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank,</source>
          <target state="translated">Джесси Рид,Бернхард Пфаринджер,Джефф Холмс,Ю Фрэнк,</target>
        </trans-unit>
        <trans-unit id="6f9c9a3eee3a8f7459d68946df6ef289f22fee94" translate="yes" xml:space="preserve">
          <source>Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, &amp;ldquo;Classifier Chains for Multi-label Classification&amp;rdquo;, 2009.</source>
          <target state="translated">Джесси Рид, Бернхард Пфарингер, Джефф Холмс, Эйбе Франк, &amp;laquo;Цепочки классификаторов для многокомпонентной классификации&amp;raquo;, 2009 г.</target>
        </trans-unit>
        <trans-unit id="43121fdb3391941437c9f79e4fe2a93d4f69bed7" translate="yes" xml:space="preserve">
          <source>Joblib also tries to limit the oversubscription by limiting the number of threads usable in some third-party library threadpools like OpenBLAS, MKL or OpenMP. The default limit in each worker is set to &lt;code&gt;max(cpu_count() // effective_n_jobs, 1)&lt;/code&gt; but this limit can be overwritten with the &lt;code&gt;inner_max_num_threads&lt;/code&gt; argument which will be used to set this limit in the child processes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbd429df4e4127b1956a8217cca140ac1f4576de" translate="yes" xml:space="preserve">
          <source>Joblib is able to support both multi-processing and multi-threading. Whether joblib chooses to spawn a thread or a process depends on the &lt;strong&gt;backend&lt;/strong&gt; that it&amp;rsquo;s using.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbbc7351b3326fa09a2af62a2a8c482a7f498e4a" translate="yes" xml:space="preserve">
          <source>Joblib is currently unable to avoid oversubscription in a multi-threading context. It can only do so with the &lt;code&gt;loky&lt;/code&gt; backend (which spawns processes).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2da78ef6529cd970b51628e985f5f2ea249ac134" translate="yes" xml:space="preserve">
          <source>Johanna Hardin, David M Rocke. The distribution of robust distances. Journal of Computational and Graphical Statistics. December 1, 2005, 14(4): 928-946.</source>
          <target state="translated">Джоанна Хардин,Дэвид М.Рокк.Распределение прочных расстояний.Журнал вычислительной и графической статистики.1 декабря 2005,14(4):928-946.</target>
        </trans-unit>
        <trans-unit id="3cd3820aa7670cf9157f83a7b518b28ca957a3fc" translate="yes" xml:space="preserve">
          <source>John K. Dixon, &amp;ldquo;Pattern Recognition with Partly Missing Data&amp;rdquo;, IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue: 10, pp. 617 - 621, Oct. 1979. &lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/4310090/&quot;&gt;http://ieeexplore.ieee.org/abstract/document/4310090/&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f669c43cc07002b0d2c74696c2e577f06e2f830d" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;.</source>
          <target state="translated">Джон. Д. Келлехер, Брайан Мак Нейми, Аойф Д'Арси, (2015). &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Основы машинного обучения для прогнозной аналитики данных: алгоритмы, рабочие примеры и тематические исследования&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7aafef76ed32e6bfff8b0b682dc86da3ac5a13fa" translate="yes" xml:space="preserve">
          <source>John. D. Kelleher, Brian Mac Namee, Aoife D&amp;rsquo;Arcy, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies&lt;/a&gt;, 2015.</source>
          <target state="translated">Джон. Д. Келлехер, Брайан Мак Нейме, Аойф Д'Арси, &lt;a href=&quot;https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics&quot;&gt;Основы машинного обучения для прогнозного анализа данных: алгоритмы, отработанные примеры и тематические исследования&lt;/a&gt; , 2015 г.</target>
        </trans-unit>
        <trans-unit id="19e6bf8efc7133dd97d0abbd89569a0495139bdc" translate="yes" xml:space="preserve">
          <source>Joint feature selection with multi-task Lasso</source>
          <target state="translated">Выбор совместной функции с многозадачным Лассо</target>
        </trans-unit>
        <trans-unit id="6e210d8e33bded6f565ddf30568ce6ee46546dcb" translate="yes" xml:space="preserve">
          <source>Joint parameter selection</source>
          <target state="translated">Совместный выбор параметров</target>
        </trans-unit>
        <trans-unit id="5dcd2dd79faa568a08732dcdc7a1c5d001632db6" translate="yes" xml:space="preserve">
          <source>Journal of Machine Learning Research 15(Oct):3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</source>
          <target state="translated">Journal of Machine Learning Research 15 (октябрь): 3221-3245, 2014. &lt;a href=&quot;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7eaac587d1f40d409b66183976f554af82049338" translate="yes" xml:space="preserve">
          <source>Journal of Machine Learning Research 15(Oct):3221-3245, 2014. &lt;a href=&quot;https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&quot;&gt;https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6689749f561220cbe925de6f0809b1dc75c6258d" translate="yes" xml:space="preserve">
          <source>July, 1988</source>
          <target state="translated">июль 1988 года</target>
        </trans-unit>
        <trans-unit id="854e66ede1ccc0e35f92ec3068666dcad934aaf9" translate="yes" xml:space="preserve">
          <source>July; 1998</source>
          <target state="translated">июль 1998 года</target>
        </trans-unit>
        <trans-unit id="a2a7da9b458fe4f43b31552673f0b66352445d61" translate="yes" xml:space="preserve">
          <source>Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN Error Measures in MultiClass Prediction</source>
          <target state="translated">Юрман,Риккадонна,Фурланелло,(2012).Сравнение мер по ошибкам MCC и CEN в многоклассовом прогнозировании.</target>
        </trans-unit>
        <trans-unit id="a8dcc7a6052d083397dd89c88efdae4d16610c1e" translate="yes" xml:space="preserve">
          <source>Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;data transformations&lt;/a&gt; similarly should be learnt from a training set and applied to held-out data for prediction:</source>
          <target state="translated">Так же, как важно протестировать предсказатель на данных, полученных в результате обучения, предварительная обработка (например, стандартизация, выбор функций и т. Д.) И аналогичные &lt;a href=&quot;http://scikit-learn.org/stable/data_transforms.html#data-transforms&quot;&gt;преобразования данных&lt;/a&gt; аналогичным образом должны быть изучены из обучающего набора и применены к удерживаемым данным для прогнозирования. :</target>
        </trans-unit>
        <trans-unit id="bb93e8a53cb9de4ad35209178664abb04cf0e5f7" translate="yes" xml:space="preserve">
          <source>Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar &lt;a href=&quot;https://scikit-learn.org/0.23/data_transforms.html#data-transforms&quot;&gt;data transformations&lt;/a&gt; similarly should be learnt from a training set and applied to held-out data for prediction:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19ba747b37c5ad6ac1cc4689022bdfff83622716" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a in b), but with a nicer default message.</source>
          <target state="translated">Так же как и self.assertTrue(a в b),но с более приятным сообщением по умолчанию.</target>
        </trans-unit>
        <trans-unit id="a7abce2837c2684f6308e0a3abb93654038ccc5f" translate="yes" xml:space="preserve">
          <source>Just like self.assertTrue(a not in b), but with a nicer default message.</source>
          <target state="translated">Так же как и self.assertTrue(a не в b),но с более приятным сообщением по умолчанию.</target>
        </trans-unit>
        <trans-unit id="57113affe2edb0e21a97719d086746970040c08f" translate="yes" xml:space="preserve">
          <source>K&amp;auml;rkk&amp;auml;inen and S. &amp;Auml;yr&amp;auml;m&amp;ouml;: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;On Computation of Spatial Median for Robust Data Mining.&lt;/a&gt;</source>
          <target state="translated">Кярккяйнен и С. Эйрамё: &lt;a href=&quot;http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf&quot;&gt;О вычислении пространственной&lt;/a&gt; медианы для надежного интеллектуального анализа данных.</target>
        </trans-unit>
        <trans-unit id="7c859ded2bd8aa408f6c0369beaf2c2cf3f0ddde" translate="yes" xml:space="preserve">
          <source>K(X, Y) = &amp;lt;X, Y&amp;gt; / (||X||*||Y||)</source>
          <target state="translated">K (X, Y) = &amp;lt;X, Y&amp;gt; / (|| X || * || Y ||)</target>
        </trans-unit>
        <trans-unit id="86beb78a3bdf4132202cbc165378339bb7f278e3" translate="yes" xml:space="preserve">
          <source>K-Folds cross-validator</source>
          <target state="translated">перекрёстный валидатор K-Fold</target>
        </trans-unit>
        <trans-unit id="66e29f0aeaaf6f3b77934175874c79014b658ea2" translate="yes" xml:space="preserve">
          <source>K-Means</source>
          <target state="translated">K-Means</target>
        </trans-unit>
        <trans-unit id="bc6e2dbca5eeaca5cfd908f6085c13e70dbbe207" translate="yes" xml:space="preserve">
          <source>K-Means clustering</source>
          <target state="translated">кластеризация Кей-Минов</target>
        </trans-unit>
        <trans-unit id="57bc3e1ca5db2c1c7f140e0c9654a7e1bd0c4cd4" translate="yes" xml:space="preserve">
          <source>K-Means clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4dcab3f446cd66684df43251a7a52921a5b665f1" translate="yes" xml:space="preserve">
          <source>K-dimensional tree for fast generalized N-point problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c532c5671424d23a3a3bc85d7cee5f6f8a964404" translate="yes" xml:space="preserve">
          <source>K-fold iterator variant with non-overlapping groups.</source>
          <target state="translated">Вариант К-образного итератора с неперекрывающимися группами.</target>
        </trans-unit>
        <trans-unit id="8434c9f312099287fd33427192dcba6bdae1583b" translate="yes" xml:space="preserve">
          <source>K-means Clustering</source>
          <target state="translated">кластеризация K-средних</target>
        </trans-unit>
        <trans-unit id="16176fa529a1e6d30521129cdc8f04353aaff22e" translate="yes" xml:space="preserve">
          <source>K-means algorithm to use. The classical EM-style algorithm is &amp;ldquo;full&amp;rdquo;. The &amp;ldquo;elkan&amp;rdquo; variation is more efficient by using the triangle inequality, but currently doesn&amp;rsquo;t support sparse data. &amp;ldquo;auto&amp;rdquo; chooses &amp;ldquo;elkan&amp;rdquo; for dense data and &amp;ldquo;full&amp;rdquo; for sparse data.</source>
          <target state="translated">Используемый алгоритм K-средних. Классический алгоритм EM-стиля - &amp;laquo;полный&amp;raquo;. Вариант &amp;laquo;elkan&amp;raquo; более эффективен при использовании неравенства треугольника, но в настоящее время не поддерживает разреженные данные. &amp;laquo;Auto&amp;raquo; выбирает &amp;laquo;elkan&amp;raquo; для плотных данных и &amp;laquo;full&amp;raquo; для разреженных данных.</target>
        </trans-unit>
        <trans-unit id="c00998c8eabed1e931fa81c6f69faf59aad07506" translate="yes" xml:space="preserve">
          <source>K-means algorithm to use. The classical EM-style algorithm is &amp;ldquo;full&amp;rdquo;. The &amp;ldquo;elkan&amp;rdquo; variation is more efficient on data with well-defined clusters, by using the triangle inequality. However it&amp;rsquo;s more memory intensive due to the allocation of an extra array of shape (n_samples, n_clusters).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="848dff73d6f69d92cd5b01b40f76a731abde9743" translate="yes" xml:space="preserve">
          <source>K-means can be used for vector quantization. This is achieved using the transform method of a trained model of &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">K-средства могут использоваться для векторного квантования. Это достигается с помощью метода преобразования обученной модели &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ba78203e9e9f38ce3f7e015938283eb704622fc1" translate="yes" xml:space="preserve">
          <source>K-means clustering</source>
          <target state="translated">K-средняя кластеризация</target>
        </trans-unit>
        <trans-unit id="4c31918fe250fba32eafec9c8bd2408d0665baa0" translate="yes" xml:space="preserve">
          <source>K-means clustering algorithm.</source>
          <target state="translated">Алгоритм кластеризации К-средства.</target>
        </trans-unit>
        <trans-unit id="3f9399be9d9993e05f4712a210efb7bcf391430f" translate="yes" xml:space="preserve">
          <source>K-means is equivalent to the expectation-maximization algorithm with a small, all-equal, diagonal covariance matrix.</source>
          <target state="translated">К-средние эквивалентно алгоритму матожидания-максимизации с маленькой,полностью равной,диагональной ковариационной матрицей.</target>
        </trans-unit>
        <trans-unit id="f931e58c5b02fb6c60e80955646f359bee6ac7ee" translate="yes" xml:space="preserve">
          <source>K-means is often referred to as Lloyd&amp;rsquo;s algorithm. In basic terms, the algorithm has three steps. The first step chooses the initial centroids, with the most basic method being to choose \(k\) samples from the dataset \(X\). After initialization, K-means consists of looping between the two other steps. The first step assigns each sample to its nearest centroid. The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids are computed and the algorithm repeats these last two steps until this value is less than a threshold. In other words, it repeats until the centroids do not move significantly.</source>
          <target state="translated">K-средних часто называют алгоритмом Ллойда. В основном алгоритм состоит из трех шагов. На первом этапе выбираются начальные центроиды, при этом самый простой метод - выбрать \ (k \) выборки из набора данных \ (X \). После инициализации K-means состоит из цикла между двумя другими шагами. На первом этапе каждой выборке присваивается ближайший центроид. На втором этапе создаются новые центроиды, взяв среднее значение всех выборок, назначенных каждому предыдущему центроиду. Вычисляется разница между старым и новым центроидами, и алгоритм повторяет эти последние два шага, пока это значение не станет меньше порогового значения. Другими словами, это повторяется до тех пор, пока центроиды не переместятся значительно.</target>
        </trans-unit>
        <trans-unit id="c91b0be65ee9c7db25b71aa279369cca08edc7ca" translate="yes" xml:space="preserve">
          <source>K-means quantization</source>
          <target state="translated">квантование K-средних</target>
        </trans-unit>
        <trans-unit id="5cf295fcd230ab825b1fa5bcf82b9dac494d126c" translate="yes" xml:space="preserve">
          <source>KDTree for fast generalized N-point problems</source>
          <target state="translated">Дерево KDTree для быстрых обобщенных проблем с N точками</target>
        </trans-unit>
        <trans-unit id="34d74f913e8bd68fa4a9d1c4d3966f34ca72fc15" translate="yes" xml:space="preserve">
          <source>KDTree(X, leaf_size=40, metric=&amp;rsquo;minkowski&amp;rsquo;, **kwargs)</source>
          <target state="translated">KDTree (X, лист_размер = 40, метрика = 'минковски', ** kwargs)</target>
        </trans-unit>
        <trans-unit id="e6f48940c5e34202cb03c9567fde221973b85eb8" translate="yes" xml:space="preserve">
          <source>KNN Based Imputation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a130d990c735953536ce43a1c5cf50c4989bca1" translate="yes" xml:space="preserve">
          <source>Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators.</source>
          <target state="translated">Оценки Kappa могут быть вычислены для двоичных или многоклассовых задач,но не для многомаркировочных задач (за исключением ручного вычисления оценки на метку)и не более чем для двух аннотаторов.</target>
        </trans-unit>
        <trans-unit id="7642aa421288e310d04c4d2f1c88ac24e935cd02" translate="yes" xml:space="preserve">
          <source>Ke et. al. &lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree&quot;&gt;&amp;ldquo;LightGBM: A Highly Efficient Gradient BoostingDecision Tree&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="992bd2f88020b43ae9d881f8a8ecb43504cd4a74" translate="yes" xml:space="preserve">
          <source>Keep the 3 RGB channels instead of averaging them to a single gray level channel. If color is True the shape of the data has one more dimension than the shape with color = False.</source>
          <target state="translated">Держите 3 канала RGB вместо того,чтобы усреднять их до одного канала уровня серого.Если цвет равен True,то форма данных имеет на одно измерение больше,чем форма с цветом=False.</target>
        </trans-unit>
        <trans-unit id="e85b73c38883acb129e419e1a2f1719d75a444c5" translate="yes" xml:space="preserve">
          <source>Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.</source>
          <target state="translated">Кен Тан и Поннутхурай Н.Шугантан и Си Яо и А.Кай Цинь.Уменьшение линейной размерности с использованием релевантной взвешенной LDA.Школа электрической и электронной техники Наньаньского технологического университета.2005.</target>
        </trans-unit>
        <trans-unit id="4ac337776123607052d628758806e2172a140241" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimate of Species Distributions</source>
          <target state="translated">Оценка ядерной плотности распределения видов</target>
        </trans-unit>
        <trans-unit id="1794dd0445cf0665650fb5446983f4ef8a3519d3" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimation</source>
          <target state="translated">оценка зерновой плотности</target>
        </trans-unit>
        <trans-unit id="9837c7505d0f3a8c028c3a0430177597bb56e3e2" translate="yes" xml:space="preserve">
          <source>Kernel Density Estimation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bd4b1d4f074cf6b0f30ea849b2a75ad1d3777d9" translate="yes" xml:space="preserve">
          <source>Kernel PCA</source>
          <target state="translated">PCA Кернел</target>
        </trans-unit>
        <trans-unit id="e5cb129fc99d7ba99fe28de6d8de36380920334b" translate="yes" xml:space="preserve">
          <source>Kernel PCA was introduced in:</source>
          <target state="translated">Кернел PCA был представлен в:</target>
        </trans-unit>
        <trans-unit id="2064482c4c2332e23a8df06a915448e7e780cd46" translate="yes" xml:space="preserve">
          <source>Kernel Principal Component Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba5a4a64bda1b4288aa7730d4a3cc2a5a99cf5dc" translate="yes" xml:space="preserve">
          <source>Kernel Principal component analysis (KPCA)</source>
          <target state="translated">Анализ основных компонентов ядра (KPCA)</target>
        </trans-unit>
        <trans-unit id="f9f3967ca79560e0b7bba219989bbd17450e2f6e" translate="yes" xml:space="preserve">
          <source>Kernel bandwidth.</source>
          <target state="translated">Полоса пропускания ядра.</target>
        </trans-unit>
        <trans-unit id="8f8874978483d89d1eb3e15131193d11bfd798e3" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">Коэффициент ядра для 'rbf', 'poly' и 'sigmoid'.</target>
        </trans-unit>
        <trans-unit id="97392135d656893f41c86b28ea3abd0d9e018bae" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf kernel.</source>
          <target state="translated">Коэффициент ядра для ядра rbf.</target>
        </trans-unit>
        <trans-unit id="0ae546d11d3317bcab299286e34e2f35ebfa8832" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Коэффициент ядра для rbf,поли и сигмовидных ядер.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="4a5a36cb73b6fa8cb90e406a9b203038f766b3f9" translate="yes" xml:space="preserve">
          <source>Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels. Ignored for &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt;.</source>
          <target state="translated">Коэффициент ядра для ядер rbf, poly, sigmoid, laplacian и chi2. Игнорируется для &lt;code&gt;affinity='nearest_neighbors'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ed139f80ae0f25db98c92c5cce6311e8435271b" translate="yes" xml:space="preserve">
          <source>Kernel density estimation in scikit-learn is implemented in the &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator, which uses the Ball Tree or KD Tree for efficient queries (see &lt;a href=&quot;neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; for a discussion of these). Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions.</source>
          <target state="translated">Оценка плотности ядра в scikit-learn реализована в &lt;a href=&quot;generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt; , который использует Ball Tree или KD Tree для эффективных запросов ( обсуждение этих вопросов см. В разделе &amp;laquo; &lt;a href=&quot;neighbors#neighbors&quot;&gt;Ближайшие соседи&amp;raquo;&lt;/a&gt; ). Хотя в приведенном выше примере для простоты используется набор одномерных данных, оценка плотности ядра может быть выполнена в любом количестве измерений, хотя на практике проклятие размерности приводит к ухудшению его производительности в больших измерениях.</target>
        </trans-unit>
        <trans-unit id="55e8fbe20e17e26ae0f3d4e88a1aeba0651c9393" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Гиперпараметры ядра, для которых оценивается предельное логарифмическое правдоподобие. Если None, возвращается предварительно вычисленное значение log_marginal_likelihood для &lt;code&gt;self.kernel_.theta&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aef459d7999942524bf342d4727b96b71e8fe80a" translate="yes" xml:space="preserve">
          <source>Kernel hyperparameters for which the log-marginal likelihood is evaluated. In the case of multi-class classification, theta may be the hyperparameters of the compound kernel or of an individual kernel. In the latter case, all individual kernel get assigned the same theta values. If None, the precomputed log_marginal_likelihood of &lt;code&gt;self.kernel_.theta&lt;/code&gt; is returned.</source>
          <target state="translated">Гиперпараметры ядра, для которых оценивается предельное логарифмическое правдоподобие. В случае многоклассовой классификации тета может быть гиперпараметрами составного ядра или отдельного ядра. В последнем случае всем индивидуальным ядрам присваиваются одинаковые значения тета. Если None, возвращается предварительно вычисленное значение log_marginal_likelihood для &lt;code&gt;self.kernel_.theta&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e5fe7d4b4a2b4b1f4287c0408af092681ae17306" translate="yes" xml:space="preserve">
          <source>Kernel k(X, Y)</source>
          <target state="translated">Ядро k(X,Y)</target>
        </trans-unit>
        <trans-unit id="3ec24bca52509370dd13e99805241c7649952db1" translate="yes" xml:space="preserve">
          <source>Kernel map to be approximated. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number.</source>
          <target state="translated">Карта ядра должна быть аппроксимирована.Вызываемый объект должен принимать два аргумента и аргументы ключевого слова,переданные этому объекту как kernel_params,и должен возвращать номер с плавающей точкой.</target>
        </trans-unit>
        <trans-unit id="819d0e343c77a54a44f85a514be1d98b92643c33" translate="yes" xml:space="preserve">
          <source>Kernel mapping used internally. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number. Set to &amp;ldquo;precomputed&amp;rdquo; in order to pass a precomputed kernel matrix to the estimator methods instead of samples.</source>
          <target state="translated">Отображение ядра для внутреннего использования. Вызываемый объект должен принимать два аргумента и аргументы ключевого слова, переданные этому объекту как kernel_params, и должен возвращать число с плавающей запятой. Установите значение &amp;laquo;предварительно вычислено&amp;raquo;, чтобы передать предварительно вычисленную матрицу ядра методам оценки вместо выборок.</target>
        </trans-unit>
        <trans-unit id="438349cc7f220c5c2d499eba1d3d6c5414057ba4" translate="yes" xml:space="preserve">
          <source>Kernel mapping used internally. This parameter is directly passed to &lt;code&gt;sklearn.metrics.pairwise.pairwise_kernel&lt;/code&gt;. If &lt;code&gt;kernel&lt;/code&gt; is a string, it must be one of the metrics in &lt;code&gt;pairwise.PAIRWISE_KERNEL_FUNCTIONS&lt;/code&gt;. If &lt;code&gt;kernel&lt;/code&gt; is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a kernel matrix. Alternatively, if &lt;code&gt;kernel&lt;/code&gt; is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two rows from X as input and return the corresponding kernel value as a single number. This means that callables from &lt;a href=&quot;../classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; are not allowed, as they operate on matrices, not single samples. Use the string identifying the kernel instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5470105c2039f2210b1a2c9d8e55edfd818f2e42" translate="yes" xml:space="preserve">
          <source>Kernel matrix.</source>
          <target state="translated">Матрица ядра.</target>
        </trans-unit>
        <trans-unit id="839a7f66845e964bf2afbaec5611c3402217b903" translate="yes" xml:space="preserve">
          <source>Kernel methods like support vector machines or kernelized PCA rely on a property of reproducing kernel Hilbert spaces. For any positive definite kernel function \(k\) (a so called Mercer kernel), it is guaranteed that there exists a mapping \(\phi\) into a Hilbert space \(\mathcal{H}\), such that</source>
          <target state="translated">Методы ядра,такие как поддерживающие векторные машины или ядро PCA,полагаются на свойство воспроизведения пространств ядра Гильберта.Для любой положительной определенной функции ядра \(k\)(так называемое ядро Мерсера)гарантируется,что существует отображение \(\phi\)в пространство Гильберта \(\mathcal{H}\),такое,что</target>
        </trans-unit>
        <trans-unit id="a3bb404582c234b1b5161269097e65342126edc8" translate="yes" xml:space="preserve">
          <source>Kernel methods to project data into alternate dimensional spaces</source>
          <target state="translated">Методы ядра для проектирования данных в альтернативные размерные пространства</target>
        </trans-unit>
        <trans-unit id="7853e504e205e94517ed94484ade6d5285c25255" translate="yes" xml:space="preserve">
          <source>Kernel operators take one or two base kernels and combine them into a new kernel. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{sum}(X, Y) = k1(X, Y) + k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k1\) and \(k2\) and combines them via \(k_{product}(X, Y) = k1(X, Y) * k2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt;&lt;code&gt;Exponentiation&lt;/code&gt;&lt;/a&gt; kernel takes one base kernel and a scalar parameter \(exponent\) and combines them via \(k_{exp}(X, Y) = k(X, Y)^\text{exponent}\).</source>
          <target state="translated">Операторы ядра берут одно или два базовых ядра и объединяют их в новое ядро. &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt; ядро имеет два ядра \ (k1 \) и \ (k2 \) и объединяет их с помощью \ (k_ {сумма} (X, Y) = k1 (X, Y) + k2 (X, Y) \). &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; &lt;/a&gt; Ядро имеет два ядра \ (k1 \) и \ (k2 \) и объединяет их с помощью \ (k_ {произведение} (X, Y) = k1 (X, Y) * k2 (X, Y) \). &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt; &lt;code&gt;Exponentiation&lt;/code&gt; &lt;/a&gt; ядро занимает одно базовое ядро и скалярный параметр \ (экспоненту \) и объединяет их с помощью \ (k_ {ехр} (X, Y) = к (X, Y) = \ текст {показатель} \).</target>
        </trans-unit>
        <trans-unit id="6d4564c4032221fcc796901a96d1a6cf81d6aa2f" translate="yes" xml:space="preserve">
          <source>Kernel operators take one or two base kernels and combine them into a new kernel. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via \(k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via \(k_{product}(X, Y) = k_1(X, Y) * k_2(X, Y)\). The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.exponentiation#sklearn.gaussian_process.kernels.Exponentiation&quot;&gt;&lt;code&gt;Exponentiation&lt;/code&gt;&lt;/a&gt; kernel takes one base kernel and a scalar parameter \(p\) and combines them via \(k_{exp}(X, Y) = k(X, Y)^p\). Note that magic methods &lt;code&gt;__add__&lt;/code&gt;, &lt;code&gt;__mul___&lt;/code&gt; and &lt;code&gt;__pow__&lt;/code&gt; are overridden on the Kernel objects, so one can use e.g. &lt;code&gt;RBF() + RBF()&lt;/code&gt; as a shortcut for &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dc320ddac29ab60da57cafc47693079e4b6b082" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; combines &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;Ridge Regression&lt;/a&gt; (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">Регрессия гребня ядра (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; сочетает в себе &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;регрессию&lt;/a&gt; гребня (линейный метод наименьших квадратов с регуляризацией по l2-норме) с уловкой ядра. Таким образом, он изучает линейную функцию в пространстве, индуцированную соответствующим ядром и данными. Для нелинейных ядер это соответствует нелинейной функции в исходном пространстве.</target>
        </trans-unit>
        <trans-unit id="3fcbd037e0e31c66e26fa73fca7d9588d56b4cd8" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) &lt;a href=&quot;#m2012&quot; id=&quot;id1&quot;&gt;[M2012]&lt;/a&gt; combines &lt;a href=&quot;linear_model#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; (linear least squares with l2-norm regularization) with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel trick&lt;/a&gt;. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d585be11bb912be319b898c908d63ce568dd8c0" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</source>
          <target state="translated">Регрессия гребня ядра (KRR)сочетает регрессию гребня (линейные наименьшие квадраты с регуляризацией l2-формы)с трюком ядра.Таким образом,она узнает линейную функцию в пространстве,индуцированном соответствующим ядром и данными.Для нелинейных ядер это соответствует нелинейной функции в исходном пространстве.</target>
        </trans-unit>
        <trans-unit id="262cee695a2ed79939315817b4a3a26823167afe" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression combines ridge regression with the kernel trick</source>
          <target state="translated">Регрессия гребня ядра сочетает в себе регрессию гребня с трюком ядра</target>
        </trans-unit>
        <trans-unit id="589ad014b6254add975c198ac204f9560e253ac1" translate="yes" xml:space="preserve">
          <source>Kernel ridge regression.</source>
          <target state="translated">Кернел-хребетная регрессия.</target>
        </trans-unit>
        <trans-unit id="a797077c9a6730a652ad75f039a934d138c2b41f" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed.</source>
          <target state="translated">Ядро для использования в модели:линейное,полиномиальное,RBF,сигмовидное или предварительно рассчитанное.</target>
        </trans-unit>
        <trans-unit id="407ab400408caf91955e34873fdbfe1f6ae14b07" translate="yes" xml:space="preserve">
          <source>Kernel to use in the model: linear, polynomial, RBF, sigmoid or precomputed. &amp;lsquo;rbf&amp;rsquo; by default.</source>
          <target state="translated">Ядро для использования в модели: линейное, полиномиальное, RBF, сигмовидное или предварительно вычисленное. По умолчанию 'rbf'.</target>
        </trans-unit>
        <trans-unit id="716837a63a81bd1da24c9f2580ff0581777fc381" translate="yes" xml:space="preserve">
          <source>Kernel which is composed of a set of other kernels.</source>
          <target state="translated">Ядро,которое состоит из набора других ядер.</target>
        </trans-unit>
        <trans-unit id="a170413f32a293189023e0700b83d22ea6042972" translate="yes" xml:space="preserve">
          <source>Kernel. Default=&amp;rdquo;linear&amp;rdquo;.</source>
          <target state="translated">Ядро. По умолчанию = &amp;laquo;линейный&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="e3cb275740ef8ee4f25f4b8b1bb2cb56094f01c1" translate="yes" xml:space="preserve">
          <source>Kernels (also called &amp;ldquo;covariance functions&amp;rdquo; in the context of GPs) are a crucial ingredient of GPs which determine the shape of prior and posterior of the GP. They encode the assumptions on the function being learned by defining the &amp;ldquo;similarity&amp;rdquo; of two datapoints combined with the assumption that similar datapoints should have similar target values. Two categories of kernels can be distinguished: stationary kernels depend only on the distance of two datapoints and not on their absolute values \(k(x_i, x_j)= k(d(x_i, x_j))\) and are thus invariant to translations in the input space, while non-stationary kernels depend also on the specific values of the datapoints. Stationary kernels can further be subdivided into isotropic and anisotropic kernels, where isotropic kernels are also invariant to rotations in the input space. For more details, we refer to Chapter 4 of &lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">Ядра (также называемые &amp;laquo;ковариационными функциями&amp;raquo; в контексте GP) являются важнейшим компонентом GP, которые определяют форму предшествующих и апостериорных функций GP. Они кодируют предположения об изучаемой функции, определяя &amp;laquo;сходство&amp;raquo; двух точек данных в сочетании с предположением, что аналогичные точки данных должны иметь похожие целевые значения. Можно выделить две категории ядер: стационарные ядра зависят только от расстояния до двух точек данных, а не от их абсолютных значений \ (k (x_i, x_j) = k (d (x_i, x_j)) \) и, таким образом, инвариантны к трансляциям. во входном пространстве, в то время как нестационарные ядра зависят также от конкретных значений точек данных. Стационарные ядра могут быть далее подразделены на изотропные и анизотропные ядра, где изотропные ядра также инвариантны к поворотам во входном пространстве. Больше подробностей,мы ссылаемся на главу 4&lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="98cdf159fe1dcd2fc6aef984c01878bfe7d52c10" translate="yes" xml:space="preserve">
          <source>Kernels (also called &amp;ldquo;covariance functions&amp;rdquo; in the context of GPs) are a crucial ingredient of GPs which determine the shape of prior and posterior of the GP. They encode the assumptions on the function being learned by defining the &amp;ldquo;similarity&amp;rdquo; of two datapoints combined with the assumption that similar datapoints should have similar target values. Two categories of kernels can be distinguished: stationary kernels depend only on the distance of two datapoints and not on their absolute values \(k(x_i, x_j)= k(d(x_i, x_j))\) and are thus invariant to translations in the input space, while non-stationary kernels depend also on the specific values of the datapoints. Stationary kernels can further be subdivided into isotropic and anisotropic kernels, where isotropic kernels are also invariant to rotations in the input space. For more details, we refer to Chapter 4 of &lt;a href=&quot;#rw2006&quot; id=&quot;id5&quot;&gt;[RW2006]&lt;/a&gt;. For guidance on how to best combine different kernels, we refer to &lt;a href=&quot;#duv2014&quot; id=&quot;id6&quot;&gt;[Duv2014]&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ad8dd8fec70a9d46c4f724f1ce47b4b45810363" translate="yes" xml:space="preserve">
          <source>Kernels are measures of similarity, i.e. &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; if objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are considered &amp;ldquo;more similar&amp;rdquo; than objects &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt;. A kernel must also be positive semi-definite.</source>
          <target state="translated">Ядра - это меры сходства, то есть &lt;code&gt;s(a, b) &amp;gt; s(a, c)&lt;/code&gt; если объекты &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;b&lt;/code&gt; считаются &amp;laquo;более похожими&amp;raquo;, чем объекты &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;c&lt;/code&gt; . Ядро также должно быть положительно полуопределенным.</target>
        </trans-unit>
        <trans-unit id="cd28143394596209b24bd87df6806973641c2997" translate="yes" xml:space="preserve">
          <source>Kernels are parameterized by a vector \(\theta\) of hyperparameters. These hyperparameters can for instance control length-scales or periodicity of a kernel (see below). All kernels support computing analytic gradients of of the kernel&amp;rsquo;s auto-covariance with respect to \(\theta\) via setting &lt;code&gt;eval_gradient=True&lt;/code&gt; in the &lt;code&gt;__call__&lt;/code&gt; method. This gradient is used by the Gaussian process (both regressor and classifier) in computing the gradient of the log-marginal-likelihood, which in turn is used to determine the value of \(\theta\), which maximizes the log-marginal-likelihood, via gradient ascent. For each hyperparameter, the initial value and the bounds need to be specified when creating an instance of the kernel. The current value of \(\theta\) can be get and set via the property &lt;code&gt;theta&lt;/code&gt; of the kernel object. Moreover, the bounds of the hyperparameters can be accessed by the property &lt;code&gt;bounds&lt;/code&gt; of the kernel. Note that both properties (theta and bounds) return log-transformed values of the internally used values since those are typically more amenable to gradient-based optimization. The specification of each hyperparameter is stored in the form of an instance of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt;&lt;code&gt;Hyperparameter&lt;/code&gt;&lt;/a&gt; in the respective kernel. Note that a kernel using a hyperparameter with name &amp;ldquo;x&amp;rdquo; must have the attributes self.x and self.x_bounds.</source>
          <target state="translated">Ядра параметризованы вектором \ (\ theta \) гиперпараметров. Эти гиперпараметры могут, например, управлять масштабами длины или периодичностью ядра (см. Ниже). Все ядра поддерживают вычисление аналитических градиентов &lt;code&gt;eval_gradient=True&lt;/code&gt; ядра по отношению к \ (\ theta \) посредством установки eval_gradient = True в методе &lt;code&gt;__call__&lt;/code&gt; . Этот градиент используется гауссовским процессом (как регрессором, так и классификатором) при вычислении градиента логарифмического предельного правдоподобия, который, в свою очередь, используется для определения значения \ (\ theta \), которое максимизирует логарифмически маржинальное правдоподобие. вероятность, через градиентный подъем. Для каждого гиперпараметра необходимо указать начальное значение и границы при создании экземпляра ядра. Текущее значение \ (\ theta \) можно получить и установить через свойство &lt;code&gt;theta&lt;/code&gt; объекта ядра. Более того, границы гиперпараметров могут быть доступны по &lt;code&gt;bounds&lt;/code&gt; свойств ядра. Обратите внимание, что оба свойства (тета и границы) возвращают логарифмически преобразованные значения внутренних значений, поскольку они обычно более поддаются оптимизации на основе градиента. Спецификация каждого гиперпараметра хранится в форме экземпляра &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt; &lt;code&gt;Hyperparameter&lt;/code&gt; &lt;/a&gt; в соответствующем ядре. Обратите внимание, что ядро, использующее гиперпараметр с именем &amp;laquo;x&amp;raquo;, должно иметь атрибуты self.x и self.x_bounds.</target>
        </trans-unit>
        <trans-unit id="4aed51cbfb6629b3c22c46504375ed74bc60a033" translate="yes" xml:space="preserve">
          <source>Kernels are parameterized by a vector \(\theta\) of hyperparameters. These hyperparameters can for instance control length-scales or periodicity of a kernel (see below). All kernels support computing analytic gradients of the kernel&amp;rsquo;s auto-covariance with respect to \(\theta\) via setting &lt;code&gt;eval_gradient=True&lt;/code&gt; in the &lt;code&gt;__call__&lt;/code&gt; method. This gradient is used by the Gaussian process (both regressor and classifier) in computing the gradient of the log-marginal-likelihood, which in turn is used to determine the value of \(\theta\), which maximizes the log-marginal-likelihood, via gradient ascent. For each hyperparameter, the initial value and the bounds need to be specified when creating an instance of the kernel. The current value of \(\theta\) can be get and set via the property &lt;code&gt;theta&lt;/code&gt; of the kernel object. Moreover, the bounds of the hyperparameters can be accessed by the property &lt;code&gt;bounds&lt;/code&gt; of the kernel. Note that both properties (theta and bounds) return log-transformed values of the internally used values since those are typically more amenable to gradient-based optimization. The specification of each hyperparameter is stored in the form of an instance of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.hyperparameter#sklearn.gaussian_process.kernels.Hyperparameter&quot;&gt;&lt;code&gt;Hyperparameter&lt;/code&gt;&lt;/a&gt; in the respective kernel. Note that a kernel using a hyperparameter with name &amp;ldquo;x&amp;rdquo; must have the attributes self.x and self.x_bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a754d09a87b01a5043bf319d676ca0f6cb6a853" translate="yes" xml:space="preserve">
          <source>Kernels:</source>
          <target state="translated">Kernels:</target>
        </trans-unit>
        <trans-unit id="c3b9fc0d0d17c07a841795715ed044ed9e710926" translate="yes" xml:space="preserve">
          <source>Kevin P. Murphy &amp;ldquo;Machine Learning: A Probabilistic Perspective&amp;rdquo;, The MIT Press chapter 14.4.3, pp. 492-493</source>
          <target state="translated">Кевин П. Мерфи &amp;laquo;Машинное обучение: вероятностная перспектива&amp;raquo;, MIT Press, глава 14.4.3, стр. 492-493</target>
        </trans-unit>
        <trans-unit id="1ebff3fd3bf929976eef25f0da78c334d18a2c1d" translate="yes" xml:space="preserve">
          <source>Keys are parameter names that can be passed to &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Ключи - это имена параметров, которые можно передать в &lt;a href=&quot;sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;set_config&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c16cf0c8b95cb6641127d4ecde39c2d13ee54107" translate="yes" xml:space="preserve">
          <source>Keyword arguments allow to adapt these defaults to specific data sets (see parameters &lt;code&gt;target_name&lt;/code&gt;, &lt;code&gt;data_name&lt;/code&gt;, &lt;code&gt;transpose_data&lt;/code&gt;, and the examples below).</source>
          <target state="translated">Аргументы ключевых слов позволяют адаптировать эти значения по умолчанию к конкретным наборам данных (см. Параметры &lt;code&gt;target_name&lt;/code&gt; , &lt;code&gt;data_name&lt;/code&gt; , &lt;code&gt;transpose_data&lt;/code&gt; и примеры ниже).</target>
        </trans-unit>
        <trans-unit id="6a687df4f73e66be23d8d5cd9810da872c9b92e2" translate="yes" xml:space="preserve">
          <source>Keyword arguments passed to the coordinate descent solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee035295632767669037b1fd1546556e8af6cebd" translate="yes" xml:space="preserve">
          <source>Keyword arguments to be passed to matplotlib&amp;rsquo;s &lt;code&gt;plot&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd2209e677c2e2331711a5337dc06706ac2ee537" translate="yes" xml:space="preserve">
          <source>Keyword arguments to pass to specified metric function.</source>
          <target state="translated">Ключевые аргументы для передачи в указанную метрическую функцию.</target>
        </trans-unit>
        <trans-unit id="b6574be8c6baa963e814d600a049a18b07924f05" translate="yes" xml:space="preserve">
          <source>Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola and Josh Attenberg (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Feature hashing for large scale multitask learning&lt;/a&gt;. Proc. ICML.</source>
          <target state="translated">Килиан Вайнбергер, Анирбан Дасгупта, Джон Лэнгфорд, Алекс Смола и Джош Аттенберг (2009). &lt;a href=&quot;http://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Функция хеширования для крупномасштабного многозадачного обучения&lt;/a&gt; . Proc. ICML.</target>
        </trans-unit>
        <trans-unit id="aaf2909b07b71367a7207c2f93060ee37cc58e6c" translate="yes" xml:space="preserve">
          <source>Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola and Josh Attenberg (2009). &lt;a href=&quot;https://alex.smola.org/papers/2009/Weinbergeretal09.pdf&quot;&gt;Feature hashing for large scale multitask learning&lt;/a&gt;. Proc. ICML.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35a95e3949c1091022c84b09bdfaee477e2ca247" translate="yes" xml:space="preserve">
          <source>Kingma, Diederik, and Jimmy Ba. &amp;ldquo;Adam: A method for stochastic</source>
          <target state="translated">Кингма, Дидерик и Джимми Ба. &amp;laquo;Адам: метод стохастического</target>
        </trans-unit>
        <trans-unit id="7bf0d4f9044d36fbabdb373fe028824c8f48b797" translate="yes" xml:space="preserve">
          <source>Kluger, Y., Basri, R., Chang, J. T., &amp;amp; Gerstein, M. (2003). Spectral biclustering of microarray data: coclustering genes and conditions. Genome research, 13(4), 703-716.</source>
          <target state="translated">Клугер, Ю., Басри, Р., Чанг, Дж. Т., и Герштейн, М. (2003). Спектральная бикластеризация данных микрочипов: гены и условия совместной кластеризации. Исследование генома, 13 (4), 703-716.</target>
        </trans-unit>
        <trans-unit id="454573718b795c598350a3ed3c4e500004992423" translate="yes" xml:space="preserve">
          <source>Kluger, Yuval, et. al., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Spectral biclustering of microarray data: coclustering genes and conditions&lt;/a&gt;.</source>
          <target state="translated">Kluger, Yuval, et. др., 2003. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1608&quot;&gt;Спектральная бикластеризация данных микрочипов: гены и условия совместной кластеризации&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c956cdb3811d15bc82b9ab562e4744234449e302" translate="yes" xml:space="preserve">
          <source>Knowing only the number of samples, the &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt;&lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;&lt;/a&gt; estimates conservatively the minimal size of the random subspace to guarantee a bounded distortion introduced by the random projection:</source>
          <target state="translated">Зная только количество выборок, &lt;a href=&quot;generated/sklearn.random_projection.johnson_lindenstrauss_min_dim#sklearn.random_projection.johnson_lindenstrauss_min_dim&quot;&gt; &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt; &lt;/a&gt; консервативно оценивает минимальный размер случайного подпространства, чтобы гарантировать ограниченное искажение , вносимое случайной проекцией:</target>
        </trans-unit>
        <trans-unit id="dc8be79b794b57340c1a9b2bf6e67594910f3213" translate="yes" xml:space="preserve">
          <source>Koby Crammer, Yoram Singer. On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines. Journal of Machine Learning Research 2, (2001), 265-292</source>
          <target state="translated">Коби Краммер,Йорам Сингер.Об алгоритмической реализации многоклассных векторных машин на основе ядра.Журнал исследований в области обучения работе с машинами 2,(2001),265-292.</target>
        </trans-unit>
        <trans-unit id="5c3682641cb862b7b72f47a7d095c9e12f698d72" translate="yes" xml:space="preserve">
          <source>Kullback-Leibler divergence after optimization.</source>
          <target state="translated">Расхождение Куллбек-Лейблера после оптимизации.</target>
        </trans-unit>
        <trans-unit id="58f9065948558949c0307af59f2acaf3f9203c82" translate="yes" xml:space="preserve">
          <source>KulsinskiDistance</source>
          <target state="translated">KulsinskiDistance</target>
        </trans-unit>
        <trans-unit id="cb6565437657bdf8e9b94faf7a832064c7b5f242" translate="yes" xml:space="preserve">
          <source>L-BFGS is a solver that approximates the Hessian matrix which represents the second-order partial derivative of a function. Further it approximates the inverse of the Hessian matrix to perform parameter updates. The implementation uses the Scipy version of &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt;.</source>
          <target state="translated">L-BFGS - это решающая программа, которая аппроксимирует матрицу Гессе, которая представляет собой частную производную второго порядка функции. Кроме того, он аппроксимирует обратную матрицу Гессе для обновления параметров. В реализации используется Scipy-версия &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="554ef38240e48c4335936815621409310d3aac71" translate="yes" xml:space="preserve">
          <source>L-BFGS is a solver that approximates the Hessian matrix which represents the second-order partial derivative of a function. Further it approximates the inverse of the Hessian matrix to perform parameter updates. The implementation uses the Scipy version of &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html&quot;&gt;L-BFGS&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bcf28acc035a046a1884f5a68a7e0642aed3a3f" translate="yes" xml:space="preserve">
          <source>L-BFGS-B &amp;ndash; Software for Large-scale Bound-constrained Optimization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9d5151f1c406ba9642eb6d20ad7472462d4b8c9" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning 24, pages 123-140, 1996.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Предикторы упаковки&amp;raquo;, Машинное обучение 24, страницы 123&amp;ndash;140, 1996.</target>
        </trans-unit>
        <trans-unit id="05401786a74b32c74f5aaf77879ff5fe2a1ce4dc" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Bagging predictors&amp;rdquo;, Machine Learning, 24(2), 123-140, 1996.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Предикторы упаковки&amp;raquo;, Машинное обучение, 24 (2), 123-140, 1996.</target>
        </trans-unit>
        <trans-unit id="ae813a657051355d781d3ca7a4417546370b5fb0" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Pasting small votes for classification in large databases and on-line&amp;rdquo;, Machine Learning, 36(1), 85-103, 1999.</source>
          <target state="translated">Л. Брейман, &amp;laquo;Вставка небольших голосов для классификации в больших базах данных и в Интернете&amp;raquo;, Машинное обучение, 36 (1), 85-103, 1999.</target>
        </trans-unit>
        <trans-unit id="97e482bcc046e44b1e543a4a852a328e802cd962" translate="yes" xml:space="preserve">
          <source>L. Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32, 2001. &lt;a href=&quot;https://doi.org/10.1023/A:1010933404324&quot;&gt;https://doi.org/10.1023/A:1010933404324&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93aaad4c8bcdef78f99bc463e879b251fb063491" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone, &amp;ldquo;Classification and Regression Trees&amp;rdquo;, Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">Л. Брейман, Дж. Фридман, Р. Олшен и К. Стоун, &amp;laquo;Деревья классификации и регрессии&amp;raquo;, Уодсворт, Белмонт, Калифорния, 1984.</target>
        </trans-unit>
        <trans-unit id="728ad1a9616394c8f19b0d53311780e8eed780ec" translate="yes" xml:space="preserve">
          <source>L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.</source>
          <target state="translated">L.Брейман,Джей Фридман,Р.Ольшен и Си Стоун.Деревья классификации и регрессии.Уодсворт,Белмонт,Калифорния,1984.</target>
        </trans-unit>
        <trans-unit id="26e831dbfd841f8bca5cddecddc5d95f765adc3b" translate="yes" xml:space="preserve">
          <source>L. Breiman, P. Spector &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Submodel selection and evaluation in regression: The X-random case&lt;/a&gt;, International Statistical Review 1992;</source>
          <target state="translated">Л. Брейман, П. Спектор &lt;a href=&quot;http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf&quot;&gt;Выбор подмоделей и оценка в регрессии: случай X&lt;/a&gt; , Международный статистический обзор 1992;</target>
        </trans-unit>
        <trans-unit id="da524759b928a0c6c0410a2ba55315d0723efbf9" translate="yes" xml:space="preserve">
          <source>L. Breiman, and A. Cutler, &amp;ldquo;Random Forests&amp;rdquo;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</source>
          <target state="translated">Л. Брейман и А. Катлер, &amp;laquo;Случайные леса&amp;raquo;, &lt;a href=&quot;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c982df17d29f8aba32aa6a03bfa726201c066e60" translate="yes" xml:space="preserve">
          <source>L. Breiman, and A. Cutler, &amp;ldquo;Random Forests&amp;rdquo;, &lt;a href=&quot;https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&quot;&gt;https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ecce2961bb8a3f0ec10fc321ad8811dfc6312ac" translate="yes" xml:space="preserve">
          <source>L. F. Kozachenko, N. N. Leonenko, &amp;ldquo;Sample Estimate of the Entropy of a Random Vector&amp;rdquo;, Probl. Peredachi Inf., 23:2 (1987), 9-16</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d97aac3a80efb6d42fc11cefc484a2c681583627" translate="yes" xml:space="preserve">
          <source>L. F. Kozachenko, N. N. Leonenko, &amp;ldquo;Sample Estimate of the Entropy of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f170f61c9bead94cf287d881c88071c0e3a5501e" translate="yes" xml:space="preserve">
          <source>L. Hubert and P. Arabie, Comparing Partitions, Journal of Classification 1985 &lt;a href=&quot;https://link.springer.com/article/10.1007%2FBF01908075&quot;&gt;https://link.springer.com/article/10.1007%2FBF01908075&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9026b644be7a2edc54521dca8f44e2af501befa2" translate="yes" xml:space="preserve">
          <source>L. Mosley, &lt;a href=&quot;https://lib.dr.iastate.edu/etd/13537/&quot;&gt;A balanced approach to the multi-class imbalance problem&lt;/a&gt;, IJCV 2010.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27e9c034667fd587e63afe1b6bd9ac5dd761c4eb" translate="yes" xml:space="preserve">
          <source>L1 AND L2 Regularization for Multiclass Hinge Loss Models by Robert C. Moore, John DeNero.</source>
          <target state="translated">Регуляризация L1 и L2 для многоклассных моделей потери шарниров Робертом К.Муром,Джоном Денеро.</target>
        </trans-unit>
        <trans-unit id="739dce23f089e2bc4737d849cf6e6812aaac6b25" translate="yes" xml:space="preserve">
          <source>L1 Penalty and Sparsity in Logistic Regression</source>
          <target state="translated">L1 Штраф и спартантизм в логистической регрессии</target>
        </trans-unit>
        <trans-unit id="8d79d7e84774c8797e94aafbcec78896f21a814d" translate="yes" xml:space="preserve">
          <source>L1 norm: \(R(w) := \sum_{i=1}^{n} |w_i|\), which leads to sparse solutions.</source>
          <target state="translated">Норма L1:\(R(w):=\sum_{i=1}^{n}|w_i|\),что приводит к разреженным решениям.</target>
        </trans-unit>
        <trans-unit id="b5bea6bb158694d1df1789af92353788b4accacc" translate="yes" xml:space="preserve">
          <source>L1 norm: \(R(w) := \sum_{j=1}^{m} |w_j|\), which leads to sparse solutions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae8ca0f194d88f499adeb94f8b5c01af62268b9f" translate="yes" xml:space="preserve">
          <source>L2 norm: \(R(w) := \frac{1}{2} \sum_{i=1}^{n} w_i^2\),</source>
          <target state="translated">Норма L2:\(R(w):=\frac{1}{2}\sum_{i=1}^{n}w_i^2\),</target>
        </trans-unit>
        <trans-unit id="2f4d6f15c348b07a6c4412e8ecac45c72eb1770b" translate="yes" xml:space="preserve">
          <source>L2 norm: \(R(w) := \frac{1}{2} \sum_{j=1}^{m} w_j^2 = ||w||_2^2\),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e55996560b375d2b1311657b3550d521d2224094" translate="yes" xml:space="preserve">
          <source>L2 penalty (regularization term) parameter.</source>
          <target state="translated">L2 штрафной параметр (срок регуляризации).</target>
        </trans-unit>
        <trans-unit id="512ddf6d4bbcf9517a6def433a9acfdaefb1e3cd" translate="yes" xml:space="preserve">
          <source>LDA is a special case of QDA, where the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This reduces the log posterior to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d7eb4b58ee70885659f8b6dfa6b739d18b840b6" translate="yes" xml:space="preserve">
          <source>LIBLINEAR &amp;ndash; A Library for Large Linear Classification</source>
          <target state="translated">LIBLINEAR - библиотека для большой линейной классификации</target>
        </trans-unit>
        <trans-unit id="23f600324ae930d885bf27049a430c382dc77087" translate="yes" xml:space="preserve">
          <source>LIBLINEAR: A Library for Large Linear Classification</source>
          <target state="translated">ЛИБЛИНАРА:Библиотека для Большой Линейной Классификации</target>
        </trans-unit>
        <trans-unit id="919f2c891fd7b6ae4005ef3cab68511f9b26c031" translate="yes" xml:space="preserve">
          <source>LIBSVM: A Library for Support Vector Machines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f7204b5759b40e38407ab9bdcb1553f2d733475" translate="yes" xml:space="preserve">
          <source>LSA is also known as latent semantic indexing, LSI, though strictly that refers to its use in persistent indexes for information retrieval purposes.</source>
          <target state="translated">LSA также известен как скрытое семантическое индексирование,LSI,хотя строго говоря,это относится к его использованию в постоянных индексах для целей информационного поиска.</target>
        </trans-unit>
        <trans-unit id="f4a5095ae748443324845cf5a2f1b28d147ed2ca" translate="yes" xml:space="preserve">
          <source>LSH Forest being an approximate method, some true neighbors from the indexed dataset might be missing from the results.</source>
          <target state="translated">Поскольку LSH Forest является приблизительным методом,некоторые истинные соседи из индексированного набора данных могут отсутствовать в результатах.</target>
        </trans-unit>
        <trans-unit id="afceea8d4c81422ac802414c94f3f49075a51ec4" translate="yes" xml:space="preserve">
          <source>LSH Forest: Locality Sensitive Hashing forest [1] is an alternative method for vanilla approximate nearest neighbor search methods. LSH forest data structure has been implemented using sorted arrays and binary search and 32 bit fixed-length hashes. Random projection is used as the hash family which approximates cosine distance.</source>
          <target state="translated">ЛШХ Лес:Locality Sensitive Hashing Forest [1]-альтернативный метод для поиска ванили,приближенной к ближайшему соседу.Структура данных леса LSH была реализована с использованием отсортированных массивов и бинарного поиска и 32-битных хэшей фиксированной длины.В качестве семейства хэшей используется случайная проекция,которая аппроксимирует косинусное расстояние.</target>
        </trans-unit>
        <trans-unit id="497cbd9196f20980eefacbc5b295901fb0a6c25f" translate="yes" xml:space="preserve">
          <source>LSTAT % lower status of the population</source>
          <target state="translated">ЗАКЛЮЧИТЕЛЬНЫЙ % более низкий статус населения</target>
        </trans-unit>
        <trans-unit id="10e8ec7cf1b34af007bc1d6b016abc85aa0b454d" translate="yes" xml:space="preserve">
          <source>Label Propagation classifier</source>
          <target state="translated">Классификатор размножения этикеток</target>
        </trans-unit>
        <trans-unit id="abaf5a09ed6812e5734e77c1313bb44d953f5d5d" translate="yes" xml:space="preserve">
          <source>Label Propagation digits active learning</source>
          <target state="translated">Цифры этикетки Пропаганда активное обучение</target>
        </trans-unit>
        <trans-unit id="a45a75b5c87b437cf487b153831ce5b94e5322d0" translate="yes" xml:space="preserve">
          <source>Label Propagation digits: Demonstrating performance</source>
          <target state="translated">Цифры этикетки &quot;Пропаганда&quot;:Демонстрационная производительность</target>
        </trans-unit>
        <trans-unit id="f15baf6416f92a52b1527f1d28d49a335fe3d388" translate="yes" xml:space="preserve">
          <source>Label Propagation learning a complex structure</source>
          <target state="translated">Label Propagation изучение сложной структуры</target>
        </trans-unit>
        <trans-unit id="5f24cba3626113f57fbd8f2c1a1dac90f055831d" translate="yes" xml:space="preserve">
          <source>Label assigned to each item via the transduction.</source>
          <target state="translated">Метка,присваиваемая каждому изделию через трансляцию.</target>
        </trans-unit>
        <trans-unit id="0154541a5d5e8e0b2444f876377737f91ad447a9" translate="yes" xml:space="preserve">
          <source>Label considered as positive and others are considered negative.</source>
          <target state="translated">Этикетка считается положительной,а другие-отрицательной.</target>
        </trans-unit>
        <trans-unit id="e1c383c45e91a1b41ae4aea8504e1ff71ada889a" translate="yes" xml:space="preserve">
          <source>Label is 1 for an inlier and -1 for an outlier according to the LOF score and the contamination parameter.</source>
          <target state="translated">Метка 1 для входа и -1 для выхода в зависимости от балла LOF и параметра загрязнения.</target>
        </trans-unit>
        <trans-unit id="0facd2ec455a2234134eaa8ce0e172bf077ca396" translate="yes" xml:space="preserve">
          <source>Label of the positive class. Defaults to the greater label unless y_true is all 0 or all -1 in which case pos_label defaults to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4a633c5d3b5ebf2a9c4453fb41f8475e350bc9" translate="yes" xml:space="preserve">
          <source>Label of the positive class. If None, the maximum label is used as positive class</source>
          <target state="translated">Ярлык положительного класса.Если Нет,то максимальная метка используется как положительный класс.</target>
        </trans-unit>
        <trans-unit id="91ed314c98998b774c857769b601470c2a4233d0" translate="yes" xml:space="preserve">
          <source>Label propagation denotes a few variations of semi-supervised graph inference algorithms.</source>
          <target state="translated">Распространение меток обозначает несколько вариаций полууправляемых алгоритмов вывода графов.</target>
        </trans-unit>
        <trans-unit id="3a4c36d2f1914cbaa6f86d2f3e759e05f747e6f8" translate="yes" xml:space="preserve">
          <source>Label propagation models have two built-in kernel methods. Choice of kernel effects both scalability and performance of the algorithms. The following are available:</source>
          <target state="translated">Модели распространения этикеток имеют два встроенных метода ядра.Выбор эффектов от ядра,как масштабируемости,так и производительности алгоритмов.Доступны следующие варианты:</target>
        </trans-unit>
        <trans-unit id="d9c8943fba1565dfa00ecc788417147c59e84b5a" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) averages over the samples the answer to the following question: for each ground truth label, what fraction of higher-ranked labels were true labels? This performance measure will be higher if you are able to give better rank to the labels associated with each sample. The obtained score is always strictly greater than 0, and the best value is 1. If there is exactly one relevant label per sample, label ranking average precision is equivalent to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;mean reciprocal rank&lt;/a&gt;.</source>
          <target state="translated">Средняя точность ранжирования меток (LRAP) усредняет по выборкам ответ на следующий вопрос: для каждой основной метки истинности какая доля меток с более высоким рейтингом была истинной? Этот показатель эффективности будет выше, если вы сможете лучше ранжировать метки, связанные с каждым образцом. Полученная оценка всегда строго больше 0, а наилучшее значение равно 1. Если имеется ровно одна релевантная метка для каждой выборки, средняя точность ранжирования меток эквивалентна &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_reciprocal_rank&quot;&gt;среднему обратному рангу&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="12d27d4c8cd4504c7079d27029449977fea3fa44" translate="yes" xml:space="preserve">
          <source>Label ranking average precision (LRAP) is the average over each ground truth label assigned to each sample, of the ratio of true vs. total labels with lower score.</source>
          <target state="translated">Средняя точность ранжирования меток (LRAP)-это среднее значение по каждой наземной истине,присвоенной каждой выборке,соотношения истинного и общего количества меток с более низкой оценкой.</target>
        </trans-unit>
        <trans-unit id="57882529b52287495d04cf4c6bba559a970b02d4" translate="yes" xml:space="preserve">
          <source>Label, which is given for outlier samples (samples with no neighbors on given radius). If set to None, ValueError is raised, when outlier is detected.</source>
          <target state="translated">Ярлык,который дается для исходных образцов (образцов без соседей по заданному радиусу).Если установлено значение None,то ValueError повышается при обнаружении отклонений.</target>
        </trans-unit>
        <trans-unit id="a3ea7d5af24c9f7706e04a90b4cc006ad64537bf" translate="yes" xml:space="preserve">
          <source>LabelSpreading model for semi-supervised learning</source>
          <target state="translated">Модель LabelSpreading для полууправляемого обучения</target>
        </trans-unit>
        <trans-unit id="82b6583f37d4a090f2277f71261de91f41eff15e" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not always pure, hence penalized:</source>
          <target state="translated">Наклейки,которые назначают всех членов классов на одни и те же кластеры,не всегда являются чистыми,а следовательно,подлежат наказанию:</target>
        </trans-unit>
        <trans-unit id="a59d28cce33bc578e32e7790445917276a69fe16" translate="yes" xml:space="preserve">
          <source>Labelings that assign all classes members to the same clusters are complete be not homogeneous, hence penalized:</source>
          <target state="translated">Маркировки,которые присваивают всем классам членов одного и того же кластера,не являются однородными и,следовательно,подлежат наказанию:</target>
        </trans-unit>
        <trans-unit id="2625047637f13a503b1aa26353d53ce007980d47" translate="yes" xml:space="preserve">
          <source>Labelings that have pure clusters with members coming from the same classes are homogeneous but un-necessary splits harms completeness and thus penalize V-measure as well:</source>
          <target state="translated">Маркировки,которые имеют чистые кластеры с членами,пришедшими из одних и тех же классов,однородны,но ненужные расщепления наносят вред полноте и,таким образом,наказывают также и V-меру:</target>
        </trans-unit>
        <trans-unit id="040e8af7f9faa240f939c7eb15dd2f3691882d68" translate="yes" xml:space="preserve">
          <source>Labelled data.</source>
          <target state="translated">Металлические данные.</target>
        </trans-unit>
        <trans-unit id="a8a910f7e8e66128e5f0f93a7ebe3b1d5812067b" translate="yes" xml:space="preserve">
          <source>Labelling a new sample is performed by finding the nearest centroid for a given sample.</source>
          <target state="translated">Пометка нового образца выполняется путем нахождения ближайшего центроида для данного образца.</target>
        </trans-unit>
        <trans-unit id="47fc9fa69e29f326a363aa6376f6761fa85e0797" translate="yes" xml:space="preserve">
          <source>Labels assigned by the first annotator.</source>
          <target state="translated">Ярлыки,присвоенные первым аннотатором.</target>
        </trans-unit>
        <trans-unit id="bdb7346e56bb733f97e8f0b9d11cce2ffadf9042" translate="yes" xml:space="preserve">
          <source>Labels assigned by the second annotator. The kappa statistic is symmetric, so swapping &lt;code&gt;y1&lt;/code&gt; and &lt;code&gt;y2&lt;/code&gt; doesn&amp;rsquo;t change the value.</source>
          <target state="translated">Ярлыки, присвоенные вторым аннотатором. Статистика каппа симметрична, поэтому замена &lt;code&gt;y1&lt;/code&gt; и &lt;code&gt;y2&lt;/code&gt; не меняет значения.</target>
        </trans-unit>
        <trans-unit id="202396c3dbc4d15cb0462523b4fd7f2f49834479" translate="yes" xml:space="preserve">
          <source>Labels assigned to the centroids of the subclusters after they are clustered globally.</source>
          <target state="translated">Ярлыки,присваиваемые центроидам подкластеров после того,как они сгруппированы по всему миру.</target>
        </trans-unit>
        <trans-unit id="86a5303314971b15773b1ad8460967a7978fc1e6" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels are ranging from 0-39 and correspond to the Subject IDs.</source>
          <target state="translated">Ярлыки,связанные с каждым изображением лица.Эти метки варьируются от 0 до 39 и соответствуют идентификаторам субъектов.</target>
        </trans-unit>
        <trans-unit id="b8a8237c586e7a43e02e7a221af16786bca65b16" translate="yes" xml:space="preserve">
          <source>Labels associated to each face image. Those labels range from 0-5748 and correspond to the person IDs.</source>
          <target state="translated">Ярлыки,связанные с каждым изображением лица.Эти ярлыки варьируются в диапазоне 0-5748 и соответствуют идентификаторам лиц.</target>
        </trans-unit>
        <trans-unit id="639c7a5f12221be9fa16d4184a91d960ee8d5fb6" translate="yes" xml:space="preserve">
          <source>Labels associated to each pair of images. The two label values being different persons or the same person.</source>
          <target state="translated">Ярлыки,связанные с каждой парой изображений.Два значения этикетки-разные люди или один и тот же человек.</target>
        </trans-unit>
        <trans-unit id="dd9359ae6e29bf7b087516560ad1a2e91d10cfb0" translate="yes" xml:space="preserve">
          <source>Labels for X.</source>
          <target state="translated">Ярлыки для Икс.</target>
        </trans-unit>
        <trans-unit id="0b53b6571e9267409e85ff23873e0a0824df02a7" translate="yes" xml:space="preserve">
          <source>Labels of each point</source>
          <target state="translated">Метки каждой точки</target>
        </trans-unit>
        <trans-unit id="4350a7104cda6c17ed013efe2d00ebaae03eeb73" translate="yes" xml:space="preserve">
          <source>Labels of each point (if compute_labels is set to True).</source>
          <target state="translated">Метки каждой точки (если значение переменной compute_labels установлено в True).</target>
        </trans-unit>
        <trans-unit id="8c76fdcbe4be61c2bbf79d2e67413441e31eb988" translate="yes" xml:space="preserve">
          <source>Labels of each point.</source>
          <target state="translated">Ярлыки каждой точки.</target>
        </trans-unit>
        <trans-unit id="9caa2dbfb17c8c2f4ae17aa6bab878223c8520e3" translate="yes" xml:space="preserve">
          <source>Labels to constrain permutation within groups, i.e. &lt;code&gt;y&lt;/code&gt; values are permuted among samples with the same group identifier. When not specified, &lt;code&gt;y&lt;/code&gt; values are permuted among all samples.</source>
          <target state="translated">Метки для ограничения перестановки внутри групп, т. &lt;code&gt;y&lt;/code&gt; Значения y переставляются среди выборок с одним и тем же идентификатором группы. Если не указано иное, значения &lt;code&gt;y&lt;/code&gt; переставляются среди всех выборок.</target>
        </trans-unit>
        <trans-unit id="c21c4f0b2fc516030c767721367e1d2fba51e007" translate="yes" xml:space="preserve">
          <source>Labels.</source>
          <target state="translated">Labels.</target>
        </trans-unit>
        <trans-unit id="45efe9972f3bf7c62e3db1678d501faf12d10c1b" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_clusters&lt;/code&gt; and &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">Большие &lt;code&gt;n_clusters&lt;/code&gt; и &lt;code&gt;n_samples&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="28e08fa26129e68210c4b016ca6da1b08a1a37e9" translate="yes" xml:space="preserve">
          <source>Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Большие &lt;code&gt;n_samples&lt;/code&gt; и &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d40959dcecc27d1d44b2e4cffa59a304e9a052a1" translate="yes" xml:space="preserve">
          <source>Large dataset, outlier removal, data reduction.</source>
          <target state="translated">Большой набор данных,удаление отклонений,уменьшение данных.</target>
        </trans-unit>
        <trans-unit id="8f1784e927c9c4e578edb46d860596eed4a90b35" translate="yes" xml:space="preserve">
          <source>Large outliers</source>
          <target state="translated">Большие отклонения</target>
        </trans-unit>
        <trans-unit id="20dfcd03ef69fe3c6c6e8549019c43956f87d5db" translate="yes" xml:space="preserve">
          <source>Lars computes a path solution only for each kink in the path. As a result, it is very efficient when there are only of few kinks, which is the case if there are few features or samples. Also, it is able to compute the full path without setting any meta parameter. On the opposite, coordinate descent compute the path points on a pre-specified grid (here we use the default). Thus it is more efficient if the number of grid points is smaller than the number of kinks in the path. Such a strategy can be interesting if the number of features is really large and there are enough samples to select a large amount. In terms of numerical errors, for heavily correlated variables, Lars will accumulate more errors, while the coordinate descent algorithm will only sample the path on a grid.</source>
          <target state="translated">Ларс вычисляет решение пути только для каждого перегиба в пути.В результате,оно очень эффективно,когда есть только несколько перегибов,что бывает в случае,если есть несколько особенностей или примеров.Кроме того,он может вычислить полный путь,не задавая никаких мета-параметров.Напротив,координатный спуск вычисляет точки пути на заранее заданной сетке (здесь мы используем значение по умолчанию).Таким образом,это более эффективно,если количество точек сетки меньше,чем количество перегибов на пути.Такая стратегия может быть интересна,если количество объектов действительно велико,а выборки достаточно велики.С точки зрения числовых ошибок,для сильнокоррелированных переменных Ларс будет накапливать больше ошибок,в то время как алгоритм координатного спуска будет сэмплировать путь только на сетке.</target>
        </trans-unit>
        <trans-unit id="fafbf93538200568ab2506c2a63168c161506b4f" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net</source>
          <target state="translated">Лассо и эластичная сеть</target>
        </trans-unit>
        <trans-unit id="64045413f4cce0f6cc0a64e33254b9beab1142d8" translate="yes" xml:space="preserve">
          <source>Lasso and Elastic Net for Sparse Signals</source>
          <target state="translated">Лассо и эластичная сеть для разделения сигналов</target>
        </trans-unit>
        <trans-unit id="02b3c1dbfc5f6c26007e2282ba4be10a77581a65" translate="yes" xml:space="preserve">
          <source>Lasso and elastic net (L1 and L2 penalisation) implemented using a coordinate descent.</source>
          <target state="translated">Лассо и эластичная сетка (наказание L1 и L2),реализованная с использованием координатного спуска.</target>
        </trans-unit>
        <trans-unit id="721bb6d50a67145009b7e81abd6add7dc9980ff6" translate="yes" xml:space="preserve">
          <source>Lasso computed by least-angle regression</source>
          <target state="translated">Лассо вычислен по регрессии наименьшего угла</target>
        </trans-unit>
        <trans-unit id="c805258f4c266592bbe9892ca4c6fe8fe41525e3" translate="yes" xml:space="preserve">
          <source>Lasso linear model with iterative fitting along a regularization path</source>
          <target state="translated">Линейная модель Лассо с итерационной подгонкой по пути регуляризации</target>
        </trans-unit>
        <trans-unit id="47657b9ded4cc2a2b0764459c9d492e6cc3f4eb7" translate="yes" xml:space="preserve">
          <source>Lasso linear model with iterative fitting along a regularization path.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af3dece2cf6ae684f46dbebc7279e4f62e00335d" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Lars using BIC or AIC for model selection</source>
          <target state="translated">Модель Lasso подходит к Ларсу,используя BIC или AIC для выбора модели.</target>
        </trans-unit>
        <trans-unit id="050a0d126029facc258b43169ac1e55a978389bf" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a.</source>
          <target state="translated">Модель Лассо подходит с регрессией по методу наименьшего угла.</target>
        </trans-unit>
        <trans-unit id="9cd5532bfae0b1e27ef3555196bbd1195b2078fe" translate="yes" xml:space="preserve">
          <source>Lasso model fit with Least Angle Regression a.k.a. Lars</source>
          <target state="translated">Модель Лассо подходит с регрессией наименьшего угла,так же известной как Ларс.</target>
        </trans-unit>
        <trans-unit id="7cbdf91f396ae23c8822ab30bdd340882655aa26" translate="yes" xml:space="preserve">
          <source>Lasso model selection: Cross-Validation / AIC / BIC</source>
          <target state="translated">Выбор модели Лассо:Перекрестная проверка/AIC/BIC</target>
        </trans-unit>
        <trans-unit id="5632592b831e91b94b8f3294c0115a52d64872b7" translate="yes" xml:space="preserve">
          <source>Lasso models (see the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; User Guide section) estimates sparse coefficients. LassoCV applies cross validation in order to determine which value of the regularization parameter (&lt;code&gt;alpha&lt;/code&gt;) is best suited for the model estimation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51c5bc73e17f640c8a180ee453dbdca923d8c408" translate="yes" xml:space="preserve">
          <source>Lasso on dense and sparse data</source>
          <target state="translated">Лассо по плотным и редким данным</target>
        </trans-unit>
        <trans-unit id="4222e17e965145615293d33dd92e1394e71c2b5b" translate="yes" xml:space="preserve">
          <source>Lasso path using LARS</source>
          <target state="translated">путь Лассо с помощью ЛАРС</target>
        </trans-unit>
        <trans-unit id="1acac83cf58491df993404acd51caed4c4458648" translate="yes" xml:space="preserve">
          <source>Lasso using coordinate descent (&lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;)</source>
          <target state="translated">Лассо с использованием координатного спуска ( &lt;a href=&quot;linear_model#lasso&quot;&gt;Лассо&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="e33c33e9d593ce188f7d437b3dd829993a23358f" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation is a generative probabilistic model for collections of discrete dataset such as text corpora. It is also a topic model that is used for discovering abstract topics from a collection of documents.</source>
          <target state="translated">Latent Dirichlet Allocation является генеративной вероятностной моделью для коллекций дискретных наборов данных,таких как текстовые корпуса.Это также тематическая модель,которая используется для открытия абстрактных тем из коллекции документов.</target>
        </trans-unit>
        <trans-unit id="b259b9fed25933f3361602dc71394efbeb9d0882" translate="yes" xml:space="preserve">
          <source>Latent Dirichlet Allocation with online variational Bayes algorithm</source>
          <target state="translated">Скрытое распределение Дирихлета с онлайн вариационным алгоритмом Байеса</target>
        </trans-unit>
        <trans-unit id="691257140e4ed31a708c6cf301cec44aee34c69f" translate="yes" xml:space="preserve">
          <source>Latent representations of the data.</source>
          <target state="translated">Скрытое представление данных.</target>
        </trans-unit>
        <trans-unit id="7972223ce1d5a83652f334b349de24d196516da5" translate="yes" xml:space="preserve">
          <source>Later you can load back the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Позже вы можете загрузить обратно маринованную модель (возможно,в другом процессе на Python)с помощью:</target>
        </trans-unit>
        <trans-unit id="af705669290f66a0c593b0deebc97c8dff7d4996" translate="yes" xml:space="preserve">
          <source>Later, you can reload the pickled model (possibly in another Python process) with:</source>
          <target state="translated">Позже вы можете перезагрузить маринованную модель (возможно,в другом процессе на Python)с помощью:</target>
        </trans-unit>
        <trans-unit id="87b4154b3c380b9ca1fa8f1419dd8e2c1d34065a" translate="yes" xml:space="preserve">
          <source>Latitude house block latitude</source>
          <target state="translated">Широта квартала дома широты</target>
        </trans-unit>
        <trans-unit id="5d6517da9252e690b07eb861ecaf7b79646512be" translate="yes" xml:space="preserve">
          <source>Leaf size passed to &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt;. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передан в &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; или&lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; . Это может повлиять на скорость построения и запроса, а также на объем памяти, необходимый для хранения дерева. Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="90341c46ba90925b69433ce5faecb3e1b8c85d8c" translate="yes" xml:space="preserve">
          <source>Leaf size passed to &lt;code&gt;BallTree&lt;/code&gt; or &lt;code&gt;KDTree&lt;/code&gt;. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="adfd1a5c3117b99a14c45a4ae06038fd4593b137" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передается в BallTree или KDTree.Это может повлиять на скорость построения и запроса,а также на память,необходимую для хранения дерева.Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="2f4f4f9d9992d30c454ebca3af5182554c5dd5d3" translate="yes" xml:space="preserve">
          <source>Leaf size passed to BallTree or cKDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.</source>
          <target state="translated">Размер листа передается в BallTree или cKDTree.Это может повлиять на скорость построения и запроса,а также на память,необходимую для хранения дерева.Оптимальное значение зависит от характера проблемы.</target>
        </trans-unit>
        <trans-unit id="31743e5f5ee8b348cb24154ab26179446399d075" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X and returns the transformed data.</source>
          <target state="translated">Изучите модель NMF для данных X и верните преобразованные данные.</target>
        </trans-unit>
        <trans-unit id="a49199fe15b3d192e2f8e78d2cfcc004b5bb592f" translate="yes" xml:space="preserve">
          <source>Learn a NMF model for the data X.</source>
          <target state="translated">Изучите модель NMF для данных X.</target>
        </trans-unit>
        <trans-unit id="f28a5a2a8197ba712162f1642134c8c32dff12de" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings and transform X.</source>
          <target state="translated">Изучите список имен функций -&amp;gt; сопоставления индексов и преобразуйте X.</target>
        </trans-unit>
        <trans-unit id="8c410f4ecac33d5545793d5deb3e8b1121157db0" translate="yes" xml:space="preserve">
          <source>Learn a list of feature name -&amp;gt; indices mappings.</source>
          <target state="translated">Изучите список названий функций -&amp;gt; сопоставления индексов.</target>
        </trans-unit>
        <trans-unit id="a753afaf1f2a5a0c1c19f381e2c844f4e69ccf16" translate="yes" xml:space="preserve">
          <source>Learn a vocabulary dictionary of all tokens in the raw documents.</source>
          <target state="translated">Изучите словарь всех жетонов в исходных документах.</target>
        </trans-unit>
        <trans-unit id="d9349583a45dc48570d0d3236e8faf8ecfef570b" translate="yes" xml:space="preserve">
          <source>Learn and apply the dimension reduction on the train data.</source>
          <target state="translated">Изучите и применяйте уменьшение размеров к данным поезда.</target>
        </trans-unit>
        <trans-unit id="c8e9cfdd99f37695b9bb2a2cf234f653fe10a376" translate="yes" xml:space="preserve">
          <source>Learn empirical variances from X.</source>
          <target state="translated">Узнайте об эмпирических изменениях из X.</target>
        </trans-unit>
        <trans-unit id="650a6ae9c550e7f32470024973e3b36aee2841fa" translate="yes" xml:space="preserve">
          <source>Learn model for the data X with variational Bayes method.</source>
          <target state="translated">Изучите модель для данных X с помощью вариационного метода Байеса.</target>
        </trans-unit>
        <trans-unit id="dacb80f7c7ce4a5db80b953f259da8b386886101" translate="yes" xml:space="preserve">
          <source>Learn the idf vector (global term weights)</source>
          <target state="translated">Изучите вектор idf (глобальные терминологические веса).</target>
        </trans-unit>
        <trans-unit id="fb7b507c119ba0834ef410110951b80a51da9b63" translate="yes" xml:space="preserve">
          <source>Learn the idf vector (global term weights).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b331e0a3149fc26c2099c41ac3e9655d530c7a47" translate="yes" xml:space="preserve">
          <source>Learn the inverse transform for non-precomputed kernels. (i.e. learn to find the pre-image of a point)</source>
          <target state="translated">Изучите обратное преобразование для неперечисленных ядер.(т.е.научиться находить предварительное изображение точки).</target>
        </trans-unit>
        <trans-unit id="351ef97b73f57653764681dfe2a94603d5d1cbab" translate="yes" xml:space="preserve">
          <source>Learn the vocabulary dictionary and return document-term matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee96e1f94ac61b3bff29cbb75afd2fdb8a437bed" translate="yes" xml:space="preserve">
          <source>Learn the vocabulary dictionary and return term-document matrix.</source>
          <target state="translated">Изучите словарь терминов и верните матрицу терминологических документов.</target>
        </trans-unit>
        <trans-unit id="65adc2e107d7d619d7107cf14005ab5e9c9cd5ef" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf from training set.</source>
          <target state="translated">Изучайте словарный запас и idf из учебного набора.</target>
        </trans-unit>
        <trans-unit id="51c9b9cb5d5b207d3afa5b6e39e7500c1ff633ed" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf, return document-term matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9ba5b6f4cc6cff1198de21973fdc3c62d64336f" translate="yes" xml:space="preserve">
          <source>Learn vocabulary and idf, return term-document matrix.</source>
          <target state="translated">Изучайте лексику и idf,возвращайте матрицу терминологического документа.</target>
        </trans-unit>
        <trans-unit id="5b86400dde56a045e486ecc10d7618c7daf0f573" translate="yes" xml:space="preserve">
          <source>Learning a graph structure</source>
          <target state="translated">Изучение графической структуры</target>
        </trans-unit>
        <trans-unit id="4ecad9f15b8037b0486e20e0cb489ddd61caeca5" translate="yes" xml:space="preserve">
          <source>Learning an embedding</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f89176d3f1741099f1479699aa585a0c6906b634" translate="yes" xml:space="preserve">
          <source>Learning and predicting</source>
          <target state="translated">Обучение и прогнозирование</target>
        </trans-unit>
        <trans-unit id="5087c606edcdf30c07ac8bd6a14c9b96c0975b25" translate="yes" xml:space="preserve">
          <source>Learning curve.</source>
          <target state="translated">Кривая обучения.</target>
        </trans-unit>
        <trans-unit id="af86142d107ea3e7d568509ca68cbef348748b05" translate="yes" xml:space="preserve">
          <source>Learning problems fall into a few categories:</source>
          <target state="translated">Проблемы с обучением делятся на несколько категорий:</target>
        </trans-unit>
        <trans-unit id="213b18cf4e4c891522544c2231435e470a8853a1" translate="yes" xml:space="preserve">
          <source>Learning rate schedule for weight updates.</source>
          <target state="translated">График обучения для обновления веса.</target>
        </trans-unit>
        <trans-unit id="ad3970bc51aa8e2c82bc13dcb9d4922e01a06590" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each classifier by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">Скорость обучения уменьшает вклад каждого классификатора на &lt;code&gt;learning_rate&lt;/code&gt; . Существует компромисс между &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cc055e36b16b7ea8669e5252649d8e3ee1af0b11" translate="yes" xml:space="preserve">
          <source>Learning rate shrinks the contribution of each regressor by &lt;code&gt;learning_rate&lt;/code&gt;. There is a trade-off between &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;n_estimators&lt;/code&gt;.</source>
          <target state="translated">Скорость обучения уменьшает вклад каждого регрессора на &lt;code&gt;learning_rate&lt;/code&gt; . Существует компромисс между &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;n_estimators&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8982fb177d3b5a895540d84670a324c9b8376572" translate="yes" xml:space="preserve">
          <source>Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called &lt;strong&gt;overfitting&lt;/strong&gt;. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a &lt;strong&gt;test set&lt;/strong&gt;&lt;code&gt;X_test, y_test&lt;/code&gt;. Note that the word &amp;ldquo;experiment&amp;rdquo; is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally.</source>
          <target state="translated">Изучение параметров функции прогнозирования и тестирование ее на одних и тех же данных является методологической ошибкой: модель, которая будет просто повторять метки образцов, которые она только что увидела, будет иметь идеальную оценку, но не сможет еще предсказать что-либо полезное. невидимые данные. Такая ситуация называется &lt;strong&gt;переобучением&lt;/strong&gt; . Чтобы этого избежать, при проведении (контролируемого) эксперимента с машинным обучением распространена практика хранения части доступных данных в виде &lt;strong&gt;тестового набора &lt;/strong&gt; &lt;code&gt;X_test, y_test&lt;/code&gt; . Обратите внимание, что слово &amp;laquo;эксперимент&amp;raquo; не предназначено для обозначения только академического использования, потому что даже в коммерческих условиях машинное обучение обычно начинается экспериментально.</target>
        </trans-unit>
        <trans-unit id="7ed56c1456833faed4202c795166989f5307ee69" translate="yes" xml:space="preserve">
          <source>Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called &lt;strong&gt;overfitting&lt;/strong&gt;. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a &lt;strong&gt;test set&lt;/strong&gt;&lt;code&gt;X_test, y_test&lt;/code&gt;. Note that the word &amp;ldquo;experiment&amp;rdquo; is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; techniques.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93c3e1794e48ba7d8637b32d813e97686cf36d4f" translate="yes" xml:space="preserve">
          <source>Learns each output independently rather than chaining.</source>
          <target state="translated">Изучает каждый выход самостоятельно,а не приковывает цепь.</target>
        </trans-unit>
        <trans-unit id="5fce8b00092369b98dfb920b76a7ee0efe5e00b1" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a.</source>
          <target state="translated">Модель регрессии по методу наименьшего угла,так же известная как...</target>
        </trans-unit>
        <trans-unit id="3b28e26eb21f16fdbdefabf1ed5ad375edeafb8b" translate="yes" xml:space="preserve">
          <source>Least Angle Regression model a.k.a. LAR</source>
          <target state="translated">Модель регрессии по методу наименьшего угла,также известная как LAR.</target>
        </trans-unit>
        <trans-unit id="b8ab306ac662259fba4aa6725b193c75be140b61" translate="yes" xml:space="preserve">
          <source>Least Squares projection of the data onto the sparse components.</source>
          <target state="translated">Проекция данных в виде наименьших квадратов на разреженные компоненты.</target>
        </trans-unit>
        <trans-unit id="2c3aa035aea93ac3dc79ecee5528b7c8dcfba4ab" translate="yes" xml:space="preserve">
          <source>Least absolute deviation (&lt;code&gt;'lad'&lt;/code&gt;): A robust loss function for regression. The initial model is given by the median of the target values.</source>
          <target state="translated">Наименьшее абсолютное отклонение ( &lt;code&gt;'lad'&lt;/code&gt; ): надежная функция потерь для регрессии. Исходная модель задается медианой целевых значений.</target>
        </trans-unit>
        <trans-unit id="3aeaacb76e6b5d496047f324133ddd0747e1d2c6" translate="yes" xml:space="preserve">
          <source>Least squares (&lt;code&gt;'ls'&lt;/code&gt;): The natural choice for regression due to its superior computational properties. The initial model is given by the mean of the target values.</source>
          <target state="translated">Метод наименьших квадратов ( &lt;code&gt;'ls'&lt;/code&gt; ): естественный выбор для регрессии из-за его превосходных вычислительных свойств. Исходная модель представлена ​​средним целевым значением.</target>
        </trans-unit>
        <trans-unit id="972ad47a68ab0dd02c8d4f9c32f25ef79120c408" translate="yes" xml:space="preserve">
          <source>Least-Squares: Linear regression (Ridge or Lasso depending on \(R\)). \(L(y_i, f(x_i)) = \frac{1}{2}(y_i - f(x_i))^2\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7963186b092849241b779637d34ce64214b0375a" translate="yes" xml:space="preserve">
          <source>Least-Squares: Ridge Regression.</source>
          <target state="translated">Меньше квадратов:Регрессия хребта.</target>
        </trans-unit>
        <trans-unit id="acf6db0396d489bb160af474285d57fb823df68a" translate="yes" xml:space="preserve">
          <source>Least-angle regression (&lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;Least Angle Regression&lt;/a&gt;)</source>
          <target state="translated">Регрессия &lt;a href=&quot;linear_model#least-angle-regression&quot;&gt;наименьшего угла&lt;/a&gt; ( наименьшая угловая регрессия )</target>
        </trans-unit>
        <trans-unit id="8427893bdf84ecb2b84085547aa1cfdd8fd0e807" translate="yes" xml:space="preserve">
          <source>Least-angle regression (LARS) is a regression algorithm for high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. LARS is similar to forward stepwise regression. At each step, it finds the feature most correlated with the target. When there are multiple features having equal correlation, instead of continuing along the same feature, it proceeds in a direction equiangular between the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="818f02ffe71d576f8833c06d3318f5d50790be37" translate="yes" xml:space="preserve">
          <source>Least-angle regression (LARS) is a regression algorithm for high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. LARS is similar to forward stepwise regression. At each step, it finds the predictor most correlated with the response. When there are multiple predictors having equal correlation, instead of continuing along the same predictor, it proceeds in a direction equiangular between the predictors.</source>
          <target state="translated">Регрессия по методу наименьшего угла (LARS)-это алгоритм регрессии для высокоразмерных данных,разработанный Брэдли Эфроном,Тревором Хасти,Иеном Джонстоуном и Робертом Тибширани.LARS похож на прогрессивную регрессию в прямом направлении.На каждом шаге он находит предиктор,наиболее коррелированный с ответом.При наличии множества предикторов,имеющих равную корреляцию,вместо того,чтобы продолжать по одному и тому же предиктору,он движется в направлении,равностороннем между предикторами.</target>
        </trans-unit>
        <trans-unit id="5cc9936fd171dfb4c941611970a01e31c9182cee" translate="yes" xml:space="preserve">
          <source>Leave One Group Out cross-validator</source>
          <target state="translated">Оставьте одну группу вне перекрёстного валидатора.</target>
        </trans-unit>
        <trans-unit id="708b3ff9ed12b2c6f3635d37f516d672f76ad26e" translate="yes" xml:space="preserve">
          <source>Leave P Group(s) Out cross-validator</source>
          <target state="translated">Оставить П-группу (группы)Вне перекрестного валидатора</target>
        </trans-unit>
        <trans-unit id="b1d423c90dfa79c0db1cf2e91d8b80c110d2debb" translate="yes" xml:space="preserve">
          <source>Leave P groups out.</source>
          <target state="translated">Оставьте &quot;П&quot; группы вне игры.</target>
        </trans-unit>
        <trans-unit id="2e788c12c63436d5bbf2b3d54792d07b4ad5906d" translate="yes" xml:space="preserve">
          <source>Leave P observations out.</source>
          <target state="translated">Оставьте наблюдения &quot;П&quot;.</target>
        </trans-unit>
        <trans-unit id="23a4dfbb0e55172e2c29fa75763519463b465b57" translate="yes" xml:space="preserve">
          <source>Leave one observation out.</source>
          <target state="translated">Оставьте одно наблюдение.</target>
        </trans-unit>
        <trans-unit id="96e7c056605d5580183d915f0e8250d81cc4028b" translate="yes" xml:space="preserve">
          <source>Leave-One-Out cross-validator</source>
          <target state="translated">Перекрёстный валидатор &quot;оставил-не оставил-не оставил&quot;.</target>
        </trans-unit>
        <trans-unit id="a3d5fb094bf6540a5945dfebfc612a40422d0970" translate="yes" xml:space="preserve">
          <source>Leave-P-Out cross-validator</source>
          <target state="translated">Перекрестный валидатор Leave-P-Out</target>
        </trans-unit>
        <trans-unit id="7fa92633d7eb4070a1a9e7f3ffd6a6dd808d5514" translate="yes" xml:space="preserve">
          <source>Ledoit O, Wolf M. Honey, I Shrunk the Sample Covariance Matrix. The Journal of Portfolio Management 30(4), 110-119, 2004.</source>
          <target state="translated">Ледуард О,Вульф М.Дорогой,я забиваю ковариационную матрицу образца.Журнал управления портфелями 30(4),110-119,2004.</target>
        </trans-unit>
        <trans-unit id="b6a08e295c1dafc447ef93ac82d0e6a70b01528e" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient is computed using O. Ledoit and M. Wolf&amp;rsquo;s formula as described in &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Ledoit and Wolf, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">Ледуа-Вольф - это особая форма усадки, где коэффициент усадки вычисляется с использованием формулы О. Ледуа и М. Вольфа, как описано в &amp;laquo;Хорошо обусловленная оценка для матриц большой размерной ковариации&amp;raquo;, Ледуа и Вольф, Журнал многомерного анализа , Том 88, выпуск 2, февраль 2004 г., страницы 365-411.</target>
        </trans-unit>
        <trans-unit id="b450ff5574aa7547a2d2804a59fde9043d1f11e3" translate="yes" xml:space="preserve">
          <source>Ledoit-Wolf vs OAS estimation</source>
          <target state="translated">Оценка Ledoit-Wolf против OAS</target>
        </trans-unit>
        <trans-unit id="74b56641357b357e1a04f8ba20caa0211258f1b9" translate="yes" xml:space="preserve">
          <source>LedoitWolf Estimator</source>
          <target state="translated">LedoitWolf Estimator</target>
        </trans-unit>
        <trans-unit id="a7127a921977497178bbe9d19b374d5b3660e695" translate="yes" xml:space="preserve">
          <source>Left argument of the returned kernel k(X, Y)</source>
          <target state="translated">Левый аргумент возвращаемого ядра k(X,Y)</target>
        </trans-unit>
        <trans-unit id="db46139863e59ff060f10e61ce009637ab35e3fe" translate="yes" xml:space="preserve">
          <source>Left argument of the returned kernel k(X, Y).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9bf558c9b2f1ab98bdd863d46c825f77b8bcb622" translate="yes" xml:space="preserve">
          <source>Left to right.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75bf879e9683d8e42f9cdbce4ac2378477aafa4c" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</source>
          <target state="translated">Длина пути. &lt;code&gt;eps=1e-3&lt;/code&gt; означает, что &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c25fd55e85b58584519914fbcbbc8e0b71dacb4b" translate="yes" xml:space="preserve">
          <source>Length of the path. &lt;code&gt;eps=1e-3&lt;/code&gt; means that &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt;.</source>
          <target state="translated">Длина пути. &lt;code&gt;eps=1e-3&lt;/code&gt; означает, что &lt;code&gt;alpha_min / alpha_max = 1e-3&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="817bbec7d68f2acac91e1c4383d071e50b618e53" translate="yes" xml:space="preserve">
          <source>Less sensitivity to the number of parameters</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="820f47ab7dc5f77aa60df5d42cf3669d7140be19" translate="yes" xml:space="preserve">
          <source>Less sensitivity to the number of parameters:</source>
          <target state="translated">Меньше чувствительности к количеству параметров:</target>
        </trans-unit>
        <trans-unit id="5f1b602bd58c70400c6cc3123702692e92eee6c0" translate="yes" xml:space="preserve">
          <source>Lessons learned</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="650648dcfa58ca5d69540fc9d7c76c71c03cdd8d" translate="yes" xml:space="preserve">
          <source>Let K(x, z) be a kernel defined by phi(x)^T phi(z), where phi is a function mapping x to a Hilbert space. KernelCenterer centers (i.e., normalize to have zero mean) the data without explicitly computing phi(x). It is equivalent to centering phi(x) with sklearn.preprocessing.StandardScaler(with_std=False).</source>
          <target state="translated">Пусть K(x,z)-это ядро,определенное phi(x)^T phi(z),где phi-это функция,отображающая x в пространство Гильберта.Центры KernelCenterer (т.е.нормализуют к нулевому среднему значению)данные без явного вычисления phi(x).Это эквивалентно центрированию фи(x)с помощью sklearn.preproprocessing.StandardScaler(with_std=False).</target>
        </trans-unit>
        <trans-unit id="821c4d001d9578c562e1b0af64f8be6da39e632f" translate="yes" xml:space="preserve">
          <source>Let \(S\) be the similarity matrix, and \(X\) the coordinates of the \(n\) input points. Disparities \(\hat{d}_{ij}\) are transformation of the similarities chosen in some optimal ways. The objective, called the stress, is then defined by \(\sum_{i &amp;lt; j} d_{ij}(X) - \hat{d}_{ij}(X)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d3e4f22e7563805ce13fd93e247765bb5c10653" translate="yes" xml:space="preserve">
          <source>Let \(S\) be the similarity matrix, and \(X\) the coordinates of the \(n\) input points. Disparities \(\hat{d}_{ij}\) are transformation of the similarities chosen in some optimal ways. The objective, called the stress, is then defined by \(sum_{i &amp;lt; j} d_{ij}(X) - \hat{d}_{ij}(X)\)</source>
          <target state="translated">Пусть \ (S \) - матрица подобия, а \ (X \) - координаты входных точек \ (n \). Неравенства \ (\ hat {d} _ {ij} \) - это преобразование подобий, выбранных некоторыми оптимальными способами. Затем цель, называемая напряжением, определяется как \ (sum_ {i &amp;lt;j} d_ {ij} (X) - \ hat {d} _ {ij} (X) \)</target>
        </trans-unit>
        <trans-unit id="5ab8a1b7961470064849295cd500b6579b4fa397" translate="yes" xml:space="preserve">
          <source>Let \(X_S\) be the set of target features (i.e. the &lt;code&gt;features&lt;/code&gt; parameter) and let \(X_C\) be its complement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0a7cf3804b0fab7efc2f61eebe3b5930a870c77" translate="yes" xml:space="preserve">
          <source>Let the data at node \(m\) be represented by \(Q\). For each candidate split \(\theta = (j, t_m)\) consisting of a feature \(j\) and threshold \(t_m\), partition the data into \(Q_{left}(\theta)\) and \(Q_{right}(\theta)\) subsets</source>
          <target state="translated">Пусть данные на узле \(m\)будут представлены \(Q\).Для каждого кандидата разбить \(\theta=(j,t_m)\)на подмножества \(j\)и порог \(t_m\),разделить данные на подмножества \(Q_{left}(\theta)\)и \(Q_{right}(\theta)\).</target>
        </trans-unit>
        <trans-unit id="0eec5761b9ded7fa59a47d01c0fcb2883cae7dd4" translate="yes" xml:space="preserve">
          <source>Let us now try to reconstruct the original image from the patches by averaging on overlapping areas:</source>
          <target state="translated">Теперь попробуем воссоздать исходное изображение по патчам,усредняя по областям перекрытия:</target>
        </trans-unit>
        <trans-unit id="b5fecaca6e2e29d4dbee3904d66ce06eade247b5" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s compute the performance of this constant prediction baseline with 3 different regression metrics:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="253db59ca1134838191e01d302a48262e9ba6374" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s consider the following trained regression model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44b9f209d8c4175d9e9b8f1619b5304447365c9" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s fit a MLPRegressor and compute single-variable partial dependence plots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c338f438f84e4277f756f203f24830c86a10546d" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s load data from the newsgroups dataset which comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b852fb92508c2f8d11c716ed1054a5db1d558210" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s load the motor claim dataset from OpenML: &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;https://www.openml.org/d/41214&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed3c266c74a01e549482a05ad99384adcdbf59a9" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s make the same partial dependence plot for the 2 features interaction, this time in 3 dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f393e9b32e94a400250ae55bd302c219802fcb3" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s now compute the partial dependence plots for this neural network using the model-agnostic (brute-force) method:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c401ba9464abf901fd51a8e8666504a0d45adbfb" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s now fit a GradientBoostingRegressor and compute the partial dependence plots either or one or two variables at a time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="106ecb5f7c6bb4669d70caeae32d17518696e61b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s print the first lines of the first loaded file:</source>
          <target state="translated">Напечатаем первые строки первого загруженного файла:</target>
        </trans-unit>
        <trans-unit id="bcd495b6fedeb570ab62363e5dbb308b08a2e969" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 25, and 50, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 25 и 50 и вы хотите узнать название их класса.</target>
        </trans-unit>
        <trans-unit id="65595eba1f80a7173dc24674f2afc2d5837968b2" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 50, and 85, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 50 и 85 и вы хотите узнать имя их класса.</target>
        </trans-unit>
        <trans-unit id="fb46983e946ca9f3803c9b6fd00931719bb67d7b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s say you are interested in the samples 10, 80, and 140, and want to know their class name.</source>
          <target state="translated">Допустим, вас интересуют образцы 10, 80 и 140 и вы хотите узнать имя их класса.</target>
        </trans-unit>
        <trans-unit id="e8b31884f71e52e12b72fcb054664d8ab80d318b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how it looks for the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; cross-validation object:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36ae1b66774b74a6fe504ba4aa0655c5c58c7d06" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how it looks for the &lt;code&gt;KFold&lt;/code&gt; cross-validation object:</source>
          <target state="translated">Посмотрим, как это выглядит для &lt;code&gt;KFold&lt;/code&gt; перекрестной проверки KFold :</target>
        </trans-unit>
        <trans-unit id="9c035fe2592c35e4264add67f9ea318300cfbf19" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take a look at what the most informative features are:</source>
          <target state="translated">Давайте посмотрим, какие функции наиболее информативны:</target>
        </trans-unit>
        <trans-unit id="fc26adc7a4427a7251d50d414ace6a50d7fbe76d" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s take an example with the following counts. The first term is present 100% of the time hence not very interesting. The two other features only in less than 50% of the time hence probably more representative of the content of the documents:</source>
          <target state="translated">Давайте рассмотрим пример со следующими подсчетами. Первый член присутствует 100% времени, поэтому не очень интересен. Две другие функции используются менее чем в 50% случаев, следовательно, вероятно, более репрезентативны для содержания документов:</target>
        </trans-unit>
        <trans-unit id="2f95c182cf5fa2e13ce2622defe8af992d765313" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s try again with the default setting:</source>
          <target state="translated">Попробуем еще раз с настройкой по умолчанию:</target>
        </trans-unit>
        <trans-unit id="c3a6b9996c4370e6a8670703084aa093c6face20" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s use it to tokenize and count the word occurrences of a minimalistic corpus of text documents:</source>
          <target state="translated">Давайте воспользуемся им для токенизации и подсчета вхождений слов в минималистичном корпусе текстовых документов:</target>
        </trans-unit>
        <trans-unit id="292ee05108cd151612c92edea6da34acc9a56662" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s use pandas to load a copy of the titanic dataset. The following shows how to apply separate preprocessing on numerical and categorical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77ba9dd4a1f63d6e3e47c6ccfdd6637c48fa284" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s visually compare the cross validation behavior for many scikit-learn cross-validation objects. Below we will loop through several common cross-validation objects, visualizing the behavior of each.</source>
          <target state="translated">Давайте визуально сравним поведение перекрестной проверки для многих объектов перекрестной проверки scikit-learn. Ниже мы переберем несколько общих объектов перекрестной проверки, визуализируя поведение каждого из них.</target>
        </trans-unit>
        <trans-unit id="6c69807d4e78cfb8da9f8e8c21f378d88124782a" translate="yes" xml:space="preserve">
          <source>Level of verbosity.</source>
          <target state="translated">Уровень глаголов.</target>
        </trans-unit>
        <trans-unit id="339e81226696b46d7377960244af7f4dcb540176" translate="yes" xml:space="preserve">
          <source>Lewis, D. D., Yang, Y., Rose, T. G., &amp;amp; Li, F. (2004). RCV1: A new benchmark collection for text categorization research. The Journal of Machine Learning Research, 5, 361-397.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee9267aef527ceaeed70f092da783571e1b2536d" translate="yes" xml:space="preserve">
          <source>Libsvm GUI</source>
          <target state="translated">Либсвм ГУИ</target>
        </trans-unit>
        <trans-unit id="87b3d037e844d0b272ce5bfc0fb0a06e31f13827" translate="yes" xml:space="preserve">
          <source>License: BSD 3 clause</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="538c09161b8497f998404cafc34964ed3a445575" translate="yes" xml:space="preserve">
          <source>Licensed under the 3-clause BSD License.</source>
          <target state="translated">Лицензия BSD 3-clause License.</target>
        </trans-unit>
        <trans-unit id="d119b02c417272fad54f56fb5c480a5a866c4e2e" translate="yes" xml:space="preserve">
          <source>Lichman, M. (2013). UCI Machine Learning Repository [&lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt;]. Irvine, CA: University of California, School of Information and Computer Science.</source>
          <target state="translated">Личман, М. (2013). Репозиторий машинного обучения UCI [ &lt;a href=&quot;http://archive.ics.uci.edu/ml&quot;&gt;http://archive.ics.uci.edu/ml&lt;/a&gt; ]. Ирвин, Калифорния: Калифорнийский университет, Школа информационных и компьютерных наук.</target>
        </trans-unit>
        <trans-unit id="e76bfa901cdd22255b64ebacf70ec6f76b7f04ab" translate="yes" xml:space="preserve">
          <source>Lichman, M. (2013). UCI Machine Learning Repository [&lt;a href=&quot;https://archive.ics.uci.edu/ml&quot;&gt;https://archive.ics.uci.edu/ml&lt;/a&gt;]. Irvine, CA: University of California, School of Information and Computer Science.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a2cabe35d47f4d173451a3dc4bce594fc9e8434" translate="yes" xml:space="preserve">
          <source>Like &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;, forests of trees also extend to &lt;a href=&quot;tree#tree-multioutput&quot;&gt;multi-output problems&lt;/a&gt; (if Y is an array of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt;).</source>
          <target state="translated">Подобно &lt;a href=&quot;tree#tree&quot;&gt;деревьям решений&lt;/a&gt; , леса деревьев также распространяются на &lt;a href=&quot;tree#tree-multioutput&quot;&gt;задачи&lt;/a&gt; с несколькими выходами (если Y является массивом размера &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="f8c94a1d14fd76e50a18d8c5112493b7c41a75b8" translate="yes" xml:space="preserve">
          <source>Like &lt;code&gt;Pipeline&lt;/code&gt;, individual steps may be replaced using &lt;code&gt;set_params&lt;/code&gt;, and ignored by setting to &lt;code&gt;'drop'&lt;/code&gt;:</source>
          <target state="translated">Как и в случае с &lt;code&gt;Pipeline&lt;/code&gt; , отдельные шаги можно заменить с помощью &lt;code&gt;set_params&lt;/code&gt; и игнорировать, установив значение &lt;code&gt;'drop'&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="09c07eeb7023cd495f9b67aa8c5832e9de0a3634" translate="yes" xml:space="preserve">
          <source>Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.</source>
          <target state="translated">Как и MultinomialNB,этот классификатор подходит для дискретных данных.Разница заключается в том,что в то время как MultinomialNB работает со счетами вхождений,BernoulliNB предназначен для двоичных/булевых функций.</target>
        </trans-unit>
        <trans-unit id="33e640491ab99ccee8501c0c94b8deb9f93a420b" translate="yes" xml:space="preserve">
          <source>Like fit(X) followed by transform(X), but does not require materializing X in memory.</source>
          <target state="translated">Подобно fit(X)с последующим преобразованием(X),но не требует материализации X в памяти.</target>
        </trans-unit>
        <trans-unit id="07a7d71492c9370f4c5f214183352ca2f48a9590" translate="yes" xml:space="preserve">
          <source>Like in Pipeline and FeatureUnion, this allows the transformer and its parameters to be set using &lt;code&gt;set_params&lt;/code&gt; and searched in grid search.</source>
          <target state="translated">Как и в Pipeline и FeatureUnion, это позволяет настраивать преобразователь и его параметры с помощью &lt;code&gt;set_params&lt;/code&gt; и выполнять поиск в поиске по сетке.</target>
        </trans-unit>
        <trans-unit id="ace16ab25f8f0e2cb278ad02989604150a81258c" translate="yes" xml:space="preserve">
          <source>Like pipelines, feature unions have a shorthand constructor called &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt;&lt;code&gt;make_union&lt;/code&gt;&lt;/a&gt; that does not require explicit naming of the components.</source>
          <target state="translated">Как и конвейеры, объединения функций имеют сокращенный конструктор &lt;a href=&quot;generated/sklearn.pipeline.make_union#sklearn.pipeline.make_union&quot;&gt; &lt;code&gt;make_union&lt;/code&gt; &lt;/a&gt; , который не требует явного именования компонентов.</target>
        </trans-unit>
        <trans-unit id="29685b73b0fbefa3dc8a3378779801b7f7266cf2" translate="yes" xml:space="preserve">
          <source>Like scalers, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt; puts all features into the same, known range or distribution. However, by performing a rank transformation, it smooths out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features.</source>
          <target state="translated">Как и скейлеры, &lt;a href=&quot;generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt; помещает все функции в один и тот же известный диапазон или распределение. Однако, выполняя преобразование ранга, он сглаживает необычные распределения и меньше подвержен влиянию выбросов, чем методы масштабирования. Однако это искажает корреляции и расстояния внутри и между объектами.</target>
        </trans-unit>
        <trans-unit id="73666b411bce492e14d6ba5736c0ca5eebf6eb1b" translate="yes" xml:space="preserve">
          <source>Like the Poisson GLM above, the gradient boosted trees model minimizes the Poisson deviance. However, because of a higher predictive power, it reaches lower values of Poisson deviance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ae4ed5af04ee97eab148462e283fb7149bd9d04" translate="yes" xml:space="preserve">
          <source>Limit in bytes of the size of the cache.</source>
          <target state="translated">Ограничение в байтах размера кэша.</target>
        </trans-unit>
        <trans-unit id="bbd76c46a461ce6867ca433ec8697501cc65b137" translate="yes" xml:space="preserve">
          <source>Limiting distance of neighbors to return. (default is the value passed to the constructor).</source>
          <target state="translated">Ограничение расстояния до соседей,чтобы вернуться.(по умолчанию-значение,переданное конструктору).</target>
        </trans-unit>
        <trans-unit id="62c917554a7197d63486db913ca90de577c0bfe0" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis</source>
          <target state="translated">Линейный анализ дискриминанта</target>
        </trans-unit>
        <trans-unit id="bb7eb231c96859c6082b4ce0d3b796b4329f6e8f" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) are two classic classifiers, with, as their names suggest, a linear and a quadratic decision surface, respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="719a12bbe391db4f9a1b1f0f22d958d133e79356" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) are two classic classifiers, with, as their names suggest, a linear and a quadratic decision surface, respectively.</source>
          <target state="translated">Линейный дискриминантный анализ ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) и квадратичный дискриминантный анализ ( &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt; ) - это два классических классификатора с, как следует из их названия, линейной и квадратичной поверхностью принятия решений соответственно.</target>
        </trans-unit>
        <trans-unit id="e36f5257c349ab3d8389a5027fa29765ef7a78a4" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance &lt;em&gt;between classes&lt;/em&gt;. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.</source>
          <target state="translated">Линейный дискриминантный анализ (LDA) пытается определить атрибуты, на которые приходится наибольшая разница &lt;em&gt;между классами&lt;/em&gt; . В частности, LDA, в отличие от PCA, является контролируемым методом, использующим известные метки классов.</target>
        </trans-unit>
        <trans-unit id="02924b985796944d65c857ba377ee96748a5fefe" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis and Quadratic Discriminant Analysis</source>
          <target state="translated">Линейный анализ дискриминантов и квадратичный анализ дискриминантов</target>
        </trans-unit>
        <trans-unit id="37e8c1f7f3b5f52be8ccec8de8de9cd593660b24" translate="yes" xml:space="preserve">
          <source>Linear Discriminant Analysis, from the &lt;a href=&quot;../../modules/classes#module-sklearn.discriminant_analysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis&lt;/code&gt;&lt;/a&gt; module, and Neighborhood Components Analysis, from the &lt;a href=&quot;../../modules/classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; module, are supervised dimensionality reduction method, i.e. they make use of the provided labels, contrary to other methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe99070400d8a366d4438afb34b3817ed643e76c" translate="yes" xml:space="preserve">
          <source>Linear Model trained with L1 prior as regularizer (aka the Lasso)</source>
          <target state="translated">Линейная модель,прошедшая обучение с L1 в качестве регулятора (он же Лассо).</target>
        </trans-unit>
        <trans-unit id="b4819d272193c458d14d3c2a02b6439edb693339" translate="yes" xml:space="preserve">
          <source>Linear Regression Example</source>
          <target state="translated">Пример линейной регрессии</target>
        </trans-unit>
        <trans-unit id="85494d31f5cd31cf05c6e37284f8e968283c0002" translate="yes" xml:space="preserve">
          <source>Linear SVC is not a probabilistic classifier by default but it has a built-in calibration option enabled in this example (&lt;code&gt;probability=True&lt;/code&gt;).</source>
          <target state="translated">Линейный SVC по умолчанию не является вероятностным классификатором, но в этом примере для него включена встроенная опция калибровки ( &lt;code&gt;probability=True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e97d7a71e4408e1f570cb8d2ee92b68f661724af" translate="yes" xml:space="preserve">
          <source>Linear SVMs</source>
          <target state="translated">Линейные СВМ</target>
        </trans-unit>
        <trans-unit id="73af0f0fe2656e7c704e9d2782f72d490054905e" translate="yes" xml:space="preserve">
          <source>Linear Sum - A n-dimensional vector holding the sum of all samples</source>
          <target state="translated">Линейная сумма-n-мерный вектор,содержащий сумму всех образцов</target>
        </trans-unit>
        <trans-unit id="1cd7978197df4491cb006d18687f0ce787689e06" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification (&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt;) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">Классификация линейных опорных &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; ( LinearSVC ) показывает еще более сигмовидную кривую, чем RandomForestClassifier, что типично для методов с максимальной маржой (сравните Никулеску-Мизил и Каруана &lt;a href=&quot;#id4&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt; ), которые сосредоточены на жестких выборках, которые близки к границе решения ( опорные векторы).</target>
        </trans-unit>
        <trans-unit id="aa48807728eba9fefe9fd82435afe3ea7ac48643" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification (&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt;) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id6&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88aaad048f30298d89bc0519c1e6f4cfbb7c20ea" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Classification.</source>
          <target state="translated">Векторная классификация линейной поддержки.</target>
        </trans-unit>
        <trans-unit id="4669e7bb12c975a34b6d592ccfe985850a9e31eb" translate="yes" xml:space="preserve">
          <source>Linear Support Vector Regression.</source>
          <target state="translated">Векторная регрессия линейной поддержки.</target>
        </trans-unit>
        <trans-unit id="299f04ebeb7ad11bec6b5498c6b639ccade4023d" translate="yes" xml:space="preserve">
          <source>Linear and Quadratic Discriminant Analysis with covariance ellipsoid</source>
          <target state="translated">Линейный и квадратичный анализ дискриминанта с ковариантным эллипсоидом</target>
        </trans-unit>
        <trans-unit id="f5530856b3075f323ba02b6ac9992d5aae8eee6e" translate="yes" xml:space="preserve">
          <source>Linear classifiers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0463594ed874e4d015c682e8a6395a05e3fbd8b" translate="yes" xml:space="preserve">
          <source>Linear classifiers (SVM, logistic regression, a.o.) with SGD training.</source>
          <target state="translated">Линейные классификаторы (SVM,логистическая регрессия,a.o.)с обучением SGD.</target>
        </trans-unit>
        <trans-unit id="9a198808a208105876aff5b3459a1743d02b9e6c" translate="yes" xml:space="preserve">
          <source>Linear classifiers (SVM, logistic regression, etc.) with SGD training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa82faf2d530b479b3e87ec39c80fc313d729e93" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of centered data, keeping only the most significant singular vectors to project the data to a lower dimensional space.</source>
          <target state="translated">Линейное уменьшение размерности с помощью Singular Value Decomposition из централизованных данных,сохраняя только наиболее значимые сингулярные векторы для проецирования данных в меньшее размерное пространство.</target>
        </trans-unit>
        <trans-unit id="9db7130b75e27bc47e2764b6ec7d1ce03bb7f92f" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.</source>
          <target state="translated">Уменьшение линейной размерности с помощью Singular Value Decomposition данных для проецирования их на меньшее размерное пространство.</target>
        </trans-unit>
        <trans-unit id="6451e9b1aa60579e3e911ed4aef57d459ed7cbf1" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7a4096bc58f13af1ea98cce08fd73c62fb91596" translate="yes" xml:space="preserve">
          <source>Linear dimensionality reduction using Singular Value Decomposition of the data, keeping only the most significant singular vectors to project the data to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="212b70af3cba5b501136f7c4f46821ce9f54ad31" translate="yes" xml:space="preserve">
          <source>Linear kernel (&lt;code&gt;kernel = 'linear'&lt;/code&gt;)</source>
          <target state="translated">Линейное ядро ​​( &lt;code&gt;kernel = 'linear'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="1196f0388e6edcd3bda2236746717385556b159a" translate="yes" xml:space="preserve">
          <source>Linear least squares with l2 regularization.</source>
          <target state="translated">Линейные наименьшие квадраты с регуляризацией l2.</target>
        </trans-unit>
        <trans-unit id="0663410286eb390a6a91a4885ecdb0348930bc50" translate="yes" xml:space="preserve">
          <source>Linear model fitted by minimizing a regularized empirical loss with SGD</source>
          <target state="translated">Линейная модель,подогнанная путем минимизации регулярных эмпирических потерь с помощью SGD</target>
        </trans-unit>
        <trans-unit id="8d6556caff9af87efd1e0ccffe2463b6a45189f7" translate="yes" xml:space="preserve">
          <source>Linear model for testing the individual effect of each of many regressors. This is a scoring function to be used in a feature selection procedure, not a free standing feature selection procedure.</source>
          <target state="translated">Линейная модель для тестирования индивидуального эффекта каждого из многих регрессоров.Это функция подсчета очков,которая будет использоваться в процедуре выбора функции,а не в процедуре свободного выбора функции.</target>
        </trans-unit>
        <trans-unit id="8f05719b5c26a33c08ae54e21caa15631a4bbbf1" translate="yes" xml:space="preserve">
          <source>Linear model: from regression to sparsity</source>
          <target state="translated">Линейная модель:от регрессии к спарсителю</target>
        </trans-unit>
        <trans-unit id="0b1d2caa3dbccbb7fc7a7a3c7fac23bacc286b81" translate="yes" xml:space="preserve">
          <source>Linear models with regularization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46d0fcb8f937066fa349aa94a3c710921424dd9b" translate="yes" xml:space="preserve">
          <source>Linear models with sparse coefficients</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c94cc16a66b49675f2acef482a0fbcd40d606ee" translate="yes" xml:space="preserve">
          <source>Linear models: \(y = X\beta + \epsilon\)</source>
          <target state="translated">Линейные модели:\(y=X\beta+\epsilon\).</target>
        </trans-unit>
        <trans-unit id="b501f602569674c31fc384f2cd7a29bcf6c1ce1f" translate="yes" xml:space="preserve">
          <source>Linear regression</source>
          <target state="translated">Линейная регрессия</target>
        </trans-unit>
        <trans-unit id="d8f88b232d41c327138bbda59458fa5fc4086fff" translate="yes" xml:space="preserve">
          <source>Linear regression model that is robust to outliers.</source>
          <target state="translated">Модель линейной регрессии,устойчивая к отклонениям.</target>
        </trans-unit>
        <trans-unit id="597ff76dcbb7bc322f194ba001977a736c193c2d" translate="yes" xml:space="preserve">
          <source>Linear regression with combined L1 and L2 priors as regularizer.</source>
          <target state="translated">Линейная регрессия с комбинированными L1 и L2 приорами в качестве регулятора.</target>
        </trans-unit>
        <trans-unit id="0a2d386e0774637a1788b00b4abdb8b2c6c38c74" translate="yes" xml:space="preserve">
          <source>Linear ridge regression.</source>
          <target state="translated">Регрессия линейного гребня.</target>
        </trans-unit>
        <trans-unit id="1dc397a187bb8fae755995aa069f79a9d565d581" translate="yes" xml:space="preserve">
          <source>Linear support vector classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5959458e20a73276c12d61f1d64604d66daab52d" translate="yes" xml:space="preserve">
          <source>LinearRegression</source>
          <target state="translated">LinearRegression</target>
        </trans-unit>
        <trans-unit id="6ff9599a07718d87fb124205a5a88e8262436582" translate="yes" xml:space="preserve">
          <source>LinearRegression fits a linear model with coefficients w = (w1, &amp;hellip;, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="daf34c391f43051e2982c2bbeba34bf1a7727132" translate="yes" xml:space="preserve">
          <source>List containing the artists for the annotation boxes making up the tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7ed3fbb6680836b95c3db482cfaf054c37a8419" translate="yes" xml:space="preserve">
          <source>List containing train-test split of inputs.</source>
          <target state="translated">Список,содержащий тестовое разделение входов.</target>
        </trans-unit>
        <trans-unit id="7946c78611ea79ca25491c94f60dac5182c68016" translate="yes" xml:space="preserve">
          <source>List of (name, class), where &lt;code&gt;name&lt;/code&gt; is the class name as string and &lt;code&gt;class&lt;/code&gt; is the actuall type of the class.</source>
          <target state="translated">Список (имя, класс), где &lt;code&gt;name&lt;/code&gt; - это имя класса в виде строки, а &lt;code&gt;class&lt;/code&gt; - это актуальный тип класса.</target>
        </trans-unit>
        <trans-unit id="01f72260e79a828ac37c6e1b27f0158a5c017639" translate="yes" xml:space="preserve">
          <source>List of (name, transform) tuples (implementing fit/transform) that are chained, in the order in which they are chained, with the last object an estimator.</source>
          <target state="translated">Список кортежей (имя,преобразование)(реализующие подгонку/преобразование),которые цепочечно,в порядке их цепочки,с последним объектом-оценщиком.</target>
        </trans-unit>
        <trans-unit id="da3552a00ac25869a883c68bd3a0b9b483a759ac" translate="yes" xml:space="preserve">
          <source>List of (name, transformer, column(s)) tuples specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="translated">Список кортежей (имя,трансформатор,столбец(ы))с указанием объектов трансформатора,которые должны применяться к подмножествам данных.</target>
        </trans-unit>
        <trans-unit id="d6a17bcffaea2ea2f18b9842614672499d0a26c6" translate="yes" xml:space="preserve">
          <source>List of (name, transformer, columns) tuples specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ce9067b559ab6542ebc584f224960b4d8e01fb3" translate="yes" xml:space="preserve">
          <source>List of &lt;code&gt;n_features&lt;/code&gt;-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Список &lt;code&gt;n_features&lt;/code&gt; -мерных точек данных. Каждая строка соответствует одной точке данных.</target>
        </trans-unit>
        <trans-unit id="5f38bb9ffb369276ed25fb7c04fb0e0e029823d8" translate="yes" xml:space="preserve">
          <source>List of all the classes that can possibly appear in the y vector.</source>
          <target state="translated">Список всех классов,которые могут появиться в y векторе.</target>
        </trans-unit>
        <trans-unit id="7cd6d854280958549421b40e7d622e1782f63df4" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If &lt;code&gt;None&lt;/code&gt; alphas are set automatically</source>
          <target state="translated">Список альфа, где вычислять модели. Если &lt;code&gt;None&lt;/code&gt; альфа устанавливается автоматически</target>
        </trans-unit>
        <trans-unit id="917b5a956108e84a4893edaf20f4507c6507d0e2" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If None alphas are set automatically</source>
          <target state="translated">Список альфов,где можно рассчитать модели.Если ни один альфа-фаз не установлен автоматически</target>
        </trans-unit>
        <trans-unit id="a5422f4e0e412f7e68186f61afde0578ebd8abd7" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If None alphas are set automatically.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d057f35a68cef6d291f5ea686ce0f4438a6a2951" translate="yes" xml:space="preserve">
          <source>List of alphas where to compute the models. If not provided, set automatically.</source>
          <target state="translated">Список альфов,где можно рассчитать модели.Если он не предусмотрен,установите его автоматически.</target>
        </trans-unit>
        <trans-unit id="fb8d4641f5ca2701f801733b19cf7bb77974f371" translate="yes" xml:space="preserve">
          <source>List of arrays of terms.</source>
          <target state="translated">Список массивов терминов.</target>
        </trans-unit>
        <trans-unit id="6ecedd8bbbc6137125014e8bb7a429cbcef11be8" translate="yes" xml:space="preserve">
          <source>List of built-in kernels.</source>
          <target state="translated">Список встроенных ядер.</target>
        </trans-unit>
        <trans-unit id="36c7ba17f19f78b4b0b98a1a27cecbfd22dc65e4" translate="yes" xml:space="preserve">
          <source>List of coefficients for the Logistic Regression model. If fit_intercept is set to True then the second dimension will be n_features + 1, where the last item represents the intercept. For &lt;code&gt;multiclass='multinomial'&lt;/code&gt;, the shape is (n_classes, n_cs, n_features) or (n_classes, n_cs, n_features + 1).</source>
          <target state="translated">Список коэффициентов модели логистической регрессии. Если для fit_intercept установлено значение True, тогда второе измерение будет n_features + 1, где последний элемент представляет точку пересечения. Для &lt;code&gt;multiclass='multinomial'&lt;/code&gt; форма имеет вид (n_classes, n_cs, n_features) или (n_classes, n_cs, n_features + 1).</target>
        </trans-unit>
        <trans-unit id="d090495d2c127f32b67f3946c4bdcba721a89fcd" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to reorder or select a subset of labels. If &lt;code&gt;None&lt;/code&gt; is given, those that appear at least once in &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; are used in sorted order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="568d5fc554d78a8c3f420990686843b1d52522c9" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to reorder or select a subset of labels. If none is given, those that appear at least once in &lt;code&gt;y_true&lt;/code&gt; or &lt;code&gt;y_pred&lt;/code&gt; are used in sorted order.</source>
          <target state="translated">Список меток для индексации матрицы. Это можно использовать для изменения порядка или выбора подмножества этикеток. Если ничего не указано, те, которые появляются хотя бы один раз в &lt;code&gt;y_true&lt;/code&gt; или &lt;code&gt;y_pred&lt;/code&gt; , используются в отсортированном порядке.</target>
        </trans-unit>
        <trans-unit id="4904457db6e3ad315971a386c35727cdd591b70f" translate="yes" xml:space="preserve">
          <source>List of labels to index the matrix. This may be used to select a subset of labels. If None, all labels that appear at least once in &lt;code&gt;y1&lt;/code&gt; or &lt;code&gt;y2&lt;/code&gt; are used.</source>
          <target state="translated">Список меток для индексации матрицы. Это может быть использовано для выбора подмножества меток. Если нет, используются все метки, которые появляются хотя бы один раз в &lt;code&gt;y1&lt;/code&gt; или &lt;code&gt;y2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b841f355bd90388eac15a6584a26192e6c900c97" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single data point.</source>
          <target state="translated">Список n_features-мерных точек данных.Каждая строка соответствует одной точке данных.</target>
        </trans-unit>
        <trans-unit id="af1051d092002bc2f98d27cb1ada3b5cc2dacea1" translate="yes" xml:space="preserve">
          <source>List of n_features-dimensional data points. Each row corresponds to a single query.</source>
          <target state="translated">Список n_features-мерных точек данных.Каждая строка соответствует одному запросу.</target>
        </trans-unit>
        <trans-unit id="85e7a2833a6b5505d28e95f0c1116dee51aa01e1" translate="yes" xml:space="preserve">
          <source>List of objects to ensure sliceability.</source>
          <target state="translated">Список объектов для обеспечения разрезаемости.</target>
        </trans-unit>
        <trans-unit id="5538dc428bf1dd702d4666daf2c6801367c4f065" translate="yes" xml:space="preserve">
          <source>List of sample weights attached to the data X.</source>
          <target state="translated">Список весов образцов,приложенных к данным X.</target>
        </trans-unit>
        <trans-unit id="af4d88e1f955adfe14752a1cab15db410dc25046" translate="yes" xml:space="preserve">
          <source>List of samples.</source>
          <target state="translated">Список образцов.</target>
        </trans-unit>
        <trans-unit id="9fa149a90ccae2cfe066dfb859bf8a7c95ef01ca" translate="yes" xml:space="preserve">
          <source>List of transformer objects to be applied to the data. The first half of each tuple is the name of the transformer.</source>
          <target state="translated">Список объектов трансформатора,которые необходимо применить к данным.Первая половина каждого кортежа-это название трансформатора.</target>
        </trans-unit>
        <trans-unit id="f2f499a9d9cf5fba3b5aa16bff4e7ad9f538a51f" translate="yes" xml:space="preserve">
          <source>List of values for the regularization parameter or integer specifying the number of regularization parameters that should be used. In this case, the parameters will be chosen in a logarithmic scale between 1e-4 and 1e4.</source>
          <target state="translated">Список значений для параметра регуляризации или целое число,указывающее количество используемых параметров регуляризации.В этом случае параметры будут выбираться в логарифмической шкале от 1e-4 до 1e4.</target>
        </trans-unit>
        <trans-unit id="d742bd356ab53d1131907c9ca41e9f89956bc677" translate="yes" xml:space="preserve">
          <source>List of weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="translated">Список типов весов для расчета баллов. Нет означает отсутствие взвешивания; &amp;laquo;Линейный&amp;raquo; означает линейно взвешенный; &amp;laquo;Квадратичный&amp;raquo; означает квадратично взвешенный.</target>
        </trans-unit>
        <trans-unit id="ccaadae3fd2b8d525242b8298319bebc15b1d7f7" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation forest.&amp;rdquo; Data Mining, 2008. ICDM&amp;lsquo;08. Eighth IEEE International Conference on.</source>
          <target state="translated">Лю, Фэй Тони, Тин, Кай Мин и Чжоу, Чжи-Хуа. &amp;laquo;Изолированный лес&amp;raquo;. Data Mining, 2008. ICDM'08. Восьмая международная конференция IEEE по.</target>
        </trans-unit>
        <trans-unit id="ef6455b6e1e2fee9a705bb5d5a6878e2089d032f" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation forest.&amp;rdquo; Data Mining, 2008. ICDM&amp;rsquo;08. Eighth IEEE International Conference on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d858831be3c025b5261ad0994fdd43e36106d2f" translate="yes" xml:space="preserve">
          <source>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. &amp;ldquo;Isolation-based anomaly detection.&amp;rdquo; ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): 3.</source>
          <target state="translated">Лю, Фэй Тони, Тин, Кай Мин и Чжоу, Чжи-Хуа. &amp;laquo;Обнаружение аномалий на основе изоляции&amp;raquo;. Транзакции ACM при обнаружении знаний из данных (TKDD) 6.1 (2012 г.): 3.</target>
        </trans-unit>
        <trans-unit id="d7cbf66ae3940637cf4feeef412f2113fd5144b3" translate="yes" xml:space="preserve">
          <source>Load Data and Train a SVC</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5a977facf077b843c15be4adf2b27656870bbc8b" translate="yes" xml:space="preserve">
          <source>Load Data and train model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc1c89a3655919cbe107b23bf70fdaef2d59b7e4" translate="yes" xml:space="preserve">
          <source>Load a datasets as downloaded from &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</source>
          <target state="translated">Загрузите наборы данных, загруженные с &lt;a href=&quot;http://mlcomp.org&quot;&gt;http://mlcomp.org&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="10fbb828ccf5ef978744b601a27eefff85b82acd" translate="yes" xml:space="preserve">
          <source>Load and return the boston house-prices dataset (regression).</source>
          <target state="translated">Загрузите и верните Бостону набор данных о ценах на жилье (регрессия).</target>
        </trans-unit>
        <trans-unit id="f0b03288037dddab02ba1bf0d814f5cc8cf63088" translate="yes" xml:space="preserve">
          <source>Load and return the breast cancer wisconsin dataset (classification).</source>
          <target state="translated">Загрузите и верните набор данных по раку молочной железы (классификация).</target>
        </trans-unit>
        <trans-unit id="fb9c782009d54032f572c4b8eb05f6ff3c69b6ee" translate="yes" xml:space="preserve">
          <source>Load and return the diabetes dataset (regression).</source>
          <target state="translated">Загрузить и вернуть набор данных по диабету (регрессия).</target>
        </trans-unit>
        <trans-unit id="5ee0c3f160bd1db558fab50ff07fd2d60e875939" translate="yes" xml:space="preserve">
          <source>Load and return the digits dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор цифр (классификация).</target>
        </trans-unit>
        <trans-unit id="91627f9a236f04bf8e67f696e6012e55dde096ca" translate="yes" xml:space="preserve">
          <source>Load and return the iris dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор данных по радужной оболочке глаза (классификация).</target>
        </trans-unit>
        <trans-unit id="08308ecd69078eb0533ddcbcb38611925dd58ae7" translate="yes" xml:space="preserve">
          <source>Load and return the linnerud dataset (multivariate regression).</source>
          <target state="translated">Загрузить и вернуть набор данных linnerud (многомерная регрессия).</target>
        </trans-unit>
        <trans-unit id="24c66578782cdc888ab71f9a25a06214508e7234" translate="yes" xml:space="preserve">
          <source>Load and return the physical excercise linnerud dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a61d81b3e38cd33952ad8e4ab4da4e0afb0ac23" translate="yes" xml:space="preserve">
          <source>Load and return the wine dataset (classification).</source>
          <target state="translated">Загрузить и вернуть набор данных о вине (классификация).</target>
        </trans-unit>
        <trans-unit id="34956b05e013a2f3d8d5817783733a9d69ea9a29" translate="yes" xml:space="preserve">
          <source>Load data from the training set</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="907ca9fec180a2f563a6eb0b2c208dd89483dfe5" translate="yes" xml:space="preserve">
          <source>Load dataset from multiple files in SVMlight format</source>
          <target state="translated">Загрузка набора данных из нескольких файлов в формате SVMlight</target>
        </trans-unit>
        <trans-unit id="e0287d019fcfe4320ef71958ec3623d393a07d68" translate="yes" xml:space="preserve">
          <source>Load datasets in the svmlight / libsvm format into sparse CSR matrix</source>
          <target state="translated">Загрузить наборы данных в формате svmlight/libsvm в разреженную CSR матрицу</target>
        </trans-unit>
        <trans-unit id="15df99bbc404778e529956fb3833b1f8b300577d" translate="yes" xml:space="preserve">
          <source>Load sample images for image manipulation.</source>
          <target state="translated">Загружайте образцы изображений для работы с ними.</target>
        </trans-unit>
        <trans-unit id="93b606a5680687306536f14272c219f02caf9a74" translate="yes" xml:space="preserve">
          <source>Load text files with categories as subfolder names.</source>
          <target state="translated">Загружайте текстовые файлы с категориями в качестве имен вложенных папок.</target>
        </trans-unit>
        <trans-unit id="ada1ba97e9c53b7b56715b1a2824f0ae676a78c6" translate="yes" xml:space="preserve">
          <source>Load the 20 newsgroups dataset and vectorize it into token counts (classification).</source>
          <target state="translated">Загрузите набор данных 20 новостных групп и векторизуйте его в подсчет маркеров (классификация).</target>
        </trans-unit>
        <trans-unit id="4f7a062fa00aaafd76d451b474abbba6455b18d1" translate="yes" xml:space="preserve">
          <source>Load the California housing dataset (regression).</source>
          <target state="translated">Загрузите калифорнийский набор данных по жилью (регрессия).</target>
        </trans-unit>
        <trans-unit id="d369acbb02d6ae84bdcebcaf52c16540c4d5f177" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).</source>
          <target state="translated">Загрузить набор данных (классификация)маркированных лиц в парах диких (LFW).</target>
        </trans-unit>
        <trans-unit id="fdf290fe8f8a97ef39a92df3e1f665ba9f5137b7" translate="yes" xml:space="preserve">
          <source>Load the Labeled Faces in the Wild (LFW) people dataset (classification).</source>
          <target state="translated">Загрузить набор данных (классификация)людей с метками в дикой природе (LFW).</target>
        </trans-unit>
        <trans-unit id="c1d9dfefbd2137b268a0489f71dee7b704510f30" translate="yes" xml:space="preserve">
          <source>Load the Olivetti faces data-set from AT&amp;amp;T (classification).</source>
          <target state="translated">Загрузите набор данных лиц Olivetti от AT&amp;amp;T (классификация).</target>
        </trans-unit>
        <trans-unit id="2772bcfa51d7f467cdc1ff56dd2a38098daf99c8" translate="yes" xml:space="preserve">
          <source>Load the RCV1 multilabel dataset (classification).</source>
          <target state="translated">Загрузить многомаркировочный набор данных RCV1 (классификация).</target>
        </trans-unit>
        <trans-unit id="b34ac8eb475e3d0c92e532ea1f16cafea2826dba" translate="yes" xml:space="preserve">
          <source>Load the covertype dataset (classification).</source>
          <target state="translated">Загрузите набор данных covertype (классификация).</target>
        </trans-unit>
        <trans-unit id="ad3fd711e27424bfdcf7677e93b2ded911f0bbc0" translate="yes" xml:space="preserve">
          <source>Load the data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="54322fa6d75ea033036ee5315e01f5a9e265e0ca" translate="yes" xml:space="preserve">
          <source>Load the filenames and data from the 20 newsgroups dataset (classification).</source>
          <target state="translated">Загрузить имена файлов и данные из набора данных 20 групп новостей (классификация).</target>
        </trans-unit>
        <trans-unit id="ae3c786b5593f01e176137f6a4960d769f8b9d22" translate="yes" xml:space="preserve">
          <source>Load the kddcup99 dataset (classification).</source>
          <target state="translated">Загрузите набор данных kddcup99 (классификация).</target>
        </trans-unit>
        <trans-unit id="820329ef76c355bc57213e87e726caebf3ec8e17" translate="yes" xml:space="preserve">
          <source>Load the numpy array of a single sample image</source>
          <target state="translated">Загрузите числовой массив одного образца изображения.</target>
        </trans-unit>
        <trans-unit id="6565057c8bbe701655d34466bc255155c3ea2c6e" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et.</source>
          <target state="translated">Загрузчик для набора данных о распределении видов от Филлипса и др.</target>
        </trans-unit>
        <trans-unit id="00912c83de18e685a34ddbd42e1354c697eb14e0" translate="yes" xml:space="preserve">
          <source>Loader for species distribution dataset from Phillips et. al. (2006)</source>
          <target state="translated">Загрузчик для набора данных о распределении видов от Филлипса и др.(2006)</target>
        </trans-unit>
        <trans-unit id="4f514b04ed6b877534da140af8e12cab5016f713" translate="yes" xml:space="preserve">
          <source>Loaders</source>
          <target state="translated">Loaders</target>
        </trans-unit>
        <trans-unit id="1d603b233f1badee343cd4d051b0c74346bf8ab5" translate="yes" xml:space="preserve">
          <source>Loading an example dataset</source>
          <target state="translated">Загрузка набора данных примера</target>
        </trans-unit>
        <trans-unit id="caf6cb93de1911a37a3c4f9c173bcddd3283525a" translate="yes" xml:space="preserve">
          <source>Loading datasets, basic feature extraction and target definitions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afb9453c6f5c0750a61be0390918061037ab3605" translate="yes" xml:space="preserve">
          <source>Loading from external datasets</source>
          <target state="translated">Загрузка из внешних наборов данных</target>
        </trans-unit>
        <trans-unit id="b4240e57d982043f1f905f33f107714b1056ff0f" translate="yes" xml:space="preserve">
          <source>Loading the 20 newsgroups dataset</source>
          <target state="translated">Загрузка набора данных 20 новостных групп</target>
        </trans-unit>
        <trans-unit id="bf453b7e00694519c6d048cddce89c9acdc80f61" translate="yes" xml:space="preserve">
          <source>Loads both, &lt;code&gt;china&lt;/code&gt; and &lt;code&gt;flower&lt;/code&gt;.</source>
          <target state="translated">Грузы и &lt;code&gt;china&lt;/code&gt; и &lt;code&gt;flower&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5a8b86a7fef7215f7de926bc65cb224b10c3ccba" translate="yes" xml:space="preserve">
          <source>Locally Linear Embedding</source>
          <target state="translated">Локальное линейное ограждение</target>
        </trans-unit>
        <trans-unit id="f71746cee5cf3673e7e527aaea93ab0ac960ab66" translate="yes" xml:space="preserve">
          <source>Locally linear embedding (LLE) seeks a lower-dimensional projection of the data which preserves distances within local neighborhoods. It can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding.</source>
          <target state="translated">Локально-линейное встраивание (LLE)ищет нижнемерную проекцию данных,которая сохраняет расстояния в пределах локальных окрестностей.Его можно рассматривать как серию локальных анализов основных компонентов,которые глобально сравниваются для поиска наилучшего нелинейного встраивания.</target>
        </trans-unit>
        <trans-unit id="ba721026e6725be51f569c81e87377b42c664dd5" translate="yes" xml:space="preserve">
          <source>Locally linear embedding can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Локально линейное встраивание может быть выполнено с помощью функции &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="120996393a2755aae459a0342f6a159574a0420b" translate="yes" xml:space="preserve">
          <source>Log likelihood of the Gaussian mixture given X.</source>
          <target state="translated">Вероятность бревна гауссовской смеси с учетом X.</target>
        </trans-unit>
        <trans-unit id="10dac5cbd2ef695e498b42bff8cc166d8d6c8a26" translate="yes" xml:space="preserve">
          <source>Log loss is undefined for p=0 or p=1, so probabilities are clipped to max(eps, min(1 - eps, p)).</source>
          <target state="translated">Потеря лога не определена для p=0 или p=1,поэтому вероятности обрезаются до max(eps,min(1-eps,p)).</target>
        </trans-unit>
        <trans-unit id="8742f15984971d3e598576d7cde59958d4df18a1" translate="yes" xml:space="preserve">
          <source>Log loss, aka logistic loss or cross-entropy loss.</source>
          <target state="translated">Потеря журнала,также известная как логистическая потеря или потеря кросс-энтропии.</target>
        </trans-unit>
        <trans-unit id="3332ed47adb99d618a3191081bd1b56f7df887fc" translate="yes" xml:space="preserve">
          <source>Log loss, also called logistic regression loss or cross-entropy loss, is defined on probability estimates. It is commonly used in (multinomial) logistic regression and neural networks, as well as in some variants of expectation-maximization, and can be used to evaluate the probability outputs (&lt;code&gt;predict_proba&lt;/code&gt;) of a classifier instead of its discrete predictions.</source>
          <target state="translated">Потери журнала, также называемые потерями логистической регрессии или кросс-энтропийными потерями, определяются на основе оценок вероятности. Он обычно используется в (полиномиальной) логистической регрессии и нейронных сетях, а также в некоторых вариантах максимизации ожидания и может использоваться для оценки вероятностных выходов ( &lt;code&gt;predict_proba&lt;/code&gt; ) классификатора вместо его дискретных прогнозов.</target>
        </trans-unit>
        <trans-unit id="f8ceba0d5dd7df5e53e4d9ba0bfe4881369ef7f1" translate="yes" xml:space="preserve">
          <source>Log of probability estimates.</source>
          <target state="translated">Журнал вероятностных оценок.</target>
        </trans-unit>
        <trans-unit id="b2dede1f561914a3bc83cf7a3f85dcff6bab8c76" translate="yes" xml:space="preserve">
          <source>Log probabilities of each data point in X.</source>
          <target state="translated">Вероятности журнала каждой точки данных в X.</target>
        </trans-unit>
        <trans-unit id="ce21bba36fd356086ab08edfbf5461d606fc0046" translate="yes" xml:space="preserve">
          <source>Log probability of each class (smoothed).</source>
          <target state="translated">Вероятность записи в журнал каждого класса (сглаженная).</target>
        </trans-unit>
        <trans-unit id="10521a3daec9ae1f69d9eb092c8ffd785e7a6414" translate="yes" xml:space="preserve">
          <source>Log-likelihood of each sample under the current model</source>
          <target state="translated">Вероятность записи в журнал каждой выборки в рамках текущей модели</target>
        </trans-unit>
        <trans-unit id="f4a66282780599e98e06ef51f0d5990ef29ec975" translate="yes" xml:space="preserve">
          <source>Log-likelihood of each sample under the current model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c1e8dc95e554810186fcd38490e4f1fe6e53c32" translate="yes" xml:space="preserve">
          <source>Log-likelihood score on left-out data across folds.</source>
          <target state="translated">Вероятность записи в журнал по пропущенным данным по сгибам.</target>
        </trans-unit>
        <trans-unit id="af6fc4d4c535e2fcc7787b2d2b354e641a5cdf07" translate="yes" xml:space="preserve">
          <source>Log-marginal likelihood of theta for training data.</source>
          <target state="translated">Журнал-маржинальная вероятность тэты для тренировочных данных.</target>
        </trans-unit>
        <trans-unit id="a79f6e0f430c7ecad68ae2bba39688851de03cfd" translate="yes" xml:space="preserve">
          <source>Log: Logistic Regression.</source>
          <target state="translated">Бревно:Логистическая регрессия.</target>
        </trans-unit>
        <trans-unit id="710d6654ab013b68e75b864460870bdb608ee833" translate="yes" xml:space="preserve">
          <source>Log: equivalent to Logistic Regression. \(L(y_i, f(x_i)) = \log(1 + \exp (-y_i f(x_i)))\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="667a374e42016ea0491009bae949bbc3eb5a98fe" translate="yes" xml:space="preserve">
          <source>Logistic Regression (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Классификатор логистической регрессии (также известный как logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="7553fecbacc2ab6c754b732dd2a40625b016efa3" translate="yes" xml:space="preserve">
          <source>Logistic Regression 3-class Classifier</source>
          <target state="translated">Классификатор логистической регрессии 3 класса</target>
        </trans-unit>
        <trans-unit id="67b9d1bed8ce4778bb74ee8f32cf37a9f88e56b4" translate="yes" xml:space="preserve">
          <source>Logistic Regression CV (aka logit, MaxEnt) classifier.</source>
          <target state="translated">Классификатор логистической регрессии CV (он же logit,MaxEnt).</target>
        </trans-unit>
        <trans-unit id="4c4251ffdad99c44ab6ab03dc44e767ed73a387b" translate="yes" xml:space="preserve">
          <source>Logistic function</source>
          <target state="translated">Логистическая функция</target>
        </trans-unit>
        <trans-unit id="90723c3f54f2127002d5e8087f3fd75704debc54" translate="yes" xml:space="preserve">
          <source>Logistic regression is implemented in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;. This implementation can fit binary, One-vs-Rest, or multinomial logistic regression with optional \(\ell_1\), \(\ell_2\) or Elastic-Net regularization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c0f1438d10823ae208574adad9979316ecf1f7d" translate="yes" xml:space="preserve">
          <source>Logistic regression on raw pixel values is presented for comparison. The example shows that the features extracted by the BernoulliRBM help improve the classification accuracy.</source>
          <target state="translated">Для сравнения представлена логистическая регрессия по значениям необработанных пикселей.Пример показывает,что особенности,извлеченные из BernoulliRBM,помогают повысить точность классификации.</target>
        </trans-unit>
        <trans-unit id="f05fe21aed88fc82a5a0513559ae877673e205fc" translate="yes" xml:space="preserve">
          <source>Logistic regression with built-in cross validation</source>
          <target state="translated">Логистическая регрессия со встроенной перекрестной проверкой</target>
        </trans-unit>
        <trans-unit id="96304f46c8b5deeee00fad5a320967f13f13e69f" translate="yes" xml:space="preserve">
          <source>Logistic regression with built-in cross validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3b2957f5500f497ec4678d49dfe4396dcf43781" translate="yes" xml:space="preserve">
          <source>Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;logistic function&lt;/a&gt;.</source>
          <target state="translated">Логистическая регрессия, несмотря на свое название, представляет собой скорее линейную модель классификации, чем регрессию. Логистическая регрессия также известна в литературе как логит-регрессия, классификация максимальной энтропии (MaxEnt) или лог-линейный классификатор. В этой модели вероятности, описывающие возможные результаты одного испытания, моделируются с использованием &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_function&quot;&gt;логистической функции&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8e225015f4826ba9beac040479565ae8cd20d1cd" translate="yes" xml:space="preserve">
          <source>Logistic regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cb16d85d5ce6d29fbfeaf0784f0b2e2c61ca591" translate="yes" xml:space="preserve">
          <source>LogisticRegression</source>
          <target state="translated">LogisticRegression</target>
        </trans-unit>
        <trans-unit id="de456a9443564fc60f026f7b3757765c6c521491" translate="yes" xml:space="preserve">
          <source>LogisticRegression returns well calibrated predictions as it directly optimizes log-loss. In contrast, the other methods return biased probabilities, with different biases per method:</source>
          <target state="translated">LogisticRegression возвращает хорошо откалиброванные прогнозы,так как она непосредственно оптимизирует потери каротажа.Другие методы,напротив,возвращают смещенные вероятности,с разными смещениями для каждого метода:</target>
        </trans-unit>
        <trans-unit id="25965de326ab0450ae299a566621b897c09262e7" translate="yes" xml:space="preserve">
          <source>Long-awaited Generalized Linear Models with non-normal loss functions are now available. In particular, three new regressors were implemented: &lt;a href=&quot;../../modules/generated/sklearn.linear_model.poissonregressor#sklearn.linear_model.PoissonRegressor&quot;&gt;&lt;code&gt;PoissonRegressor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.linear_model.gammaregressor#sklearn.linear_model.GammaRegressor&quot;&gt;&lt;code&gt;GammaRegressor&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor&quot;&gt;&lt;code&gt;TweedieRegressor&lt;/code&gt;&lt;/a&gt;. The Poisson regressor can be used to model positive integer counts, or relative frequencies. Read more in the &lt;a href=&quot;../../modules/linear_model#generalized-linear-regression&quot;&gt;User Guide&lt;/a&gt;. Additionally, &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; supports a new &amp;lsquo;poisson&amp;rsquo; loss as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83ec89bbbb1925d31612bf071115de8d555d9924" translate="yes" xml:space="preserve">
          <source>Longitude house block longitude</source>
          <target state="translated">Долгота блока домов долготы</target>
        </trans-unit>
        <trans-unit id="900f1aa8e30fd6bc29b8e8d4cae98f421ef462cd" translate="yes" xml:space="preserve">
          <source>Looking at the coefficient plot to gauge feature importance can be misleading as some of them vary on a small scale, while others, like AGE, varies a lot more, several decades.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65fb0d7c39bbac75b47a97a31a7e2974bcfa2753" translate="yes" xml:space="preserve">
          <source>Looking closely at the WAGE distribution reveals that it has a long tail. For this reason, we should take its logarithm to turn it approximately into a normal distribution (linear models such as ridge or lasso work best for a normal distribution of error).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9aa6c9b011905252d25083008c9809acc3f4160" translate="yes" xml:space="preserve">
          <source>Loss function used by the algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2ebf0012d7d593bf1ef0d0a316102397c08a9f0" translate="yes" xml:space="preserve">
          <source>Low-level methods</source>
          <target state="translated">Низкоуровневые методы</target>
        </trans-unit>
        <trans-unit id="43b8e239b3dbfa96de18c459c0e716f889fbf1ff" translate="yes" xml:space="preserve">
          <source>Lower bound on the lowest predicted value (the minimum value may still be higher). If not set, defaults to -inf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea609f61be1ccbae7413cc55d9401ee01dff16e3" translate="yes" xml:space="preserve">
          <source>Lower bound value on the likelihood (of the training data with respect to the model) of the best fit of inference.</source>
          <target state="translated">Нижняя граница значения вероятности (данных об обучении по отношению к модели)наилучшего подведения итогов.</target>
        </trans-unit>
        <trans-unit id="af301438554e0ee8815f3548a50754545e52e051" translate="yes" xml:space="preserve">
          <source>Lower bound value on the log-likelihood (of the training data with respect to the model) of the best fit of EM.</source>
          <target state="translated">Нижняя граница значения вероятности (данных обучения по отношению к модели)наилучшего соответствия ЭМ.</target>
        </trans-unit>
        <trans-unit id="4ada54abc98e483baeab7ae15def52027a7aae96" translate="yes" xml:space="preserve">
          <source>Lower-triangular Cholesky decomposition of the kernel in &lt;code&gt;X_train_&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;X_train_&lt;/code&gt; разложение ядра Холецкого в X_train_</target>
        </trans-unit>
        <trans-unit id="b93b2eafc7fea724b9bcb08bb1fb9109b8d1d561" translate="yes" xml:space="preserve">
          <source>M. Bawa, T. Condie and P. Ganesan, &amp;ldquo;LSH Forest: Self-Tuning Indexes for Similarity Search&amp;rdquo;, WWW &amp;lsquo;05 Proceedings of the 14th international conference on World Wide Web, 651-660, 2005.</source>
          <target state="translated">М. Бава, Т. Конди и П. Ганесан, &amp;laquo;Лес LSH: самонастраивающиеся индексы для поиска сходства&amp;raquo;, WWW '05 Труды 14-й международной конференции по World Wide Web, 651-660, 2005.</target>
        </trans-unit>
        <trans-unit id="e8445854a0cf4ad63f8ee64cb2fc2359051f4c85" translate="yes" xml:space="preserve">
          <source>M. Dumont et al, &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Fast multi-class image annotation with random subwindows and multiple output randomized trees&lt;/a&gt;, International Conference on Computer Vision Theory and Applications 2009</source>
          <target state="translated">М. Дюмон и др., &lt;a href=&quot;http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2009/DMWG09/dumont-visapp09-shortpaper.pdf&quot;&gt;Быстрая мультиклассовая аннотация изображений со случайными подокнами и множественными выходными рандомизированными деревьями&lt;/a&gt; , Международная конференция по теории и приложениям компьютерного зрения, 2009 г.</target>
        </trans-unit>
        <trans-unit id="4f0f168494bf38e0f99da8c5a97b71596101a871" translate="yes" xml:space="preserve">
          <source>M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine, Journal of Machine Learning Research, Vol. 1, 2001.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2422710e8cdc4f555670a3606a875134eadd99fe" translate="yes" xml:space="preserve">
          <source>M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;The Pascal Visual Object Classes (VOC) Challenge&lt;/a&gt;, IJCV 2010.</source>
          <target state="translated">М. Эверингем, Л. Ван Гул, CKI Уильямс, Дж. Винн, А. Зиссерман, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Задача классов визуальных объектов Pascal (VOC)&lt;/a&gt; , IJCV 2010.</target>
        </trans-unit>
        <trans-unit id="aa09c5b3704d1cab7c2f9d80f35ab989ea05cba1" translate="yes" xml:space="preserve">
          <source>MAE output is non-negative floating point. The best value is 0.0.</source>
          <target state="translated">Выход MAE-неотрицательная плавающая запятая.Лучшее значение-0.0.</target>
        </trans-unit>
        <trans-unit id="dcac13e5386ab7554d99f42d2774ea6dec7dc033" translate="yes" xml:space="preserve">
          <source>MARR</source>
          <target state="translated">MARR</target>
        </trans-unit>
        <trans-unit id="203b5e4f3efe3b38e1b9f876ab3923dffadb1fa1" translate="yes" xml:space="preserve">
          <source>MARR_Unmarried</source>
          <target state="translated">MARR_Unmarried</target>
        </trans-unit>
        <trans-unit id="f4d1d18b18dbadb43dc94aafefb0919124514bb4" translate="yes" xml:space="preserve">
          <source>MEDV Median value of owner-occupied homes in $1000&amp;rsquo;s</source>
          <target state="translated">MEDV Средняя стоимость частных домов в 1000 долларов</target>
        </trans-unit>
        <trans-unit id="33379c640ef1bcb7b4dbc3ceb61d0f9854342e44" translate="yes" xml:space="preserve">
          <source>MKL</source>
          <target state="translated">MKL</target>
        </trans-unit>
        <trans-unit id="a8e1fd8b99167af6d3e02ac86d0a101dabaf0e42" translate="yes" xml:space="preserve">
          <source>MLP can fit a non-linear model to the training data. &lt;code&gt;clf.coefs_&lt;/code&gt; contains the weight matrices that constitute the model parameters:</source>
          <target state="translated">MLP может подогнать нелинейную модель к обучающим данным. &lt;code&gt;clf.coefs_&lt;/code&gt; содержит весовые матрицы, составляющие параметры модели:</target>
        </trans-unit>
        <trans-unit id="7fc5f2a7a15f6ccd1641b37c2fb96c6ce75018c2" translate="yes" xml:space="preserve">
          <source>MLP is sensitive to feature scaling.</source>
          <target state="translated">MLP чувствителен к масштабированию функций.</target>
        </trans-unit>
        <trans-unit id="08431dee59de79a71b4718dbf6ee28e75fee38c3" translate="yes" xml:space="preserve">
          <source>MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.</source>
          <target state="translated">MLP требует настройки ряда гиперпараметров,таких как количество скрытых нейронов,слоев и итераций.</target>
        </trans-unit>
        <trans-unit id="e82dbcf8b443c94c79e54d7d53faa6f5db46762a" translate="yes" xml:space="preserve">
          <source>MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples:</source>
          <target state="translated">MLP тренируется на двух массивах:массиве X размера (n_samples,n_features),в котором обучающие выборки представлены в виде векторов признаков с плавающей точкой;и массиве y размера (n_samples,),в котором хранятся целевые значения (метки классов)для обучающих выборок:</target>
        </trans-unit>
        <trans-unit id="f0c27305c85163e665d40daa0f2ca2e458a2e63e" translate="yes" xml:space="preserve">
          <source>MLP trains using &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt;, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt;. Stochastic Gradient Descent (SGD) updates parameters using the gradient of the loss function with respect to a parameter that needs adaptation, i.e.</source>
          <target state="translated">MLP тренирует с использованием &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;стохастического градиентного спуска&lt;/a&gt; , &lt;a href=&quot;http://arxiv.org/abs/1412.6980&quot;&gt;Адама&lt;/a&gt; или &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt; . Стохастический градиентный спуск (SGD) обновляет параметры, используя градиент функции потерь по отношению к параметру, который требует адаптации, т. Е.</target>
        </trans-unit>
        <trans-unit id="4fc94508d8948819a05a769d08877751f90a9958" translate="yes" xml:space="preserve">
          <source>MLP trains using &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt;, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Limited-memory_BFGS&quot;&gt;L-BFGS&lt;/a&gt;. Stochastic Gradient Descent (SGD) updates parameters using the gradient of the loss function with respect to a parameter that needs adaptation, i.e.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f27922032032bfc1325082b9b33d5f3a9228ddf6" translate="yes" xml:space="preserve">
          <source>MLP trains using Backpropagation. More precisely, it trains using some form of gradient descent and the gradients are calculated using Backpropagation. For classification, it minimizes the Cross-Entropy loss function, giving a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">Поезда MLP с помощью Backpropagation.Точнее,он движется поездам,использующим ту или иную форму спуска с уклоном,а уклоны рассчитываются с помощью Backpropagation.Для классификации она минимизирует функцию Cross-Entropy loss,давая вектор вероятностных оценок \(P(y|x)\)на выборку \(x\):</target>
        </trans-unit>
        <trans-unit id="c8c1d3b7c59691465cb0496f22bcb3604bca5a60" translate="yes" xml:space="preserve">
          <source>MLP uses different loss functions depending on the problem type. The loss function for classification is Cross-Entropy, which in binary case is given as,</source>
          <target state="translated">MLP использует различные функции потерь в зависимости от типа проблемы.Функция потерь для классификации является Cross-Entropy,которая в двоичном случае дается как,</target>
        </trans-unit>
        <trans-unit id="d03f0b750d6ad970862b8ceab4b82a667eb1bc44" translate="yes" xml:space="preserve">
          <source>MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.</source>
          <target state="translated">MLP со скрытыми слоями имеют функцию несверхностных потерь,где существует более одного локального минимума.Поэтому различные случайные весовые инициализации могут привести к различной точности проверки.</target>
        </trans-unit>
        <trans-unit id="14160d0f2e53b28f2f5c2a7702cb0510220c29b8" translate="yes" xml:space="preserve">
          <source>MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">MLPClassifier тренируется итеративно,так как на каждом шаге вычисляются частичные производные функции потерь относительно параметров модели для обновления параметров.</target>
        </trans-unit>
        <trans-unit id="a1925f1c916c80accddbe48b0d0e8da75d102083" translate="yes" xml:space="preserve">
          <source>MLPRegressor</source>
          <target state="translated">MLPRegressor</target>
        </trans-unit>
        <trans-unit id="8b27d0c0c6a8a44ae6f32f660e2bfb892d109024" translate="yes" xml:space="preserve">
          <source>MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.</source>
          <target state="translated">MLPRegressor тренируется итеративно,так как на каждом шаге вычисляются частичные производные функции потерь относительно параметров модели для обновления параметров.</target>
        </trans-unit>
        <trans-unit id="8e70290c1fc16432a8f4b616e4fd6fbaa4abfbea" translate="yes" xml:space="preserve">
          <source>MNIST classfification using multinomial logistic + L1</source>
          <target state="translated">Классификация MNIST с использованием мультиномиальной логистики+L1</target>
        </trans-unit>
        <trans-unit id="fbb70ceca40f03de1a52a87cdebacfd0c2426668" translate="yes" xml:space="preserve">
          <source>MNIST classification using multinomial logistic + L1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25845da185fe3a02cb60c18fcf84202e8f31d1e7" translate="yes" xml:space="preserve">
          <source>Machine learning algorithms need data. Go to each &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; sub-folder and run the &lt;code&gt;fetch_data.py&lt;/code&gt; script from there (after having read them first).</source>
          <target state="translated">Алгоритмам машинного обучения нужны данные. Перейдите в каждую подпапку &lt;code&gt;$TUTORIAL_HOME/data&lt;/code&gt; и запустите &lt;code&gt;fetch_data.py&lt;/code&gt; скрипт fetch_data.py (предварительно прочитав их).</target>
        </trans-unit>
        <trans-unit id="45f2bd27f62f0226a5b3177e6a59d79cc23fea68" translate="yes" xml:space="preserve">
          <source>Machine learning is about learning some properties of a data set and then testing those properties against another data set. A common practice in machine learning is to evaluate an algorithm by splitting a data set into two. We call one of those sets the &lt;strong&gt;training set&lt;/strong&gt;, on which we learn some properties; we call the other set the &lt;strong&gt;testing set&lt;/strong&gt;, on which we test the learned properties.</source>
          <target state="translated">Машинное обучение - это изучение некоторых свойств набора данных и последующее тестирование этих свойств на другом наборе данных. Обычной практикой в ​​машинном обучении является оценка алгоритма путем разделения набора данных на два. Мы называем один из этих наборов &lt;strong&gt;обучающим набором&lt;/strong&gt; , на котором мы изучаем некоторые свойства; мы называем другой набор набором для &lt;strong&gt;тестирования&lt;/strong&gt; , на котором мы проверяем изученные свойства.</target>
        </trans-unit>
        <trans-unit id="17dc705c260bdc393406dc006335656d8788b655" translate="yes" xml:space="preserve">
          <source>Machine learning: the problem setting</source>
          <target state="translated">Машинное обучение:постановка задачи</target>
        </trans-unit>
        <trans-unit id="e6a69273199992ddfe41f469dda4cc1f6b79ceb0" translate="yes" xml:space="preserve">
          <source>Magnesium</source>
          <target state="translated">Magnesium</target>
        </trans-unit>
        <trans-unit id="2bb08573261ae718ebb52db49951821b64f9a80c" translate="yes" xml:space="preserve">
          <source>Magnesium:</source>
          <target state="translated">Magnesium:</target>
        </trans-unit>
        <trans-unit id="ca3ae45b6eafdd0a6dfea23df60842bdb389e9fc" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances of the training set (on which &lt;a href=&quot;#sklearn.covariance.EllipticEnvelope.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is called) observations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55e9152468183c8a16be469ac6ea3dbb0e42dd62" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances of the training set (on which &lt;a href=&quot;#sklearn.covariance.MinCovDet.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is called) observations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91059cae8d3b76142d7879b78c0a2ccaab268e7d" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances of the training set (on which &lt;code&gt;fit&lt;/code&gt; is called) observations.</source>
          <target state="translated">Дистанции Махаланобиса обучающей выборки (на которой называется &lt;code&gt;fit&lt;/code&gt; ) наблюдений.</target>
        </trans-unit>
        <trans-unit id="d469f730cc4a1b58c5ef61209e446f59013c3c80" translate="yes" xml:space="preserve">
          <source>Mahalanobis distances to centers</source>
          <target state="translated">Махаланобис расстояния до центров</target>
        </trans-unit>
        <trans-unit id="6f98cc22ed52c0a1e40fae778fadcd35627c25b5" translate="yes" xml:space="preserve">
          <source>MahalanobisDistance</source>
          <target state="translated">MahalanobisDistance</target>
        </trans-unit>
        <trans-unit id="62bce9422ff2d14f69ab80a154510232fc8a9afd" translate="yes" xml:space="preserve">
          <source>Main</source>
          <target state="translated">Main</target>
        </trans-unit>
        <trans-unit id="7a412cc8631eaef465ac98b25829da66ced3b43d" translate="yes" xml:space="preserve">
          <source>Main takeaways</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d6381188443dad8aa5d016fb4ec69dd96237200" translate="yes" xml:space="preserve">
          <source>Make a copy of input data.</source>
          <target state="translated">Сделайте копию входных данных.</target>
        </trans-unit>
        <trans-unit id="f11963f5d19078a49cfab3cc41da5922accd3330" translate="yes" xml:space="preserve">
          <source>Make a large circle containing a smaller circle in 2d.</source>
          <target state="translated">Сделайте большой круг,содержащий меньший круг в 2d.</target>
        </trans-unit>
        <trans-unit id="1cce5fef6c99c293eee32e22f026e768f4b5d892" translate="yes" xml:space="preserve">
          <source>Make a scorer from a performance metric or loss function.</source>
          <target state="translated">Сделайте счетчик из метрики производительности или потери функции.</target>
        </trans-unit>
        <trans-unit id="723bb825ac5b7b14f789cce44f7b667d39fe6543" translate="yes" xml:space="preserve">
          <source>Make and use a deep copy of X and Y (if Y exists)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdd3abd6a5ef3ffb2c4167fd4f1b6dc60d7a55bd" translate="yes" xml:space="preserve">
          <source>Make arrays indexable for cross-validation.</source>
          <target state="translated">Сделайте массивы индексируемыми для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="5f9f781fbc2f44502a26f1a8945369508ac6ebd5" translate="yes" xml:space="preserve">
          <source>Make pipeline to preprocess the data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d28cad808149ac4eb3c924434a0979417f24a68" translate="yes" xml:space="preserve">
          <source>Make sure that X has a minimum number of samples in its first axis (rows for a 2D array).</source>
          <target state="translated">Убедитесь,что X имеет минимальное количество отсчетов по первой оси (строк для 2D массива).</target>
        </trans-unit>
        <trans-unit id="b2b1ee415b35f3ec33d28dbc91a8479edeb8d71e" translate="yes" xml:space="preserve">
          <source>Make sure that array is 2D, square and symmetric.</source>
          <target state="translated">Убедитесь,что массив 2D,квадратный и симметричный.</target>
        </trans-unit>
        <trans-unit id="6885424e5e7bfa46a7e7c7cb1bd5d6e804bbccd9" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when X has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь, что 2D-массив имеет минимальное количество функций (столбцов). Значение по умолчанию 1 отклоняет пустые наборы данных. Эта проверка применяется только тогда, когда X фактически имеет 2 измерения или изначально является 1D и &lt;code&gt;ensure_2d&lt;/code&gt; имеет значение True. Установка на 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="37a276f69711964822e7fcec88111a5f6d2f84a0" translate="yes" xml:space="preserve">
          <source>Make sure that the 2D array has some minimum number of features (columns). The default value of 1 rejects empty datasets. This check is only enforced when the input data has effectively 2 dimensions or is originally 1D and &lt;code&gt;ensure_2d&lt;/code&gt; is True. Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь, что 2D-массив имеет минимальное количество функций (столбцов). Значение по умолчанию 1 отклоняет пустые наборы данных. Эта проверка выполняется только в том случае, если входные данные имеют фактически 2 измерения или изначально являются 1D и &lt;code&gt;ensure_2d&lt;/code&gt; имеет значение True. Установка на 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="c24d8a1e4fcddcfde73957adfbe65fb40c76c786" translate="yes" xml:space="preserve">
          <source>Make sure that the array has a minimum number of samples in its first axis (rows for a 2D array). Setting to 0 disables this check.</source>
          <target state="translated">Убедитесь,что в первой оси массива есть минимальное количество сэмплов (строк для 2D массива).Установка в 0 отключает эту проверку.</target>
        </trans-unit>
        <trans-unit id="fdc3084b2db3fff3561874bdbe81f2954a4b0ffc" translate="yes" xml:space="preserve">
          <source>Make sure the same scale is used over all features. Because manifold learning methods are based on a nearest-neighbor search, the algorithm may perform poorly otherwise. See &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; for convenient ways of scaling heterogeneous data.</source>
          <target state="translated">Убедитесь, что для всех функций используется один и тот же масштаб. Поскольку разнообразные методы обучения основаны на поиске ближайшего соседа, в противном случае алгоритм может работать плохо. См. &lt;a href=&quot;preprocessing#preprocessing-scaler&quot;&gt;StandardScaler&lt;/a&gt; для удобных способов масштабирования разнородных данных.</target>
        </trans-unit>
        <trans-unit id="bd58d70c4390b61fe411e7823adf47cfb5052e9e" translate="yes" xml:space="preserve">
          <source>Make sure you permute (shuffle) your training data before fitting the model or use &lt;code&gt;shuffle=True&lt;/code&gt; to shuffle after each iteration (used by default). Also, ideally, features should be standardized using e.g. &lt;code&gt;make_pipeline(StandardScaler(), SGDClassifier())&lt;/code&gt; (see &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f7e62e13bb8885a4df4d0d5a8e1dba7c3c65c15" translate="yes" xml:space="preserve">
          <source>Make sure you permute (shuffle) your training data before fitting the model or use &lt;code&gt;shuffle=True&lt;/code&gt; to shuffle after each iteration.</source>
          <target state="translated">Убедитесь, что вы переставляете (перемешиваете) свои обучающие данные перед подгонкой модели или используете &lt;code&gt;shuffle=True&lt;/code&gt; для перемешивания после каждой итерации.</target>
        </trans-unit>
        <trans-unit id="f48f3a474378f962985a41275dc98355541c63d2" translate="yes" xml:space="preserve">
          <source>Make two interleaving half circles</source>
          <target state="translated">Сделайте два чередовавшихся полуокружности</target>
        </trans-unit>
        <trans-unit id="69015b0f2ce90a52d27e40a08b160550cfb23a90" translate="yes" xml:space="preserve">
          <source>Making predictions</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a0a9871e0af603535e4f6104cfca3266e203a87" translate="yes" xml:space="preserve">
          <source>Malic Acid:</source>
          <target state="translated">Малиновая кислота:</target>
        </trans-unit>
        <trans-unit id="245748b8f3a70aaac9759204b7d3978b9d337db8" translate="yes" xml:space="preserve">
          <source>Malic acid</source>
          <target state="translated">яблочная кислота</target>
        </trans-unit>
        <trans-unit id="a81a721fb7e702ed0a37d056ec4a9d2f925e70b0" translate="yes" xml:space="preserve">
          <source>ManhattanDistance</source>
          <target state="translated">ManhattanDistance</target>
        </trans-unit>
        <trans-unit id="ccbe2127be70aaa7c3514b3155dd29902fae6143" translate="yes" xml:space="preserve">
          <source>Manifold Learning can be thought of as an attempt to generalize linear frameworks like PCA to be sensitive to non-linear structure in data. Though supervised variants exist, the typical manifold learning problem is unsupervised: it learns the high-dimensional structure of the data from the data itself, without the use of predetermined classifications.</source>
          <target state="translated">Manifold Learning можно рассматривать как попытку обобщить линейные структуры,такие как PCA,чтобы быть чувствительными к нелинейным структурам в данных.Несмотря на то,что существуют контролируемые варианты,типичная проблема многогранного обучения остается без внимания:она узнает высокоразмерную структуру данных из самих данных,без использования заранее определенных классификаций.</target>
        </trans-unit>
        <trans-unit id="7a0e60acb472080022463866637a1ea7c0251335" translate="yes" xml:space="preserve">
          <source>Manifold Learning methods on a severed sphere</source>
          <target state="translated">Манифольдовые методы обучения на разорванной сфере</target>
        </trans-unit>
        <trans-unit id="5f7bca3c10846eb5854c536c3448fedf998ffbcf" translate="yes" xml:space="preserve">
          <source>Manifold learning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aca365adba00c10f7a3cc50cff4a88afd0947dd9" translate="yes" xml:space="preserve">
          <source>Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.</source>
          <target state="translated">Обучение манифестациям-это подход к нелинейному уменьшению размерности.Алгоритмы для этой задачи основаны на идее,что размерность многих наборов данных только искусственно завышена.</target>
        </trans-unit>
        <trans-unit id="1e718f0bccbec4566b4c8536fdd24c184318a8a9" translate="yes" xml:space="preserve">
          <source>Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;</source>
          <target state="translated">Обучение многообразию рукописных цифр: локально линейное встраивание, Isomap&amp;hellip;</target>
        </trans-unit>
        <trans-unit id="ad97dd09eb7e528a0b4debe1b9c745e650b7307a" translate="yes" xml:space="preserve">
          <source>Manually setting one of the environment variables (&lt;code&gt;OMP_NUM_THREADS&lt;/code&gt;, &lt;code&gt;MKL_NUM_THREADS&lt;/code&gt;, &lt;code&gt;OPENBLAS_NUM_THREADS&lt;/code&gt;, or &lt;code&gt;BLIS_NUM_THREADS&lt;/code&gt;) will take precedence over what joblib tries to do. The total number of threads will be &lt;code&gt;n_jobs * &amp;lt;LIB&amp;gt;_NUM_THREADS&lt;/code&gt;. Note that setting this limit will also impact your computations in the main process, which will only use &lt;code&gt;&amp;lt;LIB&amp;gt;_NUM_THREADS&lt;/code&gt;. Joblib exposes a context manager for finer control over the number of threads in its workers (see joblib docs linked below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0471386edfe0bf057e3ed471b66689189fdc892c" translate="yes" xml:space="preserve">
          <source>Manufacturing</source>
          <target state="translated">Manufacturing</target>
        </trans-unit>
        <trans-unit id="0d3695eb907329bab9f0e9752d7ff00d200420c9" translate="yes" xml:space="preserve">
          <source>Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations (it is an &lt;em&gt;inlier&lt;/em&gt;), or should be considered as different (it is an &lt;em&gt;outlier&lt;/em&gt;). Often, this ability is used to clean real data sets. Two important distinctions must be made:</source>
          <target state="translated">Многие приложения требуют наличия возможности решить, принадлежит ли новое наблюдение к тому же распределению, что и существующие наблюдения (это &lt;em&gt;промежуточный результат&lt;/em&gt; ), или его следует рассматривать как другое (это &lt;em&gt;выброс&lt;/em&gt; ). Часто эта возможность используется для очистки реальных наборов данных. Необходимо сделать два важных различия:</target>
        </trans-unit>
        <trans-unit id="626f0980ad5cd6d2b6f18a99ff094a7bf141dc9a" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints</source>
          <target state="translated">Многие кластеры,возможно,ограничения связи</target>
        </trans-unit>
        <trans-unit id="9d1190903d42ddc70f3db2311f157c56b6260b92" translate="yes" xml:space="preserve">
          <source>Many clusters, possibly connectivity constraints, non Euclidean distances</source>
          <target state="translated">Многие кластеры,возможно,ограничения связи,не евклидовые расстояния</target>
        </trans-unit>
        <trans-unit id="ac65e2f8a158fa7cc404d708906171f5ea9f26fd" translate="yes" xml:space="preserve">
          <source>Many clusters, uneven cluster size, non-flat geometry</source>
          <target state="translated">Множество кластеров,неравномерный размер кластера,не плоская геометрия</target>
        </trans-unit>
        <trans-unit id="241eda779a46dbe514b8b7f2a96e98aed4d935af" translate="yes" xml:space="preserve">
          <source>Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. Often it is easiest to preprocess data before applying scikit-learn methods, for example using &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;. Processing your data before passing it to scikit-learn might be problematic for one of the following reasons:</source>
          <target state="translated">Многие наборы данных содержат объекты разных типов, например текст, числа с плавающей запятой и даты, где каждый тип объекта требует отдельных шагов предварительной обработки или извлечения признаков. Часто проще всего предварительно обработать данные перед применением методов scikit-learn, например, с помощью &lt;a href=&quot;http://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; . Обработка ваших данных перед их передачей в scikit-learn может быть проблематичной по одной из следующих причин:</target>
        </trans-unit>
        <trans-unit id="d589144c9193e129ab4721a317a3dc3eaa909106" translate="yes" xml:space="preserve">
          <source>Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. Often it is easiest to preprocess data before applying scikit-learn methods, for example using &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt;. Processing your data before passing it to scikit-learn might be problematic for one of the following reasons:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="192c25a6ed904d1327958fde4c93098505cb86b8" translate="yes" xml:space="preserve">
          <source>Many metrics are not given names to be used as &lt;code&gt;scoring&lt;/code&gt; values, sometimes because they require additional parameters, such as &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;. In such cases, you need to generate an appropriate scoring object. The simplest way to generate a callable object for scoring is by using &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt;. That function converts metrics into callables that can be used for model evaluation.</source>
          <target state="translated">Многие показатели не дают имена , которые будут использоваться в качестве &lt;code&gt;scoring&lt;/code&gt; значений, иногда потому , что они требуют дополнительных параметров, таких как &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt; . В таких случаях вам необходимо создать соответствующий объект оценки. Самый простой способ сгенерировать вызываемый объект для скоринга - использовать &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; . Эта функция преобразует метрики в вызываемые объекты, которые можно использовать для оценки модели.</target>
        </trans-unit>
        <trans-unit id="c6eff6cfb2b81378a219da9247d45ca528d18b55" translate="yes" xml:space="preserve">
          <source>Many scikit-learn estimators rely on nearest neighbors: Several classifiers and regressors such as &lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt;&lt;code&gt;KNeighborsRegressor&lt;/code&gt;&lt;/a&gt;, but also some clustering methods such as &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt;, and some manifold embeddings such as &lt;a href=&quot;generated/sklearn.manifold.tsne#sklearn.manifold.TSNE&quot;&gt;&lt;code&gt;TSNE&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a89fb6cdb80688c2fbf1190407f9abec89dd4f3" translate="yes" xml:space="preserve">
          <source>Many statistical problems require the estimation of a population&amp;rsquo;s covariance matrix, which can be seen as an estimation of data set scatter plot shape. Most of the time, such an estimation has to be done on a sample whose properties (size, structure, homogeneity) have a large influence on the estimation&amp;rsquo;s quality. The &lt;a href=&quot;classes#module-sklearn.covariance&quot;&gt;&lt;code&gt;sklearn.covariance&lt;/code&gt;&lt;/a&gt; package provides tools for accurately estimating a population&amp;rsquo;s covariance matrix under various settings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dacd10610ea3bac36f91971d47d3019273ca964d" translate="yes" xml:space="preserve">
          <source>Many statistical problems require the estimation of a population&amp;rsquo;s covariance matrix, which can be seen as an estimation of data set scatter plot shape. Most of the time, such an estimation has to be done on a sample whose properties (size, structure, homogeneity) have a large influence on the estimation&amp;rsquo;s quality. The &lt;code&gt;sklearn.covariance&lt;/code&gt; package provides tools for accurately estimating a population&amp;rsquo;s covariance matrix under various settings.</source>
          <target state="translated">Многие статистические задачи требуют оценки ковариационной матрицы совокупности, которую можно рассматривать как оценку формы диаграммы разброса набора данных. В большинстве случаев такую ​​оценку приходится проводить на выборке, свойства которой (размер, структура, однородность) имеют большое влияние на качество оценки. Пакет &lt;code&gt;sklearn.covariance&lt;/code&gt; предоставляет инструменты для точной оценки ковариационной матрицы популяции при различных настройках.</target>
        </trans-unit>
        <trans-unit id="be7bf3b7e371f4bec9a03a7522f6dcf31d112a68" translate="yes" xml:space="preserve">
          <source>Many, many more &amp;hellip;</source>
          <target state="translated">Многие, многие другие&amp;hellip;</target>
        </trans-unit>
        <trans-unit id="01a4f781a04bf81d6d3609180ff5b158082bf232" translate="yes" xml:space="preserve">
          <source>Map data to a normal distribution</source>
          <target state="translated">Карта данных для нормального распределения</target>
        </trans-unit>
        <trans-unit id="16409bc40b2df043ac11786860ad0f327aa511b9" translate="yes" xml:space="preserve">
          <source>Maps data to a normal distribution using a power transformation.</source>
          <target state="translated">Картирование данных в нормальное распределение с помощью преобразования мощности.</target>
        </trans-unit>
        <trans-unit id="05aecccd2b32722fa423ccbd7840d48763834385" translate="yes" xml:space="preserve">
          <source>Maps data to a standard normal distribution with the parameter &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Сопоставляет данные со стандартным нормальным распределением с параметром &lt;code&gt;output_distribution=&amp;rsquo;normal&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="12f61571505f27a87deaf94928434363c3add704" translate="yes" xml:space="preserve">
          <source>Maps data to a standard normal distribution with the parameter &lt;code&gt;output_distribution='normal'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2546740d19a0cb39e3dfa40dd82138fa02a22968" translate="yes" xml:space="preserve">
          <source>Maps each categorical feature name to a list of values, such that the value encoded as i is ith in the list.</source>
          <target state="translated">Сопоставляет имя каждого категориального элемента со списком значений,таким образом,чтобы значение,закодированное как i,было ith в списке.</target>
        </trans-unit>
        <trans-unit id="67b185421bf5d928c6a7d5bf74ee20d677f50228" translate="yes" xml:space="preserve">
          <source>Maps each categorical feature name to a list of values, such that the value encoded as i is ith in the list. If &lt;code&gt;as_frame&lt;/code&gt; is True, this is None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="601b228138151f5d614818578f5a990f06465ee3" translate="yes" xml:space="preserve">
          <source>Marginal distribution for the transformed data. The choices are &amp;lsquo;uniform&amp;rsquo; (default) or &amp;lsquo;normal&amp;rsquo;.</source>
          <target state="translated">Маржинальное распределение для преобразованных данных. Возможные варианты: &amp;laquo;равномерный&amp;raquo; (по умолчанию) или &amp;laquo;нормальный&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="32cec489ab51eb304acc5d56c34e0b5894817af1" translate="yes" xml:space="preserve">
          <source>Mark Schmidt, Nicolas Le Roux, and Francis Bach: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;Minimizing Finite Sums with the Stochastic Average Gradient.&lt;/a&gt;</source>
          <target state="translated">Марк Шмидт, Николя Ле Ру и Фрэнсис Бах: &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;минимизация конечных сумм с помощью стохастического среднего градиента.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c75a2b42a0ab364e58b54559c45fcda50d1973f4" translate="yes" xml:space="preserve">
          <source>Married</source>
          <target state="translated">Married</target>
        </trans-unit>
        <trans-unit id="b66f191d027329ba9273c4c5f9be765f9b3745f5" translate="yes" xml:space="preserve">
          <source>Mask to be used on X.</source>
          <target state="translated">Маска для X.</target>
        </trans-unit>
        <trans-unit id="54a21a4d94fa24c6c092fd6e4c2ec05359c76c09" translate="yes" xml:space="preserve">
          <source>MatchingDistance</source>
          <target state="translated">MatchingDistance</target>
        </trans-unit>
        <trans-unit id="38c6b835ca8294e13538ac219d64ae1244beb7fc" translate="yes" xml:space="preserve">
          <source>Matern kernel.</source>
          <target state="translated">Материнское ядро.</target>
        </trans-unit>
        <trans-unit id="c2846fd5b2a8440131137c07fea40912afc701b7" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with \(\ell_1\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,прошедшей обучение по адресу \(\ell_1\)в качестве регулятора.Объективная функция для минимизации является:</target>
        </trans-unit>
        <trans-unit id="bf1818d1c45b1997515a16368907c8cf902bab56" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior and \(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,подготовленной со смешанной \(\ell__1\)\(\ell__2\)предыдущей и \(\ell__2\)предыдущей в качестве регулятора.Объективная функция,чтобы минимизировать является:</target>
        </trans-unit>
        <trans-unit id="1d9fe275a9038555cabcfe46b4a675067788d84f" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\) prior as regularizer. The objective function to minimize is:</source>
          <target state="translated">Математически она состоит из линейной модели,подготовленной со смешанной \(\ell_1\)\(\ell__2\)до этого в качестве регулятора.Объективная функция для минимизации является:</target>
        </trans-unit>
        <trans-unit id="85bbf115a5892290f61e157be8a21f18c7185291" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\)-norm and \(\ell_2\)-norm for regularization. The objective function to minimize is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a22bf31bc3080adb481367d05d21298b6681e5ee" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model trained with a mixed \(\ell_1\)\(\ell_2\)-norm for regularization. The objective function to minimize is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47b46d2e2bec7b475ce40ef0c30d61c9f27a62f1" translate="yes" xml:space="preserve">
          <source>Mathematically, it consists of a linear model with an added regularization term. The objective function to minimize is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="461064fec990b9f56bd78c5da4699263962dc67b" translate="yes" xml:space="preserve">
          <source>Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the l2-penalized Maximum Likelihood Estimator of the covariance matrix. In practice, shrinkage boils down to a simple a convex transformation : \(\Sigma_{\rm shrunk} = (1-\alpha)\hat{\Sigma} + \alpha\frac{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).</source>
          <target state="translated">Математически эта усадка заключается в уменьшении соотношения между наименьшими и наибольшими собственными значениями эмпирической ковариационной матрицы.Это может быть сделано путем простого смещения каждого собственного значения в соответствии с заданным смещением,что эквивалентно нахождению l2-пеналлизованного Оценщика максимального правдоподобия ковариационной матрицы.На практике усадка сводится к простому выпуклому преобразованию:\(\Sigma_{\rm shrunk}=(1-\alpha)\hat{\Sigma}+\alpha\frac{{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).</target>
        </trans-unit>
        <trans-unit id="7f2fa948973686599d9719cd22bf9c261bdbf5a5" translate="yes" xml:space="preserve">
          <source>Mathematically, truncated SVD applied to training samples \(X\) produces a low-rank approximation \(X\):</source>
          <target state="translated">Математически усеченное SVD,применяемое к учебным образцам \(X\),производит низкоуровневое приближение \(X\):</target>
        </trans-unit>
        <trans-unit id="b8c6141893596b10260b39727bf4a66986a56a95" translate="yes" xml:space="preserve">
          <source>Matrices:</source>
          <target state="translated">Matrices:</target>
        </trans-unit>
        <trans-unit id="878abbe8708b2c0d949ede6590fbf80f3b3ca712" translate="yes" xml:space="preserve">
          <source>Matrix \(C\) such that \(C_{i, j}\) is the number of samples in true class \(i\) and in predicted class \(j\). If &lt;code&gt;eps is None&lt;/code&gt;, the dtype of this array will be integer. If &lt;code&gt;eps&lt;/code&gt; is given, the dtype will be float. Will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; if &lt;code&gt;sparse=True&lt;/code&gt;.</source>
          <target state="translated">Матрица \ (C \) такая, что \ (C_ {i, j} \) - это количество выборок в истинном классе \ (i \) и в предсказанном классе \ (j \). Если &lt;code&gt;eps is None&lt;/code&gt; , dtype этого массива будет целым. Если задано &lt;code&gt;eps&lt;/code&gt; , dtype будет плавающим. Будет &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; , если &lt;code&gt;sparse=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a9d3bf25623c95ec103c9ba9ebefafc39b31e10" translate="yes" xml:space="preserve">
          <source>Matrix of similarities between points</source>
          <target state="translated">Матрица сходства между точками</target>
        </trans-unit>
        <trans-unit id="fe09cc11ed56c787dbf583e1d3c86930e73d13b7" translate="yes" xml:space="preserve">
          <source>Matrix to be scaled.</source>
          <target state="translated">Матрица должна быть масштабирована.</target>
        </trans-unit>
        <trans-unit id="f581a8973d13aee9e6d301f776c7ac0aca9937df" translate="yes" xml:space="preserve">
          <source>Matrix to decompose</source>
          <target state="translated">Матрица для разложения</target>
        </trans-unit>
        <trans-unit id="64c58969af0dfb121c9b8582a353fed07f3ae81a" translate="yes" xml:space="preserve">
          <source>Matrix to normalize using the variance of the features.</source>
          <target state="translated">Матрица для нормализации с использованием дисперсии функций.</target>
        </trans-unit>
        <trans-unit id="dc67599b55e21aadb81c15a2c42c0d243f238c7f" translate="yes" xml:space="preserve">
          <source>Matrix whose two columns are to be swapped.</source>
          <target state="translated">Матрица,две колонки которой должны быть заменены.</target>
        </trans-unit>
        <trans-unit id="2ea8698954891f702cc6556af5a70f4a4777910c" translate="yes" xml:space="preserve">
          <source>Matrix whose two rows are to be swapped.</source>
          <target state="translated">Матрица,два ряда которой должны быть заменены.</target>
        </trans-unit>
        <trans-unit id="91c27cd36373d9f3e97d3e8652e4d5420038195e" translate="yes" xml:space="preserve">
          <source>Max number of iterations for updating document topic distribution in the E-step.</source>
          <target state="translated">Максимальное количество итераций для обновления распространения темы документа в E-шаге.</target>
        </trans-unit>
        <trans-unit id="00c71f39eb3784f568496e9b201bef34cf1fba1e" translate="yes" xml:space="preserve">
          <source>MaxAbsScaler</source>
          <target state="translated">MaxAbsScaler</target>
        </trans-unit>
        <trans-unit id="b19f6ae06ce0301b0f2f115ace4b151976f71361" translate="yes" xml:space="preserve">
          <source>Maximizing ELBO is equivalent to minimizing the Kullback-Leibler(KL) divergence between \(q(z,\theta,\beta)\) and the true posterior \(p(z, \theta, \beta |w, \alpha, \eta)\).</source>
          <target state="translated">Максимизация ELBO эквивалентна минимизации расхождения Kullback-Leibler(KL)между \(q(z,\theta,\beta)\)и истинным апостериорным \(p(z,\theta,\beta |w,\alpha,\eta)\).</target>
        </trans-unit>
        <trans-unit id="c7118c6c94bd33474c6bd73b2a0ef4d05bd61b9a" translate="yes" xml:space="preserve">
          <source>Maximizing the log-marginal-likelihood after subtracting the target&amp;rsquo;s mean yields the following kernel with an LML of -83.214:</source>
          <target state="translated">Максимизация логарифма маржинального правдоподобия после вычитания целевого среднего дает следующее ядро ​​с LML -83,214:</target>
        </trans-unit>
        <trans-unit id="3cc68e53e734e045e272d9b61d6ce440314a7c5a" translate="yes" xml:space="preserve">
          <source>Maximum distortion rate as defined by the Johnson-Lindenstrauss lemma. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">Максимальная скорость искажений,определенная леммой Джонсона-Линденстрауса.Если задан массив,то он вычислит безопасное количество компонентов массива.</target>
        </trans-unit>
        <trans-unit id="2648af65469bf6064127630edb239d63fa9087cb" translate="yes" xml:space="preserve">
          <source>Maximum likelihood covariance estimator</source>
          <target state="translated">Оценщик максимальной вероятности ковариаций</target>
        </trans-unit>
        <trans-unit id="c549d82a160dc50758b33cda113fa1dc7a80727c" translate="yes" xml:space="preserve">
          <source>Maximum norm of the residual. If not None, overrides n_nonzero_coefs.</source>
          <target state="translated">Максимальная норма остатка.Если нет None,переопределяет n_nonzero_coefs.</target>
        </trans-unit>
        <trans-unit id="c4d8a154588727ab7c620ef2088eb03d03fdb2cd" translate="yes" xml:space="preserve">
          <source>Maximum number of CF subclusters in each node. If a new samples enters such that the number of subclusters exceed the branching_factor then that node is split into two nodes with the subclusters redistributed in each. The parent subcluster of that node is removed and two new subclusters are added as parents of the 2 split nodes.</source>
          <target state="translated">Максимальное количество подкластеров CF в каждом узле.Если новые выборки поступают так,что количество подкластеров превышает коэффициент ветвления,то эта вершина делится на две вершины,в каждой из которых перераспределяются подкластеры.Родительский подкластер этого узла удаляется,и два новых подкластера добавляются как родители 2-х разделенных узлов.</target>
        </trans-unit>
        <trans-unit id="ffcbfb393ae9341f5e6cf4dea80093dbb65c654d" translate="yes" xml:space="preserve">
          <source>Maximum number of epochs to not meet &lt;code&gt;tol&lt;/code&gt; improvement. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Максимальное количество эпох не соответствует &lt;code&gt;tol&lt;/code&gt; улучшения. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="7d6dde474581154e61a4c14f0f2c50aef90aa524" translate="yes" xml:space="preserve">
          <source>Maximum number of imputation rounds to perform before returning the imputations computed during the final round. A round is a single imputation of each feature with missing values. The stopping criterion is met once &lt;code&gt;abs(max(X_t - X_{t-1}))/abs(max(X[known_vals]))&lt;/code&gt; &amp;lt; tol, where &lt;code&gt;X_t&lt;/code&gt; is &lt;code&gt;X&lt;/code&gt; at iteration &lt;code&gt;t. Note that early stopping is only
applied if ``sample_posterior=False`&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d31095f21fc709b8362fbfbc8701ee49bed43f4" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations</source>
          <target state="translated">Максимальное количество итераций</target>
        </trans-unit>
        <trans-unit id="ec0c7c7cfd1a4dd46776f2839b3e2ee30db0ceb0" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations allowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d0f629c611a546c50fbd29c0a5c09d14523502f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations before timing out.</source>
          <target state="translated">Максимальное количество итераций до тайминга.</target>
        </trans-unit>
        <trans-unit id="e5ab15aeae2ebd19c6cc8dd9b722001d143407e7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations during fit.</source>
          <target state="translated">Максимальное количество итераций во время посадки.</target>
        </trans-unit>
        <trans-unit id="4bd775e3e4801f1199d0d4b78f5390120406b7db" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for arpack. If None, optimal value will be chosen by arpack.</source>
          <target state="translated">Максимальное количество итераций для арпака.Если Нет,то оптимальное значение будет выбрано арпакетом.</target>
        </trans-unit>
        <trans-unit id="f374a3956c9375a530255caa54ee43ca08273ef7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; solver, the default value is 1000.</source>
          <target state="translated">Максимальное количество итераций для решателя сопряженных градиентов. Для решателей 'sparse_cg' и 'lsqr' значение по умолчанию определяется scipy.sparse.linalg. Для решателя &amp;laquo;провисания&amp;raquo; значение по умолчанию - 1000.</target>
        </trans-unit>
        <trans-unit id="11f341e8f36dbf9c1af7cfa8e66dcc9686e34f6b" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. For the &amp;lsquo;sparse_cg&amp;rsquo; and &amp;lsquo;lsqr&amp;rsquo; solvers, the default value is determined by scipy.sparse.linalg. For &amp;lsquo;sag&amp;rsquo; and saga solver, the default value is 1000.</source>
          <target state="translated">Максимальное количество итераций для решателя сопряженных градиентов. Для решателей 'sparse_cg' и 'lsqr' значение по умолчанию определяется scipy.sparse.linalg. Для решателя sag и saga значение по умолчанию - 1000.</target>
        </trans-unit>
        <trans-unit id="c5354ceb6cfff4ad460f2a35427697293dda616c" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.</source>
          <target state="translated">Максимальное количество итераций для сопряженного градиентного решателя.Значение по умолчанию определяется с помощью scipy.sparse.linalg.</target>
        </trans-unit>
        <trans-unit id="1e7dfd80e629f3bb34ea64892d98c69b612b79e1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for random sample selection.</source>
          <target state="translated">Максимальное количество итераций для случайной выборки.</target>
        </trans-unit>
        <trans-unit id="ecd130d87b8a2f3d02f709f684a50be372cae2c9" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the arpack solver. not used if eigen_solver == &amp;lsquo;dense&amp;rsquo;.</source>
          <target state="translated">Максимальное количество итераций для решателя arpack. не используется, если eigen_solver == 'density'.</target>
        </trans-unit>
        <trans-unit id="9de38c6ff2395ad8506cb6d44f0cafffcf62c788" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the calculation of spatial median.</source>
          <target state="translated">Максимальное количество итераций для расчета пространственной медианы.</target>
        </trans-unit>
        <trans-unit id="07f904d8faecfe25c803428c8e7a88d0070e3e3e" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the optimization. Should be at least 250.</source>
          <target state="translated">Максимальное количество итераций для оптимизации.Должно быть не менее 250.</target>
        </trans-unit>
        <trans-unit id="dce17045503a4e7dfc48c40d90d1aeae843b7e1f" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations for the solver.</source>
          <target state="translated">Максимальное количество итераций для решателя.</target>
        </trans-unit>
        <trans-unit id="23888143df53d4407b7d5db42e819ad8fc40bfb6" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations in the optimization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1c1739cc631f47e83bf7484461b685fd99cca3d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the SMACOF algorithm for a single run.</source>
          <target state="translated">Максимальное количество итераций алгоритма SMACOF за один прогон.</target>
        </trans-unit>
        <trans-unit id="7f1e71a3c23990192b71291657a3bae2f490d4ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm for a single run.</source>
          <target state="translated">Максимальное количество итераций алгоритма k-среднего за один прогон.</target>
        </trans-unit>
        <trans-unit id="f0e6e9653318c3bc8385e39576298e438fdcd759" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the k-means algorithm to run.</source>
          <target state="translated">Максимальное количество итераций алгоритма k-средних для запуска.</target>
        </trans-unit>
        <trans-unit id="368dd40a437636dbd3f559d65e7725494d2a9fb1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations of the optimization algorithm.</source>
          <target state="translated">Максимальное количество итераций алгоритма оптимизации.</target>
        </trans-unit>
        <trans-unit id="63c06831f070b2a52428ee45e49cb4b88ea5a09d" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.</source>
          <target state="translated">Максимальное количество итераций по всему набору данных до остановки независимо от любой эвристики раннего критерия остановки.</target>
        </trans-unit>
        <trans-unit id="a1da02f682252ffa124e7544bc23e0152d7ce8c8" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations performed on each seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff75c0f1937b00a0d18d3456b10469179a13bfd5" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations run across all classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d873ede9710528d1162698e1b4121133119149c" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations taken for the solvers to converge.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f2d5ee22794f6faeed2ed56167e69832301d9fb" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; should run for.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7899fd5b3a78738f0401cfc3b35e8ce4d2309778" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that can be skipped due to finding zero inliers or invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt; or invalid models defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">Максимальное количество итераций, которые можно пропустить из-за обнаружения нулевых меток или недопустимых данных, определенных &lt;code&gt;is_data_valid&lt;/code&gt; , или недопустимых моделей, определенных &lt;code&gt;is_model_valid&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e7fba252520d1990cf2d4eb5716def2f32bbae99" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations that scipy.optimize.fmin_l_bfgs_b should run for.</source>
          <target state="translated">Максимальное количество итераций,которое должен выполнить scipy.optim.fmin_l_bfgs_b.</target>
        </trans-unit>
        <trans-unit id="4e1098501827a192b62ebb4f1cab51c2d422cf00" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">Максимальное количество итераций для выполнения, если &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f8b9c126c90c88245cf150185cad9a95bb9ec437" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform if &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt; or &lt;code&gt;lasso_lars&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa990833ac4f020e2d41da9d6169624866ecf0ee" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform in the Lars algorithm.</source>
          <target state="translated">Максимальное количество итераций для выполнения в алгоритме Ларса.</target>
        </trans-unit>
        <trans-unit id="67f387c33c051b181969f68bc7a00e313e621f7a" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform when solving the lasso problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0f4ce7794b613699161c8c6e0e45882e1e59e63" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform, set to infinity for no limit.</source>
          <target state="translated">Максимальное количество выполняемых итераций,установлено на бесконечность без ограничения.</target>
        </trans-unit>
        <trans-unit id="6484f135db2cde17daa0042bcd9839216d734460" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="db2ca83257c5e157920232d66349b60febf20184" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations to perform. Can be used for early stopping.</source>
          <target state="translated">Максимальное количество итераций.Может использоваться для ранней остановки.</target>
        </trans-unit>
        <trans-unit id="3ae0883a212da2486dca35b829a405dbbd2b8c29" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations without progress before we abort the optimization, used after 250 initial iterations with early exaggeration. Note that progress is only checked every 50 iterations so this value is rounded to the next multiple of 50.</source>
          <target state="translated">Максимальное количество итераций без прогресса перед прерыванием оптимизации,используемое после 250 начальных итераций с ранним преувеличением.Обратите внимание,что прогресс проверяется только каждые 50 итераций,поэтому это значение округляется до следующего кратного числа 50.</target>
        </trans-unit>
        <trans-unit id="5919ba2c46521b64537304f167c62803da4391df" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations, per seed point before the clustering operation terminates (for that seed point), if has not converged yet.</source>
          <target state="translated">Максимальное количество итераций на точку посадки до окончания кластеризации (для этой точки посадки),если она еще не сошла воедино.</target>
        </trans-unit>
        <trans-unit id="3fcea6ff6580050eb63d7142d23e7d7896de7626" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations.</source>
          <target state="translated">Максимальное количество итераций.</target>
        </trans-unit>
        <trans-unit id="2bd71b5c83b9f5da0d4a94baa31a035271906ce7" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300</source>
          <target state="translated">Максимальное количество итераций.По умолчанию 300</target>
        </trans-unit>
        <trans-unit id="6740f9eed55c5399b0f5fe47513d42802b2d72aa" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Default is 300.</source>
          <target state="translated">Максимальное количество итераций.По умолчанию 300.</target>
        </trans-unit>
        <trans-unit id="78adce28aba1dcec634d8308251161f963f008c1" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. Should be greater than or equal to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d3427b734648d0ef9c00f4282011f095b732bba" translate="yes" xml:space="preserve">
          <source>Maximum number of iterations. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;) or this number of iterations. For stochastic solvers (&amp;lsquo;sgd&amp;rsquo;, &amp;lsquo;adam&amp;rsquo;), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.</source>
          <target state="translated">Максимальное количество итераций. Решающая программа выполняет итерацию до сходимости (определяемой параметром &amp;laquo;tol&amp;raquo;) или до этого количества итераций. Для стохастических решателей ('sgd', 'adam') обратите внимание, что это определяет количество эпох (сколько раз будет использоваться каждая точка данных), а не количество шагов градиента.</target>
        </trans-unit>
        <trans-unit id="647156dc0e4267e82660e321d855d0ab57ee6ce8" translate="yes" xml:space="preserve">
          <source>Maximum number of samples used to estimate the quantiles for computational efficiency. Note that the subsampling procedure may differ for value-identical sparse and dense matrices.</source>
          <target state="translated">Максимальное количество выборок,используемых для оценки квантилей для вычислительной эффективности.Обратите внимание,что процедура субсэмплинга может отличаться для среднеквадратичных разреженных и плотных матриц.</target>
        </trans-unit>
        <trans-unit id="415a2ec1c451656db8760ffe077b89b191d3a2b3" translate="yes" xml:space="preserve">
          <source>Maximum numbers of iterations to perform, therefore maximum features to include. 10% of &lt;code&gt;n_features&lt;/code&gt; but at least 5 if available.</source>
          <target state="translated">Максимальное количество выполняемых итераций, следовательно, максимальное количество функций, которые необходимо включить. 10% &lt;code&gt;n_features&lt;/code&gt; , но не менее 5, если доступно.</target>
        </trans-unit>
        <trans-unit id="631012abffd401f8346d1251260aa1bdd321bf8a" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt; or the number of nodes in the path with &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; , либо количество узлов в пути с &lt;code&gt;alpha &amp;gt;= alpha_min&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="705f01a5b973480d43f7edb8b4f1d8b46afffacc" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;max_iter&lt;/code&gt;, &lt;code&gt;n_features&lt;/code&gt;, or the number of nodes in the path with correlation greater than &lt;code&gt;alpha&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;max_iter&lt;/code&gt; , &lt;code&gt;n_features&lt;/code&gt; , либо количество узлов в пути с корреляцией больше &lt;code&gt;alpha&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="62989d4a3b259ca439d6192faa2834aa0e75a2e0" translate="yes" xml:space="preserve">
          <source>Maximum of covariances (in absolute value) at each iteration. &lt;code&gt;n_alphas&lt;/code&gt; is either &lt;code&gt;n_nonzero_coefs&lt;/code&gt; or &lt;code&gt;n_features&lt;/code&gt;, whichever is smaller.</source>
          <target state="translated">Максимум ковариаций (по модулю) на каждой итерации. &lt;code&gt;n_alphas&lt;/code&gt; - это либо &lt;code&gt;n_nonzero_coefs&lt;/code&gt; , либо &lt;code&gt;n_features&lt;/code&gt; , в зависимости от того, что меньше.</target>
        </trans-unit>
        <trans-unit id="2519f5f4a0d8bcad0dcee25fb3c2cfe0d8efda04" translate="yes" xml:space="preserve">
          <source>Maximum possible imputed value. Broadcast to shape (n_features,) if scalar. If array-like, expects shape (n_features,), one max value for each feature. &lt;code&gt;None&lt;/code&gt; (default) is converted to np.inf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e56eb85aade57d415023e1a3a8ae03f5b942a0cd" translate="yes" xml:space="preserve">
          <source>Maximum residual for a data sample to be classified as an inlier. By default the threshold is chosen as the MAD (median absolute deviation) of the target values &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Максимальный остаток для выборки данных, которая должна быть классифицирована как вставка. По умолчанию порог выбирается как MAD (среднее абсолютное отклонение) целевых значений &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6dd6334c9c1bb29cde2ace0d7ca9c039e7de14bd" translate="yes" xml:space="preserve">
          <source>Maximum size for a single training set.</source>
          <target state="translated">Максимальный размер для одного тренировочного комплекта.</target>
        </trans-unit>
        <trans-unit id="3feffec2bfb871f0142dbd2d75d410b437245309" translate="yes" xml:space="preserve">
          <source>Maximum squared sum of X over samples. Used only in SAG solver. If None, it will be computed, going through all the samples. The value should be precomputed to speed up cross validation.</source>
          <target state="translated">Максимальная квадратная сумма Х по образцам.Используется только в SAG solver.Если None,он будет вычислен,проходя через все сэмплы.Значение должно быть предварительно вычислено,чтобы ускорить перекрестную проверку.</target>
        </trans-unit>
        <trans-unit id="229948f9503f6467f2a53d61f4254093e7ca3738" translate="yes" xml:space="preserve">
          <source>Maximum step size (regularization). Defaults to 1.0.</source>
          <target state="translated">Максимальный размер шага (регуляризация).По умолчанию 1.0.</target>
        </trans-unit>
        <trans-unit id="843c61e3ff0f74449c911dbb02faa43821e29850" translate="yes" xml:space="preserve">
          <source>Maximum value of a bicluster.</source>
          <target state="translated">Максимальное значение билюстра.</target>
        </trans-unit>
        <trans-unit id="ce9a39e13a20e687ebff9fcf4496175bdfa0afbb" translate="yes" xml:space="preserve">
          <source>Maximum value of input array &lt;code&gt;X_&lt;/code&gt; for right bound.</source>
          <target state="translated">Максимальное значение входного массива &lt;code&gt;X_&lt;/code&gt; для правой границы.</target>
        </trans-unit>
        <trans-unit id="9fa80bb15d05b082522b43fcb83b05beb6f022c6" translate="yes" xml:space="preserve">
          <source>May be the string &amp;ldquo;jaccard&amp;rdquo; to use the Jaccard coefficient, or any function that takes four arguments, each of which is a 1d indicator vector: (a_rows, a_columns, b_rows, b_columns).</source>
          <target state="translated">Это может быть строка &amp;laquo;jaccard&amp;raquo; для использования коэффициента Жаккара или любая функция, которая принимает четыре аргумента, каждый из которых является 1d вектором индикатора: (a_rows, a_columns, b_rows, b_columns).</target>
        </trans-unit>
        <trans-unit id="4fad1e9d11d435bd5f0db307b217272d94f19197" translate="yes" xml:space="preserve">
          <source>May contain any subset of (&amp;lsquo;headers&amp;rsquo;, &amp;lsquo;footers&amp;rsquo;, &amp;lsquo;quotes&amp;rsquo;). Each of these are kinds of text that will be detected and removed from the newsgroup posts, preventing classifiers from overfitting on metadata.</source>
          <target state="translated">Может содержать любое подмножество (&amp;laquo;заголовки&amp;raquo;, &amp;laquo;нижние колонтитулы&amp;raquo;, &amp;laquo;кавычки&amp;raquo;). Каждый из этих типов текста будет обнаруживаться и удаляться из сообщений группы новостей, предотвращая переоснащение классификаторами метаданных.</target>
        </trans-unit>
        <trans-unit id="5b986034f147ad60f742da340ca1bd20b5f08ce7" translate="yes" xml:space="preserve">
          <source>McCullagh, Peter; Nelder, John (1989). Generalized Linear Models, Second Edition. Boca Raton: Chapman and Hall/CRC. ISBN 0-412-31760-5.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72639b42074abb6c8ea20684337c75e653e13eb2" translate="yes" xml:space="preserve">
          <source>McSherry, F., &amp;amp; Najork, M. (2008, March). Computing information retrieval performance measures efficiently in the presence of tied scores. In European conference on information retrieval (pp. 414-421). Springer, Berlin, Heidelberg.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f0935dfe9ab3f30e90c245d2338ed727682177f" translate="yes" xml:space="preserve">
          <source>Mean Absolute Error:</source>
          <target state="translated">Средняя Абсолютная Ошибка:</target>
        </trans-unit>
        <trans-unit id="90a417c7a65441a9ebd4508d554460a1437266a0" translate="yes" xml:space="preserve">
          <source>Mean Gamma deviance regression loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5e71e9559d855f0bb974ab566c48b140de9b95a" translate="yes" xml:space="preserve">
          <source>Mean Poisson deviance regression loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="007ffde203dd83c4c710b22da1cbe0b3700a98d1" translate="yes" xml:space="preserve">
          <source>Mean Silhouette Coefficient for all samples.</source>
          <target state="translated">Коэффициент среднего силуэта для всех образцов.</target>
        </trans-unit>
        <trans-unit id="2762f10f75116f5e4a70c10eb14cf5f478eb498f" translate="yes" xml:space="preserve">
          <source>Mean Squared Error:</source>
          <target state="translated">Средняя квадратичная ошибка:</target>
        </trans-unit>
        <trans-unit id="04bada6d1e51be3ec0e69f413da51c5f62d2f9fc" translate="yes" xml:space="preserve">
          <source>Mean Tweedie deviance regression loss.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43559adecf21dbddbbe17afba52b16b4a67e4402" translate="yes" xml:space="preserve">
          <source>Mean absolute error regression loss</source>
          <target state="translated">Средняя потеря регрессии абсолютной погрешности</target>
        </trans-unit>
        <trans-unit id="640f16564a014e166473dc43ba616e7e2ca59c7f" translate="yes" xml:space="preserve">
          <source>Mean accuracy of self.predict(X) w.r.t. y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec9517dd8574c2a6b45d6a307e2a503f5e6d275d" translate="yes" xml:space="preserve">
          <source>Mean accuracy of self.predict(X) wrt. y.</source>
          <target state="translated">Средняя точность самопредсказания(X)не...y.</target>
        </trans-unit>
        <trans-unit id="7493a61b1729d0e0247689ac97555930f03706df" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator</source>
          <target state="translated">Средний перекрёстный балл best_estimator</target>
        </trans-unit>
        <trans-unit id="140100875ffefa42eddb6a75afe4c55e05443030" translate="yes" xml:space="preserve">
          <source>Mean cross-validated score of the best_estimator.</source>
          <target state="translated">Средний перекрестный балл best_estimator.</target>
        </trans-unit>
        <trans-unit id="905638cd4671af1b6b218d93d25fb805a7548993" translate="yes" xml:space="preserve">
          <source>Mean of feature importance over &lt;code&gt;n_repeats&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd2a669704ec2ab03a0e4ca8e2abc9c2d42f71c6" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution a query points</source>
          <target state="translated">Среднее предсказывающее распределение точек запроса</target>
        </trans-unit>
        <trans-unit id="b609d0f7d96a7b9c8e60baf85298ffc173cbc6f7" translate="yes" xml:space="preserve">
          <source>Mean of predictive distribution of query points.</source>
          <target state="translated">Среднее предсказывающее распределение точек запроса.</target>
        </trans-unit>
        <trans-unit id="e7f5a133eabd3f3a470b8b7cb54eeb045b64973a" translate="yes" xml:space="preserve">
          <source>Mean or median or quantile of the training targets or constant value given by the user.</source>
          <target state="translated">Среднее или медианное или квантильное значение учебных целей или постоянное значение,заданное пользователем.</target>
        </trans-unit>
        <trans-unit id="9ede03e41402c8eec43dd01264f8f822af5fb92b" translate="yes" xml:space="preserve">
          <source>Mean shift clustering aims to discover &amp;ldquo;blobs&amp;rdquo; in a smooth density of samples. It is a centroid-based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids.</source>
          <target state="translated">Кластеризация среднего сдвига направлена ​​на обнаружение &amp;laquo;пятен&amp;raquo; в сглаженной плотности выборок. Это алгоритм на основе центроидов, который работает, обновляя кандидатов в центроиды, чтобы они были средними точками в данном регионе. Затем эти кандидаты фильтруются на этапе постобработки, чтобы исключить почти дубликаты и сформировать окончательный набор центроидов.</target>
        </trans-unit>
        <trans-unit id="08b2e6d37eec1f5ceae1376ffba9071609b6547f" translate="yes" xml:space="preserve">
          <source>Mean shift clustering using a flat kernel.</source>
          <target state="translated">Средняя кластеризация сдвига с помощью плоского ядра.</target>
        </trans-unit>
        <trans-unit id="4484f1a9abfaeee06549ff0a6b75712b44fd35f2" translate="yes" xml:space="preserve">
          <source>Mean square error for the test set on each fold, varying l1_ratio and alpha.</source>
          <target state="translated">Средняя квадратная погрешность для тестового набора на каждой сгибе,изменяющаяся в соотношении l1_ratio и alpha.</target>
        </trans-unit>
        <trans-unit id="4a0031a2d59450a58aeaa638a064cb2e2c9a0da5" translate="yes" xml:space="preserve">
          <source>Mean squared error regression loss</source>
          <target state="translated">Потеря регрессии средней квадратной ошибки</target>
        </trans-unit>
        <trans-unit id="831bfb250ab69b773c25fae60f230a00bfdc7239" translate="yes" xml:space="preserve">
          <source>Mean squared logarithmic error regression loss</source>
          <target state="translated">Средняя квадратичная логарифмическая ошибка потери регрессии</target>
        </trans-unit>
        <trans-unit id="2db7f6881ab1082c632822482db18fa9fc34ed90" translate="yes" xml:space="preserve">
          <source>Mean-shift</source>
          <target state="translated">Mean-shift</target>
        </trans-unit>
        <trans-unit id="896bb25ed00af769d9d9cdb21af7655bd0a22654" translate="yes" xml:space="preserve">
          <source>Measure and plot the results</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df21241945c8fd60618f888d81f315be3f7af674" translate="yes" xml:space="preserve">
          <source>Measure the similarity of two clusterings of a set of points.</source>
          <target state="translated">Измерьте схожесть двух скоплений набора точек.</target>
        </trans-unit>
        <trans-unit id="e49da6a85d81735a7b28ef79fc256dec989d2443" translate="yes" xml:space="preserve">
          <source>Measurement errors in X</source>
          <target state="translated">Погрешности измерения в Х</target>
        </trans-unit>
        <trans-unit id="471fba4dfe2d4f61d0ae5efc77acb722551abb7b" translate="yes" xml:space="preserve">
          <source>Measurement errors in y</source>
          <target state="translated">Погрешности измерения в y</target>
        </trans-unit>
        <trans-unit id="d59aa4a9911bb1573c0ba0a2779ea96a4989f27f" translate="yes" xml:space="preserve">
          <source>MedInc median income in block</source>
          <target state="translated">MedInc средний доход в блоке</target>
        </trans-unit>
        <trans-unit id="ca6bd4b635d61f1c13fd0394e55000bb30738881" translate="yes" xml:space="preserve">
          <source>Median absolute error output is non-negative floating point. The best value is 0.0. Read more in the &lt;a href=&quot;../model_evaluation#median-absolute-error&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb82014fc42479d50d7886c5d05c20bd8db97f56" translate="yes" xml:space="preserve">
          <source>Median absolute error regression loss</source>
          <target state="translated">Медианная потеря абсолютной погрешности регрессии</target>
        </trans-unit>
        <trans-unit id="9e7082d8eb8f2409deaa71605e5d6dbf5b190217" translate="yes" xml:space="preserve">
          <source>Medium &lt;code&gt;n_samples&lt;/code&gt;, small &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Средних &lt;code&gt;n_samples&lt;/code&gt; , маленьких &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="da13fe6da16d1b0d3601ee1416010215c9da2b3d" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;coef_&lt;/code&gt; holds the weights \(w\)</source>
          <target state="translated">Член &lt;code&gt;coef_&lt;/code&gt; содержит веса \ (w \)</target>
        </trans-unit>
        <trans-unit id="b26ca7073281a8f4da3f64aafb4932ce0dc723cc" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds \(b\)</source>
          <target state="translated">Элемент &lt;code&gt;intercept_&lt;/code&gt; содержит \ (b \)</target>
        </trans-unit>
        <trans-unit id="8e7e4ea63f467ef992e1b5515c3662fd092327fd" translate="yes" xml:space="preserve">
          <source>Member &lt;code&gt;intercept_&lt;/code&gt; holds the intercept (aka offset or bias):</source>
          <target state="translated">Член &lt;code&gt;intercept_&lt;/code&gt; содержит перехват (также известный как смещение или смещение):</target>
        </trans-unit>
        <trans-unit id="b6ef7f0fdf735583a61dbfc359227479e43bf842" translate="yes" xml:space="preserve">
          <source>Memmapping mode for numpy arrays passed to workers. See &amp;lsquo;max_nbytes&amp;rsquo; parameter documentation for more details.</source>
          <target state="translated">Режим Memmapping для массивов numpy передан рабочим. См. Дополнительную информацию в документации по параметру max_nbytes.</target>
        </trans-unit>
        <trans-unit id="424b610ebd2af23e4bb8a29dcabbc0551e9c3d87" translate="yes" xml:space="preserve">
          <source>Memory consumption for large sample sizes</source>
          <target state="translated">Расход памяти для больших размеров образцов</target>
        </trans-unit>
        <trans-unit id="5418f36b831a9c825f5d841c5ee3b1bdb2dd3e28" translate="yes" xml:space="preserve">
          <source>Meta-estimator to regress on a transformed target.</source>
          <target state="translated">Мета-стимулятор для регресса по преобразованной цели.</target>
        </trans-unit>
        <trans-unit id="79599678d3d5e2500fd2a7f727461a2dac0b6cd4" translate="yes" xml:space="preserve">
          <source>Meta-estimators for building composite models with transformers</source>
          <target state="translated">Мета-оценщики для построения композитных моделей с трансформаторами</target>
        </trans-unit>
        <trans-unit id="d5a7b3579e10eeaa00ced1884380b174708caebd" translate="yes" xml:space="preserve">
          <source>Meta-transformer for selecting features based on importance weights.</source>
          <target state="translated">Мета-трансформатор для выбора функций на основе весов важности.</target>
        </trans-unit>
        <trans-unit id="88306943fea7e76f9cd57cae0ea6d8b32d2e8434" translate="yes" xml:space="preserve">
          <source>Method</source>
          <target state="translated">Method</target>
        </trans-unit>
        <trans-unit id="bebb8fb7cc6768e9928f39fcd0184089c7f19d03" translate="yes" xml:space="preserve">
          <source>Method for initialization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3dad9226be4bd937f8a455ee0badad4ee6cceff1" translate="yes" xml:space="preserve">
          <source>Method for initialization of k-means algorithm; defaults to &amp;lsquo;k-means++&amp;rsquo;.</source>
          <target state="translated">Метод инициализации алгоритма k-средних; по умолчанию &quot;k-means ++&quot;.</target>
        </trans-unit>
        <trans-unit id="2c3f3dc3ba37d9b2f1af18176cea15628b89a09c" translate="yes" xml:space="preserve">
          <source>Method for initialization, default to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">Метод инициализации, по умолчанию k-means ++:</target>
        </trans-unit>
        <trans-unit id="62b8a3dc56fc8229948d624cc5b38920d22e2365" translate="yes" xml:space="preserve">
          <source>Method for initialization, defaults to &amp;lsquo;k-means++&amp;rsquo;:</source>
          <target state="translated">Метод инициализации, по умолчанию k-means ++:</target>
        </trans-unit>
        <trans-unit id="0e3feb124243dbfe777425d1e7de652a8a95432b" translate="yes" xml:space="preserve">
          <source>Method for initialization:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b1389e0e832a05337d6ccb31e50ea1425ca91a8" translate="yes" xml:space="preserve">
          <source>Method name</source>
          <target state="translated">Название метода</target>
        </trans-unit>
        <trans-unit id="f2ddbb16b4269f001b2886168e6ee73674985a74" translate="yes" xml:space="preserve">
          <source>Method of normalizing and converting singular vectors into biclusters. May be one of &amp;lsquo;scale&amp;rsquo;, &amp;lsquo;bistochastic&amp;rsquo;, or &amp;lsquo;log&amp;rsquo;. The authors recommend using &amp;lsquo;log&amp;rsquo;. If the data is sparse, however, log normalization will not work, which is why the default is &amp;lsquo;bistochastic&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b78ea13fd7ce3e01d82dac91ffffedca9d6a516f" translate="yes" xml:space="preserve">
          <source>Method of normalizing and converting singular vectors into biclusters. May be one of &amp;lsquo;scale&amp;rsquo;, &amp;lsquo;bistochastic&amp;rsquo;, or &amp;lsquo;log&amp;rsquo;. The authors recommend using &amp;lsquo;log&amp;rsquo;. If the data is sparse, however, log normalization will not work, which is why the default is &amp;lsquo;bistochastic&amp;rsquo;. CAUTION: if &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt;, the data must not be sparse.</source>
          <target state="translated">Метод нормализации и преобразования сингулярных векторов в бикластеры. Может быть &amp;laquo;масштаб&amp;raquo;, &amp;laquo;бистохастический&amp;raquo; или &amp;laquo;журнал&amp;raquo;. Авторы рекомендуют использовать log. Однако, если данные немногочисленны, нормализация журнала не будет работать, поэтому значение по умолчанию - &amp;laquo;бистохастический&amp;raquo;. ВНИМАНИЕ: если &lt;code&gt;method=&amp;rsquo;log&amp;rsquo;&lt;/code&gt; , данные не должны быть разреженными.</target>
        </trans-unit>
        <trans-unit id="7e7b59d1db0b41f1f7de6a768474fa98a959edfd" translate="yes" xml:space="preserve">
          <source>Method to use in finding shortest path.</source>
          <target state="translated">Метод поиска кратчайшего пути.</target>
        </trans-unit>
        <trans-unit id="46674c498c855af96974ed544b15ae6396d6f74f" translate="yes" xml:space="preserve">
          <source>Method used to encode the transformed result.</source>
          <target state="translated">Метод,используемый для кодирования преобразованного результата.</target>
        </trans-unit>
        <trans-unit id="155758829048f282b684f453070e5e32e8a3b098" translate="yes" xml:space="preserve">
          <source>Method used to initialize the procedure. Default: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise random. Valid options:</source>
          <target state="translated">Метод, используемый для инициализации процедуры. По умолчанию: 'nndsvd', если n_components &amp;lt;n_features, в противном случае - случайный. Допустимые варианты:</target>
        </trans-unit>
        <trans-unit id="2babbe784e2e75bf6bc5c5da588a447b4ed201c9" translate="yes" xml:space="preserve">
          <source>Method used to initialize the procedure. Default: None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7506fd4c85f1f80b13ff77585a3eea447916c5af" translate="yes" xml:space="preserve">
          <source>Method used to initialize the procedure. Default: None. Valid options:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e9cbcdd1d5058381751f008677bca0c5dd1dd9b" translate="yes" xml:space="preserve">
          <source>Method used to update &lt;code&gt;_component&lt;/code&gt;. Only used in &lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; method. In general, if the data size is large, the online update will be much faster than the batch update.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c32a8fabfe7118c5a18a023b129a09f5774d869" translate="yes" xml:space="preserve">
          <source>Method used to update &lt;code&gt;_component&lt;/code&gt;. Only used in &lt;code&gt;fit&lt;/code&gt; method. In general, if the data size is large, the online update will be much faster than the batch update.</source>
          <target state="translated">Метод, используемый для обновления &lt;code&gt;_component&lt;/code&gt; . Используется только в &lt;code&gt;fit&lt;/code&gt; методе. В целом, если размер данных большой, онлайн-обновление будет намного быстрее, чем пакетное обновление.</target>
        </trans-unit>
        <trans-unit id="7e4ac6803c9159c694f63d089cb06b2519c16aba" translate="yes" xml:space="preserve">
          <source>Methods</source>
          <target state="translated">Methods</target>
        </trans-unit>
        <trans-unit id="8de2b023f4bb12cf6f4720283ae55f1dda2214ee" translate="yes" xml:space="preserve">
          <source>Methods called for each base estimator. It can be:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66a03315f429c2912a3083f4347509dcbe2b4de3" translate="yes" xml:space="preserve">
          <source>Metric to use for distance computation. Any metric from scikit-learn or scipy.spatial.distance can be used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a01ea489bdc9c9d6a182edc027242ff94374f848" translate="yes" xml:space="preserve">
          <source>Metric used to compute distances to neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="223dc067df313c03c1e792b17b98d4c951add488" translate="yes" xml:space="preserve">
          <source>Metric used to compute the linkage. Can be &amp;ldquo;euclidean&amp;rdquo;, &amp;ldquo;l1&amp;rdquo;, &amp;ldquo;l2&amp;rdquo;, &amp;ldquo;manhattan&amp;rdquo;, &amp;ldquo;cosine&amp;rdquo;, or &amp;ldquo;precomputed&amp;rdquo;. If linkage is &amp;ldquo;ward&amp;rdquo;, only &amp;ldquo;euclidean&amp;rdquo; is accepted. If &amp;ldquo;precomputed&amp;rdquo;, a distance matrix (instead of a similarity matrix) is needed as input for the fit method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef01ecfb88c8d650a45a85cec9ebc18d89f4ecbc" translate="yes" xml:space="preserve">
          <source>Metric used to compute the linkage. Can be &amp;ldquo;euclidean&amp;rdquo;, &amp;ldquo;l1&amp;rdquo;, &amp;ldquo;l2&amp;rdquo;, &amp;ldquo;manhattan&amp;rdquo;, &amp;ldquo;cosine&amp;rdquo;, or &amp;lsquo;precomputed&amp;rsquo;. If linkage is &amp;ldquo;ward&amp;rdquo;, only &amp;ldquo;euclidean&amp;rdquo; is accepted.</source>
          <target state="translated">Метрика, используемая для вычисления связи. Может быть &amp;laquo;евклидовым&amp;raquo;, &amp;laquo;l1&amp;raquo;, &amp;laquo;l2&amp;raquo;, &amp;laquo;манхэттенским&amp;raquo;, &amp;laquo;косинусным&amp;raquo; или &amp;laquo;предварительно вычисленным&amp;raquo;. Если связь &amp;laquo;подопечная&amp;raquo;, принимается только &amp;laquo;евклидова&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="b996dbf9b464efe667f55d3c7b947b9e2ffb345f" translate="yes" xml:space="preserve">
          <source>Metrics available for various machine learning tasks are detailed in sections below.</source>
          <target state="translated">Метрики,доступные для различных задач машинного обучения,подробно описаны в разделах ниже.</target>
        </trans-unit>
        <trans-unit id="6333551e93ef2383df0508df89bd1ca423b74bc9" translate="yes" xml:space="preserve">
          <source>Michael E. Tipping, &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;Sparse Bayesian Learning and the Relevance Vector Machine&lt;/a&gt;, 2001.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="276b36ad13c4507935dcfa6095085df1bf048be3" translate="yes" xml:space="preserve">
          <source>Michael E. Tipping: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;Sparse Bayesian Learning and the Relevance Vector Machine&lt;/a&gt;</source>
          <target state="translated">Майкл Е. Типпинг: &lt;a href=&quot;http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf&quot;&gt;разреженное байесовское обучение и вектор релевантности&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ee22c86ee428b82d33b13bdebced2deed71d63a1" translate="yes" xml:space="preserve">
          <source>Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</source>
          <target state="translated">Майкл Маршалл (MARSHALL%PLU@io.arc.nasa.gov)</target>
        </trans-unit>
        <trans-unit id="f33a348553a7d85d27424bb525b1eca4fb8a5155" translate="yes" xml:space="preserve">
          <source>MinMaxScaler</source>
          <target state="translated">MinMaxScaler</target>
        </trans-unit>
        <trans-unit id="6fad9f3e5fbaefddf87807ab8e89f2398827a6e0" translate="yes" xml:space="preserve">
          <source>Mini-Batch K-Means clustering</source>
          <target state="translated">Мини-группа К-Минов кластеризация</target>
        </trans-unit>
        <trans-unit id="f81af70401b9fbaba1cc8f3d806f31408afbc851" translate="yes" xml:space="preserve">
          <source>Mini-Batch K-Means clustering.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a7343b748199980306d06faf24494c5fb233c16" translate="yes" xml:space="preserve">
          <source>Mini-batch Sparse Principal Components Analysis</source>
          <target state="translated">Миниатюрный анализ по разделению основных компонентов</target>
        </trans-unit>
        <trans-unit id="4a04231399e807603297c55fa730ae6cac785e8b" translate="yes" xml:space="preserve">
          <source>Mini-batch dictionary learning</source>
          <target state="translated">Обучение мини-словарям</target>
        </trans-unit>
        <trans-unit id="b36d4bb746673223e9f3eddf90497433b367472a" translate="yes" xml:space="preserve">
          <source>Mini-batch sparse PCA (&lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt;) is a variant of &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt;&lt;code&gt;SparsePCA&lt;/code&gt;&lt;/a&gt; that is faster but less accurate. The increased speed is reached by iterating over small chunks of the set of features, for a given number of iterations.</source>
          <target state="translated">Мини-пакетный разреженный PCA ( &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; ) - это вариант &lt;a href=&quot;generated/sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA&quot;&gt; &lt;code&gt;SparsePCA&lt;/code&gt; ,&lt;/a&gt; который работает быстрее, но менее точен. Повышенная скорость достигается путем повторения небольших фрагментов набора функций в течение заданного количества итераций.</target>
        </trans-unit>
        <trans-unit id="acc629f9bc13af6fe4ccc30d47949b9a29f4708a" translate="yes" xml:space="preserve">
          <source>Minimal cost complexity pruning recursively finds the node with the &amp;ldquo;weakest link&amp;rdquo;. The weakest link is characterized by an effective alpha, where the nodes with the smallest effective alpha are pruned first. To get an idea of what values of &lt;code&gt;ccp_alpha&lt;/code&gt; could be appropriate, scikit-learn provides &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path&quot;&gt;&lt;code&gt;DecisionTreeClassifier.cost_complexity_pruning_path&lt;/code&gt;&lt;/a&gt; that returns the effective alphas and the corresponding total leaf impurities at each step of the pruning process. As alpha increases, more of the tree is pruned, which increases the total impurity of its leaves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8dae4007afe0299bfaa99f8bc74594de701fdf" translate="yes" xml:space="preserve">
          <source>Minimal cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting, described in Chapter 3 of &lt;a href=&quot;#bre&quot; id=&quot;id2&quot;&gt;[BRE]&lt;/a&gt;. This algorithm is parameterized by \(\alpha\ge0\) known as the complexity parameter. The complexity parameter is used to define the cost-complexity measure, \(R_\alpha(T)\) of a given tree \(T\):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="338b69eb058f4b8de205ae0e6a0b364261aebe7e" translate="yes" xml:space="preserve">
          <source>Minimizes the objective function:</source>
          <target state="translated">Минимизирует объективную функцию:</target>
        </trans-unit>
        <trans-unit id="84c971787220fb3e13d325cba22644ed7cfc6396" translate="yes" xml:space="preserve">
          <source>Minimizing Finite Sums with the Stochastic Average Gradient &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</source>
          <target state="translated">Минимизация конечных сумм с помощью среднего стохастического градиента &lt;a href=&quot;https://hal.inria.fr/hal-00860051/document&quot;&gt;https://hal.inria.fr/hal-00860051/document&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="40d428add0b0bb2b15690324c7a65b1e95d21444" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant (MCD): robust estimator of covariance.</source>
          <target state="translated">Детерминант минимальной ковариативности (MCD):робастный оценщик ковариаций.</target>
        </trans-unit>
        <trans-unit id="f0d923ebaec99475dba3ff68622a8b582426df2b" translate="yes" xml:space="preserve">
          <source>Minimum Covariance Determinant Estimator</source>
          <target state="translated">Минимальный ковариационный детерминантный оценщик</target>
        </trans-unit>
        <trans-unit id="acdf76216ef7494ca3a405d1a4760970f1dcb045" translate="yes" xml:space="preserve">
          <source>Minimum correlation along the path. It corresponds to the regularization parameter alpha parameter in the Lasso.</source>
          <target state="translated">Минимальная корреляция по пути.Соответствует параметру регуляризации альфа-параметра в Лассо.</target>
        </trans-unit>
        <trans-unit id="45261c0e2275ffe7c782578b7e04c16d232cec64" translate="yes" xml:space="preserve">
          <source>Minimum number of candidates evaluated per estimator, assuming enough items meet the &lt;code&gt;min_hash_match&lt;/code&gt; constraint.</source>
          <target state="translated">Минимальное количество кандидатов, оцениваемых &lt;code&gt;min_hash_match&lt;/code&gt; оценщиком, при условии, что достаточное количество элементов соответствует ограничению min_hash_match .</target>
        </trans-unit>
        <trans-unit id="1f6032c543b0bedd4ef1a29303943c7332e81e08" translate="yes" xml:space="preserve">
          <source>Minimum number of samples chosen randomly from original data. Treated as an absolute number of samples for &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt;, treated as a relative number &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt;) for &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt;. This is typically chosen as the minimal number of samples necessary to estimate the given &lt;code&gt;base_estimator&lt;/code&gt;. By default a &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; estimator is assumed and &lt;code&gt;min_samples&lt;/code&gt; is chosen as &lt;code&gt;X.shape[1] + 1&lt;/code&gt;.</source>
          <target state="translated">Минимальное количество выборок, выбранных случайным образом из исходных данных. Рассматривается как абсолютное количество выборок для &lt;code&gt;min_samples &amp;gt;= 1&lt;/code&gt; , обрабатывается как относительное число &lt;code&gt;ceil(min_samples * X.shape[0]&lt;/code&gt; ) для &lt;code&gt;min_samples &amp;lt; 1&lt;/code&gt; . Обычно это выбирается как минимальное количество выборок, необходимое для оценки данного &lt;code&gt;base_estimator&lt;/code&gt; . По умолчанию предполагается &lt;code&gt;sklearn.linear_model.LinearRegression()&lt;/code&gt; а &lt;code&gt;min_samples&lt;/code&gt; выбирается как &lt;code&gt;X.shape[1] + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7055b8e6fba3c22d096f09a773f8fa2a0f2c2a45" translate="yes" xml:space="preserve">
          <source>Minimum number of samples in an OPTICS cluster, expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2). If &lt;code&gt;None&lt;/code&gt;, the value of &lt;code&gt;min_samples&lt;/code&gt; is used instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143330e48296c9730a85d5042f3f4108bc450e1a" translate="yes" xml:space="preserve">
          <source>Minimum number of samples in an OPTICS cluster, expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2). If &lt;code&gt;None&lt;/code&gt;, the value of &lt;code&gt;min_samples&lt;/code&gt; is used instead. Used only when &lt;code&gt;cluster_method='xi'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c28e0e254bdc137eed30061d47cd3e6720cfe75" translate="yes" xml:space="preserve">
          <source>Minimum possible imputed value. Broadcast to shape (n_features,) if scalar. If array-like, expects shape (n_features,), one min value for each feature. &lt;code&gt;None&lt;/code&gt; (default) is converted to -np.inf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a6bb55043794a0a93e8ff0524f08e79cbc35225" translate="yes" xml:space="preserve">
          <source>Minimum value of a bicluster.</source>
          <target state="translated">Минимальное значение билюстра.</target>
        </trans-unit>
        <trans-unit id="59e81ca4cbc76e95e029c93b9fa76bb8c2828a22" translate="yes" xml:space="preserve">
          <source>Minimum value of input array &lt;code&gt;X_&lt;/code&gt; for left bound.</source>
          <target state="translated">Минимальное значение входного массива &lt;code&gt;X_&lt;/code&gt; для левой границы.</target>
        </trans-unit>
        <trans-unit id="2b5d457149fe5be167ed99387c99dd4725835fe8" translate="yes" xml:space="preserve">
          <source>MinkowskiDistance</source>
          <target state="translated">MinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="8984ca78ae6f645a8da0469517e3e68a7c22986d" translate="yes" xml:space="preserve">
          <source>Mirroring the example above in grid search, we can specify a continuous random variable that is log-uniformly distributed between &lt;code&gt;1e0&lt;/code&gt; and &lt;code&gt;1e3&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3547bc4550b1de5a83615a3b3bc38cc23770ce0" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;class_log_prior_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Зеркала &lt;code&gt;class_log_prior_&lt;/code&gt; для интерпретации MultinomialNB как линейной модели.</target>
        </trans-unit>
        <trans-unit id="7814bd45bfd54f380e5f0cd3f0461e627752ef7b" translate="yes" xml:space="preserve">
          <source>Mirrors &lt;code&gt;feature_log_prob_&lt;/code&gt; for interpreting MultinomialNB as a linear model.</source>
          <target state="translated">Зеркала &lt;code&gt;feature_log_prob_&lt;/code&gt; для интерпретации MultinomialNB как линейной модели.</target>
        </trans-unit>
        <trans-unit id="5f2cbd107037ed23248e5058a7a64cd6bae05468" translate="yes" xml:space="preserve">
          <source>Miscellaneous</source>
          <target state="translated">Miscellaneous</target>
        </trans-unit>
        <trans-unit id="0d2ecb69e7b12979a3e40a5ab8b5183911f1a3c3" translate="yes" xml:space="preserve">
          <source>Miscellaneous and introductory examples for scikit-learn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26655e342820eb1000893c259228858eef67a34d" translate="yes" xml:space="preserve">
          <source>Missing Attribute Values</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e446df504bb1a7ba9afc2f86aa7e483abdbc1937" translate="yes" xml:space="preserve">
          <source>Missing Attribute Values:</source>
          <target state="translated">Пропущенные значения атрибутов:</target>
        </trans-unit>
        <trans-unit id="905705cdb93f7b29194485a892d91da6c1cdc874" translate="yes" xml:space="preserve">
          <source>Missing Value Imputation</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67cc34b1cd58b9ef03f7ff376e8541732aac180b" translate="yes" xml:space="preserve">
          <source>Missing information</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e00e76132a4d6b917901e5526c250a336a29108" translate="yes" xml:space="preserve">
          <source>Missing values can be replaced by the mean, the median or the most frequent value using the basic &lt;a href=&quot;../../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="391b82fea55e1ed8699fe6e91400e8d6055ab0df" translate="yes" xml:space="preserve">
          <source>Missing values can be replaced by the mean, the median or the most frequent value using the basic &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt;. The median is a more robust estimator for data with high magnitude variables which could dominate results (otherwise known as a &amp;lsquo;long tail&amp;rsquo;).</source>
          <target state="translated">Пропущенные значения могут быть заменены средним, медианным или наиболее частым значением с помощью базового &lt;a href=&quot;../modules/generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt; &lt;/a&gt; . Медиана является более надежной оценкой для данных с переменными высокой величины, которые могут доминировать в результатах (также известная как &amp;laquo;длинный хвост&amp;raquo;).</target>
        </trans-unit>
        <trans-unit id="7657a2d6545adb4955b10f53c4131bc5602e90eb" translate="yes" xml:space="preserve">
          <source>Missing values in the &amp;lsquo;data&amp;rsquo; are represented as NaN&amp;rsquo;s. Missing values in &amp;lsquo;target&amp;rsquo; are represented as NaN&amp;rsquo;s (numerical target) or None (categorical target)</source>
          <target state="translated">Отсутствующие значения в &amp;laquo;данных&amp;raquo; представлены как NaN. Отсутствующие значения в 'target' представлены как NaN (числовая цель) или None (категориальная цель)</target>
        </trans-unit>
        <trans-unit id="6a6932c856f91eed3dd44780fa6b9fe69490c4b8" translate="yes" xml:space="preserve">
          <source>Mixin class for all bicluster estimators in scikit-learn</source>
          <target state="translated">Класс микшина для всех оценщиков библлюстра в наушниках.</target>
        </trans-unit>
        <trans-unit id="2c10e3ce37d297d342507e753914a98859330d14" translate="yes" xml:space="preserve">
          <source>Mixin class for all classifiers in scikit-learn.</source>
          <target state="translated">Класс микшина для всех классификаторов в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="5fa39e3354bc95759f1ac752182b15d93d7771cd" translate="yes" xml:space="preserve">
          <source>Mixin class for all cluster estimators in scikit-learn.</source>
          <target state="translated">Класс микшина для всех кластерных оценок в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="eb8addc65b16d7fa21479da43bfb0ac745b8fd54" translate="yes" xml:space="preserve">
          <source>Mixin class for all density estimators in scikit-learn.</source>
          <target state="translated">Класс смешивания для всех оценщиков плотности в наукографе.</target>
        </trans-unit>
        <trans-unit id="6ac045bb154d5d0dbd1cc9d29eba911e1ea2781a" translate="yes" xml:space="preserve">
          <source>Mixin class for all regression estimators in scikit-learn.</source>
          <target state="translated">Класс Mixin для всех регрессионных оценок в Scikit-learn.</target>
        </trans-unit>
        <trans-unit id="f73bd7177b7212616f9ae4cd764e784bac6a7ce1" translate="yes" xml:space="preserve">
          <source>Mixin class for all transformers in scikit-learn.</source>
          <target state="translated">Класс микшина для всех трансформаторов в наукоемких исследованиях.</target>
        </trans-unit>
        <trans-unit id="4d9a44acff48ccb4a2b026d4835ebe86a95495fc" translate="yes" xml:space="preserve">
          <source>Model Complexity Influence</source>
          <target state="translated">Влияние сложности модели</target>
        </trans-unit>
        <trans-unit id="9c567347b8af7d91b331f07af5f77ec0a361f505" translate="yes" xml:space="preserve">
          <source>Model Selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d5e06ce8e5a0fb1e8e99aee47dbf3426de865fe" translate="yes" xml:space="preserve">
          <source>Model Selection Interface</source>
          <target state="translated">Интерфейс выбора модели</target>
        </trans-unit>
        <trans-unit id="d9b7f2bb0f8fc0d29940e1aefd1565fcc5b449f7" translate="yes" xml:space="preserve">
          <source>Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods.</source>
          <target state="translated">Смешивание моделей:когда предсказания одного контролируемого оценщика используются для обучения другого оценщика ансамблевым методам.</target>
        </trans-unit>
        <trans-unit id="c3b027b1bc55171725d0853107d2cd63b70cf1b0" translate="yes" xml:space="preserve">
          <source>Model complexity</source>
          <target state="translated">Сложность модели</target>
        </trans-unit>
        <trans-unit id="088cfdc97cd06f5c2647d7bc4d07170997a1804d" translate="yes" xml:space="preserve">
          <source>Model compression in scikit-learn only concerns linear models for the moment. In this context it means that we want to control the model sparsity (i.e. the number of non-zero coordinates in the model vectors). It is generally a good idea to combine model sparsity with sparse input data representation.</source>
          <target state="translated">Сжатие модели в Scikit-learn на данный момент относится только к линейным моделям.В этом контексте это означает,что мы хотим контролировать спектральность модели (т.е.количество ненулевых координат в векторах модели).Обычно хорошей идеей является сочетание ломкости модели с разреженным представлением входных данных.</target>
        </trans-unit>
        <trans-unit id="12cb4d758358636a28aab0195639a05c4c6adf09" translate="yes" xml:space="preserve">
          <source>Model persistence</source>
          <target state="translated">Сохранность модели</target>
        </trans-unit>
        <trans-unit id="c38101ec23202ddb2bcf9ed4925ad6d1c9181511" translate="yes" xml:space="preserve">
          <source>Model reshaping consists in selecting only a portion of the available features to fit a model. In other words, if a model discards features during the learning phase we can then strip those from the input. This has several benefits. Firstly it reduces memory (and therefore time) overhead of the model itself. It also allows to discard explicit feature selection components in a pipeline once we know which features to keep from a previous run. Finally, it can help reduce processing time and I/O usage upstream in the data access and feature extraction layers by not collecting and building features that are discarded by the model. For instance if the raw data come from a database, it can make it possible to write simpler and faster queries or reduce I/O usage by making the queries return lighter records. At the moment, reshaping needs to be performed manually in scikit-learn. In the case of sparse input (particularly in &lt;code&gt;CSR&lt;/code&gt; format), it is generally sufficient to not generate the relevant features, leaving their columns empty.</source>
          <target state="translated">Изменение формы модели заключается в выборе только части доступных функций для соответствия модели. Другими словами, если модель отбрасывает функции на этапе обучения, мы можем удалить их из входных данных. Это дает несколько преимуществ. Во-первых, это уменьшает накладные расходы на память (и, следовательно, время) самой модели. Это также позволяет отказаться от компонентов явного выбора функций в конвейере, если мы знаем, какие функции следует сохранить из предыдущего запуска. Наконец, это может помочь сократить время обработки и использование ввода-вывода в восходящем направлении на уровнях доступа к данным и извлечения признаков, поскольку не собирает и не создает объекты, которые отбрасываются моделью. Например, если необработанные данные поступают из базы данных, это может дать возможность писать более простые и быстрые запросы или уменьшить использование ввода-вывода, заставляя запросы возвращать более легкие записи. В данный момент,изменение формы необходимо выполнять вручную в scikit-learn. В случае разреженного ввода (особенно в &lt;code&gt;CSR&lt;/code&gt; Формат CSR ), как правило, достаточно не генерировать соответствующие функции, оставив их столбцы пустыми.</target>
        </trans-unit>
        <trans-unit id="28eeecfcba5c4e3a6c993b8bf2c6736730dfbd15" translate="yes" xml:space="preserve">
          <source>Model selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12aba00cd9b6d07b68e1c4795de07ac9d7b738d7" translate="yes" xml:space="preserve">
          <source>Model selection and evaluation using tools, such as &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;model_selection.cross_val_score&lt;/code&gt;&lt;/a&gt;, take a &lt;code&gt;scoring&lt;/code&gt; parameter that controls what metric they apply to the estimators evaluated.</source>
          <target state="translated">Выбор и оценка модели с использованием таких инструментов, как &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;model_selection.cross_val_score&lt;/code&gt; &lt;/a&gt; , принимают параметр &lt;code&gt;scoring&lt;/code&gt; который контролирует, какую метрику они применяют к оцениваемым оценщикам.</target>
        </trans-unit>
        <trans-unit id="855cd5c7a76f661266d80a6648a2f964caf6a19e" translate="yes" xml:space="preserve">
          <source>Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to &amp;ldquo;train&amp;rdquo; the parameters of the grid.</source>
          <target state="translated">Выбор модели путем оценки различных настроек параметров можно рассматривать как способ использования помеченных данных для &amp;laquo;обучения&amp;raquo; параметров сетки.</target>
        </trans-unit>
        <trans-unit id="89917070f2baaaaf3d7a4bc37b23fe9e19c05135" translate="yes" xml:space="preserve">
          <source>Model selection with Probabilistic PCA and Factor Analysis (FA)</source>
          <target state="translated">Выбор модели с вероятностным РСА и факторным анализом (ФА)</target>
        </trans-unit>
        <trans-unit id="96389a0f02a3826ae6017961d0301435c315a116" translate="yes" xml:space="preserve">
          <source>Model selection without nested CV uses the same data to tune model parameters and evaluate model performance. Information may thus &amp;ldquo;leak&amp;rdquo; into the model and overfit the data. The magnitude of this effect is primarily dependent on the size of the dataset and the stability of the model. See Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; for an analysis of these issues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c731d5ab6adf4a98df3f1383f23cf8f7eed3338" translate="yes" xml:space="preserve">
          <source>Model selection without nested CV uses the same data to tune model parameters and evaluate model performance. Information may thus &amp;ldquo;leak&amp;rdquo; into the model and overfit the data. The magnitude of this effect is primarily dependent on the size of the dataset and the stability of the model. See Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; for an analysis of these issues.</source>
          <target state="translated">Выбор модели без вложенного CV использует те же данные для настройки параметров модели и оценки производительности модели. Таким образом, информация может &amp;laquo;просочиться&amp;raquo; в модель и не соответствовать данным. Величина этого эффекта в первую очередь зависит от размера набора данных и стабильности модели. См. Cawley and Talbot &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; для анализа этих вопросов.</target>
        </trans-unit>
        <trans-unit id="74392d3518eac75d4c193fc75b5f4945cf9be3f9" translate="yes" xml:space="preserve">
          <source>Model selection: choosing estimators and their parameters</source>
          <target state="translated">Выбор модели:выбор оценщиков и их параметров</target>
        </trans-unit>
        <trans-unit id="ed1ba8eabae7e8d7de3d25705f2020f1428a1a11" translate="yes" xml:space="preserve">
          <source>Model the number of claims with a Poisson distribution, and the average claim amount per claim, also known as severity, as a Gamma distribution and multiply the predictions of both in order to get the total claim amount.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c9e82e3e8aa374bb01cb1f0583b83a3f30a27a0" translate="yes" xml:space="preserve">
          <source>Model the total claim amount per exposure directly, typically with a Tweedie distribution of Tweedie power \(p \in (1, 2)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad79a801df8015a66d5501cf36f7ffcd2a41ddf8" translate="yes" xml:space="preserve">
          <source>Model validation</source>
          <target state="translated">Проверка модели</target>
        </trans-unit>
        <trans-unit id="44e8839819f969bae0c352bffb18b8d9aae37a64" translate="yes" xml:space="preserve">
          <source>Modeling species&amp;rsquo; geographic distributions is an important problem in conservation biology. In this example we model the geographic distribution of two south american mammals given past observations and 14 environmental variables. Since we have only positive examples (there are no unsuccessful observations), we cast this problem as a density estimation problem and use the &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; as our modeling tool. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c7998384d3cc95ade6e27711f83c95af26806e" translate="yes" xml:space="preserve">
          <source>Modeling species&amp;rsquo; geographic distributions is an important problem in conservation biology. In this example we model the geographic distribution of two south american mammals given past observations and 14 environmental variables. Since we have only positive examples (there are no unsuccessful observations), we cast this problem as a density estimation problem and use the &lt;code&gt;OneClassSVM&lt;/code&gt; provided by the package &lt;code&gt;sklearn.svm&lt;/code&gt; as our modeling tool. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">Моделирование географического распределения видов - важная проблема природоохранной биологии. В этом примере мы моделируем географическое распределение двух южноамериканских млекопитающих с учетом прошлых наблюдений и 14 переменных окружающей среды. Поскольку у нас есть только положительные примеры (нет неудачных наблюдений), мы рассматриваем эту проблему как проблему оценки плотности и используем &lt;code&gt;OneClassSVM&lt;/code&gt; , предоставляемый пакетом &lt;code&gt;sklearn.svm&lt;/code&gt; ,в качестве инструмента моделирования. Набор данных предоставлен Phillips et. al. (2006). Если возможно, в примере используется &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;базовая карта&lt;/a&gt; для построения береговых линий и национальных границ Южной Америки.</target>
        </trans-unit>
        <trans-unit id="3432d8d9b44052d02847746ae08d1ac381072a89" translate="yes" xml:space="preserve">
          <source>Modified Huber: \(L(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))^2\) if \(y_i f(x_i) &amp;gt; 1\), and \(L(y_i, f(x_i)) = -4 y_i f(x_i)\) otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41be465b762359b2fa053c297894959404d2b4b5" translate="yes" xml:space="preserve">
          <source>Module &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt;&lt;code&gt;sklearn.kernel_ridge&lt;/code&gt;&lt;/a&gt; implements kernel ridge regression.</source>
          <target state="translated">Модуль &lt;a href=&quot;#module-sklearn.kernel_ridge&quot;&gt; &lt;code&gt;sklearn.kernel_ridge&lt;/code&gt; &lt;/a&gt; реализует регрессию гребня ядра.</target>
        </trans-unit>
        <trans-unit id="7c19bb73223842069c348f5ce2be56f6bdc47336" translate="yes" xml:space="preserve">
          <source>Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">Импульс для обновления градиентного спуска. Должно быть от 0 до 1. Используется только когда solver = 'sgd'.</target>
        </trans-unit>
        <trans-unit id="08837633f9d15f78a0ca0401b5e29aae44a3cb25" translate="yes" xml:space="preserve">
          <source>Monotonic Constraints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afdb29f8a2a5c8088f948d58228ab92ec4b8dbc8" translate="yes" xml:space="preserve">
          <source>Moosmann, F. and Triggs, B. and Jurie, F. &amp;ldquo;Fast discriminative visual codebooks using randomized clustering forests&amp;rdquo; NIPS 2007</source>
          <target state="translated">Моосманн, Ф., Триггс, Б. и Джури, Ф. &amp;laquo;Быстрые дискриминативные визуальные кодовые книги с использованием рандомизированных лесов кластеризации&amp;raquo; NIPS 2007</target>
        </trans-unit>
        <trans-unit id="3f683b2b5fe59dc7e9963e0b844a2be959abe1bd" translate="yes" xml:space="preserve">
          <source>More details about the losses formulas can be found in the &lt;a href=&quot;../sgd#sgd-mathematical-formulation&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea951c164724999b1e82491617fa7550c41c4ea4" translate="yes" xml:space="preserve">
          <source>More details can be found in the article &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Bayesian Interpolation&lt;/a&gt; by MacKay, David J. C.</source>
          <target state="translated">Более подробную информацию можно найти в статье &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9072&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Байесовская интерполяция&lt;/a&gt; Маккея, Дэвида Дж. К.</target>
        </trans-unit>
        <trans-unit id="3dd8319d03052df7074a6e0643293f5dc781d510" translate="yes" xml:space="preserve">
          <source>More details can be found in the documentation of &lt;a href=&quot;http://scikit-learn.org/stable/modules/sgd.html&quot;&gt;SGD&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5be68ba5f49b8c23c2004cef7b8f1738816fd7ff" translate="yes" xml:space="preserve">
          <source>More details can be found in the documentation of &lt;a href=&quot;sgd&quot;&gt;SGD&lt;/a&gt;</source>
          <target state="translated">Более подробную информацию можно найти в документации &lt;a href=&quot;sgd&quot;&gt;SGD.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="eeddded239db4ba79d40ed239189aa60eea25acb" translate="yes" xml:space="preserve">
          <source>More details on tools available for model selection can be found in the sections on &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; and &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">Более подробную информацию об инструментах, доступных для выбора модели, можно найти в разделах &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;Перекрестная проверка: оценка производительности оценщика&lt;/a&gt; и &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Настройка гиперпараметров оценщика&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d431b615f9733586de025b4f9872bf1a8badc9bd" translate="yes" xml:space="preserve">
          <source>More formally, the responsibility of a sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Более формально,ответственность за образец \(k\)как за образец \(i\)возложена на него:</target>
        </trans-unit>
        <trans-unit id="e5fcb8eb05185b2ae6a7561ecfd54e7e78d1825d" translate="yes" xml:space="preserve">
          <source>More formally, we define a core sample as being a sample in the dataset such that there exist &lt;code&gt;min_samples&lt;/code&gt; other samples within a distance of &lt;code&gt;eps&lt;/code&gt;, which are defined as &lt;em&gt;neighbors&lt;/em&gt; of the core sample. This tells us that the core sample is in a dense area of the vector space. A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of &lt;em&gt;their&lt;/em&gt; neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.</source>
          <target state="translated">Более формально, мы определяем образец керна как образец в наборе данных, так что существуют &lt;code&gt;min_samples&lt;/code&gt; другие образцы на расстоянии &lt;code&gt;eps&lt;/code&gt; , которые определены как &lt;em&gt;соседи&lt;/em&gt; с образцом керна. Это говорит нам о том, что основной образец находится в плотной области векторного пространства. Кластер - это набор образцов керна, который может быть создан путем рекурсивного взятия образца керна, поиска всех его соседей, которые являются образцами керна, поиска всех &lt;em&gt;их&lt;/em&gt; соседей, которые являются образцами керна, и так далее. Кластер также имеет набор неосновных выборок, которые представляют собой выборки, которые являются соседями керновой выборки в кластере, но не являются сами по себе образцами керна. Интуитивно эти образцы находятся на периферии кластера.</target>
        </trans-unit>
        <trans-unit id="39d3fe53d51c5218d78f036015830e2502c27f2b" translate="yes" xml:space="preserve">
          <source>More generally, when the accuracy of a classifier is too close to random, it probably means that something went wrong: features are not helpful, a hyperparameter is not correctly tuned, the classifier is suffering from class imbalance, etc&amp;hellip;</source>
          <target state="translated">В более общем плане, когда точность классификатора слишком близка к случайной, это, вероятно, означает, что что-то пошло не так: функции бесполезны, гиперпараметр настроен неправильно, классификатор страдает от дисбаланса классов и т. Д.</target>
        </trans-unit>
        <trans-unit id="63b4a4241c78c35e803f9a1e6a808d1813f2fb30" translate="yes" xml:space="preserve">
          <source>More information can be found on the &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;Scipy install page&lt;/a&gt; and in this &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;blog post&lt;/a&gt; from Daniel Nouri which has some nice step by step install instructions for Debian / Ubuntu.</source>
          <target state="translated">Дополнительную информацию можно найти на &lt;a href=&quot;http://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;странице установки Scipy&lt;/a&gt; и в этом &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;сообщении&lt;/a&gt; в блоге Даниэля Нури, в котором есть несколько хороших пошаговых инструкций по установке для Debian / Ubuntu.</target>
        </trans-unit>
        <trans-unit id="c3cc4720813506dbf91cef9b68d3a09728559160" translate="yes" xml:space="preserve">
          <source>More information can be found on the &lt;a href=&quot;https://docs.scipy.org/doc/numpy/user/install.html&quot;&gt;Scipy install page&lt;/a&gt; and in this &lt;a href=&quot;http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/&quot;&gt;blog post&lt;/a&gt; from Daniel Nouri which has some nice step by step install instructions for Debian / Ubuntu.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d4e98f0a8d8595ea60691c38a1427dece6499fb" translate="yes" xml:space="preserve">
          <source>More metadata from OpenML</source>
          <target state="translated">Больше метаданных из OpenML</target>
        </trans-unit>
        <trans-unit id="12db8232292ca8d1cf35bc6b9168f2c8b63d47ca" translate="yes" xml:space="preserve">
          <source>More precisely its the expectation of the target response after accounting for the initial model; partial dependence plots do not include the &lt;code&gt;init&lt;/code&gt; model.</source>
          <target state="translated">Точнее, это ожидание целевого отклика после учета исходной модели; графики частичных зависимостей не включают модель &lt;code&gt;init&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="73794f226fb348eb5da6ad63afeb16cb41727d95" translate="yes" xml:space="preserve">
          <source>More readable code, in particular since it avoids constructing list of arguments.</source>
          <target state="translated">Более читабельный код,в частности,поскольку он позволяет избежать построения списка аргументов.</target>
        </trans-unit>
        <trans-unit id="a22dda2285328f04695cb396d42b64909dfc0d90" translate="yes" xml:space="preserve">
          <source>More specifically, for linear and quadratic discriminant analysis, \(P(X|y)\) is modeled as a multivariate Gaussian distribution with density:</source>
          <target state="translated">Точнее,для линейного и квадратичного дискриминантного анализа \(P(X|y)\)смоделировано многомерное гауссово распределение с плотностью:</target>
        </trans-unit>
        <trans-unit id="2b3cb69cb34819cd8834522c11758ddc50e1f474" translate="yes" xml:space="preserve">
          <source>More specifically, for linear and quadratic discriminant analysis, \(P(x|y)\) is modeled as a multivariate Gaussian distribution with density:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79ecb6d9275fdfeccdbd69d6aa3919b92952032e" translate="yes" xml:space="preserve">
          <source>Most commonly, disparities are set to \(\hat{d}_{ij} = b S_{ij}\).</source>
          <target state="translated">Чаще всего диспропорции устанавливаются по адресу \(\hat{d}_{ij}=b S_{ij}\).</target>
        </trans-unit>
        <trans-unit id="242544fc56d0b5c7cafd51d576a4b175219e1770" translate="yes" xml:space="preserve">
          <source>Most estimators based on nearest neighbors graphs now accept precomputed sparse graphs as input, to reuse the same graph for multiple estimator fits. To use this feature in a pipeline, one can use the &lt;code&gt;memory&lt;/code&gt; parameter, along with one of the two new transformers, &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;neighbors.KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.neighbors.radiusneighborstransformer#sklearn.neighbors.RadiusNeighborsTransformer&quot;&gt;&lt;code&gt;neighbors.RadiusNeighborsTransformer&lt;/code&gt;&lt;/a&gt;. The precomputation can also be performed by custom estimators to use alternative implementations, such as approximate nearest neighbors methods. See more details in the &lt;a href=&quot;../../modules/neighbors#neighbors-transformer&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44814fa11b1099a09b484290756712e9a8679a34" translate="yes" xml:space="preserve">
          <source>Most of the parameters are unchanged from &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. One exception is the &lt;code&gt;max_iter&lt;/code&gt; parameter that replaces &lt;code&gt;n_estimators&lt;/code&gt;, and controls the number of iterations of the boosting process:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13411f05832555677b503d8db5e64b4930c99086" translate="yes" xml:space="preserve">
          <source>Most of the variance can be explained by a bell-shaped curve of width effective_rank: the low rank part of the singular values profile is:</source>
          <target state="translated">Большую часть дисперсии можно объяснить колоколообразной кривой ширины effective_rank:низкая ранговая часть профиля единичных значений:</target>
        </trans-unit>
        <trans-unit id="9a311c70d6fa85e99fb6533c84253a4d2c760cf7" translate="yes" xml:space="preserve">
          <source>Most scikit-learn models are usually pretty fast as they are implemented either with compiled Cython extensions or optimized computing libraries. On the other hand, in many real world applications the feature extraction process (i.e. turning raw data like database rows or network packets into numpy arrays) governs the overall prediction time. For example on the Reuters text classification task the whole preparation (reading and parsing SGML files, tokenizing the text and hashing it into a common vector space) is taking 100 to 500 times more time than the actual prediction code, depending on the chosen model.</source>
          <target state="translated">Большинство scikit-learn моделей обычно довольно быстры,так как они реализованы либо скомпилированными расширениями Cython,либо оптимизированными вычислительными библиотеками.С другой стороны,во многих реальных приложениях процесс извлечения функций (т.е.превращение необработанных данных,таких как строки базы данных или сетевые пакеты,в нумерованные массивы)управляет общим временем прогнозирования.Например,по задаче классификации текста Reuters вся подготовка (чтение и разбор SGML-файлов,токенирование текста и хэширование его в общее векторное пространство)занимает в 100-500 раз больше времени,чем реальный код прогнозирования,в зависимости от выбранной модели.</target>
        </trans-unit>
        <trans-unit id="1f57c7d2294fbf421c865e0ff805433c9e9164a6" translate="yes" xml:space="preserve">
          <source>Most treatments of LSA in the natural language processing (NLP) and information retrieval (IR) literature swap the axes of the matrix \(X\) so that it has shape &lt;code&gt;n_features&lt;/code&gt; &amp;times; &lt;code&gt;n_samples&lt;/code&gt;. We present LSA in a different way that matches the scikit-learn API better, but the singular values found are the same.</source>
          <target state="translated">В большинстве трактовок LSA в литературе по обработке естественного языка (NLP) и информационному поиску (IR) оси матрицы \ (X \) &lt;code&gt;n_features&lt;/code&gt; &lt;code&gt;n_samples&lt;/code&gt; так что она имеет форму n_features &amp;times; n_samples . Мы представляем LSA другим способом, который лучше соответствует API scikit-learn, но найденные единичные значения такие же.</target>
        </trans-unit>
        <trans-unit id="56ac69cc3d5e8e713d723baf0656a6eefef8f81b" translate="yes" xml:space="preserve">
          <source>Multi target classification</source>
          <target state="translated">Многоцелевая классификация</target>
        </trans-unit>
        <trans-unit id="b9b406b23aa7207ecf1f2aef41fc5c5ad0ba0c31" translate="yes" xml:space="preserve">
          <source>Multi target regression</source>
          <target state="translated">Многоцелевая регрессия</target>
        </trans-unit>
        <trans-unit id="332c064d1606c8de1a2522f9e4ee668dee56478e" translate="yes" xml:space="preserve">
          <source>Multi-class AdaBoosted Decision Trees</source>
          <target state="translated">Многоклассные AdaBoosted деревья принятия решений</target>
        </trans-unit>
        <trans-unit id="d384b7095ac166d1b587c1dafb0cadad28beb4c2" translate="yes" xml:space="preserve">
          <source>Multi-class targets.</source>
          <target state="translated">Многоклассные цели.</target>
        </trans-unit>
        <trans-unit id="3243798e9c1a783043187bb0ea60ba4b8d0dfc62" translate="yes" xml:space="preserve">
          <source>Multi-class targets. An indicator matrix turns on multilabel classification.</source>
          <target state="translated">Многоклассные цели.Матрица индикаторов включает многомаркировочную классификацию.</target>
        </trans-unit>
        <trans-unit id="552ba9a8fb8ef0b9cf8d9ea68e7f0c182ae9af5e" translate="yes" xml:space="preserve">
          <source>Multi-dimensional scaling</source>
          <target state="translated">Многомерное масштабирование</target>
        </trans-unit>
        <trans-unit id="9815dac6e8971893d838904dc7e1cfe16372af94" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron classifier.</source>
          <target state="translated">Многослойный перцептронный классификатор.</target>
        </trans-unit>
        <trans-unit id="b994a134c1a31489af71fc772bdcadb38a217ddf" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the &lt;em&gt;same&lt;/em&gt; scaling to the test set for meaningful results. You can use &lt;code&gt;StandardScaler&lt;/code&gt; for standardization.</source>
          <target state="translated">Многослойный персептрон чувствителен к масштабированию функций, поэтому настоятельно рекомендуется масштабировать ваши данные. Например, масштабируйте каждый атрибут во входном векторе X до [0, 1] или [-1, +1] или стандартизируйте его, чтобы иметь среднее значение 0 и дисперсию 1. Обратите внимание, что вы должны применить такое &lt;em&gt;же&lt;/em&gt; масштабирование к набору тестов для значимые результаты. Вы можете использовать &lt;code&gt;StandardScaler&lt;/code&gt; для стандартизации.</target>
        </trans-unit>
        <trans-unit id="8b22895cdf3840f5acfe1ac32cbc8961e8fd336a" translate="yes" xml:space="preserve">
          <source>Multi-layer Perceptron regressor.</source>
          <target state="translated">Многослойный перцептронный регрессор.</target>
        </trans-unit>
        <trans-unit id="dc72474a07afc8bb8057ac9bf6d8fbc65e56a63e" translate="yes" xml:space="preserve">
          <source>Multi-output Decision Tree Regression</source>
          <target state="translated">Регрессия дерева решений с несколькими выходами</target>
        </trans-unit>
        <trans-unit id="2627f8f7a5d9294ea8dcfe47a04508977edd8f7c" translate="yes" xml:space="preserve">
          <source>Multi-output targets predicted across multiple predictors. Note: Separate models are generated for each predictor.</source>
          <target state="translated">Множественные цели,предсказанные с помощью нескольких предикторов.Примечание:Для каждого предиктора создаются отдельные модели.</target>
        </trans-unit>
        <trans-unit id="4da1e42d60732d934b60458ac859ed1253e6bfbd" translate="yes" xml:space="preserve">
          <source>Multi-output targets.</source>
          <target state="translated">Многоцелевые цели.</target>
        </trans-unit>
        <trans-unit id="d25d7d780166f0481648cccd463a78a5e417f6f3" translate="yes" xml:space="preserve">
          <source>Multi-output targets. An indicator matrix turns on multilabel estimation.</source>
          <target state="translated">Многоцелевые цели.Матрица индикаторов включает многомаркировочную оценку.</target>
        </trans-unit>
        <trans-unit id="775030d60513b2f729789206b06d021b6661e16d" translate="yes" xml:space="preserve">
          <source>Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Многозадачная модель ElasticNet,обученная с L1/L2 смешанной формой как регуляризатор</target>
        </trans-unit>
        <trans-unit id="7259143bf01ac8062e2b5725644f1e005f808315" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 ElasticNet with built-in cross-validation.</source>
          <target state="translated">Многозадачная L1/L2 ElasticNet со встроенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="5c1ad40e838b03e514631adae1736168414d6605" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation</source>
          <target state="translated">Многозадачный L1/L2 Лассо со встроенной кросс-проверкой</target>
        </trans-unit>
        <trans-unit id="a743aa48cf046a15087b0f4886f436159c359dd5" translate="yes" xml:space="preserve">
          <source>Multi-task L1/L2 Lasso with built-in cross-validation.</source>
          <target state="translated">Многозадачный L1/L2 Lasso со встроенной перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="6377873684d0ac47f9792cf0130c074e6b5d5c8f" translate="yes" xml:space="preserve">
          <source>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer</source>
          <target state="translated">Многозадачная модель Лассо,обученная с L1/L2 смешанной формы в качестве регулятора</target>
        </trans-unit>
        <trans-unit id="162889b9c309e59105e244387d111bbb75ed4cc7" translate="yes" xml:space="preserve">
          <source>Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0119eef45392f9d57273a8cd6ca2fcc5f0003969" translate="yes" xml:space="preserve">
          <source>Multi-task linear regressors with variable selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="669e809a0e7044a9302d0da3188c44feddafe180" translate="yes" xml:space="preserve">
          <source>Multiclass and multilabel classification strategies</source>
          <target state="translated">Стратегии классификации по нескольким классам и многомаркировке</target>
        </trans-unit>
        <trans-unit id="8ddfaa46f2a114c89c7cad99fd0ddf4dc7314399" translate="yes" xml:space="preserve">
          <source>Multiclass case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="957cc5ae23e389ffa9c767fc16d7ac37036b0153" translate="yes" xml:space="preserve">
          <source>Multiclass classification</source>
          <target state="translated">Классификация по нескольким классам</target>
        </trans-unit>
        <trans-unit id="868117baea7dbed0e92972aac1d890c07c8ae48f" translate="yes" xml:space="preserve">
          <source>Multiclass data will be treated as if binarized under a one-vs-rest transformation. Returned confusion matrices will be in the order of sorted unique labels in the union of (y_true, y_pred).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d8780a18f5ba3e6cb5bb5a579ea67a8f2550bb3" translate="yes" xml:space="preserve">
          <source>Multiclass only. Determines the type of configuration to use. The default value raises an error, so either &lt;code&gt;'ovr'&lt;/code&gt; or &lt;code&gt;'ovo'&lt;/code&gt; must be passed explicitly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6acefc7f4185f0f4df5b1178aaed55afe1147ed" translate="yes" xml:space="preserve">
          <source>Multiclass only. List of labels that index the classes in &lt;code&gt;y_score&lt;/code&gt;. If &lt;code&gt;None&lt;/code&gt;, the numerical or lexicographical order of the labels in &lt;code&gt;y_true&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f43fb647f0e5eccf5a3760b6eafe5e21b79a50a6" translate="yes" xml:space="preserve">
          <source>Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan.</source>
          <target state="translated">Многоклассные вероятностные оценки получены из бинарных (однопроцентных)оценок путем простой нормализации,как рекомендуют Задрозный и Элкан.</target>
        </trans-unit>
        <trans-unit id="39d0ca41499d6b7f83a17678aedf5fae33705c06" translate="yes" xml:space="preserve">
          <source>Multiclass problems are binarized and treated like the corresponding multilabel problem:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3debc5753cd55840fa65a540929e237591ad2faf" translate="yes" xml:space="preserve">
          <source>Multiclass settings</source>
          <target state="translated">Многоклассовые настройки</target>
        </trans-unit>
        <trans-unit id="e3f8736465f26b4a50bfa9739f8adbcfb24ccc56" translate="yes" xml:space="preserve">
          <source>Multiclass sparse logisitic regression on newgroups20</source>
          <target state="translated">Многоклассная разреженная логистическая регрессия на новых группах20</target>
        </trans-unit>
        <trans-unit id="abed0a03e9d2180975b0a68aad7dbbccddc0d2d0" translate="yes" xml:space="preserve">
          <source>Multiclass sparse logistic regression on 20newgroups</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38a70920d0cd2001f4ef8f9ee41dfa6b122f018c" translate="yes" xml:space="preserve">
          <source>Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</source>
          <target state="translated">Мультиклассовая спектральная кластеризация, 2003 г. Stella X. Yu, Jianbo Shi &lt;a href=&quot;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;http://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4386a05880a13b860ce6d4571568b773373f22e3" translate="yes" xml:space="preserve">
          <source>Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi &lt;a href=&quot;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&quot;&gt;https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5d0b14c4e8dd95e44e1cd37847a8b6674049750" translate="yes" xml:space="preserve">
          <source>Multiclass vs. multilabel fitting</source>
          <target state="translated">Фитинг мультикласса против многомаркировочного фитинга</target>
        </trans-unit>
        <trans-unit id="dbc4079d7d6495ef3cfc4fdaba01141075b60d89" translate="yes" xml:space="preserve">
          <source>Multidimensional scaling</source>
          <target state="translated">Многомерное масштабирование</target>
        </trans-unit>
        <trans-unit id="7c33b81ffc3ca04c62af4f5074ba33e510028ebd" translate="yes" xml:space="preserve">
          <source>Multilabel classification</source>
          <target state="translated">Многомаркировочная классификация</target>
        </trans-unit>
        <trans-unit id="c720ba81272f13af125e464e56bd5648c8146ada" translate="yes" xml:space="preserve">
          <source>Multilabel ranking metrics</source>
          <target state="translated">Многомаркировочные метрики ранга</target>
        </trans-unit>
        <trans-unit id="ce79d912af81c5a374445c22e6e3cfe9ecb9a93c" translate="yes" xml:space="preserve">
          <source>Multilabel-indicator case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6031d58e46d313eca93045d9598faea168256f9" translate="yes" xml:space="preserve">
          <source>Multimetric scoring can either be specified as a list of strings of predefined scores names or a dict mapping the scorer name to the scorer function and/or the predefined scorer name(s). See &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Using multiple metric evaluation&lt;/a&gt; for more details.</source>
          <target state="translated">Мультиметрическая оценка может быть указана либо в виде списка строк с предварительно определенными именами оценок, либо в виде словаря, сопоставляющего имя счетчика с функцией счетчика и / или предварительно определенным именем (именами) счетчика. Дополнительные сведения см. В разделе &lt;a href=&quot;model_evaluation#multimetric-scoring&quot;&gt;Использование множественной метрической оценки&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="71e5ed6f7fb13f64a7d1e47fd6ffef12dfd5580e" translate="yes" xml:space="preserve">
          <source>Multinomial + L1 penalty</source>
          <target state="translated">Мультиномиальный+L1 штраф</target>
        </trans-unit>
        <trans-unit id="82d79c421161a2e0a31300a79127c9804ae62ed5" translate="yes" xml:space="preserve">
          <source>Multinomial + L2 penalty</source>
          <target state="translated">Мультиномиальный+L2 штраф</target>
        </trans-unit>
        <trans-unit id="efccef2252a812759badf849dd9e2acd4cd7eb95" translate="yes" xml:space="preserve">
          <source>Multinomial deviance (&lt;code&gt;'deviance'&lt;/code&gt;): The negative multinomial log-likelihood loss function for multi-class classification with &lt;code&gt;n_classes&lt;/code&gt; mutually exclusive classes. It provides probability estimates. The initial model is given by the prior probability of each class. At each iteration &lt;code&gt;n_classes&lt;/code&gt; regression trees have to be constructed which makes GBRT rather inefficient for data sets with a large number of classes.</source>
          <target state="translated">Полиномиальное отклонение ( &lt;code&gt;'deviance'&lt;/code&gt; ): отрицательная полиномиальная функция потерь логарифма правдоподобия для мультиклассовой классификации с &lt;code&gt;n_classes&lt;/code&gt; взаимоисключающими классами. Он предоставляет оценки вероятности. Исходная модель задается априорной вероятностью каждого класса. На каждой итерации должны быть построены деревья регрессии &lt;code&gt;n_classes&lt;/code&gt; , что делает GBRT довольно неэффективным для наборов данных с большим количеством классов.</target>
        </trans-unit>
        <trans-unit id="313293589005fec34a4137f7e7a462e44753a91e" translate="yes" xml:space="preserve">
          <source>Multioutput classification support can be added to any classifier with &lt;code&gt;MultiOutputClassifier&lt;/code&gt;. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3&amp;hellip;,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3&amp;hellip;,yn).</source>
          <target state="translated">Поддержка классификации с несколькими выходами может быть добавлена ​​к любому классификатору с помощью &lt;code&gt;MultiOutputClassifier&lt;/code&gt; . Эта стратегия состоит из подбора одного классификатора для каждой цели. Это позволяет несколько классификаций целевых переменных. Цель этого класса - расширить оценщики, чтобы иметь возможность оценивать серию целевых функций (f1, f2, f3&amp;hellip;, fn), которые обучаются на одной матрице предикторов X для прогнозирования серии ответов (y1, y2, y3 &amp;hellip;, Уп).</target>
        </trans-unit>
        <trans-unit id="8ec2d1e390ee85463a8b9edc1df8f6a33597454a" translate="yes" xml:space="preserve">
          <source>Multioutput methods</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e7bfb83db794fa15648cd7ab3b23c509cc8018c" translate="yes" xml:space="preserve">
          <source>Multioutput regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="086b68ade408f93caaac80f71e1eabb4cc44f3fd" translate="yes" xml:space="preserve">
          <source>Multioutput regression support can be added to any regressor with &lt;code&gt;MultiOutputRegressor&lt;/code&gt;. This strategy consists of fitting one regressor per target. Since each target is represented by exactly one regressor it is possible to gain knowledge about the target by inspecting its corresponding regressor. As &lt;code&gt;MultiOutputRegressor&lt;/code&gt; fits one regressor per target it can not take advantage of correlations between targets.</source>
          <target state="translated">Поддержка множественной регрессии может быть добавлена ​​к любому регрессору с помощью &lt;code&gt;MultiOutputRegressor&lt;/code&gt; . Эта стратегия состоит из подбора одного регрессора для каждой цели. Поскольку каждая цель представлена ​​ровно одним регрессором, можно получить информацию о цели, проверив соответствующий регрессор. Поскольку &lt;code&gt;MultiOutputRegressor&lt;/code&gt; соответствует одному регрессору для каждой цели, он не может использовать преимущества корреляции между целями.</target>
        </trans-unit>
        <trans-unit id="96d87119823da5637cea208be6276fad5c922737" translate="yes" xml:space="preserve">
          <source>Multioutput- multiclass classification</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96e252b1f2ecf6cba5d585af259eddb308663e2e" translate="yes" xml:space="preserve">
          <source>Multiple metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt; (please refer the &lt;code&gt;scoring&lt;/code&gt; parameter doc for more information)</source>
          <target state="translated">Оценка множественных показателей с использованием &lt;code&gt;cross_validate&lt;/code&gt; ( дополнительную информацию см. В документации по параметрам &lt;code&gt;scoring&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="629b6c06ee9b92eec539c00c0d5b033d1b11a26d" translate="yes" xml:space="preserve">
          <source>Multiple metric parameter search can be done by setting the &lt;code&gt;scoring&lt;/code&gt; parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables.</source>
          <target state="translated">Поиск по нескольким параметрам метрики может быть выполнен путем установки параметра &lt;code&gt;scoring&lt;/code&gt; в список имен счетчиков метрик или словаря, сопоставляющего имена счетчиков с вызываемыми счетчиками.</target>
        </trans-unit>
        <trans-unit id="24f6a3478d65f4dead755fd18d3792f81fa6260d" translate="yes" xml:space="preserve">
          <source>Multiple stacking layers can be achieved by assigning &lt;code&gt;final_estimator&lt;/code&gt; to a &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85ae0fa16a20d62aa04d6b821cea2aa9547567a2" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. Keys are transformer names, values the weights.</source>
          <target state="translated">Мультипликативный вес для каждого трансформатора.Ключи-это названия трансформаторов,значения весов.</target>
        </trans-unit>
        <trans-unit id="0634d761605b2ffdac7cc3b47cb937d2911bb7fc" translate="yes" xml:space="preserve">
          <source>Multiplicative weights for features per transformer. The output of the transformer is multiplied by these weights. Keys are transformer names, values the weights.</source>
          <target state="translated">Мультипликативный вес для каждого трансформатора.Выходная мощность трансформатора умножается на эти веса.Ключами являются названия трансформаторов,значения весов.</target>
        </trans-unit>
        <trans-unit id="afa1ae58a55a69631c4c27e76dfc260c619f73c7" translate="yes" xml:space="preserve">
          <source>Multipliers of parameter C for each class. Computed based on the &lt;code&gt;class_weight&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0e900a51b93880c89d198a9d719bd1f20cdb329" translate="yes" xml:space="preserve">
          <source>Multipliers of parameter C of each class. Computed based on the &lt;code&gt;class_weight&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f4f1f6c0e0110908215d6d402a5fd0376794171" translate="yes" xml:space="preserve">
          <source>Multiply features by the specified value. If None, then features are scaled by a random value drawn in [1, 100]. Note that scaling happens after shifting.</source>
          <target state="translated">Умножьте характеристики на указанное значение.Если Нет,то функции масштабируются на случайное значение,записанное в [1,100].Обратите внимание,что масштабирование происходит после сдвига.</target>
        </trans-unit>
        <trans-unit id="d54881ba1eca5e77240b1b917c4b4af86c4398ba" translate="yes" xml:space="preserve">
          <source>Multiplying the coefficients by the standard deviation of the related feature would reduce all the coefficients to the same unit of measure. As we will see &lt;a href=&quot;#scaling-num&quot;&gt;after&lt;/a&gt; this is equivalent to normalize numerical variables to their standard deviation, as \(y = \sum{coef_i \times X_i} = \sum{(coef_i \times std_i) \times (X_i / std_i)}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="773db00cec71fc706de69e832dff6b23a68d6b97" translate="yes" xml:space="preserve">
          <source>Multithreaded BLAS libraries sometimes conflict with Python&amp;rsquo;s &lt;code&gt;multiprocessing&lt;/code&gt; module, which is used by e.g. &lt;code&gt;GridSearchCV&lt;/code&gt; and most other estimators that take an &lt;code&gt;n_jobs&lt;/code&gt; argument (with the exception of &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;SGDRegressor&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; and tree-based methods such as random forests). This is true of Apple&amp;rsquo;s Accelerate and OpenBLAS when built with OpenMP support.</source>
          <target state="translated">Многопоточные библиотеки BLAS иногда конфликтуют с модулем &lt;code&gt;multiprocessing&lt;/code&gt; Python , который используется, например, &lt;code&gt;GridSearchCV&lt;/code&gt; и большинством других оценщиков, принимающих аргумент &lt;code&gt;n_jobs&lt;/code&gt; (за исключением &lt;code&gt;SGDClassifier&lt;/code&gt; , &lt;code&gt;SGDRegressor&lt;/code&gt; , &lt;code&gt;Perceptron&lt;/code&gt; , &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; и древовидных методов, таких как случайные леса). Это верно для Apple Accelerate и OpenBLAS, когда они созданы с поддержкой OpenMP.</target>
        </trans-unit>
        <trans-unit id="3483a919f49e511ca829411c285a74281e005ef3" translate="yes" xml:space="preserve">
          <source>Multivariate imputation of missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e386b49678343bab915e96a29e16b2a1aa09993" translate="yes" xml:space="preserve">
          <source>Multivariate imputer that estimates each feature from all the others.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="425dc1fa519b0f6261993bae28e1ad51c131bb66" translate="yes" xml:space="preserve">
          <source>Must be provided at the first call to partial_fit, can be omitted in subsequent calls.</source>
          <target state="translated">Должен предоставляться при первом вызове на partial_fit,может быть опущен при последующих вызовах.</target>
        </trans-unit>
        <trans-unit id="b6845c300d4f945b800f2e50de745703cc5cc891" translate="yes" xml:space="preserve">
          <source>Must fulfill the input assumptions of the underlying estimator.</source>
          <target state="translated">Должны соответствовать исходным допущениям базового оценщика.</target>
        </trans-unit>
        <trans-unit id="214188886e4a84a8788bdd82b6f8744f5146fead" translate="yes" xml:space="preserve">
          <source>Mutual Information (not adjusted for chance)</source>
          <target state="translated">Взаимная информация (не скорректированная с учетом случайности)</target>
        </trans-unit>
        <trans-unit id="16b7cc0e7a5234ba809ed1e09a3a8960dff39693" translate="yes" xml:space="preserve">
          <source>Mutual Information between two clusterings.</source>
          <target state="translated">Взаимная информация между двумя кластерами.</target>
        </trans-unit>
        <trans-unit id="81e08bee8a8968c08bd07aed8cef44d9fb7a13f3" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">Взаимная информация (MI) &lt;a href=&quot;#r37d39d7589e2-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; между двумя случайными величинами - это неотрицательное значение, которое измеряет зависимость между переменными. Он равен нулю тогда и только тогда, когда две случайные величины независимы, а более высокие значения означают более высокую зависимость.</target>
        </trans-unit>
        <trans-unit id="92d0e5dc6672a19ad8c5b9523b6a6d1a9b82c89e" translate="yes" xml:space="preserve">
          <source>Mutual information (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.</source>
          <target state="translated">Взаимная информация (MI) &lt;a href=&quot;#r50b872b699c4-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; между двумя случайными величинами - это неотрицательное значение, которое измеряет зависимость между переменными. Он равен нулю тогда и только тогда, когда две случайные величины независимы, а более высокие значения означают более высокую зависимость.</target>
        </trans-unit>
        <trans-unit id="4276bd70be44db9c6fb9548906a97ab826aba297" translate="yes" xml:space="preserve">
          <source>Mutual information between features and the target.</source>
          <target state="translated">Взаимная информация между функциями и целью.</target>
        </trans-unit>
        <trans-unit id="33ca9360bf5453bcb4bf9aed03e658f161f23932" translate="yes" xml:space="preserve">
          <source>Mutual information for a continuous target.</source>
          <target state="translated">Взаимная информация для постоянной цели.</target>
        </trans-unit>
        <trans-unit id="aa199ad103c044c23c4e2e0edbe572bad088827c" translate="yes" xml:space="preserve">
          <source>Mutual information for a contnuous target.</source>
          <target state="translated">Взаимная информация для совместной цели.</target>
        </trans-unit>
        <trans-unit id="ef9610a089a978dd0d661be292e2bde712e413d1" translate="yes" xml:space="preserve">
          <source>Mutual information for a discrete target.</source>
          <target state="translated">Взаимная информация для дискретной цели.</target>
        </trans-unit>
        <trans-unit id="2555b04ef28112b324874c1cc2f3bf2b5b5c384e" translate="yes" xml:space="preserve">
          <source>Mutual information, a non-negative value</source>
          <target state="translated">Взаимная информация,неотрицательная ценность</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="4e1221dedd7ee34eb6931a44dc15d9a84ca69a81" translate="yes" xml:space="preserve">
          <source>N : number of dimensions</source>
          <target state="translated">N:количество размеров</target>
        </trans-unit>
        <trans-unit id="8daf5ce04352d841160e980446540ca50cce58e4" translate="yes" xml:space="preserve">
          <source>N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.</source>
          <target state="translated">Н-бабушки на помощь! Вместо того,чтобы строить простую коллекцию униграмм (n=1),можно было бы предпочесть коллекцию биграмм (n=2),в которой подсчитываются вхождения пар последовательных слов.</target>
        </trans-unit>
        <trans-unit id="0d5c48bb908535393359e08969f6193dc43fff44" translate="yes" xml:space="preserve">
          <source>NCA can be seen as learning a (squared) Mahalanobis distance metric:</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
