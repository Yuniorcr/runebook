<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="94f937d118108bbf56d117b69cfda51f345777ab" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.StratifiedShuffleSplit&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.StratifiedShuffleSplit&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6d2a45b4a228c0ff26d151abb4398a317e97c2e2" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.TimeSeriesSplit&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.TimeSeriesSplit&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1169f405dfa22e87cb64248f2c5b612de695b324" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.cross_val_predict&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.cross_val_predict&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d1e3e38243b5c0275e9fe55822527a766daf84e5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.cross_val_score&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.cross_val_score&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cd66ce686ba75391d858a270576652221e9366cb" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.cross_validate&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64bdbb73303147fbfb7b4c72e2c5b9f862e6846a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.learning_curve&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.learning_curve&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="058189237019f568402a807ff0f37d6659f730bd" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.permutation_test_score&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.permutation_test_score&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a35d588868114f2ff75fd130567f7e47c8648990" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.train_test_split&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.train_test_split&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c436bb41de4b1b0cbaf9f2a30c84739212eaf00c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.validation_curve&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.model_selection.validation_curve&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8c90ea159f2ef33465cc5505a41ebcb13d8fa556" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3b803ea3410b546ac8080c64d5a283e65161ec36" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multioutput.ClassifierChain&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.multioutput.ClassifierChain&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="175a335aedce67fab5414504b5b10913957177f2" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multioutput.MultiOutputRegressor&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.multioutput.MultiOutputRegressor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7e5276c814e14e2874f1abc67268ecba0a9384b5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.BernoulliNB&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.naive_bayes.BernoulliNB&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="07d68dd4fe4a915ea6b5e32e2eca6d299d857bb7" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.ComplementNB&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.naive_bayes.ComplementNB&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="af3404bd8b46bee3672ba86cfbae1ef5ccc5adfa" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.GaussianNB&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.naive_bayes.GaussianNB&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="141d21773d99f3975d70ea9e9ce62f28b143b5ad" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5d999f3df66c782268c5cd0602cb79c507903292" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsClassifier&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.KNeighborsClassifier&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f26682456d970fbdab48470c970d2b2cf9d0be01" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="da4ee64191a33554442daf81f4b75c328c16de8c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsTransformer&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b0ca2d2cfcae04b6e8f648035a263800eba906a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="135f507596f50f4128ab7f674fa719851e06ba93" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.LocalOutlierFactor&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.LocalOutlierFactor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2d07ff0ebbbb5614d7d55c03e06e43f1f3f6d8b5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.NearestCentroid&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.NearestCentroid&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0749621ad934aca64b6d4bb597f488ca85f63f5a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.NeighborhoodComponentsAnalysis&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e409523b85d3bf8b35de4b9a79e58e19412df01" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.kneighbors_graph&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neighbors.kneighbors_graph&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="92b259d24e226f9725b7a2251b317d28f69ae1de" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.BernoulliRBM&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neural_network.BernoulliRBM&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bc26545aa247592ad5cae0c82982049aecb04005" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.MLPClassifier&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.neural_network.MLPClassifier&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="439d6a7e65183ef0435c18b6b323c74a5c51b635" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.MLPRegressor&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa6ee186b720b58c48c82ddfe44e7546cce24778" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.FeatureUnion&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.pipeline.FeatureUnion&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="998ec3583b26e3fb4a4ed0aff8fa32c106d8d3fd" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ce16abd7de545850afcb200375d7496f51a99f86" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.make_pipeline&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.pipeline.make_pipeline&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="22b8f1c3009cd0b959254500e33f171fb13ddc5e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.make_union&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.pipeline.make_union&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2542a7119b1badd4a5e17e03f5405355cc7a6b4e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.FunctionTransformer&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.FunctionTransformer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c5ebd1b718c2b56f55f671f8d4b702c99b6f3049" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.KBinsDiscretizer&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.KBinsDiscretizer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c4381d9fd377759510c6b6b975b0aef8ecf5740c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.MaxAbsScaler&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.MaxAbsScaler&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6c598f0cbf4e71a390fc3aa76e817310e670b681" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c1bc49d9937f0e2a5f4b0d4692671125b0d008b2" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.Normalizer&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.Normalizer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="149136e5bc700b2e0a7747b2cd498f47536f44b4" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="11c249d2a654ff2f1c2cc110185680b161c2af36" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.OrdinalEncoder&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56c4939b9d0afea5d1cebbe13cfe733258c34c00" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.PolynomialFeatures&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.PolynomialFeatures&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3a155bf7a30ca61ce1f29447001d55507068d346" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.PowerTransformer&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.PowerTransformer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="deb84a64d1425831a8777aa592bd6255271f75f8" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.QuantileTransformer&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.QuantileTransformer&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6a98bd8bd28f139beba8d2222e8707ab286c5640" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.RobustScaler&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.RobustScaler&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cc6025242e9ac27ec2143cf98f98385064f91436" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="be97d0bdf7a32b2c8b6fa3970798bb89bf783b34" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.label_binarize&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.label_binarize&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="36fa08e3b378f54ed6dffaaf0e419793c6ba101a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.minmax_scale&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.minmax_scale&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="69e893f40e9fcd420f194c86a5ec119b1f003520" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.quantile_transform&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.quantile_transform&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f1b108e5d448ff373a393340cccb912e8ffb72af" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.scale&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.preprocessing.scale&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="955e7e901699a2db4e4172aa9ab76068eea1b92f" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4c4748cf4849c5fc863bc575791af8141a34cef5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="88c1a4bb06d05e08ee20fd615bb4b53da175dc3d" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.semi_supervised.LabelSpreading&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.semi_supervised.LabelSpreading&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="737ca8cb1ccf3eeb065178263662a6be9c3d9649" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.set_config&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cd962b7c530c80e05b210277444c2bad820ca1e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="edbf5922b6f27be5c5403e10197b447705e6f9cb" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.NuSVC&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.NuSVC&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="12c9b218e18b941578bc9aca3c23747e42f54c1b" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="dea2aede79f19fb95e5148ee5c11b3c7f223323a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6bc3b4bf10642b79be6b77851a23e142b0ca36cf" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.SVC&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.SVC&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c4dcb2fd7042cd90b5cd989b10ea50e9efa48d50" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.SVR&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.SVR&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2a2669f574a679afac893b53b03bdb1bd3060d05" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="15e7f4eb0d23fc3ecea22ca0e3a3ebdefcef3322" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.DecisionTreeClassifier&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.tree.DecisionTreeClassifier&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="65c5a0a1817f47dc4a24c72d932486e31f108484" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.DecisionTreeRegressor&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.tree.DecisionTreeRegressor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="607ad6107d22cda5b789ada19b3e439fe3038b27" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.plot_tree&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b4d8799f6ce5100bf207b65e66619307f668cac" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.Bunch&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="668a018e39621dfc09781d5e1a018ed078089b72" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.Memory&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.utils.Memory&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7213df901109f2c1652eb65fa0f35fe0ff18cd9d" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.check_random_state&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.utils.check_random_state&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e9dab354869145a323333bb1a6f4abfc5f1cb7b1" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.estimator_checks.parametrize_with_checks&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2865372d64705a746f4e393e76c01c0a1fae3b37" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.extmath.density&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.utils.extmath.density&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="da99fb3fb0ad21b853976b89d77d08cdf2ec4f84" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.gen_even_slices&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851edad00347cd3937bd7ea24424c348d471aca4" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.metaestimators.if_delegate_has_method&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08628ee68b552a536a7e40670b9091a9987d81dc" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.shuffle&lt;/code&gt;</source>
          <target state="translated">Примеры использования &lt;code&gt;sklearn.utils.shuffle&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fb3447b632f6a431215776dcf254a01001a40c4f" translate="yes" xml:space="preserve">
          <source>Examples:</source>
          <target state="translated">Examples:</target>
        </trans-unit>
        <trans-unit id="2c25bc9aea0135b8a44078eaa686262d861b8d2c" translate="yes" xml:space="preserve">
          <source>Exception class to raise if estimator is used before fitting.</source>
          <target state="translated">Исключительный класс,который следует повысить,если перед монтажом используется оценочный прибор.</target>
        </trans-unit>
        <trans-unit id="7233f2cfa7da608e08349effe3a0829359d064c0" translate="yes" xml:space="preserve">
          <source>Exception.with_traceback(tb) &amp;ndash; set self.__traceback__ to tb and return self.</source>
          <target state="translated">Exception.with_traceback (tb) - установить self .__ traceback__ на tb и вернуть self.</target>
        </trans-unit>
        <trans-unit id="adb63819e55094a1c321051667ef69bc97910b3c" translate="yes" xml:space="preserve">
          <source>Exercise 1: Language identification</source>
          <target state="translated">Упражнение 1:Определение языка</target>
        </trans-unit>
        <trans-unit id="f2d31e2f590f63884cdac3b6e0353c56e95636fd" translate="yes" xml:space="preserve">
          <source>Exercise 2: Sentiment Analysis on movie reviews</source>
          <target state="translated">Упражнение 2:Анализ чувств при просмотре фильмов</target>
        </trans-unit>
        <trans-unit id="f076754d245dfa0bb055ce293bbe18bfa8d62689" translate="yes" xml:space="preserve">
          <source>Exercise 3: CLI text classification utility</source>
          <target state="translated">Упражнение 3:Утилита классификации текста CLI</target>
        </trans-unit>
        <trans-unit id="4dc503dafcf231e8065504c4cd9f19a0dcdfc147" translate="yes" xml:space="preserve">
          <source>Exercises</source>
          <target state="translated">Exercises</target>
        </trans-unit>
        <trans-unit id="9b4e2cce8211934c05426343255dbbe40e6fc29d" translate="yes" xml:space="preserve">
          <source>Exercises for the tutorials</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e172501d8e170f5e501dbb7e10f621b359347edb" translate="yes" xml:space="preserve">
          <source>Exhaustive search over specified parameter values for an estimator.</source>
          <target state="translated">Исчерпывающий поиск по заданным значениям параметров для вычислителя.</target>
        </trans-unit>
        <trans-unit id="827e74ef83aecac9c6f9fc861a3a010bc5589266" translate="yes" xml:space="preserve">
          <source>Exp-Sine-Squared kernel (aka periodic kernel).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9607bbaaa4524856cf2140445f92e407ff55546" translate="yes" xml:space="preserve">
          <source>Exp-Sine-Squared kernel.</source>
          <target state="translated">Ядро Exp-Sine-Squared.</target>
        </trans-unit>
        <trans-unit id="3b0c107b231b7c7d2dd1b666566c6604385763d3" translate="yes" xml:space="preserve">
          <source>Expected results for the top 5 most represented people in the dataset:</source>
          <target state="translated">Ожидаемые результаты по пяти наиболее представленным в наборе данных лицам:</target>
        </trans-unit>
        <trans-unit id="98312dc3857136b93e4f949a4e72a6712170156c" translate="yes" xml:space="preserve">
          <source>Explained variance regression score function</source>
          <target state="translated">Объясненная функция оценки регрессии дисперсии</target>
        </trans-unit>
        <trans-unit id="31162dbfd1baf8644ae388945633979e4d4b742f" translate="yes" xml:space="preserve">
          <source>Explicit feature map approximation for RBF kernels</source>
          <target state="translated">Явная аппроксимация карты характеристик для ядер RBF</target>
        </trans-unit>
        <trans-unit id="2139158fefd69dd7900f572f929357923b2e9c08" translate="yes" xml:space="preserve">
          <source>Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Скорость экспоненциального убывания для оценок вектора первого момента в адаме должна быть в [0, 1). Используется только когда solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="3b517f2d5130d355e5abbd42b6b2d0de0b8022fe" translate="yes" xml:space="preserve">
          <source>Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">Скорость экспоненциального убывания для оценок вектора второго момента в адаме должна быть в [0, 1). Используется только когда solver = 'adam'</target>
        </trans-unit>
        <trans-unit id="5be074c21803e5b45a92c260ef448b3876757aad" translate="yes" xml:space="preserve">
          <source>Exponential kernel (&lt;code&gt;kernel = 'exponential'&lt;/code&gt;)</source>
          <target state="translated">Экспоненциальное ядро ​​( &lt;code&gt;kernel = 'exponential'&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="4e6d09cb3f7c099f340e3cd011063b05dd20e736" translate="yes" xml:space="preserve">
          <source>Exponential loss (&lt;code&gt;'exponential'&lt;/code&gt;): The same loss function as &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt;&lt;code&gt;AdaBoostClassifier&lt;/code&gt;&lt;/a&gt;. Less robust to mislabeled examples than &lt;code&gt;'deviance'&lt;/code&gt;; can only be used for binary classification.</source>
          <target state="translated">Экспоненциальная потеря ( &lt;code&gt;'exponential'&lt;/code&gt; ): та же функция потерь, что и в &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt; &lt;code&gt;AdaBoostClassifier&lt;/code&gt; &lt;/a&gt; . Примеры менее устойчивы к неправильной маркировке, чем &lt;code&gt;'deviance'&lt;/code&gt; ; может использоваться только для двоичной классификации.</target>
        </trans-unit>
        <trans-unit id="82a5349d4a42ae4b58ce233c1fe754cf20695efd" translate="yes" xml:space="preserve">
          <source>Exponentiate kernel by given exponent.</source>
          <target state="translated">Экспонируйте ядро по заданному экспоненту.</target>
        </trans-unit>
        <trans-unit id="6a1fb392b4816003f7cab8689b69b73b81fd13d1" translate="yes" xml:space="preserve">
          <source>Export a decision tree in DOT format.</source>
          <target state="translated">Экспорт дерева решений в формате DOT.</target>
        </trans-unit>
        <trans-unit id="862ee3b17a826818107e616215cf3c3a954115aa" translate="yes" xml:space="preserve">
          <source>Exposure</source>
          <target state="translated">Exposure</target>
        </trans-unit>
        <trans-unit id="9eb0650b6756b55d46beda1492ea11acfe7e3431" translate="yes" xml:space="preserve">
          <source>Expresses to what extent the local structure is retained.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03b256629a71913d7df02c71e2c067b3de2f6cf2" translate="yes" xml:space="preserve">
          <source>External Resources, Videos and Talks</source>
          <target state="translated">Внешние ресурсы,видео и беседы</target>
        </trans-unit>
        <trans-unit id="6a53253fde7542b58764813563b294277a2499e0" translate="yes" xml:space="preserve">
          <source>External Tutorials</source>
          <target state="translated">Внешние уроки</target>
        </trans-unit>
        <trans-unit id="d29859b915eecd05832dcd65405884b6cc0d4c40" translate="yes" xml:space="preserve">
          <source>Extra keyword arguments will be passed to matplotlib&amp;rsquo;s &lt;code&gt;plot&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d6114c0a06ffd4fdec489d603f3c2293f085d8e" translate="yes" xml:space="preserve">
          <source>Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the &lt;code&gt;max_features&lt;/code&gt; randomly selected features and the best split among those is chosen. When &lt;code&gt;max_features&lt;/code&gt; is set 1, this amounts to building a totally random decision tree.</source>
          <target state="translated">Экстра-деревья отличаются от классических деревьев решений тем, как они построены. При поиске лучшего разбиения для разделения выборок узла на две группы, случайные разбиения рисуются для каждой из произвольно выбранных функций &lt;code&gt;max_features&lt;/code&gt; ,и выбирается лучшее разбиение среди них. Когда &lt;code&gt;max_features&lt;/code&gt; установлен в 1, это равносильно построению полностью случайного дерева решений.</target>
        </trans-unit>
        <trans-unit id="9955e456c4c0c464fbdd3775651693383fea52c1" translate="yes" xml:space="preserve">
          <source>Extract an ordered array of unique labels</source>
          <target state="translated">Извлечь упорядоченный набор уникальных этикеток</target>
        </trans-unit>
        <trans-unit id="73640fcc3fc33a24884d5d906a4df64cbbe3523c" translate="yes" xml:space="preserve">
          <source>Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor.</source>
          <target state="translated">Извлечение токенов из исходных текстовых документов с использованием лексики,снабженной фитингом или предоставленной конструктору.</target>
        </trans-unit>
        <trans-unit id="752e876b40a502b1de5591e926917e4bc7914d7e" translate="yes" xml:space="preserve">
          <source>Extracting features from text files</source>
          <target state="translated">Извлечение функций из текстовых файлов</target>
        </trans-unit>
        <trans-unit id="d28d7a25a071634693f533b81722275ae4a2006b" translate="yes" xml:space="preserve">
          <source>Extracting the clusters runs in linear time. Note that this results in &lt;code&gt;labels_&lt;/code&gt; which are close to a &lt;a href=&quot;sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; with similar settings and &lt;code&gt;eps&lt;/code&gt;, only if &lt;code&gt;eps&lt;/code&gt; is close to &lt;code&gt;max_eps&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f1c8b18c9f903ec74b12bbc8b3c4f7151c923f8b" translate="yes" xml:space="preserve">
          <source>Extracts an ordered list of points and reachability distances, and performs initial clustering using &lt;code&gt;max_eps&lt;/code&gt; distance specified at OPTICS object instantiation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d1d5b7b89c16041c19e08ba2433ff6ccea2c09b" translate="yes" xml:space="preserve">
          <source>Extracts patches from a collection of images</source>
          <target state="translated">Извлекает патчи из коллекции изображений</target>
        </trans-unit>
        <trans-unit id="20b1f470ded66ddce46bb1f3957f49e776657ce0" translate="yes" xml:space="preserve">
          <source>F values of features.</source>
          <target state="translated">F значения характеристик.</target>
        </trans-unit>
        <trans-unit id="94361d25a9823c7799f46133208e1994c901281f" translate="yes" xml:space="preserve">
          <source>F-beta score of the positive class in binary classification or weighted average of the F-beta score of each class for the multiclass task.</source>
          <target state="translated">F-бета оценка положительного класса в двоичной классификации или средневзвешенная F-бета оценка каждого класса для многоклассной задачи.</target>
        </trans-unit>
        <trans-unit id="b88bc0b15f26e6bb0b6f496fb42c5c9bb95eea78" translate="yes" xml:space="preserve">
          <source>F-value between label/feature for regression tasks.</source>
          <target state="translated">F-значение между меткой/печатью для задач регрессии.</target>
        </trans-unit>
        <trans-unit id="3ca92f821d80e2b3e5b34951989fdd6926d62950" translate="yes" xml:space="preserve">
          <source>F1 score of the positive class in binary classification or weighted average of the F1 scores of each class for the multiclass task.</source>
          <target state="translated">Оценка F1 положительного класса в двоичной классификации или средневзвешенная оценка F1 каждого класса для многоклассовой задачи.</target>
        </trans-unit>
        <trans-unit id="03688ba6aa340b87549088aa5739944cb6b1dc73" translate="yes" xml:space="preserve">
          <source>FAQ</source>
          <target state="translated">FAQ</target>
        </trans-unit>
        <trans-unit id="761451a93e0c15b8090688d5167bdaf6518e982d" translate="yes" xml:space="preserve">
          <source>FPR test stands for False Positive Rate test. It controls the total amount of false detections.</source>
          <target state="translated">FPR стенды для теста False Positive Rate.Он контролирует общее количество ложных срабатываний.</target>
        </trans-unit>
        <trans-unit id="385b798ea2337dc2cc46e2c01984384fa2b4a883" translate="yes" xml:space="preserve">
          <source>F_beta</source>
          <target state="translated">F_beta</target>
        </trans-unit>
        <trans-unit id="272ad30c6a89ef4d06060249f8d92df03b3df406" translate="yes" xml:space="preserve">
          <source>Face completion with a multi-output estimators</source>
          <target state="translated">Лицо завершения с несколькими выходами оценки</target>
        </trans-unit>
        <trans-unit id="0507c7e4982962e832b85d06191a2b4d2bebd20a" translate="yes" xml:space="preserve">
          <source>Face recognition with eigenfaces</source>
          <target state="translated">Распознавание лиц с собственными лицами</target>
        </trans-unit>
        <trans-unit id="2a0151d21d57d7f913fb01048c891608a6dbd1dd" translate="yes" xml:space="preserve">
          <source>Face, a 1024 x 768 size image of a raccoon face, is used here to illustrate how &lt;code&gt;k&lt;/code&gt;-means is used for vector quantization.</source>
          <target state="translated">Лицо, изображение лица енота размером 1024 x 768, используется здесь, чтобы проиллюстрировать, как &lt;code&gt;k&lt;/code&gt; - среднее используется для векторного квантования.</target>
        </trans-unit>
        <trans-unit id="e470f0e1bd32044d0ac0cbb19036da58e0de1f71" translate="yes" xml:space="preserve">
          <source>Faces dataset decompositions</source>
          <target state="translated">Разложения набора данных лиц</target>
        </trans-unit>
        <trans-unit id="05a6c8a2b029e9776dffd4a4e031ba78fd52aae9" translate="yes" xml:space="preserve">
          <source>Faces recognition example using eigenfaces and SVMs</source>
          <target state="translated">Пример распознавания лиц с использованием собственных интерфейсов и SVM.</target>
        </trans-unit>
        <trans-unit id="1395bbf4ff3a0e8184103b7a1548ed436935fe5c" translate="yes" xml:space="preserve">
          <source>Factor Analysis (FA)</source>
          <target state="translated">Факторный анализ (ФА)</target>
        </trans-unit>
        <trans-unit id="ef94831c8deb9ad37fe90ab4fff5e44828bcfdae" translate="yes" xml:space="preserve">
          <source>Factor analysis &lt;em&gt;can&lt;/em&gt; produce similar components (the columns of its loading matrix) to &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;. However, one can not make any general statements about these components (e.g. whether they are orthogonal):</source>
          <target state="translated">Факторный анализ &lt;em&gt;может&lt;/em&gt; производить компоненты, аналогичные &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; (столбцы его матрицы нагрузки) . Однако нельзя делать никаких общих заявлений об этих компонентах (например, являются ли они ортогональными):</target>
        </trans-unit>
        <trans-unit id="d48954e3f19174382e76ae0104e93e844b15de73" translate="yes" xml:space="preserve">
          <source>FactorAnalysis performs a maximum likelihood estimate of the so-called &lt;code&gt;loading&lt;/code&gt; matrix, the transformation of the latent variables to the observed ones, using SVD based approach.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6452044c700752d1602ef512b59b643cc8ae2400" translate="yes" xml:space="preserve">
          <source>FactorAnalysis performs a maximum likelihood estimate of the so-called &lt;code&gt;loading&lt;/code&gt; matrix, the transformation of the latent variables to the observed ones, using expectation-maximization (EM).</source>
          <target state="translated">FactorAnalysis выполняет оценку максимального правдоподобия так называемой матрицы &lt;code&gt;loading&lt;/code&gt; , преобразование скрытых переменных в наблюдаемые, с использованием максимизации ожидания (EM).</target>
        </trans-unit>
        <trans-unit id="cf3867c5acb3e93b6681ae294efcb69608ed1285" translate="yes" xml:space="preserve">
          <source>Factorization matrix, sometimes called &amp;lsquo;dictionary&amp;rsquo;.</source>
          <target state="translated">Матрица факторизации, иногда называемая &amp;laquo;словарем&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="c37fb3c7cf083e46f6a90c90a7e2709ff0a25468" translate="yes" xml:space="preserve">
          <source>False : never precompute distances</source>
          <target state="translated">Ложный:никогда не подсчитывать расстояния</target>
        </trans-unit>
        <trans-unit id="4031377a355ac026bbc01c0a8c66abf927d5347f" translate="yes" xml:space="preserve">
          <source>False : never precompute distances.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f59f0377a675667ec374342cc81b9550d388560" translate="yes" xml:space="preserve">
          <source>False positive rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25cefd866e6e705dad47ce327a0915fc7b301c18" translate="yes" xml:space="preserve">
          <source>False when &lt;code&gt;y&lt;/code&gt;&amp;rsquo;s shape is (n_samples, ) or (n_samples, 1) during fit otherwise True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5c093eaf163ad057d3c3eb085ce8a982ff3356" translate="yes" xml:space="preserve">
          <source>False: accept both np.inf and np.nan in X.</source>
          <target state="translated">Ложно:принять как np.inf,так и np.nan в X.</target>
        </trans-unit>
        <trans-unit id="e8392e19182108180157ea67d85038a25937bf1d" translate="yes" xml:space="preserve">
          <source>False: accepts np.inf, np.nan, pd.NA in X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed9971d141108d2bfea275398777be51a58308ae" translate="yes" xml:space="preserve">
          <source>False: accepts np.inf, np.nan, pd.NA in array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="804378d4f4edbfd6d3a924fd7282c07b3c8233b0" translate="yes" xml:space="preserve">
          <source>False: the results is casted to a signed int</source>
          <target state="translated">Ложно:результаты обнародованы в подписанном инт.</target>
        </trans-unit>
        <trans-unit id="b73e8a734794b535117e86ab6a6ba9f9a65b9a31" translate="yes" xml:space="preserve">
          <source>Fan, Rong-En, et al., &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf&quot;&gt;&amp;ldquo;LIBLINEAR: A library for large linear classification.&amp;rdquo;&lt;/a&gt;, Journal of machine learning research 9.Aug (2008): 1871-1874.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c87c316f44a57817f64366d0bec154e1f9523fd3" translate="yes" xml:space="preserve">
          <source>Fancy token-level analysis such as stemming, lemmatizing, compound splitting, filtering based on part-of-speech, etc. are not included in the scikit-learn codebase, but can be added by customizing either the tokenizer or the analyzer. Here&amp;rsquo;s a &lt;code&gt;CountVectorizer&lt;/code&gt; with a tokenizer and lemmatizer using &lt;a href=&quot;http://www.nltk.org&quot;&gt;NLTK&lt;/a&gt;:</source>
          <target state="translated">Необычный анализ на уровне токенов, такой как стемминг, лемматизация, составное разделение, фильтрация на основе части речи и т. Д., Не включены в базу кода scikit-learn, но могут быть добавлены путем настройки либо токенизатора, либо анализатора. Вот &lt;code&gt;CountVectorizer&lt;/code&gt; с токенизатором и лемматизатором с использованием &lt;a href=&quot;http://www.nltk.org&quot;&gt;NLTK&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="47db1ac61ed9cca1bf16f757f65fe37b19da02d2" translate="yes" xml:space="preserve">
          <source>Fancy token-level analysis such as stemming, lemmatizing, compound splitting, filtering based on part-of-speech, etc. are not included in the scikit-learn codebase, but can be added by customizing either the tokenizer or the analyzer. Here&amp;rsquo;s a &lt;code&gt;CountVectorizer&lt;/code&gt; with a tokenizer and lemmatizer using &lt;a href=&quot;https://www.nltk.org/&quot;&gt;NLTK&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="000599c940f606b6105f7d1916791a94094aca12" translate="yes" xml:space="preserve">
          <source>Fast computation of nearest neighbors is an active area of research in machine learning. The most naive neighbor search implementation involves the brute-force computation of distances between all pairs of points in the dataset: for \(N\) samples in \(D\) dimensions, this approach scales as \(O[D N^2]\). Efficient brute-force neighbors searches can be very competitive for small data samples. However, as the number of samples \(N\) grows, the brute-force approach quickly becomes infeasible. In the classes within &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt;, brute-force neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'brute'&lt;/code&gt;, and are computed using the routines available in &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Быстрое вычисление ближайших соседей - активная область исследований в области машинного обучения. Самая наивная реализация поиска соседей включает в себя вычисление перебором расстояний между всеми парами точек в наборе данных: для \ (N \) выборок в \ (D \) измерениях этот подход масштабируется как \ (O [DN ^ 2] \). Эффективный поиск соседей методом перебора может быть очень конкурентоспособным для небольших выборок данных. Однако по мере роста количества выборок \ (N \) метод грубой силы быстро становится невозможным. В классах внутри &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt; поиск соседей методом перебора задается с помощью ключевого слова &lt;code&gt;algorithm = 'brute'&lt;/code&gt; и вычисляется с использованием подпрограмм, доступных в &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2e91ff193b9320036698a113daf46d8118a44e7d" translate="yes" xml:space="preserve">
          <source>FastICA on 2D point clouds</source>
          <target state="translated">FastICA на 2D облаках точек</target>
        </trans-unit>
        <trans-unit id="6921319b009c74978f9e5104f25e9063c7cf2c6b" translate="yes" xml:space="preserve">
          <source>FastICA: a fast algorithm for Independent Component Analysis.</source>
          <target state="translated">FastICA:быстрый алгоритм независимого компонентного анализа.</target>
        </trans-unit>
        <trans-unit id="c2070bedc34b06cdbf740c2fed5e122d3efb93a7" translate="yes" xml:space="preserve">
          <source>Faster for large datasets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6fa15d231f996464c9e743e456c3d6855ab0d8f6" translate="yes" xml:space="preserve">
          <source>Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition Letters, 2006, 27(8):861-874.</source>
          <target state="translated">Фосетт Т.Введение в анализ ROC[J].Письма о распознавании образов,2006,27(8):861-874.</target>
        </trans-unit>
        <trans-unit id="0724b7da2e7893e2aa61b560332f137d5b0c3174" translate="yes" xml:space="preserve">
          <source>Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6d44f9610f58495afc33ead5474258ef3212417" translate="yes" xml:space="preserve">
          <source>Fawcett, T., 2001. &lt;a href=&quot;http://ieeexplore.ieee.org/document/989510/&quot;&gt;Using rule sets to maximize ROC performance&lt;/a&gt; In Data Mining, 2001. Proceedings IEEE International Conference, pp. 131-138.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="777dc3527e71dea0036f160bc11c11f47afad8e4" translate="yes" xml:space="preserve">
          <source>Fawcett, T., 2006. &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S016786550500303X&quot;&gt;An introduction to ROC analysis.&lt;/a&gt; Pattern Recognition Letters, 27(8), pp. 861-874.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79246ec7915038316872f16646be2a17cce4452e" translate="yes" xml:space="preserve">
          <source>Fawcett, T., 2006. &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S016786550500303X&quot;&gt;An introduction to ROC analysis.&lt;/a&gt; Pattern Recognition Letters, 27(8), pp. 861-874.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77834b29664ccb5e5cc9173718797e7ec674b1ed" translate="yes" xml:space="preserve">
          <source>Feature 0 (median income in a block) and feature 5 (number of households) of the &lt;a href=&quot;http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;California housing dataset&lt;/a&gt; have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.</source>
          <target state="translated">Характеристика 0 (средний доход в блоке) и характеристика 5 (количество домохозяйств) &lt;a href=&quot;http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;набора данных по жилью&lt;/a&gt; в Калифорнии имеют очень разные масштабы и содержат очень большие выбросы. Эти две характеристики затрудняют визуализацию данных и, что более важно, могут ухудшить прогнозную производительность многих алгоритмов машинного обучения. Немасштабированные данные также могут замедлить или даже предотвратить сходимость многих оценок на основе градиента.</target>
        </trans-unit>
        <trans-unit id="d43b2b4b53fe06f630d6e6fea5ae39ec97ef2464" translate="yes" xml:space="preserve">
          <source>Feature 0 (median income in a block) and feature 5 (number of households) of the &lt;a href=&quot;https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;California housing dataset&lt;/a&gt; have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e2bfc0d574ebb3c0866208d70d9a4defc9229e8" translate="yes" xml:space="preserve">
          <source>Feature Selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3290cbe981e79caf9ab6f89a8812507aa114a727" translate="yes" xml:space="preserve">
          <source>Feature agglomeration</source>
          <target state="translated">Функциональная агломерация</target>
        </trans-unit>
        <trans-unit id="81f8ec148b187c97182bf2c56b5ce15909bcbae4" translate="yes" xml:space="preserve">
          <source>Feature agglomeration vs. univariate selection</source>
          <target state="translated">Функциональная агломерация по сравнению с одномерным отбором</target>
        </trans-unit>
        <trans-unit id="49e1dcf68a4912e92e5e7f68710255b3ca05471e" translate="yes" xml:space="preserve">
          <source>Feature discretization</source>
          <target state="translated">Дискретизация функций</target>
        </trans-unit>
        <trans-unit id="3c43171269f5f432d869bba89f82c3b54ca0debf" translate="yes" xml:space="preserve">
          <source>Feature extraction</source>
          <target state="translated">Извлечение функции</target>
        </trans-unit>
        <trans-unit id="df5954aef1e3ea02a4e2fe61d1e0e10b9f726b5a" translate="yes" xml:space="preserve">
          <source>Feature extraction and normalization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aedfee8f7e4b62695a0b89930709eed1e654b00f" translate="yes" xml:space="preserve">
          <source>Feature extraction is very different from &lt;a href=&quot;feature_selection#feature-selection&quot;&gt;Feature selection&lt;/a&gt;: the former consists in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. The latter is a machine learning technique applied on these features.</source>
          <target state="translated">Извлечение функций сильно отличается от &lt;a href=&quot;feature_selection#feature-selection&quot;&gt;выбора функций&lt;/a&gt; : первый состоит в преобразовании произвольных данных, таких как текст или изображения, в числовые функции, используемые для машинного обучения. Последний представляет собой метод машинного обучения, применяемый к этим функциям.</target>
        </trans-unit>
        <trans-unit id="4c3a870a4e311a31f848b5314c8f3949d8e31e78" translate="yes" xml:space="preserve">
          <source>Feature hashing can be employed in document classification, but unlike &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt;&lt;code&gt;FeatureHasher&lt;/code&gt;&lt;/a&gt; does not do word splitting or any other preprocessing except Unicode-to-UTF-8 encoding; see &lt;a href=&quot;#hashing-vectorizer&quot;&gt;Vectorizing a large text corpus with the hashing trick&lt;/a&gt;, below, for a combined tokenizer/hasher.</source>
          <target state="translated">Хеширование функций может использоваться при классификации документов, но в отличие от &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;text.CountVectorizer&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt; &lt;code&gt;FeatureHasher&lt;/code&gt; &lt;/a&gt; не выполняет разделение слов или любую другую предварительную обработку, кроме кодирования Unicode-to-UTF-8; см. &lt;a href=&quot;#hashing-vectorizer&quot;&gt;Векторизацию большого текстового корпуса с помощью трюка с хешированием&lt;/a&gt; ниже, чтобы узнать о комбинированном токенизаторе / хешере.</target>
        </trans-unit>
        <trans-unit id="7bb8776f4e73559816ad10cf154be669f7df47cf" translate="yes" xml:space="preserve">
          <source>Feature importances with forests of trees</source>
          <target state="translated">Особенности с лесами деревьев</target>
        </trans-unit>
        <trans-unit id="561e2555a0c1659bb31a6148c1abe250489ca708" translate="yes" xml:space="preserve">
          <source>Feature mappings for the samples in X.</source>
          <target state="translated">Функциональные отображения для образцов в X.</target>
        </trans-unit>
        <trans-unit id="b96ff43d78f2a1f5a4e1d891c2cc36e4c380c32b" translate="yes" xml:space="preserve">
          <source>Feature matrix, for use with estimators or further transformers.</source>
          <target state="translated">Матрица характеристик,для использования с оценочными приборами или другими трансформаторами.</target>
        </trans-unit>
        <trans-unit id="66d052b121f901629f4ce88124bd7cb2635fe497" translate="yes" xml:space="preserve">
          <source>Feature matrix.</source>
          <target state="translated">Матрица функций.</target>
        </trans-unit>
        <trans-unit id="c4587a739696f602e34f3bba74d9106ccf3fff49" translate="yes" xml:space="preserve">
          <source>Feature names corresponding to the indices in &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="975d25794ea94f600d607356398714d33388d870" translate="yes" xml:space="preserve">
          <source>Feature names of type byte string are used as-is. Unicode strings are converted to UTF-8 first, but no Unicode normalization is done. Feature values must be (finite) numbers.</source>
          <target state="translated">Используются имена байтовых строк типа as-is.Строки в юникоде сначала преобразуются в UTF-8,но нормализация в юникоде не производится.Значения признаков должны быть (конечными)числами.</target>
        </trans-unit>
        <trans-unit id="9509bbe5f8817e2ca0562d6baac6f0ad1787e1d6" translate="yes" xml:space="preserve">
          <source>Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.</source>
          <target state="translated">Ранжирование характеристик с рекурсивным устранением признаков и перекрестным подтверждением выбора лучшего количества признаков.</target>
        </trans-unit>
        <trans-unit id="f706081a8ad25e74e9a88b9e19a48d5a46a52012" translate="yes" xml:space="preserve">
          <source>Feature ranking with recursive feature elimination.</source>
          <target state="translated">Ранжирование характеристик с рекурсивным устранением признаков.</target>
        </trans-unit>
        <trans-unit id="7f17a87c5de04e39e04129e9c0737edfeafaee92" translate="yes" xml:space="preserve">
          <source>Feature scaling through standardization (or Z-score normalization) can be an important preprocessing step for many machine learning algorithms. Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.</source>
          <target state="translated">Масштабирование функций с помощью стандартизации (или нормализации Z-образных пятен)может быть важным этапом предварительной обработки для многих алгоритмов машинного обучения.Стандартизация подразумевает перемасштабирование характеристик таким образом,чтобы они обладали свойствами стандартного нормального распределения со средним значением нуля и стандартным отклонением в единицу.</target>
        </trans-unit>
        <trans-unit id="3ac99400fe4169f40a977ea7007419c98db61771" translate="yes" xml:space="preserve">
          <source>Feature scores between 0 and 1 for all values of the regularization parameter. The reference article suggests &lt;code&gt;scores_&lt;/code&gt; is the max of &lt;code&gt;all_scores_&lt;/code&gt;.</source>
          <target state="translated">Оценка функции от 0 до 1 для всех значений параметра регуляризации. В справочной статье &lt;code&gt;scores_&lt;/code&gt; что scores_ является максимальным значением &lt;code&gt;all_scores_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="aa75d746547685bebfdc2a7e366361e478fa27f0" translate="yes" xml:space="preserve">
          <source>Feature scores between 0 and 1.</source>
          <target state="translated">Очки от 0 до 1.</target>
        </trans-unit>
        <trans-unit id="afb880f1a910829f871ab84d5509ba79bf00b111" translate="yes" xml:space="preserve">
          <source>Feature selection is usually used as a pre-processing step before doing the actual learning. The recommended way to do this in scikit-learn is to use a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Выбор функции обычно используется как этап предварительной обработки перед фактическим обучением. Рекомендуемый способ сделать это в scikit-learn - использовать &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="5a515063a6bfb2324e04a5cb7dd1fe0bf9c9b6c2" translate="yes" xml:space="preserve">
          <source>Feature selection mode.</source>
          <target state="translated">Режим выбора функций.</target>
        </trans-unit>
        <trans-unit id="c9b5854c848ad0aec62ba5b490b140e3c7a1bb7d" translate="yes" xml:space="preserve">
          <source>Feature selection using SelectFromModel and LassoCV</source>
          <target state="translated">Выбор функций с помощью SelectFromModel и LassoCV.</target>
        </trans-unit>
        <trans-unit id="d13bfd588897e09202c5ea9fa5c11da3f65c72ad" translate="yes" xml:space="preserve">
          <source>Feature selection with sparse data</source>
          <target state="translated">Выбор функций с разрозненными данными</target>
        </trans-unit>
        <trans-unit id="8a9e4457b64c8313be96ab86a00a0aa32201d58b" translate="yes" xml:space="preserve">
          <source>Feature selector that removes all low-variance features.</source>
          <target state="translated">Селектор функций,который удаляет все низкочастотные функции.</target>
        </trans-unit>
        <trans-unit id="e1b0ac4f2f2d7f5b2a31bb18d47b68f8979e7db4" translate="yes" xml:space="preserve">
          <source>Feature transformations with ensembles of trees</source>
          <target state="translated">Функциональные преобразования с ансамблями деревьев</target>
        </trans-unit>
        <trans-unit id="9a6ded29908e935164e678c6c6abd840802b0c72" translate="yes" xml:space="preserve">
          <source>Feature values below or equal to this are replaced by 0, above it by 1. Threshold may not be less than 0 for operations on sparse matrices.</source>
          <target state="translated">Значения характеристик ниже или равные им заменяются на 0,выше-на 1.Порог не может быть меньше 0 для операций на разреженных матрицах.</target>
        </trans-unit>
        <trans-unit id="0bf4742e81f7f65623aaef302013934b401b3eb5" translate="yes" xml:space="preserve">
          <source>Feature values in training data (also required for prediction)</source>
          <target state="translated">Значения характеристик в обучающих данных (также необходимы для прогнозирования)</target>
        </trans-unit>
        <trans-unit id="3252ec9f22752fab5d0e2a9197cc3c5847a58e00" translate="yes" xml:space="preserve">
          <source>Feature vectors or other representations of training data (also required for prediction).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ed37149ccf99f3ffe537e50f5c181c973cd258e" translate="yes" xml:space="preserve">
          <source>Feature vectors or other representations of training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7599b9ef6a2c582b4507f1b87929e181ce07276" translate="yes" xml:space="preserve">
          <source>Feature vectors; always 2-d.</source>
          <target state="translated">Функциональные векторы;всегда 2-d.</target>
        </trans-unit>
        <trans-unit id="8425332e36244b1448079ae72c3edeebff1ff3df" translate="yes" xml:space="preserve">
          <source>Feature-wise means</source>
          <target state="translated">Характерные средства</target>
        </trans-unit>
        <trans-unit id="4dfce3abcd43918524b8cd8b96300d3efd01d1fb" translate="yes" xml:space="preserve">
          <source>Feature-wise transformation of the data.</source>
          <target state="translated">Функциональное преобразование данных.</target>
        </trans-unit>
        <trans-unit id="5ce13d491431cc736ca395a68aa77c25024d518b" translate="yes" xml:space="preserve">
          <source>Feature-wise variances</source>
          <target state="translated">Характерные различия</target>
        </trans-unit>
        <trans-unit id="8c7ad0b456fa9bf3ae09e270340fb831f15c3f18" translate="yes" xml:space="preserve">
          <source>FeatureHasher and DictVectorizer Comparison</source>
          <target state="translated">Сравнение FeatureHasher и DictVectorizer</target>
        </trans-unit>
        <trans-unit id="fc338f87a058158eb824b53705961801516a9460" translate="yes" xml:space="preserve">
          <source>Features</source>
          <target state="translated">Features</target>
        </trans-unit>
        <trans-unit id="7b144c2dee4c701c6fc61ec2c427f38a9b6c6529" translate="yes" xml:space="preserve">
          <source>Features 1 and 2 of the diabetes-dataset are fitted and plotted below. It illustrates that although feature 2 has a strong coefficient on the full model, it does not give us much regarding &lt;code&gt;y&lt;/code&gt; when compared to just feature 1</source>
          <target state="translated">Характеристики 1 и 2 набора данных по диабету подобраны и нанесены на график ниже. Он показывает, что, хотя характеристика 2 имеет высокий коэффициент на полной модели, она не дает нам много информации относительно &lt;code&gt;y&lt;/code&gt; по сравнению с просто функцией 1.</target>
        </trans-unit>
        <trans-unit id="27bf161ea6af475b73d710eebe7f66e368f22dbd" translate="yes" xml:space="preserve">
          <source>Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.</source>
          <target state="translated">Особенности вычисляются из оцифрованного изображения тонкой иглы-аспирата (ФНК)массы груди.Они описывают характеристики ядер клеток,присутствующих на изображении.</target>
        </trans-unit>
        <trans-unit id="7dc73780307913b147af45ec74f5c7491dc77d15" translate="yes" xml:space="preserve">
          <source>Features got by optimizing the Huber loss.</source>
          <target state="translated">Особенности,полученные за счет оптимизации потери Хьюбера.</target>
        </trans-unit>
        <trans-unit id="0a06ba45f44f1716120206612e20d59fa0c2d9b4" translate="yes" xml:space="preserve">
          <source>Features that are deemed of &lt;strong&gt;low importance for a bad model&lt;/strong&gt; (low cross-validation score) could be &lt;strong&gt;very important for a good model&lt;/strong&gt;. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but &lt;strong&gt;how important this feature is for a particular model&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="285c7b098890786c959265d1fe4e4933df08392b" translate="yes" xml:space="preserve">
          <source>Features that do not occur in a sample (mapping) will have a zero value in the resulting array/matrix.</source>
          <target state="translated">Особенности,которые не встречаются в выборке (отображении),будут иметь нулевое значение в результирующем массиве/матрице.</target>
        </trans-unit>
        <trans-unit id="e9ec5e9ca7278a6df71a586ca47e81c93d4d7336" translate="yes" xml:space="preserve">
          <source>Features which contain all missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71724a67f7aa53e34d06b737e24512de12116bad" translate="yes" xml:space="preserve">
          <source>Features with a training-set variance lower than this threshold will be removed. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples.</source>
          <target state="translated">Функции,в которых разница в наборе тренировочных установок ниже этого порогового значения,будут удалены.По умолчанию все функции с ненулевой дисперсией,т.е.удаляются те функции,которые имеют одинаковое значение во всех выборках.</target>
        </trans-unit>
        <trans-unit id="c6023b69815535fce0c52cfebfa0b836b623efcf" translate="yes" xml:space="preserve">
          <source>Ferri, C&amp;egrave;sar &amp;amp; Hernandez-Orallo, Jose &amp;amp; Modroiu, R. (2009). &lt;a href=&quot;https://www.math.ucdavis.edu/~saito/data/roc/ferri-class-perf-metrics.pdf&quot;&gt;An Experimental Comparison of Performance Measures for Classification.&lt;/a&gt; Pattern Recognition Letters. 30. 27-38.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7609c48291c2fa7cc57f1dc4a85a3683c0749b4f" translate="yes" xml:space="preserve">
          <source>Fetch an mldata.org data set</source>
          <target state="translated">Получить набор данных mldata.org</target>
        </trans-unit>
        <trans-unit id="2b29d907c2ea7e85ef894ade96f5a9788aa198c9" translate="yes" xml:space="preserve">
          <source>Fetch dataset from openml by name or dataset id.</source>
          <target state="translated">Получение набора данных из openml по имени или по идентификатору набора данных.</target>
        </trans-unit>
        <trans-unit id="76c8d1e0086c4e650fc514d650a93664c1ba4aa6" translate="yes" xml:space="preserve">
          <source>Fevotte, C., &amp;amp; Idier, J. (2011). Algorithms for nonnegative matrix factorization with the beta-divergence. Neural Computation, 23(9).</source>
          <target state="translated">Февот, К., Идиер, Дж. (2011). Алгоритмы факторизации неотрицательной матрицы с бета-дивергенцией. Нейронные вычисления, 23 (9).</target>
        </trans-unit>
        <trans-unit id="07da69c9120fa48d1a8831ddfdb2e22d5f38a14c" translate="yes" xml:space="preserve">
          <source>Few clusters, even cluster size, non-flat geometry</source>
          <target state="translated">Мало кластеров,даже по размеру,не плоская геометрия.</target>
        </trans-unit>
        <trans-unit id="ba82bf0fe9bdb74f2de9056ff08a208a0201f2e5" translate="yes" xml:space="preserve">
          <source>Field &lt;code&gt;support_vectors_&lt;/code&gt; is now empty, only indices of support vectors are stored in &lt;code&gt;support_&lt;/code&gt;</source>
          <target state="translated">Поле &lt;code&gt;support_vectors_&lt;/code&gt; теперь пусто, в &lt;code&gt;support_&lt;/code&gt; хранятся только индексы опорных векторов.</target>
        </trans-unit>
        <trans-unit id="e6b7eea98ef60c86409d4e4dd54b3796ed56341b" translate="yes" xml:space="preserve">
          <source>Figure containing partial dependence plots.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf29ad109219929951ed38da3e672e781ba3fade" translate="yes" xml:space="preserve">
          <source>Figure containing the confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65bafae58e0d2ce7524ef55e10fcc5ed53a13aa4" translate="yes" xml:space="preserve">
          <source>Figure containing the curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63c41242bc3de30c7fa64bf90cc3aa34e5d08243" translate="yes" xml:space="preserve">
          <source>Filter: Select the p-values corresponding to Family-wise error rate</source>
          <target state="translated">Фильтр:Выберите р-значения,соответствующие семейному коэффициенту ошибок.</target>
        </trans-unit>
        <trans-unit id="d601967c960c718fae8a27ae10382e904525e519" translate="yes" xml:space="preserve">
          <source>Filter: Select the p-values for an estimated false discovery rate</source>
          <target state="translated">Фильтр:Выберите р-значения для предполагаемого количества ложных обнаружений.</target>
        </trans-unit>
        <trans-unit id="f9d7c51c4e21ffa778934e88c4ada6f78e753e59" translate="yes" xml:space="preserve">
          <source>Filter: Select the pvalues below alpha based on a FPR test.</source>
          <target state="translated">Фильтр:Выберите значения ниже альфа на основе теста FPR.</target>
        </trans-unit>
        <trans-unit id="fa74263b1f44e0e368feef4eccc429e274602a1d" translate="yes" xml:space="preserve">
          <source>Final perplexity score on training set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e832a73dedeb0259ac793f9ac425f8e8ee172602" translate="yes" xml:space="preserve">
          <source>Finally it is possible to discover the main topics of a corpus by relaxing the hard assignment constraint of clustering, for instance by using &lt;a href=&quot;decomposition#nmf&quot;&gt;Non-negative matrix factorization (NMF or NNMF)&lt;/a&gt;:</source>
          <target state="translated">Наконец, можно раскрыть основные темы корпуса, ослабив жесткое ограничение присваивания кластеризации, например, используя &lt;a href=&quot;decomposition#nmf&quot;&gt;неотрицательную матричную факторизацию (NMF или NNMF)&lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="3879f3b348e8db024fb12750b7a6d38d6bbf41c3" translate="yes" xml:space="preserve">
          <source>Finally one can also observe that for some intermediate values of &lt;code&gt;gamma&lt;/code&gt; we get equally performing models when &lt;code&gt;C&lt;/code&gt; becomes very large: it is not necessary to regularize by enforcing a larger margin. The radius of the RBF kernel alone acts as a good structural regularizer. In practice though it might still be interesting to simplify the decision function with a lower value of &lt;code&gt;C&lt;/code&gt; so as to favor models that use less memory and that are faster to predict.</source>
          <target state="translated">Наконец, можно также заметить, что для некоторых промежуточных значений &lt;code&gt;gamma&lt;/code&gt; мы получаем модели с одинаковой производительностью, когда &lt;code&gt;C&lt;/code&gt; становится очень большим: нет необходимости в регуляризации путем обеспечения большего запаса. Один только радиус ядра RBF действует как хороший структурный регуляризатор. На практике, хотя все еще может быть интересно упростить функцию принятия решения с более низким значением &lt;code&gt;C&lt;/code&gt; , чтобы отдать предпочтение моделям, которые используют меньше памяти и которые быстрее предсказывать.</target>
        </trans-unit>
        <trans-unit id="023b5a681b65ffd6304d113bea1d054693e2974b" translate="yes" xml:space="preserve">
          <source>Finally one should highlight that the Compound Poisson Gamma model that is directly fit on the pure premium is operationally simpler to develop and maintain as it consists in a single scikit-learn estimator instead of a pair of models, each with its own set of hyperparameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="132cf9317ef371444593d6b5ea568f7dd88cd93f" translate="yes" xml:space="preserve">
          <source>Finally we are going to visualize the score:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c7dc3c27466a01b4ea9d811b8dcf76d3f27d658" translate="yes" xml:space="preserve">
          <source>Finally we will plot the selected two features from the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="968616cc558da3fce60b0fa70563b382cf880868" translate="yes" xml:space="preserve">
          <source>Finally, &lt;a href=&quot;#dummy-estimators&quot;&gt;Dummy estimators&lt;/a&gt; are useful to get a baseline value of those metrics for random predictions.</source>
          <target state="translated">Наконец, &lt;a href=&quot;#dummy-estimators&quot;&gt;фиктивные оценки&lt;/a&gt; полезны для получения базового значения этих показателей для случайных прогнозов.</target>
        </trans-unit>
        <trans-unit id="f6d5bddccec3511395edb0437e03e1a9559b2146" translate="yes" xml:space="preserve">
          <source>Finally, as we will see next, computing partial dependence plots tree-based models is also orders of magnitude faster making it cheap to compute partial dependence plots for pairs of interacting features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bac8fe99c0a1d10b0495b7da851a20ddd76d68ac" translate="yes" xml:space="preserve">
          <source>Finally, for 3. we have a number of options inside scikit-learn. Although not all algorithms can learn incrementally (i.e. without seeing all the instances at once), all estimators implementing the &lt;code&gt;partial_fit&lt;/code&gt; API are candidates. Actually, the ability to learn incrementally from a mini-batch of instances (sometimes called &amp;ldquo;online learning&amp;rdquo;) is key to out-of-core learning as it guarantees that at any given time there will be only a small amount of instances in the main memory. Choosing a good size for the mini-batch that balances relevancy and memory footprint could involve some tuning &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f153367033a26a7113472eddd66aa5516b2f784" translate="yes" xml:space="preserve">
          <source>Finally, for 3. we have a number of options inside scikit-learn. Although not all algorithms can learn incrementally (i.e. without seeing all the instances at once), all estimators implementing the &lt;code&gt;partial_fit&lt;/code&gt; API are candidates. Actually, the ability to learn incrementally from a mini-batch of instances (sometimes called &amp;ldquo;online learning&amp;rdquo;) is key to out-of-core learning as it guarantees that at any given time there will be only a small amount of instances in the main memory. Choosing a good size for the mini-batch that balances relevancy and memory footprint could involve some tuning &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Наконец, для 3. у нас есть несколько вариантов внутри scikit-learn. Хотя не все алгоритмы могут обучаться постепенно (т. Е. Без просмотра всех экземпляров сразу), кандидатами являются все оценщики, реализующие API &lt;code&gt;partial_fit&lt;/code&gt; . На самом деле, способность учиться постепенно на мини-группе экземпляров (иногда называемая &amp;laquo;онлайн-обучение&amp;raquo;) является ключом к внешнему обучению, поскольку она гарантирует, что в любой момент времени будет только небольшое количество экземпляров в основная память. Выбор подходящего размера для мини-пакета, который уравновешивает релевантность и объем памяти, может потребовать некоторой настройки &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2ea772d9a2706e63fd635b713dfc5a265ad9f7ca" translate="yes" xml:space="preserve">
          <source>Finally, for the last data set, it is hard to say that one sample is more abnormal than another sample as they are uniformly distributed in a hypercube. Except for the &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; which overfits a little, all estimators present decent solutions for this situation. In such a case, it would be wise to look more closely at the scores of abnormality of the samples as a good estimator should assign similar scores to all the samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02251ecbb666e2a1b9f431635bb03c5b54eb0a09" translate="yes" xml:space="preserve">
          <source>Finally, for the last data set, it is hard to say that one sample is more abnormal than another sample as they are uniformly distributed in a hypercube. Except for the &lt;code&gt;svm.OneClassSVM&lt;/code&gt; which overfits a little, all estimators present decent solutions for this situation. In such a case, it would be wise to look more closely at the scores of abnormality of the samples as a good estimator should assign similar scores to all the samples.</source>
          <target state="translated">Наконец, для последнего набора данных трудно сказать, что один образец более ненормален, чем другой образец, поскольку они равномерно распределены в гиперкубе. За исключением &lt;code&gt;svm.OneClassSVM&lt;/code&gt; , который немного переигрывает, все оценщики представляют достойные решения для этой ситуации. В таком случае было бы разумно более внимательно изучить оценки отклонений от нормы в выборках, поскольку хороший оценщик должен присваивать одинаковые оценки всем выборкам.</target>
        </trans-unit>
        <trans-unit id="ced44a1e1c24bc2a905bacd41c580fdb8b398c7b" translate="yes" xml:space="preserve">
          <source>Finally, if the centered data is expected to be small enough, explicitly converting the input to an array using the &lt;code&gt;toarray&lt;/code&gt; method of sparse matrices is another option.</source>
          <target state="translated">Наконец, если ожидается, что центрированные данные будут достаточно маленькими, еще один вариант - явное преобразование ввода в массив с использованием метода разреженных матриц &lt;code&gt;toarray&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3e454243da6a98ce545408a4ef381fa38d1b1d45" translate="yes" xml:space="preserve">
          <source>Finally, many parts of the implementation of &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are parallelized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b957bcce911d726f82907b30c1a02070fcadf91" translate="yes" xml:space="preserve">
          <source>Finally, note that parameters of the models have been here handpicked but that in practice they need to be adjusted. In the absence of labelled data, the problem is completely unsupervised so model selection can be a challenge.</source>
          <target state="translated">Наконец,обратите внимание на то,что параметры моделей были здесь подобраны вручную,но на практике их необходимо корректировать.При отсутствии маркированных данных проблема полностью игнорируется,поэтому выбор модели может оказаться сложной задачей.</target>
        </trans-unit>
        <trans-unit id="657149d8f47b73d795165e7f97ca51bcb04565c9" translate="yes" xml:space="preserve">
          <source>Finally, the precomputation can be performed by custom estimators to use different implementations, such as approximate nearest neighbors methods, or implementation with special data types. The precomputed neighbors &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;sparse graph&lt;/a&gt; needs to be formatted as in &lt;a href=&quot;generated/sklearn.neighbors.radius_neighbors_graph#sklearn.neighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; output:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d0d4410d99fc712aa6cde836179153d36f8849c" translate="yes" xml:space="preserve">
          <source>Finally, the preprocessing pipeline is integrated in a full prediction pipeline using &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;, together with a simple classification model.</source>
          <target state="translated">Наконец, конвейер предварительной обработки интегрирован в конвейер полного прогнозирования с помощью &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; вместе с простой моделью классификации.</target>
        </trans-unit>
        <trans-unit id="88dd3e3888504f660d94f91abf7147882c40ab2a" translate="yes" xml:space="preserve">
          <source>Finally, this module also features the parallel construction of the trees and the parallel computation of the predictions through the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If &lt;code&gt;n_jobs=k&lt;/code&gt; then computations are partitioned into &lt;code&gt;k&lt;/code&gt; jobs, and run on &lt;code&gt;k&lt;/code&gt; cores of the machine. If &lt;code&gt;n_jobs=-1&lt;/code&gt; then all cores available on the machine are used. Note that because of inter-process communication overhead, the speedup might not be linear (i.e., using &lt;code&gt;k&lt;/code&gt; jobs will unfortunately not be &lt;code&gt;k&lt;/code&gt; times as fast). Significant speedup can still be achieved though when building a large number of trees, or when building a single tree requires a fair amount of time (e.g., on large datasets).</source>
          <target state="translated">Наконец, этот модуль также имеет параллельное построение деревьев и параллельное вычисление прогнозов с &lt;code&gt;n_jobs&lt;/code&gt; параметра n_jobs . Если &lt;code&gt;n_jobs=k&lt;/code&gt; , то вычисления разбиваются на &lt;code&gt;k&lt;/code&gt; заданий и выполняются на &lt;code&gt;k&lt;/code&gt; ядрах машины. Если &lt;code&gt;n_jobs=-1&lt;/code&gt; , то используются все ядра, доступные на машине. Обратите внимание, что из-за накладных расходов на межпроцессное взаимодействие ускорение может быть не линейным (т. Е. Использование &lt;code&gt;k&lt;/code&gt; заданий, к сожалению, не будет в &lt;code&gt;k&lt;/code&gt; раз быстрее). Тем не менее, можно добиться значительного ускорения при построении большого количества деревьев или когда построение одного дерева требует значительного количества времени (например, для больших наборов данных).</target>
        </trans-unit>
        <trans-unit id="ac4279287fdb399e92fa8f401fc1a571b7df3622" translate="yes" xml:space="preserve">
          <source>Finally, we can compare the two models using a plot of cumulated claims: for each model, the policyholders are ranked from safest to riskiest and the fraction of observed total cumulated claims is plotted on the y axis. This plot is often called the ordered Lorenz curve of the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abb5440e13032f9c21233aa604593a79c839b358" translate="yes" xml:space="preserve">
          <source>Finally, we fit our pipeline on the training data and use it to predict topics for &lt;code&gt;X_test&lt;/code&gt;. Performance metrics of our pipeline are then printed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f50b898f991b3ec8dadce88abad6749cb3fd8140" translate="yes" xml:space="preserve">
          <source>Finally, we have a full-fledged example of &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. It is aimed at providing a starting point for people wanting to build out-of-core learning systems and demonstrates most of the notions discussed above.</source>
          <target state="translated">И, наконец, у нас есть полноценный пример &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core классификации текстовых документов&lt;/a&gt; . Он нацелен на то, чтобы предоставить отправную точку для людей, желающих создавать системы обучения вне ядра, и демонстрирует большинство понятий, обсуждаемых выше.</target>
        </trans-unit>
        <trans-unit id="67b1b42b3e66107ae3b505ef41aac41ee3327ff3" translate="yes" xml:space="preserve">
          <source>Finally, we will consider a non-linear model, namely Gradient Boosting Regression Trees. Tree-based models do not require the categorical data to be one-hot encoded: instead, we can encode each category label with an arbitrary integer using &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. With this encoding, the trees will treat the categorical features as ordered features, which might not be always a desired behavior. However this effect is limited for deep enough trees which are able to recover the categorical nature of the features. The main advantage of the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt; over the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;OneHotEncoder&lt;/code&gt;&lt;/a&gt; is that it will make training faster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15e943be721eab8a2c2612f45c392677826a2d6c" translate="yes" xml:space="preserve">
          <source>Finally, we will plot the predictions made by all models for comparison.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9d6cf373d4d749e0936e6f64e1c533e8fd8ee41" translate="yes" xml:space="preserve">
          <source>Finally, we will visualize the 20 predictions. The red stars show the average prediction made by &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingregressor#sklearn.ensemble.VotingRegressor&quot;&gt;&lt;code&gt;VotingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f642cdc0abe545be7ddd1dd012ea6198c659512" translate="yes" xml:space="preserve">
          <source>Finally, we will visualize the results. To do that we will first compute the test set deviance and then plot it against boosting iterations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a40631d3e46670650e2553ca58294d12cd46b8ee" translate="yes" xml:space="preserve">
          <source>Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#lg2012&quot; id=&quot;id4&quot;&gt;[LG2012]&lt;/a&gt;.</source>
          <target state="translated">Наконец, когда базовые оценки строятся на подмножествах как образцов, так и функций, тогда метод известен как случайные &lt;a href=&quot;#lg2012&quot; id=&quot;id4&quot;&gt;исправления [LG2012]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7185a548932a7d63b1a08d591559f9d8821b9404" translate="yes" xml:space="preserve">
          <source>Find a &amp;lsquo;safe&amp;rsquo; number of components to randomly project to</source>
          <target state="translated">Найдите &amp;laquo;безопасное&amp;raquo; количество компонентов для случайного проецирования на</target>
        </trans-unit>
        <trans-unit id="e40e118fb652d4dd06f307746b620728b2345e85" translate="yes" xml:space="preserve">
          <source>Find a good set of parameters using grid search.</source>
          <target state="translated">Найдите хороший набор параметров с помощью поиска по сетке.</target>
        </trans-unit>
        <trans-unit id="022a840c39dad4bac6c36ba2a156531a2e97ca25" translate="yes" xml:space="preserve">
          <source>Find importance of the features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ff57da6a2f73ea1d0dfc969be6516b83c61b137" translate="yes" xml:space="preserve">
          <source>Find out what the actual encoding of the text is. The file might come with a header or README that tells you the encoding, or there might be some standard encoding you can assume based on where the text comes from.</source>
          <target state="translated">Узнайте,какова реальная кодировка текста.Файл может поставляться с заголовком или README,который сообщает вам кодировку,или может быть какая-то стандартная кодировка,которую вы можете предположить,основываясь на том,откуда приходит текст.</target>
        </trans-unit>
        <trans-unit id="c317277c718283dc0dcc7baf2d812226e24cc453" translate="yes" xml:space="preserve">
          <source>Find the minimum value of an array over positive values</source>
          <target state="translated">Найти минимальное значение массива поверх положительных значений</target>
        </trans-unit>
        <trans-unit id="d95b4144f33d10b131b37a33f2e7ad7cc55860b7" translate="yes" xml:space="preserve">
          <source>Find the optimal separating hyperplane using an SVC for classes that are unbalanced.</source>
          <target state="translated">Найдите оптимальную разделительную гиперплоскость с помощью SVC для классов,которые не сбалансированы.</target>
        </trans-unit>
        <trans-unit id="1c17584736b51c43c88ae3dfa46ea2817cd1a339" translate="yes" xml:space="preserve">
          <source>Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.</source>
          <target state="translated">Найдите две неотрицательные матрицы (W,H),продукт которых аппроксимирует неотрицательную матрицу X.Эта факторизация может быть использована,например,для уменьшения размерности,разделения источников или тематического выделения.</target>
        </trans-unit>
        <trans-unit id="4daca12ed4dca9ca21325e05dde77793902b89f7" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization parameter \(\alpha\) is best done using &lt;code&gt;GridSearchCV&lt;/code&gt;, usually in the range &lt;code&gt;10.0 ** -np.arange(1, 7)&lt;/code&gt;.</source>
          <target state="translated">Поиск подходящего параметра регуляризации \ (\ alpha \) лучше всего выполнять с помощью &lt;code&gt;GridSearchCV&lt;/code&gt; , обычно в диапазоне &lt;code&gt;10.0 ** -np.arange(1, 7)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d0410c73baea9b092d4edb9802ae4c10c09f4696" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization term \(\alpha\) is best done using &lt;code&gt;GridSearchCV&lt;/code&gt;, usually in the range &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt;.</source>
          <target state="translated">Поиск разумного члена регуляризации \ (\ alpha \) лучше всего выполнять с помощью &lt;code&gt;GridSearchCV&lt;/code&gt; , обычно в диапазоне &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="37e657d78a9dafeda1b142a17aaad5659fab59b7" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization term \(\alpha\) is best done using automatic hyper-parameter search, e.g. &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt;, usually in the range &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c5a640c918941c9e6a6ecbfe984c3f4bfbed0d7" translate="yes" xml:space="preserve">
          <source>Finding help</source>
          <target state="translated">Помощь в поиске</target>
        </trans-unit>
        <trans-unit id="71cc727880d53ab3c238ec955595a0ded28610b7" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) http://arxiv.org/pdf/0909.4061</source>
          <target state="translated">Нахождение структуры со случайностью:Стохастические алгоритмы построения приблизительных матричных разложений Halko и др.,2009 (arXiv:909)http://arxiv.org/pdf/0909.4061.</target>
        </trans-unit>
        <trans-unit id="de5cdfe8ddd63c8c4fb1f7f388d421a16cbbf828" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50ccb6d4c8a3bfa0951293912c0c5132106a8c89" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 &lt;a href=&quot;http://arxiv.org/abs/arXiv:0909.4061&quot;&gt;http://arxiv.org/abs/arXiv:0909.4061&lt;/a&gt;</source>
          <target state="translated">Поиск структуры со случайностью: стохастические алгоритмы для построения приближенных разложений матриц Халко и др., 2009 г. &lt;a href=&quot;http://arxiv.org/abs/arXiv:0909.4061&quot;&gt;http://arxiv.org/abs/arXiv:0909.4061&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="09110546ddb637f3471f1e7efbbe318b3963484e" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 &lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;https://arxiv.org/abs/0909.4061&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26becafaa69af10fe9097be8fd6bf298839f5095" translate="yes" xml:space="preserve">
          <source>Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.</source>
          <target state="translated">Находит словарь (набор атомов),который лучше всего использовать для представления данных с помощью разреженного кода.</target>
        </trans-unit>
        <trans-unit id="bdd5a22a4b66cac66c670f6f1297e40cb6d2aae2" translate="yes" xml:space="preserve">
          <source>Finds a sparse representation of data against a fixed, precomputed dictionary.</source>
          <target state="translated">Находит разреженное представление данных по фиксированному,предварительно составленному словарю.</target>
        </trans-unit>
        <trans-unit id="a5dbd88babc750758342dfe447e24f6c260c3097" translate="yes" xml:space="preserve">
          <source>Finds core samples of high density and expands clusters from them.</source>
          <target state="translated">Находит керновые образцы высокой плотности и расширяет из них кластеры.</target>
        </trans-unit>
        <trans-unit id="e0fb0de42fddb601e63b5dedf2b446e9b6fdd66e" translate="yes" xml:space="preserve">
          <source>Finds core samples of high density and expands clusters from them. This example uses data that is generated so that the clusters have different densities. The &lt;a href=&quot;../../modules/generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt;&lt;code&gt;sklearn.cluster.OPTICS&lt;/code&gt;&lt;/a&gt; is first used with its Xi cluster detection method, and then setting specific thresholds on the reachability, which corresponds to &lt;a href=&quot;../../modules/generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;sklearn.cluster.DBSCAN&lt;/code&gt;&lt;/a&gt;. We can see that the different clusters of OPTICS&amp;rsquo;s Xi method can be recovered with different choices of thresholds in DBSCAN.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0ac333cc4bd6a4e85a5691bb991f9cd4f114c12" translate="yes" xml:space="preserve">
          <source>Finds the K-neighbors of a point.</source>
          <target state="translated">Находит К-соседей по точке.</target>
        </trans-unit>
        <trans-unit id="e7def6740e556221f1aa42003fab4e2365f3483e" translate="yes" xml:space="preserve">
          <source>Finds the K-neighbors of a point. Returns indices of and distances to the neighbors of each point.</source>
          <target state="translated">Находит К-соседей по точке.Возвращает индексы и расстояния до соседей каждой точки.</target>
        </trans-unit>
        <trans-unit id="011362db8e96e3edcb95f8fcdf5f1e0d92d5e3e2" translate="yes" xml:space="preserve">
          <source>Finds the best dictionary and the corresponding sparse code for approximating the data matrix X by solving:</source>
          <target state="translated">Находит лучший словарь и соответствующий разреженный код для аппроксимации матрицы данных X путем решения:</target>
        </trans-unit>
        <trans-unit id="b6f70d43205a979d509f018cfbe88e93d812b3ec" translate="yes" xml:space="preserve">
          <source>Finds the neighbors within a given radius of a point or points.</source>
          <target state="translated">Находит соседей в заданном радиусе от точки или точек.</target>
        </trans-unit>
        <trans-unit id="dd8ddfd214a6d88017dd4006d52b1774d72e0be7" translate="yes" xml:space="preserve">
          <source>Finds the set of sparse components that can optimally reconstruct the data. The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.</source>
          <target state="translated">Находит набор разреженных компонентов,которые могут оптимально реконструировать данные.Количество редкостей контролируется коэффициентом L1 штрафа,заданным параметром alpha.</target>
        </trans-unit>
        <trans-unit id="9ce397e0f2c9f33bd1911b665e99384e26321100" translate="yes" xml:space="preserve">
          <source>Finite Gaussian mixture fit with EM.</source>
          <target state="translated">Финитарно-гауссовская смесь сочетается с ЭМ.</target>
        </trans-unit>
        <trans-unit id="fd9ae1ff1bfcac14b05b92d277d3f6074f078a31" translate="yes" xml:space="preserve">
          <source>First 10 columns are numeric predictive values</source>
          <target state="translated">Первые 10 столбцов являются числовыми прогностическими значениями</target>
        </trans-unit>
        <trans-unit id="30250bc7520fcdac140dbcf0c3820bc484ca88d7" translate="yes" xml:space="preserve">
          <source>First example</source>
          <target state="translated">Первый пример</target>
        </trans-unit>
        <trans-unit id="7874170ffefbed5d0d1c4372827ea2aeb194c3ba" translate="yes" xml:space="preserve">
          <source>First fit an ensemble of trees (totally random trees, a random forest, or gradient boosted trees) on the training set. Then each leaf of each tree in the ensemble is assigned a fixed arbitrary feature index in a new feature space. These leaf indices are then encoded in a one-hot fashion.</source>
          <target state="translated">Сначала на тренировочную площадку устанавливается ансамбль деревьев (совершенно случайные деревья,случайный лес,или деревья с градиентной формой).Затем каждому листу каждого дерева в ансамбле присваивается фиксированный произвольный индекс признаков в новом пространстве признаков.Эти индексы листьев затем кодируются в одноразовом режиме.</target>
        </trans-unit>
        <trans-unit id="c9c47ba90ccfdfceca4eb5b8199939d35b815802" translate="yes" xml:space="preserve">
          <source>First note that the K means \(\mu_k\) are vectors in \(\mathcal{R}^d\), and they lie in an affine subspace \(H\) of dimension at least \(K - 1\) (2 points lie on a line, 3 points lie on a plane, etc).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b7d36dc535373f63b2b8c97af1496035ebdccf8" translate="yes" xml:space="preserve">
          <source>First of all, we can take a look to the values of the coefficients of the regressor we have fitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af1667b67f8a74831d9cbccc10fec01c4bb8c75d" translate="yes" xml:space="preserve">
          <source>First we check which value of \(\alpha\) has been selected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31c524afbf18465a1ae6f80767e0e696d536b875" translate="yes" xml:space="preserve">
          <source>First we create a data set of 9 samples from 3 classes, and plot the points in the original space. For this example, we focus on the classification of point no. 3. The thickness of a link between point no. 3 and another point is proportional to their distance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66d3e97d3998fff9804546e983728130f9a1d48d" translate="yes" xml:space="preserve">
          <source>First we download the two datasets. Diabetes dataset is shipped with scikit-learn. It has 442 entries, each with 10 features. California Housing dataset is much larger with 20640 entries and 8 features. It needs to be downloaded. We will only use the first 400 entries for the sake of speeding up the calculations but feel free to use the whole dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e4b6f9c83c90558d9df87e3572e1d8ff690d21" translate="yes" xml:space="preserve">
          <source>First we need to load the data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d180e35a78f80e45c6959bdc2213230723a6ec9" translate="yes" xml:space="preserve">
          <source>First we verify which value of \(\alpha\) has been selected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da6f0be97a3f9bc23cb9968f6dd764558635185b" translate="yes" xml:space="preserve">
          <source>First, let&amp;rsquo;s get some insights by looking at the variable distributions and at the pairwise relationships between them. Only numerical variables will be used. In the following plot, each dot represents a sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c794cffa5e7e2eb61589bb3349c992e76e5c222" translate="yes" xml:space="preserve">
          <source>First, let&amp;rsquo;s load the diabetes dataset which is available from within sklearn. Then, we will look what features are collected for the diabates patients:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac3b241d42030e20b4b1109edf6cf6d51db7345" translate="yes" xml:space="preserve">
          <source>First, the precomputed graph can be re-used multiple times, for instance while varying a parameter of the estimator. This can be done manually by the user, or using the caching properties of the scikit-learn pipeline:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97be8aa0250f0cdac7301eb79bf3b2a478185ccc" translate="yes" xml:space="preserve">
          <source>First, three examplary classifiers are initialized (&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt;) and used to initialize a soft-voting &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; with weights &lt;code&gt;[1, 1, 5]&lt;/code&gt;, which means that the predicted probabilities of the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; count 5 times as much as the weights of the other classifiers when the averaged probability is calculated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16a8cd51addf2278ba02a88d4c3026fabfe281d9" translate="yes" xml:space="preserve">
          <source>First, three examplary classifiers are initialized (&lt;code&gt;LogisticRegression&lt;/code&gt;, &lt;code&gt;GaussianNB&lt;/code&gt;, and &lt;code&gt;RandomForestClassifier&lt;/code&gt;) and used to initialize a soft-voting &lt;code&gt;VotingClassifier&lt;/code&gt; with weights &lt;code&gt;[1, 1, 5]&lt;/code&gt;, which means that the predicted probabilities of the &lt;code&gt;RandomForestClassifier&lt;/code&gt; count 5 times as much as the weights of the other classifiers when the averaged probability is calculated.</source>
          <target state="translated">Сначала инициализируются три примерных классификатора ( &lt;code&gt;LogisticRegression&lt;/code&gt; , &lt;code&gt;GaussianNB&lt;/code&gt; и &lt;code&gt;RandomForestClassifier&lt;/code&gt; ), которые используются для инициализации &lt;code&gt;VotingClassifier&lt;/code&gt; с мягким голосованием с весами &lt;code&gt;[1, 1, 5]&lt;/code&gt; , что означает, что прогнозируемые вероятности &lt;code&gt;RandomForestClassifier&lt;/code&gt; в 5 раз больше, чем веса других классификаторов при вычислении средней вероятности.</target>
        </trans-unit>
        <trans-unit id="f50c60bee958db3de20cd6c08f2c3fe9b2fb6e88" translate="yes" xml:space="preserve">
          <source>First, three exemplary classifiers are initialized (&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;) and used to initialize a soft-voting &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; with weights &lt;code&gt;[2,
1, 2]&lt;/code&gt;, which means that the predicted probabilities of the &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; each count 2 times as much as the weights of the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; classifier when the averaged probability is calculated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ea180eeb1f820255090eaa2e746ff697919b622" translate="yes" xml:space="preserve">
          <source>First, three exemplary classifiers are initialized (&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;, &lt;code&gt;KNeighborsClassifier&lt;/code&gt;, and &lt;code&gt;SVC&lt;/code&gt;) and used to initialize a soft-voting &lt;code&gt;VotingClassifier&lt;/code&gt; with weights &lt;code&gt;[2, 1, 2]&lt;/code&gt;, which means that the predicted probabilities of the &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; and &lt;code&gt;SVC&lt;/code&gt; count 5 times as much as the weights of the &lt;code&gt;KNeighborsClassifier&lt;/code&gt; classifier when the averaged probability is calculated.</source>
          <target state="translated">Сначала инициализируются три примерных классификатора ( &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; , &lt;code&gt;KNeighborsClassifier&lt;/code&gt; и &lt;code&gt;SVC&lt;/code&gt; ), которые используются для инициализации &lt;code&gt;VotingClassifier&lt;/code&gt; с мягким голосованием с весами &lt;code&gt;[2, 1, 2]&lt;/code&gt; , что означает, что прогнозируемые вероятности &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; и &lt;code&gt;SVC&lt;/code&gt; в 5 раз больше как веса классификатора &lt;code&gt;KNeighborsClassifier&lt;/code&gt; при вычислении усредненной вероятности.</target>
        </trans-unit>
        <trans-unit id="5fdc5502e4f55e2ed52afffb452568aea16c1218" translate="yes" xml:space="preserve">
          <source>First, we fit the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9c4b59f96926f6f0e5f166376f8408083d95db" translate="yes" xml:space="preserve">
          <source>First, we load the wine dataset and convert it to a binary classification problem. Then, we train a support vector classifier on a training dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d07cc681f72e7314cfb570248652c85d831875b" translate="yes" xml:space="preserve">
          <source>First, we must understand the structure of our data. It has 100 randomly generated input datapoints, 3 classes split unevenly across datapoints, and 10 &amp;ldquo;groups&amp;rdquo; split evenly across datapoints.</source>
          <target state="translated">Во-первых, мы должны понять структуру наших данных. Он имеет 100 случайно сгенерированных входных точек данных, 3 класса, неравномерно разделенных по точкам данных, и 10 &amp;laquo;групп&amp;raquo;, равномерно разделенных по точкам данных.</target>
        </trans-unit>
        <trans-unit id="cc0ba427a614a821f465ac72c31717d2cbd7abed" translate="yes" xml:space="preserve">
          <source>First, we train a decision tree and a multi-layer perceptron on the diabetes dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f123dfa67a1788d2150ed770bdb351ff3e4fb8cc" translate="yes" xml:space="preserve">
          <source>First, we train a random forest on the breast cancer dataset and evaluate its accuracy on a test set:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b8f70566f670b04c1ac522dc7b0f129462badb9" translate="yes" xml:space="preserve">
          <source>First, we want to estimate the score on the original data:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fab091b4d5d2bc522f0ed86af86bd56d5c7a2d19" translate="yes" xml:space="preserve">
          <source>First, we will load the diabetes dataset and initiate a gradient boosting regressor, a random forest regressor and a linear regression. Next, we will use the 3 regressors to build the voting regressor:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5918b4ffaa61bc5b2d97e424d8740b3562535f07" translate="yes" xml:space="preserve">
          <source>First, we would like a transformer that extracts the subject and body of each post. Since this is a stateless transformation (does not require state information from training data), we can define a function that performs the data transformation then use &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt; to create a scikit-learn transformer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b01058ecfb06b2978590da1239a0a81618b1465b" translate="yes" xml:space="preserve">
          <source>Fisher transformation. Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Fisher_transformation&quot;&gt;https://en.wikipedia.org/wiki/Fisher_transformation&lt;/a&gt;</source>
          <target state="translated">Преобразование Фишера. Википедия. &lt;a href=&quot;https://en.wikipedia.org/wiki/Fisher_transformation&quot;&gt;https://en.wikipedia.org/wiki/Fisher_transformation&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="75ec02df98bcfaf21ee3dd0abe872b47c664ba1c" translate="yes" xml:space="preserve">
          <source>Fisher, R.A. &amp;ldquo;The use of multiple measurements in taxonomic problems&amp;rdquo; Annual Eugenics, 7, Part II, 179-188 (1936); also in &amp;ldquo;Contributions to Mathematical Statistics&amp;rdquo; (John Wiley, NY, 1950).</source>
          <target state="translated">Фишер Р.А. &amp;laquo;Использование множественных измерений в таксономических проблемах&amp;raquo; Annual Eugenics, 7, Part II, 179-188 (1936); также в &amp;laquo;Вкладах в математическую статистику&amp;raquo; (John Wiley, NY, 1950).</target>
        </trans-unit>
        <trans-unit id="4d49737491d2fdff73fcfce78bfa3496db9aead4" translate="yes" xml:space="preserve">
          <source>Fit Gaussian Naive Bayes according to X, y</source>
          <target state="translated">Fit Gaussian Naive Bayes в соответствии с X,y</target>
        </trans-unit>
        <trans-unit id="5697d81dd45cef7c7ddb8bf2ab425085bcc0125d" translate="yes" xml:space="preserve">
          <source>Fit Gaussian process classification model</source>
          <target state="translated">Соответствует гауссовской модели классификации процессов</target>
        </trans-unit>
        <trans-unit id="87cac59f89b2fa13ce5de11220e3eeec4bd8c5cf" translate="yes" xml:space="preserve">
          <source>Fit Gaussian process regression model.</source>
          <target state="translated">Модель регрессии гауссовых процессов.</target>
        </trans-unit>
        <trans-unit id="8eb1d823143ba03b3eb9b823b5dab8b0cf44511a" translate="yes" xml:space="preserve">
          <source>Fit Kernel Ridge regression model</source>
          <target state="translated">Встроенная регрессионная модель хребта Кернел</target>
        </trans-unit>
        <trans-unit id="62df27bb0a01d202786ab5c8f2652f91558551a4" translate="yes" xml:space="preserve">
          <source>Fit KernelCenterer</source>
          <target state="translated">Установить КернелЦентр</target>
        </trans-unit>
        <trans-unit id="f97a5239f74bba940e2a0890df2d8120afcfa03c" translate="yes" xml:space="preserve">
          <source>Fit LSI model on training data X.</source>
          <target state="translated">Встроить модель LSI по учебным данным X.</target>
        </trans-unit>
        <trans-unit id="c2f5d79cd7108f6536b92a8ab72454a376b81e9e" translate="yes" xml:space="preserve">
          <source>Fit LSI model to X and perform dimensionality reduction on X.</source>
          <target state="translated">Установите модель LSI на X и выполните уменьшение размерности на X.</target>
        </trans-unit>
        <trans-unit id="f79f31a7bd81775029053b8e229553093e280715" translate="yes" xml:space="preserve">
          <source>Fit LinearDiscriminantAnalysis model according to the given</source>
          <target state="translated">Модель Fit LinearDiscriminantAnalysis в соответствии с заданной</target>
        </trans-unit>
        <trans-unit id="5a914df7976c81fad1a03ac324a4632a19d9e602" translate="yes" xml:space="preserve">
          <source>Fit LinearDiscriminantAnalysis model according to the given training data and parameters.</source>
          <target state="translated">Модель Fit LinearDiscriminantAnalysis в соответствии с заданными учебными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="cb91a62a58b24a52b6e32fdd160e489a55cfbac1" translate="yes" xml:space="preserve">
          <source>Fit MultiTaskElasticNet model with coordinate descent</source>
          <target state="translated">Подгонка модели MultiTaskElasticNet с понижением координат</target>
        </trans-unit>
        <trans-unit id="07e793af99a651a8f0a47822a080e4cf194bac9b" translate="yes" xml:space="preserve">
          <source>Fit Naive Bayes classifier according to X, y</source>
          <target state="translated">Подходит Naive Bayes классификатор в соответствии с X,y</target>
        </trans-unit>
        <trans-unit id="afc10844f54e485a835b4e52b36e0ebefe70c8de" translate="yes" xml:space="preserve">
          <source>Fit OneHotEncoder to X, then transform X.</source>
          <target state="translated">Установите OneHotEncoder на X,затем трансформируйте X.</target>
        </trans-unit>
        <trans-unit id="6cbc8c577214883d5f9bdf864d2a7d76e95b5a74" translate="yes" xml:space="preserve">
          <source>Fit OneHotEncoder to X.</source>
          <target state="translated">Установите OneHotEncoder на X.</target>
        </trans-unit>
        <trans-unit id="7a3e15c6e4bf063bec4aa435d4748fb868286ed7" translate="yes" xml:space="preserve">
          <source>Fit Ridge and HuberRegressor on a dataset with outliers.</source>
          <target state="translated">Установите Ridge и HuberRegressor на набор данных с отклонениями.</target>
        </trans-unit>
        <trans-unit id="9157b13407894777185a7ac8935a66fc19422ca1" translate="yes" xml:space="preserve">
          <source>Fit Ridge classifier model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e744f084cdfc69f98e0c6bdc1ef85d9a5fdf52b4" translate="yes" xml:space="preserve">
          <source>Fit Ridge classifier with cv.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8e3b0b4710ae51d90dcd69d91e33d123946d3a" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model</source>
          <target state="translated">регрессионная модель Fit Ridge</target>
        </trans-unit>
        <trans-unit id="47da48f063cc42a3f008d1e6c416d90a29ea0591" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model with cv.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e3e7ebdde04653523f01d0d804ccc0c533f3460" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model.</source>
          <target state="translated">Модель регрессии Fit Ridge.</target>
        </trans-unit>
        <trans-unit id="74fbf563cb041ef637760be7f01def498fc1300e" translate="yes" xml:space="preserve">
          <source>Fit X into an embedded space and return that transformed output.</source>
          <target state="translated">Вставьте X во встроенное пространство и верните преобразованный выходной сигнал.</target>
        </trans-unit>
        <trans-unit id="97ca0bc1677dbeaefd600411062ca557eacc6754" translate="yes" xml:space="preserve">
          <source>Fit X into an embedded space.</source>
          <target state="translated">Вставьте X во встроенное пространство.</target>
        </trans-unit>
        <trans-unit id="9b21c283121f9ec299302b1b3016dbcdb3391466" translate="yes" xml:space="preserve">
          <source>Fit a Bayesian ridge model and optimize the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</source>
          <target state="translated">Подгоните байесовскую модель гребня и оптимизируйте параметры регуляризации лямбда (точность весов)и альфа (точность шума).</target>
        </trans-unit>
        <trans-unit id="dd6f625705b26516fc692deb07fa9f7046f6035b" translate="yes" xml:space="preserve">
          <source>Fit a Bayesian ridge model. See the Notes section for details on this implementation and the optimization of the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dac39fc69b5b06ff2bcc2ce8d7b8984bce5d49fc" translate="yes" xml:space="preserve">
          <source>Fit a Generalized Linear Model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8bec80135f416f6c22f260fc3b1ac04b4cff59ba" translate="yes" xml:space="preserve">
          <source>Fit a model to the random subset (&lt;code&gt;base_estimator.fit&lt;/code&gt;) and check whether the estimated model is valid (see &lt;code&gt;is_model_valid&lt;/code&gt;).</source>
          <target state="translated">&lt;code&gt;base_estimator.fit&lt;/code&gt; модель к случайному подмножеству ( base_estimator.fit ) и проверьте, действительна ли оценочная модель (см. &lt;code&gt;is_model_valid&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="ebd8c04ad061ef008e394e38c512b2d8b58287fa" translate="yes" xml:space="preserve">
          <source>Fit a semi-supervised label propagation model based</source>
          <target state="translated">Подходит для полууправляемой модели распространения этикетки на основе</target>
        </trans-unit>
        <trans-unit id="deba03b3f9d00ab1e647b43aa626a17c324cec03" translate="yes" xml:space="preserve">
          <source>Fit all the transforms one after the other and transform the data, then fit the transformed data using the final estimator.</source>
          <target state="translated">Подгоните все преобразования одно за другим и преобразовывайте данные,затем подгоните преобразованные данные с помощью конечного оценщика.</target>
        </trans-unit>
        <trans-unit id="114f8ea42731308cb5abe991bcd972d570944b6a" translate="yes" xml:space="preserve">
          <source>Fit all transformers using X.</source>
          <target state="translated">Установите все трансформаторы с помощью X.</target>
        </trans-unit>
        <trans-unit id="246e8826a6bd7a4f56f132c591c766db9ce2d6b0" translate="yes" xml:space="preserve">
          <source>Fit all transformers, transform the data and concatenate results.</source>
          <target state="translated">Установите все трансформаторы,трансформируйте данные и скомканируйте результаты.</target>
        </trans-unit>
        <trans-unit id="922528f3171c2d46b470779ae89446b3062cf8a4" translate="yes" xml:space="preserve">
          <source>Fit estimator and transform dataset.</source>
          <target state="translated">Установите оценочное устройство и трансформируйте набор данных.</target>
        </trans-unit>
        <trans-unit id="54af94e49eb61f7670851d6ef57ae7193fdff2da" translate="yes" xml:space="preserve">
          <source>Fit estimator to data.</source>
          <target state="translated">Подгоните оценщик под данные.</target>
        </trans-unit>
        <trans-unit id="85fa5fe8b9795ca2b319f392f4a4756a8b584c81" translate="yes" xml:space="preserve">
          <source>Fit estimator using RANSAC algorithm.</source>
          <target state="translated">Установите оценщик,используя алгоритм RANSAC.</target>
        </trans-unit>
        <trans-unit id="820a840249b34711a41e746dbc8ea00e0bef6043" translate="yes" xml:space="preserve">
          <source>Fit estimator.</source>
          <target state="translated">Подходит оценщик.</target>
        </trans-unit>
        <trans-unit id="c7654cec30bb319e2781e513c9f9ca93708de9b2" translate="yes" xml:space="preserve">
          <source>Fit is on grid of alphas and best alpha estimated by cross-validation.</source>
          <target state="translated">Установка находится на сетке альфов и лучшего альфа,оцененного путем перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="b8cbf7d1420444207c14a8b65b5fcf478860f130" translate="yes" xml:space="preserve">
          <source>Fit label binarizer</source>
          <target state="translated">Встроенный бинаризатор этикеток</target>
        </trans-unit>
        <trans-unit id="e7ecedc7848a8ef424a3d78854bd272e8154c780" translate="yes" xml:space="preserve">
          <source>Fit label binarizer and transform multi-class labels to binary labels.</source>
          <target state="translated">Установите бинаризатор этикеток и трансформируйте многоклассные этикетки в двоичные.</target>
        </trans-unit>
        <trans-unit id="c75cef45e92464b24b2d996a50f9aed44b9ef31e" translate="yes" xml:space="preserve">
          <source>Fit label encoder</source>
          <target state="translated">Встроенный кодировщик этикеток</target>
        </trans-unit>
        <trans-unit id="5de88deba19907fdf6f6eb3678730f7aacb3c312" translate="yes" xml:space="preserve">
          <source>Fit label encoder and return encoded labels</source>
          <target state="translated">Встроенный кодировщик этикеток и возвращаемые кодированные этикетки</target>
        </trans-unit>
        <trans-unit id="cf615a74e4f9177f1a29f39484c75ecef454ecbe" translate="yes" xml:space="preserve">
          <source>Fit linear model with Passive Aggressive algorithm.</source>
          <target state="translated">Подгоните линейную модель под алгоритм пассивной агрессивности.</target>
        </trans-unit>
        <trans-unit id="def5054532c40485109a181ee65c06aba2df1b53" translate="yes" xml:space="preserve">
          <source>Fit linear model with Stochastic Gradient Descent.</source>
          <target state="translated">Подходит линейная модель со стохастическим градиентным спуском.</target>
        </trans-unit>
        <trans-unit id="80dff5f041e36b3407c4f4e7528431510ae562cc" translate="yes" xml:space="preserve">
          <source>Fit linear model with coordinate descent</source>
          <target state="translated">Установить линейную модель с координатным спуском</target>
        </trans-unit>
        <trans-unit id="4a42bd8bc00e1e2eb46153b9c0e14ea2a3d30f42" translate="yes" xml:space="preserve">
          <source>Fit linear model.</source>
          <target state="translated">Подгоните линейную модель.</target>
        </trans-unit>
        <trans-unit id="596c5db56f9a987de5f7691971fcf687d77673ec" translate="yes" xml:space="preserve">
          <source>Fit model to data.</source>
          <target state="translated">Подгоните модель под данные.</target>
        </trans-unit>
        <trans-unit id="7bad9b91d21434b63dea0481c80eaf84a7cbcb25" translate="yes" xml:space="preserve">
          <source>Fit model with coordinate descent.</source>
          <target state="translated">Установите модель с координатным спуском.</target>
        </trans-unit>
        <trans-unit id="8c69e1745d795a8f39d4e8e6661ab7afc8b0bcff" translate="yes" xml:space="preserve">
          <source>Fit regression model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dddcb769b9b69c71c174f417fcd2a333b19f55fd" translate="yes" xml:space="preserve">
          <source>Fit regression model with Bayesian Ridge Regression.</source>
          <target state="translated">Подгоните регрессионную модель под Байесовский хребет.</target>
        </trans-unit>
        <trans-unit id="dda67be7d4db5d3187deb44446a3404222c185a6" translate="yes" xml:space="preserve">
          <source>Fit the ARDRegression model according to the given training data and parameters.</source>
          <target state="translated">Установите модель ARDRegression в соответствии с заданными учебными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="b5a680830417593aa73dd7de7fcef69c6ed24e1b" translate="yes" xml:space="preserve">
          <source>Fit the EllipticEnvelope model.</source>
          <target state="translated">Подходит под модель EllipticEnvelope.</target>
        </trans-unit>
        <trans-unit id="b52ba2a596ae6c033bcc7f3cf20ecd5c58d00c2f" translate="yes" xml:space="preserve">
          <source>Fit the FactorAnalysis model to X using EM</source>
          <target state="translated">Подгоните модель FactorAnalysis к X,используя EM</target>
        </trans-unit>
        <trans-unit id="d35f22f8e1c64965b364c3173e1ec356759343b4" translate="yes" xml:space="preserve">
          <source>Fit the FactorAnalysis model to X using SVD based approach</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6613ce48c67ddab345a10c60b764cb90b5d43667" translate="yes" xml:space="preserve">
          <source>Fit the Kernel Density model on the data.</source>
          <target state="translated">Подгоните модель Kernel Density под данные.</target>
        </trans-unit>
        <trans-unit id="18de2bdae7f6b4aabf66891dec1f775662960310" translate="yes" xml:space="preserve">
          <source>Fit the LSH forest on the data.</source>
          <target state="translated">Установите лес LSH по данным.</target>
        </trans-unit>
        <trans-unit id="12a1c0d798db89b07ae159bda7700f6de8a414b1" translate="yes" xml:space="preserve">
          <source>Fit the Ledoit-Wolf shrunk covariance model according to the given training data and parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e835684e570bb3989f14c8abec4c77362174b02" translate="yes" xml:space="preserve">
          <source>Fit the NearestCentroid model according to the given training data.</source>
          <target state="translated">Установите модель NearestCentroid в соответствии с данными тренинга.</target>
        </trans-unit>
        <trans-unit id="faef2120c4a0d719909dbc882126884ed71710cf" translate="yes" xml:space="preserve">
          <source>Fit the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f68da32a4110559ba3f4b03666c6374bbe1b67bc" translate="yes" xml:space="preserve">
          <source>Fit the OrdinalEncoder to X.</source>
          <target state="translated">Установите орденальный кодировщик на X.</target>
        </trans-unit>
        <trans-unit id="9efb3f60cfc062ba641dafe57455afe5be189469" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and automatically tune the number of selected</source>
          <target state="translated">Встроить RFE модель и автоматически настроить количество выбранных</target>
        </trans-unit>
        <trans-unit id="a1f31e1eab4986ee8b13885092428f58b3a203e9" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and automatically tune the number of selected features.</source>
          <target state="translated">Установите RFE модель и автоматически настройте количество выбранных функций.</target>
        </trans-unit>
        <trans-unit id="9813edcd03393c0187279f71f7b7e90f266a7ca4" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and then the underlying estimator on the selected</source>
          <target state="translated">Установите RFE модель,а затем базовый оценщик на выбранный</target>
        </trans-unit>
        <trans-unit id="2e888db086bdb6861e2b6c27ddb4959896a661ee" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and then the underlying estimator on the selected features.</source>
          <target state="translated">Установите RFE модель,а затем оценочное значение для выбранных функций.</target>
        </trans-unit>
        <trans-unit id="3e8e54a78ebc1bc30d8f6371731aa34e571e1cb7" translate="yes" xml:space="preserve">
          <source>Fit the SVM model according to the given training data.</source>
          <target state="translated">Установите модель SVM в соответствии с заданными учебными данными.</target>
        </trans-unit>
        <trans-unit id="e094bb2f16b3f77c4f0ded4998dd5acef469f424" translate="yes" xml:space="preserve">
          <source>Fit the SelectFromModel meta-transformer only once.</source>
          <target state="translated">Установите мета-трансформатор SelectFromModel только один раз.</target>
        </trans-unit>
        <trans-unit id="4f2b5174d874ffda16493a72eb6b7d9e49692dfa" translate="yes" xml:space="preserve">
          <source>Fit the SelectFromModel meta-transformer.</source>
          <target state="translated">Установите мета-трансформатор SelectFromModel.</target>
        </trans-unit>
        <trans-unit id="48df38063d696d0aeb8b0988a010338565cac757" translate="yes" xml:space="preserve">
          <source>Fit the calibrated model</source>
          <target state="translated">Подберите калиброванную модель</target>
        </trans-unit>
        <trans-unit id="c57e47c49821e6802e2a740c9051d8c66c744ebb" translate="yes" xml:space="preserve">
          <source>Fit the clustering from features or affinity matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9687ab7d6ecd0d65550bf660d242c20bd8d898b" translate="yes" xml:space="preserve">
          <source>Fit the clustering from features, or affinity matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="548ac10033a88a7f2f90c29b16d9b1eac7c9baf8" translate="yes" xml:space="preserve">
          <source>Fit the data from X, and returns the embedded coordinates</source>
          <target state="translated">Устанавливает данные из X и возвращает встроенные координаты</target>
        </trans-unit>
        <trans-unit id="08758549856b6a0e509ce1e713cae02d47e4bedc" translate="yes" xml:space="preserve">
          <source>Fit the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="855887273459477b0845aa915278722b2bfdc95e" translate="yes" xml:space="preserve">
          <source>Fit the estimators.</source>
          <target state="translated">Подгоните оценщиков.</target>
        </trans-unit>
        <trans-unit id="78a5f0fa7f9e8e8876e6f8fdd879d2a72169691e" translate="yes" xml:space="preserve">
          <source>Fit the gradient boosting model.</source>
          <target state="translated">Установите модель увеличения градиента.</target>
        </trans-unit>
        <trans-unit id="59e531372ee14a17e072823da12da9c216d03637" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering from features or distance matrix, and return cluster labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f5e34ffa1bdd98c15becac765f254aeb2f0a093" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering from features, or distance matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6951b3b9c1e77870a95debb989a3776ac4c5d6a1" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering on the data</source>
          <target state="translated">Установить иерархическую кластеризацию данных</target>
        </trans-unit>
        <trans-unit id="5b5563854bcbf3fe8e972427b6550f84e6f5e44a" translate="yes" xml:space="preserve">
          <source>Fit the imputer on X.</source>
          <target state="translated">Установите имплантатор на Икс.</target>
        </trans-unit>
        <trans-unit id="f79ad350ada74918a25b6a18b9c98a44219aea81" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer and transform the given label sets</source>
          <target state="translated">Установите бинаризатор наборов этикеток и трансформируйте данные наборы этикеток.</target>
        </trans-unit>
        <trans-unit id="93ac61c2b8893a8a8dc44af4d06cf2252851b7b2" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer, storing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-classes&quot;&gt;classes_&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aff4cb7658d810f05c33be44cd22feded7d4bab1" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer, storing &lt;code&gt;classes_&lt;/code&gt;</source>
          <target state="translated">Подгонка под метку устанавливает бинаризатор, сохраняя &lt;code&gt;classes_&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8fe48671e323549fd93560341a4a3c7b625e4c7d" translate="yes" xml:space="preserve">
          <source>Fit the model</source>
          <target state="translated">Подгоните модель</target>
        </trans-unit>
        <trans-unit id="4a0fb954f184570eb54f89782d45ff6b62de8f93" translate="yes" xml:space="preserve">
          <source>Fit the model according to the given training data and parameters.</source>
          <target state="translated">Установите модель в соответствии с заданными учебными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="226810036d48f43519ac6362c835a5ebb75ac273" translate="yes" xml:space="preserve">
          <source>Fit the model according to the given training data.</source>
          <target state="translated">Подгоните модель в соответствии с заданными учебными данными.</target>
        </trans-unit>
        <trans-unit id="12dc3b0f35bd8c187f3d6ad72da28e55416ad4ec" translate="yes" xml:space="preserve">
          <source>Fit the model and recover the sources from X.</source>
          <target state="translated">Подгоните модель и восстановите источники из X.</target>
        </trans-unit>
        <trans-unit id="71e9ee1734e2bbf9ac4fe07ac1b6c03c04237b08" translate="yes" xml:space="preserve">
          <source>Fit the model and transform with the final estimator</source>
          <target state="translated">Подгоните модель и трансформируйте ее с помощью конечного оценщика</target>
        </trans-unit>
        <trans-unit id="6b8aa0f161bb8a77dc4775ed1ee1fcfc2c406c82" translate="yes" xml:space="preserve">
          <source>Fit the model from data in X and transform X.</source>
          <target state="translated">Поместите модель из данных в X и преобразовать X.</target>
        </trans-unit>
        <trans-unit id="0aa179622924cc08ee70a31764d01ab49bbf6bcd" translate="yes" xml:space="preserve">
          <source>Fit the model from data in X.</source>
          <target state="translated">Поместите модель из данных в X.</target>
        </trans-unit>
        <trans-unit id="09a244ac4f08853db4f27fa0f56ca2d8ae157c91" translate="yes" xml:space="preserve">
          <source>Fit the model to X.</source>
          <target state="translated">Установите модель на X.</target>
        </trans-unit>
        <trans-unit id="d8fc33348e2baabb167cc4df9e594abe384c1eb2" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and target y.</source>
          <target state="translated">Подгоните модель под матрицу данных X и цель y.</target>
        </trans-unit>
        <trans-unit id="a08fe1d5397b99194d7ea288b13912038b863a22" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and target(s) y.</source>
          <target state="translated">Подгоните модель под матрицу данных X и цель(ы)y.</target>
        </trans-unit>
        <trans-unit id="5260da8ec9e88ebba64d6137961aeb8e84b7f391" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and targets Y.</source>
          <target state="translated">Подгоните модель под матрицу данных X и цели Y.</target>
        </trans-unit>
        <trans-unit id="45ba17915e2e3031d1582da2d277da7f4931a4e1" translate="yes" xml:space="preserve">
          <source>Fit the model to data.</source>
          <target state="translated">Подгоните модель под данные.</target>
        </trans-unit>
        <trans-unit id="afd434d49f80c8d01132ca406d4c79b805654e96" translate="yes" xml:space="preserve">
          <source>Fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">Подгоните модель под данные.Устанавливайте отдельную модель для каждой выходной переменной.</target>
        </trans-unit>
        <trans-unit id="cfdc299b35aa8a48c0af501e27ae7cce65e8f528" translate="yes" xml:space="preserve">
          <source>Fit the model to the data X which should contain a partial segment of the data.</source>
          <target state="translated">Подгоните модель под данные X,которые должны содержать частичный сегмент данных.</target>
        </trans-unit>
        <trans-unit id="b93160749fdae6a7fa042ecb31b3787d54faa056" translate="yes" xml:space="preserve">
          <source>Fit the model to the data X.</source>
          <target state="translated">Подгоните модель под данные X.</target>
        </trans-unit>
        <trans-unit id="22b95bc22aacaf67cf593094b402a5ffdf9c9f1a" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data</source>
          <target state="translated">Установите модель,используя X в качестве обучающих данных</target>
        </trans-unit>
        <trans-unit id="c8f2bc6ec471b46a95d660913e3db5351ccdd413" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data and y as target values</source>
          <target state="translated">Установите модель,используя X в качестве обучающих данных и y в качестве целевых значений.</target>
        </trans-unit>
        <trans-unit id="67d84010e7f659892bf337ed29c5877ed8354203" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data.</source>
          <target state="translated">Установите модель,используя X в качестве обучающих данных.</target>
        </trans-unit>
        <trans-unit id="3b6c346e2454cc9e9a61a017fe7c431d552c8c5b" translate="yes" xml:space="preserve">
          <source>Fit the model using X, y as training data.</source>
          <target state="translated">Установите модель,используя X,y в качестве тренировочных данных.</target>
        </trans-unit>
        <trans-unit id="5c7f073bf35ac36015511e86a701acdf9d1f18c6" translate="yes" xml:space="preserve">
          <source>Fit the model with X and apply the dimensionality reduction on X.</source>
          <target state="translated">Установите модель на X и применяйте уменьшение размерности на X.</target>
        </trans-unit>
        <trans-unit id="ea7ce544f3a486e6f2a49538bf4fe64bf5a8afde" translate="yes" xml:space="preserve">
          <source>Fit the model with X, using minibatches of size batch_size.</source>
          <target state="translated">Подгоните модель под X,используя мини-пакеты размера batch_size.</target>
        </trans-unit>
        <trans-unit id="e7967bf329b3c1f757d75d92e374951929321ba7" translate="yes" xml:space="preserve">
          <source>Fit the model with X.</source>
          <target state="translated">Подгоните модель под Икс.</target>
        </trans-unit>
        <trans-unit id="a5abbc09518b549e779e08db2e6e49f0ba32533d" translate="yes" xml:space="preserve">
          <source>Fit the random classifier.</source>
          <target state="translated">Поместите случайный классификатор.</target>
        </trans-unit>
        <trans-unit id="30f7575e3bac8aaa2852370b548ad3f04b290586" translate="yes" xml:space="preserve">
          <source>Fit the random regressor.</source>
          <target state="translated">Установите случайный регрессор.</target>
        </trans-unit>
        <trans-unit id="4fae2d49ee8a5e8d8ea52343db3e2b05ff45988e" translate="yes" xml:space="preserve">
          <source>Fit the ridge classifier.</source>
          <target state="translated">Подходит под классификатор хребтов.</target>
        </trans-unit>
        <trans-unit id="1e4446f620ec40ca22b46eba2b6f8ce6be3c57e2" translate="yes" xml:space="preserve">
          <source>Fit the shrunk covariance model according to the given training data and parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b96765d688b574c756064537ec2686c8ac36571" translate="yes" xml:space="preserve">
          <source>Fit the transformer on X.</source>
          <target state="translated">Установите трансформатор на Х.</target>
        </trans-unit>
        <trans-unit id="acd485cd941415835a11d2180278c2146ce5888c" translate="yes" xml:space="preserve">
          <source>Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Also estimate the parameters lambda (precisions of the distributions of the weights) and alpha (precision of the distribution of the noise). The estimation is done by an iterative procedures (Evidence Maximization)</source>
          <target state="translated">Установите веса регрессионной модели,используя ARD prior.Предполагается,что веса регрессионной модели находятся в гауссовых распределениях.Также оценивают параметры лямбда (точности распределения весов)и альфа (точность распределения шума).Оценка производится с помощью итерационных процедур (Evidence Maximization).</target>
        </trans-unit>
        <trans-unit id="ea18404b90123396c3f41537d11afad54c507780" translate="yes" xml:space="preserve">
          <source>Fit to data, then transform it.</source>
          <target state="translated">Подгоните под данные,а затем трансформируйте их.</target>
        </trans-unit>
        <trans-unit id="c2cf341635a3875675d46dd618b9a1757d9a6c7c" translate="yes" xml:space="preserve">
          <source>Fit transformer by checking X.</source>
          <target state="translated">Установите трансформатор,проверив X.</target>
        </trans-unit>
        <trans-unit id="eb75d7eb91b3dadf245e1b3bf8f4c37a27824085" translate="yes" xml:space="preserve">
          <source>Fit underlying estimators.</source>
          <target state="translated">Подходит для базовых оценок.</target>
        </trans-unit>
        <trans-unit id="c093c0cee7f3b9fa93ffb32acb026baea322889f" translate="yes" xml:space="preserve">
          <source>Fits a Minimum Covariance Determinant with the FastMCD algorithm.</source>
          <target state="translated">Устанавливает детерминант минимальной ковариативности с помощью алгоритма FastMCD.</target>
        </trans-unit>
        <trans-unit id="f30506afc59d08eae550fdeb02ae856731ea996b" translate="yes" xml:space="preserve">
          <source>Fits all the transforms one after the other and transforms the data, then uses fit_transform on transformed data with the final estimator.</source>
          <target state="translated">Устанавливает все преобразования одно за другим и преобразует данные,затем использует функцию fit_transform на преобразованных данных с конечным оценщиком.</target>
        </trans-unit>
        <trans-unit id="c5c1cc9c0352ec3e2d5fcc0df63b71ce152f382f" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso covariance model to X.</source>
          <target state="translated">Подходит для ковариационной модели GraphicalLasso в X.</target>
        </trans-unit>
        <trans-unit id="268ae9ae0a9043d80b2e575c7e344f83f78e662d" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso model to X.</source>
          <target state="translated">Подходит для модели GraphicalLasso в X.</target>
        </trans-unit>
        <trans-unit id="643e04850030e1e1aeeaf619a88e7dab7e6a06be" translate="yes" xml:space="preserve">
          <source>Fits the Ledoit-Wolf shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">Подходит для модели Ledoit-Wolf shrunk covariance в соответствии с заданными тренировочными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="60a2c06b8221e361c36d5fdce8ee644d8456bfce" translate="yes" xml:space="preserve">
          <source>Fits the Maximum Likelihood Estimator covariance model according to the given training data and parameters.</source>
          <target state="translated">Подходит для модели ковариаций оценщика максимального правдоподобия в соответствии с заданными тренировочными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="9b00c787fd8f13356df0bf86c478f2b7848ac4d7" translate="yes" xml:space="preserve">
          <source>Fits the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</source>
          <target state="translated">Подходит для модели Oracle Approximating Shrinkage covariance в соответствии с заданными учебными данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="2fb3d8548147a6429a7eeed9e3fbe0456049bc8c" translate="yes" xml:space="preserve">
          <source>Fits the estimator.</source>
          <target state="translated">Подходит для оценщика.</target>
        </trans-unit>
        <trans-unit id="3cea2475743e34d34ded723467b2a735e1203cfc" translate="yes" xml:space="preserve">
          <source>Fits the imputer on X and return self.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bb471485459c492057aae581eaa0cf9c4592a1d" translate="yes" xml:space="preserve">
          <source>Fits the imputer on X and return the transformed X.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c13921c2e1a959ce7d05648d804f502aded299cf" translate="yes" xml:space="preserve">
          <source>Fits the model to the training set X and returns the labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f6beb1ac87a74b86b8c1fedd5ae0ed0ac89461" translate="yes" xml:space="preserve">
          <source>Fits the shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">Подходит для модели суженного ковариата в соответствии с заданными обучающими данными и параметрами.</target>
        </trans-unit>
        <trans-unit id="f072640da94e1ad56e67373f3632aeaebdd8b854" translate="yes" xml:space="preserve">
          <source>Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.</source>
          <target state="translated">Устанавливает трансформатор в X и y с дополнительными параметрами fit_params и возвращает преобразованную версию X.</target>
        </trans-unit>
        <trans-unit id="06f59e2a32c90e6aa8aff9dfb100b6f03f2af9ff" translate="yes" xml:space="preserve">
          <source>Fitted classifier or a fitted &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; in which the last estimator is a classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0dea44d64bdac3b47bf2c46576cad767f74d843" translate="yes" xml:space="preserve">
          <source>Fitted estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd568de48dadd27cd4e3ca2395da082642e8f8ec" translate="yes" xml:space="preserve">
          <source>Fitted regressor.</source>
          <target state="translated">Встроенный регрессор.</target>
        </trans-unit>
        <trans-unit id="f162f6bcf340dc521df64a1aae70440e61c389db" translate="yes" xml:space="preserve">
          <source>Fitted scaler.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bccb0ee0062e477c480530940a0aca37551f6020" translate="yes" xml:space="preserve">
          <source>Fitted vectorizer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14c6da7cd39661e1b0c6468a3c6a5907d4f99a9c" translate="yes" xml:space="preserve">
          <source>Fitting transformers may be computationally expensive. With its &lt;code&gt;memory&lt;/code&gt; parameter set, &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; will cache each transformer after calling &lt;code&gt;fit&lt;/code&gt;. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical. A typical example is the case of a grid search in which the transformers can be fitted only once and reused for each configuration.</source>
          <target state="translated">Установка трансформаторов может быть дорогостоящей в вычислительном отношении. При установленном параметре &lt;code&gt;memory&lt;/code&gt; &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt; кэширует каждый преобразователь после вызова &lt;code&gt;fit&lt;/code&gt; . Эта функция используется, чтобы избежать вычисления подходящих трансформаторов в трубопроводе, если параметры и входные данные идентичны. Типичным примером является случай поиска в сети, в котором трансформаторы могут быть установлены только один раз и повторно использованы для каждой конфигурации.</target>
        </trans-unit>
        <trans-unit id="01fe05c223cb56d84d085e38ca62de1932a87e50" translate="yes" xml:space="preserve">
          <source>Flag indicating if the cross-validation values corresponding to each alpha should be stored in the &lt;code&gt;cv_values_&lt;/code&gt; attribute (see below). This flag is only compatible with &lt;code&gt;cv=None&lt;/code&gt; (i.e. using Generalized Cross-Validation).</source>
          <target state="translated">Флаг, указывающий, должны ли значения перекрестной проверки, соответствующие каждому альфа- &lt;code&gt;cv_values_&lt;/code&gt; храниться в атрибуте cv_values_ (см. Ниже). Этот флаг совместим только с &lt;code&gt;cv=None&lt;/code&gt; (т. Е. С использованием обобщенной перекрестной проверки).</target>
        </trans-unit>
        <trans-unit id="1f498759924682e2363e94f7b83282b97429fcf5" translate="yes" xml:space="preserve">
          <source>Flag indicating which strategy to use when performing Generalized Cross-Validation. Options are:</source>
          <target state="translated">Флаг,указывающий,какую стратегию использовать при проведении Обобщенной перекрестной проверки.Возможны варианты:</target>
        </trans-unit>
        <trans-unit id="3407c4421a1f6ede0cab565dc5123546e65ddde6" translate="yes" xml:space="preserve">
          <source>Flat geometry, good for density estimation</source>
          <target state="translated">Плоская геометрия,хорошо подходит для оценки плотности</target>
        </trans-unit>
        <trans-unit id="748a38982c93bb25fbfeb18b34277c35439ac98c" translate="yes" xml:space="preserve">
          <source>Flavanoids</source>
          <target state="translated">Flavanoids</target>
        </trans-unit>
        <trans-unit id="f55beb472c3b08362b7861294963760ddd037d08" translate="yes" xml:space="preserve">
          <source>Flavanoids:</source>
          <target state="translated">Flavanoids:</target>
        </trans-unit>
        <trans-unit id="1bf94453d6aa9e9092828eefafa6394692100339" translate="yes" xml:space="preserve">
          <source>Flexible pickling control for the communication to and from the worker processes.</source>
          <target state="translated">Гибкий контроль травления для связи с рабочими процессами и от них.</target>
        </trans-unit>
        <trans-unit id="2d83a2dbf42ef510856c4fe5eb69b3efa4599763" translate="yes" xml:space="preserve">
          <source>Flow Chart</source>
          <target state="translated">Потоковая диаграмма</target>
        </trans-unit>
        <trans-unit id="87698cca8f914c77b735bad53fe489d2af135e70" translate="yes" xml:space="preserve">
          <source>Folder to be used by the pool for memmapping large arrays for sharing memory with worker processes. If None, this will try in order:</source>
          <target state="translated">Папка,используемая пулом для запоминания больших массивов для совместного использования памяти с рабочими процессами.Если Нет,то попробуем по порядку:</target>
        </trans-unit>
        <trans-unit id="c09a9bf27e9aabfc7b35dc309da81eb816c5e989" translate="yes" xml:space="preserve">
          <source>Following special cases exist,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="313fc38f449c398563f152e4416c92af47202923" translate="yes" xml:space="preserve">
          <source>Follows Algorithm 4.3 of Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) http://arxiv.org/pdf/0909.4061</source>
          <target state="translated">Следует алгоритму 4.3 Найти структуру со случайностью:Стохастические алгоритмы построения приблизительных матричных разложений Halko и др.,2009 (arXiv:909)http://arxiv.org/pdf/0909.4061.</target>
        </trans-unit>
        <trans-unit id="061a7a165d75c1efa21f2a2a8a850415a95a5911" translate="yes" xml:space="preserve">
          <source>Follows Algorithm 4.3 of Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec0c3b76630fd745381cc215a284820af75a683a" translate="yes" xml:space="preserve">
          <source>Footnotes</source>
          <target state="translated">Footnotes</target>
        </trans-unit>
        <trans-unit id="871453ce5a358112246d8fa103eff55b515e95a2" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;one-vs-rest&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;(n_classes, n_features)&lt;/code&gt; and &lt;code&gt;(n_classes,)&lt;/code&gt; respectively. Each row of the coefficients corresponds to one of the &lt;code&gt;n_classes&lt;/code&gt; &amp;ldquo;one-vs-rest&amp;rdquo; classifiers and similar for the intercepts, in the order of the &amp;ldquo;one&amp;rdquo; class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="41e2c901c13d4daacf7c9adad4d559c077a8e51e" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;one-vs-rest&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class, n_features]&lt;/code&gt; and &lt;code&gt;[n_class]&lt;/code&gt; respectively. Each row of the coefficients corresponds to one of the &lt;code&gt;n_class&lt;/code&gt; many &amp;ldquo;one-vs-rest&amp;rdquo; classifiers and similar for the intercepts, in the order of the &amp;ldquo;one&amp;rdquo; class.</source>
          <target state="translated">Для &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; &amp;laquo;один против остальных&amp;raquo; атрибуты &lt;code&gt;coef_&lt;/code&gt; и &lt;code&gt;intercept_&lt;/code&gt; имеют форму &lt;code&gt;[n_class, n_features]&lt;/code&gt; и &lt;code&gt;[n_class]&lt;/code&gt; соответственно. Каждая строка коэффициентов соответствует одному из &lt;code&gt;n_class&lt;/code&gt; классификаторов &amp;laquo;один против остальных&amp;raquo; и аналогичных для перехватов в порядке класса &amp;laquo;один&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="c6cc35fe8de003f58f84a7c02bbc9d4b652dc227" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;pairwise&amp;rdquo; metrics, between &lt;em&gt;samples&lt;/em&gt; and not estimators or predictions, see the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section.</source>
          <target state="translated">&amp;laquo;Парные&amp;raquo; метрики между &lt;em&gt;выборками,&lt;/em&gt; а не оценками или прогнозами, см. В разделе &amp;laquo; &lt;a href=&quot;metrics#metrics&quot;&gt;Парные метрики, сходства и ядра&lt;/a&gt; &amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="935f9d2961eec1b64a8d3f62208c3a16e0e7ef63" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; of trees (e.g. RandomForest, GBT, ExtraTrees etc) the number of trees and their depth play the most important role. Latency and throughput should scale linearly with the number of trees. In this case we used directly the &lt;code&gt;n_estimators&lt;/code&gt; parameter of &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt;.</source>
          <target state="translated">Для &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt; деревьев (например, RandomForest, GBT, ExtraTrees и т.д.) наиболее важную роль играет количество деревьев и их глубина. Задержка и пропускная способность должны линейно масштабироваться с количеством деревьев. В данном случае мы использовали непосредственно &lt;code&gt;n_estimators&lt;/code&gt; параметр &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c2e53d45d0579b4b39658069206cb04a03ac3808" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; (e.g. Lasso, ElasticNet, SGDClassifier/Regressor, Ridge &amp;amp; RidgeClassifier, PassiveAggressiveClassifier/Regressor, LinearSVC, LogisticRegression&amp;hellip;) the decision function that is applied at prediction time is the same (a dot product) , so latency should be equivalent.</source>
          <target state="translated">Для &lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; &lt;/a&gt; (например, Lasso, ElasticNet, SGDClassifier / Regressor, Ridge &amp;amp; RidgeClassifier, PassiveAggressiveClassifier / Regressor, LinearSVC, LogisticRegression&amp;hellip;) функция принятия решения, которая применяется во время прогнозирования, такая же (точечный продукт), поэтому задержка должна быть эквивалентной .</target>
        </trans-unit>
        <trans-unit id="b1a84d28126765870388f5c6f8149674d42fd858" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt;, note that the output of the &lt;code&gt;estimators&lt;/code&gt; is controlled by the parameter &lt;code&gt;stack_method&lt;/code&gt; and it is called by each estimator. This parameter is either a string, being estimator method names, or &lt;code&gt;'auto'&lt;/code&gt; which will automatically identify an available method depending on the availability, tested in the order of preference: &lt;code&gt;predict_proba&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5bf64c1d60fc523cf9cf35c71f5018653089c51" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt;, when using &lt;code&gt;stack_method_='predict_proba'&lt;/code&gt;, the first column is dropped when the problem is a binary classification problem. Indeed, both probability columns predicted by each estimator are perfectly collinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d0c4acadc1a3e244ad80f139e9b2149c5787665" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;) any input passed as a numpy array will be copied and converted to the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input, we suggest to use the &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; class instead. The objective function can be configured to be almost the same as the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8582a7ae6ed830b76bb2d9fd21363d4d3995f59c" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;) any input passed as a numpy array will be copied and converted to the liblinear internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input we suggest to use the &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; class instead. The objective function can be configured to be almost the same as the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; model.</source>
          <target state="translated">Для &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; (и &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; ) любой ввод, переданный как массив numpy, будет скопирован и преобразован в liblinear внутреннее разреженное представление данных (числа с плавающей запятой двойной точности и индексы int32 ненулевых компонентов). Если вы хотите вписать крупномасштабный линейный классификатор без копирования плотного numpy C-смежного массива двойной точности в качестве входных данных, мы предлагаем вместо этого использовать класс &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt; . Целевая функция может быть настроена почти так же, как модель &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2643eb1343d14a8cde9753d0546e2bd56743d7c1" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, the &amp;lsquo;recursion&amp;rsquo; method (used by default) will not account for the &lt;code&gt;init&lt;/code&gt; predictor of the boosting process. In practice, this will produce the same values as &amp;lsquo;brute&amp;rsquo; up to a constant offset in the target response, provided that &lt;code&gt;init&lt;/code&gt; is a constant estimator (which is the default). However, if &lt;code&gt;init&lt;/code&gt; is not a constant estimator, the partial dependence values are incorrect for &amp;lsquo;recursion&amp;rsquo; because the offset will be sample-dependent. It is preferable to use the &amp;lsquo;brute&amp;rsquo; method. Note that this only applies to &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, not to &lt;a href=&quot;sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9c95b352fd6ddba1a98d2caa12d747735ff41c3" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;0 &amp;lt; power &amp;lt; 1&lt;/code&gt;, no distribution exists.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e56c72d645a0047396221ed2eb5407914a9b6bf6" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;make_classification&lt;/code&gt;, three binary and two multi-class classification datasets are generated, with different numbers of informative features and clusters per class.</source>
          <target state="translated">Для &lt;code&gt;make_classification&lt;/code&gt; создаются три бинарных и два набора данных для классификации нескольких классов с разным количеством информативных функций и кластеров для каждого класса.</target>
        </trans-unit>
        <trans-unit id="dda7c631740b122861937f9ebbfdde73fd44b016" translate="yes" xml:space="preserve">
          <source>For Gaussian distributed data, the distance of an observation \(x_i\) to the mode of the distribution can be computed using its Mahalanobis distance: \(d_{(\mu,\Sigma)}(x_i)^2 = (x_i - \mu)'\Sigma^{-1}(x_i - \mu)\) where \(\mu\) and \(\Sigma\) are the location and the covariance of the underlying Gaussian distribution.</source>
          <target state="translated">Для гауссовых распределенных данных расстояние наблюдения \(x_i\)до режима распределения можно рассчитать по его расстоянию в Махаланобисе:\(d_{(\mu,\Sigma)}(x_i)^2=(x_i-\mu)'\Sigma^{-1}(x_i-\mu)\),где \(\mu\)и \(\Sigma\)-расположение и ковариативность лежащего в основе гауссовского распределения.</target>
        </trans-unit>
        <trans-unit id="3fb903a20f5aad7e20f9123d2edfa2a0638dc6bc" translate="yes" xml:space="preserve">
          <source>For \(k\) clusters, the Calinski-Harabaz score \(s\) is given as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:</source>
          <target state="translated">Для кластеров \(k\)оценка &quot;Калинский-Харабаз&quot; \(s\)приведена в виде соотношения среднего дисперсии между кластерами и дисперсии внутри кластера:</target>
        </trans-unit>
        <trans-unit id="d27bcc7c91650762beefd01dc3089ec6978d5c87" translate="yes" xml:space="preserve">
          <source>For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.</source>
          <target state="translated">Для классификационной модели возвращается прогнозируемый класс для каждой выборки в Х.Для регрессионной модели возвращается предсказанное значение,основанное на X.</target>
        </trans-unit>
        <trans-unit id="e6fd66f776dfd09a091bc857e8c9d10d50ac3ba8" translate="yes" xml:space="preserve">
          <source>For a comparison of the different scalers, transformers, and normalizers, see &lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;examples/preprocessing/plot_all_scaling.py&lt;/a&gt;.</source>
          <target state="translated">Для сравнения различных масштабаторов, преобразователей и нормализаторов см. &lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Examples / preprocessing / plot_all_scaling.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="33f57a2a03940da66a0808ac0a9d7e45bc98afe2" translate="yes" xml:space="preserve">
          <source>For a complete probabilistic model we also need a prior distribution for the latent variable \(h\). The most straightforward assumption (based on the nice properties of the Gaussian distribution) is \(h \sim \mathcal{N}(0, \mathbf{I})\). This yields a Gaussian as the marginal distribution of \(x\):</source>
          <target state="translated">Для полной вероятностной модели нам также необходимо предварительное распределение для скрытой переменной \(h\).Наиболее простым предположением (основанным на хороших свойствах гауссовского распределения)является \(h \sim \mathcal{N}(0,\mathbf{I})\).Это дает гауссовское распределение в качестве предельного \(x\):</target>
        </trans-unit>
        <trans-unit id="7e3b25cfbbacb17bf9ce066c3983b6610e3fab10" translate="yes" xml:space="preserve">
          <source>For a constant learning rate use &lt;code&gt;learning_rate='constant'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the learning rate.</source>
          <target state="translated">Для постоянной скорости обучения используйте &lt;code&gt;learning_rate='constant'&lt;/code&gt; и используйте &lt;code&gt;eta0&lt;/code&gt; , чтобы указать скорость обучения.</target>
        </trans-unit>
        <trans-unit id="76a9227cf28fa05c9bb19673e15a2774476a035c" translate="yes" xml:space="preserve">
          <source>For a description of the implementation and details of the algorithms used, please refer to</source>
          <target state="translated">Описание реализации и подробности используемых алгоритмов приведены по адресу</target>
        </trans-unit>
        <trans-unit id="ccaff5036b34bf3986d666eb2f98e4ef943f3dfd" translate="yes" xml:space="preserve">
          <source>For a discussion and comparison of these algorithms, see the &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;manifold module page&lt;/a&gt;</source>
          <target state="translated">Для обсуждения и сравнения этих алгоритмов см. &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;Страницу модуля многообразия.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7b7d7f03d534f8340da15e8579a79cb680de77bd" translate="yes" xml:space="preserve">
          <source>For a document generated from multiple topics, all topics are weighted equally in generating its bag of words.</source>
          <target state="translated">Для документа,созданного из нескольких тем,все темы имеют одинаковый вес при создании пакета слов.</target>
        </trans-unit>
        <trans-unit id="b87483db50bfd800e7f61326ccd19592abcc3547" translate="yes" xml:space="preserve">
          <source>For a few of the best biclusters, its most common document categories and its ten most important words get printed. The best biclusters are determined by their normalized cut. The best words are determined by comparing their sums inside and outside the bicluster.</source>
          <target state="translated">Для нескольких лучших велосипедистов печатаются самые распространенные категории документов и десять самых важных слов.Лучшие велосипедные блюстеры определяются по их нормализованному срезу.Лучшие слова определяются путем сравнения их сумм внутри и снаружи билюстра.</target>
        </trans-unit>
        <trans-unit id="859f5c51d38da3ad244e41ebf28b507a4a99bc62" translate="yes" xml:space="preserve">
          <source>For a full code example that demonstrates using a &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt; to do custom feature selection, see &lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;Using FunctionTransformer to select columns&lt;/a&gt;</source>
          <target state="translated">Полный пример кода, демонстрирующий использование &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt; для выбора настраиваемых функций, см. В разделе &lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;Использование FunctionTransformer для выбора столбцов.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a29c02b5f33160de772eacbd74337a53f6625181" translate="yes" xml:space="preserve">
          <source>For a full-fledged example of out-of-core scaling in a text classification task see &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;.</source>
          <target state="translated">Полный пример масштабирования вне ядра в задаче классификации текста см. В разделе &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Классификация текстовых документов вне ядра&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d78aafa74d01fdbbdb67982f22aabb8fb92e6131" translate="yes" xml:space="preserve">
          <source>For a given value of &lt;code&gt;n_components&lt;/code&gt;&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is often less accurate as &lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is cheaper to compute, though, making use of larger feature spaces more efficient.</source>
          <target state="translated">Для заданного значения &lt;code&gt;n_components&lt;/code&gt; &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; часто менее точен, чем &lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt; . &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt; дешевле в вычислении, так как он позволяет более эффективно использовать большие пространства функций.</target>
        </trans-unit>
        <trans-unit id="46cec00c813e8ea8e2f5bd58264262a28ac481cf" translate="yes" xml:space="preserve">
          <source>For a good choice of alpha, the &lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; can fully recover the exact set of non-zero variables using only few observations, provided certain specific conditions are met. In particular, the number of samples should be &amp;ldquo;sufficiently large&amp;rdquo;, or L1 models will perform at random, where &amp;ldquo;sufficiently large&amp;rdquo; depends on the number of non-zero coefficients, the logarithm of the number of features, the amount of noise, the smallest absolute value of non-zero coefficients, and the structure of the design matrix X. In addition, the design matrix must display certain specific properties, such as not being too correlated.</source>
          <target state="translated">Для правильного выбора альфа-канала &lt;a href=&quot;linear_model#lasso&quot;&gt;лассо&lt;/a&gt; может полностью восстановить точный набор ненулевых переменных, используя только несколько наблюдений, при соблюдении определенных конкретных условий. В частности, количество выборок должно быть &amp;laquo;достаточно большим&amp;raquo;, иначе модели L1 будут работать случайным образом, где &amp;laquo;достаточно большое&amp;raquo; зависит от количества ненулевых коэффициентов, логарифма количества функций, количества шума, наименьшее абсолютное значение ненулевых коэффициентов и структура матрицы плана X. Кроме того, матрица плана должна отображать определенные специфические свойства, например, не быть слишком коррелированными.</target>
        </trans-unit>
        <trans-unit id="283fe9d87c4a4faac62d4b9cee8a3089a1cb638f" translate="yes" xml:space="preserve">
          <source>For a multi-label classification problem with N classes, N binary classifiers are assigned an integer between 0 and N-1. These integers define the order of models in the chain. Each classifier is then fit on the available training data plus the true labels of the classes whose models were assigned a lower number.</source>
          <target state="translated">Для проблемы многомаркировочной классификации с N классами N двоичным классификаторам присваивается целое число в диапазоне от 0 до N-1.Эти целые числа определяют порядок моделей в цепочке.Каждый классификатор затем помещается на имеющиеся обучающие данные плюс истинные метки классов,моделям которых было присвоено меньшее число.</target>
        </trans-unit>
        <trans-unit id="73e6ca6403df9166903acb4326e48adf2d2e8f55" translate="yes" xml:space="preserve">
          <source>For a multi_class problem, if multi_class is set to be &amp;ldquo;multinomial&amp;rdquo; the softmax function is used to find the predicted probability of each class. Else use a one-vs-rest approach, i.e calculate the probability of each class assuming it to be positive using the logistic function. and normalize these values across all the classes.</source>
          <target state="translated">Для задачи multi_class, если multi_class установлен как &amp;laquo;мультиномиальный&amp;raquo;, функция softmax используется для нахождения предсказанной вероятности каждого класса. В противном случае используйте подход &amp;laquo;один против остальных&amp;raquo;, то есть рассчитайте вероятность каждого класса, предполагая, что она положительна, с помощью логистической функции. и нормализовать эти значения по всем классам.</target>
        </trans-unit>
        <trans-unit id="642c44d27e63bf2bd3e040832cd67d4f4b97be3d" translate="yes" xml:space="preserve">
          <source>For a multiclass problem, the hyperparameters for each class are computed using the best scores got by doing a one-vs-rest in parallel across all folds and classes. Hence this is not the true multinomial loss.</source>
          <target state="translated">Для многоклассовой задачи,гиперпараметры для каждого класса вычисляются,используя лучшие результаты,полученные при параллельном выполнении одного противника по всем сгибам и классам.Следовательно,это не является истинным мультиномиальным потерей.</target>
        </trans-unit>
        <trans-unit id="3c102da8b9e1a48c3e9639790d9170902789d884" translate="yes" xml:space="preserve">
          <source>For a new point entering the root, it is merged with the subcluster closest to it and the linear sum, squared sum and the number of samples of that subcluster are updated. This is done recursively till the properties of the leaf node are updated.</source>
          <target state="translated">Для новой точки,входящей в корень,она сливается с ближайшим к ней подкластером и обновляется линейная сумма,квадратная сумма и количество отсчетов этого подкластера.Это делается рекурсивно до тех пор,пока свойства узла листа не будут обновлены.</target>
        </trans-unit>
        <trans-unit id="14657655d860195eca6994d15ac16d17936616a4" translate="yes" xml:space="preserve">
          <source>For a one-class model, +1 or -1 is returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49c44661048e1cd2101f0d885d98fc8331d85aee" translate="yes" xml:space="preserve">
          <source>For a set of data \(E\) of size \(n_E\) which has been clustered into \(k\) clusters, the Calinski-Harabasz score \(s\) is defined as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d36945b7ba93218440d9a3fb3620ffe9bc7ebec1" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to a sphere dataset, see &lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;Manifold Learning methods on a severed sphere&lt;/a&gt;</source>
          <target state="translated">Для аналогичного примера, где методы применяются к набору данных сферы, см. &lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;Методы обучения манифольду на отрезанной сфере.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="945c76e7faeb6fe6d013381d6851dfb972b0f8ae" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to the S-curve dataset, see &lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt;</source>
          <target state="translated">Для аналогичного примера, где методы применяются к набору данных S-кривой, см. &lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Сравнение методов обучения многообразию.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5693da1a0a426bf5e6f357791de67cea3dcb709e" translate="yes" xml:space="preserve">
          <source>For an adaptively decreasing learning rate, use &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the starting learning rate. When the stopping criterion is reached, the learning rate is divided by 5, and the algorithm does not stop. The algorithm stops when the learning rate goes below 1e-6.</source>
          <target state="translated">Для адаптивного уменьшения скорости обучения используйте &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; и используйте &lt;code&gt;eta0&lt;/code&gt; , чтобы указать начальную скорость обучения. При достижении критерия остановки скорость обучения делится на 5, и алгоритм не останавливается. Алгоритм останавливается, когда скорость обучения опускается ниже 1e-6.</target>
        </trans-unit>
        <trans-unit id="289eda38dfb97e5735805aabc918de776eb35066" translate="yes" xml:space="preserve">
          <source>For an estimator to be effective, you need the distance between neighboring points to be less than some value \(d\), which depends on the problem. In one dimension, this requires on average \(n \sim 1/d\) points. In the context of the above \(k\)-NN example, if the data is described by just one feature with values ranging from 0 to 1 and with \(n\) training observations, then new data will be no further away than \(1/n\). Therefore, the nearest neighbor decision rule will be efficient as soon as \(1/n\) is small compared to the scale of between-class feature variations.</source>
          <target state="translated">Для того чтобы оценка была эффективной,необходимо,чтобы расстояние между соседними точками было меньше некоторого значения \(d\),которое зависит от поставленной задачи.В одном измерении это требует в среднем точек \(n \sim 1/d\).В контексте вышеприведенного примера \(k\)-NN,если данные описываются только одной характеристикой со значениями от 0 до 1 и с учебными наблюдениями \(n\),то новые данные будут не дальше \(1/n\).Следовательно,правило решения о ближайшем соседе будет эффективным,как только \(1/n\)будет малым по сравнению с масштабом межклассовых вариаций признаков.</target>
        </trans-unit>
        <trans-unit id="cc92ccd33be99f33389b25ab23e30ca5c4b36d12" translate="yes" xml:space="preserve">
          <source>For an example of using this dataset with scikit-learn, see &lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples/applications/plot_species_distribution_modeling.py&lt;/a&gt;.</source>
          <target state="translated">Пример использования этого набора данных с scikit-learn см. В &lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples / applications / plot_species_distribution_modeling.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="84cc57ff6bd3680e44c549367baf76fa37633107" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;examples/cluster/plot_affinity_propagation.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;Examples / cluster / plot_affinity_propagation.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="550540d863fd72ef27788284d554fe3cf91d4d31" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;examples/cluster/plot_dbscan.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;Examples / cluster / plot_dbscan.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5a609c98d64d09ee64c2c225998c2e63797d885b" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;examples/cluster/plot_mean_shift.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;Examples / cluster / plot_mean_shift.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0c7aeec7cbc3121a908ff21339ef38d8e3682ea4" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;examples/linear_model/plot_ard.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;Examples / linear_model / plot_ard.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8606b3a4ce46a8dc7d8f3fc386175108176c1a2f" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;examples/linear_model/plot_bayesian_ridge.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;Examples / linear_model / plot_bayesian_ridge.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1a253fcf6bd3baedce8e1812aafc9e481fd05853" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;examples/linear_model/plot_lasso_coordinate_descent_path.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;Examples / linear_model / plot_lasso_coordinate_descent_path.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dd893fae3c875581ed42afc5493c8a73ae57ea3a" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;examples/linear_model/plot_lasso_model_selection.py&lt;/a&gt;.</source>
          <target state="translated">Для примера см. &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;Examples / linear_model / plot_lasso_model_selection.py&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7185c2666c1903f0809fab3c9082ec1324c6a9c7" translate="yes" xml:space="preserve">
          <source>For an introduction to Unicode and character encodings in general, see Joel Spolsky&amp;rsquo;s &lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Absolute Minimum Every Software Developer Must Know About Unicode&lt;/a&gt;.</source>
          <target state="translated">Для введения в Unicode и кодировки символов в целом см. &lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Абсолютный минимум&lt;/a&gt; Джоэла Спольски, который должен знать каждый разработчик программного обеспечения о Unicode .</target>
        </trans-unit>
        <trans-unit id="28d13aab6e72bcde5f37b4278086b064720820de" translate="yes" xml:space="preserve">
          <source>For an introduction to Unicode and character encodings in general, see Joel Spolsky&amp;rsquo;s &lt;a href=&quot;https://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Absolute Minimum Every Software Developer Must Know About Unicode&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a88e794655306a2809e5d03a41b7ab87506c6aa" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 (inlier) or -1 (outlier) is returned.</source>
          <target state="translated">Для одноклассной модели возвращается +1 (вылет)или -1 (вылет).</target>
        </trans-unit>
        <trans-unit id="6b041f627b95dafb713c53f369d3fb59c9505ee0" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 or -1 is returned.</source>
          <target state="translated">Для одноклассной модели возвращается +1 или -1.</target>
        </trans-unit>
        <trans-unit id="90c9667034ee59a28024b8500c3a1c0772f75e0b" translate="yes" xml:space="preserve">
          <source>For an overview of available strategies in scikit-learn, see also the &lt;a href=&quot;computing#scaling-strategies&quot;&gt;out-of-core learning&lt;/a&gt; documentation.</source>
          <target state="translated">Для обзора доступных стратегий в scikit-learn см. Также документацию по внешнему &lt;a href=&quot;computing#scaling-strategies&quot;&gt;обучению&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="bd83f9999f935e2f6fce3641b48e5b3393b97a71" translate="yes" xml:space="preserve">
          <source>For binary classification with a true label \(y \in \{0,1\}\) and a probability estimate \(p = \operatorname{Pr}(y = 1)\), the log loss per sample is the negative log-likelihood of the classifier given the true label:</source>
          <target state="translated">Для бинарной классификации с истинной меткой \(y \in \{0,1\}\)и оценкой вероятности \(p=\operatorname{Pr}(y=1)\),потеря журнала на выборку является отрицательной лог-вероятностью классификатора при истинной метке:</target>
        </trans-unit>
        <trans-unit id="23a4f6b8b8e57d58b02ac23ef6f32b82b6049d45" translate="yes" xml:space="preserve">
          <source>For binary classification, \(f(x)\) passes through the logistic function \(g(z)=1/(1+e^{-z})\) to obtain output values between zero and one. A threshold, set to 0.5, would assign samples of outputs larger or equal 0.5 to the positive class, and the rest to the negative class.</source>
          <target state="translated">Для двоичной классификации \(f(x)\)проходит через логистическую функцию \(g(z)=1/(1+e^{-z})\)для получения выходных значений между нулем и единицей.Порог,установленный в 0.5,назначает выборки выходов больше или равные 0.5 для класса положительных значений,а остальные-для класса отрицательных.</target>
        </trans-unit>
        <trans-unit id="883efcc2dc17e184b74392564fb44d2a6f9c0bf6" translate="yes" xml:space="preserve">
          <source>For binary problems, we can get counts of true negatives, false positives, false negatives and true positives as follows:</source>
          <target state="translated">Для двоичных проблем,мы можем получить подсчет истинных отрицательных,ложных положительных,ложных отрицательных и истинных положительных результатов следующим образом:</target>
        </trans-unit>
        <trans-unit id="7f954d6786e07c3ef37ff8e0245acb91efbb4b2a" translate="yes" xml:space="preserve">
          <source>For classification with &lt;code&gt;loss='deviance'&lt;/code&gt; the target response is logit(p).</source>
          <target state="translated">Для классификации с &lt;code&gt;loss='deviance'&lt;/code&gt; целевой ответ - логит (p).</target>
        </trans-unit>
        <trans-unit id="4118e1de638d62fd337275c2f8d28f38f1e40db3" translate="yes" xml:space="preserve">
          <source>For classification with a logistic loss, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Для классификации с логистическими потерями доступен другой вариант SGD со стратегией усреднения с алгоритмом стохастического среднего градиента (SAG), доступным в качестве решателя в &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7a750c34f262db1f2c0c844eb9774104416e6f5c" translate="yes" xml:space="preserve">
          <source>For classification you can think of it as the regression score before the link function.</source>
          <target state="translated">Для классификации вы можете думать об этом как о балле регрессии перед функцией связи.</target>
        </trans-unit>
        <trans-unit id="6a3d9b2c887776af95639587c4c76f62b0d1c8f1" translate="yes" xml:space="preserve">
          <source>For classification, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt;&lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='hinge'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_hinge'&lt;/code&gt; (PA-II). For regression, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt;&lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; (PA-II).</source>
          <target state="translated">Для классификации &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt; &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; &lt;/a&gt; можно использовать с &lt;code&gt;loss='hinge'&lt;/code&gt; (PA-I) или &lt;code&gt;loss='squared_hinge'&lt;/code&gt; (PA-II). Для регрессии можно использовать &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt; &lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt; &lt;/a&gt; с &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; (PA-I) или &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; (PA-II).</target>
        </trans-unit>
        <trans-unit id="27898fb8346ff80dce087f616900965fd4196842" translate="yes" xml:space="preserve">
          <source>For classification, a somewhat important thing to note is that although a stateless feature extraction routine may be able to cope with new/unseen attributes, the incremental learner itself may be unable to cope with new/unseen targets classes. In this case you have to pass all the possible classes to the first &lt;code&gt;partial_fit&lt;/code&gt; call using the &lt;code&gt;classes=&lt;/code&gt; parameter.</source>
          <target state="translated">Для классификации важно отметить, что, хотя процедура извлечения признаков без сохранения состояния может справляться с новыми / невидимыми атрибутами, инкрементный обучающийся сам может оказаться неспособным справиться с новыми / невидимыми целевыми классами. В этом случае вы должны передать все возможные классы первому вызову &lt;code&gt;partial_fit&lt;/code&gt; с помощью параметра &lt;code&gt;classes=&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fda4c776ec3f2170d3e99301b50afa3144298d48" translate="yes" xml:space="preserve">
          <source>For classification, as in the labeling &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; task, linear regression is not the right approach as it will give too much weight to data far from the decision frontier. A linear approach is to fit a sigmoid function or &lt;strong&gt;logistic&lt;/strong&gt; function:</source>
          <target state="translated">Для классификации, как и в задаче разметки &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;радужной оболочки&lt;/a&gt; , линейная регрессия не является правильным подходом, поскольку она придает слишком большой вес данным, находящимся далеко от границы принятия решений. Линейный подход заключается в подборе сигмовидной функции или &lt;strong&gt;логистической&lt;/strong&gt; функции:</target>
        </trans-unit>
        <trans-unit id="cda870024c615048609a38e867ca66fe1aaab764" translate="yes" xml:space="preserve">
          <source>For classification, the target response may be the probability of a class (the positive class for binary classification), or the decision function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="049512f622ab4a1900a694aa9ec5fcf56244d47a" translate="yes" xml:space="preserve">
          <source>For classification: &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt;&lt;code&gt;f_classif&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Для классификации: &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt; &lt;code&gt;f_classif&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2b5c234d472222c920c562abfd3ef4ec80e6cfee" translate="yes" xml:space="preserve">
          <source>For comparison, a quantized image using a random codebook (colors picked up randomly) is also shown.</source>
          <target state="translated">Для сравнения показано также квантованное изображение с помощью случайной кодовой книги (цвета подобраны случайным образом).</target>
        </trans-unit>
        <trans-unit id="3be5878f7d3ebd4495804d5a6a55058ed71eceb1" translate="yes" xml:space="preserve">
          <source>For comparison, the documents are also clustered using MiniBatchKMeans. The document clusters derived from the biclusters achieve a better V-measure than clusters found by MiniBatchKMeans.</source>
          <target state="translated">Для сравнения,документы также сгруппированы с помощью MiniBatchKMeans.Кластеры документов,полученных из библлястеров достичь лучшего V-измерения,чем кластеры,найденные MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="9da7ddf96abc62edc6f61720c2e84583fe9d6b7c" translate="yes" xml:space="preserve">
          <source>For comparison, we also add the output from &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt;. It can force any arbitrary distribution into a gaussian, provided that there are enough training samples (thousands). Because it is a non-parametric method, it is harder to interpret than the parametric ones (Box-Cox and Yeo-Johnson).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d421941474530194b10c6be8d7b89e2eb530191" translate="yes" xml:space="preserve">
          <source>For comparison, we also add the output from &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt;. It can force any arbitrary distribution into a gaussian, provided that there are enough training samples (thousands). Because it is a non-parametric method, it is harder to interpret than the parametric ones (Box-Cox and Yeo-Johnson).</source>
          <target state="translated">Для сравнения мы также добавляем результат &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt; . Он может преобразовать любое произвольное распределение в гауссовское при условии, что имеется достаточно обучающих выборок (тысячи). Поскольку это непараметрический метод, его труднее интерпретировать, чем параметрические (Бокс-Кокс и Йео-Джонсон).</target>
        </trans-unit>
        <trans-unit id="3fedc899dde91ba75e541f7b8d87d7a3665ca193" translate="yes" xml:space="preserve">
          <source>For compatibility, user code relying on this method should wrap its calls in &lt;code&gt;np.asarray&lt;/code&gt; to avoid type issues.</source>
          <target state="translated">Для совместимости пользовательский код, использующий этот метод, должен &lt;code&gt;np.asarray&lt;/code&gt; свои вызовы в np.asarray, чтобы избежать проблем с типом.</target>
        </trans-unit>
        <trans-unit id="6f31aee2196032d492cf3c67f7f43ab3f6981996" translate="yes" xml:space="preserve">
          <source>For continuous parameters, such as &lt;code&gt;C&lt;/code&gt; above, it is important to specify a continuous distribution to take full advantage of the randomization. This way, increasing &lt;code&gt;n_iter&lt;/code&gt; will always lead to a finer search.</source>
          <target state="translated">Для непрерывных параметров, таких как &lt;code&gt;C&lt;/code&gt; выше, важно указать непрерывное распределение, чтобы использовать все преимущества рандомизации. Таким образом, увеличение &lt;code&gt;n_iter&lt;/code&gt; всегда приведет к более точному поиску.</target>
        </trans-unit>
        <trans-unit id="4288bdf523218f188616117af5e7ab510c1e81a7" translate="yes" xml:space="preserve">
          <source>For cross-validation, we use 20-fold with 2 algorithms to compute the Lasso path: coordinate descent, as implemented by the LassoCV class, and Lars (least angle regression) as implemented by the LassoLarsCV class. Both algorithms give roughly the same results. They differ with regards to their execution speed and sources of numerical errors.</source>
          <target state="translated">Для перекрестной проверки мы используем 20-кратный алгоритм вычисления пути Лассо:спуск по координатам,реализованный классом LassoCV,и Lars (регрессия наименьшего угла),реализованный классом LassoLarsCV.Оба алгоритма дают примерно одинаковые результаты.Они отличаются скоростью их выполнения и источниками числовых ошибок.</target>
        </trans-unit>
        <trans-unit id="c8cbf2457961ac615bed8ee5d0896fee418cd0e6" translate="yes" xml:space="preserve">
          <source>For custom messages if &amp;ldquo;%(name)s&amp;rdquo; is present in the message string, it is substituted for the estimator name.</source>
          <target state="translated">Для настраиваемых сообщений, если &amp;laquo;% (name) s&amp;raquo; присутствует в строке сообщения, оно заменяется именем оценщика.</target>
        </trans-unit>
        <trans-unit id="67e0a596cb4bf62edc844af1488251663768a571" translate="yes" xml:space="preserve">
          <source>For details on the precise mathematical formulation of the provided kernel functions and how &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;coef0&lt;/code&gt; and &lt;code&gt;degree&lt;/code&gt; affect each other, see the corresponding section in the narrative documentation: &lt;a href=&quot;../svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">Подробные сведения о точной математической формулировке предоставленных функций ядра и о том , как &lt;code&gt;gamma&lt;/code&gt; , &lt;code&gt;coef0&lt;/code&gt; и &lt;code&gt;degree&lt;/code&gt; влияют друг на друга, см. В соответствующем разделе описательной документации: &lt;a href=&quot;../svm#svm-kernels&quot;&gt;Функции ядра&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="885e0e96d0439bc0a3432bfe3535963e5dbd93a5" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape (n_features, n_k), where &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; It is the rotation of the Gaussian distribution, i.e. its principal axis. It corresponds to &lt;code&gt;V&lt;/code&gt;, the matrix of eigenvectors coming from the SVD of &lt;code&gt;Xk = U S Vt&lt;/code&gt; where &lt;code&gt;Xk&lt;/code&gt; is the centered matrix of samples from class k.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4ed0f1e2f8642affc7014ca7518ae7bfac1b31c" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_features, n_k], with &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; It is the rotation of the Gaussian distribution, i.e. its principal axis.</source>
          <target state="translated">Для каждого класса k массив формы [n_features, n_k], где &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; Это вращение гауссова распределения, то есть его главная ось.</target>
        </trans-unit>
        <trans-unit id="a5ae820e12dddee4457f060f6b705b304ca3a1e3" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_k]. It contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system.</source>
          <target state="translated">Для каждого класса k существует массив формы [n_k].Он содержит масштабирование гауссовых распределений по его главным осям,т.е.дисперсию в повернутой системе координат.</target>
        </trans-unit>
        <trans-unit id="bb1ef71f090300eb5b67a4f2bd338bada7005d30" translate="yes" xml:space="preserve">
          <source>For each class of models we make the model complexity vary through the choice of relevant model parameters and measure the influence on both computational performance (latency) and predictive power (MSE or Hamming Loss).</source>
          <target state="translated">Для каждого класса моделей мы изменяем сложность модели путем выбора соответствующих параметров и измеряем влияние как на вычислительную производительность (латентность),так и на прогнозную мощность (MSE или потеря Хамминга).</target>
        </trans-unit>
        <trans-unit id="21f3c14e6817e5773b09bd85149800940dffa132" translate="yes" xml:space="preserve">
          <source>For each class, contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system. It corresponds to &lt;code&gt;S^2 /
(n_samples - 1)&lt;/code&gt;, where &lt;code&gt;S&lt;/code&gt; is the diagonal matrix of singular values from the SVD of &lt;code&gt;Xk&lt;/code&gt;, where &lt;code&gt;Xk&lt;/code&gt; is the centered matrix of samples from class k.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93f968263bf15ebdfa5ca6b61b7631f18bb2dedd" translate="yes" xml:space="preserve">
          <source>For each class, gives the covariance matrix estimated using the samples of that class. The estimations are unbiased. Only present if &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51af5a1cbe5b213e1b6f97e9040e40d195d22222" translate="yes" xml:space="preserve">
          <source>For each component k, find the weights u, v that maximizes max corr(Xk u, Yk v), such that &lt;code&gt;|u| = |v| = 1&lt;/code&gt;</source>
          <target state="translated">Для каждой компоненты k найдите веса u, v, которые максимизируют max corr (Xk u, Yk v), такие что &lt;code&gt;|u| = |v| = 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0acc93a412fe0bc296f4de29ad2df21b9415e5fb" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimize:</source>
          <target state="translated">Для каждого компонента k найдите вес u,v,который оптимизирует:</target>
        </trans-unit>
        <trans-unit id="34ffb7458447c8e84aeb0c0dcae78f73f1c9783e" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimizes: &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt;, such that &lt;code&gt;|u| = 1&lt;/code&gt;</source>
          <target state="translated">Для каждого компонента k найдите веса u, v, которые оптимизируют: &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt; , такие что &lt;code&gt;|u| = 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9db939b51ba3d78630796e1c0444915001bc251" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator.</source>
          <target state="translated">Для каждой точки отсчета x в X и для каждого дерева в ансамбле верните индекс листа x в каждой оценке.</target>
        </trans-unit>
        <trans-unit id="4571d700205de7840eb7f685393b9c35a449521a" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator. In the case of binary classification n_classes is 1.</source>
          <target state="translated">Для каждой точки отсчета x в X и для каждого дерева в ансамбле верните индекс листа x в каждой оценке.В случае двоичной классификации n_классов равно 1.</target>
        </trans-unit>
        <trans-unit id="44ac20da24a40ac490697d0897d69873261c6900" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.</source>
          <target state="translated">Для каждой точки отсчета x в X и для каждого дерева в лесу верните индекс листа x в конце.</target>
        </trans-unit>
        <trans-unit id="d82941d49be2d46b8acb0305feded896c81f7a70" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt;, possibly with gaps in the numbering.</source>
          <target state="translated">Для каждой точки данных x в X вернуть индекс листа, на котором заканчивается x. Листья пронумерованы в пределах &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt; , возможно, с пробелами в нумерации.</target>
        </trans-unit>
        <trans-unit id="7b85d3d77de0d2c34f470b25ce92cd73fbf8293c" translate="yes" xml:space="preserve">
          <source>For each dataset, 15% of samples are generated as random uniform noise. This proportion is the value given to the nu parameter of the OneClassSVM and the contamination parameter of the other outlier detection algorithms. Decision boundaries between inliers and outliers are displayed in black except for Local Outlier Factor (LOF) as it has no predict method to be applied on new data when it is used for outlier detection.</source>
          <target state="translated">Для каждого набора данных 15% образцов генерируются как случайный равномерный шум.Эта пропорция является значением,заданным nu-параметру OneClassSVM и параметру загрязнения других алгоритмов обнаружения случайных выбросов.Границы решения между промахами и выбросами отображаются черным цветом,за исключением Коэффициента локального выброса (LOF),так как он не имеет метода предсказания,который может быть применен к новым данным,когда он используется для обнаружения выброса.</target>
        </trans-unit>
        <trans-unit id="894d665cd020f2e7e68923ae49f3798173d1a959" translate="yes" xml:space="preserve">
          <source>For each document &lt;code&gt;#i&lt;/code&gt;, count the number of occurrences of each word &lt;code&gt;w&lt;/code&gt; and store it in &lt;code&gt;X[i, j]&lt;/code&gt; as the value of feature &lt;code&gt;#j&lt;/code&gt; where &lt;code&gt;j&lt;/code&gt; is the index of word &lt;code&gt;w&lt;/code&gt; in the dictionary.</source>
          <target state="translated">Для каждого документа &lt;code&gt;#i&lt;/code&gt; подсчитайте количество вхождений каждого слова &lt;code&gt;w&lt;/code&gt; и сохраните его в &lt;code&gt;X[i, j]&lt;/code&gt; как значение признака &lt;code&gt;#j&lt;/code&gt; , где &lt;code&gt;j&lt;/code&gt; - индекс слова &lt;code&gt;w&lt;/code&gt; в словаре.</target>
        </trans-unit>
        <trans-unit id="086df8ffb1b70734dd37b88cb050e6a142a873b8" translate="yes" xml:space="preserve">
          <source>For each document \(d \in D\), draw the topic proportions \(\theta_d \sim \mathrm{Dirichlet}(\alpha)\). \(\alpha\) corresponds to &lt;code&gt;doc_topic_prior&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f8df1081a030b15d2d8afea6cd05ff167080d1cd" translate="yes" xml:space="preserve">
          <source>For each document \(d\), draw \(\theta_d \sim \mathrm{Dirichlet}(\alpha), \: d=1...D\)</source>
          <target state="translated">Для каждого документа \(d\),рисовать \(\theta_d \sim \mathrm{Dirichlet}(\alpha),\:d=1...D\).</target>
        </trans-unit>
        <trans-unit id="6eb16a2ee99fe65f3a14878a1546f940e1e0bd2a" translate="yes" xml:space="preserve">
          <source>For each feature \(i\) in the training set \(X\), &lt;a href=&quot;generated/sklearn.naive_bayes.categoricalnb#sklearn.naive_bayes.CategoricalNB&quot;&gt;&lt;code&gt;CategoricalNB&lt;/code&gt;&lt;/a&gt; estimates a categorical distribution for each feature i of X conditioned on the class y. The index set of the samples is defined as \(J = \{ 1, \dots, m \}\), with \(m\) as the number of samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9366e353cbe2cfb64854c09c8a8adb8df13a11b1" translate="yes" xml:space="preserve">
          <source>For each feature \(j\) (column of \(D\)):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d88ce97fd881b7b3225357f99ece9e603e7378b5" translate="yes" xml:space="preserve">
          <source>For each observation, tells whether or not (+1 or -1) it should be considered as an inlier according to the fitted model.</source>
          <target state="translated">Для каждого наблюдения указывается,следует ли (+1 или -1)рассматривать его как вводный показатель в соответствии с установленной моделью.</target>
        </trans-unit>
        <trans-unit id="ceeb3b0129a3e252c3947f10f0ffdea6343158bd" translate="yes" xml:space="preserve">
          <source>For each pair of iris features, the decision tree learns decision boundaries made of combinations of simple thresholding rules inferred from the training samples.</source>
          <target state="translated">Для каждой пары особенностей диафрагмы дерево решений изучает границы решений,составленных из комбинаций простых правил порога,выведенных из обучающих образцов.</target>
        </trans-unit>
        <trans-unit id="63ed3328d4a6b49da02c095fda15b05ff5f99ccf" translate="yes" xml:space="preserve">
          <source>For each repetition \(k\) in \({1, ..., K}\):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebc579ef4368e5d7216210ea27aaa16d7216a1cd" translate="yes" xml:space="preserve">
          <source>For each sample, the generative process is:</source>
          <target state="translated">Для каждого образца-генеративный процесс:</target>
        </trans-unit>
        <trans-unit id="d05dbfe66f302738b6b31b31becd47c7eec37764" translate="yes" xml:space="preserve">
          <source>For each topic \(k \in K\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta)\). This provides a distribution over the words, i.e. the probability of a word appearing in topic \(k\). \(\eta\) corresponds to &lt;code&gt;topic_word_prior&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="884540e9625ad90cb4316f6468437987a56adbd4" translate="yes" xml:space="preserve">
          <source>For each topic \(k\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta),\: k =1...K\)</source>
          <target state="translated">По каждой теме \(k\),рисовать \(\beta_k \sim \mathrm{Dirichlet}(\eta),\:k =1...K\).</target>
        </trans-unit>
        <trans-unit id="ebc60a8584824b9b236f9d24a5aa9b01b10427f0" translate="yes" xml:space="preserve">
          <source>For each value of &lt;code&gt;n_components&lt;/code&gt;, we plot:</source>
          <target state="translated">Для каждого значения &lt;code&gt;n_components&lt;/code&gt; мы строим график:</target>
        </trans-unit>
        <trans-unit id="6ad9736839514923dd21aa4c5541f4da9ec0e497" translate="yes" xml:space="preserve">
          <source>For each value of the &amp;lsquo;target&amp;rsquo; features in the &lt;code&gt;grid&lt;/code&gt; the partial dependence function need to marginalize the predictions of a tree over all possible values of the &amp;lsquo;complement&amp;rsquo; features. In decision trees this function can be evaluated efficiently without reference to the training data. For each grid point a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed, otherwise both branches are followed, each branch is weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all visited leaves. For tree ensembles the results of each individual tree are again averaged.</source>
          <target state="translated">Для каждого значения &amp;laquo;целевых&amp;raquo; функций в &lt;code&gt;grid&lt;/code&gt; функция частичной зависимости должна ограничивать предсказания дерева по всем возможным значениям &amp;laquo;дополнительных&amp;raquo; функций. В деревьях решений эту функцию можно эффективно оценить без ссылки на данные обучения. Для каждой точки сетки выполняется взвешенный обход дерева: если разделенный узел включает в себя `` целевую '' функцию, следует соответствующая левая или правая ветвь, в противном случае следуют обе ветви, каждая ветвь взвешивается по доле обучающих выборок, которые вошли в эту филиал. Наконец, частичная зависимость дается средневзвешенным значением всех посещенных листьев. Для ансамблей деревьев результаты каждого отдельного дерева снова усредняются.</target>
        </trans-unit>
        <trans-unit id="719d4a30c8dd97a24789edd5bdd1f3a14cdc8a6c" translate="yes" xml:space="preserve">
          <source>For each word \(i\) in document \(d\):</source>
          <target state="translated">По каждому слову \(i\)в документе \(d\):</target>
        </trans-unit>
        <trans-unit id="d13eb916a8aa10457ca38f56195d8da451f22b82" translate="yes" xml:space="preserve">
          <source>For efficiency reasons, the euclidean distance between a pair of row vector x and y is computed as:</source>
          <target state="translated">Из соображений эффективности,эвклидовое расстояние между парой векторов ряда x и y вычисляется как:</target>
        </trans-unit>
        <trans-unit id="9aa1f675d2607b44cb2ebebaba9400cb8fdf4c6d" translate="yes" xml:space="preserve">
          <source>For evaluating multiple metrics, either give a list of (unique) strings or a dict with names as keys and callables as values.</source>
          <target state="translated">Для оценки нескольких метрик,либо дайте список (уникальных)строк,либо диктат с именами как ключами,а позывными как значениями.</target>
        </trans-unit>
        <trans-unit id="091a4026feae279bd855844156c1035b747b54da" translate="yes" xml:space="preserve">
          <source>For example &lt;code&gt;average_precision&lt;/code&gt; or the area under the roc curve can not be computed using discrete predictions alone.</source>
          <target state="translated">Например, &lt;code&gt;average_precision&lt;/code&gt; или площадь под кривой roc не могут быть вычислены с использованием одних только дискретных прогнозов.</target>
        </trans-unit>
        <trans-unit id="d73a71b2256308d0d5e12341f8e7d64f3e849f98" translate="yes" xml:space="preserve">
          <source>For example try instead of the &lt;code&gt;SVC&lt;/code&gt;:</source>
          <target state="translated">Например, попробуйте вместо &lt;code&gt;SVC&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="541edf61321b8728dd0c7cafa11d713cadb8fb1e" translate="yes" xml:space="preserve">
          <source>For example, a less computationally intensive alternative to &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; would be &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt;.</source>
          <target state="translated">Например, менее ресурсоемкой альтернативой &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; будет &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65cec63d764ed66c423ae4b0636bcfb02973f7ba" translate="yes" xml:space="preserve">
          <source>For example, a simple linear regression can be extended by constructing &lt;strong&gt;polynomial features&lt;/strong&gt; from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:</source>
          <target state="translated">Например, простая линейная регрессия может быть расширена путем построения &lt;strong&gt;полиномиальных функций&lt;/strong&gt; из коэффициентов. В случае стандартной линейной регрессии у вас может быть модель, которая выглядит следующим образом для двумерных данных:</target>
        </trans-unit>
        <trans-unit id="8a4469c2cb53cff6560ff1210e7df829ee4e673a" translate="yes" xml:space="preserve">
          <source>For example, classification of the properties &amp;ldquo;type of fruit&amp;rdquo; and &amp;ldquo;colour&amp;rdquo; for a set of images of fruit. The property &amp;ldquo;type of fruit&amp;rdquo; has the possible classes: &amp;ldquo;apple&amp;rdquo;, &amp;ldquo;pear&amp;rdquo; and &amp;ldquo;orange&amp;rdquo;. The property &amp;ldquo;colour&amp;rdquo; has the possible classes: &amp;ldquo;green&amp;rdquo;, &amp;ldquo;red&amp;rdquo;, &amp;ldquo;yellow&amp;rdquo; and &amp;ldquo;orange&amp;rdquo;. Each sample is an image of a fruit, a label is output for both properties and each label is one of the possible classes of the corresponding property.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="794a77a9ad99cd614e0490463df18e6667fa3c9c" translate="yes" xml:space="preserve">
          <source>For example, classification using features extracted from a set of images of fruit, where each image may either be of an orange, an apple, or a pear. Each image is one sample and is labelled as one of the 3 possible classes. Multiclass classification makes the assumption that each sample is assigned to one and only one label - one sample cannot, for example, be both a pear and an apple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f87725ef6020293ce39f30b54128c30f50570f0e" translate="yes" xml:space="preserve">
          <source>For example, if each point is just a single number (8 bytes), then an effective \(k\)-NN estimator in a paltry \(p \sim 20\) dimensions would require more training data than the current estimated size of the entire internet (&amp;plusmn;1000 Exabytes or so).</source>
          <target state="translated">Например, если каждая точка представляет собой всего лишь одно число (8 байтов), то эффективная оценка \ (k \) - NN в ничтожных \ (p \ sim 20 \) измерениях потребует больше обучающих данных, чем текущий предполагаемый размер весь Интернет (&amp;plusmn; 1000 эксабайт или около того).</target>
        </trans-unit>
        <trans-unit id="5e44134c443036a12804aff41c3842c8f74c39ce" translate="yes" xml:space="preserve">
          <source>For example, in random projection, this warning is raised when the number of components, which quantifies the dimensionality of the target projection space, is higher than the number of features, which quantifies the dimensionality of the original source space, to imply that the dimensionality of the problem will not be reduced.</source>
          <target state="translated">Например,в случайной проекции это предупреждение поднимается,когда количество компонентов,которые количественно определяют размерность целевого проекционного пространства,больше,чем количество элементов,которые количественно определяют размерность исходного исходного пространства,что подразумевает,что размерность задачи не будет уменьшена.</target>
        </trans-unit>
        <trans-unit id="4bb7f297d1cf6895bcaff7553e1e2a2edd1164e9" translate="yes" xml:space="preserve">
          <source>For example, in the cases of multiple experiments, &lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt;&lt;code&gt;LeaveOneGroupOut&lt;/code&gt;&lt;/a&gt; can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one:</source>
          <target state="translated">Например, в случаях нескольких экспериментов &lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt; &lt;code&gt;LeaveOneGroupOut&lt;/code&gt; &lt;/a&gt; можно использовать для создания перекрестной проверки на основе различных экспериментов: мы создаем обучающий набор, используя образцы всех экспериментов, кроме одного:</target>
        </trans-unit>
        <trans-unit id="9dc98c27045ddaa13bc1efc30f0c70951a11ebf1" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s look at the results of a multinomial Naive Bayes classifier, which is fast to train and achieves a decent F-score:</source>
          <target state="translated">Например, давайте посмотрим на результаты полиномиального наивного байесовского классификатора, который быстро обучается и получает приличный F-балл:</target>
        </trans-unit>
        <trans-unit id="85d6aa34dc31a086da5a0b5a46fa6367e968ccaf" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s say we&amp;rsquo;re dealing with a corpus of two documents: &lt;code&gt;['words', 'wprds']&lt;/code&gt;. The second document contains a misspelling of the word &amp;lsquo;words&amp;rsquo;. A simple bag of words representation would consider these two as very distinct documents, differing in both of the two possible features. A character 2-gram representation, however, would find the documents matching in 4 out of 8 features, which may help the preferred classifier decide better:</source>
          <target state="translated">Например, предположим, что мы имеем дело с корпусом из двух документов: &lt;code&gt;['words', 'wprds']&lt;/code&gt; . Во втором документе слово &amp;laquo;слова&amp;raquo; написано неправильно. При простом представлении набора слов эти два документа можно рассматривать как очень разные документы, различающиеся обеими возможными характеристиками. Однако в символьном 2-граммовом представлении документы будут соответствовать 4 из 8 функций, что может помочь предпочтительному классификатору решить лучше:</target>
        </trans-unit>
        <trans-unit id="a387381a97998b7238fd2bc704165170ce740115" translate="yes" xml:space="preserve">
          <source>For example, prediction of both wind speed and wind direction, in degrees, using data obtained at a certain location. Each sample would be data obtained at one location and both wind speed and direction would be output for each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0256c851cb28fec27d5dcefe2d74c45aece1b249" translate="yes" xml:space="preserve">
          <source>For example, prediction of the topics relevant to a text document or video. The document or video may be about one of &amp;lsquo;religion&amp;rsquo;, &amp;lsquo;politics&amp;rsquo;, &amp;lsquo;finance&amp;rsquo; or &amp;lsquo;education&amp;rsquo;, several of the topic classes or all of the topic classes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a34fc3c98b3c662bed7829df5d3e68b291f14f22" translate="yes" xml:space="preserve">
          <source>For example, suppose that we have a first algorithm that extracts Part of Speech (PoS) tags that we want to use as complementary tags for training a sequence classifier (e.g. a chunker). The following dict could be such a window of features extracted around the word &amp;lsquo;sat&amp;rsquo; in the sentence &amp;lsquo;The cat sat on the mat.&amp;rsquo;:</source>
          <target state="translated">Например, предположим, что у нас есть первый алгоритм, который извлекает теги части речи (PoS), которые мы хотим использовать в качестве дополнительных тегов для обучения классификатора последовательности (например, фрагмента). Следующее изречение могло быть таким окном черт, выделенных вокруг слова &amp;laquo;сидел&amp;raquo; в предложении &amp;laquo;Кот сел на циновку&amp;raquo;:</target>
        </trans-unit>
        <trans-unit id="5b46799167b8bb61c43e949f07a2335c6f7cd1fa" translate="yes" xml:space="preserve">
          <source>For example, the distance between &lt;code&gt;[3, na, na, 6]&lt;/code&gt; and &lt;code&gt;[1, na, 4, 5]&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="875d6b4f0ebd92b4525ff9ff007e35a4ef09b992" translate="yes" xml:space="preserve">
          <source>For example, the following snippet uses &lt;code&gt;chardet&lt;/code&gt; (not shipped with scikit-learn, must be installed separately) to figure out the encoding of three texts. It then vectorizes the texts and prints the learned vocabulary. The output is not shown here.</source>
          <target state="translated">Например, в следующем фрагменте &lt;code&gt;chardet&lt;/code&gt; используется chardet (не входит в комплект scikit-learn, необходимо устанавливать отдельно) для определения кодировки трех текстов. Затем он векторизует тексты и распечатывает выученную лексику. Результат здесь не показан.</target>
        </trans-unit>
        <trans-unit id="a5b55b26c17fcbb577abf03053fdea355f9d1a85" translate="yes" xml:space="preserve">
          <source>For example, this warning may occur when the user</source>
          <target state="translated">Например,это предупреждение может появиться,когда пользователь</target>
        </trans-unit>
        <trans-unit id="fa61683485e98ae724ab66c0cc502f9a28b6f341" translate="yes" xml:space="preserve">
          <source>For example, to download a dataset of gene expressions in mice brains:</source>
          <target state="translated">Например,скачать набор данных по экспрессиям генов в мозгах мышей:</target>
        </trans-unit>
        <trans-unit id="0fb165a7680e316154f88ea288da16adb651003b" translate="yes" xml:space="preserve">
          <source>For example, to use &lt;code&gt;n_jobs&lt;/code&gt; greater than 1 in the example below, &lt;code&gt;custom_scoring_function&lt;/code&gt; function is saved in a user-created module (&lt;code&gt;custom_scorer_module.py&lt;/code&gt;) and imported:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bea8752fb35944e93422e8c1c3a159c63e531901" translate="yes" xml:space="preserve">
          <source>For example, we can compute the tf-idf of the first term in the first document in the &lt;code&gt;counts&lt;/code&gt; array as follows:</source>
          <target state="translated">Например, мы можем вычислить tf-idf первого члена в первом документе в массиве &lt;code&gt;counts&lt;/code&gt; следующим образом:</target>
        </trans-unit>
        <trans-unit id="8e5e851ba9e40a81086c0f41a19109e3eeaaee54" translate="yes" xml:space="preserve">
          <source>For example, when dealing with boolean features, \(x_i^n = x_i\) for all \(n\) and is therefore useless; but \(x_i x_j\) represents the conjunction of two booleans. This way, we can solve the XOR problem with a linear classifier:</source>
          <target state="translated">Например,при работе с булевыми функциями,\(x_i^n=x_i\)для всех \(n\)и поэтому бесполезен;но \(x_i x_j\)представляет собой соединение двух булеонов.Таким образом,мы можем решить проблему XOR с помощью линейного классификатора:</target>
        </trans-unit>
        <trans-unit id="dfe2d757676022996b9aa748350ec295d5357a7e" translate="yes" xml:space="preserve">
          <source>For example, when using a validation set, set the &lt;code&gt;test_fold&lt;/code&gt; to 0 for all samples that are part of the validation set, and to -1 for all other samples.</source>
          <target state="translated">Например, при использовании набора проверки установите для &lt;code&gt;test_fold&lt;/code&gt; значение 0 для всех образцов, которые являются частью набора проверки, и значение -1 для всех других образцов.</target>
        </trans-unit>
        <trans-unit id="98a47ab600b3d6adb5169d4d316e6fcca6b662b8" translate="yes" xml:space="preserve">
          <source>For examples on how it is to be used refer to the sections below.</source>
          <target state="translated">Примеры его использования приведены ниже.</target>
        </trans-unit>
        <trans-unit id="717701439dd44ea572c3fc98c89180aa00806795" translate="yes" xml:space="preserve">
          <source>For further details on bias-variance decomposition, see section 7.3 of &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fd7dfc113fdc87e0b1f446fd7d77e9da35e9457" translate="yes" xml:space="preserve">
          <source>For further details on bias-variance decomposition, see section 7.3 of &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">Для получения дополнительных сведений о разложении отклонения и отклонения см. Раздел 7.3 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2f1f137cd461ac2e31c6cc087610e0dfea901ed1" translate="yes" xml:space="preserve">
          <source>For further details, &amp;ldquo;How to Use t-SNE Effectively&amp;rdquo; &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt; provides a good discussion of the effects of various parameters, as well as interactive plots to explore those effects.</source>
          <target state="translated">Для получения дополнительной информации, &amp;laquo;Как эффективно использовать t-SNE&amp;raquo; &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt; предоставляет хорошее обсуждение эффектов различных параметров, а также интерактивные графики для изучения этих эффектов.</target>
        </trans-unit>
        <trans-unit id="0482a5c448a6c0f244b48ce337c6748a1bc4ca45" translate="yes" xml:space="preserve">
          <source>For further details, &amp;ldquo;How to Use t-SNE Effectively&amp;rdquo; &lt;a href=&quot;https://distill.pub/2016/misread-tsne/&quot;&gt;https://distill.pub/2016/misread-tsne/&lt;/a&gt; provides a good discussion of the effects of various parameters, as well as interactive plots to explore those effects.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f1bbe6e8000be72ab1e63dd45896ee0e4b6eb7a" translate="yes" xml:space="preserve">
          <source>For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (&lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;) can perform effective non-linear feature extraction.</source>
          <target state="translated">Для данных изображения в градациях серого, где значения пикселей можно интерпретировать как степени черноты на белом фоне, например, распознавание рукописных цифр, ограниченная модель машины Больцмана &lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt; ( BernoulliRBM ) может выполнять эффективное нелинейное извлечение признаков.</target>
        </trans-unit>
        <trans-unit id="0f8240ee0365c34e0de439585e58b6dfcdcc2ed3" translate="yes" xml:space="preserve">
          <source>For high-dimensional datasets with many collinear features, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt; is most often preferable. However, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt;&lt;code&gt;LassoLarsCV&lt;/code&gt;&lt;/a&gt; has the advantage of exploring more relevant values of &lt;code&gt;alpha&lt;/code&gt; parameter, and if the number of samples is very small compared to the number of features, it is often faster than &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="866314f9db098f25a642d6cb6f4a133adac68ce1" translate="yes" xml:space="preserve">
          <source>For high-dimensional datasets with many collinear regressors, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt; is most often preferable. However, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt;&lt;code&gt;LassoLarsCV&lt;/code&gt;&lt;/a&gt; has the advantage of exploring more relevant values of &lt;code&gt;alpha&lt;/code&gt; parameter, and if the number of samples is very small compared to the number of features, it is often faster than &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Для многомерных наборов данных с множеством коллинеарных регрессоров чаще всего предпочтительнее использовать &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt; . Тем не менее, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt; &lt;code&gt;LassoLarsCV&lt;/code&gt; &lt;/a&gt; имеет то преимущество, что исследует более релевантные значения параметра &lt;code&gt;alpha&lt;/code&gt; , и если количество выборок очень мало по сравнению с количеством функций, это часто быстрее, чем &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="aff7e1aca1f3054316321a609c5b24bbfe0a02a6" translate="yes" xml:space="preserve">
          <source>For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.</source>
          <target state="translated">Информацию о процедуре предварительной обработки в NIST см.в документах M.D.Garris,J.L.Blue,G.T.Candela,D.L.Dimmick,J.Geist,P.J.Grother,S.A.Janet,и C.L.Wilson,NIST Form-Based Handprint Recognition System,NISTIR 5469,1994.</target>
        </trans-unit>
        <trans-unit id="ee57e485cfe4c61d12541e3ea6e169aab79014e8" translate="yes" xml:space="preserve">
          <source>For instance a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.</source>
          <target state="translated">Например,в коллекции из 10 000 коротких текстовых документов (таких как электронные письма)будет использоваться словарь размером порядка 100 000 уникальных слов,в то время как каждый документ будет использовать от 100 до 1000 уникальных слов в отдельности.</target>
        </trans-unit>
        <trans-unit id="4e9f2f3fee78ca296cddfe5ea5b4e060f79a0a4e" translate="yes" xml:space="preserve">
          <source>For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">Например,многие элементы,используемые в объектной функции алгоритма обучения (такие как ядро RBF Support Vector Machines или регуляторы L1 и L2 линейных моделей),предполагают,что все функции центрированы около 0 и имеют дисперсию в одном и том же порядке.Если какой-либо признак имеет дисперсию на порядок больше,чем другие,то он может доминировать над объектной функцией и сделать так,что оценщик не сможет правильно учиться у других признаков,как это ожидается.</target>
        </trans-unit>
        <trans-unit id="9c54ff6618aa4505fc044efee7a1b7aa2d457afd" translate="yes" xml:space="preserve">
          <source>For instance the below given table</source>
          <target state="translated">Например,нижеприведённая таблица</target>
        </trans-unit>
        <trans-unit id="61fc71afaf6946d5d1cad0702c1f4030326fcb83" translate="yes" xml:space="preserve">
          <source>For instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.</source>
          <target state="translated">Например,группы могут являться годом сбора проб и,таким образом,позволять проводить перекрестную проверку на основе временных разделений.</target>
        </trans-unit>
        <trans-unit id="c007161505dacd37b43b63ce0c84bfbd3ce25160" translate="yes" xml:space="preserve">
          <source>For instance, assuming that the inlier data are Gaussian distributed, it will estimate the inlier location and covariance in a robust way (i.e. without being influenced by outliers). The Mahalanobis distances obtained from this estimate is used to derive a measure of outlyingness. This strategy is illustrated below.</source>
          <target state="translated">Например,если предположить,что данные о рассадке распределены по Гауссу,то это позволит робастно (т.е.без влияния отклонений)оценить местоположение рассадки и ее ковариативность.Расстояния Махаланобиса,полученные из этой оценки,используются для получения измерения отклонений.Эта стратегия проиллюстрирована ниже.</target>
        </trans-unit>
        <trans-unit id="7519828cefe279ed0b1f593fd20db7243c914832" translate="yes" xml:space="preserve">
          <source>For instance, given a matrix of shape &lt;code&gt;(10, 10)&lt;/code&gt;, one possible bicluster with three rows and two columns induces a submatrix of shape &lt;code&gt;(3, 2)&lt;/code&gt;:</source>
          <target state="translated">Например, для матрицы формы &lt;code&gt;(10, 10)&lt;/code&gt; один возможный бикластер с тремя строками и двумя столбцами индуцирует подматрицу формы &lt;code&gt;(3, 2)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="66b8e52235d720becae09b00e19696b279a13527" translate="yes" xml:space="preserve">
          <source>For instance, if \(p\) singular vectors were calculated, the \(q\) best are found as described, where \(q&amp;lt;p\). Let \(U\) be the matrix with columns the \(q\) best left singular vectors, and similarly \(V\) for the right. To partition the rows, the rows of \(A\) are projected to a \(q\) dimensional space: \(A * V\). Treating the \(m\) rows of this \(m \times q\) matrix as samples and clustering using k-means yields the row labels. Similarly, projecting the columns to \(A^{\top} * U\) and clustering this \(n \times q\) matrix yields the column labels.</source>
          <target state="translated">Например, если были вычислены \ (p \) сингулярные векторы, наилучшие \ (q \) будут найдены, как описано, где \ (q &amp;lt;p \). Пусть \ (U \) будет матрицей со столбцами, \ (q \) лучшими левыми сингулярными векторами, и аналогично \ (V \) для правых. Чтобы разделить строки, строки \ (A \) проецируются в \ (q \) мерное пространство: \ (A * V \). Обработка \ (m \) строк этой матрицы \ (m \ times q \) как выборок и кластеризация с использованием k-средних дает метки строк. Аналогично, проецирование столбцов на \ (A ^ {\ top} * U \) и кластеризация этой матрицы \ (n \ times q \) дает метки столбцов.</target>
        </trans-unit>
        <trans-unit id="040e034a022032a75dc3b85f4ce9de7cff88a6fc" translate="yes" xml:space="preserve">
          <source>For instance, if we work with 64x64 pixel gray-level pictures for face recognition, the dimensionality of the data is 4096 and it is slow to train an RBF support vector machine on such wide data. Furthermore we know that the intrinsic dimensionality of the data is much lower than 4096 since all pictures of human faces look somewhat alike. The samples lie on a manifold of much lower dimension (say around 200 for instance). The PCA algorithm can be used to linearly transform the data while both reducing the dimensionality and preserve most of the explained variance at the same time.</source>
          <target state="translated">Например,если мы работаем с 64x64 пиксельными картинками серого цвета для распознавания лиц,то размерность данных составляет 4096 и обучение векторной машины поддержки RBF на таких широких данных происходит медленно.Более того,мы знаем,что внутренняя размерность данных значительно меньше 4096,так как все картинки человеческих лиц выглядят несколько одинаково.Образцы лежат на многообразии гораздо меньшей размерности (скажем,около 200).Алгоритм PCA может использоваться для линейного преобразования данных,одновременно уменьшая размерность и сохраняя большую часть объясненной дисперсии.</target>
        </trans-unit>
        <trans-unit id="f676ab37a8d5ec2f850de1fcd3ee779d6ce55a52" translate="yes" xml:space="preserve">
          <source>For instance, in the case of the digits dataset, &lt;code&gt;digits.data&lt;/code&gt; gives access to the features that can be used to classify the digits samples:</source>
          <target state="translated">Например, в случае набора данных &lt;code&gt;digits.data&lt;/code&gt; предоставляет доступ к функциям, которые можно использовать для классификации образцов цифр:</target>
        </trans-unit>
        <trans-unit id="0b72faa109feccaf14265d5a54672e188bc4b73a" translate="yes" xml:space="preserve">
          <source>For instance, in the example below, decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.</source>
          <target state="translated">Например,в примере ниже,деревья решений учатся на основе данных аппроксимировать синусоидальную кривую с набором правил принятия решений if-then-else.Чем глубже дерево,тем сложнее правила принятия решений и тем лучше подгоняется модель.</target>
        </trans-unit>
        <trans-unit id="a42ba327206d2f6a371d1c7b16518c8946340f21" translate="yes" xml:space="preserve">
          <source>For instance, let&amp;rsquo;s compare the two predictions 1.0 and 100 that are both 50% of their corresponding true value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb4b6181584be99d136bb8fd3d82dd09da37eec0" translate="yes" xml:space="preserve">
          <source>For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">Например,многие элементы,используемые в объектной функции алгоритма обучения (такие как ядро RBF Support Vector Machines или регуляторы l1 и l2 линейных моделей),предполагают,что все функции центрированы вокруг нуля и имеют дисперсию в одном и том же порядке.Если какой-либо признак имеет дисперсию на порядок больше других,то он может доминировать над объектной функцией и сделать так,что оценщик не сможет правильно учиться у других признаков,как это ожидается.</target>
        </trans-unit>
        <trans-unit id="2500a85d8a54066d44afc291418c2bdbdb2d8331" translate="yes" xml:space="preserve">
          <source>For instance, the following shows 16 sample portraits (centered around 0.0) from the Olivetti dataset. On the right hand side are the first 16 singular vectors reshaped as portraits. Since we only require the top 16 singular vectors of a dataset with size \(n_{samples} = 400\) and \(n_{features} = 64 \times 64 = 4096\), the computation time is less than 1s:</source>
          <target state="translated">Например,ниже показаны 16 образцов портретов (с центром около 0,0)из набора данных Olivetti.Справа изображены первые 16 единичных векторов,переформулированных как портреты.Так как нам нужны только верхние 16 сингулярных векторов набора данных с размером \(n_{samples}=400\)и \(n_{features}=64 \times 64=4096\),то время вычисления меньше 1 с:</target>
        </trans-unit>
        <trans-unit id="8f189274df939cb66095eb188cc3a399c86cb294" translate="yes" xml:space="preserve">
          <source>For instance, we can perform a \(\chi^2\) test to the samples to retrieve only the two best features as follows:</source>
          <target state="translated">Например,мы можем выполнить тест \(\chi^2\)на сэмплы,чтобы получить только две лучшие возможности следующим образом:</target>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="translated">Например:</target>
        </trans-unit>
        <trans-unit id="c017c696c4eba476debcc2637355a4ef09f7c0a3" translate="yes" xml:space="preserve">
          <source>For int/None inputs, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="560fc78b966a9c766c4d5505bc2466cc24122eb7" translate="yes" xml:space="preserve">
          <source>For int/None inputs, if the estimator is a classifier and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21205df9d4ba13a75af14823666b84f64bd04084" translate="yes" xml:space="preserve">
          <source>For integer/None inputs &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">Для входов &lt;code&gt;KFold&lt;/code&gt; integer / None используется KFold .</target>
        </trans-unit>
        <trans-unit id="f4cdf9352c6e062816193041b97f5514c42b421e" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">Для входов типа integer / None используется &lt;code&gt;KFold&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f206c091dc56a7e693c1c1efe6b0899c57cec04a" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used, else, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Для входных &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; integer / None, если &lt;code&gt;y&lt;/code&gt; двоичный или многоклассовый, используется sklearn.model_selection.StratifiedKFold , в противном &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; используется sklearn.model_selection.KFold .</target>
        </trans-unit>
        <trans-unit id="84373ac49af10a751441a8470e060e3de62490b1" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Для входных &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; integer / None, если &lt;code&gt;y&lt;/code&gt; двоичный или многоклассовый, используется sklearn.model_selection.StratifiedKFold . Если &lt;code&gt;y&lt;/code&gt; не является ни двоичным, ни многоклассовым, используется &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="8d4fea32021fed22e35126e0e01d0c620369dc78" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If the estimator is a classifier or if &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Для входных &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt; integer / None, если &lt;code&gt;y&lt;/code&gt; двоичный или многоклассовый, используется sklearn.model_selection.StratifiedKFold . Если оценщик является классификатором или если &lt;code&gt;y&lt;/code&gt; не является ни двоичным, ни многоклассовым, используется &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="68ad85210cd514ab63c161f2689020aa738ee186" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if classifier is True and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Для входных значений типа integer / None, если классификатор True и &lt;code&gt;y&lt;/code&gt; либо двоичный, либо мультиклассовый, используется &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; . Во всех остальных случаях используется &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="821cadb32f750528bd31875526972b81201437b9" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if the estimator is a classifier and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">Для входных данных типа integer / None, если оценщик является классификатором, а &lt;code&gt;y&lt;/code&gt; является двоичным или многоклассовым, используется &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; . Во всех остальных случаях используется &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ec46cd7e35a119deeb6479ced2aa91071495e898" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, &lt;code&gt;StratifiedKFold&lt;/code&gt; is used. In all other cases, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfc9bcb00c8530f8c99a68584e1330a4da8fc56a" translate="yes" xml:space="preserve">
          <source>For intermediate values, we can see on the second plot that good models can be found on a diagonal of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. Smooth models (lower &lt;code&gt;gamma&lt;/code&gt; values) can be made more complex by increasing the importance of classifying each point correctly (larger &lt;code&gt;C&lt;/code&gt; values) hence the diagonal of good performing models.</source>
          <target state="translated">Для промежуточных значений на втором графике видно, что хорошие модели можно найти на диагонали &lt;code&gt;C&lt;/code&gt; и &lt;code&gt;gamma&lt;/code&gt; . Гладкие модели (более низкие значения &lt;code&gt;gamma&lt;/code&gt; ) можно сделать более сложными, увеличив важность правильной классификации каждой точки (более высокие значения &lt;code&gt;C&lt;/code&gt; ), следовательно, диагональ хорошо работающих моделей.</target>
        </trans-unit>
        <trans-unit id="eb96f16ecd15a6be088f1dc93fa28ca4ca7ecca5" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples_test, n_samples_train).</source>
          <target state="translated">Для kernel = &quot;precomputed&quot; ожидаемая форма X будет (n_samples_test, n_samples_train).</target>
        </trans-unit>
        <trans-unit id="93c16e02e4641d6fe7bdb8a83439c237817b53cd" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is [n_samples_test, n_samples_train]</source>
          <target state="translated">Для kernel = &quot;precomputed&quot; ожидаемая форма X будет [n_samples_test, n_samples_train]</target>
        </trans-unit>
        <trans-unit id="9cb299cfc771ccbc3a241c16ffeed37fabbcff7c" translate="yes" xml:space="preserve">
          <source>For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss.</source>
          <target state="translated">Для большого набора данных вы также можете рассмотреть возможность использования &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt; с потерей журнала.</target>
        </trans-unit>
        <trans-unit id="3b24421d17b9758d0c0e99f847aff320121bf350" translate="yes" xml:space="preserve">
          <source>For large datasets, similar (but not identical) results can be obtained via &lt;a href=&quot;https://hdbscan.readthedocs.io&quot;&gt;HDBSCAN&lt;/a&gt;. The HDBSCAN implementation is multithreaded, and has better algorithmic runtime complexity than OPTICS, at the cost of worse memory scaling. For extremely large datasets that exhaust system memory using HDBSCAN, OPTICS will maintain &lt;em&gt;n&lt;/em&gt; (as opposed to &lt;em&gt;n^2&lt;/em&gt;) memory scaling; however, tuning of the &lt;code&gt;max_eps&lt;/code&gt; parameter will likely need to be used to give a solution in a reasonable amount of wall time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98187e1f181515ca77d41de7fa27ac44b69c7c11" translate="yes" xml:space="preserve">
          <source>For many estimators, including the SVMs, having datasets with unit standard deviation for each feature is important to get good prediction.</source>
          <target state="translated">Для многих оценщиков,включая SVM,наличие наборов данных с единичным стандартным отклонением для каждой функции важно для получения хорошего прогноза.</target>
        </trans-unit>
        <trans-unit id="f1359c1e0656157adbc7e3ee11ae253cb961bb70" translate="yes" xml:space="preserve">
          <source>For mono-output tasks it is:</source>
          <target state="translated">Для моно-выпускных задач это так:</target>
        </trans-unit>
        <trans-unit id="c24592da8118b35d1dd067bf2a75576669aef344" translate="yes" xml:space="preserve">
          <source>For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression,&amp;rdquo; Annals of Statistics (with discussion), 407-499. (&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;)</source>
          <target state="translated">Для получения дополнительной информации см .: Брэдли Эфрон, Тревор Хасти, Иэн Джонстон и Роберт Тибширани (2004) &amp;laquo;Регрессия наименьшего угла&amp;raquo;, Annals of Statistics (с обсуждением), 407-499. ( &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="d5e463f9f0eea6808a42462cec939570f71a16a6" translate="yes" xml:space="preserve">
          <source>For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression,&amp;rdquo; Annals of Statistics (with discussion), 407-499. (&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4bc4c3f735998ec8c1614ec6127a37e3e7a02d8" translate="yes" xml:space="preserve">
          <source>For more information, see &lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;.</source>
          <target state="translated">Для получения дополнительной информации см. &lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;Иерархическая кластеризация&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b089e1ecd97ba592f22037a3c3fabf2924387c39" translate="yes" xml:space="preserve">
          <source>For more on usage see the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Подробнее об использовании см. &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;Руководство пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2e682df49d58d058f1f4b4c26ca6fb15a2f979d8" translate="yes" xml:space="preserve">
          <source>For multi-class classification, &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt;&lt;code&gt;AdaBoostClassifier&lt;/code&gt;&lt;/a&gt; implements AdaBoost-SAMME and AdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]&lt;/a&gt;.</source>
          <target state="translated">Для мультиклассовой классификации &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt; &lt;code&gt;AdaBoostClassifier&lt;/code&gt; &lt;/a&gt; реализует AdaBoost-SAMME и AdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="416ab9ed1829c79f2f091ddf9b13cfb5bb7486ce" translate="yes" xml:space="preserve">
          <source>For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.</source>
          <target state="translated">Для классификации нескольких классов,классификаторы n_класса обучены подходу &quot;один-на-все-все&quot;.Конкретно это реализовано с помощью поддержки многовариантного ответа в Ridge.</target>
        </trans-unit>
        <trans-unit id="f04898b2d6925a5dec9ef02339647623f6f19f8d" translate="yes" xml:space="preserve">
          <source>For multi-class classification, you need to set the class label for which the PDPs should be created via the &lt;code&gt;target&lt;/code&gt; argument:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65042013a5d26811a6a7088f4c47e70c6ddb0074" translate="yes" xml:space="preserve">
          <source>For multi-class models, you need to set the class label for which the PDPs should be created via the &lt;code&gt;label&lt;/code&gt; argument:</source>
          <target state="translated">Для мультиклассовых моделей вам необходимо установить метку класса, для которого должны быть созданы PDP, с помощью аргумента &lt;code&gt;label&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="ccc2264ef7a998ec0c6ed9c92245080e0f0807c7" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, the scores for all the scorers are available in the &lt;code&gt;cv_results_&lt;/code&gt; dict at the keys ending with that scorer&amp;rsquo;s name (&lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt;) instead of &lt;code&gt;'_score'&lt;/code&gt; shown above. (&amp;lsquo;split0_test_precision&amp;rsquo;, &amp;lsquo;mean_train_precision&amp;rsquo; etc.)</source>
          <target state="translated">Для многомерной оценки оценки для всех &lt;code&gt;cv_results_&lt;/code&gt; доступны в cv_results_ dict в ключах, оканчивающихся на имя этого секретаря ( &lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt; ) вместо &lt;code&gt;'_score'&lt;/code&gt; , показанного выше. ('split0_test_precision', 'mean_train_precision' и т. д.)</target>
        </trans-unit>
        <trans-unit id="6cd27769ef18013ec211b9a824f9bced7dd1ce74" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute holds the validated &lt;code&gt;scoring&lt;/code&gt; dict which maps the scorer key to the scorer callable.</source>
          <target state="translated">Для многомерной оценки этот атрибут содержит утвержденный &lt;code&gt;scoring&lt;/code&gt; словарь, который сопоставляет ключ секретаря с вызываемым счетчиком.</target>
        </trans-unit>
        <trans-unit id="39c0f65b87a914c1f3244978c44bbc4d0d1190be" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">Для многомерной оценки этот атрибут присутствует только в том случае, если указано &lt;code&gt;refit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dd788cb84c37fa5cbd110321907573fb764ddce9" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is not available if &lt;code&gt;refit&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. See &lt;code&gt;refit&lt;/code&gt; parameter for more information.</source>
          <target state="translated">Для многомерной оценки это недоступно, если &lt;code&gt;refit&lt;/code&gt; имеет значение &lt;code&gt;False&lt;/code&gt; . Для получения дополнительной информации см. Параметр &lt;code&gt;refit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4367b150d838b05eaff7170a1426f1dc4e6edc76" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">Для многомерной оценки это присутствует, только если указано &lt;code&gt;refit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d328aa31182c6b57c5d921c1da1c7333c03486fe" translate="yes" xml:space="preserve">
          <source>For multi-output tasks it is:</source>
          <target state="translated">Для задач с несколькими выходами это так:</target>
        </trans-unit>
        <trans-unit id="22c12fa701004eab18f67dae2fb9f6cb3b68f428" translate="yes" xml:space="preserve">
          <source>For multi-output, the weights of each column of y will be multiplied.</source>
          <target state="translated">Для мультивыхода веса каждого столбца y будут умножены.</target>
        </trans-unit>
        <trans-unit id="77f8b599f18368a52e2142c2cada7c61eef9fbca" translate="yes" xml:space="preserve">
          <source>For multiclass classification with a &amp;ldquo;negative class&amp;rdquo;, it is possible to exclude some labels:</source>
          <target state="translated">Для мультиклассовой классификации с &amp;laquo;отрицательным классом&amp;raquo; можно исключить некоторые метки:</target>
        </trans-unit>
        <trans-unit id="dedd3af803ae0305b6a99c040827201493989ff1" translate="yes" xml:space="preserve">
          <source>For multiclass classification, K trees (for K classes) are built at each of the \(M\) iterations. The probability that \(x_i\) belongs to class k is modeled as a softmax of the \(F_{M,k}(x_i)\) values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="393c73f8bfb73747a6a85987ccf51d73c8d3636f" translate="yes" xml:space="preserve">
          <source>For multiclass problems, only &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; handle multinomial loss; &amp;lsquo;liblinear&amp;rsquo; is limited to one-versus-rest schemes.</source>
          <target state="translated">Для задач мультикласса только 'newton-cg', 'sag', 'saga' и 'lbfgs' обрабатывают полиномиальные потери; &amp;laquo;liblinear&amp;raquo; ограничивается схемами &amp;laquo;один против остальных&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="de227a68bb98af9d7f682ac4556427f028c04d66" translate="yes" xml:space="preserve">
          <source>For multiple labels per instance, use &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">Для нескольких меток на экземпляр используйте &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="36264d57db60ea0d287310ae67879ef2207922af" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a &lt;code&gt;str&lt;/code&gt; denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="088c3cd08ec3b30c1e8d705dc9f773b25266ffd1" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer is used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">Для многократной оценки метрик,это должна быть строка,обозначающая оценщик,которая используется для поиска лучших параметров для переоснащения оценщика в конце.</target>
        </trans-unit>
        <trans-unit id="ab406c3bb6ddaeec6408e58ba4985d8a5097ee33" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">Для многократной метрической оценки это должна быть строка,обозначающая оценщик,которая будет использоваться для поиска наилучших параметров для переоснащения оценщика в конце.</target>
        </trans-unit>
        <trans-unit id="f895ac59b8264ca94c275f903e2d6c6c438b4c9c" translate="yes" xml:space="preserve">
          <source>For multiplicative-update (&amp;lsquo;mu&amp;rsquo;) solver, the Frobenius norm (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss, by changing the beta_loss parameter.</source>
          <target state="translated">Для решателя мультипликативного обновления ('mu') норма Фробениуса (0,5 * || X - WH || _Fro ^ 2) может быть изменена на другую потерю бета-дивергенции, изменив параметр beta_loss.</target>
        </trans-unit>
        <trans-unit id="4d0bed9bc5aa3b36bb0ba6ad6bc592a5bb3e78af" translate="yes" xml:space="preserve">
          <source>For n_components == &amp;lsquo;mle&amp;rsquo;, this class uses the method of &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt;</source>
          <target state="translated">Для n_components == 'mle' в этом классе используется метод &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bd307d11754e6296ef567a0e60c357948ac810da" translate="yes" xml:space="preserve">
          <source>For n_components == &amp;lsquo;mle&amp;rsquo;, this class uses the method of &lt;em&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f27cc961ae174b8e96b15764c2907159174c2c2" translate="yes" xml:space="preserve">
          <source>For non-sparse models, i.e. when there are not many zeros in &lt;code&gt;coef_&lt;/code&gt;, this may actually &lt;em&gt;increase&lt;/em&gt; memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt;, must be more than 50% for this to provide significant benefits.</source>
          <target state="translated">Для не разреженных моделей, т.е. когда в &lt;code&gt;coef_&lt;/code&gt; не так много нулей , это может фактически &lt;em&gt;увеличить&lt;/em&gt; использование памяти, поэтому используйте этот метод с осторожностью. Эмпирическое правило состоит в том, что количество нулевых элементов, которые можно вычислить с помощью &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt; , должно быть больше 50%, чтобы это обеспечило значительные преимущества.</target>
        </trans-unit>
        <trans-unit id="ffa9a81349b558a734852a9e93a9e01e72e14f97" translate="yes" xml:space="preserve">
          <source>For normalized mutual information and adjusted mutual information, the normalizing value is typically some &lt;em&gt;generalized&lt;/em&gt; mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides &amp;ldquo;qualitatively similar behaviours&amp;rdquo; &lt;a href=&quot;#yat2016&quot; id=&quot;id14&quot;&gt;[YAT2016]&lt;/a&gt;. In our implementation, this is controlled by the &lt;code&gt;average_method&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e62cf2ed735d43186d3b55660d3dd2856258814f" translate="yes" xml:space="preserve">
          <source>For normalized mutual information and adjusted mutual information, the normalizing value is typically some &lt;em&gt;generalized&lt;/em&gt; mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides &amp;ldquo;qualitatively similar behaviours&amp;rdquo; [YAT2016]. In our implementation, this is controlled by the &lt;code&gt;average_method&lt;/code&gt; parameter.</source>
          <target state="translated">Для нормализованной взаимной информации и скорректированной взаимной информации нормализующее значение обычно представляет собой некоторое &lt;em&gt;обобщенное&lt;/em&gt; среднее энтропий каждой кластеризации. Существуют различные обобщенные средства, и не существует твердых правил предпочтения одного из них. Решение в основном принимается отдельно для каждого поля; например, при обнаружении сообществ наиболее часто используется среднее арифметическое. Каждый метод нормализации обеспечивает &amp;laquo;качественно похожее поведение&amp;raquo; [YAT2016]. В нашей реализации это контролируется параметром &lt;code&gt;average_method&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8d22dd702102471017e490a2b7bc8b22b9add5e5" translate="yes" xml:space="preserve">
          <source>For now &amp;ldquo;auto&amp;rdquo; (kept for backward compatibiliy) chooses &amp;ldquo;elkan&amp;rdquo; but it might change in the future for a better heuristic.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5573de0c3d8eae2871980794db1007675aa56eed" translate="yes" xml:space="preserve">
          <source>For now, we will consider the estimator as a black box:</source>
          <target state="translated">Пока мы будем рассматривать оценку как черный ящик:</target>
        </trans-unit>
        <trans-unit id="436dc589cc421427188d0cca81de34e1e73f3c7d" translate="yes" xml:space="preserve">
          <source>For one sample, given the vector of continuous ground-truth values for each target \(y \in \mathbb{R}^{M}\), where \(M\) is the number of outputs, and the prediction \(\hat{y}\), which induces the ranking function \(f\), the DCG score is</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09d6f289aa89a27e5d33a2c2e001f7d32a001ce5" translate="yes" xml:space="preserve">
          <source>For our dataset, again the model is not very predictive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a7f8c21b68cc173c251c1992bff906fb9b13f276" translate="yes" xml:space="preserve">
          <source>For parameter estimation, the posterior distribution is:</source>
          <target state="translated">Для оценки параметров используется апостериорное распределение:</target>
        </trans-unit>
        <trans-unit id="acaedbca04fb48c0d8436452cabe74f03629d275" translate="yes" xml:space="preserve">
          <source>For regression the default learning rate schedule is inverse scaling (&lt;code&gt;learning_rate='invscaling'&lt;/code&gt;), given by</source>
          <target state="translated">Для регрессии график скорости обучения по умолчанию - обратное масштабирование ( &lt;code&gt;learning_rate='invscaling'&lt;/code&gt; ), заданное следующим образом:</target>
        </trans-unit>
        <trans-unit id="17d6bf85a6ee02e9c1e3f5f799f4a791f96ca437" translate="yes" xml:space="preserve">
          <source>For regression with a squared loss and a l2 penalty, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Для регрессии с квадратом потерь и штрафом l2 доступен другой вариант SGD со стратегией усреднения с алгоритмом стохастического среднего градиента (SAG), доступным в качестве решателя в &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="82e8631b28597b123d5803439222a08ee2e59047" translate="yes" xml:space="preserve">
          <source>For regression, &lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt;&lt;code&gt;AdaBoostRegressor&lt;/code&gt;&lt;/a&gt; implements AdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]&lt;/a&gt;.</source>
          <target state="translated">Для регрессии &lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt; &lt;code&gt;AdaBoostRegressor&lt;/code&gt; &lt;/a&gt; реализует AdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="faab950ebeb88e87f11e22c6efcd943439e07aea" translate="yes" xml:space="preserve">
          <source>For regression, MLP uses the Square Error loss function; written as,</source>
          <target state="translated">Для регрессии MLP использует функцию Square Error loss;записывается как,</target>
        </trans-unit>
        <trans-unit id="a8c842b7da02e24dac30b073413aa7112e52aecd" translate="yes" xml:space="preserve">
          <source>For regression: &lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt;&lt;code&gt;f_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Для регрессии: &lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt; &lt;code&gt;f_regression&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e8aa16ccbf6b94ae32b7c5b78e608f800f0eb6cd" translate="yes" xml:space="preserve">
          <source>For scikit-learn versions 0.14.1 and prior, return_as=np.ndarray was handled by returning a dense np.matrix instance. Going forward, np.ndarray returns an np.ndarray, as expected.</source>
          <target state="translated">Для scikit-learn версий 0.14.1 и более ранних,return_as=np.ndarray обрабатывался возвращением плотного экземпляра np.matrix.В дальнейшем np.ndarray возвращает np.ndarray,как и ожидалось.</target>
        </trans-unit>
        <trans-unit id="2410f1ccaa1a03065aaeec2b709967381feb9cea" translate="yes" xml:space="preserve">
          <source>For simple transformations, instead of a Transformer object, a pair of functions can be passed, defining the transformation and its inverse mapping:</source>
          <target state="translated">Для простых преобразований вместо объекта Трансформатор может быть передана пара функций,определяющих преобразование и его обратное отображение:</target>
        </trans-unit>
        <trans-unit id="2f72f7e3c1f68f97fc714ad1c06f3f5738fb15a6" translate="yes" xml:space="preserve">
          <source>For simplicity the equation above is written for a single training example. The gradient with respect to the weights is formed of two terms corresponding to the ones above. They are usually known as the positive gradient and the negative gradient, because of their respective signs. In this implementation, the gradients are estimated over mini-batches of samples.</source>
          <target state="translated">Для простоты вышеприведенное уравнение написано для одного обучающего примера.Градиент по отношению к весам формируется из двух членов,соответствующих вышеприведенным.Они обычно называются положительным градиентом и отрицательным градиентом из-за соответствующих признаков.В этой реализации градиенты оцениваются по мини-группам проб.</target>
        </trans-unit>
        <trans-unit id="27c46746207f2a31ae25da1632ef3ccf3ef87e4d" translate="yes" xml:space="preserve">
          <source>For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</source>
          <target state="translated">Для оценки с одним показателем, где параметром оценки является строка, вызываемая или None, ключи будут - &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a0a8bb77034843b440cd9ae1f7c55bd3aa47ece1" translate="yes" xml:space="preserve">
          <source>For small data sets (\(N\) less than 30 or so), \(\log(N)\) is comparable to \(N\), and brute force algorithms can be more efficient than a tree-based approach. Both &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; address this through providing a &lt;em&gt;leaf size&lt;/em&gt; parameter: this controls the number of samples at which a query switches to brute-force. This allows both algorithms to approach the efficiency of a brute-force computation for small \(N\).</source>
          <target state="translated">Для небольших наборов данных (\ (N \) менее 30 или около того), \ (\ log (N) \) сравнимо с \ (N \), а алгоритмы грубой силы могут быть более эффективными, чем подход на основе дерева. И &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; ,&lt;/a&gt; и &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; решают эту проблему, предоставляя параметр &lt;em&gt;размера листа&lt;/em&gt; : он контролирует количество выборок, при котором запрос переключается на грубую силу. Это позволяет обоим алгоритмам приблизиться к эффективности вычисления методом перебора при малых \ ​​(N \).</target>
        </trans-unit>
        <trans-unit id="4638d963661692a289a12b8cac2d92a9d2c758fa" translate="yes" xml:space="preserve">
          <source>For small datasets, &amp;lsquo;liblinear&amp;rsquo; is a good choice, whereas &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; are faster for large ones.</source>
          <target state="translated">Для небольших наборов данных &quot;liblinear&quot; - хороший выбор, тогда как &quot;sag&quot; и &quot;saga&quot; быстрее для больших.</target>
        </trans-unit>
        <trans-unit id="dffce5e2239efe7c22f00e78e9cfce148c8ba698" translate="yes" xml:space="preserve">
          <source>For some applications the amount of examples, features (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. In these cases scikit-learn has a number of options you can consider to make your system scale.</source>
          <target state="translated">Для некоторых приложений количество примеров,функций (или и тех,и других)и/или скорость,с которой они должны быть обработаны,являются сложными для традиционных подходов.В этих случаях у Scikit-learn есть несколько вариантов,которые вы можете рассмотреть,чтобы сделать вашу систему масштабируемой.</target>
        </trans-unit>
        <trans-unit id="d0fa030cdd6e029de147eaddac9b22a69b1ced78" translate="yes" xml:space="preserve">
          <source>For some applications the performance (mainly latency and throughput at prediction time) of estimators is crucial. It may also be of interest to consider the training throughput but this is often less important in a production setup (where it often takes place offline).</source>
          <target state="translated">Для некоторых приложений решающее значение имеет производительность (в основном,задержка и пропускная способность в прогнозируемое время)оценочных приборов.Также может представлять интерес учебная пропускная способность,но это часто менее важно в производственной установке (где это часто происходит в автономном режиме).</target>
        </trans-unit>
        <trans-unit id="7c42c316b39e1433fd7efc7ca18424a81519f374" translate="yes" xml:space="preserve">
          <source>For some business applications, we are interested in the ability of the model to rank the riskiest from the safest policyholders, irrespective of the absolute value of the prediction. In this case, the model evaluation would cast the problem as a ranking problem rather than a regression problem.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7400fa7073eb75f62370e5aadbb0f2aef8d5fc81" translate="yes" xml:space="preserve">
          <source>For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using &lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt;&lt;code&gt;PredefinedSplit&lt;/code&gt;&lt;/a&gt; it is possible to use these folds e.g. when searching for hyperparameters.</source>
          <target state="translated">Для некоторых наборов данных уже существует предварительно определенное разделение данных на свертки обучения и проверки или на несколько сверток перекрестной проверки. Используя &lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt; &lt;code&gt;PredefinedSplit&lt;/code&gt; ,&lt;/a&gt; можно использовать эти свертки, например, при поиске гиперпараметров.</target>
        </trans-unit>
        <trans-unit id="694369dc091b24e34e3df33be9eef2601d0ef6d1" translate="yes" xml:space="preserve">
          <source>For some losses, e.g. the least absolute deviation (LAD) where the gradients are \(\pm 1\), the values predicted by a fitted \(h_m\) are not accurate enough: the tree can only output integer values. As a result, the leaves values of the tree \(h_m\) are modified once the tree is fitted, such that the leaves values minimize the loss \(L_m\). The update is loss-dependent: for the LAD loss, the value of a leaf is updated to the median of the samples in that leaf.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c50bf24a893de08f1d0809fe397202f1a031fb85" translate="yes" xml:space="preserve">
          <source>For some miscellaneous data such as images, videos, and audio, you may wish to refer to:</source>
          <target state="translated">Для некоторых различных данных,таких как изображения,видео и аудио,вы можете сослаться на них:</target>
        </trans-unit>
        <trans-unit id="303cfe0bd7811405e77868ed843c4904556ebde5" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;) before being fed to efficient Cython routines. To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">Для разреженного ввода данные &lt;strong&gt;преобразуются в представление сжатых разреженных строк&lt;/strong&gt; (см. &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; ) перед подачей в эффективные подпрограммы Cython. Чтобы избежать ненужных копий памяти, рекомендуется выбирать представление CSR в восходящем направлении.</target>
        </trans-unit>
        <trans-unit id="44ae99861a7942ab4350b3f16d27ddb33207e51f" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;). To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">Для разреженного ввода данные &lt;strong&gt;преобразуются в представление сжатых разреженных строк&lt;/strong&gt; (см. &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; ). Чтобы избежать ненужных копий памяти, рекомендуется выбирать представление CSR в восходящем направлении.</target>
        </trans-unit>
        <trans-unit id="a6ddfb481ebd700db5464677bebe705030e704c9" translate="yes" xml:space="preserve">
          <source>For speed and space efficiency reasons &lt;code&gt;scikit-learn&lt;/code&gt; loads the target attribute as an array of integers that corresponds to the index of the category name in the &lt;code&gt;target_names&lt;/code&gt; list. The category integer id of each sample is stored in the &lt;code&gt;target&lt;/code&gt; attribute:</source>
          <target state="translated">Из соображений скорости и экономии места &lt;code&gt;scikit-learn&lt;/code&gt; загружает целевой атрибут как массив целых чисел, который соответствует индексу имени категории в списке &lt;code&gt;target_names&lt;/code&gt; . Целочисленный идентификатор категории каждого образца сохраняется в &lt;code&gt;target&lt;/code&gt; атрибуте:</target>
        </trans-unit>
        <trans-unit id="7ace947ef3298ab26b0edee5253deecf977a3b02" translate="yes" xml:space="preserve">
          <source>For speed, all real work is done at the C level in function copy_predict (libsvm_helper.c).</source>
          <target state="translated">Для скорости вся реальная работа выполняется на уровне C в функции copy_predict (libsvm_helper.c).</target>
        </trans-unit>
        <trans-unit id="1c3a0f29bcc1c543ffc020478b77d5b706223ce4" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit domain-specific stratification of the dataset.</source>
          <target state="translated">Для разделения данных в соответствии с явной доменной стратификацией набора данных.</target>
        </trans-unit>
        <trans-unit id="0adf7a63adc917db1adffd6d4cf61e05de34a6e7" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit, domain-specific stratification of the dataset.</source>
          <target state="translated">Для разделения данных в соответствии с явным,специфическим для домена расслоением набора данных.</target>
        </trans-unit>
        <trans-unit id="ab4a742934d8510715858d09854f728742beaaec" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;arpack&amp;rsquo;, refer to &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;.</source>
          <target state="translated">Для svd_solver == 'arpack' обратитесь к &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="25caaa7ea914cf58c60f262a55964ee17d21e090" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;randomized&amp;rsquo;, see: &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; and also &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</source>
          <target state="translated">Для svd_solver == 'randomized' см .: &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; а также &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c853f7e3d4c36b0f8076402fc9583125688d75a1" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;randomized&amp;rsquo;, see: &lt;em&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/em&gt; and also &lt;em&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/em&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7341be727234aad9fa4e331ba9d61b6fce122ff" translate="yes" xml:space="preserve">
          <source>For the &amp;lsquo;liblinear&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">Для решателей liblinear, sag и lbfgs установите verbose на любое положительное число для детализации.</target>
        </trans-unit>
        <trans-unit id="e0f6f55d7894824895d15fbf0dd2debb3188c403" translate="yes" xml:space="preserve">
          <source>For the &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; family of algorithms with a non-linear kernel, the latency is tied to the number of support vectors (the fewer the faster). Latency and throughput should (asymptotically) grow linearly with the number of support vectors in a SVC or SVR model. The kernel will also influence the latency as it is used to compute the projection of the input vector once per support vector. In the following graph the &lt;code&gt;nu&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt;&lt;/a&gt; was used to influence the number of support vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a081b6c50a07cf5457333031806f4c48e54ea42e" translate="yes" xml:space="preserve">
          <source>For the &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; family of algorithms with a non-linear kernel, the latency is tied to the number of support vectors (the fewer the faster). Latency and throughput should (asymptotically) grow linearly with the number of support vectors in a SVC or SVR model. The kernel will also influence the latency as it is used to compute the projection of the input vector once per support vector. In the following graph the &lt;code&gt;nu&lt;/code&gt; parameter of &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; was used to influence the number of support vectors.</source>
          <target state="translated">Для семейства алгоритмов &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt; с нелинейным ядром задержка связана с количеством векторов поддержки (чем меньше, тем быстрее). Задержка и пропускная способность должны (асимптотически) расти линейно с увеличением числа поддерживающих векторов в модели SVC или SVR. Ядро также будет влиять на задержку, поскольку оно используется для вычисления проекции входного вектора один раз на вектор поддержки. На следующем графике параметр &lt;code&gt;nu&lt;/code&gt; в &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; использовался для влияния на количество опорных векторов.</target>
        </trans-unit>
        <trans-unit id="49dfac47eea992144c43ccc29f61713fabd0e5ae" translate="yes" xml:space="preserve">
          <source>For the &lt;code&gt;l2&lt;/code&gt; penalty case, the best result comes from the case where &lt;code&gt;C&lt;/code&gt; is not scaled.</source>
          <target state="translated">Для случая штрафа &lt;code&gt;l2&lt;/code&gt; лучший результат получается в случае, когда &lt;code&gt;C&lt;/code&gt; не масштабируется.</target>
        </trans-unit>
        <trans-unit id="b64515e541acdc2619277e9fede8598b267eca89" translate="yes" xml:space="preserve">
          <source>For the coefficient analysis, scaling is not needed this time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="73523e969cb224887344b79725c4bd74783daf1f" translate="yes" xml:space="preserve">
          <source>For the grid of &lt;code&gt;Cs&lt;/code&gt; values and &lt;code&gt;l1_ratios&lt;/code&gt; values, the best hyperparameter is selected by the cross-validator &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt;, but it can be changed using the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; parameter. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers can warm-start the coefficients (see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;Glossary&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9f81a56586341e43516abb99b238b1b5d6587c8" translate="yes" xml:space="preserve">
          <source>For the grid of Cs values (that are set by default to be ten values in a logarithmic scale between 1e-4 and 1e4), the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter. In the case of newton-cg and lbfgs solvers, we warm start along the path i.e guess the initial coefficients of the present fit to be the coefficients got after convergence in the previous fit, so it is supposed to be faster for high-dimensional dense data.</source>
          <target state="translated">Для сетки значений Cs (которые по умолчанию установлены в десять значений в логарифмической шкале между 1e-4 и 1e4)лучший гиперпараметр выбирается кросс-валидатором StratifiedKFold,но его можно изменить с помощью параметра cv.В случае решателей newton-cg и lbfgs разогреваем старт по пути,т.е.угадываем начальные коэффициенты настоящего пригонка как коэффициенты,полученные после сходимости в предыдущем пригонке,поэтому для высокоплотных данных с высокой плотностью он должен быть быстрее.</target>
        </trans-unit>
        <trans-unit id="a2e465567e94e51f5ccdac035f7ba7d95a9eeb84" translate="yes" xml:space="preserve">
          <source>For the lbfgs solver set verbose to any positive number for verbosity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93f0b6841feed67e5fc00af0443562656921cce7" translate="yes" xml:space="preserve">
          <source>For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">Для губчатых и lbfgs solvers установите любое положительное число для глаголов.</target>
        </trans-unit>
        <trans-unit id="181a8f355e9076e45b2bb33dd2324e0459310c3b" translate="yes" xml:space="preserve">
          <source>For the linear case, the algorithm used in &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; by the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; implementation is much more efficient than its &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; counterpart and can scale almost linearly to millions of samples and/or features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c4a7d0fb25ecd0231acfef000eb4ebb4024b077" translate="yes" xml:space="preserve">
          <source>For the most common use cases, you can designate a scorer object with the &lt;code&gt;scoring&lt;/code&gt; parameter; the table below shows all possible values. All scorer objects follow the convention that &lt;strong&gt;higher return values are better than lower return values&lt;/strong&gt;. Thus metrics which measure the distance between the model and the data, like &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;metrics.mean_squared_error&lt;/code&gt;&lt;/a&gt;, are available as neg_mean_squared_error which return the negated value of the metric.</source>
          <target state="translated">Для наиболее распространенных случаев использования вы можете назначить объект &lt;code&gt;scoring&lt;/code&gt; с помощью параметра оценки ; в таблице ниже показаны все возможные значения. Все объекты счетчика следуют соглашению о том, что &lt;strong&gt;более высокие возвращаемые значения лучше, чем более низкие возвращаемые значения&lt;/strong&gt; . Таким образом, метрики, которые измеряют расстояние между моделью и данными, такие как &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;metrics.mean_squared_error&lt;/code&gt; &lt;/a&gt; , доступны как neg_mean_squared_error, которые возвращают отрицательное значение метрики.</target>
        </trans-unit>
        <trans-unit id="d789fec5338f15a1f2a15098b90094ce0875aa16" translate="yes" xml:space="preserve">
          <source>For the naive Bayes, both the validation score and the training score converge to a value that is quite low with increasing size of the training set. Thus, we will probably not benefit much from more training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c5d7d9872e083b1cf44dccc9ef51ebf6d1fc473" translate="yes" xml:space="preserve">
          <source>For the rationale behind the names &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt;, i.e. naive Bayes as a linear classifier, see J. Rennie et al. (2003), Tackling the poor assumptions of naive Bayes text classifiers, ICML.</source>
          <target state="translated">Обоснование названий &lt;code&gt;coef_&lt;/code&gt; и &lt;code&gt;intercept_&lt;/code&gt; , то есть наивного Байеса как линейного классификатора, см. В J. Rennie et al. (2003), Устранение плохих предположений наивных байесовских классификаторов текста, ICML.</target>
        </trans-unit>
        <trans-unit id="1a1a7cda3c63aae62fc5939e46e880b718f959b0" translate="yes" xml:space="preserve">
          <source>For the remainder of this example, we remove the last element in &lt;code&gt;clfs&lt;/code&gt; and &lt;code&gt;ccp_alphas&lt;/code&gt;, because it is the trivial tree with only one node. Here we show that the number of nodes and tree depth decreases as alpha increases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="08233f540a36ed45603c5cb01e2e4f593cd79c27" translate="yes" xml:space="preserve">
          <source>For the simple task of finding the nearest neighbors between two sets of data, the unsupervised algorithms within &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; can be used:</source>
          <target state="translated">Для простой задачи поиска ближайших соседей между двумя наборами данных можно использовать неконтролируемые алгоритмы в &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="a0a1bdaba8df32e218fd25f1e35b96e97a68bb33" translate="yes" xml:space="preserve">
          <source>For this data, we might want to encode the &lt;code&gt;'city'&lt;/code&gt; column as a categorical variable using &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; but apply a &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;'title'&lt;/code&gt; column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say &lt;code&gt;'city_category'&lt;/code&gt; and &lt;code&gt;'title_bow'&lt;/code&gt;. By default, the remaining rating columns are ignored (&lt;code&gt;remainder='drop'&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="daed0c58d42835f25cc91f4ef37c8c2918d442fd" translate="yes" xml:space="preserve">
          <source>For this data, we might want to encode the &lt;code&gt;'city'&lt;/code&gt; column as a categorical variable, but apply a &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;'title'&lt;/code&gt; column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say &lt;code&gt;'city_category'&lt;/code&gt; and &lt;code&gt;'title_bow'&lt;/code&gt;. By default, the remaining rating columns are ignored (&lt;code&gt;remainder='drop'&lt;/code&gt;):</source>
          <target state="translated">Для этих данных мы могли бы захотеть закодировать столбец &lt;code&gt;'city'&lt;/code&gt; как категориальную переменную, но примените &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt; к столбцу &lt;code&gt;'title'&lt;/code&gt; . Поскольку мы можем использовать несколько методов извлечения признаков в одном столбце, мы даем каждому преобразователю уникальное имя, например &lt;code&gt;'city_category'&lt;/code&gt; и &lt;code&gt;'title_bow'&lt;/code&gt; . По умолчанию остальные столбцы рейтинга игнорируются ( &lt;code&gt;remainder='drop'&lt;/code&gt; ):</target>
        </trans-unit>
        <trans-unit id="2e47bbc09921a29cf4a007e2d92242f5a8a9f3d8" translate="yes" xml:space="preserve">
          <source>For this example we will use the &lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;yeast&lt;/a&gt; dataset which contains 2417 datapoints each with 103 features and 14 possible labels. Each data point has at least one label. As a baseline we first train a logistic regression classifier for each of the 14 labels. To evaluate the performance of these classifiers we predict on a held-out test set and calculate the &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;jaccard similarity score&lt;/a&gt;.</source>
          <target state="translated">В этом примере мы будем использовать набор данных &lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;дрожжей,&lt;/a&gt; который содержит 2417 точек данных, каждая из которых содержит 103 функции и 14 возможных меток. Каждая точка данных имеет по крайней мере одну метку. В качестве основы мы сначала обучаем классификатор логистической регрессии для каждой из 14 меток. Чтобы оценить производительность этих классификаторов, мы делаем прогноз на основе проведенного набора тестов и вычисляем &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;показатель сходства&lt;/a&gt; по Жаккару .</target>
        </trans-unit>
        <trans-unit id="ccd3bf49df3c855961b0d8c881b499df98dfa5eb" translate="yes" xml:space="preserve">
          <source>For this example we will use the &lt;a href=&quot;https://www.openml.org/d/40597&quot;&gt;yeast&lt;/a&gt; dataset which contains 2417 datapoints each with 103 features and 14 possible labels. Each data point has at least one label. As a baseline we first train a logistic regression classifier for each of the 14 labels. To evaluate the performance of these classifiers we predict on a held-out test set and calculate the &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;jaccard score&lt;/a&gt; for each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50c8fe3ea12a1b37824eecf96be6564acb86b697" translate="yes" xml:space="preserve">
          <source>For this example, the impurity-based and permutation methods identify the same 2 strongly predictive features but not in the same order. The third most predictive feature, &amp;ldquo;bp&amp;rdquo;, is also the same for the 2 methods. The remaining features are less predictive and the error bars of the permutation plot show that they overlap with 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a29265ef3f92733677c4dbea10c38e7e64e8fed9" translate="yes" xml:space="preserve">
          <source>For this example, we load a blood transfusion service center data set from &lt;code&gt;OpenML &amp;lt;https://www.openml.org/d/1464&amp;gt;&lt;/code&gt;. This is a binary classification problem where the target is whether an individual donated blood. Then the data is split into a train and test dataset and a logistic regression is fitted wtih the train dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ab77ac3ad8536d0d4bc113a409f055607cd6e01" translate="yes" xml:space="preserve">
          <source>For this method, M may be a dense matrix, sparse matrix, or general linear operator. Warning: ARPACK can be unstable for some problems. It is best to try several random seeds in order to check results.</source>
          <target state="translated">Для этого метода M может быть плотной матрицей,разреженной матрицей или общим линейным оператором.Внимание:ARPACK может быть нестабильным для некоторых проблем.Лучше всего попробовать несколько случайных семян,чтобы проверить результаты.</target>
        </trans-unit>
        <trans-unit id="08c8de94919880222510697f43131d88196a6fc1" translate="yes" xml:space="preserve">
          <source>For this particular pattern of missing values we see that &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.bayesianridge#sklearn.linear_model.BayesianRidge&quot;&gt;&lt;code&gt;sklearn.linear_model.BayesianRidge&lt;/code&gt;&lt;/a&gt; give the best results.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="201d282b655d8d026b78eb9f9255553e50678277" translate="yes" xml:space="preserve">
          <source>For this purpose, the estimators use a &amp;lsquo;connectivity&amp;rsquo; matrix, giving which samples are connected.</source>
          <target state="translated">Для этой цели оценщики используют матрицу &amp;laquo;связности&amp;raquo;, указывающую, какие образцы связаны.</target>
        </trans-unit>
        <trans-unit id="764ea2ccb7951b3db73f825ee916559c0e4bce1d" translate="yes" xml:space="preserve">
          <source>For this reason, the functions that load 20 Newsgroups data provide a parameter called &lt;strong&gt;remove&lt;/strong&gt;, telling it what kinds of information to strip out of each file. &lt;strong&gt;remove&lt;/strong&gt; should be a tuple containing any subset of &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt;, telling it to remove headers, signature blocks, and quotation blocks respectively.</source>
          <target state="translated">По этой причине функции, загружающие данные 20 групп новостей, предоставляют параметр с именем &lt;strong&gt;remove&lt;/strong&gt; , сообщающий ему, какие виды информации нужно удалить из каждого файла. &lt;strong&gt;remove&lt;/strong&gt; должен быть кортежем, содержащим любое подмножество &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt; , сообщающее ему удалить заголовки, блоки подписи и блоки цитат соответственно.</target>
        </trans-unit>
        <trans-unit id="60d82b78a5294ae2dc0ada0318b904b11e85c403" translate="yes" xml:space="preserve">
          <source>For two clusters, SpectralClustering solves a convex relaxation of the &lt;a href=&quot;https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;normalised cuts&lt;/a&gt; problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images, where graph vertices are pixels, and weights of the edges of the similarity graph are computed using a function of a gradient of the image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2d2e6058597b408c702846b2d537e901630ce3a" translate="yes" xml:space="preserve">
          <source>For two clusters, it solves a convex relaxation of the &lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;normalised cuts&lt;/a&gt; problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images: graph vertices are pixels, and edges of the similarity graph are a function of the gradient of the image.</source>
          <target state="translated">Для двух кластеров он решает выпуклую релаксацию задачи &lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;нормализованных разрезов&lt;/a&gt; на графе подобия: разрезание графа пополам так, чтобы вес разрезаемых ребер был мал по сравнению с весами рёбер внутри каждого кластера. Этот критерий особенно интересен при работе с изображениями: вершины графа - это пиксели, а края графа подобия - функция градиента изображения.</target>
        </trans-unit>
        <trans-unit id="4092abbbb6ead577ab2b40e6704455f3cb4d3df5" translate="yes" xml:space="preserve">
          <source>For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt; entry on imputation.</source>
          <target state="translated">По разным причинам многие наборы данных реального мира содержат пропущенные значения, часто закодированные как пробелы, NaN или другие заполнители. Однако такие наборы данных несовместимы с оценками scikit-learn, которые предполагают, что все значения в массиве являются числовыми и что все они имеют и имеют значение. Основная стратегия использования неполных наборов данных - отбрасывать целые строки и / или столбцы, содержащие пропущенные значения. Однако это происходит ценой потери данных, которые могут быть ценными (даже если они неполные). Лучшая стратегия - это вменять недостающие значения, т. Е. Вывести их из известной части данных. См. Статью о вменении в &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Глоссарии общих терминов и элементов API&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e2303c3ef75d0f928a4dd5ec4517d95f82d7d02b" translate="yes" xml:space="preserve">
          <source>For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt; entry on imputation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f12e7919ffa1c3009c9eefff46504b7c0642e13" translate="yes" xml:space="preserve">
          <source>For visualization purpose (which is the main use case of t-SNE), using the Barnes-Hut method is strongly recommended. The exact t-SNE method is useful for checking the theoretically properties of the embedding possibly in higher dimensional space but limit to small datasets due to computational constraints.</source>
          <target state="translated">Для визуализации (что является основным случаем использования t-SNE)настоятельно рекомендуется использовать метод Барнс-Хат.Точный метод t-SNE полезен для проверки теоретических свойств встраивания,возможно,в пространстве больших размеров,но ограничивается небольшими наборами данных из-за вычислительных ограничений.</target>
        </trans-unit>
        <trans-unit id="e7a5b4b1244321faa67509dff73df9a23d7da1b3" translate="yes" xml:space="preserve">
          <source>For visualization purposes, given a bicluster, the rows and columns of the data matrix may be rearranged to make the bicluster contiguous.</source>
          <target state="translated">В целях визуализации,при наличии билюстра,строки и столбцы матрицы данных могут быть переставлены таким образом,чтобы сделать билюстер соприкасающимся.</target>
        </trans-unit>
        <trans-unit id="d62d3122e2e4eef979e7c46fd629936aec0233be" translate="yes" xml:space="preserve">
          <source>For visualization purposes, we need to lay out the different symbols on a 2D canvas. For this we use &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;Manifold learning&lt;/a&gt; techniques to retrieve 2D embedding.</source>
          <target state="translated">Для визуализации нам нужно расположить различные символы на 2D-холсте. Для этого мы используем методы &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;обучения Manifold&lt;/a&gt; для извлечения 2D-встраивания.</target>
        </trans-unit>
        <trans-unit id="c502fd7960fae5affa9295a7a329adeddad6ab37" translate="yes" xml:space="preserve">
          <source>Force row-by-row generation by reducing &lt;code&gt;working_memory&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;working_memory&lt;/code&gt; генерацию за счет уменьшения working_memory :</target>
        </trans-unit>
        <trans-unit id="4bb98e5d778957b0dd66fa6aed87be22d170768c" translate="yes" xml:space="preserve">
          <source>Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.</source>
          <target state="translated">Форина,М.и др.,ПАРВУС-Расширяемый пакет для разведки,классификации и корреляции данных.Институт анализа и технологий фармацевтики и пищевых продуктов,Виа Бригата Салерно,16147 Генуя,Италия.</target>
        </trans-unit>
        <trans-unit id="35705e005c1f18ed14dab92df9e1435742858283" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the average precision is defined as</source>
          <target state="translated">Формально,с учетом двоичной матрицы индикаторов основной истины меток \(y \in \left\{0,1\right\}^{n_\text{samples}\times n_\text{labels}}\)и оценки,связанной с каждой меткой \(\hat{f}\in \mathbb{R}^{n_\text{samples}\times n_\text{labels}}\),средняя оценка точности определяется как</target>
        </trans-unit>
        <trans-unit id="4f395914b8fb9e643646835cc07cbc38c9742edc" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the coverage is defined as</source>
          <target state="translated">Формально,с учетом двоичной матрицы индикаторов основной истины метки \(y \in \left\{0,1\right\}^{n_\text{samples}\times n_\text{labels}}\)и оценки,связанной с каждой меткой \(\hat{f}\in \mathbb{R}^{n_\text{samples}\times n_\text{labels}}\),покрытие определено как</target>
        </trans-unit>
        <trans-unit id="c175d46f254d733413b5b0ee831c9d600136a7b6" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the ranking loss is defined as</source>
          <target state="translated">Формально,учитывая двоичную матрицу индикаторов основных истины меток \(y \in \left\{0,1\right\}^{n_\text{samples}\times n_\text{labels}}\)и оценку,связанную с каждой меткой \(\hat{f}\in \mathbb{R}^{n_\text{samples}\times n_\text{labels}}\),потеря рейтинга определяется как</target>
        </trans-unit>
        <trans-unit id="c45b835372dc3641934de6a0e36f8d5df72bc091" translate="yes" xml:space="preserve">
          <source>Format specification for values in confusion matrix. If &lt;code&gt;None&lt;/code&gt;, the format specification is &amp;lsquo;d&amp;rsquo; or &amp;lsquo;.2g&amp;rsquo; whichever is shorter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47fb5045fef615598469a37da8a59110352753ff" translate="yes" xml:space="preserve">
          <source>Forms an affinity matrix given by the specified function and applies spectral decomposition to the corresponding graph laplacian. The resulting transformation is given by the value of the eigenvectors for each data point.</source>
          <target state="translated">Формирует матрицу сродства,заданную заданной функцией,и применяет спектральное разложение к соответствующему лаплацкому графу.Полученное преобразование задается значением собственных векторов для каждой точки данных.</target>
        </trans-unit>
        <trans-unit id="638babaaa209a18fe959f40f19725a01af068351" translate="yes" xml:space="preserve">
          <source>Fortunately, &lt;strong&gt;most values in X will be zeros&lt;/strong&gt; since for a given document less than a few thousand distinct words will be used. For this reason we say that bags of words are typically &lt;strong&gt;high-dimensional sparse datasets&lt;/strong&gt;. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory.</source>
          <target state="translated">К счастью, &lt;strong&gt;большинство значений в X будут нулями,&lt;/strong&gt; поскольку для данного документа будет использовано менее нескольких тысяч различных слов. По этой причине мы говорим, что пакеты слов обычно представляют собой &lt;strong&gt;разреженные наборы данных большой размерности&lt;/strong&gt; . Мы можем сэкономить много памяти, сохраняя в памяти только ненулевые части векторов признаков.</target>
        </trans-unit>
        <trans-unit id="e399cc71dd11205217c77d4c7f1a914e719b462c" translate="yes" xml:space="preserve">
          <source>Frequency model &amp;ndash; Poisson distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="659b18cdaec75234c8e955e09af5dc004ab6498a" translate="yes" xml:space="preserve">
          <source>Frequently asked questions about the project and contributing.</source>
          <target state="translated">Часто задаваемые вопросы о проекте и участии в нем.</target>
        </trans-unit>
        <trans-unit id="c378e5372fbcc6968de3f23916b1cc385b9617be" translate="yes" xml:space="preserve">
          <source>Friedman et al, &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Sparse inverse covariance estimation with the graphical lasso&amp;rdquo;&lt;/a&gt;, Biostatistics 9, pp 432, 2008</source>
          <target state="translated">Фридман и др., &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;laquo;Оценка разреженной обратной ковариации с помощью графического лассо&amp;raquo;&lt;/a&gt; , Biostatistics 9, стр. 432, 2008 г.</target>
        </trans-unit>
        <trans-unit id="563c92aa7d72e63e351914d407eb4e8a1bed4188" translate="yes" xml:space="preserve">
          <source>Friedman et al, &lt;a href=&quot;https://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Sparse inverse covariance estimation with the graphical lasso&amp;rdquo;&lt;/a&gt;, Biostatistics 9, pp 432, 2008</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8438e27109208985a133518d65493568dedc6924" translate="yes" xml:space="preserve">
          <source>Friedman, &amp;ldquo;Stochastic Gradient Boosting&amp;rdquo;, 1999</source>
          <target state="translated">Фридман, &amp;laquo;Стохастическое повышение градиента&amp;raquo;, 1999 г.</target>
        </trans-unit>
        <trans-unit id="9fcad16d5a3614a8ac9a3dd3615a46004936d92d" translate="yes" xml:space="preserve">
          <source>Friedman, Stochastic Gradient Boosting, 1999</source>
          <target state="translated">Фридман,Стохастический градиентный подъем,1999 г.</target>
        </trans-unit>
        <trans-unit id="910211d4464f03643fe19d7b724011f366eafec5" translate="yes" xml:space="preserve">
          <source>Friedmann, Jerome H., 2007, &lt;a href=&quot;https://statweb.stanford.edu/~jhf/ftp/stobst.pdf&quot;&gt;&amp;ldquo;Stochastic Gradient Boosting&amp;rdquo;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d93c5ad51427861e9927c0f93ba75f21fa7b3769" translate="yes" xml:space="preserve">
          <source>Frobenius norm of the matrix difference, or beta-divergence, between the training data &lt;code&gt;X&lt;/code&gt; and the reconstructed data &lt;code&gt;WH&lt;/code&gt; from the fitted model.</source>
          <target state="translated">Норма Фробениуса разности матриц или бета-дивергенции между обучающими данными &lt;code&gt;X&lt;/code&gt; и восстановленными данными &lt;code&gt;WH&lt;/code&gt; из подобранной модели.</target>
        </trans-unit>
        <trans-unit id="c51f06e97e3098b2be5170a19f440afe2d031cf5" translate="yes" xml:space="preserve">
          <source>From features with fewest missing values to most.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42591b8a9cd574128a8414edcfb65dcf2e26248d" translate="yes" xml:space="preserve">
          <source>From features with most missing values to fewest.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a2bd03e6f160e636919837a5a755bde731a1eeb" translate="yes" xml:space="preserve">
          <source>From images</source>
          <target state="translated">Изображения</target>
        </trans-unit>
        <trans-unit id="5ff0ffd1e24dbd90ba4e307313dc3fed8b0cd6c4" translate="yes" xml:space="preserve">
          <source>From occurrences to frequencies</source>
          <target state="translated">От происшествий к частотам</target>
        </trans-unit>
        <trans-unit id="4a6ea847ae49dd26abc66504268644d690f3206b" translate="yes" xml:space="preserve">
          <source>From scikit-learn: [&amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;, &amp;lsquo;euclidean&amp;rsquo;, &amp;lsquo;l1&amp;rsquo;, &amp;lsquo;l2&amp;rsquo;, &amp;lsquo;manhattan&amp;rsquo;]. These metrics support sparse matrix inputs.</source>
          <target state="translated">Из scikit-learn: ['cityblock', 'косинус', 'евклидова', 'l1', 'l2', 'манхэттен']. Эти метрики поддерживают разреженные входные данные матрицы.</target>
        </trans-unit>
        <trans-unit id="e036581a0079e3a00bbe6bddf83817f4c4f30e31" translate="yes" xml:space="preserve">
          <source>From scikit-learn: [&amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;, &amp;lsquo;euclidean&amp;rsquo;, &amp;lsquo;l1&amp;rsquo;, &amp;lsquo;l2&amp;rsquo;, &amp;lsquo;manhattan&amp;rsquo;]. These metrics support sparse matrix inputs. [&amp;lsquo;nan_euclidean&amp;rsquo;] but it does not yet support sparse matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6d8d962b98fbbe50de709ee2f1e71db53d579c2e" translate="yes" xml:space="preserve">
          <source>From scipy.spatial.distance: [&amp;lsquo;braycurtis&amp;rsquo;, &amp;lsquo;canberra&amp;rsquo;, &amp;lsquo;chebyshev&amp;rsquo;, &amp;lsquo;correlation&amp;rsquo;, &amp;lsquo;dice&amp;rsquo;, &amp;lsquo;hamming&amp;rsquo;, &amp;lsquo;jaccard&amp;rsquo;, &amp;lsquo;kulsinski&amp;rsquo;, &amp;lsquo;mahalanobis&amp;rsquo;, &amp;lsquo;minkowski&amp;rsquo;, &amp;lsquo;rogerstanimoto&amp;rsquo;, &amp;lsquo;russellrao&amp;rsquo;, &amp;lsquo;seuclidean&amp;rsquo;, &amp;lsquo;sokalmichener&amp;rsquo;, &amp;lsquo;sokalsneath&amp;rsquo;, &amp;lsquo;sqeuclidean&amp;rsquo;, &amp;lsquo;yule&amp;rsquo;] See the documentation for scipy.spatial.distance for details on these metrics. These metrics do not support sparse matrix inputs.</source>
          <target state="translated">Из scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev', 'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'minkowski', 'rogerstanimoto ',' russellrao ',' seuclidean ',' sokalmichener ',' sokalsneath ',' sqeuclidean ',' yule '] Подробную информацию об этих показателях см. в документации для scipy.spatial.distance. Эти показатели не поддерживают входные данные с разреженной матрицей.</target>
        </trans-unit>
        <trans-unit id="d3990f36d057d6745fedc272447b2563e02193f7" translate="yes" xml:space="preserve">
          <source>From text</source>
          <target state="translated">Из текста</target>
        </trans-unit>
        <trans-unit id="b8b69c633940e44df1e4f7cf5b91c3ed0ce89b65" translate="yes" xml:space="preserve">
          <source>From the Wikipedia page for Discounted Cumulative Gain:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eea6e746f349894e725f780b7f19777ab0b59905" translate="yes" xml:space="preserve">
          <source>From the above formula, it is clear that LDA has a linear decision surface. In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id5&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13bce2493b501286a428cebcb4e0bc57e6083c63" translate="yes" xml:space="preserve">
          <source>From the implementation point of view, this is just plain Ordinary Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.</source>
          <target state="translated">С точки зрения реализации,это обычные обычные наименьшие квадраты (scipy.linalg.lstsq),обернутые как объект-предсказатель.</target>
        </trans-unit>
        <trans-unit id="704f1c6d00ec317ee90c0b6672883e3dd205ae68" translate="yes" xml:space="preserve">
          <source>From the programming standpoint, it is interesting because it shows how to use the online API of the scikit-learn to process a very large dataset by chunks. The way we proceed is that we load an image at a time and extract randomly 50 patches from this image. Once we have accumulated 500 of these patches (using 10 images), we run the &lt;a href=&quot;../../modules/generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method of the online KMeans object, MiniBatchKMeans.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae8e3bdf9c1967ed71af43f356a6c2d5d1712708" translate="yes" xml:space="preserve">
          <source>From the programming standpoint, it is interesting because it shows how to use the online API of the scikit-learn to process a very large dataset by chunks. The way we proceed is that we load an image at a time and extract randomly 50 patches from this image. Once we have accumulated 500 of these patches (using 10 images), we run the &lt;code&gt;partial_fit&lt;/code&gt; method of the online KMeans object, MiniBatchKMeans.</source>
          <target state="translated">С точки зрения программирования это интересно, поскольку показывает, как использовать онлайн-API scikit-learn для обработки очень большого набора данных по частям. Мы действуем следующим образом: мы загружаем изображение за раз и извлекаем из него случайным образом 50 патчей. После того, как мы накопили 500 таких патчей (используя 10 изображений), мы запускаем метод &lt;code&gt;partial_fit&lt;/code&gt; онлайн-объекта KMeans, MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="f1e410ad1472b42cb42cc98962428637290b6706" translate="yes" xml:space="preserve">
          <source>Function</source>
          <target state="translated">Function</target>
        </trans-unit>
        <trans-unit id="9f410a9e5384dfe1720c4cd228fe7bb63965656b" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">Функция принимает два массива X и y и возвращает пару массивов (оценки, pvalues) или один массив с оценками. По умолчанию - f_classif (см. Ниже &amp;laquo;См. Также&amp;raquo;). Функция по умолчанию работает только с задачами классификации.</target>
        </trans-unit>
        <trans-unit id="a8696032e0adf35ffec7c9da28cd036adeb91c99" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">Функция, которая принимает два массива X и y и возвращает пару массивов (scores, pvalues). По умолчанию - f_classif (см. Ниже &amp;laquo;См. Также&amp;raquo;). Функция по умолчанию работает только с задачами классификации.</target>
        </trans-unit>
        <trans-unit id="acf1f055cd0885a9fc7d245efda7d1c727fca691" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). For modes &amp;lsquo;percentile&amp;rsquo; or &amp;lsquo;kbest&amp;rsquo; it can return a single array scores.</source>
          <target state="translated">Функция, которая принимает два массива X и y и возвращает пару массивов (scores, pvalues). Для режимов &amp;laquo;процентиль&amp;raquo; или &amp;laquo;кбест&amp;raquo; он может возвращать единый массив оценок.</target>
        </trans-unit>
        <trans-unit id="0c64f21c81859fb42c302c0d2cd301e40332c2c7" translate="yes" xml:space="preserve">
          <source>Function to apply to &lt;code&gt;y&lt;/code&gt; before passing to &lt;code&gt;fit&lt;/code&gt;. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt;. The function needs to return a 2-dimensional array. If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the function used will be the identity function.</source>
          <target state="translated">Функция, применяемая к &lt;code&gt;y&lt;/code&gt; перед передачей в &lt;code&gt;fit&lt;/code&gt; . Не может быть установлен одновременно с &lt;code&gt;transformer&lt;/code&gt; . Функция должна возвращать двумерный массив. Если &lt;code&gt;func&lt;/code&gt; равно &lt;code&gt;None&lt;/code&gt; , используемая функция будет функцией идентификации.</target>
        </trans-unit>
        <trans-unit id="f712e33ad68950dd5132b77ad3129994bf2cbbce" translate="yes" xml:space="preserve">
          <source>Function to apply to the prediction of the regressor. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt; as well. The function needs to return a 2-dimensional array. The inverse function is used to return predictions to the same space of the original training labels.</source>
          <target state="translated">Функция, применяемая к предсказанию регрессора. Также не может быть установлен одновременно с &lt;code&gt;transformer&lt;/code&gt; . Функция должна возвращать двумерный массив. Обратная функция используется для возврата прогнозов в то же пространство исходных обучающих меток.</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="c216053588b385d3de175b467017426b8b421912" translate="yes" xml:space="preserve">
          <source>Further discussion on the importance of centering and scaling data is available on this FAQ: &lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;Should I normalize/standardize/rescale the data?&lt;/a&gt;</source>
          <target state="translated">Дальнейшее обсуждение важности центрирования и масштабирования данных доступно в этом FAQ: &lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;Следует ли мне нормализовать / стандартизировать / масштабировать данные?&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="606b0f774f1d5e4151969dbb768df62ebca8a20e" translate="yes" xml:space="preserve">
          <source>Further removes the linear correlation across features with &amp;lsquo;whiten=True&amp;rsquo;.</source>
          <target state="translated">Далее удаляет линейную корреляцию между функциями с 'whiten = True'.</target>
        </trans-unit>
        <trans-unit id="ec9ba56eabfa3f70786eb84612f0623df80dfc4d" translate="yes" xml:space="preserve">
          <source>Further, the model supports &lt;a href=&quot;multiclass#multiclass&quot;&gt;multi-label classification&lt;/a&gt; in which a sample can belong to more than one class. For each class, the raw output passes through the logistic function. Values larger or equal to &lt;code&gt;0.5&lt;/code&gt; are rounded to &lt;code&gt;1&lt;/code&gt;, otherwise to &lt;code&gt;0&lt;/code&gt;. For a predicted output of a sample, the indices where the value is &lt;code&gt;1&lt;/code&gt; represents the assigned classes of that sample:</source>
          <target state="translated">Кроме того, модель поддерживает &lt;a href=&quot;multiclass#multiclass&quot;&gt;классификацию с несколькими метками,&lt;/a&gt; в которой образец может принадлежать более чем одному классу. Для каждого класса необработанные выходные данные проходят через логистическую функцию. Значения больше или равные &lt;code&gt;0.5&lt;/code&gt; округляются до &lt;code&gt;1&lt;/code&gt; , в противном случае - до &lt;code&gt;0&lt;/code&gt; . Для прогнозируемых выходных данных выборки индексы со значением &lt;code&gt;1&lt;/code&gt; представляют присвоенные классы этой выборки:</target>
        </trans-unit>
        <trans-unit id="cc118108875cca01a2724ce6e20debf4e124a846" translate="yes" xml:space="preserve">
          <source>Furthermore, &lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt;&lt;code&gt;adjusted_rand_score&lt;/code&gt;&lt;/a&gt; is &lt;strong&gt;symmetric&lt;/strong&gt;: swapping the argument does not change the score. It can thus be used as a &lt;strong&gt;consensus measure&lt;/strong&gt;:</source>
          <target state="translated">Кроме того, значение &lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt; &lt;code&gt;adjusted_rand_score&lt;/code&gt; &lt;/a&gt; является &lt;strong&gt;симметричным&lt;/strong&gt; : замена аргумента не меняет счет. Таким образом, его можно использовать в качестве &lt;strong&gt;меры консенсуса&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="f148ccef557451e9c13ec83bfface59d01588547" translate="yes" xml:space="preserve">
          <source>Furthermore, impurity-based feature importance for trees are &lt;strong&gt;strongly biased&lt;/strong&gt; and &lt;strong&gt;favor high cardinality features&lt;/strong&gt; (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7218de362b7befd5a71b1a5a01365e3552aa1087" translate="yes" xml:space="preserve">
          <source>Furthermore, it also shows the evolution of the performance of different algorithms with the number of processed examples.</source>
          <target state="translated">Кроме того,он также показывает эволюцию производительности различных алгоритмов с количеством обработанных примеров.</target>
        </trans-unit>
        <trans-unit id="17753e7322d4f150d032ddf1f2dbdf4fe6d38592" translate="yes" xml:space="preserve">
          <source>Furthermore, the default parameter &lt;code&gt;smooth_idf=True&lt;/code&gt; adds &amp;ldquo;1&amp;rdquo; to the numerator and denominator as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions:</source>
          <target state="translated">Кроме того, параметр по умолчанию &lt;code&gt;smooth_idf=True&lt;/code&gt; добавляет &amp;laquo;1&amp;raquo; к числителю и знаменателю, как если бы был замечен дополнительный документ, содержащий каждый термин в коллекции ровно один раз, что предотвращает нулевое деление:</target>
        </trans-unit>
        <trans-unit id="2e93583dd7fd8dcf1f0371a9818f0db1fd3c80a7" translate="yes" xml:space="preserve">
          <source>Furthermore, the formulas used to compute tf and idf depend on parameter settings that correspond to the SMART notation used in IR as follows:</source>
          <target state="translated">Кроме того,формулы,используемые для вычисления tf и idf,зависят от настроек параметров,которые соответствуют SMART-нотации,используемой в IR следующим образом:</target>
        </trans-unit>
        <trans-unit id="f576c03970023ff0ede275b819158dc78e4bd414" translate="yes" xml:space="preserve">
          <source>Furthermore, the impurity-based feature importance of random forests suffers from being computed on statistics derived from the training dataset: the importances can be high even for features that are not predictive of the target variable, as long as the model has the capacity to use them to overfit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a28e3ed3e4426c3b74ba7f5c5c797d3018edc64c" translate="yes" xml:space="preserve">
          <source>Furthermore, when splitting each node during the construction of a tree, the best split is found either from all input features or a random subset of size &lt;code&gt;max_features&lt;/code&gt;. (See the &lt;a href=&quot;#random-forest-parameters&quot;&gt;parameter tuning guidelines&lt;/a&gt; for more details).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b6ca190d547b1e777d8fa3e93274ce6ad7c42b4" translate="yes" xml:space="preserve">
          <source>G. Brier, &lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;Verification of forecasts expressed in terms of probability&lt;/a&gt;, Monthly weather review 78.1 (1950)</source>
          <target state="translated">Дж. Брайер, &lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;Проверка прогнозов, выраженных в терминах вероятности&lt;/a&gt; , Ежемесячный обзор погоды 78.1 (1950)</target>
        </trans-unit>
        <trans-unit id="8ccf25498da17f5ff69133909511a6d98d2976f3" translate="yes" xml:space="preserve">
          <source>G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert, &amp;ldquo;Regularization in regression: comparing Bayesian and frequentist methods in a poorly informative situation&amp;rdquo;, 2009.</source>
          <target state="translated">Дж. Селё, М. Эль-Анбари, Ж.-М. Марин, С. П. Роберт, &amp;laquo;Регуляризация в регрессии: сравнение байесовских и частотных методов в малоинформативной ситуации&amp;raquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="623c67fa2cbbcf37d713401c722eceec0b680645" translate="yes" xml:space="preserve">
          <source>G. Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5, Section 5.4.4, pp. 252-253.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="755f0c9208b383f3b380dd0d2b1a156d6d5865c4" translate="yes" xml:space="preserve">
          <source>G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer 2013.</source>
          <target state="translated">Дж. Джеймс, Д. Виттен, Т. Хасти, Р. Тибширани, &lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;Введение в статистическое обучение&lt;/a&gt; , Springer 2013.</target>
        </trans-unit>
        <trans-unit id="3cb2eea23f004b3e761d528ddc6b2e3e79458d85" translate="yes" xml:space="preserve">
          <source>G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;https://www-bcf.usc.edu/~gareth/ISL/&quot;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer 2013.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28ef1689ee2219c624cfde5d7c88afdcae0138ec" translate="yes" xml:space="preserve">
          <source>G. Louppe and P. Geurts, &amp;ldquo;Ensembles on Random Patches&amp;rdquo;, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</source>
          <target state="translated">Г. Луппе и П. Геуртс, &amp;laquo;Ансамбли на случайных участках&amp;raquo;, Машинное обучение и обнаружение знаний в базах данных, 346-361, 2012.</target>
        </trans-unit>
        <trans-unit id="c722e87d5d9d7dbc54dd2b811a759cc621efb047" translate="yes" xml:space="preserve">
          <source>G. Louppe, &amp;ldquo;Understanding Random Forests: From Theory to Practice&amp;rdquo;, PhD Thesis, U. of Liege, 2014.</source>
          <target state="translated">Г. Луппе, &amp;laquo;Понимание случайных лесов: от теории к практике&amp;raquo;, докторская диссертация, Льежский университет, 2014 г.</target>
        </trans-unit>
        <trans-unit id="80030b72580197a6197c00418acf9f08511c2c49" translate="yes" xml:space="preserve">
          <source>G. Ridgeway, &amp;ldquo;Generalized Boosted Models: A guide to the gbm package&amp;rdquo;, 2007</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8ed6bad205ec1f52f0b48e7f8377435663ec074" translate="yes" xml:space="preserve">
          <source>G.E.P. Box and D.R. Cox, &amp;ldquo;An Analysis of Transformations&amp;rdquo;, Journal of the Royal Statistical Society B, 26, 211-252 (1964).</source>
          <target state="translated">GEP Box и Д. Р. Кокс, &amp;laquo;Анализ преобразований&amp;raquo;, журнал Королевского статистического общества B, 26, 211&amp;ndash;252 (1964).</target>
        </trans-unit>
        <trans-unit id="83c6052410f7be2971558c8f2b162b661b4a734b" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion. Regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8cb867b444fe174ab482df0a111ed147a9ceddf" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage &lt;code&gt;n_classes_&lt;/code&gt; regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.</source>
          <target state="translated">GB строит аддитивную модель поэтапно; он позволяет оптимизировать произвольные дифференцируемые функции потерь. На каждом этапе &lt;code&gt;n_classes_&lt;/code&gt; деревьев регрессии соответствуют отрицательному градиенту биномиальной или полиномиальной функции потерь отклонения. Бинарная классификация - это особый случай, когда индуцируется только одно дерево регрессии.</target>
        </trans-unit>
        <trans-unit id="80f39c4fc4a6461ea00d5d7be636d9c6f77055de" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.</source>
          <target state="translated">GB строит аддитивную модель по принципу &quot;вперед&quot;,что позволяет оптимизировать функции произвольных дифференцируемых потерь.На каждом этапе дерево регрессии помещается на отрицательный градиент заданной функции потерь.</target>
        </trans-unit>
        <trans-unit id="2c1af0078ebec6d87c6fe14b52a6ca7ecb93e0e6" translate="yes" xml:space="preserve">
          <source>GBRT considers additive models of the following form:</source>
          <target state="translated">GBRT рассматривает модели добавок следующей формы:</target>
        </trans-unit>
        <trans-unit id="af90cc1188550654bd22990a09c9155ebaa04680" translate="yes" xml:space="preserve">
          <source>GBRT regressors are additive models whose prediction \(y_i\) for a given input \(x_i\) is of the following form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="348ddf733ebe39c89fe60cc4aea0def489f0df0c" translate="yes" xml:space="preserve">
          <source>GMM covariances</source>
          <target state="translated">коварианцы ГММ</target>
        </trans-unit>
        <trans-unit id="89a541e422be32f4e38c95b70a35778f6b3b29a5" translate="yes" xml:space="preserve">
          <source>G[i,j] gives the shortest distance from point i to point j along the graph.</source>
          <target state="translated">G[i,j]дает кратчайшее расстояние от точки i до точки j вдоль графика.</target>
        </trans-unit>
        <trans-unit id="dc7da4ca9757d9015c0ba1d2228560006792966e" translate="yes" xml:space="preserve">
          <source>Gallery generated by Sphinx-Gallery</source>
          <target state="translated">Галерея,созданная галереей Сфинкса</target>
        </trans-unit>
        <trans-unit id="cba508b12182b68f501d6af46c4f03f8fc5d2473" translate="yes" xml:space="preserve">
          <source>Gamma</source>
          <target state="translated">Gamma</target>
        </trans-unit>
        <trans-unit id="927ef8e7f274c04e9c8836a36352812cc37bb26c" translate="yes" xml:space="preserve">
          <source>Gamma deviance is equivalent to the Tweedie deviance with the power parameter &lt;code&gt;power=2&lt;/code&gt;. It is invariant to scaling of the target variable, and measures relative errors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24f0f86d8b8da4a3eb66c5315b49fb7db14a0fa6" translate="yes" xml:space="preserve">
          <source>Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.</source>
          <target state="translated">Гамма-параметр для RBF,лаплацового,полиномиального,экспоненциального chi2 и сигмовидного ядер.Интерпретация значения по умолчанию оставлена на усмотрение ядра;см.документацию по sklearn.metrics.pairwise.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="8abb933fe9bd6d8a92eb104bdc2fd613c351d44f" translate="yes" xml:space="preserve">
          <source>Gamma parameter in rbf, poly and sigmoid kernels. Ignored by other kernels. 0.1 by default.</source>
          <target state="translated">Гамма-параметр в rbf,поли-и сигмоидных ядрах.Игнорируется другими ядрами.0.1 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="86050f4573c138fca290821e4b579d6d320e40d1" translate="yes" xml:space="preserve">
          <source>Gates, G.W. (1972) &amp;ldquo;The Reduced Nearest Neighbor Rule&amp;rdquo;. IEEE Transactions on Information Theory, May 1972, 431-433.</source>
          <target state="translated">Гейтс, GW (1972) &amp;laquo;Правило редуцированного ближайшего соседа&amp;raquo;. IEEE Transactions по теории информации, май 1972 г., стр. 431-433.</target>
        </trans-unit>
        <trans-unit id="46a57bcdd34ea523f3417e94b431a41097b638e9" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Ellipsoids</source>
          <target state="translated">Гауссова модель смеси Эллипсоиды</target>
        </trans-unit>
        <trans-unit id="2f22bd1dad8340bd3d8973db40a56083b791482c" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Selection</source>
          <target state="translated">Выбор гауссовской модели смеси</target>
        </trans-unit>
        <trans-unit id="7ada59d703243073c5122ce20c200108df4cf582" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Sine Curve</source>
          <target state="translated">Гауссова модель смеси Синусоидальная кривая</target>
        </trans-unit>
        <trans-unit id="b8fb995e81cb89650fea0baec9d6ae8f98a9538f" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Models</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="662a25df4ddd527b4e6e6b4415fd19857fcb55fc" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture.</source>
          <target state="translated">Гауссова смесь.</target>
        </trans-unit>
        <trans-unit id="52d32c3ce740bd6bf6fa9b8c9a00c471e2b8ab61" translate="yes" xml:space="preserve">
          <source>Gaussian Naive Bayes (GaussianNB)</source>
          <target state="translated">Гауссовские наивные бухты (ГауссенНБ)</target>
        </trans-unit>
        <trans-unit id="d854cefb413c2902ad18940be1c741ae3117e7e6" translate="yes" xml:space="preserve">
          <source>Gaussian Process for Machine Learning</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e71cc209c706f89187660af28df9dbd656b7dfb" translate="yes" xml:space="preserve">
          <source>Gaussian Processes regression: basic introductory example</source>
          <target state="translated">Регрессия гауссовых процессов:основной вводный пример</target>
        </trans-unit>
        <trans-unit id="7c9060d2e2a8ab44211d4b8690374c1230f1b7f2" translate="yes" xml:space="preserve">
          <source>Gaussian kernel (&lt;code&gt;kernel = 'gaussian'&lt;/code&gt;)</source>
          <target state="translated">Гауссово ядро ​​( &lt;code&gt;kernel = 'gaussian'&lt;/code&gt; гауссово ' )</target>
        </trans-unit>
        <trans-unit id="16bd9bbb5a5342036acd14278f2e03ad41c57f6a" translate="yes" xml:space="preserve">
          <source>Gaussian mixture model fit with a variational inference.</source>
          <target state="translated">Гауссовская модель смеси подходит с вариационным выводом.</target>
        </trans-unit>
        <trans-unit id="c4278ff51902cddfc2c28028add69085822b616d" translate="yes" xml:space="preserve">
          <source>Gaussian mixture models, useful for clustering, are described in &lt;a href=&quot;mixture#mixture&quot;&gt;another chapter of the documentation&lt;/a&gt; dedicated to mixture models. KMeans can be seen as a special case of Gaussian mixture model with equal covariance per component.</source>
          <target state="translated">Модели гауссовой смеси, полезные для кластеризации, описаны в &lt;a href=&quot;mixture#mixture&quot;&gt;другой главе документации,&lt;/a&gt; посвященной моделям смеси. KMeans можно рассматривать как частный случай модели гауссовой смеси с равной ковариацией для каждого компонента.</target>
        </trans-unit>
        <trans-unit id="52102b8851b98924c7d8b1f347902fc1a6a2f6c4" translate="yes" xml:space="preserve">
          <source>Gaussian mixtures</source>
          <target state="translated">гауссовские смеси</target>
        </trans-unit>
        <trans-unit id="fb2ed046d4b5b73ab490df316744dbd7803b27c6" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) based on Laplace approximation.</source>
          <target state="translated">Гауссовская классификация процессов (GPC),основанная на аппроксимации Лапласа.</target>
        </trans-unit>
        <trans-unit id="6022eb0f0e245ca9c1dcd7d4b4311ff01e4db354" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) on iris dataset</source>
          <target state="translated">Гауссовская классификация процессов (GPC)на наборе данных радужной оболочки глаза</target>
        </trans-unit>
        <trans-unit id="21a63bbdb2d774ad21ffa6c87b635dc00ddbdcbd" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) on Mauna Loa CO2 data.</source>
          <target state="translated">Гауссовская регрессия процесса (GPR)по данным о CO2 Мауна Лоа.</target>
        </trans-unit>
        <trans-unit id="0c7b8e025d47923893c509b893c584646dec60f9" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) with noise-level estimation</source>
          <target state="translated">Гауссовская регрессия процесса (GPR)с оценкой уровня шума</target>
        </trans-unit>
        <trans-unit id="e020234a1ce464bccd79fd7ca6cd9571320c3263" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR).</source>
          <target state="translated">Гауссовская регрессия процессов (GPR).</target>
        </trans-unit>
        <trans-unit id="81d5ab12411c6f249a3ae9ff3884b17e3d00399b" translate="yes" xml:space="preserve">
          <source>Gaussian processes on discrete data structures</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eef2758f8f04922436ba69e73f365c3b677d080" translate="yes" xml:space="preserve">
          <source>GaussianNaiveBayes tends to push probabilities to 0 or 1 (note the counts in the histograms). This is mainly because it makes the assumption that features are conditionally independent given the class, which is not the case in this dataset which contains 2 redundant features.</source>
          <target state="translated">GaussianNaiveBayes имеет тенденцию подталкивать вероятности к 0 или 1 (обратите внимание на подсчеты в гистограммах).Это в основном связано с тем,что в данном наборе данных,содержащем 2 избыточных признака,предполагается,что признаки являются условно-независимыми для данного класса,чего нет в данном наборе данных.</target>
        </trans-unit>
        <trans-unit id="9ee50bfb8852bcfbfa07c7c7a246c842043563a2" translate="yes" xml:space="preserve">
          <source>General KDD structure :</source>
          <target state="translated">Общая структура KDD :</target>
        </trans-unit>
        <trans-unit id="082e84b7a80940ab38b8fafffced3896fbf61a5f" translate="yes" xml:space="preserve">
          <source>General examples about classification algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="340183f53d5a585fe2f90b1573169f80622dc9bd" translate="yes" xml:space="preserve">
          <source>General-purpose, even cluster size, flat geometry, not too many clusters</source>
          <target state="translated">Общего назначения,даже размер кластера,плоская геометрия,не слишком много кластеров</target>
        </trans-unit>
        <trans-unit id="5a99200d3c187d0fcefb7b4df6803366dc2748df" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Gamma distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ed4c66ad535ba7380d74741129413d4f8c145bc" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Poisson distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d682c681b1fa1783371317722a00ec63b80aa77c" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Tweedie distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b17d9222a12b9513aac695dd37d7bdc64c218d77" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcbd479b250088e4214e337494acb2a2758516bc" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models (GLM) extend linear models in two ways &lt;a href=&quot;#id33&quot; id=&quot;id31&quot;&gt;10&lt;/a&gt;. First, the predicted values \(\hat{y}\) are linked to a linear combination of the input variables \(X\) via an inverse link function \(h\) as</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="050c76b497e038e0c5a06ed24dce47a6958dfb02" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models, and Poisson loss for gradient boosting</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="194ee7e5ec30d094070f5f72a72c8597376dc276" translate="yes" xml:space="preserve">
          <source>Generalized linear models (GLM) for regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a807e718c7c2444084ecd599b5293f02618f18b0" translate="yes" xml:space="preserve">
          <source>Generally speaking, when model complexity increases, predictive power and latency are supposed to increase. Increasing predictive power is usually interesting, but for many applications we would better not increase prediction latency too much. We will now review this idea for different families of supervised models.</source>
          <target state="translated">Вообще говоря,когда сложность модели возрастает,прогнозирующая мощность и латентность должны увеличиваться.Увеличение прогностической мощности обычно интересно,но для многих приложений лучше не увеличивать латентность прогнозирования слишком сильно.Сейчас мы рассмотрим эту идею для различных семейств контролируемых моделей.</target>
        </trans-unit>
        <trans-unit id="af9887d0c879889fc0d4b97d28831fef1da0e335" translate="yes" xml:space="preserve">
          <source>Generate a distance matrix chunk by chunk with optional reduction</source>
          <target state="translated">Сгенерировать матрицу расстояний по кусочкам с опциональным сокращением</target>
        </trans-unit>
        <trans-unit id="06c2a79c89c40ddc99e314455bfeabb348baaefc" translate="yes" xml:space="preserve">
          <source>Generate a mostly low rank matrix with bell-shaped singular values</source>
          <target state="translated">Сгенерировать матрицу преимущественно низкого ранга с колоколообразными сингулярными значениями.</target>
        </trans-unit>
        <trans-unit id="c1825817fcf44112a4d64fe6f2acf131fceae396" translate="yes" xml:space="preserve">
          <source>Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].</source>
          <target state="translated">Сгенерировать новую матрицу признаков,состоящую из всех полиномиальных комбинаций признаков со степенью меньше или равной заданной.Например,если входной образец является двухмерным и имеет форму [a,b],то многочленом степени 2 являются [1,a,b,a^2,ab,b^2].</target>
        </trans-unit>
        <trans-unit id="138afdc51f7a90d9b74b5dc5c84735ab7ad5ab97" translate="yes" xml:space="preserve">
          <source>Generate a random multilabel classification problem.</source>
          <target state="translated">Генерируйте случайную многоэлементную классификацию.</target>
        </trans-unit>
        <trans-unit id="6e53d56707f7eb93fc64a285e9e5b0c1571546a7" translate="yes" xml:space="preserve">
          <source>Generate a random n-class classification problem.</source>
          <target state="translated">Сгенерировать случайную проблему классификации n-класса.</target>
        </trans-unit>
        <trans-unit id="45b70aa4bfe7b5254dd4845949fd163391dae828" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem with sparse uncorrelated design</source>
          <target state="translated">Сгенерировать случайную регрессионную проблему с разреженной некорректной конструкцией.</target>
        </trans-unit>
        <trans-unit id="097811da2f026de1c67525043ab17d6d057450a6" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem.</source>
          <target state="translated">Генерируйте случайную регрессионную проблему.</target>
        </trans-unit>
        <trans-unit id="90aba5bbbbad8863550c06ced91ee520b1c0caff" translate="yes" xml:space="preserve">
          <source>Generate a random symmetric, positive-definite matrix.</source>
          <target state="translated">Сгенерируйте случайную симметричную матрицу с положительным значением.</target>
        </trans-unit>
        <trans-unit id="b303920886f4c442ac72ea67b8bd3cb1b7460430" translate="yes" xml:space="preserve">
          <source>Generate a signal as a sparse combination of dictionary elements.</source>
          <target state="translated">Сгенерировать сигнал в виде разреженной комбинации элементов словаря.</target>
        </trans-unit>
        <trans-unit id="035b22a208f9d34d7467f70a3f8e5a4c27edb9b2" translate="yes" xml:space="preserve">
          <source>Generate a sparse random projection matrix</source>
          <target state="translated">Сгенерировать разреженную матрицу случайной проекции</target>
        </trans-unit>
        <trans-unit id="4dc557ac054fd2b6925cea078345560226a5469c" translate="yes" xml:space="preserve">
          <source>Generate a sparse symmetric definite positive matrix.</source>
          <target state="translated">Сгенерировать разреженную симметричную определённую положительную матрицу.</target>
        </trans-unit>
        <trans-unit id="2b6ed08a20bd86f602cf70906530ae751a13aa6a" translate="yes" xml:space="preserve">
          <source>Generate a swiss roll dataset.</source>
          <target state="translated">Сгенерируй набор данных по швейцарскому роллу.</target>
        </trans-unit>
        <trans-unit id="2f7e815b3b193bc1cd3e7e4a28307316625909c7" translate="yes" xml:space="preserve">
          <source>Generate an S curve dataset.</source>
          <target state="translated">Сгенерируйте набор данных S-кривой.</target>
        </trans-unit>
        <trans-unit id="a97cf86ca659bda28267893fc11990f8622b62e7" translate="yes" xml:space="preserve">
          <source>Generate an array with block checkerboard structure for biclustering.</source>
          <target state="translated">Сгенерируйте массив с блочной шахматной структурой для билюстрации.</target>
        </trans-unit>
        <trans-unit id="a9f13a8783d09446e6122b3e3234e1d6fcb95591" translate="yes" xml:space="preserve">
          <source>Generate an array with constant block diagonal structure for biclustering.</source>
          <target state="translated">Сгенерируйте массив с постоянной блочной диагональной структурой для билюстрации.</target>
        </trans-unit>
        <trans-unit id="afeaee3f091598162e7eb33b08779a77e0e748f4" translate="yes" xml:space="preserve">
          <source>Generate cross-validated estimates for each input data point</source>
          <target state="translated">Сгенерировать перекрестные оценки для каждой точки входных данных.</target>
        </trans-unit>
        <trans-unit id="99b9ba538a40d50737f63d924a3c7ce27d75993f" translate="yes" xml:space="preserve">
          <source>Generate datasets. We choose the size big enough to see the scalability of the algorithms, but not too big to avoid too long running times</source>
          <target state="translated">Генерировать наборы данных.Мы выбираем размер достаточно большой,чтобы увидеть масштабируемость алгоритмов,но не слишком большой,чтобы избежать слишком долгого времени работы.</target>
        </trans-unit>
        <trans-unit id="c00dd920cc2725de42546dcb337634c4ac897029" translate="yes" xml:space="preserve">
          <source>Generate indices to split data into training and test set.</source>
          <target state="translated">Сгенерировать индексы для разделения данных на тренировочный и тестовый набор.</target>
        </trans-unit>
        <trans-unit id="5107cc8a6ff57cac684ccce1f62420eaa4260507" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian and label samples by quantile</source>
          <target state="translated">Генерировать изотропные гауссовские и маркировочные образцы по квантилям</target>
        </trans-unit>
        <trans-unit id="8e89de3bc63d92fa78eda36337c27db80aab71fe" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian blobs for clustering.</source>
          <target state="translated">Генерировать изотропные гауссовские капли для кластеризации.</target>
        </trans-unit>
        <trans-unit id="37d03dbfefb10390fe483e5ed2d7b03c5a459fa1" translate="yes" xml:space="preserve">
          <source>Generate missing values indicator for X.</source>
          <target state="translated">Сгенерировать индикатор пропущенных значений для X.</target>
        </trans-unit>
        <trans-unit id="462cab2784077aa54955d18bb40a9de12e6edf3c" translate="yes" xml:space="preserve">
          <source>Generate polynomial and interaction features.</source>
          <target state="translated">Генерировать полиномы и особенности взаимодействия.</target>
        </trans-unit>
        <trans-unit id="d1bba874447d3710a4261bda204e3775c6148149" translate="yes" xml:space="preserve">
          <source>Generate random samples from the fitted Gaussian distribution.</source>
          <target state="translated">Генерировать случайные образцы из подогнанного гауссовского распределения.</target>
        </trans-unit>
        <trans-unit id="ce67c2d91c83a1d56ab9a9ee35d822063af6506a" translate="yes" xml:space="preserve">
          <source>Generate random samples from the model.</source>
          <target state="translated">Генерируйте случайные образцы из модели.</target>
        </trans-unit>
        <trans-unit id="077b466863e9f097ef6d30c373ea7fea91f90736" translate="yes" xml:space="preserve">
          <source>Generate test sets such that all contain the same distribution of classes, or as close as possible.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7afab3e6555db4edb28194e580e8ac980040a53c" translate="yes" xml:space="preserve">
          <source>Generate test sets where the smallest and largest differ by at most one sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4defed702b6f02ff908f1cd9f8b411c35ee40dd" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #1&amp;rdquo; regression problem</source>
          <target state="translated">Сгенерируйте регрессионную задачу &amp;laquo;Фридмана №1&amp;raquo;</target>
        </trans-unit>
        <trans-unit id="75088d435099809ee2a5f0ec830b6e2b26fb0500" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #2&amp;rdquo; regression problem</source>
          <target state="translated">Сгенерируйте регрессионную задачу &amp;laquo;Фридмана №2&amp;raquo;</target>
        </trans-unit>
        <trans-unit id="18ca02f4b303dec3c31289cd6db22246b19d8adb" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #3&amp;rdquo; regression problem</source>
          <target state="translated">Сгенерируйте регрессионную задачу &amp;laquo;Фридмана №3&amp;raquo;</target>
        </trans-unit>
        <trans-unit id="1526c84b2e9b495f9ed3216009ebf8b31d461518" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al.</source>
          <target state="translated">Генерирует данные для бинарной классификации,используемой в Hastie и др.</target>
        </trans-unit>
        <trans-unit id="c2cb269fed6a06711794c0a014b9a89e92300ddb" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al. 2009, Example 10.2.</source>
          <target state="translated">Генерирует данные для бинарной классификации,использованной в Хасти и др.2009 г.,Пример 10.2.</target>
        </trans-unit>
        <trans-unit id="fbfd61fc35f16aea2f376426724b313bf45b644a" translate="yes" xml:space="preserve">
          <source>Generates indices to split data into training and test set.</source>
          <target state="translated">Генерирует индексы для разделения данных на тренировочный и тестовый набор.</target>
        </trans-unit>
        <trans-unit id="9a963ad633fdf36ff4f1d429308e1f3d90a2ceea" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on predefined splits.</source>
          <target state="translated">Генерирует индексы поездов/тестов на основе предопределенных сплитов.</target>
        </trans-unit>
        <trans-unit id="4678269441c5cad2dec162c29e80b19e70944794" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on random permutation.</source>
          <target state="translated">Генерирует индексы поездов/тестов на основе случайной перестановки.</target>
        </trans-unit>
        <trans-unit id="025efadf6f18cb5d61732c8188dd311431f2fe8b" translate="yes" xml:space="preserve">
          <source>Generator on parameters sampled from given distributions.</source>
          <target state="translated">Генератор по параметрам,отобранным из заданных распределений.</target>
        </trans-unit>
        <trans-unit id="6d76c76581c79bfcc7307e6698c50d3852025179" translate="yes" xml:space="preserve">
          <source>Generator that yields (estimator, check) tuples. Returned when &lt;code&gt;generate_only=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9008c79b50b6e856f48dd8a1acb75bd481c83565" translate="yes" xml:space="preserve">
          <source>Generator to create n_packs slices going up to n.</source>
          <target state="translated">Генератор для создания n_packs фрагментов до n.</target>
        </trans-unit>
        <trans-unit id="6a34af9aa1c17133e53bdde13fa952c7bcbcf3f6" translate="yes" xml:space="preserve">
          <source>Geometry (metric used)</source>
          <target state="translated">Геометрия (используется метрика)</target>
        </trans-unit>
        <trans-unit id="e5f048789e3e59e8993091df470af502112331aa" translate="yes" xml:space="preserve">
          <source>George W Bush</source>
          <target state="translated">Джордж Буш</target>
        </trans-unit>
        <trans-unit id="b583db923d23716d80d92ca8bb6a609aa1f738a2" translate="yes" xml:space="preserve">
          <source>Gerhard Schroeder</source>
          <target state="translated">Герхард Шредер</target>
        </trans-unit>
        <trans-unit id="33868dad5f60b783d41cfb7c4e686fd5af82ea02" translate="yes" xml:space="preserve">
          <source>Get a list of all estimators from sklearn.</source>
          <target state="translated">Получите список всех оценщиков из Sklearn.</target>
        </trans-unit>
        <trans-unit id="c89b4f911ae16fa0b7caa09ce0c140306df6a7bd" translate="yes" xml:space="preserve">
          <source>Get a mask, or integer index, of the features selected</source>
          <target state="translated">Получить маску,или целочисленный индекс,из выбранных характеристик.</target>
        </trans-unit>
        <trans-unit id="72908cf84377de645c7534a22afeddeeaba91d9d" translate="yes" xml:space="preserve">
          <source>Get a scorer from string</source>
          <target state="translated">Получить счетчик со строки</target>
        </trans-unit>
        <trans-unit id="892dda63b5e110479cdb36e62f1ec2fd9807071b" translate="yes" xml:space="preserve">
          <source>Get a scorer from string.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9077d712fdd7764174aa9d64af32e58e63a20fd2" translate="yes" xml:space="preserve">
          <source>Get data and node arrays.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45a250b2600ca82b0e59f392e6c981ee3cc2728d" translate="yes" xml:space="preserve">
          <source>Get feature names from all transformers.</source>
          <target state="translated">Получите имена функций от всех трансформаторов.</target>
        </trans-unit>
        <trans-unit id="29212f8ab4fb514c62f70555a85d5fbb976ec617" translate="yes" xml:space="preserve">
          <source>Get number of calls.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4be0c520942fc8926cfd53e42cd4ae1d1cc70df9" translate="yes" xml:space="preserve">
          <source>Get parameters for this estimator.</source>
          <target state="translated">Получить параметры для этой оценки.</target>
        </trans-unit>
        <trans-unit id="fe15f50ace10fe1b8c70139542f4a1796682abb3" translate="yes" xml:space="preserve">
          <source>Get parameters of this kernel.</source>
          <target state="translated">Получить параметры этого ядра.</target>
        </trans-unit>
        <trans-unit id="1314abe875bac1db97b1a7155d7b4a8c13c230ee" translate="yes" xml:space="preserve">
          <source>Get predictions from each split of cross-validation for diagnostic purposes.</source>
          <target state="translated">Получайте прогнозы из каждого раздела перекрестной проверки для диагностических целей.</target>
        </trans-unit>
        <trans-unit id="dd0a065fc935a1fd709e1a1d7d55ca6c3433dca5" translate="yes" xml:space="preserve">
          <source>Get the given distance metric from the string identifier.</source>
          <target state="translated">Получить метрику заданного расстояния от строкового идентификатора.</target>
        </trans-unit>
        <trans-unit id="d1f7f6e0092ef00a29852a7f857762682fb899cd" translate="yes" xml:space="preserve">
          <source>Get the parameters of an estimator from the ensemble.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df2089c702273c8bc78b6842775813fe9702ad55" translate="yes" xml:space="preserve">
          <source>Get the parameters of the VotingClassifier</source>
          <target state="translated">Получить параметры Голосового Классификатора</target>
        </trans-unit>
        <trans-unit id="44fa9d84cdb2287aa5766955eab26611c0998b04" translate="yes" xml:space="preserve">
          <source>Get tree status.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f6030226293d5ed7b4d4b045e215d6de20db61c" translate="yes" xml:space="preserve">
          <source>Getter for the precision matrix.</source>
          <target state="translated">Получите прецизионную матрицу.</target>
        </trans-unit>
        <trans-unit id="24670d1cd19283e4b5f2e1096ab423493375ec8f" translate="yes" xml:space="preserve">
          <source>Gibbs sampling from visible and hidden layers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53379a8bafa1cbd8bc5da14050f14d3817f01039" translate="yes" xml:space="preserve">
          <source>Given 2 multivariate covarying two-dimensional datasets, X, and Y, PLS extracts the &amp;lsquo;directions of covariance&amp;rsquo;, i.e. the components of each datasets that explain the most shared variance between both datasets. This is apparent on the &lt;strong&gt;scatterplot matrix&lt;/strong&gt; display: components 1 in dataset X and dataset Y are maximally correlated (points lie around the first diagonal). This is also true for components 2 in both dataset, however, the correlation across datasets for different components is weak: the point cloud is very spherical.</source>
          <target state="translated">Учитывая 2 многомерных коварирующих двумерных набора данных, X и Y, PLS извлекает &amp;laquo;направления ковариации&amp;raquo;, то есть компоненты каждого набора данных, которые объясняют наиболее общие различия между обоими наборами данных. Это видно на отображении &lt;strong&gt;матрицы точечной диаграммы&lt;/strong&gt; : компоненты 1 в наборе данных X и наборе данных Y максимально коррелированы (точки лежат вокруг первой диагонали). Это также верно для компонентов 2 в обоих наборах данных, однако корреляция между наборами данных для разных компонентов слабая: облако точек очень сферическое.</target>
        </trans-unit>
        <trans-unit id="16179644ab5a4c2a1f730ff634ab3d4d3a869791" translate="yes" xml:space="preserve">
          <source>Given a candidate centroid \(x_i\) for iteration \(t\), the candidate is updated according to the following equation:</source>
          <target state="translated">С учетом того,что кандидат на итеранцию был представлен на сайте центроида \(x_i\),он был обновлен в соответствии со следующим уравнением:</target>
        </trans-unit>
        <trans-unit id="4368fa47ed8eb35b757e7b3d5aaf6d7ee1cd4ff6" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to a binary one-hot encoding.</source>
          <target state="translated">Учитывая набор данных с двумя функциями,мы позволяем кодировщику находить уникальные значения для каждой функции и преобразовывать данные в двоичную одноразовую кодировку.</target>
        </trans-unit>
        <trans-unit id="a65060cb3a96ad97e8800308b9076a9a49180060" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to an ordinal encoding.</source>
          <target state="translated">Учитывая набор данных с двумя функциями,мы позволяем кодировщику находить уникальные значения для каждой функции и преобразовывать данные в обычную кодировку.</target>
        </trans-unit>
        <trans-unit id="6cc0cdb4252ae3fe585bd759a612161dfe7c6d85" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^n\) and \(y_i \in \{0, 1\}\), a one hidden layer one hidden neuron MLP learns the function \(f(x) = W_2 g(W_1^T x + b_1) + b_2\) where \(W_1 \in \mathbf{R}^m\) and \(W_2, b_1, b_2 \in \mathbf{R}\) are model parameters. \(W_1, W_2\) represent the weights of the input layer and hidden layer, respectively; and \(b_1, b_2\) represent the bias added to the hidden layer and the output layer, respectively. \(g(\cdot) : R \rightarrow R\) is the activation function, set by default as the hyperbolic tan. It is given as,</source>
          <target state="translated">Приведем набор учебных примеров \((x_1,y_1),(x_2,y_2),\ldots,(x_n,y_n)\),где \(x_i \in \mathbf{R}^n\)и \(y_i \in \{0,1\}\),один скрытый слой один нейрон MLP учит функцию \(f(x)=W_2 g(W_1^T x+b_1)+b_2\),где \(W_1 \in \mathbf{R}^m\)и \(W_2,b_1,b_2 \in \mathbf{R}\)являются модельными параметрами.\(W_1,W_2\)представляют веса входного и скрытого слоев соответственно;а \(b_1,b_2\)представляют смещение,добавленное к скрытому и выходному слою соответственно.\(g(\cdot):R \rightarrow R\)является функцией активации,установленной по умолчанию как гиперболический загар.Она указана как,</target>
        </trans-unit>
        <trans-unit id="c774496cc27fa29850b7be4385a4e837807fe19c" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \mathcal{R}\) (\(y_i \in {-1, 1}\) for classification), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions for binary classification, we simply look at the sign of \(f(x)\). To find the model parameters, we minimize the regularized training error given by</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99b85508f1069fad6e9945b3624fea4140b5fbae" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \{-1,1\}\), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions, we simply look at the sign of \(f(x)\). A common choice to find the model parameters is by minimizing the regularized training error given by</source>
          <target state="translated">Приведем набор учебных примеров \((x_1,y_1),\ldots,(x_n,y_n)\),где \(x_i \in \mathbf{R}^m\)и \(y_i \in \{-1,1\}\),Наша цель-изучить линейную скоринговую функцию \(f(x)=w^T x+b\)с параметрами модели \(w \in \mathbf{R}^m\)и перехватить \(b \in \mathbf{R}\).Для того чтобы сделать прогноз,достаточно посмотреть на знак \(f(x)\).Обычным выбором для поиска параметров модели является минимизация регуляризованной ошибки обучения,заданной</target>
        </trans-unit>
        <trans-unit id="f05ffd1dc56829aeb2ce3b1aa47183d5a5a71272" translate="yes" xml:space="preserve">
          <source>Given an exception, a callable to raise the exception, and a message string, tests that the correct exception is raised and that the message is a substring of the error thrown. Used to test that the specific message thrown during an exception is correct.</source>
          <target state="translated">Получив исключение,вызываемое для поднятия исключения,и строку сообщения,проверяет,что правильное исключение поднято и что сообщение является подстрокой брошенной ошибки.Используется для проверки того,что конкретное сообщение,брошенное во время исключения,корректно.</target>
        </trans-unit>
        <trans-unit id="d5588778e54082615cf481fafbc7dcf0b337d76d" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (&lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt;&lt;code&gt;RFE&lt;/code&gt;&lt;/a&gt;) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">При наличии внешнего оценщика, который присваивает веса характеристикам (например, коэффициентам линейной модели), рекурсивное исключение признаков ( &lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt; &lt;code&gt;RFE&lt;/code&gt; &lt;/a&gt; ) заключается в выборе признаков путем рекурсивного рассмотрения все меньших и меньших наборов признаков. Сначала оценщик обучается на начальном наборе функций, и важность каждой функции определяется либо с &lt;code&gt;coef_&lt;/code&gt; атрибута coef_, либо с помощью атрибута &lt;code&gt;feature_importances_&lt;/code&gt; . Затем наименее важные функции удаляются из текущего набора функций. Эта процедура рекурсивно повторяется для сокращенного набора до тех пор, пока в конечном итоге не будет достигнуто желаемое количество функций для выбора.</target>
        </trans-unit>
        <trans-unit id="0a3e62329db7e0582a525546102e4bc5a3e414ee" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">При наличии внешнего оценщика, который присваивает веса характеристикам (например, коэффициентам линейной модели), целью рекурсивного исключения признаков (RFE) является выбор признаков путем рекурсивного рассмотрения все меньших и меньших наборов признаков. Сначала оценщик обучается на начальном наборе функций, и важность каждой функции определяется либо с &lt;code&gt;coef_&lt;/code&gt; атрибута coef_, либо с помощью атрибута &lt;code&gt;feature_importances_&lt;/code&gt; . Затем наименее важные функции удаляются из текущего набора функций. Эта процедура рекурсивно повторяется для сокращенного набора до тех пор, пока в конечном итоге не будет достигнуто желаемое количество функций для выбора.</target>
        </trans-unit>
        <trans-unit id="2e4a90e9413cabdb8d0d79c137af8efe3fbd16ef" translate="yes" xml:space="preserve">
          <source>Given enough time, K-means will always converge, however this may be to a local minimum. This is highly dependent on the initialization of the centroids. As a result, the computation is often done several times, with different initializations of the centroids. One method to help address this issue is the k-means++ initialization scheme, which has been implemented in scikit-learn (use the &lt;code&gt;init='k-means++'&lt;/code&gt; parameter). This initializes the centroids to be (generally) distant from each other, leading to provably better results than random initialization, as shown in the reference.</source>
          <target state="translated">По прошествии достаточного времени K-средних всегда будет сходиться, однако это может быть локальным минимумом. Это сильно зависит от инициализации центроидов. В результате вычисление часто выполняется несколько раз с разными инициализациями центроидов. Одним из способов решения этой проблемы является схема инициализации k-means ++, которая была реализована в scikit-learn (используйте параметр &lt;code&gt;init='k-means++'&lt;/code&gt; ). Это инициализирует центроиды (как правило) удаленными друг от друга, что приводит к доказуемо лучшим результатам, чем случайная инициализация, как показано в ссылке.</target>
        </trans-unit>
        <trans-unit id="74d4aecb20e2cdcd5c8865136aad914eecac7d61" translate="yes" xml:space="preserve">
          <source>Given the iris dataset, if we knew that there were 3 types of iris, but did not have access to a taxonomist to label them: we could try a &lt;strong&gt;clustering task&lt;/strong&gt;: split the observations into well-separated group called &lt;em&gt;clusters&lt;/em&gt;.</source>
          <target state="translated">Учитывая набор данных радужной оболочки глаза, если бы мы знали, что существует 3 типа радужной оболочки, но не имели доступа к таксономисту, чтобы пометить их: мы могли бы попробовать &lt;strong&gt;задачу кластеризации&lt;/strong&gt; : разделить наблюдения на хорошо разделенные группы, называемые &lt;em&gt;кластерами&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="7ffdaa4cdda4b54b62086a7f5ac68bd7ea3b5908" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;Mutual Information&lt;/strong&gt; is a function that measures the &lt;strong&gt;agreement&lt;/strong&gt; of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, &lt;strong&gt;Normalized Mutual Information (NMI)&lt;/strong&gt; and &lt;strong&gt;Adjusted Mutual Information (AMI)&lt;/strong&gt;. NMI is often used in the literature, while AMI was proposed more recently and is &lt;strong&gt;normalized against chance&lt;/strong&gt;:</source>
          <target state="translated">Учитывая знания о назначениях классов истинности &lt;code&gt;labels_true&lt;/code&gt; и назначениях нашим алгоритмом кластеризации одних и тех же образцов &lt;code&gt;labels_pred&lt;/code&gt; , &lt;strong&gt;Mutual Information&lt;/strong&gt; - это функция, которая измеряет &lt;strong&gt;согласованность&lt;/strong&gt; двух назначений, игнорируя перестановки. Доступны две различные нормализованные версии этой меры: &lt;strong&gt;нормализованная взаимная информация (NMI)&lt;/strong&gt; и &lt;strong&gt;скорректированная взаимная информация (AMI)&lt;/strong&gt; . NMI часто используется в литературе, в то время как AMI был предложен совсем недавно и &lt;strong&gt;нормируется на случайность&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="943836cb04e0640667940c68f56d5deeb3e35898" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;adjusted Rand index&lt;/strong&gt; is a function that measures the &lt;strong&gt;similarity&lt;/strong&gt; of the two assignments, ignoring permutations and &lt;strong&gt;with chance normalization&lt;/strong&gt;:</source>
          <target state="translated">Учитывая знания о назначениях классов истинности &lt;code&gt;labels_true&lt;/code&gt; и назначениях нашим алгоритмом кластеризации одних и тех же выборок &lt;code&gt;labels_pred&lt;/code&gt; , &lt;strong&gt;скорректированный индекс Rand&lt;/strong&gt; представляет собой функцию, которая измеряет &lt;strong&gt;сходство&lt;/strong&gt; двух назначений, игнорируя перестановки и &lt;strong&gt;со случайной нормализацией&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="3a989bbd6a98db5dab53799fee5637e2080ce141" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments of the samples, it is possible to define some intuitive metric using conditional entropy analysis.</source>
          <target state="translated">Учитывая знание класса грунтовой истины заданий образцов,можно определить некоторую интуитивно понятную метрику,используя анализ условной энтропии.</target>
        </trans-unit>
        <trans-unit id="4d7a7b1af5c7c7276434270fce7100038c705add" translate="yes" xml:space="preserve">
          <source>Given these singular vectors, they are ranked according to which can be best approximated by a piecewise-constant vector. The approximations for each vector are found using one-dimensional k-means and scored using the Euclidean distance. Some subset of the best left and right singular vector are selected. Next, the data is projected to this best subset of singular vectors and clustered.</source>
          <target state="translated">Учитывая эти сингулярные векторы,они ранжируются,согласно которым их лучше всего аппроксимировать кусочно-постоянным вектором.Аппроксимации для каждого вектора найдены с помощью одномерных k-средних и оценены с помощью евклидового расстояния.Выбирается подмножество лучших левого и правого сингулярных векторов.Затем данные проецируются на это лучшее подмножество сингулярных векторов и группируются.</target>
        </trans-unit>
        <trans-unit id="21675a464e2ca3b8f99eef191d00e106aa21c0dd" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in R^n\), i=1,&amp;hellip;, l and a label vector \(y \in R^l\), a decision tree recursively partitions the space such that the samples with the same labels are grouped together.</source>
          <target state="translated">Учитывая обучающие векторы \ (x_i \ in R ^ n \), i = 1,&amp;hellip;, l и вектор меток \ (y \ in R ^ l \), дерево решений рекурсивно разбивает пространство таким образом, что образцы с одинаковыми ярлыки сгруппированы вместе.</target>
        </trans-unit>
        <trans-unit id="02fd4db44c84fce9026584422f7727ba079bc40a" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, and a vector \(y \in \mathbb{R}^n\)\(\varepsilon\)-SVR solves the following primal problem:</source>
          <target state="translated">Даны обучающие векторы \ (x_i \ in \ mathbb {R} ^ p \), i = 1,&amp;hellip;, n, и вектор \ (y \ in \ mathbb {R} ^ n \) \ (\ varepsilon \) - SVR решает следующую основную проблему:</target>
        </trans-unit>
        <trans-unit id="70e397398a5003e0a6b00de067e9804bfe571e70" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, in two classes, and a vector \(y \in \{1, -1\}^n\), SVC solves the following primal problem:</source>
          <target state="translated">Даны обучающие векторы \ (x_i \ in \ mathbb {R} ^ p \), i = 1,&amp;hellip;, n, в двух классах, и вектор \ (y \ in \ {1, -1 \} ^ n \) , SVC решает следующую основную задачу:</target>
        </trans-unit>
        <trans-unit id="e43c2f871d10fa4875c4f15e109aeb5faf94fb18" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, in two classes, and a vector \(y \in \{1, -1\}^n\), our goal is to find \(w \in \mathbb{R}^p\) and \(b \in \mathbb{R}\) such that the prediction given by \(\text{sign} (w^T\phi(x) + b)\) is correct for most samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e44bf83eca8aa1cc0c5bdaa89da0afa702f51625" translate="yes" xml:space="preserve">
          <source>Gives the number of (complex) sampling points.</source>
          <target state="translated">Дает количество (сложных)точек выборки.</target>
        </trans-unit>
        <trans-unit id="ac4e9c94eac5d688eef08c9122f5d38187b8f922" translate="yes" xml:space="preserve">
          <source>Global min and max average predictions, such that all plots will have the same scale and y limits. &lt;code&gt;pdp_lim[1]&lt;/code&gt; is the global min and max for single partial dependence curves. &lt;code&gt;pdp_lim[2]&lt;/code&gt; is the global min and max for two-way partial dependence curves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f36c7685daa8ebc7e1344aa0d6e3a7d679decebf" translate="yes" xml:space="preserve">
          <source>Global structure is not explicitly preserved. This is problem is mitigated by initializing points with PCA (using &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt;).</source>
          <target state="translated">Глобальная структура явно не сохраняется. Эта проблема &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt; инициализацией точек с помощью PCA (с использованием init = 'pca' ).</target>
        </trans-unit>
        <trans-unit id="01649050ef673ff19d8d011219103526d0d7370d" translate="yes" xml:space="preserve">
          <source>Global structure is not explicitly preserved. This problem is mitigated by initializing points with PCA (using &lt;code&gt;init='pca'&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="178c27bf7200da0534de904ea7e6ca7da842dbb5" translate="yes" xml:space="preserve">
          <source>Glorot, Xavier, and Yoshua Bengio. &amp;ldquo;Understanding the difficulty of</source>
          <target state="translated">Глорот, Ксавьер и Йошуа Бенжио. &amp;laquo;Понимание сложности</target>
        </trans-unit>
        <trans-unit id="7427cf697be16a4ec1d916910128a59d920125e7" translate="yes" xml:space="preserve">
          <source>Glossary</source>
          <target state="translated">Glossary</target>
        </trans-unit>
        <trans-unit id="f7c22aaad44fb28f4ee8f06d6d4f4f14ac9ce899" translate="yes" xml:space="preserve">
          <source>Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5,</source>
          <target state="translated">Голуб и К.Ван Лоан.Матричные вычисления,третье издание,глава 5,</target>
        </trans-unit>
        <trans-unit id="1de5b736be2f9def46d07ed88549feeeea5a97b0" translate="yes" xml:space="preserve">
          <source>Gorodkin, (2004). Comparing two K-category assignments by a K-category correlation coefficient</source>
          <target state="translated">Городкин,(2004).Сравнение двух присваиваний K-категории по коэффициенту корреляции K-категории</target>
        </trans-unit>
        <trans-unit id="46268d41f41f8e1954ca3d54fd29ddb1959ea6db" translate="yes" xml:space="preserve">
          <source>Gradient Boosting Out-of-Bag estimates</source>
          <target state="translated">Оценки градиентного всплеска из сумки</target>
        </trans-unit>
        <trans-unit id="ff01958eb0f121764b2210794dcbe435f29dcc7a" translate="yes" xml:space="preserve">
          <source>Gradient Boosting Regression Trees for Poisson regression</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9396c57fff04d750ce06a05cfd3c756b4f971532" translate="yes" xml:space="preserve">
          <source>Gradient Boosting also gives the possibility to fit the trees with a Poisson loss (with an implicit log-link function) instead of the default least-squares loss. Here we only fit trees with the Poisson loss to keep this example concise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e3d95a92c5a33953c001956fd3fd6ac3b1082fa" translate="yes" xml:space="preserve">
          <source>Gradient Boosting attempts to solve this minimization problem numerically via steepest descent: The steepest descent direction is the negative gradient of the loss function evaluated at the current model \(F_{m-1}\) which can be calculated for any differentiable loss function:</source>
          <target state="translated">Gradient Boosting пытается решить эту проблему минимизации численно через самый крутой спуск:Крутейшим направлением спуска является отрицательный градиент функции потерь,оцененный на текущей модели \(F_{m-1}\),который может быть вычислен для любой дифференцируемой функции потерь:</target>
        </trans-unit>
        <trans-unit id="be45c92854a0f55592d6c3c1c28201cf75d59d94" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for classification.</source>
          <target state="translated">Градиентное повышение для классификации.</target>
        </trans-unit>
        <trans-unit id="65fd480d2da13d80eb18643fd08c31b9e5239c9a" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for regression.</source>
          <target state="translated">Усиление градиента для регрессии.</target>
        </trans-unit>
        <trans-unit id="23dcf8253cdacbdd915f0e5e69e684c3457ad1df" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regression</source>
          <target state="translated">Регрессия градиентной стимуляции</target>
        </trans-unit>
        <trans-unit id="33b1659de13c2a7e036f71b3c26eda1d552a4b1c" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regularization</source>
          <target state="translated">Регуляризация градиентов</target>
        </trans-unit>
        <trans-unit id="a558a9ccdbbb397deb97e7223684a95578fb2ba7" translate="yes" xml:space="preserve">
          <source>Gradient boosting for classification is very similar to the regression case. However, the sum of the trees \(F_M(x_i) = \sum_m h_m(x_i)\) is not homogeneous to a prediction: it cannot be a class, since the trees predict continuous values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf9557c4e6e59de44aebd2e8b07221ff19e46958" translate="yes" xml:space="preserve">
          <source>Gradient boosting is an ensembling technique where several weak learners (regression trees) are combined to yield a powerful single model, in an iterative fashion.</source>
          <target state="translated">Повышение градиента-это техника ансамбля,при которой несколько слабых учащихся (регрессионных деревьев)объединяются в мощную единую модель,итеративно повторяющую друг друга.</target>
        </trans-unit>
        <trans-unit id="692996b3838fb57cde4b100ea1ec7f66fff47afe" translate="yes" xml:space="preserve">
          <source>Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when &lt;code&gt;eval_gradient&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4611f197e5e7430aa271445ae503720ad1cf3d4" translate="yes" xml:space="preserve">
          <source>Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True.</source>
          <target state="translated">Градиент лог-маржинальной вероятности относительно гиперпараметров ядра в позиции тета.Возвращается только тогда,когда eval_gradient равен True.</target>
        </trans-unit>
        <trans-unit id="e64c4914bb8a27678b7a6969455bd717adc62d09" translate="yes" xml:space="preserve">
          <source>GradientBoostingRegressor</source>
          <target state="translated">GradientBoostingRegressor</target>
        </trans-unit>
        <trans-unit id="e2fb5831cb5dd547c1703af3319394a3f8535468" translate="yes" xml:space="preserve">
          <source>Gram = np.dot(X.T * X).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f77edae6db0cdcd4449adeeb038c653af7406ea3" translate="yes" xml:space="preserve">
          <source>Gram Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">Преследование по ортогональному совпадению граммов (OMP)</target>
        </trans-unit>
        <trans-unit id="10ef9123115df39a65f62ffa3d9d0e10899ca7cd" translate="yes" xml:space="preserve">
          <source>Gram matrix of the input data: X.T * X</source>
          <target state="translated">Графическая матрица входных данных:X.T*X</target>
        </trans-unit>
        <trans-unit id="a83784084519ce853a92535121a74c85019c19b0" translate="yes" xml:space="preserve">
          <source>Graph distance (e.g. nearest-neighbor graph)</source>
          <target state="translated">Графическое расстояние (например,график ближайшего соседа)</target>
        </trans-unit>
        <trans-unit id="8d5c9a04db77341319c1b38643f0d38066fc8710" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel connections</source>
          <target state="translated">График соединений пиксель-пиксель</target>
        </trans-unit>
        <trans-unit id="1b6f746d097f9fe3740f364d944363a7e3d991f9" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel gradient connections</source>
          <target state="translated">График градиентных соединений пиксель-пиксель</target>
        </trans-unit>
        <trans-unit id="a291a5c559f789dd92fe83af065257b966fe9953" translate="yes" xml:space="preserve">
          <source>Graph where A[i, j] is assigned the weight of edge that connects i to j. The matrix is of CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="933bf21afdd55a0d2283845fed0e7bbdd1f5db49" translate="yes" xml:space="preserve">
          <source>Green</source>
          <target state="translated">Green</target>
        </trans-unit>
        <trans-unit id="9786dcbe8afbab8ac93bdfcd6653b6cd7aa7993b" translate="yes" xml:space="preserve">
          <source>Grid of Cs used for cross-validation.</source>
          <target state="translated">Сетка Cs,используемая для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="5bd85812ea7e2436359885d902fd71d10cd1c2d9" translate="yes" xml:space="preserve">
          <source>Grid of parameters with a discrete number of values for each.</source>
          <target state="translated">Сетка параметров с дискретным количеством значений для каждого.</target>
        </trans-unit>
        <trans-unit id="4a6f9190abeab5c3ccde3d9c276bc4db019e7d38" translate="yes" xml:space="preserve">
          <source>Grid search can also be performed on the different preprocessing steps defined in the &lt;code&gt;ColumnTransformer&lt;/code&gt; object, together with the classifier&amp;rsquo;s hyperparameters as part of the &lt;code&gt;Pipeline&lt;/code&gt;. We will search for both the imputer strategy of the numeric preprocessing and the regularization parameter of the logistic regression using &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Поиск по сетке также может выполняться на различных этапах предварительной обработки, определенных в объекте &lt;code&gt;ColumnTransformer&lt;/code&gt; , вместе с гиперпараметрами классификатора как части &lt;code&gt;Pipeline&lt;/code&gt; . Мы будем искать как импьютерную стратегию числовой предварительной обработки, так и параметр регуляризации логистической регрессии, используя &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="71a1782f5aa6d2b7cc26a083f91eef66c1cf3aff" translate="yes" xml:space="preserve">
          <source>Grid-search</source>
          <target state="translated">Grid-search</target>
        </trans-unit>
        <trans-unit id="ed926e289de9aa5047e6b09f7b537df04bde4bbf" translate="yes" xml:space="preserve">
          <source>Grid-search and cross-validated estimators</source>
          <target state="translated">Сереброисследовательские и перекрестнопроверенные оценочные показатели</target>
        </trans-unit>
        <trans-unit id="64ba146c44fdd8e95f622a314398320f76845aed" translate="yes" xml:space="preserve">
          <source>GridSearchCV implements a &amp;ldquo;fit&amp;rdquo; and a &amp;ldquo;score&amp;rdquo; method. It also implements &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; and &amp;ldquo;inverse_transform&amp;rdquo; if they are implemented in the estimator used.</source>
          <target state="translated">GridSearchCV реализует методы &amp;laquo;соответствия&amp;raquo; и &amp;laquo;оценки&amp;raquo;. Он также реализует &amp;laquo;прогноз&amp;raquo;, &amp;laquo;прогноз_прогнозирования&amp;raquo;, &amp;laquo;функция решения&amp;raquo;, &amp;laquo;преобразование&amp;raquo; и &amp;laquo;обратное преобразование&amp;raquo;, если они реализованы в используемом оценщике.</target>
        </trans-unit>
        <trans-unit id="2e6f2bdd92d1c5e33352841cf6b10ed864b19fa7" translate="yes" xml:space="preserve">
          <source>Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification: An Overview. International Journal of Data Warehousing &amp;amp; Mining, 3(3), 1-13, July-September 2007.</source>
          <target state="translated">Григориос Цумакас, Иоаннис Катакис. Классификация по нескольким меткам: обзор. Международный журнал хранилищ данных и майнинга, 3 (3), 1-13, июль-сентябрь 2007 г.</target>
        </trans-unit>
        <trans-unit id="796325c68f51f69a2afcc84a9fb61fa1d8420435" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels for n_samples samples.</source>
          <target state="translated">Наземные истины (правильные)метки для образцов n_samples.</target>
        </trans-unit>
        <trans-unit id="740dd68aa13d511b42941c79135a52aa5a0f5bc4" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels.</source>
          <target state="translated">Название &quot;грубая правда&quot; (верно).</target>
        </trans-unit>
        <trans-unit id="cf154969e860842a471602bf65b740057751e47b" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values.</source>
          <target state="translated">Основные (правильные)целевые значения.</target>
        </trans-unit>
        <trans-unit id="b29893e6134ceb0ae63100b750ea64cd6227af16" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values. Requires y_true &amp;gt; 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8dcf4476037b86142a6c723cc6d58c74ce6fa30f" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values. Requires y_true &amp;gt;= 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="691f624e8ff75b4d50175631f407699ccfb7e35d" translate="yes" xml:space="preserve">
          <source>Ground truth class labels to be used as a reference</source>
          <target state="translated">Метки класса истины заземления для использования в качестве эталона.</target>
        </trans-unit>
        <trans-unit id="2859baca63ac3255284d20bc28f887a4c54fefb4" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set.</source>
          <target state="translated">Групповые этикетки для образцов,используемых при разбиении набора данных на состав поездов/тестов.</target>
        </trans-unit>
        <trans-unit id="da0d044e30ddccc2bad0f6e17da06a788ea2385a" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set. Only used in conjunction with a &amp;ldquo;Group&amp;rdquo; &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; instance (e.g., &lt;a href=&quot;sklearn.model_selection.groupkfold#sklearn.model_selection.GroupKFold&quot;&gt;&lt;code&gt;GroupKFold&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5ee660cf40b3d432d2833cbe2c4255cb71b873d" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set. This &amp;lsquo;groups&amp;rsquo; parameter must always be specified to calculate the number of splits, though the other parameters can be omitted.</source>
          <target state="translated">Сгруппируйте метки для образцов, используемых при разделении набора данных на набор поездов / тестов. Этот параметр &amp;laquo;группы&amp;raquo; необходимо всегда указывать для расчета количества разделений, хотя другие параметры можно не указывать.</target>
        </trans-unit>
        <trans-unit id="2fe58cc1aca321453c1632eb3218b2ee2034ed27" translate="yes" xml:space="preserve">
          <source>Grow a tree with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">Вырастите дерево с &lt;code&gt;max_leaf_nodes&lt;/code&gt; способом &amp;laquo; лучший первый&amp;raquo;. Лучшие узлы определяются как относительное уменьшение примесей. Если нет, то неограниченное количество листовых узлов.</target>
        </trans-unit>
        <trans-unit id="9f319cd9d13cdc03649579ff252c6b96c720508d" translate="yes" xml:space="preserve">
          <source>Grow trees with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">Выращивайте деревья с помощью &lt;code&gt;max_leaf_nodes&lt;/code&gt; способом &amp;laquo; лучший первый&amp;raquo;. Лучшие узлы определяются как относительное уменьшение примесей. Если нет, то неограниченное количество листовых узлов.</target>
        </trans-unit>
        <trans-unit id="bf073fae640ded81eeb7a4cee70faff4a623c16c" translate="yes" xml:space="preserve">
          <source>Guide</source>
          <target state="translated">Guide</target>
        </trans-unit>
        <trans-unit id="1fd932db6b504d046b60a30c3273eb39ba2ac7a5" translate="yes" xml:space="preserve">
          <source>Guyon, I., Weston, J., Barnhill, S., &amp;amp; Vapnik, V., &amp;ldquo;Gene selection for cancer classification using support vector machines&amp;rdquo;, Mach. Learn., 46(1-3), 389&amp;ndash;422, 2002.</source>
          <target state="translated">Гайон, И., Уэстон, Дж., Барнхилл, С., и Вапник, В., &amp;laquo;Выбор генов для классификации рака с использованием опорных векторных машин&amp;raquo;, Mach. ЖЖ., 46 (1-3), 389&amp;ndash;422, 2002.</target>
        </trans-unit>
        <trans-unit id="dd4d457c816b0cb358c91f5b8813986bac26cb3d" translate="yes" xml:space="preserve">
          <source>H. Zhang (2004). &lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;The optimality of Naive Bayes.&lt;/a&gt; Proc. FLAIRS.</source>
          <target state="translated">Х. Чжан (2004). &lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;Оптимальность наивного Байеса. &lt;/a&gt;Proc. FLAIRS.</target>
        </trans-unit>
        <trans-unit id="ce3bde746d403806636c8d155597ef91ca7e1f03" translate="yes" xml:space="preserve">
          <source>H. Zhang (2004). &lt;a href=&quot;https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;The optimality of Naive Bayes.&lt;/a&gt; Proc. FLAIRS.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de489f31c1f185d4a81f0399ead4e066a95b91be" translate="yes" xml:space="preserve">
          <source>HTML representation of &lt;code&gt;Pipeline&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d930a6037b9120a42017959402d9dc27dd6bf69c" translate="yes" xml:space="preserve">
          <source>HTML representation of estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5b6915b0e377ea69d7b62d27d3f027cc63657d7" translate="yes" xml:space="preserve">
          <source>Hagai Attias. (2000). &amp;ldquo;A Variational Bayesian Framework for Graphical Models&amp;rdquo;. In Advances in Neural Information Processing Systems 12.</source>
          <target state="translated">Хагай Аттиас. (2000). &amp;laquo;Вариационная байесовская структура для графических моделей&amp;raquo;. Прогресс в системах обработки нейронной информации 12.</target>
        </trans-unit>
        <trans-unit id="8446ed65374f4c03b547ffebe7ab69437207be78" translate="yes" xml:space="preserve">
          <source>Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). &amp;ldquo;On Clustering Validation Techniques&amp;rdquo; Journal of Intelligent Information Systems, 17(2-3), 107-145. &lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;doi:10.1023/A:1012801612483&lt;/a&gt;.</source>
          <target state="translated">Халкиди, Мария; Батистакис, Яннис; Вазиргианнис, Михалис (2001). &amp;laquo;О методах проверки кластеризации&amp;raquo; Журнал интеллектуальных информационных систем, 17 (2-3), 107-145. &lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;DOI: 10,1023 / А: 1012801612483&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="959a6f4c185bd74a74d43205ed3cc9281eca4d45" translate="yes" xml:space="preserve">
          <source>Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). &amp;ldquo;On Clustering Validation Techniques&amp;rdquo; Journal of Intelligent Information Systems, 17(2-3), 107-145. &lt;a href=&quot;https://doi.org/10.1023/A:1012801612483&quot;&gt;doi:10.1023/A:1012801612483&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57fe625410e680c160d128700bfb1af1b965809e" translate="yes" xml:space="preserve">
          <source>HammingDistance</source>
          <target state="translated">HammingDistance</target>
        </trans-unit>
        <trans-unit id="9757089e5251a143827d61ff72e389c7fd386869" translate="yes" xml:space="preserve">
          <source>Hand, D.J. and Till, R.J., (2001). &lt;a href=&quot;http://link.springer.com/article/10.1023/A:1010920819831&quot;&gt;A simple generalisation of the area under the ROC curve for multiple class classification problems.&lt;/a&gt; Machine learning, 45(2), pp.171-186.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b654c73f6303f0d27e1fbee4658df85b5cd876f" translate="yes" xml:space="preserve">
          <source>Hand, D.J. and Till, R.J., (2001). &lt;a href=&quot;https://link.springer.com/article/10.1023/A:1010920819831&quot;&gt;A simple generalisation of the area under the ROC curve for multiple class classification problems.&lt;/a&gt; Machine learning, 45(2), pp.171-186.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88b6ef37ba2f9ba619bbf453c13dce1665119f21" translate="yes" xml:space="preserve">
          <source>Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems. Machine Learning, 45(2), 171-186.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dee17735ec3038cb9f5dda5413031eefdf59071a" translate="yes" xml:space="preserve">
          <source>Handle or name of the output file. If &lt;code&gt;None&lt;/code&gt;, the result is returned as a string.</source>
          <target state="translated">Дескриптор или имя выходного файла. Если &lt;code&gt;None&lt;/code&gt; , результат возвращается в виде строки.</target>
        </trans-unit>
        <trans-unit id="528b68d16981ccbe32f7d51bc822d75e077c8b80" translate="yes" xml:space="preserve">
          <source>Handling Multicollinear Features</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="077bb86f8a4736a0992a0b108c1d4b8e9298e04f" translate="yes" xml:space="preserve">
          <source>Hard constraint to select the backend. If set to &amp;lsquo;sharedmem&amp;rsquo;, the selected backend will be single-host and thread-based even if the user asked for a non-thread based backend with parallel_backend.</source>
          <target state="translated">Жесткое ограничение на выбор серверной части. Если установлено значение sharedmem, выбранный бэкэнд будет однопоточным и будет основан на потоках, даже если пользователь запросил бэкэнд без потоковой передачи с parallel_backend.</target>
        </trans-unit>
        <trans-unit id="9b9156693e970a15a3c18a9425374c7bf2903574" translate="yes" xml:space="preserve">
          <source>Hard limit on iterations within solver, or -1 for no limit.</source>
          <target state="translated">Жесткий лимит на итерации внутри решателя,или -1 без ограничения.</target>
        </trans-unit>
        <trans-unit id="73dd008516fbc283773051e5943e3b658488b1b1" translate="yes" xml:space="preserve">
          <source>Harrison, D. and Rubinfeld, D.L.</source>
          <target state="translated">Гаррисон,Ди и Рубинфельд,ДиЭл.</target>
        </trans-unit>
        <trans-unit id="c23f4e8aad7e2235e0ebdbc3c9d2bf9b602d6e3d" translate="yes" xml:space="preserve">
          <source>Hash function g(p,x) for a tree is an array of 32 randomly generated float arrays with the same dimension as the data set. This array is stored in GaussianRandomProjectionHash object and can be obtained from &lt;code&gt;components_&lt;/code&gt; attribute.</source>
          <target state="translated">Хеш-функция g (p, x) для дерева представляет собой массив из 32 случайно сгенерированных массивов с плавающей запятой с той же размерностью, что и набор данных. Этот массив хранится в объекте GaussianRandomProjectionHash и может быть получен из атрибута &lt;code&gt;components_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8b5d87d4a16c0b826cb8988befd77a0e52c765c1" translate="yes" xml:space="preserve">
          <source>Hashing feature transformation using Totally Random Trees</source>
          <target state="translated">Преобразование хеширования с использованием полностью случайных деревьев</target>
        </trans-unit>
        <trans-unit id="717a562588a8bf4bd25fb65069c4d3192c7a16dc" translate="yes" xml:space="preserve">
          <source>HashingVectorizer does not provide IDF weighting as this is a stateless model (the fit method does nothing). When IDF weighting is needed it can be added by pipelining its output to a TfidfTransformer instance.</source>
          <target state="translated">HashingVectorizer не предоставляет взвешивание ЦАХАЛа,так как это модель без гражданства (метод подгонки ничего не делает).Когда взвешивание IDF необходимо,оно может быть добавлено путем обвязки его вывода в экземпляр TfidfTransformer.</target>
        </trans-unit>
        <trans-unit id="d06cc92706967f16b8b9c95848cf5aff7ec1c456" translate="yes" xml:space="preserve">
          <source>HashingVectorizer hashes word occurrences to a fixed dimensional space, possibly with collisions. The word count vectors are then normalized to each have l2-norm equal to one (projected to the euclidean unit-ball) which seems to be important for k-means to work in high dimensional space.</source>
          <target state="translated">HashingVectorizer хэширует словосочетания с фиксированным пространством размеров,возможно,при столкновениях.Счетные векторы слова нормализуются к каждому из них l2-нормой,равной единице (проецируемой на эвклидовый единично-шарик),что,по-видимому,важно для работы k-средних в большом размерном пространстве.</target>
        </trans-unit>
        <trans-unit id="28041ffc119d6685560d28cedcd34e917cd495e5" translate="yes" xml:space="preserve">
          <source>Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Хасти, Р. Тибширани и Дж. Фридман, &amp;laquo;Элементы статистического обучения, изд. 2 &amp;rdquo;, Springer, 2009.</target>
        </trans-unit>
        <trans-unit id="9803f456bd9f04731b6843d220c5ae89fa289aa2" translate="yes" xml:space="preserve">
          <source>Haussler, D. (1999). Convolution kernels on discrete structures (Vol. 646). Technical report, Department of Computer Science, University of California at Santa Cruz.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8dd0d155e19e8a71f19b1bbe40cdccabf151805" translate="yes" xml:space="preserve">
          <source>Have a look at the &lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt; as a memory efficient alternative to &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Взгляните на &lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt; как на эффективную с точки &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; памяти альтернативу CountVectorizer .</target>
        </trans-unit>
        <trans-unit id="a899619755f5d06da20b9b2964b88739a1ab106e" translate="yes" xml:space="preserve">
          <source>Have a look at using &lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core Classification&lt;/a&gt; to learn from data that would not fit into the computer main memory.</source>
          <target state="translated">Посмотрите, как использовать &lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;классификацию вне ядра,&lt;/a&gt; чтобы учиться на данных, которые не помещаются в основную память компьютера.</target>
        </trans-unit>
        <trans-unit id="27a688f240efc4c1f8111e73298dc1d5dd7e9964" translate="yes" xml:space="preserve">
          <source>HaversineDistance</source>
          <target state="translated">HaversineDistance</target>
        </trans-unit>
        <trans-unit id="260c7f8bcac0cff0858b268328a3c57270e6d05b" translate="yes" xml:space="preserve">
          <source>He, Kaiming, et al. &amp;ldquo;Delving deep into rectifiers: Surpassing human-level</source>
          <target state="translated">Он, Кайминг и др. &amp;laquo;Углубиться в выпрямители: превзойти человеческий уровень</target>
        </trans-unit>
        <trans-unit id="2f8a00b4f7c2990e23253c9271642cb45a1f2224" translate="yes" xml:space="preserve">
          <source>Helper class for readable parallel mapping.</source>
          <target state="translated">Вспомогательный класс для читабельного параллельного отображения.</target>
        </trans-unit>
        <trans-unit id="15e3ecfce92d858c5fac5d21e2153dba45c36e72" translate="yes" xml:space="preserve">
          <source>Helper function to test the message raised in an exception.</source>
          <target state="translated">Функция помощника для проверки сообщения,поднятого в исключении.</target>
        </trans-unit>
        <trans-unit id="e22b8152bb5ec7ad5480951d5d1692b1809abba4" translate="yes" xml:space="preserve">
          <source>Hence using random projections on the digits dataset which only has 64 features in the input space does not make sense: it does not allow for dimensionality reduction in this case.</source>
          <target state="translated">Поэтому использование случайных проекций на набор данных из цифр,который имеет только 64 признака во входном пространстве,не имеет смысла:это не позволяет уменьшить размерность в данном случае.</target>
        </trans-unit>
        <trans-unit id="858c4ba42a503184b8af0061cb8145e1add6548c" translate="yes" xml:space="preserve">
          <source>Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:</source>
          <target state="translated">Поэтому слова,которые не были замечены в учебном корпусе,будут полностью проигнорированы в будущих обращениях к методу трансформации:</target>
        </trans-unit>
        <trans-unit id="3fea43b2d3bbf05cef0fdbdec4ca7b01a2de9eb5" translate="yes" xml:space="preserve">
          <source>Hence, the None case results in:</source>
          <target state="translated">Следовательно,дело &quot;Никто&quot; не приводит:</target>
        </trans-unit>
        <trans-unit id="4fffc6a6ec537bad9c19e154df4fbf4c1dee1839" translate="yes" xml:space="preserve">
          <source>Here &lt;code&gt;func&lt;/code&gt; is a function which takes two one-dimensional numpy arrays, and returns a distance. Note that in order to be used within the BallTree, the distance must be a true metric: i.e. it must satisfy the following properties</source>
          <target state="translated">Здесь &lt;code&gt;func&lt;/code&gt; - это функция, которая принимает два одномерных массива numpy и возвращает расстояние. Обратите внимание, что для использования в BallTree расстояние должно быть истинной метрикой: т.е. оно должно удовлетворять следующим свойствам</target>
        </trans-unit>
        <trans-unit id="8918252717f29fe05952e0490941948a7c1afcd2" translate="yes" xml:space="preserve">
          <source>Here a sine function is fit with a polynomial of order 3, for values close to zero.</source>
          <target state="translated">Здесь синусоидальная функция подходит к многочлену порядка 3,для значений близких к нулю.</target>
        </trans-unit>
        <trans-unit id="dd2684d229285b3b1a04454d9cd068cd1e054408" translate="yes" xml:space="preserve">
          <source>Here a small example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a binary class problem:</source>
          <target state="translated">Вот небольшой пример , демонстрирующий использование &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; функции с SVM классификатора в задаче двоичная класса:</target>
        </trans-unit>
        <trans-unit id="5113795d86cf9b1916006aecdb0ceee73192da33" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the Gaussian random projection transformer:</source>
          <target state="translated">Здесь небольшой отрывок,который иллюстрирует,как использовать трансформатор случайной проекции Гаусса:</target>
        </trans-unit>
        <trans-unit id="d838251a264bfc0a86e50e7c2f5d9ef6f54d10aa" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the sparse random projection transformer:</source>
          <target state="translated">Здесь небольшой отрывок,который иллюстрирует,как использовать трансформатор разреженной случайной проекции:</target>
        </trans-unit>
        <trans-unit id="32f51b9dd909238771016da8eae995fa183bb752" translate="yes" xml:space="preserve">
          <source>Here are a few suggestions to help further your scikit-learn intuition upon the completion of this tutorial:</source>
          <target state="translated">Вот несколько советов,которые помогут вам развить вашу научно-обученную интуицию после завершения этого урока:</target>
        </trans-unit>
        <trans-unit id="3dda6ea8d57e795e10f1bb02b3e190ba1eee1ee3" translate="yes" xml:space="preserve">
          <source>Here are some examples demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function to calculate recall (or sensitivity), specificity, fall out and miss rate for each class in a problem with multilabel indicator matrix input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d2ed57227d29b030e11d07a6ad14619156d6baa" translate="yes" xml:space="preserve">
          <source>Here are some recommended ways to load standard columnar data into a format usable by scikit-learn:</source>
          <target state="translated">Вот несколько рекомендуемых способов загрузки стандартных данных столбцов в формат,используемый scikit-learn:</target>
        </trans-unit>
        <trans-unit id="6caa2e3f5fa319efda163f3ada59f70b9af4251d" translate="yes" xml:space="preserve">
          <source>Here are some small examples in binary classification:</source>
          <target state="translated">Вот несколько небольших примеров в бинарной классификации:</target>
        </trans-unit>
        <trans-unit id="cad58f968788a0c8b830200526f46c2e8380af6d" translate="yes" xml:space="preserve">
          <source>Here is a list of incremental estimators for different tasks:</source>
          <target state="translated">Ниже приведен список инкрементальных оценок для различных задач:</target>
        </trans-unit>
        <trans-unit id="e5cc3ef05cd44a377ff0113c5a0144a6cd05b3f4" translate="yes" xml:space="preserve">
          <source>Here is a sample output of a run on a quad-core machine:</source>
          <target state="translated">Вот образец вывода пробного прогона на четырехъядерной машине:</target>
        </trans-unit>
        <trans-unit id="00dac27806e77f637d738445566eb627365e0881" translate="yes" xml:space="preserve">
          <source>Here is a sketch of a system designed to achieve this goal:</source>
          <target state="translated">Вот эскиз системы,предназначенной для достижения этой цели:</target>
        </trans-unit>
        <trans-unit id="c595619fa24f58ee3930e8429960f874f9b329e7" translate="yes" xml:space="preserve">
          <source>Here is a small example illustrating the usage of the &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример, иллюстрирующий использование функции &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="423aaa3f8753fc630af578bc1fbb46728b5a06e5" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="1875c837ecf1df623da5e8546dcb195bb9e83c64" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb41f576a02130e8636700bae5b58c941781076b" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="7c0ba7d72bd4599fa8b6676ec86f846e3705f7da" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="0be0450f469be9534c036908ab2afdbd59b24548" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="f8da86e09b21d704ee9aa6f7fcb4b0cf6258a18d" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="e0060b4a19332fa9cdf176d47debc4e3de22af1f" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">Вот небольшой пример использования функции &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="2121874e07dc9ac1fb205417370f94e728d5e5e6" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function:</source>
          <target state="translated">Приведем небольшой пример использования этой функции:</target>
        </trans-unit>
        <trans-unit id="f03ea6f9a5b7db0b84376e166dbfe9d87d690fa9" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function::</source>
          <target state="translated">Приведем небольшой пример использования этой функции::</target>
        </trans-unit>
        <trans-unit id="da9291cb119f102218681b72119ede84a1e93115" translate="yes" xml:space="preserve">
          <source>Here is a usage example:</source>
          <target state="translated">Вот пример использования:</target>
        </trans-unit>
        <trans-unit id="ec46f6fe41e667dcb81fcf9a89e2aaf0a6763af5" translate="yes" xml:space="preserve">
          <source>Here is a visual representation of such a confusion matrix (this figure comes from the &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; example):</source>
          <target state="translated">Вот визуальное представление такой матрицы неточностей (этот рисунок взят из примера &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;матрицы&lt;/a&gt; неточностей):</target>
        </trans-unit>
        <trans-unit id="876abdb2188ee5022ae84c77928e2082f05a478c" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior.</source>
          <target state="translated">Вот визуализация перекрестной проверки поведения.</target>
        </trans-unit>
        <trans-unit id="d5a8fd11bd11ae3f4eb764b39ba1acfee92579af" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">Вот визуализация поведения перекрестной проверки. Обратите внимание, что &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; не зависит от классов или групп.</target>
        </trans-unit>
        <trans-unit id="e10cd61d7e44ad9e6bb0d4cec30745248d4c4e93" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">Вот визуализация поведения перекрестной проверки. Обратите внимание, что &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt; не зависит от классов или групп.</target>
        </trans-unit>
        <trans-unit id="0b166c480658b240c273df0a43ce9ffa8405561c" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a multiclass problem:</source>
          <target state="translated">Вот пример, демонстрирующий использование &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt; функции с SVM классификатора в мультиклассируют проблемы:</target>
        </trans-unit>
        <trans-unit id="01baca5f1060ff615b57707b27b89349c3831f22" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function with &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac06b69a6bbd9ae081c446d18662dd3517d588fd" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function with &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multilabel-indicator-matrix&quot;&gt;multilabel indicator matrix&lt;/a&gt; input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58bc8e3595ba3624485387b6def524d2d31bae65" translate="yes" xml:space="preserve">
          <source>Here is an example of &lt;code&gt;cross_validate&lt;/code&gt; using a single metric:</source>
          <target state="translated">Вот пример &lt;code&gt;cross_validate&lt;/code&gt; с использованием одной метрики:</target>
        </trans-unit>
        <trans-unit id="f7e50cdf4078c7823c206e72ce0bf5486f1e2a9f" translate="yes" xml:space="preserve">
          <source>Here is an example of applying this idea to one-dimensional data, using polynomial features of varying degrees:</source>
          <target state="translated">Приведем пример применения этой идеи к одномерным данным,использующим в разной степени полиномиальные особенности:</target>
        </trans-unit>
        <trans-unit id="8375acd14d3c16b75f14ad4cf9799bf09154cba1" translate="yes" xml:space="preserve">
          <source>Here is an example of building custom scorers, and of using the &lt;code&gt;greater_is_better&lt;/code&gt; parameter:</source>
          <target state="translated">Вот пример создания настраиваемых счетчиков очков и использования &lt;code&gt;greater_is_better&lt;/code&gt; параметра better_is_better :</target>
        </trans-unit>
        <trans-unit id="3be41bccb12847b90804b0be88468f33593d4dc5" translate="yes" xml:space="preserve">
          <source>Here is an example of stratified 3-fold cross-validation on a dataset with 50 samples from two unbalanced classes. We show the number of samples in each class and compare with &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="120ffb4ca9b2da814644df8eb634b8cef584b2a0" translate="yes" xml:space="preserve">
          <source>Here is an example to scale a toy data matrix to the &lt;code&gt;[0, 1]&lt;/code&gt; range:</source>
          <target state="translated">Вот пример масштабирования матрицы данных игрушек до &lt;code&gt;[0, 1]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="04b3257d3ad37f9ca0ccbd79a367325c6e1ed5f4" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;elasticnet&lt;/code&gt; penalty. The regularization strength is globally controlled by the &lt;code&gt;alpha&lt;/code&gt; parameter. With a sufficiently high &lt;code&gt;alpha&lt;/code&gt;, one can then increase the &lt;code&gt;l1_ratio&lt;/code&gt; parameter of &lt;code&gt;elasticnet&lt;/code&gt; to enforce various levels of sparsity in the model coefficients. Higher sparsity here is interpreted as less model complexity as we need fewer coefficients to describe it fully. Of course sparsity influences in turn the prediction time as the sparse dot-product takes time roughly proportional to the number of non-zero coefficients.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f89ae42a83e786b17cd6f1b83024799754e5687" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; with the &lt;code&gt;elasticnet&lt;/code&gt; penalty. The regularization strength is globally controlled by the &lt;code&gt;alpha&lt;/code&gt; parameter. With a sufficiently high &lt;code&gt;alpha&lt;/code&gt;, one can then increase the &lt;code&gt;l1_ratio&lt;/code&gt; parameter of &lt;code&gt;elasticnet&lt;/code&gt; to enforce various levels of sparsity in the model coefficients. Higher sparsity here is interpreted as less model complexity as we need fewer coefficients to describe it fully. Of course sparsity influences in turn the prediction time as the sparse dot-product takes time roughly proportional to the number of non-zero coefficients.</source>
          <target state="translated">Вот пример использования &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; со &lt;code&gt;elasticnet&lt;/code&gt; за эластичность . Сила регуляризации глобально контролируется параметром &lt;code&gt;alpha&lt;/code&gt; . При достаточно высоком &lt;code&gt;l1_ratio&lt;/code&gt; &lt;code&gt;alpha&lt;/code&gt; можно затем увеличить параметр l1_ratio &lt;code&gt;elasticnet&lt;/code&gt; чтобы обеспечить различные уровни разреженности в коэффициентах модели. Более высокая разреженность здесь интерпретируется как меньшая сложность модели, поскольку нам нужно меньше коэффициентов для ее полного описания. Конечно, разреженность, в свою очередь, влияет на время прогнозирования, поскольку разреженное скалярное произведение требует времени, примерно пропорционального количеству ненулевых коэффициентов.</target>
        </trans-unit>
        <trans-unit id="540ee2aaf7182c6dfc449b18e5accb694e3b0894" translate="yes" xml:space="preserve">
          <source>Here is an example:</source>
          <target state="translated">Вот пример:</target>
        </trans-unit>
        <trans-unit id="a1ce1cc95adf7777aaf8483ebc72e46f7e0c5dd5" translate="yes" xml:space="preserve">
          <source>Here is how to use the toy data from the previous example with this scaler:</source>
          <target state="translated">Вот как использовать данные игрушек из предыдущего примера с этим скалером:</target>
        </trans-unit>
        <trans-unit id="da00252cb105e8e07c4719d8131543c2597c6b64" translate="yes" xml:space="preserve">
          <source>Here is sample code that illustrates the use of the &lt;code&gt;sparsify()&lt;/code&gt; method:</source>
          <target state="translated">Вот пример кода, который иллюстрирует использование &lt;code&gt;sparsify()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="b1b76d97b9ed98e3661e06b53d247e6f552362c3" translate="yes" xml:space="preserve">
          <source>Here is sample code to test the sparsity of your input:</source>
          <target state="translated">Ниже приведен пример кода для проверки редкости вашего ввода:</target>
        </trans-unit>
        <trans-unit id="7a4f1fdf399f62578619e41a5fba4a345597683a" translate="yes" xml:space="preserve">
          <source>Here is the list of models benefiting from the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) for automated model selection:</source>
          <target state="translated">Ниже приведен список моделей,подпадающих под действие Информационного критерия Акайке (Akaike Information Criterion,AIC)или Байесского информационного критерия (Bayesian Information Criterion,BIC)для автоматизированного отбора моделей:</target>
        </trans-unit>
        <trans-unit id="24d46233c5b1cf5947d798926d1e317b272fc656" translate="yes" xml:space="preserve">
          <source>Here is the list of such models:</source>
          <target state="translated">Вот список таких моделей:</target>
        </trans-unit>
        <trans-unit id="757c8807092bec583b3c00400f122f638dd1b02a" translate="yes" xml:space="preserve">
          <source>Here one can observe that the train accuracy is very high (the forest model has enough capacity to completely memorize the training set) but it can still generalize well enough to the test set thanks to the built-in bagging of random forests.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15f3441e24a8e858a11c375d5c2fee3bc8aa09ba" translate="yes" xml:space="preserve">
          <source>Here our goal goal is to predict the expected value, i.e. the mean, of the total claim amount per exposure unit also referred to as the pure premium.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="785dc58756e0e128c51d97262d985997dfc75263" translate="yes" xml:space="preserve">
          <source>Here the &lt;code&gt;transform&lt;/code&gt; operation returns \(LX^T\), therefore its time complexity equals &lt;code&gt;n_components * n_features * n_samples_test&lt;/code&gt;. There is no added space complexity in the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8029b08717fd12d596415c9951c99ad442611512" translate="yes" xml:space="preserve">
          <source>Here the computation is achieved thanks to Martinsson&amp;rsquo;s Randomized SVD algorithm implemented in scikit-learn.</source>
          <target state="translated">Здесь вычисление достигается благодаря алгоритму рандомизированного SVD Мартинссона, реализованному в scikit-learn.</target>
        </trans-unit>
        <trans-unit id="baa6fd34087f3f3b80a068e5198c152eb2224084" translate="yes" xml:space="preserve">
          <source>Here the results are not as good as they could be as our choice for the regularization parameter C was not the best. In real life applications this parameter is usually chosen using &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">Здесь результаты не так хороши, как могли бы быть, поскольку наш выбор параметра регуляризации C был не лучшим. В реальных приложениях этот параметр обычно выбирается с помощью &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;настройки гиперпараметров оценщика&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="e33a1b9fd8981a72cf8c17c638c489933e2535f4" translate="yes" xml:space="preserve">
          <source>Here we choose the SAGA solver because it can efficiently optimize for the Logistic Regression loss with a non-smooth, sparsity inducing l1 penalty.</source>
          <target state="translated">Здесь мы выбираем SAGA solver,потому что он может эффективно оптимизировать потери логистической регрессии с негладкой,скудной,вызывающей l1 штраф.</target>
        </trans-unit>
        <trans-unit id="15d9d9f74de48f0968b756664a2f90e7435e3e3c" translate="yes" xml:space="preserve">
          <source>Here we choose the liblinear solver because it can efficiently optimize for the Logistic Regression loss with a non-smooth, sparsity inducing l1 penalty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4668460d1dfffc9a12dd3f0ca645c8016c22599" translate="yes" xml:space="preserve">
          <source>Here we compare 3 approaches:</source>
          <target state="translated">Здесь мы сравниваем 3 подхода:</target>
        </trans-unit>
        <trans-unit id="3aadfee7aa5bef8aeacf179790398b01b017dc93" translate="yes" xml:space="preserve">
          <source>Here we describe variational inference algorithms on Dirichlet process mixture. The Dirichlet process is a prior probability distribution on &lt;em&gt;clusterings with an infinite, unbounded, number of partitions&lt;/em&gt;. Variational techniques let us incorporate this prior structure on Gaussian mixture models at almost no penalty in inference time, comparing with a finite Gaussian mixture model.</source>
          <target state="translated">Здесь мы описываем вариационные алгоритмы вывода на смеси процессов Дирихле. Процесс Дирихле - это априорное распределение вероятностей для &lt;em&gt;кластеризации с бесконечным неограниченным числом разбиений&lt;/em&gt; . Вариационные методы позволяют нам включить эту априорную структуру в модели гауссовой смеси практически без потери времени вывода по сравнению с моделью конечной гауссовой смеси.</target>
        </trans-unit>
        <trans-unit id="19eba1946aa4b2b6c504a0a7a0b9c334a19205ae" translate="yes" xml:space="preserve">
          <source>Here we fit a multinomial logistic regression with L1 penalty on a subset of the MNIST digits classification task. We use the SAGA algorithm for this purpose: this a solver that is fast when the number of samples is significantly larger than the number of features and is able to finely optimize non-smooth objective functions which is the case with the l1-penalty. Test accuracy reaches &amp;gt; 0.8, while weight vectors remains &lt;em&gt;sparse&lt;/em&gt; and therefore more easily &lt;em&gt;interpretable&lt;/em&gt;.</source>
          <target state="translated">Здесь мы подбираем полиномиальную логистическую регрессию со штрафом L1 для подмножества задачи классификации цифр MNIST. Для этой цели мы используем алгоритм SAGA: это решающая программа, которая работает быстро, когда количество выборок значительно превышает количество функций, и может точно оптимизировать негладкие целевые функции, как в случае с l1-штрафом. Точность теста достигает&amp;gt; 0,8, а весовые векторы остаются &lt;em&gt;разреженными&lt;/em&gt; и, следовательно, более легко &lt;em&gt;интерпретируемыми.&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="bc0bdb5bd44175832d7fcee805ba26710508e043" translate="yes" xml:space="preserve">
          <source>Here we have used &lt;code&gt;kernel='gaussian'&lt;/code&gt;, as seen above. Mathematically, a kernel is a positive function \(K(x;h)\) which is controlled by the bandwidth parameter \(h\). Given this kernel form, the density estimate at a point \(y\) within a group of points \(x_i; i=1\cdots N\) is given by:</source>
          <target state="translated">Здесь мы использовали &lt;code&gt;kernel='gaussian'&lt;/code&gt; , как показано выше. Математически ядро ​​- это положительная функция \ (K (x; h) \), которая контролируется параметром полосы пропускания \ (h \). Учитывая эту форму ядра, оценка плотности в точке \ (y \) внутри группы точек \ (x_i; i = 1 \ cdots N \) задается следующим образом:</target>
        </trans-unit>
        <trans-unit id="9bc4f467db4b070f940a4ae98fc40a9d9951075c" translate="yes" xml:space="preserve">
          <source>Here we simulate independent sources using a highly non-Gaussian process, 2 student T with a low number of degrees of freedom (top left figure). We mix them to create observations (top right figure). In this raw observation space, directions identified by PCA are represented by orange vectors. We represent the signal in the PCA space, after whitening by the variance corresponding to the PCA vectors (lower left). Running ICA corresponds to finding a rotation in this space to identify the directions of largest non-Gaussianity (lower right).</source>
          <target state="translated">Здесь мы симулируем независимые источники,используя высоко негауссовский процесс,2 студента T с небольшим количеством степеней свободы (верхний левый рисунок).Мы смешиваем их для создания наблюдений (верхняя правая фигура).В этом необработанном пространстве наблюдения направления,идентифицируемые PCA,представлены оранжевыми векторами.Мы представляем сигнал в пространстве СПС после отбеливания дисперсией,соответствующей векторам СПС (нижняя левая фигура).Запуск ICA соответствует поиску вращения в этом пространстве для идентификации направлений наибольшего негауссовости (нижнее правое).</target>
        </trans-unit>
        <trans-unit id="72e463d9d9e7402af61cb976f70a41a655f66554" translate="yes" xml:space="preserve">
          <source>Here we use the caching property of pipelines to cache the nearest neighbors graph between multiple fits of KNeighborsClassifier. The first call is slow since it computes the neighbors graph, while subsequent call are faster as they do not need to recompute the graph. Here the durations are small since the dataset is small, but the gain can be more substantial when the dataset grows larger, or when the grid of parameter to search is large.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4efad2f65eb490631f07741acecbb3c6dbc45f0c" translate="yes" xml:space="preserve">
          <source>Here we use the l1 sparsity that trims the weights of not informative features to zero. This is good if the goal is to extract the strongly discriminative vocabulary of each class. If the goal is to get the best predictive accuracy, it is better to use the non sparsity-inducing l2 penalty instead.</source>
          <target state="translated">Здесь мы используем лонжероны l1,которые обнуляют вес неинформативных признаков.Это хорошо,если цель состоит в том,чтобы извлечь сильно дискриминирующий словарь каждого класса.Если цель состоит в том,чтобы получить наилучшую точность прогнозирования,лучше использовать не вызывающее спарсибо l2 наказание.</target>
        </trans-unit>
        <trans-unit id="0013bebf729b11b2c5dfc0313efdfb116ab3b0c5" translate="yes" xml:space="preserve">
          <source>Here we want to model the frequency &lt;code&gt;y = ClaimNb / Exposure&lt;/code&gt; conditionally on &lt;code&gt;X&lt;/code&gt; via a (scaled) Poisson distribution, and use &lt;code&gt;Exposure&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="034b3c08e48de8757b6f1f86830d0869f87a8e39" translate="yes" xml:space="preserve">
          <source>Here, &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; is the parameter name of the nested estimator, in this case &lt;code&gt;base_estimator&lt;/code&gt;. If the meta-estimator is constructed as a collection of estimators as in &lt;code&gt;pipeline.Pipeline&lt;/code&gt;, then &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; refers to the name of the estimator, see &lt;a href=&quot;compose#pipeline-nested-parameters&quot;&gt;Nested parameters&lt;/a&gt;. In practice, there can be several levels of nesting:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0260adbe3be54cb933a36e08a92f87d76459f0fc" translate="yes" xml:space="preserve">
          <source>Here, \(\alpha \geq 0\) is a complexity parameter that controls the amount of shrinkage: the larger the value of \(\alpha\), the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.</source>
          <target state="translated">Здесь \(\alpha \geq 0\)-параметр сложности,который контролирует величину усадки:чем больше значение \(\alpha\),тем больше величина усадки и,следовательно,коэффициенты становятся более устойчивыми к коллинеарности.</target>
        </trans-unit>
        <trans-unit id="9412689bc5806775f9bf0419d0db25d5c39e9741" translate="yes" xml:space="preserve">
          <source>Here, the classifier is &lt;code&gt;fit()&lt;/code&gt; on a 2d binary label representation of &lt;code&gt;y&lt;/code&gt;, using the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt;&lt;code&gt;LabelBinarizer&lt;/code&gt;&lt;/a&gt;. In this case &lt;code&gt;predict()&lt;/code&gt; returns a 2d array representing the corresponding multilabel predictions.</source>
          <target state="translated">Здесь классификатор &lt;code&gt;fit()&lt;/code&gt; на двумерном двоичном представлении метки &lt;code&gt;y&lt;/code&gt; с использованием &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt; &lt;code&gt;LabelBinarizer&lt;/code&gt; &lt;/a&gt; . В этом случае &lt;code&gt;predict()&lt;/code&gt; прогноз возвращает двумерный массив, представляющий соответствующие многозначные прогнозы.</target>
        </trans-unit>
        <trans-unit id="e42ec4b790491f01a91defa6334fdc833c4f6019" translate="yes" xml:space="preserve">
          <source>Here, the default kernel &lt;code&gt;rbf&lt;/code&gt; is first changed to &lt;code&gt;linear&lt;/code&gt; via &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt;&lt;code&gt;SVC.set_params()&lt;/code&gt;&lt;/a&gt; after the estimator has been constructed, and changed back to &lt;code&gt;rbf&lt;/code&gt; to refit the estimator and to make a second prediction.</source>
          <target state="translated">Здесь стандартное ядро &lt;code&gt;rbf&lt;/code&gt; сначала изменяется на &lt;code&gt;linear&lt;/code&gt; помощью &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt; &lt;code&gt;SVC.set_params()&lt;/code&gt; &lt;/a&gt; после того, как оценщик был построен, и снова изменяется на &lt;code&gt;rbf&lt;/code&gt; , чтобы обновить оценщик и сделать второй прогноз.</target>
        </trans-unit>
        <trans-unit id="379b23b33ba6458bba2f568a4c2b136ad7c827a5" translate="yes" xml:space="preserve">
          <source>Here, the first &lt;code&gt;predict()&lt;/code&gt; returns an integer array, since &lt;code&gt;iris.target&lt;/code&gt; (an integer array) was used in &lt;code&gt;fit&lt;/code&gt;. The second &lt;code&gt;predict()&lt;/code&gt; returns a string array, since &lt;code&gt;iris.target_names&lt;/code&gt; was for fitting.</source>
          <target state="translated">Здесь первая &lt;code&gt;predict()&lt;/code&gt; возвращает целочисленный массив, так как &lt;code&gt;iris.target&lt;/code&gt; (целочисленный массив) использовался в &lt;code&gt;fit&lt;/code&gt; . Второй &lt;code&gt;predict()&lt;/code&gt; возвращает массив строк, поскольку &lt;code&gt;iris.target_names&lt;/code&gt; для подгонки.</target>
        </trans-unit>
        <trans-unit id="21a97ae1e0557499a4ed4420c47199de8f6f0cde" translate="yes" xml:space="preserve">
          <source>Here, the number of samples is slightly larger than the number of dimensions, thus the empirical covariance is still invertible. However, as the observations are strongly correlated, the empirical covariance matrix is ill-conditioned and as a result its inverse &amp;ndash;the empirical precision matrix&amp;ndash; is very far from the ground truth.</source>
          <target state="translated">Здесь количество выборок немного больше, чем количество измерений, поэтому эмпирическая ковариация по-прежнему обратима. Однако, поскольку наблюдения сильно коррелированы, эмпирическая ковариационная матрица плохо обусловлена, и в результате ее обратная - матрица эмпирической точности - очень далека от истины.</target>
        </trans-unit>
        <trans-unit id="2c6a31e993187ebfe932ff15824a46e0c83fd078" translate="yes" xml:space="preserve">
          <source>Here, the predicted class label is 2, since it has the highest average probability.</source>
          <target state="translated">Здесь прогнозируемая метка класса-2,так как она имеет наибольшую среднюю вероятность.</target>
        </trans-unit>
        <trans-unit id="2ac251de8487bd51d665dc484131dc49cb351bf8" translate="yes" xml:space="preserve">
          <source>Here, the scores for the test data call for caution as they are significantly worse than for the training data indicating an overfit despite the strong regularization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4ef491b953b35546ea7174e484d0bf1fa4f7b9b" translate="yes" xml:space="preserve">
          <source>Here, we are penalizing samples whose prediction is at least \(\varepsilon\) away from their true target. These samples penalize the objective by \(\zeta_i\) or \(\zeta_i^*\), depending on whether their predictions lie above or below the \(\varepsilon\) tube.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3799f87043c16356967f90e71e555e0bd9e10d17" translate="yes" xml:space="preserve">
          <source>Here, we combine 3 learners (linear and non-linear) and use a ridge regressor to combine their outputs together.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a1c9125aac07396a0a83a0358b1364478df4bbe" translate="yes" xml:space="preserve">
          <source>Here, we plot the partial dependence curves for a single feature, &amp;ldquo;age&amp;rdquo;, on the same axes. In this case, &lt;code&gt;tree_disp.axes_&lt;/code&gt; is passed into the second plot function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69bdd751bbdbd7bb5746658b628d98b5240af47b" translate="yes" xml:space="preserve">
          <source>Here, we used the default hyperparameters for the gradient boosting model without any preprocessing as tree-based models are naturally robust to monotonic transformations of numerical features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="264995c0dc7ac7309d4709ed0ce1258e4439b015" translate="yes" xml:space="preserve">
          <source>Hessian Eigenmapping (also known as Hessian-based LLE: HLLE) is another method of solving the regularization problem of LLE. It revolves around a hessian-based quadratic form at each neighborhood which is used to recover the locally linear structure. Though other implementations note its poor scaling with data size, &lt;code&gt;sklearn&lt;/code&gt; implements some algorithmic improvements which make its cost comparable to that of other LLE variants for small output dimension. HLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'hessian'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt;.</source>
          <target state="translated">Собственное отображение Гессе (также известное как LLE на основе гессиана: HLLE) - еще один метод решения проблемы регуляризации LLE. Он вращается вокруг квадратичной формы на основе гессиана в каждой окрестности, которая используется для восстановления локально линейной структуры. Хотя в других реализациях отмечается плохое масштабирование с размером данных, &lt;code&gt;sklearn&lt;/code&gt; реализует некоторые алгоритмические улучшения, которые делают его стоимость сопоставимой со стоимостью других вариантов LLE для небольшого размера вывода. HLLE может быть выполнен с помощью функции &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt; или ее объектно-ориентированного аналога &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; с ключевым словом &lt;code&gt;method = 'hessian'&lt;/code&gt; . Для этого требуется &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4b22ade72c6627b1b562254b0df9c6b4d814d7ac" translate="yes" xml:space="preserve">
          <source>Hidden Activation sampled from the model distribution, where batch_size in the number of examples per minibatch and n_components is the number of hidden units.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="afac02e66e409c4004e2cc2adafb5b5e842109eb" translate="yes" xml:space="preserve">
          <source>Hierarchical agglomerative clustering: Ward</source>
          <target state="translated">Иерархическая агломеративная кластеризация:Ward</target>
        </trans-unit>
        <trans-unit id="09f7d65b121068e93f6d1d655d20b242aded6b7b" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering is a general family of clustering algorithms that build nested clusters by merging or splitting them successively. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample. See the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;Wikipedia page&lt;/a&gt; for more details.</source>
          <target state="translated">Иерархическая кластеризация - это общее семейство алгоритмов кластеризации, которые создают вложенные кластеры путем их последовательного слияния или разделения. Эта иерархия кластеров представлена ​​в виде дерева (или дендрограммы). Корень дерева - это уникальный кластер, который собирает все образцы, а листья - это кластеры только с одним образцом. См. &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;Страницу&lt;/a&gt; в Википедии для получения более подробной информации.</target>
        </trans-unit>
        <trans-unit id="dbe40063cd6e20f1519715e45afa5ca7ed6442de" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering: structured vs unstructured ward</source>
          <target state="translated">Иерархическая кластеризация:структурированная по сравнению с неструктурированной палатой</target>
        </trans-unit>
        <trans-unit id="645ba4388b8ba9172558b321f188082e4d2fd9ef" translate="yes" xml:space="preserve">
          <source>High-dimensional datasets can be very difficult to visualize. While data in two or three dimensions can be plotted to show the inherent structure of the data, equivalent high-dimensional plots are much less intuitive. To aid visualization of the structure of a dataset, the dimension must be reduced in some way.</source>
          <target state="translated">Высокоразмерные наборы данных могут быть очень трудно визуализировать.В то время как данные в двух или трех измерениях могут быть построены на графике,чтобы показать присущую им структуру данных,эквивалентные высокоразмерные графики гораздо менее интуитивно понятны.Чтобы облегчить визуализацию структуры набора данных,размерность должна быть каким-то образом уменьшена.</target>
        </trans-unit>
        <trans-unit id="769f5c4cc60f755dfe8d93fd7b194f0c3a9b7156" translate="yes" xml:space="preserve">
          <source>Hinge (soft-margin): equivalent to Support Vector Classification. \(L(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75c18021e736bcb99a099c597122a642054caa8c" translate="yes" xml:space="preserve">
          <source>Hinge: (soft-margin) Support Vector Machines.</source>
          <target state="translated">Петля:Поддержите векторные машины.</target>
        </trans-unit>
        <trans-unit id="a319ae13863bb8d6da087a8b6e0305de9278e27f" translate="yes" xml:space="preserve">
          <source>Hinton, Geoffrey E.</source>
          <target state="translated">Хинтон,Джеффри И.</target>
        </trans-unit>
        <trans-unit id="04790fed22fa2f8c9274791cf963a575a884ed64" translate="yes" xml:space="preserve">
          <source>Hispanic</source>
          <target state="translated">Hispanic</target>
        </trans-unit>
        <trans-unit id="d6215d83f5c22f8bb7c1095fa0298c0dd2d51f9d" translate="yes" xml:space="preserve">
          <source>Histogram-based Gradient Boosting Classification Tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="772913778b88215dfb5f0c612cecbcae2c4b1a8f" translate="yes" xml:space="preserve">
          <source>Histogram-based Gradient Boosting Regression Tree.</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
