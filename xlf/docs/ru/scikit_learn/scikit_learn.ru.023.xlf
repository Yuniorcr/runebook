<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="7c9f9f5dcfc8aebd4eea110198ededa32c4b1278" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Значение, присваиваемое баллу, если при подгонке оценщика возникает ошибка. Если установлено значение &amp;laquo;поднять&amp;raquo;, возникает ошибка. Если задано числовое значение, возникает FitFailedWarning. Этот параметр не влияет на этап переоборудования, который всегда вызывает ошибку. По умолчанию - &amp;laquo;поднять&amp;raquo;, но с версии 0.22 он изменится на np.nan.</target>
        </trans-unit>
        <trans-unit id="51fe27463b1bbffac6c175b98fff3a09a8ef007a" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If set to &amp;lsquo;raise-deprecating&amp;rsquo;, a FutureWarning is printed before the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise-deprecating&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">Значение, присваиваемое оценке, если при подборе оценщика возникает ошибка. Если установлено значение &amp;laquo;поднять&amp;raquo;, возникает ошибка. Если установлено значение &amp;laquo;raise-deprecating&amp;raquo;, FutureWarning печатается до возникновения ошибки. Если задано числовое значение, возникает FitFailedWarning. Этот параметр не влияет на этап переоборудования, который всегда вызывает ошибку. По умолчанию это &quot;повышение-устаревшее&quot;, но с версии 0.22 оно изменится на np.nan.</target>
        </trans-unit>
        <trans-unit id="402a4cfb84a22d3670431b1576518e6587de93b8" translate="yes" xml:space="preserve">
          <source>Value to use for the dummy feature.</source>
          <target state="translated">Значение для использования функции манекена.</target>
        </trans-unit>
        <trans-unit id="82321dd8f607145fb8d2875c3e367d82d45dfc71" translate="yes" xml:space="preserve">
          <source>Value with which negative labels must be encoded.</source>
          <target state="translated">Значение,с которым должны быть закодированы отрицательные метки.</target>
        </trans-unit>
        <trans-unit id="4e0758fceaa4f106e89501aa7c196eea7d1ad1c2" translate="yes" xml:space="preserve">
          <source>Value with which positive labels must be encoded.</source>
          <target state="translated">Значение,с которым должны быть закодированы положительные метки.</target>
        </trans-unit>
        <trans-unit id="ca5e1888f7ff9f4679a3377b455596a48d014681" translate="yes" xml:space="preserve">
          <source>ValueError</source>
          <target state="translated">ValueError</target>
        </trans-unit>
        <trans-unit id="6a7ed2e67e56dace630120ac5c7bd01e4d032523" translate="yes" xml:space="preserve">
          <source>Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0. With the default threshold of 0, only positive values map to 1.</source>
          <target state="translated">Значения больше карты порога до 1,а значения меньше или равны карте порога до 0.При пороге по умолчанию 0,только положительные значения карты до 1.</target>
        </trans-unit>
        <trans-unit id="0a659f48fb09b2c2dd949774cc3bd6b7ffd6fd87" translate="yes" xml:space="preserve">
          <source>Values in each bin have the same nearest center of a 1D k-means cluster.</source>
          <target state="translated">Значения в каждом мусорном контейнере имеют один и тот же ближайший центр кластера 1D к-средних.</target>
        </trans-unit>
        <trans-unit id="c67d763b94a97115ba7ee9d49115a272cb508cf6" translate="yes" xml:space="preserve">
          <source>Values of n_samples samples drawn from Gaussian process and evaluated at query points.</source>
          <target state="translated">Значения образцов n_samples,взятых из Гауссовского процесса и вычисленных в точках запроса.</target>
        </trans-unit>
        <trans-unit id="1cd1b62dfd3b6a63572d1bf631789bd088451d1d" translate="yes" xml:space="preserve">
          <source>Values of the visible layer after one Gibbs step.</source>
          <target state="translated">Значения видимого слоя после одного шага Гиббса.</target>
        </trans-unit>
        <trans-unit id="c9500aef779ad4ab4355590ca05b9c0de0aa083a" translate="yes" xml:space="preserve">
          <source>Values of the visible layer to start from.</source>
          <target state="translated">Значения видимого слоя для начала.</target>
        </trans-unit>
        <trans-unit id="d9ca5115511a5b00d878e1de5b9daa8f530b632c" translate="yes" xml:space="preserve">
          <source>Values of the visible layer. Must be all-boolean (not checked).</source>
          <target state="translated">Значения видимого слоя.Должно быть,все булевые (не проверено).</target>
        </trans-unit>
        <trans-unit id="35e8d31773dfd80568909d00a3100d73e50de4e1" translate="yes" xml:space="preserve">
          <source>Values predicted by each regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="445d09e482944669dc8a6e893591f45bda28254b" translate="yes" xml:space="preserve">
          <source>Vanschoren, van Rijn, Bischl and Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;OpenML: networked science in machine learning&amp;rdquo;&lt;/a&gt;, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014.</source>
          <target state="translated">Ваншорен, ван Рейн, Бишл и Торго &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;laquo;OpenML: сетевая наука в машинном обучении&amp;raquo;&lt;/a&gt; , ACM SIGKDD Explorations Newsletter, 15 (2), 49-60, 2014.</target>
        </trans-unit>
        <trans-unit id="ba47c39bbafea14cc75438e6420272a547d1a3e3" translate="yes" xml:space="preserve">
          <source>Variance explained by each of the selected components.</source>
          <target state="translated">Различия объясняются каждым из выбранных компонентов.</target>
        </trans-unit>
        <trans-unit id="17b5cb397e6ad9830d59b5fc66bebb45024c7ef4" translate="yes" xml:space="preserve">
          <source>Variances of individual features.</source>
          <target state="translated">Варианты индивидуальных особенностей.</target>
        </trans-unit>
        <trans-unit id="7933f72bf76c6cfbc1dde87498522f5e833878e6" translate="yes" xml:space="preserve">
          <source>Variational Bayesian estimation of a Gaussian mixture.</source>
          <target state="translated">Вариационная байесовская оценка гауссовской смеси.</target>
        </trans-unit>
        <trans-unit id="e459652719d6e0edf38bb3c9f14dba040888c62f" translate="yes" xml:space="preserve">
          <source>Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.</source>
          <target state="translated">Вариационный вывод является продолжением матожидания-максимизации,максимизирующим нижний предел на модельных доказательствах (включая приоры)вместо вероятности данных.Принцип,лежащий в основе вариационных методов,тот же,что и в случае с матожиданием-максимизацией (т.е.итерационные алгоритмы,которые чередуются между поиском вероятностей для каждой точки,генерируемой каждой смесью,и подгонкой смеси под эти заданные точки),но вариационные методы добавляют регуляризацию,интегрируя информацию из предыдущих распределений.Это позволяет избежать сингулярностей,часто встречающихся в решениях по матожиданию-максимизации,но привносит в модель некоторые тонкие смещения.Выводы часто бывают заметно медленнее,но,как правило,не настолько,чтобы сделать использование непрактичным.</target>
        </trans-unit>
        <trans-unit id="009e019794c4b5a288d65b8e0eabe9064e298c81" translate="yes" xml:space="preserve">
          <source>Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the &amp;ldquo;true&amp;rdquo; number of components, affects only algorithmic complexity, not the actual number of components used).</source>
          <target state="translated">Методы вариационного вывода для процесса Дирихле по-прежнему работают с конечным приближением к этой модели бесконечной смеси, но вместо того, чтобы заранее указывать, сколько компонентов нужно использовать, нужно просто указать параметр концентрации и верхнюю границу количества смеси. компонентов (эта верхняя граница, если предполагается, что она превышает &amp;laquo;истинное&amp;raquo; количество компонентов, влияет только на алгоритмическую сложность, а не на фактическое количество используемых компонентов).</target>
        </trans-unit>
        <trans-unit id="bfc42eb1bb86ce5f62b086e9ffd3c67a080b0730" translate="yes" xml:space="preserve">
          <source>Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, &lt;code&gt;components_[i, j]&lt;/code&gt; can be viewed as pseudocount that represents the number of times word &lt;code&gt;j&lt;/code&gt; was assigned to topic &lt;code&gt;i&lt;/code&gt;. It can also be viewed as distribution over the words for each topic after normalization: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt;.</source>
          <target state="translated">Вариационные параметры распределения тематических слов. Поскольку полное условие для распределения тематических слов - это Дирихле, &lt;code&gt;components_[i, j]&lt;/code&gt; можно рассматривать как псевдосчет, который представляет количество раз, когда слово &lt;code&gt;j&lt;/code&gt; было присвоено теме &lt;code&gt;i&lt;/code&gt; . Его также можно рассматривать как распределение по словам для каждой темы после нормализации: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="65cb8d21f19957f8f56d7ec3aeccadf0c1efbc6f" translate="yes" xml:space="preserve">
          <source>Various Agglomerative Clustering on a 2D embedding of digits</source>
          <target state="translated">Различная агломеративная кластеризация на 2D-встраивании цифр</target>
        </trans-unit>
        <trans-unit id="ddbf21d472ec4b83f538c33f12eb263b69f44ca0" translate="yes" xml:space="preserve">
          <source>Various improvements were made to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. On top of the Poisson loss mentionned above, these estimators now support &lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;sample weights&lt;/a&gt;. Also, an automatic early-stopping criterion was added: early-stopping is enabled by default when the number of samples exceeds 10k. Finally, users can now define &lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;monotonic constraints&lt;/a&gt; to constrain the predictions based on the variations of specific features. In the following example, we construct a target that is generally positively correlated with the first feature, with some noise. Applying monotoinc constraints allows the prediction to capture the global effect of the first feature, instead of fitting the noise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1e276370580ceeca94d9a25d3b75abf89a69938" translate="yes" xml:space="preserve">
          <source>Varying regularization in Multi-layer Perceptron</source>
          <target state="translated">Варьирующаяся регуляризация в многослойном Perceptron</target>
        </trans-unit>
        <trans-unit id="1e178759402bc070ae202c1ae1b1666da0dd6a9c" translate="yes" xml:space="preserve">
          <source>Vector Quantization Example</source>
          <target state="translated">Пример векторного квантования</target>
        </trans-unit>
        <trans-unit id="ba8b3829eecac2c5ad85a64a161b0e7f2fae54cf" translate="yes" xml:space="preserve">
          <source>Vector of errors at each iteration.</source>
          <target state="translated">Вектор ошибок на каждой итерации.</target>
        </trans-unit>
        <trans-unit id="4e8912fa819c195ed09c153115c88939fa1f2e3c" translate="yes" xml:space="preserve">
          <source>Vector to be scored, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf31e021601b7cdd3aba8ca6f6502b2543cdeb94" translate="yes" xml:space="preserve">
          <source>VehAge</source>
          <target state="translated">VehAge</target>
        </trans-unit>
        <trans-unit id="ea3a474961d1b758addd0978141f5ebc1f6f2b70" translate="yes" xml:space="preserve">
          <source>VehBrand</source>
          <target state="translated">VehBrand</target>
        </trans-unit>
        <trans-unit id="fda6c72b6cabb64878498cd55268cca04e8d770b" translate="yes" xml:space="preserve">
          <source>VehGas</source>
          <target state="translated">VehGas</target>
        </trans-unit>
        <trans-unit id="9e0c38e996b000566fa359d3ed449ba796915a3e" translate="yes" xml:space="preserve">
          <source>VehPower</source>
          <target state="translated">VehPower</target>
        </trans-unit>
        <trans-unit id="93c6f0903309fd539ceb7d4710cf07f7db8cb1d8" translate="yes" xml:space="preserve">
          <source>Verbose mode when fitting the model.</source>
          <target state="translated">Вербозный режим при установке модели.</target>
        </trans-unit>
        <trans-unit id="ee5731f921bfe2d1197cd007f006306ad3328112" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeb343db47ab9124ef417c41d9bdb92839772dc0" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations. Defaults to 0.</source>
          <target state="translated">Обратный вывод во время вычислений PD.По умолчанию 0.</target>
        </trans-unit>
        <trans-unit id="65d3f9d357c8217e4b4161cc31c9983e755e9511" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated.</source>
          <target state="translated">Флаг Verbosity,управляет отладочными сообщениями,которые выдаются как функции оцениваются.</target>
        </trans-unit>
        <trans-unit id="66d100e92da285b9102a10ebf1825a4d7ce2d91c" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a606460a9db19f2456900341e545d542d386dcd0" translate="yes" xml:space="preserve">
          <source>Verbosity level.</source>
          <target state="translated">Уровень вербозности.</target>
        </trans-unit>
        <trans-unit id="9cadb350a887ea26b759cec53fba259b94be0b70" translate="yes" xml:space="preserve">
          <source>Verbosity level. Setting verbose &amp;gt; 0 will display additional information depending on the solver used.</source>
          <target state="translated">Уровень детализации. Установка подробного&amp;gt; 0 отобразит дополнительную информацию в зависимости от используемого решателя.</target>
        </trans-unit>
        <trans-unit id="c09635f4883cd7798a06597eead68509e08bef52" translate="yes" xml:space="preserve">
          <source>Verbosity mode.</source>
          <target state="translated">Режим вербозности.</target>
        </trans-unit>
        <trans-unit id="4ee9c427e0cc678ca91bc7294708dc43db03512b" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#gp-kernels&quot;&gt;kernels&lt;/a&gt; can be specified. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Универсальность: можно указать разные &lt;a href=&quot;#gp-kernels&quot;&gt;ядра&lt;/a&gt; . Предоставляются общие ядра, но также можно указать собственные ядра.</target>
        </trans-unit>
        <trans-unit id="4b16fac84e3102257e26d97dc6bcc2775a76c275" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">Универсальность: для функции принятия решения могут быть указаны различные &lt;a href=&quot;#svm-kernels&quot;&gt;функции ядра&lt;/a&gt; . Предоставляются общие ядра, но также можно указать собственные ядра.</target>
        </trans-unit>
        <trans-unit id="102caab3d934ebf62d9240e41edbdfb96ec830ff" translate="yes" xml:space="preserve">
          <source>Version of the dataset. Can only be provided if also &lt;code&gt;name&lt;/code&gt; is given. If &amp;lsquo;active&amp;rsquo; the oldest version that&amp;rsquo;s still active is used. Since there may be more than one active version of a dataset, and those versions may fundamentally be different from one another, setting an exact version is highly recommended.</source>
          <target state="translated">Версия набора данных. Может быть предоставлено, только если также указано &lt;code&gt;name&lt;/code&gt; . Если активна, то используется самая старая версия, которая все еще активна. Поскольку может быть несколько активных версий набора данных, и эти версии могут существенно отличаться друг от друга, настоятельно рекомендуется установить точную версию.</target>
        </trans-unit>
        <trans-unit id="2d0ab9e3d9a896817cdfc684c77fbf9f0c4f1aac" translate="yes" xml:space="preserve">
          <source>Version: RCV1-v2, vectors, full sets, topics multilabels.</source>
          <target state="translated">Версия:RCV1-v2,векторы,полные наборы,темы многомаркировки.</target>
        </trans-unit>
        <trans-unit id="dfb46f94f7d77a5ddeabfd408748577e450d338b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3496b8ff284f2499d5b89bafe815a9579d5a779b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">Очень большие &lt;code&gt;n_samples&lt;/code&gt; , средние &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90edfe52a065a045edbdd25bf2f2316a234658ac" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch code&lt;/a&gt;</source>
          <target state="translated">Очень большие &lt;code&gt;n_samples&lt;/code&gt; , средние &lt;code&gt;n_clusters&lt;/code&gt; с &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;кодом MiniBatch&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56b71e89fb1079caaadefd0889e9a22e8b0560e3" translate="yes" xml:space="preserve">
          <source>Videos</source>
          <target state="translated">Videos</target>
        </trans-unit>
        <trans-unit id="644cc701dadc9ddd9912f1b11b35ead35737260b" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method &lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f74a22805e87ed187a5bf75da0c74d88f9fc4e05" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh et al. (2010) назвали варианты NMI и AMI методом их усреднения [VEB2010]. Их средние &quot;sqrt&quot; и &quot;sum&quot; являются средними геометрическими и арифметическими; мы используем эти более общие имена.</target>
        </trans-unit>
        <trans-unit id="3e1bb17ff94c0af1df416cfea07d80b830f06013" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa05fa0b125b1736672a1d80de8273f7659ae9f5" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40fdfddfc4699e8e891d021e6ce4e4252243f9c7" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR</source>
          <target state="translated">Винь,Эппс и Бейли,(2010).Информационно-теоретические меры для сравнения кластеров:Варианты,Свойства,Нормализация и коррекция для шансов,JMLR</target>
        </trans-unit>
        <trans-unit id="64eeb8915eff8290b0627c8aa96dd46ee4bda6f1" translate="yes" xml:space="preserve">
          <source>Visualise your tree as you are training by using the &lt;code&gt;export&lt;/code&gt; function. Use &lt;code&gt;max_depth=3&lt;/code&gt; as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.</source>
          <target state="translated">Визуализируйте свое дерево во время обучения с помощью функции &lt;code&gt;export&lt;/code&gt; . Используйте &lt;code&gt;max_depth=3&lt;/code&gt; в качестве начальной глубины дерева, чтобы понять, насколько дерево соответствует вашим данным, а затем увеличьте глубину.</target>
        </trans-unit>
        <trans-unit id="d175985b87dd9f620aa960059c730b4a35e3bcb5" translate="yes" xml:space="preserve">
          <source>Visualization</source>
          <target state="translated">Visualization</target>
        </trans-unit>
        <trans-unit id="38623835e09f3cd243cdf966707dad9de4ecfeda" translate="yes" xml:space="preserve">
          <source>Visualization of MLP weights on MNIST</source>
          <target state="translated">Визуализация весов MLP на MNIST</target>
        </trans-unit>
        <trans-unit id="a291ff40a157c9afd67fb01fd3c6b6d368d78978" translate="yes" xml:space="preserve">
          <source>Visualization of predictions obtained from different models.</source>
          <target state="translated">Визуализация прогнозов,полученных из различных моделей.</target>
        </trans-unit>
        <trans-unit id="94a741e26bd8d9bfdacbab90c67da4753dcabca8" translate="yes" xml:space="preserve">
          <source>Visualizations with Display Objects</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6c65fa336dc53edc04e670583358fb288a99997" translate="yes" xml:space="preserve">
          <source>Visualize cross-validation indices for many CV objects</source>
          <target state="translated">Визуализируйте перекрестные проверочные индексы для многих объектов CV</target>
        </trans-unit>
        <trans-unit id="4a2bddc914855cb9100c33fc5e346e89e1926136" translate="yes" xml:space="preserve">
          <source>Visualize our data</source>
          <target state="translated">Визуализируйте наши данные</target>
        </trans-unit>
        <trans-unit id="28ba2de8813583360eb0588f62cb6dc19a1f4072" translate="yes" xml:space="preserve">
          <source>Visualize the resulting regions</source>
          <target state="translated">Визуализируйте результирующие регионы</target>
        </trans-unit>
        <trans-unit id="b77da1f257213eacf5971ec98d2f34c8fe910374" translate="yes" xml:space="preserve">
          <source>Visualizing cross-validation behavior in scikit-learn</source>
          <target state="translated">Визуализация перекрёстно-проверочного поведения в наукографе.</target>
        </trans-unit>
        <trans-unit id="e6614e53d3137ea4329f7b88a52f014060c402bb" translate="yes" xml:space="preserve">
          <source>Visualizing the stock market structure</source>
          <target state="translated">Визуализация структуры фондового рынка</target>
        </trans-unit>
        <trans-unit id="3e1e0ef10e7a115946f530e934380438421c5b34" translate="yes" xml:space="preserve">
          <source>Vocabulary: classification and regression</source>
          <target state="translated">Словарь:классификация и регрессия</target>
        </trans-unit>
        <trans-unit id="9b3e588521f2631086f0d4ea61248bd80936e042" translate="yes" xml:space="preserve">
          <source>VotingRegressor</source>
          <target state="translated">VotingRegressor</target>
        </trans-unit>
        <trans-unit id="dd7b37acd93acaf11b82a9ebbc3eea819b85e0ef" translate="yes" xml:space="preserve">
          <source>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.</source>
          <target state="translated">У.Х.Вольберг,У.Н.Стрит и О.Л.Мангасарян.Машинное обучение методам диагностики рака молочной железы от аспиратов с тонкой иголкой.Раковые письма 77 (1994)163-171.</target>
        </trans-unit>
        <trans-unit id="985d7c09beb3a8622b6c063b009de9296fdb89ed" translate="yes" xml:space="preserve">
          <source>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</source>
          <target state="translated">WN Street, WH Wolberg и OL Mangasarian. Извлечение ядерных признаков для диагностики опухолей молочной железы. IS &amp;amp; T / SPIE 1993 Международный симпозиум по электронной визуализации: наука и технология, том 1905, страницы 861-870, Сан-Хосе, Калифорния, 1993.</target>
        </trans-unit>
        <trans-unit id="0525374f4c7331dc5d256feba32a265d327160ed" translate="yes" xml:space="preserve">
          <source>WDBC-Benign</source>
          <target state="translated">WDBC-Benign</target>
        </trans-unit>
        <trans-unit id="fd630df285b07b6076d3b38d88445f6031d3902e" translate="yes" xml:space="preserve">
          <source>WDBC-Malignant</source>
          <target state="translated">WDBC-Malignant</target>
        </trans-unit>
        <trans-unit id="9b852a8108b3e892136da9e7da9f0a5bb56540ea" translate="yes" xml:space="preserve">
          <source>WMinkowskiDistance</source>
          <target state="translated">WMinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="c3600a53fe931326fad0ec5abc0f593830220f56" translate="yes" xml:space="preserve">
          <source>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp;amp; Liu, T. Y. (2013, May). A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e8ee595c7db5dd5f284f8fb603cc66c6c8287ae" translate="yes" xml:space="preserve">
          <source>Ward clustering based on a Feature matrix.</source>
          <target state="translated">Кластеризация палат на основе матрицы функций.</target>
        </trans-unit>
        <trans-unit id="1af684513cf70467c9307765e01677f8970cff6e" translate="yes" xml:space="preserve">
          <source>Ward hierarchical clustering</source>
          <target state="translated">Иерархическая кластеризация палат</target>
        </trans-unit>
        <trans-unit id="d2173ac976f5809b703436c0de33dab1598b674c" translate="yes" xml:space="preserve">
          <source>Ward is the most effective method for noisy data.</source>
          <target state="translated">Уорд является наиболее эффективным методом для шумных данных.</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="44d79cfceaac3d6c963709a9f443a7578dfdd3fa" translate="yes" xml:space="preserve">
          <source>Warning class used if there is an error while fitting the estimator.</source>
          <target state="translated">Класс предупреждения,используемый в случае ошибки при установке оценочного устройства.</target>
        </trans-unit>
        <trans-unit id="c56f46b7e83e71f0bcaf54dacd8cfc15c71ef274" translate="yes" xml:space="preserve">
          <source>Warning class used to notify the user of any change in the behavior.</source>
          <target state="translated">Предупреждающий класс,используемый для оповещения пользователя о любых изменениях в поведении.</target>
        </trans-unit>
        <trans-unit id="43a2ad1c4144ef567b3006486da55db4df5bcce7" translate="yes" xml:space="preserve">
          <source>Warning used to notify implicit data conversions happening in the code.</source>
          <target state="translated">Предупреждение,используемое для уведомления о неявном преобразовании данных,происходящем в коде.</target>
        </trans-unit>
        <trans-unit id="69bb37448a64e3ca58327c210b042b57b19259a7" translate="yes" xml:space="preserve">
          <source>Warning used to notify the user of inefficient computation.</source>
          <target state="translated">Предупреждение,используемое для уведомления пользователя о неэффективности вычислений.</target>
        </trans-unit>
        <trans-unit id="95fde5bcc048210bdd2da0e9628c10dadee1ce1e" translate="yes" xml:space="preserve">
          <source>Warning used when the dot operation does not use BLAS.</source>
          <target state="translated">Предупреждение,используемое,когда точка операция не использует BLAS.</target>
        </trans-unit>
        <trans-unit id="77d4a9d6a0a46436c153d66828a62d378a7e1f5d" translate="yes" xml:space="preserve">
          <source>Warning used when the metric is invalid</source>
          <target state="translated">Предупреждение,используемое,когда метрика недействительна</target>
        </trans-unit>
        <trans-unit id="d0aaba5d13d0d7235d440530a46ccfa6343b56ff" translate="yes" xml:space="preserve">
          <source>Warning: Extra-trees should only be used within ensemble methods.</source>
          <target state="translated">Внимание:Дополнительные деревья должны использоваться только в ансамблевых методах.</target>
        </trans-unit>
        <trans-unit id="c083bc8548c03dc08f53c7e8a611e5699830557a" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a70a0040ebdf5db3cf497e998d5844dc921e921b" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2eb6fdf9d13ab34884681ef0c66f41e16b52aad" translate="yes" xml:space="preserve">
          <source>Warning: this function is experimental and subject to change in a future version of joblib.</source>
          <target state="translated">Предупреждение:эта функция является экспериментальной и может быть изменена в будущей версии joblib.</target>
        </trans-unit>
        <trans-unit id="b33d3bb4e4bfe5e80c2407f4ead429c7fa466ef0" translate="yes" xml:space="preserve">
          <source>We achieved 83.5% accuracy. Let&amp;rsquo;s see if we can do better with a linear &lt;a href=&quot;../../modules/svm#svm&quot;&gt;support vector machine (SVM)&lt;/a&gt;, which is widely regarded as one of the best text classification algorithms (although it&amp;rsquo;s also a bit slower than na&amp;iuml;ve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:</source>
          <target state="translated">Мы достигли точности 83,5%. Посмотрим, сможем ли мы добиться большего успеха с помощью линейной &lt;a href=&quot;../../modules/svm#svm&quot;&gt;машины опорных векторов (SVM)&lt;/a&gt; , которая широко считается одним из лучших алгоритмов классификации текста (хотя она также немного медленнее, чем наивный байесовский алгоритм). Мы можем изменить учащегося, просто подключив другой объект классификатора к нашему конвейеру:</target>
        </trans-unit>
        <trans-unit id="5e4234559a6f8eb7829d45ed1528d4d2b014e858" translate="yes" xml:space="preserve">
          <source>We achieved 91.3% accuracy using the SVM. &lt;code&gt;scikit-learn&lt;/code&gt; provides further utilities for more detailed performance analysis of the results:</source>
          <target state="translated">Мы достигли точности 91,3% с помощью SVM. &lt;code&gt;scikit-learn&lt;/code&gt; предоставляет дополнительные утилиты для более подробного анализа результатов:</target>
        </trans-unit>
        <trans-unit id="4073bf855ec3741a8d17116f66549a3127ee1b52" translate="yes" xml:space="preserve">
          <source>We add observation noise to these waveforms. We generate very sparse noise: only 6% of the time points contain noise. As a result, the l1 norm of this noise (ie &amp;ldquo;cityblock&amp;rdquo; distance) is much smaller than it&amp;rsquo;s l2 norm (&amp;ldquo;euclidean&amp;rdquo; distance). This can be seen on the inter-class distance matrices: the values on the diagonal, that characterize the spread of the class, are much bigger for the Euclidean distance than for the cityblock distance.</source>
          <target state="translated">Мы добавляем к этим сигналам шум наблюдения. Мы генерируем очень разреженный шум: только 6% временных точек содержат шум. В результате норма этого шума l1 (то есть расстояние &amp;laquo;городской квартал&amp;raquo;) намного меньше его нормы l2 (&amp;laquo;евклидово&amp;raquo; расстояние). Это можно увидеть на матрицах межклассовых расстояний: значения на диагонали, которые характеризуют разброс класса, намного больше для евклидова расстояния, чем для расстояния между кварталами города.</target>
        </trans-unit>
        <trans-unit id="0408d5d268f82423b1624837fe33bcd8dd7f81b2" translate="yes" xml:space="preserve">
          <source>We also observe that &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; has much smoother predictions than &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. For the plots to be comparable, it is necessary to subtract the average value of the target &lt;code&gt;y&lt;/code&gt;: The &amp;lsquo;recursion&amp;rsquo; method, used by default for &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, does not account for the initial predictor (in our case the average target). Setting the target average to 0 avoids this bias.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fc281c3e8b120a8bce90f392d5367731bdfa8e6" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for ARD for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">Мы также построим прогнозы и неопределенности для ARD для одномерной регрессии,используя расширение полиномиальных признаков.Обратите внимание,что неопределенности начинают расти в правой части графика.Это связано с тем,что эти тестовые образцы находятся за пределами диапазона тренировочных образцов.</target>
        </trans-unit>
        <trans-unit id="bda5a1ba58eab4f9acd36ef763104051f247918e" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for Bayesian Ridge Regression for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">Мы также построим прогнозы и неопределенности для Байесовской хребтовой регрессии для одномерной регрессии с использованием разложения полиномиальных признаков.Обратите внимание,что неопределенности начинают расти в правой части графика.Это связано с тем,что эти тестовые образцы находятся за пределами диапазона тренировочных образцов.</target>
        </trans-unit>
        <trans-unit id="796db2c0bddee3a97c873bf6deae5d571e22b022" translate="yes" xml:space="preserve">
          <source>We also show the tree structure of a model built on all of the features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b29f4bff482ccd99c1af96e146d78b516ea318aa" translate="yes" xml:space="preserve">
          <source>We also use warm_start=True which means that the coefficients of the models are reused to initialize the next model fit to speed-up the computation of the full-path.</source>
          <target state="translated">Мы также используем параметр warm_start=True,что означает,что коэффициенты моделей используются повторно для инициализации подгонки следующей модели,чтобы ускорить вычисление полного пути.</target>
        </trans-unit>
        <trans-unit id="58db9129e28b6367a4c4b1cf6dbdf62e7e4b259e" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85e7dd24e85e9c4275de753975b0d57e773f0b77" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. &lt;strong&gt;For an exhaustive list of all the changes&lt;/strong&gt;, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f24896ee5efd7713cddd30b90821fa31665d4c0" translate="yes" xml:space="preserve">
          <source>We assume that the observations are independent and identically distributed (i.i.d.).</source>
          <target state="translated">Мы предполагаем,что наблюдения независимы и одинаково распределены (i.i.d.).</target>
        </trans-unit>
        <trans-unit id="1552999210b3502aaea38a27415ef28fc1fbf44a" translate="yes" xml:space="preserve">
          <source>We build an artificial dataset where the target value is in general positively correlated with the first feature (with some random and non-random variations), and in general negatively correlated with the second feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b19a456f973e90e2b4e21cdba9f00b15173fd0ef" translate="yes" xml:space="preserve">
          <source>We call &lt;strong&gt;vectorization&lt;/strong&gt; the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the &lt;strong&gt;Bag of Words&lt;/strong&gt; or &amp;ldquo;Bag of n-grams&amp;rdquo; representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</source>
          <target state="translated">Мы называем &lt;strong&gt;векторизацией&lt;/strong&gt; общий процесс превращения набора текстовых документов в числовые векторы признаков. Эта конкретная стратегия (токенизация, подсчет и нормализация) называется представлением &amp;laquo; &lt;strong&gt;Мешок слов&amp;raquo;&lt;/strong&gt; или &amp;laquo;Мешок н-грамм&amp;raquo;. Документы описываются по вхождению слов при полном игнорировании информации об относительном положении слов в документе.</target>
        </trans-unit>
        <trans-unit id="c42f4b562ec41f92f6f2792dcf47013aca7ffcc1" translate="yes" xml:space="preserve">
          <source>We can additionally validate these models by comparing observed and predicted total claim amount over the test and train subsets. We see that, on average, both model tend to underestimate the total claim (but this behavior depends on the amount of regularization).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63503e35b14a81c8aca7c86c612044cbc5b560d3" translate="yes" xml:space="preserve">
          <source>We can also export the tree in &lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with &lt;code&gt;conda install python-graphviz&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="096029ae48dbb08bf7baa8066a510ed0e5cf55ab" translate="yes" xml:space="preserve">
          <source>We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.</source>
          <target state="translated">Мы также можем предсказать на основе неподготовленной модели,используя GP prior.В дополнение к среднему значению предсказывающего распределения,также можно предсказать его стандартное отклонение (return_std=True)или ковариацию (return_cov=True).Обратите внимание,что в большинстве случаев может быть запрошено одно из этих двух.</target>
        </trans-unit>
        <trans-unit id="c4674ccfad638384c25bbb5d0cf26d42218171fa" translate="yes" xml:space="preserve">
          <source>We can check the coefficient variability through cross-validation: it is a form of data perturbation (related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;resampling&lt;/a&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f60df7f123136fa11f4ddf222fab31a6a72d17d" translate="yes" xml:space="preserve">
          <source>We can choose &lt;code&gt;alpha&lt;/code&gt; to minimize left out error, this time using the diabetes dataset rather than our synthetic data:</source>
          <target state="translated">Мы можем выбрать &lt;code&gt;alpha&lt;/code&gt; чтобы минимизировать пропущенную ошибку, на этот раз используя набор данных о диабете, а не наши синтетические данные:</target>
        </trans-unit>
        <trans-unit id="a7e4da902c37585f80154c204f27a006746ba8cb" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the average occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="469d4e6eabf44c56eec1620cbb6087744c30d3f6" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the avg. occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">Мы ясно видим,что медианная цена дома показывает линейную связь с медианным доходом (вверху слева),и что цена дома падает,когда авг.человек на домохозяйство увеличивается (вверху посередине).Верхний правый участок показывает,что возраст дома в районе не оказывает сильного влияния на цену дома (медиана);так же как и средние комнаты на домохозяйство.Галочки на оси x представляют собой децили значений характеристик в данных обучения.</target>
        </trans-unit>
        <trans-unit id="c32b4a200d58f731852c3f4a8eefb32ef18f31ed" translate="yes" xml:space="preserve">
          <source>We can keep the remaining rating columns by setting &lt;code&gt;remainder='passthrough'&lt;/code&gt;. The values are appended to the end of the transformation:</source>
          <target state="translated">Мы можем сохранить оставшиеся столбцы рейтинга, установив &lt;code&gt;remainder='passthrough'&lt;/code&gt; . Значения добавляются в конец преобразования:</target>
        </trans-unit>
        <trans-unit id="a59ff6e4288992e31a9513b51da5a036927e8ec8" translate="yes" xml:space="preserve">
          <source>We can now load the list of files matching those categories as follows:</source>
          <target state="translated">Теперь мы можем загрузить список файлов,соответствующих этим категориям следующим образом:</target>
        </trans-unit>
        <trans-unit id="f1f864cfbdff004081b5667459fd9c49d8fcf703" translate="yes" xml:space="preserve">
          <source>We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:</source>
          <target state="translated">Теперь мы можем быстро отбирать набор для обучения,при этом удерживая 40% данных для тестирования (оценки)нашего классификатора:</target>
        </trans-unit>
        <trans-unit id="6d11b97d462683ffa27a678189fc90fddb4a8ee5" translate="yes" xml:space="preserve">
          <source>We can observe that the &lt;code&gt;embarked&lt;/code&gt; and &lt;code&gt;sex&lt;/code&gt; columns were tagged as &lt;code&gt;category&lt;/code&gt; columns when loading the data with &lt;code&gt;fetch_openml&lt;/code&gt;. Therefore, we can use this information to dispatch the categorical columns to the &lt;code&gt;categorical_transformer&lt;/code&gt; and the remaining columns to the &lt;code&gt;numerical_transformer&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850dcea5aea59348ecbdc161cc86fe56ad9b64b5" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">Мы можем уменьшить размерность еще больше до выбранного \ (L \), проецируя на линейное подпространство \ (H_L \), которое максимизирует дисперсию \ (\ mu ^ * _ k \) после проецирования (фактически, мы делают форму PCA для преобразованных средств класса \ (\ mu ^ * _ k \)). Этот \ (L \) соответствует параметру &lt;code&gt;n_components&lt;/code&gt; , используемому в методе &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt; . См. &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; для более подробной информации.</target>
        </trans-unit>
        <trans-unit id="92db19023b735fef317e25e1a918af44df264854" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32e64fece84cec61516540c9bc9ea581152251c6" translate="yes" xml:space="preserve">
          <source>We can see that &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; preserves the class ratios (approximately 1 / 10) in both train and test dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bee45302ee9842b9e6d2e72404b6369d8b7e97cc" translate="yes" xml:space="preserve">
          <source>We can see that for low values of &lt;code&gt;n_components&lt;/code&gt; the distribution is wide with many distorted pairs and a skewed distribution (due to the hard limit of zero ratio on the left as distances are always positives) while for larger values of n_components the distortion is controlled and the distances are well preserved by the random projection.</source>
          <target state="translated">Мы можем видеть, что для низких значений &lt;code&gt;n_components&lt;/code&gt; распределение широкое с большим количеством искаженных пар и перекосом (из-за жесткого ограничения нулевого отношения слева, поскольку расстояния всегда положительны), в то время как для больших значений n_components искажение контролируется и расстояния хорошо сохраняются случайной проекцией.</target>
        </trans-unit>
        <trans-unit id="d51b2a4e76fb7eb99807202c5234812c15585e4c" translate="yes" xml:space="preserve">
          <source>We can see that if the maximum depth of the tree (controlled by the &lt;code&gt;max_depth&lt;/code&gt; parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.</source>
          <target state="translated">Мы можем видеть, что если максимальная глубина дерева (управляемая параметром &lt;code&gt;max_depth&lt;/code&gt; ) установлена ​​слишком высокой, деревья решений узнают слишком мелкие детали обучающих данных и учатся на шуме, то есть они переоснащаются.</target>
        </trans-unit>
        <trans-unit id="5bc27bfd8c709ab5505734b2124db3dbd09e7af4" translate="yes" xml:space="preserve">
          <source>We can see that, although feature 2 has a strong coefficient on the full model, it conveys little information on &lt;code&gt;y&lt;/code&gt; when considered with feature 1.</source>
          <target state="translated">Мы можем видеть, что, хотя характеристика 2 имеет сильный коэффициент для полной модели, она дает мало информации о &lt;code&gt;y&lt;/code&gt; при рассмотрении с функцией 1.</target>
        </trans-unit>
        <trans-unit id="208e5f1f40787dd5dcd62a253128bd90d5a3414b" translate="yes" xml:space="preserve">
          <source>We can turn those concept as scores &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt;. Both are bounded below by 0.0 and above by 1.0 (higher is better):</source>
          <target state="translated">Мы можем преобразовать эти концепции в оценки &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt; . Оба ограничены снизу 0,0 и выше 1,0 (чем выше, тем лучше):</target>
        </trans-unit>
        <trans-unit id="592289b1a6fdac7a6256bbd4a62b88701d16e505" translate="yes" xml:space="preserve">
          <source>We can use the function &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt;&lt;code&gt;learning_curve&lt;/code&gt;&lt;/a&gt; to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):</source>
          <target state="translated">Мы можем использовать функцию &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt; &lt;code&gt;learning_curve&lt;/code&gt; &lt;/a&gt; для генерации значений, необходимых для построения такой кривой обучения (количество использованных образцов, средние баллы на обучающих наборах и средние баллы на проверочных наборах):</target>
        </trans-unit>
        <trans-unit id="36de20f1638d2356805015f502415f93be57efc5" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated by the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;), vehicle age (&lt;code&gt;VehAge&lt;/code&gt;) and the insurance bonus/malus (&lt;code&gt;BonusMalus&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0507ecbdf9b58dd0986ef6194b95f4c79d58f52" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated for the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c55a99ecafce9d11edefa5f7981438b525c546b" translate="yes" xml:space="preserve">
          <source>We classify 8x8 images of digits into two classes: 0-4 against 5-9. The visualization shows coefficients of the models for varying C.</source>
          <target state="translated">Мы классифицируем 8х8 изображений цифр на два класса:0-4 против 5-9.Визуализация показывает коэффициенты моделей для различных C.</target>
        </trans-unit>
        <trans-unit id="523600239bb64c3dc717f02d73255329247ddc08" translate="yes" xml:space="preserve">
          <source>We configured a pipeline to scale the numerical input features and tuned the neural network size and learning rate to get a reasonable compromise between training time and predictive performance on a test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c2ceff57e3b51d317fe78664f4ea8312ed35966" translate="yes" xml:space="preserve">
          <source>We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the target depends on them as follows:</source>
          <target state="translated">Рассмотрим 3 особенности x_1,x_2,x_3,равномерно распределенных по [0,1],от них зависит цель:</target>
        </trans-unit>
        <trans-unit id="f5f452641b4c7cde04f8f2f3146b6f807ae80e50" translate="yes" xml:space="preserve">
          <source>We construct the freMTPL2 dataset by joining the freMTPL2freq table, containing the number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;), with the freMTPL2sev table, containing the claim amount (&lt;code&gt;ClaimAmount&lt;/code&gt;) for the same policy ids (&lt;code&gt;IDpol&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b738423194ebf355d81c34c5848e446f6f25c86" translate="yes" xml:space="preserve">
          <source>We create a multi-label dataset, to illustrate the precision-recall in multi-label settings</source>
          <target state="translated">Мы создаем набор данных для нескольких этикеток,чтобы проиллюстрировать точность вызова в настройках нескольких этикеток.</target>
        </trans-unit>
        <trans-unit id="2b472a5c2bccac31b45ff227b2c9930cbabaf64f" translate="yes" xml:space="preserve">
          <source>We create the preprocessing pipelines for both numeric and categorical data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6395abe83d6b6a4aa4bc2a531d4a8a4bd65d8620" translate="yes" xml:space="preserve">
          <source>We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in &lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f9ff80fbe7d3d20607821a1978395dad8f7243a" translate="yes" xml:space="preserve">
          <source>We describe these 3 scenarios in the following subsections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7df3a30efca0a13e3a362147c9be1fa02a3e02fd" translate="yes" xml:space="preserve">
          <source>We don&amp;rsquo;t allow:</source>
          <target state="translated">Мы не разрешаем:</target>
        </trans-unit>
        <trans-unit id="484dbca389e5beb12ba95d531ed59ac647119de0" translate="yes" xml:space="preserve">
          <source>We fetch the data from &lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;. Note that setting the parameter &lt;code&gt;as_frame&lt;/code&gt; to True will retrieve the data as a pandas dataframe.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43167795aabd351e0317ac3702c4dd940441044a" translate="yes" xml:space="preserve">
          <source>We filter out &lt;code&gt;ClaimAmount == 0&lt;/code&gt; as the Gamma distribution has support on \((0, \infty)\), not \([0, \infty)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c17cba12ad6e5c2f931d1de0fcadd712e7bb0a0a" translate="yes" xml:space="preserve">
          <source>We first find the separating plane with a plain SVC and then plot (dashed) the separating hyperplane with automatically correction for unbalanced classes.</source>
          <target state="translated">Сначала мы находим разделительную плоскость с простым SVC,а затем рисуем (пунктиром)разделительную гиперплоскость с автоматической коррекцией для несбалансированных классов.</target>
        </trans-unit>
        <trans-unit id="1b6887ebea04d51a67698037588b0795f4c76e3a" translate="yes" xml:space="preserve">
          <source>We first present GBRT for regression, and then detail the classification case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="916afde7457af1caed530318ff87e1a7a139918e" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">Мы обнаружили, что &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; дает сопоставимые результаты с &lt;code&gt;max_depth=k-1&lt;/code&gt; , но обучение проходит значительно быстрее за счет немного большей ошибки обучения. Параметр &lt;code&gt;max_leaf_nodes&lt;/code&gt; соответствует переменной &lt;code&gt;J&lt;/code&gt; в главе о повышении градиента в &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; и связан с параметром &lt;code&gt;interaction.depth&lt;/code&gt; в пакете R gbm, где &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a42cbe6e58382c593ff38ee7701bfc70bcd66e4" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72f7189dc223c470430f67b7332d9ced78363339" translate="yes" xml:space="preserve">
          <source>We found that Averaged SGD works best with a larger number of features and a higher eta0</source>
          <target state="translated">Мы обнаружили,что Averaged SGD лучше всего работает с большим количеством функций и более высоким показателем eta0.</target>
        </trans-unit>
        <trans-unit id="2147828a070acc191399f3a8049f6a914fdacd22" translate="yes" xml:space="preserve">
          <source>We further include two random variables that are not correlated in any way with the target variable (&lt;code&gt;survived&lt;/code&gt;):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ecc641e4f0c3be544f8ba1b6978d12b64c778e22" translate="yes" xml:space="preserve">
          <source>We generate data from three groups of waveforms. Two of the waveforms (waveform 1 and waveform 2) are proportional one to the other. The cosine distance is invariant to a scaling of the data, as a result, it cannot distinguish these two waveforms. Thus even with no noise, clustering using this distance will not separate out waveform 1 and 2.</source>
          <target state="translated">Мы генерируем данные из трех групп волновых форм.Две формы волны (форма волны 1 и форма волны 2)пропорциональны друг другу.Косинусное расстояние инвариантно масштабированию данных,в результате,оно не может различать эти две формы волн.Таким образом,даже при отсутствии шума кластеризация с использованием этого расстояния не сможет отделить кривые 1 и 2.</target>
        </trans-unit>
        <trans-unit id="03835cacd7901d07f747c14f209b80543758c4fd" translate="yes" xml:space="preserve">
          <source>We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators:</source>
          <target state="translated">Мы видели,что некоторые оценщики могут преобразовывать данные,а некоторые-предсказывать переменные.Мы также можем создавать комбинированные оценки:</target>
        </trans-unit>
        <trans-unit id="996013b3c282443801da622c65fee1deca3cef01" translate="yes" xml:space="preserve">
          <source>We have seen that sparsity could be used to mitigate the curse of dimensionality, &lt;em&gt;i.e&lt;/em&gt; an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: &lt;strong&gt;feature agglomeration&lt;/strong&gt;. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data.</source>
          <target state="translated">Мы видели, что разреженность может быть использована для смягчения проклятия размерности, &lt;em&gt;то&lt;/em&gt; есть недостаточного количества наблюдений по сравнению с количеством функций. Другой подход - объединить похожие функции: &lt;strong&gt;агломерация признаков&lt;/strong&gt; . Этот подход может быть реализован путем кластеризации в направлении признаков, другими словами кластеризации транспонированных данных.</target>
        </trans-unit>
        <trans-unit id="f70b46435230cf70b0b3d749ceef620b9bcdee9d" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">Мы специально воздержались от оптимизации, используемой авторами обеих статей, QR-разложения, используемого в определенных ситуациях для уменьшения алгоритмической сложности SVD. Источник для этой техники - &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt; . Этот метод был опущен, потому что он &lt;code&gt;n_samples&lt;/code&gt; только при разложении матрицы с n_samples (строки)&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; (столбцы) и ухудшает читабельность реализованного алгоритма. Это будет хорошей возможностью для будущей оптимизации, если она будет сочтена необходимой.</target>
        </trans-unit>
        <trans-unit id="ac54e4e32d1eea16ad8753f857ea27f0962cb421" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;em&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/em&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db298eced453f06f8efed43be73a03415c98ca01" translate="yes" xml:space="preserve">
          <source>We have to reconstruct model and parameters to make sure we stay in sync with the python object.</source>
          <target state="translated">Мы должны реконструировать модель и параметры,чтобы убедиться,что мы синхронизированы с объектом питона.</target>
        </trans-unit>
        <trans-unit id="ca5f08fcacf0548e5e0c637b82c4414e44704050" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) (instead of \(C\)) which controls the number of support vectors and &lt;em&gt;margin errors&lt;/em&gt;: \(\nu \in (0, 1]\) is an upper bound on the fraction of margin errors and a lower bound of the fraction of support vectors. A margin error corresponds to a sample that lies on the wrong side of its margin boundary: it is either misclassified, or it is correctly classified but does not lie beyond the margin.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2683785e1f3e3ccb40d3941fed7d5fa67a33cfc" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) which controls the number of support vectors and training errors. The parameter \(\nu \in (0, 1]\) is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</source>
          <target state="translated">Мы вводим новый параметр \(\nu\),который контролирует количество векторов поддержки и ошибок обучения.Параметр \(\nu \in (0,1]\)-это верхняя граница доли обучающих ошибок и нижняя граница доли поддерживающих векторов.</target>
        </trans-unit>
        <trans-unit id="60ccb05e0b7446f76670a424f0fabb01d1ca71b3" translate="yes" xml:space="preserve">
          <source>We need a vectorized version of the image. &lt;code&gt;'rescaled_coins'&lt;/code&gt; is a down-scaled version of the coins image to speed up the process:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="284f00654c2880797bacd24e85e3bc2f5ec8be8d" translate="yes" xml:space="preserve">
          <source>We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.</source>
          <target state="translated">Мы больше не получаем столкновений,но это происходит за счет гораздо большей размерности выходного пространства.Конечно,другие термины,кроме 19,используемые здесь,все еще могут сталкиваться друг с другом.</target>
        </trans-unit>
        <trans-unit id="a19ee5584b95e367f6c768452e1c513e3bb433ea" translate="yes" xml:space="preserve">
          <source>We now inspect the coefficients across several cross-validation folds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d37726e46e38fa3806c6050ccef5f0b5ccde0ad" translate="yes" xml:space="preserve">
          <source>We now provide a &lt;code&gt;pytest&lt;/code&gt; specific decorator which allows &lt;code&gt;pytest&lt;/code&gt; to run all checks independently and report the checks that are failing.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b22fff2428986dd4d9e25659e5099f6fa799f31a" translate="yes" xml:space="preserve">
          <source>We now support imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b146f434972f2182b845909391decf90277ad41" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the perplexity value increases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e7a6d4d2e128e719f76bf1799c4515162612bfb" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the preplexity value increases.</source>
          <target state="translated">Мы наблюдаем тенденцию к более четким формам по мере увеличения значения докомплексности.</target>
        </trans-unit>
        <trans-unit id="3705c31d0fb66694929007b0cdad834fbbaf06c2" translate="yes" xml:space="preserve">
          <source>We plot partial dependence curves for features &amp;ldquo;age&amp;rdquo; and &amp;ldquo;bmi&amp;rdquo; (body mass index) for the decision tree. With two features, &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; expects to plot two curves. Here the plot function place a grid of two plots using the space defined by &lt;code&gt;ax&lt;/code&gt; .</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4e7d2188aa62b346706f6bd2a1ae94095756883" translate="yes" xml:space="preserve">
          <source>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</source>
          <target state="translated">Мы строим предсказанные метки как на тренинге,так и на тестовых данных,используя различные ковариационные типы GMM на наборе данных по радужной оболочке глаза.Мы сравниваем GMM со сферическими,диагональными,полными и связанными ковариационными матрицами в порядке возрастания производительности.Хотя можно было бы ожидать,что полная ковариация будет работать лучше всего в целом,она склонна к переподгонке на небольших наборах данных и не обобщает хорошо проведенных тестовых данных.</target>
        </trans-unit>
        <trans-unit id="7ead9de71a0f24e08ddaae8aaa6dd6470443d3a2" translate="yes" xml:space="preserve">
          <source>We recommend &lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt; and &lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt; as good references for the theory and practicalities of SVMs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a444360e57dc0870f14b3c959a7b626922e7571" translate="yes" xml:space="preserve">
          <source>We see that &lt;code&gt;SVC&lt;/code&gt; doesn&amp;rsquo;t do much better than a dummy classifier. Now, let&amp;rsquo;s change the kernel:</source>
          <target state="translated">Мы видим, что &lt;code&gt;SVC&lt;/code&gt; не намного лучше, чем фиктивный классификатор. Теперь изменим ядро:</target>
        </trans-unit>
        <trans-unit id="9619f66671fbeb88bbee2c1b3d850c22bdb6ab25" translate="yes" xml:space="preserve">
          <source>We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt; section for details.</source>
          <target state="translated">Мы видим, что точность увеличена почти до 100%. Рекомендуется стратегия перекрестной проверки для лучшей оценки точности, если она не требует слишком больших затрат на ЦП. Дополнительные сведения см. В разделе &amp;laquo; &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Перекрестная проверка: оценка производительности средства оценки&lt;/a&gt; &amp;raquo;. Более того, если вы хотите оптимизировать пространство параметров, настоятельно рекомендуется использовать соответствующую методологию; подробности см. в разделе &amp;laquo; &lt;a href=&quot;grid_search#grid-search&quot;&gt;Настройка гиперпараметров оценщика&lt;/a&gt; &amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="b05b900d7824680be8b5fe4195a1e87507494a4c" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d680bb4e5101fe3a9df93911d26cfa982767e679" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we&amp;rsquo;d considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">Мы видим, что полученная &lt;em&gt;полиномиальная регрессия&lt;/em&gt; относится к тому же классу линейных моделей, который мы рассматривали выше (т.е. модель линейна по \ (w \)) и может быть решена с помощью тех же методов. Рассматривая линейные соответствия в многомерном пространстве, построенном с помощью этих базисных функций, модель обладает гибкостью, позволяющей соответствовать гораздо более широкому диапазону данных.</target>
        </trans-unit>
        <trans-unit id="1a0e7af8231b7a460dcfd9acf44c6323ad1ea844" translate="yes" xml:space="preserve">
          <source>We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.</source>
          <target state="translated">Мы выбрали два набора двух переменных из набора данных по корпусу в Бостоне в качестве иллюстрации того,какой анализ может быть выполнен с помощью нескольких инструментов обнаружения отклонений.Для визуализации мы работаем с двумерными примерами,но следует помнить,что,как будет указано,в высоком измерении вещи не так тривиальны.</target>
        </trans-unit>
        <trans-unit id="940e7a9289cb117779f9b0e089fc6f41ec456057" translate="yes" xml:space="preserve">
          <source>We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations &lt;code&gt;n_splits&lt;/code&gt; at the expense of compute time. Increasing the value number of &lt;code&gt;C_range&lt;/code&gt; and &lt;code&gt;gamma_range&lt;/code&gt; steps will increase the resolution of the hyper-parameter heat map.</source>
          <target state="translated">Мы также должны отметить, что небольшие различия в оценках являются результатом случайного разделения процедуры перекрестной проверки. Эти ложные вариации можно сгладить, увеличив количество итераций CV &lt;code&gt;n_splits&lt;/code&gt; за счет времени вычислений. Увеличение числа &lt;code&gt;C_range&lt;/code&gt; шагов C_range и &lt;code&gt;gamma_range&lt;/code&gt; увеличит разрешение тепловой карты гиперпараметров.</target>
        </trans-unit>
        <trans-unit id="1cbc5d306e08afa1d68b1045fc6a567611cf26d2" translate="yes" xml:space="preserve">
          <source>We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.</source>
          <target state="translated">Мы показываем,что linear_model.Lasso дает одинаковые результаты для плотных и разреженных данных и что в случае разреженных данных скорость улучшается.</target>
        </trans-unit>
        <trans-unit id="971fe5258bb92dd314d2f061a23d12526523f329" translate="yes" xml:space="preserve">
          <source>We split the sample into a train and a test dataset. Only the train dataset will be used in the following exploratory analysis. This is a way to emulate a real situation where predictions are performed on an unknown target, and we don&amp;rsquo;t want our analysis and decisions to be biased by our knowledge of the test data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9729e48da1dbe46bc3dec3ab22ad1f98a7a56bb9" translate="yes" xml:space="preserve">
          <source>We start by modeling the target variable with the (l2 penalized) least squares linear regression model, more comonly known as Ridge regression. We use a low penalization &lt;code&gt;alpha&lt;/code&gt;, as we expect such a linear model to under-fit on such a large dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efbf964638e7ca0fbdc3e1bd2a5029a9cbed6b8c" translate="yes" xml:space="preserve">
          <source>We start by training a label propagation model with only 10 labeled points, then we select the top five most uncertain points to label. Next, we train with 15 labeled points (original 10 + 5 new ones). We repeat this process four times to have a model trained with 30 labeled examples. Note you can increase this to label more than 30 by changing &lt;code&gt;max_iterations&lt;/code&gt;. Labeling more than 30 can be useful to get a sense for the speed of convergence of this active learning technique.</source>
          <target state="translated">Мы начинаем с обучения модели распространения меток только с 10 помеченными точками, а затем выбираем пять наиболее неопределенных точек для маркировки. Далее мы тренируемся с 15 отмеченными точками (исходные 10 + 5 новых). Мы повторяем этот процесс четыре раза, чтобы обучить модель с 30 помеченными примерами. Обратите внимание, что вы можете увеличить это значение до более 30, изменив &lt;code&gt;max_iterations&lt;/code&gt; . Присвоение более 30 баллов может быть полезно для понимания скорости конвергенции этой техники активного обучения.</target>
        </trans-unit>
        <trans-unit id="b926aa4a7c89ca684b4dc714781356e70fac60ed" translate="yes" xml:space="preserve">
          <source>We thus transform the KDD Data set into two different data sets: SA and SF.</source>
          <target state="translated">Таким образом,мы преобразуем набор данных KDD в два различных набора данных:SA и SF.</target>
        </trans-unit>
        <trans-unit id="c5856ddc1b1774be0ac4aef6a043703c4e71a274" translate="yes" xml:space="preserve">
          <source>We train a random forest classifier and create a plot comparing it to the SVC ROC curve. Notice how &lt;code&gt;svc_disp&lt;/code&gt; uses &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; to plot the SVC ROC curve without recomputing the values of the roc curve itself. Furthermore, we pass &lt;code&gt;alpha=0.8&lt;/code&gt; to the plot functions to adjust the alpha values of the curves.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="38d99d5f10e1040b13651031a8f4b3d74d91ef9a" translate="yes" xml:space="preserve">
          <source>We train and test the datasets with 15 different classification models and get performance results for each model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f695efb4e75bb85159c9142762a64409b0330558" translate="yes" xml:space="preserve">
          <source>We use &lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; to learn an embedding and plot the points after the transformation. We then take the embedding and find the nearest neighbors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b8cd078987f149b454cdac8f89f7fb050617be5" translate="yes" xml:space="preserve">
          <source>We use &lt;code&gt;ClaimNb&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt; to account for policies that contain more than one claim.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13122bf873819e99a4ec7d32c926bbee95474f9b" translate="yes" xml:space="preserve">
          <source>We use a GridSearchCV to set the dimensionality of the PCA</source>
          <target state="translated">Мы используем GridSearchCV для определения размерности СПС</target>
        </trans-unit>
        <trans-unit id="61efd119ac2fcb7bb96489a56e2c262d1e964f20" translate="yes" xml:space="preserve">
          <source>We use a biased estimator for the standard deviation, equivalent to &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt;. Note that the choice of &lt;code&gt;ddof&lt;/code&gt; is unlikely to affect model performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="83c28baded6fcaa48849ef740f04075945b33344" translate="yes" xml:space="preserve">
          <source>We use clustering to group together quotes that behave similarly. Here, amongst the &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;various clustering techniques&lt;/a&gt; available in the scikit-learn, we use &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation&lt;/a&gt; as it does not enforce equal-size clusters, and it can choose automatically the number of clusters from the data.</source>
          <target state="translated">Мы используем кластеризацию, чтобы группировать цитаты, которые ведут себя одинаково. Здесь, среди &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;различных методов кластеризации,&lt;/a&gt; доступных в scikit-learn, мы используем &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation, так&lt;/a&gt; как он не требует кластеров одинакового размера и может автоматически выбирать количество кластеров из данных.</target>
        </trans-unit>
        <trans-unit id="78d7bc0e66fad92fa188a5bbaa0a7aaa581101c6" translate="yes" xml:space="preserve">
          <source>We use sparse inverse covariance estimation to find which quotes are correlated conditionally on the others. Specifically, sparse inverse covariance gives us a graph, that is a list of connection. For each symbol, the symbols that it is connected too are those useful to explain its fluctuations.</source>
          <target state="translated">Мы используем разреженную обратную ковариационную оценку,чтобы найти,какие котировки коррелируют условно с другими.В частности,разреженная обратная ковариация дает нам график,то есть список связей.Для каждого символа,символы,с которыми он связан,также являются теми,которые полезны для объяснения его флуктуаций.</target>
        </trans-unit>
        <trans-unit id="0bc034dd2aa1865c002d495e95115e5b8c709a84" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the 20 newsgroups text document (TF-IDF word frequencies) dataset or on the digits dataset:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4e3f49993eefd3c100d45584ffc552355d0d52e7" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the digits dataset or on the 20 newsgroups text document (TF-IDF word frequencies) dataset:</source>
          <target state="translated">Мы подтверждаем вышеперечисленные границы в наборе цифровых данных или в текстовом документе 20 новостных групп (TF-IDF word frequencyencies):</target>
        </trans-unit>
        <trans-unit id="63b1da5381eb76c29e4f139b0a4a0f6fa6f76bca" translate="yes" xml:space="preserve">
          <source>We want to calculate the distance between the Ezeiza Airport (Buenos Aires, Argentina) and the Charles de Gaulle Airport (Paris, France)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bd2e73735072e414ab7c853666f3b851cc359c1" translate="yes" xml:space="preserve">
          <source>We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;).</source>
          <target state="translated">Мы хотим сравнить производительность MiniBatchKMeans и KMeans: MiniBatchKMeans быстрее, но дает немного разные результаты (см. &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Мини-пакетные K-средние&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="76b3c7c02e156a1d558e413ab95dd6c124236bdc" translate="yes" xml:space="preserve">
          <source>We will also create a transformer that extracts the length of the text and the number of sentences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ae1ec8b6dd301757e7e59be0a9aeff645f7f18" translate="yes" xml:space="preserve">
          <source>We will cluster a set of data, first with KMeans and then with MiniBatchKMeans, and plot the results. We will also plot the points that are labelled differently between the two algorithms.</source>
          <target state="translated">Мы сконцентрируем набор данных сначала с KMeans,а затем с MiniBatchKMeans,и построим график результатов.Мы также построим графики точек,которые помечены по-разному между двумя алгоритмами.</target>
        </trans-unit>
        <trans-unit id="de730c276ad64150c605a83740871002db6683ff" translate="yes" xml:space="preserve">
          <source>We will compare the performance of both approaches. To quantify the performance of both models, one can compute the mean deviance of the train and test data assuming a Compound Poisson-Gamma distribution of the total claim amount. This is equivalent to a Tweedie distribution with a &lt;code&gt;power&lt;/code&gt; parameter between 1 and 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4cfcf9a2f9d6095c0707be11ca996fe9017bf9d" translate="yes" xml:space="preserve">
          <source>We will probably have to use an estimator or a parametrization of the current estimator that can learn more complex concepts (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.</source>
          <target state="translated">Вероятно,нам придется использовать вычислитель или параметризацию текущей вычислительной системы,которая сможет изучить более сложные понятия (т.е.имеет меньший смещение).Если оценка обучения намного больше,чем оценка валидации для максимального количества обучающих выборок,то добавление большего количества обучающих выборок,скорее всего,увеличит обобщение.На следующем рисунке видно,что SVM может выиграть от большего количества учебных примеров.</target>
        </trans-unit>
        <trans-unit id="3f09acb611dde4d0822059b7dd910a6bf0d4be22" translate="yes" xml:space="preserve">
          <source>We will review here the orders of magnitude you can expect from a number of scikit-learn estimators in different contexts and provide some tips and tricks for overcoming performance bottlenecks.</source>
          <target state="translated">Мы рассмотрим здесь порядки величин,которые вы можете ожидать от ряда научно-обученных оценщиков в различных контекстах,и дадим некоторые советы и уловки для преодоления узких мест в производительности.</target>
        </trans-unit>
        <trans-unit id="7c06ec0897b21dbb460bd6d56256bf3c61c9d6ea" translate="yes" xml:space="preserve">
          <source>We will train our classifier with the following features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3be1dd4cfac1d63b4ce361f8740d86e98582c7b5" translate="yes" xml:space="preserve">
          <source>We will use &lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;Ames Housing&lt;/a&gt; dataset which was first compiled by Dean De Cock and became better known after it was used in Kaggle challenge. It is a set of 1460 residential homes in Ames, Iowa, each described by 80 features. We will use it to predict the final logarithmic price of the houses. In this example we will use only 20 most interesting features chosen using GradientBoostingRegressor() and limit number of entries (here we won&amp;rsquo;t go into the details on how to select the most interesting features).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="037b81bcdb33690797b74b53d8be309b975609a6" translate="yes" xml:space="preserve">
          <source>We will use data from the &lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;&amp;ldquo;Current Population Survey&amp;rdquo;&lt;/a&gt; from 1985 to predict wage as a function of various features such as experience, age, or education.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b44f9dbf66aa535fbabfa2d804ce4636c53d36" translate="yes" xml:space="preserve">
          <source>We will use the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20 newsgroups dataset&lt;/a&gt;, which comprises posts from newsgroups on 20 topics. This dataset is split into train and test subsets based on messages posted before and after a specific date. We will only use posts from 2 categories to speed up running time.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="889d3befa932d46595e6941bb656f25678ccbe94" translate="yes" xml:space="preserve">
          <source>We will use two datasets: Diabetes dataset which consists of 10 feature variables collected from diabetes patients with an aim to predict disease progression and California Housing dataset for which the target is the median house value for California districts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7968cd3ef765f8c808b9f8985bbceb6fcebbccfc" translate="yes" xml:space="preserve">
          <source>We will work with the diabetes dataset which consists of 10 features collected from a cohort of diabetes patients. The target is a quantitative measure of disease progression one year after baseline.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ab95440492dec088ab7d086a3622b86acadc7e7" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ll define a function that lets us visualize the behavior of each cross-validation object. We&amp;rsquo;ll perform 4 splits of the data. On each split, we&amp;rsquo;ll visualize the indices chosen for the training set (in blue) and the test set (in red).</source>
          <target state="translated">Мы определим функцию, которая позволит нам визуализировать поведение каждого объекта перекрестной проверки. Мы выполним 4 разделения данных. На каждом сплите мы визуализируем индексы, выбранные для обучающего набора (синим цветом) и тестового набора (красным).</target>
        </trans-unit>
        <trans-unit id="70c023ae490fc71ae664cdd80527ab708a5db4b9" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ve already encountered some parameters such as &lt;code&gt;use_idf&lt;/code&gt; in the &lt;code&gt;TfidfTransformer&lt;/code&gt;. Classifiers tend to have many parameters as well; e.g., &lt;code&gt;MultinomialNB&lt;/code&gt; includes a smoothing parameter &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;SGDClassifier&lt;/code&gt; has a penalty parameter &lt;code&gt;alpha&lt;/code&gt; and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python &lt;code&gt;help&lt;/code&gt; function to get a description of these).</source>
          <target state="translated">Мы уже встречались с некоторыми параметрами, такими как &lt;code&gt;use_idf&lt;/code&gt; , в &lt;code&gt;TfidfTransformer&lt;/code&gt; . Классификаторы также имеют много параметров; например, &lt;code&gt;MultinomialNB&lt;/code&gt; включает параметр сглаживания &lt;code&gt;alpha&lt;/code&gt; а &lt;code&gt;SGDClassifier&lt;/code&gt; имеет параметр штрафа &lt;code&gt;alpha&lt;/code&gt; и настраиваемые параметры потерь и штрафа в целевой функции (см. документацию модуля или используйте функцию &lt;code&gt;help&lt;/code&gt; Python, чтобы получить их описание).</target>
        </trans-unit>
        <trans-unit id="e255008aad692a93735d4b63680bd4a96fdd74f7" translate="yes" xml:space="preserve">
          <source>Weight function used in prediction. Possible values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96df76d7fa199e301349be570d5ef4d0bb6a7f3d" translate="yes" xml:space="preserve">
          <source>Weight given to each sample.</source>
          <target state="translated">Вес,присвоенный каждому образцу.</target>
        </trans-unit>
        <trans-unit id="a7a3ce3e7a16ef99378bfef64690454462da25e9" translate="yes" xml:space="preserve">
          <source>Weight matrix, where n_features in the number of visible units and n_components is the number of hidden units.</source>
          <target state="translated">Весовая матрица,где n_функции в количестве видимых единиц и n_компонент-количество скрытых единиц.</target>
        </trans-unit>
        <trans-unit id="77c7b393c2f516d7fd42969c3e5ce51aceb4c82c" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0664e46a183d0a2a2e3afcbc3b6c5ba30a9d4ef" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">Вес каждого образца, так что образец с весом не менее &lt;code&gt;min_samples&lt;/code&gt; сам по себе является образцом керна; образец с отрицательным весом может препятствовать тому, чтобы его eps-сосед был ядром. Обратите внимание, что веса являются абсолютными и по умолчанию равны 1.</target>
        </trans-unit>
        <trans-unit id="5cc536fd8cf249ec4c2e295665e0070f1b9cec67" translate="yes" xml:space="preserve">
          <source>Weight of precision in harmonic mean.</source>
          <target state="translated">Вес точности в гармоническом средстве.</target>
        </trans-unit>
        <trans-unit id="6cd90e03c276712f974984f65620519bcea49500" translate="yes" xml:space="preserve">
          <source>Weight vector(s).</source>
          <target state="translated">Весовой вектор(ы).</target>
        </trans-unit>
        <trans-unit id="ac0d2c9a738f9c54a5d208ddac8f22019ff9c627" translate="yes" xml:space="preserve">
          <source>Weight, Waist and Pulse.</source>
          <target state="translated">Вес,талия и пульс.</target>
        </trans-unit>
        <trans-unit id="c74e4e7c5caf95682fb65872b5814741f06c7fac" translate="yes" xml:space="preserve">
          <source>Weighted average</source>
          <target state="translated">Средневзвешенное значение</target>
        </trans-unit>
        <trans-unit id="39392047d0260b6fc1e042825fdae9116d630e28" translate="yes" xml:space="preserve">
          <source>Weighted average probability for each class per sample.</source>
          <target state="translated">Средневзвешенная вероятность для каждого класса на выборку.</target>
        </trans-unit>
        <trans-unit id="62deefeab258040887cdf6743a94e11a29168c6f" translate="yes" xml:space="preserve">
          <source>Weighted within-class covariance matrix. It corresponds to &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; where &lt;code&gt;C_k&lt;/code&gt; is the covariance matrix of the samples in class &lt;code&gt;k&lt;/code&gt;. The &lt;code&gt;C_k&lt;/code&gt; are estimated using the (potentially shrunk) biased estimator of covariance. If solver is &amp;lsquo;svd&amp;rsquo;, only exists when &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec852c96538aadaa4b0b959b23f492c546aedd45" translate="yes" xml:space="preserve">
          <source>Weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a702ae7f12a23bf0cde9786ae821e6b340d4991" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples (1. for unweighted).</source>
          <target state="translated">Веса,применяемые к отдельным образцам (1.для не взвешенных).</target>
        </trans-unit>
        <trans-unit id="0c68217fe30f051f7b997da07ad569653cfdb104" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed.</source>
          <target state="translated">Веса,применяемые к отдельным образцам.Если это не указано,то предполагается,что речь идет об однородных весах.</target>
        </trans-unit>
        <trans-unit id="3070fe087be2b6fbe15f65d4db644297c1112686" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified</source>
          <target state="translated">Веса,применяемые к отдельным образцам.Если это не указано,то предполагается,что речь идет об однородных весах.Эти веса будут умножены на class_weight (передаются через конструктор),если указан class_weight</target>
        </trans-unit>
        <trans-unit id="479d03c6533edea4de55367d8593a7974391f281" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b1d5826d4836f8e129b6346c9e9e60976aafee" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</source>
          <target state="translated">Веса,присвоенные признакам (коэффициенты в основной задаче).Это доступно только в случае линейного ядра.</target>
        </trans-unit>
        <trans-unit id="4b149f5e057b5bff95048ebeff46bfac0e7a368d" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features.</source>
          <target state="translated">Веса,присвоенные функциям.</target>
        </trans-unit>
        <trans-unit id="4094f309127a892ba2564eecc3f5264343e18998" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8064bf8d5d6b0c15f7ed813823cc0da43a8bc7e6" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Веса, связанные с классами в форме &lt;code&gt;{class_label: weight}&lt;/code&gt; . Если не указано иное, все классы должны иметь вес один.</target>
        </trans-unit>
        <trans-unit id="96f3238c530c2df09403ab213fee9515feb36c99" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">Веса, связанные с классами в форме &lt;code&gt;{class_label: weight}&lt;/code&gt; . Если не указано иное, все классы должны иметь вес один. Для задач с несколькими выходами список dicts может быть предоставлен в том же порядке, что и столбцы y.</target>
        </trans-unit>
        <trans-unit id="4a87f3dd4dfb432aa1a51752552e165c9cc23301" translate="yes" xml:space="preserve">
          <source>Weights associated with classes. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">Веса,связанные с классами.Если не указано,то все классы должны иметь вес один.</target>
        </trans-unit>
        <trans-unit id="4837ab63e8195a91fca82bbd82590df1bbe7fcc4" translate="yes" xml:space="preserve">
          <source>Weights for each estimator in the boosted ensemble.</source>
          <target state="translated">Веса для каждого оценщика в усиленном ансамбле.</target>
        </trans-unit>
        <trans-unit id="5f0089227653fec68913be1b7a199c273e750b44" translate="yes" xml:space="preserve">
          <source>Weights of training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55ddc90a49d39d4b40d722b720afa82441019829" translate="yes" xml:space="preserve">
          <source>Weights on each point of the regression. If None, weight is set to 1 (equal weights).</source>
          <target state="translated">Веса на каждой точке регрессии.Если None,то вес устанавливается равным 1 (равные веса).</target>
        </trans-unit>
        <trans-unit id="0946f675292deb36a2ff9f4a33806ccd9e9e1833" translate="yes" xml:space="preserve">
          <source>Weights. If set to None, all weights will be set to 1 (equal weights).</source>
          <target state="translated">Весы.Если установлено значение None,то все веса будут установлены на 1 (равные веса).</target>
        </trans-unit>
        <trans-unit id="c1f521c553b00dab458900dd1fb3f949a6ba99ab" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class.</source>
          <target state="translated">Хорошо откалиброванные классификаторы являются вероятностными классификаторами,для которых выход метода predict_proba может быть непосредственно интерпретирован как уровень доверия.Например,хорошо откалиброванный (бинарный)классификатор должен классифицировать выборки таким образом,чтобы среди выборок,для которых он дал значение предсказания_пробы близкое к 0.8,примерно 80% действительно принадлежали к положительному классу.</target>
        </trans-unit>
        <trans-unit id="8b629519ceaa09dd1767dbc350008d2ef28e9249" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db2509535d857954c618d97c17994b5d42574ae" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:</source>
          <target state="translated">Хорошо откалиброванные классификаторы являются вероятностными классификаторами,для которых выход метода predict_proba может быть непосредственно интерпретирован как уровень доверия.Например,хорошо откалиброванный (бинарный)классификатор должен классифицировать выборки таким образом,чтобы среди выборок,для которых он дал значение предсказания_пробы близкое к 0.8,примерно 80% действительно принадлежали к положительному классу.Следующий график сравнивает,насколько хорошо откалиброваны вероятностные прогнозы различных классификаторов:</target>
        </trans-unit>
        <trans-unit id="830bc34728ca0799f710b4883d58631c6dfded76" translate="yes" xml:space="preserve">
          <source>Wether to include meta-estimators that are somehow special and can not be default-constructed sensibly. These are currently Pipeline, FeatureUnion and GridSearchCV</source>
          <target state="translated">Не следует включать метаоценщики,которые каким-то образом являются особенными и не могут быть разумно построены по умолчанию.В настоящее время это &quot;Трубопровод&quot;,&quot;Характеристика&quot; и &quot;Сеть поиска&quot;.</target>
        </trans-unit>
        <trans-unit id="d4f157bc9962e4b0dc2a197ed14e50902555d749" translate="yes" xml:space="preserve">
          <source>What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?</source>
          <target state="translated">Каковы различные алгоритмы дерева решений и чем они отличаются друг от друга? Какой из них реализован в наукоёмких исследованиях?</target>
        </trans-unit>
        <trans-unit id="a1f5f9cd3d06157b8582b1ca4000a5bc395e765a" translate="yes" xml:space="preserve">
          <source>What this example shows us is the behavior &amp;ldquo;rich getting richer&amp;rdquo; of agglomerative clustering that tends to create uneven cluster sizes. This behavior is pronounced for the average linkage strategy, that ends up with a couple of singleton clusters, while in the case of single linkage we get a single central cluster with all other clusters being drawn from noise points around the fringes.</source>
          <target state="translated">Этот пример показывает нам поведение агломеративной кластеризации &amp;laquo;богатый становится еще богаче&amp;raquo;, которая имеет тенденцию создавать кластеры неравномерного размера. Такое поведение ярко выражено для стратегии усредненного связывания, которая заканчивается парой одноэлементных кластеров, в то время как в случае одиночного связывания мы получаем один центральный кластер, а все остальные кластеры выводятся из точек шума по краям.</target>
        </trans-unit>
        <trans-unit id="32580ac608fcdadc1c2050695a6c24cae1fcef1f" translate="yes" xml:space="preserve">
          <source>What we can see that:</source>
          <target state="translated">То,что мы видим:</target>
        </trans-unit>
        <trans-unit id="bd10ebd98b3e733be938ffeb72efbd3793589a2c" translate="yes" xml:space="preserve">
          <source>When &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; is applied on a &amp;ldquo;document-term&amp;rdquo; matrix, the matrix will be decomposed into a &amp;ldquo;topic-term&amp;rdquo; matrix and a &amp;ldquo;document-topic&amp;rdquo; matrix. While &amp;ldquo;topic-term&amp;rdquo; matrix is stored as &lt;code&gt;components_&lt;/code&gt; in the model, &amp;ldquo;document-topic&amp;rdquo; matrix can be calculated from &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">Когда &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt; применяется к матрице &amp;laquo;документ-термин&amp;raquo;, матрица будет разложена на матрицу &amp;laquo;тема-термин&amp;raquo; и матрица &amp;laquo;документ-тема&amp;raquo;. В то время как матрица &amp;laquo;тема-термин&amp;raquo; хранится в модели как &lt;code&gt;components_&lt;/code&gt; , матрица &amp;laquo;документ-тема&amp;raquo; может быть вычислена методом &lt;code&gt;transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0c7daae89d35601e80a373ec7022d580692d615d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;False&lt;/code&gt;, checks are evaluated when &lt;code&gt;check_estimator&lt;/code&gt; is called. When &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;check_estimator&lt;/code&gt; returns a generator that yields (estimator, check) tuples. The check is run by calling &lt;code&gt;check(estimator)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d35c02f0322e905eb57e225a27ca83f7c5f6cc47" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=0&lt;/code&gt;, columns which only contained missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">Когда &lt;code&gt;axis=0&lt;/code&gt; , столбцы, которые содержат только недостающие значения при &lt;code&gt;fit&lt;/code&gt; , отбрасываются при &lt;code&gt;transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cf98e7188203ecb0d30e3564b161d5393433799" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=1&lt;/code&gt;, an exception is raised if there are rows for which it is not possible to fill in the missing values (e.g., because they only contain missing values).</source>
          <target state="translated">Когда &lt;code&gt;axis=1&lt;/code&gt; , возникает исключение, если есть строки, для которых невозможно заполнить отсутствующие значения (например, потому что они содержат только отсутствующие значения).</target>
        </trans-unit>
        <trans-unit id="efffb9d033635c3e5b63e6f6f527201ab0e206e9" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;ccp_alpha&lt;/code&gt; is set to zero and keeping the other default parameters of &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. In this example, setting &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; maximizes the testing accuracy.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4bce6b6fbd4b9fe79bfc7468f7df9f938d3ce841" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;fit&lt;/code&gt; does not converge, &lt;code&gt;cluster_centers_&lt;/code&gt; becomes an empty array and all training samples will be labelled as &lt;code&gt;-1&lt;/code&gt;. In addition, &lt;code&gt;predict&lt;/code&gt; will then label every sample as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">Когда &lt;code&gt;fit&lt;/code&gt; не сходится, &lt;code&gt;cluster_centers_&lt;/code&gt; становится пустым массивом, и все обучающие выборки будут помечены как &lt;code&gt;-1&lt;/code&gt; . Кроме того, &lt;code&gt;predict&lt;/code&gt; , будет маркировать каждую выборку , как &lt;code&gt;-1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f7c77c5939a6b7b3a7ed9ce47827d49725522a57" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;gamma&lt;/code&gt; is very small, the model is too constrained and cannot capture the complexity or &amp;ldquo;shape&amp;rdquo; of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.</source>
          <target state="translated">Когда &lt;code&gt;gamma&lt;/code&gt; очень мала, модель слишком ограничена и не может уловить сложность или &amp;laquo;форму&amp;raquo; данных. Область влияния любого выбранного вектора поддержки будет включать в себя весь комплекс подготовки. Результирующая модель будет вести себя аналогично линейной модели с набором гиперплоскостей, разделяющих центры высокой плотности любой пары из двух классов.</target>
        </trans-unit>
        <trans-unit id="6579a89bba02e2aa5596acf0a356de3285b5831f" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;learning_method&lt;/code&gt; is &amp;lsquo;online&amp;rsquo;, use mini-batch update. Otherwise, use batch update.</source>
          <target state="translated">Когда &lt;code&gt;learning_method&lt;/code&gt; находится в режиме онлайн, используйте мини-пакетное обновление. В противном случае используйте пакетное обновление.</target>
        </trans-unit>
        <trans-unit id="1789662661fe322dc45828ec3c3eb62749643034" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;novelty&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; be aware that you must only use &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; on new unseen data and not on the training samples as this would lead to wrong results. The scores of abnormality of the training samples are always accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">Когда &lt;code&gt;novelty&lt;/code&gt; устанавливается в &lt;code&gt;True&lt;/code&gt; , иметь в виду , что вы должны использовать только &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; и &lt;code&gt;score_samples&lt;/code&gt; на новом невидимом данных , а не на учебных образцов , так как это привело бы к ошибочным результатам. Оценки отклонений обучающих выборок всегда доступны через атрибут &lt;code&gt;negative_outlier_factor_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6539967754248da8802fa11e92b0d1b2532b93b8" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;predict_proba&lt;/code&gt; is used by each estimator (i.e. most of the time for &lt;code&gt;stack_method='auto'&lt;/code&gt; or specifically for &lt;code&gt;stack_method='predict_proba'&lt;/code&gt;), The first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="380c86407d2b15e6e735d8a020999525510d4000" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold for each class. Otherwise, leave &lt;code&gt;random_state&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dba0ae97777bf9e3aca974d6ebb1591964b94b4e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f36c5dece71799d4edbabcfff5ea8ed2f825b4d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43540f9f914266a4b6caeeeeef53fc90c0648c6e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt; or &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, f-score returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ba4ca3b8ef57a04587026d0caa7a41ba81b60463" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision is undefined; When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall is undefined. In such cases, by default the metric will be set to 0, as will f-score, and &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; will be raised. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54bb2862f6516891f7056fa35777ac8bd097188" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70168d4d772dfaf9b58be440f7660f3adf7f21be" translate="yes" xml:space="preserve">
          <source>When False, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; both being sparse will yield sparse output. When True, output will always be a dense array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3329fe0cead2a208482794593628ff4dce53789" translate="yes" xml:space="preserve">
          <source>When False, either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; being sparse will yield sparse output. When True, output will always be an array.</source>
          <target state="translated">Если задано значение False, то либо &lt;code&gt;a&lt;/code&gt; , либо &lt;code&gt;b&lt;/code&gt; являются разреженными, результат будет разреженным. Когда True, вывод всегда будет массивом.</target>
        </trans-unit>
        <trans-unit id="1bb4bf21b8d21fdceb61000bf23d6624de5a3ca6" translate="yes" xml:space="preserve">
          <source>When False, only the predictions of estimators will be used as training data for &lt;code&gt;final_estimator&lt;/code&gt;. When True, the &lt;code&gt;final_estimator&lt;/code&gt; is trained on the predictions as well as the original training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0baad85c0e4d647371baa109869739d44cb0f600" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are divided by &lt;code&gt;n_samples&lt;/code&gt; times &lt;code&gt;components_&lt;/code&gt; to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Когда True (по умолчанию False), векторы &lt;code&gt;components_&lt;/code&gt; делятся на &lt;code&gt;n_samples&lt;/code&gt; , умноженные на &lt;code&gt;components_&lt;/code&gt; , чтобы гарантировать некоррелированные выходы с единичными покомпонентными дисперсиями.</target>
        </trans-unit>
        <trans-unit id="3eaa2881688032030c765cb871d4c787aff03fe7" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Когда True (по умолчанию False), векторы &lt;code&gt;components_&lt;/code&gt; умножаются на квадратный корень из n_samples, а затем делятся на сингулярные значения, чтобы гарантировать некоррелированные выходы с единичными покомпонентными дисперсиями.</target>
        </trans-unit>
        <trans-unit id="afb8087ad0f4a499dd14f72be9807792c351ecd8" translate="yes" xml:space="preserve">
          <source>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</source>
          <target state="translated">При значении True к матрице свойств применяется абсолютное значение до ее возврата.При использовании в сочетании с переменной alternate_sign=True это значительно снижает внутреннее свойство сохранения продукта.</target>
        </trans-unit>
        <trans-unit id="204d5c48d22bd9cd74d36182840231c3ecac4f55" translate="yes" xml:space="preserve">
          <source>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</source>
          <target state="translated">Когда параметр True,к характеристикам добавляется переменный знак для того,чтобы приблизительно сохранить внутренний продукт в хэш-памяти даже при небольших n_функциях.Такой подход аналогичен разреженной случайной проекции.</target>
        </trans-unit>
        <trans-unit id="e4283276989a341cb6ca6bb94564d0f53f92318b" translate="yes" xml:space="preserve">
          <source>When X and/or Y are CSR sparse matrices and they are not already in canonical format, this function modifies them in-place to make them canonical.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e08ec276d8bba6d4be8a6e677715ca1a35d4dd15" translate="yes" xml:space="preserve">
          <source>When a grouped cross-validator is used, the group labels are also passed on to the &lt;code&gt;split&lt;/code&gt; method of the cross-validator. The cross-validator uses them for grouping the samples while splitting the dataset into train/test set.</source>
          <target state="translated">Когда используется сгруппированный кросс-валидатор, групповые метки также передаются в метод &lt;code&gt;split&lt;/code&gt; кросс-валидатора. Кросс-валидатор использует их для группировки выборок при разделении набора данных на набор для обучения / тестирования.</target>
        </trans-unit>
        <trans-unit id="96fd8c38f0f9978d89774efb70a7d42aee5d30ee" translate="yes" xml:space="preserve">
          <source>When a specific number of neighbors is queried (using &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt;), the definition of &lt;code&gt;n_neighbors&lt;/code&gt; is ambiguous since it can either include each training point as its own neighbor, or exclude them. Neither choice is perfect, since including them leads to a different number of non-self neighbors during training and testing, while excluding them leads to a difference between &lt;code&gt;fit(X).transform(X)&lt;/code&gt; and &lt;code&gt;fit_transform(X)&lt;/code&gt;, which is against scikit-learn API. In &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;. However, for compatibility reasons with other estimators which use the other definition, one extra neighbor will be computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. To maximise compatibility with all estimators, a safe choice is to always include one extra neighbor in a custom nearest neighbors estimator, since unnecessary neighbors will be filtered by following estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c0f90cdc44694d62adb6ac9bccd5513d6bf148f" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, &lt;code&gt;fit&lt;/code&gt; will result in a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Когда все обучающие выборки имеют одинаковое сходство и одинаковые предпочтения, назначение центров кластеров и меток зависит от предпочтения. Если предпочтение меньше, чем сходство, &lt;code&gt;fit&lt;/code&gt; приведет к единственному центру кластера и метке &lt;code&gt;0&lt;/code&gt; для каждой выборки. В противном случае каждая обучающая выборка становится собственным центром кластера и получает уникальную метку.</target>
        </trans-unit>
        <trans-unit id="c440a8e563c9cc7b9752f14072284d81697bdfcd" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample will be returned. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">Когда все обучающие выборки имеют одинаковое сходство и одинаковые предпочтения, назначение центров кластеров и меток зависит от предпочтения. Если предпочтение меньше, чем сходство, будет возвращен единый центр кластера и метка &lt;code&gt;0&lt;/code&gt; для каждого образца. В противном случае каждая обучающая выборка становится собственным центром кластера и получает уникальную метку.</target>
        </trans-unit>
        <trans-unit id="2494d11b03713922afdad3fa1bc52bb7064577b4" translate="yes" xml:space="preserve">
          <source>When alpha is very large, the regularization effect dominates the squared loss function and the coefficients tend to zero. At the end of the path, as alpha tends toward zero and the solution tends towards the ordinary least squares, coefficients exhibit big oscillations. In practise it is necessary to tune alpha in such a way that a balance is maintained between both.</source>
          <target state="translated">Когда альфа очень большой,эффект регуляризации доминирует над квадратной функцией потерь,а коэффициенты стремятся к нулю.В конце пути,когда альфа стремится к нулю,а решение стремится к обычным наименьшим квадратам,коэффициенты проявляют большие колебания.На практике необходимо настраивать альфа так,чтобы поддерживался баланс между ними.</target>
        </trans-unit>
        <trans-unit id="e93a4fdf68d407dc869190eca6cd7dfaf57ad986" translate="yes" xml:space="preserve">
          <source>When applying LOF for outlier detection, there are no &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods but only a &lt;code&gt;fit_predict&lt;/code&gt; method. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute. Note that &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; can be used on new unseen data when LOF is applied for novelty detection, i.e. when the &lt;code&gt;novelty&lt;/code&gt; parameter is set to &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;#novelty-with-lof&quot;&gt;Novelty detection with Local Outlier Factor&lt;/a&gt;.</source>
          <target state="translated">При применении LOF для обнаружения выбросов не &lt;code&gt;score_samples&lt;/code&gt; методы &lt;code&gt;predict&lt;/code&gt; , функция &lt;code&gt;decision_function&lt;/code&gt; и оценка_выборки, а есть только метод &lt;code&gt;fit_predict&lt;/code&gt; . Оценки отклонений от нормы обучающих выборок доступны через атрибут &lt;code&gt;negative_outlier_factor_&lt;/code&gt; . Обратите внимание , что &lt;code&gt;predict&lt;/code&gt; , &lt;code&gt;decision_function&lt;/code&gt; и &lt;code&gt;score_samples&lt;/code&gt; могут быть использованы на новых невидимых данных , когда LOF применяется для детекции новизны, то есть , когда &lt;code&gt;novelty&lt;/code&gt; параметр установлен в значение &lt;code&gt;True&lt;/code&gt; . См. &lt;a href=&quot;#novelty-with-lof&quot;&gt;Обнаружение новинок с помощью локального выброса&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2ec6d5a6d0d8178f2ec5cc1ea59ce167ddd0a98a" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="869141a5ff3e1444543cdaec8c9968684d76b66e" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">При построении словаря игнорируйте термины,которые имеют частоту документа строго выше заданного порога (стоп-слова по корпусу).Если параметр float,то он представляет собой пропорцию документов,целочисленные абсолютные числа.Этот параметр игнорируется,если в словаре нет None.</target>
        </trans-unit>
        <trans-unit id="d83f4236f3f25a9891417b446059c6cca3f6ec76" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f13ad80586b74ad6fdc521fde036c051cf6e0e7" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">При построении словаря игнорируйте термины,которые имеют частоту документа строго ниже заданного порога.В литературе это значение также называется отсечением.Если float,то параметр представляет собой пропорцию документов,целочисленные абсолютные числа.Этот параметр игнорируется,если словарь не None.</target>
        </trans-unit>
        <trans-unit id="757013c910e6b4628ced11d689b0016d8c17e540" translate="yes" xml:space="preserve">
          <source>When calculating class-wise multilabel confusion matrix \(C\), the count of true negatives for class \(i\) is \(C_{i,0,0}\), false negatives is \(C_{i,1,0}\), true positives is \(C_{i,1,1}\) and false positives is \(C_{i,0,1}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ed788b8f95069d89dcb15b1bea5b5e7da9a9648" translate="yes" xml:space="preserve">
          <source>When calling &lt;code&gt;fit&lt;/code&gt;, an affinity matrix is constructed using either kernel function such the Gaussian (aka RBF) kernel of the euclidean distanced &lt;code&gt;d(X, X)&lt;/code&gt;:</source>
          <target state="translated">При вызове &lt;code&gt;fit&lt;/code&gt; строится матрица аффинности с использованием любой функции ядра, такой как гауссово (также известное как RBF) ядро ​​евклидова удаленного &lt;code&gt;d(X, X)&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="5c5941b79e3bd733fe2a806a66f459a87c19af32" translate="yes" xml:space="preserve">
          <source>When dealing with a cleaned dataset, the preprocessing can be automatic by using the data types of the column to decide whether to treat a column as a numerical or categorical feature. &lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt;&lt;/a&gt; gives this possibility. First, let&amp;rsquo;s only select a subset of columns to simplify our example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9c4333516559f145c3dcae1d1fd9f5e0da891d" translate="yes" xml:space="preserve">
          <source>When doing classification in scikit-learn, &lt;code&gt;y&lt;/code&gt; is a vector of integers or strings.</source>
          <target state="translated">При выполнении классификации в scikit-learn &lt;code&gt;y&lt;/code&gt; - это вектор целых чисел или строк.</target>
        </trans-unit>
        <trans-unit id="fb08dbb1ad477236e66b72b0cef9bccfd1ceec61" translate="yes" xml:space="preserve">
          <source>When doing supervised learning, a simple sanity check consists of comparing one&amp;rsquo;s estimator against simple rules of thumb. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt; implements several such simple strategies for classification:</source>
          <target state="translated">При обучении с учителем простая проверка работоспособности состоит из сравнения своей оценки с простыми практическими правилами. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt; реализует несколько таких простых стратегий классификации:</target>
        </trans-unit>
        <trans-unit id="3bf9748662d1dbe365a15ba24b002d016f11408b" translate="yes" xml:space="preserve">
          <source>When evaluating different settings (&amp;ldquo;hyperparameters&amp;rdquo;) for estimators, such as the &lt;code&gt;C&lt;/code&gt; setting that must be manually set for an SVM, there is still a risk of overfitting &lt;em&gt;on the test set&lt;/em&gt; because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can &amp;ldquo;leak&amp;rdquo; into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called &amp;ldquo;validation set&amp;rdquo;: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.</source>
          <target state="translated">При оценке различных настроек (&amp;laquo;гиперпараметров&amp;raquo;) для оценщиков, таких как настройка &lt;code&gt;C&lt;/code&gt; , которая должна быть установлена ​​вручную для SVM, все еще существует риск переобучения &lt;em&gt;на тестовом наборе,&lt;/em&gt; поскольку параметры можно настраивать до тех пор, пока оценщик не будет работать оптимально. Таким образом, знания о наборе тестов могут &amp;laquo;просочиться&amp;raquo; в модель, а показатели оценки больше не будут сообщать о производительности обобщения. Чтобы решить эту проблему, еще одна часть набора данных может быть представлена ​​как так называемый &amp;laquo;набор для проверки&amp;raquo;: обучение продолжается на обучающем наборе, после чего выполняется оценка на проверочном наборе, и когда эксперимент кажется успешным. , окончательную оценку можно провести на тестовом наборе.</target>
        </trans-unit>
        <trans-unit id="b6d52e3adfb55f9048c5ef57545d77d640ae7db4" translate="yes" xml:space="preserve">
          <source>When evaluating text classifiers on the 20 Newsgroups data, you should strip newsgroup-related metadata. In scikit-learn, you can do this by setting &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt;. The F-score will be lower because it is more realistic.</source>
          <target state="translated">При оценке текстовых классификаторов для данных 20 групп новостей следует удалить метаданные, относящиеся к группам новостей. В scikit-learn вы можете сделать это, установив &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt; . F-оценка будет ниже, потому что это более реалистично.</target>
        </trans-unit>
        <trans-unit id="b44ace677df67ec762b5f7d213266d4181953b1c" translate="yes" xml:space="preserve">
          <source>When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a &lt;strong&gt;development set&lt;/strong&gt; (to be fed to the &lt;code&gt;GridSearchCV&lt;/code&gt; instance) and an &lt;strong&gt;evaluation set&lt;/strong&gt; to compute performance metrics.</source>
          <target state="translated">При оценке полученной модели важно делать это на удерживаемых выборках, которые не были замечены в процессе поиска по сетке: рекомендуется разделить данные на &lt;strong&gt;набор&lt;/strong&gt; для &lt;strong&gt;разработки&lt;/strong&gt; (для &lt;code&gt;GridSearchCV&lt;/code&gt; экземпляр GridSearchCV ) и &lt;strong&gt;набор для оценки.&lt;/strong&gt; для вычисления показателей производительности.</target>
        </trans-unit>
        <trans-unit id="1a86b5b9ee94c593acad1b7968fd00ab3b487df9" translate="yes" xml:space="preserve">
          <source>When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature &amp;ldquo;f&amp;rdquo; that can take on the values &amp;ldquo;ham&amp;rdquo; and &amp;ldquo;spam&amp;rdquo; will become two features in the output, one signifying &amp;ldquo;f=ham&amp;rdquo;, the other &amp;ldquo;f=spam&amp;rdquo;.</source>
          <target state="translated">Когда значения функции являются строками, этот преобразователь будет выполнять двоичное кодирование по принципу &amp;laquo;одноразовое&amp;raquo; (также известное как &amp;laquo;один из K&amp;raquo;): для каждого из возможных строковых значений, которые может принимать функция, создается одна функция с логическим значением. Например, функция &amp;laquo;f&amp;raquo;, которая может принимать значения &amp;laquo;ветчина&amp;raquo; и &amp;laquo;спам&amp;raquo;, станет двумя функциями на выходе, одна из которых будет означать &amp;laquo;f = ветчина&amp;raquo;, а другая &amp;laquo;f = спам&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="81d685e408d1bc940e50f235a77cb7283ea2909d" translate="yes" xml:space="preserve">
          <source>When features are collinear, permutating one feature will have little effect on the models performance because it can get the same information from a correlated feature. One way to handle multicollinear features is by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster. First, we plot a heatmap of the correlated features:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3d8c3576d6baaf6f77dc4e34223e91a48a8c662" translate="yes" xml:space="preserve">
          <source>When fitting a model to a matrix X_train and evaluating it against a matrix X_test, it is essential that X_train and X_test have the same number of features (X_train.shape[1] == X_test.shape[1]). This may not be the case if you load the files individually with load_svmlight_file.</source>
          <target state="translated">При подгонке модели к матрице X_train и ее оценке в сравнении с матрицей X_test необходимо,чтобы X_train и X_test имели одинаковое количество признаков (X_train.shape[1]==X_test.shape[1]).Этого может не произойти,если загружать файлы по отдельности файлом load_svmlight_file.</target>
        </trans-unit>
        <trans-unit id="618912ddd6add9bc398f8cf8343e255bb5f0ac59" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</source>
          <target state="translated">В случае сомнений используйте &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4150d19b2bd7fadd0941f6ca06455157d317e492" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ebc317e66e94c9c3ce7d1b975021eefa97b880b" translate="yes" xml:space="preserve">
          <source>When individual estimators are fast to train or predict using &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; can result in slower performance due to the overhead of spawning processes.</source>
          <target state="translated">Когда отдельные оценщики быстро обучаются или предсказывают, используя &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; ,это может привести к снижению производительности из-за накладных расходов на процессы порождения.</target>
        </trans-unit>
        <trans-unit id="5223d409a8ec7650bd8559a52e22ddb32a950ada" translate="yes" xml:space="preserve">
          <source>When loss=&amp;rdquo;modified_huber&amp;rdquo;, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.</source>
          <target state="translated">Когда loss = &quot;modified_huber&quot;, оценки вероятности могут быть точными нулями и единицами, поэтому логарифмирование невозможно.</target>
        </trans-unit>
        <trans-unit id="3169e6d4a043a16249e2b124b1d248f9aac1b1e2" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics, with \(K\) corresponding to &lt;code&gt;n_components&lt;/code&gt; in the API:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63fb46936ec9f0c71e69b897d1f9d91941d422e3" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics:</source>
          <target state="translated">При моделировании текстовой корпорации модель предполагает следующий генеративный процесс для корпуса с документами \(D\)и темами \(K\):</target>
        </trans-unit>
        <trans-unit id="744347c999c68da3080dd50ae1b985e4b97e385e" translate="yes" xml:space="preserve">
          <source>When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.</source>
          <target state="translated">При недостаточном количестве точек на смесь оценка ковариационных матриц становится затруднительной,а алгоритм,как известно,расходится и находит решения с бесконечной вероятностью,если только ковариарии искусственно не легализуются.</target>
        </trans-unit>
        <trans-unit id="e24f09e860711fd3a63a21415134601f90e4efc0" translate="yes" xml:space="preserve">
          <source>When parametrized by error using the parameter &lt;code&gt;tol&lt;/code&gt;: argmin ||gamma||_0 subject to ||y - Xgamma||^2 &amp;lt;= tol</source>
          <target state="translated">При параметризации по ошибке с использованием параметра &lt;code&gt;tol&lt;/code&gt; : argmin || gamma || _0 при условии || y - Xgamma || ^ 2 &amp;lt;= tol</target>
        </trans-unit>
        <trans-unit id="70b3334d846e26366c45a04fb1a4a39af8e3ec45" translate="yes" xml:space="preserve">
          <source>When parametrized by the number of non-zero coefficients using &lt;code&gt;n_nonzero_coefs&lt;/code&gt;: argmin ||y - Xgamma||^2 subject to ||gamma||_0 &amp;lt;= n_{nonzero coefs}</source>
          <target state="translated">При параметризации числом ненулевых коэффициентов с использованием &lt;code&gt;n_nonzero_coefs&lt;/code&gt; : argmin || y - Xgamma || ^ 2 при условии || gamma || _0 &amp;lt;= n_ {ненулевые коэффициенты}</target>
        </trans-unit>
        <trans-unit id="10d326cee514d3b967129b254954126bcda90793" translate="yes" xml:space="preserve">
          <source>When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier.</source>
          <target state="translated">При выполнении классификации часто хочется предсказать не только метку класса,но и связанную с ней вероятность.Эта вероятность дает некоторую уверенность в предсказании.Этот пример демонстрирует,как показать,насколько хорошо откалиброваны предсказанные вероятности и как откалибровать некалиброванный классификатор.</target>
        </trans-unit>
        <trans-unit id="533cc79868c5585705042f97bd64dbf9b1c6133f" translate="yes" xml:space="preserve">
          <source>When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.</source>
          <target state="translated">При выполнении классификации часто требуется не только предсказать метку класса,но и получить вероятность соответствующей метки.Эта вероятность дает вам некоторую уверенность в предсказании.Некоторые модели могут дать вам плохие оценки вероятности класса,а некоторые даже не поддерживают предсказание вероятности.Модуль калибровки позволяет Вам лучше калибровать вероятности данной модели или добавить поддержку прогноза вероятности.</target>
        </trans-unit>
        <trans-unit id="ede14543224daf4bd7da97ebebdbcb4bdb8fe514" translate="yes" xml:space="preserve">
          <source>When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&amp;rsquo;s score (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;).</source>
          <target state="translated">При выполнении классификации часто требуется предсказать не только метку класса, но и соответствующую вероятность. Эта вероятность дает вам некоторую уверенность в прогнозе. Однако не все классификаторы обеспечивают хорошо откалиброванные вероятности: некоторые из них слишком уверены, а другие - недостаточно. Таким образом, в качестве постобработки часто желательна отдельная калибровка предсказанных вероятностей. Этот пример иллюстрирует два разных метода этой калибровки и оценивает качество возвращаемых вероятностей с использованием оценки Бриера (см. &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;Https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="47397daaf8d579706c38eeae4f614a41b7464779" translate="yes" xml:space="preserve">
          <source>When performing cross-validation for the &lt;code&gt;power&lt;/code&gt; parameter of &lt;code&gt;TweedieRegressor&lt;/code&gt;, it is advisable to specify an explicit &lt;code&gt;scoring&lt;/code&gt; function, because the default scorer &lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt;&lt;code&gt;TweedieRegressor.score&lt;/code&gt;&lt;/a&gt; is a function of &lt;code&gt;power&lt;/code&gt; itself.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e99cb78745b2020137c83400ee3d8d22f37293c0" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.</source>
          <target state="translated">При предварительном вычислении расстояний более точным с числовой точки зрения является выравнивание данных в первую очередь.Если copy_x-True (по умолчанию),то исходные данные не изменяются,что обеспечивает С-сопряжение X.Если False,то исходные данные модифицируются и возвращаются обратно до того,как функция вернётся,но небольшие числовые различия могут быть введены путём вычитания и последующего сложения среднего значения данных,в этом случае также не будет обеспечена С-сопряжённость данных,что может привести к значительному замедлению работы.</target>
        </trans-unit>
        <trans-unit id="785dafae54d31c04c4a974bc00da768d9cfae46f" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="55ac178846c6596090a6f8d0133ba62fcd26aebb" translate="yes" xml:space="preserve">
          <source>When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.</source>
          <target state="translated">При предсказании истинные метки будут недоступны.Вместо этого предсказания каждой модели передаются последующим моделям в цепочке для использования в качестве признаков.</target>
        </trans-unit>
        <trans-unit id="441463f4c28b96b4ca0739417ce251a6d1637336" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;.</source>
          <target state="translated">Когда случайные подмножества набора данных рисуются как случайные подмножества признаков, этот метод известен как случайные подпространства &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ed3a388f4c5d9809937b1b2fceecd5d5d41437fc" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;.</source>
          <target state="translated">Когда случайные подмножества набора данных рисуются как случайные подмножества выборок, этот алгоритм известен как Вставка &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f494cf947867cf3181ff2c5eaa996adc8d0ce783" translate="yes" xml:space="preserve">
          <source>When requesting a dataset with a name that is in mock_datasets, this object creates a fake dataset in a StringIO object and returns it. Otherwise, it raises an HTTPError.</source>
          <target state="translated">При запросе набора данных с именем,которое находится в mock_datasets,этот объект создает поддельный набор данных в StringIO-объекте и возвращает его.В противном случае он вызывает HTTPError.</target>
        </trans-unit>
        <trans-unit id="f6f6725ccb736a3cf59a107563029dd1f92b7eb9" translate="yes" xml:space="preserve">
          <source>When sample_weight is provided, the selected hyperparameter may depend on whether we use generalized cross-validation (cv=None or cv=&amp;rsquo;auto&amp;rsquo;) or another form of cross-validation, because only generalized cross-validation takes the sample weights into account when computing the validation score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d66c9681351cfa02a7cc3145d8e8cc7e7a3877b3" translate="yes" xml:space="preserve">
          <source>When samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;.</source>
          <target state="translated">Когда образцы &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;отбираются&lt;/a&gt; с заменой, этот метод известен как Bagging [B1996] .</target>
        </trans-unit>
        <trans-unit id="b67d588266cee585b7c0608db5b116728771921f" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt;, i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Когда self.fit_intercept имеет значение True, вектор экземпляра x становится &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt; , т.е. &amp;laquo;синтетический&amp;raquo; объект с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится intercept_scaling * синтетический вес признака. Примечание! синтетический вес признака подлежит регуляризации l1 / l2, как и все другие признаки. Чтобы уменьшить влияние регуляризации на вес синтетических признаков (и, следовательно, на перехват), необходимо увеличить intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="339fba0d20ce2052ad9daa9e3c6cc55589d832bc" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">Когда self.fit_intercept имеет значение True, вектор экземпляра x становится [x, self.intercept_scaling], т.е. &amp;laquo;синтетический&amp;raquo; объект с постоянным значением, равным intercept_scaling, добавляется к вектору экземпляра. Перехват становится intercept_scaling * синтетический вес признака. Примечание! синтетический вес признака подлежит регуляризации l1 / l2, как и все другие признаки. Чтобы уменьшить влияние регуляризации на вес синтетических признаков (и, следовательно, на перехват), необходимо увеличить intercept_scaling.</target>
        </trans-unit>
        <trans-unit id="ad06c0ce7c1fc91387cf888768a953ddfc43c4b6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;False&lt;/code&gt;, ignore special characters for PostScript compatibility.</source>
          <target state="translated">Если установлено значение &lt;code&gt;False&lt;/code&gt; , игнорируйте специальные символы для совместимости с PostScript.</target>
        </trans-unit>
        <trans-unit id="d1b93df55570608a785000a0ebdde0c1a478b680" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, change the display of &amp;lsquo;values&amp;rsquo; and/or &amp;lsquo;samples&amp;rsquo; to be proportions and percentages respectively.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , измените отображение &amp;laquo;значений&amp;raquo; и / или &amp;laquo;образцов&amp;raquo; на пропорции и проценты соответственно.</target>
        </trans-unit>
        <trans-unit id="3843d20a53a1ef3b59460be1fa7cb77d3c2ee1f6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw all leaf nodes at the bottom of the tree.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , нарисуйте все листовые узлы в нижней части дерева.</target>
        </trans-unit>
        <trans-unit id="1dd8441b2d9ea649f69d55eb070005c43dff3ea1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , рисовать блоки узлов с закругленными углами и использовать шрифты Helvetica вместо Times-Roman.</target>
        </trans-unit>
        <trans-unit id="37e5e7c90dcc2881b20280bd58a636a2601aa0c6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, forces the coefficients to be positive.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , коэффициенты будут положительными.</target>
        </trans-unit>
        <trans-unit id="a556178389cf10e9a8f97ab94b5cbc137168d877" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, orient tree left to right rather than top-down.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , ориентировать дерево слева направо, а не сверху вниз.</target>
        </trans-unit>
        <trans-unit id="db2d0a81092e78238cdb916143e482a964d5a789" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , закрашивайте узлы, чтобы указать класс большинства для классификации, крайние значения для регрессии или чистоту узла для множественного вывода.</target>
        </trans-unit>
        <trans-unit id="387704ecb7f5fc4e8c941c08ae18f72e58104663" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы подогнать и добавить больше оценщиков в ансамбль, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="42b61336d9e93453cd22782ddee266aae253af56" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e08becb1d7f3dabb059c61e3163efbfc5e9d6bd5" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы подогнать и добавить больше оценщиков в ансамбль, в противном случае просто поместите весь новый лес. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4ca94f8cc22fb05a614eaf938146928a9cad01e1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b034ef6cd843a9c71bbf2f16594203b3e34675bd" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ddb18c96e1fca0312edb00f224f2db160c80a30" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="06f93e3e87621fa903e7cdd20131cea02e9878ba" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="303e5cc9af6656c2592224b864d50a2e7f014b54" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the ID number on each node.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , показывать идентификационный номер на каждом узле.</target>
        </trans-unit>
        <trans-unit id="d19057d05dc608969ed0862b9054b2defc3fb482" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the impurity at each node.</source>
          <target state="translated">Если установлено значение &lt;code&gt;True&lt;/code&gt; , показывать примеси в каждом узле.</target>
        </trans-unit>
        <trans-unit id="ee8efaddcdb7929ada76230c032dd700897cd47f" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights accross all updates and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches &lt;code&gt;average&lt;/code&gt;. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0199409f1eeb1aa7581c717d5c23e182af166761" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">Если установлено значение True, вычисляет усредненные веса SGD и сохраняет результат в &lt;code&gt;coef_&lt;/code&gt; . Если установлено значение int больше 1, усреднение начнется, когда общее количество наблюдаемых выборок достигнет среднего. Таким образом, &lt;code&gt;average=10&lt;/code&gt; начнется усреднение после просмотра 10 образцов.</target>
        </trans-unit>
        <trans-unit id="19c4ca669b90d48df2f3aa161b89103ea08c0cbd" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</source>
          <target state="translated">Если установлено значение True, вычисляет усредненные веса SGD и сохраняет результат в &lt;code&gt;coef_&lt;/code&gt; . Если установлено значение int больше 1, усреднение начнется, когда общее количество наблюдаемых выборок достигнет среднего. Таким образом, среднее значение = 10 начнется усреднение после просмотра 10 образцов.</target>
        </trans-unit>
        <trans-unit id="e60b70114bd43f63c876204c608aaaaca2e5c6d2" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение из предыдущего вызова, чтобы подогнать и добавить больше оценщиков к ансамблю, в противном случае просто подгоните полностью новый ансамбль. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="fb1187119affc46cd36d1e1403f76ef562249b84" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0615ecfccfe9c12eea86adfdd92570d0b3a6f9cf" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="b9ddbc0f60da434a4d403c500c89b585a3aeef7d" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="869683b3c71be56286e995de01f21c989fc735d8" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Если установлено значение True, повторно используйте решение предыдущего вызова, чтобы оно соответствовало инициализации, в противном случае просто удалите предыдущее решение. Бесполезен для либлинеарного решателя. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="90df9a75b07a1010dc74b460f30a26d769910e81" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61362ce0a02977970071e88e9dc71d066251fcde" translate="yes" xml:space="preserve">
          <source>When specifying multiple metrics, the &lt;code&gt;refit&lt;/code&gt; parameter must be set to the metric (string) for which the &lt;code&gt;best_params_&lt;/code&gt; will be found and used to build the &lt;code&gt;best_estimator_&lt;/code&gt; on the whole dataset. If the search should not be refit, set &lt;code&gt;refit=False&lt;/code&gt;. Leaving refit to the default value &lt;code&gt;None&lt;/code&gt; will result in an error when using multiple metrics.</source>
          <target state="translated">При указании нескольких метрик параметр &lt;code&gt;refit&lt;/code&gt; должен быть установлен на метрику (строку), для которой будет найден &lt;code&gt;best_params_&lt;/code&gt; и будет использоваться для построения &lt;code&gt;best_estimator_&lt;/code&gt; для всего набора данных. Если поиск не должен повторяться, установите &lt;code&gt;refit=False&lt;/code&gt; . Если оставить для параметра refit значение по умолчанию &lt;code&gt;None&lt;/code&gt; , при использовании нескольких показателей возникнет ошибка.</target>
        </trans-unit>
        <trans-unit id="8303fa1cd1689a65bba6fc9b59c3502d4f370e6f" translate="yes" xml:space="preserve">
          <source>When starting from the default values (alpha_init = 1.90, lambda_init = 1.), the bias of the resulting curve is large, and the variance is small. So, lambda_init should be relatively small (1.e-3) so as to reduce the bias.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="765386eefc1dd2e9ed203024ee007c99e07f6618" translate="yes" xml:space="preserve">
          <source>When strategy == &amp;ldquo;constant&amp;rdquo;, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and &amp;ldquo;missing_value&amp;rdquo; for strings or object data types.</source>
          <target state="translated">Когда стратегия == &amp;laquo;константа&amp;raquo;, fill_value используется для замены всех вхождений missing_values. Если оставить значение по умолчанию, fill_value будет равно 0 при подстановке числовых данных и &amp;laquo;missing_value&amp;raquo; для строк или типов данных объекта.</target>
        </trans-unit>
        <trans-unit id="234c27f3e17ce7a8cf496679483a69e65bcabb05" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;Pipeline&lt;/code&gt; is printed out in a jupyter notebook an HTML representation of the estimator is displayed as follows:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3973bbeeefced2bd7eb8aaa05fcc0fadc5e600b" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;cv&lt;/code&gt; argument is an integer, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; uses the &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; strategies by default, the latter being used if the estimator derives from &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt;&lt;code&gt;ClassifierMixin&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Если аргумент &lt;code&gt;cv&lt;/code&gt; является целым числом, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; по умолчанию использует стратегии &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt; , причем последняя используется, если оценщик является производным от &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt; &lt;code&gt;ClassifierMixin&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c7d238875ff93bafa2620f7a2d7675b937a2183b" translate="yes" xml:space="preserve">
          <source>When the algorithm does not converge, it returns an empty array as &lt;code&gt;cluster_center_indices&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; as label for each training sample.</source>
          <target state="translated">Когда алгоритм не сходится, он возвращает пустой массив как &lt;code&gt;cluster_center_indices&lt;/code&gt; и &lt;code&gt;-1&lt;/code&gt; как метку для каждой обучающей выборки.</target>
        </trans-unit>
        <trans-unit id="b4fdfb364ee084bf57bd04a0f7c8f0c41739edf4" translate="yes" xml:space="preserve">
          <source>When the data is not initially in the &lt;code&gt;(n_samples, n_features)&lt;/code&gt; shape, it needs to be preprocessed in order to be used by scikit-learn.</source>
          <target state="translated">Когда данные изначально не &lt;code&gt;(n_samples, n_features)&lt;/code&gt; форму (n_samples, n_features) , их необходимо предварительно обработать, чтобы использовать scikit-learn.</target>
        </trans-unit>
        <trans-unit id="4b1639b675f158aa2d42c71150242e159f59e266" translate="yes" xml:space="preserve">
          <source>When the missingness pattern is predictive, the splits can be done on whether the feature value is missing or not:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90e4401cde0f238342524a25385b7071cd57b4a0" translate="yes" xml:space="preserve">
          <source>When the underlying implementation uses joblib, the number of workers (threads or processes) that are spawned in parallel can be controlled via the &lt;code&gt;n_jobs&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aaeec02a52e8579f06c37808c9e18fa50d637a08" translate="yes" xml:space="preserve">
          <source>When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground true labels. The maximum value is always +1.</source>
          <target state="translated">При наличии более двух меток значение ЦУД больше не будет находиться в диапазоне от -1 до +1.Вместо этого минимальное значение будет находиться где-то между -1 и 0 в зависимости от количества и распределения заземленных истинных меток.Максимальное значение всегда равно +1.</target>
        </trans-unit>
        <trans-unit id="5c69ffd1e0dc71befa67c00726bc6370582b5df5" translate="yes" xml:space="preserve">
          <source>When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.</source>
          <target state="translated">При отсутствии корреляции между выходами очень простой способ решения такой задачи-построить n независимых моделей,т.е.по одной для каждой из выходов,а затем использовать эти модели для независимого предсказания каждой из n выходов.Однако,поскольку вполне вероятно,что выходные значения,связанные с одним и тем же входом,сами по себе коррелируют,зачастую лучший способ-построить единую модель,способную предсказывать одновременно все n выходов.Во-первых,это требует меньшего времени на обучение,так как строится только один оценщик.Во-вторых,точность обобщения результирующей оценки часто может быть увеличена.</target>
        </trans-unit>
        <trans-unit id="ebcc7b732996f47559f9fb2cca7527f873584d5f" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikit-learn and joblib need to be compatible. Currently, joblib 0.11+ is supported. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c7fa59e2b8c1ce3abb542d1d5f76caddd1816f1" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikt-learn and joblib need to be compatible. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">Когда эта переменная окружения установлена в ненулевое значение,scikit-learn использует joblib сайта,а не его обожествленную версию.Следовательно,для работы scikit-learn должен быть установлен joblib.Обратите внимание,что использование библиотеки joblib сайта на ваш страх и риск:версии scikt-learn и joblib должны быть совместимы.Кроме того,дампов с joblib.Memory может быть несовместимым,и вы можете потерять некоторые кэши и будете вынуждены перезагружать некоторые наборы данных.</target>
        </trans-unit>
        <trans-unit id="743d4762d28a3d61488ddf12d10bce762b152657" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, the tests that need network access are skipped.</source>
          <target state="translated">Когда эта переменная окружения установлена на ненулевое значение,тесты,которым необходим доступ к сети,пропускаются.</target>
        </trans-unit>
        <trans-unit id="beb3490e0a85d3bcf9f4888cb75a6b1ea2e1e6a8" translate="yes" xml:space="preserve">
          <source>When training an SVM with the &lt;em&gt;Radial Basis Function&lt;/em&gt; (RBF) kernel, two parameters must be considered: &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. The parameter &lt;code&gt;C&lt;/code&gt;, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low &lt;code&gt;C&lt;/code&gt; makes the decision surface smooth, while a high &lt;code&gt;C&lt;/code&gt; aims at classifying all training examples correctly. &lt;code&gt;gamma&lt;/code&gt; defines how much influence a single training example has. The larger &lt;code&gt;gamma&lt;/code&gt; is, the closer other examples must be to be affected.</source>
          <target state="translated">При обучении SVM с помощью ядра &lt;em&gt;радиальной базовой функции&lt;/em&gt; (RBF) необходимо учитывать два параметра: &lt;code&gt;C&lt;/code&gt; и &lt;code&gt;gamma&lt;/code&gt; . Параметр &lt;code&gt;C&lt;/code&gt; , общий для всех ядер SVM, сводит на нет неправильную классификацию обучающих примеров и простоту поверхности принятия решений. Низкий &lt;code&gt;C&lt;/code&gt; делает поверхность принятия решения гладкой, а высокий &lt;code&gt;C&lt;/code&gt; направлен на правильную классификацию всех обучающих примеров. &lt;code&gt;gamma&lt;/code&gt; определяет, какое влияние имеет один обучающий пример. Чем больше &lt;code&gt;gamma&lt;/code&gt; , тем ближе другие примеры должны быть затронуты.</target>
        </trans-unit>
        <trans-unit id="4f5d7a3d8a7ab119798fbec5ead8471db219e63d" translate="yes" xml:space="preserve">
          <source>When true, the result is adjusted for chance, so that random performance would score 0, and perfect performance scores 1.</source>
          <target state="translated">Если это так,то результат корректируется на случайность,так что случайное исполнение набрало бы 0 баллов,а идеальное исполнение-1.</target>
        </trans-unit>
        <trans-unit id="7dbd1175230450ef2444fe8de9e5557001f2473c" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt;), this transformation is known as &lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a756308318fb23f07be0498c8c83a0d088f9279a" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;code&gt;CountVectorizer&lt;/code&gt; or &lt;code&gt;TfidfVectorizer&lt;/code&gt;), this transformation is known as &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">Когда усеченный SVD применяется к матрицам терминов-документов (возвращаемых &lt;code&gt;CountVectorizer&lt;/code&gt; или &lt;code&gt;TfidfVectorizer&lt;/code&gt; ), это преобразование известно как &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;латентный семантический анализ&lt;/a&gt; (LSA), поскольку оно преобразует такие матрицы в &amp;laquo;семантическое&amp;raquo; пространство низкой размерности. В частности, известно, что LSA борется с эффектами синонимии и многозначности (оба из которых примерно означают наличие нескольких значений на слово), из-за которых матрицы терминов-документов становятся слишком разреженными и демонстрируют плохое сходство по таким параметрам, как косинусное сходство.</target>
        </trans-unit>
        <trans-unit id="38dbd2ff8901fd68988a77a08c59409f80468575" translate="yes" xml:space="preserve">
          <source>When two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might &lt;em&gt;actually&lt;/em&gt; be important.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="726430099b436b4edbed2772b4e46aec59296fe0" translate="yes" xml:space="preserve">
          <source>When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.</source>
          <target state="translated">При использовании для классификации текста с векторами tf-idf,этот классификатор также известен как классификатор Роккио.</target>
        </trans-unit>
        <trans-unit id="b1373e66b4937bbac8defef2fa925bed61a8d596" translate="yes" xml:space="preserve">
          <source>When used to &lt;em&gt;transform&lt;/em&gt; data, PCA can reduce the dimensionality of the data by projecting on a principal subspace.</source>
          <target state="translated">При использовании для &lt;em&gt;преобразования&lt;/em&gt; данных PCA может уменьшить размерность данных за счет проецирования на главное подпространство.</target>
        </trans-unit>
        <trans-unit id="93429c223efcd8d6622a4c8e5f0e71f13358e226" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;multiclass classifiers&lt;/code&gt;&lt;/a&gt;, the learning and prediction task that is performed is dependent on the format of the target data fit upon:</source>
          <target state="translated">При использовании &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;multiclass classifiers&lt;/code&gt; &lt;/a&gt; выполняемая задача обучения и прогнозирования зависит от формата целевых данных, соответствующих:</target>
        </trans-unit>
        <trans-unit id="bf430655a414d830d0ddbbfedf78ab7c208919a9" translate="yes" xml:space="preserve">
          <source>When using Averaged SGD (with the &lt;code&gt;average&lt;/code&gt; parameter), &lt;code&gt;coef_&lt;/code&gt; is set to the average weight across all updates: &lt;code&gt;coef_&lt;/code&gt;\(= \frac{1}{T} \sum_{t=0}^{T-1} w^{(t)}\), where \(T\) is the total number of updates, found in the &lt;code&gt;t_&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb56aa339cbb48c9a75d42d2c7bf7e7858b3170b" translate="yes" xml:space="preserve">
          <source>When using ensemble methods base upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.</source>
          <target state="translated">При использовании ансамблевых методов на основе мешков,т.е.при создании новых тренировочных комплектов на основе отбора проб с заменой,часть тренировочного комплекта остается неиспользованной.Для каждого классификатора в ансамбле не используется отдельная часть тренировочного комплекта.</target>
        </trans-unit>
        <trans-unit id="7a60d247990a32a468cae00d5ed7b0c825a81e35" translate="yes" xml:space="preserve">
          <source>When using the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; in a &lt;code&gt;Pipeline&lt;/code&gt;, be sure to use the &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt; to add the indicator features to the regular features. First we obtain the &lt;code&gt;iris&lt;/code&gt; dataset, and add some missing values to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9696826aefafecc5b32845bc270f3c2cabe6664" translate="yes" xml:space="preserve">
          <source>When using these images, please give credit to AT&amp;amp;T Laboratories Cambridge.</source>
          <target state="translated">При использовании этих изображений, пожалуйста, отдайте должное AT&amp;amp;T Laboratories Cambridge.</target>
        </trans-unit>
        <trans-unit id="5a6f9e7437ff7d6762455e24a46c4771dc2e0a37" translate="yes" xml:space="preserve">
          <source>When using, for example, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;, to set the amount of regularization with &lt;code&gt;C&lt;/code&gt;, there will be a different amount of samples between the main problem and the smaller problems within the folds of the cross validation.</source>
          <target state="translated">При использовании, например, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;перекрестной проверки&lt;/a&gt; , чтобы установить степень регуляризации с помощью &lt;code&gt;C&lt;/code&gt; , будет различное количество выборок между основной проблемой и меньшими проблемами в пределах складок перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="5dae0cb2a4d8c33bb8e68ee9ffd452db73e27eb2" translate="yes" xml:space="preserve">
          <source>When we apply clustering to the data, we find that the clustering reflects what was in the distance matrices. Indeed, for the Euclidean distance, the classes are ill-separated because of the noise, and thus the clustering does not separate the waveforms. For the cityblock distance, the separation is good and the waveform classes are recovered. Finally, the cosine distance does not separate at all waveform 1 and 2, thus the clustering puts them in the same cluster.</source>
          <target state="translated">Когда мы применяем кластеризацию к данным,мы обнаруживаем,что кластеризация отражает то,что было в матрицах расстояний.Действительно,для евклидового расстояния классы плохо разделены из-за шума,и поэтому кластеризация не разделяет формы волн.Для расстояния до ситиблока разделение хорошо,и классы формы волны восстанавливаются.Наконец,косинусоидальное расстояние не разделяет кривые 1 и 2,поэтому кластеризация помещает их в один и тот же кластер.</target>
        </trans-unit>
        <trans-unit id="8975b7dd097c19a6af3c2b4b090f357f96aab52d" translate="yes" xml:space="preserve">
          <source>When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.</source>
          <target state="translated">При работе с оценкой ковариации обычно используется оценка максимального правдоподобия, например &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt; . Он несмещен, т. Е. Сходится к истинной (популяционной) ковариации при большом количестве наблюдений. Однако также может быть полезно упорядочить его, чтобы уменьшить его дисперсию; это, в свою очередь, вносит некоторую предвзятость. Этот пример иллюстрирует простую регуляризацию, используемую в &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;оценках Shrunk Covariance&lt;/a&gt; . В частности, он фокусируется на том, как установить степень регуляризации, то есть как выбрать компромисс между смещением и дисперсией.</target>
        </trans-unit>
        <trans-unit id="17b704aa73a46ef6f9edddecff620d33c0b705d7" translate="yes" xml:space="preserve">
          <source>When you want to apply different transformations to each field of the data, see the related class &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;#column-transformer&quot;&gt;user guide&lt;/a&gt;).</source>
          <target state="translated">Если вы хотите применить различные преобразования к каждому полю данных, см. Связанный класс &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt; (см. &lt;a href=&quot;#column-transformer&quot;&gt;Руководство пользователя&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="8d5450715de6c511faca4e5034a6c5d189b2299d" translate="yes" xml:space="preserve">
          <source>Where (and how) parallelization happens in the estimators is currently poorly documented. Please help us by improving our docs and tackle &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;issue 14228&lt;/a&gt;!</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffd889b6ef09600260c419603787a00c67ae551d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in both the true labels and the predicted labels), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in the true labels and not in the predicted labels) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in the predicted labels and not in the true labels).</source>
          <target state="translated">Где &lt;code&gt;TP&lt;/code&gt; - это количество &lt;strong&gt;истинно положительных&lt;/strong&gt; (т. Е. Количество пар точек, которые принадлежат одним и тем же кластерам как в истинных, так и в предсказанных метках), &lt;code&gt;FP&lt;/code&gt; - это количество &lt;strong&gt;ложных положительных результатов&lt;/strong&gt; (то есть количество пар точек, принадлежащих к одним и тем же кластерам в истинных метках, а не в предсказанных метках), а &lt;code&gt;FN&lt;/code&gt; - это количество &lt;strong&gt;ложных отрицательных&lt;/strong&gt; значений (т. е. количество пар точек, которые принадлежат одним и тем же кластерам в предсказанных метках, а не в истинных метках).</target>
        </trans-unit>
        <trans-unit id="276f699fa82da6208d110c0a23b40d61550922dd" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in both &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt;), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_true&lt;/code&gt; and not in &lt;code&gt;labels_pred&lt;/code&gt;) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_pred&lt;/code&gt; and not in &lt;code&gt;labels_True&lt;/code&gt;).</source>
          <target state="translated">Где &lt;code&gt;TP&lt;/code&gt; это число &lt;strong&gt;истинно положительный&lt;/strong&gt; (т.е. числа пар точек , которая принадлежит в одних и тех же кластерах в обоих &lt;code&gt;labels_true&lt;/code&gt; и &lt;code&gt;labels_pred&lt;/code&gt; ), &lt;code&gt;FP&lt;/code&gt; является числом &lt;strong&gt;ложного положительным&lt;/strong&gt; (т.е. числа пар точек , которая принадлежит в одних и тех же кластерах в &lt;code&gt;labels_true&lt;/code&gt; , а не в &lt;code&gt;labels_pred&lt;/code&gt; ) и &lt;code&gt;FN&lt;/code&gt; является числом &lt;strong&gt;Ложноотрицательного&lt;/strong&gt; (то есть число пар точек , которая принадлежит в одних и тех же кластерах в &lt;code&gt;labels_pred&lt;/code&gt; и не &lt;code&gt;labels_True&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="e78195e2eb2711f3bb8a0d7f4e3c56eea492c48d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;delta&lt;/code&gt; is a free parameter representing the width of the Gaussian kernel.</source>
          <target state="translated">Где &lt;code&gt;delta&lt;/code&gt; - это свободный параметр, представляющий ширину ядра Гаусса.</target>
        </trans-unit>
        <trans-unit id="6d88fb8179777bb060d39d8e880a1a6ec89efb59" translate="yes" xml:space="preserve">
          <source>Where C is the number of permutations whose score &amp;gt;= the true score.</source>
          <target state="translated">Где C - количество перестановок, оценка которых&amp;gt; = истинная оценка.</target>
        </trans-unit>
        <trans-unit id="0426d1b8d26623c0079356962f68cf2595f6d67a" translate="yes" xml:space="preserve">
          <source>Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:</source>
          <target state="translated">Где D-матрица расстояний для входных данных X,D_fit-матрица расстояний для выходных встраиваемых X_fit,а K-изомапное ядро:</target>
        </trans-unit>
        <trans-unit id="77844a8258430d31f41a5c27fd5c3c817a4c46f5" translate="yes" xml:space="preserve">
          <source>Where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset (without ordering).</source>
          <target state="translated">Где \(C_2^{n_{samples}}\)-общее количество возможных пар в наборе данных (без заказа).</target>
        </trans-unit>
        <trans-unit id="45f9706f8e40bfee3b8f4082279b7c1694d8aead" translate="yes" xml:space="preserve">
          <source>Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R &lt;code&gt;glasso&lt;/code&gt; package.</source>
          <target state="translated">Где \ (K \) - это матрица точности, которую необходимо оценить, а \ (S \) - это выборочная ковариационная матрица. \ (\ | K \ | _1 \) - это сумма абсолютных значений недиагональных коэффициентов \ (K \). Для решения этой проблемы используется алгоритм GLasso из статьи Friedman 2008 Biostatistics. Это тот же алгоритм, что и в пакете R &lt;code&gt;glasso&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="23038cc6fb25ab648004d5485267f6db76cb9eda" translate="yes" xml:space="preserve">
          <source>Where \(N(x_i)\) is the neighborhood of samples within a given distance around \(x_i\) and \(m\) is the &lt;em&gt;mean shift&lt;/em&gt; vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:</source>
          <target state="translated">Где \ (N (x_i) \) - это окрестность выборок на заданном расстоянии вокруг \ (x_i \), а \ (m \) - вектор &lt;em&gt;среднего сдвига,&lt;/em&gt; который вычисляется для каждого центроида, который указывает на область максимального увеличения по плотности точек. Это вычисляется с использованием следующего уравнения, эффективно обновляющего центроид до среднего значения выборок в его окрестности:</target>
        </trans-unit>
        <trans-unit id="c4be16a40b65a723b122e1219966e4db066c1f56" translate="yes" xml:space="preserve">
          <source>Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).</source>
          <target state="translated">Где \(R\)-диагональная матрица с записью \(i\),равной \(\sum_{j}A_{ij}\)и \(C\)-диагональная матрица с записью \(j\),равной \(\sum_{i}A_{ij}\).</target>
        </trans-unit>
        <trans-unit id="06bd15907339a321f45a7707ee037e3bf4bb294c" translate="yes" xml:space="preserve">
          <source>Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.</source>
          <target state="translated">Где \(\langle \cdot,\cdot\)обозначает внутренний продукт в пространстве Гильберта.</target>
        </trans-unit>
        <trans-unit id="b505305e3f68e0055136674f6671623549265da7" translate="yes" xml:space="preserve">
          <source>Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.</source>
          <target state="translated">Где \(\log_e (x)\)означает естественный логарифм \(x\).Этот показатель лучше всего использовать,когда речь идет о целях,имеющих экспоненциальный рост,таких как численность населения,средний объем продаж какого-либо товара за период времени и т.д.Обратите внимание,что данная метрика предусматривает штрафные санкции за недопредставленную оценку,превышающую завышенную оценку.</target>
        </trans-unit>
        <trans-unit id="dc652afd01d2a671ac597240d27fcb8fb6f2cb88" translate="yes" xml:space="preserve">
          <source>Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Где \(s(i,k)\)-это сходство между образцами \(i\)и \(k\).Наличие образца \(k\)является примером образца \(i\):</target>
        </trans-unit>
        <trans-unit id="9fa1e5b532b4ed4720d23061371103281dda3d83" translate="yes" xml:space="preserve">
          <source>Where r is defined per sample, we need to make use of &lt;code&gt;start&lt;/code&gt;:</source>
          <target state="translated">Где r определяется для каждого образца, нам нужно использовать &lt;code&gt;start&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c16b06fa7e959786262fbf5823a1d1a66514be0c" translate="yes" xml:space="preserve">
          <source>Where the step length \(\gamma_m\) is chosen using line search:</source>
          <target state="translated">Где длина шага \(\gamma_m\)выбирается с помощью поиска по строке:</target>
        </trans-unit>
        <trans-unit id="096f899281fbd2d32d659004bce326784eacf79e" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given &lt;code&gt;cv_results_&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be446fd5f2cab9d9132f73b7df79724fa271f7f8" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given the &lt;code&gt;cv_results&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e4c7785f80a06d28d2e2b965c377764abc1c026" translate="yes" xml:space="preserve">
          <source>Where to from here</source>
          <target state="translated">Куда отсюда</target>
        </trans-unit>
        <trans-unit id="17eb390ca1dec9880beb722610077dafb8edc9ac" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features] and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Где u и v-любые строки,взятые из набора данных формы [n_samples,n_features]и p-это проекция случайной гауссовской N(0,1)матрицы с формой [n_компоненты,n_features](или разреженной ахлиоптасовой матрицы).</target>
        </trans-unit>
        <trans-unit id="c5759c4abe89df832c23e0269eba38e4f1ad0ad7" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features], eps is in ]0, 1[ and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">Где u и v-любые строки,взятые из набора данных формы [n_samples,n_features],eps находится в ]0,1[и p-проекция случайной гауссовской N(0,1)матрицы с формой [n_компоненты,n_features](или разреженной ахлиоптасовой матрицей).</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="16270a9447d061ffaba6de4c25d0370619ae5579" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07f1abf8acdb3dcd49bde3ee8a201c3421831b31" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting. True by default.</source>
          <target state="translated">Будьте &lt;code&gt;feature_names_&lt;/code&gt; и &lt;code&gt;vocabulary_&lt;/code&gt; должны быть отсортированы при установке. Верно по умолчанию.</target>
        </trans-unit>
        <trans-unit id="e61b5eefa6a0d8caaa65c0cf06600523e6eded8c" translate="yes" xml:space="preserve">
          <source>Whether a forced copy will be triggered. If copy=False, a copy might be triggered by a conversion.</source>
          <target state="translated">Сработает ли принудительная копия.Если Copy=False,копия может быть вызвана преобразованием.</target>
        </trans-unit>
        <trans-unit id="6817dee267fec06b200988a35092c9fafdb28df4" translate="yes" xml:space="preserve">
          <source>Whether a prefit model is expected to be passed into the constructor directly or not. If True, &lt;code&gt;transform&lt;/code&gt; must be called directly and SelectFromModel cannot be used with &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;GridSearchCV&lt;/code&gt; and similar utilities that clone the estimator. Otherwise train the model using &lt;code&gt;fit&lt;/code&gt; and then &lt;code&gt;transform&lt;/code&gt; to do feature selection.</source>
          <target state="translated">Ожидается, что предварительная модель будет передана в конструктор напрямую или нет. Если True, &lt;code&gt;transform&lt;/code&gt; должно вызываться напрямую, а SelectFromModel нельзя использовать с &lt;code&gt;cross_val_score&lt;/code&gt; , &lt;code&gt;GridSearchCV&lt;/code&gt; и аналогичными утилитами, которые клонируют оценщик. В противном случае обучите модель, используя &lt;code&gt;fit&lt;/code&gt; а затем &lt;code&gt;transform&lt;/code&gt; чтобы выбрать элементы.</target>
        </trans-unit>
        <trans-unit id="e67f675f1639113224879739e0229eb2671df0d3" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style.</source>
          <target state="translated">Будет ли массив вынужден быть фортран или c-стилем.</target>
        </trans-unit>
        <trans-unit id="57d1f88164d54372295bc307285273118c662089" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style. When order is None (default), then if copy=False, nothing is ensured about the memory layout of the output array; otherwise (copy=True) the memory layout of the returned array is kept as close as possible to the original array.</source>
          <target state="translated">Будет ли массив вынужден быть фортран или c-стилем.Если порядок None (по умолчанию),то если copy=False,то о компоновке памяти выходного массива ничего не известно;в противном случае (copy=True)компоновка памяти возвращаемого массива хранится как можно ближе к исходному массиву.</target>
        </trans-unit>
        <trans-unit id="f6541283616583040ce3e73f070cbb436dbc5da9" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees.</source>
          <target state="translated">Используются ли при строительстве деревьев образцы бутстрап.</target>
        </trans-unit>
        <trans-unit id="1349327857b1cdc30e7f508422cffd4b74a570bf" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="344e324f858395af07d0534305d3cd485a522869" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; is passed. If &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to &lt;code&gt;zero_based=True&lt;/code&gt; to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Независимо от того, отсчитываются ли индексы столбцов в f от нуля (True) или от единицы (False). Если индексы столбцов начинаются с единицы, они преобразуются в нулевые, чтобы соответствовать соглашениям Python / NumPy. Если установлено значение &amp;laquo;авто&amp;raquo;, применяется эвристическая проверка, чтобы определить это по содержимому файла. Оба типа файлов встречаются &amp;laquo;в дикой природе&amp;raquo;, но, к сожалению, они не самоидентифицируются. Использование &amp;laquo;auto&amp;raquo; или &amp;laquo;True&amp;raquo; всегда должно быть безопасным, если не передается &lt;code&gt;offset&lt;/code&gt; или &lt;code&gt;length&lt;/code&gt; . Если &lt;code&gt;offset&lt;/code&gt; или &lt;code&gt;length&lt;/code&gt; переданы, режим &amp;laquo;auto&amp;raquo; возвращается к &lt;code&gt;zero_based=True&lt;/code&gt; чтобы избежать получения несогласованных результатов эвристической проверки в разных сегментах файла.</target>
        </trans-unit>
        <trans-unit id="f00bfe1387e4927051573cb3d574287560206c66" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no offset or length is passed. If offset or length are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to zero_based=True to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">Независимо от того, отсчитываются ли индексы столбцов в f от нуля (True) или от единицы (False). Если индексы столбцов начинаются с единицы, они преобразуются в нулевые, чтобы соответствовать соглашениям Python / NumPy. Если установлено значение &amp;laquo;авто&amp;raquo;, применяется эвристическая проверка, чтобы определить это по содержимому файла. Оба типа файлов встречаются &amp;laquo;в дикой природе&amp;raquo;, но, к сожалению, они не самоидентифицируются. Использование &amp;laquo;auto&amp;raquo; или &amp;laquo;True&amp;raquo; всегда должно быть безопасным, если не передается смещение или длина. Если смещение или длина переданы, режим &amp;laquo;auto&amp;raquo; возвращается к нулевому_based = True, чтобы избежать получения несогласованных результатов эвристической проверки в разных сегментах файла.</target>
        </trans-unit>
        <trans-unit id="be05ee9a303aba9073e602f5af4606db8dba467c" translate="yes" xml:space="preserve">
          <source>Whether column indices should be written zero-based (True) or one-based (False).</source>
          <target state="translated">Должны ли индексы столбца быть написаны на нулевой основе (True)или на одной основе (False).</target>
        </trans-unit>
        <trans-unit id="426c392bb98aa08b186e867710abfa024378fa01" translate="yes" xml:space="preserve">
          <source>Whether features are drawn with replacement.</source>
          <target state="translated">Отрисовываются ли функции с заменой.</target>
        </trans-unit>
        <trans-unit id="b1153e9c8e50c0d286811aaf218a31fa047ae93d" translate="yes" xml:space="preserve">
          <source>Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.</source>
          <target state="translated">Проводится ли вторая нормализация весов или нет.Поведение по умолчанию зеркально отражает реализации,найденные в Махауте и Веке,которые не следуют полному алгоритму,описанному в таблице 9 статьи.</target>
        </trans-unit>
        <trans-unit id="1500a013d74d8899d6c67c8489e35470d425474d" translate="yes" xml:space="preserve">
          <source>Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter &lt;code&gt;fit_intercept&lt;/code&gt;.</source>
          <target state="translated">Должна ли модель использовать перехват, т. &lt;code&gt;fit_intercept&lt;/code&gt; гиперплоскость, контролируется параметром fit_intercept .</target>
        </trans-unit>
        <trans-unit id="c17699d69c93a1c9674665b22c836f689e7a71a8" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch.</source>
          <target state="translated">Должны ли данные тренировки быть перетасованы после каждой эпохи или нет.</target>
        </trans-unit>
        <trans-unit id="2f96d4cd24a907c94c91a597b369db5ae9d183fe" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch. Defaults to True.</source>
          <target state="translated">Должны ли данные тренировки быть перетасованы после каждой эпохи или нет.По умолчанию установлено значение True.</target>
        </trans-unit>
        <trans-unit id="21e287c040da0ab9f7612eda4a9df397d21447be" translate="yes" xml:space="preserve">
          <source>Whether or not to compute labels for each fit.</source>
          <target state="translated">Рассчитывать ли этикетки для каждого подбора или нет.</target>
        </trans-unit>
        <trans-unit id="ae7627e3aed47d9187a8dde354d4bd8908f66e18" translate="yes" xml:space="preserve">
          <source>Whether or not to consider raw Mahalanobis distances as the decision function. Must be False (default) for compatibility with the others outlier detection tools.</source>
          <target state="translated">Рассматривать или не рассматривать необработанные расстояния Махаланобиса как функцию решения.Должно быть Ложно (по умолчанию)для совместимости с другими инструментами обнаружения отклонений.</target>
        </trans-unit>
        <trans-unit id="d7d36162415efc2dece0359749393df764e8f212" translate="yes" xml:space="preserve">
          <source>Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.</source>
          <target state="translated">Соответствует ли перехват или нет.Это может быть установлено в значение False,если данные уже сосредоточены вокруг источника.</target>
        </trans-unit>
        <trans-unit id="99ecd63bc30b233e173e08d6a58d2b609112b08a" translate="yes" xml:space="preserve">
          <source>Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Сделать или не сделать копию данных.Если установлено значение False,начальные данные будут перезаписаны.</target>
        </trans-unit>
        <trans-unit id="95950f270865da71d578c03fd7275708de2f1edb" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &amp;lsquo;auto&amp;rsquo;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d8aa347bdbdfa6dd79051c8fee2f95fc5666522" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &lt;code&gt;None&lt;/code&gt;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo; as this will preserve backwards compatibility.</source>
          <target state="translated">Следует ли отмечать каждый образец как первого ближайшего соседа к себе. Если &lt;code&gt;None&lt;/code&gt; , то True используется для mode = 'connectivity' и False для mode = 'distance', так как это сохранит обратную совместимость.</target>
        </trans-unit>
        <trans-unit id="a1d6eb056f01f6a77d40d6f787612d8008f1be4b" translate="yes" xml:space="preserve">
          <source>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</source>
          <target state="translated">Возвращать или не возвращать разреженную матрицу CSR,как поведение по умолчанию,или возвращать плотный массив,совместимый с операторами плотных трубопроводов.</target>
        </trans-unit>
        <trans-unit id="8f592bf838896fb605ecc15c063970bf58250eab" translate="yes" xml:space="preserve">
          <source>Whether or not to return the number of iterations.</source>
          <target state="translated">Вернуть или не вернуть количество итераций.</target>
        </trans-unit>
        <trans-unit id="3433b032133d6a741db0a6ccce9ce8005a84877d" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.</source>
          <target state="translated">Перетасовывать данные перед разбиением или нет.Если shuffle=False,то стратификация должна быть None.</target>
        </trans-unit>
        <trans-unit id="d797771ee8d7ac8a664344b3d1655c54bf4a7c5a" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data: might be important for models that make the assumption that the samples are independent and identically distributed (i.i.d.), such as stochastic gradient descent.</source>
          <target state="translated">Переставлять или не переставлять данные:может быть важно для моделей,которые делают предположение,что образцы независимы и идентично распределены (i.i.d.),например,стохастический градиентный спуск.</target>
        </trans-unit>
        <trans-unit id="169aa17090e9b82766c818a4a09acd1cb51fcb24" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement.</source>
          <target state="translated">Отбираются ли образцы с заменой.</target>
        </trans-unit>
        <trans-unit id="11994582207268a83009eceee1185d13dd22bd86" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement. If False, sampling without replacement is performed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b61c81ce74fc75ce6a90c790bfafe984d14c7994" translate="yes" xml:space="preserve">
          <source>Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.</source>
          <target state="translated">Является ли функция score_func функцией оценки (по умолчанию),означающей,что максимум-это хорошо,или функция потерь,означающая,что минимум-это хорошо.В последнем случае,объект scorer будет означать результат функции score_func.</target>
        </trans-unit>
        <trans-unit id="01c7a3b4947bb7aed2272a78dd753a14b9e24fdc" translate="yes" xml:space="preserve">
          <source>Whether score_func requires predict_proba to get probability estimates out of a classifier.</source>
          <target state="translated">Требуется ли sco_func прогноз_proba,чтобы получить из классификатора вероятностные оценки.</target>
        </trans-unit>
        <trans-unit id="e86601bb1c2db478564381eb9b1a33fc72f3ad69" translate="yes" xml:space="preserve">
          <source>Whether score_func takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method.</source>
          <target state="translated">Принимает ли sco_func непрерывное решение с уверенностью.Это работает только для бинарной классификации с использованием оценщиков,которые имеют либо метод decision_function,либо метод predict_proba.</target>
        </trans-unit>
        <trans-unit id="62e384e32324c7d8c05ac06534cda98d3cbc0def" translate="yes" xml:space="preserve">
          <source>Whether support is a list of indices.</source>
          <target state="translated">Является ли поддержка списком индексов.</target>
        </trans-unit>
        <trans-unit id="970ea0e030e6e4be6469b0282edfb558e0e9066d" translate="yes" xml:space="preserve">
          <source>Whether the algorithm should be applied to M.T instead of M. The result should approximately be the same. The &amp;lsquo;auto&amp;rsquo; mode will trigger the transposition if M.shape[1] &amp;gt; M.shape[0] since this implementation of randomized SVD tend to be a little faster in that case.</source>
          <target state="translated">Следует ли применять алгоритм к МП вместо М. Результат должен быть примерно таким. &amp;laquo;Автоматический&amp;raquo; режим запускает транспонирование, если M.shape [1]&amp;gt; M.shape [0], поскольку эта реализация рандомизированного SVD имеет тенденцию быть немного быстрее в этом случае.</target>
        </trans-unit>
        <trans-unit id="3226951d2ead1297a694651602f8538f5e93757c" translate="yes" xml:space="preserve">
          <source>Whether the covariance vector Xy must be copied by the algorithm. If False, it may be overwritten.</source>
          <target state="translated">Должен ли ковариационный вектор Xy быть скопирован алгоритмом.Если False,то он может быть переписан.</target>
        </trans-unit>
        <trans-unit id="d2b667c3b7746e3e678455d8b2d703997aeb5e60" translate="yes" xml:space="preserve">
          <source>Whether the deflation be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effects</source>
          <target state="translated">Будет ли дефляция сделана на копии. Оставьте значение по умолчанию True, если вас не волнуют побочные эффекты.</target>
        </trans-unit>
        <trans-unit id="1cba92780e42c1ebe55ada467260206516898de8" translate="yes" xml:space="preserve">
          <source>Whether the deflation should be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effect</source>
          <target state="translated">Следует ли производить дефляцию на копии. Оставьте значение по умолчанию True, если вас не волнует побочный эффект.</target>
        </trans-unit>
        <trans-unit id="99f0df0508624fcfafef99671905c951f197a398" translate="yes" xml:space="preserve">
          <source>Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Должна ли матрица проектирования X быть скопирована алгоритмом.Ложное значение полезно только в том случае,если X уже заказана по Fortran,в противном случае копия все равно будет сделана.</target>
        </trans-unit>
        <trans-unit id="6f829dc8dcc41b94f325536e7999d7feb34a89f1" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word n-gram or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f62ef19aafedabcbf9aa2a6c1cbcccaa900e840f" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams.</source>
          <target state="translated">Должна ли эта функция быть сделана из слова или из n-грамм символов.</target>
        </trans-unit>
        <trans-unit id="9c1354d44a66effd212e821b1aba74fe08612248" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">Должен ли признак состоять из словесных или символьных н-граммов. Опция 'char_wb' создает н-граммы символов только из текста внутри границ слова; n-граммы по краям слов заполняются пробелами.</target>
        </trans-unit>
        <trans-unit id="824ad07968fefbc8aa1fba0ade7c849f0d099562" translate="yes" xml:space="preserve">
          <source>Whether the gram matrix must be copied by the algorithm. A false value is only helpful if it is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">Должна ли грамматическая матрица быть скопирована алгоритмом.Ложное значение полезно только в том случае,если оно уже заказано Fortran,в противном случае копия все равно будет сделана.</target>
        </trans-unit>
        <trans-unit id="23571fa5c9f0e8d5b2ce0915807aa480e23639d3" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask format should be sparse or dense.</source>
          <target state="translated">Должен ли формат маски принтера быть разреженным или плотным.</target>
        </trans-unit>
        <trans-unit id="b70758cdff0513f8822d9fb7393f16dda3f13af9" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask should represent all or a subset of features.</source>
          <target state="translated">Должна ли маска вмятины представлять все или подмножество возможностей.</target>
        </trans-unit>
        <trans-unit id="11709e37813efd2480c1d891188cf0d8201c8a69" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If &lt;code&gt;False&lt;/code&gt;, the data is assumed to be already centered.</source>
          <target state="translated">Следует ли оценивать перехват или нет. Если &lt;code&gt;False&lt;/code&gt; , предполагается, что данные уже центрированы.</target>
        </trans-unit>
        <trans-unit id="0ccd5f6458ed970eecf03c787120d2831e50f140" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.</source>
          <target state="translated">Должен ли перехват быть оценен или нет.Если Фальшивка,то предполагается,что данные уже центрированы.</target>
        </trans-unit>
        <trans-unit id="2fafec857734808cd372cb104d91a568d25acbf6" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</source>
          <target state="translated">Должен ли перехват быть оценен или нет.Если Фальшивка,то предполагается,что данные уже центрированы.По умолчанию-True.</target>
        </trans-unit>
        <trans-unit id="1369ea0f90c1ab8c31f4e5d5e2b327950f322e67" translate="yes" xml:space="preserve">
          <source>Whether the kernel works only on fixed-length feature vectors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efe887a2120302f3ddf508ce39115dacb905298c" translate="yes" xml:space="preserve">
          <source>Whether the parameter was found to be a named parameter of the estimator&amp;rsquo;s fit method.</source>
          <target state="translated">Было ли обнаружено, что параметр является именованным параметром метода подбора оценщика.</target>
        </trans-unit>
        <trans-unit id="e3e6070e7b1bf06bd46c63ade906ee83f84569ff" translate="yes" xml:space="preserve">
          <source>Whether the power iterations are normalized with step-by-step QR factorization (the slowest but most accurate), &amp;lsquo;none&amp;rsquo; (the fastest but numerically unstable when &lt;code&gt;n_iter&lt;/code&gt; is large, e.g. typically 5 or larger), or &amp;lsquo;LU&amp;rsquo; factorization (numerically stable but can lose slightly in accuracy). The &amp;lsquo;auto&amp;rsquo; mode applies no normalization if &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 and switches to LU otherwise.</source>
          <target state="translated">Нормализованы ли итерации мощности с помощью пошаговой QR-факторизации (самая медленная, но наиболее точная), &amp;laquo;none&amp;raquo; (самая быстрая, но численно нестабильная, когда &lt;code&gt;n_iter&lt;/code&gt; большое, например, обычно 5 или больше), или факторизация &amp;laquo;LU&amp;raquo; (численно стабильно, но может немного потерять точность). В автоматическом режиме нормализация не применяется, если &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2, в противном случае переключается на LU.</target>
        </trans-unit>
        <trans-unit id="00c2bc5048e0182a905dad0c4dec40740dd521b8" translate="yes" xml:space="preserve">
          <source>Whether the relationship is increasing or decreasing.</source>
          <target state="translated">Увеличиваются ли отношения или уменьшаются.</target>
        </trans-unit>
        <trans-unit id="dc0314689b038e45038d5534e1499b2766f8b916" translate="yes" xml:space="preserve">
          <source>Whether the return value is an array of sparse matrix depends on the type of the input X.</source>
          <target state="translated">Является ли возвращаемое значение массивом разреженной матрицы,зависит от типа входа X.</target>
        </trans-unit>
        <trans-unit id="ed44b1dc96dab239fb6ac2dc375f2ee5fe3ae793" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, i.e., the mean of the observed target values become zero. This parameter should be set to True if the target values&amp;rsquo; mean is expected to differ considerable from zero. When enabled, the normalization effectively modifies the GP&amp;rsquo;s prior based on the data, which contradicts the likelihood principle; normalization is thus disabled per default.</source>
          <target state="translated">Нормализованы ли целевые значения y, т. Е. Среднее из наблюдаемых целевых значений становится нулевым. Для этого параметра следует установить значение True, если ожидается, что среднее целевых значений будет значительно отличаться от нуля. Когда эта функция включена, нормализация эффективно изменяет априорность GP на основе данных, что противоречит принципу правдоподобия; поэтому по умолчанию нормализация отключена.</target>
        </trans-unit>
        <trans-unit id="cb8d2af32f6e15f6d8381b5609652e77d17356c4" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, the mean and variance of the target values are set equal to 0 and 1 respectively. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d56de522c2f2c8fa83698a0d6921644d35a5428" translate="yes" xml:space="preserve">
          <source>Whether the task is a classification task, in which case stratified KFold will be used.</source>
          <target state="translated">Является ли задача классификационной задачей,в этом случае будет использоваться расслоенный KFold.</target>
        </trans-unit>
        <trans-unit id="667f96156fffe3e4c7c8342ead32f8ae00d3d84f" translate="yes" xml:space="preserve">
          <source>Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If None is passed, the &amp;ldquo;fixed&amp;rdquo; is derived based on the given bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cb255093bce0eff775d5414b35fcd6fbd07931b" translate="yes" xml:space="preserve">
          <source>Whether this is a multilabel classifier</source>
          <target state="translated">Является ли это многоэлементным классификатором</target>
        </trans-unit>
        <trans-unit id="b1be5efdade94da8e67722b4ba2f983efa0225c5" translate="yes" xml:space="preserve">
          <source>Whether to allow 2-d y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">Разрешать ли 2-d y (массив или разреженная матрица).Если false,то y будет проверяться как вектор.y не может иметь np.nan или np.inf значений,если multi_output=True.</target>
        </trans-unit>
        <trans-unit id="110cd422886570c5a4fe2834aa70ff221b2cdcaf" translate="yes" xml:space="preserve">
          <source>Whether to allow 2D y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ecc2d4e014d3f2172c25597969963bd34e18f05" translate="yes" xml:space="preserve">
          <source>Whether to allow X.ndim &amp;gt; 2.</source>
          <target state="translated">Разрешить ли X.ndim&amp;gt; 2.</target>
        </trans-unit>
        <trans-unit id="7a4a847db3917eeca38ca476c1ad3e57930cf992" translate="yes" xml:space="preserve">
          <source>Whether to allow array.ndim &amp;gt; 2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5dcbf9253f384309cfbc4a594ef7b057c1cb7e6" translate="yes" xml:space="preserve">
          <source>Whether to also return the code U or just the dictionary V.</source>
          <target state="translated">Вернуть ли также код U или просто словарь V.</target>
        </trans-unit>
        <trans-unit id="c6289192e1f815e2a760fe289e8841e73f51c42c" translate="yes" xml:space="preserve">
          <source>Whether to be verbose.</source>
          <target state="translated">Будет ли это многословно.</target>
        </trans-unit>
        <trans-unit id="ccada94fe77cfa7bf4094a2aaa2265ce9f9f4e5f" translate="yes" xml:space="preserve">
          <source>Whether to cache downloaded datasets using joblib.</source>
          <target state="translated">Кэшировать ли загруженные наборы данных с помощью joblib.</target>
        </trans-unit>
        <trans-unit id="86614eccba121d18979d29b5e6a1aceed9dc9343" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение False,то перехват не будет использоваться в расчетах (например,ожидается,что данные уже будут центрированы).</target>
        </trans-unit>
        <trans-unit id="7285fa12a56fc9f408db5bd27934d6f0654e6093" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="943768cddf06aea5cdead26cd3dff69cb74196ef" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,то перехват не будет использоваться в вычислениях (например,ожидается,что данные уже будут по центру).</target>
        </trans-unit>
        <trans-unit id="27f8a383f138130dd1f45baee7b1d68ad4ce59f4" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be already centered).</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,то перехват не будет использоваться в вычислениях (т.е.ожидается,что данные уже будут по центру).</target>
        </trans-unit>
        <trans-unit id="34dd726eec26b92f0d7e507bd65e8b16cfaec4c8" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0336ff17d311b84566800e5cf35b415ab2b27f38" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.</source>
          <target state="translated">Рассчитать ли перехват для этой модели.Если установлено значение false,перехват не будет использоваться в вычислениях.</target>
        </trans-unit>
        <trans-unit id="7c201504f17506a2291f5d939998458e72428d3b" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. The intercept is not treated as a probabilistic parameter and thus has no associated variance. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="471ed2aff4494fad57e380482ee0a58232333b20" translate="yes" xml:space="preserve">
          <source>Whether to check that &lt;code&gt;transform&lt;/code&gt; followed by &lt;code&gt;inverse_transform&lt;/code&gt; or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original targets.</source>
          <target state="translated">&lt;code&gt;inverse_transform&lt;/code&gt; ли проверять, что &lt;code&gt;transform&lt;/code&gt; за которым следует inverse_transform, или &lt;code&gt;func&lt;/code&gt; , за которым следует &lt;code&gt;inverse_func&lt;/code&gt; , приводит к исходным целям.</target>
        </trans-unit>
        <trans-unit id="3c61d748141856e990caff79c0b01fd8a4086321" translate="yes" xml:space="preserve">
          <source>Whether to check that or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original inputs. It can be used for a sanity check, raising a warning when the condition is not fulfilled.</source>
          <target state="translated">Проверять ли это или &lt;code&gt;func&lt;/code&gt; , за которым следует &lt;code&gt;inverse_func&lt;/code&gt; , приводит к исходным входным данным. Его можно использовать для проверки работоспособности, выдавая предупреждение, когда условие не выполняется.</target>
        </trans-unit>
        <trans-unit id="50850a0df7fa2328560b0d7ebe31ee1142901517" translate="yes" xml:space="preserve">
          <source>Whether to compute &lt;code&gt;y_&lt;/code&gt; is increasing (if set to True) or decreasing (if set to False)</source>
          <target state="translated">&lt;code&gt;y_&lt;/code&gt; ли вычислять y_ : увеличивается (если установлено значение True) или уменьшается (если установлено значение False)</target>
        </trans-unit>
        <trans-unit id="5fbe7e9ef9385d70942ace9201de11e6cead8f8d" translate="yes" xml:space="preserve">
          <source>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</source>
          <target state="translated">Будь то вычисление нормы квадратной ошибки или нормы ошибки.Если значение True (по умолчанию),возвращается норма ошибки в квадрате.Если False,возвращается норма ошибки.</target>
        </trans-unit>
        <trans-unit id="01086dba4779bb032a62d90a9f9152dc1b833baf" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place computations.</source>
          <target state="translated">Скопировать ли X и Y,или выполнить вычисления на месте.</target>
        </trans-unit>
        <trans-unit id="725302de0fd34aabdbfc0e0affbd4f4fb754127c" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place normalization.</source>
          <target state="translated">Скопировать ли X и Y или выполнить локальную нормализацию.</target>
        </trans-unit>
        <trans-unit id="7462b314a4fe2fff7847f10014abb6b1183fa84f" translate="yes" xml:space="preserve">
          <source>Whether to copy X and operate on the copy or perform in-place operations.</source>
          <target state="translated">Будь то копирование X и работа с копией или выполнение операций на месте.</target>
        </trans-unit>
        <trans-unit id="3692936737114d51a6bb410cb3531454c9ad1d68" translate="yes" xml:space="preserve">
          <source>Whether to copy the precomputed covariance matrix; if False, it may be overwritten.</source>
          <target state="translated">Скопировать ли предварительно вычисленную ковариационную матрицу;если False,то она может быть перезаписана.</target>
        </trans-unit>
        <trans-unit id="324d6fe1307968790ddbb142ded331e1979517da" translate="yes" xml:space="preserve">
          <source>Whether to create a copy of X and operate on it or to perform inplace computation (default behaviour).</source>
          <target state="translated">Создавать ли копию X и работать ли над ней или выполнять вычисления на месте (поведение по умолчанию).</target>
        </trans-unit>
        <trans-unit id="62527ff1b5ed50e080e833b6d4fd94a862b78590" translate="yes" xml:space="preserve">
          <source>Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.</source>
          <target state="translated">Следует ли снижать некоторые неоптимальные пороговые значения,которые не будут отображаться на построенной ROC-кривой.Это полезно для создания более легких УХО-кривых.</target>
        </trans-unit>
        <trans-unit id="9851e7fdf1748b99ff7c24c940b7ce5f334a6a27" translate="yes" xml:space="preserve">
          <source>Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.</source>
          <target state="translated">Неважно,сбросить ли первый собственный вектор.Для спектральной встраивания,это должно быть True,так как первый собственный вектор должен быть постоянным вектором для связанного графика,но для спектральной кластеризации,это должно быть сохранено как False,чтобы сохранить первый собственный вектор.</target>
        </trans-unit>
        <trans-unit id="5f99ffcc1bc3b15acf95363130c37cd5b381a91e" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, and will slow down that method.</source>
          <target state="translated">Следует ли включать оценки вероятности. Это должно быть включено до вызова &lt;code&gt;fit&lt;/code&gt; и замедлит этот метод.</target>
        </trans-unit>
        <trans-unit id="1a58ce6c20ca7e5e36327e21b19b4ffc278a0174" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, will slow down that method as it internally uses 5-fold cross-validation, and &lt;code&gt;predict_proba&lt;/code&gt; may be inconsistent with &lt;code&gt;predict&lt;/code&gt;. Read more in the &lt;a href=&quot;../svm#scores-probabilities&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a4497ffca40d00ae7a4f4bda08e5dece2337700" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the code.</source>
          <target state="translated">Привести ли в исполнение позитивность при нахождении кода.</target>
        </trans-unit>
        <trans-unit id="2920a1115fbc090ce8de93fb299e0d53a98e0404" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary</source>
          <target state="translated">Навязывать ли позитивность при поиске словаря...</target>
        </trans-unit>
        <trans-unit id="cc323427a6369f3d4c345df0c7eab9b613a4b184" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary.</source>
          <target state="translated">Привести ли в исполнение позитивность при поиске словаря.</target>
        </trans-unit>
        <trans-unit id="0c86815e9d15a8d79f49100b7de99ab0894ffb4b" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the encoding.</source>
          <target state="translated">Навязывать ли позитивность при поиске кодировки.</target>
        </trans-unit>
        <trans-unit id="67962e408072673f64867d41053d2df5bd8ffd92" translate="yes" xml:space="preserve">
          <source>Whether to ensure that y has a numeric type. If dtype of y is object, it is converted to float64. Should only be used for regression algorithms.</source>
          <target state="translated">Убедиться,что у вас есть цифровой тип.Если тип y является объектным,то он преобразуется в float64.Должен использоваться только для алгоритмов регрессии.</target>
        </trans-unit>
        <trans-unit id="a89a89f1fbc0cff73f883e4748e4c43034f0361e" translate="yes" xml:space="preserve">
          <source>Whether to filter invalid parameters or not.</source>
          <target state="translated">Фильтрация недействительных параметров или нет.</target>
        </trans-unit>
        <trans-unit id="8bd7eb051fe8793acf6505d7ff57ac8a40be3e89" translate="yes" xml:space="preserve">
          <source>Whether to fit an intercept for the model. In this case the shape of the returned array is (n_cs, n_features + 1).</source>
          <target state="translated">Подогнать ли перехват под модель.В этом случае форма возвращаемого массива будет (n_cs,n_features+1).</target>
        </trans-unit>
        <trans-unit id="86604814c1d6f6dc79ece6e1aa0e214e981e58a5" translate="yes" xml:space="preserve">
          <source>Whether to fit the intercept for this model. If set to false, no intercept will be used in calculations (i.e. &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are expected to be centered).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e39ad37924100e174516b8fe05585ae0c11a660" translate="yes" xml:space="preserve">
          <source>Whether to include &amp;ldquo;special&amp;rdquo; label estimator or test processors.</source>
          <target state="translated">Следует ли включать &amp;laquo;специальный&amp;raquo; оценщик этикеток или тестовые процессоры.</target>
        </trans-unit>
        <trans-unit id="84818ba086581abd044063f9dd3c5b2beb12eda7" translate="yes" xml:space="preserve">
          <source>Whether to include meta-estimators that can be constructed using an estimator as their first argument. These are currently BaseEnsemble, OneVsOneClassifier, OutputCodeClassifier, OneVsRestClassifier, RFE, RFECV.</source>
          <target state="translated">Включить ли в качестве первого аргумента метаоценщики,которые могут быть построены с использованием оценочного средства.В настоящее время это BaseEnsemble,OneVsOneClassifier,OutputCodeClassifier,OneVsRestClassifier,RFE,RFECV.</target>
        </trans-unit>
        <trans-unit id="74d7014a87bc3e04b7cb4d5881013af41aaf9d5f" translate="yes" xml:space="preserve">
          <source>Whether to include train scores.</source>
          <target state="translated">Включить ли баллы поезда.</target>
        </trans-unit>
        <trans-unit id="5a33027c8dd2a3a26ddc387706fe4e97d00f5eae" translate="yes" xml:space="preserve">
          <source>Whether to include train scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b770fc1f2ccfc02ef3107a2ecac741b2276c37e8" translate="yes" xml:space="preserve">
          <source>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</source>
          <target state="translated">Изучать ли класс предыдущие вероятности или нет.Если это ложь,будет использована единообразная предшествующая.</target>
        </trans-unit>
        <trans-unit id="8606bf192804810fba78c6bd2b8805fda4483156" translate="yes" xml:space="preserve">
          <source>Whether to load only 10 percent of the data.</source>
          <target state="translated">Загружать ли только 10 процентов данных.</target>
        </trans-unit>
        <trans-unit id="3156faf4c491e77c08d3500dd2b8c76947137632" translate="yes" xml:space="preserve">
          <source>Whether to load or not the content of the different files. If true a &amp;lsquo;data&amp;rsquo; attribute containing the text information is present in the data structure returned. If not, a filenames attribute gives the path to the files.</source>
          <target state="translated">Загружать или нет содержимое разных файлов. Если true, в возвращаемой структуре данных присутствует атрибут data, содержащий текстовую информацию. Если нет, атрибут filenames дает путь к файлам.</target>
        </trans-unit>
        <trans-unit id="81f8d6a01f7cffb7f53496e9cfd84f1ce27de740" translate="yes" xml:space="preserve">
          <source>Whether to make X at least 2d.</source>
          <target state="translated">Сделать ли Х как минимум 2d.</target>
        </trans-unit>
        <trans-unit id="2a578215f5e1bceb4eddd518c894532f84a10916" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of X. If &lt;code&gt;False&lt;/code&gt;, the input X gets overwritten during fitting.</source>
          <target state="translated">Делать ли копию X. Если &lt;code&gt;False&lt;/code&gt; , вход X перезаписывается во время подгонки.</target>
        </trans-unit>
        <trans-unit id="e2abdc017941ef25090c0789fe34541086dc5677" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">Сделать ли копию данных.Если установлено значение False,начальные данные будут перезаписаны.</target>
        </trans-unit>
        <trans-unit id="df62a350cab30808585d28e267100de2daf97811" translate="yes" xml:space="preserve">
          <source>Whether to normalize the output matrix to make the leading diagonal elements all 1</source>
          <target state="translated">Нормализовать ли выходную матрицу,чтобы сделать ведущие диагональные элементы все 1</target>
        </trans-unit>
        <trans-unit id="ba6415e4db38e5cea33cf7fab1a514fcf5285867" translate="yes" xml:space="preserve">
          <source>Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.</source>
          <target state="translated">Будет ли выполняться пре-вычисление.Улучшает производительность,когда n_targets или n_samples очень большие.</target>
        </trans-unit>
        <trans-unit id="4010b2bff9133aaf08486f7fb645e8e39634583e" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. Auto mode by default will use presorting on dense data and default to normal sorting on sparse data. Setting presort to true on sparse data will raise an error.</source>
          <target state="translated">Предварительная сортировка данных для ускорения поиска наилучшего разделения при монтаже.Автоматический режим по умолчанию будет использовать предварительную сортировку на плотных данных,а по умолчанию-обычную сортировку на разреженных данных.Установка параметра presort в true для разреженных данных приведет к ошибке.</target>
        </trans-unit>
        <trans-unit id="29f75c6794195c888ce8399680c96d5b14e65048" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. For the default settings of a decision tree on large datasets, setting this to true may slow down the training process. When using either a smaller dataset or a restricted depth, this may speed up the training.</source>
          <target state="translated">Предварительная сортировка данных для ускорения поиска наилучшего разделения при монтаже.При настройке по умолчанию дерева решений на больших наборах данных,установка этого значения в true может замедлить тренировочный процесс.При использовании либо меньшего набора данных,либо ограниченной глубины это может ускорить тренировочный процесс.</target>
        </trans-unit>
        <trans-unit id="cc4d3f96c9bc487e50b4fc4701212f323c65bca6" translate="yes" xml:space="preserve">
          <source>Whether to print progress messages to stdout.</source>
          <target state="translated">Следует ли распечатывать сообщения о ходе работы в stdout.</target>
        </trans-unit>
        <trans-unit id="1ef1345441f84cbc6b06cbfc2b69b730789a6079" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b44ea19ee67df3ef30c54f3be25f24e67c4f3a60" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2d.</source>
          <target state="translated">Следует ли увеличивать ошибку значения,если X не 2d.</target>
        </trans-unit>
        <trans-unit id="64b755e00dbefa679127012ca837c554b0c217d7" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if array is not 2D.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5d06b3c83946e2cd2c05192b834ad6e01c6a1d5" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. The possibilities are:</source>
          <target state="translated">Поднять ли ошибку на np.inf и np.nan в X.Возможности таковы:</target>
        </trans-unit>
        <trans-unit id="eaa329f6263ead71ba810671bba1e6a99379040d" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. This parameter does not influence whether y can have np.inf or np.nan values. The possibilities are:</source>
          <target state="translated">Поднять ли ошибку на np.inf и np.nan в X.Этот параметр не влияет на то,может ли y иметь значения np.inf или np.nan.Возможности таковы:</target>
        </trans-unit>
        <trans-unit id="ec8573b1162223970fd6725eca010725203428e3" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68ace26fa0c8880f45dfa331c844e7939329fec1" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter does not influence whether y can have np.inf, np.nan, pd.NA values. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bbeec18546bd2f3b8cccf2897d9a3a9aee68173" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in array. The possibilities are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c551edd4edb4cf1081c3e3d3eb3a36ad8f839a51" translate="yes" xml:space="preserve">
          <source>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to &amp;lsquo;ignore&amp;rsquo; and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.</source>
          <target state="translated">Следует ли выдавать ошибку или игнорировать, если во время преобразования присутствует неизвестная категориальная функция (по умолчанию возникает ошибка). Если для этого параметра задано значение &amp;laquo;игнорировать&amp;raquo; и во время преобразования обнаруживается неизвестная категория, в результирующих столбцах с горячим кодированием для этой функции будут все нули. В обратном преобразовании неизвестная категория будет обозначена как None.</target>
        </trans-unit>
        <trans-unit id="55b5cf4021bca4319afc6cff07e1e1c5a8e21c80" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).</source>
          <target state="translated">Следует ли возвращать функцию принятия решения one-vs-rest ('ovr') формы (n_samples, n_classes), как все другие классификаторы, или исходную функцию принятия решения one-vs-one ('ovo') библиотеки libsvm, которая имеет форму (n_samples , n_классов * (n_classes - 1) / 2).</target>
        </trans-unit>
        <trans-unit id="3e008ca3901c2f4656b69b334cd2bbf88df838cc" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy.</source>
          <target state="translated">Следует ли возвращать функцию принятия решения one-vs-rest ('ovr') формы (n_samples, n_classes), как все другие классификаторы, или исходную функцию принятия решения one-vs-one ('ovo') библиотеки libsvm, которая имеет форму (n_samples , n_классов * (n_classes - 1) / 2). Однако стратегия &amp;laquo;один против одного&amp;raquo; (&amp;laquo;ово&amp;raquo;) всегда используется как мультиклассовая стратегия.</target>
        </trans-unit>
        <trans-unit id="7af50893420dd3e6c393c168dece6ee3ddea82a0" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy. The parameter is ignored for binary classification.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebccc28d7f21db5d9325894eec5fc9e6d02d15c3" translate="yes" xml:space="preserve">
          <source>Whether to return dense output even when the input is sparse. If &lt;code&gt;False&lt;/code&gt;, the output is sparse if both input arrays are sparse.</source>
          <target state="translated">Следует ли возвращать плотный вывод, даже если ввод разреженный. Если &lt;code&gt;False&lt;/code&gt; , выходные данные будут разреженными, если оба входных массива разрежены.</target>
        </trans-unit>
        <trans-unit id="12da7a3ff0421b885caca94ef2caa65b1b016c5f" translate="yes" xml:space="preserve">
          <source>Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.</source>
          <target state="translated">Следует ли возвращать каждое значение ненулевых коэффициентов на прямом пути.Полезно для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="6a16a084b2e44866fb8e9c04ea892f46ef9407d0" translate="yes" xml:space="preserve">
          <source>Whether to return the estimators fitted on each split.</source>
          <target state="translated">Следует ли возвращать оценочные приборы,установленные на каждом отдельном участке.</target>
        </trans-unit>
        <trans-unit id="5e04c1a3b3a800f3b607834e4028e06fab1a7b16" translate="yes" xml:space="preserve">
          <source>Whether to return the fit and score times.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0296def7d7feccd7f063d12d572b0bb6de2b0cd" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations or not.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="642c6fa9e4316671c7770b59f9d72b6641ef628f" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations.</source>
          <target state="translated">Вернуть ли количество итераций.</target>
        </trans-unit>
        <trans-unit id="b549a24da790409f4ec3623e7b38a8b83191c416" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction.</source>
          <target state="translated">Вернуть ли стандартное отклонение апостериорного прогноза.</target>
        </trans-unit>
        <trans-unit id="b33ff2a27948731af021590a907c614a500fc29d" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction. All zeros in this case.</source>
          <target state="translated">Вернуть ли стандартное отклонение апостериорного прогноза.Все нули в этом случае.</target>
        </trans-unit>
        <trans-unit id="7f1c62ca9183e80a5d93cc97ae0f6b09aa7ca43f" translate="yes" xml:space="preserve">
          <source>Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support &lt;code&gt;return_std&lt;/code&gt; in its &lt;code&gt;predict&lt;/code&gt; method if set to &lt;code&gt;True&lt;/code&gt;. Set to &lt;code&gt;True&lt;/code&gt; if using &lt;code&gt;IterativeImputer&lt;/code&gt; for multiple imputations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef9a1d5fe208dc604ffba3d0e60394e32f61bdb0" translate="yes" xml:space="preserve">
          <source>Whether to scale X and Y.</source>
          <target state="translated">Будь то шкала X и Y.</target>
        </trans-unit>
        <trans-unit id="06ccde346dfb7273af2d0810793b1fb5e47df0dc" translate="yes" xml:space="preserve">
          <source>Whether to show informative labels for impurity, etc. Options include &amp;lsquo;all&amp;rsquo; to show at every node, &amp;lsquo;root&amp;rsquo; to show only at the top root node, or &amp;lsquo;none&amp;rsquo; to not show at any node.</source>
          <target state="translated">Показывать ли информативные метки для примесей и т. Д. Параметры включают &amp;laquo;все&amp;raquo; для отображения на каждом узле, &amp;laquo;корень&amp;raquo; для отображения только в верхнем корневом узле или &amp;laquo;нет&amp;raquo;, чтобы не отображать ни на одном узле.</target>
        </trans-unit>
        <trans-unit id="bcd035c2f558018eebfd4e5534f5df5bef89069a" translate="yes" xml:space="preserve">
          <source>Whether to shuffle dataset.</source>
          <target state="translated">Перетасовывать ли набор данных.</target>
        </trans-unit>
        <trans-unit id="9ebdad6142b719150be2c8f67618dba47007c5fd" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each class&amp;rsquo;s samples before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8704d580bb26c2f6617363a0297f26abfb9fda30" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each stratification of the data before splitting into batches.</source>
          <target state="translated">Следует ли перетасовать каждую стратификацию данных,прежде чем разбивать их на части.</target>
        </trans-unit>
        <trans-unit id="5de7b9303caa771da78304a93ebeac224ba77f9b" translate="yes" xml:space="preserve">
          <source>Whether to shuffle samples in each iteration. Only used when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;.</source>
          <target state="translated">Следует ли перемешивать образцы на каждой итерации. Используется только когда solver = 'sgd' или 'adam'.</target>
        </trans-unit>
        <trans-unit id="3558a0c3a77b9ce3c242cc621a2d776c46a133af" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches.</source>
          <target state="translated">Следует ли перетасовать данные до их разделения на части.</target>
        </trans-unit>
        <trans-unit id="2b23f04bb0d66dad8fab9e868398f1780b26b6ed" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ddc8f26baf73b311e3fd82ce49af7a5449330660" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting it in batches.</source>
          <target state="translated">Следует ли перетасовывать данные,прежде чем разбивать их на части.</target>
        </trans-unit>
        <trans-unit id="f23a63355a4e388bf6ee14cbad5c7c9c8b8c8007" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the samples.</source>
          <target state="translated">Неважно,перетасовывать ли образцы.</target>
        </trans-unit>
        <trans-unit id="a5c75421672ae29d738aa02687f5d9f3ec0cf20c" translate="yes" xml:space="preserve">
          <source>Whether to shuffle training data before taking prefixes of it based on``train_sizes``.</source>
          <target state="translated">Перетасовывать ли тренировочные данные до получения префиксов на основе ``тренировочных размеров``.</target>
        </trans-unit>
        <trans-unit id="ce33fd98a79a5db67d420efb6fcabed70acb96c4" translate="yes" xml:space="preserve">
          <source>Whether to sort x before computing. If False, assume that x must be either monotonic increasing or monotonic decreasing. If True, y is used to break ties when sorting x. Make sure that y has a monotonic relation to x when setting reorder to True.</source>
          <target state="translated">Сортировать ли х перед вычислением.Если False,предположим,что x должен быть либо монотонным увеличивающимся,либо монотонным уменьшающимся.Если True,то y используется для разрыва связей при сортировке x.Убедитесь,что y имеет монотонное отношение к x при установке переупорядочивания в True.</target>
        </trans-unit>
        <trans-unit id="5091491cac888f3972a1197cfef1256978c18b5f" translate="yes" xml:space="preserve">
          <source>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</source>
          <target state="translated">Разделить ли разреженный характерный вектор на конкатенуацию его отрицательной и положительной частей.Это может улучшить производительность последующих классификаторов.</target>
        </trans-unit>
        <trans-unit id="8b58e41338c55eaf50346244bd6082e4f3c1a628" translate="yes" xml:space="preserve">
          <source>Whether to use Nesterov&amp;rsquo;s momentum. Only used when solver=&amp;rsquo;sgd&amp;rsquo; and momentum &amp;gt; 0.</source>
          <target state="translated">Использовать ли импульс Нестерова. Используется только когда solver = 'sgd' и импульс&amp;gt; 0.</target>
        </trans-unit>
        <trans-unit id="6cb6c1fd9950933ec2b1bd309d3cbc04da69eccd" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d97545296a16ed9ee24e38ded3551b9344d66c64" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;code&gt;n_targets&lt;/code&gt; or &lt;code&gt;n_samples&lt;/code&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама и Xy для ускорения вычислений. Повышает производительность, когда &lt;code&gt;n_targets&lt;/code&gt; или &lt;code&gt;n_samples&lt;/code&gt; очень большие. Обратите внимание: если у вас уже есть такие матрицы, вы можете передать их непосредственно методу fit.</target>
        </trans-unit>
        <trans-unit id="7dc600168d6ae4c500452eb14badcdfddafb11ff" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &amp;lsquo;auto&amp;rsquo; let us decide. The Gram matrix can also be passed as argument, but it will be used only for the selection of parameter alpha, if alpha is &amp;lsquo;aic&amp;rsquo; or &amp;lsquo;bic&amp;rsquo;.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &amp;laquo;авто&amp;raquo;, мы решим. Матрица Грама также может быть передана в качестве аргумента, но она будет использоваться только для выбора параметра alpha, если alpha равно 'aic' или 'bic'.</target>
        </trans-unit>
        <trans-unit id="0057a82fcc5e3ed086a2d1961e27e45b3f58597f" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрица Грама также может быть передана в качестве аргумента.</target>
        </trans-unit>
        <trans-unit id="419f7e60c7c4f4f84360a1078ab4b36ce5bf208a" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрица Грама также может быть передана в качестве аргумента. Для разреженного ввода эта опция всегда имеет значение &lt;code&gt;True&lt;/code&gt; , чтобы сохранить разреженность.</target>
        </trans-unit>
        <trans-unit id="18cfe378dd4d6390fca460de4e70af73f097cdf4" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Если установлено &lt;code&gt;'auto'&lt;/code&gt; мы решим. Матрицу Грама нельзя передавать в качестве аргумента, поскольку мы будем использовать только подмножества X.</target>
        </trans-unit>
        <trans-unit id="2bc24bd08e69b99e2a7b63ee3e5ac92e16a75bc1" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">Следует ли использовать предварительно вычисленную матрицу Грама для ускорения вычислений. Матрица Грама также может быть передана в качестве аргумента. Для разреженного ввода эта опция всегда имеет значение &lt;code&gt;True&lt;/code&gt; , чтобы сохранить разреженность.</target>
        </trans-unit>
        <trans-unit id="1efc80d653c0b8715eb15bdf1b19f3becd74a957" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Использовать ли раннюю остановку для прекращения обучения,когда оценка не улучшается.Если установлено значение True,то это автоматически откладывает часть тренировочных данных как валидацию и прекращает обучение,когда результат валидации не улучшается,по крайней мере,на n_iter_no_change последовательных эпох.</target>
        </trans-unit>
        <trans-unit id="46750b1ddce70e8be53fc930ce5b9a753b67b8f6" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="febff6e36a4dd65c498e48c75789d34dc34067ef" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9af303ba091050935df1b1843777cae63d69ca4c" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Следует ли использовать раннюю остановку для прекращения обучения, когда оценка валидации не улучшается. Если установлено значение true, он автоматически выделяет 10% обучающих данных в качестве проверки и прекращает обучение, если оценка проверки не улучшается по крайней мере на &lt;code&gt;tol&lt;/code&gt; для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных эпох. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="998484dc55c21823abb36e2b54f5b8f623a0a41f" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">Следует ли использовать раннюю остановку для прекращения обучения, когда оценка валидации не улучшается. Если установлено значение true, он автоматически выделяет 10% обучающих данных в качестве проверки и прекращает обучение, если оценка проверки не улучшается по крайней мере на tol для &lt;code&gt;n_iter_no_change&lt;/code&gt; последовательных эпох. Действует только когда solver = 'sgd' или 'adam'</target>
        </trans-unit>
        <trans-unit id="87617bcbcc672722844a1d3a57de3b252ff02aa0" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cec695b146ca339e70be6934dce1a5005aa741f4" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">Использовать ли раннюю остановку для прекращения тренировок при проверке.оценка не улучшается.Если установлено значение True,то это автоматически откладывает часть тренировочных данных как валидацию и прекращает обучение,когда результат валидации не улучшается,по крайней мере,допустимо для n_iter_no_change последовательных эпох.</target>
        </trans-unit>
        <trans-unit id="09b2b6c8cb36dc98a800b35af81d1805bc50fee1" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aad0324e5e5b11eda436b08ef9513e34456be6fd" translate="yes" xml:space="preserve">
          <source>Whether to use mini-batch k-means, which is faster but may get different results.</source>
          <target state="translated">Использовать ли мини-компоненты k-средств,что быстрее,но может дать разные результаты.</target>
        </trans-unit>
        <trans-unit id="098e9f05a9707c21daca2709c375c5f67a6fc326" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">Использовать ли нестандартные выборки для оценки R^2 на невидимых данных.</target>
        </trans-unit>
        <trans-unit id="cf1378e2f07c46392b05b68a8d3fb4a1b87de256" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization accuracy.</source>
          <target state="translated">Использовать ли нестандартные образцы для оценки точности обобщения.</target>
        </trans-unit>
        <trans-unit id="b9d7a8d80bd713aecc3b75a6342d626d4ac28b69" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization error.</source>
          <target state="translated">Использовать ли нестандартные примеры для оценки погрешности обобщения.</target>
        </trans-unit>
        <trans-unit id="3aa24f38e2caae33363ee03e7cecc2915d7b4a6e" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic.</source>
          <target state="translated">Использовать ли сокращающуюся эвристику.</target>
        </trans-unit>
        <trans-unit id="f030250afefd9a8186bdcbf55c79f9c30e8d6a17" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic. See the &lt;a href=&quot;../svm#shrinking-svm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0fcee6cb3493ee9e39e4cf5b70ffc63bc5b7fc72" translate="yes" xml:space="preserve">
          <source>Whether to zip the stored data on disk. If an integer is given, it should be between 1 and 9, and sets the amount of compression. Note that compressed arrays cannot be read by memmapping.</source>
          <target state="translated">Следует ли заархивировать сохраненные на диске данные.Если задано целое число,то оно должно быть между 1 и 9 и задает степень сжатия.Обратите внимание,что сжатые массивы не могут быть прочитаны путем запоминания.</target>
        </trans-unit>
        <trans-unit id="67c666eda0eb6c9f89cf06ca0fe8ba3d19260935" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8c18609d5573425cb13e22e1562611896bad931" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices. True by default.</source>
          <target state="translated">Должна ли трансформация производить scipy.редкие матрицы.По умолчанию верно.</target>
        </trans-unit>
        <trans-unit id="a2a2f7408a4ab356f12406498e7b656415a8f8e4" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the [0, 1] interval, i.e. is not a proper probability. If True, the smallest value in y_prob is linearly mapped onto 0 and the largest one onto 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96e3c213b0373954a6f42c2953a288bf58e9c8e1" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not a proper probability. If True, the smallest value in y_prob is mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">Нужно ли нормировать y_prob в бине [0,1],т.е.не является правильной вероятностью.Если True,то наименьшее значение в y_prob отображается на 0,а наибольшее-на 1.</target>
        </trans-unit>
        <trans-unit id="673ccf9c3156ee120e948d124a09a8f79d0986df" translate="yes" xml:space="preserve">
          <source>Which SVD method to use. If &amp;lsquo;lapack&amp;rsquo; use standard SVD from scipy.linalg, if &amp;lsquo;randomized&amp;rsquo; use fast &lt;code&gt;randomized_svd&lt;/code&gt; function. Defaults to &amp;lsquo;randomized&amp;rsquo;. For most applications &amp;lsquo;randomized&amp;rsquo; will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for &lt;code&gt;iterated_power&lt;/code&gt;. If this is not sufficient, for maximum precision you should choose &amp;lsquo;lapack&amp;rsquo;.</source>
          <target state="translated">Какой метод СВД использовать. Если &quot;Lapack&quot; использует стандартный SVD из scipy.linalg, если &quot;randomized&quot;, используйте быструю функцию &lt;code&gt;randomized_svd&lt;/code&gt; . По умолчанию &quot;рандомизировано&quot;. Для большинства приложений &amp;laquo;рандомизация&amp;raquo; будет достаточно точной, но при этом обеспечит значительный прирост скорости. Точность также можно повысить, установив более высокие значения для &lt;code&gt;iterated_power&lt;/code&gt; . Если этого недостаточно, для максимальной точности следует выбрать &amp;laquo;лапак&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="3f4bd36722594cddb9c4f04fa1feac290cb2c703" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &amp;lsquo;precomputed&amp;rsquo; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &amp;lsquo;euclidean&amp;rsquo; uses the negative squared euclidean distance between points.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f51286fa5438dabdb2fdc9e6a35c79244bd208d2" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &lt;code&gt;precomputed&lt;/code&gt; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &lt;code&gt;euclidean&lt;/code&gt; uses the negative squared euclidean distance between points.</source>
          <target state="translated">Какое сходство использовать. На данный момент поддерживаются &lt;code&gt;precomputed&lt;/code&gt; и &lt;code&gt;euclidean&lt;/code&gt; . &lt;code&gt;euclidean&lt;/code&gt; использует отрицательный квадрат евклидова расстояния между точками.</target>
        </trans-unit>
        <trans-unit id="0a291d7f5d694ce4dae77d370f938e385f2f41cf" translate="yes" xml:space="preserve">
          <source>Which kind of estimators should be returned. If None, no filter is applied and all estimators are returned. Possible values are &amp;lsquo;classifier&amp;rsquo;, &amp;lsquo;regressor&amp;rsquo;, &amp;lsquo;cluster&amp;rsquo; and &amp;lsquo;transformer&amp;rsquo; to get estimators only of these specific types, or a list of these to get the estimators that fit at least one of the types.</source>
          <target state="translated">Какие оценщики нужно вернуть. Если Нет, фильтр не применяется, и возвращаются все оценки. Возможные значения: &amp;laquo;классификатор&amp;raquo;, &amp;laquo;регрессор&amp;raquo;, &amp;laquo;кластер&amp;raquo; и &amp;laquo;преобразователь&amp;raquo;, чтобы получить оценщики только этих конкретных типов, или их список, чтобы получить оценщики, соответствующие хотя бы одному из типов.</target>
        </trans-unit>
        <trans-unit id="9ab873abc046d5e79c6628d1e73d15a9a8c8a011" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Какой критерий связи использовать.Критерий связи определяет,какое расстояние использовать между наборами функций.Алгоритм объединит пары кластеров,которые минимизируют этот критерий.</target>
        </trans-unit>
        <trans-unit id="17ba6fc895d15866ea1e60a4db791726755dc58f" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">Какой критерий связи использовать.Критерий связи определяет,какое расстояние использовать между наборами наблюдений.Алгоритм объединит пары кластеров,которые минимизируют этот критерий.</target>
        </trans-unit>
        <trans-unit id="7c032065ee1e199d65a12de581955d2510001155" translate="yes" xml:space="preserve">
          <source>Which metric to use for computing pairwise distances between samples from the original input space. If metric is &amp;lsquo;precomputed&amp;rsquo;, X must be a matrix of pairwise distances or squared distances. Otherwise, see the documentation of argument metric in sklearn.pairwise.pairwise_distances for a list of available metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ca40022d1c5dcd68056f855d9cb29fbb48c9062" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgement: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">Какая модель является лучшей-это вопрос субъективного суждения:хотим ли мы отдавать предпочтение моделям,которые только захватывают большую картину,чтобы суммировать и объяснить большую часть структуры данных,игнорируя при этом детали,или же мы предпочитаем модели,которые близко следуют за областями высокой плотности сигнала?</target>
        </trans-unit>
        <trans-unit id="3bad9460d63c46d91cb72ce5e70c801fdf7d8e5b" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgment: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9b07db46ccf2aab5a3f471f9311e28ace0c3658" translate="yes" xml:space="preserve">
          <source>Which strategy to use to initialize the missing values. Same as the &lt;code&gt;strategy&lt;/code&gt; parameter in &lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt; Valid values: {&amp;ldquo;mean&amp;rdquo;, &amp;ldquo;median&amp;rdquo;, &amp;ldquo;most_frequent&amp;rdquo;, or &amp;ldquo;constant&amp;rdquo;}.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8cddae54ed0b1b16ee030ff58543e83ff547ded" translate="yes" xml:space="preserve">
          <source>While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.</source>
          <target state="translated">В то время как Isomap,LLE и варианты лучше всего подходят для разворачивания одного непрерывного низкоразмерного коллектора,t-SNE сосредоточится на локальной структуре данных и будет стремиться к извлечению кластеризованных локальных групп образцов,как показано на примере S-образной кривой.Такая возможность группировать образцы на основе локальной структуры может быть полезна для визуального разворачивания набора данных,который состоит из нескольких коллекторов одновременно,как это происходит в наборе цифровых данных.</target>
        </trans-unit>
        <trans-unit id="d80a7676bafb31f5f9bcb99f7aed7e1817a9d535" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">В то время как модели SVM, полученные из &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; и &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear,&lt;/a&gt; используют &lt;code&gt;C&lt;/code&gt; в качестве параметра регуляризации, большинство других оценщиков используют &lt;code&gt;alpha&lt;/code&gt; . Точная эквивалентность между степенью регуляризации двух моделей зависит от точной целевой функции, оптимизированной моделью. Например, когда используется &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; регрессии sklearn.linear_model.Ridge , отношение между ними задается как \ (C = \ frac {1} {alpha} \).</target>
        </trans-unit>
        <trans-unit id="e19b90ac75c89776c8025a4fe5ef49998061f2d2" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b688dd0a76a7a11c780bc8304b263ca13e9c529b" translate="yes" xml:space="preserve">
          <source>While both methods should be close in general, they might differ in some specific settings. The &amp;lsquo;brute&amp;rsquo; method assumes the existence of the data points \((x_S, x_C^{(i)})\). When the features are correlated, such artificial samples may have a very low probability mass. The &amp;lsquo;brute&amp;rsquo; and &amp;lsquo;recursion&amp;rsquo; methods will likely disagree regarding the value of the partial dependence, because they will treat these unlikely samples differently. Remember, however, that the primary assumption for interpreting PDPs is that the features should be independent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb6c7d447c33735b14bfab3f939085b49d50d551" translate="yes" xml:space="preserve">
          <source>While defining the custom scoring function alongside the calling function should work out of the box with the default joblib backend (loky), importing it from another module will be a more robust approach and work independently of the joblib backend.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c20daeb41107431c48223b43ad4fe138aa4845d5" translate="yes" xml:space="preserve">
          <source>While experimenting with any learning algorithm, it is important not to test the prediction of an estimator on the data used to fit the estimator as this would not be evaluating the performance of the estimator on &lt;strong&gt;new data&lt;/strong&gt;. This is why datasets are often split into &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; data.</source>
          <target state="translated">Экспериментируя с любым алгоритмом обучения, важно не тестировать предсказание оценщика на данных, используемых для соответствия оценщику, так как это не будет оценивать производительность оценщика на &lt;strong&gt;новых данных&lt;/strong&gt; . Вот почему наборы данных часто разделяются на данные для &lt;em&gt;обучения&lt;/em&gt; и &lt;em&gt;тестирования&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="f8808630553e3f4de197fcbd8d96757a9a769400" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt;. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d04cd5b9d0463d9bc89f841d571873fec4953569" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it&amp;rsquo;s safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt; Similarly if we know that the generative process has a group structure (samples from collected from different subjects, experiments, measurement devices) it safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">Хотя данные iid являются распространенным предположением в теории машинного обучения, на практике оно редко выполняется. Если один знает , что образцы были получены с использованием процесса , зависящих от времени, это безопаснее использовать &lt;a href=&quot;#timeseries-cv&quot;&gt;осведомленный схемы кросс-валидации временных рядов&lt;/a&gt; Аналогично , если мы знаем , что порождающий процесс имеет структуру группы (образцы из собраны из разных предметов, экспериментов , измерительные устройства) безопаснее использовать &lt;a href=&quot;#group-cv&quot;&gt;групповую перекрестную проверку&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0526a7a936d1a8c691dcdaa23691304fc8ebc7ef" translate="yes" xml:space="preserve">
          <source>While in the spirit of an online algorithm, the class &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt; does not implement &lt;code&gt;partial_fit&lt;/code&gt; because the algorithm is online along the features direction, not the samples direction.</source>
          <target state="translated">В духе интерактивного алгоритма класс &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt; не реализует &lt;code&gt;partial_fit&lt;/code&gt; , потому что алгоритм находится в оперативном режиме по направлению функций, а не по направлению выборки.</target>
        </trans-unit>
        <trans-unit id="c8d4a37562dd2bb8e9910fd82f43df80f682c63a" translate="yes" xml:space="preserve">
          <source>While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the &amp;lsquo;weight&amp;rsquo; axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.</source>
          <target state="translated">Хотя многие алгоритмы (такие как SVM, K-ближайших соседей и логистическая регрессия) требуют нормализации функций, интуитивно мы можем рассматривать анализ основных компонентов (PCA) как яркий пример того, когда важна нормализация. В PCA нас интересуют компоненты, которые увеличивают дисперсию. Если один компонент (например, рост человека) меняется меньше, чем другой (например, вес) из-за их соответствующих масштабов (метры против килограммов), PCA может определить, что направление максимальной дисперсии более точно соответствует оси &amp;laquo;веса&amp;raquo;, если эти характеристики не масштабируются. Поскольку изменение роста на один метр может считаться гораздо более важным, чем изменение веса на один килограмм, это явно неверно.</target>
        </trans-unit>
        <trans-unit id="3e272f5577ff59f34cc0835d41b4f8bd0e7fa207" translate="yes" xml:space="preserve">
          <source>While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.</source>
          <target state="translated">В то время как модели,сохранённые с помощью одной версии scikit-learn,могут загружаться в других версиях,это совершенно не поддерживается и не рекомендуется.Следует также помнить,что операции,выполняемые с такими данными,могут дать разные и неожиданные результаты.</target>
        </trans-unit>
        <trans-unit id="5cdd1c0f02e03a5a1b156076678017404f8561ab" translate="yes" xml:space="preserve">
          <source>While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell &lt;code&gt;[i, j]&lt;/code&gt; has value 1 if sample &lt;code&gt;i&lt;/code&gt; has label &lt;code&gt;j&lt;/code&gt; and value 0 otherwise.</source>
          <target state="translated">В то время как многоклассовые данные предоставляются метрике, как двоичные цели, в виде массива меток классов, данные с несколькими метками указываются как индикаторная матрица, в которой ячейка &lt;code&gt;[i, j]&lt;/code&gt; имеет значение 1, если образец &lt;code&gt;i&lt;/code&gt; имеет метку &lt;code&gt;j&lt;/code&gt; , и значение 0 в противном случае. .</target>
        </trans-unit>
        <trans-unit id="ed422f68a65d31027201e13d55d1a7c59ba06f45" translate="yes" xml:space="preserve">
          <source>While not particularly fast to process, Python&amp;rsquo;s &lt;code&gt;dict&lt;/code&gt; has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.</source>
          <target state="translated">Хотя Python &lt;code&gt;dict&lt;/code&gt; не особенно быстро обрабатывается, он имеет преимущества в том, что он удобен в использовании, является разреженным (отсутствующие функции не нужно сохранять) и хранит имена функций в дополнение к значениям.</target>
        </trans-unit>
        <trans-unit id="6575e62afd8d9d86f5e5759f0c1f4bf12add49e4" translate="yes" xml:space="preserve">
          <source>While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.</source>
          <target state="translated">В то время как некоторая локальная информация о позиционировании может быть сохранена путем извлечения n-грамм вместо отдельных слов,мешок слов и мешок n-грамм разрушают большую часть внутренней структуры документа и,следовательно,большую часть смысла,несущего эту внутреннюю структуру.</target>
        </trans-unit>
        <trans-unit id="f9eb71a899b2efe02a5e86463ae919f1b60ed0f7" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any (sparse) feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">В то время как преобразователь &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; работает с любой (разреженной) матрицей признаков, рекомендуется использовать его для матриц tf &amp;ndash; idf вместо необработанных частотных подсчетов в настройке обработки LSA / документа. В частности, следует включить сублинейное масштабирование и обратную частоту документа ( &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ), чтобы приблизить значения функций к гауссовскому распределению, компенсируя ошибочные предположения LSA о текстовых данных.</target>
        </trans-unit>
        <trans-unit id="f9e8e04743afddc659f8d58efbc124813976ac9e" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29a2650e25fbd5181744282ce886a2b96e4ac93d" translate="yes" xml:space="preserve">
          <source>While the above example sets the &lt;code&gt;standardize&lt;/code&gt; option to &lt;code&gt;False&lt;/code&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; will apply zero-mean, unit-variance normalization to the transformed output by default.</source>
          <target state="translated">В то время как в приведенном выше примере для параметра &lt;code&gt;standardize&lt;/code&gt; значение &lt;code&gt;False&lt;/code&gt; , &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; по умолчанию&lt;/a&gt; применяет нормализацию с нулевым средним и единичной дисперсией к преобразованному результату.</target>
        </trans-unit>
        <trans-unit id="e50cabfff84e84e9590f53c8299406f023e4e46d" translate="yes" xml:space="preserve">
          <source>While the hyperparameters chosen by optimizing LML have a considerable larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad) This undesirable effect is caused by the Laplace approximation used internally by GPC.</source>
          <target state="translated">В то время как гиперпараметры,выбранные при оптимизации LML,имеют значительно больший размер LML,они работают несколько хуже по лог-потере на тестовых данных.Из рисунка видно,что это происходит потому,что они демонстрируют резкое изменение вероятностей класса на границах класса (что хорошо),но предсказывают вероятности вблизи 0.5 расстояния от границ класса (что плохо)Этот нежелательный эффект вызван аппроксимацией Лапласа,используемой внутри GPC.</target>
        </trans-unit>
        <trans-unit id="2c9458b61e67bda12a1df752c0cc6921b6ff30dd" translate="yes" xml:space="preserve">
          <source>While the parameter &lt;code&gt;min_samples&lt;/code&gt; primarily controls how tolerant the algorithm is towards noise (on noisy and large data sets it may be desirable to increase this parameter), the parameter &lt;code&gt;eps&lt;/code&gt; is &lt;em&gt;crucial to choose appropriately&lt;/em&gt; for the data set and distance function and usually cannot be left at the default value. It controls the local neighborhood of the points. When chosen too small, most data will not be clustered at all (and labeled as &lt;code&gt;-1&lt;/code&gt; for &amp;ldquo;noise&amp;rdquo;). When chosen too large, it causes close clusters to be merged into one cluster, and eventually the entire data set to be returned as a single cluster. Some heuristics for choosing this parameter have been discussed in the literature, for example based on a knee in the nearest neighbor distances plot (as discussed in the references below).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17e6df329175ba9fee759ed839a4afe469b184fd" translate="yes" xml:space="preserve">
          <source>While the tf&amp;ndash;idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the &lt;code&gt;binary&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. In particular, some estimators such as &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf&amp;ndash;idf values while the binary occurrence info is more stable.</source>
          <target state="translated">Хотя нормализация tf &amp;ndash; idf часто бывает очень полезной, могут быть случаи, когда двоичные маркеры вхождения могут предложить лучшие функции. Этого можно достичь с помощью &lt;code&gt;binary&lt;/code&gt; параметра &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; . В частности, некоторые оценщики, такие как &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes,&lt;/a&gt; явно моделируют дискретные логические случайные величины. Кроме того, очень короткие тексты могут иметь зашумленные значения tf &amp;ndash; idf, тогда как двоичная информация о вхождении более стабильна.</target>
        </trans-unit>
        <trans-unit id="ed181b0221327c005991b804ef6da84808fa6b75" translate="yes" xml:space="preserve">
          <source>While these examples give some intuition about the algorithms, this intuition might not apply to very high dimensional data.</source>
          <target state="translated">Хотя эти примеры дают некоторое представление об алгоритмах,эта интуиция может не относиться к очень объемным данным.</target>
        </trans-unit>
        <trans-unit id="20e141fdf1f5d5d16051f029790d3b9e841c723d" translate="yes" xml:space="preserve">
          <source>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</source>
          <target state="translated">Хотя использование сетки настроек параметров в настоящее время является наиболее широко используемым методом оптимизации параметров, другие методы поиска обладают более благоприятными свойствами. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; реализует рандомизированный поиск по параметрам, где каждый параметр выбирается из распределения по возможным значениям параметров. У этого есть два основных преимущества перед исчерпывающим поиском:</target>
        </trans-unit>
        <trans-unit id="37619fc13053f82b7cb7da3d24ceb1598ab6d05c" translate="yes" xml:space="preserve">
          <source>White</source>
          <target state="translated">White</target>
        </trans-unit>
        <trans-unit id="ae7c1638fd1917cb535ca7c68b4bd5f19a47ea30" translate="yes" xml:space="preserve">
          <source>White kernel.</source>
          <target state="translated">Белое ядро.</target>
        </trans-unit>
        <trans-unit id="6eaf9e8193566018ccba0d72a95d7647c23f2585" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.</source>
          <target state="translated">Отбеливание удалит некоторую информацию из преобразованного сигнала (шкалы относительной дисперсии компонентов),но может в какой-то момент улучшить точность прогнозирования последующих оценок,заставив их данные уважать некоторые жестко привязанные предположения.</target>
        </trans-unit>
        <trans-unit id="07aaa00ad7b994406ce70b8bd7598f7e15e6859a" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.</source>
          <target state="translated">Отбеливание удалит некоторую информацию из преобразованного сигнала (шкалы относительной дисперсии компонентов),но иногда может повысить точность прогнозирования последующих оценок,заставляя данные учитывать некоторые жестко установленные допущения.</target>
        </trans-unit>
        <trans-unit id="c6caecec2578a0de52910be667f4fa7e322f3d31" translate="yes" xml:space="preserve">
          <source>Why does the plot above suggest that an increase in age leads to a decrease in wage? Why the &lt;a href=&quot;#marginal-dependencies&quot;&gt;initial pairplot&lt;/a&gt; is telling the opposite?</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5ed864ec9d16ad31c6639d1d4c3bf64e3372001" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Davies-Bouldin index.</source>
          <target state="translated">Запись в Википедии для индекса Дэвиса-Болдин.</target>
        </trans-unit>
        <trans-unit id="3ce8e9b9f756deae78c09a314c4cf49a1aacdb66" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Discounted Cumulative Gain</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0184957526e21d06d99d8f077fe30eb4aaec4f9" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for contingency matrix</source>
          <target state="translated">Запись в Википедии для матрицы непредвиденных обстоятельств</target>
        </trans-unit>
        <trans-unit id="55a3b17abc1268c1d436ba897c97b456b993b4ea" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the (normalized) Mutual Information</source>
          <target state="translated">Запись в Википедии для (нормализованной)взаимной информации</target>
        </trans-unit>
        <trans-unit id="1f069c9fec7504cb4f8a493de2e1b54ffc547081" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Adjusted Mutual Information</source>
          <target state="translated">Запись в Википедии для скорректированной взаимной информации</target>
        </trans-unit>
        <trans-unit id="8030a2f6eb81271b3b56dfad08af7aaea7fcfc10" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Average precision</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca2fe3eff096e2c0ff94d3c0f6ce61af74cc646f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Brier score.</source>
          <target state="translated">Запись в Википедии очков Брайера.</target>
        </trans-unit>
        <trans-unit id="ffd655e9eb3a21416da69aac696bc5ce043a000f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Cohen&amp;rsquo;s kappa.</source>
          <target state="translated">Запись в Википедии о каппе Коэна.</target>
        </trans-unit>
        <trans-unit id="8d8ae14fc3bcf00321ca2d4b9c37c609195c6275" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the F1-score</source>
          <target state="translated">Запись в Википедии для F1-экрана</target>
        </trans-unit>
        <trans-unit id="0d85777073541b6f8aecb3488f1962f6903fd77c" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Fowlkes-Mallows Index</source>
          <target state="translated">Вход в Википедию для Индекса Фаулкс Допусков</target>
        </trans-unit>
        <trans-unit id="738fb31d9583a6207339f58c0335e89437aa096f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Jaccard index</source>
          <target state="translated">Запись в Википедии для индекса Jaccard</target>
        </trans-unit>
        <trans-unit id="d69dce297a7e32abae3549494346594b424875bc" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Matthews Correlation Coefficient</source>
          <target state="translated">Запись в Википедии о коэффициенте корреляции Матфея</target>
        </trans-unit>
        <trans-unit id="d1c0692994293b3fef98ac5de7dd74e23175c8d1" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Precision and recall</source>
          <target state="translated">Запись в Википедии о Точности и Вспоминании</target>
        </trans-unit>
        <trans-unit id="6c2dd7ccbd3afed766d1ee6ce92b068445c27bbb" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Receiver operating characteristic</source>
          <target state="translated">Запись в Википедии об операционной характеристике приемника</target>
        </trans-unit>
        <trans-unit id="caae1d529b64ebeb0d4804273e9107122a389ac6" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the adjusted Rand index</source>
          <target state="translated">Запись в Википедии для скорректированного индекса Рэнда</target>
        </trans-unit>
        <trans-unit id="ccc412d2bb1bb2397fbce7363889e5816eda01a2" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b36309de0386ff9491f5f72624bcd77d6a05e19" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis &lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af0472efa729237e92d89bb05e9ca0c8e7f37b5f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Coefficient of determination</source>
          <target state="translated">Запись в Википедии о Коэффициенте определения</target>
        </trans-unit>
        <trans-unit id="e345be5719f19335870d8d3a8cdd20b6bd307aa0" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hamming distance</source>
          <target state="translated">Запись в Википедии о расстоянии до Хэмминга</target>
        </trans-unit>
        <trans-unit id="1857fa6b095ad66d104ea60f4be3df45f12529a3" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hinge loss</source>
          <target state="translated">Запись в Википедии о потере шарнира</target>
        </trans-unit>
        <trans-unit id="d4ccd1b47442c7552ebe73794cdd38515c5ffdef" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Lasso</source>
          <target state="translated">Запись в Википедии о Лассо</target>
        </trans-unit>
        <trans-unit id="8751f23b19110bb289e70c6d8c900548f6c9b761" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Least-angle regression</source>
          <target state="translated">Запись в Википедии о регрессии по наименее развитым уголкам</target>
        </trans-unit>
        <trans-unit id="ed8f4a303fe71f9ad0ec1e1b74ef6fe644dad80d" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Silhouette Coefficient</source>
          <target state="translated">Запись в Википедии о коэффициенте силуэта</target>
        </trans-unit>
        <trans-unit id="0b665174747365aef367583fb0c32fb021d06a22" translate="yes" xml:space="preserve">
          <source>Wikipedia principal eigenvector</source>
          <target state="translated">Главный собачий вектор Википедии</target>
        </trans-unit>
        <trans-unit id="713348b23d025b202ea7f033591c046a82a1973b" translate="yes" xml:space="preserve">
          <source>Will be ignored when &lt;code&gt;y_true&lt;/code&gt; is binary.</source>
          <target state="translated">Будет игнорироваться, если &lt;code&gt;y_true&lt;/code&gt; является двоичным.</target>
        </trans-unit>
        <trans-unit id="af498f4dd6f24dbc1f93745e77fe6ed29d0b9d0c" translate="yes" xml:space="preserve">
          <source>Will return sparse matrix if set True else will return an array.</source>
          <target state="translated">Возвращает разреженную матрицу,если установлено значение True else,возвращает массив.</target>
        </trans-unit>
        <trans-unit id="f02c359862a5df44abc185413e06bdb77cfc5770" translate="yes" xml:space="preserve">
          <source>Williams, C.K.I. and Seeger, M. &amp;ldquo;Using the Nystroem method to speed up kernel machines&amp;rdquo;, Advances in neural information processing systems 2001</source>
          <target state="translated">Уильямс, CKI и Сигер, М. &amp;laquo;Использование метода Nystroem для ускорения ядерных машин&amp;raquo;, Успехи в системах обработки нейронной информации 2001</target>
        </trans-unit>
        <trans-unit id="a20af0cf6ba0496377888d152bfba536fcfdefc1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{\text{n\_classes}}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">Если установлено значение &lt;code&gt;adjusted=True&lt;/code&gt; , сбалансированная точность сообщает об относительном увеличении от \ (\ texttt {сбалансированная-точность} (y, \ mathbf {0}, w) = \ frac {1} {\ text {n \ _classes}}} \). В двоичном случае это также известно как &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* статистика Юдена *&lt;/a&gt; , или &lt;em&gt;информированность&lt;/em&gt; .</target>
        </trans-unit>
        <trans-unit id="ad0e52061072794be72972cbf40b994abb34f953" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{n\_classes}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8a7d860e7dc8979710329f97e747eaff0d3415d3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the input data.</source>
          <target state="translated">При &lt;code&gt;early_stopping=False&lt;/code&gt; модель подбирается для всех входных данных, а критерий остановки основан на целевой функции, вычисленной на входных данных.</target>
        </trans-unit>
        <trans-unit id="3fe735414475494b49457f76f31eea3026d08560" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5515c693f110557bb04dd8dc133e8927dc9c68e0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score (using the &lt;code&gt;score&lt;/code&gt; method) computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ceb9e226f3e04a8a66252e3801eed93f740afd9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">При &lt;code&gt;early_stopping=True&lt;/code&gt; входные данные разделяются на обучающий набор и проверочный набор. Затем модель настраивается на обучающий набор, и критерий остановки основан на оценке прогноза, вычисленной на проверочном наборе. Размер набора проверки можно изменить с помощью параметра &lt;code&gt;validation_fraction&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="318aced6d4dfc924ad223bd54e79ede301143b06" translate="yes" xml:space="preserve">
          <source>With SGD or Adam, training supports online and mini-batch learning.</source>
          <target state="translated">С помощью SGD или Адама обучение поддерживается в режиме онлайн и в мини-группах.</target>
        </trans-unit>
        <trans-unit id="bebfaf6a5f7ee4311c7425773ef87a0b1b61dcc0" translate="yes" xml:space="preserve">
          <source>With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.</source>
          <target state="translated">При использовании SVM и логистической регрессии параметр C управляет редкостью:чем меньше C,тем меньше функций выбрано.С Lasso,чем выше альфа-параметр,тем меньше функций выбрано.</target>
        </trans-unit>
        <trans-unit id="2e07775067fbbb8cee792ed1d4b4b0282fd223be" translate="yes" xml:space="preserve">
          <source>With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:</source>
          <target state="translated">С \(P'(j)=|V_j|/N\).Взаимная информация (MI)между \(U\)и \(V\)рассчитывается по:</target>
        </trans-unit>
        <trans-unit id="2042997590ba0f656467c3f6df43427a875d6409" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5313dd287c9c493fc21b86c81282cea7d0608304" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image:</source>
          <target state="translated">С помощью агломеративной кластеризации можно указать,какие образцы могут быть сгруппированы вместе,предоставив график соединений.Графики в scikit-learn представлены их матрицей связности.Часто используется разреженная матрица.Это может быть полезно,например,для получения связанных областей (иногда также называемых связанными компонентами)при кластеризации изображения:</target>
        </trans-unit>
        <trans-unit id="ebae629f7af13ae26b867ab75161458173d10bdc" translate="yes" xml:space="preserve">
          <source>With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:</source>
          <target state="translated">Что касается деревьев принятия решений,то эта стратегия может быть легко использована для поддержки многопроизводительных задач.Это требует следующих изменений:</target>
        </trans-unit>
        <trans-unit id="d6eab2b8513179355ba20cab88473d0665849027" translate="yes" xml:space="preserve">
          <source>With such an abundance of clues that distinguish newsgroups, the classifiers barely have to identify topics from text at all, and they all perform at the same high level.</source>
          <target state="translated">При таком изобилии подсказок,отличающих новостные группы,классификаторам едва ли удается выделить темы из текста,и все они работают на одном и том же высоком уровне.</target>
        </trans-unit>
        <trans-unit id="ba25a12704b8225df22eb5cee35ebe73afb76c8b" translate="yes" xml:space="preserve">
          <source>With sum_over_features equal to False it returns the componentwise distances.</source>
          <target state="translated">С параметрами sum_over_features равными False он возвращает компонентные расстояния.</target>
        </trans-unit>
        <trans-unit id="54cc29b6387240d37c6717d5c94b33d650c1152c" translate="yes" xml:space="preserve">
          <source>With the &amp;lsquo;brute&amp;rsquo; method, the parameter &lt;code&gt;X&lt;/code&gt; is used both for generating the grid of values \(x_S\) and the complement feature values \(x_C\). However with the &amp;lsquo;recursion&amp;rsquo; method, &lt;code&gt;X&lt;/code&gt; is only used for the grid values: implicitly, the \(x_C\) values are those of the training data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67616371d2f2a0ec7fd27c8038627dc9ef441900" translate="yes" xml:space="preserve">
          <source>With the fitted model, we compute the predictions of the model on the test dataset. These predictions are used to compute the confustion matrix which is plotted with the &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03d84c3da120d3c6633bcd8017a1f00e1bb6dad8" translate="yes" xml:space="preserve">
          <source>With this class, the base_estimator is fit on the train set of the cross-validation generator and the test set is used for calibration. The probabilities for each of the folds are then averaged for prediction. In case that cv=&amp;rdquo;prefit&amp;rdquo; is passed to __init__, it is assumed that base_estimator has been fitted already and all data is used for calibration. Note that data for fitting the classifier and for calibrating it must be disjoint.</source>
          <target state="translated">С этим классом base_estimator подходит для набора поездов генератора перекрестной проверки, а набор тестов используется для калибровки. Вероятности для каждой из складок затем усредняются для прогноза. В случае, если cv = &amp;rdquo;prefit&amp;rdquo; передается в __init__, предполагается, что base_estimator уже настроен, и все данные используются для калибровки. Обратите внимание, что данные для подбора классификатора и для его калибровки не должны пересекаться.</target>
        </trans-unit>
        <trans-unit id="07ec442186310e3d4d8de1ef730f033183a12d2a" translate="yes" xml:space="preserve">
          <source>With this re-labeling of the data, our problem can be written</source>
          <target state="translated">При такой перемаркировке данных,наша проблема может быть записана...</target>
        </trans-unit>
        <trans-unit id="bb9dc2936468de0109f9958206c68ba68552df6f" translate="yes" xml:space="preserve">
          <source>With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a &lt;em&gt;KD-tree&lt;/em&gt; in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt;&lt;/a&gt;. Alternatively, the user can work with the &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class directly.</source>
          <target state="translated">При такой настройке одного расчета расстояния между контрольной точкой и центроидом достаточно, чтобы определить нижнюю и верхнюю границы расстояния до всех точек в узле. Из-за сферической геометрии узлов шарового дерева он может превзойти &lt;em&gt;KD-дерево&lt;/em&gt; в больших измерениях, хотя фактическая производительность сильно зависит от структуры обучающих данных. В scikit-learn поиск соседей на основе дерева мячей задается с помощью ключевого слова &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt; и вычисляется с использованием класса &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt; &lt;/a&gt; . В качестве альтернативы пользователь может напрямую работать с классом &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c5b891d6db4b2b53f2c329c62187e665d9759f8a" translate="yes" xml:space="preserve">
          <source>Without any prior information on the sample, the number of projections required to reconstruct the image is of the order of the linear size &lt;code&gt;l&lt;/code&gt; of the image (in pixels). For simplicity we consider here a sparse image, where only pixels on the boundary of objects have a non-zero value. Such data could correspond for example to a cellular material. Note however that most images are sparse in a different basis, such as the Haar wavelets. Only &lt;code&gt;l/7&lt;/code&gt; projections are acquired, therefore it is necessary to use prior information available on the sample (its sparsity): this is an example of &lt;strong&gt;compressive sensing&lt;/strong&gt;.</source>
          <target state="translated">Без какой-либо предварительной информации об образце количество проекций, необходимых для восстановления изображения, порядка линейного размера &lt;code&gt;l&lt;/code&gt; изображения (в пикселях). Для простоты мы рассматриваем здесь разреженное изображение, где только пиксели на границе объектов имеют ненулевое значение. Такие данные могут соответствовать, например, клеточному материалу. Обратите внимание, однако, что большинство изображений разрежены на другой основе, такой как вейвлеты Хаара. Только &lt;code&gt;l/7&lt;/code&gt; проекций приобретаются, поэтому необходимо использовать априорную информацию можно найти на образце (его разреженность): это пример &lt;strong&gt;сжимающего зондирования&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="087783a9ac4373b41b03a4f66d5eaf61d7d47ff1" translate="yes" xml:space="preserve">
          <source>Without reduce_func:</source>
          <target state="translated">Без reduce_func:</target>
        </trans-unit>
        <trans-unit id="e6002e635270be50830b0534ba0aafc304922d8b" translate="yes" xml:space="preserve">
          <source>Without shuffling, &lt;code&gt;X&lt;/code&gt; horizontally stacks features in the following order: the primary &lt;code&gt;n_informative&lt;/code&gt; features, followed by &lt;code&gt;n_redundant&lt;/code&gt; linear combinations of the informative features, followed by &lt;code&gt;n_repeated&lt;/code&gt; duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt;.</source>
          <target state="translated">Без перетасовки &lt;code&gt;X&lt;/code&gt; горизонтально складывает объекты в следующем порядке: первичные &lt;code&gt;n_informative&lt;/code&gt; признаки, за которыми следуют &lt;code&gt;n_redundant&lt;/code&gt; линейных комбинаций информативных признаков, за которыми следуют &lt;code&gt;n_repeated&lt;/code&gt; дубликаты, нарисованные случайным образом с заменой информативных и избыточных признаков. Остальные особенности заполнены случайным шумом. Таким образом, без перемешивания, все полезные функции содержатся в столбцах &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6943d5826611d6c30be0d7d32e8882ddb2f3e560" translate="yes" xml:space="preserve">
          <source>Wolpert, David H. &amp;ldquo;Stacked generalization.&amp;rdquo; Neural networks 5.2 (1992): 241-259.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2a146386973596d64e5c0f348ec45ab36bab658" translate="yes" xml:space="preserve">
          <source>Working With Text Data</source>
          <target state="translated">Работа с текстовыми данными</target>
        </trans-unit>
        <trans-unit id="61f49f0587c5992cc8f414bbf22889f09b8f3976" translate="yes" xml:space="preserve">
          <source>Working with text documents</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b5ef6667bd92ea247084ea267c265251f4aa7de" translate="yes" xml:space="preserve">
          <source>Works with sparse matrices. Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">Работает с разреженными матрицами. Работает только при &lt;code&gt;columns_&lt;/code&gt; атрибутов &lt;code&gt;rows_&lt;/code&gt; и columns_ .</target>
        </trans-unit>
        <trans-unit id="926da419b9cc98b9060a6d00fb8d48cd55be86f9" translate="yes" xml:space="preserve">
          <source>Wrapper for kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">Обертка для ядер в sklearn.metrics.pairwise.</target>
        </trans-unit>
        <trans-unit id="f986c2ac1f7dce99239d5b1ba2c2c97de265f3fa" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline to classify movie reviews as either positive or negative.</source>
          <target state="translated">Напишите текстовый конвейер классификации для классификации отзывов на фильмы как положительные или отрицательные.</target>
        </trans-unit>
        <trans-unit id="c1b32a0493a32a44864910f6b6b9c9398af4b20e" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline using a custom preprocessor and &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; using data from Wikipedia articles as training set.</source>
          <target state="translated">Напишите конвейер классификации текста с помощью настраиваемого препроцессора и &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; , используя данные из статей Википедии в качестве обучающего набора.</target>
        </trans-unit>
        <trans-unit id="c72e193d2469d6cfb2918ba7a00dbc8ed1d451d6" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Ву, Линь и Венг, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;laquo;Оценки вероятности многоклассовой классификации путем попарного связывания&amp;raquo;&lt;/a&gt; , JMLR 5: 975-1005, 2004.</target>
        </trans-unit>
        <trans-unit id="11ab439af4c255f5f8d3594c0dad27bd31f9055a" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8c1574205d07b839af62817660ba2b78f320cd0" translate="yes" xml:space="preserve">
          <source>X block loadings vectors.</source>
          <target state="translated">Векторы блокировки нагрузки Х.</target>
        </trans-unit>
        <trans-unit id="b8076ad410e1a569012d16107ff003e5d358439f" translate="yes" xml:space="preserve">
          <source>X block to latents rotations.</source>
          <target state="translated">Х-блок к скрытым вращениям.</target>
        </trans-unit>
        <trans-unit id="a6b8640132f42899bc713ee5acc307439a5b7049" translate="yes" xml:space="preserve">
          <source>X block weights vectors.</source>
          <target state="translated">Векторы веса блока Х.</target>
        </trans-unit>
        <trans-unit id="51ee8a5ebc2ecb45284445a844d1c86426452ff9" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set, using minibatches of size batch_size if X is sparse.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6bc2e58339df2a473a9897261f25e31780f738c" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set.</source>
          <target state="translated">X проецируется на первые основные компоненты,ранее извлеченные из учебного набора.</target>
        </trans-unit>
        <trans-unit id="81850902f59e77236b068c4b29af3fcf5c8ba36f" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; needs X to interpolate new input data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7228d382c859d348525ccb5bce51e5752c38bc04" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;code&gt;transform&lt;/code&gt; needs X to interpolate new input data.</source>
          <target state="translated">X сохраняется для будущего использования, поскольку &lt;code&gt;transform&lt;/code&gt; требуется X для интерполяции новых входных данных.</target>
        </trans-unit>
        <trans-unit id="3074bef8d8da5f206ce501f5438e3d5abb038064" translate="yes" xml:space="preserve">
          <source>X must have been produced by this DictVectorizer&amp;rsquo;s transform or fit_transform method; it may only have passed through transformers that preserve the number of features and their order.</source>
          <target state="translated">X должен быть создан с помощью метода преобразования или fit_transform этого DictVectorizer; он мог пройти только через трансформаторы, сохраняющие количество функций и их порядок.</target>
        </trans-unit>
        <trans-unit id="d0ad8e13f68af13dec8ad59c4f3a6a0df7a4de08" translate="yes" xml:space="preserve">
          <source>X scores.</source>
          <target state="translated">Х баллов.</target>
        </trans-unit>
        <trans-unit id="28a3e4c54c0fde2f1aaa67a11fe405d430c2fe41" translate="yes" xml:space="preserve">
          <source>X transformed in the new space.</source>
          <target state="translated">Икс трансформировался в новом пространстве.</target>
        </trans-unit>
        <trans-unit id="ae3643384dc9ac54889b85ea1da357f34b173e6e" translate="yes" xml:space="preserve">
          <source>X_embedded: ndarray of shape (n_samples, n_components)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d925cac037a82cae915e8a0893b59ac5a4590490" translate="yes" xml:space="preserve">
          <source>X_new array, shape (n_samples, n_components)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0e804c93132e5ef73393b841ae090d872aa2191" translate="yes" xml:space="preserve">
          <source>X_original array-like, shape (n_samples, n_features)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="feedfda54d7431e28acb98075b2c2bd9cf8331f2" translate="yes" xml:space="preserve">
          <source>Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</source>
          <target state="translated">Сяоцзинь Чжу и Зубин Гахрамани. Изучение помеченных и немаркированных данных с распространением меток. Технический отчет CMU-CALD-02-107, Университет Карнеги-Меллона, 2002 г. &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5c986ee528dd9bdf7a6c8d0101f77976c47ae9d2" translate="yes" xml:space="preserve">
          <source>Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;Theil-Sen Estimators in a Multiple Linear Regression Model.&lt;/a&gt;</source>
          <target state="translated">Синь Данг, Ханьсян Пэн, Сюэцинь Ван и Хэпин Чжан: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;оценки Тейл-Сен в модели множественной линейной регрессии.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3674e6b71697b8f4a5e14e694db26daa53371e84" translate="yes" xml:space="preserve">
          <source>Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c93217dd923de34853280b8058e56203ef9ee737" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</source>
          <target state="translated">Xy=np.dot(X.T,y),которая может быть предварительно рассчитана.Это полезно только тогда,когда предварительно вычисляется грамм-матрица.</target>
        </trans-unit>
        <trans-unit id="700502aa71883c1784c7b4df71f7526cabc3833b" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23eb4d3f4155395a74e9d534f97ff4c1908f5aac" translate="yes" xml:space="preserve">
          <source>Y</source>
          <target state="translated">Y</target>
        </trans-unit>
        <trans-unit id="aac13ced89d2b311880e53ba16f36f4513402a98" translate="yes" xml:space="preserve">
          <source>Y block loadings vectors.</source>
          <target state="translated">Векторы блокировки нагрузки Y.</target>
        </trans-unit>
        <trans-unit id="148708c0aec99251158277d2fc4d038d62f32551" translate="yes" xml:space="preserve">
          <source>Y block to latents rotations.</source>
          <target state="translated">Блок Y-скрытые вращения.</target>
        </trans-unit>
        <trans-unit id="8f4ded8aca1a84f4452774f8bc622751045ade48" translate="yes" xml:space="preserve">
          <source>Y block weights vectors.</source>
          <target state="translated">Векторы веса блока Y.</target>
        </trans-unit>
        <trans-unit id="780dd8f1641062cfc0af001d2fcfedba3262be26" translate="yes" xml:space="preserve">
          <source>Y scores.</source>
          <target state="translated">Y баллов.</target>
        </trans-unit>
        <trans-unit id="93b5936ef31b077aecad8b961838c412166e9fd0" translate="yes" xml:space="preserve">
          <source>Y. Freund, R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting&amp;rdquo;, 1995.</source>
          <target state="translated">Ю. Фройнд, Р. Шапайр, &amp;laquo;Теоретико-решающее обобщение онлайн-обучения и его применение для повышения эффективности&amp;raquo;, 1995.</target>
        </trans-unit>
        <trans-unit id="bf931371fe813e68af145bc28f1f0c59ead42876" translate="yes" xml:space="preserve">
          <source>Y. Freund, and R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting&amp;rdquo;, 1997.</source>
          <target state="translated">Ю. Фройнд и Р. Шапайр, &amp;laquo;Теоретико-решающее обобщение онлайн-обучения и приложение для повышения эффективности&amp;raquo;, 1997.</target>
        </trans-unit>
        <trans-unit id="982b5c305af507a5853864a0280fe0330e5fb9d9" translate="yes" xml:space="preserve">
          <source>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</source>
          <target state="translated">Y[argmin[i],:]-это строка в Y,которая наиболее близка к X[i,:].</target>
        </trans-unit>
        <trans-unit id="6cc2acee87fd2b4d368d7294a14e1666de3c66f0" translate="yes" xml:space="preserve">
          <source>Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3526f607bcd4f51ad0bc05f814579a42c2c0ba57" translate="yes" xml:space="preserve">
          <source>Yellow</source>
          <target state="translated">Yellow</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="44e848b37858df8125129ee3d3911783b05fb21f" translate="yes" xml:space="preserve">
          <source>Yields indices to split data into training and test sets.</source>
          <target state="translated">Индексы урожайности для разделения данных на тренировочные и тестовые наборы.</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e285a8203a02b899c727c909bb971f8a5290d1a9" translate="yes" xml:space="preserve">
          <source>You can &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; over parameters of all estimators in the pipeline at once.</source>
          <target state="translated">Вы можете выполнять &lt;a href=&quot;grid_search#grid-search&quot;&gt;поиск&lt;/a&gt; по сетке сразу по параметрам всех оценщиков в конвейере.</target>
        </trans-unit>
        <trans-unit id="afc09f41b74c7e769c70223fd4fc6ea043be4f9a" translate="yes" xml:space="preserve">
          <source>You can access the newly created figure and Axes objects using &lt;code&gt;plt.gcf()&lt;/code&gt; and &lt;code&gt;plt.gca()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4f0eb08d1e594cb4ba39dda583b2124c29e8d3e" translate="yes" xml:space="preserve">
          <source>You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them.</source>
          <target state="translated">Вы можете настроить количество категорий,дав их имена загрузчику набора данных или установив их в None,чтобы получить 20 из них.</target>
        </trans-unit>
        <trans-unit id="d6a91645b832623d5d5110588ef04aebdc451880" translate="yes" xml:space="preserve">
          <source>You can already copy the skeletons into a new folder somewhere on your hard-drive named &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; where you will edit your own files for the exercises while keeping the original skeletons intact:</source>
          <target state="translated">Вы уже можете скопировать скелеты в новую папку где-нибудь на вашем жестком диске с именем &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; , где вы будете редактировать свои собственные файлы для упражнений, сохраняя исходные скелеты нетронутыми:</target>
        </trans-unit>
        <trans-unit id="1cf0d94595a131d36f8236532aeafb049eaa6dbc" translate="yes" xml:space="preserve">
          <source>You can also specify both the name and the version, which also uniquely identifies the dataset:</source>
          <target state="translated">Вы также можете указать как имя,так и версию,которая также однозначно идентифицирует набор данных:</target>
        </trans-unit>
        <trans-unit id="ae5f0da778f6ff8c0d5d1c2ccd6f86bebea3d9e0" translate="yes" xml:space="preserve">
          <source>You can also use your own defined kernels by passing a function to the keyword &lt;code&gt;kernel&lt;/code&gt; in the constructor.</source>
          <target state="translated">Вы также можете использовать свои собственные определенные ядра, передав функцию ключевому слову &lt;code&gt;kernel&lt;/code&gt; в конструкторе.</target>
        </trans-unit>
        <trans-unit id="c90fd70bc9584ad72350fadce865213cd8c472be" translate="yes" xml:space="preserve">
          <source>You can combine &lt;code&gt;KBinsDiscretizer&lt;/code&gt; with &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; if you only want to preprocess part of the features.</source>
          <target state="translated">Вы можете комбинировать &lt;code&gt;KBinsDiscretizer&lt;/code&gt; с &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; ,&lt;/a&gt; если вы хотите предварительно обработать только часть функций.</target>
        </trans-unit>
        <trans-unit id="b37a62ca838923df55452889a68156ed8900e3e5" translate="yes" xml:space="preserve">
          <source>You can control the exact number of threads that are used via the &lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; environment variable:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="579522a3d8d5bf3b4958e7c2d681266388521dce" translate="yes" xml:space="preserve">
          <source>You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.</source>
          <target state="translated">Вы можете определить свои собственные ядра либо передав кернел в виде питоновой функции,либо предварительно вычислив матрицу Грама.</target>
        </trans-unit>
        <trans-unit id="5a14b3f83e3bd81fa3adef5b677dc7c591d450db" translate="yes" xml:space="preserve">
          <source>You can display the BLAS / LAPACK implementation used by your NumPy / SciPy / scikit-learn install with the following commands:</source>
          <target state="translated">Вы можете отобразить реализацию BLAS/LAPACK,используемую при установке NumPy/SciPy/scikit-learn со следующими командами:</target>
        </trans-unit>
        <trans-unit id="929abd63168ac2d721d4708b8ef8be3cd51b08a0" translate="yes" xml:space="preserve">
          <source>You can ensure that &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt; are the inverse of each other by setting &lt;code&gt;check_inverse=True&lt;/code&gt; and calling &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt;. Please note that a warning is raised and can be turned into an error with a &lt;code&gt;filterwarnings&lt;/code&gt;:</source>
          <target state="translated">Вы можете гарантировать, что &lt;code&gt;func&lt;/code&gt; и &lt;code&gt;inverse_func&lt;/code&gt; являются обратными друг другу, установив &lt;code&gt;check_inverse=True&lt;/code&gt; и вызвав &lt;code&gt;fit&lt;/code&gt; перед &lt;code&gt;transform&lt;/code&gt; . Обратите внимание, что появляется предупреждение, которое может быть преобразовано в ошибку с помощью &lt;code&gt;filterwarnings&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="8fe8cd91261eb27750ae7b2f82fa15c24077f346" translate="yes" xml:space="preserve">
          <source>You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt; factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:</source>
          <target state="translated">Вы можете создавать еще более гибкие модели скоринга, &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt; свой собственный скоринговый объект с нуля, без использования фабрики make_scorer . Чтобы вызываемый может быть бомбардиром, он должен соответствовать протоколу, определенному следующими двумя правилами:</target>
        </trans-unit>
        <trans-unit id="cb07d258c61c328d902779de990b642f82ba2beb" translate="yes" xml:space="preserve">
          <source>You can get more information on the dataset by looking at the &lt;code&gt;DESCR&lt;/code&gt; and &lt;code&gt;details&lt;/code&gt; attributes:</source>
          <target state="translated">Вы можете получить дополнительную информацию о наборе данных, просмотрев &lt;code&gt;DESCR&lt;/code&gt; и &lt;code&gt;details&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="316dc294ff0e2890db335b30189c691f1a723809" translate="yes" xml:space="preserve">
          <source>You can now see many things that these features have overfit to:</source>
          <target state="translated">Теперь вы можете видеть много вещей,к которым эти функции имеют переоснащение:</target>
        </trans-unit>
        <trans-unit id="e2cf6b0ce385c4e9fb3f4b5189c83feb905d92cf" translate="yes" xml:space="preserve">
          <source>You can pass pre-computed kernels by using the &lt;code&gt;kernel='precomputed'&lt;/code&gt; option. You should then pass Gram matrix instead of X to the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods. The kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee86b8b814976ee239ecfc8e86907133be9d3afc" translate="yes" xml:space="preserve">
          <source>You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the &lt;code&gt;n_features&lt;/code&gt; parameter.</source>
          <target state="translated">Вы можете видеть, что в векторных выходных данных было извлечено 16 ненулевых маркеров функций: это меньше, чем 19 ненулевых &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; извлеченных ранее CountVectorizer в том же корпусе игрушек. Несоответствие происходит из-за конфликтов хэш-функций из-за низкого значения параметра &lt;code&gt;n_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6b3885cd10ec182cb98af7964ed686cdd6c77762" translate="yes" xml:space="preserve">
          <source>You can specify a monotonic constraint on each feature using the &lt;code&gt;monotonic_cst&lt;/code&gt; parameter. For each feature, a value of 0 indicates no constraint, while -1 and 1 indicate a negative and positive constraint, respectively:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c31033fd31d22147ea7534b97a7d63f646fe3e48" translate="yes" xml:space="preserve">
          <source>You can then edit the content of the workspace without fear of losing the original exercise instructions.</source>
          <target state="translated">После этого вы можете редактировать содержимое рабочего пространства,не опасаясь потерять исходные инструкции по выполнению упражнений.</target>
        </trans-unit>
        <trans-unit id="bc5b6b055370779ded34375c059372bbad8d8da3" translate="yes" xml:space="preserve">
          <source>You can use your own defined kernels by passing a function to the &lt;code&gt;kernel&lt;/code&gt; parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e21dcf7dc4d8353d8949b3e6ddc2c35c364a9b4a" translate="yes" xml:space="preserve">
          <source>You cannot nest objects with parallel computing (&lt;code&gt;n_jobs&lt;/code&gt; different than 1).</source>
          <target state="translated">Вы не можете &lt;code&gt;n_jobs&lt;/code&gt; объекты с параллельными вычислениями ( n_jobs отличное от 1).</target>
        </trans-unit>
        <trans-unit id="d086a1b811e8ad563a3cd7d98758c535aff811c7" translate="yes" xml:space="preserve">
          <source>You could try UTF-8 and disregard the errors. You can decode byte strings with &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; to replace all decoding errors with a meaningless character, or set &lt;code&gt;decode_error='replace'&lt;/code&gt; in the vectorizer. This may damage the usefulness of your features.</source>
          <target state="translated">Вы можете попробовать UTF-8 и не обращать внимания на ошибки. Вы можете декодировать байтовые строки с помощью &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; чтобы заменить все ошибки декодирования бессмысленным символом, или установить &lt;code&gt;decode_error='replace'&lt;/code&gt; в векторизаторе. Это может повредить полезности ваших функций.</target>
        </trans-unit>
        <trans-unit id="c0d5a5afa92ed6aa301d13299623473f530c94ba" translate="yes" xml:space="preserve">
          <source>You may also load two (or more) datasets at once:</source>
          <target state="translated">Вы также можете загружать два (или более)набора данных одновременно:</target>
        </trans-unit>
        <trans-unit id="a822ec525f0ce269b9b885feec474e1f8b512e04" translate="yes" xml:space="preserve">
          <source>You may also retain the estimator fitted on each training set by setting &lt;code&gt;return_estimator=True&lt;/code&gt;.</source>
          <target state="translated">Вы также можете сохранить оценщик, установленный на каждом обучающем наборе, установив &lt;code&gt;return_estimator=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c9bcd37e9efb4d07a927274f7ad017afc3f094c8" translate="yes" xml:space="preserve">
          <source>You may be able to find out what kind of encoding it is in general using the UNIX command &lt;code&gt;file&lt;/code&gt;. The Python &lt;code&gt;chardet&lt;/code&gt; module comes with a script called &lt;code&gt;chardetect.py&lt;/code&gt; that will guess the specific encoding, though you cannot rely on its guess being correct.</source>
          <target state="translated">Вы можете узнать, что это за кодировка в целом, с помощью командного &lt;code&gt;file&lt;/code&gt; UNIX . Модуль Python &lt;code&gt;chardet&lt;/code&gt; поставляется со скриптом под названием &lt;code&gt;chardetect.py&lt;/code&gt; , который угадывает конкретную кодировку, хотя вы не можете полагаться на его правильность.</target>
        </trans-unit>
        <trans-unit id="04405b99190799597dab92e2ef615219d1447404" translate="yes" xml:space="preserve">
          <source>You may load a dataset like as follows:</source>
          <target state="translated">Вы можете загрузить набор данных следующим образом:</target>
        </trans-unit>
        <trans-unit id="f9f71500b978e09c529098f893f05269c79caaff" translate="yes" xml:space="preserve">
          <source>You may want to include the parameters of the preprocessors in a &lt;a href=&quot;grid_search#grid-search&quot;&gt;parameter search&lt;/a&gt;.</source>
          <target state="translated">Вы можете включить параметры препроцессоров в &lt;a href=&quot;grid_search#grid-search&quot;&gt;поиск параметров&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4cbe0908270a3a4effe7f03ed10c6fc1b573bdb1" translate="yes" xml:space="preserve">
          <source>You might get slightly different results with the solver liblinear than with the others since this uses LIBLINEAR which penalizes the intercept.</source>
          <target state="translated">Вы можете получить немного другие результаты с solver liblinear,чем с другими,так как это использует LIBLINEAR,который наказывает перехват.</target>
        </trans-unit>
        <trans-unit id="eacc5e93bbce61c3d762f60af9c0b85d6ab90006" translate="yes" xml:space="preserve">
          <source>You might have noticed that the samples were shuffled randomly when we called &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt;: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.</source>
          <target state="translated">Вы могли заметить, что образцы были перемешаны случайным образом, когда мы вызывали &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt; : это полезно, если вы хотите выбрать только подмножество образцов, чтобы быстро обучить модель и получить первую представление результатов перед повторным обучением на полном наборе данных позже.</target>
        </trans-unit>
        <trans-unit id="c8c03561e45bae9c49c8b8f096417e119a986f38" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c0c1bb33d891f47deca1c516d19aa08bd8443b9" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">Вам нужно только один раз вызвать &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; свои данные, чтобы соответствовать всей последовательности оценщиков.</target>
        </trans-unit>
        <trans-unit id="8f00f0e599f4c3a7b71dcab47e41c43fc685f526" translate="yes" xml:space="preserve">
          <source>You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is split into &lt;em&gt;we&lt;/em&gt; and &lt;em&gt;ve&lt;/em&gt; by CountVectorizer&amp;rsquo;s default tokenizer, so if &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is in &lt;code&gt;stop_words&lt;/code&gt;, but &lt;em&gt;ve&lt;/em&gt; is not, &lt;em&gt;ve&lt;/em&gt; will be retained from &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.</source>
          <target state="translated">Вы также должны убедиться, что в списке стоп-слов была применена такая же предварительная обработка и токенизация, как и в векторизаторе. Слово &lt;em&gt;мы&lt;/em&gt; в расщепляется на &lt;em&gt;мы&lt;/em&gt; и &lt;em&gt;ве&lt;/em&gt; по умолчанию Tokenizer CountVectorizer, поэтому , если &lt;em&gt;мы&lt;/em&gt; в в &lt;code&gt;stop_words&lt;/code&gt; , но &lt;em&gt;ве&lt;/em&gt; не является, &lt;em&gt;ве&lt;/em&gt; будет удерживаться от &lt;em&gt;мы&lt;/em&gt; в в преобразованном тексте. Наши векторизаторы попытаются выявить некоторые несоответствия и предупредить о них.</target>
        </trans-unit>
        <trans-unit id="c05eee82bc79ecab0104c0f165ab54dde97d70eb" translate="yes" xml:space="preserve">
          <source>You will find additional details about joblib mitigation of oversubscription in &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblib documentation&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="03e4dbf3891b38cb2bcd04772f91e994b5e9c01b" translate="yes" xml:space="preserve">
          <source>Your dataset consists of heterogeneous data types (e.g. raster images and text captions)</source>
          <target state="translated">Ваш набор данных состоит из разнородных типов данных (например,растровые изображения и текстовые подписи).</target>
        </trans-unit>
        <trans-unit id="7b0a68e70dc900bed821b4c342a07edfa667e451" translate="yes" xml:space="preserve">
          <source>Your dataset is stored in a Pandas DataFrame and different columns require different processing pipelines.</source>
          <target state="translated">Ваш набор данных хранится в фрейме Pandas DataFrame,и различные столбцы требуют различных трубопроводов обработки.</target>
        </trans-unit>
        <trans-unit id="cf246e4fd612425ede440737acf49a3220f42916" translate="yes" xml:space="preserve">
          <source>Your kernel must take as arguments two matrices of shape &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt;, &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; and return a kernel matrix of shape &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt;.</source>
          <target state="translated">Ваше ядро ​​должно принимать в качестве аргументов две матрицы формы &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt; , &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; и возвращать матрицу ядра формы &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a97cec9f16597107c699027a6e02cf1c0426b74a" translate="yes" xml:space="preserve">
          <source>ZN proportion of residential land zoned for lots over 25,000 sq.ft.</source>
          <target state="translated">ZN доля жилой земли,районированной на участки площадью более 25 000 кв.футов.</target>
        </trans-unit>
        <trans-unit id="712d097b167e76a6e9d59b3e5e274cb4dc4edfe4" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;lsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">Задрозный и Элькан, &amp;laquo;Преобразование оценок классификатора в оценки вероятности нескольких классов&amp;raquo;, SIGKDD'02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2a3a7f6ae69d75cdee1953a2daa7e044766fcafc" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f05a65af97509516c00dcac126500e3f1415b5be" translate="yes" xml:space="preserve">
          <source>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">Нулевой коэффициент для полиномиальных и сигмовидных ядер.Игнорируется другими ядрами.</target>
        </trans-unit>
        <trans-unit id="e35caa5ca631cf4323249c1e10ca37b600a29376" translate="yes" xml:space="preserve">
          <source>Zero is the lowest possible score. Values closer to zero indicate a better partition.</source>
          <target state="translated">Ноль-это минимально возможный балл.Значения ближе к нулю указывают на лучшее разделение.</target>
        </trans-unit>
        <trans-unit id="4196df3003bc4705f3359c145eca39ac9042a13b" translate="yes" xml:space="preserve">
          <source>Zero-one classification loss.</source>
          <target state="translated">Нулевая потеря классификации.</target>
        </trans-unit>
        <trans-unit id="ee137211a128584365e4b492f8f1e31e317a831d" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Чжан Дж. И Маршалек М. и Лазебник С. и Шмид К. Локальные особенности и ядра для классификации текстур и категорий объектов: комплексное исследование International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/ ru-ru / um / people / manik / projects / trade-off / paper / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="78f8c38e7e05f7b4f27cc97ecbaeea34135ce110" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c6fefb0786b59f4ca28434a9adf73a14f912b16" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e40887e48b748aeda9c07d81d6206e919ed1f726" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f2ef1b5180fd57b17245a5c505519733d35270d" translate="yes" xml:space="preserve">
          <source>Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Чжу, Х. Цзоу, С. Россет, Т. Хасти, &amp;laquo;Мультиклассовый AdaBoost&amp;raquo;, 2009.</target>
        </trans-unit>
        <trans-unit id="8ce45cc584babf565a133f667c041638840fdfd3" translate="yes" xml:space="preserve">
          <source>Zoubir A., Koivunen V., Chakhchoukh Y. and Muma M. (2012). Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts. IEEE Signal Processing Magazine 29(4), 61-80.</source>
          <target state="translated">Зоубир А.,Койвунен В.,Чахчух Ю.и Мума М.(2012).Надежная оценка при обработке сигналов:Учебно-методическая трактовка фундаментальных понятий.Журнал по обработке сигналов IEEE 29(4),61-80.</target>
        </trans-unit>
        <trans-unit id="e2b89a96fcf50192e8235c2260c291f63c7f4fa9" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;additive_chi2&amp;rsquo;, &amp;lsquo;chi2&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;laplacian&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd3417b4282b09dc45879fe7c77bee8859983780" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['rbf', 'сигмоид', 'полином', 'поли', 'линейный', 'косинус']</target>
        </trans-unit>
        <trans-unit id="7c0453b88eaf6a5b1a0ac2faa1dec6c20e0dda6a" translate="yes" xml:space="preserve">
          <source>[1, x_2, x_2 ** 2, x_2 ** 3, &amp;hellip;], &amp;hellip;]</source>
          <target state="translated">[1, x_2, x_2 ** 2, x_2 ** 3,&amp;hellip;],&amp;hellip;]</target>
        </trans-unit>
        <trans-unit id="af237073ca841ce40d3b1c3f9ec3b84ba9e8c1ce" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Online Learning for Latent Dirichlet Allocation&amp;rdquo;, Matthew D. Hoffman,</source>
          <target state="translated">[1] &amp;laquo;Онлайн-обучение скрытому распределению Дирихле&amp;raquo;, Мэтью Д. Хоффман,</target>
        </trans-unit>
        <trans-unit id="a5828c16246e11e0eda2596d27fdd402ee57d009" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">[1] &amp;laquo;Алгоритмы сжатия для оценки ковариации MMSE&amp;raquo; Чен и др., IEEE Trans. на знак. Proc., Volume 58, Issue 10, October 2010.</target>
        </trans-unit>
        <trans-unit id="c5ae55965c66d78c700f954c5d28c9832964e702" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] &amp;laquo;Взвешенные суммы случайных кухонных раковин: замена минимизации рандомизацией в обучении&amp;raquo; А. Рахими и Бенджамина Рехта. ( &lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt; )</target>
        </trans-unit>
        <trans-unit id="4bdc516c4c0b901726d527e6df8200cdc4a8acc8" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="066cf0134c1716b5ce53bcaba6c6b8d7e86263f5" translate="yes" xml:space="preserve">
          <source>[1] Hastie, T., Tibshirani, R.,, Friedman, J. (2001). Model Assessment and Selection. The Elements of Statistical Learning (pp. 219-260). New York, NY, USA: Springer New York Inc..</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="851ede0920efe80a8308115ddfdc22058d99b224" translate="yes" xml:space="preserve">
          <source>[1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for</source>
          <target state="translated">[1] Hinton, GE, Osindero, S. и Teh, Y. Алгоритм быстрого обучения для</target>
        </trans-unit>
        <trans-unit id="3208128766e3298f0714b3eacb4e2ecfc88475e9" translate="yes" xml:space="preserve">
          <source>[1] L. Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ab6918e1971671fbb440a7f8e61bfcc4315791" translate="yes" xml:space="preserve">
          <source>[1] P. J. Rousseeuw. Least median of squares regression. J. Am</source>
          <target state="translated">[1] PJ Rousseeuw. Наименьшая медиана квадратов регрессии. Варенье</target>
        </trans-unit>
        <trans-unit id="4becf43125cdaf0ec29f63ac1f954b679ab8e6bc" translate="yes" xml:space="preserve">
          <source>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</source>
          <target state="translated">[1] Йошуа Бенжио, Оливье Делалло, Николя Ле Ру. In Semi-Supervised Learning (2006), pp. 193-216.</target>
        </trans-unit>
        <trans-unit id="9a201577697a06c9ac689a946ae70d44d48c0e7c" translate="yes" xml:space="preserve">
          <source>[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data</source>
          <target state="translated">[1] ван дер Маатен, ЛДП; Хинтон, GE Визуализация многомерных данных</target>
        </trans-unit>
        <trans-unit id="8eeff125eef3cfca1ff3f8b3157054b95e0b3509" translate="yes" xml:space="preserve">
          <source>[2] &amp;ldquo;Stochastic Variational Inference&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</source>
          <target state="translated">[2] &amp;laquo;Стохастический вариационный вывод&amp;raquo;, Мэтью Д. Хоффман, Дэвид М. Блей,</target>
        </trans-unit>
        <trans-unit id="ea3c887d7b7624a41f686043b166f388d3617ff3" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Оливье Делалло, Йошуа Бенжио, Николя Ле Ру. Эффективная индукция непараметрических функций при полу-контролируемом обучении. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73434047889c8334ffffe648547654fa2862e107" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="390f7912993134abee39b500fe8ff987c558bcc7" translate="yes" xml:space="preserve">
          <source>[2] Tieleman, T. Training Restricted Boltzmann Machines using</source>
          <target state="translated">[2] Тилеман, Т. Тренировка машин Больцмана с ограничениями с использованием</target>
        </trans-unit>
        <trans-unit id="936e8131576c3002ff436671f77d81f6c95e71d7" translate="yes" xml:space="preserve">
          <source>[2] Wilson, E. B., &amp;amp; Hilferty, M. M. (1931). The distribution of chi-square.</source>
          <target state="translated">[2] Уилсон, Э.Б., и Хильферти, М.М. (1931). Распределение хи-квадрат.</target>
        </trans-unit>
        <trans-unit id="5cccbf6c7fe7c1f50410b68e37c12f00b67f9330" translate="yes" xml:space="preserve">
          <source>[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding</source>
          <target state="translated">[2] ван дер Маатен, LJP t-Распределенное стохастическое соседнее вложение.</target>
        </trans-unit>
        <trans-unit id="740947d1c8302c56dc8a9209234aab173f75acad" translate="yes" xml:space="preserve">
          <source>[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.</source>
          <target state="translated">[3] LJP van der Maaten. Ускорение t-SNE с использованием древовидных алгоритмов.</target>
        </trans-unit>
        <trans-unit id="a16dde9090b3c419b1ba6d8027b90785ddf73263" translate="yes" xml:space="preserve">
          <source>[3] Matthew D. Hoffman&amp;rsquo;s onlineldavb code. Link:</source>
          <target state="translated">[3] Онлайн-код Мэтью Д. Хоффмана. Ссылка на сайт:</target>
        </trans-unit>
        <trans-unit id="2091fb37b7afd77ae2e8e60855d4cad2538ba378" translate="yes" xml:space="preserve">
          <source>[B1996]</source>
          <target state="translated">[B1996]</target>
        </trans-unit>
        <trans-unit id="66fa89cedf249bba6f8bbd7ca59a6edba1eb2520" translate="yes" xml:space="preserve">
          <source>[B1998]</source>
          <target state="translated">[B1998]</target>
        </trans-unit>
        <trans-unit id="7665023d9511c3ea5a7a3e7baca06057eba900d6" translate="yes" xml:space="preserve">
          <source>[B1999]</source>
          <target state="translated">[B1999]</target>
        </trans-unit>
        <trans-unit id="5c075f95c1e65a7e49dec5ad30ee36d1fb13b2b6" translate="yes" xml:space="preserve">
          <source>[B2001]</source>
          <target state="translated">[B2001]</target>
        </trans-unit>
        <trans-unit id="04bec92cc809290da2bf608da574e1877293633f" translate="yes" xml:space="preserve">
          <source>[B2011]</source>
          <target state="translated">[B2011]</target>
        </trans-unit>
        <trans-unit id="2b6c9f7f2623b948c281da789073abc37bb7f8fa" translate="yes" xml:space="preserve">
          <source>[ButlerDavies]</source>
          <target state="translated">[ButlerDavies]</target>
        </trans-unit>
        <trans-unit id="1d442f2d1661e89f1bc869a582a8d649d24881e4" translate="yes" xml:space="preserve">
          <source>[D1997]</source>
          <target state="translated">[D1997]</target>
        </trans-unit>
        <trans-unit id="20e70caf2f764d35f0c5f51eb6c2cc52a6f947f2" translate="yes" xml:space="preserve">
          <source>[Davis2006]</source>
          <target state="translated">[Davis2006]</target>
        </trans-unit>
        <trans-unit id="3b0f17e8250c1e7b54512123b77c31bb0899ae7a" translate="yes" xml:space="preserve">
          <source>[Everingham2010]</source>
          <target state="translated">[Everingham2010]</target>
        </trans-unit>
        <trans-unit id="e5ff04dac92d8d5710e2d4ade54a4899d9a01662" translate="yes" xml:space="preserve">
          <source>[F1999]</source>
          <target state="translated">[F1999]</target>
        </trans-unit>
        <trans-unit id="ddfaba8b68f822d387eefcc49dbcf89bee83fcbe" translate="yes" xml:space="preserve">
          <source>[F2001]</source>
          <target state="translated">[F2001]</target>
        </trans-unit>
        <trans-unit id="5712ff07224dea2f09976ad1b5f9060cea098ee8" translate="yes" xml:space="preserve">
          <source>[FS1995]</source>
          <target state="translated">[FS1995]</target>
        </trans-unit>
        <trans-unit id="111b120f6e2f3a7d9723c16133fcfb1ce7b7557b" translate="yes" xml:space="preserve">
          <source>[Flach2015]</source>
          <target state="translated">[Flach2015]</target>
        </trans-unit>
        <trans-unit id="0be1b91bf292e6f295e73f8ba1626aa315ca1709" translate="yes" xml:space="preserve">
          <source>[Guyon2015]</source>
          <target state="translated">[Guyon2015]</target>
        </trans-unit>
        <trans-unit id="16deff704a4f867ca18d98b22e63afcb70ec96d2" translate="yes" xml:space="preserve">
          <source>[H1998]</source>
          <target state="translated">[H1998]</target>
        </trans-unit>
        <trans-unit id="346ddc10d1a23f1ff0ba05ea1da881f4666595c5" translate="yes" xml:space="preserve">
          <source>[HTF2009]</source>
          <target state="translated">[HTF2009]</target>
        </trans-unit>
        <trans-unit id="2b6bce181ae06e6796d39628b4dc12ca65767e20" translate="yes" xml:space="preserve">
          <source>[HTF]</source>
          <target state="translated">[HTF]</target>
        </trans-unit>
        <trans-unit id="8f4756ba18c793a637ad7568fd4450479f47b718" translate="yes" xml:space="preserve">
          <source>[Hubert1985]</source>
          <target state="translated">[Hubert1985]</target>
        </trans-unit>
        <trans-unit id="1c2acae56920363d695dc395b30aa0dac0656aa7" translate="yes" xml:space="preserve">
          <source>[Jen09]</source>
          <target state="translated">[Jen09]</target>
        </trans-unit>
        <trans-unit id="52833f723be6af6645b6622da4d471b65e89d942" translate="yes" xml:space="preserve">
          <source>[Kelleher2015]</source>
          <target state="translated">[Kelleher2015]</target>
        </trans-unit>
        <trans-unit id="8d63f432cd9715591fb04662784fbed01426124f" translate="yes" xml:space="preserve">
          <source>[L2014]</source>
          <target state="translated">[L2014]</target>
        </trans-unit>
        <trans-unit id="e6f810474b9d9bf1966e66d024bfd2d0d9af7983" translate="yes" xml:space="preserve">
          <source>[LG2012]</source>
          <target state="translated">[LG2012]</target>
        </trans-unit>
        <trans-unit id="4108a351bec333bc41371d8be81bbf1f0bd216a0" translate="yes" xml:space="preserve">
          <source>[LS2010]</source>
          <target state="translated">[LS2010]</target>
        </trans-unit>
        <trans-unit id="36c1f9470816b8da81a8ed80471ace8df2456c31" translate="yes" xml:space="preserve">
          <source>[M2012]</source>
          <target state="translated">[M2012]</target>
        </trans-unit>
        <trans-unit id="536dc6f43e65eedbc7dcd92d64ef850b0a7951d3" translate="yes" xml:space="preserve">
          <source>[MRS2008]</source>
          <target state="translated">[MRS2008]</target>
        </trans-unit>
        <trans-unit id="350f14f810397ce0cd7520f35f0fae7d54d72023" translate="yes" xml:space="preserve">
          <source>[Manning2008]</source>
          <target state="translated">[Manning2008]</target>
        </trans-unit>
        <trans-unit id="0cc214a1564fbbf90b4daa0b0972b6f8408e3afc" translate="yes" xml:space="preserve">
          <source>[Mosley2013]</source>
          <target state="translated">[Mosley2013]</target>
        </trans-unit>
        <trans-unit id="73be0b37b87d3c88f49438b3a7ca251dc3d3c1d2" translate="yes" xml:space="preserve">
          <source>[Mrl09]</source>
          <target state="translated">[Mrl09]</target>
        </trans-unit>
        <trans-unit id="690e639d5d468ec30ab9e54cb03287a1d07d286f" translate="yes" xml:space="preserve">
          <source>[NQY18]</source>
          <target state="translated">[NQY18]</target>
        </trans-unit>
        <trans-unit id="95849b59dfe0de62fa4f930bc19ca3b64ad51c5b" translate="yes" xml:space="preserve">
          <source>[R2007]</source>
          <target state="translated">[R2007]</target>
        </trans-unit>
        <trans-unit id="d27f89b25dd2806ef3b69d37ac341ea761b1f775" translate="yes" xml:space="preserve">
          <source>[RR2007]</source>
          <target state="translated">[RR2007]</target>
        </trans-unit>
        <trans-unit id="99aae3a9e5135b3c3c9e6f81c5583f53ea54b161" translate="yes" xml:space="preserve">
          <source>[RVD]</source>
          <target state="translated">[RVD]</target>
        </trans-unit>
        <trans-unit id="7fc4fd0834c6c78f63966f47416f1e672a05b032" translate="yes" xml:space="preserve">
          <source>[RVDriessen]</source>
          <target state="translated">[RVDriessen]</target>
        </trans-unit>
        <trans-unit id="9a3d290ec7e0cf466e2e530b732c430fd93742e5" translate="yes" xml:space="preserve">
          <source>[RW2006]</source>
          <target state="translated">[RW2006]</target>
        </trans-unit>
        <trans-unit id="ab40883d6ce3b576febad86ad20a220ae60fc722" translate="yes" xml:space="preserve">
          <source>[Rouseeuw1984]</source>
          <target state="translated">[Rouseeuw1984]</target>
        </trans-unit>
        <trans-unit id="f4ff5aad65e1461e94ef70a659337011d0c58126" translate="yes" xml:space="preserve">
          <source>[Rousseeuw]</source>
          <target state="translated">[Rousseeuw]</target>
        </trans-unit>
        <trans-unit id="74f2d2c5b044f5dc96afc1e0482d2495c57d5370" translate="yes" xml:space="preserve">
          <source>[Urbanowicz2015]</source>
          <target state="translated">[Urbanowicz2015]</target>
        </trans-unit>
        <trans-unit id="34cb3f1593778c84c25ed6665ee9a323140a68d9" translate="yes" xml:space="preserve">
          <source>[VEB2009] Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">[VEB2009] Винь, Эппс и Бейли, (2009). &amp;laquo;Теоретико-информационные меры для сравнения кластеризации&amp;raquo;. Материалы 26-й ежегодной международной конференции по машинному обучению - ICML '09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;DOI: 10.1145 / 1553374.1553511&lt;/a&gt; . ISBN 9781605585161.</target>
        </trans-unit>
        <trans-unit id="48a5d15f42b24744d500812bf01a83ad55ecae83" translate="yes" xml:space="preserve">
          <source>[VEB2010] Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">[VEB2010] Винь, Эппс и Бейли, (2010). &amp;laquo;Теоретико-информационные меры для сравнения кластеризации: варианты, свойства, нормализация и поправка на случайность&amp;raquo;. JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="0cb878c6eb08bc32d947d6ddc4baaa42377cefd9" translate="yes" xml:space="preserve">
          <source>[VVZ2010]</source>
          <target state="translated">[VVZ2010]</target>
        </trans-unit>
        <trans-unit id="3db6db2379703ce194c034f1bb123b847f702832" translate="yes" xml:space="preserve">
          <source>[VZ2010]</source>
          <target state="translated">[VZ2010]</target>
        </trans-unit>
        <trans-unit id="4f385f25921c7c64a43d9b5e0a8904686fbad4ed" translate="yes" xml:space="preserve">
          <source>[X1, y1, &amp;hellip;, Xn, yn]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70b15e6dab0cb6917fd158eac29a9ddf08fcef21" translate="yes" xml:space="preserve">
          <source>[YAT2016] Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">[YAT2016] Ян, Альгешаймер и Тессон, (2016). &amp;laquo;Сравнительный анализ алгоритмов обнаружения сообществ в искусственных сетях&amp;raquo;. Научные отчеты 6: 30750. DOI &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;: 10.1038 / srep30750&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="652e235b7dc2f3d75c7f909152b3819c6c97a6ec" translate="yes" xml:space="preserve">
          <source>[Yates2011]</source>
          <target state="translated">[Yates2011]</target>
        </trans-unit>
        <trans-unit id="e3b9ec6790a1b2a9d7bcca67037f67b282ccc4ee" translate="yes" xml:space="preserve">
          <source>[ZZRH2009]</source>
          <target state="translated">[ZZRH2009]</target>
        </trans-unit>
        <trans-unit id="96b76160e0ad993ba5f0d18a67c96f386933b35a" translate="yes" xml:space="preserve">
          <source>[[1, x_1, x_1 ** 2, x_1 ** 3, &amp;hellip;],</source>
          <target state="translated">[[1, x_1, x_1 ** 2, x_1 ** 3,&amp;hellip;],</target>
        </trans-unit>
        <trans-unit id="2eab98aedd6e4787cc1b6ed7c5288a5a2279237c" translate="yes" xml:space="preserve">
          <source>[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.</source>
          <target state="translated">[callable]: определяемая пользователем функция, которая принимает массив расстояний и возвращает массив той же формы, содержащий веса.</target>
        </trans-unit>
        <trans-unit id="b622702bcf4592f09f68d731f0a4b9f486da53eb" translate="yes" xml:space="preserve">
          <source>[n_samples_a, n_features] otherwise Array of pairwise distances between samples, or a feature array.</source>
          <target state="translated">[n_samples_a, n_features] в противном случае Массив попарных расстояний между выборками или массив характеристик.</target>
        </trans-unit>
        <trans-unit id="361169bda90a02e4e54f39ff838115b39a75d83d" translate="yes" xml:space="preserve">
          <source>[wk]</source>
          <target state="translated">[wk]</target>
        </trans-unit>
        <trans-unit id="a4fcb5a87f4e322ea14fa74b5213a00a6d8c1551" translate="yes" xml:space="preserve">
          <source>\((y-\hat{y})^2\)</source>
          <target state="translated">\((y-\hat{y})^2\)</target>
        </trans-unit>
        <trans-unit id="b66b6613ed1a2db616d592d66bc160b7abcc7139" translate="yes" xml:space="preserve">
          <source>\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</source>
          <target state="translated">\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</target>
        </trans-unit>
        <trans-unit id="764bb49b144ee69e8d51ad0d7a5cedd15acf75d9" translate="yes" xml:space="preserve">
          <source>\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</source>
          <target state="translated">\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</target>
        </trans-unit>
        <trans-unit id="cade30b6baa03b8bc431f6cb3586bc5b1d642a6f" translate="yes" xml:space="preserve">
          <source>\(C\) is used to set the amount of regularization</source>
          <target state="translated">\ (C \) используется для установки степени регуляризации</target>
        </trans-unit>
        <trans-unit id="ad93e4d23ea1b4d81a2b3f3c3d29dff7d49b5d27" translate="yes" xml:space="preserve">
          <source>\(D\) : input dimension</source>
          <target state="translated">\ (D \): входной размер</target>
        </trans-unit>
        <trans-unit id="a32e93d880aaba8a860e59edd1cb39f288e59537" translate="yes" xml:space="preserve">
          <source>\(F1 = 2\frac{P \times R}{P+R}\)</source>
          <target state="translated">\ (F1 = 2 \ frac {P \ times R} {P + R} \)</target>
        </trans-unit>
        <trans-unit id="6e8b3587e80a2131c2360cdeb81572614017e523" translate="yes" xml:space="preserve">
          <source>\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</source>
          <target state="translated">\ (F_ \ beta (A, B): = \ left (1 + \ beta ^ 2 \ right) \ frac {P (A, B) \ times R (A, B)} {\ beta ^ 2 P (A , B) + R (A, B)} \)</target>
        </trans-unit>
        <trans-unit id="9a350d9475f7eafeffa8a9835bca28d431bee93e" translate="yes" xml:space="preserve">
          <source>\(F_\beta(y, \hat{y})\)</source>
          <target state="translated">\ (F_ \ beta (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="09eb5f139bd0c207766706ffe3b5d171a556d4ec" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - \frac{x^2}{h^2}\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 - \ frac {x ^ 2} {h ^ 2} \)</target>
        </trans-unit>
        <trans-unit id="95dfc8e81899d8cb940cb0df0bfaa1052ffb36d2" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - x/h\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 - x / h \), если \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="2a910118bdbf495d82747952ba6971367b93dfac" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto 1 \), если \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="4b298d5bd2fdf7182db10bf076925db3745527a8" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \cos(\frac{\pi x}{2h})\) if \(x &amp;lt; h\)</source>
          <target state="translated">\ (K (x; h) \ propto \ cos (\ frac {\ pi x} {2h}) \), если \ (x &amp;lt;h \)</target>
        </trans-unit>
        <trans-unit id="a4443829e2c48ab72daedb9b74f9dc8debc9681a" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(- \frac{x^2}{2h^2} )\)</source>
          <target state="translated">\ (K (x; h) \ propto \ exp (- \ frac {x ^ 2} {2h ^ 2}) \)</target>
        </trans-unit>
        <trans-unit id="c70853c06adf6986de8dcbc5a8f801fc0502ae1b" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(-x/h)\)</source>
          <target state="translated">\ (К (х; ч) \ пропто \ ехр (-х / ч) \)</target>
        </trans-unit>
        <trans-unit id="7d9776eac061dd7f197e8155c6784a047082de92" translate="yes" xml:space="preserve">
          <source>\(L\) the set of labels</source>
          <target state="translated">\ (L \) набор меток</target>
        </trans-unit>
        <trans-unit id="f0f78908f9cef66c5c39e39b004aba794a24d223" translate="yes" xml:space="preserve">
          <source>\(N\) : number of training data points</source>
          <target state="translated">\ (N \): количество точек данных обучения</target>
        </trans-unit>
        <trans-unit id="85d811223bbd2564d928a5184adabae9693a9903" translate="yes" xml:space="preserve">
          <source>\(P = \frac{T_p}{T_p+F_p}\)</source>
          <target state="translated">\ (P = \ frac {T_p} {T_p + F_p} \)</target>
        </trans-unit>
        <trans-unit id="5c7b5d8ee367861eab9617a9df8debede099fe4a" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</source>
          <target state="translated">\ (P (A, B): = \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \)</target>
        </trans-unit>
        <trans-unit id="b2e10949fc710189ed8a464185eb0fbad995ab8d" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\) for some sets \(A\) and \(B\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c180cdb6205e02ec243b8a0c392cb71991d0a3d0" translate="yes" xml:space="preserve">
          <source>\(P(y, \hat{y})\)</source>
          <target state="translated">\ (P (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="c753c8fc287915fbc16c3d512099716031e38eb4" translate="yes" xml:space="preserve">
          <source>\(R = \frac{T_p}{T_p + F_n}\)</source>
          <target state="translated">\ (R = \ frac {T_p} {T_p + F_n} \)</target>
        </trans-unit>
        <trans-unit id="2d1e6161821a7c78dd1e8cc86ac7329f67bfcf0c" translate="yes" xml:space="preserve">
          <source>\(R(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\) (Conventions vary on handling \(B = \emptyset\); this implementation uses \(R(A, B):=0\), and similar for \(P\).)</source>
          <target state="translated">\ (R (A, B): = \ frac {\ left | A \ cap B \ right |} {\ left | B \ right |} \) (Соглашения зависят от обработки \ (B = \ emptyset \); это реализация использует \ (R (A, B): = 0 \) и аналогично для \ (P \).)</target>
        </trans-unit>
        <trans-unit id="76e12b53dc747a452508648de37b3bbf1292886a" translate="yes" xml:space="preserve">
          <source>\(R(y, \hat{y})\)</source>
          <target state="translated">\ (R (y, \ hat {y}) \)</target>
        </trans-unit>
        <trans-unit id="fe30e7d28d145393d116de8ccfdb95f1930cc647" translate="yes" xml:space="preserve">
          <source>\(S\) the set of samples</source>
          <target state="translated">\ (S \) набор образцов</target>
        </trans-unit>
        <trans-unit id="4d975b6c5632f1c81d6cf8cc9f674c8e0d143548" translate="yes" xml:space="preserve">
          <source>\(X\): data</source>
          <target state="translated">\ (X \): данные</target>
        </trans-unit>
        <trans-unit id="59b5b0f07758a431bbb7dbf6ebe63bc98b0cd7dd" translate="yes" xml:space="preserve">
          <source>\(\Omega\) is a &lt;code&gt;penalty&lt;/code&gt; function of our model parameters</source>
          <target state="translated">\ (\ Omega \) - &lt;code&gt;penalty&lt;/code&gt; функция параметров нашей модели</target>
        </trans-unit>
        <trans-unit id="d82693345c0acee22512b8f82f5807d2eafe4d72" translate="yes" xml:space="preserve">
          <source>\(\Psi = \mathrm{diag}(\psi_1, \psi_2, \dots, \psi_n)\): This model is called &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt;&lt;code&gt;FactorAnalysis&lt;/code&gt;&lt;/a&gt;, a classical statistical model. The matrix W is sometimes called the &amp;ldquo;factor loading matrix&amp;rdquo;.</source>
          <target state="translated">\ (\ Psi = \ mathrm {diag} (\ psi_1, \ psi_2, \ dots, \ psi_n) \): эта модель называется &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt; &lt;code&gt;FactorAnalysis&lt;/code&gt; &lt;/a&gt; , классической статистической моделью. Матрицу W иногда называют &amp;laquo;матрицей факторных нагрузок&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="fbd9ea497a59df8b22d9aee98766b15298f6f7b0" translate="yes" xml:space="preserve">
          <source>\(\Psi = \sigma^2 \mathbf{I}\): This assumption leads to the probabilistic model of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">\ (\ Psi = \ sigma ^ 2 \ mathbf {I} \): Это предположение приводит к вероятностной модели &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="01f8f0e3a7f60922aad934db70b43f4626579a4f" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,1}\)</source>
          <target state="translated">\(\alpha^{0}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="51f4c7f6d4e230692f7f7ca95d3a951f2ccb6900" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,2}\)</source>
          <target state="translated">\(\alpha^{0}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="fc59eea930c0650810949c61616237e10d7608e7" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,0}\)</source>
          <target state="translated">\(\alpha^{0}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="b7a1987ec2f1ae255445b9203ba76dab46f8180e" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,2}\)</source>
          <target state="translated">\(\alpha^{0}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="ddda7bd4dda2cccb6220d08cd96b97d2564703fc" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,0}\)</source>
          <target state="translated">\(\alpha^{0}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="cd76d3a6ac27cf4608fdba8c1bcefea98e40a082" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,1}\)</source>
          <target state="translated">\(\alpha^{0}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="670a0c506ecd80ad22241edc90899b4ca5a65063" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,1}\)</source>
          <target state="translated">\(\alpha^{1}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="715b85177f34a3aec41f1d6aca5ea943c045452d" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,2}\)</source>
          <target state="translated">\(\alpha^{1}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="9bafd2e8e2343917301e41ef344db246b60c40d3" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,0}\)</source>
          <target state="translated">\(\alpha^{1}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="bd6409137f75a05bb280bc5000840c3e16f9d850" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,2}\)</source>
          <target state="translated">\(\alpha^{1}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="e31f66e6ca63dbde84a383e5d61ebb97f39d2fa6" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,0}\)</source>
          <target state="translated">\(\alpha^{1}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="603e33877eb24d9878fa7efb61a9c926fb80dd71" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,1}\)</source>
          <target state="translated">\(\alpha^{1}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="9ffe8c9fb6dee2771ab0ca39575e1df479c8a1ca" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,1}\)</source>
          <target state="translated">\(\alpha^{2}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="7f0fc3efbc7900034a8626635972b65d78e7a257" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,2}\)</source>
          <target state="translated">\(\alpha^{2}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="69166f5380836f7b04cceea34acce5263efbceff" translate="yes" xml:space="preserve">
          <source>\(\beta\): Coefficients</source>
          <target state="translated">\ (\ beta \): Коэффициенты</target>
        </trans-unit>
        <trans-unit id="fec074bbf7d22c3b3d841bc5e89270a0a2f32779" translate="yes" xml:space="preserve">
          <source>\(\epsilon\): Observation noise</source>
          <target state="translated">\ (\ epsilon \): шум наблюдения</target>
        </trans-unit>
        <trans-unit id="12791ef36495d018e1daf82140fd4c3db8180c28" translate="yes" xml:space="preserve">
          <source>\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</source>
          <target state="translated">\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</target>
        </trans-unit>
        <trans-unit id="08cc56772d86f4dfece03ec8003aba4f776d2aab" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} F_ \ beta (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="8c4693b66d3ba7a40d8a9abfe000616818f55aaf" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} P (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="52e6ce52e9b8ae2877c124e769de40084f5638d9" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} R (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="7f2d1bc16a43e60170cc4d3e4429f1eaefb3b9b2" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} F_ \ beta (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="301209259a59426be923af21027651f698a1adbb" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} P (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="76d3b6c7bb7266c85c29df970c85d63d00762934" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)</source>
          <target state="translated">\ (\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} R (y_s, \ hat {y} _s) \)</target>
        </trans-unit>
        <trans-unit id="771a76dcfeccc7d1c5c81729270313804a1579cd" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | F_ \ beta (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="8c17ed8e7ab856a74c9c5ce2466ffe22f7bfd45b" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | P (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="084995f248284e6186e09f61b6402476e717eb20" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\ (\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | R (y_l, \ hat {y} _l) \)</target>
        </trans-unit>
        <trans-unit id="6e89e30113ce1a3053ff34b9257e3d282abe2f88" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 1.8473]}{\sqrt{\big(3^2 + 0^2 + 1.8473^2\big)}} = [0.8515, 0, 0.5243]\):</source>
          <target state="translated">\ (\ frac {[3, 0, 1.8473]} {\ sqrt {\ big (3 ^ 2 + 0 ^ 2 + 1.8473 ^ 2 \ big)}} = [0.8515, 0, 0.5243] \):</target>
        </trans-unit>
        <trans-unit id="673551b6d125b3cd94d7674f49f994c6afdd6f65" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 2.0986]}{\sqrt{\big(3^2 + 0^2 + 2.0986^2\big)}} = [ 0.819, 0, 0.573].\)</source>
          <target state="translated">\ (\ frac {[3, 0, 2.0986]} {\ sqrt {\ big (3 ^ 2 + 0 ^ 2 + 2.0986 ^ 2 \ big)}} = [0.819, 0, 0.573]. \)</target>
        </trans-unit>
        <trans-unit id="1a5082b9d05f10e66dae95fed7849c72d0a8cfc1" translate="yes" xml:space="preserve">
          <source>\(\gamma\) is known as slope</source>
          <target state="translated">\ (\ gamma \) известен как наклон</target>
        </trans-unit>
        <trans-unit id="126898e7757cd77e4cefb87e42f683763bf54571" translate="yes" xml:space="preserve">
          <source>\(\hat{y}\) the set of &lt;em&gt;true&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\ (\ hat {y} \) набор &lt;em&gt;истинных&lt;/em&gt; пар \ ((sample, label) \)</target>
        </trans-unit>
        <trans-unit id="9f39f60cd1f2428420af5f2dec2780245432c521" translate="yes" xml:space="preserve">
          <source>\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle F_ \ beta (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="f3dc3b8f8243a37f6cfc63694bfee10bbc8dbb16" translate="yes" xml:space="preserve">
          <source>\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle P (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="1c6337bdf58558dfa45a337181a8da415d8b489c" translate="yes" xml:space="preserve">
          <source>\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\ (\ langle R (y_l, \ hat {y} _l) | l \ in L \ rangle \)</target>
        </trans-unit>
        <trans-unit id="825ca6208fb0c99a89fb31d3479b162477b3c1b6" translate="yes" xml:space="preserve">
          <source>\(\mathcal{L}\) is a &lt;code&gt;loss&lt;/code&gt; function of our samples and our model parameters.</source>
          <target state="translated">\ (\ mathcal {L} \) - это функция &lt;code&gt;loss&lt;/code&gt; наших выборок и параметров нашей модели.</target>
        </trans-unit>
        <trans-unit id="2a02f90f2b2001d6562373a7ae2a2e1dfb4565e2" translate="yes" xml:space="preserve">
          <source>\(\text{AP} = \sum_n (R_n - R_{n-1}) P_n\)</source>
          <target state="translated">\ (\ текст {AP} = \ sum_n (R_n - R_ {n-1}) P_n \)</target>
        </trans-unit>
        <trans-unit id="db505c609ecce8b6164765bd7848f3b41ea35f0d" translate="yes" xml:space="preserve">
          <source>\(\text{df}(d, t)_{\text{term1}} = 6\)</source>
          <target state="translated">\ (\ text {df} (d, t) _ {\ text {term1}} = 6 \)</target>
        </trans-unit>
        <trans-unit id="e0997db48a8d87bf8ee1c7a8fcaa36916a54e707" translate="yes" xml:space="preserve">
          <source>\(\text{df}(t)_{\text{term1}} = 6\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3761c41a5e61f125696abaab3d6ab5e6c9467a9a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(d, t)_{\text{term1}} = log \frac{n_d}{\text{df}(d, t)} + 1 = log(1)+1 = 1\)</source>
          <target state="translated">\ (\ text {idf} (d, t) _ {\ text {term1}} = log \ frac {n_d} {\ text {df} (d, t)} + 1 = log (1) +1 = 1 \)</target>
        </trans-unit>
        <trans-unit id="aa5a67b1ed0374bd72cf6f0e10b3fe3a74615260" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="528e4287e895ebbf7910677616d1f6077d104040" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="61843849cf83ac9cc60022c827bcec315d11ec03" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3943a22b1a933b8cec2e621f9da837d0f8e0bccb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="418ed87bb3a9ff83d64cef6c0afed152e2ce9063" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {1 + n_d} {1+ \ text {df} (d, t)}} + 1 \)</target>
        </trans-unit>
        <trans-unit id="cbf2fa82ddd1456d42b5d1023dd8e97cfb8e3a89" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\),</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {1 + n_d} {1+ \ text {df} (d, t)}} + 1 \),</target>
        </trans-unit>
        <trans-unit id="4b7b756caf347e71181dfa1202016ab8356f261a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{1+\text{df}(d,t)}}.\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {n_d} {1+ \ text {df} (d, t)}}. \)</target>
        </trans-unit>
        <trans-unit id="4034a1550b8c7d630dbd8eba4c06d1a4f1d30dc5" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\ (\ text {idf} (t) = log {\ frac {n_d} {\ text {df} (d, t)}} + 1 \)</target>
        </trans-unit>
        <trans-unit id="96edf4cb5b96d644ba339f4099a39ef286ca85fb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f18c6689111b29d4354e7fffcee7cc0802b481a5" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{raw}} = [3, 0, 2.0986].\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {raw}} = [3, 0, 2.0986]. \)</target>
        </trans-unit>
        <trans-unit id="80aba8c317a078e4609ae8bd36660d65edad7083" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term1}} = \text{tf} \times \text{idf} = 3 \times 1 = 3\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term1}} = \ text {tf} \ times \ text {idf} = 3 \ times 1 = 3 \)</target>
        </trans-unit>
        <trans-unit id="1d70946637e51aace1378ca1a204825107f21cdf" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f8322f95350f60ce08c7cdd3032f22e074bd2b1" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (log(6/1)+1) = 0\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term2}} = 0 \ times (журнал (6/1) +1) = 0 \)</target>
        </trans-unit>
        <trans-unit id="a326be18c218e6683afc2f56f1612584e40eaa79" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcd228feb463195495d0b530544c87a8f5f36307" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term3}} = 1 \ times (log (6/2) +1) \ приблизительно 2,0986 \)</target>
        </trans-unit>
        <trans-unit id="9c4af8e7df634860beafeba835d8777813396030" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8c4b99bd2ff2af3e5f2b8ace2008c6e0a9ef2e7" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\ (\ text {tf-idf} _ {\ text {term3}} = 1 \ times log (7/3) +1 \ приблизительно 1,8473 \)</target>
        </trans-unit>
        <trans-unit id="b1e424267dd17efa4321c87fe24219eaad1c3249" translate="yes" xml:space="preserve">
          <source>\(a\), the number of pairs of elements that are in the same set in C and in the same set in K</source>
          <target state="translated">\ (a \), количество пар элементов, которые находятся в одном наборе в C и в одном наборе в K</target>
        </trans-unit>
        <trans-unit id="ffa07cceebbfadc52e2be9cdf6b9599e34083b82" translate="yes" xml:space="preserve">
          <source>\(b\), the number of pairs of elements that are in different sets in C and in different sets in K</source>
          <target state="translated">\ (b \), количество пар элементов, которые находятся в разных наборах в C и в разных наборах в K</target>
        </trans-unit>
        <trans-unit id="9634b82eb2f3a1a53f10d0105fa96b96683012b1" translate="yes" xml:space="preserve">
          <source>\(c=\sum_{k}^{K} C_{kk}\) the total number of samples correctly predicted,</source>
          <target state="translated">\ (c = \ sum_ {k} ^ {K} C_ {kk} \) общее количество правильно предсказанных выборок,</target>
        </trans-unit>
        <trans-unit id="e0b006e0f953d2967208fad0e101db9a95b1773e" translate="yes" xml:space="preserve">
          <source>\(c_0\) is known as intercept</source>
          <target state="translated">\ (c_0 \) известен как перехват</target>
        </trans-unit>
        <trans-unit id="20f463b5231561db0d1529b308e8cd1a67579869" translate="yes" xml:space="preserve">
          <source>\(d\) : output dimension</source>
          <target state="translated">\ (d \): выходной размер</target>
        </trans-unit>
        <trans-unit id="3c2644dcb6baee3a2f0954ec1f4febb35c2c968e" translate="yes" xml:space="preserve">
          <source>\(d_{ij}\), the distance between cluster centroids \(i\) and \(j\).</source>
          <target state="translated">\ (d_ {ij} \), расстояние между центроидами кластера \ (i \) и \ (j \).</target>
        </trans-unit>
        <trans-unit id="464de6af9c88cdb5c8c4a2137401febf7a5e41c7" translate="yes" xml:space="preserve">
          <source>\(k\) : number of nearest neighbors</source>
          <target state="translated">\ (k \): количество ближайших соседей</target>
        </trans-unit>
        <trans-unit id="ded29692d567c68006b5e22274ae992999727d77" translate="yes" xml:space="preserve">
          <source>\(n = 6\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f8783323f752c7593ada8acf8c4d67282a83607" translate="yes" xml:space="preserve">
          <source>\(n_{d} = 6\)</source>
          <target state="translated">\ (n_ {d} = 6 \)</target>
        </trans-unit>
        <trans-unit id="13e265f7db3a9509d50f014f7170db211a73f394" translate="yes" xml:space="preserve">
          <source>\(p_k=\sum_{i}^{K} C_{ki}\) the number of times class \(k\) was predicted,</source>
          <target state="translated">\ (p_k = \ sum_ {i} ^ {K} C_ {ki} \) количество предсказаний класса \ (k \),</target>
        </trans-unit>
        <trans-unit id="cc4e2c50ba94767cc02eead7002753560f0219c2" translate="yes" xml:space="preserve">
          <source>\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\) the total number of samples.</source>
          <target state="translated">\ (s = \ sum_ {i} ^ {K} \ sum_ {j} ^ {K} C_ {ij} \) общее количество выборок.</target>
        </trans-unit>
        <trans-unit id="6eb93fac640cf512d1e63922116e7722c92fabe0" translate="yes" xml:space="preserve">
          <source>\(s_i\), the average distance between each point of cluster \(i\) and the centroid of that cluster &amp;ndash; also know as cluster diameter.</source>
          <target state="translated">\ (s_i \), среднее расстояние между каждой точкой кластера \ (i \) и центроидом этого кластера - также известное как диаметр кластера.</target>
        </trans-unit>
        <trans-unit id="2904d711734ca668dfddae3cff9c273e4d482636" translate="yes" xml:space="preserve">
          <source>\(t_k=\sum_{i}^{K} C_{ik}\) the number of times class \(k\) truly occurred,</source>
          <target state="translated">\ (t_k = \ sum_ {i} ^ {K} C_ {ik} \) количество раз, когда класс \ (k \) действительно произошел,</target>
        </trans-unit>
        <trans-unit id="0a59d79c97bec565e1c47b5aab7109c37d7376fa" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\)</source>
          <target state="translated">\ (v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \)</target>
        </trans-unit>
        <trans-unit id="ef3a9e22b14c74ec22385c615853f9e45898420d" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\).</source>
          <target state="translated">\ (v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \).</target>
        </trans-unit>
        <trans-unit id="e9fe36499695707a4fa25e6312e0decc4b5ce11a" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12ab6bd6cdfcad92f2c8d9cd45d8531fb50b8225" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2)\), where \(F\) is the predictor with two features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d224f9dd671e9669fa16b0ba657459625c42e63b" translate="yes" xml:space="preserve">
          <source>\(y \in (-\infty, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fb9264ce64cd7d5e1a33f2fcf663917cc9226ab" translate="yes" xml:space="preserve">
          <source>\(y \in (0, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ffefe23f049210303238c3770c5a3a8cbf9ad47" translate="yes" xml:space="preserve">
          <source>\(y \in [0, \infty)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f32f66d76e16029cdb54470231bf86f45c56290" translate="yes" xml:space="preserve">
          <source>\(y\) the set of &lt;em&gt;predicted&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\ (y \) набор &lt;em&gt;предсказанных&lt;/em&gt; пар \ ((выборка, метка) \)</target>
        </trans-unit>
        <trans-unit id="84dbf0f25232d7453b4b36e6d3fffb9c5594408b" translate="yes" xml:space="preserve">
          <source>\(y\): target variable</source>
          <target state="translated">\ (y \): целевая переменная</target>
        </trans-unit>
        <trans-unit id="29655c66149656107eee3658832dbefda0f10f88" translate="yes" xml:space="preserve">
          <source>\(y_l\) the subset of \(y\) with label \(l\)</source>
          <target state="translated">\ (y_l \) подмножество \ (y \) с меткой \ (l \)</target>
        </trans-unit>
        <trans-unit id="2e082165475a8fcee912e7d794c4b87072c02854" translate="yes" xml:space="preserve">
          <source>\(y_s\) the subset of \(y\) with sample \(s\), i.e. \(y_s := \left\{(s', l) \in y | s' = s\right\}\)</source>
          <target state="translated">\ (y_s \) подмножество \ (y \) с образцом \ (s \), то есть \ (y_s: = \ left \ {(s ', l) \ in y | s' = s \ right \} \ )</target>
        </trans-unit>
        <trans-unit id="83a2c7fcc781f513174d7284ba894e2de571456a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\\\Downarrow\\\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} P (y \ mid x_1, \ dots, x_n) \ propto P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y) \\ \ Downarrow \\\ hat {y} = \ arg \ max_y P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y), \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="c500aca02db178fd925a59974dd45ddee8face02" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}Q_{left}(\theta) = {(x, y) | x_j &amp;lt;= t_m}\\Q_{right}(\theta) = Q \setminus Q_{left}(\theta)\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} Q_ {left} (\ theta) = {(x, y) | x_j &amp;lt;= t_m} \\ Q_ {right} (\ theta) = Q \ setminus Q_ {left} (\ theta) \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6d63d132be650c44cbd8191fea374d6099c68415" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} (y_i - \bar{y}_m)^2\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H (X_m) = \ frac {1} {N_m &amp;raquo; } \ sum_ {i \ in N_m} (y_i - \ bar {y} _m) ^ 2 \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="09657abb97474afe531f716bc21393139a923381" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - \bar{y}_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H (X_m) = \ frac {1} {N_m &amp;raquo; } \ sum_ {i \ in N_m} | y_i - \ bar {y} _m | \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="a6a013161b26d9345009bc657a0fa52bacc545a7" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\hat{\theta}_{ci} = \frac{\alpha_i + \sum_{j:y_j \neq c} d_{ij}} {\alpha + \sum_{j:y_j \neq c} \sum_{k} d_{kj}}\\w_{ci} = \log \hat{\theta}_{ci}\\w_{ci} = \frac{w_{ci}}{\sum_{j} |w_{cj}|}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ hat {\ theta} _ {ci} = \ frac {\ alpha_i + \ sum_ {j: y_j \ neq c} d_ {ij}} {\ alpha + \ sum_ {j: y_j \ neq c} \ sum_ {k} d_ {kj}} \\ w_ {ci} = \ log \ hat {\ theta} _ {ci} \\ w_ {ci} = \ frac {w_ {ci }} {\ sum_ {j} | w_ {cj} |} \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="3d5da4b9043141ddac28de63232838abbbe5a18b" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\log\left(\frac{P(y=k|X)}{P(y=l|X)}\right)= \log\left(\frac{P(X|y=k)P(y=k)}{P(X|y=l)P(y=l)}\right)=0 \Leftrightarrow\\(\mu_k-\mu_l)^t\Sigma^{-1} X = \frac{1}{2} (\mu_k^t \Sigma^{-1} \mu_k - \mu_l^t \Sigma^{-1} \mu_l) - \log\frac{P(y=k)}{P(y=l)}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ log \ left (\ frac {P (y = k | X)} ​​{P (y = l | X)} ​​\ right) = \ log \ left (\ frac {P (X | y = k) P (y = k)} {P (X | y = l) P (y = l)} \ right) = 0 \ Leftrightarrow \\ (\ mu_k- \ mu_l) ^ t \ Sigma ^ {- 1} X = \ frac {1} {2} (\ mu_k ^ t \ Sigma ^ {- 1} \ mu_k - \ mu_l ^ t \ Sigma ^ {- 1} \ mu_l) - \ log \ гидроразрыв {P (y = k)} {P (y = l)} \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="970228f13e58c5000f67243636530c2e6768a476" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta, \zeta^*} \frac{1}{2} w^T w + C \sum_{i=1}^{n} (\zeta_i + \zeta_i^*)\\\begin{split}\textrm {subject to } &amp;amp; y_i - w^T \phi (x_i) - b \leq \varepsilon + \zeta_i,\\ &amp;amp; w^T \phi (x_i) + b - y_i \leq \varepsilon + \zeta_i^*,\\ &amp;amp; \zeta_i, \zeta_i^* \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ min_ {w, b, \ zeta, \ zeta ^ *} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ { n} (\ zeta_i + \ zeta_i ^ *) \\\ begin {split} \ textrm {subject to} &amp;amp; y_i - w ^ T \ phi (x_i) - b \ leq \ varepsilon + \ zeta_i, \\ &amp;amp; w ^ T \ phi (x_i) + b - y_i \ leq \ varepsilon + \ zeta_i ^ *, \\ &amp;amp; \ zeta_i, \ zeta_i ^ * \ geq 0, i = 1, ..., n \ end {split} \ end {выровнено} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="e7cf54257feefa3a1cdfa65288e5d1230916a9ce" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i\\\begin{split}\textrm {subject to } &amp;amp; y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\ &amp;amp; \zeta_i \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ min_ {w, b, \ zeta} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ {n} \ zeta_i \ \\ begin {split} \ textrm {при условии} &amp;amp; y_i (w ^ T \ phi (x_i) + b) \ geq 1 - \ zeta_i, \\ &amp;amp; \ zeta_i \ geq 0, i = 1, ..., п \ конец {разделение} \ конец {выровнено} \ конец {выравнивание} \]</target>
        </trans-unit>
        <trans-unit id="80291068f9bc632282f639938cf37593076f7e40" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha, \alpha^*} \frac{1}{2} (\alpha - \alpha^*)^T Q (\alpha - \alpha^*) + \varepsilon e^T (\alpha + \alpha^*) - y^T (\alpha - \alpha^*)\\\begin{split} \textrm {subject to } &amp;amp; e^T (\alpha - \alpha^*) = 0\\ &amp;amp; 0 \leq \alpha_i, \alpha_i^* \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ min _ {\ alpha, \ alpha ^ *} \ frac {1} {2} (\ alpha - \ alpha ^ *) ^ TQ (\ alpha - \ alpha ^ * ) + \ varepsilon e ^ T (\ alpha + \ alpha ^ *) - y ^ T (\ alpha - \ alpha ^ *) \\\ begin {split} \ textrm {при условии} &amp;amp; e ^ T (\ alpha - \ alpha ^ *) = 0 \\ &amp;amp; 0 \ leq \ alpha_i, \ alpha_i ^ * \ leq C, i = 1, ..., n \ end {split} \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6c7b70ef69da1a978d3d70eb6e72d1cfe185904a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha} \frac{1}{2} \alpha^T Q \alpha - e^T \alpha\\\begin{split} \textrm {subject to } &amp;amp; y^T \alpha = 0\\ &amp;amp; 0 \leq \alpha_i \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {align} \ min _ {\ alpha} \ frac {1} {2} \ alpha ^ TQ \ alpha - e ^ T \ alpha \\\ begin {split} \ textrm {с учетом } &amp;amp; y ^ T \ alpha = 0 \\ &amp;amp; 0 \ leq \ alpha_i \ leq C, i = 1, ..., n \ end {split} \ end {align} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="b61ecb24510d037b2f103f5394b305a25a58f23a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}median(y)_m = \underset{i \in N_m}{\mathrm{median}}(y_i)\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - median(y)_m|\end{aligned}\end{align} \]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6188a7c021d3288e439ea7246a74358b63a884c" translate="yes" xml:space="preserve">
          <source>\[(1 - eps) \|u - v\|^2 &amp;lt; \|p(u) - p(v)\|^2 &amp;lt; (1 + eps) \|u - v\|^2\]</source>
          <target state="translated">\ [(1 - eps) \ | u - v \ | ^ 2 &amp;lt;\ | p (u) - p (v) \ | ^ 2 &amp;lt;(1 + eps) \ | u - v \ | ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c4407dbb151e2710b04032ff6939f68ed3c7179c" translate="yes" xml:space="preserve">
          <source>\[A_n = R^{-1/2} A C^{-1/2}\]</source>
          <target state="translated">\ [A_n = R ^ {- 1/2} AC ^ {- 1/2} \]</target>
        </trans-unit>
        <trans-unit id="f6b0d9bcf51ca0db910abd2831694b2e6df3d3e4" translate="yes" xml:space="preserve">
          <source>\[BS = \frac{1}{N} \sum_{t=1}^{N}(f_t - o_t)^2\]</source>
          <target state="translated">\ [BS = \ frac {1} {N} \ sum_ {t = 1} ^ {N} (f_t - o_t) ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c92a9c50030567e1c914fdb60f6f36c624d7857a" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_q n_q (c_q - c) (c_q - c)^T\]</source>
          <target state="translated">\ [B_k = \ sum_q n_q (c_q - c) (c_q - c) ^ T \]</target>
        </trans-unit>
        <trans-unit id="ba2a7d3bd989e0c77672451c8ebf6d95f02e79e3" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7004892a8adf03dbfdffcdcf3787b7ebb419e77" translate="yes" xml:space="preserve">
          <source>\[C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)\]</source>
          <target state="translated">\ [C \ sum_ {i = 1, n} \ mathcal {L} (f (x_i), y_i) + \ Omega (w) \]</target>
        </trans-unit>
        <trans-unit id="cdd0300688de915acfc1a115df5a69adf7a6197d" translate="yes" xml:space="preserve">
          <source>\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24e7ca264d5b1b5ecf81452a44a55176b2008b8c" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69d401f524d7e967afe2dcb64dc99487200dfcd8" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\ [DB = \ frac {1} {k} \ sum {i = 1} ^ k \ max_ {i \ neq j} R_ {ij} \]</target>
        </trans-unit>
        <trans-unit id="0e40c0ff9b9201b3e6cc8ee7f729672fe6ce4c93" translate="yes" xml:space="preserve">
          <source>\[E(\mathbf{v}, \mathbf{h}) = -\sum_i \sum_j w_{ij}v_ih_j - \sum_i b_iv_i - \sum_j c_jh_j\]</source>
          <target state="translated">\ [E (\ mathbf {v}, \ mathbf {h}) = - \ sum_i \ sum_j w_ {ij} v_ih_j - \ sum_i b_iv_i - \ sum_j c_jh_j \]</target>
        </trans-unit>
        <trans-unit id="783de3e797180d6f4ba6c3e9379606ecef2ead2a" translate="yes" xml:space="preserve">
          <source>\[E(w,b) = \frac{1}{n}\sum_{i=1}^{n} L(y_i, f(x_i)) + \alpha R(w)\]</source>
          <target state="translated">\ [E (w, b) = \ frac {1} {n} \ sum_ {i = 1} ^ {n} L (y_i, f (x_i)) + \ alpha R (w) \]</target>
        </trans-unit>
        <trans-unit id="365f54944565346973bba6038073efb7e313ed11" translate="yes" xml:space="preserve">
          <source>\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+ }^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right) \frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})! (N-a_i-b_j+n_{ij})!}\]</source>
          <target state="translated">\ [E [\ text {MI} (U, V)] = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ sum_ {n_ {ij} = (a_i + b_j-N) ^ +} ^ {\ min (a_i, b_j)} \ frac {n_ {ij}} {N} \ log \ left (\ frac {N.n_ {ij}} {a_i b_j} \ right) \ frac {a_i! b_j! (N-a_i)! (N-b_j)!} {N! n_ {ij}! (a_i-n_ {ij})! (b_j-n_ {ij})! (N-a_i-b_j + n_ {ij})!} \]</target>
        </trans-unit>
        <trans-unit id="fa1ff8faa81d9e66252f62a095f5cf70ca1078c1" translate="yes" xml:space="preserve">
          <source>\[F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F (x) = \ sum_ {m = 1} ^ {M} \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="8b0368e365c0b4ab2c5226a46b2b8384821b7abd" translate="yes" xml:space="preserve">
          <source>\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}.\]</source>
          <target state="translated">\ [F_ \ beta = (1 + \ beta ^ 2) \ frac {\ text {precision} \ times \ text {вспомнить}} {\ beta ^ 2 \ text {precision} + \ text {вспомнить}}. \]</target>
        </trans-unit>
        <trans-unit id="c9eeb87b260c2954980548a507a8b1393c039854" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \arg\min_{h} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + h(x))\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ arg \ min_ {h} \ sum_ {i = 1} ^ {n} L (y_i, F_ {m-1} (x_i) + h) (Икс))\]</target>
        </trans-unit>
        <trans-unit id="c3b959c536d9b51ce676e93f30895d0c6d681eae" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="9b119698c7b1cbf47db5678415973bc69f053f0c" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) + \ nu \ gamma_m h_m (x) \]</target>
        </trans-unit>
        <trans-unit id="f67ac5f779f99408bbddee5aabe3119d85a325aa" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="53cc4ef6b492c65482e59fea0173cd005acf6ca7" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + h_m(x),\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79620d3f64f3ecc0a5f216eb6a57691d801c15cd" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^{n} \nabla_F L(y_i, F_{m-1}(x_i))\]</source>
          <target state="translated">\ [F_m (x) = F_ {m-1} (x) - \ gamma_m \ sum_ {i = 1} ^ {n} \ nabla_F L (y_i, F_ {m-1} (x_i)) \]</target>
        </trans-unit>
        <trans-unit id="90cafad385d21b4d4db9860dff7480af31e6cc3a" translate="yes" xml:space="preserve">
          <source>\[G(Q, \theta) = \frac{n_{left}}{N_m} H(Q_{left}(\theta)) + \frac{n_{right}}{N_m} H(Q_{right}(\theta))\]</source>
          <target state="translated">\ [G (Q, \ theta) = \ frac {n_ {left}} {N_m} H (Q_ {left} (\ theta)) + \ frac {n_ {right}} {N_m} H (Q_ {right} (\ theta)) \]</target>
        </trans-unit>
        <trans-unit id="a3b30c3461532826adfe7425f51daed9aaf98e97" translate="yes" xml:space="preserve">
          <source>\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</source>
          <target state="translated">\ [H (C) = - \ sum_ {c = 1} ^ {| C |} \ frac {n_c} {n} \ cdot \ log \ left (\ frac {n_c} {n} \ right) \]</target>
        </trans-unit>
        <trans-unit id="672f9873cccc012ff842c8c7fce069ac5cd92675" translate="yes" xml:space="preserve">
          <source>\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n} \cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</source>
          <target state="translated">\ [H (C | K) = - \ sum_ {c = 1} ^ {| C |} \ sum_ {k = 1} ^ {| K |} \ frac {n_ {c, k}} {n} \ cdot \ log \ left (\ frac {n_ {c, k}} {n_k} \ right) \]</target>
        </trans-unit>
        <trans-unit id="9dcc776906a998f47112457373d3636e82b5c382" translate="yes" xml:space="preserve">
          <source>\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</source>
          <target state="translated">\ [H (U) = - \ sum_ {i = 1} ^ {| U |} P (i) \ log (P (i)) \]</target>
        </trans-unit>
        <trans-unit id="bf873d01bafa66fa00d4a9abe244e71c3ad5c483" translate="yes" xml:space="preserve">
          <source>\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</source>
          <target state="translated">\ [H (V) = - \ sum_ {j = 1} ^ {| V |} P '(j) \ log (P' (j)) \]</target>
        </trans-unit>
        <trans-unit id="825bd8051092a0ff4da11fbb8a018da499318440" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = - \sum_k p_{mk} \log(p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = - \ sum_k p_ {mk} \ log (p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="86fb9fbe52343d6db8c412062ca26e8b3a61d7f8" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = 1 - \max(p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = 1 - \ max (p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="471e679a9a1baa18ae5b83f786849ce5561bcf62" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = \sum_k p_{mk} (1 - p_{mk})\]</source>
          <target state="translated">\ [H (X_m) = \ sum_k p_ {mk} (1 - p_ {mk}) \]</target>
        </trans-unit>
        <trans-unit id="d07612141f923e53a5d822ae265800fc511ebfa2" translate="yes" xml:space="preserve">
          <source>\[J(A, B) = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}\]</source>
          <target state="translated">\ [J (A, B) = \ frac {| A \ cap B |} {| A | + | B | - | A \ cap B |} \]</target>
        </trans-unit>
        <trans-unit id="b38d8ccb5f6105408ebebb5c4de384f0bcc0244c" translate="yes" xml:space="preserve">
          <source>\[J(y_i, \hat{y}_i) = \frac{|y_i \cap \hat{y}_i|}{|y_i \cup \hat{y}_i|}.\]</source>
          <target state="translated">\ [J (y_i, \ hat {y} _i) = \ frac {| y_i \ cap \ hat {y} _i |} {| y_i \ cup \ hat \ hat {y} _i |}. \]</target>
        </trans-unit>
        <trans-unit id="d318f9ea1800cd74dd7a27a0e7aa26e39a217efa" translate="yes" xml:space="preserve">
          <source>\[K_{ij} = L_{ij} - \overline{L_{i \cdot}} - \overline{L_{\cdot j}} + \overline{L_{\cdot \cdot}}\]</source>
          <target state="translated">\ [K_ {ij} = L_ {ij} - \ overline {L_ {i \ cdot}} - \ overline {L _ {\ cdot j}} + \ overline {L _ {\ cdot \ cdot}} \]</target>
        </trans-unit>
        <trans-unit id="4f142a1b3f1a25b7844f5bd577802840d9086424" translate="yes" xml:space="preserve">
          <source>\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0} \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</source>
          <target state="translated">\ [LRAP (y, \ hat {f}) = \ frac {1} {n _ {\ text {samples}}} \ sum_ {i = 0} ^ {n _ {\ text {samples}} - 1} \ frac {1} {|| y_i || _0} \ sum_ {j: y_ {ij} = 1} \ frac {| \ mathcal {L} _ {ij} |} {\ text {rank} _ {ij}} \ ]</target>
        </trans-unit>
        <trans-unit id="ce318e5aa62c88285e6dbc3450ddc43884867d96" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y, w) = \max\left\{1 - wy, 0\right\} = \left|1 - wy\right|_+\]</source>
          <target state="translated">\ [L_ \ text {Hinge} (y, w) = \ max \ left \ {1 - wy, 0 \ right \} = \ left | 1 - wy \ right | _ + \]</target>
        </trans-unit>
        <trans-unit id="ba42e2e6c73e49cc69262971d98739da8f3de127" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y_w, y_t) = \max\left\{1 + y_t - y_w, 0\right\}\]</source>
          <target state="translated">\ [L_ \ text {Hinge} (y_w, y_t) = \ max \ left \ {1 + y_t - y_w, 0 \ right \} \]</target>
        </trans-unit>
        <trans-unit id="7d42c3e71601b07673f2ff67be6498a9b9b5b660" translate="yes" xml:space="preserve">
          <source>\[L_{0-1}(y_i, \hat{y}_i) = 1(\hat{y}_i \not= y_i)\]</source>
          <target state="translated">\ [L_ {0-1} (y_i, \ hat {y} _i) = 1 (\ hat {y} _i \ not = y_i) \]</target>
        </trans-unit>
        <trans-unit id="2d55be0d74f5ef605272bd6c32e6867b2bf3e8e6" translate="yes" xml:space="preserve">
          <source>\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{labels}} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_j \not= y_j)\]</source>
          <target state="translated">\ [L_ {Hamming} (y, \ hat {y}) = \ frac {1} {n_ \ text {label}} \ sum_ {j = 0} ^ {n_ \ text {label} - 1} 1 (\ шляпа {y} _j \ not = y_j) \]</target>
        </trans-unit>
        <trans-unit id="b3092c91dac051243dcdc2b0e51b2cc71f3f1851" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</source>
          <target state="translated">\ [L _ {\ log} (Y, P) = - \ log \ operatorname {Pr} (Y | P) = - \ frac {1} {N} \ sum_ {i = 0} ^ {N-1} \ сумма_ {k = 0} ^ {K-1} y_ {i, k} \ log p_ {i, k} \]</target>
        </trans-unit>
        <trans-unit id="253a9ad7d14147f9b4d52f808d7adc29f4f1d369" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</source>
          <target state="translated">\ [L _ {\ log} (y, p) = - \ log \ operatorname {Pr} (y | p) = - (y \ log (p) + (1 - y) \ log (1 - p)) \ ]</target>
        </trans-unit>
        <trans-unit id="2efbeda9bdd157cc2d7a3c7780634a18e9cf252c" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2\]</source>
          <target state="translated">\ [Потеря (\ hat {y}, y, W) = -y \ ln {\ hat {y}} - (1-y) \ ln {(1- \ hat {y})} + \ alpha || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ad216be468be053e061c385b7f1c21d710fe84a9" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = \frac{1}{2}||\hat{y} - y ||_2^2 + \frac{\alpha}{2} ||W||_2^2\]</source>
          <target state="translated">\ [Потеря (\ hat {y}, y, W) = \ frac {1} {2} || \ hat {y} - y || _2 ^ 2 + \ frac {\ alpha} {2} || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="3d4d43e0aa8af2572cd4c7afaa27772d600c52ba" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{ c \times s - \sum_{k}^{K} p_k \times t_k }{\sqrt{ (s^2 - \sum_{k}^{K} p_k^2) \times (s^2 - \sum_{k}^{K} t_k^2) }}\]</source>
          <target state="translated">\ [MCC = \ frac {c \ times s - \ sum_ {k} ^ {K} p_k \ times t_k} {\ sqrt {(s ^ 2 - \ sum_ {k} ^ {K} p_k ^ 2) \ times (s ^ 2 - \ sum_ {k} ^ {K} t_k ^ 2)}} \]</target>
        </trans-unit>
        <trans-unit id="f5497e39840904c9cb7d2472c1ab3621a66cd485" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</source>
          <target state="translated">\ [MCC = \ frac {tp \ times tn - fp \ times fn} {\ sqrt {(tp + fp) (tp + fn) (tn + fp) (tn + fn)}}. \]</target>
        </trans-unit>
        <trans-unit id="a3da3c85336ea30ff991df5f7886c792d671d3d1" translate="yes" xml:space="preserve">
          <source>\[MI(U,V)=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i\cap V_j|}{N} \log\frac{N|U_i \cap V_j|}{|U_i||V_j|}\]</source>
          <target state="translated">\ [MI (U, V) = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ frac {| U_i \ cap V_j |} {N} \ log \ frac {N | U_i \ cap V_j |} {| U_i || V_j |} \]</target>
        </trans-unit>
        <trans-unit id="c94cfec038c55c60afa9fef476e0a1aad2563170" translate="yes" xml:space="preserve">
          <source>\[P(X | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (X-\mu_k)^t \Sigma_k^{-1} (X-\mu_k)\right)\]</source>
          <target state="translated">\ [P (X | y = k) = \ frac {1} {(2 \ pi) ^ {d / 2} | \ Sigma_k | ^ {1/2}} \ exp \ left (- \ frac {1} {2} (X- \ mu_k) ^ t \ Sigma_k ^ {- 1} (X- \ mu_k) \ right) \]</target>
        </trans-unit>
        <trans-unit id="cd893dbc741157abd91341aed411a740724f85fa" translate="yes" xml:space="preserve">
          <source>\[P(\mathbf{v}, \mathbf{h}) = \frac{e^{-E(\mathbf{v}, \mathbf{h})}}{Z}\]</source>
          <target state="translated">\ [P (\ mathbf {v}, \ mathbf {h}) = \ frac {e ^ {- E (\ mathbf {v}, \ mathbf {h})}} {Z} \]</target>
        </trans-unit>
        <trans-unit id="7e8396a93e6bd3272f4718e7de218023882d7d31" translate="yes" xml:space="preserve">
          <source>\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f84acbf7827b429f5edf701fe90ef79259a19956" translate="yes" xml:space="preserve">
          <source>\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a8ab66c6ea03a89651facccbd08d5f0c9be8c6d" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = P(i \mid y) x_i + (1 - P(i \mid y)) (1 - x_i)\]</source>
          <target state="translated">\ [P (x_i \ mid y) = P (i \ mid y) x_i + (1 - P (i \ mid y)) (1 - x_i) \]</target>
        </trans-unit>
        <trans-unit id="33b093ce0e5d6e386417ef609cc2f6a855343cc3" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)\]</source>
          <target state="translated">\ [P (x_i \ mid y) = \ frac {1} {\ sqrt {2 \ pi \ sigma ^ 2_y}} \ exp \ left (- \ frac {(x_i - \ mu_y) ^ 2} {2 \ sigma ^ 2_y} \ right) \]</target>
        </trans-unit>
        <trans-unit id="1f013d2ae1dd46efa06019f68c7849dc72ce7f4e" translate="yes" xml:space="preserve">
          <source>\[P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y),\]</source>
          <target state="translated">\ [P (x_i | y, x_1, \ dots, x_ {i-1}, x_ {i + 1}, \ dots, x_n) = P (x_i | y), \]</target>
        </trans-unit>
        <trans-unit id="c732ad1752bec3f2371482df4bfec3ce784d1ec4" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P (y \ mid x_1, \ dots, x_n) = \ frac {P (y) P (x_1, \ dots x_n \ mid y)} {P (x_1, \ dots, x_n)} \]</target>
        </trans-unit>
        <trans-unit id="facd455c5147b9177420e6f465438d2ec052942b" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84c8d40000ffaabc15011af6c72fc5efaa03e40c" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P (y \ mid x_1, \ dots, x_n) = \ frac {P (y) \ prod_ {i = 1} ^ {n} P (x_i \ mid y)} {P (x_1, \ dots, x_n )} \]</target>
        </trans-unit>
        <trans-unit id="edcd72a09735a7f6adceea22c0b30c20fbfbd80a" translate="yes" xml:space="preserve">
          <source>\[P(y=k | X) = \frac{P(X | y=k) P(y=k)}{P(X)} = \frac{P(X | y=k) P(y = k)}{ \sum_{l} P(X | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\ [P (y = k | X) = \ frac {P (X | y = k) P (y = k)} {P (X)} = \ frac {P (X | y = k) P (y = k)} {\ sum_ {l} P (X | y = l) \ cdot P (y = l)} \]</target>
        </trans-unit>
        <trans-unit id="d0d051ebe8e5f14c78017b6beb24cfde6b45cc0c" translate="yes" xml:space="preserve">
          <source>\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5a07827e49a88167851d8970eaa9edda3b99d65" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{\text{samples}} - 1} (y_i - \hat{y}_i)^2}{\sum_{i=0}^{n_\text{samples} - 1} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\ [R ^ 2 (y, \ hat {y}) = 1 - \ frac {\ sum_ {i = 0} ^ {n _ {\ text {samples}} - 1} (y_i - \ hat {y} _i) ^ 2} {\ sum_ {i = 0} ^ {n_ \ text {samples} - 1} (y_i - \ bar {y}) ^ 2} \]</target>
        </trans-unit>
        <trans-unit id="75a581e81c894ca3d5a39bbe361df977932542f2" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9b98e0db2ea75d1dfbeda81f631985feb91e53a" translate="yes" xml:space="preserve">
          <source>\[R_\alpha(T) = R(T) + \alpha|T|\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4a8061b9eb9628b02ec75d4e5fc5a21d09cd880" translate="yes" xml:space="preserve">
          <source>\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</source>
          <target state="translated">\ [R_ {ij} = \ frac {s_i + s_j} {d_ {ij}} \]</target>
        </trans-unit>
        <trans-unit id="a0fa8b8fb90971dc259d470e1011abda5608da98" translate="yes" xml:space="preserve">
          <source>\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7faa52dada966b566ea53656a8bd94425e2b50a6" translate="yes" xml:space="preserve">
          <source>\[W^{i+1} = W^i - \epsilon \nabla {Loss}_{W}^{i}\]</source>
          <target state="translated">\ [W ^ {i + 1} = W ^ i - \ epsilon \ nabla {Loss} _ {W} ^ {i} \]</target>
        </trans-unit>
        <trans-unit id="e598814b9bd2e3db200ccff196ebf646bf738ec7" translate="yes" xml:space="preserve">
          <source>\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</source>
          <target state="translated">\ [W_k = \ sum_ {q = 1} ^ k \ sum_ {x \ in C_q} (x - c_q) (x - c_q) ^ T \]</target>
        </trans-unit>
        <trans-unit id="7eb30be4ba7f05878cf003c46dfa54b35d57c946" translate="yes" xml:space="preserve">
          <source>\[X \approx X_k = U_k \Sigma_k V_k^\top\]</source>
          <target state="translated">\ [X \ приблизительно X_k = U_k \ Sigma_k V_k ^ \ top \]</target>
        </trans-unit>
        <trans-unit id="c7c03179d6deebc1c581ff68076935c59051f655" translate="yes" xml:space="preserve">
          <source>\[X' = X V_k\]</source>
          <target state="translated">\ [X '= X V_k \]</target>
        </trans-unit>
        <trans-unit id="1b12fce875e4a7610479762a7e27b3b69634b6af" translate="yes" xml:space="preserve">
          <source>\[X^* = D^{-1/2}U^t X\text{ with }\Sigma = UDU^t\]</source>
          <target state="translated">\ [X ^ * = D ^ {- 1/2} U ^ t X \ text {with} \ Sigma = UDU ^ t \]</target>
        </trans-unit>
        <trans-unit id="15463a9b27ce80c407246ad66ee390a5bc003068" translate="yes" xml:space="preserve">
          <source>\[\alpha \rho ||W||_1 + \alpha \rho ||H||_1 + \frac{\alpha(1-\rho)}{2} ||W||_{\mathrm{Fro}} ^ 2 + \frac{\alpha(1-\rho)}{2} ||H||_{\mathrm{Fro}} ^ 2\]</source>
          <target state="translated">\ [\ alpha \ rho || W || _1 + \ alpha \ rho || H || _1 + \ frac {\ alpha (1- \ rho)} {2} || W || _ {\ mathrm {Fro }} ^ 2 + \ frac {\ alpha (1- \ rho)} {2} || H || _ {\ mathrm {Fro}} ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ecb4b9fe8fc24f73a20eeac8e7781ad331ab3cc6" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||U||_1 \\ \text{subject to } &amp;amp; ||V_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{\mathrm{atoms}}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} (U ^ *, V ^ *) = \ underset {U, V} {\ operatorname {arg \, min \,}} &amp;amp; \ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || U || _1 \\ \ text {при условии} &amp;amp; || V_k || _2 = 1 \ text {для всех} 0 \ leq k &amp;lt;n _ {\ mathrm {atom}} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="113192b0908b5ad7f78568d56440ab2d30ef92e9" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||V||_1 \\ \text{subject to } &amp;amp; ||U_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{components}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} (U ^ *, V ^ *) = \ underset {U, V} {\ operatorname {arg \, min \,}} &amp;amp; \ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || V || _1 \\ \ text {при условии} &amp;amp; || U_k || _2 = 1 \ text {для всех} 0 \ leq k &amp;lt;n_ {components} \ end {split } \]</target>
        </trans-unit>
        <trans-unit id="3136579a6b2a85a0be46315eb9cbc3ba1e261551" translate="yes" xml:space="preserve">
          <source>\[\begin{split}H_{\epsilon}(z) = \begin{cases} z^2, &amp;amp; \text {if } |z| &amp;lt; \epsilon, \\ 2\epsilon|z| - \epsilon^2, &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} H _ {\ epsilon} (z) = \ begin {cases} z ^ 2, &amp;amp; \ text {if} | z | &amp;lt;\ epsilon, \\ 2 \ epsilon | z | - \ epsilon ^ 2, &amp;amp; \ text {иначе} \ end {case} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="b46cf81ba2e913dc611a985b07c8255c093eef0a" translate="yes" xml:space="preserve">
          <source>\[\begin{split}P(v_i=1|\mathbf{h}) = \sigma(\sum_j w_{ij}h_j + b_i) \\ P(h_i=1|\mathbf{v}) = \sigma(\sum_i w_{ij}v_i + c_j)\end{split}\]</source>
          <target state="translated">\ [\ begin {split} P (v_i = 1 | \ mathbf {h}) = \ sigma (\ sum_j w_ {ij} h_j + b_i) \\ P (h_i = 1 | \ mathbf {v}) = \ sigma (\ sum_i w_ {ij} v_i + c_j) \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="2a61de83e06a531ec76671fed3f61a04aabc9bf7" translate="yes" xml:space="preserve">
          <source>\[\begin{split}Z = \begin{bmatrix} R^{-1/2} U \\\\ C^{-1/2} V \end{bmatrix}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} Z = \ begin {bmatrix} R ^ {- 1/2} U \\\\ C ^ {- 1/2} V \ end {bmatrix} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="8fd5d1a7323dcc269879eaa3da3604856f3eb3a0" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\left\{ \begin{array}{c c l} -\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ 0 &amp;amp;\text{with probability} &amp;amp; 1 - 1 / s \\ +\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ \end{array} \right.\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ left \ {\ begin {array} {ccl} - \ sqrt {\ frac {s} {n _ {\ text {components}}}} &amp;amp; &amp;amp; 1 / 2s \\ 0 &amp;amp; \ text {с вероятностью} &amp;amp; 1 - 1 / s \\ + \ sqrt {\ frac {s} {n _ {\ text {components}}}} &amp;amp; &amp;amp; 1 / 2s \\ \ end {array} \ right. \ end { Трещина}\]</target>
        </trans-unit>
        <trans-unit id="240e6564ced61b1bc331dcf97a462834371b6641" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\log P(y=k | x) &amp;amp;= \log P(x | y=k) + \log P(y = k) + Cst \\ &amp;amp;= -\frac{1}{2} \log |\Sigma_k| -\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k) + \log P(y = k) + Cst,\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cce5812b4c3daf727144c68d463e8caf50c7bfbb" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} \begin{cases} (y_i-\hat{y}_i)^2, &amp;amp; \text{for }p=0\text{ (Normal)}\\ 2(y_i \log(y/\hat{y}_i) + \hat{y}_i - y_i), &amp;amp; \text{for}p=1\text{ (Poisson)}\\ 2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1), &amp;amp; \text{for}p=2\text{ (Gamma)}\\ 2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}- \frac{y\,\hat{y}^{1-p}_i}{1-p}+\frac{\hat{y}^{2-p}_i}{2-p}\right), &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64d0ec223c44ca16fb23a31d32e7c757a5e38ba8" translate="yes" xml:space="preserve">
          <source>\[\begin{split}h_i \bot h_j | \mathbf{v} \\ v_i \bot v_j | \mathbf{h}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} h_i \ bot h_j | \ mathbf {v} \\ v_i \ bot v_j | \ mathbf {h} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3a84b3b0085920a5dafc19e08421419f997fff14" translate="yes" xml:space="preserve">
          <source>\[\begin{split}pd_{X_S}(x_S) &amp;amp;\overset{def}{=} \mathbb{E}_{X_C}\left[ f(x_S, X_C) \right]\\ &amp;amp;= \int f(x_S, x_C) p(x_C) dx_C,\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6675ac3debfec98638ba1f9b136883988a6a0c0b" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i + 1)} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3198bb38407bb1554dc0d1959561349fcfcad349" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i) + 1} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {(\ lambda)} = \ begin {cases} [(x_i + 1) ^ \ lambda - 1] / \ lambda &amp;amp; \ text {if} \ lambda \ neq 0, x_i \ geq 0, \\ [8pt] \ ln {(x_i) + 1} &amp;amp; \ text {if} \ lambda = 0, x_i \ geq 0 \\ [8pt] - [(- x_i + 1) ^ {2 - \ lambda} - 1] / (2 - \ lambda) &amp;amp; \ text {if} \ lambda \ neq 2, x_i &amp;lt;0, \\ [8pt] - \ ln (- x_i + 1) &amp;amp; \ text {if} \ lambda = 2, x_i &amp;lt;0 \ end {case} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="dc87ecfd4801e13673bdd8bb567f720368f1d00c" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} \dfrac{x_i^\lambda - 1}{\lambda} &amp;amp; \text{if } \lambda \neq 0, \\[8pt] \ln{(x_i)} &amp;amp; \text{if } \lambda = 0, \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {(\ lambda)} = \ begin {cases} \ dfrac {x_i ^ \ lambda - 1} {\ lambda} &amp;amp; \ text {if} \ lambda \ neq 0, \\ [ 8pt] \ ln {(x_i)} &amp;amp; \ text {if} \ lambda = 0, \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="4537e01f403cf1db6a1704e87011ad05c2900083" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</source>
          <target state="translated">\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</target>
        </trans-unit>
        <trans-unit id="a73d653ad8356da32b64d5107d59910b4574da8f" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{samples}}{n_{subsamples}}\]</source>
          <target state="translated">\[\binom{n_{samples}}{n_{subsamples}}\]</target>
        </trans-unit>
        <trans-unit id="ac1ff82d2bb9be7a891279ff19e58ef9606ac1e2" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac {1}{\alpha (t_0 + t)}\]</source>
          <target state="translated">\ [\ eta ^ {(t)} = \ frac {1} {\ alpha (t_0 + t)} \]</target>
        </trans-unit>
        <trans-unit id="94fa32af9a54520431e5e0db6110f5f4be3adb89" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac{eta_0}{t^{power\_t}}\]</source>
          <target state="translated">\ [\ eta ^ {(t)} = \ frac {eta_0} {t ^ {power \ _t}} \]</target>
        </trans-unit>
        <trans-unit id="5914d3325cfa1135b23fa0bc1a30756771d61bd1" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23f7d8421e9f7d86dc62315499303963443744dd" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ab74fa9a47831af7bc26708f2eb4bb36eb7c478" translate="yes" xml:space="preserve">
          <source>\[\gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) - \gamma \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)})\]</source>
          <target state="translated">\ [\ gamma_m = \ arg \ min _ {\ gamma} \ sum_ {i = 1} ^ {n} L (y_i, F_ {m-1} (x_i) - \ gamma \ frac {\ partial L (y_i, F_ {m-1} (x_i))} {\ partial F_ {m-1} (x_i)}) \]</target>
        </trans-unit>
        <trans-unit id="03488d7aa371e338e3a792b1ee0314e7750d1c23" translate="yes" xml:space="preserve">
          <source>\[\hat{K} = \mathrm{argmin}_K \big( \mathrm{tr} S K - \mathrm{log} \mathrm{det} K + \alpha \|K\|_1 \big)\]</source>
          <target state="translated">\ [\ hat {K} = \ mathrm {argmin} _K \ big (\ mathrm {tr} SK - \ mathrm {log} \ mathrm {det} K + \ alpha \ | K \ | _1 \ big) \]</target>
        </trans-unit>
        <trans-unit id="9d564db2d54a230e005c20037b5a37d139fd79dd" translate="yes" xml:space="preserve">
          <source>\[\hat{\theta}_{yi} = \frac{ N_{yi} + \alpha}{N_y + \alpha n}\]</source>
          <target state="translated">\ [\ hat {\ theta} _ {yi} = \ frac {N_ {yi} + \ alpha} {N_y + \ alpha n} \]</target>
        </trans-unit>
        <trans-unit id="c11c6e06d183bd2451c8cb2b3112bec0b1bc1ee8" translate="yes" xml:space="preserve">
          <source>\[\hat{c} = \arg\min_c \sum_{i} t_i w_{ci}\]</source>
          <target state="translated">\ [\ hat {c} = \ arg \ min_c \ sum_ {i} t_i w_ {ci} \]</target>
        </trans-unit>
        <trans-unit id="0d0878697ede61cc2d8e8a17d350fedc4b3570ca" translate="yes" xml:space="preserve">
          <source>\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</source>
          <target state="translated">\ [\ hat {w} _i = \ frac {w_i} {\ sum_j {1 (y_j = y_i) w_j}} \]</target>
        </trans-unit>
        <trans-unit id="2a9f64bd46b89b26f87a73f822e103df8215fc20" translate="yes" xml:space="preserve">
          <source>\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4cf751319dcee1f0c7d13ac626ea9ed7a5bb6a9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, X) = h(Xw).\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="463125ace329bbcbe2634beaad2a87856ea8f696" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + ... + w_p x_p \]</target>
        </trans-unit>
        <trans-unit id="d7104cc52e967d53cc9bb7db2f89101bc8dd84a8" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1 ^ 2 + w_5 x_2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="658832cb765efda37a6b6c541d565e8e7abeaf9e" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 x_1 + w_2 x_2 \]</target>
        </trans-unit>
        <trans-unit id="e16dea6416d3f9e94f0e5c1b50c7914fc96699e9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\ [\ hat {y} (w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5 \]</target>
        </trans-unit>
        <trans-unit id="1ef6664dd57ac85f53b0ac082bd4ac87b3d1bc48" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ee9d5e754305261d56bc754281eac2d4bc47e43" translate="yes" xml:space="preserve">
          <source>\[\kappa = (p_o - p_e) / (1 - p_e)\]</source>
          <target state="translated">\ [\ kappa = (p_o - p_e) / (1 - p_e) \]</target>
        </trans-unit>
        <trans-unit id="167a98e04ab5b59774a90feac289ea3a97af6579" translate="yes" xml:space="preserve">
          <source>\[\log P(v) = \log \sum_h e^{-E(v, h)} - \log \sum_{x, y} e^{-E(x, y)}\]</source>
          <target state="translated">\ [\ log P (v) = \ log \ sum_h e ^ {- E (v, h)} - \ log \ sum_ {x, y} e ^ {- E (x, y)} \]</target>
        </trans-unit>
        <trans-unit id="3615a8591ff789e7148f8d4eaedd232d6f832187" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a818beecd93bff11790e50acc933a2d8090bf837" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = \omega_k^t x + \omega_{k0} + Cst.\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad74f3245329845209a6a11327e3e01ab638c922" translate="yes" xml:space="preserve">
          <source>\[\log\: P(w | \alpha, \eta) \geq L(w,\phi,\gamma,\lambda) \overset{\triangle}{=} E_{q}[\log\:p(w,z,\theta,\beta|\alpha,\eta)] - E_{q}[\log\:q(z, \theta, \beta)]\]</source>
          <target state="translated">\ [\ log \: P (w | \ alpha, \ eta) \ geq L (w, \ phi, \ gamma, \ lambda) \ overset {\ треугольник} {=} E_ {q} [\ log \: p (w, z, \ theta, \ beta | \ alpha, \ eta)] - E_ {q} [\ log \: q (z, \ theta, \ beta)] \]</target>
        </trans-unit>
        <trans-unit id="acd2ba041ece952cccd5e4312456e983a53c6177" translate="yes" xml:space="preserve">
          <source>\[\mathbf{X} = W \mathbf{H} + \mathbf{M} + \mathbf{E}\]</source>
          <target state="translated">\ [\ mathbf {X} = W \ mathbf {H} + \ mathbf {M} + \ mathbf {E} \]</target>
        </trans-unit>
        <trans-unit id="3fc441ca9a3b802fffa9f5232b4a01983592e3f6" translate="yes" xml:space="preserve">
          <source>\[\mathrm{Var}[X] = p(1 - p)\]</source>
          <target state="translated">\ [\ mathrm {Var} [X] = p (1 - p) \]</target>
        </trans-unit>
        <trans-unit id="115415b8df2e0037567cec45ba374bf6acae476a" translate="yes" xml:space="preserve">
          <source>\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, y_i (w^T \phi(x_i) + b)),\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff67bbd323e7ac7f1f2a65cc0812c3d22a62f042" translate="yes" xml:space="preserve">
          <source>\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, |y_i - (w^T \phi(x_i) + b)| - \varepsilon),\]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fa465ae3dc6f6cd2a645126f7fc3c5985939961" translate="yes" xml:space="preserve">
          <source>\[\min_{W} { \frac{1}{2n_{\text{samples}}} ||X W - Y||_{\text{Fro}}^2 + \alpha \rho ||W||_{2 1} + \frac{\alpha(1-\rho)}{2} ||W||_{\text{Fro}}^2}\]</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
