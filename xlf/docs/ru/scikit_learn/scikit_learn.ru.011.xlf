<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="d4e46a5f1bb78af76b3523ee33b19eb9c786ce08" translate="yes" xml:space="preserve">
          <source>A common practice for evaluating the results of image denoising is by looking at the difference between the reconstruction and the original image. If the reconstruction is perfect this will look like Gaussian noise.</source>
          <target state="translated">Обычная практика оценки результатов шумопоглощения растра заключается в рассмотрении разницы между реконструированным и исходным растром.Если реконструкция безупречна,то она будет выглядеть как гауссовский шум.</target>
        </trans-unit>
        <trans-unit id="4ed0a0436668c33a0351f627732f0587ac7983ed" translate="yes" xml:space="preserve">
          <source>A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this example is to illustrate the nature of decision boundaries of different classifiers. This should be taken with a grain of salt, as the intuition conveyed by these examples does not necessarily carry over to real datasets.</source>
          <target state="translated">Сравнение нескольких классификаторов в научном пособии по синтетическим наборам данных.Смысл этого примера заключается в том,чтобы проиллюстрировать природу границ решений различных классификаторов.Это следует делать с помощью зерна соли,поскольку интуиция,передаваемая этими примерами,не обязательно переносится на реальные наборы данных.</target>
        </trans-unit>
        <trans-unit id="08896462e97fc3765d56051f9cf494df2d13585e" translate="yes" xml:space="preserve">
          <source>A comparison of different values for regularization parameter &amp;lsquo;alpha&amp;rsquo; on synthetic datasets. The plot shows that different alphas yield different decision functions.</source>
          <target state="translated">Сравнение различных значений параметра регуляризации &amp;laquo;альфа&amp;raquo; на синтетических наборах данных. График показывает, что разные альфы дают разные функции принятия решений.</target>
        </trans-unit>
        <trans-unit id="5ffdb4122629b0408fc648de5eb2e8856b001ee3" translate="yes" xml:space="preserve">
          <source>A comparison of the clustering algorithms in scikit-learn</source>
          <target state="translated">Сравнение алгоритмов кластеризации в науках.</target>
        </trans-unit>
        <trans-unit id="3aba9c608b9764b22ebdea01be3ad9e7396b0707" translate="yes" xml:space="preserve">
          <source>A comparison of the outlier detection algorithms in scikit-learn. Local Outlier Factor (LOF) does not show a decision boundary in black as it has no predict method to be applied on new data when it is used for outlier detection.</source>
          <target state="translated">Сравнение алгоритмов обнаружения отклонений в науках.Local Outlier Factor (LOF)не показывает границу решения черным цветом,так как не имеет метода предсказания,который может быть применен к новым данным,когда он используется для обнаружения отклонений.</target>
        </trans-unit>
        <trans-unit id="d90a43f9bc5a8cfdf7c44591b758b4103cd4b78a" translate="yes" xml:space="preserve">
          <source>A complete example of this classification problem is available as an example that you can run and study: &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt;.</source>
          <target state="translated">Полный пример этой проблемы классификации доступен в качестве примера, который вы можете запустить и изучить: &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Распознавание рукописных цифр&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5fa8afb91b45355653b6f013837f985ec55a809c" translate="yes" xml:space="preserve">
          <source>A constant prediction baseline</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4711e9024cec2c4a1383670cb0218b599982c096" translate="yes" xml:space="preserve">
          <source>A context object for caching a function&amp;rsquo;s return value each time it is called with the same input arguments.</source>
          <target state="translated">Объект контекста для кэширования возвращаемого значения функции каждый раз, когда она вызывается с теми же входными аргументами.</target>
        </trans-unit>
        <trans-unit id="198c09de283f0c6001f8ae5be18eb83356d81a3a" translate="yes" xml:space="preserve">
          <source>A contiguous slice of distance matrix, optionally processed by &lt;code&gt;reduce_func&lt;/code&gt;.</source>
          <target state="translated">Непрерывный фрагмент матрицы расстояний, необязательно обрабатываемый &lt;code&gt;reduce_func&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2ac4a68a26c3c2eae7c82c7be7376e0b1206d26c" translate="yes" xml:space="preserve">
          <source>A contingency matrix given by the &lt;code&gt;contingency_matrix&lt;/code&gt; function. If value is &lt;code&gt;None&lt;/code&gt;, it will be computed, otherwise the given value is used, with &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt; ignored.</source>
          <target state="translated">Матрица непредвиденных обстоятельств, заданная функцией &lt;code&gt;contingency_matrix&lt;/code&gt; . Если значение равно &lt;code&gt;None&lt;/code&gt; , оно будет вычислено, в противном случае используется заданное значение, а &lt;code&gt;labels_true&lt;/code&gt; и &lt;code&gt;labels_pred&lt;/code&gt; игнорируются.</target>
        </trans-unit>
        <trans-unit id="e9c011a87c5032bcc5be043ba28885f86dd1572a" translate="yes" xml:space="preserve">
          <source>A continuous log-uniform random variable is available through &lt;code&gt;loguniform&lt;/code&gt;. This is a continuous version of log-spaced parameters. For example to specify &lt;code&gt;C&lt;/code&gt; above, &lt;code&gt;loguniform(1,
100)&lt;/code&gt; can be used instead of &lt;code&gt;[1, 10, 100]&lt;/code&gt; or &lt;code&gt;np.logspace(0, 2,
num=1000)&lt;/code&gt;. This is an alias to SciPy&amp;rsquo;s &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.reciprocal.html&quot;&gt;stats.reciprocal&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54ec3e229cd991b7b39939aa120ad2133da3723" translate="yes" xml:space="preserve">
          <source>A copy of the &lt;code&gt;classes&lt;/code&gt; parameter where provided, or otherwise, the sorted set of classes found when fitting.</source>
          <target state="translated">Копия параметра &lt;code&gt;classes&lt;/code&gt; если предоставлена, или, в противном случае, отсортированный набор классов, найденный при подгонке.</target>
        </trans-unit>
        <trans-unit id="0460778fea705652baf3b5d397ac145e2c8d559f" translate="yes" xml:space="preserve">
          <source>A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.</source>
          <target state="translated">Таким образом,корпус документов может быть представлен матрицей с одной строкой на документ и одной колонкой на токен (например,слово),встречающимися в корпусе.</target>
        </trans-unit>
        <trans-unit id="b1d91a72335bd05329f277d8169a200f3a7e7461" translate="yes" xml:space="preserve">
          <source>A cross-validation generator splits the whole dataset k times in training and test data. Subsets of the training set with varying sizes will be used to train the estimator and a score for each training subset size and the test set will be computed. Afterwards, the scores will be averaged over all k runs for each training subset size.</source>
          <target state="translated">Генератор перекрестной проверки разбивает весь набор данных k раз при обучении и испытаниях.Для обучения оценщика будут использоваться подмножества обучающего набора с различными размерами,и будет вычислен балл для каждого подмножества обучения,а также тестовый набор.После этого оценки будут усреднены по всем подмножествам k для каждого размера подмножества обучения.</target>
        </trans-unit>
        <trans-unit id="2e60520122aededd78427759b8d5e2ce36a7e309" translate="yes" xml:space="preserve">
          <source>A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the &lt;code&gt;.data&lt;/code&gt; member, which is a &lt;code&gt;n_samples, n_features&lt;/code&gt; array. In the case of supervised problem, one or more response variables are stored in the &lt;code&gt;.target&lt;/code&gt; member. More details on the different datasets can be found in the &lt;a href=&quot;../../datasets/index#datasets&quot;&gt;dedicated section&lt;/a&gt;.</source>
          <target state="translated">Набор данных - это подобный словарю объект, который содержит все данные и некоторые метаданные о данных. Эти данные хранятся в элементе &lt;code&gt;.data&lt;/code&gt; , который представляет собой &lt;code&gt;n_samples, n_features&lt;/code&gt; . В случае контролируемой проблемы одна или несколько переменных ответа сохраняются в &lt;code&gt;.target&lt;/code&gt; . Более подробную информацию о различных наборах данных можно найти в &lt;a href=&quot;../../datasets/index#datasets&quot;&gt;специальном разделе&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c689c278ed2c402419ef82b79e626634acb9d7dd" translate="yes" xml:space="preserve">
          <source>A dataset is uniquely specified by its &lt;code&gt;data_id&lt;/code&gt;, but not necessarily by its name. Several different &amp;ldquo;versions&amp;rdquo; of a dataset with the same name can exist which can contain entirely different datasets. If a particular version of a dataset has been found to contain significant issues, it might be deactivated. Using a name to specify a dataset will yield the earliest version of a dataset that is still active. That means that &lt;code&gt;fetch_openml(name=&quot;miceprotein&quot;)&lt;/code&gt; can yield different results at different times if earlier versions become inactive. You can see that the dataset with &lt;code&gt;data_id&lt;/code&gt; 40966 that we fetched above is the version 1 of the &amp;ldquo;miceprotein&amp;rdquo; dataset:</source>
          <target state="translated">Набор данных однозначно определяется своим &lt;code&gt;data_id&lt;/code&gt; , но не обязательно своим именем. Может существовать несколько разных &amp;laquo;версий&amp;raquo; набора данных с одинаковым именем, которые могут содержать совершенно разные наборы данных. Если определенная версия набора данных содержит серьезные проблемы, ее можно отключить. Использование имени для указания набора данных даст самую раннюю версию набора данных, которая все еще активна. Это означает, что &lt;code&gt;fetch_openml(name=&quot;miceprotein&quot;)&lt;/code&gt; может давать разные результаты в разное время, если более ранние версии становятся неактивными. Вы можете видеть, что набор данных с &lt;code&gt;data_id&lt;/code&gt; 40966, который мы получили выше, является версией 1 набора данных &amp;laquo;miceprotein&amp;raquo;:</target>
        </trans-unit>
        <trans-unit id="015b04be42703b2ddb8ba533bada1a317c896a28" translate="yes" xml:space="preserve">
          <source>A decision tree classifier.</source>
          <target state="translated">Классификатор дерева решений.</target>
        </trans-unit>
        <trans-unit id="2630b9dcfdbd7604846f7a233491e190f45a9740" translate="yes" xml:space="preserve">
          <source>A decision tree is boosted using the AdaBoost.R2 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; algorithm on a 1D sinusoidal dataset with a small amount of Gaussian noise. 299 boosts (300 decision trees) is compared with a single decision tree regressor. As the number of boosts is increased the regressor can fit more detail.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1457482037e3da549c4d599a20c71477d87290a" translate="yes" xml:space="preserve">
          <source>A decision tree is boosted using the AdaBoost.R2 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; algorithm on a 1D sinusoidal dataset with a small amount of Gaussian noise. 299 boosts (300 decision trees) is compared with a single decision tree regressor. As the number of boosts is increased the regressor can fit more detail.</source>
          <target state="translated">Дерево решений усиливается с помощью алгоритма AdaBoost.R2 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; на одномерном синусоидальном наборе данных с небольшим количеством гауссовского шума. 299 повышений (300 деревьев решений) сравнивается с одним регрессором дерева решений. По мере увеличения количества повышений регрессор может отображать больше деталей.</target>
        </trans-unit>
        <trans-unit id="98423fef8caf500459be69ac8cff91bec1b557c8" translate="yes" xml:space="preserve">
          <source>A decision tree regressor.</source>
          <target state="translated">Регрессор дерева решений.</target>
        </trans-unit>
        <trans-unit id="fac54dbce7b4a9529cb6b07cf132d857e0fb7a2e" translate="yes" xml:space="preserve">
          <source>A demo of K-Means clustering on the handwritten digits data</source>
          <target state="translated">Демонстрация кластеризации K-Means на данных рукописных цифр.</target>
        </trans-unit>
        <trans-unit id="985d8495d6de7661e6b4b5a0919641f87e6bc3f6" translate="yes" xml:space="preserve">
          <source>A demo of structured Ward hierarchical clustering on an image of coins</source>
          <target state="translated">Демонстрация структурированной иерархической кластеризации Уорда на изображении монет.</target>
        </trans-unit>
        <trans-unit id="728da4fce5aa5c78dc45e16c348781662170d8aa" translate="yes" xml:space="preserve">
          <source>A demo of the Spectral Biclustering algorithm</source>
          <target state="translated">Демонстрация алгоритма Спектральной Биклюстинга.</target>
        </trans-unit>
        <trans-unit id="9435014b37ab8720ce8e8dead6831ddaa2609878" translate="yes" xml:space="preserve">
          <source>A demo of the Spectral Co-Clustering algorithm</source>
          <target state="translated">Демонстрация алгоритма спектрального со-клестера.</target>
        </trans-unit>
        <trans-unit id="35f2c0aaf840683641795d09aa0a1e201f37f9de" translate="yes" xml:space="preserve">
          <source>A demo of the mean-shift clustering algorithm</source>
          <target state="translated">Демонстрация алгоритма кластеризации среднего сдвига.</target>
        </trans-unit>
        <trans-unit id="d3781231daa22a497eef6f674b9f3cd7b216bf2a" translate="yes" xml:space="preserve">
          <source>A demonstration of feature discretization on synthetic classification datasets. Feature discretization decomposes each feature into a set of bins, here equally distributed in width. The discrete values are then one-hot encoded, and given to a linear classifier. This preprocessing enables a non-linear behavior even though the classifier is linear.</source>
          <target state="translated">Демонстрация дискретизации функций на синтетических классификационных наборах данных.Дискретизация функций разлагает каждую функцию на набор бункеров,здесь они равномерно распределены по ширине.Затем дискретные значения кодируются в один момент и передаются линейному классификатору.Такая препроцессинговая обработка обеспечивает нелинейное поведение,даже если классификатор является линейным.</target>
        </trans-unit>
        <trans-unit id="95eced0791e7dfa2447624723a21d4f3bf963a74" translate="yes" xml:space="preserve">
          <source>A detailed description of the algorithm can be found in the documentation of the &lt;code&gt;linear_model&lt;/code&gt; sub-package.</source>
          <target state="translated">Подробное описание алгоритма можно найти в документации &lt;code&gt;linear_model&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="85ef0d1a4425c2a7d76f392327f60a1b7513d0f1" translate="yes" xml:space="preserve">
          <source>A dict of arrays containing the score/time arrays for each scorer is returned. The possible keys for this &lt;code&gt;dict&lt;/code&gt; are:</source>
          <target state="translated">Возвращается dict из массивов, содержащих массивы очков / времени для каждого секретаря. Возможные ключи для этого &lt;code&gt;dict&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="111521e1b62dc92a5d55cc421f659d37509b3d83" translate="yes" xml:space="preserve">
          <source>A dict with keys as column headers and values as columns, that can be imported into a pandas &lt;code&gt;DataFrame&lt;/code&gt;.</source>
          <target state="translated">Dict с ключами в качестве заголовков столбцов и значениями в качестве столбцов, которые можно импортировать в &lt;code&gt;DataFrame&lt;/code&gt; pandas .</target>
        </trans-unit>
        <trans-unit id="c8159c56c705a647167c0db6b7eec6aec52babc5" translate="yes" xml:space="preserve">
          <source>A dictionary mapping feature names to feature indices.</source>
          <target state="translated">Отображение в словаре названий объектов на предметных указателях.</target>
        </trans-unit>
        <trans-unit id="d69a0d863960291435690723c91aee6afd547cfb" translate="yes" xml:space="preserve">
          <source>A dictionary of {dataset_name: data_dict}, or {dataset_name: (data_dict, ordering). &lt;code&gt;data_dict&lt;/code&gt; itself is a dictionary of {column_name: data_array}, and &lt;code&gt;ordering&lt;/code&gt; is a list of column_names to determine the ordering in the data set (see &lt;code&gt;fake_mldata&lt;/code&gt; for details).</source>
          <target state="translated">Словарь {dataset_name: data_dict} или {dataset_name: (data_dict, ordering). &lt;code&gt;data_dict&lt;/code&gt; сам по себе является словарем {column_name: data_array}, а &lt;code&gt;ordering&lt;/code&gt; - это список имен column_names для определения порядка в наборе данных ( подробности см. в &lt;code&gt;fake_mldata&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="f0df6656a799b1b490376f17c246c83878449378" translate="yes" xml:space="preserve">
          <source>A different approach for approximating an additive variant of the chi squared kernel.</source>
          <target state="translated">Другой подход к аппроксимации аддитивного варианта квадратного ядра чи.</target>
        </trans-unit>
        <trans-unit id="183fe0e3f615bfbf70ad6cec7cbf647c2be26b19" translate="yes" xml:space="preserve">
          <source>A discrepancy between the number of terms reported for DictVectorizer and for FeatureHasher is to be expected due to hash collisions.</source>
          <target state="translated">Из-за столкновений хэшей следует ожидать расхождения между количеством терминов,сообщаемых для DictVectorizer и для FeatureHasher.</target>
        </trans-unit>
        <trans-unit id="5359a8a92b18a35ca1595de7bb20b2a0c7e2882d" translate="yes" xml:space="preserve">
          <source>A distance matrix D such that D_{i, j} is the distance between the ith and jth vectors of the given matrix X, if Y is None. If Y is not None, then D_{i, j} is the distance between the ith array from X and the jth array from Y.</source>
          <target state="translated">Матрица расстояний D такая,что D_{i,j}-это расстояние между ith и jth векторами заданной матрицы X,если Y равно None.Если Y не None,то D_{i,j}-это расстояние между ith-массивом от X и jth-массивом от Y.</target>
        </trans-unit>
        <trans-unit id="91104d203f36a74818ec42e8962e98d2f258acd0" translate="yes" xml:space="preserve">
          <source>A document is a sequence of \(N\) words.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ce7ab60e9677f7708dd8a607942d2c0cccce5364" translate="yes" xml:space="preserve">
          <source>A feature array, or array of distances between samples if &lt;code&gt;metric='precomputed'&lt;/code&gt;.</source>
          <target state="translated">Массив объектов или массив расстояний между выборками, если &lt;code&gt;metric='precomputed'&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b2db61a5e11f04d01b2535f105cf88de339d5444" translate="yes" xml:space="preserve">
          <source>A feature array, or array of distances between samples if metric=&amp;rsquo;precomputed&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb559e312d64d98c335a9c4be5e943c082d9b127" translate="yes" xml:space="preserve">
          <source>A feature array, or array of distances between samples if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="798664f5f45f763ed33c1b77b763944574aa4f4f" translate="yes" xml:space="preserve">
          <source>A few definitions:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86908273dab820320f981714d4826279093534cf" translate="yes" xml:space="preserve">
          <source>A few definitions: a &lt;em&gt;claim&lt;/em&gt; is the request made by a policyholder to the insurer to compensate for a loss covered by the insurance. The &lt;em&gt;claim amount&lt;/em&gt; is the amount of money that the insurer must pay. The &lt;em&gt;exposure&lt;/em&gt; is the duration of the insurance coverage of a given policy, in years.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24d02e76c875ea70e2d1746a2ae2b7543f98dedf" translate="yes" xml:space="preserve">
          <source>A few features available in this model:</source>
          <target state="translated">Несколько функций,доступных в этой модели:</target>
        </trans-unit>
        <trans-unit id="a596b46f1e97e6f01add8ad1641f2aa816638c4f" translate="yes" xml:space="preserve">
          <source>A figure object onto which the plots will be drawn, after the figure has been cleared. By default, a new one is created.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24026427c908afb044a16ec627f1f7bf5b040d61" translate="yes" xml:space="preserve">
          <source>A fitted estimator object implementing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;, or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;. Multioutput-multiclass classifiers are not supported.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06304e4581de12feb43d312c564ae9a70106b9ba" translate="yes" xml:space="preserve">
          <source>A fitted gradient boosting model.</source>
          <target state="translated">Встроенная модель увеличения уклона.</target>
        </trans-unit>
        <trans-unit id="ad78d890244343cb481ec0d46fb95ae01e19e178" translate="yes" xml:space="preserve">
          <source>A function to handle preprocessing, tokenization and n-grams generation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c6e87ebdac3e8a70f2ac508aaddfaa8df544da7" translate="yes" xml:space="preserve">
          <source>A function to preprocess the text before tokenization.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="004f6b369bbbaaeac6e581b99b63af10868df162" translate="yes" xml:space="preserve">
          <source>A function to split a string into a sequence of tokens.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70c3f4d0379ae967616e2ce28baef3bbea4be9cf" translate="yes" xml:space="preserve">
          <source>A generator over parameter settings, constructed from param_distributions.</source>
          <target state="translated">Генератор над настройками параметров,построенный из параметров param_distributions.</target>
        </trans-unit>
        <trans-unit id="ab5af31ec50522e8f84b5fd320b5185d1e649aae" translate="yes" xml:space="preserve">
          <source>A good introduction to Bayesian methods is given in C. Bishop: Pattern Recognition and Machine learning</source>
          <target state="translated">Хорошее введение в байесовские методы дано в К.Бишопе:Распознавание образов и машинное обучение</target>
        </trans-unit>
        <trans-unit id="2abfd97b78d2efa9a468ce9e53e4e40c6a740a0c" translate="yes" xml:space="preserve">
          <source>A good value reported by this method does not imply the best information retrieval.</source>
          <target state="translated">Хорошее значение,сообщаемое этим методом,не подразумевает наилучшего поиска информации.</target>
        </trans-unit>
        <trans-unit id="ee0139a4c757902f8a15e776dbb86ec75b8b58ee" translate="yes" xml:space="preserve">
          <source>A graphical overview of basic areas of machine learning, and guidance which kind of algorithms to use in a given situation.</source>
          <target state="translated">Графический обзор основных областей машинного обучения и указания,какие алгоритмы использовать в данной ситуации.</target>
        </trans-unit>
        <trans-unit id="09adb6eadfd2176464d83487c19995d3ec4f7162" translate="yes" xml:space="preserve">
          <source>A histogram is a simple visualization of data where bins are defined, and the number of data points within each bin is tallied. An example of a histogram can be seen in the upper-left panel of the following figure:</source>
          <target state="translated">Гистограмма представляет собой простую визуализацию данных,где определяются бины,и подсчитывается количество точек данных внутри каждого бина.Пример гистограммы можно посмотреть на верхней левой панели следующего рисунка:</target>
        </trans-unit>
        <trans-unit id="7bef6839991533f8c855219658630fb1d97c3e13" translate="yes" xml:space="preserve">
          <source>A kernel between the gene sequences is defined using R-convolution &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; by integrating a binary letter-wise kernel over all pairs of letters among a pair of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d7d25ec6ddbab84b2f2e99ec27b1c5e75159286" translate="yes" xml:space="preserve">
          <source>A kernel hyperparameter&amp;rsquo;s specification in form of a namedtuple.</source>
          <target state="translated">Спецификация гиперпараметра ядра в виде именованного кортежа.</target>
        </trans-unit>
        <trans-unit id="9dd2e21d515f945fa766366930e3f2f884774833" translate="yes" xml:space="preserve">
          <source>A kernel matrix K such that K_{i, j} is the kernel between the ith and jth vectors of the given matrix X, if Y is None. If Y is not None, then K_{i, j} is the kernel between the ith array from X and the jth array from Y.</source>
          <target state="translated">Матрица кернела K такая,что K_{i,j}-это кернел между ith и jth векторами заданной матрицы X,если Y равно None.Если Y не None,то K_{i,j}-кернел между ith-массивом из X и jth-массивом из Y.</target>
        </trans-unit>
        <trans-unit id="1c832d0ad2e131abf1539cfeafad1048954835e4" translate="yes" xml:space="preserve">
          <source>A larger &lt;code&gt;leaf_size&lt;/code&gt; leads to a faster tree construction time, because fewer nodes need to be created</source>
          <target state="translated">&lt;code&gt;leaf_size&lt;/code&gt; больше leaf_size, тем быстрее строится дерево, так как нужно создавать меньше узлов.</target>
        </trans-unit>
        <trans-unit id="5116c45ec5d86e0d701daa6fab158df33c292bf3" translate="yes" xml:space="preserve">
          <source>A larger number of split will provide no benefits if the number of training samples is large enough. Indeed, the training time will increase. &lt;code&gt;cv&lt;/code&gt; is not used for model evaluation but for prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f498b24974153e962b445930a2302cf78d89cfc" translate="yes" xml:space="preserve">
          <source>A last major parameter is also the possibility to do predictions in bulk or one-at-a-time mode.</source>
          <target state="translated">Последним основным параметром также является возможность делать прогнозы в режиме bulk или one-at-a-time.</target>
        </trans-unit>
        <trans-unit id="b50d9ba875cfa3e1bbfa88757252d5cc5b663f5e" translate="yes" xml:space="preserve">
          <source>A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. Consider the following example where we plot the learning curve of a naive Bayes classifier and an SVM.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ca8b138a43ce55d825b3e612cada7898d228b4c" translate="yes" xml:space="preserve">
          <source>A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data. In the following plot you can see an example: naive Bayes roughly converges to a low score.</source>
          <target state="translated">Кривая обучения показывает валидацию и оценку успеваемости оценщика при различном количестве проб обучения.Это инструмент,позволяющий выяснить,какую пользу приносит добавление дополнительных данных об обучении и страдает ли оценщик в большей степени от ошибки дисперсии или ошибки перекоса.Если и результат проверки,и результат обучения сходятся в слишком низком значении с увеличением размера учебного набора,то мы не получим большой пользы от добавления большего количества учебных данных.На следующем графике вы можете видеть пример:наивный Бэйес примерно сходится с низким значением.</target>
        </trans-unit>
        <trans-unit id="2cc6d3a8d1e5bdfb3693da69e5fd147a58a0255e" translate="yes" xml:space="preserve">
          <source>A list of arguments name to ignore in the hashing</source>
          <target state="translated">Список имен аргументов,которые нужно игнорировать при хэшировании.</target>
        </trans-unit>
        <trans-unit id="977999f316fb9d6c637d2852021b1d8363940c27" translate="yes" xml:space="preserve">
          <source>A list of arrays of length &lt;code&gt;len(estimators_)&lt;/code&gt; containing the class labels for each estimator in the chain.</source>
          <target state="translated">Список массивов длины &lt;code&gt;len(estimators_)&lt;/code&gt; содержащих метки классов для каждой оценки в цепочке.</target>
        </trans-unit>
        <trans-unit id="8b21b4fe65d64da1a4d1d84446f550bb55759446" translate="yes" xml:space="preserve">
          <source>A list of class labels known to the classifier.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5eaed1c27ab8dfc53ee38efebd6c102a71098c5" translate="yes" xml:space="preserve">
          <source>A list of classes or column indices to select some (or to force inclusion of classes absent from the data)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a8fb99b6c7b15c5d0f9079fcee9eb1e89cb6ab1c" translate="yes" xml:space="preserve">
          <source>A list of clones of base_estimator.</source>
          <target state="translated">Список клонов base_estimator.</target>
        </trans-unit>
        <trans-unit id="53426e5188a28c01da334e8bfdbe7c9957c50862" translate="yes" xml:space="preserve">
          <source>A list of feature names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="371683d834fcd55b1b47a55ccdff2980b0102eb8" translate="yes" xml:space="preserve">
          <source>A list of length n_features containing the feature names (e.g., &amp;ldquo;f=ham&amp;rdquo; and &amp;ldquo;f=spam&amp;rdquo;).</source>
          <target state="translated">Список длиной n_features, содержащий имена функций (например, &amp;laquo;f = ham&amp;raquo; и &amp;laquo;f = spam&amp;raquo;).</target>
        </trans-unit>
        <trans-unit id="3e9dc6d758a5816faa5f49abd255ba444796f1a7" translate="yes" xml:space="preserve">
          <source>A list of length n_features containing the feature names. If None generic names will be used (&amp;ldquo;feature_0&amp;rdquo;, &amp;ldquo;feature_1&amp;rdquo;, &amp;hellip;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7951c01a96e3650048b499324860f7763c837156" translate="yes" xml:space="preserve">
          <source>A list of stop words.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c84a50cbe409f7bcbe9aef60e47724b3d0374c13" translate="yes" xml:space="preserve">
          <source>A logistic regression with L1 penalty yields sparse models, and can thus be used to perform feature selection, as detailed in &lt;a href=&quot;feature_selection#l1-feature-selection&quot;&gt;L1-based feature selection&lt;/a&gt;.</source>
          <target state="translated">Логистическая регрессия со штрафом L1 дает разреженные модели и, таким образом, может использоваться для выполнения выбора признаков, как подробно описано в &lt;a href=&quot;feature_selection#l1-feature-selection&quot;&gt;разделе Выбор признаков на основе L1&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2e8f6767450aa8f965fa6ba15414ee47e53d061d" translate="yes" xml:space="preserve">
          <source>A logistic regression with \(\ell_1\) penalty yields sparse models, and can thus be used to perform feature selection, as detailed in &lt;a href=&quot;feature_selection#l1-feature-selection&quot;&gt;L1-based feature selection&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed6a763f542c3b72714c079a2432308cb03a943b" translate="yes" xml:space="preserve">
          <source>A major difference is that GPR can choose the kernel&amp;rsquo;s hyperparameters based on gradient-ascent on the marginal likelihood function while KRR needs to perform a grid search on a cross-validated loss function (mean-squared error loss). A further difference is that GPR learns a generative, probabilistic model of the target function and can thus provide meaningful confidence intervals and posterior samples along with the predictions while KRR only provides predictions.</source>
          <target state="translated">Основное различие состоит в том, что GPR может выбирать гиперпараметры ядра на основе градиентного подъема на функции предельного правдоподобия, в то время как KRR должен выполнять поиск по сетке с перекрестно проверенной функцией потерь (среднеквадратичная потеря ошибки). Еще одно отличие состоит в том, что GPR изучает генеративную вероятностную модель целевой функции и, таким образом, может предоставлять значимые доверительные интервалы и апостериорные выборки вместе с прогнозами, в то время как KRR предоставляет только прогнозы.</target>
        </trans-unit>
        <trans-unit id="413fd0e2f5ff27577a8397f2320f65ec5d748528" translate="yes" xml:space="preserve">
          <source>A major motivation of this method is F1-scoring, when the positive class is in the minority.</source>
          <target state="translated">Главной мотивацией этого метода является балл F1,когда положительный класс находится в меньшинстве.</target>
        </trans-unit>
        <trans-unit id="ef86aa8565e00b57d2c91be8664b6a11d798a158" translate="yes" xml:space="preserve">
          <source>A major problem with histograms, however, is that the choice of binning can have a disproportionate effect on the resulting visualization. Consider the upper-right panel of the above figure. It shows a histogram over the same data, with the bins shifted right. The results of the two visualizations look entirely different, and might lead to different interpretations of the data.</source>
          <target state="translated">Однако основная проблема с гистограммами заключается в том,что выбор биннинга может непропорционально сильно влиять на получаемую визуализацию.Рассмотрим верхнюю правую панель вышеприведенного рисунка.Она показывает гистограмму по тем же данным,при этом бины сдвинуты вправо.Результаты двух визуализаций выглядят совершенно по-разному и могут привести к разным интерпретациям данных.</target>
        </trans-unit>
        <trans-unit id="b4945c81d17c82b3985167f2fe21eac206551aeb" translate="yes" xml:space="preserve">
          <source>A mapping of terms to feature indices.</source>
          <target state="translated">Отображение терминов по характерным индексам.</target>
        </trans-unit>
        <trans-unit id="d80b1965676bd061b195356f9e0d7d581d27bcda" translate="yes" xml:space="preserve">
          <source>A mask of the observations that have been used to compute the raw robust estimates of location and shape, before correction and re-weighting.</source>
          <target state="translated">Маска наблюдений,использовавшихся для расчета сырых робастных оценок местоположения и формы,перед корректировкой и повторным взвешиванием.</target>
        </trans-unit>
        <trans-unit id="0ec3f28dc02dc03ba22d583507907375d9c62b5f" translate="yes" xml:space="preserve">
          <source>A mask of the observations that have been used to compute the re-weighted robust location and covariance estimates.</source>
          <target state="translated">Маска наблюдений,использовавшихся для расчета повторно-взвешенных робастных оценок местоположения и ковариаций.</target>
        </trans-unit>
        <trans-unit id="adea06a15a23aac7c9d9327f52e8025add2d08fa" translate="yes" xml:space="preserve">
          <source>A mask of the observations that have been used to compute the robust estimates of location and shape.</source>
          <target state="translated">Маска наблюдений,использованных для расчета робастных оценок местоположения и формы.</target>
        </trans-unit>
        <trans-unit id="8be3be97461376c787b398256771e5f8ab1ed15d" translate="yes" xml:space="preserve">
          <source>A matrix containing only 1s ands 0s.</source>
          <target state="translated">Матрица,содержащая только 1с и 0с.</target>
        </trans-unit>
        <trans-unit id="957a75d1eeb1c72e470b64334da958786ce3e979" translate="yes" xml:space="preserve">
          <source>A matrix of shape (n_samples, n_samples) will be created from this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="259daba30c783e777c062485d929bc6df3c76ec7" translate="yes" xml:space="preserve">
          <source>A matrix of term/token counts.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="151a7f165ba08edb6c7ba1bd07841827b86e653b" translate="yes" xml:space="preserve">
          <source>A matrix such that &lt;code&gt;y_indicator[i, j] = 1&lt;/code&gt; iff &lt;code&gt;classes_[j]&lt;/code&gt; is in &lt;code&gt;y[i]&lt;/code&gt;, and 0 otherwise.</source>
          <target state="translated">Матрица такая, что &lt;code&gt;y_indicator[i, j] = 1&lt;/code&gt; если &lt;code&gt;classes_[j]&lt;/code&gt; находится в &lt;code&gt;y[i]&lt;/code&gt; , и 0 в противном случае.</target>
        </trans-unit>
        <trans-unit id="6ac1281f3fac07a890a7987a1940a19d553f0540" translate="yes" xml:space="preserve">
          <source>A model is trained using \(k-1\) of the folds as training data;</source>
          <target state="translated">Модель обучается с использованием \(k-1\)складок в качестве обучающих данных;</target>
        </trans-unit>
        <trans-unit id="ca1ea4d381438e8c7ee31dbdc82c2c3f3b443e43" translate="yes" xml:space="preserve">
          <source>A more detailed summary of the search is available at &lt;code&gt;gs_clf.cv_results_&lt;/code&gt;.</source>
          <target state="translated">Более подробная информация о поиске доступна на &lt;code&gt;gs_clf.cv_results_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="0abf01b95edac52233877bfdb4963759d68aad5b" translate="yes" xml:space="preserve">
          <source>A more sophisticated approach is to use the &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; class, which models each feature with missing values as a function of other features, and uses that estimate for imputation. It does so in an iterated round-robin fashion: at each step, a feature column is designated as output &lt;code&gt;y&lt;/code&gt; and the other feature columns are treated as inputs &lt;code&gt;X&lt;/code&gt;. A regressor is fit on &lt;code&gt;(X,
y)&lt;/code&gt; for known &lt;code&gt;y&lt;/code&gt;. Then, the regressor is used to predict the missing values of &lt;code&gt;y&lt;/code&gt;. This is done for each feature in an iterative fashion, and then is repeated for &lt;code&gt;max_iter&lt;/code&gt; imputation rounds. The results of the final imputation round are returned.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1a254f5635c860c720fd64108216f6d8c4b1064" translate="yes" xml:space="preserve">
          <source>A more traditional (and possibly better) way to predict on a sparse subset of input features would be to use univariate feature selection followed by a traditional (l2-penalised) logistic regression model.</source>
          <target state="translated">Более традиционным (и,возможно,лучшим)способом предсказания на разрозненном подмножестве входных признаков было бы использование одномерного выбора признаков,за которым следовала бы традиционная (l2-пенализированная)логистическая регрессионная модель.</target>
        </trans-unit>
        <trans-unit id="fc3b3b1809b0fddd0d084276f73f16c23ecf93ac" translate="yes" xml:space="preserve">
          <source>A multi-label model that arranges binary classifiers into a chain.</source>
          <target state="translated">Модель с несколькими этикетками,которая объединяет бинарные классификаторы в цепочку.</target>
        </trans-unit>
        <trans-unit id="07157eeb8d3c41fd6ae5f1ce4e96d98c52fa44ce" translate="yes" xml:space="preserve">
          <source>A multi-label model that arranges regressions into a chain.</source>
          <target state="translated">Мульти-маркировочная модель,которая организует регрессии в цепочку.</target>
        </trans-unit>
        <trans-unit id="9e05b7bdec595d3e973dea3540db250a47de0ecd" translate="yes" xml:space="preserve">
          <source>A multi-output problem is a supervised learning problem with several outputs to predict, that is when Y is a 2d array of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt;.</source>
          <target state="translated">Задача с несколькими выходами - это проблема контролируемого обучения с несколькими выходами для прогнозирования, то есть когда Y является 2- &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; массивом размера [n_samples, n_outputs] .</target>
        </trans-unit>
        <trans-unit id="0d0f038bfe45a99c12fb61542c6de1b37df0ed3c" translate="yes" xml:space="preserve">
          <source>A new plotting API is available for creating visualizations. This new API allows for quickly adjusting the visuals of a plot without involving any recomputation. It is also possible to add different plots to the same figure. The following example illustrates &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;plot_roc_curve&lt;/code&gt;&lt;/a&gt;, but other plots utilities are supported like &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_confusion_matrix#sklearn.metrics.plot_confusion_matrix&quot;&gt;&lt;code&gt;plot_confusion_matrix&lt;/code&gt;&lt;/a&gt;. Read more about this new API in the &lt;a href=&quot;https://scikit-learn.org/0.23/visualizations.html#visualizations&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df611f66ef7be3083c893378a9603e78fdf46201" translate="yes" xml:space="preserve">
          <source>A new sample is inserted into the root of the CF Tree which is a CF Node. It is then merged with the subcluster of the root, that has the smallest radius after merging, constrained by the threshold and branching factor conditions. If the subcluster has any child node, then this is done repeatedly till it reaches a leaf. After finding the nearest subcluster in the leaf, the properties of this subcluster and the parent subclusters are recursively updated.</source>
          <target state="translated">В корень дерева CF вставляется новый образец,который является узлом CF.Затем он сливается с подкластером корня,имеющего наименьший радиус после слияния,ограниченный пороговыми условиями и условиями коэффициента ветвления.Если в подкластере есть дочерний узел,то это делается несколько раз до тех пор,пока он не достигнет листа.После нахождения ближайшего подкластера в листе свойства этого подкластера и родительских подкластеров обновляются рекурсивно.</target>
        </trans-unit>
        <trans-unit id="06b4df58df49d31652c1e508653814db2c7c4b45" translate="yes" xml:space="preserve">
          <source>A node will be split if this split induces a decrease of the impurity greater than or equal to this value.</source>
          <target state="translated">Узел будет разделен,если это разделение вызовет уменьшение примеси больше или равно этому значению.</target>
        </trans-unit>
        <trans-unit id="f2f0f4cbbbaee87b8b7904e37994705d9bd8774b" translate="yes" xml:space="preserve">
          <source>A noise-free case</source>
          <target state="translated">Безшумный случай</target>
        </trans-unit>
        <trans-unit id="a9448dea0ed4384de356358aa919a44c7d032339" translate="yes" xml:space="preserve">
          <source>A noisy case with known noise-level per datapoint</source>
          <target state="translated">Шумный случай с известным уровнем шума в каждой точке данных.</target>
        </trans-unit>
        <trans-unit id="b96ec23e53414db9b11937cf799cd6c1f6432a32" translate="yes" xml:space="preserve">
          <source>A non-negative floating point value (the best value is 0.0), or an array of floating point values, one for each individual target.</source>
          <target state="translated">Отрицательное значение с плавающей точкой (лучшее значение 0,0),или массив значений с плавающей точкой,по одному для каждой отдельной цели.</target>
        </trans-unit>
        <trans-unit id="2ced62a814e481bd22a6aa7667bcac7ac64675cc" translate="yes" xml:space="preserve">
          <source>A non-negative floating point value (the best value is 0.0).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ef179d616825b29b180ecdb28f9b1e0bfb64faf" translate="yes" xml:space="preserve">
          <source>A non-parametric supervised learning method used for classification. Creates a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9c1cbeaf3f9c4d5469e9c590dbc955ea1a377cb" translate="yes" xml:space="preserve">
          <source>A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. In theory, &lt;code&gt;log2(n_classes) / n_classes&lt;/code&gt; is sufficient to represent each class unambiguously. However, in practice, it may not lead to good accuracy since &lt;code&gt;log2(n_classes)&lt;/code&gt; is much smaller than n_classes.</source>
          <target state="translated">Число от 0 до 1 потребует меньше классификаторов, чем один против остальных. Теоретически &lt;code&gt;log2(n_classes) / n_classes&lt;/code&gt; достаточно для однозначного представления каждого класса. Однако на практике это может не привести к хорошей точности, поскольку &lt;code&gt;log2(n_classes)&lt;/code&gt; намного меньше, чем n_classes.</target>
        </trans-unit>
        <trans-unit id="75b2970d65b634b9e917fd730d5f1ac86be5fb84" translate="yes" xml:space="preserve">
          <source>A number greater than 1 will require more classifiers than one-vs-the-rest. In this case, some classifiers will in theory correct for the mistakes made by other classifiers, hence the name &amp;ldquo;error-correcting&amp;rdquo;. In practice, however, this may not happen as classifier mistakes will typically be correlated. The error-correcting output codes have a similar effect to bagging.</source>
          <target state="translated">Число больше 1 потребует больше классификаторов, чем один против остальных. В этом случае некоторые классификаторы теоретически исправят ошибки, допущенные другими классификаторами, отсюда и название &amp;laquo;исправляющие ошибки&amp;raquo;. Однако на практике этого может не произойти, поскольку ошибки классификатора обычно коррелируют. Коды вывода с исправлением ошибок имеют тот же эффект, что и упаковка.</target>
        </trans-unit>
        <trans-unit id="303cdccb0a0b9ef8ee02f659c78579cbfb972892" translate="yes" xml:space="preserve">
          <source>A object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a &lt;code&gt;score&lt;/code&gt; function, or &lt;code&gt;scoring&lt;/code&gt; must be passed.</source>
          <target state="translated">Для каждой точки сетки создается экземпляр этого типа. Предполагается, что это реализует интерфейс оценщика scikit-learn. Либо оценщик должен обеспечить &lt;code&gt;score&lt;/code&gt; функцию, или &lt;code&gt;scoring&lt;/code&gt; должен быть принят.</target>
        </trans-unit>
        <trans-unit id="56be8330a991d6aa887f39d43a91aa1ac6760e20" translate="yes" xml:space="preserve">
          <source>A one-dimensional array of distances</source>
          <target state="translated">Одномерный массив расстояний</target>
        </trans-unit>
        <trans-unit id="77da2f75f17e6ea0f8d3b4beab5a8c65d7801934" translate="yes" xml:space="preserve">
          <source>A paragraph describing the characteristic of the dataset: its source, reference, etc.</source>
          <target state="translated">Пункт,описывающий характеристику набора данных:его источник,ссылка и т.д.</target>
        </trans-unit>
        <trans-unit id="8831c41b4fb10cdce1530c46ecbd5c89f650c66c" translate="yes" xml:space="preserve">
          <source>A parameter can be given to allow K-means to be run in parallel, called &lt;code&gt;n_jobs&lt;/code&gt;. Giving this parameter a positive value uses that many processors (default: 1). A value of -1 uses all available processors, with -2 using one less, and so on. Parallelization generally speeds up computation at the cost of memory (in this case, multiple copies of centroids need to be stored, one for each job).</source>
          <target state="translated">Может быть задан параметр, позволяющий K-means работать параллельно, называется &lt;code&gt;n_jobs&lt;/code&gt; . При присвоении этому параметру положительного значения используется такое же количество процессоров (по умолчанию: 1). Значение -1 использует все доступные процессоры, -2 - на один меньше, и так далее. Распараллеливание обычно ускоряет вычисления за счет памяти (в этом случае необходимо хранить несколько копий центроидов, по одной для каждого задания).</target>
        </trans-unit>
        <trans-unit id="c76c7128eb10e519c4cde4416a2b5ebd1e864530" translate="yes" xml:space="preserve">
          <source>A plot that compares the various Beta-divergence loss functions supported by the Multiplicative-Update (&amp;lsquo;mu&amp;rsquo;) solver in &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">График, который сравнивает различные функции потерь бета-расхождения, поддерживаемые решателем Multiplicative-Update ('mu') в &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c428b2107a14d30575de38f7fc951c176630f469" translate="yes" xml:space="preserve">
          <source>A plot that compares the various convex loss functions supported by &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; .</source>
          <target state="translated">График, сравнивающий различные функции выпуклых потерь, поддерживаемые &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="9c371e4431820ea4253b6da8f883638e2996e440" translate="yes" xml:space="preserve">
          <source>A plot will appear showing the top 5 most uncertain digits for each iteration of training. These may or may not contain mistakes, but we will train the next model with their true labels.</source>
          <target state="translated">Появится сюжет,показывающий 5 самых неопределенных цифр для каждой итерации тренировки.Они могут содержать или не содержать ошибок,но мы будем тренировать следующую модель с их истинными метками.</target>
        </trans-unit>
        <trans-unit id="d0a927be776ddcc1a3b0a115e5ff9bf99815db03" translate="yes" xml:space="preserve">
          <source>A positive floating point value (the best value is 0.0).</source>
          <target state="translated">Положительное значение с плавающей запятой (лучшее значение-0,0).</target>
        </trans-unit>
        <trans-unit id="2e47d08f91be7ad2360165e81b098e1d32db277c" translate="yes" xml:space="preserve">
          <source>A positive monotonic constraint is a constraint of the form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9fa1e2038dd5a4a82d42f5d5bcbe0df63da34a6c" translate="yes" xml:space="preserve">
          <source>A practical advantage of trading-off between Lasso and Ridge is it allows Elastic-Net to inherit some of Ridge&amp;rsquo;s stability under rotation.</source>
          <target state="translated">Практическое преимущество компромисса между Lasso и Ridge заключается в том, что он позволяет Elastic-Net унаследовать часть устойчивости Ridge при вращении.</target>
        </trans-unit>
        <trans-unit id="fd73c2da7375a102550eb9b6f798b301111f7f0e" translate="yes" xml:space="preserve">
          <source>A practical advantage of trading-off between Lasso and Ridge is that it allows Elastic-Net to inherit some of Ridge&amp;rsquo;s stability under rotation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0644879ffb5a73e0cac4122d0a74647c32667b9b" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator object or a seed for it if int. If &lt;code&gt;init='random'&lt;/code&gt;, &lt;code&gt;random_state&lt;/code&gt; is used to initialize the random transformation. If &lt;code&gt;init='pca'&lt;/code&gt;, &lt;code&gt;random_state&lt;/code&gt; is passed as an argument to PCA when initializing the transformation. Pass an int for reproducible results across multiple function calls. See :term: &lt;code&gt;Glossary &amp;lt;random_state&amp;gt;&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4370bf36aea658b96c83523c6e4601f6e89a2b33" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator used for the initialization of the lobpcg eigen vectors decomposition when &lt;code&gt;eigen_solver='amg'&lt;/code&gt; and by the K-Means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5ce137982e9454ec15b3a9266e29af4a861559f3" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator used for the initialization of the lobpcg eigen vectors decomposition when eigen_solver == &amp;lsquo;amg&amp;rsquo; and by the K-Means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">Генератор псевдослучайных чисел, используемый для инициализации разложения собственных векторов lobpcg, когда eigen_solver == 'amg' и при инициализации K-средних. Используйте int, чтобы сделать случайность детерминированной. См. &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Глоссарий&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4da70ee0892b2024f8c0c33c157ae6f4ed05fab9" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator used for the initialization of the lobpcg eigen vectors decomposition when eigen_solver == &amp;lsquo;amg&amp;rsquo; and by the K-Means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c41ce7b7d007fb54c5cb75f35d5c711d3e908a9" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator used for the initialization of the lobpcg eigenvectors decomposition. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;amg&amp;rsquo;.</source>
          <target state="translated">Генератор псевдослучайных чисел, используемый для инициализации разложения собственных векторов lobpcg. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;solver&lt;/code&gt; == 'amg'.</target>
        </trans-unit>
        <trans-unit id="8d91d68f1ffad3cd242144da0cec28854cf478b1" translate="yes" xml:space="preserve">
          <source>A pseudo random number generator used for the initialization of the lobpcg eigenvectors. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;amg&amp;rsquo;.</source>
          <target state="translated">Генератор псевдослучайных чисел, используемый для инициализации собственных векторов lobpcg. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; . Используется, когда &lt;code&gt;solver&lt;/code&gt; == 'amg'.</target>
        </trans-unit>
        <trans-unit id="ee2bf152e538d224d6fde70d9b0dd7a1cdbb5755" translate="yes" xml:space="preserve">
          <source>A random forest classifier.</source>
          <target state="translated">Случайный лесной классификатор.</target>
        </trans-unit>
        <trans-unit id="e60aacdcc2887bf4d3963c64796dccc1910a3c9c" translate="yes" xml:space="preserve">
          <source>A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if &lt;code&gt;bootstrap=True&lt;/code&gt; (default).</source>
          <target state="translated">Случайный лес - это метаоценка, которая соответствует ряду классификационных деревьев решений для различных подвыборок набора данных и использует усреднение для повышения точности прогнозирования и контроля избыточной подгонки. Размер подвыборки всегда совпадает с размером исходной входной выборки, но выборки рисуются с заменой, если &lt;code&gt;bootstrap=True&lt;/code&gt; (по умолчанию).</target>
        </trans-unit>
        <trans-unit id="6d7fe13f3eb79eb708ba336fe6e8fed09167f0c0" translate="yes" xml:space="preserve">
          <source>A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the &lt;code&gt;max_samples&lt;/code&gt; parameter if &lt;code&gt;bootstrap=True&lt;/code&gt; (default), otherwise the whole dataset is used to build each tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6afddbc046b0606e01c6a10f7c579e615a468bc2" translate="yes" xml:space="preserve">
          <source>A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if &lt;code&gt;bootstrap=True&lt;/code&gt; (default).</source>
          <target state="translated">Случайный лес - это метаоценка, которая соответствует ряду классификаторов дерева решений для различных подвыборок набора данных и использует усреднение для повышения точности прогнозирования и контроля чрезмерной подгонки. Размер подвыборки всегда совпадает с размером исходной входной выборки, но выборки рисуются с заменой, если &lt;code&gt;bootstrap=True&lt;/code&gt; (по умолчанию).</target>
        </trans-unit>
        <trans-unit id="8049315f314116153326eb819ff277cc1b244e8c" translate="yes" xml:space="preserve">
          <source>A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the &lt;code&gt;max_samples&lt;/code&gt; parameter if &lt;code&gt;bootstrap=True&lt;/code&gt; (default), otherwise the whole dataset is used to build each tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c30f02c56b168ad378f278a145ee7ca666d2b4b" translate="yes" xml:space="preserve">
          <source>A random forest regressor.</source>
          <target state="translated">Случайный лесной регрессор.</target>
        </trans-unit>
        <trans-unit id="517674d6fed45c030e35daafc36d33d7e1cb17fe" translate="yes" xml:space="preserve">
          <source>A random number generator instance to define the state of the random permutations generator. If an integer is given, it fixes the seed. Defaults to the global numpy random number generator.</source>
          <target state="translated">Экземпляр генератора случайных чисел для определения состояния генератора случайных перестановок.Если задано целое число,он исправляет посылку.По умолчанию задает глобальный генератор случайных чисел.</target>
        </trans-unit>
        <trans-unit id="ad42d75eb3232815220e50c42e13b1c5a583a979" translate="yes" xml:space="preserve">
          <source>A random number generator instance to define the state of the random permutations generator. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">Экземпляр генератора случайных чисел для определения состояния генератора случайных перестановок. Если int, random_state - это начальное число, используемое генератором случайных чисел; Если экземпляр RandomState, random_state является генератором случайных чисел; Если None, генератор случайных чисел - это экземпляр RandomState, используемый &lt;code&gt;np.random&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="282455615e66e12f3be6646a3e4853abf573194f" translate="yes" xml:space="preserve">
          <source>A random number generator instance to define the state of the random permutations generator. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3de0a58d62c3c2bcc234bd4e43f83d387ef4775e" translate="yes" xml:space="preserve">
          <source>A random order for each round.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4166975533e11bd5bc32126880dea04c49362bfe" translate="yes" xml:space="preserve">
          <source>A randomized algorithm for the decomposition of matrices Per-Gunnar Martinsson, Vladimir Rokhlin and Mark Tygert</source>
          <target state="translated">Рандомизированный алгоритм разложения матриц Пер-Гуннара Мартинсона,Владимира Рохлина и Марка Тигерта</target>
        </trans-unit>
        <trans-unit id="1bef857d80e5f022acdf94565f064371e78877b1" translate="yes" xml:space="preserve">
          <source>A recursive feature elimination example showing the relevance of pixels in a digit classification task.</source>
          <target state="translated">Пример устранения рекурсивного признака,показывающий релевантность пикселей в задаче классификации цифр.</target>
        </trans-unit>
        <trans-unit id="59abf2d80f7d73a7cc0db592c8bcede424657b87" translate="yes" xml:space="preserve">
          <source>A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation.</source>
          <target state="translated">Пример устранения рекурсивных функций с автоматической настройкой количества функций,выбранных с перекрестной проверкой.</target>
        </trans-unit>
        <trans-unit id="dcc2f34db796875ac21f4e9f9639246afd97a032" translate="yes" xml:space="preserve">
          <source>A reference (and not a copy) of the first argument in the &lt;code&gt;fit()&lt;/code&gt; method is stored for future reference. If that array changes between the use of &lt;code&gt;fit()&lt;/code&gt; and &lt;code&gt;predict()&lt;/code&gt; you will have unexpected results.</source>
          <target state="translated">Ссылка (а не копия) первого аргумента в методе &lt;code&gt;fit()&lt;/code&gt; сохраняется для использования в будущем. Если этот массив изменится между использованием &lt;code&gt;fit()&lt;/code&gt; и &lt;code&gt;predict()&lt;/code&gt; вы получите неожиданные результаты.</target>
        </trans-unit>
        <trans-unit id="d5fde252cc168f1a7ffd9faadab134fe0513cbda" translate="yes" xml:space="preserve">
          <source>A regressor which will be used to combine the base estimators. The default regressor is a &lt;code&gt;RidgeCV&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b815536c2d161fd6acf2bcd856fde57736561c74" translate="yes" xml:space="preserve">
          <source>A representation of the full diabetes dataset would involve 11 dimensions (10 feature dimensions and one of the target variable). It is hard to develop an intuition on such representation, but it may be useful to keep in mind that it would be a fairly &lt;em&gt;empty&lt;/em&gt; space.</source>
          <target state="translated">Представление полного набора данных о диабете будет включать 11 измерений (10 измерений характеристик и одну из целевой переменной). Трудно развить интуицию в отношении такого представления, но может быть полезно иметь в виду, что это будет довольно &lt;em&gt;пустое&lt;/em&gt; место.</target>
        </trans-unit>
        <trans-unit id="fb7d808e9a808e07d251ec0ab6593856a70a9b8b" translate="yes" xml:space="preserve">
          <source>A scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;.</source>
          <target state="translated">Вызываемый объект / функция счетчика с сигнатурой &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cd458b3d90a800480ecc75cb9b07374a934f767b" translate="yes" xml:space="preserve">
          <source>A search consists of:</source>
          <target state="translated">Поиск состоит из..:</target>
        </trans-unit>
        <trans-unit id="4faa007b7ff82792cbf9f6b91017a8816af3cc88" translate="yes" xml:space="preserve">
          <source>A second feature array only if X has shape [n_samples_a, n_features].</source>
          <target state="translated">Второй массив признаков только в том случае,если X имеет форму [n_samples_a,n_features].</target>
        </trans-unit>
        <trans-unit id="b3743bb79cbeb6292d7788299c27fa0302da1677" translate="yes" xml:space="preserve">
          <source>A selection of dtypes to exclude. For more details, see &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes&quot;&gt;&lt;code&gt;pandas.DataFrame.select_dtypes&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ed7392ea2bcc5742fc5a21d5c3ccda544426c7d" translate="yes" xml:space="preserve">
          <source>A selection of dtypes to include. For more details, see &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes&quot;&gt;&lt;code&gt;pandas.DataFrame.select_dtypes&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee9834606bdd77c4a06472befa3674177dd91a7e" translate="yes" xml:space="preserve">
          <source>A seq of Axis objects, one for each subplot.</source>
          <target state="translated">Посек объектов Оси,по одному на каждый подгрупп.</target>
        </trans-unit>
        <trans-unit id="09a68a5ad2629329af5cff530eb7ba2ddf7ad320" translate="yes" xml:space="preserve">
          <source>A sequence of dicts signifies a sequence of grids to search, and is useful to avoid exploring parameter combinations that make no sense or have no effect. See the examples below.</source>
          <target state="translated">Последовательность знаков обозначает последовательность сеток для поиска и полезна,чтобы избежать изучения комбинаций параметров,которые не имеют смысла или эффекта.См.примеры ниже.</target>
        </trans-unit>
        <trans-unit id="5ad6cb6da544247e185919510fbbf9bbac2dfc37" translate="yes" xml:space="preserve">
          <source>A set of labels (any orderable and hashable object) for each sample. If the &lt;code&gt;classes&lt;/code&gt; parameter is set, &lt;code&gt;y&lt;/code&gt; will not be iterated.</source>
          <target state="translated">Набор меток (любой упорядочиваемый и хешируемый объект) для каждого образца. Если параметр &lt;code&gt;classes&lt;/code&gt; установлен, &lt;code&gt;y&lt;/code&gt; не будет повторяться.</target>
        </trans-unit>
        <trans-unit id="7b19a5a4863d81ac862d0e9be41e4683721f5dd5" translate="yes" xml:space="preserve">
          <source>A similar clustering at multiple values of eps. Our implementation is optimized for memory usage.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb593a41404fe5b14fb797c942b194b27f9badb7" translate="yes" xml:space="preserve">
          <source>A similar clustering for a specified neighborhood radius (eps). Our implementation is optimized for runtime.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="134a4703b97e34542f6c5ec20a8b6025ee87dd8f" translate="yes" xml:space="preserve">
          <source>A simple choice to construct \(R_ij\) so that it is nonnegative and symmetric is:</source>
          <target state="translated">Простой выбор,чтобы построить \(R_ij\)так,чтобы он был неотрицательным и симметричным:</target>
        </trans-unit>
        <trans-unit id="11b768780ec203929a5802877f9f67a2310663fd" translate="yes" xml:space="preserve">
          <source>A simple example shipped with scikit-learn: iris dataset</source>
          <target state="translated">Простой пример,поставляемый с набором данных scikit-learn:набор данных радужной оболочки глаза</target>
        </trans-unit>
        <trans-unit id="8e839688e01ba01e9dfe145feb09335f1aa963d0" translate="yes" xml:space="preserve">
          <source>A simple example:</source>
          <target state="translated">Простой пример:</target>
        </trans-unit>
        <trans-unit id="2a7be91a45219aa7eb5e6e5584cdc7ab00269326" translate="yes" xml:space="preserve">
          <source>A simple graphical frontend for Libsvm mainly intended for didactic purposes. You can create data points by point and click and visualize the decision region induced by different kernels and parameter settings.</source>
          <target state="translated">Простой графический фронтенд для Libsvm,предназначенный в основном для дидактических целей.Вы можете создавать точки данных по пунктам,нажимать на них и визуализировать область принятия решения,вызванную различными ядрами и параметрами.</target>
        </trans-unit>
        <trans-unit id="08a70c5b3e130b5b3a3556a3a9d846d499b809af" translate="yes" xml:space="preserve">
          <source>A simple linear generative model with Gaussian latent variables.</source>
          <target state="translated">Простая линейная генеративная модель с гауссовыми латентными переменными.</target>
        </trans-unit>
        <trans-unit id="7ed72a91acd5901b2715fbe7249ca1b4b882cab1" translate="yes" xml:space="preserve">
          <source>A simple one-dimensional regression example computed in two different ways:</source>
          <target state="translated">Простой одномерный пример регрессии,вычисленный двумя разными способами:</target>
        </trans-unit>
        <trans-unit id="d0a2166f9acbabe38964ccee31d9e7127ebb3bd0" translate="yes" xml:space="preserve">
          <source>A simple toy dataset to visualize clustering and classification algorithms.</source>
          <target state="translated">Простой набор данных игрушек для визуализации алгоритмов кластеризации и классификации.</target>
        </trans-unit>
        <trans-unit id="47127c0ac17be6b42bd52820b6c53e975ec33072" translate="yes" xml:space="preserve">
          <source>A simple toy dataset to visualize clustering and classification algorithms. Read more in the &lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">Простой набор данных игрушек для визуализации алгоритмов кластеризации и классификации. Подробнее читайте в &lt;a href=&quot;../../datasets/index#sample-generators&quot;&gt;Руководстве пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0963c917bb15b907590115ef7d8ee882d54970b8" translate="yes" xml:space="preserve">
          <source>A single str (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;) to evaluate the predictions on the test set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc426ce246dcb8426ecbbb6a60a4ff7a07e84ce" translate="yes" xml:space="preserve">
          <source>A single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;) to evaluate the predictions on the test set.</source>
          <target state="translated">Одна строка (см. &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;Параметр оценки: определение правил оценки модели&lt;/a&gt; ) или вызываемый объект (см. &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Определение стратегии&lt;/a&gt; оценки на основе метрических функций ) для оценки прогнозов по набору тестов.</target>
        </trans-unit>
        <trans-unit id="2e53707c3f177aad6668f2e995ecf10221437949" translate="yes" xml:space="preserve">
          <source>A small value of &lt;code&gt;C&lt;/code&gt; includes more/all the observations, allowing the margins to be calculated using all the data in the area.</source>
          <target state="translated">Небольшое значение &lt;code&gt;C&lt;/code&gt; включает больше / все наблюдения, что позволяет рассчитать поля с использованием всех данных в области.</target>
        </trans-unit>
        <trans-unit id="e33601e97cbb479e0128e302bee052e1e2030a89" translate="yes" xml:space="preserve">
          <source>A solution in high-dimensional statistical learning is to &lt;em&gt;shrink&lt;/em&gt; the regression coefficients to zero: any two randomly chosen set of observations are likely to be uncorrelated. This is called &lt;a href=&quot;../../modules/generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; regression:</source>
          <target state="translated">Решение в многомерном статистическом обучении состоит в том, чтобы &lt;em&gt;уменьшить&lt;/em&gt; коэффициенты регрессии до нуля: любые два случайно выбранных набора наблюдений, вероятно, не будут коррелированы. Это называется регрессией &lt;a href=&quot;../../modules/generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; :</target>
        </trans-unit>
        <trans-unit id="dcd1f54984c6dffbbcff2667b694f4185f6ec040" translate="yes" xml:space="preserve">
          <source>A solution to this problem is a procedure called &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-validation_(statistics)&quot;&gt;cross-validation&lt;/a&gt; (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called &lt;em&gt;k&lt;/em&gt;-fold CV, the training set is split into &lt;em&gt;k&lt;/em&gt; smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the &lt;em&gt;k&lt;/em&gt; &amp;ldquo;folds&amp;rdquo;:</source>
          <target state="translated">Решением этой проблемы является процедура &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-validation_(statistics)&quot;&gt;перекрестной проверки&lt;/a&gt; (сокращенно CV). Набор тестов все еще должен быть предоставлен для окончательной оценки, но набор для проверки больше не нужен при выполнении CV. В базовом подходе, называемом &lt;em&gt;k-&lt;/em&gt; кратным CV, обучающий набор разбивается на &lt;em&gt;k&lt;/em&gt; меньших наборов (другие подходы описаны ниже, но обычно следуют тем же принципам). Для каждой из &lt;em&gt;k&lt;/em&gt; &amp;laquo;складок&amp;raquo; выполняется следующая процедура :</target>
        </trans-unit>
        <trans-unit id="538e1506057d7a3220a186af08ab5489676c59df" translate="yes" xml:space="preserve">
          <source>A sparse radius neighborhood graph (where missing entries are presumed to be out of eps) can be precomputed in a memory-efficient way and dbscan can be run over this with &lt;code&gt;metric='precomputed'&lt;/code&gt;. See &lt;a href=&quot;generated/sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">График окрестностей с разреженным радиусом (где предполагается, что отсутствующие записи находятся за пределами eps) может быть предварительно вычислен с эффективным использованием памяти, и dbscan может быть запущен по нему с помощью &lt;code&gt;metric='precomputed'&lt;/code&gt; . См. &lt;a href=&quot;generated/sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5434739c8a85282e43e6d41eec6550c57895597f" translate="yes" xml:space="preserve">
          <source>A star marks the expected sample for each class; its size reflects the probability of selecting that class label.</source>
          <target state="translated">Звездочка отмечает ожидаемую выборку для каждого класса;ее размер отражает вероятность выбора этой метки класса.</target>
        </trans-unit>
        <trans-unit id="a226eb090c390674deacec5886c6aefd3ca76b60" translate="yes" xml:space="preserve">
          <source>A str (see model evaluation documentation) or a scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt; which should return only a single value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7313aa5f13cd15f69aa6d50563adc57324fb0eb6" translate="yes" xml:space="preserve">
          <source>A str (see model evaluation documentation) or a scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d85d389496ba61c19ce84f015d0fceafa4c84844" translate="yes" xml:space="preserve">
          <source>A str, giving an expression as a function of n_jobs, as in &amp;lsquo;2*n_jobs&amp;rsquo;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31ecf6c64ee79cd0b8c2879dbc516ad7450905ee" translate="yes" xml:space="preserve">
          <source>A strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cc68f40152c74e41efd28d7122ce96e71e57739" translate="yes" xml:space="preserve">
          <source>A strategy to implement out-of-core scaling is to stream data to the estimator in mini-batches. Each mini-batch is vectorized using &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; so as to guarantee that the input space of the estimator has always the same dimensionality. The amount of memory used at any time is thus bounded by the size of a mini-batch. Although there is no limit to the amount of data that can be ingested using such an approach, from a practical point of view the learning time is often limited by the CPU time one wants to spend on the task.</source>
          <target state="translated">Стратегия реализации масштабирования вне ядра заключается в потоковой передаче данных в оценщик минипакетами. Каждый мини-пакет векторизуется с помощью &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; ,&lt;/a&gt; чтобы гарантировать, что входное пространство оценщика всегда имеет одинаковую размерность. Таким образом, объем памяти, используемый в любой момент времени, ограничен размером мини-пакета. Хотя нет ограничений на количество данных, которые могут быть получены с использованием такого подхода, с практической точки зрения время обучения часто ограничивается временем процессора, которое нужно потратить на задачу.</target>
        </trans-unit>
        <trans-unit id="7c0e35a146ea0efee84f42e6ee454306c5da4827" translate="yes" xml:space="preserve">
          <source>A string (see model evaluation documentation) or a scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;.</source>
          <target state="translated">Строка (см. Документацию по оценке модели) или вызываемый объект / функция счетчика с сигнатурой &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fad6fe3853f8abecb73cc5e995f9131ee653eef0" translate="yes" xml:space="preserve">
          <source>A string (see model evaluation documentation) or a scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;. For a list of scoring functions that can be used, look at &lt;a href=&quot;../classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt;. The default scoring option used is &amp;lsquo;accuracy&amp;rsquo;.</source>
          <target state="translated">Строка (см. Документацию по оценке модели) или вызываемый объект / функция счетчика с сигнатурой &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt; . Список функций оценки, которые можно использовать, &lt;a href=&quot;../classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; &lt;/a&gt; . На sklearn.metrics . Используемая по умолчанию опция оценки - &amp;laquo;точность&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="1963bcb955646804f10ec7ad2d71cbad666ea477" translate="yes" xml:space="preserve">
          <source>A string (see model evaluation documentation) or a scorer callable object / function with signature &lt;code&gt;scorer(estimator, X, y)&lt;/code&gt;. If None, the negative mean squared error if cv is &amp;lsquo;auto&amp;rsquo; or None (i.e. when using generalized cross-validation), and r2 score otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e94d51ba3f9b9473065d98a0a11ca48ef9ac3a04" translate="yes" xml:space="preserve">
          <source>A string of unicode symbols.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93b243cc3849b7302c5dad12c7987dfe501650ad" translate="yes" xml:space="preserve">
          <source>A string, giving an expression as a function of n_jobs, as in &amp;lsquo;2*n_jobs&amp;rsquo;</source>
          <target state="translated">Строка, дающая выражение как функцию от n_jobs, как в '2 * n_jobs'</target>
        </trans-unit>
        <trans-unit id="82f0cd7ca226a86963abc9437ca213dfd9c32ccc" translate="yes" xml:space="preserve">
          <source>A sub-pipeline can also be extracted using the slicing notation commonly used for Python Sequences such as lists or strings (although only a step of 1 is permitted). This is convenient for performing only some of the transformations (or their inverse):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="84dd7b04896fc19b0373bd22f46ebced4bcbae51" translate="yes" xml:space="preserve">
          <source>A supervised learning estimator with a &lt;code&gt;fit&lt;/code&gt; method that provides information about feature importance either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute.</source>
          <target state="translated">&lt;code&gt;coef_&lt;/code&gt; контролируемого обучения с методом &lt;code&gt;fit&lt;/code&gt; который предоставляет информацию о важности функции либо через атрибут coef_, либо через атрибут &lt;code&gt;feature_importances_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="be778589a42569621d412c8d143e2c4ecab0280f" translate="yes" xml:space="preserve">
          <source>A support vector machine constructs a hyper-plane or set of hyper-planes in a high or infinite dimensional space, which can be used for classification, regression or other tasks. Intuitively, a good separation is achieved by the hyper-plane that has the largest distance to the nearest training data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier.</source>
          <target state="translated">Опорная векторная машина создает гиперплоскость или набор гиперплоскостей в высоком или бесконечном размерном пространстве,которые могут быть использованы для классификации,регрессии или других задач.Интуитивно хорошее разделение достигается с помощью гиперплоскости,которая имеет наибольшее расстояние до ближайших точек тренировочных данных любого класса (так называемое функциональное поле),так как в общем случае чем больше поле,тем ниже ошибка обобщения классификатора.</target>
        </trans-unit>
        <trans-unit id="b0f8a884660f9ed7117b59341660ac6dff079372" translate="yes" xml:space="preserve">
          <source>A support vector machine constructs a hyper-plane or set of hyper-planes in a high or infinite dimensional space, which can be used for classification, regression or other tasks. Intuitively, a good separation is achieved by the hyper-plane that has the largest distance to the nearest training data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier. The figure below shows the decision function for a linearly separable problem, with three samples on the margin boundaries, called &amp;ldquo;support vectors&amp;rdquo;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a7e8b3dcde624d3d8f97ed6de9c3edf28cc3212" translate="yes" xml:space="preserve">
          <source>A synthetic random regression problem is generated. The targets &lt;code&gt;y&lt;/code&gt; are modified by: (i) translating all targets such that all entries are non-negative and (ii) applying an exponential function to obtain non-linear targets which cannot be fitted using a simple linear model.</source>
          <target state="translated">Генерируется синтетическая задача случайной регрессии. Цели &lt;code&gt;y&lt;/code&gt; модифицируются: (i) преобразованием всех целей так, чтобы все записи были неотрицательными, и (ii) применением экспоненциальной функции для получения нелинейных целей, которые нельзя подобрать с помощью простой линейной модели.</target>
        </trans-unit>
        <trans-unit id="0903abbf1faeca209d35b8701b7569a1792a87c6" translate="yes" xml:space="preserve">
          <source>A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly.</source>
          <target state="translated">Система с высокой отзывчивостью,но низкой точностью дает много результатов,но большинство ее предсказанных этикеток неверны по сравнению с учебными этикетками.Система с высокой точностью,но низкой точностью отзыва,возвращает очень мало результатов,но большинство ее предсказанных этикеток являются правильными по сравнению с учебными этикетками.Идеальная система с высокой точностью и высокой отзывностью вернет много результатов,при этом все результаты будут помечены правильно.</target>
        </trans-unit>
        <trans-unit id="173f587454933c3828450ea8ca8b53629bab1434" translate="yes" xml:space="preserve">
          <source>A thin wrapper around the functionality of the kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">Тонкая обёртка вокруг функциональности ядер в sklearn.metrics.pairwise.</target>
        </trans-unit>
        <trans-unit id="66676f8254f2529112cd062a4d4d85367f781237" translate="yes" xml:space="preserve">
          <source>A trivial solution to this problem is to set all the points on the origin. In order to avoid that, the disparities \(\hat{d}_{ij}\) are normalized.</source>
          <target state="translated">Тривиальным решением этой задачи является установка всех точек на начало координат.Чтобы избежать этого,нормализуются диспропорции \(\hat{d}_{ij}\).</target>
        </trans-unit>
        <trans-unit id="92110b9d440ed0f7743804ea18583b68d039b315" translate="yes" xml:space="preserve">
          <source>A tutorial exercise for using different SVM kernels.</source>
          <target state="translated">Учебное упражнение по использованию различных ядер SVM.</target>
        </trans-unit>
        <trans-unit id="b027711ce35320d3d1f8472a3216da00739d6438" translate="yes" xml:space="preserve">
          <source>A tutorial exercise regarding the use of classification techniques on the Digits dataset.</source>
          <target state="translated">Учебное упражнение по использованию методов классификации в наборе данных &quot;Цифры&quot;.</target>
        </trans-unit>
        <trans-unit id="f2776a357a1de5e5a81f9ce6aa4ab14f87148c15" translate="yes" xml:space="preserve">
          <source>A tutorial exercise using Cross-validation with an SVM on the Digits dataset.</source>
          <target state="translated">Учебное упражнение с использованием перекрестной проверки с SVM в наборе данных &quot;Цифры&quot;.</target>
        </trans-unit>
        <trans-unit id="b2628903b486483a05c00dab06ec0310f6a300cc" translate="yes" xml:space="preserve">
          <source>A tutorial exercise which uses cross-validation with linear models.</source>
          <target state="translated">Учебное упражнение,в котором используется перекрестная проверка с линейными моделями.</target>
        </trans-unit>
        <trans-unit id="cd8b8f382c4d69a8c061676d971b4b4296bfd8b7" translate="yes" xml:space="preserve">
          <source>A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">Учебное пособие по статистике для обработки научных данных.</target>
        </trans-unit>
        <trans-unit id="59f7f31eba85f0c9b2945699e7dc03221dcc0732" translate="yes" xml:space="preserve">
          <source>A two-dimensional classification example showing iso-probability lines for the predicted probabilities.</source>
          <target state="translated">Пример двумерной классификации,показывающий линии изо-вероятности для прогнозируемых вероятностей.</target>
        </trans-unit>
        <trans-unit id="027a04b42d0e6eeb4156be0ce184aaf749b2c919" translate="yes" xml:space="preserve">
          <source>A typical &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/blob/master/benchmarks/bench_sparsify.py&quot;&gt;benchmark&lt;/a&gt; on synthetic data yields a &amp;gt;30% decrease in latency when both the model and input are sparse (with 0.000024 and 0.027400 non-zero coefficients ratio respectively). Your mileage may vary depending on the sparsity and size of your data and model. Furthermore, sparsifying can be very useful to reduce the memory usage of predictive models deployed on production servers.</source>
          <target state="translated">Типичный &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/blob/master/benchmarks/bench_sparsify.py&quot;&gt;тест&lt;/a&gt; синтетических данных дает уменьшение задержки&amp;gt; 30%, когда и модель, и входные данные являются разреженными (с соотношением ненулевых коэффициентов 0,000024 и 0,027400 соответственно). Ваш пробег может варьироваться в зависимости от разреженности и размера ваших данных и модели. Кроме того, разрежение может быть очень полезно для уменьшения использования памяти прогнозными моделями, развернутыми на производственных серверах.</target>
        </trans-unit>
        <trans-unit id="ec7bb89c7f50ac1476a296b31de1d976e3adfdc7" translate="yes" xml:space="preserve">
          <source>A valid representation of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multilabel&quot;&gt;multilabel&lt;/a&gt;&lt;code&gt;y&lt;/code&gt; is an either dense or sparse &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-binary&quot;&gt;binary&lt;/a&gt; matrix of shape &lt;code&gt;(n_samples, n_classes)&lt;/code&gt;. Each column represents a class. The &lt;code&gt;1&lt;/code&gt;&amp;rsquo;s in each row denote the positive classes a sample has been labelled with. An example of a dense matrix &lt;code&gt;y&lt;/code&gt; for 3 samples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd911da25d74dfd6322d9ef6e738de82cbe5f6c0" translate="yes" xml:space="preserve">
          <source>A valid representation of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multioutput&quot;&gt;multioutput&lt;/a&gt;&lt;code&gt;y&lt;/code&gt; is a dense matrix of shape &lt;code&gt;(n_samples, n_classes)&lt;/code&gt; of class labels. A column wise concatenation of 1d &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; variables. An example of &lt;code&gt;y&lt;/code&gt; for 3 samples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b5488b6a26a1d957fe479981670f261e01fd257" translate="yes" xml:space="preserve">
          <source>A valid representation of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multioutput&quot;&gt;multioutput&lt;/a&gt;&lt;code&gt;y&lt;/code&gt; is a dense matrix of shape &lt;code&gt;(n_samples, n_classes)&lt;/code&gt; of floats. A column wise concatenation of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-continuous&quot;&gt;continuous&lt;/a&gt; variables. An example of &lt;code&gt;y&lt;/code&gt; for 3 samples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7b09774b632b4a2428bc3dfc2607f68bc8654b3" translate="yes" xml:space="preserve">
          <source>A value ranges from 0 to 1. Radius neighbors will be searched until the ratio between total neighbors within the radius and the total candidates becomes less than this value unless it is terminated by hash length reaching &lt;code&gt;min_hash_match&lt;/code&gt;.</source>
          <target state="translated">Диапазон значений от 0 до 1. Поиск соседей по радиусу будет выполняться до тех пор, пока соотношение между общим количеством соседей в пределах радиуса и общим количеством кандидатов не станет меньше этого значения, если только он не завершится достижением длины хэша &lt;code&gt;min_hash_match&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2582a27b00b61e2b9522f341f9a346d9f6709d01" translate="yes" xml:space="preserve">
          <source>A vector of size n_samples with the values of Xred assigned to each of the cluster of samples.</source>
          <target state="translated">Вектор размера n_образцов со значениями Xred,присвоенными каждому из кластеров выборок.</target>
        </trans-unit>
        <trans-unit id="d6682290692f64a366a7947dddf0230094bb4014" translate="yes" xml:space="preserve">
          <source>A very short introduction into machine learning problems and how to solve them using scikit-learn. Introduced basic concepts and conventions.</source>
          <target state="translated">Очень короткое введение в проблемы машинного обучения и в то,как их решать с помощью программы &quot;наука-обучение&quot;.Введение в основные понятия и конвенции.</target>
        </trans-unit>
        <trans-unit id="c7690c5e442eb70039d5b5e2448652422a789b71" translate="yes" xml:space="preserve">
          <source>A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f36937969f4f8fe7fe83a3d1b4c3ed127cd62323" translate="yes" xml:space="preserve">
          <source>A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction. We will use three different regressors to predict the data: &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.linearregression#sklearn.linear_model.LinearRegression&quot;&gt;&lt;code&gt;LinearRegression&lt;/code&gt;&lt;/a&gt;). Then the above 3 regressors will be used for the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingregressor#sklearn.ensemble.VotingRegressor&quot;&gt;&lt;code&gt;VotingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e5f7b45681bf1702c76ccf69a63504aee5a5896" translate="yes" xml:space="preserve">
          <source>A {n_samples by n_samples} size matrix will be created from this</source>
          <target state="translated">Из этого будет создана матрица размеров {n_samples by n_samples}</target>
        </trans-unit>
        <trans-unit id="fcc549a5a2b9c6ffeadeffd9e820de04a6f70e50" translate="yes" xml:space="preserve">
          <source>A. Kraskov, H. Stogbauer and P. Grassberger, &amp;ldquo;Estimating mutual information&amp;rdquo;. Phys. Rev. E 69, 2004.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f18974816a09bbd22c4a7050c6bc6030b7596e3" translate="yes" xml:space="preserve">
          <source>A. McCallum and K. Nigam (1998). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.1529&quot;&gt;A comparison of event models for Naive Bayes text classification.&lt;/a&gt; Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp. 41-48.</source>
          <target state="translated">А. МакКаллум и К. Нигам (1998). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.1529&quot;&gt;Сравнение моделей событий для классификации наивного байесовского текста. &lt;/a&gt;Proc. Практикум AAAI / ICML-98 по обучению категоризации текста, стр. 41-48.</target>
        </trans-unit>
        <trans-unit id="09ff19e0224a8e064521a1f035498a8575f6b1a4" translate="yes" xml:space="preserve">
          <source>A. McCallum and K. Nigam (1998). A comparison of event models for naive Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp. 41-48.</source>
          <target state="translated">A.МакКаллум и К.Найгам (1998).Сравнение моделей событий для классификации текста наивного Бейеса.Труды.AAAI/ICML-98 Семинар по обучению для классификации текста,стр.41-48.</target>
        </trans-unit>
        <trans-unit id="664157aad39c267bf285cc58317f2c271aa8f944" translate="yes" xml:space="preserve">
          <source>A. Noll, R. Salzmann and M.V. Wuthrich, Case Study: French Motor Third-Party Liability Claims (November 8, 2018). &lt;a href=&quot;http://dx.doi.org/10.2139/ssrn.3164764&quot;&gt;doi:10.2139/ssrn.3164764&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4aaae5b2c1983dccf44b8ac2ef0c2ae6d4b3ffdb" translate="yes" xml:space="preserve">
          <source>AGE</source>
          <target state="translated">AGE</target>
        </trans-unit>
        <trans-unit id="4aecbad800270fae47218d640b45ace7ade395c4" translate="yes" xml:space="preserve">
          <source>AGE proportion of owner-occupied units built prior to 1940</source>
          <target state="translated">АПЭ доля занятых владельцем единиц,построенных до 1940 г.</target>
        </trans-unit>
        <trans-unit id="80cd3c2daea500fa1de49e5116e93d233f023eef" translate="yes" xml:space="preserve">
          <source>AIC is the Akaike information criterion and BIC is the Bayes Information criterion. Such criteria are useful to select the value of the regularization parameter by making a trade-off between the goodness of fit and the complexity of the model. A good model should explain well the data while being simple.</source>
          <target state="translated">АИК-критерий информации Акайке,а БИК-критерий информации Байеса.Такие критерии полезны для выбора значения параметра регуляризации,делая компромисс между хорошей пригодностью и сложностью модели.Хорошая модель должна хорошо объяснять данные,но при этом быть простой.</target>
        </trans-unit>
        <trans-unit id="fedf36066038cc2bbe4c1f8d6f37bca1d4a271f3" translate="yes" xml:space="preserve">
          <source>AMI</source>
          <target state="translated">AMI</target>
        </trans-unit>
        <trans-unit id="977d221308080b656b11030badda34761fa1379d" translate="yes" xml:space="preserve">
          <source>ANOVA F-value between label/feature for classification tasks.</source>
          <target state="translated">ANOVA F-значение между этикеткой и температурой для задач классификации.</target>
        </trans-unit>
        <trans-unit id="500622cc8c5af556f9bf30d45e5a5dc4d38771d9" translate="yes" xml:space="preserve">
          <source>AP and the trapezoidal area under the operating points (&lt;a href=&quot;../../modules/generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt;&lt;code&gt;sklearn.metrics.auc&lt;/code&gt;&lt;/a&gt;) are common ways to summarize a precision-recall curve that lead to different results. Read more in the &lt;a href=&quot;../../modules/model_evaluation#precision-recall-f-measure-metrics&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">AP и трапециевидная область под рабочими точками ( &lt;a href=&quot;../../modules/generated/sklearn.metrics.auc#sklearn.metrics.auc&quot;&gt; &lt;code&gt;sklearn.metrics.auc&lt;/code&gt; &lt;/a&gt; ) - распространенные способы суммирования кривой точности-отзыва, которые приводят к различным результатам. Подробнее читайте в &lt;a href=&quot;../../modules/model_evaluation#precision-recall-f-measure-metrics&quot;&gt;Руководстве пользователя&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="7ce6548ae70272727979635a979ae4f9ea8a3a93" translate="yes" xml:space="preserve">
          <source>AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:</source>
          <target state="translated">AP суммирует кривую точности вызова как средневзвешенное значение точности,достигнутое на каждом пороге,с увеличением вызова по сравнению с предыдущим пороговым значением,используемым в качестве веса:</target>
        </trans-unit>
        <trans-unit id="d93d10ff0fbef1b4aa0ddc24e10e907746d3c85a" translate="yes" xml:space="preserve">
          <source>API</source>
          <target state="translated">API</target>
        </trans-unit>
        <trans-unit id="b276f94cd8d0e74a21de6e5939b8c10ca9a975d6" translate="yes" xml:space="preserve">
          <source>API Reference</source>
          <target state="translated">API ссылка</target>
        </trans-unit>
        <trans-unit id="044c42df47a473e04593a603631e399678960367" translate="yes" xml:space="preserve">
          <source>ARD is also known in the literature as &lt;em&gt;Sparse Bayesian Learning&lt;/em&gt; and &lt;em&gt;Relevance Vector Machine&lt;/em&gt;&lt;a href=&quot;#id16&quot; id=&quot;id12&quot;&gt;3&lt;/a&gt;&lt;a href=&quot;#id18&quot; id=&quot;id13&quot;&gt;4&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc664a8aed1b7702083559e78f4a1b25e63a7739" translate="yes" xml:space="preserve">
          <source>ARD is also known in the literature as &lt;em&gt;Sparse Bayesian Learning&lt;/em&gt; and &lt;em&gt;Relevance Vector Machine&lt;/em&gt;&lt;a href=&quot;#id20&quot; id=&quot;id16&quot;&gt;[3]&lt;/a&gt;&lt;a href=&quot;#id21&quot; id=&quot;id17&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">ARD также известен в литературе как &lt;em&gt;машина &lt;/em&gt;&lt;em&gt;разреженного байесовского обучения&lt;/em&gt; и &lt;em&gt;векторов релевантности &lt;/em&gt;&lt;a href=&quot;#id20&quot; id=&quot;id16&quot;&gt;[3] &lt;/a&gt;&lt;a href=&quot;#id21&quot; id=&quot;id17&quot;&gt;[4]&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a1df128dfacd3f460cbb61bb4087bb92287d3fcb" translate="yes" xml:space="preserve">
          <source>ARI</source>
          <target state="translated">ARI</target>
        </trans-unit>
        <trans-unit id="8c442cbb4124477c731be288798913c884c906af" translate="yes" xml:space="preserve">
          <source>ARI is a symmetric measure:</source>
          <target state="translated">ARI-симметричная мера:</target>
        </trans-unit>
        <trans-unit id="b6cdde34aa4cbbe354d4a8fe12fbb26711ad6710" translate="yes" xml:space="preserve">
          <source>ARI is symmetric, so labelings that have pure clusters with members coming from the same classes but unnecessary splits are penalized:</source>
          <target state="translated">ARI симметричен,поэтому маркировки,которые имеют чистые кластеры с членами,принадлежащими к одним и тем же классам,но ненужные расщепления,наказываются:</target>
        </trans-unit>
        <trans-unit id="5045d88e766edf44d9736d9751b0aa0b647864ac" translate="yes" xml:space="preserve">
          <source>A[i, j] is assigned the weight of edge that connects i to j.</source>
          <target state="translated">A[i,j]присваивается вес кромки,соединяющей i с j.</target>
        </trans-unit>
        <trans-unit id="9f4a63ae0bf1594deea5ea12c509b27f409ce3db" translate="yes" xml:space="preserve">
          <source>Aaron Defazio, Francis Bach, Simon Lacoste-Julien: &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.&lt;/a&gt;</source>
          <target state="translated">Аарон Дефазио, Фрэнсис Бах, Саймон Лакост-Жюльен: &lt;a href=&quot;https://arxiv.org/abs/1407.0202&quot;&gt;SAGA: метод быстрого инкрементного градиента с поддержкой несильно выпуклых составных целей.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e82c46cc189803ea687c96da2038982e9dcb6a4b" translate="yes" xml:space="preserve">
          <source>Ability to use shared memory efficiently with worker processes for large numpy-based datastructures.</source>
          <target state="translated">Возможность эффективного использования общей памяти с рабочими процессами для больших нумерованных структур данных.</target>
        </trans-unit>
        <trans-unit id="54d1141ddccb7851744d76084cc8611f93e2cfc3" translate="yes" xml:space="preserve">
          <source>Able to handle both numerical and categorical data. Other techniques are usually specialised in analysing datasets that have only one type of variable. See &lt;a href=&quot;#tree-algorithms&quot;&gt;algorithms&lt;/a&gt; for more information.</source>
          <target state="translated">Может обрабатывать как числовые, так и категориальные данные. Другие методы обычно специализируются на анализе наборов данных, содержащих только один тип переменных. См. &lt;a href=&quot;#tree-algorithms&quot;&gt;Алгоритмы&lt;/a&gt; для получения дополнительной информации.</target>
        </trans-unit>
        <trans-unit id="2367c2ca7022225c20205571d9433b5b6b84cd68" translate="yes" xml:space="preserve">
          <source>Able to handle multi-output problems.</source>
          <target state="translated">Способен справляться с проблемами с несколькими выходами.</target>
        </trans-unit>
        <trans-unit id="da22d4ef976c68e8fef4ef4e1a2681784cdddf3a" translate="yes" xml:space="preserve">
          <source>Above, we limited this regularization to a very little amount. Regularization improves the conditioning of the problem and reduces the variance of the estimates. RidgeCV applies cross validation in order to determine which value of the regularization parameter (&lt;code&gt;alpha&lt;/code&gt;) is best suited for prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c09e3c38ba7261734dc4ab72dcf1ef3efd8a152" translate="yes" xml:space="preserve">
          <source>Absolute threshold for a singular value of X to be considered significant, used to estimate the rank of X. Dimensions whose singular values are non-significant are discarded. Only used if solver is &amp;lsquo;svd&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aa749baee7b6d0eb7f8d7395643fd7e673c649b" translate="yes" xml:space="preserve">
          <source>Absolute threshold for a singular value to be considered significant, used to estimate the rank of &lt;code&gt;Xk&lt;/code&gt; where &lt;code&gt;Xk&lt;/code&gt; is the centered matrix of samples in class k. This parameter does not affect the predictions. It only controls a warning that is raised when features are considered to be colinear.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f587c3583da9a191a72d5ff01fbfedde272f2898" translate="yes" xml:space="preserve">
          <source>Absolute tolerance for equivalence of arrays. Default = 1E-10.</source>
          <target state="translated">Абсолютная толерантность к эквивалентности массивов.По умолчанию=1E-10.</target>
        </trans-unit>
        <trans-unit id="d79faf207bac3f682107ababce293b4eceadf34c" translate="yes" xml:space="preserve">
          <source>Acceptable data types for the parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a62a0f9649f4eb6fd92f87e85b475e87182d6e46" translate="yes" xml:space="preserve">
          <source>Access the fitted transformer by name.</source>
          <target state="translated">Доступ к встроенному трансформатору по имени.</target>
        </trans-unit>
        <trans-unit id="9e0e7377700ae6d6f91649710d89b9dd54aaa033" translate="yes" xml:space="preserve">
          <source>According to the JL lemma, projecting 500 samples without too much distortion will require at least several thousands dimensions, irrespective of the number of features of the original dataset.</source>
          <target state="translated">Согласно JL lemma,для проецирования 500 отсчетов без излишних искажений потребуется как минимум несколько тысяч размеров,независимо от количества особенностей исходного набора данных.</target>
        </trans-unit>
        <trans-unit id="caff4ed631e2a64d90ad9e75e695e4cb077ff929" translate="yes" xml:space="preserve">
          <source>According to the model above, the log of the posterior is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e10c7e434a3850cc1ce980a85ce2c40965ebbd1" translate="yes" xml:space="preserve">
          <source>According to the observed data, the frequency of accidents is higher for drivers younger than 30 years old, and is positively correlated with the &lt;code&gt;BonusMalus&lt;/code&gt; variable. Our model is able to mostly correctly model this behaviour.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b168ce1b26b0ed19f0857c9a9e0275bc2a86de2" translate="yes" xml:space="preserve">
          <source>Accuracy classification score.</source>
          <target state="translated">Оценка точности классификации.</target>
        </trans-unit>
        <trans-unit id="ed1b27307b9c829fdd35ed1ccf294d2e82a6dfcb" translate="yes" xml:space="preserve">
          <source>Accuracy of the Model</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b171ff92fbbc89c347ecf11b61ad701495ae9495" translate="yes" xml:space="preserve">
          <source>Accuracy vs alpha for training and testing sets</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3159fc0c287c6fa355557d0a32e1e4fbdd60d32b" translate="yes" xml:space="preserve">
          <source>Across the module, we designate the vector \(w = (w_1, ..., w_p)\) as &lt;code&gt;coef_&lt;/code&gt; and \(w_0\) as &lt;code&gt;intercept_&lt;/code&gt;.</source>
          <target state="translated">В модуле мы обозначаем вектор \ (w = (w_1, ..., w_p) \) как &lt;code&gt;coef_&lt;/code&gt; и \ (w_0 \) как &lt;code&gt;intercept_&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1e74068a27362b129f4808ec6412c747359a90d1" translate="yes" xml:space="preserve">
          <source>Activation function for the hidden layer.</source>
          <target state="translated">Функция активации скрытого слоя.</target>
        </trans-unit>
        <trans-unit id="13466b0d67f826e470f7f662a0fa9b98771bd57d" translate="yes" xml:space="preserve">
          <source>Actual class (observation)</source>
          <target state="translated">Фактический класс (наблюдение)</target>
        </trans-unit>
        <trans-unit id="4bda103291a01841e5d33c04e072de1679753a3f" translate="yes" xml:space="preserve">
          <source>Actual number of iteration for each Cs.</source>
          <target state="translated">Фактическое количество итераций для каждой Cs.</target>
        </trans-unit>
        <trans-unit id="b9e108d70e5d6e1ab362876cb4abfe8b3ea0d61c" translate="yes" xml:space="preserve">
          <source>Actual number of iterations for all classes, folds and Cs. In the binary or multinomial cases, the first dimension is equal to 1.</source>
          <target state="translated">Фактическое количество итераций для всех классов,складок и Cs.В двоичном или многочленном случае первое измерение равно 1.</target>
        </trans-unit>
        <trans-unit id="e15b0921ef0e026565cb96038a661f88e504a7d1" translate="yes" xml:space="preserve">
          <source>Actual number of iterations for all classes, folds and Cs. In the binary or multinomial cases, the first dimension is equal to 1. If &lt;code&gt;penalty='elasticnet'&lt;/code&gt;, the shape is &lt;code&gt;(n_classes, n_folds,
n_cs, n_l1_ratios)&lt;/code&gt; or &lt;code&gt;(1, n_folds, n_cs, n_l1_ratios)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7c00438aea9f14670d9e5ce3ad69eadb9e56fa7" translate="yes" xml:space="preserve">
          <source>Actual number of iterations for all classes. If binary or multinomial, it returns only 1 element. For liblinear solver, only the maximum number of iteration across all classes is given.</source>
          <target state="translated">Фактическое количество итераций для всех классов.Если двоичный или многочленный,то возвращается только 1 элемент.Для liblinear solver дается только максимальное число итераций по всем классам.</target>
        </trans-unit>
        <trans-unit id="41eb0ffb0b86a2b7fa1c30caad1eab7979f038bb" translate="yes" xml:space="preserve">
          <source>Actual number of iterations for each target. Available only for sag and lsqr solvers. Other solvers will return None.</source>
          <target state="translated">Фактическое количество итераций для каждой цели.Доступно только для растворителей sag и lsqr.Другие решатели не вернутся.</target>
        </trans-unit>
        <trans-unit id="5f183a64b01f4bbfef50fc734f02625115726f0b" translate="yes" xml:space="preserve">
          <source>Actual number of iterations used in the solver.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5f57bad41ea8a1cc3f7ad65dabd66fae549152b" translate="yes" xml:space="preserve">
          <source>Actual number of iterations.</source>
          <target state="translated">Фактическое количество итераций.</target>
        </trans-unit>
        <trans-unit id="e88dbeae46a975e549a3e1b429ac335f1717a327" translate="yes" xml:space="preserve">
          <source>AdaBoost can be used both for classification and regression problems:</source>
          <target state="translated">AdaBoost может использоваться как для классификации,так и для регрессии:</target>
        </trans-unit>
        <trans-unit id="1c3d2a8d1e7ee52688369f7b268da1f090f613a4" translate="yes" xml:space="preserve">
          <source>Adam is similar to SGD in a sense that it is a stochastic optimizer, but it can automatically adjust the amount to update parameters based on adaptive estimates of lower-order moments.</source>
          <target state="translated">Адам похож на SGD в том смысле,что это стохастический оптимизатор,но он может автоматически регулировать количество обновляемых параметров на основе адаптивных оценок моментов нижнего порядка.</target>
        </trans-unit>
        <trans-unit id="37193f0def1de066166921b64d73e81a4207486f" translate="yes" xml:space="preserve">
          <source>Add plots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71042ebf81b88cec72926e5e2da3d76737a8fc09" translate="yes" xml:space="preserve">
          <source>Adding a constant kernel is equivalent to adding a constant:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57edf9b3cf9cc602f38d55f2f3497cc8e4458efe" translate="yes" xml:space="preserve">
          <source>Adding parameters that do not influence the performance does not decrease efficiency.</source>
          <target state="translated">Добавление параметров,не влияющих на производительность,не снижает эффективность.</target>
        </trans-unit>
        <trans-unit id="d8b82f8ac1fd93a8c5863d25cc6558cb656b7f40" translate="yes" xml:space="preserve">
          <source>Additional Resources</source>
          <target state="translated">Дополнительные ресурсы</target>
        </trans-unit>
        <trans-unit id="28c6073bb46543d76ed56428ba51e1f98f703736" translate="yes" xml:space="preserve">
          <source>Additional fit parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bc09d37c7749b14dd88f92786b449d978558dbf" translate="yes" xml:space="preserve">
          <source>Additional keyword arguments for the metric function.</source>
          <target state="translated">Дополнительные аргументы по ключевым словам для метрической функции.</target>
        </trans-unit>
        <trans-unit id="448e0ea40ef1f0816d1ba3c00c7fd9818ee1579c" translate="yes" xml:space="preserve">
          <source>Additional keyword arguments for the metric function. For most metrics will be same with &lt;code&gt;metric_params&lt;/code&gt; parameter, but may also contain the &lt;code&gt;p&lt;/code&gt; parameter value if the &lt;code&gt;effective_metric_&lt;/code&gt; attribute is set to &amp;lsquo;minkowski&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a84da277628ee33f1ee92b82eb0c5a6af6d0524" translate="yes" xml:space="preserve">
          <source>Additional number of random vectors to sample the range of M so as to ensure proper conditioning. The total number of random vectors used to find the range of M is n_components + n_oversamples. Smaller number can improve speed but can negatively impact the quality of approximation of singular vectors and singular values.</source>
          <target state="translated">Дополнительное количество случайных векторов для выборки диапазона М,чтобы обеспечить правильную кондиционирование.Общее количество случайных векторов,используемых для нахождения диапазона M,составляет n_компонент+n_oversamples.Меньшее число может улучшить скорость,но может негативно повлиять на качество аппроксимации сингулярных векторов и сингулярных значений.</target>
        </trans-unit>
        <trans-unit id="7cc2d5826a730e9f6abc3aeeee28797fe00b8570" translate="yes" xml:space="preserve">
          <source>Additional parameter passed to the fit function of the estimator.</source>
          <target state="translated">Дополнительный параметр передается в подходящую функцию оценочного устройства.</target>
        </trans-unit>
        <trans-unit id="df9b29356cfac6bb58ec5dca9394f2d9dfc4703b" translate="yes" xml:space="preserve">
          <source>Additional parameters (keyword arguments) for kernel function passed as callable object.</source>
          <target state="translated">Дополнительные параметры (аргументы ключевых слов)для функции кернела,передаваемые как вызываемый объект.</target>
        </trans-unit>
        <trans-unit id="39a26d6ec93b4bd557ff0d3e3333c06661f787d5" translate="yes" xml:space="preserve">
          <source>Additional parameters to be passed to score_func.</source>
          <target state="translated">Дополнительные параметры для передачи в score_func.</target>
        </trans-unit>
        <trans-unit id="71247cd4c08f9e15e8cf580ef4b1b215b5be4541" translate="yes" xml:space="preserve">
          <source>Additional parameters to be passed to the tree for use with the metric. For more information, see the documentation of &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Дополнительные параметры, передаваемые в дерево для использования с метрикой. Для получения дополнительной информации см. Документацию &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="36da43716a16aade125d9759679637e39761ccc9" translate="yes" xml:space="preserve">
          <source>Additionally compute class covariance matrix (default False), used only in &amp;lsquo;svd&amp;rsquo; solver.</source>
          <target state="translated">Дополнительно вычислить матрицу ковариации класса (по умолчанию False), используемую только в решателе 'svd'.</target>
        </trans-unit>
        <trans-unit id="cb731300b5471fde45bf8790ae9ce49720693175" translate="yes" xml:space="preserve">
          <source>Additionally, &lt;code&gt;Pipeline&lt;/code&gt; can be instantiated with the &lt;code&gt;memory&lt;/code&gt; argument to memoize the transformers within the pipeline, avoiding to fit again the same transformers over and over.</source>
          <target state="translated">Кроме того, можно создать экземпляр &lt;code&gt;Pipeline&lt;/code&gt; с аргументом &lt;code&gt;memory&lt;/code&gt; , чтобы запоминать трансформаторы внутри конвейера, избегая повторной установки одних и тех же трансформаторов снова и снова.</target>
        </trans-unit>
        <trans-unit id="4fcf36ef35c92f01311334b57dea32bb115ca779" translate="yes" xml:space="preserve">
          <source>Additionally, latent semantic analysis can also be used to reduce dimensionality and discover latent patterns in the data.</source>
          <target state="translated">Кроме того,скрытый семантический анализ может быть использован для уменьшения размерности и обнаружения скрытых закономерностей в данных.</target>
        </trans-unit>
        <trans-unit id="c13231af636098d832d9fddca4838809fd525e6e" translate="yes" xml:space="preserve">
          <source>Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).</source>
          <target state="translated">Добавочный (Лаплас/Лидстоун)параметр сглаживания (0 для отсутствия сглаживания).</target>
        </trans-unit>
        <trans-unit id="b8c1aaec1a2a62d157d744d0faee837709b2772c" translate="yes" xml:space="preserve">
          <source>Adjacency matrix of the graph</source>
          <target state="translated">Матрица адъюнктуры графика</target>
        </trans-unit>
        <trans-unit id="250995e59d0465859871db4d7d37821f2e9e268c" translate="yes" xml:space="preserve">
          <source>Adjusted Mutual Information</source>
          <target state="translated">Скорректированная взаимная информация</target>
        </trans-unit>
        <trans-unit id="11e5941af4a261b664e9f0491f0ecd18e8412b46" translate="yes" xml:space="preserve">
          <source>Adjusted Mutual Information (AMI) is an adjustment of the Mutual Information (MI) score to account for chance. It accounts for the fact that the MI is generally higher for two clusterings with a larger number of clusters, regardless of whether there is actually more information shared. For two clusterings \(U\) and \(V\), the AMI is given as:</source>
          <target state="translated">Скорректированная взаимная информация (СВИ)-это корректировка баллов Взаимной информации (ВИ)для учета шансов.Это объясняет тот факт,что MI,как правило,выше для двух кластеров с большим количеством кластеров,независимо от того,есть ли на самом деле больше совместно используемой информации.Для двух кластеров \(U\)и \(V\),AMI указан как:</target>
        </trans-unit>
        <trans-unit id="4a1b6ee1509942e0e22b1880790459ca848319f4" translate="yes" xml:space="preserve">
          <source>Adjusted Mutual Information (adjusted against chance)</source>
          <target state="translated">Скорректированная взаимная информация (скорректированная с учетом случайности)</target>
        </trans-unit>
        <trans-unit id="4630f03a5a119c76517981dad27161c68958ec63" translate="yes" xml:space="preserve">
          <source>Adjusted Mutual Information between two clusterings.</source>
          <target state="translated">Скорректированная взаимная информация между двумя кластерами.</target>
        </trans-unit>
        <trans-unit id="1802b8bdeb7acaeda57735feed31e0ee765d7139" translate="yes" xml:space="preserve">
          <source>Adjusted Rand Index</source>
          <target state="translated">Скорректированный индекс диапазона</target>
        </trans-unit>
        <trans-unit id="31e214397fb70765d3e9e011e4c9138d3d446804" translate="yes" xml:space="preserve">
          <source>Adjusted against chance Mutual Information</source>
          <target state="translated">Откорректировано против случайности Взаимная информация</target>
        </trans-unit>
        <trans-unit id="a058b0be3c60201e595de35ba7261933ab6a3173" translate="yes" xml:space="preserve">
          <source>Adjusted for chance measure such as ARI display some random variations centered around a mean score of 0.0 for any number of samples and clusters.</source>
          <target state="translated">Откорректировано для случайных измерений,таких как ARI отображение некоторых случайных вариаций с центром вокруг средней оценки 0,0 для любого количества выборок и кластеров.</target>
        </trans-unit>
        <trans-unit id="b80cf8c9df3b30a05f03bffeb2976e09c960b38a" translate="yes" xml:space="preserve">
          <source>Adjustment for chance in clustering performance evaluation</source>
          <target state="translated">Корректировка шансов при оценке эффективности кластеризации</target>
        </trans-unit>
        <trans-unit id="7a26e45b68e65e5d705e3f16c6dd31629c5f071a" translate="yes" xml:space="preserve">
          <source>Advanced Plotting With Partial Dependence</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c22815e21882a0aa7a6a9b8a93ee5e8e17ca7614" translate="yes" xml:space="preserve">
          <source>Affects shape of transform output only when voting=&amp;rsquo;soft&amp;rsquo; If voting=&amp;rsquo;soft&amp;rsquo; and flatten_transform=True, transform method returns matrix with shape (n_samples, n_classifiers * n_classes). If flatten_transform=False, it returns (n_classifiers, n_samples, n_classes).</source>
          <target state="translated">Влияет на форму вывода преобразования только при голосовании = 'soft'. Если голосование = 'soft' и flatten_transform = True, метод преобразования возвращает матрицу с формой (n_samples, n_classifiers * n_classes). Если flatten_transform = False, он возвращает (n_classifiers, n_samples, n_classes).</target>
        </trans-unit>
        <trans-unit id="6be196ba0996dde7d9ed4c8d27213a288c55819b" translate="yes" xml:space="preserve">
          <source>Affinity Propagation can be interesting as it chooses the number of clusters based on the data provided. For this purpose, the two important parameters are the &lt;em&gt;preference&lt;/em&gt;, which controls how many exemplars are used, and the &lt;em&gt;damping factor&lt;/em&gt; which damps the responsibility and availability messages to avoid numerical oscillations when updating these messages.</source>
          <target state="translated">Affinity Propagation может быть интересным, так как выбирает количество кластеров на основе предоставленных данных. Для этой цели двумя важными параметрами являются &lt;em&gt;предпочтение&lt;/em&gt; , которое контролирует количество используемых экземпляров, и &lt;em&gt;коэффициент демпфирования,&lt;/em&gt; который снижает ответственность и сообщения о доступности, чтобы избежать числовых колебаний при обновлении этих сообщений.</target>
        </trans-unit>
        <trans-unit id="f0a35e8a6a6b08571acff68f4d3ca53b52b812c7" translate="yes" xml:space="preserve">
          <source>Affinity matrix used for clustering. Available only if after calling &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">Матрица аффинности, используемая для кластеризации. Доступно только если после звонка &lt;code&gt;fit&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="63246ae129dc66d8916faa22ac2026722fe870df" translate="yes" xml:space="preserve">
          <source>Affinity propagation</source>
          <target state="translated">Распространение аффинити</target>
        </trans-unit>
        <trans-unit id="50cd6f7778a2976318486216f7be1102ea3c2dbd" translate="yes" xml:space="preserve">
          <source>Affinity_matrix constructed from samples or precomputed.</source>
          <target state="translated">Матрица_аффинити,построенная из образцов или прекомпилированная.</target>
        </trans-unit>
        <trans-unit id="9d6ec54ac3f9f07d1c79bc7828709b2a1ebe0b76" translate="yes" xml:space="preserve">
          <source>After being fitted, the model can then be used to predict new values:</source>
          <target state="translated">После установки модель может быть использована для прогнозирования новых значений:</target>
        </trans-unit>
        <trans-unit id="56033184bfd4d9eb6d5cedda898ff603a56457b5" translate="yes" xml:space="preserve">
          <source>After being fitted, the model can then be used to predict the class of samples:</source>
          <target state="translated">После подгонки модель может быть использована для прогнозирования класса образцов:</target>
        </trans-unit>
        <trans-unit id="d1a9437feb3595025967367029f3b25aca08ed48" translate="yes" xml:space="preserve">
          <source>After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.</source>
          <target state="translated">После вызова этого метода дальнейшая подгонка метода partial_fit (если он есть)не будет работать до тех пор,пока не будет вызван метод densify.</target>
        </trans-unit>
        <trans-unit id="1ac4b13a36333967e31b510f39d76728b1ade858" translate="yes" xml:space="preserve">
          <source>After discretization, linear regression and decision tree make exactly the same prediction. As features are constant within each bin, any model must predict the same value for all points within a bin. Compared with the result before discretization, linear model become much more flexible while decision tree gets much less flexible. Note that binning features generally has no beneficial effect for tree-based models, as these models can learn to split up the data anywhere.</source>
          <target state="translated">После дискретизации линейная регрессия и дерево решений делают точно такой же прогноз.Так как характеристики постоянны внутри каждого бина,любая модель должна предсказывать одно и то же значение для всех точек внутри бина.По сравнению с результатом до дискретизации,линейная модель становится намного более гибкой,в то время как дерево решений становится намного менее гибким.Обратите внимание,что функции бининга,как правило,не оказывают положительного влияния на древовидные модели,так как эти модели могут научиться разбивать данные в любом месте.</target>
        </trans-unit>
        <trans-unit id="eef177bc3be0e883eb6e86188495b80899ebaefb" translate="yes" xml:space="preserve">
          <source>After fitting (training), the model can predict labels for new samples:</source>
          <target state="translated">После подгонки (обучения)модель может предсказывать этикетки для новых образцов:</target>
        </trans-unit>
        <trans-unit id="5e6425357ee2c6e34c7ccf4e621fb9b2e0d28394" translate="yes" xml:space="preserve">
          <source>After fitting a model, row and column cluster membership can be found in the &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes. &lt;code&gt;rows_[i]&lt;/code&gt; is a binary vector with nonzero entries corresponding to rows that belong to bicluster &lt;code&gt;i&lt;/code&gt;. Similarly, &lt;code&gt;columns_[i]&lt;/code&gt; indicates which columns belong to bicluster &lt;code&gt;i&lt;/code&gt;.</source>
          <target state="translated">После подбора модели членство в кластере строк и столбцов можно найти в &lt;code&gt;rows_&lt;/code&gt; и &lt;code&gt;columns_&lt;/code&gt; . &lt;code&gt;rows_[i]&lt;/code&gt; - двоичный вектор с ненулевыми элементами, соответствующими строкам, принадлежащим бикластеру &lt;code&gt;i&lt;/code&gt; . Точно так же &lt;code&gt;columns_[i]&lt;/code&gt; указывает, какие столбцы принадлежат бикластеру &lt;code&gt;i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="71ae50af31deda9eff4041050d01116db2fe0b76" translate="yes" xml:space="preserve">
          <source>After normalizing, the first few singular vectors are computed, just as in the Spectral Co-Clustering algorithm.</source>
          <target state="translated">После нормализации вычисляются первые несколько сингулярных векторов,как и в алгоритме спектрального со-клестера.</target>
        </trans-unit>
        <trans-unit id="c326685e6de3fbd40d347b380da45cf33d03051c" translate="yes" xml:space="preserve">
          <source>After this operation, \(U_k \Sigma_k^\top\) is the transformed training set with \(k\) features (called &lt;code&gt;n_components&lt;/code&gt; in the API).</source>
          <target state="translated">После этой операции \ (U_k \ Sigma_k ^ \ top \) представляет собой преобразованный обучающий набор с функциями \ (k \) (называемыми &lt;code&gt;n_components&lt;/code&gt; в API).</target>
        </trans-unit>
        <trans-unit id="d10a093c92eea73e29249b26fe409d51c485f495" translate="yes" xml:space="preserve">
          <source>After training a scikit-learn model, it is desirable to have a way to persist the model for future use without having to retrain. The following section gives you an example of how to persist a model with pickle. We&amp;rsquo;ll also review a few security and maintainability issues when working with pickle serialization.</source>
          <target state="translated">После обучения модели scikit-learn желательно иметь способ сохранить модель для будущего использования без необходимости повторного обучения. В следующем разделе приведен пример того, как сохранить модель с помощью pickle. Мы также рассмотрим несколько проблем с безопасностью и ремонтопригодностью при работе с сериализацией pickle.</target>
        </trans-unit>
        <trans-unit id="24449d2cd36cc7fedaa85e80b22b4a39b7f8e2cc" translate="yes" xml:space="preserve">
          <source>After using such a procedure to fit the dictionary, the transform is simply a sparse coding step that shares the same implementation with all dictionary learning objects (see &lt;a href=&quot;#sparsecoder&quot;&gt;Sparse coding with a precomputed dictionary&lt;/a&gt;).</source>
          <target state="translated">После использования такой процедуры для соответствия словарю преобразование представляет собой просто этап разреженного кодирования, который имеет ту же реализацию, что и все объекты изучения словаря (см. &lt;a href=&quot;#sparsecoder&quot;&gt;Разреженное кодирование с предварительно вычисленным словарем&lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="2b35bdc816ab119e837a0f526e39f92fef72f3ba" translate="yes" xml:space="preserve">
          <source>Again please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details on all the parameters.</source>
          <target state="translated">Опять же, пожалуйста, обратитесь к &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;справочной документации&lt;/a&gt; для получения подробной информации обо всех параметрах.</target>
        </trans-unit>
        <trans-unit id="99e1009ea0e8d7b9e4e16a4193c8696d68c4efff" translate="yes" xml:space="preserve">
          <source>Again, we check the performance of the computed model using, for example, the median absolute error of the model and the R squared coefficient.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff9f1ff32120d8b893c1ded522d49590353b29a6" translate="yes" xml:space="preserve">
          <source>Age</source>
          <target state="translated">Age</target>
        </trans-unit>
        <trans-unit id="e869aecf975cf3b336fce1699b0d4503e42564de" translate="yes" xml:space="preserve">
          <source>Agglomerate features.</source>
          <target state="translated">Особенности агломерата.</target>
        </trans-unit>
        <trans-unit id="dbb914491e4e2790ae24eaabcabbe0b9aa470c77" translate="yes" xml:space="preserve">
          <source>Agglomerative Clustering</source>
          <target state="translated">агломеративная кластеризация</target>
        </trans-unit>
        <trans-unit id="35bb423e043758761d2f3e248257c1ca705a5ac8" translate="yes" xml:space="preserve">
          <source>Agglomerative cluster has a &amp;ldquo;rich get richer&amp;rdquo; behavior that leads to uneven cluster sizes. In this regard, single linkage is the worst strategy, and Ward gives the most regular sizes. However, the affinity (or distance used in clustering) cannot be varied with Ward, thus for non Euclidean metrics, average linkage is a good alternative. Single linkage, while not robust to noisy data, can be computed very efficiently and can therefore be useful to provide hierarchical clustering of larger datasets. Single linkage can also perform well on non-globular data.</source>
          <target state="translated">Агломеративный кластер ведет себя по принципу &amp;laquo;богатый становится богаче&amp;raquo;, что приводит к неравномерному размеру кластера. В этом отношении одинарная связь - худшая стратегия, и Уорд дает самые обычные размеры. Однако сродство (или расстояние, используемое в кластеризации) нельзя изменять с помощью Уорда, поэтому для неевклидовых показателей хорошей альтернативой является среднее связывание. Одиночная связь, хотя и не устойчива к зашумленным данным, может быть вычислена очень эффективно и поэтому может быть полезна для обеспечения иерархической кластеризации больших наборов данных. Одинарная связь также может хорошо работать с неглобулярными данными.</target>
        </trans-unit>
        <trans-unit id="890d73cb8666b8b11b8fc128eb14fe1823b0fbff" translate="yes" xml:space="preserve">
          <source>Agglomerative clustering</source>
          <target state="translated">агломеративная кластеризация</target>
        </trans-unit>
        <trans-unit id="21c09abace100a2c8351e8288af87cf02023a3a7" translate="yes" xml:space="preserve">
          <source>Agglomerative clustering with and without structure</source>
          <target state="translated">Агломеративная кластеризация со структурой и без структуры</target>
        </trans-unit>
        <trans-unit id="06e589f9bfed18f64327ae7d57413054b3c6f8de" translate="yes" xml:space="preserve">
          <source>Agglomerative clustering with different metrics</source>
          <target state="translated">Агломеративная кластеризация с различными метриками</target>
        </trans-unit>
        <trans-unit id="4d6b62f2cefed7f7111116c687eea9e3676aa5b0" translate="yes" xml:space="preserve">
          <source>Agnostic</source>
          <target state="translated">Agnostic</target>
        </trans-unit>
        <trans-unit id="ac9f2566d02b5e4600cd56af348af55d70c023a7" translate="yes" xml:space="preserve">
          <source>Agnostic:</source>
          <target state="translated">Agnostic:</target>
        </trans-unit>
        <trans-unit id="a679479691140b63a2247391cf7941ca13e56589" translate="yes" xml:space="preserve">
          <source>Agriculture / weather modeling: number of rain events per year (Poisson), amount of rainfall per event (Gamma), total rainfall per year (Tweedie / Compound Poisson Gamma).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a88029fe8eca09e8e53e31e892c06950617c42cc" translate="yes" xml:space="preserve">
          <source>Akaike information criterion for the current model on the input X.</source>
          <target state="translated">Информационный критерий Акайке для текущей модели на входе X.</target>
        </trans-unit>
        <trans-unit id="471a24dc120a414840a5a390be002dd1fb20dce7" translate="yes" xml:space="preserve">
          <source>Alcalinity of Ash:</source>
          <target state="translated">Алкалине Эша:</target>
        </trans-unit>
        <trans-unit id="1c996292fc0f34e9abb2ed1bce253f665b2889f0" translate="yes" xml:space="preserve">
          <source>Alcalinity of ash</source>
          <target state="translated">Масличность золы</target>
        </trans-unit>
        <trans-unit id="35fa6a7b518a822ef300d3ac95936a0d4551ed5f" translate="yes" xml:space="preserve">
          <source>Alcohol</source>
          <target state="translated">Alcohol</target>
        </trans-unit>
        <trans-unit id="4537230d988c507a37af5da4b6f068cb25fae3fd" translate="yes" xml:space="preserve">
          <source>Alcohol:</source>
          <target state="translated">Alcohol:</target>
        </trans-unit>
        <trans-unit id="a755c4c6a00484a10fdd39c78f5316741e33717a" translate="yes" xml:space="preserve">
          <source>Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good Probabilities With Supervised Learning, in Proceedings of the 22nd International Conference on Machine Learning (ICML). See section 4 (Qualitative Analysis of Predictions).</source>
          <target state="translated">Александру Никулеску-Мизиль и Рич Каруана (2005 г.)&quot;Прогнозирование хороших вероятностей при обучении под наблюдением&quot; в материалах 22-й Международной конференции по машинному обучению (ICML).См.раздел 4 (Качественный анализ прогнозов).</target>
        </trans-unit>
        <trans-unit id="e00df3c495c9c818a9560b719b9887130853cc0a" translate="yes" xml:space="preserve">
          <source>Algorithm to use for nearest neighbors search, passed to neighbors.NearestNeighbors instance.</source>
          <target state="translated">Алгоритм поиска ближайших соседей,переданный соседям.NearestNeighbors instance.</target>
        </trans-unit>
        <trans-unit id="c6ad136737477e6b0db26cf9286713a801e6cd45" translate="yes" xml:space="preserve">
          <source>Algorithm to use in the optimization problem.</source>
          <target state="translated">Алгоритм для использования в задаче оптимизации.</target>
        </trans-unit>
        <trans-unit id="c739143784c9537893f5a8383165eeec97c8efbf" translate="yes" xml:space="preserve">
          <source>Algorithm used to compute the nearest neighbors:</source>
          <target state="translated">Алгоритм,используемый для вычисления ближайших соседей:</target>
        </trans-unit>
        <trans-unit id="cb151b633578d2167df8c911cd7019b2a2913090" translate="yes" xml:space="preserve">
          <source>Algorithm used to transform the data lars: uses the least angle regression method (linear_model.lars_path) lasso_lars: uses Lars to compute the Lasso solution lasso_cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). lasso_lars will be faster if the estimated components are sparse. omp: uses orthogonal matching pursuit to estimate the sparse solution threshold: squashes to zero all coefficients less than alpha from the projection &lt;code&gt;dictionary * X'&lt;/code&gt;</source>
          <target state="translated">Алгоритм, используемый для преобразования данных lars: использует метод регрессии наименьшего угла (linear_model.lars_path) lasso_lars: использует Lars для вычисления решения лассо lasso_cd: использует метод спуска координат для вычисления решения лассо (linear_model.Lasso). lasso_lars будет быстрее, если предполагаемые компоненты разрежены. omp: использует поиск ортогонального сопоставления для оценки порога разреженного решения: сводит к нулю все коэффициенты меньше альфа из &lt;code&gt;dictionary * X'&lt;/code&gt; проекции * X '</target>
        </trans-unit>
        <trans-unit id="59c5f2e6c851221e36e62f9314e77aa5b776cd59" translate="yes" xml:space="preserve">
          <source>Algorithm used to transform the data. lars: uses the least angle regression method (linear_model.lars_path) lasso_lars: uses Lars to compute the Lasso solution lasso_cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). lasso_lars will be faster if the estimated components are sparse. omp: uses orthogonal matching pursuit to estimate the sparse solution threshold: squashes to zero all coefficients less than alpha from the projection dictionary * X&amp;rsquo;</source>
          <target state="translated">Алгоритм, используемый для преобразования данных. lars: использует метод регрессии наименьшего угла (linear_model.lars_path) lasso_lars: использует Lars для вычисления решения Lasso lasso_cd: использует метод спуска координат для вычисления решения Lasso (linear_model.Lasso). lasso_lars будет быстрее, если предполагаемые компоненты разрежены. omp: использует поиск ортогонального сопоставления для оценки порога разреженного решения: сводит к нулю все коэффициенты меньше альфа из словаря проекции * X '</target>
        </trans-unit>
        <trans-unit id="d57ea62b7e17ad495e3491babf97d100e18a1702" translate="yes" xml:space="preserve">
          <source>Algorithm used to transform the data: lars: uses the least angle regression method (linear_model.lars_path) lasso_lars: uses Lars to compute the Lasso solution lasso_cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). lasso_lars will be faster if the estimated components are sparse. omp: uses orthogonal matching pursuit to estimate the sparse solution threshold: squashes to zero all coefficients less than alpha from the projection &lt;code&gt;dictionary * X'&lt;/code&gt;</source>
          <target state="translated">Алгоритм, используемый для преобразования данных: lars: использует метод регрессии наименьшего угла (linear_model.lars_path) lasso_lars: использует Lars для вычисления решения лассо lasso_cd: использует метод спуска координат для вычисления решения лассо (linear_model.Lasso). lasso_lars будет быстрее, если предполагаемые компоненты разрежены. omp: использует поиск ортогонального сопоставления для оценки порога разреженного решения: сводит к нулю все коэффициенты меньше альфа из &lt;code&gt;dictionary * X'&lt;/code&gt; проекции * X '</target>
        </trans-unit>
        <trans-unit id="6dd589ff391e3fe9203a6e5ffaf1bc46cb8b74f7" translate="yes" xml:space="preserve">
          <source>Algorithms also differ in how rows and columns may be assigned to biclusters, which leads to different bicluster structures. Block diagonal or checkerboard structures occur when rows and columns are divided into partitions.</source>
          <target state="translated">Алгоритмы также отличаются тем,как строки и столбцы могут быть отнесены к билюстрам,что приводит к различным структурам билюстра.Блок-диагональные или шахматные структуры возникают,когда строки и столбцы разделены на перегородки.</target>
        </trans-unit>
        <trans-unit id="06560884189da8b18b9514c9f15fcee660a6560e" translate="yes" xml:space="preserve">
          <source>Algorithms differ in how they define biclusters. Some of the common types include:</source>
          <target state="translated">Алгоритмы отличаются тем,как они определяют библлюстеры.Некоторые из распространенных типов включают в себя:</target>
        </trans-unit>
        <trans-unit id="f7b4372e3de7ce07bac66d661704328db6f955a4" translate="yes" xml:space="preserve">
          <source>Alias for field number 0</source>
          <target state="translated">Псевдоним для поля номер 0</target>
        </trans-unit>
        <trans-unit id="bbef6b362c3d3509157f18014e4e5a25eb4e07ea" translate="yes" xml:space="preserve">
          <source>Alias for field number 1</source>
          <target state="translated">Псевдоним для поля 1</target>
        </trans-unit>
        <trans-unit id="cb7d09e2006a3aec07c13d82496b6f2adb24a1f7" translate="yes" xml:space="preserve">
          <source>Alias for field number 2</source>
          <target state="translated">Псевдоним для поля 2</target>
        </trans-unit>
        <trans-unit id="2116d748feb69a3af8d3d3f32852bff649bb421e" translate="yes" xml:space="preserve">
          <source>Alias for field number 3</source>
          <target state="translated">Псевдоним для поля 3</target>
        </trans-unit>
        <trans-unit id="8ba0e524b527e040b1c69a39c8c3727540cd8735" translate="yes" xml:space="preserve">
          <source>Alias for field number 4</source>
          <target state="translated">Псевдоним для поля 4</target>
        </trans-unit>
        <trans-unit id="e972f77e5bbab5ce66decc0654515ea9c4cce33b" translate="yes" xml:space="preserve">
          <source>All Gaussian process kernels are interoperable with &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; and vice versa: instances of subclasses of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.kernel#sklearn.gaussian_process.kernels.Kernel&quot;&gt;&lt;code&gt;Kernel&lt;/code&gt;&lt;/a&gt; can be passed as &lt;code&gt;metric&lt;/code&gt; to &lt;code&gt;pairwise_kernels&lt;/code&gt; from &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt;. Moreover, kernel functions from pairwise can be used as GP kernels by using the wrapper class &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.pairwisekernel#sklearn.gaussian_process.kernels.PairwiseKernel&quot;&gt;&lt;code&gt;PairwiseKernel&lt;/code&gt;&lt;/a&gt;. The only caveat is that the gradient of the hyperparameters is not analytic but numeric and all those kernels support only isotropic distances. The parameter &lt;code&gt;gamma&lt;/code&gt; is considered to be a hyperparameter and may be optimized. The other kernel parameters are set directly at initialization and are kept fixed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c99cb316a9285e1cd15f4f7521535d0751148726" translate="yes" xml:space="preserve">
          <source>All Gaussian process kernels are interoperable with &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; and vice versa: instances of subclasses of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.kernel#sklearn.gaussian_process.kernels.Kernel&quot;&gt;&lt;code&gt;Kernel&lt;/code&gt;&lt;/a&gt; can be passed as &lt;code&gt;metric&lt;/code&gt; to pairwise_kernels`` from &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt;. Moreover, kernel functions from pairwise can be used as GP kernels by using the wrapper class &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.pairwisekernel#sklearn.gaussian_process.kernels.PairwiseKernel&quot;&gt;&lt;code&gt;PairwiseKernel&lt;/code&gt;&lt;/a&gt;. The only caveat is that the gradient of the hyperparameters is not analytic but numeric and all those kernels support only isotropic distances. The parameter &lt;code&gt;gamma&lt;/code&gt; is considered to be a hyperparameter and may be optimized. The other kernel parameters are set directly at initialization and are kept fixed.</source>
          <target state="translated">Все ядра гауссовских процессов совместимы с &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; и наоборот: экземпляры подклассов &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.kernel#sklearn.gaussian_process.kernels.Kernel&quot;&gt; &lt;code&gt;Kernel&lt;/code&gt; &lt;/a&gt; могут быть переданы как &lt;code&gt;metric&lt;/code&gt; в &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt; из sklearn.metrics.pairwise . Более того, попарные функции ядра могут использоваться как ядра GP с помощью класса-оболочки &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.pairwisekernel#sklearn.gaussian_process.kernels.PairwiseKernel&quot;&gt; &lt;code&gt;PairwiseKernel&lt;/code&gt; &lt;/a&gt; . Единственное предостережение: градиент гиперпараметров не аналитический, а числовой, и все эти ядра поддерживают только изотропные расстояния. Параметр &lt;code&gt;gamma&lt;/code&gt; считается гиперпараметром и может быть оптимизирован. Остальные параметры ядра устанавливаются непосредственно при инициализации и остаются неизменными.</target>
        </trans-unit>
        <trans-unit id="facb53030a78059078bd7255fa4340b830781f6e" translate="yes" xml:space="preserve">
          <source>All above functions (i.e. &lt;a href=&quot;generated/sklearn.preprocessing.scale#sklearn.preprocessing.scale&quot;&gt;&lt;code&gt;scale&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.minmax_scale#sklearn.preprocessing.minmax_scale&quot;&gt;&lt;code&gt;minmax_scale&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.maxabs_scale#sklearn.preprocessing.maxabs_scale&quot;&gt;&lt;code&gt;maxabs_scale&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt;&lt;code&gt;robust_scale&lt;/code&gt;&lt;/a&gt;) accept 1D array which can be useful in some specific case.</source>
          <target state="translated">Все вышеперечисленные функции (например, &lt;a href=&quot;generated/sklearn.preprocessing.scale#sklearn.preprocessing.scale&quot;&gt; &lt;code&gt;scale&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.preprocessing.minmax_scale#sklearn.preprocessing.minmax_scale&quot;&gt; &lt;code&gt;minmax_scale&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.preprocessing.maxabs_scale#sklearn.preprocessing.maxabs_scale&quot;&gt; &lt;code&gt;maxabs_scale&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt; &lt;code&gt;robust_scale&lt;/code&gt; &lt;/a&gt; ) принимают одномерный массив, который может быть полезен в некоторых конкретных случаях.</target>
        </trans-unit>
        <trans-unit id="e88245fc777e7533587c2f8e718d50cd7116a3f1" translate="yes" xml:space="preserve">
          <source>All available versions</source>
          <target state="translated">Все доступные версии</target>
        </trans-unit>
        <trans-unit id="03af622cdb4aac726985802a2b9d3765c7a41749" translate="yes" xml:space="preserve">
          <source>All bins in each feature have identical widths.</source>
          <target state="translated">Все бункеры в каждой функции имеют одинаковую ширину.</target>
        </trans-unit>
        <trans-unit id="59c634de3245b210109c9f97187eafdfb201b388" translate="yes" xml:space="preserve">
          <source>All bins in each feature have the same number of points.</source>
          <target state="translated">Все бункеры в каждой функции имеют одинаковое количество точек.</target>
        </trans-unit>
        <trans-unit id="8e7d5dca10b34ad961d839250513b9c8a0893f0e" translate="yes" xml:space="preserve">
          <source>All classifiers in scikit-learn do multiclass classification out-of-the-box. You don&amp;rsquo;t need to use the &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module unless you want to experiment with different multiclass strategies.</source>
          <target state="translated">Все классификаторы в scikit-learn делают мультиклассовую классификацию &quot;из коробки&quot;. Вам не нужно использовать модуль &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; ,&lt;/a&gt; если вы не хотите экспериментировать с различными мультиклассовыми стратегиями.</target>
        </trans-unit>
        <trans-unit id="026ccd1f86687bfe3e5f08bd5747feaae826b1dc" translate="yes" xml:space="preserve">
          <source>All classifiers in scikit-learn implement multiclass classification; you only need to use this module if you want to experiment with custom multiclass strategies.</source>
          <target state="translated">Все классификаторы в Scikit-learn реализуют классификацию по нескольким классам;вам нужно использовать этот модуль только в том случае,если вы хотите поэкспериментировать с пользовательскими стратегиями по нескольким классам.</target>
        </trans-unit>
        <trans-unit id="c78fdb80201033cef297ce6fb5232c2383bd7521" translate="yes" xml:space="preserve">
          <source>All decision trees use &lt;code&gt;np.float32&lt;/code&gt; arrays internally. If training data is not in this format, a copy of the dataset will be made.</source>
          <target state="translated">Все деревья &lt;code&gt;np.float32&lt;/code&gt; внутренне используют массивы np.float32 . Если данные обучения не в этом формате, будет сделана копия набора данных.</target>
        </trans-unit>
        <trans-unit id="41b549b6eacc2f621d683cbb4d8d7de1b7ed3ca8" translate="yes" xml:space="preserve">
          <source>All entries of this dict (if any) are passed as keyword arguments to the pairwise kernel function.</source>
          <target state="translated">Все записи этого диктата (если таковые имеются)передаются в качестве аргументов по ключевым словам в функцию парного ядра.</target>
        </trans-unit>
        <trans-unit id="ff969c4b66fd28ef01340faf70c8e905bbf72131" translate="yes" xml:space="preserve">
          <source>All estimator objects expose a &lt;code&gt;fit&lt;/code&gt; method that takes a dataset (usually a 2-d array):</source>
          <target state="translated">Все объекты оценщика предоставляют метод &lt;code&gt;fit&lt;/code&gt; который принимает набор данных (обычно двумерный массив):</target>
        </trans-unit>
        <trans-unit id="8781771bbb6ededabb6ec83fb1b33a34b860476e" translate="yes" xml:space="preserve">
          <source>All estimators in a pipeline, except the last one, must be transformers (i.e. must have a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-transform&quot;&gt;transform&lt;/a&gt; method). The last estimator may be any type (transformer, classifier, etc.).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9616c63898ea085d32d1415c7461f768e275753" translate="yes" xml:space="preserve">
          <source>All estimators in a pipeline, except the last one, must be transformers (i.e. must have a &lt;code&gt;transform&lt;/code&gt; method). The last estimator may be any type (transformer, classifier, etc.).</source>
          <target state="translated">Все оценщики в конвейере, кроме последнего, должны быть преобразователями (т. Е. Должны иметь метод &lt;code&gt;transform&lt;/code&gt; ). Последний оценщик может быть любого типа (преобразователь, классификатор и т. Д.).</target>
        </trans-unit>
        <trans-unit id="7c3fa432791090758c929f832210b21538e1fa2f" translate="yes" xml:space="preserve">
          <source>All estimators in the pipeline must support &lt;code&gt;inverse_transform&lt;/code&gt;.</source>
          <target state="translated">Все оценщики в конвейере должны поддерживать &lt;code&gt;inverse_transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b2ef621d2a7c2b25a3be25bb6ebef0201032958b" translate="yes" xml:space="preserve">
          <source>All estimators should specify all the parameters that can be set at the class level in their &lt;code&gt;__init__&lt;/code&gt; as explicit keyword arguments (no &lt;code&gt;*args&lt;/code&gt; or &lt;code&gt;**kwargs&lt;/code&gt;).</source>
          <target state="translated">Все оценщики должны указывать все параметры, которые могут быть установлены на уровне класса в их &lt;code&gt;__init__&lt;/code&gt; , как явные аргументы ключевого слова (без &lt;code&gt;*args&lt;/code&gt; или &lt;code&gt;**kwargs&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="24e3691f195d78233bed4d7732d29903c7a0bfe6" translate="yes" xml:space="preserve">
          <source>All last five solvers support both dense and sparse data. However, only &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; supports sparse input when &lt;code&gt;fit_intercept&lt;/code&gt; is True.</source>
          <target state="translated">Все последние пять решателей поддерживают как плотные, так и разреженные данные. Однако только sag и saga поддерживают разреженный ввод, когда &lt;code&gt;fit_intercept&lt;/code&gt; имеет значение True.</target>
        </trans-unit>
        <trans-unit id="61f9c2a4b604c0e088d2123f4269900a4c32a338" translate="yes" xml:space="preserve">
          <source>All last five solvers support both dense and sparse data. However, only &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; supports sparse input when`fit_intercept` is True.</source>
          <target state="translated">Все последние пять решателей поддерживают как плотные, так и разреженные данные. Однако только 'sag' и 'saga' поддерживают разреженный ввод, когда'fit_intercept 'имеет значение True.</target>
        </trans-unit>
        <trans-unit id="f728f573fb469cf76a885b25e7cd8d2d6661b65d" translate="yes" xml:space="preserve">
          <source>All last five solvers support both dense and sparse data. However, only &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;sparse_cg&amp;rsquo; supports sparse input when &lt;code&gt;fit_intercept&lt;/code&gt; is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b477d9d300bf316e6d73adbb21d261c724739c5" translate="yes" xml:space="preserve">
          <source>All of X is processed as a single batch. This is intended for cases when &lt;a href=&quot;#sklearn.preprocessing.MaxAbsScaler.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3fc8e75fa02a8bfaeaedb8d116922428a0fe800" translate="yes" xml:space="preserve">
          <source>All of X is processed as a single batch. This is intended for cases when &lt;a href=&quot;#sklearn.preprocessing.MinMaxScaler.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0771ca4e648606c13a5db59d2963430f3dd6f313" translate="yes" xml:space="preserve">
          <source>All of X is processed as a single batch. This is intended for cases when &lt;a href=&quot;#sklearn.preprocessing.StandardScaler.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e879aa8d08a0dbe80a902ae3611f1bc99c99eb6" translate="yes" xml:space="preserve">
          <source>All of the above are supported by &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe669fffadfc5710970ab03a9fde631f4966ca91" translate="yes" xml:space="preserve">
          <source>All of the above are supported by &lt;code&gt;sklearn.linear_model.stochastic_gradient&lt;/code&gt;.</source>
          <target state="translated">Все вышеперечисленное поддерживается &lt;code&gt;sklearn.linear_model.stochastic_gradient&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b5ed2e5e9ebf405638935350a19afaab363efb49" translate="yes" xml:space="preserve">
          <source>All of the above loss functions can be regarded as an upper bound on the misclassification error (Zero-one loss) as shown in the Figure below.</source>
          <target state="translated">Все вышеперечисленные функции потерь можно рассматривать как верхнюю границу ошибки неправильной классификации (Zero-one loss),как показано на рисунке ниже.</target>
        </trans-unit>
        <trans-unit id="0050a0a20cce6934eea13e5fb5f70c03d8a3e6cd" translate="yes" xml:space="preserve">
          <source>All penalization parameters explored.</source>
          <target state="translated">Изучены все параметры пенализации.</target>
        </trans-unit>
        <trans-unit id="955d9d437b529cc06e590b033bee6c6f48038cb1" translate="yes" xml:space="preserve">
          <source>All scikit-learn classifiers are capable of multiclass classification, but the meta-estimators offered by &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; permit changing the way they handle more than two classes because this may have an effect on classifier performance (either in terms of generalization error or required computational resources).</source>
          <target state="translated">Все классификаторы scikit-learn поддерживают мультиклассовую классификацию, но метаоценки, предлагаемые &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; ,&lt;/a&gt; позволяют изменять способ обработки более двух классов, поскольку это может повлиять на производительность классификатора (либо с точки зрения ошибки обобщения, либо с точки зрения требуемых вычислительных ресурсов). Ресурсы).</target>
        </trans-unit>
        <trans-unit id="196b45b70e9cf2661d4f75a2029c5a0c8898e090" translate="yes" xml:space="preserve">
          <source>All settings, not just those presently modified, will be returned to their previous values when the context manager is exited. This is not thread-safe.</source>
          <target state="translated">При выходе из контекстного менеджера все настройки,а не только те,которые были изменены в данный момент,будут возвращены к своим предыдущим значениям.Это не является потокобезопасным.</target>
        </trans-unit>
        <trans-unit id="aa66fd6d2b23c29862eb90bc96dba9c2ff577f39" translate="yes" xml:space="preserve">
          <source>All supervised &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimators&lt;/a&gt; in scikit-learn implement a &lt;code&gt;fit(X, y)&lt;/code&gt; method to fit the model and a &lt;code&gt;predict(X)&lt;/code&gt; method that, given unlabeled observations &lt;code&gt;X&lt;/code&gt;, returns the predicted labels &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">Все контролируемые &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;оценщики&lt;/a&gt; в scikit-learn реализуют метод &lt;code&gt;fit(X, y)&lt;/code&gt; чтобы соответствовать модели, и метод &lt;code&gt;predict(X)&lt;/code&gt; который, учитывая немаркированные наблюдения &lt;code&gt;X&lt;/code&gt; , возвращает прогнозируемые метки &lt;code&gt;y&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5fd3433668568da7d84a79ee4e0518a15dd72a27" translate="yes" xml:space="preserve">
          <source>All the input data is provided matrix X (labeled and unlabeled) and corresponding label matrix y with a dedicated marker value for unlabeled samples.</source>
          <target state="translated">Все входные данные представлены матрицей X (помеченные и не помеченные)и соответствующей матрицей этикеток y со специальным значением маркера для не помеченных образцов.</target>
        </trans-unit>
        <trans-unit id="799926dcab2e28e1fbc27d0dc0ec06e58ac91465" translate="yes" xml:space="preserve">
          <source>All these estimators can compute internally the nearest neighbors, but most of them also accept precomputed nearest neighbors &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;sparse graph&lt;/a&gt;, as given by &lt;a href=&quot;generated/sklearn.neighbors.kneighbors_graph#sklearn.neighbors.kneighbors_graph&quot;&gt;&lt;code&gt;kneighbors_graph&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.radius_neighbors_graph#sklearn.neighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;radius_neighbors_graph&lt;/code&gt;&lt;/a&gt;. With mode &lt;code&gt;mode='connectivity'&lt;/code&gt;, these functions return a binary adjacency sparse graph as required, for instance, in &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt;. Whereas with &lt;code&gt;mode='distance'&lt;/code&gt;, they return a distance sparse graph as required, for instance, in &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt;. To include these functions in a scikit-learn pipeline, one can also use the corresponding classes &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborstransformer#sklearn.neighbors.RadiusNeighborsTransformer&quot;&gt;&lt;code&gt;RadiusNeighborsTransformer&lt;/code&gt;&lt;/a&gt;. The benefits of this sparse graph API are multiple.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3103275737fc127cec8d65804a5477574232497" translate="yes" xml:space="preserve">
          <source>All three models are significantly better than chance but also very far from making perfect predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68201d9ddadd1b10424b1028599271aea0a81e03" translate="yes" xml:space="preserve">
          <source>All values are cached on the filesystem, in a deep directory structure.</source>
          <target state="translated">Все значения кэшируются в файловой системе,в глубокой структуре каталогов.</target>
        </trans-unit>
        <trans-unit id="ad92361405543cadf3390872502b0368070801b1" translate="yes" xml:space="preserve">
          <source>All, &lt;a href=&quot;generated/sklearn.metrics.mutual_info_score#sklearn.metrics.mutual_info_score&quot;&gt;&lt;code&gt;mutual_info_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt;&lt;code&gt;adjusted_mutual_info_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; are symmetric: swapping the argument does not change the score. Thus they can be used as a &lt;strong&gt;consensus measure&lt;/strong&gt;:</source>
          <target state="translated">Все, &lt;a href=&quot;generated/sklearn.metrics.mutual_info_score#sklearn.metrics.mutual_info_score&quot;&gt; &lt;code&gt;mutual_info_score&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt; &lt;code&gt;adjusted_mutual_info_score&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt; симметричны: замена аргумент не меняет рейтинг. Таким образом, их можно использовать в качестве &lt;strong&gt;меры консенсуса&lt;/strong&gt; :</target>
        </trans-unit>
        <trans-unit id="9cc3cbd54e82f76756e09725006efed713dfb14b" translate="yes" xml:space="preserve">
          <source>Allow to bypass several input checking. Don&amp;rsquo;t use this parameter unless you know what you do.</source>
          <target state="translated">Позволяет обойти проверку нескольких входов. Не используйте этот параметр, если не знаете, что делаете.</target>
        </trans-unit>
        <trans-unit id="b2988d20e10f74030eeb38e913a183de75189dbb" translate="yes" xml:space="preserve">
          <source>Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.</source>
          <target state="translated">Разрешенные входные данные-это списки,нумерованные массивы,научно-разрозненные матрицы или кадры данных панд.</target>
        </trans-unit>
        <trans-unit id="246073e83f7bacaf2b27a7cb44f4ce78f91064b5" translate="yes" xml:space="preserve">
          <source>Allows NaN in the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d1bd9e91706d2b4396d936c8102ad0f0e779fcd" translate="yes" xml:space="preserve">
          <source>Allows NaN/Inf in the input if the underlying estimator does as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b369263cc488ea5fca6946112c8afe7517b680b5" translate="yes" xml:space="preserve">
          <source>Allows simple indexing of lists or arrays.</source>
          <target state="translated">Позволяет легко индексировать списки или массивы.</target>
        </trans-unit>
        <trans-unit id="bd0b505b007b0a8de2703b572d4c9c27c39f3415" translate="yes" xml:space="preserve">
          <source>Allows to examine the spread of each true cluster across predicted clusters and vice versa.</source>
          <target state="translated">Позволяет исследовать распространение каждого истинного кластера по прогнозируемым кластерам и наоборот.</target>
        </trans-unit>
        <trans-unit id="036fd67d51f9b182736132cac7fb44d0406f98ef" translate="yes" xml:space="preserve">
          <source>Almost every group is distinguished by whether headers such as &lt;code&gt;NNTP-Posting-Host:&lt;/code&gt; and &lt;code&gt;Distribution:&lt;/code&gt; appear more or less often.</source>
          <target state="translated">Практически каждая группа отличается тем, что заголовки, такие как &lt;code&gt;NNTP-Posting-Host:&lt;/code&gt; и &lt;code&gt;Distribution:&lt;/code&gt; , появляются чаще или реже.</target>
        </trans-unit>
        <trans-unit id="54076ee073b95c8e2227a7529bbd3c040278da4f" translate="yes" xml:space="preserve">
          <source>Alpaydin (alpaydin &amp;lsquo;@&amp;rsquo; boun.edu.tr)</source>
          <target state="translated">Алпайдин (alpaydin '@' boun.edu.tr)</target>
        </trans-unit>
        <trans-unit id="78d537ced7a0f9450c0b7f5b446829da6458dfc9" translate="yes" xml:space="preserve">
          <source>Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.</source>
          <target state="translated">Альпайдин,К.Кайнак (1998)Каскадные классификаторы,Кибернетика.</target>
        </trans-unit>
        <trans-unit id="bc0f2eb3e0375e2eb0ff510eb47611a2b3ce02af" translate="yes" xml:space="preserve">
          <source>Alpha is a parameter for regularization term, aka penalty term, that combats overfitting by constraining the size of the weights. Increasing alpha may fix high variance (a sign of overfitting) by encouraging smaller weights, resulting in a decision boundary plot that appears with lesser curvatures. Similarly, decreasing alpha may fix high bias (a sign of underfitting) by encouraging larger weights, potentially resulting in a more complicated decision boundary.</source>
          <target state="translated">Альфа-это параметр для термина регуляризации,так же известный как штрафной термин,который борется с переподготовкой,ограничивая размер весов.Увеличение альфа может исправить высокую дисперсию (признак переподготовки),поощряя меньшие веса,в результате чего появляется граничный график решения с меньшими кривизнами.Аналогичным образом,уменьшение альфа может исправить большое смещение (признак недостаточной эластичности),поощряя большие веса,что может привести к более сложной границе решения.</target>
        </trans-unit>
        <trans-unit id="a01b7375f883c68c86f4064f9c436e0a18c14d5d" translate="yes" xml:space="preserve">
          <source>Alpha is again treated as a random variable that is to be estimated from the data.</source>
          <target state="translated">Альфа снова рассматривается как случайная переменная,которая должна быть оценена по данным.</target>
        </trans-unit>
        <trans-unit id="9bc4ba22610a89d08abe53892ec649b1e8a46ce9" translate="yes" xml:space="preserve">
          <source>Also for multiple metric evaluation, the attributes &lt;code&gt;best_index_&lt;/code&gt;, &lt;code&gt;best_score_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will only be available if &lt;code&gt;refit&lt;/code&gt; is set and all of them will be determined w.r.t this specific scorer.</source>
          <target state="translated">Также для оценки множественных показателей атрибуты &lt;code&gt;best_index_&lt;/code&gt; , &lt;code&gt;best_score_&lt;/code&gt; и &lt;code&gt;best_params_&lt;/code&gt; будут доступны только в том случае, если установлено &lt;code&gt;refit&lt;/code&gt; и все они будут определяться конкретным счетчиком.</target>
        </trans-unit>
        <trans-unit id="7c913c796a2efc191b66ad3c6a4c672e085ca88e" translate="yes" xml:space="preserve">
          <source>Also from the thickness of the silhouette plot the cluster size can be visualized. The silhouette plot for cluster 0 when &lt;code&gt;n_clusters&lt;/code&gt; is equal to 2, is bigger in size owing to the grouping of the 3 sub clusters into one big cluster. However when the &lt;code&gt;n_clusters&lt;/code&gt; is equal to 4, all the plots are more or less of similar thickness and hence are of similar sizes as can be also verified from the labelled scatter plot on the right.</source>
          <target state="translated">Также по толщине силуэтного графика можно визуализировать размер кластера. График силуэта для кластера 0, когда &lt;code&gt;n_clusters&lt;/code&gt; равно 2, больше по размеру из-за группировки 3 субкластеров в один большой кластер. Однако, когда &lt;code&gt;n_clusters&lt;/code&gt; равно 4, все графики имеют более или менее одинаковую толщину и, следовательно, имеют аналогичные размеры, что также можно проверить на помеченном графике разброса справа.</target>
        </trans-unit>
        <trans-unit id="11074bab0d4cf60477f10f484031e0877ac22e6b" translate="yes" xml:space="preserve">
          <source>Also known as one-vs-all, this strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for multiclass classification and is a fair default choice.</source>
          <target state="translated">Эта стратегия, также известная как &amp;laquo;один против всех&amp;raquo;, заключается в подборе одного классификатора для каждого класса. Для каждого классификатора класс сопоставляется со всеми другими классами. В дополнение к его вычислительной эффективности (необходимы только классификаторы &lt;code&gt;n_classes&lt;/code&gt; ), одним из преимуществ этого подхода является его интерпретируемость. Поскольку каждый класс представлен только одним и одним классификатором, можно получить информацию о классе, проверив соответствующий классификатор. Это наиболее часто используемая стратегия для мультиклассовой классификации и справедливый выбор по умолчанию.</target>
        </trans-unit>
        <trans-unit id="cc34e41c8fa23138f4c5476496b3bc4a71c58fb4" translate="yes" xml:space="preserve">
          <source>Also note that both random features have very low importances (close to 0) as expected.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f4d07ff4d50db829057964fee42d298814f3483" translate="yes" xml:space="preserve">
          <source>Also note that even though Box-Cox seems to perform better than Yeo-Johnson for lognormal and chi-squared distributions, keep in mind that Box-Cox does not support inputs with negative values.</source>
          <target state="translated">Также обратите внимание,что хотя Box-Cox,кажется,работает лучше,чем Yeo-Johnson для логнормальных и хи-квадратичных распределений,имейте в виду,что Box-Cox не поддерживает входы с отрицательными значениями.</target>
        </trans-unit>
        <trans-unit id="0af9b79bdfeacc61c23bfadd6f95c644ff726db7" translate="yes" xml:space="preserve">
          <source>Also note that for the linear case, the algorithm used in &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; by the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; implementation is much more efficient than its &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; counterpart and can scale almost linearly to millions of samples and/or features.</source>
          <target state="translated">Также отметим , что для линейного случая, алгоритм , используемый в &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; по &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; реализации является гораздо более эффективным , чем его &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; -На &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; аналог и может масштабироваться почти линейно миллионов образцов и / или функций.</target>
        </trans-unit>
        <trans-unit id="5de10864fc42a72508361320516be4ba6cf282ee" translate="yes" xml:space="preserve">
          <source>Also note that the digits labels roughly match the natural grouping found by t-SNE while the linear 2D projection of the PCA model yields a representation where label regions largely overlap. This is a strong clue that this data can be well separated by non linear methods that focus on the local structure (e.g. an SVM with a Gaussian RBF kernel). However, failing to visualize well separated homogeneously labeled groups with t-SNE in 2D does not necessarily imply that the data cannot be correctly classified by a supervised model. It might be the case that 2 dimensions are not low enough to accurately represents the internal structure of the data.</source>
          <target state="translated">Отметим также,что цифровые метки примерно соответствуют естественной группировке,найденной t-SNE,в то время как линейная 2D проекция модели PCA дает представление,где области метки в значительной степени пересекаются.Это является сильным аргументом в пользу того,что эти данные могут быть хорошо разделены нелинейными методами,которые фокусируются на локальной структуре (например,SVM с гауссовым ядром RBF).Однако отсутствие визуализации хорошо разделенных однородно обозначенных групп с t-SNE в 2D не обязательно означает,что данные не могут быть правильно классифицированы контролируемой моделью.Может случиться так,что 2 измерения не будут достаточно низкими,чтобы точно представить внутреннюю структуру данных.</target>
        </trans-unit>
        <trans-unit id="ab26a7a4f86bc166b4ac9642686ddf7141b2b207" translate="yes" xml:space="preserve">
          <source>Also note that we set a low value for the tolerance to make sure that the model has converged before collecting the coefficients.</source>
          <target state="translated">Также обратите внимание,что мы устанавливаем низкое значение для допуска,чтобы убедиться,что модель сошлась до сбора коэффициентов.</target>
        </trans-unit>
        <trans-unit id="7d37adf37d9aef6924cdccc898bbb4ca10bb0758" translate="yes" xml:space="preserve">
          <source>Also useful for lower-level tasks is the function &lt;a href=&quot;generated/sklearn.linear_model.lasso_path#sklearn.linear_model.lasso_path&quot;&gt;&lt;code&gt;lasso_path&lt;/code&gt;&lt;/a&gt; that computes the coefficients along the full path of possible values.</source>
          <target state="translated">Также для задач нижнего уровня полезна функция &lt;a href=&quot;generated/sklearn.linear_model.lasso_path#sklearn.linear_model.lasso_path&quot;&gt; &lt;code&gt;lasso_path&lt;/code&gt; ,&lt;/a&gt; которая вычисляет коэффициенты по всему пути возможных значений.</target>
        </trans-unit>
        <trans-unit id="2587ad1f75524017fb1ecdf6376d89726a0f6825" translate="yes" xml:space="preserve">
          <source>Also, by evaluating log marginal likelihood (L) of these models, we can determine which one is better. It can be concluded that the model with larger L is more likely.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b5de16e36a8364053840b53f5f6fe23ce35a1bc" translate="yes" xml:space="preserve">
          <source>Also, the EXPERIENCE and AGE are strongly linearly correlated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a2b5f07f08a470a2b2e7ef1ae5a0e4e195af3e0" translate="yes" xml:space="preserve">
          <source>Also, these routines have not been tested for graphs with negative distances. Negative distances can lead to infinite cycles that must be handled by specialized algorithms.</source>
          <target state="translated">Кроме того,эти подпрограммы не были протестированы для графиков с отрицательными расстояниями.Отрицательные расстояния могут привести к бесконечным циклам,которые должны обрабатываться специализированными алгоритмами.</target>
        </trans-unit>
        <trans-unit id="9ba49a974ea195b74ff8d485a45574a6c2262ea1" translate="yes" xml:space="preserve">
          <source>Also, this estimator is different from the R implementation of Robust Regression (&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;) because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.</source>
          <target state="translated">Кроме того, эта оценка отличается от реализации робастной регрессии R ( &lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt; ), потому что реализация R выполняет взвешенную реализацию методом наименьших квадратов с весами, присвоенными каждую выборку на основе того, насколько остаток превышает определенный порог.</target>
        </trans-unit>
        <trans-unit id="8c3843c6d1de204ea6ff77660712728c7734da35" translate="yes" xml:space="preserve">
          <source>Alternate label propagation strategy more robust to noise</source>
          <target state="translated">Альтернативная стратегия распространения этикетки более устойчива к шуму</target>
        </trans-unit>
        <trans-unit id="a1df7e48a8694bc511c33f4fdb83c6299c349bb3" translate="yes" xml:space="preserve">
          <source>Alternate output array in which to place the result. The default is &lt;code&gt;None&lt;/code&gt;; if provided, it must have the same shape as the expected output, but the type will be cast if necessary. See &lt;code&gt;doc.ufuncs&lt;/code&gt; for details.</source>
          <target state="translated">Альтернативный выходной массив, в который помещается результат. По умолчанию - &lt;code&gt;None&lt;/code&gt; ; если предоставлен, он должен иметь ту же форму, что и ожидаемый результат, но при необходимости тип будет приведен. Подробнее см. &lt;code&gt;doc.ufuncs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1444a36563243cd516125e47e643f6c86af2b2d3" translate="yes" xml:space="preserve">
          <source>Alternating Least Squares (Fast HALS).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16e8b22da1997a9e7a46f4b2f3065cb731917af6" translate="yes" xml:space="preserve">
          <source>Alternative implementation that does incremental updates of the centers&amp;rsquo; positions using mini-batches.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9319ffecfc2401bba3b77152ec4f1cf3bfc1dbce" translate="yes" xml:space="preserve">
          <source>Alternative online implementation that does incremental updates of the centers positions using mini-batches. For large scale learning (say n_samples &amp;gt; 10k) MiniBatchKMeans is probably much faster than the default batch implementation.</source>
          <target state="translated">Альтернативная онлайн-реализация, которая выполняет инкрементное обновление позиций центров с помощью мини-пакетов. Для крупномасштабного обучения (скажем, n_samples&amp;gt; 10k) MiniBatchKMeans, вероятно, намного быстрее, чем пакетная реализация по умолчанию.</target>
        </trans-unit>
        <trans-unit id="203de1a7976ebc427fc76b372cb16da457115e31" translate="yes" xml:space="preserve">
          <source>Alternatively binaries for graphviz can be downloaded from the graphviz project homepage, and the Python wrapper installed from pypi with &lt;code&gt;pip install graphviz&lt;/code&gt;.</source>
          <target state="translated">В качестве альтернативы двоичные файлы для graphviz можно загрузить с домашней страницы проекта graphviz, а оболочку Python установить из pypi с помощью &lt;code&gt;pip install graphviz&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a86f6ee74cd1a30708099bd1d22a36b2f08e9a0f" translate="yes" xml:space="preserve">
          <source>Alternatively the backend can be passed directly as an instance.</source>
          <target state="translated">Или же бэкэнд может быть передан непосредственно в качестве экземпляра.</target>
        </trans-unit>
        <trans-unit id="76c8a1ac67e02525fd024c6509339aad00aeced5" translate="yes" xml:space="preserve">
          <source>Alternatively, it can be set by the &amp;lsquo;SCIKIT_LEARN_DATA&amp;rsquo; environment variable or programmatically by giving an explicit folder path. The &amp;lsquo;~&amp;rsquo; symbol is expanded to the user home folder.</source>
          <target state="translated">В качестве альтернативы его можно установить с помощью переменной среды SCIKIT_LEARN_DATA или программно, указав явный путь к папке. Символ &amp;laquo;~&amp;raquo; заменяется на домашнюю папку пользователя.</target>
        </trans-unit>
        <trans-unit id="adf895b415f65b1116cbe9c2579f72b5380f5476" translate="yes" xml:space="preserve">
          <source>Alternatively, one can directly model the total loss with a unique Compound Poisson Gamma generalized linear model (with a log link function). This model is a special case of the Tweedie GLM with a &amp;ldquo;power&amp;rdquo; parameter \(p \in (1, 2)\). Here, we fix apriori the &lt;code&gt;power&lt;/code&gt; parameter of the Tweedie model to some arbitrary value (1.9) in the valid range. Ideally one would select this value via grid-search by minimizing the negative log-likelihood of the Tweedie model, but unfortunately the current implementation does not allow for this (yet).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd953719fa9152bd6124ae49c16c66b8c780a34" translate="yes" xml:space="preserve">
          <source>Alternatively, one can use the &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; classes directly to find nearest neighbors. This is the functionality wrapped by the &lt;a href=&quot;generated/sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors&quot;&gt;&lt;code&gt;NearestNeighbors&lt;/code&gt;&lt;/a&gt; class used above. The Ball Tree and KD Tree have the same interface; we&amp;rsquo;ll show an example of using the KD Tree here:</source>
          <target state="translated">В качестве альтернативы можно &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; классы KDTree или BallTree для поиска ближайших соседей. Это функциональность, заключенная в класс &lt;a href=&quot;generated/sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors&quot;&gt; &lt;code&gt;NearestNeighbors&lt;/code&gt; ,&lt;/a&gt; использованный выше. Ball Tree и KD Tree имеют одинаковый интерфейс; мы покажем здесь пример использования KD Tree:</target>
        </trans-unit>
        <trans-unit id="a2b3bf63690d9fdf9c988aa4c9e184e0fbef9897" translate="yes" xml:space="preserve">
          <source>Alternatively, orthogonal matching pursuit can target a specific error instead of a specific number of non-zero coefficients. This can be expressed as:</source>
          <target state="translated">В качестве альтернативы,поиск ортогонального соответствия может быть направлен на конкретную ошибку,а не на определенное количество ненулевых коэффициентов.Это может быть выражено как:</target>
        </trans-unit>
        <trans-unit id="0f7ec2ff37de8d3d768baf118074df7d6149a11f" translate="yes" xml:space="preserve">
          <source>Alternatively, the &lt;code&gt;scoring&lt;/code&gt; argument can be provided to specify an alternative scoring method.</source>
          <target state="translated">В качестве альтернативы можно предоставить аргумент &lt;code&gt;scoring&lt;/code&gt; чтобы указать альтернативный метод оценки.</target>
        </trans-unit>
        <trans-unit id="ea61f1eddfe969d509258a2bd8bcd0672a722400" translate="yes" xml:space="preserve">
          <source>Alternatively, the estimator &lt;a href=&quot;generated/sklearn.linear_model.lassolarsic#sklearn.linear_model.LassoLarsIC&quot;&gt;&lt;code&gt;LassoLarsIC&lt;/code&gt;&lt;/a&gt; proposes to use the Akaike information criterion (AIC) and the Bayes Information criterion (BIC). It is a computationally cheaper alternative to find the optimal value of alpha as the regularization path is computed only once instead of k+1 times when using k-fold cross-validation. However, such criteria needs a proper estimation of the degrees of freedom of the solution, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">В качестве альтернативы оценщик &lt;a href=&quot;generated/sklearn.linear_model.lassolarsic#sklearn.linear_model.LassoLarsIC&quot;&gt; &lt;code&gt;LassoLarsIC&lt;/code&gt; &lt;/a&gt; предлагает использовать информационный критерий Акаике (AIC) и информационный критерий Байеса (BIC). Это более дешевая в вычислительном отношении альтернатива нахождению оптимального значения альфа, поскольку путь регуляризации вычисляется только один раз вместо k + 1 раз при использовании k-кратной перекрестной проверки. Однако такие критерии требуют надлежащей оценки степеней свободы решения, выводятся для больших выборок (асимптотические результаты) и предполагают, что модель верна, т.е. что данные фактически генерируются этой моделью. Они также имеют тенденцию ломаться, когда проблема плохо обусловлена ​​(больше функций, чем образцов).</target>
        </trans-unit>
        <trans-unit id="f454663104fe93624afb99e1fe4ea6ef9bcd01cf" translate="yes" xml:space="preserve">
          <source>Alternatively, the probability of each class can be predicted, which is the fraction of training samples of the same class in a leaf:</source>
          <target state="translated">В качестве альтернативы можно предсказать вероятность каждого класса,что является долей обучающих образцов одного и того же класса в листе:</target>
        </trans-unit>
        <trans-unit id="5c74d35687e3587d17adc94ee7b35af54787e26a" translate="yes" xml:space="preserve">
          <source>Alternatively, the tree can also be exported in textual format with the function &lt;a href=&quot;generated/sklearn.tree.export_text#sklearn.tree.export_text&quot;&gt;&lt;code&gt;export_text&lt;/code&gt;&lt;/a&gt;. This method doesn&amp;rsquo;t require the installation of external libraries and is more compact:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d7768459c8a27625c6b1edd47cdb7cdd42a8dbd" translate="yes" xml:space="preserve">
          <source>Alternatively, using &lt;code&gt;precomputed&lt;/code&gt;, a user-provided affinity matrix can be used.</source>
          <target state="translated">В качестве альтернативы можно использовать &lt;code&gt;precomputed&lt;/code&gt; вычисленную матрицу аффинности, предоставленную пользователем.</target>
        </trans-unit>
        <trans-unit id="408564450de584fdcd4c6ffe287273935ea61be3" translate="yes" xml:space="preserve">
          <source>Alternatively, you can control the tree size by specifying the number of leaf nodes via the parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt;. In this case, trees will be grown using best-first search where nodes with the highest improvement in impurity will be expanded first. A tree with &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; has &lt;code&gt;k - 1&lt;/code&gt; split nodes and thus can model interactions of up to order &lt;code&gt;max_leaf_nodes - 1&lt;/code&gt; .</source>
          <target state="translated">В качестве альтернативы вы можете управлять размером дерева, указав количество &lt;code&gt;max_leaf_nodes&lt;/code&gt; узлов с помощью параметра max_leaf_nodes . В этом случае деревья будут расти с использованием поиска по первому наилучшему, при этом узлы с наибольшим улучшением примеси будут расширены первыми. Дерево с &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; имеет &lt;code&gt;k - 1&lt;/code&gt; разделенных узлов и, таким образом, может моделировать взаимодействия вплоть до &lt;code&gt;max_leaf_nodes - 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9d8e5a012d3af6b5916c5e0e392c2cf43112fb2f" translate="yes" xml:space="preserve">
          <source>Although GMM are often used for clustering, we can compare the obtained clusters with the actual classes from the dataset. We initialize the means of the Gaussians with the means of the classes from the training set to make this comparison valid.</source>
          <target state="translated">Хотя GMM часто используется для кластеризации,мы можем сравнить полученные кластеры с реальными классами из набора данных.Мы инициализируем средства гаусси с помощью средств классов из обучающего набора,чтобы сделать это сравнение корректным.</target>
        </trans-unit>
        <trans-unit id="9e3f75157b99771eea902cdfb247d8150fcbbb65" translate="yes" xml:space="preserve">
          <source>Although a list of sets or tuples is a very intuitive format for multilabel data, it is unwieldy to process. This transformer converts between this intuitive format and the supported multilabel format: a (samples x classes) binary matrix indicating the presence of a class label.</source>
          <target state="translated">Хотя список множеств или кортежей является очень интуитивным форматом для многомаркировочных данных,его трудно обрабатывать.Этот трансформатор преобразует между этим интуитивным форматом и поддерживаемым многомаркировочным форматом:двоичная матрица (примеры х классов),указывающая на наличие метки класса.</target>
        </trans-unit>
        <trans-unit id="6b97831f2bf852269cd56a6950af72a787322f90" translate="yes" xml:space="preserve">
          <source>Although online method is guaranteed to converge to a local optimum point, the quality of the optimum point and the speed of convergence may depend on mini-batch size and attributes related to learning rate setting.</source>
          <target state="translated">Хотя онлайн-метод гарантированно сходится в локальной оптимальной точке,качество оптимальной точки и скорость сходимости могут зависеть от размера мини-пачек и атрибутов,связанных с настройкой скорости обучения.</target>
        </trans-unit>
        <trans-unit id="be1a3f200b8c31300cb53ca0638c27940f9fd773" translate="yes" xml:space="preserve">
          <source>Although the online method is guaranteed to converge to a local optimum point, the quality of the optimum point and the speed of convergence may depend on mini-batch size and attributes related to learning rate setting.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b824f979746fff21942ed5a8526c30831b67aa67" translate="yes" xml:space="preserve">
          <source>Always ignored, exists for compatibility.</source>
          <target state="translated">Всегда игнорируется,существует для совместимости.</target>
        </trans-unit>
        <trans-unit id="f671e33354d7ef61d0b19d9b0bec50200bf9529c" translate="yes" xml:space="preserve">
          <source>Always ignored, exists for compatibility. &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder.</source>
          <target state="translated">Всегда игнорируется, существует для совместимости. &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; может использоваться как заполнитель.</target>
        </trans-unit>
        <trans-unit id="86f5a3adc76607b6ec083bd7a2c05aeeca017cf3" translate="yes" xml:space="preserve">
          <source>Amount of ridge shrinkage to apply in order to improve conditioning when calling the transform method.</source>
          <target state="translated">Величина усадки гребня,применяемая для улучшения кондиционирования при вызове метода преобразования.</target>
        </trans-unit>
        <trans-unit id="a7500e59c81a09edaea684ef869962960b125989" translate="yes" xml:space="preserve">
          <source>Amount of ridge shrinkage to apply in order to improve conditioning.</source>
          <target state="translated">Количество усадки коньков для применения в целях улучшения кондиционирования.</target>
        </trans-unit>
        <trans-unit id="a93d54da303ddad51202c963e4858505c997f8d0" translate="yes" xml:space="preserve">
          <source>Amount of verbosity.</source>
          <target state="translated">Количество глаголов.</target>
        </trans-unit>
        <trans-unit id="40cf2c52a2e789ddb84ca29dcc3ddee6f4122f49" translate="yes" xml:space="preserve">
          <source>An AdaBoost [1] classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.</source>
          <target state="translated">Классификатор AdaBoost [1]является метаоценкой,которая начинается с установки классификатора на исходный набор данных,а затем подгоняется к дополнительным копиям классификатора на том же наборе данных,но когда вес неправильно классифицированных экземпляров корректируется таким образом,чтобы последующие классификаторы больше внимания уделяли трудным случаям.</target>
        </trans-unit>
        <trans-unit id="043d85ce90b3af29bb38c14a359edb987b27e86d" translate="yes" xml:space="preserve">
          <source>An AdaBoost [1] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.</source>
          <target state="translated">AdaBoost [1]регрессор-это мета-оценщик,который начинает с установки регрессора на исходный набор данных,а затем устанавливает дополнительные копии регрессора на тот же набор данных,но где весы экземпляров корректируются в соответствии с ошибкой текущего прогноза.Таким образом,последующие регрессоры больше внимания уделяют сложным случаям.</target>
        </trans-unit>
        <trans-unit id="a0726965169fa1a924e6755570036e923d55d00c" translate="yes" xml:space="preserve">
          <source>An AdaBoost classifier.</source>
          <target state="translated">Классификатор АдаБуст.</target>
        </trans-unit>
        <trans-unit id="3388a3be3246d31996f2f786da9e288b6011901a" translate="yes" xml:space="preserve">
          <source>An AdaBoost regressor that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f161ccb66d6dfc0409a9a54a8f62d08c472ddf6" translate="yes" xml:space="preserve">
          <source>An AdaBoost regressor.</source>
          <target state="translated">Регрессор АдаБуст.</target>
        </trans-unit>
        <trans-unit id="6356fae027d92d258a26309d7a3f256df2c9cc55" translate="yes" xml:space="preserve">
          <source>An Exception object.</source>
          <target state="translated">Объект Исключения.</target>
        </trans-unit>
        <trans-unit id="91b401262ec54e41ccc28fc97e3dca77764edee1" translate="yes" xml:space="preserve">
          <source>An already fitted classifier can be calibrated by setting &lt;code&gt;cv=&quot;prefit&quot;&lt;/code&gt;. In this case, the data is only used to fit the regressor. It is up to the user make sure that the data used for fitting the classifier is disjoint from the data used for fitting the regressor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96b2243b1ac08495762e9c93f82c1e26829c8a97" translate="yes" xml:space="preserve">
          <source>An alternative and recommended approach is to use &lt;code&gt;StandardScaler&lt;/code&gt; in a &lt;code&gt;Pipeline&lt;/code&gt;</source>
          <target state="translated">Альтернативный и рекомендуемый подход - использовать &lt;code&gt;StandardScaler&lt;/code&gt; в &lt;code&gt;Pipeline&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6bcd8e2a5d780cc52692b09904c485c359805e94" translate="yes" xml:space="preserve">
          <source>An alternative standardization is scaling features to lie between a given minimum and maximum value, often between zero and one, or so that the maximum absolute value of each feature is scaled to unit size. This can be achieved using &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;MinMaxScaler&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.preprocessing.maxabsscaler#sklearn.preprocessing.MaxAbsScaler&quot;&gt;&lt;code&gt;MaxAbsScaler&lt;/code&gt;&lt;/a&gt;, respectively.</source>
          <target state="translated">Альтернативная стандартизация - это масштабирование функций так, чтобы они находились между заданным минимальным и максимальным значением, часто между нулем и единицей, или так, чтобы максимальное абсолютное значение каждой функции было масштабировано до размера единицы. Этого можно добиться с помощью &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;MinMaxScaler&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;generated/sklearn.preprocessing.maxabsscaler#sklearn.preprocessing.MaxAbsScaler&quot;&gt; &lt;code&gt;MaxAbsScaler&lt;/code&gt; &lt;/a&gt; соответственно.</target>
        </trans-unit>
        <trans-unit id="dc1db7ec650725e3eb3f215f1e02c7a5ab5d599a" translate="yes" xml:space="preserve">
          <source>An alternative task, Face Recognition or Face Identification is: given the picture of the face of an unknown person, identify the name of the person by referring to a gallery of previously seen pictures of identified persons.</source>
          <target state="translated">Альтернативное задание-распознавание лица или идентификация лица-заключается в том,чтобы по фотографии лица неизвестного лица идентифицировать имя лица по ссылке на галерею ранее просмотренных фотографий идентифицированных лиц.</target>
        </trans-unit>
        <trans-unit id="9f1396eaada67d4771525d15c3b9982306c357b5" translate="yes" xml:space="preserve">
          <source>An alternative to pickling is to export the model to another format using one of the model export tools listed under &lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;. Unlike pickling, once exported you cannot recover the full Scikit-learn estimator object, but you can deploy the model for prediction, usually by using tools supporting open model interchange formats such as &lt;a href=&quot;https://onnx.ai/&quot;&gt;ONNX&lt;/a&gt; or &lt;a href=&quot;http://dmg.org/pmml/v4-4/GeneralStructure.html&quot;&gt;PMML&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63983f26490d9d0dd330cb65d368efc57d509991" translate="yes" xml:space="preserve">
          <source>An application of the different &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;Manifold learning&lt;/a&gt; techniques on a spherical data-set. Here one can see the use of dimensionality reduction in order to gain some intuition regarding the manifold learning methods. Regarding the dataset, the poles are cut from the sphere, as well as a thin slice down its side. This enables the manifold learning techniques to &amp;lsquo;spread it open&amp;rsquo; whilst projecting it onto two dimensions.</source>
          <target state="translated">Применение различных методов &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;обучения Manifold&lt;/a&gt; на сферическом наборе данных. Здесь можно увидеть использование уменьшения размерности, чтобы получить некоторое представление о разнообразных методах обучения. Что касается набора данных, полюса вырезаны из сферы, а также тонкий срез по ее стороне. Это позволяет разнообразным методам обучения &amp;laquo;раскрыть&amp;raquo; его, одновременно проецируя его на два измерения.</target>
        </trans-unit>
        <trans-unit id="7255375783faf14b00594786271748afe79b54ea" translate="yes" xml:space="preserve">
          <source>An approximate solution to the optimal normalized cut may be found via the generalized eigenvalue decomposition of the Laplacian of the graph. Usually this would mean working directly with the Laplacian matrix. If the original data matrix \(A\) has shape \(m \times n\), the Laplacian matrix for the corresponding bipartite graph has shape \((m + n) \times (m + n)\). However, in this case it is possible to work directly with \(A\), which is smaller and more efficient.</source>
          <target state="translated">Ориентировочное решение оптимального нормализованного разреза может быть найдено через обобщенное собственное разложение лаплацианского графика.Обычно это означает работу непосредственно с лаплакийской матрицей.Если исходная матрица данных \(A\)имеет форму \(m \times n\),то Лаплацианская матрица для соответствующего бипартитового графа имеет форму \((m+n)\times(m+n)\).Однако в этом случае можно работать непосредственно с \(A\),которая меньше по размеру и более эффективна.</target>
        </trans-unit>
        <trans-unit id="abda993d7d851644a2cce6e5b3201fc8e649cfdf" translate="yes" xml:space="preserve">
          <source>An approximation to the RBF kernel using random Fourier features.</source>
          <target state="translated">Аппроксимация к ядру RBF с использованием случайных особенностей Фурье.</target>
        </trans-unit>
        <trans-unit id="56451d3e9b79dc1326101c93a26155d78a7c4638" translate="yes" xml:space="preserve">
          <source>An array of arrays of indices of the approximate nearest points from the population matrix that lie within a ball of size &lt;code&gt;radius&lt;/code&gt; around the query points.</source>
          <target state="translated">Массив массивов индексов приблизительных ближайших точек из матрицы совокупности, которые лежат в пределах шара &lt;code&gt;radius&lt;/code&gt; размера вокруг точек запроса.</target>
        </trans-unit>
        <trans-unit id="69a7cca6f3965cdbc1f2a0f6316fc86cbe697d1b" translate="yes" xml:space="preserve">
          <source>An array of norms along given axis for X. When X is sparse, a NotImplementedError will be raised for norm &amp;lsquo;l1&amp;rsquo; or &amp;lsquo;l2&amp;rsquo;.</source>
          <target state="translated">Массив норм вдоль данной оси для X. Если X является разреженным, для нормы &amp;laquo;l1&amp;raquo; или &amp;laquo;l2&amp;raquo; будет выдана NotImplementedError.</target>
        </trans-unit>
        <trans-unit id="9eb7e49edfb49a7576a2bc3ab22563bf222603f7" translate="yes" xml:space="preserve">
          <source>An array of points to query</source>
          <target state="translated">Массив точек для запроса</target>
        </trans-unit>
        <trans-unit id="deb131dede53f65a17272e64b8336596d48d67e7" translate="yes" xml:space="preserve">
          <source>An array of points to query. Last dimension should match dimension of training data (n_features).</source>
          <target state="translated">Массив точек для запроса.Последнее измерение должно соответствовать размерности обучающих данных (n_features).</target>
        </trans-unit>
        <trans-unit id="ce1fbc6a1ce43e2f3a3c1ddf094fbdf1907a173f" translate="yes" xml:space="preserve">
          <source>An array of points to query. Last dimension should match dimension of training data.</source>
          <target state="translated">Массив точек для запроса.Последнее измерение должно соответствовать размеру обучающих данных.</target>
        </trans-unit>
        <trans-unit id="f7729a5fd61fb2317d29018126beb8ea2ea03054" translate="yes" xml:space="preserve">
          <source>An array of type np.float</source>
          <target state="translated">Массив типа np.float</target>
        </trans-unit>
        <trans-unit id="9febb5eef4fe704c0e2f76fc17196ae84e5bb310" translate="yes" xml:space="preserve">
          <source>An array with shape (n_samples_X, n_features).</source>
          <target state="translated">Массив с формой (n_samples_X,n_features).</target>
        </trans-unit>
        <trans-unit id="43ecc2546079acafbd51894522d368c0004da034" translate="yes" xml:space="preserve">
          <source>An array with shape (n_samples_X, n_samples_Y).</source>
          <target state="translated">Массив с формой (n_samples_X,n_samples_Y).</target>
        </trans-unit>
        <trans-unit id="4e6f0a1fd0fa00a29e1c148218c8f262ec65e6a9" translate="yes" xml:space="preserve">
          <source>An array with shape (n_samples_Y, n_features).</source>
          <target state="translated">Массив с формой (n_samples_Y,n_features).</target>
        </trans-unit>
        <trans-unit id="55ae6635fc7f12f40e0f75b8c113526f67ceb18f" translate="yes" xml:space="preserve">
          <source>An axis object onto which the plots will be drawn.</source>
          <target state="translated">Осевой объект,на который будут нарисованы графики.</target>
        </trans-unit>
        <trans-unit id="25ca61d5a0ba319e8f5dd67899dd1b75491f14b8" translate="yes" xml:space="preserve">
          <source>An early approach to taking advantage of this aggregate information was the &lt;em&gt;KD tree&lt;/em&gt; data structure (short for &lt;em&gt;K-dimensional tree&lt;/em&gt;), which generalizes two-dimensional &lt;em&gt;Quad-trees&lt;/em&gt; and 3-dimensional &lt;em&gt;Oct-trees&lt;/em&gt; to an arbitrary number of dimensions. The KD tree is a binary tree structure which recursively partitions the parameter space along the data axes, dividing it into nested orthotropic regions into which data points are filed. The construction of a KD tree is very fast: because partitioning is performed only along the data axes, no \(D\)-dimensional distances need to be computed. Once constructed, the nearest neighbor of a query point can be determined with only \(O[\log(N)]\) distance computations. Though the KD tree approach is very fast for low-dimensional (\(D &amp;lt; 20\)) neighbors searches, it becomes inefficient as \(D\) grows very large: this is one manifestation of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;. In scikit-learn, KD tree neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'kd_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Ранним подходом к использованию преимуществ этой совокупной информации была структура данных &lt;em&gt;KD tree&lt;/em&gt; (сокращение от &lt;em&gt;K-Dimension Tree&lt;/em&gt; ), которая обобщает двумерные &lt;em&gt;Quad-деревья&lt;/em&gt; и 3-мерные &lt;em&gt;Oct-деревья.&lt;/em&gt;к произвольному количеству измерений. KD-дерево представляет собой двоичную древовидную структуру, которая рекурсивно разделяет пространство параметров по осям данных, разделяя его на вложенные ортотропные области, в которые заносятся точки данных. Построение KD-дерева происходит очень быстро: поскольку разбиение выполняется только по осям данных, вычислять \ (D \) -мерные расстояния не требуется. После построения ближайший сосед точки запроса может быть определен только с помощью вычислений расстояния \ (O [\ log (N)] \). Хотя метод KD-дерева очень быстр для поиска соседей малой размерности (\ (D &amp;lt;20 \)), он становится неэффективным, когда \ (D \) становится очень большим: это одно из проявлений так называемого &amp;laquo;проклятия размерности&amp;raquo;. &amp;raquo;. В scikit-learn поиск соседей по дереву KD определяется с использованием ключевого слова &lt;code&gt;algorithm = 'kd_tree'&lt;/code&gt; , и вычисляются с использованием класса &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="099567709025ab0aa48e57d57280b0443b9a24ed" translate="yes" xml:space="preserve">
          <source>An empty dict signifies default parameters.</source>
          <target state="translated">Пустая надпись означает параметры по умолчанию.</target>
        </trans-unit>
        <trans-unit id="ffa5ed2f9779625aa20adf682c3351ed0a53fb7f" translate="yes" xml:space="preserve">
          <source>An encoding can also be called a &amp;lsquo;character set&amp;rsquo;, but this term is less accurate: several encodings can exist for a single character set.</source>
          <target state="translated">Кодировку также можно назвать &amp;laquo;набором символов&amp;raquo;, но этот термин менее точен: для одного набора символов может существовать несколько кодировок.</target>
        </trans-unit>
        <trans-unit id="15c84c56e7d6dd7f29f03b3419a89a1fa5861864" translate="yes" xml:space="preserve">
          <source>An ensemble of totally random trees.</source>
          <target state="translated">Ансамбль совершенно случайных деревьев.</target>
        </trans-unit>
        <trans-unit id="372a9ef151ce0e02d102211d2e14fc577127d782" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b0193485700595d6695b40a0a211b9e29e959231" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and one of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="215970b6b504c6bfb744566538a8accc41cd92e5" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-score&quot;&gt;score&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed51316796470f5285f1ea5227efd05cf75b44c0" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Объект оценки, реализующий &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2c736b1e847c7ee4aecf59b3bb14cb64e436dee2" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;code&gt;fit&lt;/code&gt; and one of &lt;code&gt;decision_function&lt;/code&gt; or &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">Объект оценки, реализующий &lt;code&gt;fit&lt;/code&gt; и одно из функций &lt;code&gt;decision_function&lt;/code&gt; или &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="016774ede32e1f200ea316bb37e829ebc5d620e2" translate="yes" xml:space="preserve">
          <source>An estimator object implementing &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;score&lt;/code&gt; and &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">Объект оценки, реализующий &lt;code&gt;fit&lt;/code&gt; , &lt;code&gt;score&lt;/code&gt; и &lt;code&gt;predict_proba&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bc6d2e5beaf0995cbcda2b429dbc0e874dd47ce4" translate="yes" xml:space="preserve">
          <source>An estimator object that is used to compute the initial predictions. &lt;code&gt;init&lt;/code&gt; has to provide &lt;a href=&quot;#sklearn.ensemble.GradientBoostingClassifier.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#sklearn.ensemble.GradientBoostingClassifier.predict_proba&quot;&gt;&lt;code&gt;predict_proba&lt;/code&gt;&lt;/a&gt;. If &amp;lsquo;zero&amp;rsquo;, the initial raw predictions are set to zero. By default, a &lt;code&gt;DummyEstimator&lt;/code&gt; predicting the classes priors is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd1e7319f04194cc6e7a0ff87c048ca39034bdd7" translate="yes" xml:space="preserve">
          <source>An estimator object that is used to compute the initial predictions. &lt;code&gt;init&lt;/code&gt; has to provide &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. If &amp;lsquo;zero&amp;rsquo;, the initial raw predictions are set to zero. By default a &lt;code&gt;DummyEstimator&lt;/code&gt; is used, predicting either the average target value (for loss=&amp;rsquo;ls&amp;rsquo;), or a quantile for the other losses.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e3cbd1a80e427709b1e224e290f485edaa6e701" translate="yes" xml:space="preserve">
          <source>An estimator object that is used to compute the initial predictions. &lt;code&gt;init&lt;/code&gt; has to provide &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;. If None it uses &lt;code&gt;loss.init_estimator&lt;/code&gt;.</source>
          <target state="translated">Объект оценки, который используется для вычисления начальных прогнозов. &lt;code&gt;init&lt;/code&gt; должен обеспечивать &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;predict&lt;/code&gt; . Если нет, используется &lt;code&gt;loss.init_estimator&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cf6861479f811af12e4fa2074ef55363e1ab1784" translate="yes" xml:space="preserve">
          <source>An estimator that has already been &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;fitted&lt;/a&gt; and is compatible with &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;scorer&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8add3305e3de95c19db62ec2f9ba60a9992f6c8c" translate="yes" xml:space="preserve">
          <source>An estimator to inspect.</source>
          <target state="translated">Оценщик для проверки.</target>
        </trans-unit>
        <trans-unit id="0c14b451345a9bebab4624cdfc1eb448ab003b65" translate="yes" xml:space="preserve">
          <source>An example comparing nearest neighbors classification with and without Neighborhood Components Analysis.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0583622ca0751c993f08e9d98041286805dcca3a" translate="yes" xml:space="preserve">
          <source>An example comparing the effect of reconstructing noisy fragments of a raccoon face image using firstly online &lt;a href=&quot;../../modules/decomposition#dictionarylearning&quot;&gt;Dictionary Learning&lt;/a&gt; and various transform methods.</source>
          <target state="translated">Пример сравнения эффекта восстановления зашумленных фрагментов изображения лица енота с использованием в первую очередь &lt;a href=&quot;../../modules/decomposition#dictionarylearning&quot;&gt;изучения словаря&lt;/a&gt; онлайн и различных методов преобразования.</target>
        </trans-unit>
        <trans-unit id="d3ed7be079cbbb4b66d35ed08e7318047e508129" translate="yes" xml:space="preserve">
          <source>An example illustrating the approximation of the feature map of an RBF kernel.</source>
          <target state="translated">Пример,иллюстрирующий аппроксимацию карты характеристик ядра RBF.</target>
        </trans-unit>
        <trans-unit id="5f84ab4970b6751b484f351a6364e917ee9e2e2e" translate="yes" xml:space="preserve">
          <source>An example of a chunked operation adhering to this setting is &lt;code&gt;metric.pairwise_distances_chunked&lt;/code&gt;, which facilitates computing row-wise reductions of a pairwise distance matrix.</source>
          <target state="translated">Примером операции с фрагментами, придерживающейся этого параметра, является &lt;code&gt;metric.pairwise_distances_chunked&lt;/code&gt; , который упрощает вычисление построчных сокращений попарной матрицы расстояний.</target>
        </trans-unit>
        <trans-unit id="d30da83c344e58d7fad635964b30a7c96a578d3f" translate="yes" xml:space="preserve">
          <source>An example of an estimator is the class &lt;code&gt;sklearn.svm.SVC&lt;/code&gt;, which implements &lt;a href=&quot;https://en.wikipedia.org/wiki/Support_vector_machine&quot;&gt;support vector classification&lt;/a&gt;. The estimator&amp;rsquo;s constructor takes as arguments the model&amp;rsquo;s parameters.</source>
          <target state="translated">Примером оценщика является класс &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; , который реализует &lt;a href=&quot;https://en.wikipedia.org/wiki/Support_vector_machine&quot;&gt;поддержку векторной классификации&lt;/a&gt; . Конструктор оценщика принимает в качестве аргументов параметры модели.</target>
        </trans-unit>
        <trans-unit id="2a28c2a5262858339108957d662b2d9ad76c60fe" translate="yes" xml:space="preserve">
          <source>An example of biclusters formed by partitioning rows and columns.</source>
          <target state="translated">Пример билюстра,образованного разбиением строк и столбцов.</target>
        </trans-unit>
        <trans-unit id="4ec3a210a521488a01f06a7254c4cbcafb1acb47" translate="yes" xml:space="preserve">
          <source>An example of checkerboard biclusters.</source>
          <target state="translated">Пример шахматных бильярдов.</target>
        </trans-unit>
        <trans-unit id="263d7481d0f6606e447078322b3482f64ed58b85" translate="yes" xml:space="preserve">
          <source>An example of estimating sources from noisy data.</source>
          <target state="translated">Пример оценки источников по шумным данным.</target>
        </trans-unit>
        <trans-unit id="ba8a60e5ae0a34a0a9e8c9683b9f2c1dae098cc6" translate="yes" xml:space="preserve">
          <source>An example of reshaping data would be the digits dataset</source>
          <target state="translated">Примером изменения данных может служить набор цифр.</target>
        </trans-unit>
        <trans-unit id="fbe3a4b0f4df558e025b4b6c278ce0b8f2e24f89" translate="yes" xml:space="preserve">
          <source>An example of the HTML output can be seen in the &lt;strong&gt;HTML representation of Pipeline&lt;/strong&gt; section of &lt;a href=&quot;../auto_examples/compose/plot_column_transformer_mixed_types#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py&quot;&gt;Column Transformer with Mixed Types&lt;/a&gt;. As an alternative, the HTML can be written to a file using &lt;a href=&quot;generated/sklearn.utils.estimator_html_repr#sklearn.utils.estimator_html_repr&quot;&gt;&lt;code&gt;estimator_html_repr&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fbe1528edfe5c2ef6e2542ba5d3a7a740cb4806" translate="yes" xml:space="preserve">
          <source>An example of the same &lt;code&gt;y&lt;/code&gt; in sparse matrix form:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2d2bef04bd500898cd35385a3db44c487620221" translate="yes" xml:space="preserve">
          <source>An example showing how different online solvers perform on the hand-written digits dataset.</source>
          <target state="translated">Пример,показывающий,как различные онлайновые решатели работают на рукописном наборе данных с цифрами.</target>
        </trans-unit>
        <trans-unit id="2aae52ed09d5204233cf6faccc3b62129219ab9a" translate="yes" xml:space="preserve">
          <source>An example showing how the scikit-learn can be used to recognize images of hand-written digits.</source>
          <target state="translated">Пример,показывающий,как наука может быть использована для распознавания изображений рукописных цифр.</target>
        </trans-unit>
        <trans-unit id="dc6fbf3a5e9982b266901310af78a9acc8d8b83c" translate="yes" xml:space="preserve">
          <source>An example showing univariate feature selection.</source>
          <target state="translated">Пример,показывающий одномерный выбор функций.</target>
        </trans-unit>
        <trans-unit id="a63d45f44a041fe05e157072e07ec905aa6168f0" translate="yes" xml:space="preserve">
          <source>An example to compare multi-output regression with random forest and the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; meta-estimator.</source>
          <target state="translated">Пример сравнения регрессии с несколькими выходами со случайным лесом и метаоценкой &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d69827da4fe888278b671529418570646583bc79" translate="yes" xml:space="preserve">
          <source>An example to illustrate multi-output regression with decision tree.</source>
          <target state="translated">Пример для иллюстрации многовыходной регрессии с деревом решений.</target>
        </trans-unit>
        <trans-unit id="278a8759739f9d084f6d58de5359105935a98d5a" translate="yes" xml:space="preserve">
          <source>An example to show covariance estimation with the Mahalanobis distances on Gaussian distributed data.</source>
          <target state="translated">Пример,показывающий оценку ковариаций с расстояниями Махаланобиса на гауссовых распределенных данных.</target>
        </trans-unit>
        <trans-unit id="79be1ff44d921e5597feeeddf48473c82478df46" translate="yes" xml:space="preserve">
          <source>An example using &lt;a href=&quot;../../modules/generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;sklearn.ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; for anomaly detection.</source>
          <target state="translated">Пример использования &lt;a href=&quot;../../modules/generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;sklearn.ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt; для обнаружения аномалии.</target>
        </trans-unit>
        <trans-unit id="c015cad72773b21af2994319c7e4935c0925533a" translate="yes" xml:space="preserve">
          <source>An example using a one-class SVM for novelty detection.</source>
          <target state="translated">Пример использования одноклассного SVM для обнаружения новинок.</target>
        </trans-unit>
        <trans-unit id="e3e6ce179701e2cc84a27da4032032e9c54e1a80" translate="yes" xml:space="preserve">
          <source>An extra-trees classifier.</source>
          <target state="translated">Классификатор лишних деревьев.</target>
        </trans-unit>
        <trans-unit id="402fd1d845155a85adc98aea2772c11c414eb821" translate="yes" xml:space="preserve">
          <source>An extra-trees regressor.</source>
          <target state="translated">Регрессор лишних деревьев.</target>
        </trans-unit>
        <trans-unit id="36e1ed7c225c31bf0ba3eb4dff97aa286624cf9d" translate="yes" xml:space="preserve">
          <source>An extremely randomized tree classifier.</source>
          <target state="translated">Чрезвычайно рандомизированный классификатор деревьев.</target>
        </trans-unit>
        <trans-unit id="2963ff7051490c77b458af39546e6bfce2134347" translate="yes" xml:space="preserve">
          <source>An extremely randomized tree regressor.</source>
          <target state="translated">Чрезвычайно рандомизированный регрессор деревьев.</target>
        </trans-unit>
        <trans-unit id="2e305a3161f1f3a1a75895f3bf89737b2fa1110e" translate="yes" xml:space="preserve">
          <source>An illustration of Swiss Roll reduction with locally linear embedding</source>
          <target state="translated">Иллюстрация уменьшения швейцарского рулона с локальной линейной вставкой</target>
        </trans-unit>
        <trans-unit id="ff57c22861af0b46c7c064d86f712f1102614de2" translate="yes" xml:space="preserve">
          <source>An illustration of dimensionality reduction on the S-curve dataset with various manifold learning methods.</source>
          <target state="translated">Иллюстрация уменьшения размерности на наборе данных S-образной кривой с помощью различных методов обучения.</target>
        </trans-unit>
        <trans-unit id="461c40d4fafb15fd1dbf5dddb7defd80f66220bc" translate="yes" xml:space="preserve">
          <source>An illustration of t-SNE on the two concentric circles and the S-curve datasets for different perplexity values.</source>
          <target state="translated">Иллюстрация t-SNE на двух концентрических окружностях и наборов данных S-образной кривой для различных значений сложности.</target>
        </trans-unit>
        <trans-unit id="4217a4a05133f009315b7adf6df3894014f6eea5" translate="yes" xml:space="preserve">
          <source>An illustration of the isotonic regression on generated data. The isotonic regression finds a non-decreasing approximation of a function while minimizing the mean squared error on the training data. The benefit of such a model is that it does not assume any form for the target function such as linearity. For comparison a linear regression is also presented.</source>
          <target state="translated">Иллюстрация изотонической регрессии по сгенерированным данным.Изотоническая регрессия находит не уменьшающееся приближение функции при минимизации средней квадратной ошибки на тренировочных данных.Преимущество такой модели состоит в том,что она не принимает никакой формы для целевой функции,такой как линейность.Для сравнения представлена также линейная регрессия.</target>
        </trans-unit>
        <trans-unit id="95f191130b61aa88bf4d9f0c56ed2e78e6bd9498" translate="yes" xml:space="preserve">
          <source>An illustration of the metric and non-metric MDS on generated noisy data.</source>
          <target state="translated">Иллюстрация метрических и неметрических MDS на сгенерированных шумных данных.</target>
        </trans-unit>
        <trans-unit id="4ed4596d6f2bc0049548fe72a3bd1528d6ff1a95" translate="yes" xml:space="preserve">
          <source>An illustration of various embeddings on the digits dataset.</source>
          <target state="translated">Иллюстрация различных встраиваний в набор данных по цифрам.</target>
        </trans-unit>
        <trans-unit id="5349a7af33dbb0da98921a0576af67237bdedc22" translate="yes" xml:space="preserve">
          <source>An illustration of various linkage option for agglomerative clustering on a 2D embedding of the digits dataset.</source>
          <target state="translated">Иллюстрация различных вариантов связывания для агломеративной кластеризации при 2D-встраивании набора данных из цифр.</target>
        </trans-unit>
        <trans-unit id="9431c782d6d1945d9109d26f9bdc51c8ca5b4cc9" translate="yes" xml:space="preserve">
          <source>An implementation of a randomized algorithm for principal component analysis A. Szlam et al. 2014</source>
          <target state="translated">Реализация рандомизированного алгоритма для основного компонентного анализа А.Шлам и др.2014</target>
        </trans-unit>
        <trans-unit id="97eec2318d7e6e3549c069ff7f108d7733cec0af" translate="yes" xml:space="preserve">
          <source>An important aspect of performance optimization is also that it can hurt prediction accuracy. Indeed, simpler models (e.g. linear instead of non-linear, or with fewer parameters) often run faster but are not always able to take into account the same exact properties of the data as more complex ones.</source>
          <target state="translated">Важным аспектом оптимизации производительности также является то,что это может повредить точности прогнозирования.Действительно,более простые модели (например,линейные вместо нелинейных или с меньшим количеством параметров)часто работают быстрее,но не всегда могут учитывать те же точные свойства данных,что и более сложные.</target>
        </trans-unit>
        <trans-unit id="44f31261fda2a48216b1472f9c206633a0f349f1" translate="yes" xml:space="preserve">
          <source>An important notion of robust fitting is that of breakdown point: the fraction of data that can be outlying for the fit to start missing the inlying data.</source>
          <target state="translated">Важным понятием робастной подгонки является точка пробоя:часть данных,которая может быть удалена,чтобы подгонка начала пропускать входящие данные.</target>
        </trans-unit>
        <trans-unit id="98153081fcfad9474299ea23738f0ec83b423b23" translate="yes" xml:space="preserve">
          <source>An important question is how can the Dirichlet process use an infinite, unbounded number of clusters and still be consistent. While a full explanation doesn&amp;rsquo;t fit this manual, one can think of its &lt;a href=&quot;https://en.wikipedia.org/wiki/Dirichlet_process#The_stick-breaking_process&quot;&gt;stick breaking process&lt;/a&gt; analogy to help understanding it. The stick breaking process is a generative story for the Dirichlet process. We start with a unit-length stick and in each step we break off a portion of the remaining stick. Each time, we associate the length of the piece of the stick to the proportion of points that falls into a group of the mixture. At the end, to represent the infinite mixture, we associate the last remaining piece of the stick to the proportion of points that don&amp;rsquo;t fall into all the other groups. The length of each piece is a random variable with probability proportional to the concentration parameter. Smaller value of the concentration will divide the unit-length into larger pieces of the stick (defining more concentrated distribution). Larger concentration values will create smaller pieces of the stick (increasing the number of components with non zero weights).</source>
          <target state="translated">Важный вопрос заключается в том, как процесс Дирихле может использовать бесконечное неограниченное число кластеров и при этом быть согласованным. Хотя полное объяснение не подходит для этого руководства, можно подумать о &lt;a href=&quot;https://en.wikipedia.org/wiki/Dirichlet_process#The_stick-breaking_process&quot;&gt;процессе разрушения палки.&lt;/a&gt;аналогия, чтобы помочь понять это. Процесс разрушения палки - это генеративная история для процесса Дирихле. Мы начинаем с палки единичной длины и на каждом этапе отламываем часть оставшейся палки. Каждый раз мы связываем длину кусочка палки с долей точек, попадающих в группу смеси. В конце, чтобы представить бесконечную смесь, мы связываем последний оставшийся кусок палки с долей точек, которые не попадают во все другие группы. Длина каждого куска является случайной величиной с вероятностью, пропорциональной параметру концентрации. Меньшее значение концентрации разделит единицу длины на более крупные части палочки (определяя более концентрированное распределение).Более высокие значения концентрации создадут меньшие кусочки палочки (увеличивая количество компонентов с ненулевым весом).</target>
        </trans-unit>
        <trans-unit id="627c954c961a3acd43edae0e16b57eae5630ce43" translate="yes" xml:space="preserve">
          <source>An improvement of the Ledoit-Wolf shrinkage, the &lt;a href=&quot;../../modules/generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;sklearn.covariance.OAS&lt;/code&gt;&lt;/a&gt;, proposed by Chen et al. Its convergence is significantly better under the assumption that the data are Gaussian, in particular for small samples.</source>
          <target state="translated">Улучшение усадки Ледуа-Вольфа, &lt;a href=&quot;../../modules/generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;sklearn.covariance.OAS&lt;/code&gt; &lt;/a&gt; , предложенное Chen et al. Его сходимость значительно лучше при предположении, что данные являются гауссовыми, особенно для небольших выборок.</target>
        </trans-unit>
        <trans-unit id="370f3995d8ef065bc41012596e70d603a42a06c3" translate="yes" xml:space="preserve">
          <source>An index that selects the retained features from a feature vector. If &lt;code&gt;indices&lt;/code&gt; is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If &lt;code&gt;indices&lt;/code&gt; is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.</source>
          <target state="translated">Индекс, который выбирает сохраненные объекты из вектора признаков. Если &lt;code&gt;indices&lt;/code&gt; имеет значение False, это логический массив формы [# input features], в котором элемент имеет значение True, если его соответствующая функция выбрана для сохранения. Если &lt;code&gt;indices&lt;/code&gt; имеет значение True, это целочисленный массив формы [# output features], значения которого являются индексами во входном векторе признаков.</target>
        </trans-unit>
        <trans-unit id="537bad4eab470a047cae67c34b767bf9f3d01c01" translate="yes" xml:space="preserve">
          <source>An instance of the estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0f36ad8d88245eefc6653aba92b1989e3a7de69" translate="yes" xml:space="preserve">
          <source>An int, giving the exact number of total jobs that are spawned</source>
          <target state="translated">Инт,указывая точное количество созданных рабочих мест.</target>
        </trans-unit>
        <trans-unit id="efb853d408e1363bd14470415d5367521c99f9fa" translate="yes" xml:space="preserve">
          <source>An interesting aspect of &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt; is that connectivity constraints can be added to this algorithm (only adjacent clusters can be merged together), through a connectivity matrix that defines for each sample the neighboring samples following a given structure of the data. For instance, in the swiss-roll example below, the connectivity constraints forbid the merging of points that are not adjacent on the swiss roll, and thus avoid forming clusters that extend across overlapping folds of the roll.</source>
          <target state="translated">Интересным аспектом &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; &lt;/a&gt; является то, что к этому алгоритму могут быть добавлены ограничения связи (только соседние кластеры могут быть объединены вместе) через матрицу связности, которая определяет для каждой выборки соседние выборки, следующие заданной структуре данных. Например, в приведенном ниже примере швейцарского рулона ограничения связности запрещают слияние точек, которые не являются смежными на швейцарском рулоне, и, таким образом, избегают образования кластеров, которые проходят через перекрывающиеся складки рулона.</target>
        </trans-unit>
        <trans-unit id="edca22917cc04c2cee4dca2af159124718d78594" translate="yes" xml:space="preserve">
          <source>An interesting development of using a &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; is the ability to perform &lt;a href=&quot;https://en.wikipedia.org/wiki/Out-of-core_algorithm&quot;&gt;out-of-core&lt;/a&gt; scaling. This means that we can learn from data that does not fit into the computer&amp;rsquo;s main memory.</source>
          <target state="translated">Интересное развитие использования &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt; - это возможность выполнять масштабирование &lt;a href=&quot;https://en.wikipedia.org/wiki/Out-of-core_algorithm&quot;&gt;вне ядра&lt;/a&gt; . Это означает, что мы можем учиться на данных, которые не помещаются в основную память компьютера.</target>
        </trans-unit>
        <trans-unit id="e061f170f65c98ddc125ba623de0d484bced6052" translate="yes" xml:space="preserve">
          <source>An introduction to machine learning with scikit-learn</source>
          <target state="translated">Введение в машинное обучение с помощью научно-обученного.</target>
        </trans-unit>
        <trans-unit id="f8000912a05784b4ed09f166d2281bb382154409" translate="yes" xml:space="preserve">
          <source>An iterable which yields either str, unicode or file objects.</source>
          <target state="translated">Итерабель,который дает либо строку,юникод или файловые объекты.</target>
        </trans-unit>
        <trans-unit id="ed21dc2777fffee9a18d3be232cdf0f7a675b104" translate="yes" xml:space="preserve">
          <source>An iterable yielding (train, test) splits as arrays of indices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26021975f66731cfc83771c3f9a3b8617a224127" translate="yes" xml:space="preserve">
          <source>An iterable yielding train, test splits.</source>
          <target state="translated">Итерабельный уступчивый поезд,тестовые расщепления.</target>
        </trans-unit>
        <trans-unit id="793ecf7b6fedca1d245cd9de3dfad1789ad435c2" translate="yes" xml:space="preserve">
          <source>An iterable yielding train/test splits.</source>
          <target state="translated">Итерабельное расщепление поезда/теста.</target>
        </trans-unit>
        <trans-unit id="2c74b450a38327bc579731e9a6b693f5a72972a9" translate="yes" xml:space="preserve">
          <source>An object for detecting outliers in a Gaussian distributed dataset.</source>
          <target state="translated">Объект для обнаружения промахов в гауссовом распределенном наборе данных.</target>
        </trans-unit>
        <trans-unit id="bb3e30a61bd34f61e007c1401c3e81f0d43c8edb" translate="yes" xml:space="preserve">
          <source>An object of that type which is cloned for each validation.</source>
          <target state="translated">Объект такого типа,который клонируется для каждой проверки.</target>
        </trans-unit>
        <trans-unit id="9720a88e8aa2bbe2107788283b8978f9a7cb4b22" translate="yes" xml:space="preserve">
          <source>An object to be used as a cross-validation generator,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbffbe09f32930b2800698ca47bd093017747bdf" translate="yes" xml:space="preserve">
          <source>An object to be used as a cross-validation generator.</source>
          <target state="translated">Объект для использования в качестве генератора перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="a7002171a59c54b21633748422d618355d53d5f0" translate="yes" xml:space="preserve">
          <source>An optional mask of the image, to consider only part of the pixels.</source>
          <target state="translated">Необязательная маска растра,учитывающая только часть пикселей.</target>
        </trans-unit>
        <trans-unit id="fe8123eda49913b2b31a4b7b815dc029043ed233" translate="yes" xml:space="preserve">
          <source>An optional progress meter.</source>
          <target state="translated">Опциональный счетчик прогресса.</target>
        </trans-unit>
        <trans-unit id="229c2b7073ef4d939c3f4e9dc0933cc0c25d3c6e" translate="yes" xml:space="preserve">
          <source>An optional second feature array. Only allowed if metric != &amp;ldquo;precomputed&amp;rdquo;.</source>
          <target state="translated">Необязательный второй массив функций. Разрешено, только если метрика! = &amp;laquo;Предварительно вычислено&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="0072ba612e2ac9888a715c6d07a5f35671c0b0f4" translate="yes" xml:space="preserve">
          <source>An ordered array of unique labels.</source>
          <target state="translated">Заказанный набор уникальных этикеток.</target>
        </trans-unit>
        <trans-unit id="a760a22c84feac040244658e5cd6e733d7fd7a9c" translate="yes" xml:space="preserve">
          <source>An unsupervised transformation of a dataset to a high-dimensional sparse representation. A datapoint is coded according to which leaf of each tree it is sorted into. Using a one-hot encoding of the leaves, this leads to a binary coding with as many ones as there are trees in the forest.</source>
          <target state="translated">Неконтролируемое преобразование набора данных в высокоразмерное разреженное представление.Кодируется точка отсчета,согласно которой отсортирован лист каждого дерева.Используя одноразовое кодирование листьев,это приводит к бинарной кодировке с таким же количеством деревьев,как и в лесу.</target>
        </trans-unit>
        <trans-unit id="8bba08ddfbe8b42a7ddb2ba7f5d85088746ededd" translate="yes" xml:space="preserve">
          <source>An upper bound on the fraction of margin errors (see &lt;a href=&quot;../svm#nu-svc&quot;&gt;User Guide&lt;/a&gt;) and a lower bound of the fraction of support vectors. Should be in the interval (0, 1].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d82cfe79ef09c873c85764ea87217dd841df582" translate="yes" xml:space="preserve">
          <source>An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1].</source>
          <target state="translated">Верхняя граница на дроби ошибок обучения и нижняя граница на дроби векторов поддержки.Должна быть в интервале (0,1].</target>
        </trans-unit>
        <trans-unit id="5f9f028f3aaaed07cbca0fd41b78759c2fe2428d" translate="yes" xml:space="preserve">
          <source>An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.</source>
          <target state="translated">Верхняя граница на дроби ошибок обучения и нижняя граница на дроби векторов поддержки.Должна быть в интервале (0,1].По умолчанию будет принято значение 0.5.</target>
        </trans-unit>
        <trans-unit id="c638b2709b286483a90c4415602f89072f7cd76d" translate="yes" xml:space="preserve">
          <source>Analysis of the plots</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="130d90555949c1ba7863adb5fc8aa4d5f4dd611e" translate="yes" xml:space="preserve">
          <source>Analyzing a portion of the ROC curve. McClish, 1989</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b98195adea1583e9b237e74652523f846b2b1879" translate="yes" xml:space="preserve">
          <source>And for multiple metric evaluation, the return value is a dict with the following keys - &lt;code&gt;['test_&amp;lt;scorer1_name&amp;gt;', 'test_&amp;lt;scorer2_name&amp;gt;', 'test_&amp;lt;scorer...&amp;gt;', 'fit_time', 'score_time']&lt;/code&gt;</source>
          <target state="translated">А для оценки нескольких показателей возвращаемое значение - это dict со следующими ключами - &lt;code&gt;['test_&amp;lt;scorer1_name&amp;gt;', 'test_&amp;lt;scorer2_name&amp;gt;', 'test_&amp;lt;scorer...&amp;gt;', 'fit_time', 'score_time']&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c48696369bc4cd123e13a474e64394fa9533d40a" translate="yes" xml:space="preserve">
          <source>And some work with binary and multilabel (but not multiclass) problems:</source>
          <target state="translated">А также некоторые работы с бинарными и мульти-маркировочными (но не мульти-классовыми)проблемами:</target>
        </trans-unit>
        <trans-unit id="551fc600bc5b2c147bfd7d608b1227c6f0c95818" translate="yes" xml:space="preserve">
          <source>And the L2-normalized tf-idf changes to</source>
          <target state="translated">И L2-нормализованный tf-idf изменяется на</target>
        </trans-unit>
        <trans-unit id="fd06a66dae1b69b6eb93cccfb52c33888c5a371c" translate="yes" xml:space="preserve">
          <source>And the classifier &amp;ldquo;predictions&amp;rdquo; are perfect:</source>
          <target state="translated">И классификатор &amp;laquo;прогнозы&amp;raquo; идеален:</target>
        </trans-unit>
        <trans-unit id="b646eac54bde60aa4d7c89014b7fd028412efa2f" translate="yes" xml:space="preserve">
          <source>Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A conditional entropy-based external cluster evaluation measure</source>
          <target state="translated">Эндрю Розенберг и Джулия Хиршберг,2007.V-мероприятие:Мера внешней кластерной оценки на основе условной энтропии.</target>
        </trans-unit>
        <trans-unit id="5ca338dedf0d8331238e60ad1d0242b94a749529" translate="yes" xml:space="preserve">
          <source>Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and J&amp;ouml;rg Sander. &amp;ldquo;OPTICS: ordering points to identify the clustering structure.&amp;rdquo; ACM SIGMOD Record 28, no. 2 (1999): 49-60.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2b1b23fa02a3f4b2a576f98b5ef19fd6944167" translate="yes" xml:space="preserve">
          <source>Another alternative is to take a symmetric version of the k nearest neighbors connectivity matrix of the points.</source>
          <target state="translated">Другой вариант-взять симметричную версию матрицы связности k ближайших соседей точек.</target>
        </trans-unit>
        <trans-unit id="c8a5ccc165016bcc8540311d11c1eec6480387f0" translate="yes" xml:space="preserve">
          <source>Another approach is to monitor convergence on a validation score. In this case, the input data is split into a training set and a validation set. The model is then fitted on the training set and the stopping criterion is based on the prediction score computed on the validation set. This enables us to find the least number of iterations which is sufficient to build a model that generalizes well to unseen data and reduces the chance of over-fitting the training data.</source>
          <target state="translated">Другой подход заключается в мониторинге конвергенции по балльной оценке.В этом случае входные данные разбиваются на обучающий и валидационный набор.Затем модель подгоняется к обучающему набору,а критерий остановки основывается на балле прогнозирования,вычисленном на основе валидационного набора.Это позволяет найти наименьшее количество итераций,которого достаточно для построения модели,хорошо обобщающей невидимые данные и уменьшающей шанс переподгонки тренировочных данных.</target>
        </trans-unit>
        <trans-unit id="be7184b0e2bd98f85cd552cd8ec12d77ca9e3964" translate="yes" xml:space="preserve">
          <source>Another aspect to consider when choosing a proper algorithm is that not all of them put the same importance on each example over time. Namely, the &lt;code&gt;Perceptron&lt;/code&gt; is still sensitive to badly labeled examples even after many examples whereas the &lt;code&gt;SGD*&lt;/code&gt; and &lt;code&gt;PassiveAggressive*&lt;/code&gt; families are more robust to this kind of artifacts. Conversely, the latter also tend to give less importance to remarkably different, yet properly labeled examples when they come late in the stream as their learning rate decreases over time.</source>
          <target state="translated">Другой аспект, который следует учитывать при выборе правильного алгоритма, заключается в том, что не все из них придают одинаковое значение каждому примеру с течением времени. А именно, &lt;code&gt;Perceptron&lt;/code&gt; по-прежнему чувствителен к примерам с плохой маркировкой даже после множества примеров, тогда как семейства &lt;code&gt;SGD*&lt;/code&gt; и &lt;code&gt;PassiveAggressive*&lt;/code&gt; более устойчивы к такого рода артефактам. И наоборот, последние также склонны придавать меньшее значение заметно различающимся, но должным образом обозначенным примерам, когда они появляются поздно в потоке, поскольку их скорость обучения снижается со временем.</target>
        </trans-unit>
        <trans-unit id="32a1cd2cb87665a11effa4dc4df8f03517ac0638" translate="yes" xml:space="preserve">
          <source>Another common application is to use time information: for instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.</source>
          <target state="translated">Другим распространенным приложением является использование информации о времени:например,группы могут быть годом сбора образцов и,таким образом,позволяют проводить перекрестную проверку по временным разбиениям.</target>
        </trans-unit>
        <trans-unit id="8230731c6a46697977b2ab40afba474c6e0f5aba" translate="yes" xml:space="preserve">
          <source>Another efficient way to perform outlier detection on moderately high dimensional datasets is to use the Local Outlier Factor (LOF) algorithm.</source>
          <target state="translated">Другой эффективный способ определения отклонений на наборах данных умеренно высоких размеров-это использование алгоритма Local Outlier Factor (LOF).</target>
        </trans-unit>
        <trans-unit id="421e4566a6c577d45c51d939beed6fdb20866913" translate="yes" xml:space="preserve">
          <source>Another evaluation measure for multi-class classification is macro-averaging, which gives equal weight to the classification of each label.</source>
          <target state="translated">Другой оценочной мерой для многоклассовой классификации является макроусреднение,которое дает равный вес классификации каждой маркировки.</target>
        </trans-unit>
        <trans-unit id="9aeb8b5cf9580937985ce741399f76caf7f788f7" translate="yes" xml:space="preserve">
          <source>Another evaluation measure for multi-label classification is macro-averaging, which gives equal weight to the classification of each label.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="103287c3ab74c62412ea0fba62e90af2b9fbac2a" translate="yes" xml:space="preserve">
          <source>Another important metric to care about when sizing production systems is the throughput i.e. the number of predictions you can make in a given amount of time. Here is a benchmark from the &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt; example that measures this quantity for a number of estimators on synthetic data:</source>
          <target state="translated">Еще одна важная метрика, о которой нужно заботиться при определении размеров производственных систем, - это пропускная способность, то есть количество прогнозов, которые вы можете сделать за заданный промежуток времени. Вот эталон из примера &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency,&lt;/a&gt; который измеряет эту величину для ряда оценщиков синтетических данных:</target>
        </trans-unit>
        <trans-unit id="57f765049776b7061ec3ebaa517aed91ea1819db" translate="yes" xml:space="preserve">
          <source>Another option is the &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt;. This uses round-robin linear regression, modeling each feature with missing values as a function of other features, in turn. The version implemented assumes Gaussian (output) variables. If your features are obviously non-normal, consider transforming them to look more normal to potentially improve performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8eb27e015d30244a13ff2ea0a8b9e91973d57ab" translate="yes" xml:space="preserve">
          <source>Another option is to use an iterable yielding (train, test) splits as arrays of indices, for example:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebe975675e662edf348908a46736c6c5923bfe28" translate="yes" xml:space="preserve">
          <source>Another possibility to convert categorical features to features that can be used with scikit-learn estimators is to use a one-of-K, also known as one-hot or dummy encoding. This type of encoding can be obtained with the &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;OneHotEncoder&lt;/code&gt;&lt;/a&gt;, which transforms each categorical feature with &lt;code&gt;n_categories&lt;/code&gt; possible values into &lt;code&gt;n_categories&lt;/code&gt; binary features, with one of them 1, and all others 0.</source>
          <target state="translated">Еще одна возможность преобразовать категориальные функции в функции, которые можно использовать с оценками scikit-learn, - это использовать кодировку &amp;laquo;один из K&amp;raquo;, также известную как одноразовое или фиктивное кодирование. Этот тип кодирования может быть получен с &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;OneHotEncoder&lt;/code&gt; &lt;/a&gt; , который преобразует каждый категорическую функцию с &lt;code&gt;n_categories&lt;/code&gt; возможных значений в &lt;code&gt;n_categories&lt;/code&gt; двоичных функции, с одним из них 1, а всех остальных 0.</target>
        </trans-unit>
        <trans-unit id="be92131a59ab295e72fcba022db0017e8b66e901" translate="yes" xml:space="preserve">
          <source>Another possibility to take into account correlated variables in the dataset, is to estimate sparse coefficients. In some way we already did it manually when we dropped the AGE column in a previous Ridge estimation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd4ca3c02f5c305e57327d7ebc584dba1a900469" translate="yes" xml:space="preserve">
          <source>Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.</source>
          <target state="translated">Еще одно уточнение на вершине tf состоит в том,чтобы уменьшить вес слов,которые встречаются во многих документах корпуса и поэтому менее информативны,чем те,которые встречаются только в меньшей части корпуса.</target>
        </trans-unit>
        <trans-unit id="b069cfdd4eba1168499f693bf3d06a42576bfe6a" translate="yes" xml:space="preserve">
          <source>Another set of biclusters like &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="translated">Другой набор biclusters нравится . &lt;code&gt;a&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="dbed96b9cee766d1a5bef03a5ad136b7f76de1ff" translate="yes" xml:space="preserve">
          <source>Another significant feature involves whether the sender is affiliated with a university, as indicated either by their headers or their signature.</source>
          <target state="translated">Другая важная особенность заключается в том,связан ли отправитель с университетом,о чем свидетельствуют либо его заголовки,либо его подпись.</target>
        </trans-unit>
        <trans-unit id="943b31c92155c4448885494636d7164b8dc15821" translate="yes" xml:space="preserve">
          <source>Another strategy to reduce the variance is by subsampling the features analogous to the random splits in &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; . The number of subsampled features can be controlled via the &lt;code&gt;max_features&lt;/code&gt; parameter.</source>
          <target state="translated">Другая стратегия уменьшения дисперсии - подвыборка функций, аналогичных случайным разбиениям в &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt; . Количество субдискретизированных функций можно контролировать с помощью параметра &lt;code&gt;max_features&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9bb442d3ca7e5d02384e286ef663eab8b5ac3081" translate="yes" xml:space="preserve">
          <source>Another way to compare the curves is to plot them on top of each other. Here, we create a figure with one row and two columns. The axes are passed into the &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; function as a list, which will plot the partial dependence curves of each model on the same axes. The length of the axes list must be equal to the number of plots drawn.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7f320421764ca2c9e221a3ad89c0802b9dda00c" translate="yes" xml:space="preserve">
          <source>Another way to reduce memory and computation time is to remove (near-)duplicate points and use &lt;code&gt;sample_weight&lt;/code&gt; instead.</source>
          <target state="translated">Другой способ уменьшить память и время вычислений - удалить (почти) повторяющиеся точки и вместо этого использовать &lt;code&gt;sample_weight&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c89aea8f1a22bc16a7ca2249f6b1aa681a716bbf" translate="yes" xml:space="preserve">
          <source>Any core sample is part of a cluster, by definition. Any sample that is not a core sample, and is at least &lt;code&gt;eps&lt;/code&gt; in distance from any core sample, is considered an outlier by the algorithm.</source>
          <target state="translated">Любой образец керна по определению является частью кластера. Любой образец, который не является образцом керна и находится на расстоянии не менее &lt;code&gt;eps&lt;/code&gt; от любого образца керна, алгоритм считает выбросом.</target>
        </trans-unit>
        <trans-unit id="3a31e829c68185fcae1e17d8f929a1d6c89d47e3" translate="yes" xml:space="preserve">
          <source>Any estimator using the Huber loss would also be robust to outliers, e.g. &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;loss='huber'&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68c9d8de07d4bc7df0a34b129a047212dbcfefbc" translate="yes" xml:space="preserve">
          <source>Any further parameters are passed directly to the distance function. If using a &lt;code&gt;scipy.spatial.distance&lt;/code&gt; metric, the parameters are still metric dependent. See the scipy docs for usage examples.</source>
          <target state="translated">Любые другие параметры передаются непосредственно в функцию расстояния. При использовании метрики &lt;code&gt;scipy.spatial.distance&lt;/code&gt; параметры по-прежнему зависят от метрики. См. Scipy docs для примеров использования.</target>
        </trans-unit>
        <trans-unit id="38f47dd09163cb40bcb092eb016347a6afcf892a" translate="yes" xml:space="preserve">
          <source>Any further parameters are passed directly to the distance function. If using a scipy.spatial.distance metric, the parameters are still metric dependent. See the scipy docs for usage examples.</source>
          <target state="translated">Дальнейшие параметры передаются непосредственно в функцию расстояния.Если используется научно-пространственная метрика расстояния,то параметры все равно остаются зависимыми от метрики.Примеры использования см.в научных документах.</target>
        </trans-unit>
        <trans-unit id="3ac4cf049edcb6bb9798310f2f664afd413547f9" translate="yes" xml:space="preserve">
          <source>Any further parameters are passed directly to the kernel function.</source>
          <target state="translated">Дальнейшие параметры передаются непосредственно в функцию ядра.</target>
        </trans-unit>
        <trans-unit id="02eaff0fa77b6c45a1e6d5d1d919c0643a037a82" translate="yes" xml:space="preserve">
          <source>Any pairwise distance</source>
          <target state="translated">Любое парное расстояние</target>
        </trans-unit>
        <trans-unit id="b551d3f373e53d945ef845b2e543fa8abdb837a0" translate="yes" xml:space="preserve">
          <source>Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, to find the names and current values for all parameters for a given estimator, use:</source>
          <target state="translated">Любой параметр,предоставляемый при построении сметы,может быть оптимизирован таким образом.В частности,для поиска имен и текущих значений всех параметров для данного оценочного средства,используйте его:</target>
        </trans-unit>
        <trans-unit id="767d84a7d28245adee41a36e340241d2beefe72a" translate="yes" xml:space="preserve">
          <source>Apart from a scalar or a single item list, the column selection can be specified as a list of multiple items, an integer array, a slice, a boolean mask, or with a &lt;a href=&quot;generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;make_column_selector&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&quot;generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;make_column_selector&lt;/code&gt;&lt;/a&gt; is used to select columns based on data type or column name:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c69ec44124fc60e723479a565a556b4cda43066" translate="yes" xml:space="preserve">
          <source>Apart from a scalar or a single item list, the column selection can be specified as a list of multiple items, an integer array, a slice, or a boolean mask. Strings can reference columns if the input is a DataFrame, integers are always interpreted as the positional columns.</source>
          <target state="translated">Кроме скаляра или одного списка элементов,выбор столбца может быть указан как список из нескольких элементов,целочисленный массив,срез или булевая маска.Строки могут содержать ссылки на столбцы,если входной поток является DataFrame,целые числа всегда интерпретируются как позиционные столбцы.</target>
        </trans-unit>
        <trans-unit id="4989a2f6df8d0581f9c1d9a7bb746db90f17c597" translate="yes" xml:space="preserve">
          <source>Apple Accelerate and vecLib frameworks (OSX only)</source>
          <target state="translated">Apple Accelerate и vecLib фреймворки (только для OSX)</target>
        </trans-unit>
        <trans-unit id="a10c2e4fa481f8ae4b6f36b04c8c93e1d4615114" translate="yes" xml:space="preserve">
          <source>Applications to real world problems with some medium sized datasets or interactive user interface.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="781951ec1e6932c1ea70532655c1b03656c5caff" translate="yes" xml:space="preserve">
          <source>Applies fit_predict of last step in pipeline after transforms.</source>
          <target state="translated">Применяет fit_predict последнего шага в трубопроводе после трансформации.</target>
        </trans-unit>
        <trans-unit id="b55937b5acc0d0ace1d8fc39be387e51d59bfd33" translate="yes" xml:space="preserve">
          <source>Applies fit_transforms of a pipeline to the data, followed by the fit_predict method of the final estimator in the pipeline. Valid only if the final estimator implements fit_predict.</source>
          <target state="translated">Применяет Fit_transforms трубопровода к данным,а затем метод Fit_predict конечного оценщика в трубопроводе.Действительно только в том случае,если итоговый оценщик реализует метод fit_predict.</target>
        </trans-unit>
        <trans-unit id="e8dcdf95b2627510067599d6b4df4640274e7f9c" translate="yes" xml:space="preserve">
          <source>Applies the learned transformation to the given data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e21a5ab651c86df31d86409fda574ccc4b1b0811" translate="yes" xml:space="preserve">
          <source>Applies transformers to columns of an array or pandas DataFrame.</source>
          <target state="translated">Применяет трансформаторы к столбцам массива или панды DataFrame.</target>
        </trans-unit>
        <trans-unit id="bc1fc2d494d882727c783481b882146100e6cdea" translate="yes" xml:space="preserve">
          <source>Apply Term Frequency Inverse Document Frequency normalization to a sparse matrix of occurrence counts.</source>
          <target state="translated">Применить нормирование предельной частоты обратной записи документа к разреженной матрице подсчета числа вхождений.</target>
        </trans-unit>
        <trans-unit id="48ea2e033ed029c8a6ff54b6ec3dbb5f6c117a68" translate="yes" xml:space="preserve">
          <source>Apply a correction to raw Minimum Covariance Determinant estimates.</source>
          <target state="translated">Применить поправку к необработанным оценкам минимального ковариационного детерминанта.</target>
        </trans-unit>
        <trans-unit id="3438e96e607439758fb53dafc23a0586474578cd" translate="yes" xml:space="preserve">
          <source>Apply a power transform featurewise to make data more Gaussian-like.</source>
          <target state="translated">Применяйте функцию преобразования мощности,чтобы сделать данные более гауссово подобными.</target>
        </trans-unit>
        <trans-unit id="2abb9abf1584e2411d2ab4707e053695cc0afad4" translate="yes" xml:space="preserve">
          <source>Apply approximate feature map to X.</source>
          <target state="translated">Применить приблизительную карту характеристик к X.</target>
        </trans-unit>
        <trans-unit id="72616a249f3c4471d707b9e1210b174fad823e8d" translate="yes" xml:space="preserve">
          <source>Apply clustering to a projection of the normalized Laplacian.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5fc36d5b38e5cc48bf65799eb3ba1f5f5dd4c40" translate="yes" xml:space="preserve">
          <source>Apply clustering to a projection to the normalized laplacian.</source>
          <target state="translated">Применить кластеризацию к проекции на нормализованный лацкан.</target>
        </trans-unit>
        <trans-unit id="8426b1a96ac4159519d28aa77b01e6e7ff1b8a94" translate="yes" xml:space="preserve">
          <source>Apply decision function to an array of samples.</source>
          <target state="translated">Применить функцию принятия решения к массиву образцов.</target>
        </trans-unit>
        <trans-unit id="ae4427937ffbc660a10ac85e3e1e095b79e74a1a" translate="yes" xml:space="preserve">
          <source>Apply dimensionality reduction to X using the model.</source>
          <target state="translated">Применить уменьшение размерности к Х с помощью модели.</target>
        </trans-unit>
        <trans-unit id="94efd724519284be8c4f7f9c1263433e19686d0b" translate="yes" xml:space="preserve">
          <source>Apply dimensionality reduction to X.</source>
          <target state="translated">Применить уменьшение размерности к X.</target>
        </trans-unit>
        <trans-unit id="067a30cda0bacc8769ba06b4343f4bb4f1512cf6" translate="yes" xml:space="preserve">
          <source>Apply feature map to X.</source>
          <target state="translated">Применить карту функций к X.</target>
        </trans-unit>
        <trans-unit id="019b3cb4563fab68f9b7e6cb2810fdfe13086cd9" translate="yes" xml:space="preserve">
          <source>Apply inverse transformations in reverse order</source>
          <target state="translated">Применить обратные преобразования в обратном порядке</target>
        </trans-unit>
        <trans-unit id="8ba6ffbae8fd06f4432eaf3f6080e23e84a08a61" translate="yes" xml:space="preserve">
          <source>Apply parallel or deflational algorithm for FastICA.</source>
          <target state="translated">Применить параллельный или дефляционный алгоритм для FastICA.</target>
        </trans-unit>
        <trans-unit id="052f087320408b50bb181caf401c6c09884401a8" translate="yes" xml:space="preserve">
          <source>Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).</source>
          <target state="translated">Применить подлинейное масштабирование tf,т.е.заменить tf на 1+log(tf).</target>
        </trans-unit>
        <trans-unit id="e79510482ec62ac16315b7e449f2ba4c8500bc2e" translate="yes" xml:space="preserve">
          <source>Apply the approximate feature map to X.</source>
          <target state="translated">Примените приблизительную карту объекта к X.</target>
        </trans-unit>
        <trans-unit id="125fbeef808b6029be65b8119e0b6dcb36461fee" translate="yes" xml:space="preserve">
          <source>Apply the dimension reduction learned on the train data.</source>
          <target state="translated">Применить уменьшение размеров,полученное в данных о поезде.</target>
        </trans-unit>
        <trans-unit id="ccff7a762ba43bf734237ef3a3f86ce4e5f76a2a" translate="yes" xml:space="preserve">
          <source>Apply the inverse power transformation using the fitted lambdas.</source>
          <target state="translated">Применить обратное преобразование мощности с помощью встроенных барашек.</target>
        </trans-unit>
        <trans-unit id="0977868498dbf8902c5244b7ef40fc62ab65dab8" translate="yes" xml:space="preserve">
          <source>Apply the power transform to each feature using the fitted lambdas.</source>
          <target state="translated">Приложите трансформатор питания к каждой функции,используя встроенные ламбды.</target>
        </trans-unit>
        <trans-unit id="82b34785a3e300efc01281606b13c116a0d93f34" translate="yes" xml:space="preserve">
          <source>Apply transforms to the data, and predict with the final estimator</source>
          <target state="translated">Применить трансформации к данным и предсказать с помощью конечного оценщика.</target>
        </trans-unit>
        <trans-unit id="ca1ed4363821df5fce03d98ccc01802e4bf47ad5" translate="yes" xml:space="preserve">
          <source>Apply transforms, and decision_function of the final estimator</source>
          <target state="translated">Применяет трансформации,и функция decision_function конечного оценщика</target>
        </trans-unit>
        <trans-unit id="2f4f9e2645ee8d058965cbdacfaf2a7eb9788d03" translate="yes" xml:space="preserve">
          <source>Apply transforms, and predict_log_proba of the final estimator</source>
          <target state="translated">Применить трансформации,и предсказать_log_proba конечной оценки</target>
        </trans-unit>
        <trans-unit id="476ce75d7df4464fc2850d9c9869c6985e6ab19f" translate="yes" xml:space="preserve">
          <source>Apply transforms, and predict_proba of the final estimator</source>
          <target state="translated">Применить трансформации,и предсказать_проба конечного оценщика</target>
        </trans-unit>
        <trans-unit id="4521c8878b7f577e2b39e24b7f82d01d4c53bdb4" translate="yes" xml:space="preserve">
          <source>Apply transforms, and score with the final estimator</source>
          <target state="translated">Применить трансформации,и получить балл с окончательной оценкой.</target>
        </trans-unit>
        <trans-unit id="d02b9d52a2cce495b36832a6628a7547a7253b34" translate="yes" xml:space="preserve">
          <source>Apply transforms, and score_samples of the final estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef451a675f7839fb36e9b71a5c79c50af524605d" translate="yes" xml:space="preserve">
          <source>Apply transforms, and transform with the final estimator</source>
          <target state="translated">Применить трансформации,и преобразовать с окончательной оценкой</target>
        </trans-unit>
        <trans-unit id="de81ef7ceb9f90b36294e9caf98f17d7f5fb716c" translate="yes" xml:space="preserve">
          <source>Apply trees in the ensemble to X, return leaf indices.</source>
          <target state="translated">Нанести деревья в ансамбле на Х,вернуть индексы листьев.</target>
        </trans-unit>
        <trans-unit id="46e9e1565b766b82cfa48c8669ac20be4ae1efca" translate="yes" xml:space="preserve">
          <source>Apply trees in the forest to X, return leaf indices.</source>
          <target state="translated">Нанести деревья в лесу на Х,вернуть индексы листьев.</target>
        </trans-unit>
        <trans-unit id="c1f7ec5473437cc6f706dcde780cf75354c5c9db" translate="yes" xml:space="preserve">
          <source>Approximate a kernel map using a subset of the training data.</source>
          <target state="translated">Приблизительная карта ядра с использованием подмножества обучающих данных.</target>
        </trans-unit>
        <trans-unit id="99c9230e6f99f216d46b329fe823b6165b309c69" translate="yes" xml:space="preserve">
          <source>Approximate feature map for additive chi2 kernel.</source>
          <target state="translated">Примерная карта характеристик для аддитивного ядра chi2.</target>
        </trans-unit>
        <trans-unit id="08c300a2e35faf622b6d14b8c7a89fd4c1146cc4" translate="yes" xml:space="preserve">
          <source>Approximate nearest neighbors in TSNE</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79a233ba78739efc19c54579d317a0c2897cb08a" translate="yes" xml:space="preserve">
          <source>Approximated breakdown point.</source>
          <target state="translated">Приблизительная точка пробоя.</target>
        </trans-unit>
        <trans-unit id="80c9ab0b0026778753b68f0b79aed7c300d9ec18" translate="yes" xml:space="preserve">
          <source>Approximates feature map of an RBF kernel by Monte Carlo approximation of its Fourier transform.</source>
          <target state="translated">Аппроксимирует карту характеристик ядра RBF Монте-Карло,аппроксимирующую его преобразование Фурье.</target>
        </trans-unit>
        <trans-unit id="c5cd123a52fffa6abe1c128079596542a14c93e1" translate="yes" xml:space="preserve">
          <source>Approximates feature map of the &amp;ldquo;skewed chi-squared&amp;rdquo; kernel by Monte Carlo approximation of its Fourier transform.</source>
          <target state="translated">Аппроксимирует отображение характеристик ядра &amp;laquo;скошенного хи-квадрат&amp;raquo; с помощью аппроксимации Монте-Карло его преобразования Фурье.</target>
        </trans-unit>
        <trans-unit id="0747da454303400f203ff73991292f2e6b1d8099" translate="yes" xml:space="preserve">
          <source>Approximations to the Likelihood Gradient. International Conference on Machine Learning (ICML) 2008</source>
          <target state="translated">Приближение к градиенту вероятности.Международная конференция по машинному обучению (ИКМЛ)2008 г.</target>
        </trans-unit>
        <trans-unit id="3121863aa17e74b4053a8b1b5b5e368203cc9eae" translate="yes" xml:space="preserve">
          <source>Are computed such that:</source>
          <target state="translated">вычисляются так:</target>
        </trans-unit>
        <trans-unit id="2745debaa64a20eedb49d9f14a0b807c87aa2d2a" translate="yes" xml:space="preserve">
          <source>Area</source>
          <target state="translated">Area</target>
        </trans-unit>
        <trans-unit id="40f1ed31aa37ba1df6f1e12267ca0106d885adfa" translate="yes" xml:space="preserve">
          <source>Area under ROC curve. If None, the roc_auc score is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef8721938ea54cef3b6761a4de1893a7d8b789aa" translate="yes" xml:space="preserve">
          <source>Area under ROC for the multiclass problem</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9981f730845b36824e5458276d9c866bb62f0b81" translate="yes" xml:space="preserve">
          <source>Area under the precision-recall curve</source>
          <target state="translated">Площадь под кривой точного вызова</target>
        </trans-unit>
        <trans-unit id="0d216eb7e93b45a2be7855da027249526cd9509f" translate="yes" xml:space="preserve">
          <source>Argument to the kernel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e08f171a6f1a9519e5708f61bf31cc48538834b" translate="yes" xml:space="preserve">
          <source>Arguments to send to the functional form. If empty and if fun=&amp;rsquo;logcosh&amp;rsquo;, fun_args will take value {&amp;lsquo;alpha&amp;rsquo; : 1.0}.</source>
          <target state="translated">Аргументы для отправки в функциональную форму. Если пусто и fun = 'logcosh', fun_args будет принимать значение {'alpha': 1.0}.</target>
        </trans-unit>
        <trans-unit id="c45228c98edaaa951ea722f923e4cffb69731e7a" translate="yes" xml:space="preserve">
          <source>Ariel Sharon</source>
          <target state="translated">Ариэль Шэрон</target>
        </trans-unit>
        <trans-unit id="11f09cc06ef4f6b2c8293917d6e2b9c293adc607" translate="yes" xml:space="preserve">
          <source>Array 1 for distance computation.</source>
          <target state="translated">Массив 1 для расчета расстояния.</target>
        </trans-unit>
        <trans-unit id="2b2aa765e7ec61bcc3223e5c31148344ebd52c37" translate="yes" xml:space="preserve">
          <source>Array 2 for distance computation.</source>
          <target state="translated">Массив 2 для расчета расстояния.</target>
        </trans-unit>
        <trans-unit id="8a65824231356d07c95aeae6f87001027ea0bef6" translate="yes" xml:space="preserve">
          <source>Array containing labels.</source>
          <target state="translated">Массив,содержащий этикетки.</target>
        </trans-unit>
        <trans-unit id="e6449394cdaf60dea5ac71fdd09a0ed9e9fcf7ee" translate="yes" xml:space="preserve">
          <source>Array containing numbers whose mean is desired. If &lt;code&gt;a&lt;/code&gt; is not an array, a conversion is attempted.</source>
          <target state="translated">Массив, содержащий числа, среднее значение которых требуется. Если &lt;code&gt;a&lt;/code&gt; не массив, предпринимается попытка преобразования.</target>
        </trans-unit>
        <trans-unit id="c018e704aa26bba356828629d984b5289beaf058" translate="yes" xml:space="preserve">
          <source>Array containing pairwise preference constraints (qid in svmlight format).</source>
          <target state="translated">Массив,содержащий парные ограничения предпочтений (qid в формате svmlight).</target>
        </trans-unit>
        <trans-unit id="91335d05435a126405d2a8a45dca985aad48295a" translate="yes" xml:space="preserve">
          <source>Array containing points.</source>
          <target state="translated">Массив,содержащий точки.</target>
        </trans-unit>
        <trans-unit id="6f0a003e95ad4e5813fec46743d334c40fd183c4" translate="yes" xml:space="preserve">
          <source>Array dimensions of training vector &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e25bba3f8d7bf2293b0ad16bc13aa9e306ca9914" translate="yes" xml:space="preserve">
          <source>Array mapping from feature integer indices to feature name</source>
          <target state="translated">Отображение массива от целочисленных индексов объекта до имени объекта</target>
        </trans-unit>
        <trans-unit id="ea79422025037006dbb9fa56f6952fdafa7b797f" translate="yes" xml:space="preserve">
          <source>Array mapping from feature integer indices to feature name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70e68dbf5038082528f259bb78c1b52974cdd1b7" translate="yes" xml:space="preserve">
          <source>Array of C i.e. inverse of regularization parameter values used for cross-validation.</source>
          <target state="translated">Массив С,т.е.обратный значениям параметров регуляризации,используемым для перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="f23db680f590249d8c9bf389de4a77cfbca412ab" translate="yes" xml:space="preserve">
          <source>Array of C that maps to the best scores across every class. If refit is set to False, then for each class, the best C is the average of the C&amp;rsquo;s that correspond to the best scores for each fold. &lt;code&gt;C_&lt;/code&gt; is of shape(n_classes,) when the problem is binary.</source>
          <target state="translated">Массив C, который соответствует лучшим результатам по каждому классу. Если для параметра refit установлено значение False, то для каждого класса лучшим C является среднее значение C, которые соответствуют лучшим результатам для каждой складки. &lt;code&gt;C_&lt;/code&gt; имеет форму (n_classes,), когда проблема двоичная.</target>
        </trans-unit>
        <trans-unit id="a55c3729a06f5322394066f1c0c8cd702750ec36" translate="yes" xml:space="preserve">
          <source>Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;1 / (2C)&lt;/code&gt; in other linear models such as &lt;a href=&quot;sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ee7705f66f6136357dc8015abf939ac9ba5f0a41" translate="yes" xml:space="preserve">
          <source>Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;1 / (2C)&lt;/code&gt; in other linear models such as &lt;a href=&quot;sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt;. If using generalized cross-validation, alphas must be positive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bcf7c58e5cd52bc0017cb778f5c70ae9fb7f4c3" translate="yes" xml:space="preserve">
          <source>Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to &lt;code&gt;C^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC.</source>
          <target state="translated">Массив альфа-значений, чтобы попробовать. Сила регуляризации; должен быть положительным числом с плавающей запятой. Регуляризация улучшает условия проблемы и снижает разброс оценок. Большие значения указывают на более сильную регуляризацию. Альфа соответствует &lt;code&gt;C^-1&lt;/code&gt; в других линейных моделях, таких как LogisticRegression или LinearSVC.</target>
        </trans-unit>
        <trans-unit id="56fbe430ec1266429078a0ab631106976ff42e91" translate="yes" xml:space="preserve">
          <source>Array of feature names.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f66e9a562c0b4e0d27e475880657f80a6deb9514" translate="yes" xml:space="preserve">
          <source>Array of feature-wise means to update with the new data X.</source>
          <target state="translated">Массив функциональных средств для обновления с новыми данными X.</target>
        </trans-unit>
        <trans-unit id="f6c98b4462671d9e778e0d714eb0f164a1614fcd" translate="yes" xml:space="preserve">
          <source>Array of feature-wise var to update with the new data X.</source>
          <target state="translated">Массив функциональных var для обновления с новыми данными X.</target>
        </trans-unit>
        <trans-unit id="5fcd28abe38a5e4606c96fde73b0772080b7a651" translate="yes" xml:space="preserve">
          <source>Array of images from which to extract patches. For color images, the last dimension specifies the channel: a RGB image would have &lt;code&gt;n_channels=3&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f81a8f931ec6cc551fbd84a217b7d3ae7ae6320" translate="yes" xml:space="preserve">
          <source>Array of indices to be used in a subsample. Can be of length less than n_samples in the case of a subsample, or equal to n_samples in the case of a bootstrap subsample with repeated indices. If None, the sample weight will be calculated over the full sample. Only &amp;ldquo;balanced&amp;rdquo; is supported for class_weight if this is provided.</source>
          <target state="translated">Массив индексов для использования в подвыборке. Может иметь длину меньше n_samples в случае подвыборки или равную n_samples в случае начальной подвыборки с повторяющимися индексами. Если нет, вес образца будет рассчитан по всей выборке. Только &amp;laquo;сбалансированный&amp;raquo; поддерживается для class_weight, если это предусмотрено.</target>
        </trans-unit>
        <trans-unit id="68493ef46dcb2bca2edbdc205fc9d64a4faedf4e" translate="yes" xml:space="preserve">
          <source>Array of l1_ratio that maps to the best scores across every class. If refit is set to False, then for each class, the best l1_ratio is the average of the l1_ratio&amp;rsquo;s that correspond to the best scores for each fold. &lt;code&gt;l1_ratio_&lt;/code&gt; is of shape(n_classes,) when the problem is binary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fac2540408435b364a56995dfc908b1ce3b3f1b5" translate="yes" xml:space="preserve">
          <source>Array of l1_ratios used for cross-validation. If no l1_ratio is used (i.e. penalty is not &amp;lsquo;elasticnet&amp;rsquo;), this is set to &lt;code&gt;[None]&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeab30110685755d1d6fcfd1bdec963e11fd2b40" translate="yes" xml:space="preserve">
          <source>Array of labels assigned to the input data. if partial_fit is used instead of fit, they are assigned to the last batch of data.</source>
          <target state="translated">Массив меток,назначенных входным данным.если вместо fit используется partial_fit,они назначаются последнему пакету данных.</target>
        </trans-unit>
        <trans-unit id="7713344316e6072a30843b91363d87cccda00c35" translate="yes" xml:space="preserve">
          <source>Array of matplotlib axes. &lt;code&gt;None&lt;/code&gt; if &lt;code&gt;include_values&lt;/code&gt; is false.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4370a66f6bded85adaf7548951f4179c0716e58" translate="yes" xml:space="preserve">
          <source>Array of modal values.</source>
          <target state="translated">Массив модальных значений.</target>
        </trans-unit>
        <trans-unit id="1fd74761ce4c1dfdbf88f10700afe7876dc7373c" translate="yes" xml:space="preserve">
          <source>Array of ordered feature names used in the dataset.</source>
          <target state="translated">Массив упорядоченных имен функций,используемых в наборе данных.</target>
        </trans-unit>
        <trans-unit id="0f885b177d721fef81c6f0296028811159f9ce61" translate="yes" xml:space="preserve">
          <source>Array of original class labels per sample.</source>
          <target state="translated">Массив оригинальных этикеток класса на образец.</target>
        </trans-unit>
        <trans-unit id="7800a77bf571d12be284509e1c1715411139d56e" translate="yes" xml:space="preserve">
          <source>Array of original class labels per sample;</source>
          <target state="translated">Массив оригинальных этикеток класса на образец;</target>
        </trans-unit>
        <trans-unit id="96778e504b9d48e677b9fd575a4cafc7576e9a4e" translate="yes" xml:space="preserve">
          <source>Array of pairwise distances between samples, or a feature array.</source>
          <target state="translated">Массив парных расстояний между образцами или массив функций.</target>
        </trans-unit>
        <trans-unit id="e091a26de25f0600efda87ce52273e245aa786c4" translate="yes" xml:space="preserve">
          <source>Array of pairwise kernels between samples, or a feature array.</source>
          <target state="translated">Массив парных ядер между примерами или массив функций.</target>
        </trans-unit>
        <trans-unit id="7ad46daa8cb15b6370dc0bc3d5a37d6d0d152fc8" translate="yes" xml:space="preserve">
          <source>Array of positive distances. If vertex i is connected to vertex j, then dist_matrix[i,j] gives the distance between the vertices. If vertex i is not connected to vertex j, then dist_matrix[i,j] = 0</source>
          <target state="translated">Массив положительных расстояний.Если вершина i связана с вершиной j,то dist_matrix[i,j]дает расстояние между вершинами.Если вершина i не связана с вершиной j,то dist_matrix[i,j]=0</target>
        </trans-unit>
        <trans-unit id="4e5f1b979067f81092a1e7cd9ffe302fc627e739" translate="yes" xml:space="preserve">
          <source>Array of precomputed feature-wise values to use for scaling.</source>
          <target state="translated">Массив предварительно вычисленных функциональных значений для использования при масштабировании.</target>
        </trans-unit>
        <trans-unit id="6812a29eee4afd325221734d77b9a4dae2cd6936" translate="yes" xml:space="preserve">
          <source>Array of precomputed sample-wise values to use for scaling.</source>
          <target state="translated">Массив предварительно вычисленных выборочных значений для использования при масштабировании.</target>
        </trans-unit>
        <trans-unit id="fdeed78489293ac715c2ab2eb4b0404b2b3869aa" translate="yes" xml:space="preserve">
          <source>Array of samples (test vectors).</source>
          <target state="translated">Массив образцов (тестовые векторы).</target>
        </trans-unit>
        <trans-unit id="24f920c86b265a90a5e0d4a36297a04667e3e9df" translate="yes" xml:space="preserve">
          <source>Array of samples/test vectors.</source>
          <target state="translated">Массив образцов/тестовых векторов.</target>
        </trans-unit>
        <trans-unit id="3fbc39a14b9b4da5186fad432e1588423be425d4" translate="yes" xml:space="preserve">
          <source>Array of scores of the estimator for each run of the cross validation.</source>
          <target state="translated">Массив баллов оценщика за каждый прогон перекрестной проверки.</target>
        </trans-unit>
        <trans-unit id="45ad4c3a294e4989b4c11ac5e758294b0026c988" translate="yes" xml:space="preserve">
          <source>Array of shape (Nx, D), representing Nx points in D dimensions.</source>
          <target state="translated">Массив фигур (Nx,D),представляющий точки Nx в размерах D.</target>
        </trans-unit>
        <trans-unit id="fc8b99cd3247136d0c5bc8738933867c6b7310fe" translate="yes" xml:space="preserve">
          <source>Array of shape (Ny, D), representing Ny points in D dimensions. If not specified, then Y=X.</source>
          <target state="translated">Массив фигур (Ny,D),представляющий Ny точек в D размерах.Если не указано,то Y=X.</target>
        </trans-unit>
        <trans-unit id="250d74905474bfb993e7135f2cc0cab46c1b40f6" translate="yes" xml:space="preserve">
          <source>Array of the classes occurring in the data, as given by &lt;code&gt;np.unique(y_org)&lt;/code&gt; with &lt;code&gt;y_org&lt;/code&gt; the original class labels.</source>
          <target state="translated">Массив классов, встречающихся в данных, как указано &lt;code&gt;np.unique(y_org)&lt;/code&gt; с &lt;code&gt;y_org&lt;/code&gt; исходными метками классов.</target>
        </trans-unit>
        <trans-unit id="b78e425c6e49838f94af51fc89b925b7dde837d3" translate="yes" xml:space="preserve">
          <source>Array of weighted counts for each mode.</source>
          <target state="translated">Массив взвешенных подсчетов для каждого режима.</target>
        </trans-unit>
        <trans-unit id="94dd9c0571a23f9d9a0e09a5e6b6a6f23711b3ea" translate="yes" xml:space="preserve">
          <source>Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.</source>
          <target state="translated">Массив весов,которые присваиваются индивидуальным образцам.Если он не предоставляется,то каждому образцу присваивается вес единицы.</target>
        </trans-unit>
        <trans-unit id="2d23bb743e4774802fe069cba46f38744d42d230" translate="yes" xml:space="preserve">
          <source>Array representing the cosine distances to each point, only present if return_distance=True.</source>
          <target state="translated">Массив,представляющий косинусные расстояния до каждой точки,присутствует только в том случае,если return_distance=True.</target>
        </trans-unit>
        <trans-unit id="a5f32f9aefd1234d15dbae57ece52e2602c42baf" translate="yes" xml:space="preserve">
          <source>Array representing the distances to each point, only present if return_distance=True. The distance values are computed according to the &lt;code&gt;metric&lt;/code&gt; constructor parameter.</source>
          <target state="translated">Массив, представляющий расстояния до каждой точки, присутствует, только если return_distance = True. Значения расстояния вычисляются в соответствии с параметром конструктора &lt;code&gt;metric&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="dadd9836b98c2a8bfba00660688e29f8956840ae" translate="yes" xml:space="preserve">
          <source>Array representing the lengths to points, only present if return_distance=True</source>
          <target state="translated">Массив,представляющий длины до точек,присутствует только в том случае,если return_distance=True</target>
        </trans-unit>
        <trans-unit id="128b0965caa89fb141c0f27357f3b344c8ae14e0" translate="yes" xml:space="preserve">
          <source>Array with class_weight_vect[i] the weight for i-th class</source>
          <target state="translated">Массив с class_weight_vect[i]весом для i-го класса</target>
        </trans-unit>
        <trans-unit id="8071ea6e98367794e2540e75731701074b3502c7" translate="yes" xml:space="preserve">
          <source>Array with sample weights as applied to the original y</source>
          <target state="translated">Массив с образцом веса в соответствии с исходным y</target>
        </trans-unit>
        <trans-unit id="454c01b5a8f0e04bcddbd63e1a11312ba378a0a5" translate="yes" xml:space="preserve">
          <source>Arrays containing points.</source>
          <target state="translated">Массивы,содержащие точки.</target>
        </trans-unit>
        <trans-unit id="55e1c09be8a72c22c42432b49cce52b8593ad9f3" translate="yes" xml:space="preserve">
          <source>Arrays containing points. Respective shapes (n_samples1, n_features) and (n_samples2, n_features)</source>
          <target state="translated">Массивы,содержащие точки.Соответствующие формы (n_samples1,n_features)и (n_samples2,n_features).</target>
        </trans-unit>
        <trans-unit id="617153f408d9e36a02ce1e1b9ef6e01cb4b4ace4" translate="yes" xml:space="preserve">
          <source>Arrays for storing tree data, index, node data and node bounds.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c2af9f8f5cb14e6db46f51362b9496e9213d67c" translate="yes" xml:space="preserve">
          <source>Art B. Owen (2006), A robust hybrid of lasso and ridge regression. &lt;a href=&quot;http://statweb.stanford.edu/~owen/reports/hhu.pdf&quot;&gt;http://statweb.stanford.edu/~owen/reports/hhu.pdf&lt;/a&gt;</source>
          <target state="translated">Арт Б. Оуэн (2006), Надежный гибрид лассо и регрессии гребня. &lt;a href=&quot;http://statweb.stanford.edu/~owen/reports/hhu.pdf&quot;&gt;http://statweb.stanford.edu/~owen/reports/hhu.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7c8d50e29fabbeb579c5217b8bfc0480f3d25842" translate="yes" xml:space="preserve">
          <source>Art B. Owen (2006), A robust hybrid of lasso and ridge regression. &lt;a href=&quot;https://statweb.stanford.edu/~owen/reports/hhu.pdf&quot;&gt;https://statweb.stanford.edu/~owen/reports/hhu.pdf&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="280c547a1f162abeda960694ff094a09bc3e0f0d" translate="yes" xml:space="preserve">
          <source>As &lt;code&gt;RobustScaler&lt;/code&gt;, &lt;code&gt;QuantileTransformer&lt;/code&gt; is robust to outliers in the sense that adding or removing outliers in the training set will yield approximately the same transformation on held out data. But contrary to &lt;code&gt;RobustScaler&lt;/code&gt;, &lt;code&gt;QuantileTransformer&lt;/code&gt; will also automatically collapse any outlier by setting them to the a priori defined range boundaries (0 and 1).</source>
          <target state="translated">Как &lt;code&gt;RobustScaler&lt;/code&gt; , &lt;code&gt;QuantileTransformer&lt;/code&gt; является устойчивым к выбросам в том смысле , что добавление или удаление выбросов в обучающем наборе будет давать примерно такое же преобразование на проводимых вне данных. Но вопреки &lt;code&gt;RobustScaler&lt;/code&gt; , &lt;code&gt;QuantileTransformer&lt;/code&gt; будет автоматически разрушаться любой выброс, установив их в заранее заданных границ диапазона (0 и 1).</target>
        </trans-unit>
        <trans-unit id="4f9342a94a131883760ca784477b6aa2e1e17246" translate="yes" xml:space="preserve">
          <source>As &lt;code&gt;StandardScaler&lt;/code&gt;, &lt;code&gt;MinMaxScaler&lt;/code&gt; is very sensitive to the presence of outliers.</source>
          <target state="translated">Как и &lt;code&gt;StandardScaler&lt;/code&gt; , &lt;code&gt;MinMaxScaler&lt;/code&gt; очень чувствителен к наличию выбросов.</target>
        </trans-unit>
        <trans-unit id="0473784855cee607ac3c3e8942e446aa86c45018" translate="yes" xml:space="preserve">
          <source>As &lt;code&gt;leaf_size&lt;/code&gt; increases, the memory required to store a tree structure decreases. This is especially important in the case of ball tree, which stores a \(D\)-dimensional centroid for each node. The required storage space for &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; is approximately &lt;code&gt;1 / leaf_size&lt;/code&gt; times the size of the training set.</source>
          <target state="translated">По &lt;code&gt;leaf_size&lt;/code&gt; увеличения leaf_size объем памяти, необходимый для хранения древовидной структуры, уменьшается. Это особенно важно в случае шарового дерева, в котором хранится \ (D \) -мерный центроид для каждого узла. Требуемое пространство для хранения &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt; примерно в &lt;code&gt;1 / leaf_size&lt;/code&gt; раз на размер листа больше размера обучающего набора.</target>
        </trans-unit>
        <trans-unit id="5ba99528590cd9030f3ddfaa7772e7d00f041704" translate="yes" xml:space="preserve">
          <source>As F-test captures only linear dependency, it rates x_1 as the most discriminative feature. On the other hand, mutual information can capture any kind of dependency between variables and it rates x_2 as the most discriminative feature, which probably agrees better with our intuitive perception for this example. Both methods correctly marks x_3 as irrelevant.</source>
          <target state="translated">Так как F-тест фиксирует только линейную зависимость,он оценивает x_1 как наиболее дискриминирующую характеристику.С другой стороны,взаимная информация может фиксировать любую зависимость между переменными,и она оценивает x_2 как наиболее дискриминирующую характеристику,что,вероятно,лучше согласуется с нашим интуитивным восприятием этого примера.Оба метода правильно отмечают x_3 как несущественные.</target>
        </trans-unit>
        <trans-unit id="d26c8ba867b91d66c4620ebdebaef0da4c712fd2" translate="yes" xml:space="preserve">
          <source>As \(\nu\rightarrow\infty\), the Mat&amp;eacute;rn kernel converges to the RBF kernel. When \(\nu = 1/2\), the Mat&amp;eacute;rn kernel becomes identical to the absolute exponential kernel, i.e.,</source>
          <target state="translated">Как \ (\ nu \ rightarrow \ infty \), ядро ​​Матерна сходится к ядру RBF. Когда \ (\ nu = 1/2 \), ядро ​​Матерна становится идентичным абсолютному экспоненциальному ядру, т. Е.</target>
        </trans-unit>
        <trans-unit id="fd1774dd2550566b72e9349a744134b65f1d5b37" translate="yes" xml:space="preserve">
          <source>As \(k\) becomes large compared to \(N\), the ability to prune branches in a tree-based query is reduced. In this situation, Brute force queries can be more efficient.</source>
          <target state="translated">Поскольку \(k\)становится большим по сравнению с \(N\),уменьшается возможность подрезать ветви в древовидном запросе.В этой ситуации более эффективными могут быть запросы с использованием грубой силы.</target>
        </trans-unit>
        <trans-unit id="faf1e694d41950e191ce698208593222026d0616" translate="yes" xml:space="preserve">
          <source>As a general rule, most authors, and empirical evidence, suggest that 5- or 10- fold cross validation should be preferred to LOO.</source>
          <target state="translated">Как правило,большинство авторов и эмпирические данные предполагают,что 5-или 10-кратное перекрестное подтверждение должно быть предпочтительнее LOO.</target>
        </trans-unit>
        <trans-unit id="7511794679052faea86272ecd7141a948a5ee019" translate="yes" xml:space="preserve">
          <source>As a rule of thumb you can consider that if the sparsity ratio is greater than 90% you can probably benefit from sparse formats. Check Scipy&amp;rsquo;s sparse matrix formats &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;documentation&lt;/a&gt; for more information on how to build (or convert your data to) sparse matrix formats. Most of the time the &lt;code&gt;CSR&lt;/code&gt; and &lt;code&gt;CSC&lt;/code&gt; formats work best.</source>
          <target state="translated">Как правило, вы можете принять во внимание, что если коэффициент разреженности превышает 90%, вы, вероятно, сможете извлечь выгоду из разреженных форматов. Обратитесь к &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;документации&lt;/a&gt; по форматам разреженных матриц Scipy для получения дополнительной информации о том, как создавать (или преобразовывать данные) в форматы разреженных матриц. В большинстве случаев форматы &lt;code&gt;CSR&lt;/code&gt; и &lt;code&gt;CSC&lt;/code&gt; работают лучше всего.</target>
        </trans-unit>
        <trans-unit id="e6d544b03b9c4badced861e6939e6f09869b8c86" translate="yes" xml:space="preserve">
          <source>As a rule of thumb you can consider that if the sparsity ratio is greater than 90% you can probably benefit from sparse formats. Check Scipy&amp;rsquo;s sparse matrix formats &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;documentation&lt;/a&gt; for more information on how to build (or convert your data to) sparse matrix formats. Most of the time the &lt;code&gt;CSR&lt;/code&gt; and &lt;code&gt;CSC&lt;/code&gt; formats work best.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="353bdb2ad3c8962f2cd7a3693251833639b2a66a" translate="yes" xml:space="preserve">
          <source>As a stochastic method, the loss function is not necessarily decreasing at each iteration, and convergence is only guaranteed in expectation. For this reason, monitoring the convergence on the loss function can be difficult.</source>
          <target state="translated">Как стохастический метод,функция потерь не обязательно уменьшается на каждой итерации,а сходимость гарантируется только в ожидании.По этой причине мониторинг сходимости на функции потерь может быть затруднен.</target>
        </trans-unit>
        <trans-unit id="42def8933b75f8dc81489a17ca6bf2a4d3b1aab6" translate="yes" xml:space="preserve">
          <source>As a user, you may control the backend that joblib will use (regardless of what scikit-learn recommends) by using a context manager:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c5c1051c685f7a17c464794391d76e887c975059" translate="yes" xml:space="preserve">
          <source>As alpha tends toward zero the coefficients found by Ridge regression stabilize towards the randomly sampled vector w. For big alpha (strong regularisation) the coefficients are smaller (eventually converging at 0) leading to a simpler and biased solution. These dependencies can be observed on the left plot.</source>
          <target state="translated">По мере того,как альфа-альфа стремится к нулю,коэффициенты,найденные по хребтовой регрессии,стабилизируются в направлении случайно отобранного вектора w.Для больших альфа-альф (сильная регуляризация)коэффициенты меньше (в конечном счете сходятся при 0),что приводит к более простому и смещенному решению.Эти зависимости можно наблюдать на левом графике.</target>
        </trans-unit>
        <trans-unit id="24f37f11c718f612ad3749aae9a0a774bc0cfd6c" translate="yes" xml:space="preserve">
          <source>As an alternative, the permutation importances of &lt;code&gt;rf&lt;/code&gt; are computed on a held out test set. This shows that the low cardinality categorical feature, &lt;code&gt;sex&lt;/code&gt; is the most important feature.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c04824c2f2c674faf4d7d29dd0f1d9a774a897e" translate="yes" xml:space="preserve">
          <source>As an example, consider a word-level natural language processing task that needs features extracted from &lt;code&gt;(token, part_of_speech)&lt;/code&gt; pairs. One could use a Python generator function to extract features:</source>
          <target state="translated">В качестве примера рассмотрим задачу обработки естественного языка на уровне слов, для которой требуются функции, извлеченные из пар &lt;code&gt;(token, part_of_speech)&lt;/code&gt; . Можно использовать функцию генератора Python для извлечения функций:</target>
        </trans-unit>
        <trans-unit id="440e47d9bdf54f0d76b208827e3f8a7246ce9187" translate="yes" xml:space="preserve">
          <source>As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by</source>
          <target state="translated">В качестве примера,предположим,что у нас есть набор данных с булевыми функциями,и мы хотим удалить все функции,которые являются либо одной,либо нулевыми (включенными или выключенными)в более чем 80% отсчетов.Булевы функции являются случайными переменными Бернулли,и дисперсия таких переменных дается с помощью</target>
        </trans-unit>
        <trans-unit id="0fc331775bcbccb582b3c6648f3387e8f638bc0a" translate="yes" xml:space="preserve">
          <source>As an iterable of string metrics::</source>
          <target state="translated">Как итерабельное из строковых метрик::</target>
        </trans-unit>
        <trans-unit id="670a68b39de7d2dc4b153165f015b7c7235ba10c" translate="yes" xml:space="preserve">
          <source>As an optimization problem, binary class L2 penalized logistic regression minimizes the following cost function:</source>
          <target state="translated">В качестве задачи оптимизации двоичный класс L2,наложивший штраф на логистическую регрессию,минимизирует следующую стоимостную функцию:</target>
        </trans-unit>
        <trans-unit id="f278c77eb641c2fca3187e677f3037bfd6ce972e" translate="yes" xml:space="preserve">
          <source>As an optimization problem, binary class \(\ell_2\) penalized logistic regression minimizes the following cost function:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0923a21facc4895041c36b66fbffdd3ccd57707" translate="yes" xml:space="preserve">
          <source>As currently implemented, Dijkstra&amp;rsquo;s algorithm does not work for graphs with direction-dependent distances when directed == False. i.e., if dist_matrix[i,j] and dist_matrix[j,i] are not equal and both are nonzero, method=&amp;rsquo;D&amp;rsquo; will not necessarily yield the correct result.</source>
          <target state="translated">В настоящее время реализованный алгоритм Дейкстры не работает для графов с расстояниями, зависящими от направления, когда направлено == False. то есть, если dist_matrix [i, j] и dist_matrix [j, i] не равны и оба отличны от нуля, method = 'D' не обязательно даст правильный результат.</target>
        </trans-unit>
        <trans-unit id="18ae6c61fa89653926b85f1ce590dca96bbcbbc7" translate="yes" xml:space="preserve">
          <source>As described on the original website:</source>
          <target state="translated">Как описано на оригинальном сайте:</target>
        </trans-unit>
        <trans-unit id="5aa4aad7dfb43ef2769419ae7f460971c9284dbe" translate="yes" xml:space="preserve">
          <source>As described previously, the most widely used distance function is the squared Frobenius norm, which is an obvious extension of the Euclidean norm to matrices:</source>
          <target state="translated">Как было описано выше,наиболее широко используемой функцией расстояния является квадратная норма Frobenius,которая является очевидным продолжением евклидовой нормы до матриц:</target>
        </trans-unit>
        <trans-unit id="e81ebe44fbcb1c67bb2bf8d6d2417ec1c47e735b" translate="yes" xml:space="preserve">
          <source>As expected the confusion matrix shows that posts from the newsgroups on atheism and Christianity are more often confused for one another than with computer graphics.</source>
          <target state="translated">Как и ожидалось,матрица замешательства показывает,что сообщения из новостных групп об атеизме и христианстве чаще путают друг с другом,чем с компьютерной графикой.</target>
        </trans-unit>
        <trans-unit id="a21f305b83f6ecc940d012c4c2d2b2809b12f48f" translate="yes" xml:space="preserve">
          <source>As expected, &lt;code&gt;VarianceThreshold&lt;/code&gt; has removed the first column, which has a probability \(p = 5/6 &amp;gt; .8\) of containing a zero.</source>
          <target state="translated">Как и ожидалось, &lt;code&gt;VarianceThreshold&lt;/code&gt; удалил первый столбец, который с вероятностью \ (p = 5/6&amp;gt; 0,8 \) содержит ноль.</target>
        </trans-unit>
        <trans-unit id="0a862c171ad9c6c90137a8961c4a49a8109f123e" translate="yes" xml:space="preserve">
          <source>As expected, the dummy regressor is unable to correctly rank the samples and therefore performs the worst on this plot.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1461782e678132cdda4c11cb8a9f0f36fdc4dc12" translate="yes" xml:space="preserve">
          <source>As expected, the plot suggests that 3 features are informative, while the remaining are not.</source>
          <target state="translated">Как и ожидалось,сюжет предполагает,что 3 черты являются информативными,а остальные-нет.</target>
        </trans-unit>
        <trans-unit id="21dea3d956b97f59f6554850f2e02a18d3e3f037" translate="yes" xml:space="preserve">
          <source>As for the &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt;&lt;code&gt;Normalizer&lt;/code&gt;&lt;/a&gt;, the utility class &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is meant to be used in the early stages of &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;. The &lt;code&gt;fit&lt;/code&gt; method does nothing as each sample is treated independently of others:</source>
          <target state="translated">Что касается &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt; &lt;code&gt;Normalizer&lt;/code&gt; &lt;/a&gt; , служебный класс &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt; предназначен для использования на ранних этапах &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt; . &lt;code&gt;fit&lt;/code&gt; метод не делает ничего , поскольку каждый образец обрабатывают независимо от других:</target>
        </trans-unit>
        <trans-unit id="448fad632016e4e86e34b67a2dd205dc93981193" translate="yes" xml:space="preserve">
          <source>As for the &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt;&lt;code&gt;Normalizer&lt;/code&gt;&lt;/a&gt; classes, the preprocessing module provides a companion function &lt;a href=&quot;generated/sklearn.preprocessing.binarize#sklearn.preprocessing.binarize&quot;&gt;&lt;code&gt;binarize&lt;/code&gt;&lt;/a&gt; to be used when the transformer API is not necessary.</source>
          <target state="translated">Что касается классов &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt; &lt;code&gt;Normalizer&lt;/code&gt; &lt;/a&gt; , модуль предварительной обработки предоставляет сопутствующую функцию &lt;a href=&quot;generated/sklearn.preprocessing.binarize#sklearn.preprocessing.binarize&quot;&gt; &lt;code&gt;binarize&lt;/code&gt; ,&lt;/a&gt; которая будет использоваться, когда API-интерфейс преобразователя не нужен.</target>
        </trans-unit>
        <trans-unit id="7e4621ab54b3c13fd3d03c5dfae345e68a0fd95a" translate="yes" xml:space="preserve">
          <source>As in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; centers but does not scale the input data for each feature before applying the SVD.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79a9833b8f532d00a6b35f7523ca2a620de3d115" translate="yes" xml:space="preserve">
          <source>As in the classification setting, the fit method will take as argument arrays X and y, only that in this case y is expected to have floating point values instead of integer values:</source>
          <target state="translated">Как и в настройках классификации,метод fit будет принимать в качестве аргументов массивы X и y,только то,что в данном случае y будет иметь значения с плавающей точкой,а не целочисленные значения:</target>
        </trans-unit>
        <trans-unit id="357549c786d11a83e9ad1e4e4484c10d048f813a" translate="yes" xml:space="preserve">
          <source>As is shown in the result before discretization, linear model is fast to build and relatively straightforward to interpret, but can only model linear relationships, while decision tree can build a much more complex model of the data. One way to make linear model more powerful on continuous data is to use discretization (also known as binning). In the example, we discretize the feature and one-hot encode the transformed data. Note that if the bins are not reasonably wide, there would appear to be a substantially increased risk of overfitting, so the discretizer parameters should usually be tuned under cross validation.</source>
          <target state="translated">Как видно из результата до дискретизации,линейная модель быстра на построение и относительно проста в интерпретации,но может моделировать только линейные связи,в то время как дерево решений может строить гораздо более сложную модель данных.Одним из способов сделать линейную модель более мощной на непрерывных данных является использование дискретизации (также известной как биннинг).В примере мы дискретизируем функцию и одноразовое кодирование преобразованных данных.Отметим,что если бинты не достаточно широки,то,как представляется,существенно повышается риск переподгонки,поэтому параметры дискретизатора обычно должны настраиваться под перекрестную валидацию.</target>
        </trans-unit>
        <trans-unit id="67535506d22839df286d2c74a169c907b47bc78e" translate="yes" xml:space="preserve">
          <source>As mentioned above, we can interpret LDA as assigning \(x\) to the class whose mean \(\mu_k\) is the closest in terms of Mahalanobis distance, while also accounting for the class prior probabilities. Alternatively, LDA is equivalent to first &lt;em&gt;sphering&lt;/em&gt; the data so that the covariance matrix is the identity, and then assigning \(x\) to the closest mean in terms of Euclidean distance (still accounting for the class priors).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d80681701a6bd5948db2415d41ef49851684994" translate="yes" xml:space="preserve">
          <source>As mentioned in the introduction, the total claim amount per unit of exposure can be modeled as the product of the prediction of the frequency model by the prediction of the severity model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9026eb9b1171dae37e620c4611084cbf5214d244" translate="yes" xml:space="preserve">
          <source>As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have many feature values that are zeros (typically more than 99% of them).</source>
          <target state="translated">Поскольку в большинстве документов обычно используется очень маленькое подмножество слов,используемых в корпусе,результирующая матрица будет иметь много значений признаков,которые являются нулями (обычно более 99% из них).</target>
        </trans-unit>
        <trans-unit id="80903649b427f38994df0cc2bd896c257816e4cc" translate="yes" xml:space="preserve">
          <source>As neighboring data points are more likely to lie within the same leaf of a tree, the transformation performs an implicit, non-parametric density estimation.</source>
          <target state="translated">Поскольку соседние точки данных с большей вероятностью лежат в пределах одного листа дерева,преобразование выполняет неявную,непараметрическую оценку плотности.</target>
        </trans-unit>
        <trans-unit id="604835d70709f3a91a0d5148ef02789e712875c2" translate="yes" xml:space="preserve">
          <source>As neither of these datasets have missing values, we will remove some values to create new versions with artificially missing data. The performance of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; on the full original dataset is then compared the performance on the altered datasets with the artificially missing values imputed using different techniques.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b3b8dbd06a75124d0b25055322ec22921d45503" translate="yes" xml:space="preserve">
          <source>As noted above, for small sample sizes a brute force search can be more efficient than a tree-based query. This fact is accounted for in the ball tree and KD tree by internally switching to brute force searches within leaf nodes. The level of this switch can be specified with the parameter &lt;code&gt;leaf_size&lt;/code&gt;. This parameter choice has many effects:</source>
          <target state="translated">Как отмечалось выше, для небольших размеров выборки поиск методом перебора может быть более эффективным, чем запрос на основе дерева. Этот факт учитывается в дереве шаров и дереве KD за счет внутреннего переключения на поиск методом грубой силы внутри листовых узлов. Уровень этого переключателя можно указать с помощью параметра &lt;code&gt;leaf_size&lt;/code&gt; . Этот выбор параметра имеет множество эффектов:</target>
        </trans-unit>
        <trans-unit id="02cd1e4aacf73905da270451ea593d54a1eead69" translate="yes" xml:space="preserve">
          <source>As other classifiers, &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; take as input two arrays: an array &lt;code&gt;X&lt;/code&gt; of shape &lt;code&gt;(n_samples, n_features)&lt;/code&gt; holding the training samples, and an array &lt;code&gt;y&lt;/code&gt; of class labels (strings or integers), of shape &lt;code&gt;(n_samples)&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="480621b1ef230a82c36b7031ee3539b5a66ef9c0" translate="yes" xml:space="preserve">
          <source>As other classifiers, &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; take as input two arrays: an array X of size &lt;code&gt;[n_samples,
n_features]&lt;/code&gt; holding the training samples, and an array y of class labels (strings or integers), size &lt;code&gt;[n_samples]&lt;/code&gt;:</source>
          <target state="translated">Как и другие классификаторы, &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt; принимают в качестве входных данных два массива: массив X размера &lt;code&gt;[n_samples, n_features]&lt;/code&gt; содержащий обучающие образцы, и массив y меток классов (строки или целые числа), размер &lt;code&gt;[n_samples]&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="7f73865c72a9e8a8b8d3c39d4c4f128f641ec5e7" translate="yes" xml:space="preserve">
          <source>As other classifiers, SGD has to be fitted with two arrays: an array &lt;code&gt;X&lt;/code&gt; of shape (n_samples, n_features) holding the training samples, and an array y of shape (n_samples,) holding the target values (class labels) for the training samples:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86b96557b2fb9eb69b558f788f743c67cbdf526d" translate="yes" xml:space="preserve">
          <source>As other classifiers, SGD has to be fitted with two arrays: an array X of size [n_samples, n_features] holding the training samples, and an array Y of size [n_samples] holding the target values (class labels) for the training samples:</source>
          <target state="translated">Как и другие классификаторы,SGD должен быть оснащен двумя массивами:массивом X размера [n_samples,n_features],содержащим обучающие выборки,и массивом Y размера [n_samples],содержащим целевые значения (метки классов)для обучающих выборок:</target>
        </trans-unit>
        <trans-unit id="ba8715d103d1eabb437e2b429e94c0804a44a2eb" translate="yes" xml:space="preserve">
          <source>As other classifiers, forest classifiers have to be fitted with two arrays: a sparse or dense array X of size &lt;code&gt;[n_samples, n_features]&lt;/code&gt; holding the training samples, and an array Y of size &lt;code&gt;[n_samples]&lt;/code&gt; holding the target values (class labels) for the training samples:</source>
          <target state="translated">Как и другие классификаторы, классификаторы лесов должны быть оснащены двумя массивами: разреженным или плотным массивом X размера &lt;code&gt;[n_samples, n_features]&lt;/code&gt; содержащим обучающие выборки, и массивом Y размера &lt;code&gt;[n_samples]&lt;/code&gt; , содержащим целевые значения (метки классов) для обучающие образцы:</target>
        </trans-unit>
        <trans-unit id="9d7e042981f1b86e720810a559a0b5f85e715465" translate="yes" xml:space="preserve">
          <source>As said above (see &amp;ldquo;&lt;a href=&quot;#the-pipeline&quot;&gt;The machine-learning pipeline&lt;/a&gt;&amp;rdquo;), we could also choose to scale numerical values before training the model. This can be useful to apply a similar amount regularization to all of them in the Ridge. The preprocessor is redefined in order to subtract the mean and scale variables to unit variance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d9c002345c84e7b31630185ef2325d2598748527" translate="yes" xml:space="preserve">
          <source>As scikit-learn relies heavily on Numpy/Scipy and linear algebra in general it makes sense to take explicit care of the versions of these libraries. Basically, you ought to make sure that Numpy is built using an optimized &lt;a href=&quot;https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms&quot;&gt;BLAS&lt;/a&gt; / &lt;a href=&quot;https://en.wikipedia.org/wiki/LAPACK&quot;&gt;LAPACK&lt;/a&gt; library.</source>
          <target state="translated">Поскольку scikit-learn сильно зависит от Numpy / Scipy и линейной алгебры в целом, имеет смысл явно позаботиться о версиях этих библиотек. По сути, вы должны убедиться, что Numpy построен с использованием оптимизированной библиотеки &lt;a href=&quot;https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms&quot;&gt;BLAS&lt;/a&gt; / &lt;a href=&quot;https://en.wikipedia.org/wiki/LAPACK&quot;&gt;LAPACK&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="52ae38c76153b785a0e48dca405bc79c3254bacc" translate="yes" xml:space="preserve">
          <source>As seen previously, the dataset contains columns with different data types and we need to apply a specific preprocessing for each data types. In particular categorical variables cannot be included in linear model if not coded as integers first. In addition, to avoid categorical features to be treated as ordered values, we need to one-hot-encode them. Our pre-processor will</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de312b28ec8e48929f9dedcb0b6804aa5a471fe2" translate="yes" xml:space="preserve">
          <source>As shown below, t-SNE for higher perplexities finds meaningful topology of two concentric circles, however the size and the distance of the circles varies slightly from the original. Contrary to the two circles dataset, the shapes visually diverge from S-curve topology on the S-curve dataset even for larger perplexity values.</source>
          <target state="translated">Как показано ниже,t-SNE для более высоких недоразумений находит значимую топологию двух концентрических кругов,однако размер и расстояние кругов несколько отличаются от оригинала.В отличие от набора данных по двум окружностям,формы визуально отличаются от топологии S-образной кривой на наборе данных по S-образной кривой даже при больших значениях недоумения.</target>
        </trans-unit>
        <trans-unit id="d368728d274b369ac777e6745357cba862711ccd" translate="yes" xml:space="preserve">
          <source>As such variance is dataset dependent, R&amp;sup2; may not be meaningfully comparable across different datasets. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R&amp;sup2; score of 0.0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8731c43edea0fd3a0536e8161228e2825929062b" translate="yes" xml:space="preserve">
          <source>As tf&amp;ndash;idf is very often used for text features, there is also another class called &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; that combines all the options of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; in a single model:</source>
          <target state="translated">Поскольку tf &amp;ndash; idf очень часто используется для текстовых функций, существует также другой класс, называемый &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; ,&lt;/a&gt; который объединяет все параметры &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; в одной модели:</target>
        </trans-unit>
        <trans-unit id="9ec60e63b98738f893cbc703b7a17df4dbce6a3b" translate="yes" xml:space="preserve">
          <source>As the Earth is nearly spherical, the haversine formula provides a good approximation of the distance between two points of the Earth surface, with a less than 1% error on average.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff6adce24795bb660ac39f8e682709377eb07fe5" translate="yes" xml:space="preserve">
          <source>As the Lasso regression yields sparse models, it can thus be used to perform feature selection, as detailed in &lt;a href=&quot;feature_selection#l1-feature-selection&quot;&gt;L1-based feature selection&lt;/a&gt;.</source>
          <target state="translated">Поскольку регрессия Лассо дает разреженные модели, ее можно использовать для выбора признаков, как подробно описано в &lt;a href=&quot;feature_selection#l1-feature-selection&quot;&gt;разделе &quot;Выбор объектов на основе L1&quot;&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="dc66d7007c269247f1b0a3bd5e17ce48735d32b4" translate="yes" xml:space="preserve">
          <source>As the algorithm tries to balance the volume (ie balance the region sizes), if we take circles with different sizes, the segmentation fails.</source>
          <target state="translated">Так как алгоритм пытается сбалансировать объем (т.е.сбалансировать размеры региона),то если взять круги с разными размерами,то сегментация не удастся.</target>
        </trans-unit>
        <trans-unit id="ca54f3bcc5c655eebc87fa446a643204f651e5fe" translate="yes" xml:space="preserve">
          <source>As the ground truth is known here, we also apply different cluster quality metrics to judge the goodness of fit of the cluster labels to the ground truth.</source>
          <target state="translated">Как земля истина известна здесь,мы также применяем различные метрики качества кластера,чтобы судить о хорошей пригодности кластерных этикеток к земле истина.</target>
        </trans-unit>
        <trans-unit id="26f19c73cbdda7d655c1c419bc1b28d6aee89730" translate="yes" xml:space="preserve">
          <source>As the negative of a distance, this kernel is only conditionally positive definite.</source>
          <target state="translated">Как отрицатель расстояния,это ядро является только условно положительным определённым.</target>
        </trans-unit>
        <trans-unit id="74315005f7ce6ac1c1dafe71dd19e66293fa501a" translate="yes" xml:space="preserve">
          <source>As the prior on the weights is a Gaussian prior, the histogram of the estimated weights is Gaussian.</source>
          <target state="translated">Поскольку предыдущая гистограмма весов является гауссовской,гистограмма предполагаемых весов-гауссовской.</target>
        </trans-unit>
        <trans-unit id="f78b7e4ef3de6f9908e43081399b599b6d846fba" translate="yes" xml:space="preserve">
          <source>As this algorithm maximizes only the likelihood, it will not bias the means towards zero, or bias the cluster sizes to have specific structures that might or might not apply.</source>
          <target state="translated">Поскольку этот алгоритм максимизирует только вероятность,он не будет сбрасывать средства к нулю или смещать размеры кластеров,чтобы иметь специфические структуры,которые могут применяться или не применяться.</target>
        </trans-unit>
        <trans-unit id="492cebfc31b9e0ae2de0bb7669534987ce58057c" translate="yes" xml:space="preserve">
          <source>As usual the best way to adjust the feature extraction parameters is to use a cross-validated grid search, for instance by pipelining the feature extractor with a classifier:</source>
          <target state="translated">Как обычно,лучший способ регулировки параметров извлечения объекта-это использование перекрестного поиска по сетке,например,путем обвязки экстрактора объекта с помощью классификатора:</target>
        </trans-unit>
        <trans-unit id="ea78a4c7988b659783feac98fcd695de89f8d61f" translate="yes" xml:space="preserve">
          <source>As we have seen, every estimator exposes a &lt;code&gt;score&lt;/code&gt; method that can judge the quality of the fit (or the prediction) on new data. &lt;strong&gt;Bigger is better&lt;/strong&gt;.</source>
          <target state="translated">Как мы видели, каждый оценщик предоставляет метод &lt;code&gt;score&lt;/code&gt; который может судить о качестве соответствия (или прогноза) на новых данных. &lt;strong&gt;Больше - лучше&lt;/strong&gt; .</target>
        </trans-unit>
        <trans-unit id="fff4f5f3ab6438d863abba19bbb7c007a060f360" translate="yes" xml:space="preserve">
          <source>As we&amp;rsquo;ll see, some cross-validation objects do specific things with labeled data, others behave differently with grouped data, and others do not use this information.</source>
          <target state="translated">Как мы увидим, некоторые объекты перекрестной проверки выполняют определенные действия с помеченными данными, другие по-разному ведут себя с сгруппированными данными, а третьи не используют эту информацию.</target>
        </trans-unit>
        <trans-unit id="c2a5e94d01ebd06105b2b62c25b4b493ea944024" translate="yes" xml:space="preserve">
          <source>As with &lt;a href=&quot;generated/sklearn.preprocessing.scale#sklearn.preprocessing.scale&quot;&gt;&lt;code&gt;scale&lt;/code&gt;&lt;/a&gt;, the module further provides convenience functions &lt;a href=&quot;generated/sklearn.preprocessing.minmax_scale#sklearn.preprocessing.minmax_scale&quot;&gt;&lt;code&gt;minmax_scale&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.maxabs_scale#sklearn.preprocessing.maxabs_scale&quot;&gt;&lt;code&gt;maxabs_scale&lt;/code&gt;&lt;/a&gt; if you don&amp;rsquo;t want to create an object.</source>
          <target state="translated">Как и в случае с &lt;a href=&quot;generated/sklearn.preprocessing.scale#sklearn.preprocessing.scale&quot;&gt; &lt;code&gt;scale&lt;/code&gt; &lt;/a&gt; , модуль дополнительно предоставляет удобные функции &lt;a href=&quot;generated/sklearn.preprocessing.minmax_scale#sklearn.preprocessing.minmax_scale&quot;&gt; &lt;code&gt;minmax_scale&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;generated/sklearn.preprocessing.maxabs_scale#sklearn.preprocessing.maxabs_scale&quot;&gt; &lt;code&gt;maxabs_scale&lt;/code&gt; ,&lt;/a&gt; если вы не хотите создавать объект.</target>
        </trans-unit>
        <trans-unit id="c97bbdc8d450f400aad05e1727632d201bf17f90" translate="yes" xml:space="preserve">
          <source>As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values:</source>
          <target state="translated">Как и в классификационных классах,метод fit будет принимать в качестве аргумента векторы X,y,только то,что в данном случае y будет иметь значения с плавающей точкой,а не целочисленные значения:</target>
        </trans-unit>
        <trans-unit id="320d01bbc29ff09708f415fa50fd9da6e6972d95" translate="yes" xml:space="preserve">
          <source>As with other classifiers, &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; takes as input two arrays: an array X, sparse or dense, of size &lt;code&gt;[n_samples, n_features]&lt;/code&gt; holding the training samples, and an array Y of integer values, size &lt;code&gt;[n_samples]&lt;/code&gt;, holding the class labels for the training samples:</source>
          <target state="translated">Как и другие классификаторы, &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt; принимает в качестве входных данных два массива: массив X, разреженный или плотный, размером &lt;code&gt;[n_samples, n_features]&lt;/code&gt; содержащий обучающие образцы, и массив Y целочисленных значений, размер &lt;code&gt;[n_samples]&lt;/code&gt; , содержащий метки классов для обучающие образцы:</target>
        </trans-unit>
        <trans-unit id="211544b1f9de9dd9d971b4d12a5c9dd1ee84dd6a" translate="yes" xml:space="preserve">
          <source>As with other linear models, &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; will take in its &lt;code&gt;fit&lt;/code&gt; method arrays X, y and will store the coefficients \(w\) of the linear model in its &lt;code&gt;coef_&lt;/code&gt; member:</source>
          <target state="translated">Как и с другими линейными моделями, &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; будет принимать в &lt;code&gt;fit&lt;/code&gt; метод массивов X, Y и будет хранить коэффициенты \ (ш \) линейная модель в ее &lt;code&gt;coef_&lt;/code&gt; члене:</target>
        </trans-unit>
        <trans-unit id="0550c97cec757ba988ca448a8879bb1fa8d6048a" translate="yes" xml:space="preserve">
          <source>As you can imagine, if one extracts such a context around each individual word of a corpus of documents the resulting matrix will be very wide (many one-hot-features) with most of them being valued to zero most of the time. So as to make the resulting data structure able to fit in memory the &lt;code&gt;DictVectorizer&lt;/code&gt; class uses a &lt;code&gt;scipy.sparse&lt;/code&gt; matrix by default instead of a &lt;code&gt;numpy.ndarray&lt;/code&gt;.</source>
          <target state="translated">Как вы можете себе представить, если выделить такой контекст вокруг каждого отдельного слова в корпусе документов, результирующая матрица будет очень широкой (много однозначных функций), и большинство из них большую часть времени оцениваются равными нулю. Таким образом , чтобы сделать полученную структуру данных в состоянии вписаться в памяти &lt;code&gt;DictVectorizer&lt;/code&gt; класс использует &lt;code&gt;scipy.sparse&lt;/code&gt; матрицы по умолчанию вместо &lt;code&gt;numpy.ndarray&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bf1b1999c59fa9b3c0bf1aeb80e6b35e3cde33f4" translate="yes" xml:space="preserve">
          <source>As you can see, by default the KFold cross-validation iterator does not take either datapoint class or group into consideration. We can change this by using the &lt;code&gt;StratifiedKFold&lt;/code&gt; like so.</source>
          <target state="translated">Как видите, по умолчанию итератор перекрестной проверки KFold не принимает во внимание ни класс точки данных, ни группу. Мы можем изменить это, используя &lt;code&gt;StratifiedKFold&lt;/code&gt; вот так.</target>
        </trans-unit>
        <trans-unit id="4243f9f7d96f83f5f8fe40416e149534c5c3a7c1" translate="yes" xml:space="preserve">
          <source>As you can see, it is a challenging task: after all, the images are of poor resolution. Do you agree with the classifier?</source>
          <target state="translated">Как видите,это непростая задача:в конце концов,изображения имеют плохое разрешение.Вы согласны с классификатором?</target>
        </trans-unit>
        <trans-unit id="91d172a6c45b01ca0f06c000f8b26183873978d6" translate="yes" xml:space="preserve">
          <source>As you can see, it returns [[0.5]], and [[2]], which means that the element is at distance 0.5 and is the third element of samples (indexes start at 0). You can also query for multiple points:</source>
          <target state="translated">Как видно,возвращается [[0.5]],и [[2]],что означает,что элемент находится на расстоянии 0.5 и является третьим элементом выборки (индексы начинаются с 0).Можно также запросить несколько точек:</target>
        </trans-unit>
        <trans-unit id="285f08a9d27e1e1ebbb2de47dbd27bd9e8a8b2c7" translate="yes" xml:space="preserve">
          <source>As you can see, the &lt;code&gt;[1, 0]&lt;/code&gt; is comfortably classified as &lt;code&gt;1&lt;/code&gt; since the first two samples are ignored due to their sample weights.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1273827574a8e654ba4e8fa3b455e8b899058288" translate="yes" xml:space="preserve">
          <source>Ash</source>
          <target state="translated">Ash</target>
        </trans-unit>
        <trans-unit id="7e00bdd748db07e532eed9a3a30221202b903645" translate="yes" xml:space="preserve">
          <source>Ash:</source>
          <target state="translated">Ash:</target>
        </trans-unit>
        <trans-unit id="fa6467e4d61dfb46a998615f44d406b657f3e65c" translate="yes" xml:space="preserve">
          <source>Assign a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices).</source>
          <target state="translated">Присваивать фиксированный целочисленный идентификатор каждому слову,встречающемуся в любом документе учебного набора (например,путем построения словаря из слов в целые индексы).</target>
        </trans-unit>
        <trans-unit id="07fb5452be9437f82662fee13a0f5824d7cc38d4" translate="yes" xml:space="preserve">
          <source>Assign biclusters from one set to another in a one-to-one fashion to maximize the sum of their similarities. This step is performed using the Hungarian algorithm.</source>
          <target state="translated">Назначайте библлюстеры из одного набора в другой один-на-один,чтобы максимизировать сумму их сходства.Этот шаг выполняется с использованием венгерского алгоритма.</target>
        </trans-unit>
        <trans-unit id="341c86e4b7fe6ff7ce7735c5402c926cbe3cd37f" translate="yes" xml:space="preserve">
          <source>Assume that there are no ties in y_score (which is likely to be the case if y_score is continuous) for efficiency gains.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eeab86fb8cce55c225e83b0d2dc18f408531cb78" translate="yes" xml:space="preserve">
          <source>Assume two label assignments (of the same N objects), \(U\) and \(V\). Their entropy is the amount of uncertainty for a partition set, defined by:</source>
          <target state="translated">Допустим,два назначения меток (одних и тех же N объектов),\(U\)и \(V\).Их энтропия-это величина неопределенности для набора простенков,определяемая:</target>
        </trans-unit>
        <trans-unit id="0e5d6eebf8d779ccbfdee109f1d6bfd1baee97c2" translate="yes" xml:space="preserve">
          <source>Assuming that some data is Independent and Identically Distributed (i.i.d.) is making the assumption that all samples stem from the same generative process and that the generative process is assumed to have no memory of past generated samples.</source>
          <target state="translated">Предполагая,что некоторые данные являются независимыми и идентично распределенными (i.i.d.),можно предположить,что все образцы происходят от одного и того же генеративного процесса,и что генеративный процесс,как предполагается,не имеет памяти о прошлых образцах.</target>
        </trans-unit>
        <trans-unit id="fc888006cf2fe36cad38d794da87b3aa0beb9fc6" translate="yes" xml:space="preserve">
          <source>At each stage the decision tree \(h_m(x)\) is chosen to minimize the loss function \(L\) given the current model \(F_{m-1}\) and its fit \(F_{m-1}(x_i)\)</source>
          <target state="translated">На каждом этапе для минимизации убыточной функции \(h_m(x)\)выбирается дерево решений \(h_m(x)L\)с учетом текущей модели \(F_{m-1}\)и ее соответствия \(F_{m-1}(x_i)\).</target>
        </trans-unit>
        <trans-unit id="bfe84c1effa1f2d8d0a150671e591a10f6f5331c" translate="yes" xml:space="preserve">
          <source>At first, a linear model will be applied on the original targets. Due to the non-linearity, the model trained will not be precise during the prediction. Subsequently, a logarithmic function is used to linearize the targets, allowing better prediction even with a similar linear model as reported by the median absolute error (MAE).</source>
          <target state="translated">Сначала будет применена линейная модель к исходным целям.В связи с нелинейностью,подготовленная модель не будет точной во время прогнозирования.Впоследствии для линеаризации целей используется логарифмическая функция,позволяющая лучше предсказывать даже при аналогичной линейной модели,о которой сообщает средняя абсолютная погрешность (MAE).</target>
        </trans-unit>
        <trans-unit id="3103892102cc58ce3e902fe26301aa542c051586" translate="yes" xml:space="preserve">
          <source>At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen.</source>
          <target state="translated">В подходящее время устанавливается один бинарный классификатор на бит в кодовой книге.В момент прогнозирования классификаторы используются для проецирования новых точек в пространстве классов и выбирается класс,наиболее близкий к точкам.</target>
        </trans-unit>
        <trans-unit id="a0707d969d20d6e3136e641e1fe81f003f9dea63" translate="yes" xml:space="preserve">
          <source>At learning time, this simply consists in learning one regressor or binary classifier per class. In doing so, one needs to convert multi-class labels to binary labels (belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method.</source>
          <target state="translated">В учебное время это просто состоит в изучении одного регрессора или двоичного классификатора на класс.При этом необходимо преобразовать метки нескольких классов в двоичные метки (принадлежащие или не принадлежащие классу).LabelBinarizer облегчает этот процесс с помощью метода преобразования.</target>
        </trans-unit>
        <trans-unit id="934e61570171dfc9a4fde1dc5a30d65977fe4f97" translate="yes" xml:space="preserve">
          <source>At prediction time, one assigns the class for which the corresponding model gave the greatest confidence. LabelBinarizer makes this easy with the inverse_transform method.</source>
          <target state="translated">В момент прогнозирования присваивается класс,для которого соответствующая модель дала наибольшую уверенность.LabelBinarizer упрощает это с помощью метода inverse_transform.</target>
        </trans-unit>
        <trans-unit id="01685dbfb47dea411fa9fd7d65acd3b07b6bad19" translate="yes" xml:space="preserve">
          <source>At present, no metric in &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; supports the multioutput-multiclass classification task.</source>
          <target state="translated">В настоящее время ни одна метрика в &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; не&lt;/a&gt; поддерживает задачу классификации нескольких выходов и нескольких классов.</target>
        </trans-unit>
        <trans-unit id="e6b9e03e5fa2d5e24dd0fa35a80f06e2085ef3ae" translate="yes" xml:space="preserve">
          <source>At the end, the top 10 most uncertain predictions will be shown.</source>
          <target state="translated">В конце будет показана десятка самых неопределенных прогнозов.</target>
        </trans-unit>
        <trans-unit id="7dcf986df80f51359fc05a76ec4e2e0108cdc275" translate="yes" xml:space="preserve">
          <source>At the moment, we also don&amp;rsquo;t allow &amp;ldquo;multiclass-multioutput&amp;rdquo; input type.</source>
          <target state="translated">На данный момент мы также не разрешаем ввод типа &amp;laquo;мультикласс - несколько выходов&amp;raquo;.</target>
        </trans-unit>
        <trans-unit id="c524e1372c32ce7785a6874af380c32795f14a92" translate="yes" xml:space="preserve">
          <source>At the time of writing (2019), NumPy and SciPy packages distributed on pypi.org (used by &lt;code&gt;pip&lt;/code&gt;) and on the conda-forge channel are linked with OpenBLAS, while conda packages shipped on the &amp;ldquo;defaults&amp;rdquo; channel from anaconda.org are linked by default with MKL.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9df8fa75ddc8543ff453e545d20ad90388cfe52d" translate="yes" xml:space="preserve">
          <source>Atlas (need hardware specific tuning by rebuilding on the target machine)</source>
          <target state="translated">Атлас (нуждается в специфической настройке аппаратуры путем перестройки на целевой машине)</target>
        </trans-unit>
        <trans-unit id="ea953d1f635660a779a7b571a3caa0a7e2c19942" translate="yes" xml:space="preserve">
          <source>Attribute Information</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f84e7881c1e8ab9dc1a7da3d9d41fc35c6c92bb" translate="yes" xml:space="preserve">
          <source>Attribute Information (in order)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="023272de4f331b86e2df4744d3b1e32a0350f127" translate="yes" xml:space="preserve">
          <source>Attribute Information (in order):</source>
          <target state="translated">Атрибутивная информация (по порядку):</target>
        </trans-unit>
        <trans-unit id="f66b29f74a8ebab57ad67bac7a0ee9e151e247d3" translate="yes" xml:space="preserve">
          <source>Attribute Information:</source>
          <target state="translated">Атрибутивная информация:</target>
        </trans-unit>
        <trans-unit id="08359a131c436e0cfbcef05e6e7b301827c6d117" translate="yes" xml:space="preserve">
          <source>Attribute name(s) given as string or a list/tuple of strings Eg.: &lt;code&gt;[&quot;coef_&quot;, &quot;estimator_&quot;, ...], &quot;coef_&quot;&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3d9c6c9c4fb8ae7805f1c9bc9a51e56b622aec7" translate="yes" xml:space="preserve">
          <source>Attribute to access any fitted sub-estimators by name.</source>
          <target state="translated">Атрибут для доступа к любым установленным субоценщикам по имени.</target>
        </trans-unit>
        <trans-unit id="e30390c6b25519953f15954ce4132cba67fdd587" translate="yes" xml:space="preserve">
          <source>AttributeError</source>
          <target state="translated">AttributeError</target>
        </trans-unit>
        <trans-unit id="a6652617f2c799eb11ee727b16c5646c48af6905" translate="yes" xml:space="preserve">
          <source>Attributes</source>
          <target state="translated">Attributes</target>
        </trans-unit>
        <trans-unit id="12b65a8e129440be6a666c5f76241c3731cf3a1b" translate="yes" xml:space="preserve">
          <source>Attributes of named_steps map to keys, enabling tab completion in interactive environments:</source>
          <target state="translated">Атрибуты карты names_steps для ключей,позволяющей заполнение табуляции в интерактивных средах:</target>
        </trans-unit>
        <trans-unit id="b8087185e5ee37cef4c337de5697d35d75d909fd" translate="yes" xml:space="preserve">
          <source>Attributes:</source>
          <target state="translated">Attributes:</target>
        </trans-unit>
        <trans-unit id="662dd9f8d8390601f16824595a7c397648198b36" translate="yes" xml:space="preserve">
          <source>Augment dataset with an additional dummy feature.</source>
          <target state="translated">Набор данных дополнения с дополнительной функцией манекена.</target>
        </trans-unit>
        <trans-unit id="6060232846b2935a9975d9bd33986976db84e5d5" translate="yes" xml:space="preserve">
          <source>Authors : Kemal Eren License: BSD 3 clause</source>
          <target state="translated">Авторы:Лицензия Kemal Eren:BSD 3 пункт</target>
        </trans-unit>
        <trans-unit id="c8696543eb048b80bb9394a738477bc586b5e9f7" translate="yes" xml:space="preserve">
          <source>Authors: &lt;a href=&quot;mailto:mks542%40nyu.edu&quot;&gt;Manoj Kumar&lt;/a&gt;, &lt;a href=&quot;https://github.com/maikia&quot;&gt;Maria Telenczuk&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b98ce7a4dae4be4f8e868a70ee741cf11d8125c8" translate="yes" xml:space="preserve">
          <source>Automatic Relevance Determination Regression (ARD)</source>
          <target state="translated">Автоматическое определение релевантности регрессии (ARD)</target>
        </trans-unit>
        <trans-unit id="79d2e9f45916ec9baf098fb8e9c666bf3b326d9b" translate="yes" xml:space="preserve">
          <source>Automatic grouping of similar objects into sets.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef442c781e8f4741229b1581adda336c7e2079fb" translate="yes" xml:space="preserve">
          <source>Automatic selection</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1af4aed4c1976557d8776224b00250d32e50c1e" translate="yes" xml:space="preserve">
          <source>Automatic selection:</source>
          <target state="translated">Автоматический выбор:</target>
        </trans-unit>
        <trans-unit id="023744d610124c3af17954739cd092606ebe3ff4" translate="yes" xml:space="preserve">
          <source>Automatically extract clusters according to the Xi-steep method.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cfaabc56d1e51ca7fb8958edc60fddd81d43492" translate="yes" xml:space="preserve">
          <source>Available Metrics</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66f9440a5b62bebabad643e5080d2b83ccab9f91" translate="yes" xml:space="preserve">
          <source>Available Metrics The following lists the string metric identifiers and the associated distance metric classes:</source>
          <target state="translated">Доступные метрики Ниже перечислены строковые метрические идентификаторы и связанные с ними метрические классы расстояний:</target>
        </trans-unit>
        <trans-unit id="7d386374f19b16d2a68aae1af1097f01c0217752" translate="yes" xml:space="preserve">
          <source>Available losses for regression are &amp;lsquo;least_squares&amp;rsquo;, &amp;lsquo;least_absolute_deviation&amp;rsquo;, which is less sensitive to outliers, and &amp;lsquo;poisson&amp;rsquo;, which is well suited to model counts and frequencies. For classification, &amp;lsquo;binary_crossentropy&amp;rsquo; is used for binary classification and &amp;lsquo;categorical_crossentropy&amp;rsquo; is used for multiclass classification. By default the loss is &amp;lsquo;auto&amp;rsquo; and will select the appropriate loss depending on &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt; passed to &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eca931fa62c0bd7287f5c68d38715d784e965be8" translate="yes" xml:space="preserve">
          <source>AveBedrms average number of bedrooms</source>
          <target state="translated">AveBedrms среднее количество спален</target>
        </trans-unit>
        <trans-unit id="a283071b7681c2d8946f1976d0c70df9b6239788" translate="yes" xml:space="preserve">
          <source>AveOccup average house occupancy</source>
          <target state="translated">средняя вместимость дома AveOccup</target>
        </trans-unit>
        <trans-unit id="17df5670db0dd155c5ad44fbbe5780684721e711" translate="yes" xml:space="preserve">
          <source>AveRooms average number of rooms</source>
          <target state="translated">AveRooms среднее количество номеров</target>
        </trans-unit>
        <trans-unit id="09b414b4c6acadd2002166fddf247cff6dfe513e" translate="yes" xml:space="preserve">
          <source>Average anomaly score of X of the base classifiers.</source>
          <target state="translated">Средняя оценка аномалии X базовых классификаторов.</target>
        </trans-unit>
        <trans-unit id="aaed8a8037e41bff9561818c652346d8c7001f53" translate="yes" xml:space="preserve">
          <source>Average blood pressure</source>
          <target state="translated">Среднее давление</target>
        </trans-unit>
        <trans-unit id="6a54e71704b0c1b179b46e11f33d130b77d3a0d5" translate="yes" xml:space="preserve">
          <source>Average hinge loss (non-regularized)</source>
          <target state="translated">Средняя потеря шарниров (не регуляризованная)</target>
        </trans-unit>
        <trans-unit id="6b044db8b528a2f509603d248114c200773b5ebd" translate="yes" xml:space="preserve">
          <source>Average log-likelihood of the samples under the current model</source>
          <target state="translated">Средняя лог-вероятность образцов при текущей модели</target>
        </trans-unit>
        <trans-unit id="eb68b4c700400b34d7c3583315c40c631209f07e" translate="yes" xml:space="preserve">
          <source>Average log-likelihood of the samples under the current model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c993da9cb729cacf8ff6fdcfed939fa26cd8fbe9" translate="yes" xml:space="preserve">
          <source>Average of each column of kernel matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85f369d4432a9c6380c3e6b6c74d7a111da4715c" translate="yes" xml:space="preserve">
          <source>Average of kernel matrix</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0fd4fa14e78cac718fcf8ea4ba2f14bf0250758" translate="yes" xml:space="preserve">
          <source>Average of the decision functions of the base classifiers.</source>
          <target state="translated">Среднее значение функций принятия решений базовых классификаторов.</target>
        </trans-unit>
        <trans-unit id="6599ad46541efb6c59215eff61a003e0c6f84646" translate="yes" xml:space="preserve">
          <source>Average precision. If None, the average precision is not shown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af6f79d617c2284de9fdf1ff445ccb0bef8560e1" translate="yes" xml:space="preserve">
          <source>Averaged weights assigned to the features.</source>
          <target state="translated">Средние веса,присвоенные функциям.</target>
        </trans-unit>
        <trans-unit id="f2d4013e90ff32393ce2936382f74ff4d17a82cb" translate="yes" xml:space="preserve">
          <source>Averaged weights assigned to the features. Only available if &lt;code&gt;average=True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="964142eff5ddb8396f41dd41083f429f4f575768" translate="yes" xml:space="preserve">
          <source>Avoid computation of the row norms of X.</source>
          <target state="translated">Избегайте вычисления норм строки X.</target>
        </trans-unit>
        <trans-unit id="9941876a6243b1a2b044ada9bc274f0eac824c27" translate="yes" xml:space="preserve">
          <source>Axes object to plot on. If &lt;code&gt;None&lt;/code&gt;, a new figure and axes is created.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdbc35f14da17d95fedf51be8b6d0e5ffbe47113" translate="yes" xml:space="preserve">
          <source>Axes to plot to. If None, use current axis. Any previous content is cleared.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4301ccb7939c0c6e359abdb2441c99fb2531f767" translate="yes" xml:space="preserve">
          <source>Axes with ROC Curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ff3b86b5f5ed2e8ea1a56f1b370527db0b52d66c" translate="yes" xml:space="preserve">
          <source>Axes with confusion matrix.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d788fc3169dcbb97f9fc05c8f3617be236c43224" translate="yes" xml:space="preserve">
          <source>Axes with precision recall curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94256a7c3ba8c276f8434ee8dd2981a7e1ebede5" translate="yes" xml:space="preserve">
          <source>Axis along which the argmin and distances are to be computed.</source>
          <target state="translated">Ось,по которой должны быть рассчитаны аргомин и расстояния.</target>
        </trans-unit>
        <trans-unit id="9912ed29fe6a32ef154522ba9276f54ba95862ff" translate="yes" xml:space="preserve">
          <source>Axis along which the axis should be computed.</source>
          <target state="translated">Ось,вдоль которой должна быть рассчитана ось.</target>
        </trans-unit>
        <trans-unit id="e908ee13d1946f0bd5dd05b5fc4432878bcf585b" translate="yes" xml:space="preserve">
          <source>Axis along which to operate. Default is 0, i.e. the first axis.</source>
          <target state="translated">Ось,по которой нужно действовать.По умолчанию 0,т.е.первая ось.</target>
        </trans-unit>
        <trans-unit id="5bcbcdbcc90358e775edd4243e64cbf53abf5bcb" translate="yes" xml:space="preserve">
          <source>Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.</source>
          <target state="translated">Оси или оси,по которым рассчитываются средства.По умолчанию вычисляется среднее значение сплющенного массива.</target>
        </trans-unit>
        <trans-unit id="ebbac4e2a88e22f8f6d03a59528261348ca05f77" translate="yes" xml:space="preserve">
          <source>Axis used to compute the means and standard deviations along. If 0, transform each feature, otherwise (if 1) transform each sample.</source>
          <target state="translated">Ось,используемая для вычисления средств и стандартных отклонений.Если 0,преобразовать каждый признак,в противном случае (если 1)преобразовать каждый образец.</target>
        </trans-unit>
        <trans-unit id="1f1b4d8a7c2bf89e7c753b7dde1a7de7538ad410" translate="yes" xml:space="preserve">
          <source>Axis used to scale along. If 0, independently scale each feature, otherwise (if 1) scale each sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae4f281df5a5d0ff3cad6371f76d5c29b6d953ec" translate="yes" xml:space="preserve">
          <source>B</source>
          <target state="translated">B</target>
        </trans-unit>
        <trans-unit id="f9392f6fda3d4e0cffc8528669a8abc510a0238a" translate="yes" xml:space="preserve">
          <source>B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</source>
          <target state="translated">B 1000(Bk-0.63)^2 где Bk-доля черных по городу</target>
        </trans-unit>
        <trans-unit id="0286abf8af6c149d27c85dea93b91d7cc057559a" translate="yes" xml:space="preserve">
          <source>B. C. Ross &amp;ldquo;Mutual Information between Discrete and Continuous Data Sets&amp;rdquo;. PLoS ONE 9(2), 2014.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e776d2e85d14b59e337010c96ae3a1db78bda84a" translate="yes" xml:space="preserve">
          <source>B12</source>
          <target state="translated">B12</target>
        </trans-unit>
        <trans-unit id="598b91099876ac145b645491cf669799147b8703" translate="yes" xml:space="preserve">
          <source>Back-projection to the original space.</source>
          <target state="translated">Обратная проекция в оригинальное пространство.</target>
        </trans-unit>
        <trans-unit id="e935196220898869d9edfac83ba997f81f0fb5f8" translate="yes" xml:space="preserve">
          <source>Bad (e.g. independent labelings) have negative or close to 0.0 scores:</source>
          <target state="translated">Плохие (например,независимые маркировки)имеют отрицательные или близкие к 0,0 баллы:</target>
        </trans-unit>
        <trans-unit id="739e4c11d3b87131b9d408fbaefcc186a18d8f06" translate="yes" xml:space="preserve">
          <source>Bad (e.g. independent labelings) have non-positive scores:</source>
          <target state="translated">Плохие (например,независимые маркировки)имеют неположительные оценки:</target>
        </trans-unit>
        <trans-unit id="3594d99d3d09849089991e6e49125443f8f3dc1b" translate="yes" xml:space="preserve">
          <source>Bad (e.g. independent labelings) have zero scores:</source>
          <target state="translated">Плохие (например,независимые маркировки)имеют нулевые оценки:</target>
        </trans-unit>
        <trans-unit id="ab5267c44135f5b9260b00b1b8283ecbffae624a" translate="yes" xml:space="preserve">
          <source>Bagging methods come in many flavours but mostly differ from each other by the way they draw random subsets of the training set:</source>
          <target state="translated">Методы упаковки приходят во многих вкусах,но в основном отличаются друг от друга тем,как они рисуют случайные подмножества тренировочного набора:</target>
        </trans-unit>
        <trans-unit id="c18dc564424c60fd05a12c3420895fdf2cfdfe52" translate="yes" xml:space="preserve">
          <source>Bags of words</source>
          <target state="translated">Мешки с текстом</target>
        </trans-unit>
        <trans-unit id="c108b519256622b208a24e6481a9d957224afa52" translate="yes" xml:space="preserve">
          <source>Balance model complexity and cross-validated score</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95bff14a4bbf238a2164b4e0cae458c0fe2685ef" translate="yes" xml:space="preserve">
          <source>Balance your dataset before training to prevent the tree from being biased toward the classes that are dominant. Class balancing can be done by sampling an equal number of samples from each class, or preferably by normalizing the sum of the sample weights (&lt;code&gt;sample_weight&lt;/code&gt;) for each class to the same value. Also note that weight-based pre-pruning criteria, such as &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt;, will then be less biased toward dominant classes than criteria that are not aware of the sample weights, like &lt;code&gt;min_samples_leaf&lt;/code&gt;.</source>
          <target state="translated">Сбалансируйте набор данных перед обучением, чтобы дерево не смещалось в сторону доминирующих классов. Балансировка классов может быть выполнена путем выборки равного количества выборок из каждого класса или, предпочтительно, путем нормализации суммы весов выборок ( &lt;code&gt;sample_weight&lt;/code&gt; ) для каждого класса к одному и тому же значению. Также обратите внимание, что критерии предварительной обрезки на основе веса, такие как &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt; , будут менее смещены в сторону доминирующих классов, чем критерии, которые не знают весов выборки, например &lt;code&gt;min_samples_leaf&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05f675285d8ed3983e70827edce654b1139be242" translate="yes" xml:space="preserve">
          <source>Balanced Accuracy as described in &lt;a href=&quot;#urbanowicz2015&quot; id=&quot;id10&quot;&gt;[Urbanowicz2015]&lt;/a&gt;: the average of sensitivity and specificity is computed for each class and then averaged over total number of classes.</source>
          <target state="translated">Сбалансированная точность, как описано в &lt;a href=&quot;#urbanowicz2015&quot; id=&quot;id10&quot;&gt;[Urbanowicz2015]&lt;/a&gt; : среднее значение чувствительности и специфичности вычисляется для каждого класса, а затем усредняется по общему количеству классов.</target>
        </trans-unit>
        <trans-unit id="784fa76a8b1c1ec60f28239d94fc65e8d7be9167" translate="yes" xml:space="preserve">
          <source>Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the accuracy of prediction algorithms for classification: an overview</source>
          <target state="translated">Бальди,Брунак,Чаувин,Андерсен и Нильсен,(2000).Оценка точности алгоритмов прогнозирования для классификации:обзор.</target>
        </trans-unit>
        <trans-unit id="06f9184e762e9e45e71254eb60f8399d4c411472" translate="yes" xml:space="preserve">
          <source>Ball tree for fast generalized N-point problems.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7faaf3d73987f1f3ca80fb71528f4fcc07c23b8e" translate="yes" xml:space="preserve">
          <source>BallTree for fast generalized N-point problems</source>
          <target state="translated">BallTree для быстрых обобщенных проблем с N-баллами.</target>
        </trans-unit>
        <trans-unit id="fef5acd09f6d09b9952e2688ee6340fe9a396e5b" translate="yes" xml:space="preserve">
          <source>BallTree(X, leaf_size=40, metric=&amp;rsquo;minkowski&amp;rsquo;, **kwargs)</source>
          <target state="translated">BallTree (X, leaf_size = 40, metric = 'minkowski', ** kwargs)</target>
        </trans-unit>
        <trans-unit id="f72ce994093395e37676061f1dd51a4ea80c1082" translate="yes" xml:space="preserve">
          <source>Bandwidth used in the RBF kernel.</source>
          <target state="translated">Полоса пропускания,используемая в ядре RBF.</target>
        </trans-unit>
        <trans-unit id="0c486c3167e8e5060c79997e836642fbe914971f" translate="yes" xml:space="preserve">
          <source>Barnes-Hut is an approximation of the exact method. The approximation is parameterized with the angle parameter, therefore the angle parameter is unused when method=&amp;rdquo;exact&amp;rdquo;</source>
          <target state="translated">Barnes-Hut является приближением точного метода. Приближение параметризуется с помощью параметра угла, поэтому параметр угла не используется, когда метод = &quot;точный&quot;.</target>
        </trans-unit>
        <trans-unit id="3b0ab9922dcf0fcbb725191c9b8bc0a7c9ecc19c" translate="yes" xml:space="preserve">
          <source>Barnes-Hut is significantly more scalable. Barnes-Hut can be used to embed hundred of thousands of data points while the exact method can handle thousands of samples before becoming computationally intractable</source>
          <target state="translated">Барнс-Хат значительно более масштабируемый.Barnes-Hut можно использовать для встраивания сотен тысяч точек данных,в то время как точный метод может обрабатывать тысячи образцов до того,как станет трудно поддающимся вычислениям.</target>
        </trans-unit>
        <trans-unit id="b10a9a2aa738bc222bc8e12bf3c9da484bcf459f" translate="yes" xml:space="preserve">
          <source>Barnes-Hut only works with dense input data. Sparse data matrices can only be embedded with the exact method or can be approximated by a dense low rank projection for instance using &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;sklearn.decomposition.TruncatedSVD&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Barnes-Hut работает только с плотными входными данными. Матрицы разреженных данных могут быть встроены только с помощью точного метода или могут быть аппроксимированы плотной проекцией низкого ранга, например, с помощью &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;sklearn.decomposition.TruncatedSVD&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7063b67add41dd6938d0fe03decc31a786e18ce9" translate="yes" xml:space="preserve">
          <source>Base class for all estimators in scikit-learn</source>
          <target state="translated">Базовый класс для всех оценщиков в наукоемких исследованиях</target>
        </trans-unit>
        <trans-unit id="b3ed1a2c57def49034ad9434aa34e34b64c59294" translate="yes" xml:space="preserve">
          <source>Base class for all kernels.</source>
          <target state="translated">Базовый класс для всех ядер.</target>
        </trans-unit>
        <trans-unit id="597d1d5f179914ea7470a3760bd8ee3a2400c1bc" translate="yes" xml:space="preserve">
          <source>Base classes</source>
          <target state="translated">Базовые классы</target>
        </trans-unit>
        <trans-unit id="425994da22262a2dfe067d38bec718a9f15fcaea" translate="yes" xml:space="preserve">
          <source>Base classes for all estimators.</source>
          <target state="translated">Базовые классы для всех оценщиков.</target>
        </trans-unit>
        <trans-unit id="b0cdf2e205135846db5a02006385fb2f510f153e" translate="yes" xml:space="preserve">
          <source>Base classifier for this ensemble.</source>
          <target state="translated">Базовый классификатор для этого ансамбля.</target>
        </trans-unit>
        <trans-unit id="61ae0e2f9a4051180ae0aa7361de2f44f1e6a032" translate="yes" xml:space="preserve">
          <source>Base estimator for this ensemble.</source>
          <target state="translated">Базовый оценщик для этого ансамбля.</target>
        </trans-unit>
        <trans-unit id="96ce9dc70ae7445a77ac8ebb388087887574787e" translate="yes" xml:space="preserve">
          <source>Base estimator object which implements the following methods:</source>
          <target state="translated">Объект базовой оценки,который реализует следующие методы:</target>
        </trans-unit>
        <trans-unit id="a4f9906b1c0bdc268249c9569eb1485c9b45d816" translate="yes" xml:space="preserve">
          <source>Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to &amp;lsquo;drop&amp;rsquo; using &lt;code&gt;set_params&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3f0bf51e2f9cb27fcde269872aa74bb4b0677d2" translate="yes" xml:space="preserve">
          <source>Base of the logarithm used for the discount. A low value means a sharper discount (top results are more important).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6856d61f849440214e260ddb8260a2004382c80" translate="yes" xml:space="preserve">
          <source>Based on these bin intervals, &lt;code&gt;X&lt;/code&gt; is transformed as follows:</source>
          <target state="translated">На основе этих интервалов бинов &lt;code&gt;X&lt;/code&gt; преобразуется следующим образом:</target>
        </trans-unit>
        <trans-unit id="623eb094427cb27d5c4cd4b74097a0449f38ab15" translate="yes" xml:space="preserve">
          <source>Basically, 1. may be a reader that yields instances from files on a hard drive, a database, from a network stream etc. However, details on how to achieve this are beyond the scope of this documentation.</source>
          <target state="translated">В основном,1.может быть читателем,который получает экземпляры из файлов на жестком диске,из базы данных,из сетевого потока и т.д.Однако,подробности о том,как этого добиться,выходят за рамки данной документации.</target>
        </trans-unit>
        <trans-unit id="93b2071c2229aa4389154bc62f3ee3617cb13ae0" translate="yes" xml:space="preserve">
          <source>Bayesian ARD regression.</source>
          <target state="translated">Байесовская АРД регрессия.</target>
        </trans-unit>
        <trans-unit id="53c3e11f0d41baa7b5753d8723cd4012a9d964c3" translate="yes" xml:space="preserve">
          <source>Bayesian Ridge Regression</source>
          <target state="translated">регрессия Байесанского хребта</target>
        </trans-unit>
        <trans-unit id="5f8e5b5e24015d9adc82586dba204556446370ab" translate="yes" xml:space="preserve">
          <source>Bayesian Ridge Regression is used for regression:</source>
          <target state="translated">Байесанская хребтовая регрессия используется для регрессии:</target>
        </trans-unit>
        <trans-unit id="c13c97854320151b1c6271dc7d1a9fd73998cc11" translate="yes" xml:space="preserve">
          <source>Bayesian information criterion for the current model on the input X.</source>
          <target state="translated">Байесовский информационный критерий для текущей модели на входе X.</target>
        </trans-unit>
        <trans-unit id="9caaf8acefcf32287fe9e5bedbc0bc32de3a2bfd" translate="yes" xml:space="preserve">
          <source>Bayesian regression techniques can be used to include regularization parameters in the estimation procedure: the regularization parameter is not set in a hard sense but tuned to the data at hand.</source>
          <target state="translated">Байесовские методы регрессии могут быть использованы для включения параметров регуляризации в процедуру оценки:параметр регуляризации не задается в жестком смысле слова,а настраивается на имеющиеся данные.</target>
        </trans-unit>
        <trans-unit id="f02284fac00f823c24638d260dbf19c33e10b7f5" translate="yes" xml:space="preserve">
          <source>Bayesian regressors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b720ec1817dce1bf9d7dcbcab6e206b85efdaa6" translate="yes" xml:space="preserve">
          <source>Bayesian ridge regression</source>
          <target state="translated">регрессия Байесовского хребта</target>
        </trans-unit>
        <trans-unit id="66a81420e9a002d3d7820b1130f20af6976fb2b7" translate="yes" xml:space="preserve">
          <source>Bayesian ridge regression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13244381ac86550f492dc53b5005b711b59fb204" translate="yes" xml:space="preserve">
          <source>Be aware that the number of features in the output array scales polynomially in the number of features of the input array, and exponentially in the degree. High degrees can cause overfitting.</source>
          <target state="translated">Имейте в виду,что количество признаков в выходном массиве масштабируется полиномиально по количеству признаков во входном массиве и экспоненциально по степени.Высокие степени могут привести к переподбору.</target>
        </trans-unit>
        <trans-unit id="3faa94ddadd318647d89d2a02f2d45606c753b0d" translate="yes" xml:space="preserve">
          <source>Be invariant to class label: relabelling &lt;code&gt;y = [&quot;Happy&quot;, &quot;Sad&quot;]&lt;/code&gt; to &lt;code&gt;y = [1, 0]&lt;/code&gt; should not change the indices generated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3a63e14a349843f9c954f28468802eec39d0181f" translate="yes" xml:space="preserve">
          <source>Be mindful that this function is an order of magnitude slower than other metrics, such as the Adjusted Rand Index.</source>
          <target state="translated">Помните,что эта функция на порядок медленнее,чем другие метрики,такие как Adjusted Rand Index.</target>
        </trans-unit>
        <trans-unit id="83921ebb17d38b8a4b1a1e3f6653eb2aa6327ec9" translate="yes" xml:space="preserve">
          <source>Because LARS is based upon an iterative refitting of the residuals, it would appear to be especially sensitive to the effects of noise. This problem is discussed in detail by Weisberg in the discussion section of the Efron et al. (2004) Annals of Statistics article.</source>
          <target state="translated">Поскольку LARS основан на итеративном переоснащении остатков,кажется,что он особенно чувствителен к воздействию шума.Эта проблема подробно обсуждается Вайсбергом в дискуссионном разделе статьи &quot;Анналы статистики&quot; Ефрона и др.(2004).</target>
        </trans-unit>
        <trans-unit id="5dbb3cd2ef2ab4d2456b8c42be279603ef8045ba" translate="yes" xml:space="preserve">
          <source>Because of scaling performed by this method, it is discouraged to use it together with methods that are not scale-invariant (like SVMs)</source>
          <target state="translated">Из-за масштабирования,выполняемого этим методом,не рекомендуется использовать его вместе с методами,которые не являются масштабируемыми (например,SVM).</target>
        </trans-unit>
        <trans-unit id="63be2fc59867472cdd54d70a5100dc5be4d8ddfa" translate="yes" xml:space="preserve">
          <source>Because of the Python object overhead involved in calling the python function, this will be fairly slow, but it will have the same scaling as other distances.</source>
          <target state="translated">Из-за того,что объект Python над головой участвует в вызове функции питона,это будет довольно медленно,но будет иметь такой же масштаб,как и другие расстояния.</target>
        </trans-unit>
        <trans-unit id="8e7a8c8acef8e25d8225bca274332d6c56e271be" translate="yes" xml:space="preserve">
          <source>Because the models in each chain are arranged randomly there is significant variation in performance among the chains. Presumably there is an optimal ordering of the classes in a chain that will yield the best performance. However we do not know that ordering a priori. Instead we can construct an voting ensemble of classifier chains by averaging the binary predictions of the chains and apply a threshold of 0.5. The Jaccard similarity score of the ensemble is greater than that of the independent models and tends to exceed the score of each chain in the ensemble (although this is not guaranteed with randomly ordered chains).</source>
          <target state="translated">Так как модели в каждой цепи расположены случайным образом,между цепями существуют значительные различия в производительности.Предположительно,существует оптимальное упорядочение классов в цепочке,которое даст наилучшую производительность.Однако мы не знаем,что заказ априори.Вместо этого мы можем построить голосующий ансамбль цепочек классификатора,усреднив бинарные предсказания цепочек,и применить порог в 0,5.Оценка схожести Jaccard у ансамбля больше,чем у независимых моделей,и,как правило,превышает оценку каждой цепочки в ансамбле (хотя это не гарантируется случайно упорядоченными цепочками).</target>
        </trans-unit>
        <trans-unit id="7223d10fe616d4b0ef82e34ecf5c077bba0a2d4c" translate="yes" xml:space="preserve">
          <source>Because the number of neighbors of each point is not necessarily equal, the results for multiple query points cannot be fit in a standard data array. For efficiency, &lt;code&gt;radius_neighbors&lt;/code&gt; returns arrays of objects, where each object is a 1D array of indices or distances.</source>
          <target state="translated">Поскольку количество соседей каждой точки не обязательно равно, результаты для нескольких точек запроса не могут быть помещены в стандартный массив данных. Ради эффективности &lt;code&gt;radius_neighbors&lt;/code&gt; возвращает массивы объектов, где каждый объект представляет собой одномерный массив индексов или расстояний.</target>
        </trans-unit>
        <trans-unit id="5b27b93fd142831db995faecc3827454df4cf37d" translate="yes" xml:space="preserve">
          <source>Because the query set matches the training set, the nearest neighbor of each point is the point itself, at a distance of zero.</source>
          <target state="translated">Так как набор запросов совпадает с обучающим набором,то ближайшим соседом каждой точки является сама точка,на расстоянии нуля.</target>
        </trans-unit>
        <trans-unit id="40a1ac9f9c5627c60c3da1e0a0050f7b91b8daf1" translate="yes" xml:space="preserve">
          <source>Because this implementation uses a flat kernel and a Ball Tree to look up members of each kernel, the complexity will tend towards O(T*n*log(n)) in lower dimensions, with n the number of samples and T the number of points. In higher dimensions the complexity will tend towards O(T*n^2).</source>
          <target state="translated">Поскольку эта реализация использует плоское ядро и дерево шариков для поиска членов каждого ядра,сложность будет стремиться к O(T*n*log(n))в меньших размерах,с n количеством выборок и T количеством точек.В больших измерениях сложность будет стремиться к O(T*n^2).</target>
        </trans-unit>
        <trans-unit id="5430204387d0c34e554350a9ea0af84d5f7d324c" translate="yes" xml:space="preserve">
          <source>Before we can use Ames dataset we still need to do some preprocessing. First, the dataset has many missing values. To impute them, we will exchange categorical missing values with the new category &amp;lsquo;missing&amp;rsquo; while the numerical missing values with the &amp;lsquo;mean&amp;rsquo; of the column. We will also encode the categories with either &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OrdinalEncoder&lt;/code&gt;&lt;/a&gt; depending for which type of model we will use them (linear or non-linear model). To falicitate this preprocessing we will make two pipelines. You can skip this section if your data is ready to use and does not need preprocessing</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3c17036de4b5ca609e4df67622292c35365a396" translate="yes" xml:space="preserve">
          <source>Behaviour of the &lt;code&gt;decision_function&lt;/code&gt; which can be either &amp;lsquo;old&amp;rsquo; or &amp;lsquo;new&amp;rsquo;. Passing &lt;code&gt;behaviour='new'&lt;/code&gt; makes the &lt;code&gt;decision_function&lt;/code&gt; change to match other anomaly detection algorithm API which will be the default behaviour in the future. As explained in details in the &lt;code&gt;offset_&lt;/code&gt; attribute documentation, the &lt;code&gt;decision_function&lt;/code&gt; becomes dependent on the contamination parameter, in such a way that 0 becomes its natural threshold to detect outliers.</source>
          <target state="translated">Поведение функции &lt;code&gt;decision_function&lt;/code&gt; которое может быть &quot;старым&quot; или &quot;новым&quot;. Переходя &lt;code&gt;behaviour='new'&lt;/code&gt; делает &lt;code&gt;decision_function&lt;/code&gt; изменения , чтобы соответствовать другим обнаружения аномалий алгоритма API , который будет по умолчанию в будущем. Как подробно объясняется в документации по атрибуту &lt;code&gt;offset_&lt;/code&gt; ,функция &lt;code&gt;decision_function&lt;/code&gt; становится зависимой от параметра загрязнения таким образом, что 0 становится ее естественным порогом для обнаружения выбросов.</target>
        </trans-unit>
        <trans-unit id="20bc631a66b3cc1b1a3392b3fbbb196ee59f89ba" translate="yes" xml:space="preserve">
          <source>Being a forward feature selection method like &lt;a href=&quot;#least-angle-regression&quot;&gt;Least Angle Regression&lt;/a&gt;, orthogonal matching pursuit can approximate the optimum solution vector with a fixed number of non-zero elements:</source>
          <target state="translated">Будучи методом прямого выбора функции, таким как &lt;a href=&quot;#least-angle-regression&quot;&gt;регрессия по наименьшему углу&lt;/a&gt; , поиск ортогонального сопоставления может аппроксимировать вектор оптимального решения с фиксированным числом ненулевых элементов:</target>
        </trans-unit>
        <trans-unit id="305fd1e902f73a5b60bc86a4bdd6b4a6ea0e533f" translate="yes" xml:space="preserve">
          <source>Below are examples of Box-Cox and Yeo-Johnson applied to various probability distributions. Note that when applied to certain distributions, the power transforms achieve very Gaussian-like results, but with others, they are ineffective. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">Ниже приведены примеры Box-Cox и Yeo-Johnson,применяемых к различным распределениям вероятностей.Обратите внимание,что при применении к некоторым распределениям мощности трансформации достигают очень гауссово-подобных результатов,но с другими они неэффективны.Это подчеркивает важность визуализации данных до и после преобразования.</target>
        </trans-unit>
        <trans-unit id="15f2be220fb72bee910f5e62c59989aad06195d5" translate="yes" xml:space="preserve">
          <source>Below is a summary of the classifiers supported by scikit-learn grouped by strategy; you don&amp;rsquo;t need the meta-estimators in this class if you&amp;rsquo;re using one of these, unless you want custom multiclass behavior:</source>
          <target state="translated">Ниже приводится сводка классификаторов, поддерживаемых scikit-learn, сгруппированных по стратегиям; вам не нужны мета-оценщики в этом классе, если вы используете один из них, если вы не хотите настраиваемое поведение мультикласса:</target>
        </trans-unit>
        <trans-unit id="108ff87be25a1c1dd2316c9f1fb3ba28787755c8" translate="yes" xml:space="preserve">
          <source>Below is an example graphviz export of the above tree trained on the entire iris dataset; the results are saved in an output file &lt;code&gt;iris.pdf&lt;/code&gt;:</source>
          <target state="translated">Ниже приведен пример экспорта graphviz вышеуказанного дерева, обученного на всем наборе данных радужной оболочки глаза; результаты сохраняются в выходном файле &lt;code&gt;iris.pdf&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="f4264cf8db047b13d2c0262177f6f646451f4fbb" translate="yes" xml:space="preserve">
          <source>Below is an example of multiclass learning using Output-Codes:</source>
          <target state="translated">Ниже приведен пример многоклассного обучения с использованием Output-Codes:</target>
        </trans-unit>
        <trans-unit id="b49bf188ea86adad6efb34f880d43936d0fc0ac2" translate="yes" xml:space="preserve">
          <source>Below is an example of multiclass learning using OvO:</source>
          <target state="translated">Ниже приведен пример многоклассного обучения с использованием OvO:</target>
        </trans-unit>
        <trans-unit id="687c4cfff2712863f68152405d4b2638d130c286" translate="yes" xml:space="preserve">
          <source>Below is an example of multiclass learning using OvR:</source>
          <target state="translated">Ниже приведен пример многоклассного обучения с использованием OvR:</target>
        </trans-unit>
        <trans-unit id="c80585dafc7b9164da5261a6f83e5756b02054c8" translate="yes" xml:space="preserve">
          <source>Below is an example of multioutput classification:</source>
          <target state="translated">Ниже приведен пример многовыходной классификации:</target>
        </trans-unit>
        <trans-unit id="5323f7dfcb00efe99d53b8ad7c93f56a3771bb8d" translate="yes" xml:space="preserve">
          <source>Below is an example of multioutput regression:</source>
          <target state="translated">Ниже приведен пример многовыходной регрессии:</target>
        </trans-unit>
        <trans-unit id="c1920b9ad7a1724faf2c50a13254e745783c4989" translate="yes" xml:space="preserve">
          <source>Below is an example of the iris dataset, which is comprised of 4 features, projected on the 2 dimensions that explain most variance:</source>
          <target state="translated">Ниже приведен пример набора данных по радужной оболочке глаза,состоящего из 4-х элементов,спроецированных на 2 измерения,которые объясняют наибольшую дисперсию:</target>
        </trans-unit>
        <trans-unit id="fe179d558d43e31394bc90d2c2bd912f3d7ad712" translate="yes" xml:space="preserve">
          <source>Belsley, Kuh &amp;amp; Welsch, &amp;lsquo;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&amp;rsquo;, Wiley, 1980. 244-261.</source>
          <target state="translated">Belsley, Kuh &amp;amp; Welsch, &amp;laquo;Регрессионная диагностика: определение важных данных и источников коллинеарности&amp;raquo;, Wiley, 1980. 244&amp;ndash;261.</target>
        </trans-unit>
        <trans-unit id="9f292c5936105126748d157311146c4c77a1cc65" translate="yes" xml:space="preserve">
          <source>Benchmark classifiers</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe07a59cb91f8e159239a44b010528ab1c647c88" translate="yes" xml:space="preserve">
          <source>Bergstra, J. and Bengio, Y., Random search for hyper-parameter optimization, The Journal of Machine Learning Research (2012)</source>
          <target state="translated">Бергстра Дж.и Бенджио Й.,Случайный поиск гиперпараметрической оптимизации,Журнал исследований в области обучения работе с машинами (2012 г.)</target>
        </trans-unit>
        <trans-unit id="acb0e0e454302529b80959f07b2776ace520ba67" translate="yes" xml:space="preserve">
          <source>Bernhard Schoelkopf, Alexander J. Smola, and Klaus-Robert Mueller. 1999. Kernel principal component analysis. In Advances in kernel methods, MIT Press, Cambridge, MA, USA 327-352.</source>
          <target state="translated">Бернхард Шелкопф,Александр Дж.Смола и Клаус-Роберт Мюллер.1999.Анализ основных компонентов ядра.Достижения в методах ядерного анализа,MIT Press,Кембридж,Массачусетс,США 327-352.</target>
        </trans-unit>
        <trans-unit id="d8b44488165a02f44f4a67e6ba1ce39e5b9c9bb9" translate="yes" xml:space="preserve">
          <source>Bernoulli Restricted Boltzmann Machine (RBM).</source>
          <target state="translated">Bernoulli Restricted Boltzmann Machine (RBM).</target>
        </trans-unit>
        <trans-unit id="5923a4b6b18db19ea579977a7a07a6737359d838" translate="yes" xml:space="preserve">
          <source>Besides scikit-learn, NumPy and SciPy also use BLAS internally, as explained earlier.</source>
          <target state="translated">Как объяснялось ранее,помимо Scikit-learn,NumPy и SciPy также используют BLAS внутри организации.</target>
        </trans-unit>
        <trans-unit id="7d9a50881bd5d34faa0a8f3ad342e9a7c84f5b08" translate="yes" xml:space="preserve">
          <source>Best fitted model (copy of the &lt;code&gt;base_estimator&lt;/code&gt; object).</source>
          <target state="translated">Модель наилучшего соответствия (копия объекта &lt;code&gt;base_estimator&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="12a49239d2ca4095c10a87ae8e694332610beadd" translate="yes" xml:space="preserve">
          <source>Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</source>
          <target state="translated">Лучший возможный балл-1.0,и он может быть отрицательным (потому что модель может быть произвольно хуже).Константная модель,которая всегда предсказывает ожидаемое значение y,без учета входных характеристик,получит оценку R^2 в 0.0.</target>
        </trans-unit>
        <trans-unit id="792cb529b422a1c11c9b2f8bb241ed31b32984d9" translate="yes" xml:space="preserve">
          <source>Best possible score is 1.0, lower values are worse.</source>
          <target state="translated">Лучший возможный балл-1,0,ниже-хуже.</target>
        </trans-unit>
        <trans-unit id="28c6b37b189c99aed8957aff1f021f2f9f59464b" translate="yes" xml:space="preserve">
          <source>Beta-divergence loss functions</source>
          <target state="translated">Функции потери бета-дивергенции</target>
        </trans-unit>
        <trans-unit id="d2c95a0bd9e48b10416c4f3dc812e08319356fa2" translate="yes" xml:space="preserve">
          <source>Beware not to use a regression scoring function with a classification problem, you will get useless results.</source>
          <target state="translated">Остерегайтесь не использовать функцию регрессионного скоринга с проблемой классификации,вы получите бесполезные результаты.</target>
        </trans-unit>
        <trans-unit id="a9f3a13f44f7a1a81c6757a16dde70a0eb1d4b70" translate="yes" xml:space="preserve">
          <source>Bias</source>
          <target state="translated">Bias</target>
        </trans-unit>
        <trans-unit id="ba237b5bed1b1a1e028b039eda8969e7ed30ca0a" translate="yes" xml:space="preserve">
          <source>Bias and variance are inherent properties of estimators and we usually have to select learning algorithms and hyperparameters so that both bias and variance are as low as possible (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias-variance_dilemma&quot;&gt;Bias-variance dilemma&lt;/a&gt;). Another way to reduce the variance of a model is to use more training data. However, you should only collect more training data if the true function is too complex to be approximated by an estimator with a lower variance.</source>
          <target state="translated">Смещение и дисперсия являются неотъемлемыми свойствами оценщиков, и обычно нам приходится выбирать алгоритмы обучения и гиперпараметры так, чтобы смещение и дисперсия были как можно более низкими (см. &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias-variance_dilemma&quot;&gt;Дилемма смещения и дисперсии&lt;/a&gt; ). Другой способ уменьшить дисперсию модели - использовать больше обучающих данных. Однако вам следует собирать больше обучающих данных, только если истинная функция слишком сложна для аппроксимации с помощью оценщика с более низкой дисперсией.</target>
        </trans-unit>
        <trans-unit id="06f19409a98653c678fe6ff3c120895b283ca5ff" translate="yes" xml:space="preserve">
          <source>Bias-variance trade-off when setting the shrinkage: comparing the choices of Ledoit-Wolf and OAS estimators</source>
          <target state="translated">Bias-вариант компромисса при установке усадки:сравнение выбора Ledoit-Волк и OAS оценщики</target>
        </trans-unit>
        <trans-unit id="7c5f1fb15e060b340fb270b747d162cde9961929" translate="yes" xml:space="preserve">
          <source>Bias.</source>
          <target state="translated">Bias.</target>
        </trans-unit>
        <trans-unit id="e26ae344044922af518669ed7912f3779c4b00f9" translate="yes" xml:space="preserve">
          <source>Bias:</source>
          <target state="translated">Bias:</target>
        </trans-unit>
        <trans-unit id="6b339e821e48cfc38068b641fe05c82a58e3e342" translate="yes" xml:space="preserve">
          <source>Biases of the hidden units.</source>
          <target state="translated">Предвзятость скрытых подразделений.</target>
        </trans-unit>
        <trans-unit id="e50dfa9d24499c67dd80dc7ae0f62d209963644d" translate="yes" xml:space="preserve">
          <source>Biases of the visible units.</source>
          <target state="translated">Предвзятость видимых блоков.</target>
        </trans-unit>
        <trans-unit id="d4404195d10795d2fac0ea59f4bd8efbaf381e98" translate="yes" xml:space="preserve">
          <source>Biclustering</source>
          <target state="translated">Biclustering</target>
        </trans-unit>
        <trans-unit id="a252b47dd9e6fba33ce507e3a8e6ec1bb1e9c7d0" translate="yes" xml:space="preserve">
          <source>Biclustering can be performed with the module &lt;a href=&quot;classes#module-sklearn.cluster.bicluster&quot;&gt;&lt;code&gt;sklearn.cluster.bicluster&lt;/code&gt;&lt;/a&gt;. Biclustering algorithms simultaneously cluster rows and columns of a data matrix. These clusters of rows and columns are known as biclusters. Each determines a submatrix of the original data matrix with some desired properties.</source>
          <target state="translated">Бикластеризацию можно выполнить с помощью модуля &lt;a href=&quot;classes#module-sklearn.cluster.bicluster&quot;&gt; &lt;code&gt;sklearn.cluster.bicluster&lt;/code&gt; &lt;/a&gt; . Алгоритмы бикластеризации одновременно группируют строки и столбцы матрицы данных. Эти кластеры строк и столбцов известны как бикластеры. Каждый определяет подматрицу исходной матрицы данных с некоторыми желаемыми свойствами.</target>
        </trans-unit>
        <trans-unit id="edf2774b82282aef622b14eeaa9c74d15c4f211e" translate="yes" xml:space="preserve">
          <source>Biclustering can be performed with the module &lt;code&gt;sklearn.cluster.bicluster&lt;/code&gt;. Biclustering algorithms simultaneously cluster rows and columns of a data matrix. These clusters of rows and columns are known as biclusters. Each determines a submatrix of the original data matrix with some desired properties.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec46a574c9badafd039dd72d03169fe1273b5603" translate="yes" xml:space="preserve">
          <source>Biclustering documents with the Spectral Co-clustering algorithm</source>
          <target state="translated">Биклюстинг документов с алгоритмом спектральной кокластеризации</target>
        </trans-unit>
        <trans-unit id="ee86c7bb4d236ce105b92fe63ada05dd4ec5870a" translate="yes" xml:space="preserve">
          <source>Biclustering has many other names in different fields including co-clustering, two-mode clustering, two-way clustering, block clustering, coupled two-way clustering, etc. The names of some algorithms, such as the Spectral Co-Clustering algorithm, reflect these alternate names.</source>
          <target state="translated">Biclustering имеет много других имен в различных областях,включая совместную кластеризацию,двухрежимную кластеризацию,двухстороннюю кластеризацию,блочную кластеризацию,сдвоенную двухстороннюю кластеризацию и др.Названия некоторых алгоритмов,таких как спектральная кластеризация,отражают эти альтернативные названия.</target>
        </trans-unit>
        <trans-unit id="9dbdcbb1f58605adc858ff7ea9bd66e335bd0acc" translate="yes" xml:space="preserve">
          <source>Biclustering metrics</source>
          <target state="translated">билюстрирующие показатели</target>
        </trans-unit>
        <trans-unit id="d9cf1c1fb4521641a79265f68d061558d2a8f977" translate="yes" xml:space="preserve">
          <source>Bigger is better, i.e. large values correspond to inliers.</source>
          <target state="translated">Больше-лучше,т.е.большие значения соответствуют инсайдерам.</target>
        </trans-unit>
        <trans-unit id="8a391f29f990251d22520f34bdb4ac600bbfd771" translate="yes" xml:space="preserve">
          <source>Bin continuous data into intervals.</source>
          <target state="translated">Разбивать непрерывные данные на интервалы.</target>
        </trans-unit>
        <trans-unit id="271e5dda8b524cc22b71bebf5401052359debca7" translate="yes" xml:space="preserve">
          <source>Binarization is a common operation on text count data where the analyst can decide to only consider the presence or absence of a feature rather than a quantified number of occurrences for instance.</source>
          <target state="translated">Бинаризация-это обычная операция по подсчету текстовых данных,при которой аналитик может решить рассмотреть только наличие или отсутствие признака,а не,например,количественное число происшествий.</target>
        </trans-unit>
        <trans-unit id="98a952cd8923e662b6dc4cb343f8e07b8c748673" translate="yes" xml:space="preserve">
          <source>Binarize data (set feature values to 0 or 1) according to a threshold</source>
          <target state="translated">Бинаризация данных (установите значения характеристик на 0 или 1)в соответствии с пороговым значением.</target>
        </trans-unit>
        <trans-unit id="e6093920f16b7a0a90021c0a6f1b3ba3a339b537" translate="yes" xml:space="preserve">
          <source>Binarize each element of X</source>
          <target state="translated">Бинаризировать каждый элемент X</target>
        </trans-unit>
        <trans-unit id="0b5b7e155ae5a5495c55eaab6001751a5f50a1e4" translate="yes" xml:space="preserve">
          <source>Binarize labels in a one-vs-all fashion</source>
          <target state="translated">Бинаризировать этикетки в едином стиле.</target>
        </trans-unit>
        <trans-unit id="44b97fdbb0f9ad559fc3a3794b99c9bc30004c1c" translate="yes" xml:space="preserve">
          <source>Binarizes labels in a one-vs-all fashion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c6db33026290c5eceb25ad459dd62fbc5de5524" translate="yes" xml:space="preserve">
          <source>Binary and multiclass labels are supported. Only in the binary case does this relate to information about true and false positives and negatives. See references below.</source>
          <target state="translated">Поддерживаются бинарные и многоклассовые метки.Только в бинарном случае это относится к информации об истинных и ложных срабатываниях и негативах.См.ссылки ниже.</target>
        </trans-unit>
        <trans-unit id="76f6ce139477b2ff40abfa10ccd09f75138f8a5a" translate="yes" xml:space="preserve">
          <source>Binary array containing the code of each class.</source>
          <target state="translated">Двоичный массив,содержащий код каждого класса.</target>
        </trans-unit>
        <trans-unit id="d5752168a3a19813275e09ded6a3644b6b365056" translate="yes" xml:space="preserve">
          <source>Binary indicators for missing values.</source>
          <target state="translated">Двоичные индикаторы пропущенных значений.</target>
        </trans-unit>
        <trans-unit id="d20fae796db569b25a51c85d3dbd034384870434" translate="yes" xml:space="preserve">
          <source>Binary probability estimates for loss=&amp;rdquo;modified_huber&amp;rdquo; are given by (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions it is necessary to perform proper probability calibration by wrapping the classifier with &lt;a href=&quot;sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;sklearn.calibration.CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">Бинарные оценки вероятности для loss = &quot;modified_huber&quot; даются как (clip (solution_function (X), -1, 1) + 1) / 2. Для других функций потерь необходимо выполнить правильную калибровку вероятности, обернув классификатор &lt;a href=&quot;sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;sklearn.calibration.CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6ea0caebd3956174ca222001571ec7f4a771808d" translate="yes" xml:space="preserve">
          <source>Binary target values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e17841c821731bb47f4b19f4849e509ece4c5657" translate="yes" xml:space="preserve">
          <source>Binary targets transform to a column vector</source>
          <target state="translated">Двоичные цели преобразуются в вектор столбца</target>
        </trans-unit>
        <trans-unit id="2a2767f039bc988b0f4c4e7163ccdacd052867c1" translate="yes" xml:space="preserve">
          <source>Binding of the cross-validation routine (low-level routine)</source>
          <target state="translated">Привязка процедуры перекрестной проверки (процедура низкого уровня)</target>
        </trans-unit>
        <trans-unit id="64fb71b36aba4bcefad2e5d527659e300a2b2c01" translate="yes" xml:space="preserve">
          <source>Binomial deviance (&lt;code&gt;'deviance'&lt;/code&gt;): The negative binomial log-likelihood loss function for binary classification (provides probability estimates). The initial model is given by the log odds-ratio.</source>
          <target state="translated">Биномиальное отклонение ( &lt;code&gt;'deviance'&lt;/code&gt; ): функция потерь с отрицательным биномиальным логарифмическим правдоподобием для двоичной классификации (обеспечивает оценки вероятности). Исходная модель дается логарифмическим отношением шансов.</target>
        </trans-unit>
        <trans-unit id="7eef6382001e9a152cc75ac79b202341870bb6db" translate="yes" xml:space="preserve">
          <source>Birch</source>
          <target state="translated">Birch</target>
        </trans-unit>
        <trans-unit id="c8804a672e163b7d85424df4080099668af078fd" translate="yes" xml:space="preserve">
          <source>Birch does not scale very well to high dimensional data. As a rule of thumb if &lt;code&gt;n_features&lt;/code&gt; is greater than twenty, it is generally better to use MiniBatchKMeans.</source>
          <target state="translated">Береза ​​не очень хорошо масштабируется для данных больших размеров. Как показывает &lt;code&gt;n_features&lt;/code&gt; если n_features больше двадцати, обычно лучше использовать MiniBatchKMeans.</target>
        </trans-unit>
        <trans-unit id="055a71a716f70327eef9729a95cd9e98a091a68c" translate="yes" xml:space="preserve">
          <source>Bishop, &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&quot;&gt;Pattern recognition and machine learning&lt;/a&gt;, chapter 7 Sparse Kernel Machines</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35b99b7929918827477b2be5f13db5f62d5bed94" translate="yes" xml:space="preserve">
          <source>Bishop, Christopher M. (2006). &amp;ldquo;Pattern recognition and machine learning&amp;rdquo;. Vol. 4 No. 4. New York: Springer.</source>
          <target state="translated">Епископ, Кристофер М. (2006). &amp;laquo;Распознавание образов и машинное обучение&amp;raquo;. Vol. 4 № 4. Нью-Йорк: Спрингер.</target>
        </trans-unit>
        <trans-unit id="3ee00b8c0e8ff24c1a59dc452e853cf83ab3d2bf" translate="yes" xml:space="preserve">
          <source>Blei, David M. and Michael I. Jordan. (2006). &amp;ldquo;Variational inference for Dirichlet process mixtures&amp;rdquo;. Bayesian analysis 1.1</source>
          <target state="translated">Блей, Дэвид М. и Майкл И. Джордан. (2006). &amp;laquo;Вариационный вывод для технологических смесей Дирихле&amp;raquo;. Байесовский анализ 1.1</target>
        </trans-unit>
        <trans-unit id="66370792731dff7f31408706eed1fd3ef5297d11" translate="yes" xml:space="preserve">
          <source>Blind source separation using FastICA</source>
          <target state="translated">Разделение слепого источника с помощью FastICA</target>
        </trans-unit>
        <trans-unit id="7d44bc449c2a26374800a503f10f3d8949505f40" translate="yes" xml:space="preserve">
          <source>Blue</source>
          <target state="translated">Blue</target>
        </trans-unit>
        <trans-unit id="d1411ae3cdd27fda5ea57577c408be223f586cf0" translate="yes" xml:space="preserve">
          <source>Body mass index</source>
          <target state="translated">Индекс массы тела</target>
        </trans-unit>
        <trans-unit id="eeb4978eef8f0138e90d13575223e62053c06fa3" translate="yes" xml:space="preserve">
          <source>Bonus point if the utility is able to give a confidence level for its predictions.</source>
          <target state="translated">Бонусное очко,если утилита способна дать уровень уверенности для своих прогнозов.</target>
        </trans-unit>
        <trans-unit id="20ee87c5c904919ec390ea5b4c0a66ba0775ae58" translate="yes" xml:space="preserve">
          <source>BonusMalus</source>
          <target state="translated">BonusMalus</target>
        </trans-unit>
        <trans-unit id="3605ba73833c24e0fbda3c252c7bb0e601382c92" translate="yes" xml:space="preserve">
          <source>Boolean flag indicating wether the output of &lt;code&gt;transform&lt;/code&gt; is a sparse matrix or a dense numpy array, which depends on the output of the individual transformers and the &lt;code&gt;sparse_threshold&lt;/code&gt; keyword.</source>
          <target state="translated">Логический флаг, указывающий, является ли результат &lt;code&gt;transform&lt;/code&gt; разреженной матрицей или плотным массивом numpy, который зависит от выходных данных отдельных преобразователей и &lt;code&gt;sparse_threshold&lt;/code&gt; слова sparse_threshold .</target>
        </trans-unit>
        <trans-unit id="c9d24ce1f33e1a2da8b7d2e8d02488db3a1a0ff6" translate="yes" xml:space="preserve">
          <source>Boolean flag indicating whether the output of &lt;code&gt;transform&lt;/code&gt; is a sparse matrix or a dense numpy array, which depends on the output of the individual transformers and the &lt;code&gt;sparse_threshold&lt;/code&gt; keyword.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd883a95149825523369daab7f0f8ca0aca6e0ac" translate="yes" xml:space="preserve">
          <source>Boolean mask of inliers classified as &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">Логическая маска вставок, классифицированных как &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d2ef2625261226f9417113c581f3bab51f99fc11" translate="yes" xml:space="preserve">
          <source>Boolean mask or indices for test set.</source>
          <target state="translated">Булева маска или индексы для тестового набора.</target>
        </trans-unit>
        <trans-unit id="30de559b973b97451b964227c7184d452eca2270" translate="yes" xml:space="preserve">
          <source>Boolean mask or indices for training set.</source>
          <target state="translated">Булева маска или индексы для тренировочного набора.</target>
        </trans-unit>
        <trans-unit id="a38162711f2499e7a5519304c06ab030205ccd3e" translate="yes" xml:space="preserve">
          <source>Boolean mask or list of indices (as returned by the get_support member of feature selectors).</source>
          <target state="translated">Булева маска или список индексов (возвращается членом get_support селекторов функций).</target>
        </trans-unit>
        <trans-unit id="c3ff5ac4f1442b62c49b82219fbca08a9aaf6fc5" translate="yes" xml:space="preserve">
          <source>Boolean thresholding of array-like or scipy.sparse matrix</source>
          <target state="translated">Булевский порог массивовидной или научно-разреженной матрицы</target>
        </trans-unit>
        <trans-unit id="52747050c0ad2a1de070c473421346e630cdac3f" translate="yes" xml:space="preserve">
          <source>Both &amp;lsquo;ascii&amp;rsquo; and &amp;lsquo;unicode&amp;rsquo; use NFKD normalization from &lt;a href=&quot;https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize&quot;&gt;&lt;code&gt;unicodedata.normalize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">И ascii, и unicode используют нормализацию &lt;a href=&quot;https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize&quot;&gt; &lt;code&gt;unicodedata.normalize&lt;/code&gt; &lt;/a&gt; из unicodedata.normalize .</target>
        </trans-unit>
        <trans-unit id="cc08d18c56138ef4e57769f94344c2fcddc0c71c" translate="yes" xml:space="preserve">
          <source>Both &lt;a href=&quot;../modules/generated/sklearn.datasets.make_blobs#sklearn.datasets.make_blobs&quot;&gt;&lt;code&gt;make_blobs&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_classification#sklearn.datasets.make_classification&quot;&gt;&lt;code&gt;make_classification&lt;/code&gt;&lt;/a&gt; create multiclass datasets by allocating each class one or more normally-distributed clusters of points. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_blobs#sklearn.datasets.make_blobs&quot;&gt;&lt;code&gt;make_blobs&lt;/code&gt;&lt;/a&gt; provides greater control regarding the centers and standard deviations of each cluster, and is used to demonstrate clustering. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_classification#sklearn.datasets.make_classification&quot;&gt;&lt;code&gt;make_classification&lt;/code&gt;&lt;/a&gt; specialises in introducing noise by way of: correlated, redundant and uninformative features; multiple Gaussian clusters per class; and linear transformations of the feature space.</source>
          <target state="translated">И &lt;a href=&quot;../modules/generated/sklearn.datasets.make_blobs#sklearn.datasets.make_blobs&quot;&gt; &lt;code&gt;make_blobs&lt;/code&gt; ,&lt;/a&gt; и &lt;a href=&quot;../modules/generated/sklearn.datasets.make_classification#sklearn.datasets.make_classification&quot;&gt; &lt;code&gt;make_classification&lt;/code&gt; &lt;/a&gt; создают наборы данных мультиклассов, выделяя каждому классу один или несколько нормально распределенных кластеров точек. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_blobs#sklearn.datasets.make_blobs&quot;&gt; &lt;code&gt;make_blobs&lt;/code&gt; &lt;/a&gt; обеспечивает больший контроль относительно центров и стандартных отклонений каждого кластера и используется для демонстрации кластеризации. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_classification#sklearn.datasets.make_classification&quot;&gt; &lt;code&gt;make_classification&lt;/code&gt; &lt;/a&gt; специализируется на введении шума посредством: коррелированных, избыточных и неинформативных функций; несколько гауссовских кластеров на класс; и линейные преобразования пространства признаков.</target>
        </trans-unit>
        <trans-unit id="4b01e39314cd0b6e82319a49bae49952bbdf5790" translate="yes" xml:space="preserve">
          <source>Both &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; support &lt;code&gt;warm_start=True&lt;/code&gt; which allows you to add more estimators to an already fitted model.</source>
          <target state="translated">И &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; ,&lt;/a&gt; и &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt; поддерживают &lt;code&gt;warm_start=True&lt;/code&gt; , что позволяет добавлять дополнительные оценщики к уже подогнанной модели.</target>
        </trans-unit>
        <trans-unit id="0fdd261ec2b6eab839fe6617683b34303696fb85" translate="yes" xml:space="preserve">
          <source>Both &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; can be used in a Pipeline as a way to build a composite estimator that supports imputation. See &lt;a href=&quot;../auto_examples/impute/plot_missing_values#sphx-glr-auto-examples-impute-plot-missing-values-py&quot;&gt;Imputing missing values before building an estimator&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf6c6c4310ce5d3e1dff50dd933fcb1d3d517f90" translate="yes" xml:space="preserve">
          <source>Both &lt;a href=&quot;generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier&quot;&gt;&lt;code&gt;MLPClassifier&lt;/code&gt;&lt;/a&gt; use parameter &lt;code&gt;alpha&lt;/code&gt; for regularization (L2 regularization) term which helps in avoiding overfitting by penalizing weights with large magnitudes. Following plot displays varying decision function with value of alpha.</source>
          <target state="translated">И &lt;a href=&quot;generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt; &lt;code&gt;MLPRegressor&lt;/code&gt; ,&lt;/a&gt; и &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier&quot;&gt; &lt;code&gt;MLPClassifier&lt;/code&gt; &lt;/a&gt; используют параметр &lt;code&gt;alpha&lt;/code&gt; для термина регуляризации (L2-регуляризация), который помогает избежать переобучения за счет штрафов за веса с большими величинами. Следующий график отображает изменяющуюся функцию принятия решения со значением альфа.</target>
        </trans-unit>
        <trans-unit id="b53b3117e47a61020f59f56f0ab84443cf5a1cc4" translate="yes" xml:space="preserve">
          <source>Both &lt;strong&gt;tf&lt;/strong&gt; and &lt;strong&gt;tf&amp;ndash;idf&lt;/strong&gt; can be computed as follows using &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">И &lt;strong&gt;tf,&lt;/strong&gt; и &lt;strong&gt;tf &amp;ndash; idf&lt;/strong&gt; можно вычислить с помощью &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt; следующим образом :</target>
        </trans-unit>
        <trans-unit id="4bf93c5f6114d3860df00831377e70ae0b54b0c9" translate="yes" xml:space="preserve">
          <source>Both Face Verification and Face Recognition are tasks that are typically performed on the output of a model trained to perform Face Detection. The most popular model for Face Detection is called Viola-Jones and is implemented in the OpenCV library. The LFW faces were extracted by this face detector from various online websites.</source>
          <target state="translated">Как Face Verification (Проверка лиц),так и Face Recognition (Распознавание лиц)-это задачи,которые обычно выполняются на выходе модели,обученной выполнению функции распознавания лиц.Наиболее популярная модель для распознавания лиц называется Viola-Jones и реализована в библиотеке OpenCV.LFW лица были извлечены этим детектором лиц с различных онлайн сайтов.</target>
        </trans-unit>
        <trans-unit id="ca7325084a8f64bcbbcfe176b54a08f8e59fb609" translate="yes" xml:space="preserve">
          <source>Both LDA and QDA can be derived from simple probabilistic models which model the class conditional distribution of the data \(P(X|y=k)\) for each class \(k\). Predictions can then be obtained by using Bayes&amp;rsquo; rule, for each training sample \(x \in \mathcal{R}^d\):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91e41139595583cca1f08b85e6f25218cb1d806a" translate="yes" xml:space="preserve">
          <source>Both LDA and QDA can be derived from simple probabilistic models which model the class conditional distribution of the data \(P(X|y=k)\) for each class \(k\). Predictions can then be obtained by using Bayes&amp;rsquo; rule:</source>
          <target state="translated">И LDA, и QDA могут быть получены из простых вероятностных моделей, которые моделируют условное распределение данных \ (P (X | y = k) \) для каждого класса \ (k \). Затем прогнозы можно получить с помощью правила Байеса:</target>
        </trans-unit>
        <trans-unit id="88ef4403ed65b61f6ce7d70445c003a80e194980" translate="yes" xml:space="preserve">
          <source>Both a large or small &lt;code&gt;leaf_size&lt;/code&gt; can lead to suboptimal query cost. For &lt;code&gt;leaf_size&lt;/code&gt; approaching 1, the overhead involved in traversing nodes can significantly slow query times. For &lt;code&gt;leaf_size&lt;/code&gt; approaching the size of the training set, queries become essentially brute force. A good compromise between these is &lt;code&gt;leaf_size = 30&lt;/code&gt;, the default value of the parameter.</source>
          <target state="translated">И большой, и маленький &lt;code&gt;leaf_size&lt;/code&gt; могут привести к неоптимальной стоимости запроса. Для параметра &lt;code&gt;leaf_size&lt;/code&gt; , приближающегося к 1, накладные расходы, связанные с обходом узлов, могут значительно замедлить время запроса. Для &lt;code&gt;leaf_size&lt;/code&gt; приближающегося к размеру обучающего набора, запросы становятся по сути грубой силой. Хороший компромисс между ними - &lt;code&gt;leaf_size = 30&lt;/code&gt; , значение параметра по умолчанию.</target>
        </trans-unit>
        <trans-unit id="fa5698e1f194999c5b948025698f212260de6074" translate="yes" xml:space="preserve">
          <source>Both for the &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_people#sklearn.datasets.fetch_lfw_people&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_lfw_people&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt;&lt;/a&gt; function it is possible to get an additional dimension with the RGB color channels by passing &lt;code&gt;color=True&lt;/code&gt;, in that case the shape will be &lt;code&gt;(2200, 2, 62, 47, 3)&lt;/code&gt;.</source>
          <target state="translated">Как для функции &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_people#sklearn.datasets.fetch_lfw_people&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_lfw_people&lt;/code&gt; ,так&lt;/a&gt; и &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt; &lt;/a&gt; функции sklearn.datasets.fetch_lfw_pairs можно получить дополнительное измерение с цветовыми каналами RGB, передав &lt;code&gt;color=True&lt;/code&gt; , в этом случае форма будет &lt;code&gt;(2200, 2, 62, 47, 3)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f849c057a89abeca98a91c38c141c4422d4b9044" translate="yes" xml:space="preserve">
          <source>Both kernel ridge regression (KRR) and GPR learn a target function by employing internally the &amp;ldquo;kernel trick&amp;rdquo;. KRR learns a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. The linear function in the kernel space is chosen based on the mean-squared error loss with ridge regularization. GPR uses the kernel to define the covariance of a prior distribution over the target functions and uses the observed training data to define a likelihood function. Based on Bayes theorem, a (Gaussian) posterior distribution over target functions is defined, whose mean is used for prediction.</source>
          <target state="translated">И регрессия гребня ядра (KRR), и GPR изучают целевую функцию, используя внутри себя &amp;laquo;трюк с ядром&amp;raquo;. KRR изучает линейную функцию в пространстве, индуцированную соответствующим ядром, которая соответствует нелинейной функции в исходном пространстве. Линейная функция в пространстве ядра выбирается на основе среднеквадратичной потери ошибки с регуляризацией гребня. GPR использует ядро ​​для определения ковариации предварительного распределения по целевым функциям и использует наблюдаемые обучающие данные для определения функции правдоподобия. На основе теоремы Байеса определяется (гауссово) апостериорное распределение по целевым функциям, среднее значение которого используется для прогнозирования.</target>
        </trans-unit>
        <trans-unit id="23db30f840724e288d4f8f1371ac596206d41d32" translate="yes" xml:space="preserve">
          <source>Both kernel ridge regression (KRR) and Gaussian process regression (GPR) learn a target function by employing internally the &amp;ldquo;kernel trick&amp;rdquo;. KRR learns a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. The linear function in the kernel space is chosen based on the mean-squared error loss with ridge regularization. GPR uses the kernel to define the covariance of a prior distribution over the target functions and uses the observed training data to define a likelihood function. Based on Bayes theorem, a (Gaussian) posterior distribution over target functions is defined, whose mean is used for prediction.</source>
          <target state="translated">И регрессия гребня ядра (KRR), и регрессия гауссовского процесса (GPR) изучают целевую функцию, используя внутренне &amp;laquo;трюк с ядром&amp;raquo;. KRR изучает линейную функцию в пространстве, индуцированную соответствующим ядром, которая соответствует нелинейной функции в исходном пространстве. Линейная функция в пространстве ядра выбирается на основе среднеквадратичной потери ошибки с регуляризацией гребня. GPR использует ядро ​​для определения ковариации предварительного распределения по целевым функциям и использует наблюдаемые обучающие данные для определения функции правдоподобия. На основе теоремы Байеса определяется (гауссово) апостериорное распределение по целевым функциям, среднее значение которого используется для прогнозирования.</target>
        </trans-unit>
        <trans-unit id="a2ae11bd288fcc4a889903f5cd55e2c7dc5062c9" translate="yes" xml:space="preserve">
          <source>Both kernel ridge regression (KRR) and SVR learn a non-linear function by employing the kernel trick, i.e., they learn a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. They differ in the loss functions (ridge versus epsilon-insensitive loss). In contrast to SVR, fitting a KRR can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR at prediction-time.</source>
          <target state="translated">И регрессия гребня ядра (KRR),и SVR учат нелинейную функцию,используя трюк ядра,т.е.они учат линейную функцию в пространстве,индуцированном соответствующим ядром,что соответствует нелинейной функции в исходном пространстве.Они различаются по потерянным функциям (гребень по сравнению с нечувствительными к эпсилону потерями).В отличие от SVR,подгонка KRR может быть выполнена в закрытой форме и обычно быстрее для средних наборов данных.С другой стороны,изученная модель не является разреженной и,следовательно,медленнее,чем SVR во время прогнозирования.</target>
        </trans-unit>
        <trans-unit id="9f6802fa6da263e373ed1a0b728e154415b2fd58" translate="yes" xml:space="preserve">
          <source>Both kinds of calibration can fix this issue and yield nearly identical results. This shows that sigmoid calibration can deal with situations where the calibration curve of the base classifier is sigmoid (e.g., for LinearSVC) but not where it is transposed-sigmoid (e.g., Gaussian naive Bayes).</source>
          <target state="translated">Оба вида калибровки могут исправить эту проблему и дать почти идентичные результаты.Это показывает,что калибровка сигмоида может иметь дело с ситуациями,когда калибровочная кривая базового классификатора сигмоидальная (например,для LinearSVC),но не там,где она транспонирована сигмоидальная (например,Гауссовский наивный Бэйес).</target>
        </trans-unit>
        <trans-unit id="708135c11a370a819f586687e493e8e334b863bb" translate="yes" xml:space="preserve">
          <source>Both linear models have linear decision boundaries (intersecting hyperplanes) while the non-linear kernel models (polynomial or Gaussian RBF) have more flexible non-linear decision boundaries with shapes that depend on the kind of kernel and its parameters.</source>
          <target state="translated">Обе линейные модели имеют линейные границы решений (пересекающиеся гиперплоскости),в то время как нелинейные модели ядра (полиномиальные или гауссовские RBF)имеют более гибкие границы нелинейных решений с формами,зависящими от вида ядра и его параметров.</target>
        </trans-unit>
        <trans-unit id="26e0a0e806824f91854b61cb523786b2b1be2f09" translate="yes" xml:space="preserve">
          <source>Both loaders and fetchers functions return a &lt;a href=&quot;../modules/generated/sklearn.utils.bunch#sklearn.utils.Bunch&quot;&gt;&lt;code&gt;sklearn.utils.Bunch&lt;/code&gt;&lt;/a&gt; object holding at least two items: an array of shape &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; with key &lt;code&gt;data&lt;/code&gt; (except for 20newsgroups) and a numpy array of length &lt;code&gt;n_samples&lt;/code&gt;, containing the target values, with key &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc56722e0a950bb51331dfd1a0000b2f92f9cd59" translate="yes" xml:space="preserve">
          <source>Both loaders and fetchers functions return a dictionary-like object holding at least two items: an array of shape &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; with key &lt;code&gt;data&lt;/code&gt; (except for 20newsgroups) and a numpy array of length &lt;code&gt;n_samples&lt;/code&gt;, containing the target values, with key &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="translated">И загрузчики, и функции сборщика возвращают объект, подобный словарю, содержащий как минимум два элемента: массив формы &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; с ключевыми &lt;code&gt;data&lt;/code&gt; (кроме 20newsgroups) и numpy массив длины &lt;code&gt;n_samples&lt;/code&gt; , содержащий целевые значения, с ключевой &lt;code&gt;target&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c429ee44d91d629f81b84bf7db1e8151de09efd7" translate="yes" xml:space="preserve">
          <source>Both methods are compared in a regression problem using a BayesianRidge as supervised estimator.</source>
          <target state="translated">Оба метода сравниваются в регрессионной задаче с использованием Байесиана-Риджа в качестве контролируемого оценщика.</target>
        </trans-unit>
        <trans-unit id="1f719d18cf26f246fcd8f594b634dc25f50e93c4" translate="yes" xml:space="preserve">
          <source>Both models are able to rank policyholders by risky-ness significantly better than chance although they are also both far from perfect due to the natural difficulty of the prediction problem from few features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c567880fbb130b2f00326a7eed156cd91692677" translate="yes" xml:space="preserve">
          <source>Both models essentially estimate a Gaussian with a low-rank covariance matrix. Because both models are probabilistic they can be integrated in more complex models, e.g. Mixture of Factor Analysers. One gets very different models (e.g. &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;FastICA&lt;/code&gt;&lt;/a&gt;) if non-Gaussian priors on the latent variables are assumed.</source>
          <target state="translated">Обе модели по существу оценивают гауссиан с ковариационной матрицей низкого ранга. Поскольку обе модели являются вероятностными, их можно интегрировать в более сложные модели, например, в смесь факторных анализаторов. Можно получить очень разные модели (например, &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;FastICA&lt;/code&gt; &lt;/a&gt; ), если предполагается негауссовский априор для скрытых переменных.</target>
        </trans-unit>
        <trans-unit id="a62e9a7de64eaa33971b5c3675cc0b062a65784c" translate="yes" xml:space="preserve">
          <source>Both models have access to five components with which to fit the data. Note that the Expectation Maximisation model will necessarily use all five components while the Variational Inference model will effectively only use as many as are needed for a good fit. Here we can see that the Expectation Maximisation model splits some components arbitrarily, because it is trying to fit too many components, while the Dirichlet Process model adapts it number of state automatically.</source>
          <target state="translated">Обе модели имеют доступ к пяти компонентам,с помощью которых можно подогнать данные.Обратите внимание,что модель Expectation Maximisation будет обязательно использовать все пять компонентов,в то время как модель Varitional Inference будет эффективно использовать только столько компонентов,сколько необходимо для хорошей подгонки.Здесь мы видим,что модель Expectation Maximisation разбивает некоторые компоненты произвольно,поскольку пытается подогнать слишком много компонентов,в то время как модель процесса Дирихлета автоматически подстраивает их количество.</target>
        </trans-unit>
        <trans-unit id="5b17a14614025b8fc55b61f491f7a477ebf75742" translate="yes" xml:space="preserve">
          <source>Both scores have positive values between 0.0 and 1.0, larger values being desirable.</source>
          <target state="translated">Обе оценки имеют положительные значения в диапазоне от 0,0 до 1,0,более высокие значения желательны.</target>
        </trans-unit>
        <trans-unit id="be67d7e7cbf7e3b7b92ab971146cc493ee899201" translate="yes" xml:space="preserve">
          <source>Box-Cox can only be applied to strictly positive data. In both methods, the transformation is parameterized by \(\lambda\), which is determined through maximum likelihood estimation. Here is an example of using Box-Cox to map samples drawn from a lognormal distribution to a normal distribution:</source>
          <target state="translated">Box-Cox может применяться только к строго положительным данным.В обоих методах трансформация параметризуется по адресу \(\lambda\),который определяется через оценку максимальной вероятности.Приведем пример использования Box-Cox для отображения образцов,взятых из логнормального распределения,в нормальное:</target>
        </trans-unit>
        <trans-unit id="3b31bca12137b60e3b02c5fa6fcbe997bf063055" translate="yes" xml:space="preserve">
          <source>Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data.</source>
          <target state="translated">Box-Cox требует,чтобы входные данные были строго положительными,в то время как Yeo-Johnson поддерживает как положительные,так и отрицательные данные.</target>
        </trans-unit>
        <trans-unit id="3a33122410e3d55ce36b5d7a297f38716ddc9fb2" translate="yes" xml:space="preserve">
          <source>BrayCurtisDistance</source>
          <target state="translated">BrayCurtisDistance</target>
        </trans-unit>
        <trans-unit id="9567cb56bbf5a464a471c7e7c0603402f701c1b5" translate="yes" xml:space="preserve">
          <source>Breiman, &amp;ldquo;Arcing Classifiers&amp;rdquo;, Annals of Statistics 1998.</source>
          <target state="translated">Брейман, &amp;laquo;Классификаторы дугового разряда&amp;raquo;, Annals of Statistics 1998.</target>
        </trans-unit>
        <trans-unit id="b92ea166bdb68582b38ba5d28898e88166331fb5" translate="yes" xml:space="preserve">
          <source>Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32, 2001.</source>
          <target state="translated">Брейман, &amp;laquo;Случайные леса&amp;raquo;, Машинное обучение, 45 (1), 5-32, 2001.</target>
        </trans-unit>
        <trans-unit id="e706a24019de3d6255ea9f7b340895835c77d481" translate="yes" xml:space="preserve">
          <source>Brendan J. Frey and Delbert Dueck, &amp;ldquo;Clustering by Passing Messages Between Data Points&amp;rdquo;, Science Feb. 2007</source>
          <target state="translated">Брендан Дж. Фрей и Делберт Дук, &amp;laquo;Кластеризация путем передачи сообщений между точками данных&amp;raquo;, Science, февраль 2007 г.</target>
        </trans-unit>
        <trans-unit id="91c2780c7ce208d81dbc70c79b98b19c560e01f7" translate="yes" xml:space="preserve">
          <source>Breunig, Kriegel, Ng, and Sander (2000) &lt;a href=&quot;http://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf&quot;&gt;LOF: identifying density-based local outliers.&lt;/a&gt; Proc. ACM SIGMOD</source>
          <target state="translated">Breunig, Kriegel, Ng, and Sander (2000) &lt;a href=&quot;http://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf&quot;&gt;LOF: определение локальных выбросов на основе плотности. &lt;/a&gt;Proc. ACM SIGMOD</target>
        </trans-unit>
        <trans-unit id="b62edbfb07bbbc25ba8cf8bbc25ed044eba7bbe5" translate="yes" xml:space="preserve">
          <source>Breunig, M. M., Kriegel, H. P., Ng, R. T., &amp;amp; Sander, J. (2000, May). LOF: identifying density-based local outliers. In ACM sigmod record.</source>
          <target state="translated">Breunig, MM, Kriegel, HP, Ng, RT, &amp;amp; Sander, J. (2000, май). LOF: определение локальных выбросов на основе плотности. В ACM запись sigmod.</target>
        </trans-unit>
        <trans-unit id="f5333384a370e2b255c6a3cf2b193f53e9cafb20" translate="yes" xml:space="preserve">
          <source>Briefly, a first-order Taylor approximation says that \(l(z) \approx l(a) + (z - a) \frac{\partial l(a)}{\partial a}\). Here, \(z\) corresponds to \(F_{m - 1}(x_i) + h_m(x_i)\), and \(a\) corresponds to \(F_{m-1}(x_i)\)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fb0165005c94e23be947347cfac674726ddcc8f3" translate="yes" xml:space="preserve">
          <source>Brier score</source>
          <target state="translated">Балл Брайера</target>
        </trans-unit>
        <trans-unit id="ce9563b2203c4e120af29d083264cdec661286f1" translate="yes" xml:space="preserve">
          <source>Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010). The balanced accuracy and its posterior distribution. Proceedings of the 20th International Conference on Pattern Recognition, 3121-24.</source>
          <target state="translated">Бродерсен,К.Х.;Онг,К.С.;Стефан,К.Е.;Буманн,Дж.М.(2010 год).Сбалансированная точность и ее последующее распределение.Труды 20-ой Международной конференции по распознаванию образов,3121-24.</target>
        </trans-unit>
        <trans-unit id="3a47350b7d7cb691a01ccff5ad5d3aca87290c28" translate="yes" xml:space="preserve">
          <source>Brown</source>
          <target state="translated">Brown</target>
        </trans-unit>
        <trans-unit id="5b66173631e06f3f28d6125b3cb26a28cb7fca86" translate="yes" xml:space="preserve">
          <source>Build a Bagging ensemble of estimators from the training</source>
          <target state="translated">Постройте ансамбль мешковщиков из тренировочной группы.</target>
        </trans-unit>
        <trans-unit id="794678e50f47205b9017d4e509f3518d6f5fadf5" translate="yes" xml:space="preserve">
          <source>Build a Bagging ensemble of estimators from the training set (X, y).</source>
          <target state="translated">Постройте ансамбль Бэггингов оценщиков из тренировочного комплекта (Х,у).</target>
        </trans-unit>
        <trans-unit id="187f33f95926319c2456d01efd577acf94dfa6ae" translate="yes" xml:space="preserve">
          <source>Build a CF Tree for the input data.</source>
          <target state="translated">Постройте CF-дерево для входных данных.</target>
        </trans-unit>
        <trans-unit id="1367324c6e1505253779ffa63a9ab3c72dfbf04f" translate="yes" xml:space="preserve">
          <source>Build a HTML representation of an estimator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e09fb3267f6b0d5980c9be2a9dffb892209f693" translate="yes" xml:space="preserve">
          <source>Build a boosted classifier from the training set (X, y).</source>
          <target state="translated">Постройте усиленный классификатор из тренировочного набора (X,y).</target>
        </trans-unit>
        <trans-unit id="bb1580cf6761f3cb6ad38eda4b239ef5f0001320" translate="yes" xml:space="preserve">
          <source>Build a boosted regressor from the training set (X, y).</source>
          <target state="translated">Постройте усиленный регрессор из тренировочной установки (X,y).</target>
        </trans-unit>
        <trans-unit id="250228e6d05087ab14d0d947456ba0aa59ea7050" translate="yes" xml:space="preserve">
          <source>Build a contingency matrix describing the relationship between labels.</source>
          <target state="translated">Постройте матрицу непредвиденных обстоятельств,описывающую взаимосвязь между этикетками.</target>
        </trans-unit>
        <trans-unit id="d74890ceefdff850d4364b5427ecc2c4535dee78" translate="yes" xml:space="preserve">
          <source>Build a decision tree classifier from the training set (X, y).</source>
          <target state="translated">Постройте классификатор дерева решений из обучающего набора (X,y).</target>
        </trans-unit>
        <trans-unit id="2b1b91e53bab7f86a619b51147d8ac61611972f5" translate="yes" xml:space="preserve">
          <source>Build a decision tree regressor from the training set (X, y).</source>
          <target state="translated">Постройте регрессор дерева решений из тренировочного набора (X,y).</target>
        </trans-unit>
        <trans-unit id="255fad2483c531d4d8beb88f94f03694ee2b25aa" translate="yes" xml:space="preserve">
          <source>Build a forest of trees from the training set (X, y).</source>
          <target state="translated">Постройте лес из деревьев из учебного набора (X,y).</target>
        </trans-unit>
        <trans-unit id="54ca7aba833ca6776a4b555adf51f52c37364032" translate="yes" xml:space="preserve">
          <source>Build a text report showing the main classification metrics</source>
          <target state="translated">Составить текстовый отчет,показывающий основные классификационные метрики.</target>
        </trans-unit>
        <trans-unit id="0acb360cebaf298906fb4db3eabfa00d9453c9d3" translate="yes" xml:space="preserve">
          <source>Build a text report showing the main classification metrics.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02e35795301c2dfa78447e621bba28f5e7d78fd9" translate="yes" xml:space="preserve">
          <source>Build a text report showing the rules of a decision tree.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="657256d2b304ff4131eae140a5931256c38a3879" translate="yes" xml:space="preserve">
          <source>Build or fetch the effective stop words list</source>
          <target state="translated">Построить или получить эффективный список стоп-слов.</target>
        </trans-unit>
        <trans-unit id="c274aea56fd427bf062945c347f3184c61ce0dda" translate="yes" xml:space="preserve">
          <source>Build or fetch the effective stop words list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1696170a9053ac1d87e48bfb4ce1d22a7e994777" translate="yes" xml:space="preserve">
          <source>Building a pipeline</source>
          <target state="translated">Строительство трубопровода</target>
        </trans-unit>
        <trans-unit id="d58a993cf5326c10970b9b4db170c35508c44151" translate="yes" xml:space="preserve">
          <source>Bunch objects are sometimes used as an output for functions and methods. They extend dictionaries by enabling values to be accessed by key, &lt;code&gt;bunch[&quot;value_key&quot;]&lt;/code&gt;, or by an attribute, &lt;code&gt;bunch.value_key&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b9d2f152fc732c61d6802508ad1d27938fd60fa" translate="yes" xml:space="preserve">
          <source>By &lt;strong&gt;averaging&lt;/strong&gt; the estimates of predictive ability over several randomized trees one can &lt;strong&gt;reduce the variance&lt;/strong&gt; of such an estimate and use it for feature selection. This is known as the mean decrease in impurity, or MDI. Refer to &lt;a href=&quot;#l2014&quot; id=&quot;id7&quot;&gt;[L2014]&lt;/a&gt; for more information on MDI and feature importance evaluation with Random Forests.</source>
          <target state="translated">Путем &lt;strong&gt;усреднения&lt;/strong&gt; оценок прогнозирующей способности в течение нескольких рандомизированных деревьев можно &lt;strong&gt;уменьшить дисперсию&lt;/strong&gt; такой оценки и использовать его для отбора признаков. Это известно как среднее уменьшение примесей или MDI. См. &lt;a href=&quot;#l2014&quot; id=&quot;id7&quot;&gt;[L2014]&lt;/a&gt; для получения дополнительной информации о MDI и оценке важности функций с помощью случайных лесов.</target>
        </trans-unit>
        <trans-unit id="4271aec9443f091b8f5d73284775ad1de7a16657" translate="yes" xml:space="preserve">
          <source>By contrast, in &lt;strong&gt;boosting methods&lt;/strong&gt;, base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.</source>
          <target state="translated">Напротив, в &lt;strong&gt;методах повышения&lt;/strong&gt; базовые оценки строятся последовательно, и каждый пытается уменьшить смещение комбинированной оценки. Мотивация состоит в том, чтобы объединить несколько слабых моделей для создания мощного ансамбля.</target>
        </trans-unit>
        <trans-unit id="6c32bdf454c04c997b80ade2a7001005f06bf56a" translate="yes" xml:space="preserve">
          <source>By default \(\alpha_1 = \alpha_2 = \lambda_1 = \lambda_2 = 10^{-6}\).</source>
          <target state="translated">По умолчанию \(\alpha_1=\alpha_2=\lambda_1=\lambda_2=10^{-6}\).</target>
        </trans-unit>
        <trans-unit id="471aed0559b4b66da1109f2dd8bd4a3412768eaf" translate="yes" xml:space="preserve">
          <source>By default all available workers will be used (&lt;code&gt;n_jobs=-1&lt;/code&gt;) unless the caller passes an explicit value for the &lt;code&gt;n_jobs&lt;/code&gt; parameter.</source>
          <target state="translated">По умолчанию будут использоваться все доступные &lt;code&gt;n_jobs=-1&lt;/code&gt; ( n_jobs = -1 ), если вызывающий не передаст явное значение для параметра &lt;code&gt;n_jobs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5f6c87aa078eb9e4a070352402cf9ac4b38861b8" translate="yes" xml:space="preserve">
          <source>By default no shuffling occurs, including for the (stratified) K fold cross- validation performed by specifying &lt;code&gt;cv=some_integer&lt;/code&gt; to &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;, grid search, etc. Keep in mind that &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; still returns a random split.</source>
          <target state="translated">По умолчанию перемешивание не происходит, в том числе для (стратифицированной) перекрестной проверки K- &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt; , выполняемой путем указания &lt;code&gt;cv=some_integer&lt;/code&gt; для cross_val_score , поиска по сетке и т. Д. Имейте в виду, что &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; по-&lt;/a&gt; прежнему возвращает случайное разбиение.</target>
        </trans-unit>
        <trans-unit id="e7a2fba0300cf0e1fb0a656c1e5e19ff70aee869" translate="yes" xml:space="preserve">
          <source>By default the data dir is set to a folder named &amp;lsquo;scikit_learn_data&amp;rsquo; in the user home folder.</source>
          <target state="translated">По умолчанию каталог данных установлен в папку с именем scikit_learn_data в домашней папке пользователя.</target>
        </trans-unit>
        <trans-unit id="78999f1442e19c854d03f2d5d120c491c2044f43" translate="yes" xml:space="preserve">
          <source>By default the estimator&amp;rsquo;s &lt;code&gt;score&lt;/code&gt; method is used to compute the individual scores.</source>
          <target state="translated">По умолчанию в Оценщике &lt;code&gt;score&lt;/code&gt; метод используется для расчета индивидуальных баллов.</target>
        </trans-unit>
        <trans-unit id="4b5dc2d778b41c185a986f8e9ad3bff91cf8ed7b" translate="yes" xml:space="preserve">
          <source>By default the following backends are available:</source>
          <target state="translated">По умолчанию доступны следующие бэкэнды:</target>
        </trans-unit>
        <trans-unit id="c9a567aacd54237b7723e5584e83694cffe0556c" translate="yes" xml:space="preserve">
          <source>By default the gradient calculation algorithm uses Barnes-Hut approximation running in O(NlogN) time. method=&amp;rsquo;exact&amp;rsquo; will run on the slower, but exact, algorithm in O(N^2) time. The exact algorithm should be used when nearest-neighbor errors need to be better than 3%. However, the exact method cannot scale to millions of examples.</source>
          <target state="translated">По умолчанию алгоритм вычисления градиента использует приближение Barnes-Hut, работающее за время O (NlogN). Метод = 'точный' будет работать на более медленном, но точном алгоритме за время O (N ^ 2). Точный алгоритм следует использовать, когда ошибки ближайшего соседа должны быть лучше 3%. Однако точный метод нельзя масштабировать до миллионов примеров.</target>
        </trans-unit>
        <trans-unit id="572245e5c8e088605558017246250c8893d52627" translate="yes" xml:space="preserve">
          <source>By default the order will be determined by the order of columns in the label matrix Y.:</source>
          <target state="translated">По умолчанию порядок будет определяться порядком столбцов в матрице меток Y:</target>
        </trans-unit>
        <trans-unit id="cab46542ee630d0794253cdc9adb3976a1835662" translate="yes" xml:space="preserve">
          <source>By default the output is one-hot encoded into a sparse matrix (See &lt;a href=&quot;#preprocessing-categorical-features&quot;&gt;Encoding categorical features&lt;/a&gt;) and this can be configured with the &lt;code&gt;encode&lt;/code&gt; parameter. For each feature, the bin edges are computed during &lt;code&gt;fit&lt;/code&gt; and together with the number of bins, they will define the intervals. Therefore, for the current example, these intervals are defined as:</source>
          <target state="translated">По умолчанию выходные данные быстро кодируются в разреженную матрицу (см. &lt;a href=&quot;#preprocessing-categorical-features&quot;&gt;Категориальные функции кодирования&lt;/a&gt; ), и это можно настроить с помощью параметра &lt;code&gt;encode&lt;/code&gt; . Для каждого объекта границы интервалов вычисляются во время &lt;code&gt;fit&lt;/code&gt; и вместе с количеством интервалов они определяют интервалы. Следовательно, для текущего примера эти интервалы определены как:</target>
        </trans-unit>
        <trans-unit id="7638d24983f6f0c8d02846709e02c43bfb3124b9" translate="yes" xml:space="preserve">
          <source>By default, &lt;a href=&quot;generated/sklearn.decomposition.minibatchdictionarylearning#sklearn.decomposition.MiniBatchDictionaryLearning&quot;&gt;&lt;code&gt;MiniBatchDictionaryLearning&lt;/code&gt;&lt;/a&gt; divides the data into mini-batches and optimizes in an online manner by cycling over the mini-batches for the specified number of iterations. However, at the moment it does not implement a stopping condition.</source>
          <target state="translated">По умолчанию &lt;a href=&quot;generated/sklearn.decomposition.minibatchdictionarylearning#sklearn.decomposition.MiniBatchDictionaryLearning&quot;&gt; &lt;code&gt;MiniBatchDictionaryLearning&lt;/code&gt; &lt;/a&gt; разделяет данные на мини-пакеты и оптимизирует их в интерактивном режиме, циклически перебирая мини-пакеты на указанное количество итераций. Однако на данный момент он не реализует условие остановки.</target>
        </trans-unit>
        <trans-unit id="2eb2435c3e98faf455297cd059d456431f056aed" translate="yes" xml:space="preserve">
          <source>By default, &lt;code&gt;float16&lt;/code&gt; results are computed using &lt;code&gt;float32&lt;/code&gt; intermediates for extra precision.</source>
          <target state="translated">По умолчанию результаты &lt;code&gt;float16&lt;/code&gt; вычисляются с использованием промежуточных &lt;code&gt;float32&lt;/code&gt; для дополнительной точности.</target>
        </trans-unit>
        <trans-unit id="06b991078a7a86c59d05afe16f66234f800e038c" translate="yes" xml:space="preserve">
          <source>By default, LocalOutlierFactor is only meant to be used for outlier detection (novelty=False). Set novelty to True if you want to use LocalOutlierFactor for novelty detection. In this case be aware that that you should only use predict, decision_function and score_samples on new unseen data and not on the training set.</source>
          <target state="translated">По умолчанию LocalOutlierFactor предназначен только для обнаружения отклонений (newty=False).Установите новинку в True,если вы хотите использовать LocalOutlierFactor для определения новизны.В этом случае знайте,что вы должны использовать только прогноз,функцию decision_function и примеры sco_samples на новых невидимых данных,а не на обучающем множестве.</target>
        </trans-unit>
        <trans-unit id="2fb7ae3e457e09c80061e4212540f2949867d13f" translate="yes" xml:space="preserve">
          <source>By default, it performs Generalized Cross-Validation, which is a form of efficient Leave-One-Out cross-validation.</source>
          <target state="translated">По умолчанию она выполняет Обобщенную перекрестную проверку,которая является одной из форм эффективной перекрестной проверки &quot;оставил-не оставил-не оставил&quot;.</target>
        </trans-unit>
        <trans-unit id="76317967f826fa82a2b4a34c8b9f11ee88f99afc" translate="yes" xml:space="preserve">
          <source>By default, it performs Generalized Cross-Validation, which is a form of efficient Leave-One-Out cross-validation. Currently, only the n_features &amp;gt; n_samples case is handled efficiently.</source>
          <target state="translated">По умолчанию он выполняет обобщенную перекрестную проверку, которая является формой эффективной перекрестной проверки с исключением одного и того же. В настоящее время эффективно обрабатывается только случай n_features&amp;gt; n_samples.</target>
        </trans-unit>
        <trans-unit id="c04cdaf41bfb70ed4b9c123ddaef4117557b0e3d" translate="yes" xml:space="preserve">
          <source>By default, only the specified columns in &lt;code&gt;transformers&lt;/code&gt; are transformed and combined in the output, and the non-specified columns are dropped. (default of &lt;code&gt;'drop'&lt;/code&gt;). By specifying &lt;code&gt;remainder='passthrough'&lt;/code&gt;, all remaining columns that were not specified in &lt;code&gt;transformers&lt;/code&gt; will be automatically passed through. This subset of columns is concatenated with the output of the transformers. By setting &lt;code&gt;remainder&lt;/code&gt; to be an estimator, the remaining non-specified columns will use the &lt;code&gt;remainder&lt;/code&gt; estimator. The estimator must support &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-transform&quot;&gt;transform&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15494fd5cbda86aa1f330192fb9882a6711f9c4e" translate="yes" xml:space="preserve">
          <source>By default, only the specified columns in &lt;code&gt;transformers&lt;/code&gt; are transformed and combined in the output, and the non-specified columns are dropped. (default of &lt;code&gt;'drop'&lt;/code&gt;). By specifying &lt;code&gt;remainder='passthrough'&lt;/code&gt;, all remaining columns that were not specified in &lt;code&gt;transformers&lt;/code&gt; will be automatically passed through. This subset of columns is concatenated with the output of the transformers. By setting &lt;code&gt;remainder&lt;/code&gt; to be an estimator, the remaining non-specified columns will use the &lt;code&gt;remainder&lt;/code&gt; estimator. The estimator must support &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-transform&quot;&gt;transform&lt;/a&gt;. Note that using this feature requires that the DataFrame columns input at &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-transform&quot;&gt;transform&lt;/a&gt; have identical order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7750d963aa2e941a76e470078ac6c086adc6dcda" translate="yes" xml:space="preserve">
          <source>By default, only the specified columns in &lt;code&gt;transformers&lt;/code&gt; are transformed and combined in the output, and the non-specified columns are dropped. (default of &lt;code&gt;'drop'&lt;/code&gt;). By specifying &lt;code&gt;remainder='passthrough'&lt;/code&gt;, all remaining columns that were not specified in &lt;code&gt;transformers&lt;/code&gt; will be automatically passed through. This subset of columns is concatenated with the output of the transformers. By setting &lt;code&gt;remainder&lt;/code&gt; to be an estimator, the remaining non-specified columns will use the &lt;code&gt;remainder&lt;/code&gt; estimator. The estimator must support &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">По умолчанию только указанные столбцы в &lt;code&gt;transformers&lt;/code&gt; преобразуются и объединяются в выводе, а неуказанные столбцы удаляются. (по умолчанию &lt;code&gt;'drop'&lt;/code&gt; ). При указании &lt;code&gt;remainder='passthrough'&lt;/code&gt; все оставшиеся столбцы, которые не были указаны в &lt;code&gt;transformers&lt;/code&gt; будут автоматически пропущены. Это подмножество столбцов объединяется с выходом трансформаторов. Если установить &lt;code&gt;remainder&lt;/code&gt; в качестве оценщика, оставшиеся неуказанные столбцы будут использовать оценщик &lt;code&gt;remainder&lt;/code&gt; . Оценщик должен поддерживать &lt;code&gt;fit&lt;/code&gt; и &lt;code&gt;transform&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="4a782d670d6fc36b236c4a8940c016b292a90c5d" translate="yes" xml:space="preserve">
          <source>By default, parameter search uses the &lt;code&gt;score&lt;/code&gt; function of the estimator to evaluate a parameter setting. These are the &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;sklearn.metrics.accuracy_score&lt;/code&gt;&lt;/a&gt; for classification and &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;sklearn.metrics.r2_score&lt;/code&gt;&lt;/a&gt; for regression. For some applications, other scoring functions are better suited (for example in unbalanced classification, the accuracy score is often uninformative). An alternative scoring function can be specified via the &lt;code&gt;scoring&lt;/code&gt; parameter to &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; and many of the specialized cross-validation tools described below. See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for more details.</source>
          <target state="translated">По умолчанию поиск параметр используется &lt;code&gt;score&lt;/code&gt; функции оценки для оценки параметра. Это &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;sklearn.metrics.accuracy_score&lt;/code&gt; &lt;/a&gt; для классификации и &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;sklearn.metrics.r2_score&lt;/code&gt; &lt;/a&gt; для регрессии. Для некоторых приложений лучше подходят другие функции оценки (например, при несбалансированной классификации оценка точности часто неинформативна). Альтернативная функция оценки может быть указана с помощью параметра &lt;code&gt;scoring&lt;/code&gt; для &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; , &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt; и многих специализированных инструментов перекрестной проверки, описанных ниже. Дополнительные сведения см. &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;В&lt;/a&gt; разделе Параметр оценки: определение правил оценки модели .</target>
        </trans-unit>
        <trans-unit id="14b262313cef67a36d56fb94a78ec0ffe131d0f9" translate="yes" xml:space="preserve">
          <source>By default, the &amp;lsquo;recursion&amp;rsquo; method is used on tree-based estimators that support it, and &amp;lsquo;brute&amp;rsquo; is used for the rest.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd89643870e89d7d33668ed08a7b04e11606d0f7" translate="yes" xml:space="preserve">
          <source>By default, the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; uses a 3-fold cross-validation. However, if it detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold. The default will change to a 5-fold cross-validation in version 0.22.</source>
          <target state="translated">По умолчанию &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt; использует трехкратную перекрестную проверку. Однако, если он обнаруживает, что передан классификатор, а не регрессор, он использует стратифицированный 3-кратный. В версии 0.22 значение по умолчанию изменится на 5-кратную перекрестную проверку.</target>
        </trans-unit>
        <trans-unit id="d01628e3c1ff7c3c146d98c4400e308b8d21e62e" translate="yes" xml:space="preserve">
          <source>By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the &lt;code&gt;categories&lt;/code&gt; manually.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aabd7b3f7cca56e260a395d6492aceaf31d56d74" translate="yes" xml:space="preserve">
          <source>By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the &lt;code&gt;categories&lt;/code&gt; manually. The OneHotEncoder previously assumed that the input features take on values in the range [0, max(values)). This behaviour is deprecated.</source>
          <target state="translated">По умолчанию кодировщик выводит категории на основе уникальных значений в каждой функции. Кроме того, вы также можете указать &lt;code&gt;categories&lt;/code&gt; вручную. OneHotEncoder ранее предполагал, что входные функции принимают значения в диапазоне [0, max (values)). Такое поведение устарело.</target>
        </trans-unit>
        <trans-unit id="e22c55145c4d94c4a5b62e5b6f40a60aa6e4907e" translate="yes" xml:space="preserve">
          <source>By default, the initial model \(F_{0}\) is chosen as the constant that minimizes the loss: for a least-squares loss, this is the empirical mean of the target values. The initial model can also be specified via the &lt;code&gt;init&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e16205e1ed0a918834ac9076544d9991fc9c4ca6" translate="yes" xml:space="preserve">
          <source>By default, the input is checked to be a non-empty 2D array containing only finite values. If the dtype of the array is object, attempt converting to float, raising on failure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0397cff741cdca99d6793cf68ca8a230e768dce2" translate="yes" xml:space="preserve">
          <source>By default, the input is converted to an at least 2D numpy array. If the dtype of the array is object, attempt converting to float, raising on failure.</source>
          <target state="translated">По умолчанию вход преобразуется как минимум в массив 2D numpy.Если d-тип массива является объектным,попробуйте преобразовать его в float,повысившись на неудачу.</target>
        </trans-unit>
        <trans-unit id="9dfabb9221fc44d77597df9d22d00887ce88c6cb" translate="yes" xml:space="preserve">
          <source>By default, the provided functions are checked at each fit to be the inverse of each other. However, it is possible to bypass this checking by setting &lt;code&gt;check_inverse&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;:</source>
          <target state="translated">По умолчанию предоставленные функции проверяются при каждой подгонке, чтобы быть противоположными друг другу. Однако эту проверку можно обойти, установив &lt;code&gt;check_inverse&lt;/code&gt; в &lt;code&gt;False&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="761cb5c85c42ad01cf3595b928efe71009e68e6e" translate="yes" xml:space="preserve">
          <source>By default, the score computed at each CV iteration is the &lt;code&gt;score&lt;/code&gt; method of the estimator. It is possible to change this by using the scoring parameter:</source>
          <target state="translated">По умолчанию, оценка вычисляется на каждой итерации CV является &lt;code&gt;score&lt;/code&gt; метод оценки. Это можно изменить, используя параметр оценки:</target>
        </trans-unit>
        <trans-unit id="61fe756b7e3e334c670a2007b6939f399986a294" translate="yes" xml:space="preserve">
          <source>By default, the values each feature can take is inferred automatically from the dataset and can be found in the &lt;code&gt;categories_&lt;/code&gt; attribute:</source>
          <target state="translated">По умолчанию значения каждая функция может принимать выводится автоматически из набора данных и могут быть найдены в &lt;code&gt;categories_&lt;/code&gt; атрибута:</target>
        </trans-unit>
        <trans-unit id="588af344f8a3913fdf9179a25370573310fcee34" translate="yes" xml:space="preserve">
          <source>By default, zero-mean, unit-variance normalization is applied to the transformed data.</source>
          <target state="translated">По умолчанию к преобразованным данным применяется нуль-среднеквадратическое,единично-вариантное нормирование.</target>
        </trans-unit>
        <trans-unit id="11243048cfb311c05ea90a5cca047fa81467c316" translate="yes" xml:space="preserve">
          <source>By definition a confusion matrix \(C\) is such that \(C_{i, j}\) is equal to the number of observations known to be in group \(i\) and predicted to be in group \(j\).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c874644c0e92eeddd8de26271a422d136d288139" translate="yes" xml:space="preserve">
          <source>By definition a confusion matrix \(C\) is such that \(C_{i, j}\) is equal to the number of observations known to be in group \(i\) but predicted to be in group \(j\).</source>
          <target state="translated">По определению матрица путаницы \(C\)такова,что \(C_{i,j}\)равна количеству наблюдений,известных как находящиеся в группе \(i\),но предсказанных как находящиеся в группе \(j\).</target>
        </trans-unit>
        <trans-unit id="7edbd0cd8c2bac6d61783ee719a48e462c1cfcf6" translate="yes" xml:space="preserve">
          <source>By definition, entry \(i, j\) in a confusion matrix is the number of observations actually in group \(i\), but predicted to be in group \(j\). Here is an example:</source>
          <target state="translated">По определению,запись \(i,j\)в матрице путаницы-это количество наблюдений,фактически проведенных в группе \(i\),но прогнозируемых в группе \(j\).Вот пример:</target>
        </trans-unit>
        <trans-unit id="70e3cb436db4ad1c973fa29cd922d3f24b1b4676" translate="yes" xml:space="preserve">
          <source>By imposing a positive (increasing) or negative (decreasing) constraint on the features during the learning process, the estimator is able to properly follow the general trend instead of being subject to the variations.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1dfab6b69e192f9e6ae185588957d2e4ef21b660" translate="yes" xml:space="preserve">
          <source>C parameter in C-Support Vector Classification</source>
          <target state="translated">C-параметр в C-векторной классификации поддержки</target>
        </trans-unit>
        <trans-unit id="cdda2bb3aa8ccb7b0f69433506f364d34d2e9052" translate="yes" xml:space="preserve">
          <source>C parameter in C-Support Vector Classification. 1 by default.</source>
          <target state="translated">C-параметр в C-векторной классификации поддержки.1 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="613d7a720c0f1c9138a31585cc88659b028aac73" translate="yes" xml:space="preserve">
          <source>C-Support Vector Classification.</source>
          <target state="translated">Классификация векторов поддержки С.</target>
        </trans-unit>
        <trans-unit id="bd2a390d1ac4f130ef2be0118bce6d064e5c8f80" translate="yes" xml:space="preserve">
          <source>C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their Applications to Handwritten Digit Recognition, MSc Thesis, Institute of Graduate Studies in Science and Engineering, Bogazici University.</source>
          <target state="translated">C.Кайнак (1995)&quot;Методы объединения множественных классификаторов и их применение для распознавания рукописных цифр&quot;,магистерская диссертация,Институт аспирантуры в области науки и техники,Университет Богазичи.</target>
        </trans-unit>
        <trans-unit id="233528e4f33123dff21e034b86ff445b99733c7a" translate="yes" xml:space="preserve">
          <source>C. Molnar, &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/&quot;&gt;Interpretable Machine Learning&lt;/a&gt;, Section 5.1, 2019.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da3d99d58e8919ce7a794351fb460091679af9c1" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Sch&amp;uuml;tze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 118-120.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da9635593b5caf5d4585f5ff3fe3cc183bfd45ee" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Sch&amp;uuml;tze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265.</source>
          <target state="translated">CD Manning, P. Raghavan и H. Sch&amp;uuml;tze (2008). Введение в поиск информации. Cambridge University Press, стр. 234-265.</target>
        </trans-unit>
        <trans-unit id="14a7f63b48e4cd57491d39ae8fbc9659df0b4285" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Sch&amp;uuml;tze (2008). Introduction to Information Retrieval. Cambridge University Press. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&lt;/a&gt;</source>
          <target state="translated">CD Manning, P. Raghavan и H. Sch&amp;uuml;tze (2008). Введение в поиск информации. Издательство Кембриджского университета. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d8731241db66672efece43e5d06ce590569a5d55" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Sch&amp;uuml;tze (2008). Introduction to Information Retrieval. Cambridge University Press. &lt;a href=&quot;https://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&quot;&gt;https://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f2e75005cfe431b03b43e4219e3b46d7acd0ff4" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&lt;/a&gt;</source>
          <target state="translated">CD Manning, P. Raghavan и H. Schuetze (2008). Введение в поиск информации. Cambridge University Press, стр. 234-265. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="75ec24d6932a118f83e8d64145c0a2ded87f2b67" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&lt;/a&gt;</source>
          <target state="translated">CD Manning, P. Raghavan и H. Schuetze (2008). Введение в поиск информации. Cambridge University Press, стр. 234-265. &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&quot;&gt;http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="01f3fb182680db69cebca5748ed6286feb50b1a9" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. &lt;a href=&quot;https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&quot;&gt;https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9600fefe6b9e4b354eca34f86431cfc60b66dab3" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. &lt;a href=&quot;https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&quot;&gt;https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d19ae811e7ffeb32597a550f21eb906e9869f42b" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan, H. Sch&amp;uuml;tze, &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html&quot;&gt;Introduction to Information Retrieval&lt;/a&gt;, 2008.</source>
          <target state="translated">CD Manning, P. Raghavan, H. Sch&amp;uuml;tze, &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html&quot;&gt;Introduction to Information Retrieval&lt;/a&gt; , 2008.</target>
        </trans-unit>
        <trans-unit id="015610fbd8f75c742ed46a08abb26c26092afe90" translate="yes" xml:space="preserve">
          <source>C.D. Manning, P. Raghavan, H. Sch&amp;uuml;tze, &lt;a href=&quot;https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html&quot;&gt;Introduction to Information Retrieval&lt;/a&gt;, 2008.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac35b04dfbcb3d2d718c41403e2829f9afacc158" translate="yes" xml:space="preserve">
          <source>C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer, p. 209.</source>
          <target state="translated">К.М.Бишоп (2006).Распознавание образов и машинное обучение.Спрингер,с.209.</target>
        </trans-unit>
        <trans-unit id="4e28cad37c371942b28c3b9844d1c63eab0cd98c" translate="yes" xml:space="preserve">
          <source>C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. These accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a rule&amp;rsquo;s precondition if the accuracy of the rule improves without it.</source>
          <target state="translated">C4.5 является преемником ID3 и снял ограничение на то, что функции должны быть категориальными, путем динамического определения дискретного атрибута (на основе числовых переменных), который разделяет непрерывное значение атрибута на дискретный набор интервалов. C4.5 преобразует обученные деревья (т.е. выходные данные алгоритма ID3) в наборы правил &amp;laquo;если-то&amp;raquo;. Затем оценивается точность каждого правила, чтобы определить порядок, в котором они должны применяться. Удаление выполняется путем удаления предусловия правила, если без него точность правила улучшается.</target>
        </trans-unit>
        <trans-unit id="f38b90367c7c83e3cb66fb496411f772ac84712e" translate="yes" xml:space="preserve">
          <source>C5.0 is Quinlan&amp;rsquo;s latest version release under a proprietary license. It uses less memory and builds smaller rulesets than C4.5 while being more accurate.</source>
          <target state="translated">C5.0 - это последняя версия Quinlan под собственной лицензией. Он использует меньше памяти и создает меньшие наборы правил, чем C4.5, но при этом является более точным.</target>
        </trans-unit>
        <trans-unit id="d173d3b539a344f61d41ecea5a62c323f7d19142" translate="yes" xml:space="preserve">
          <source>CCA Canonical Correlation Analysis.</source>
          <target state="translated">Канонический корреляционный анализ CCA.</target>
        </trans-unit>
        <trans-unit id="b29de26d602ff110fad786ea8b03d97b6805af56" translate="yes" xml:space="preserve">
          <source>CCA inherits from PLS with mode=&amp;rdquo;B&amp;rdquo; and deflation_mode=&amp;rdquo;canonical&amp;rdquo;.</source>
          <target state="translated">CCA наследуется от PLS с mode = &quot;B&quot; и deflation_mode = &quot;canonical&quot;.</target>
        </trans-unit>
        <trans-unit id="3b8d88f34c322c835ae4b658c65d92bfd4b52c68" translate="yes" xml:space="preserve">
          <source>CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</source>
          <target state="translated">CHAS переменная манекена Чарльз Ривер (=1,если тракт граничит с рекой;0 в противном случае)</target>
        </trans-unit>
        <trans-unit id="65e7931e7d9586486554e7903a3ba08da00b37e4" translate="yes" xml:space="preserve">
          <source>CRIM per capita crime rate by town</source>
          <target state="translated">Уровень преступности на душу населения по городам</target>
        </trans-unit>
        <trans-unit id="c1c39cb0e3578f55a7a5c64e876c1d8c4ac8dfba" translate="yes" xml:space="preserve">
          <source>CSR, CSC, and LIL sparse matrices are supported. COO sparse matrices are not supported.</source>
          <target state="translated">Поддерживаются разреженные матрицы CSR,CSC и LIL.COO разреженные матрицы не поддерживаются.</target>
        </trans-unit>
        <trans-unit id="73f41c9b08913eecfdd5c30b35b021c1e2d148fd" translate="yes" xml:space="preserve">
          <source>Cache size for gram matrix columns (in megabytes). 100 by default.</source>
          <target state="translated">Размер кэша для грамм-матричных столбцов (в мегабайтах).100 по умолчанию.</target>
        </trans-unit>
        <trans-unit id="596160dd9a9ac13e48baafc6fcbec2fd25ca71f9" translate="yes" xml:space="preserve">
          <source>Caching nearest neighbors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ff21fb5eb8a4fa17d7e155397ec6ccfabcba0a4" translate="yes" xml:space="preserve">
          <source>Caching transformers within a &lt;code&gt;Pipeline&lt;/code&gt;</source>
          <target state="translated">Кэширование трансформаторов в &lt;code&gt;Pipeline&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bc2913cfd35cdeb7164299f7eca5904d9beb65fc" translate="yes" xml:space="preserve">
          <source>Calculate approximate log-likelihood as score.</source>
          <target state="translated">Рассчитайте приблизительную вероятность записи в журнал как балл.</target>
        </trans-unit>
        <trans-unit id="c1ebfc4b9bd037366318ba68c2c2cca59e1e8374" translate="yes" xml:space="preserve">
          <source>Calculate approximate perplexity for data X.</source>
          <target state="translated">Рассчитайте приблизительное недоумение для данных X.</target>
        </trans-unit>
        <trans-unit id="d43ab93e0150f4ef29d06ad998812dd6ba91c9c1" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">Вычислите метрики для каждого экземпляра и найдите их среднее значение (имеет смысл только для классификации с несколькими ярлыками, если это значение отличается от &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="e282cf212dffcdd940b3d9463a8434aa0c623305" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="59762e6da26cf0edea79b5cf712b11b4295f7c3a" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each instance, and find their average.</source>
          <target state="translated">Рассчитайте метрики для каждого случая и найдите их среднее значение.</target>
        </trans-unit>
        <trans-unit id="b0449c6e69f12738c5fc9e626586315cc55b3e5c" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters &amp;lsquo;macro&amp;rsquo; to account for label imbalance; it can result in an F-score that is not between precision and recall.</source>
          <target state="translated">Вычислите метрики для каждой метки и найдите их средневзвешенные значения по поддержке (количество истинных экземпляров для каждой метки). Это изменяет &amp;laquo;макрос&amp;raquo; для учета дисбаланса меток; это может привести к получению F-оценки, которая не находится между точностью и отзывчивостью.</target>
        </trans-unit>
        <trans-unit id="bc72c4ff58beeced2951accfefb204124157b6da" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label).</source>
          <target state="translated">Рассчитайте метрики для каждой метки и найдите их среднее значение,взвешенное по поддержке (количество истинных экземпляров для каждой метки).</target>
        </trans-unit>
        <trans-unit id="a0980fad9587146eedd0aa21fe16b429b81ffb7a" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label). This alters &amp;lsquo;macro&amp;rsquo; to account for label imbalance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9463a17edbcd91794095643439dd340e0b094af" translate="yes" xml:space="preserve">
          <source>Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.</source>
          <target state="translated">Рассчитайте метрики для каждой этикетки и найдите их невзвешенное среднее значение.При этом не учитывается дисбаланс этикеток.</target>
        </trans-unit>
        <trans-unit id="a029600dc316664ad0a95bc83365c7c5938aa93b" translate="yes" xml:space="preserve">
          <source>Calculate metrics globally by considering each element of the label indicator matrix as a label.</source>
          <target state="translated">Рассчитывайте метрики глобально,рассматривая каждый элемент матрицы индикаторов метки как метку.</target>
        </trans-unit>
        <trans-unit id="734c6eed79b78874fafa14f9d8cbb9961b3a854c" translate="yes" xml:space="preserve">
          <source>Calculate metrics globally by counting the total true positives, false negatives and false positives.</source>
          <target state="translated">Вычислять метрики глобально путем подсчета суммарных истинных положительных,ложных отрицательных и ложных срабатываний.</target>
        </trans-unit>
        <trans-unit id="23f0cbdf1f8f2eb83817496535820388353f4a46" translate="yes" xml:space="preserve">
          <source>Calculate the euclidean distances in the presence of missing values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49fff0d8477b2f29bd766898572fb8e020082b5d" translate="yes" xml:space="preserve">
          <source>Calculates a covariance matrix shrunk on the diagonal</source>
          <target state="translated">Вычисляет ковариационную матрицу,сжимаемую по диагонали</target>
        </trans-unit>
        <trans-unit id="f0383dd4fd81be714fa7344f5483fa52315c3c0b" translate="yes" xml:space="preserve">
          <source>Calculating &lt;a href=&quot;https://en.wikipedia.org/wiki/False_positive_rate&quot;&gt;fall out&lt;/a&gt; (also called the false positive rate) for each class:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89465d26eac0f77a714d2eb41333a3104974a090" translate="yes" xml:space="preserve">
          <source>Calculating &lt;a href=&quot;https://en.wikipedia.org/wiki/False_positives_and_false_negatives&quot;&gt;miss rate&lt;/a&gt; (also called the false negative rate) for each class:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="485cdc580455f224386f0fdb1e7fd3b7d1083ba4" translate="yes" xml:space="preserve">
          <source>Calculating &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;recall&lt;/a&gt; (also called the true positive rate or the sensitivity) for each class:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9101242444ef9428e2eaa8ec947f98e495b1f80" translate="yes" xml:space="preserve">
          <source>Calculating &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (also called the true negative rate) for each class:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c97307180f2f1c1353791c3b1ff02010b40d4cbc" translate="yes" xml:space="preserve">
          <source>Calculation over a dense representation, however, may leverage highly optimised vector operations and multithreading in BLAS, and tends to result in fewer CPU cache misses. So the sparsity should typically be quite high (10% non-zeros max, to be checked depending on the hardware) for the sparse input representation to be faster than the dense input representation on a machine with many CPUs and an optimized BLAS implementation.</source>
          <target state="translated">Вычисление по плотному представлению,однако,может использовать высоко оптимизированные векторные операции и многопотоковую работу в BLAS,и,как правило,приводит к меньшему количеству пропусков кэш-памяти процессора.Таким образом,разреженность обычно должна быть достаточно высокой (10% ненулевого максимума,который должен быть проверен в зависимости от аппаратного обеспечения),чтобы разреженное представление входа было быстрее,чем плотное представление входа на машине с большим количеством процессоров и оптимизированной реализацией BLAS.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
