<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="43db2050e085fb9fa1a38e497ee835b64fcdd7a3" translate="yes" xml:space="preserve">
          <source>.inverse()</source>
          <target state="translated">.inverse()</target>
        </trans-unit>
        <trans-unit id="d7a151f4bfd05d71568a450b94954b6ae113cd61" translate="yes" xml:space="preserve">
          <source>.irecv()</source>
          <target state="translated">.irecv()</target>
        </trans-unit>
        <trans-unit id="755d2f2a1ef24eed39bd8e91b88985167994ff75" translate="yes" xml:space="preserve">
          <source>.irfft()</source>
          <target state="translated">.irfft()</target>
        </trans-unit>
        <trans-unit id="5fe8069b3a150e053aa11e7c3335f5cd69c03d88" translate="yes" xml:space="preserve">
          <source>.irfftn()</source>
          <target state="translated">.irfftn()</target>
        </trans-unit>
        <trans-unit id="82752ccb7f5bed8637967b46c2eb5cd3b9a2f061" translate="yes" xml:space="preserve">
          <source>.is_available()</source>
          <target state="translated">.is_available()</target>
        </trans-unit>
        <trans-unit id="8289705cc85974fb987229e727ca49dbe701c0f5" translate="yes" xml:space="preserve">
          <source>.is_complex()</source>
          <target state="translated">.is_complex()</target>
        </trans-unit>
        <trans-unit id="e673809c5eb3dadcbfb615b159979642175567ff" translate="yes" xml:space="preserve">
          <source>.is_contiguous()</source>
          <target state="translated">.is_contiguous()</target>
        </trans-unit>
        <trans-unit id="431ba9df5d02ea376c83c48fd600cc3e6b7d300e" translate="yes" xml:space="preserve">
          <source>.is_cuda</source>
          <target state="translated">.is_cuda</target>
        </trans-unit>
        <trans-unit id="f82823a24473bdd4737f89f787629e43f66285fd" translate="yes" xml:space="preserve">
          <source>.is_deterministic()</source>
          <target state="translated">.is_deterministic()</target>
        </trans-unit>
        <trans-unit id="608667e402dacfbbe040fe24f326305b8cdfebca" translate="yes" xml:space="preserve">
          <source>.is_floating_point()</source>
          <target state="translated">.is_floating_point()</target>
        </trans-unit>
        <trans-unit id="67cab9c42018ac867fd43073bcebec315e210775" translate="yes" xml:space="preserve">
          <source>.is_in_onnx_export()</source>
          <target state="translated">.is_in_onnx_export()</target>
        </trans-unit>
        <trans-unit id="e53e01b2bcf00c842d6a24f459c7b8bd69da64f9" translate="yes" xml:space="preserve">
          <source>.is_initialized()</source>
          <target state="translated">.is_initialized()</target>
        </trans-unit>
        <trans-unit id="bef1a137706dd718df07a8179aefb690f37edce1" translate="yes" xml:space="preserve">
          <source>.is_meta</source>
          <target state="translated">.is_meta</target>
        </trans-unit>
        <trans-unit id="844f50276a79a5fd87aa73a299de9c846a5c039c" translate="yes" xml:space="preserve">
          <source>.is_mpi_available()</source>
          <target state="translated">.is_mpi_available()</target>
        </trans-unit>
        <trans-unit id="33630e113e1da06d62fadbf80bc01ec6d1ee124d" translate="yes" xml:space="preserve">
          <source>.is_nccl_available()</source>
          <target state="translated">.is_nccl_available()</target>
        </trans-unit>
        <trans-unit id="4eda273ea148c68930ec2f09a468acdace98c71a" translate="yes" xml:space="preserve">
          <source>.is_ninja_available()</source>
          <target state="translated">.is_ninja_available()</target>
        </trans-unit>
        <trans-unit id="dea05f5ed418298cd8afa76562eb5e798e514b66" translate="yes" xml:space="preserve">
          <source>.is_nonzero()</source>
          <target state="translated">.is_nonzero()</target>
        </trans-unit>
        <trans-unit id="10b335d2e039781b17c8ddbd3e12a06f39685bb6" translate="yes" xml:space="preserve">
          <source>.is_pinned()</source>
          <target state="translated">.is_pinned()</target>
        </trans-unit>
        <trans-unit id="616963012a9a556a2b18648c1300b8008ce52ac0" translate="yes" xml:space="preserve">
          <source>.is_quantized</source>
          <target state="translated">.is_quantized</target>
        </trans-unit>
        <trans-unit id="ff826b1019661ba426b51eef0105ba5a08e10b2e" translate="yes" xml:space="preserve">
          <source>.is_set_to()</source>
          <target state="translated">.is_set_to()</target>
        </trans-unit>
        <trans-unit id="78c9ecbb3c6a11586a64dd53cb36e28b2b0bd0b5" translate="yes" xml:space="preserve">
          <source>.is_shared()</source>
          <target state="translated">.is_shared()</target>
        </trans-unit>
        <trans-unit id="e29b7c939eb6a2a9aa8910d6f3d2980ea61cddcf" translate="yes" xml:space="preserve">
          <source>.is_signed()</source>
          <target state="translated">.is_signed()</target>
        </trans-unit>
        <trans-unit id="de6743a626e195a43a95ef77072b69ee735ea652" translate="yes" xml:space="preserve">
          <source>.is_sparse</source>
          <target state="translated">.is_sparse</target>
        </trans-unit>
        <trans-unit id="204717da0b0d04d3ad3d56ba4950596a1cf4c8a7" translate="yes" xml:space="preserve">
          <source>.is_storage()</source>
          <target state="translated">.is_storage()</target>
        </trans-unit>
        <trans-unit id="20cba67a9af951032ceed95c4aa1f8bf2d41abbb" translate="yes" xml:space="preserve">
          <source>.is_tensor()</source>
          <target state="translated">.is_tensor()</target>
        </trans-unit>
        <trans-unit id="8d5ef197a48b7f48809639940e58cd08a2918fec" translate="yes" xml:space="preserve">
          <source>.isclose()</source>
          <target state="translated">.isclose()</target>
        </trans-unit>
        <trans-unit id="7590f8c1bc747b5d924dca61c8d91f044ecb213c" translate="yes" xml:space="preserve">
          <source>.isend()</source>
          <target state="translated">.isend()</target>
        </trans-unit>
        <trans-unit id="a244e43b28aa26181c7a662ce09e0ea06e5a9211" translate="yes" xml:space="preserve">
          <source>.isfinite()</source>
          <target state="translated">.isfinite()</target>
        </trans-unit>
        <trans-unit id="37eaf88513313181a01036eadbfe9a0478f6055b" translate="yes" xml:space="preserve">
          <source>.isinf()</source>
          <target state="translated">.isinf()</target>
        </trans-unit>
        <trans-unit id="5a23ee1f2ccfa4589952f9181698127e30a4a21e" translate="yes" xml:space="preserve">
          <source>.isnan()</source>
          <target state="translated">.isnan()</target>
        </trans-unit>
        <trans-unit id="f9746ca126e9176f16e1fa9410e37453695c8c4a" translate="yes" xml:space="preserve">
          <source>.isneginf()</source>
          <target state="translated">.isneginf()</target>
        </trans-unit>
        <trans-unit id="0b1be7577126c429b9ad75852fdbae67355413ee" translate="yes" xml:space="preserve">
          <source>.isposinf()</source>
          <target state="translated">.isposinf()</target>
        </trans-unit>
        <trans-unit id="6cd3eed7e0454ec6be28b052028a9a7b57eb423d" translate="yes" xml:space="preserve">
          <source>.isreal()</source>
          <target state="translated">.isreal()</target>
        </trans-unit>
        <trans-unit id="004daaf47030bda2c2de4a06571832140e187b60" translate="yes" xml:space="preserve">
          <source>.istft()</source>
          <target state="translated">.istft()</target>
        </trans-unit>
        <trans-unit id="599aa2b3b7853ecceaa5a41a4f716dc4c4b19f36" translate="yes" xml:space="preserve">
          <source>.item()</source>
          <target state="translated">.item()</target>
        </trans-unit>
        <trans-unit id="a63a9b35c6495ab11f50b093575a223552e1b357" translate="yes" xml:space="preserve">
          <source>.kaiming_normal_()</source>
          <target state="translated">.kaiming_normal_()</target>
        </trans-unit>
        <trans-unit id="a264b115b595d153fa67c7f64fe5b6fbd9bb3731" translate="yes" xml:space="preserve">
          <source>.kaiming_uniform_()</source>
          <target state="translated">.kaiming_uniform_()</target>
        </trans-unit>
        <trans-unit id="643ebe0dbeea2361b4640d8a6635eed00ce030c9" translate="yes" xml:space="preserve">
          <source>.kaiser_window()</source>
          <target state="translated">.kaiser_window()</target>
        </trans-unit>
        <trans-unit id="d57e5404c4f6180c70111f6e32d61611bcb8de42" translate="yes" xml:space="preserve">
          <source>.kl_div()</source>
          <target state="translated">.kl_div()</target>
        </trans-unit>
        <trans-unit id="a0d1954ce045f2549fb7f0978153785f39a8108b" translate="yes" xml:space="preserve">
          <source>.kthvalue()</source>
          <target state="translated">.kthvalue()</target>
        </trans-unit>
        <trans-unit id="af7488248abd0a0fc14a20098f5f13ce4657590d" translate="yes" xml:space="preserve">
          <source>.l1_loss()</source>
          <target state="translated">.l1_loss()</target>
        </trans-unit>
        <trans-unit id="0c78bdca4573145df714f67702a16b9d3084dbe3" translate="yes" xml:space="preserve">
          <source>.layer_norm()</source>
          <target state="translated">.layer_norm()</target>
        </trans-unit>
        <trans-unit id="76a3b15f7e58012e92e79ff78711c7eb0cd3e534" translate="yes" xml:space="preserve">
          <source>.lcm()</source>
          <target state="translated">.lcm()</target>
        </trans-unit>
        <trans-unit id="f35a7884729ce435a433cb5d82dcc39108f35705" translate="yes" xml:space="preserve">
          <source>.lcm_()</source>
          <target state="translated">.lcm_()</target>
        </trans-unit>
        <trans-unit id="0aa877ae32875f4a5db73eb4cfedcd8242ac74ce" translate="yes" xml:space="preserve">
          <source>.le_()</source>
          <target state="translated">.le_()</target>
        </trans-unit>
        <trans-unit id="612025e303779fb4cc1fc108c4f335504bd8998f" translate="yes" xml:space="preserve">
          <source>.leaky_relu()</source>
          <target state="translated">.leaky_relu()</target>
        </trans-unit>
        <trans-unit id="640e8e833f5b4d72a78648fa389f8ff0b85ed64d" translate="yes" xml:space="preserve">
          <source>.leaky_relu_()</source>
          <target state="translated">.leaky_relu_()</target>
        </trans-unit>
        <trans-unit id="0a41235baae68523ad44c47a21052cc657cbb736" translate="yes" xml:space="preserve">
          <source>.lerp()</source>
          <target state="translated">.lerp()</target>
        </trans-unit>
        <trans-unit id="b525262ab852d7dd4ca21364d7fcc8f3f5586bcf" translate="yes" xml:space="preserve">
          <source>.lerp_()</source>
          <target state="translated">.lerp_()</target>
        </trans-unit>
        <trans-unit id="8586b7377a5b0c63873f2b9ad09e7422c871cfd8" translate="yes" xml:space="preserve">
          <source>.less()</source>
          <target state="translated">.less()</target>
        </trans-unit>
        <trans-unit id="c632a159cca56fcea340e687cc56b4e2706d70c5" translate="yes" xml:space="preserve">
          <source>.less_()</source>
          <target state="translated">.less_()</target>
        </trans-unit>
        <trans-unit id="bdffd03c839732cd577e142065210fae0833231e" translate="yes" xml:space="preserve">
          <source>.less_equal()</source>
          <target state="translated">.less_equal()</target>
        </trans-unit>
        <trans-unit id="68ed6270bac9857f344bfabf60c3474c7cf69bec" translate="yes" xml:space="preserve">
          <source>.less_equal_()</source>
          <target state="translated">.less_equal_()</target>
        </trans-unit>
        <trans-unit id="e89241c79f137b22917fe2df1889ea8e348ebe3b" translate="yes" xml:space="preserve">
          <source>.lgamma()</source>
          <target state="translated">.lgamma()</target>
        </trans-unit>
        <trans-unit id="44fd0f5f4b4a6ce5090a0ac1bb0d548503d68133" translate="yes" xml:space="preserve">
          <source>.lgamma_()</source>
          <target state="translated">.lgamma_()</target>
        </trans-unit>
        <trans-unit id="74f38e70ce6d3e0f6db6a7f1551173ef0e17c676" translate="yes" xml:space="preserve">
          <source>.linear()</source>
          <target state="translated">.linear()</target>
        </trans-unit>
        <trans-unit id="37cfae94717cd47c627ec036c017b2b798f2991d" translate="yes" xml:space="preserve">
          <source>.linspace()</source>
          <target state="translated">.linspace()</target>
        </trans-unit>
        <trans-unit id="1fa380fe7d4cfbfba39d39aacdb52abcfeb8cb26" translate="yes" xml:space="preserve">
          <source>.list()</source>
          <target state="translated">.list()</target>
        </trans-unit>
        <trans-unit id="1b28eb5257373d65704b8c80f2f0cc3b48f1f028" translate="yes" xml:space="preserve">
          <source>.load()</source>
          <target state="translated">.load()</target>
        </trans-unit>
        <trans-unit id="cffeb5e7bece026ef8d3f583ef3a5e9d50b348a7" translate="yes" xml:space="preserve">
          <source>.load_inline()</source>
          <target state="translated">.load_inline()</target>
        </trans-unit>
        <trans-unit id="873480c238b16e001827680156be8cb38cb5d2d0" translate="yes" xml:space="preserve">
          <source>.load_state_dict_from_url()</source>
          <target state="translated">.load_state_dict_from_url()</target>
        </trans-unit>
        <trans-unit id="8f528340d5c7c212c0767ebc8a5263a9e5a72c0f" translate="yes" xml:space="preserve">
          <source>.load_url()</source>
          <target state="translated">.load_url()</target>
        </trans-unit>
        <trans-unit id="97e9e6d4092125e3ea205473898760af06e1ccf1" translate="yes" xml:space="preserve">
          <source>.lobpcg()</source>
          <target state="translated">.lobpcg()</target>
        </trans-unit>
        <trans-unit id="44f83c9cbcff978ccb6d0a91f42e90c3a00a29f4" translate="yes" xml:space="preserve">
          <source>.local_response_norm()</source>
          <target state="translated">.local_response_norm()</target>
        </trans-unit>
        <trans-unit id="cc1c4c5971115fe8bc28aa74901f7003b993de9d" translate="yes" xml:space="preserve">
          <source>.log()</source>
          <target state="translated">.log()</target>
        </trans-unit>
        <trans-unit id="cac9f52f41156c86480fe7a9371d6ba58f38406b" translate="yes" xml:space="preserve">
          <source>.log10()</source>
          <target state="translated">.log10()</target>
        </trans-unit>
        <trans-unit id="46137a16ded7dbe3345e7a1e3e9dc648140a77e0" translate="yes" xml:space="preserve">
          <source>.log10_()</source>
          <target state="translated">.log10_()</target>
        </trans-unit>
        <trans-unit id="1e03b609a89689dae8c12c71022346903c02c662" translate="yes" xml:space="preserve">
          <source>.log1p()</source>
          <target state="translated">.log1p()</target>
        </trans-unit>
        <trans-unit id="7d603d5379c4ac05d275533f8be22cc5d3e7fff7" translate="yes" xml:space="preserve">
          <source>.log1p_()</source>
          <target state="translated">.log1p_()</target>
        </trans-unit>
        <trans-unit id="d486122b1ff5c3be4b5281d2d92a564fcd7110e8" translate="yes" xml:space="preserve">
          <source>.log2()</source>
          <target state="translated">.log2()</target>
        </trans-unit>
        <trans-unit id="1ba8406fce848cf2133c3b950af1cc80d2c1d66a" translate="yes" xml:space="preserve">
          <source>.log2_()</source>
          <target state="translated">.log2_()</target>
        </trans-unit>
        <trans-unit id="942c4c4c27a912dd91b888b1e47061d388174b5f" translate="yes" xml:space="preserve">
          <source>.log_()</source>
          <target state="translated">.log_()</target>
        </trans-unit>
        <trans-unit id="a8ab8fbfcf7c062e410e45fab88a02988c08898f" translate="yes" xml:space="preserve">
          <source>.log_normal_()</source>
          <target state="translated">.log_normal_()</target>
        </trans-unit>
        <trans-unit id="0abf1a7178bcd34764910ddfc9a43b4c26aedcfe" translate="yes" xml:space="preserve">
          <source>.log_softmax()</source>
          <target state="translated">.log_softmax()</target>
        </trans-unit>
        <trans-unit id="15b2416a06b7f80e619d53384aa261d42e0cffd9" translate="yes" xml:space="preserve">
          <source>.logaddexp()</source>
          <target state="translated">.logaddexp()</target>
        </trans-unit>
        <trans-unit id="92634be2d2818a1cd9d1b052c4335f0835c3f656" translate="yes" xml:space="preserve">
          <source>.logaddexp2()</source>
          <target state="translated">.logaddexp2()</target>
        </trans-unit>
        <trans-unit id="e7c2e7a27d3a4a711996d7680c149521727e9347" translate="yes" xml:space="preserve">
          <source>.logcumsumexp()</source>
          <target state="translated">.logcumsumexp()</target>
        </trans-unit>
        <trans-unit id="63a0405172b6a7444e3bfc29fa2480b0ca86e75f" translate="yes" xml:space="preserve">
          <source>.logdet()</source>
          <target state="translated">.logdet()</target>
        </trans-unit>
        <trans-unit id="2059ef5aa76d72af43bef4ab5b7780792fa66570" translate="yes" xml:space="preserve">
          <source>.logical_and()</source>
          <target state="translated">.logical_and()</target>
        </trans-unit>
        <trans-unit id="53cba07fcccf5e26e2f836124508227f330a17d6" translate="yes" xml:space="preserve">
          <source>.logical_and_()</source>
          <target state="translated">.logical_and_()</target>
        </trans-unit>
        <trans-unit id="13daebff0ac12adfb1e929fa41bdfc8fb733d3e2" translate="yes" xml:space="preserve">
          <source>.logical_not()</source>
          <target state="translated">.logical_not()</target>
        </trans-unit>
        <trans-unit id="640ae6988c962d158885a754e11942808dc1b176" translate="yes" xml:space="preserve">
          <source>.logical_not_()</source>
          <target state="translated">.logical_not_()</target>
        </trans-unit>
        <trans-unit id="46b11b8d1287faaaf839674cebaebb6a0a51bc70" translate="yes" xml:space="preserve">
          <source>.logical_or()</source>
          <target state="translated">.logical_or()</target>
        </trans-unit>
        <trans-unit id="ae46745f58a51ea20b9bed2e333191f6ae59b15c" translate="yes" xml:space="preserve">
          <source>.logical_or_()</source>
          <target state="translated">.logical_or_()</target>
        </trans-unit>
        <trans-unit id="84d4a9f94d61d5819e4470ac27006374e4cf7094" translate="yes" xml:space="preserve">
          <source>.logical_xor()</source>
          <target state="translated">.logical_xor()</target>
        </trans-unit>
        <trans-unit id="2399ee650fe09fcd66728c8b7cb0d6e8cff11fe1" translate="yes" xml:space="preserve">
          <source>.logical_xor_()</source>
          <target state="translated">.logical_xor_()</target>
        </trans-unit>
        <trans-unit id="5044c26506ab620583288331af5e64b547db7e4d" translate="yes" xml:space="preserve">
          <source>.logit()</source>
          <target state="translated">.logit()</target>
        </trans-unit>
        <trans-unit id="12e2e5abbccaad27e567c91c4395d4aaeebdc97c" translate="yes" xml:space="preserve">
          <source>.logit_()</source>
          <target state="translated">.logit_()</target>
        </trans-unit>
        <trans-unit id="fe002c0710de42f5b7b245401ea1fa7c99384b87" translate="yes" xml:space="preserve">
          <source>.logsigmoid()</source>
          <target state="translated">.logsigmoid()</target>
        </trans-unit>
        <trans-unit id="a35f63a5ccef71fc3ca1fa448385efae05321522" translate="yes" xml:space="preserve">
          <source>.logspace()</source>
          <target state="translated">.logspace()</target>
        </trans-unit>
        <trans-unit id="16db9f27e91d3a7119552ad8f4dd06cdd16a5287" translate="yes" xml:space="preserve">
          <source>.logsumexp()</source>
          <target state="translated">.logsumexp()</target>
        </trans-unit>
        <trans-unit id="ac9c9f3fb720a8947b52480b009c6d15205d466c" translate="yes" xml:space="preserve">
          <source>.long()</source>
          <target state="translated">.long()</target>
        </trans-unit>
        <trans-unit id="b48274f9cf9266d5b1cb906f4c1995e7f5e8b458" translate="yes" xml:space="preserve">
          <source>.lp_pool1d()</source>
          <target state="translated">.lp_pool1d()</target>
        </trans-unit>
        <trans-unit id="9beb39421a4920f6aae58b7d9ae9ec78ed6cd4d6" translate="yes" xml:space="preserve">
          <source>.lp_pool2d()</source>
          <target state="translated">.lp_pool2d()</target>
        </trans-unit>
        <trans-unit id="b0a2c41f7425eb43a5539aa8883e874019169e1c" translate="yes" xml:space="preserve">
          <source>.lstsq()</source>
          <target state="translated">.lstsq()</target>
        </trans-unit>
        <trans-unit id="76bcff4faaf3f57925bc854e2e1ba33cef9c6943" translate="yes" xml:space="preserve">
          <source>.lt_()</source>
          <target state="translated">.lt_()</target>
        </trans-unit>
        <trans-unit id="879592003d287d997b9a0dc46b60e4b2950a01fd" translate="yes" xml:space="preserve">
          <source>.lu_solve()</source>
          <target state="translated">.lu_solve()</target>
        </trans-unit>
        <trans-unit id="dfc7ed55f2405ec684e1146f94a0ed67274b0f00" translate="yes" xml:space="preserve">
          <source>.lu_unpack()</source>
          <target state="translated">.lu_unpack()</target>
        </trans-unit>
        <trans-unit id="f2d98eefe5ce6ee7f2eec0df50ba6384f2cd9d5c" translate="yes" xml:space="preserve">
          <source>.manual_seed()</source>
          <target state="translated">.manual_seed()</target>
        </trans-unit>
        <trans-unit id="84a9ddf20c04c24e14e0338c19d97a2e184a9b80" translate="yes" xml:space="preserve">
          <source>.map_()</source>
          <target state="translated">.map_()</target>
        </trans-unit>
        <trans-unit id="80632cc62b5b12fe2dda28e622d1ef3029abfbdf" translate="yes" xml:space="preserve">
          <source>.margin_ranking_loss()</source>
          <target state="translated">.margin_ranking_loss()</target>
        </trans-unit>
        <trans-unit id="41045df277f07b5e9a519e0d1019057e0054062f" translate="yes" xml:space="preserve">
          <source>.masked_fill()</source>
          <target state="translated">.masked_fill()</target>
        </trans-unit>
        <trans-unit id="1efa948b0b9464e4617776266af5cfc28dea8776" translate="yes" xml:space="preserve">
          <source>.masked_fill_()</source>
          <target state="translated">.masked_fill_()</target>
        </trans-unit>
        <trans-unit id="ec12189ed639f065d73234b4f932e94e6ac45baa" translate="yes" xml:space="preserve">
          <source>.masked_scatter()</source>
          <target state="translated">.masked_scatter()</target>
        </trans-unit>
        <trans-unit id="fdd722180b05385b477193864010a823557399e3" translate="yes" xml:space="preserve">
          <source>.masked_scatter_()</source>
          <target state="translated">.masked_scatter_()</target>
        </trans-unit>
        <trans-unit id="9b7e172b470d28bf6cb47bd475e8f1e340204da0" translate="yes" xml:space="preserve">
          <source>.masked_select()</source>
          <target state="translated">.masked_select()</target>
        </trans-unit>
        <trans-unit id="6241d4016a283d240f265e490a837e2ab572de0e" translate="yes" xml:space="preserve">
          <source>.matmul()</source>
          <target state="translated">.matmul()</target>
        </trans-unit>
        <trans-unit id="3bb87ee952aa22e6b5295968b15372f22b9018e2" translate="yes" xml:space="preserve">
          <source>.matrix_exp()</source>
          <target state="translated">.matrix_exp()</target>
        </trans-unit>
        <trans-unit id="8857db07810e7e7b0d108e1dcb780212b7fed0ba" translate="yes" xml:space="preserve">
          <source>.matrix_power()</source>
          <target state="translated">.matrix_power()</target>
        </trans-unit>
        <trans-unit id="f5898d8443599c872cb4c50f9fc3f4798d5a4199" translate="yes" xml:space="preserve">
          <source>.matrix_rank()</source>
          <target state="translated">.matrix_rank()</target>
        </trans-unit>
        <trans-unit id="ae7e8f74ac4e2c0e12821fe16f559c8cdb7dfa1a" translate="yes" xml:space="preserve">
          <source>.max()</source>
          <target state="translated">.max()</target>
        </trans-unit>
        <trans-unit id="fb481ad270244853e5154d7dd1ed06263ce37c85" translate="yes" xml:space="preserve">
          <source>.max_pool1d()</source>
          <target state="translated">.max_pool1d()</target>
        </trans-unit>
        <trans-unit id="a93a3f93a66bc6106938f094a1d7e69f39b98682" translate="yes" xml:space="preserve">
          <source>.max_pool2d()</source>
          <target state="translated">.max_pool2d()</target>
        </trans-unit>
        <trans-unit id="2038b9e568490dd1f656fab36ce4ad90c1f59b86" translate="yes" xml:space="preserve">
          <source>.max_pool3d()</source>
          <target state="translated">.max_pool3d()</target>
        </trans-unit>
        <trans-unit id="1ab5e6352ce17be974d42add393c20d1c484386c" translate="yes" xml:space="preserve">
          <source>.max_unpool1d()</source>
          <target state="translated">.max_unpool1d()</target>
        </trans-unit>
        <trans-unit id="2ff7fe7a3681eca2c259bae9011b456e8d0ece58" translate="yes" xml:space="preserve">
          <source>.max_unpool2d()</source>
          <target state="translated">.max_unpool2d()</target>
        </trans-unit>
        <trans-unit id="8df8f6c560ef764e540da0ed9b9353b480f6ff5a" translate="yes" xml:space="preserve">
          <source>.max_unpool3d()</source>
          <target state="translated">.max_unpool3d()</target>
        </trans-unit>
        <trans-unit id="8d8107d51de585e17b93ea8708cc48fd3bd6eb97" translate="yes" xml:space="preserve">
          <source>.maximum()</source>
          <target state="translated">.maximum()</target>
        </trans-unit>
        <trans-unit id="f95ac655c8c224aeed22b799f46cf3b03aecbdca" translate="yes" xml:space="preserve">
          <source>.mean()</source>
          <target state="translated">.mean()</target>
        </trans-unit>
        <trans-unit id="85635a8d0fd726c2ffecf44b53ddf06349b4d714" translate="yes" xml:space="preserve">
          <source>.median()</source>
          <target state="translated">.median()</target>
        </trans-unit>
        <trans-unit id="2a9b8b487600380a2baae4eac5e8267fcd54665d" translate="yes" xml:space="preserve">
          <source>.meshgrid()</source>
          <target state="translated">.meshgrid()</target>
        </trans-unit>
        <trans-unit id="fe56cd3a51f42631214987863b59d824bfe5b922" translate="yes" xml:space="preserve">
          <source>.min()</source>
          <target state="translated">.min()</target>
        </trans-unit>
        <trans-unit id="ed183459ca98d436d1777662619b43dbd1754ebe" translate="yes" xml:space="preserve">
          <source>.minimum()</source>
          <target state="translated">.minimum()</target>
        </trans-unit>
        <trans-unit id="287c89ddbb4a162d0fe43714c7ba07354654c224" translate="yes" xml:space="preserve">
          <source>.mkl.is_available()</source>
          <target state="translated">.mkl.is_available()</target>
        </trans-unit>
        <trans-unit id="dfdc64f594bf03478dbde4515a3533bcb41ac12d" translate="yes" xml:space="preserve">
          <source>.mkldnn.is_available()</source>
          <target state="translated">.mkldnn.is_available()</target>
        </trans-unit>
        <trans-unit id="a76f6fa6a87026e5df8a89f16294204b78d7c154" translate="yes" xml:space="preserve">
          <source>.mnasnet0_5()</source>
          <target state="translated">.mnasnet0_5()</target>
        </trans-unit>
        <trans-unit id="78b3778f096432ccb2b0188142563cdeb5af4281" translate="yes" xml:space="preserve">
          <source>.mnasnet0_75()</source>
          <target state="translated">.mnasnet0_75()</target>
        </trans-unit>
        <trans-unit id="ce423a662a5682783f67b545ff556c99662a45eb" translate="yes" xml:space="preserve">
          <source>.mnasnet1_0()</source>
          <target state="translated">.mnasnet1_0()</target>
        </trans-unit>
        <trans-unit id="f484650c0519e7a77d0730dc1f8274f4a3e45870" translate="yes" xml:space="preserve">
          <source>.mnasnet1_3()</source>
          <target state="translated">.mnasnet1_3()</target>
        </trans-unit>
        <trans-unit id="ad0a058af3d7706be750f9ca6b04d7cc4315871f" translate="yes" xml:space="preserve">
          <source>.mobilenet_v2()</source>
          <target state="translated">.mobilenet_v2()</target>
        </trans-unit>
        <trans-unit id="641ce3bceea79812320c478bd354cc0aed1e72d1" translate="yes" xml:space="preserve">
          <source>.mode()</source>
          <target state="translated">.mode()</target>
        </trans-unit>
        <trans-unit id="fcc774d16d1eaa2da5dbab78d134404d2e7ec303" translate="yes" xml:space="preserve">
          <source>.movedim()</source>
          <target state="translated">.movedim()</target>
        </trans-unit>
        <trans-unit id="ea99adcdf604cb6e646aa43414df262ed971b4bb" translate="yes" xml:space="preserve">
          <source>.mse_loss()</source>
          <target state="translated">.mse_loss()</target>
        </trans-unit>
        <trans-unit id="db12345621f935f79b0c9e045994bca669b7079b" translate="yes" xml:space="preserve">
          <source>.mul()</source>
          <target state="translated">.mul()</target>
        </trans-unit>
        <trans-unit id="cdccfce32f026fbf8773278e0c8f0c02332621ac" translate="yes" xml:space="preserve">
          <source>.mul_()</source>
          <target state="translated">.mul_()</target>
        </trans-unit>
        <trans-unit id="14a94ad61f6a052252637c759de394c4550688ee" translate="yes" xml:space="preserve">
          <source>.multi_margin_loss()</source>
          <target state="translated">.multi_margin_loss()</target>
        </trans-unit>
        <trans-unit id="2ec374a2358df3405afecc9695ff7a48a38b7b91" translate="yes" xml:space="preserve">
          <source>.multilabel_margin_loss()</source>
          <target state="translated">.multilabel_margin_loss()</target>
        </trans-unit>
        <trans-unit id="8dd7dafa66a4ca0f339a72006a0fd1dcd6a6a437" translate="yes" xml:space="preserve">
          <source>.multilabel_soft_margin_loss()</source>
          <target state="translated">.multilabel_soft_margin_loss()</target>
        </trans-unit>
        <trans-unit id="09fb7b62d08a504ab317e18a6e3217a97a452b5c" translate="yes" xml:space="preserve">
          <source>.multinomial()</source>
          <target state="translated">.multinomial()</target>
        </trans-unit>
        <trans-unit id="113c7f980cd252560c0677243014edeaeb8b7b82" translate="yes" xml:space="preserve">
          <source>.multiply()</source>
          <target state="translated">.multiply()</target>
        </trans-unit>
        <trans-unit id="d4a60b9a0a2ee2d8c0eb44760cac59647d964b8f" translate="yes" xml:space="preserve">
          <source>.multiply_()</source>
          <target state="translated">.multiply_()</target>
        </trans-unit>
        <trans-unit id="efdb7a866c115b10355ce2d6dc45fab8ec9cefb7" translate="yes" xml:space="preserve">
          <source>.mvlgamma()</source>
          <target state="translated">.mvlgamma()</target>
        </trans-unit>
        <trans-unit id="b8af49e4c90f3af6d89a5d9cfd89ef3416b2252c" translate="yes" xml:space="preserve">
          <source>.mvlgamma_()</source>
          <target state="translated">.mvlgamma_()</target>
        </trans-unit>
        <trans-unit id="6dcbdad52c38aab725f99e6542bcf7e68d25a5b6" translate="yes" xml:space="preserve">
          <source>.nanquantile()</source>
          <target state="translated">.nanquantile()</target>
        </trans-unit>
        <trans-unit id="8d355e8231d619c825beb12c95f54e7996ed2939" translate="yes" xml:space="preserve">
          <source>.nansum()</source>
          <target state="translated">.nansum()</target>
        </trans-unit>
        <trans-unit id="ced27941ecd5aa0a5559e3f5d30bbdfadd073feb" translate="yes" xml:space="preserve">
          <source>.narrow()</source>
          <target state="translated">.narrow()</target>
        </trans-unit>
        <trans-unit id="ebbf7376ec2552b91a3d37943152b2eed6af04cd" translate="yes" xml:space="preserve">
          <source>.narrow_copy()</source>
          <target state="translated">.narrow_copy()</target>
        </trans-unit>
        <trans-unit id="16f06e1127043da5e10a863088e5ff54c1de811a" translate="yes" xml:space="preserve">
          <source>.ndimension()</source>
          <target state="translated">.ndimension()</target>
        </trans-unit>
        <trans-unit id="0adc72018e4f9b602d0d3c1ca4c4d178445b4fd0" translate="yes" xml:space="preserve">
          <source>.ne_()</source>
          <target state="translated">.ne_()</target>
        </trans-unit>
        <trans-unit id="405e620af87384790a975293156eedba27f1b06d" translate="yes" xml:space="preserve">
          <source>.neg()</source>
          <target state="translated">.neg()</target>
        </trans-unit>
        <trans-unit id="1a6eaac585bb82d0a4714a815b94ac5146530a88" translate="yes" xml:space="preserve">
          <source>.neg_()</source>
          <target state="translated">.neg_()</target>
        </trans-unit>
        <trans-unit id="420ff81f6313ce0841505282db9242ba8e43e635" translate="yes" xml:space="preserve">
          <source>.negative()</source>
          <target state="translated">.negative()</target>
        </trans-unit>
        <trans-unit id="3ea3e049d2a7ebb6f6fe105c6bb3729f851ae655" translate="yes" xml:space="preserve">
          <source>.negative_()</source>
          <target state="translated">.negative_()</target>
        </trans-unit>
        <trans-unit id="58505742b48c770397dd201ba4a7a39c9dbaf16a" translate="yes" xml:space="preserve">
          <source>.nelement()</source>
          <target state="translated">.nelement()</target>
        </trans-unit>
        <trans-unit id="c42947054ce721ee3ad1e19b37261c38dace7b4e" translate="yes" xml:space="preserve">
          <source>.new_empty()</source>
          <target state="translated">.new_empty()</target>
        </trans-unit>
        <trans-unit id="9fd266ccaf81cc0770958bc6c8d9ec0ac2ff4b77" translate="yes" xml:space="preserve">
          <source>.new_full()</source>
          <target state="translated">.new_full()</target>
        </trans-unit>
        <trans-unit id="d3f50ed773f92dd404b0058d3d11e6e22cf8811f" translate="yes" xml:space="preserve">
          <source>.new_group()</source>
          <target state="translated">.new_group()</target>
        </trans-unit>
        <trans-unit id="cff3f6828d438e2dbed5e12d2611703791d1d17d" translate="yes" xml:space="preserve">
          <source>.new_ones()</source>
          <target state="translated">.new_ones()</target>
        </trans-unit>
        <trans-unit id="720136da1af9f06a0ba211db6fe21b85d0dec7ad" translate="yes" xml:space="preserve">
          <source>.new_tensor()</source>
          <target state="translated">.new_tensor()</target>
        </trans-unit>
        <trans-unit id="ae849fd1413b3729ecb0f93672840cba1741dc1d" translate="yes" xml:space="preserve">
          <source>.new_zeros()</source>
          <target state="translated">.new_zeros()</target>
        </trans-unit>
        <trans-unit id="b6a61ccfe3f770569870ac6080eacf6ebe6ce16e" translate="yes" xml:space="preserve">
          <source>.nextafter()</source>
          <target state="translated">.nextafter()</target>
        </trans-unit>
        <trans-unit id="7a527d7e5fd055605ad5c425ef494f8973ea140a" translate="yes" xml:space="preserve">
          <source>.nextafter_()</source>
          <target state="translated">.nextafter_()</target>
        </trans-unit>
        <trans-unit id="17a29d92bf647d5c115bd5505b4ef86add1045e3" translate="yes" xml:space="preserve">
          <source>.nll_loss()</source>
          <target state="translated">.nll_loss()</target>
        </trans-unit>
        <trans-unit id="35d33db48b1e82f9f688756132ca3aacf156cb4a" translate="yes" xml:space="preserve">
          <source>.no_grad</source>
          <target state="translated">.no_grad</target>
        </trans-unit>
        <trans-unit id="ab3d23da008e39957d73c6dc4156b0ca62e1748a" translate="yes" xml:space="preserve">
          <source>.nonzero()</source>
          <target state="translated">.nonzero()</target>
        </trans-unit>
        <trans-unit id="153c560c8aaa02001d37ba63ad9a676234bf48e8" translate="yes" xml:space="preserve">
          <source>.norm()</source>
          <target state="translated">.norm()</target>
        </trans-unit>
        <trans-unit id="63fcd742eab40e0ec8ed5bd3014978a2797680eb" translate="yes" xml:space="preserve">
          <source>.normal()</source>
          <target state="translated">.normal()</target>
        </trans-unit>
        <trans-unit id="002c9456e75c0e24bb4a1661cd21b705f7fcdf5a" translate="yes" xml:space="preserve">
          <source>.normal_()</source>
          <target state="translated">.normal_()</target>
        </trans-unit>
        <trans-unit id="079230870d6aecfe576acb6c78f12e8b26ad2755" translate="yes" xml:space="preserve">
          <source>.normalize()</source>
          <target state="translated">.normalize()</target>
        </trans-unit>
        <trans-unit id="07a4911cd7c1e9e04b7d9373c52825922d3d8c79" translate="yes" xml:space="preserve">
          <source>.not_equal()</source>
          <target state="translated">.not_equal()</target>
        </trans-unit>
        <trans-unit id="bd8b36be02d94f128512b6739e2994e1ee4aa865" translate="yes" xml:space="preserve">
          <source>.not_equal_()</source>
          <target state="translated">.not_equal_()</target>
        </trans-unit>
        <trans-unit id="4ef1f9fb5060123254c4778642f7990043a89261" translate="yes" xml:space="preserve">
          <source>.numel()</source>
          <target state="translated">.numel()</target>
        </trans-unit>
        <trans-unit id="86d45b231bd3dac1a8ef8c9758bb63e6aa54f8d0" translate="yes" xml:space="preserve">
          <source>.numpy()</source>
          <target state="translated">.numpy()</target>
        </trans-unit>
        <trans-unit id="5a2d568adc7b0e179dd840a89dc4cfa4dabdb5d6" translate="yes" xml:space="preserve">
          <source>.one_hot()</source>
          <target state="translated">.one_hot()</target>
        </trans-unit>
        <trans-unit id="e6a0deec49c92e334455188e6732dc9775a87943" translate="yes" xml:space="preserve">
          <source>.ones()</source>
          <target state="translated">.ones()</target>
        </trans-unit>
        <trans-unit id="ca3fa8e68a475de1aca4fb1aef8419a52d56c91d" translate="yes" xml:space="preserve">
          <source>.ones_()</source>
          <target state="translated">.ones_()</target>
        </trans-unit>
        <trans-unit id="31265dd6aa6ec9eef86a34ea54c27d4be6f7d1b6" translate="yes" xml:space="preserve">
          <source>.ones_like()</source>
          <target state="translated">.ones_like()</target>
        </trans-unit>
        <trans-unit id="aa628ab6f235b18da491b868808ef007acbc1f22" translate="yes" xml:space="preserve">
          <source>.openmp.is_available()</source>
          <target state="translated">.openmp.is_available()</target>
        </trans-unit>
        <trans-unit id="6f93ce880d00063624383fb4c6e8c4a2ad29434b" translate="yes" xml:space="preserve">
          <source>.operators.shape_as_tensor()</source>
          <target state="translated">.operators.shape_as_tensor()</target>
        </trans-unit>
        <trans-unit id="4401dd6e7dc3cb218b26a2ab17620fb3646c3217" translate="yes" xml:space="preserve">
          <source>.optimize_for_mobile()</source>
          <target state="translated">.optimize_for_mobile()</target>
        </trans-unit>
        <trans-unit id="ab23460329e238d03512cafff0fd5747797f9951" translate="yes" xml:space="preserve">
          <source>.orgqr()</source>
          <target state="translated">.orgqr()</target>
        </trans-unit>
        <trans-unit id="3eda8363d660ed02c8753f4363ae730df5e5d0a0" translate="yes" xml:space="preserve">
          <source>.ormqr()</source>
          <target state="translated">.ormqr()</target>
        </trans-unit>
        <trans-unit id="bdee1df289865e28336c9e4a62f565c9105423a4" translate="yes" xml:space="preserve">
          <source>.orthogonal_()</source>
          <target state="translated">.orthogonal_()</target>
        </trans-unit>
        <trans-unit id="f16ae520cfba40e2324a212c272aa538e1584243" translate="yes" xml:space="preserve">
          <source>.outer()</source>
          <target state="translated">.outer()</target>
        </trans-unit>
        <trans-unit id="3778242dea279c042535a64749e6969e51972903" translate="yes" xml:space="preserve">
          <source>.pad()</source>
          <target state="translated">.pad()</target>
        </trans-unit>
        <trans-unit id="304a28ec1dc68af8aaf06ba91f28431c71c465fe" translate="yes" xml:space="preserve">
          <source>.pairwise_distance()</source>
          <target state="translated">.pairwise_distance()</target>
        </trans-unit>
        <trans-unit id="2f144beb9ba006d113635f279d40746b612efc46" translate="yes" xml:space="preserve">
          <source>.parallel.DistributedDataParallel</source>
          <target state="translated">.parallel.DistributedDataParallel</target>
        </trans-unit>
        <trans-unit id="18c87f5ace6b245e17879c380199597cfa7ad426" translate="yes" xml:space="preserve">
          <source>.parallel.DistributedDataParallel.join()</source>
          <target state="translated">.parallel.DistributedDataParallel.join()</target>
        </trans-unit>
        <trans-unit id="5013c5937421b0ba0a036bc901b2bcd778322aa8" translate="yes" xml:space="preserve">
          <source>.parallel.DistributedDataParallel.no_sync()</source>
          <target state="translated">.parallel.DistributedDataParallel.no_sync()</target>
        </trans-unit>
        <trans-unit id="4893ff04a49d911f0e61b112b142a8d43b4f7bd0" translate="yes" xml:space="preserve">
          <source>.parameter.Parameter</source>
          <target state="translated">.parameter.Parameter</target>
        </trans-unit>
        <trans-unit id="048d5a43a5c9d68d087463818c3b6b308eb54e39" translate="yes" xml:space="preserve">
          <source>.pca_lowrank()</source>
          <target state="translated">.pca_lowrank()</target>
        </trans-unit>
        <trans-unit id="713c100357a9a5a755016c76ffd018a72ebb4372" translate="yes" xml:space="preserve">
          <source>.pdist()</source>
          <target state="translated">.pdist()</target>
        </trans-unit>
        <trans-unit id="e3730585998bbc8e75886b3260af2820c75cbd92" translate="yes" xml:space="preserve">
          <source>.permute()</source>
          <target state="translated">.permute()</target>
        </trans-unit>
        <trans-unit id="6bbecb0f7df5154c2612becf059c1c7632f531dd" translate="yes" xml:space="preserve">
          <source>.pin_memory()</source>
          <target state="translated">.pin_memory()</target>
        </trans-unit>
        <trans-unit id="f0bda7e71cab2a1e1e872aab4d506ffdd76d149d" translate="yes" xml:space="preserve">
          <source>.pinverse()</source>
          <target state="translated">.pinverse()</target>
        </trans-unit>
        <trans-unit id="74302b4b40050cfb26e24afc83381fe733795b2a" translate="yes" xml:space="preserve">
          <source>.pixel_shuffle()</source>
          <target state="translated">.pixel_shuffle()</target>
        </trans-unit>
        <trans-unit id="55548277f7f20cfea142466127ce76ad5b48fd60" translate="yes" xml:space="preserve">
          <source>.poisson()</source>
          <target state="translated">.poisson()</target>
        </trans-unit>
        <trans-unit id="f33418bf1a71e1b0e7f470f1309e7e5d7d4a441b" translate="yes" xml:space="preserve">
          <source>.poisson_nll_loss()</source>
          <target state="translated">.poisson_nll_loss()</target>
        </trans-unit>
        <trans-unit id="f3edd91e9e7f57c1dce2ab5a65087c0596c88c99" translate="yes" xml:space="preserve">
          <source>.polar()</source>
          <target state="translated">.polar()</target>
        </trans-unit>
        <trans-unit id="505b93f0d970049dc5541a129ae4d40359213bce" translate="yes" xml:space="preserve">
          <source>.polygamma()</source>
          <target state="translated">.polygamma()</target>
        </trans-unit>
        <trans-unit id="9008fbda2314a421026383cd45f6c40d3cacb3c1" translate="yes" xml:space="preserve">
          <source>.polygamma_()</source>
          <target state="translated">.polygamma_()</target>
        </trans-unit>
        <trans-unit id="9c24b35a0041727641a5eb203fdea8324561f74f" translate="yes" xml:space="preserve">
          <source>.pow()</source>
          <target state="translated">.pow()</target>
        </trans-unit>
        <trans-unit id="7700e06004da87d5727b26d62f3ebcf526495761" translate="yes" xml:space="preserve">
          <source>.pow_()</source>
          <target state="translated">.pow_()</target>
        </trans-unit>
        <trans-unit id="537b8729eb3927c053076444b0299682ef7a32a9" translate="yes" xml:space="preserve">
          <source>.prelu()</source>
          <target state="translated">.prelu()</target>
        </trans-unit>
        <trans-unit id="7b8761d9c3abd8d18e7add1efe8c75a7e07f65a4" translate="yes" xml:space="preserve">
          <source>.prod()</source>
          <target state="translated">.prod()</target>
        </trans-unit>
        <trans-unit id="830ffd5c9a6a1172a3645d522ec7a952ee851763" translate="yes" xml:space="preserve">
          <source>.promote_types()</source>
          <target state="translated">.promote_types()</target>
        </trans-unit>
        <trans-unit id="8d732bd72c95efb56c5a3f83bce97d706037e203" translate="yes" xml:space="preserve">
          <source>.put_()</source>
          <target state="translated">.put_()</target>
        </trans-unit>
        <trans-unit id="e5c864eac444c2d59163ac40cd877cf78a8b5a84" translate="yes" xml:space="preserve">
          <source>.q_per_channel_axis()</source>
          <target state="translated">.q_per_channel_axis()</target>
        </trans-unit>
        <trans-unit id="dde25a4d91e219f8db3e791aed4f7503b3792b19" translate="yes" xml:space="preserve">
          <source>.q_per_channel_scales()</source>
          <target state="translated">.q_per_channel_scales()</target>
        </trans-unit>
        <trans-unit id="b3a4fde0a2531b119338cf28194c2bcc2cbfad72" translate="yes" xml:space="preserve">
          <source>.q_per_channel_zero_points()</source>
          <target state="translated">.q_per_channel_zero_points()</target>
        </trans-unit>
        <trans-unit id="ae9ff1c6f94c8792b73d842e50080dcc077dc530" translate="yes" xml:space="preserve">
          <source>.q_scale()</source>
          <target state="translated">.q_scale()</target>
        </trans-unit>
        <trans-unit id="003468f74077a9679625c10f4b99043f3490827d" translate="yes" xml:space="preserve">
          <source>.q_zero_point()</source>
          <target state="translated">.q_zero_point()</target>
        </trans-unit>
        <trans-unit id="a662cb176cb42f8d33faa1b2081529b674f3f2ba" translate="yes" xml:space="preserve">
          <source>.qscheme()</source>
          <target state="translated">.qscheme()</target>
        </trans-unit>
        <trans-unit id="c1feb94d9066ab4aa2b0ff98f298370edebd0fae" translate="yes" xml:space="preserve">
          <source>.quantile()</source>
          <target state="translated">.quantile()</target>
        </trans-unit>
        <trans-unit id="713892ac044eddfd24ee4b9276d8161fd6177825" translate="yes" xml:space="preserve">
          <source>.quantize_per_channel()</source>
          <target state="translated">.quantize_per_channel()</target>
        </trans-unit>
        <trans-unit id="310b4f36f7ba8f7a004d888d7de956bd6fc69be3" translate="yes" xml:space="preserve">
          <source>.quantize_per_tensor()</source>
          <target state="translated">.quantize_per_tensor()</target>
        </trans-unit>
        <trans-unit id="7205b6fe4998a52995f8ab3ed21b82f8f1d23026" translate="yes" xml:space="preserve">
          <source>.quasirandom.SobolEngine</source>
          <target state="translated">.quasirandom.SobolEngine</target>
        </trans-unit>
        <trans-unit id="4257baf4e045b753653194cd3d1469dc6663f066" translate="yes" xml:space="preserve">
          <source>.quasirandom.SobolEngine.draw()</source>
          <target state="translated">.quasirandom.SobolEngine.draw()</target>
        </trans-unit>
        <trans-unit id="3b272232546f04f36c425d4891f8a26a8c1fcae3" translate="yes" xml:space="preserve">
          <source>.quasirandom.SobolEngine.fast_forward()</source>
          <target state="translated">.quasirandom.SobolEngine.fast_forward()</target>
        </trans-unit>
        <trans-unit id="4c696d2c62ffbf4255110eeb05e251e4db1c9802" translate="yes" xml:space="preserve">
          <source>.quasirandom.SobolEngine.reset()</source>
          <target state="translated">.quasirandom.SobolEngine.reset()</target>
        </trans-unit>
        <trans-unit id="c109491ba5d4a3816a02405f3c4a7df89cd012d5" translate="yes" xml:space="preserve">
          <source>.rad2deg()</source>
          <target state="translated">.rad2deg()</target>
        </trans-unit>
        <trans-unit id="f4738eac5218eb110f1f77c0c0cc7eed7c6f6482" translate="yes" xml:space="preserve">
          <source>.rand()</source>
          <target state="translated">.rand()</target>
        </trans-unit>
        <trans-unit id="256e9aad6e1bef311bf9fa7d0b3fef17d0ad2e77" translate="yes" xml:space="preserve">
          <source>.rand_like()</source>
          <target state="translated">.rand_like()</target>
        </trans-unit>
        <trans-unit id="dba37e3526f1502ba3f7f7bd69e802ef93b9c356" translate="yes" xml:space="preserve">
          <source>.randint()</source>
          <target state="translated">.randint()</target>
        </trans-unit>
        <trans-unit id="a121b47b5e7038aba60fe4002bbe0f31e5c198b1" translate="yes" xml:space="preserve">
          <source>.randint_like()</source>
          <target state="translated">.randint_like()</target>
        </trans-unit>
        <trans-unit id="d89922498b925555f4a31d0207da3b99356199e3" translate="yes" xml:space="preserve">
          <source>.randn()</source>
          <target state="translated">.randn()</target>
        </trans-unit>
        <trans-unit id="3545f75edb8e6f7f4507df60a07256290eae7790" translate="yes" xml:space="preserve">
          <source>.randn_like()</source>
          <target state="translated">.randn_like()</target>
        </trans-unit>
        <trans-unit id="feeeef12069cc2e2bd68b6cd681da4924d91e6dc" translate="yes" xml:space="preserve">
          <source>.random_()</source>
          <target state="translated">.random_()</target>
        </trans-unit>
        <trans-unit id="469ae0deab6a4fddccf192f5653e6fc7c408de28" translate="yes" xml:space="preserve">
          <source>.randperm()</source>
          <target state="translated">.randperm()</target>
        </trans-unit>
        <trans-unit id="ec224322a02df2abf99caf35364fcc497ed9b1aa" translate="yes" xml:space="preserve">
          <source>.range()</source>
          <target state="translated">.range()</target>
        </trans-unit>
        <trans-unit id="e4bdd417e313747a4ef9663cbee1af3de56c1585" translate="yes" xml:space="preserve">
          <source>.real()</source>
          <target state="translated">.real()</target>
        </trans-unit>
        <trans-unit id="ff725bd7568176108cc316afa46424c431d0b177" translate="yes" xml:space="preserve">
          <source>.reciprocal()</source>
          <target state="translated">.reciprocal()</target>
        </trans-unit>
        <trans-unit id="2d8374225707e2ed1b20ae40905e8e3c026584c4" translate="yes" xml:space="preserve">
          <source>.reciprocal_()</source>
          <target state="translated">.reciprocal_()</target>
        </trans-unit>
        <trans-unit id="13739ad1ddd1496ddd5a390ab8e1173193c8edc0" translate="yes" xml:space="preserve">
          <source>.record_stream()</source>
          <target state="translated">.record_stream()</target>
        </trans-unit>
        <trans-unit id="30fc021e4665211f5034884dab26a7e4a8721c62" translate="yes" xml:space="preserve">
          <source>.recv()</source>
          <target state="translated">.recv()</target>
        </trans-unit>
        <trans-unit id="d0f4b4460b8db067171b431083b80dc1bb7de9b4" translate="yes" xml:space="preserve">
          <source>.reduce()</source>
          <target state="translated">.reduce()</target>
        </trans-unit>
        <trans-unit id="8e1ae55339fe7baed495d278fc7208dee4d0ee10" translate="yes" xml:space="preserve">
          <source>.reduce_multigpu()</source>
          <target state="translated">.reduce_multigpu()</target>
        </trans-unit>
        <trans-unit id="2e35550a3d698b65ae414c34691dc4ed9bad3607" translate="yes" xml:space="preserve">
          <source>.reduce_op</source>
          <target state="translated">.reduce_op</target>
        </trans-unit>
        <trans-unit id="c8d3bb18ed8060e20e4089dada88a2fc9abaf4ea" translate="yes" xml:space="preserve">
          <source>.reduce_scatter()</source>
          <target state="translated">.reduce_scatter()</target>
        </trans-unit>
        <trans-unit id="b676f649de7adf0571f62ecef4ec6eb95f3a2ac0" translate="yes" xml:space="preserve">
          <source>.reduce_scatter_multigpu()</source>
          <target state="translated">.reduce_scatter_multigpu()</target>
        </trans-unit>
        <trans-unit id="260f9c6757bf0e2f3ac704f9d9c18d3380ca7a28" translate="yes" xml:space="preserve">
          <source>.register_custom_op_symbolic()</source>
          <target state="translated">.register_custom_op_symbolic()</target>
        </trans-unit>
        <trans-unit id="a461ae597eff3cd3cb4e7c30c4d8e1d8798d37ce" translate="yes" xml:space="preserve">
          <source>.relu()</source>
          <target state="translated">.relu()</target>
        </trans-unit>
        <trans-unit id="0e10a705998253513a3e9be6bd4037de81091d7a" translate="yes" xml:space="preserve">
          <source>.relu6()</source>
          <target state="translated">.relu6()</target>
        </trans-unit>
        <trans-unit id="b28d5fc2a05f978f9430847696c2ad4e94393288" translate="yes" xml:space="preserve">
          <source>.relu_()</source>
          <target state="translated">.relu_()</target>
        </trans-unit>
        <trans-unit id="48cbb4616c25681840d43e8a2690c66e87b55f3c" translate="yes" xml:space="preserve">
          <source>.remainder()</source>
          <target state="translated">.remainder()</target>
        </trans-unit>
        <trans-unit id="95c1b067c5c6da416465b9829b1ee97d8522f37c" translate="yes" xml:space="preserve">
          <source>.remainder_()</source>
          <target state="translated">.remainder_()</target>
        </trans-unit>
        <trans-unit id="7c4492807c71eea0d7b596b1308f8d47b2b45fb8" translate="yes" xml:space="preserve">
          <source>.renorm()</source>
          <target state="translated">.renorm()</target>
        </trans-unit>
        <trans-unit id="39ad51f95748712af0b4236f512975843da35256" translate="yes" xml:space="preserve">
          <source>.renorm_()</source>
          <target state="translated">.renorm_()</target>
        </trans-unit>
        <trans-unit id="39a498aa1d62619ed3613e27febe29ff0d2c083f" translate="yes" xml:space="preserve">
          <source>.repeat()</source>
          <target state="translated">.repeat()</target>
        </trans-unit>
        <trans-unit id="779491dd9a987cfe7c66bec80c103ab9a2fa0e9e" translate="yes" xml:space="preserve">
          <source>.repeat_interleave()</source>
          <target state="translated">.repeat_interleave()</target>
        </trans-unit>
        <trans-unit id="4b63bb5a2f9ac432fa3fa5e76bcc816aa61735c4" translate="yes" xml:space="preserve">
          <source>.requires_grad_()</source>
          <target state="translated">.requires_grad_()</target>
        </trans-unit>
        <trans-unit id="ea268674e5ef68fe7e005576fcab96760aa08b2a" translate="yes" xml:space="preserve">
          <source>.reshape()</source>
          <target state="translated">.reshape()</target>
        </trans-unit>
        <trans-unit id="4815f0ee3057bf5532d8a61f8fdc3b4134bdeff2" translate="yes" xml:space="preserve">
          <source>.reshape_as()</source>
          <target state="translated">.reshape_as()</target>
        </trans-unit>
        <trans-unit id="1d5c2a4027c25c593dd2d25446a1331bc7b9e144" translate="yes" xml:space="preserve">
          <source>.resize_()</source>
          <target state="translated">.resize_()</target>
        </trans-unit>
        <trans-unit id="61785c46dcb73cecf6a24c9374a662fbea2b501d" translate="yes" xml:space="preserve">
          <source>.resize_as_()</source>
          <target state="translated">.resize_as_()</target>
        </trans-unit>
        <trans-unit id="db770385f62fe507c07a5fcac29c845171607d0e" translate="yes" xml:space="preserve">
          <source>.resnet101()</source>
          <target state="translated">.resnet101()</target>
        </trans-unit>
        <trans-unit id="d0234156ce2f14cffe6ca0312da2a1151146300d" translate="yes" xml:space="preserve">
          <source>.resnet152()</source>
          <target state="translated">.resnet152()</target>
        </trans-unit>
        <trans-unit id="75393dfa359f4eb086b75af3951514b3ef9392f0" translate="yes" xml:space="preserve">
          <source>.resnet18()</source>
          <target state="translated">.resnet18()</target>
        </trans-unit>
        <trans-unit id="5e4f88a030eebb7f3d20ad3f98ef29ed2f0d1f88" translate="yes" xml:space="preserve">
          <source>.resnet34()</source>
          <target state="translated">.resnet34()</target>
        </trans-unit>
        <trans-unit id="07b55eb9a696136cea9e8b6d896a9299244e1a38" translate="yes" xml:space="preserve">
          <source>.resnet50()</source>
          <target state="translated">.resnet50()</target>
        </trans-unit>
        <trans-unit id="0410890d9c42598a3d1266c3a4abdb12b30365bb" translate="yes" xml:space="preserve">
          <source>.resnext101_32x8d()</source>
          <target state="translated">.resnext101_32x8d()</target>
        </trans-unit>
        <trans-unit id="81bd4512dccaeae65a94ac3d87696fefbc650839" translate="yes" xml:space="preserve">
          <source>.resnext50_32x4d()</source>
          <target state="translated">.resnext50_32x4d()</target>
        </trans-unit>
        <trans-unit id="f5db8ba7047c17aca100f0df5f51cc78fa989beb" translate="yes" xml:space="preserve">
          <source>.result_type()</source>
          <target state="translated">.result_type()</target>
        </trans-unit>
        <trans-unit id="d9857c795c3ce28b1f2286c64f23294c95ad8249" translate="yes" xml:space="preserve">
          <source>.rfft()</source>
          <target state="translated">.rfft()</target>
        </trans-unit>
        <trans-unit id="fc539189f1b36df30307c2cafaacfab4352d121c" translate="yes" xml:space="preserve">
          <source>.rfftn()</source>
          <target state="translated">.rfftn()</target>
        </trans-unit>
        <trans-unit id="85fb9e63907bed3723016ffbd14f5a7b193e0f70" translate="yes" xml:space="preserve">
          <source>.roll()</source>
          <target state="translated">.roll()</target>
        </trans-unit>
        <trans-unit id="98a3c8287b049743283a869226452451ba0f800c" translate="yes" xml:space="preserve">
          <source>.rot90()</source>
          <target state="translated">.rot90()</target>
        </trans-unit>
        <trans-unit id="a0f37b794f988a1a203150e554d6ebfb10d67c9d" translate="yes" xml:space="preserve">
          <source>.round()</source>
          <target state="translated">.round()</target>
        </trans-unit>
        <trans-unit id="40ce45f0c9896853e6301239dad8b40a9d910418" translate="yes" xml:space="preserve">
          <source>.round_()</source>
          <target state="translated">.round_()</target>
        </trans-unit>
        <trans-unit id="da736f2a9feaa9d63df44443b151005893064953" translate="yes" xml:space="preserve">
          <source>.rrelu()</source>
          <target state="translated">.rrelu()</target>
        </trans-unit>
        <trans-unit id="be6c317fa56f4724bfc2eeb75440520bfe2175f1" translate="yes" xml:space="preserve">
          <source>.rrelu_()</source>
          <target state="translated">.rrelu_()</target>
        </trans-unit>
        <trans-unit id="044564f1abbef1db33a6993c39190fcfa7862691" translate="yes" xml:space="preserve">
          <source>.rsqrt()</source>
          <target state="translated">.rsqrt()</target>
        </trans-unit>
        <trans-unit id="a1d4c68a2088fd074ac9ff2550ccabbffc39ffb8" translate="yes" xml:space="preserve">
          <source>.rsqrt_()</source>
          <target state="translated">.rsqrt_()</target>
        </trans-unit>
        <trans-unit id="8813cefdfb8ee3c21106b18a0d860871c098f69a" translate="yes" xml:space="preserve">
          <source>.save()</source>
          <target state="translated">.save()</target>
        </trans-unit>
        <trans-unit id="62b8bb0762dd041a4d8dd40bc69fb4d807d83f88" translate="yes" xml:space="preserve">
          <source>.scatter()</source>
          <target state="translated">.scatter()</target>
        </trans-unit>
        <trans-unit id="ff0937ffc23347d1a9b63942462894ff702c095a" translate="yes" xml:space="preserve">
          <source>.scatter_()</source>
          <target state="translated">.scatter_()</target>
        </trans-unit>
        <trans-unit id="21041fac69fe46a787d9e65c2c54dd444f502f19" translate="yes" xml:space="preserve">
          <source>.scatter_add()</source>
          <target state="translated">.scatter_add()</target>
        </trans-unit>
        <trans-unit id="736497159631a664cd967939f4a0573c1c1a6980" translate="yes" xml:space="preserve">
          <source>.scatter_add_()</source>
          <target state="translated">.scatter_add_()</target>
        </trans-unit>
        <trans-unit id="ded87a05366a34e9cb2c940bb8cae3550f61d41d" translate="yes" xml:space="preserve">
          <source>.searchsorted()</source>
          <target state="translated">.searchsorted()</target>
        </trans-unit>
        <trans-unit id="01223ae8003f0e203cdb0de81bcbbdc7da659187" translate="yes" xml:space="preserve">
          <source>.seed()</source>
          <target state="translated">.seed()</target>
        </trans-unit>
        <trans-unit id="39f0c563915af575961bd794f619c1f2ffd893f9" translate="yes" xml:space="preserve">
          <source>.segmentation.deeplabv3_resnet101()</source>
          <target state="translated">.segmentation.deeplabv3_resnet101()</target>
        </trans-unit>
        <trans-unit id="57262cd602cf92638364627fa9368b5aaae852db" translate="yes" xml:space="preserve">
          <source>.segmentation.deeplabv3_resnet50()</source>
          <target state="translated">.segmentation.deeplabv3_resnet50()</target>
        </trans-unit>
        <trans-unit id="ca158ee6e63b5127b53cec7600f02e04d48b1471" translate="yes" xml:space="preserve">
          <source>.segmentation.fcn_resnet101()</source>
          <target state="translated">.segmentation.fcn_resnet101()</target>
        </trans-unit>
        <trans-unit id="23441f1ad563d558cf097114d3daea421c3120d5" translate="yes" xml:space="preserve">
          <source>.segmentation.fcn_resnet50()</source>
          <target state="translated">.segmentation.fcn_resnet50()</target>
        </trans-unit>
        <trans-unit id="de1a745e154b52757243ad903567dc7e79a15b6c" translate="yes" xml:space="preserve">
          <source>.select()</source>
          <target state="translated">.select()</target>
        </trans-unit>
        <trans-unit id="88afb87d815a369533180e09edbea89c048aa5d5" translate="yes" xml:space="preserve">
          <source>.select_model_mode_for_export()</source>
          <target state="translated">.select_model_mode_for_export()</target>
        </trans-unit>
        <trans-unit id="438dea373f8cf5d0f3b2566c248d24d2744ab4ad" translate="yes" xml:space="preserve">
          <source>.selu()</source>
          <target state="translated">.selu()</target>
        </trans-unit>
        <trans-unit id="3f1df0644f32586fe1e99b5aa5992b2169c9c2f8" translate="yes" xml:space="preserve">
          <source>.send()</source>
          <target state="translated">.send()</target>
        </trans-unit>
        <trans-unit id="bcb2a6a502a4615e4924e5d4f52e28b77206ec66" translate="yes" xml:space="preserve">
          <source>.set_()</source>
          <target state="translated">.set_()</target>
        </trans-unit>
        <trans-unit id="7ec9abe3471b5cd47f8f0bba0e3b9a34d4e729cf" translate="yes" xml:space="preserve">
          <source>.set_default_dtype()</source>
          <target state="translated">.set_default_dtype()</target>
        </trans-unit>
        <trans-unit id="fe5ac0ae470ec952c218935213c15271d6af3966" translate="yes" xml:space="preserve">
          <source>.set_default_tensor_type()</source>
          <target state="translated">.set_default_tensor_type()</target>
        </trans-unit>
        <trans-unit id="5373fec047d2ec63b70111c76ec142d588fd2534" translate="yes" xml:space="preserve">
          <source>.set_deterministic()</source>
          <target state="translated">.set_deterministic()</target>
        </trans-unit>
        <trans-unit id="03505130b756d153d241d1db047570b284b03e00" translate="yes" xml:space="preserve">
          <source>.set_dir()</source>
          <target state="translated">.set_dir()</target>
        </trans-unit>
        <trans-unit id="c47387e20d16181b0ba18415a96fa0b109157e7f" translate="yes" xml:space="preserve">
          <source>.set_flush_denormal()</source>
          <target state="translated">.set_flush_denormal()</target>
        </trans-unit>
        <trans-unit id="b09f0aed3f52bd18d1fb1507c499ff8a0713540e" translate="yes" xml:space="preserve">
          <source>.set_grad_enabled</source>
          <target state="translated">.set_grad_enabled</target>
        </trans-unit>
        <trans-unit id="165ad19ebf178295164f8cae99be3d826be57a9e" translate="yes" xml:space="preserve">
          <source>.set_num_interop_threads()</source>
          <target state="translated">.set_num_interop_threads()</target>
        </trans-unit>
        <trans-unit id="f00acdb084d801367ab3deff484c6fca90622db4" translate="yes" xml:space="preserve">
          <source>.set_num_threads()</source>
          <target state="translated">.set_num_threads()</target>
        </trans-unit>
        <trans-unit id="c91631a78fab223338d177bd41dd0196999b1bbb" translate="yes" xml:space="preserve">
          <source>.set_printoptions()</source>
          <target state="translated">.set_printoptions()</target>
        </trans-unit>
        <trans-unit id="a2fab4a8d9e5009a515668219aaeab76ada2557f" translate="yes" xml:space="preserve">
          <source>.set_rng_state()</source>
          <target state="translated">.set_rng_state()</target>
        </trans-unit>
        <trans-unit id="f375040fa980e0694f4a5147fa52fbbe38771b71" translate="yes" xml:space="preserve">
          <source>.sgn()</source>
          <target state="translated">.sgn()</target>
        </trans-unit>
        <trans-unit id="2b55916013bbc9b04d1e96010344b0e2ae567899" translate="yes" xml:space="preserve">
          <source>.sgn_()</source>
          <target state="translated">.sgn_()</target>
        </trans-unit>
        <trans-unit id="1b7aabf96857d52c3f32a01662633445d978e765" translate="yes" xml:space="preserve">
          <source>.share_memory_()</source>
          <target state="translated">.share_memory_()</target>
        </trans-unit>
        <trans-unit id="44147d2fb5124f87e29b8251c37a01cd4296a721" translate="yes" xml:space="preserve">
          <source>.short()</source>
          <target state="translated">.short()</target>
        </trans-unit>
        <trans-unit id="366f1377cf56973b90a68c60d8278781c4ad733d" translate="yes" xml:space="preserve">
          <source>.shufflenet_v2_x0_5()</source>
          <target state="translated">.shufflenet_v2_x0_5()</target>
        </trans-unit>
        <trans-unit id="753ebdd93368a76e5e4bf31606867dec70bfba8a" translate="yes" xml:space="preserve">
          <source>.shufflenet_v2_x1_0()</source>
          <target state="translated">.shufflenet_v2_x1_0()</target>
        </trans-unit>
        <trans-unit id="45142ca8cfbac4d1b1aa435098ca043c77e8e608" translate="yes" xml:space="preserve">
          <source>.shufflenet_v2_x1_5()</source>
          <target state="translated">.shufflenet_v2_x1_5()</target>
        </trans-unit>
        <trans-unit id="4ed8aa4da0458fa6cb2c6d9e968c8e9f43134b28" translate="yes" xml:space="preserve">
          <source>.shufflenet_v2_x2_0()</source>
          <target state="translated">.shufflenet_v2_x2_0()</target>
        </trans-unit>
        <trans-unit id="dd0d81f5cdfe4acaffe4019c2775c5e66f0dd0c5" translate="yes" xml:space="preserve">
          <source>.sigmoid()</source>
          <target state="translated">.sigmoid()</target>
        </trans-unit>
        <trans-unit id="7b9795dc95ebcd1ce29bda1fe0b8453f469d5696" translate="yes" xml:space="preserve">
          <source>.sigmoid_()</source>
          <target state="translated">.sigmoid_()</target>
        </trans-unit>
        <trans-unit id="90f2ba5ae71a455f915f41ad47348629a70744ca" translate="yes" xml:space="preserve">
          <source>.sign()</source>
          <target state="translated">.sign()</target>
        </trans-unit>
        <trans-unit id="e986a5a8ad69d4b98eb0a7c9d88a2a2aac649a34" translate="yes" xml:space="preserve">
          <source>.sign_()</source>
          <target state="translated">.sign_()</target>
        </trans-unit>
        <trans-unit id="c37f378042811db1e4cd3adfd28f351154f75b67" translate="yes" xml:space="preserve">
          <source>.signbit()</source>
          <target state="translated">.signbit()</target>
        </trans-unit>
        <trans-unit id="d9ef56ae8ab81afa1cc36d3542b0cf8ed56d1b68" translate="yes" xml:space="preserve">
          <source>.silu()</source>
          <target state="translated">.silu()</target>
        </trans-unit>
        <trans-unit id="875c058869ba972cb392729cdad2c0ee8aa41ea7" translate="yes" xml:space="preserve">
          <source>.sin()</source>
          <target state="translated">.sin()</target>
        </trans-unit>
        <trans-unit id="9e36136e15da00ef1a173aec4ce0639f4e182b17" translate="yes" xml:space="preserve">
          <source>.sin_()</source>
          <target state="translated">.sin_()</target>
        </trans-unit>
        <trans-unit id="538f978751c8cc4fc0ec9b6165995ca88e86eaf1" translate="yes" xml:space="preserve">
          <source>.sinh()</source>
          <target state="translated">.sinh()</target>
        </trans-unit>
        <trans-unit id="41d133259e3a9f5be18e8c4c34392beceed9bced" translate="yes" xml:space="preserve">
          <source>.sinh_()</source>
          <target state="translated">.sinh_()</target>
        </trans-unit>
        <trans-unit id="476df900fe6e01298d54955f7a3cf825555f0364" translate="yes" xml:space="preserve">
          <source>.size()</source>
          <target state="translated">.size()</target>
        </trans-unit>
        <trans-unit id="bf86368d7913dfd18c39c49a206c71d1e85a1163" translate="yes" xml:space="preserve">
          <source>.slogdet()</source>
          <target state="translated">.slogdet()</target>
        </trans-unit>
        <trans-unit id="558e2fae7e5d02aa8cd1cd0d8ee1c35369338df9" translate="yes" xml:space="preserve">
          <source>.smooth_l1_loss()</source>
          <target state="translated">.smooth_l1_loss()</target>
        </trans-unit>
        <trans-unit id="bc88d33da5665ba782aa5fce727a51561047c75b" translate="yes" xml:space="preserve">
          <source>.soft_margin_loss()</source>
          <target state="translated">.soft_margin_loss()</target>
        </trans-unit>
        <trans-unit id="5919237fa9192e93ac9dc8e14561b0aef46dcfc4" translate="yes" xml:space="preserve">
          <source>.softmax()</source>
          <target state="translated">.softmax()</target>
        </trans-unit>
        <trans-unit id="d9ff7b59f6e1fd2cc76a7541cace7e2618623b86" translate="yes" xml:space="preserve">
          <source>.softmin()</source>
          <target state="translated">.softmin()</target>
        </trans-unit>
        <trans-unit id="c3cc6625403229e25442666a9f05bdaaf0c25a03" translate="yes" xml:space="preserve">
          <source>.softplus()</source>
          <target state="translated">.softplus()</target>
        </trans-unit>
        <trans-unit id="2fed695b769f633b305c93001e3b71da7119186b" translate="yes" xml:space="preserve">
          <source>.softshrink()</source>
          <target state="translated">.softshrink()</target>
        </trans-unit>
        <trans-unit id="7626eaae9dea4923326578d8430429ae2137744f" translate="yes" xml:space="preserve">
          <source>.softsign()</source>
          <target state="translated">.softsign()</target>
        </trans-unit>
        <trans-unit id="c15d256e9c6872c2970f9ac525df3c47d0344645" translate="yes" xml:space="preserve">
          <source>.solve()</source>
          <target state="translated">.solve()</target>
        </trans-unit>
        <trans-unit id="04f10b62f5957c03f949a789e69c46e07c97e47b" translate="yes" xml:space="preserve">
          <source>.sort()</source>
          <target state="translated">.sort()</target>
        </trans-unit>
        <trans-unit id="f8df0797f2a9f188846ec67f8d93e09572ac595c" translate="yes" xml:space="preserve">
          <source>.sparse_()</source>
          <target state="translated">.sparse_()</target>
        </trans-unit>
        <trans-unit id="bb43ced301c062ed8821c74cd5ec85a371803970" translate="yes" xml:space="preserve">
          <source>.sparse_coo_tensor()</source>
          <target state="translated">.sparse_coo_tensor()</target>
        </trans-unit>
        <trans-unit id="045fb7896cb7b2f2a76d0fb97c2aa9feedacfdb1" translate="yes" xml:space="preserve">
          <source>.sparse_dim()</source>
          <target state="translated">.sparse_dim()</target>
        </trans-unit>
        <trans-unit id="11b81ec49cc41119c0023dbab947225fb7a6ab96" translate="yes" xml:space="preserve">
          <source>.sparse_mask()</source>
          <target state="translated">.sparse_mask()</target>
        </trans-unit>
        <trans-unit id="9232b1533fec08b8a90a088dbc7e292113bdbeac" translate="yes" xml:space="preserve">
          <source>.split()</source>
          <target state="translated">.split()</target>
        </trans-unit>
        <trans-unit id="42492b71f886f2787610573a31ebb493cbf7bab0" translate="yes" xml:space="preserve">
          <source>.sqrt()</source>
          <target state="translated">.sqrt()</target>
        </trans-unit>
        <trans-unit id="cd80831d4e37bd07226f0df4f7da11b8ace8dc67" translate="yes" xml:space="preserve">
          <source>.sqrt_()</source>
          <target state="translated">.sqrt_()</target>
        </trans-unit>
        <trans-unit id="d05a9f831d00403bd0f2a880fe7b2bceb5585ce5" translate="yes" xml:space="preserve">
          <source>.square()</source>
          <target state="translated">.square()</target>
        </trans-unit>
        <trans-unit id="0fd89af3d9b1026da1eb6fad05b81d95076e715d" translate="yes" xml:space="preserve">
          <source>.square_()</source>
          <target state="translated">.square_()</target>
        </trans-unit>
        <trans-unit id="0184163dc86b67573479ba51a1632bf59d761e7a" translate="yes" xml:space="preserve">
          <source>.squeeze()</source>
          <target state="translated">.squeeze()</target>
        </trans-unit>
        <trans-unit id="20175c664848d089e507013566c89be29331d219" translate="yes" xml:space="preserve">
          <source>.squeeze_()</source>
          <target state="translated">.squeeze_()</target>
        </trans-unit>
        <trans-unit id="97a026e723871763cb5e9ce9c5632a60038e05d9" translate="yes" xml:space="preserve">
          <source>.squeezenet1_0()</source>
          <target state="translated">.squeezenet1_0()</target>
        </trans-unit>
        <trans-unit id="d79e965d2a44f02a409225ddea4fe9cb9b4dd73f" translate="yes" xml:space="preserve">
          <source>.squeezenet1_1()</source>
          <target state="translated">.squeezenet1_1()</target>
        </trans-unit>
        <trans-unit id="9c2b76ff8cff72f3804f23a7a2a8ebda3e58e7cc" translate="yes" xml:space="preserve">
          <source>.stack()</source>
          <target state="translated">.stack()</target>
        </trans-unit>
        <trans-unit id="2e48ca05f7d89f069597793aa8f51ade229477b0" translate="yes" xml:space="preserve">
          <source>.std()</source>
          <target state="translated">.std()</target>
        </trans-unit>
        <trans-unit id="44d7a55ac0a00ead82e9cb01739a62ecf26d21a0" translate="yes" xml:space="preserve">
          <source>.std_mean()</source>
          <target state="translated">.std_mean()</target>
        </trans-unit>
        <trans-unit id="856eb70c575c404f9dc54591f4ef1737d4843557" translate="yes" xml:space="preserve">
          <source>.stft()</source>
          <target state="translated">.stft()</target>
        </trans-unit>
        <trans-unit id="c5aad634deacb2bfb136946a3472b89c4285f653" translate="yes" xml:space="preserve">
          <source>.storage()</source>
          <target state="translated">.storage()</target>
        </trans-unit>
        <trans-unit id="19ccb832c67ea892d3287320d7658004b22c0435" translate="yes" xml:space="preserve">
          <source>.storage_offset()</source>
          <target state="translated">.storage_offset()</target>
        </trans-unit>
        <trans-unit id="191ca6fbf533b95582c6ecd0c1c6d0466a0f6c5f" translate="yes" xml:space="preserve">
          <source>.storage_type()</source>
          <target state="translated">.storage_type()</target>
        </trans-unit>
        <trans-unit id="9d77d1a62dfc3e046a3367b8851c3b6b598b97ab" translate="yes" xml:space="preserve">
          <source>.stride()</source>
          <target state="translated">.stride()</target>
        </trans-unit>
        <trans-unit id="211e0f6761cd4bb7840199794efd5c9c9bf00403" translate="yes" xml:space="preserve">
          <source>.sub()</source>
          <target state="translated">.sub()</target>
        </trans-unit>
        <trans-unit id="3d8976b3696117049a31689a18509a6382f8c846" translate="yes" xml:space="preserve">
          <source>.sub_()</source>
          <target state="translated">.sub_()</target>
        </trans-unit>
        <trans-unit id="9c0ab8ec122a606521077c94c81cb4573153acc3" translate="yes" xml:space="preserve">
          <source>.subtract()</source>
          <target state="translated">.subtract()</target>
        </trans-unit>
        <trans-unit id="ed8cef7bdbae533e24a2c1f60bae8d9d2e1236d7" translate="yes" xml:space="preserve">
          <source>.subtract_()</source>
          <target state="translated">.subtract_()</target>
        </trans-unit>
        <trans-unit id="7d69e314f129bc6da2427bcac20d11fb0d178ba0" translate="yes" xml:space="preserve">
          <source>.sum()</source>
          <target state="translated">.sum()</target>
        </trans-unit>
        <trans-unit id="4eb0609c113811ec2733b26128ee66905a4aa31c" translate="yes" xml:space="preserve">
          <source>.sum_to_size()</source>
          <target state="translated">.sum_to_size()</target>
        </trans-unit>
        <trans-unit id="1eeef8e426b148bce9237ca29b19dc43af083de9" translate="yes" xml:space="preserve">
          <source>.svd()</source>
          <target state="translated">.svd()</target>
        </trans-unit>
        <trans-unit id="f50d90099aff24cfc0bb6efdfda3620c0fc9a8a0" translate="yes" xml:space="preserve">
          <source>.svd_lowrank()</source>
          <target state="translated">.svd_lowrank()</target>
        </trans-unit>
        <trans-unit id="da0b77c2b6d8262a79453fb1abe7fe06a7be6ca9" translate="yes" xml:space="preserve">
          <source>.symeig()</source>
          <target state="translated">.symeig()</target>
        </trans-unit>
        <trans-unit id="7faf3458b784d61691190c0c700940b7a94e6510" translate="yes" xml:space="preserve">
          <source>.take()</source>
          <target state="translated">.take()</target>
        </trans-unit>
        <trans-unit id="6d022c8e0f34b92a09b21a1e7a21a617761329c0" translate="yes" xml:space="preserve">
          <source>.tan()</source>
          <target state="translated">.tan()</target>
        </trans-unit>
        <trans-unit id="49e71684557f266a05e9478b7ae0ad2347851710" translate="yes" xml:space="preserve">
          <source>.tan_()</source>
          <target state="translated">.tan_()</target>
        </trans-unit>
        <trans-unit id="697420814aa788e479a07a1a632b12d9f187e443" translate="yes" xml:space="preserve">
          <source>.tanh()</source>
          <target state="translated">.tanh()</target>
        </trans-unit>
        <trans-unit id="8ef8c422b6b8bbfeeda2f41b7562cb81373dfa89" translate="yes" xml:space="preserve">
          <source>.tanh_()</source>
          <target state="translated">.tanh_()</target>
        </trans-unit>
        <trans-unit id="ebbab9c632935a173ecba012eebc22893c970d6c" translate="yes" xml:space="preserve">
          <source>.tanhshrink()</source>
          <target state="translated">.tanhshrink()</target>
        </trans-unit>
        <trans-unit id="9c1a457596281837d9d812da83bd92b0b99c6f03" translate="yes" xml:space="preserve">
          <source>.tensor()</source>
          <target state="translated">.tensor()</target>
        </trans-unit>
        <trans-unit id="6e59e92359cb39f736e0bc7732015926a771464e" translate="yes" xml:space="preserve">
          <source>.tensordot()</source>
          <target state="translated">.tensordot()</target>
        </trans-unit>
        <trans-unit id="de50bba4e15b3ae8183a3d686ad3cf9bd4bf9d5c" translate="yes" xml:space="preserve">
          <source>.threshold()</source>
          <target state="translated">.threshold()</target>
        </trans-unit>
        <trans-unit id="2784618253a05d3efde86bc7179746541649ad08" translate="yes" xml:space="preserve">
          <source>.threshold_()</source>
          <target state="translated">.threshold_()</target>
        </trans-unit>
        <trans-unit id="dd162dcf3fbd9aa6106a9c79b637651799e7cb13" translate="yes" xml:space="preserve">
          <source>.to_dlpack()</source>
          <target state="translated">.to_dlpack()</target>
        </trans-unit>
        <trans-unit id="423ff7c0c49d148365a07fee5e5ee2eb306fe8fc" translate="yes" xml:space="preserve">
          <source>.to_mkldnn()</source>
          <target state="translated">.to_mkldnn()</target>
        </trans-unit>
        <trans-unit id="d9bd76d9a572363ba122f59c6952a41c71dc3310" translate="yes" xml:space="preserve">
          <source>.to_sparse()</source>
          <target state="translated">.to_sparse()</target>
        </trans-unit>
        <trans-unit id="303b537a482013e2edaa96c96d8bc533a7590af4" translate="yes" xml:space="preserve">
          <source>.tolist()</source>
          <target state="translated">.tolist()</target>
        </trans-unit>
        <trans-unit id="f0f8475467821edd47e2e7d403c6afb9322035bd" translate="yes" xml:space="preserve">
          <source>.topk()</source>
          <target state="translated">.topk()</target>
        </trans-unit>
        <trans-unit id="ff116fa0a6fc698c506a9dc524a339c38524dfb4" translate="yes" xml:space="preserve">
          <source>.torch.default_generator</source>
          <target state="translated">.torch.default_generator</target>
        </trans-unit>
        <trans-unit id="d1a890a2476a467fdcdc84fc775d21e47856cc87" translate="yes" xml:space="preserve">
          <source>.trace()</source>
          <target state="translated">.trace()</target>
        </trans-unit>
        <trans-unit id="18db170abe73e611b17d08cadfba0ccea41c74d3" translate="yes" xml:space="preserve">
          <source>.transpose()</source>
          <target state="translated">.transpose()</target>
        </trans-unit>
        <trans-unit id="a3f26ee1a5791707598e2381dcbe482877c51178" translate="yes" xml:space="preserve">
          <source>.transpose_()</source>
          <target state="translated">.transpose_()</target>
        </trans-unit>
        <trans-unit id="4a1bd5832914a12c9353cd29afbd71faef177586" translate="yes" xml:space="preserve">
          <source>.trapz()</source>
          <target state="translated">.trapz()</target>
        </trans-unit>
        <trans-unit id="0205a5739ea5acdf656634be9c364103dfb66164" translate="yes" xml:space="preserve">
          <source>.triangular_solve()</source>
          <target state="translated">.triangular_solve()</target>
        </trans-unit>
        <trans-unit id="39f8e1599c129d75bb9ca2cede39b77a84acba1a" translate="yes" xml:space="preserve">
          <source>.tril()</source>
          <target state="translated">.tril()</target>
        </trans-unit>
        <trans-unit id="7c74bfa2f2755454bf3dbccccd0861c0ff574732" translate="yes" xml:space="preserve">
          <source>.tril_()</source>
          <target state="translated">.tril_()</target>
        </trans-unit>
        <trans-unit id="adbe511abb1a7862fc9be5cf976020001e746d65" translate="yes" xml:space="preserve">
          <source>.tril_indices()</source>
          <target state="translated">.tril_indices()</target>
        </trans-unit>
        <trans-unit id="bd53b189d7d1fef8556e3a2eb649268feb1e9d68" translate="yes" xml:space="preserve">
          <source>.triplet_margin_loss()</source>
          <target state="translated">.triplet_margin_loss()</target>
        </trans-unit>
        <trans-unit id="68071b1a506e81beccbfb3bd4da54ff430975ea6" translate="yes" xml:space="preserve">
          <source>.triplet_margin_with_distance_loss()</source>
          <target state="translated">.triplet_margin_with_distance_loss()</target>
        </trans-unit>
        <trans-unit id="aa96b2a5e645ae68ff255e3a73bdc7ae0cd7cccd" translate="yes" xml:space="preserve">
          <source>.triu()</source>
          <target state="translated">.triu()</target>
        </trans-unit>
        <trans-unit id="cbcfe8cfe253dda84911856726de94b4a6eb7ed7" translate="yes" xml:space="preserve">
          <source>.triu_()</source>
          <target state="translated">.triu_()</target>
        </trans-unit>
        <trans-unit id="496dbfaf126700d56937a27dc38a2409f1cfd641" translate="yes" xml:space="preserve">
          <source>.triu_indices()</source>
          <target state="translated">.triu_indices()</target>
        </trans-unit>
        <trans-unit id="a11177383fe24123e60b511196ac8926ab899ff8" translate="yes" xml:space="preserve">
          <source>.true_divide()</source>
          <target state="translated">.true_divide()</target>
        </trans-unit>
        <trans-unit id="b8877cf82793c3b00cc0a2b9a3432075645f0c36" translate="yes" xml:space="preserve">
          <source>.true_divide_()</source>
          <target state="translated">.true_divide_()</target>
        </trans-unit>
        <trans-unit id="3850aa6565ec178de32ae95d22b12e8e031ef113" translate="yes" xml:space="preserve">
          <source>.trunc()</source>
          <target state="translated">.trunc()</target>
        </trans-unit>
        <trans-unit id="7c70001439c0ea5afa2756e52400e7dc28572a06" translate="yes" xml:space="preserve">
          <source>.trunc_()</source>
          <target state="translated">.trunc_()</target>
        </trans-unit>
        <trans-unit id="f5fb766a24e15073c66504e0601b39744e6a61ce" translate="yes" xml:space="preserve">
          <source>.type()</source>
          <target state="translated">.type()</target>
        </trans-unit>
        <trans-unit id="843546b413ee61cd39c64ccd6f73f47c597e8b3e" translate="yes" xml:space="preserve">
          <source>.type_as()</source>
          <target state="translated">.type_as()</target>
        </trans-unit>
        <trans-unit id="0cc283ec17ace99481800b35e9706821f154a432" translate="yes" xml:space="preserve">
          <source>.unbind()</source>
          <target state="translated">.unbind()</target>
        </trans-unit>
        <trans-unit id="4cca7d379848fa784a81b35088d777e3f0ffac0e" translate="yes" xml:space="preserve">
          <source>.unfold()</source>
          <target state="translated">.unfold()</target>
        </trans-unit>
        <trans-unit id="e9f6e4d88272af65c760c43c8c7acd9ac74b96b8" translate="yes" xml:space="preserve">
          <source>.uniform_()</source>
          <target state="translated">.uniform_()</target>
        </trans-unit>
        <trans-unit id="6e771e27bf2551db42f2ade2e0d03fe149757002" translate="yes" xml:space="preserve">
          <source>.unique()</source>
          <target state="translated">.unique()</target>
        </trans-unit>
        <trans-unit id="6f3fd575f9904071eee4e8c961873b800c312611" translate="yes" xml:space="preserve">
          <source>.unique_consecutive()</source>
          <target state="translated">.unique_consecutive()</target>
        </trans-unit>
        <trans-unit id="2edb941068f7ebcc58767bc4983b3ff8be0a7559" translate="yes" xml:space="preserve">
          <source>.unsqueeze()</source>
          <target state="translated">.unsqueeze()</target>
        </trans-unit>
        <trans-unit id="4193b6733d1c5bc9ef647f1db45cf03307739dbd" translate="yes" xml:space="preserve">
          <source>.unsqueeze_()</source>
          <target state="translated">.unsqueeze_()</target>
        </trans-unit>
        <trans-unit id="ef40cba3c70a780dc0e3b1308b40f6678a981376" translate="yes" xml:space="preserve">
          <source>.upsample()</source>
          <target state="translated">.upsample()</target>
        </trans-unit>
        <trans-unit id="346b436d9a21086505ddfd3ac7681072ad40b5aa" translate="yes" xml:space="preserve">
          <source>.upsample_bilinear()</source>
          <target state="translated">.upsample_bilinear()</target>
        </trans-unit>
        <trans-unit id="d660a2d87df9f0905a9839cc47d9779b871ac3eb" translate="yes" xml:space="preserve">
          <source>.upsample_nearest()</source>
          <target state="translated">.upsample_nearest()</target>
        </trans-unit>
        <trans-unit id="a4d7de7d850d920a3196c19ee751ce2a6ba03721" translate="yes" xml:space="preserve">
          <source>.utils.clip_grad_norm_()</source>
          <target state="translated">.utils.clip_grad_norm_()</target>
        </trans-unit>
        <trans-unit id="56722b30ba8a6849b0deeed45443857255dedf9d" translate="yes" xml:space="preserve">
          <source>.utils.clip_grad_value_()</source>
          <target state="translated">.utils.clip_grad_value_()</target>
        </trans-unit>
        <trans-unit id="a19ef4d2ec72a434d9e9b8f99d3ac2b65c96f2fb" translate="yes" xml:space="preserve">
          <source>.utils.parameters_to_vector()</source>
          <target state="translated">.utils.parameters_to_vector()</target>
        </trans-unit>
        <trans-unit id="68018fa9ec54f3596eab0dcd7d27f000706f95ef" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod</source>
          <target state="translated">.utils.prune.BasePruningMethod</target>
        </trans-unit>
        <trans-unit id="96dbe35a2adb32cb2212e56febd6924087ba7352" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod.apply()</source>
          <target state="translated">.utils.prune.BasePruningMethod.apply()</target>
        </trans-unit>
        <trans-unit id="13bba3d546cf08f465bd098d67c02b2ef03e72ca" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod.apply_mask()</source>
          <target state="translated">.utils.prune.BasePruningMethod.apply_mask()</target>
        </trans-unit>
        <trans-unit id="0418a37c213661401eb955456f4222cc2d961827" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod.compute_mask()</source>
          <target state="translated">.utils.prune.BasePruningMethod.compute_mask()</target>
        </trans-unit>
        <trans-unit id="ec6b23c12c41cf0782abde73840e4ca3f9d1f08a" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod.prune()</source>
          <target state="translated">.utils.prune.BasePruningMethod.prune()</target>
        </trans-unit>
        <trans-unit id="792a79b733e393e54f95e90dd0c16df323b6b271" translate="yes" xml:space="preserve">
          <source>.utils.prune.BasePruningMethod.remove()</source>
          <target state="translated">.utils.prune.BasePruningMethod.remove()</target>
        </trans-unit>
        <trans-unit id="2e395cb0178292dcf70c9f32e4cd5821e4432e3d" translate="yes" xml:space="preserve">
          <source>.utils.prune.CustomFromMask</source>
          <target state="translated">.utils.prune.CustomFromMask</target>
        </trans-unit>
        <trans-unit id="ed03ba2b1e6de6c0670564b16a916ae54727a4f5" translate="yes" xml:space="preserve">
          <source>.utils.prune.CustomFromMask.apply()</source>
          <target state="translated">.utils.prune.CustomFromMask.apply()</target>
        </trans-unit>
        <trans-unit id="64ef5d83525121064a749aabbb214dc00872c0f2" translate="yes" xml:space="preserve">
          <source>.utils.prune.CustomFromMask.apply_mask()</source>
          <target state="translated">.utils.prune.CustomFromMask.apply_mask()</target>
        </trans-unit>
        <trans-unit id="8e5a6b0339ae23bc8af4d543082e16e416d2e514" translate="yes" xml:space="preserve">
          <source>.utils.prune.CustomFromMask.prune()</source>
          <target state="translated">.utils.prune.CustomFromMask.prune()</target>
        </trans-unit>
        <trans-unit id="54f36359f04ff123e80f7565ba107757ad853858" translate="yes" xml:space="preserve">
          <source>.utils.prune.CustomFromMask.remove()</source>
          <target state="translated">.utils.prune.CustomFromMask.remove()</target>
        </trans-unit>
        <trans-unit id="9c1c859a1e251eb9ee4744176f23d8beffe2090d" translate="yes" xml:space="preserve">
          <source>.utils.prune.Identity</source>
          <target state="translated">.utils.prune.Identity</target>
        </trans-unit>
        <trans-unit id="44ac6cd35a3fa67527830d15e4d9fef7fff11b2a" translate="yes" xml:space="preserve">
          <source>.utils.prune.Identity.apply()</source>
          <target state="translated">.utils.prune.Identity.apply()</target>
        </trans-unit>
        <trans-unit id="9754b28831ce3a820a7fb051c22032370845e6c7" translate="yes" xml:space="preserve">
          <source>.utils.prune.Identity.apply_mask()</source>
          <target state="translated">.utils.prune.Identity.apply_mask()</target>
        </trans-unit>
        <trans-unit id="7eac65adca57d0383e31d16f7508a8db02041db0" translate="yes" xml:space="preserve">
          <source>.utils.prune.Identity.prune()</source>
          <target state="translated">.utils.prune.Identity.prune()</target>
        </trans-unit>
        <trans-unit id="0e38670d866fafaa3bc4860340e24324c0b5099c" translate="yes" xml:space="preserve">
          <source>.utils.prune.Identity.remove()</source>
          <target state="translated">.utils.prune.Identity.remove()</target>
        </trans-unit>
        <trans-unit id="2030af0f697cc4389f87fe8f6342ac1fe1aef911" translate="yes" xml:space="preserve">
          <source>.utils.prune.L1Unstructured</source>
          <target state="translated">.utils.prune.L1Unstructured</target>
        </trans-unit>
        <trans-unit id="361e78be318756b87bc6ae0dba42af5d01f20c65" translate="yes" xml:space="preserve">
          <source>.utils.prune.L1Unstructured.apply()</source>
          <target state="translated">.utils.prune.L1Unstructured.apply()</target>
        </trans-unit>
        <trans-unit id="fafef35c6885a91de9ec9230c954e2e415bc94dc" translate="yes" xml:space="preserve">
          <source>.utils.prune.L1Unstructured.apply_mask()</source>
          <target state="translated">.utils.prune.L1Unstructured.apply_mask()</target>
        </trans-unit>
        <trans-unit id="9dee284a345a5b2c0b9e1f2b07498a7971e34351" translate="yes" xml:space="preserve">
          <source>.utils.prune.L1Unstructured.prune()</source>
          <target state="translated">.utils.prune.L1Unstructured.prune()</target>
        </trans-unit>
        <trans-unit id="419d1d14223c38487b597018e4f9d7a2920c47e5" translate="yes" xml:space="preserve">
          <source>.utils.prune.L1Unstructured.remove()</source>
          <target state="translated">.utils.prune.L1Unstructured.remove()</target>
        </trans-unit>
        <trans-unit id="87fa2f72156040a66c616e68af625c02c61eef44" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured</source>
          <target state="translated">.utils.prune.LnStructured</target>
        </trans-unit>
        <trans-unit id="7f612adf783133cb7be0cd455e4fdc47f45759fa" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured.apply()</source>
          <target state="translated">.utils.prune.LnStructured.apply()</target>
        </trans-unit>
        <trans-unit id="518c56e0cf5a22176dd099c4733007bd269f3c23" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured.apply_mask()</source>
          <target state="translated">.utils.prune.LnStructured.apply_mask()</target>
        </trans-unit>
        <trans-unit id="d305f982e3a0da53cb0ce3e22a96c758768c03e8" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured.compute_mask()</source>
          <target state="translated">.utils.prune.LnStructured.compute_mask()</target>
        </trans-unit>
        <trans-unit id="fd44a6a2284ca91cda7c482f09cd28568c8793ab" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured.prune()</source>
          <target state="translated">.utils.prune.LnStructured.prune()</target>
        </trans-unit>
        <trans-unit id="9e2a0133b183d221e537f5100f3be1a427566446" translate="yes" xml:space="preserve">
          <source>.utils.prune.LnStructured.remove()</source>
          <target state="translated">.utils.prune.LnStructured.remove()</target>
        </trans-unit>
        <trans-unit id="2762b4113260249364cce816ae13a60911bedf09" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer</source>
          <target state="translated">.utils.prune.PruningContainer</target>
        </trans-unit>
        <trans-unit id="32a375f629c3b6abd90d6390cba2dcb015bd3a2f" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.add_pruning_method()</source>
          <target state="translated">.utils.prune.PruningContainer.add_pruning_method()</target>
        </trans-unit>
        <trans-unit id="4e020fd4f1d246ddae87c1b59b87586f019702d9" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.apply()</source>
          <target state="translated">.utils.prune.PruningContainer.apply()</target>
        </trans-unit>
        <trans-unit id="75fc8a864e7486049aa9dcc170357d29acd6fe2b" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.apply_mask()</source>
          <target state="translated">.utils.prune.PruningContainer.apply_mask()</target>
        </trans-unit>
        <trans-unit id="72412a8efc573232ad0b26ad8416c4f81fbada32" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.compute_mask()</source>
          <target state="translated">.utils.prune.PruningContainer.compute_mask()</target>
        </trans-unit>
        <trans-unit id="d6d7e6419fc2fcf38771b140a223bb97b6863cd7" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.prune()</source>
          <target state="translated">.utils.prune.PruningContainer.prune()</target>
        </trans-unit>
        <trans-unit id="9366f472fe3452797e6d8d463e0e7622f02d17f4" translate="yes" xml:space="preserve">
          <source>.utils.prune.PruningContainer.remove()</source>
          <target state="translated">.utils.prune.PruningContainer.remove()</target>
        </trans-unit>
        <trans-unit id="a80c25d8a55e2926bb0bec6c2c1b983bdc50b3fe" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured</source>
          <target state="translated">.utils.prune.RandomStructured</target>
        </trans-unit>
        <trans-unit id="54916d5fb2b17e463926116684b8307112a9e0e6" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured.apply()</source>
          <target state="translated">.utils.prune.RandomStructured.apply()</target>
        </trans-unit>
        <trans-unit id="db516e752ac3f006556cacafc3775790890619a7" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured.apply_mask()</source>
          <target state="translated">.utils.prune.RandomStructured.apply_mask()</target>
        </trans-unit>
        <trans-unit id="892798850dd69b0c3571b807788c93565c865904" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured.compute_mask()</source>
          <target state="translated">.utils.prune.RandomStructured.compute_mask()</target>
        </trans-unit>
        <trans-unit id="26c6a9d31fa31ed7c07722f2d6829b2e0575ec65" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured.prune()</source>
          <target state="translated">.utils.prune.RandomStructured.prune()</target>
        </trans-unit>
        <trans-unit id="732bb2cb4bc908a527037d28e7293fda686259f4" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomStructured.remove()</source>
          <target state="translated">.utils.prune.RandomStructured.remove()</target>
        </trans-unit>
        <trans-unit id="e9809353eddb480205e70436c6fb08121a4293c8" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomUnstructured</source>
          <target state="translated">.utils.prune.RandomUnstructured</target>
        </trans-unit>
        <trans-unit id="14b281c91bb9aca7679e8879a28c4d714bc640e0" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomUnstructured.apply()</source>
          <target state="translated">.utils.prune.RandomUnstructured.apply()</target>
        </trans-unit>
        <trans-unit id="f3aa5d2a109fe7541e28f44c2811f66fb599b3fd" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomUnstructured.apply_mask()</source>
          <target state="translated">.utils.prune.RandomUnstructured.apply_mask()</target>
        </trans-unit>
        <trans-unit id="02f1aaeefe028697a07a5bcfcc34208b1fcd3706" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomUnstructured.prune()</source>
          <target state="translated">.utils.prune.RandomUnstructured.prune()</target>
        </trans-unit>
        <trans-unit id="080c6adff197caf016241c0a4e203d0b1546551a" translate="yes" xml:space="preserve">
          <source>.utils.prune.RandomUnstructured.remove()</source>
          <target state="translated">.utils.prune.RandomUnstructured.remove()</target>
        </trans-unit>
        <trans-unit id="b3e1115f3e3ceed16f3b3281e7b24ffbbbe2950b" translate="yes" xml:space="preserve">
          <source>.utils.prune.custom_from_mask()</source>
          <target state="translated">.utils.prune.custom_from_mask()</target>
        </trans-unit>
        <trans-unit id="e342e24ac0789edc3c2e09099212f61cff0ea1d1" translate="yes" xml:space="preserve">
          <source>.utils.prune.global_unstructured()</source>
          <target state="translated">.utils.prune.global_unstructured()</target>
        </trans-unit>
        <trans-unit id="7dfebef5c315757bfd8ade4d97e2be24edbf521f" translate="yes" xml:space="preserve">
          <source>.utils.prune.is_pruned()</source>
          <target state="translated">.utils.prune.is_pruned()</target>
        </trans-unit>
        <trans-unit id="b5e3b558bc281e4ba71f0c0cc5634ef8cb2a62a5" translate="yes" xml:space="preserve">
          <source>.utils.prune.l1_unstructured()</source>
          <target state="translated">.utils.prune.l1_unstructured()</target>
        </trans-unit>
        <trans-unit id="0451c8af8dbc5a12e46d4e0154ad12c5f789586b" translate="yes" xml:space="preserve">
          <source>.utils.prune.ln_structured()</source>
          <target state="translated">.utils.prune.ln_structured()</target>
        </trans-unit>
        <trans-unit id="d59d4f9dd5fded9a9fff7402036d4c71797c5817" translate="yes" xml:space="preserve">
          <source>.utils.prune.random_structured()</source>
          <target state="translated">.utils.prune.random_structured()</target>
        </trans-unit>
        <trans-unit id="169a51d5c29377b07a68700faebcae405f69e6e9" translate="yes" xml:space="preserve">
          <source>.utils.prune.random_unstructured()</source>
          <target state="translated">.utils.prune.random_unstructured()</target>
        </trans-unit>
        <trans-unit id="3cec9f8b7dc54e2f8294df5a4f02f3a77e920c0b" translate="yes" xml:space="preserve">
          <source>.utils.prune.remove()</source>
          <target state="translated">.utils.prune.remove()</target>
        </trans-unit>
        <trans-unit id="9571745212c6640b95859bbac1729f6f8a974efe" translate="yes" xml:space="preserve">
          <source>.utils.remove_spectral_norm()</source>
          <target state="translated">.utils.remove_spectral_norm()</target>
        </trans-unit>
        <trans-unit id="d552147f1ebb43e7ce607b2b4bad97a5d3a52959" translate="yes" xml:space="preserve">
          <source>.utils.remove_weight_norm()</source>
          <target state="translated">.utils.remove_weight_norm()</target>
        </trans-unit>
        <trans-unit id="ea781bfa019f8a74e057f697563e764755acf04e" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence</source>
          <target state="translated">.utils.rnn.PackedSequence</target>
        </trans-unit>
        <trans-unit id="486bd4ea3c44b99bc13ae807c50d5c9371ea177a" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.batch_sizes()</source>
          <target state="translated">.utils.rnn.PackedSequence.batch_sizes()</target>
        </trans-unit>
        <trans-unit id="258095aac360c23227ac51915ab47d2c94edff32" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.count()</source>
          <target state="translated">.utils.rnn.PackedSequence.count()</target>
        </trans-unit>
        <trans-unit id="78320203d07f3c6b0ddf07782f7eebd12aa56a56" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.data()</source>
          <target state="translated">.utils.rnn.PackedSequence.data()</target>
        </trans-unit>
        <trans-unit id="e8919c6fc3b2cc6886414990087b9c024f3c9faf" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.index()</source>
          <target state="translated">.utils.rnn.PackedSequence.index()</target>
        </trans-unit>
        <trans-unit id="54c2c103f2b922261518e1f22c44028107107280" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.is_cuda()</source>
          <target state="translated">.utils.rnn.PackedSequence.is_cuda()</target>
        </trans-unit>
        <trans-unit id="9f4f225d3a19fc94de6d4e252618a251bf936b85" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.is_pinned()</source>
          <target state="translated">.utils.rnn.PackedSequence.is_pinned()</target>
        </trans-unit>
        <trans-unit id="8c867f5a5c3248b079fdbed30af896484176591b" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.sorted_indices()</source>
          <target state="translated">.utils.rnn.PackedSequence.sorted_indices()</target>
        </trans-unit>
        <trans-unit id="f80b1d41067dd96230c92d44c21c947fb3fdd109" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.to()</source>
          <target state="translated">.utils.rnn.PackedSequence.to()</target>
        </trans-unit>
        <trans-unit id="a327649f7bff462deb40e7d9141f9f7fffdd8987" translate="yes" xml:space="preserve">
          <source>.utils.rnn.PackedSequence.unsorted_indices()</source>
          <target state="translated">.utils.rnn.PackedSequence.unsorted_indices()</target>
        </trans-unit>
        <trans-unit id="b38b535f3c6c98e337b7a2a5d0581f72d057b8e5" translate="yes" xml:space="preserve">
          <source>.utils.rnn.pack_padded_sequence()</source>
          <target state="translated">.utils.rnn.pack_padded_sequence()</target>
        </trans-unit>
        <trans-unit id="b6a789a7f834efb1c9210039cb8a5f6817673462" translate="yes" xml:space="preserve">
          <source>.utils.rnn.pack_sequence()</source>
          <target state="translated">.utils.rnn.pack_sequence()</target>
        </trans-unit>
        <trans-unit id="8a6285d3d5b4e9b23a7dcdb0d2b5f1299b675c82" translate="yes" xml:space="preserve">
          <source>.utils.rnn.pad_packed_sequence()</source>
          <target state="translated">.utils.rnn.pad_packed_sequence()</target>
        </trans-unit>
        <trans-unit id="cb432081928a7350e469045713c34bfc662fc8ed" translate="yes" xml:space="preserve">
          <source>.utils.rnn.pad_sequence()</source>
          <target state="translated">.utils.rnn.pad_sequence()</target>
        </trans-unit>
        <trans-unit id="7f063f88c99cafbf19141f232b85f2b56553b56f" translate="yes" xml:space="preserve">
          <source>.utils.spectral_norm()</source>
          <target state="translated">.utils.spectral_norm()</target>
        </trans-unit>
        <trans-unit id="40000b57cf745437ea0330c8c50ee4ac4d76bb2f" translate="yes" xml:space="preserve">
          <source>.utils.vector_to_parameters()</source>
          <target state="translated">.utils.vector_to_parameters()</target>
        </trans-unit>
        <trans-unit id="e96fb3a30945e7c711ad2d92b3d8bda8280c1d3e" translate="yes" xml:space="preserve">
          <source>.utils.weight_norm()</source>
          <target state="translated">.utils.weight_norm()</target>
        </trans-unit>
        <trans-unit id="f095a951ddd4708b007f7f966f920a77064ff6c5" translate="yes" xml:space="preserve">
          <source>.values()</source>
          <target state="translated">.values()</target>
        </trans-unit>
        <trans-unit id="791f24061091d43bf02384bef1fcd51db838a0c1" translate="yes" xml:space="preserve">
          <source>.vander()</source>
          <target state="translated">.vander()</target>
        </trans-unit>
        <trans-unit id="bee05a1805d6f7be25c09d7aeca4fa8ab4a42dee" translate="yes" xml:space="preserve">
          <source>.var()</source>
          <target state="translated">.var()</target>
        </trans-unit>
        <trans-unit id="ca6f91060e59f0bb42f634e1fda75895e7e6d888" translate="yes" xml:space="preserve">
          <source>.var_mean()</source>
          <target state="translated">.var_mean()</target>
        </trans-unit>
        <trans-unit id="ea848ffbb3a855e2a566a197134b320662418544" translate="yes" xml:space="preserve">
          <source>.vdot()</source>
          <target state="translated">.vdot()</target>
        </trans-unit>
        <trans-unit id="dfc01c50796d5440f7251cfb966e52697b4f762b" translate="yes" xml:space="preserve">
          <source>.verify_ninja_availability()</source>
          <target state="translated">.verify_ninja_availability()</target>
        </trans-unit>
        <trans-unit id="b8c4c9c9eae61f0fcb7b859e35818e1502fc6f0b" translate="yes" xml:space="preserve">
          <source>.vgg11()</source>
          <target state="translated">.vgg11()</target>
        </trans-unit>
        <trans-unit id="ced4a297283c69bd31170094b460550f6338b144" translate="yes" xml:space="preserve">
          <source>.vgg11_bn()</source>
          <target state="translated">.vgg11_bn()</target>
        </trans-unit>
        <trans-unit id="4df2b1d0335c46528ff73e9cd0823934a4a131b0" translate="yes" xml:space="preserve">
          <source>.vgg13()</source>
          <target state="translated">.vgg13()</target>
        </trans-unit>
        <trans-unit id="b2ade82c95c34861c4b3b58beb3feaa1b2d1e7ec" translate="yes" xml:space="preserve">
          <source>.vgg13_bn()</source>
          <target state="translated">.vgg13_bn()</target>
        </trans-unit>
        <trans-unit id="d38ee571c7da5a485a9e2020bd27d9de287bbede" translate="yes" xml:space="preserve">
          <source>.vgg16()</source>
          <target state="translated">.vgg16()</target>
        </trans-unit>
        <trans-unit id="b362b99ff9741cec04e3d0c176bb2975f4858a27" translate="yes" xml:space="preserve">
          <source>.vgg16_bn()</source>
          <target state="translated">.vgg16_bn()</target>
        </trans-unit>
        <trans-unit id="694202a41d501435e9ed6825a32e31cb0b580ba6" translate="yes" xml:space="preserve">
          <source>.vgg19()</source>
          <target state="translated">.vgg19()</target>
        </trans-unit>
        <trans-unit id="623d5541309a178748a07d5b9dc6c3f373b906db" translate="yes" xml:space="preserve">
          <source>.vgg19_bn()</source>
          <target state="translated">.vgg19_bn()</target>
        </trans-unit>
        <trans-unit id="64a13b8f84912e57eaba60ca0d7a928bf3ef96f6" translate="yes" xml:space="preserve">
          <source>.video.mc3_18()</source>
          <target state="translated">.video.mc3_18()</target>
        </trans-unit>
        <trans-unit id="d383689be72c653e7f2f8a85653e7b5a57f29f96" translate="yes" xml:space="preserve">
          <source>.video.r2plus1d_18()</source>
          <target state="translated">.video.r2plus1d_18()</target>
        </trans-unit>
        <trans-unit id="fcf5f0a465809d92c8a97182a00eec7a3834e59b" translate="yes" xml:space="preserve">
          <source>.video.r3d_18()</source>
          <target state="translated">.video.r3d_18()</target>
        </trans-unit>
        <trans-unit id="87529b42ed4149aebe46e22160e346cecafca6b6" translate="yes" xml:space="preserve">
          <source>.view()</source>
          <target state="translated">.view()</target>
        </trans-unit>
        <trans-unit id="fa34117009286039cbdfbb0d9ca44ba27dd2d166" translate="yes" xml:space="preserve">
          <source>.view_as()</source>
          <target state="translated">.view_as()</target>
        </trans-unit>
        <trans-unit id="58890cc87aa3e2d48d7a3f5f86550ad691d357fa" translate="yes" xml:space="preserve">
          <source>.view_as_complex()</source>
          <target state="translated">.view_as_complex()</target>
        </trans-unit>
        <trans-unit id="7d4fecdc7697b890c88ece4514c9e9e3aff6fe4b" translate="yes" xml:space="preserve">
          <source>.view_as_real()</source>
          <target state="translated">.view_as_real()</target>
        </trans-unit>
        <trans-unit id="8f1517832f213f70c1f39fd69baab84c5c5c3b30" translate="yes" xml:space="preserve">
          <source>.vstack()</source>
          <target state="translated">.vstack()</target>
        </trans-unit>
        <trans-unit id="a79be19130326003d959c1911788107f349dd10b" translate="yes" xml:space="preserve">
          <source>.wait_all()</source>
          <target state="translated">.wait_all()</target>
        </trans-unit>
        <trans-unit id="5ef852ff8afae23ed766e2efe539bbbe7f511989" translate="yes" xml:space="preserve">
          <source>.where()</source>
          <target state="translated">.where()</target>
        </trans-unit>
        <trans-unit id="d125194c5a6580d7fb7f2c53b4031a5e0052de93" translate="yes" xml:space="preserve">
          <source>.wide_resnet101_2()</source>
          <target state="translated">.wide_resnet101_2()</target>
        </trans-unit>
        <trans-unit id="0798f1a241b54039c8508174a596e1ddb78ac690" translate="yes" xml:space="preserve">
          <source>.wide_resnet50_2()</source>
          <target state="translated">.wide_resnet50_2()</target>
        </trans-unit>
        <trans-unit id="342316886ebc6056053f1a56e66ed68be70c2337" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter</source>
          <target state="translated">.writer.SummaryWriter</target>
        </trans-unit>
        <trans-unit id="c55e96f2437ab352a013b3946fb1cce653b9f4e3" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.__init__()</source>
          <target state="translated">.writer.SummaryWriter.__init__()</target>
        </trans-unit>
        <trans-unit id="a30808c11002df6419b9a86d550f90ab1e88d880" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_audio()</source>
          <target state="translated">.writer.SummaryWriter.add_audio()</target>
        </trans-unit>
        <trans-unit id="6d2e34fa75e2c0f25dd5a177ee95fac37e2eb4b9" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_custom_scalars()</source>
          <target state="translated">.writer.SummaryWriter.add_custom_scalars()</target>
        </trans-unit>
        <trans-unit id="a650f27a72e42aebc42db2e2edff51f3858af32b" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_embedding()</source>
          <target state="translated">.writer.SummaryWriter.add_embedding()</target>
        </trans-unit>
        <trans-unit id="a72f0aba7b88e656d7a35f6ea734887c8e84d601" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_figure()</source>
          <target state="translated">.writer.SummaryWriter.add_figure()</target>
        </trans-unit>
        <trans-unit id="d8e520cb4aff28d3804344bac4cb9d5483e318d4" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_graph()</source>
          <target state="translated">.writer.SummaryWriter.add_graph()</target>
        </trans-unit>
        <trans-unit id="484c618dfce96cfcd8597427dc094db5f4cb57d4" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_histogram()</source>
          <target state="translated">.writer.SummaryWriter.add_histogram()</target>
        </trans-unit>
        <trans-unit id="3f1efefed25d0ffc3616f2eb75d71e86bc91ad42" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_hparams()</source>
          <target state="translated">.writer.SummaryWriter.add_hparams()</target>
        </trans-unit>
        <trans-unit id="9ef20d91870514a05fea7c9158c6750bbaedde3b" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_image()</source>
          <target state="translated">.writer.SummaryWriter.add_image()</target>
        </trans-unit>
        <trans-unit id="dee546381ff29747a2a82e110ecf7b339ec4f2f1" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_images()</source>
          <target state="translated">.writer.SummaryWriter.add_images()</target>
        </trans-unit>
        <trans-unit id="352012cb5ff026470489850c02c9868f653dbc30" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_mesh()</source>
          <target state="translated">.writer.SummaryWriter.add_mesh()</target>
        </trans-unit>
        <trans-unit id="7f901cf67c175697e552ba870101c527f0df372d" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_pr_curve()</source>
          <target state="translated">.writer.SummaryWriter.add_pr_curve()</target>
        </trans-unit>
        <trans-unit id="fb9fa36b1d5edd64a1ba4febeb762a165c592b4d" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_scalar()</source>
          <target state="translated">.writer.SummaryWriter.add_scalar()</target>
        </trans-unit>
        <trans-unit id="c73cbe93a612a3a3f77dae592e35d43e29f6990f" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_scalars()</source>
          <target state="translated">.writer.SummaryWriter.add_scalars()</target>
        </trans-unit>
        <trans-unit id="fa88e8f90389ee075c0080c7d0ba996f3df9db60" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_text()</source>
          <target state="translated">.writer.SummaryWriter.add_text()</target>
        </trans-unit>
        <trans-unit id="33d0b12351829f76d0fdfdbde528fa9ab887a96d" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.add_video()</source>
          <target state="translated">.writer.SummaryWriter.add_video()</target>
        </trans-unit>
        <trans-unit id="2ce43ddd4f5b07c009571bfbe8f9de0b760f9d9f" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.close()</source>
          <target state="translated">.writer.SummaryWriter.close()</target>
        </trans-unit>
        <trans-unit id="5175efcd264d3e40342a4eb30cc137ac8d311ada" translate="yes" xml:space="preserve">
          <source>.writer.SummaryWriter.flush()</source>
          <target state="translated">.writer.SummaryWriter.flush()</target>
        </trans-unit>
        <trans-unit id="4c4b14ec7a98b18cc43f836d4565dd49e9812243" translate="yes" xml:space="preserve">
          <source>.xavier_normal_()</source>
          <target state="translated">.xavier_normal_()</target>
        </trans-unit>
        <trans-unit id="e1f5e1756c2d74d4921d452efbfe9a310762d424" translate="yes" xml:space="preserve">
          <source>.xavier_uniform_()</source>
          <target state="translated">.xavier_uniform_()</target>
        </trans-unit>
        <trans-unit id="ae72a00bc11f23b1d0c1a7abcadbdeb36c55deae" translate="yes" xml:space="preserve">
          <source>.zero_()</source>
          <target state="translated">.zero_()</target>
        </trans-unit>
        <trans-unit id="d07a9662233bd9366ceeee9762b929ddd0e79974" translate="yes" xml:space="preserve">
          <source>.zeros()</source>
          <target state="translated">.zeros()</target>
        </trans-unit>
        <trans-unit id="56ae697d095c633dd04c61fc4601a8f76117f84c" translate="yes" xml:space="preserve">
          <source>.zeros_()</source>
          <target state="translated">.zeros_()</target>
        </trans-unit>
        <trans-unit id="52d75b9a91d0cc525872765a9cafc21ba812e425" translate="yes" xml:space="preserve">
          <source>.zeros_like()</source>
          <target state="translated">.zeros_like()</target>
        </trans-unit>
        <trans-unit id="4a87db4219191c81a8ffbdb1d4f5aeda7aea887c" translate="yes" xml:space="preserve">
          <source>0 &amp;lt;= \texttt{target[i]} &amp;lt;= \texttt{n\_classes}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aab3f799387c1b75f55a4d81e5026a8e9e807e7d" translate="yes" xml:space="preserve">
          <source>0 &amp;lt;= c &amp;lt;= \texttt{n\_classes}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86e9851bbf6adb75227d9b1eca23401142ae383f" translate="yes" xml:space="preserve">
          <source>0 \leq \omega &amp;lt; \text{n\_fft}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="335823265c4483b98c34377e1496d179d90f5b8c" translate="yes" xml:space="preserve">
          <source>0 \leq \text{input}_i \leq 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d80d54fddf514c1f3efbd05e08e9d1bed1a5b1d1" translate="yes" xml:space="preserve">
          <source>0 \leq \text{targets}[i] \leq C-1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="820a85abb467f452b4b1c01b0e17ac1a2628ad98" translate="yes" xml:space="preserve">
          <source>0 \leq y \leq \text{x.size}(1)-1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b1620a98f62ccdde010f7543176ebe811021b60" translate="yes" xml:space="preserve">
          <source>0 \leq y[j] \leq \text{x.size}(0)-1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c94362de3aa9fed4a438b7001e0d9d92032ae326" translate="yes" xml:space="preserve">
          <source>0-D and 1-D tensors are returned as is. When input is a 2-D tensor this is equivalent to &lt;code&gt;transpose(input, 0, 1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7afea2ff51c34cf0d0079d0f969bb5d3c49ba3b4" translate="yes" xml:space="preserve">
          <source>1-D</source>
          <target state="translated">1-D</target>
        </trans-unit>
        <trans-unit id="50658d0e96e0ccf8b0271abcad847a3cd3f1214f" translate="yes" xml:space="preserve">
          <source>1. &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;torch.jit.script&lt;/code&gt;&lt;/a&gt; will now attempt to recursively compile functions, methods, and classes that it encounters. Once you call &lt;code&gt;torch.jit.script&lt;/code&gt;, compilation is &amp;ldquo;opt-out&amp;rdquo;, rather than &amp;ldquo;opt-in&amp;rdquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6d3007f5bc9d5459a2bf2fd888fac22d58fbf5e" translate="yes" xml:space="preserve">
          <source>1. &lt;code&gt;nn.Parameter&lt;/code&gt; - Values wrapped in &lt;code&gt;nn.Parameter&lt;/code&gt; will work as they do on &lt;code&gt;nn.Module&lt;/code&gt;s</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="377fd2d385c6c9df87bb06f01b8268570e10c25d" translate="yes" xml:space="preserve">
          <source>1. This utility and multi-process distributed (single-node or multi-node) GPU training currently only achieves the best performance using the NCCL distributed backend. Thus NCCL backend is the recommended backend to use for GPU training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="525108fcf9aab2b4f5e2b2bc40917b1214736069" translate="yes" xml:space="preserve">
          <source>1/r</source>
          <target state="translated">1/r</target>
        </trans-unit>
        <trans-unit id="3001085edad568d460b6703715740aa1e3239a09" translate="yes" xml:space="preserve">
          <source>128-bit complex</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a6e9614989fb3c07a2e0abb61f5facd1d36c45e6" translate="yes" xml:space="preserve">
          <source>16-bit floating point &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd934478b9268a218ce967ce088c68bb465a4ded" translate="yes" xml:space="preserve">
          <source>16-bit floating point &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4553e424e20dabcf0eb05b6e471c12a26dd548cb" translate="yes" xml:space="preserve">
          <source>16-bit integer (signed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6148fb4084092cf021ca443a258430f5c054bd3" translate="yes" xml:space="preserve">
          <source>2-D tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f80cf0a811f49fd09054a0c0f08216a4b837d79" translate="yes" xml:space="preserve">
          <source>2-D tensors. This product is efficiently computed using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms of arithmetic operations (&lt;a href=&quot;https://mitpress.mit.edu/books/introduction-algorithms-third-edition&quot;&gt;[CLRS]&lt;/a&gt;). Note that since this is a function to compute the product,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca458b144cdb3378a7b877d7532a92b5025a52c5" translate="yes" xml:space="preserve">
          <source>2-norm</source>
          <target state="translated">2-norm</target>
        </trans-unit>
        <trans-unit id="5b93e9ada884414b5ec351182b9d3ab8ea0569f0" translate="yes" xml:space="preserve">
          <source>2-norm (largest sing. value)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8570bc94a60c507b08d31d6f8219f669f17b75c9" translate="yes" xml:space="preserve">
          <source>2. &lt;code&gt;register_buffer&lt;/code&gt; - Values wrapped in &lt;code&gt;register_buffer&lt;/code&gt; will work as they do on &lt;code&gt;nn.Module&lt;/code&gt;s. This is equivalent to an attribute (see 4) of type &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2750531b3636cf3777bbe9bdb3a2d500e3d0af50" translate="yes" xml:space="preserve">
          <source>2. &lt;code&gt;torch.jit.script(nn_module_instance)&lt;/code&gt; is now the preferred way to create &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;s, instead of inheriting from &lt;code&gt;torch.jit.ScriptModule&lt;/code&gt;. These changes combine to provide a simpler, easier-to-use API for converting your &lt;code&gt;nn.Module&lt;/code&gt;s into &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;s, ready to be optimized and executed in a non-Python environment.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebce31b241125f3b1f3d5eec87256a45096e867e" translate="yes" xml:space="preserve">
          <source>2. In your training program, you must parse the command-line argument: &lt;code&gt;--local_rank=LOCAL_PROCESS_RANK&lt;/code&gt;, which will be provided by this module. If your training program uses GPUs, you should ensure that your code only runs on the GPU device of LOCAL_PROCESS_RANK. This can be done by:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0bcabad9bb4fd5ebaafd22cc43b4ea54825045ea" translate="yes" xml:space="preserve">
          <source>2. Keep producer process running until all consumers exits. This will prevent the situation when the producer process releasing memory which is still in use by the consumer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7660227d44daf6b2b88ac05a2d085306d9a49369" translate="yes" xml:space="preserve">
          <source>3. Constants - Annotating a class member as &lt;code&gt;Final&lt;/code&gt; (or adding it to a list called &lt;code&gt;__constants__&lt;/code&gt; at the class definition level) will mark the contained names as constants. Constants are saved directly in the code of the model. See &lt;code&gt;builtin-constants&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69eb583a4d67c412f7b23a556bf72ba2d6469458" translate="yes" xml:space="preserve">
          <source>3. In your training program, you are supposed to call the following function at the beginning to start the distributed backend. You need to make sure that the init_method uses &lt;code&gt;env://&lt;/code&gt;, which is the only supported &lt;code&gt;init_method&lt;/code&gt; by this module.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da18265156e24117c9a4e3e5330b4295b716f1cf" translate="yes" xml:space="preserve">
          <source>32-bit complex</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae668bebc086179c8fc19ca0dce26efb2d1d55d6" translate="yes" xml:space="preserve">
          <source>32-bit floating point</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="539c17308922218bb4f53ba6655b67dbb912b1fe" translate="yes" xml:space="preserve">
          <source>32-bit integer (signed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bc234ef4c454a6f874806fbd03f3d9d0fd0ef92f" translate="yes" xml:space="preserve">
          <source>3\times 100=300</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="882814b06c355d3c7c03a580ac059f27429b96b6" translate="yes" xml:space="preserve">
          <source>4. Attributes - Values that are a &lt;code&gt;supported type&lt;/code&gt; can be added as mutable attributes. Most types can be inferred but some may need to be specified, see &lt;code&gt;module attributes&lt;/code&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9069a00923a294a8df05b76c8e124a72cb1bd585" translate="yes" xml:space="preserve">
          <source>4. In your training program, you can either use regular distributed functions or use &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; module. If your training program uses GPUs for training and you would like to use &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; module, here is how to configure it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3de80fd3d0d6e9ea6f81995d1048c402265bfd48" translate="yes" xml:space="preserve">
          <source>5. Another way to pass &lt;code&gt;local_rank&lt;/code&gt; to the subprocesses via environment variable &lt;code&gt;LOCAL_RANK&lt;/code&gt;. This behavior is enabled when you launch the script with &lt;code&gt;--use_env=True&lt;/code&gt;. You must adjust the subprocess example above to replace &lt;code&gt;args.local_rank&lt;/code&gt; with &lt;code&gt;os.environ['LOCAL_RANK']&lt;/code&gt;; the launcher will not pass &lt;code&gt;--local_rank&lt;/code&gt; when you specify this flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f28bf95ede5b752ccd17fea3f58699ffcb5cc56" translate="yes" xml:space="preserve">
          <source>64-bit complex</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6879ad37f6917f2009f6728dcba67536db7896ad" translate="yes" xml:space="preserve">
          <source>64-bit floating point</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2683fa6ca52169baaff61b26d022504a665ba1b8" translate="yes" xml:space="preserve">
          <source>64-bit integer (signed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f988e45c840740cf9d994af1cd19c3b6d592b7b1" translate="yes" xml:space="preserve">
          <source>8-bit integer (signed)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c00577a05120e836abc6bf2b03143271ce54fa2" translate="yes" xml:space="preserve">
          <source>8-bit integer (unsigned)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22590cc508b5741673b13c66585b59e9782a996e" translate="yes" xml:space="preserve">
          <source>: returns matrix &lt;code&gt;inv&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a54bcfff7e5c161e98a8e10e7bc3784f3e512750" translate="yes" xml:space="preserve">
          <source>: returns matrix &lt;code&gt;inv&lt;/code&gt;. The inverse is computed using LAPACK routines &lt;code&gt;dpotri&lt;/code&gt; and &lt;code&gt;spotri&lt;/code&gt; (and the corresponding MAGMA routines).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="477ab8ebdf8696d83323fb9919db3a93661644fe" translate="yes" xml:space="preserve">
          <source>:attr:&lt;code&gt;reduction&lt;/code&gt; = &lt;code&gt;'mean'&lt;/code&gt; doesn&amp;rsquo;t return the true kl divergence value, please use :attr:&lt;code&gt;reduction&lt;/code&gt; = &lt;code&gt;'batchmean'&lt;/code&gt; which aligns with KL math definition. In the next major release, &lt;code&gt;'mean'&lt;/code&gt; will be changed to be the same as &amp;lsquo;batchmean&amp;rsquo;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c40bb86e72d8e8efe6bccbd7e20b38c5a66e4ed9" translate="yes" xml:space="preserve">
          <source>; to pad the last 2 dimensions of the input tensor, then use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="787c3d1d527ea8f9b7e804368cb551c0f7cb16f5" translate="yes" xml:space="preserve">
          <source>; to pad the last 3 dimensions, use</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24f83c418d09eab31416c1d4aff2761d4e934a86" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#data-loading-order-and-sampler&quot;&gt;customizing data loading order&lt;/a&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1287ce1498528d2fadb682b4bcfb0eeb71efb39" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#dataset-types&quot;&gt;map-style and iterable-style datasets&lt;/a&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58634712feb4566a8e8a8805c7625629f8769a48" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#iterable-style-datasets&quot;&gt;iterable-style datasets&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a2ccc69d72fa4953394d9b86e11aba9541bf2f77" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#loading-batched-and-non-batched-data&quot;&gt;automatic batching&lt;/a&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6747f85cfc85b5ac4f7e5e6e522e651fa3988163" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#map-style-datasets&quot;&gt;map-style datasets&lt;/a&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="071bd3bb6c490756d934eebcaeb553ecec1b6807" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#memory-pinning&quot;&gt;automatic memory pinning&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99341b61d49ce6b5d0d24229a8676d1293c098aa" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#module-torch.distributed.optim&quot;&gt;&lt;code&gt;torch.distributed.optim&lt;/code&gt;&lt;/a&gt; exposes DistributedOptimizer, which takes a list of remote parameters (&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt;) and runs the optimizer locally on the workers where the parameters live. The distributed optimizer can use any of the local optimizer &lt;a href=&quot;optim#optimizer-algorithms&quot;&gt;Algorithms&lt;/a&gt; to apply the gradients on each worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f7a9c23154b6050d943a6d62290ae130840d40f" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#module-torch.optim&quot;&gt;&lt;code&gt;torch.optim&lt;/code&gt;&lt;/a&gt; is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48d5c781a83a17f35abeac24bdb014fdd1a9f6c6" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#single-and-multi-process-data-loading&quot;&gt;single- and multi-process data loading&lt;/a&gt;,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88f247a9629f4ff69c252f2d37cde517e2411aa3" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is an alias for the default tensor type (&lt;code&gt;torch.FloatTensor&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39cb8b635ad5957fc54d597a8dc815658cb43249" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; may contain up to one Ellipsis (&lt;code&gt;...&lt;/code&gt;). The Ellipsis is expanded greedily; it is expanded in-place to fill &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; to the same length as &lt;code&gt;self.dim()&lt;/code&gt; using names from the corresponding indices of &lt;code&gt;self.names&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d8e3352f844fda269c67d30d49f5952a62adac0" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; may contain up to one Ellipsis (&lt;code&gt;...&lt;/code&gt;). The Ellipsis is expanded to be equal to all dimension names of &lt;code&gt;self&lt;/code&gt; that are not mentioned in &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;, in the order that they appear in &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f3fe877175d6211f00ba8f1451d8b6604d1f3d73" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.new_tensor&quot;&gt;&lt;code&gt;new_tensor()&lt;/code&gt;&lt;/a&gt; always copies &lt;code&gt;data&lt;/code&gt;. If you have a Tensor &lt;code&gt;data&lt;/code&gt; and want to avoid a copy, use &lt;a href=&quot;#torch.Tensor.requires_grad_&quot;&gt;&lt;code&gt;torch.Tensor.requires_grad_()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;autograd#torch.Tensor.detach&quot;&gt;&lt;code&gt;torch.Tensor.detach()&lt;/code&gt;&lt;/a&gt;. If you have a numpy array and want to avoid a copy, use &lt;a href=&quot;generated/torch.from_numpy#torch.from_numpy&quot;&gt;&lt;code&gt;torch.from_numpy()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43033fba892f4d4e8d789c2b9d7d50753fdcf631" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.repeat&quot;&gt;&lt;code&gt;repeat()&lt;/code&gt;&lt;/a&gt; behaves differently from &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html&quot;&gt;numpy.repeat&lt;/a&gt;, but is more similar to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html&quot;&gt;numpy.tile&lt;/a&gt;. For the operator similar to &lt;code&gt;numpy.repeat&lt;/code&gt;, see &lt;a href=&quot;generated/torch.repeat_interleave#torch.repeat_interleave&quot;&gt;&lt;code&gt;torch.repeat_interleave()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34bbf74defdb167d9281c10c26ec1cf0c6982f15" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.requires_grad_&quot;&gt;&lt;code&gt;requires_grad_()&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s main use case is to tell autograd to begin recording operations on a Tensor &lt;code&gt;tensor&lt;/code&gt;. If &lt;code&gt;tensor&lt;/code&gt; has &lt;code&gt;requires_grad=False&lt;/code&gt; (because it was obtained through a DataLoader, or required preprocessing or initialization), &lt;code&gt;tensor.requires_grad_()&lt;/code&gt; makes it so that autograd will begin to record operations on &lt;code&gt;tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="42339127ad2edb3a7a27bf8579a58fb6f540ff1f" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.Tensor.select&quot;&gt;&lt;code&gt;select()&lt;/code&gt;&lt;/a&gt; is equivalent to slicing. For example, &lt;code&gt;tensor.select(0, index)&lt;/code&gt; is equivalent to &lt;code&gt;tensor[index]&lt;/code&gt; and &lt;code&gt;tensor.select(2, index)&lt;/code&gt; is equivalent to &lt;code&gt;tensor[:,:,index]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16db46ffddceeedf2323748d5dd173aa01d13165" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cat&quot;&gt;&lt;code&gt;torch.cat()&lt;/code&gt;&lt;/a&gt; can be best understood via examples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2b08333af76599fc76581a665025e8999f3c373" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cat&quot;&gt;&lt;code&gt;torch.cat()&lt;/code&gt;&lt;/a&gt; can be seen as an inverse operation for &lt;a href=&quot;torch.split#torch.split&quot;&gt;&lt;code&gt;torch.split()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.chunk#torch.chunk&quot;&gt;&lt;code&gt;torch.chunk()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c88b9823b46a924bf19ce9694ed0c39485f877b0" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.get_scale&quot;&gt;&lt;code&gt;get_scale()&lt;/code&gt;&lt;/a&gt; incurs a CPU-GPU sync.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27c7731bf2b6becc75c5ba46348d94d240570353" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt; carries out the following two operations:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dded969dc9048c2d16b6704977a1c3f86a782db1" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; does not incur a CPU-GPU sync.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c231a9ba712da56f84d68ad04f2ff6f69d57f43" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; is optional, serving cases where you need to &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#working-with-unscaled-gradients&quot;&gt;modify or inspect gradients&lt;/a&gt; between the backward pass(es) and &lt;a href=&quot;#torch.cuda.amp.GradScaler.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt;. If &lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; is not called explicitly, gradients will be unscaled automatically during &lt;a href=&quot;#torch.cuda.amp.GradScaler.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bda8880862d8c8bdb9ba1127fecc4632fcc584fb" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; may unscale sparse gradients out of place, replacing the &lt;code&gt;.grad&lt;/code&gt; attribute.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f6ffb902d0efdd7e13ccaeda874e6cde12e38e9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; should only be called once per optimizer per &lt;a href=&quot;#torch.cuda.amp.GradScaler.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt; call, and only after all gradients for that optimizer&amp;rsquo;s assigned parameters have been accumulated. Calling &lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; twice for a given optimizer between each &lt;a href=&quot;#torch.cuda.amp.GradScaler.step&quot;&gt;&lt;code&gt;step()&lt;/code&gt;&lt;/a&gt; triggers a RuntimeError.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72b30758d7757257fab2c07043cf64e98bd27870" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.GradScaler.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt; should only be called at the end of the iteration, after &lt;code&gt;scaler.step(optimizer)&lt;/code&gt; has been invoked for all optimizers used this iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd643d07a5bceca4d05a8262b5c28e333276b7f8" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt;&lt;code&gt;autocast&lt;/code&gt;&lt;/a&gt; can also be used as a decorator, e.g., on the &lt;code&gt;forward&lt;/code&gt; method of your model:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0dd806f9c308d81d75b304905839ce6f59ed41fb" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt;&lt;code&gt;autocast&lt;/code&gt;&lt;/a&gt; should wrap only the forward pass(es) of your network, including the loss computation(s). Backward passes under autocast are not recommended. Backward ops run in the same type that autocast used for corresponding forward ops.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="961695c6cbdcbf22c861da65d0fb7ba7becc61fb" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.cuda.empty_cache&quot;&gt;&lt;code&gt;empty_cache()&lt;/code&gt;&lt;/a&gt; doesn&amp;rsquo;t increase the amount of GPU memory available for PyTorch. However, it may help reduce fragmentation of GPU memory in certain cases. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-management&quot;&gt;Memory management&lt;/a&gt; for more details about GPU memory management.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e5d0b554f71fff92ccd2a86c3f4da6ae5745236" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributed.ReduceOp&quot;&gt;&lt;code&gt;ReduceOp&lt;/code&gt;&lt;/a&gt; is recommended to use instead.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efe0186cdd6058324c8ec2bd7de91b91e781badc" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributed.isend&quot;&gt;&lt;code&gt;isend()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.irecv&quot;&gt;&lt;code&gt;irecv()&lt;/code&gt;&lt;/a&gt; return distributed request objects when used. In general, the type of this object is unspecified as they should never be created manually, but they are guaranteed to support two methods:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="005b7d57f3f85946d4635c13ceefa8d67528707a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; instance for the given &lt;code&gt;worker_name&lt;/code&gt; or &lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; of the current worker if &lt;code&gt;worker_name&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="634ca1533f427472501289938fa9cc9ec6d6ebe1" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; must be non-negative, finite and have a non-zero sum, and it will be normalized to sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="790bfbb285e9a82d198a60cf90867497c5526c1b" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributions.multinomial.Multinomial.log_prob&quot;&gt;&lt;code&gt;log_prob()&lt;/code&gt;&lt;/a&gt; allows different &lt;code&gt;total_count&lt;/code&gt; for each parameter and sample.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ec99e2269dffe6c5a6f85e02cb736b31cf7bd44" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributions.multinomial.Multinomial.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; must be non-negative, finite and have a non-zero sum, and it will be normalized to sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36930c3ef21ef2e73443ac2fd3bd085091c8ca0c" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributions.multinomial.Multinomial.sample&quot;&gt;&lt;code&gt;sample()&lt;/code&gt;&lt;/a&gt; requires a single shared &lt;code&gt;total_count&lt;/code&gt; for all parameters and samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cda3cae240cbeae6089e44586aa5f122f72a053b" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.distributions.one_hot_categorical.OneHotCategorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; must be non-negative, finite and have a non-zero sum, and it will be normalized to sum to 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b01e3129970e6ebd7c01a519d733c8aed3b94b9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.fft.hfft&quot;&gt;&lt;code&gt;hfft()&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt; are analogous to &lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;. The real FFT expects a real signal in the time-domain and gives a Hermitian symmetry in the frequency-domain. The Hermitian FFT is the opposite; Hermitian symmetric in the time-domain and real-valued in the frequency-domain. For this reason, special care needs to be taken with the length argument &lt;code&gt;n&lt;/code&gt;, in the same way as with &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a00dbdf4d18f236871216189027732ef96b6a53" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.imag&quot;&gt;&lt;code&gt;imag()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with complex dtypes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="838d9429e47c05a7cf049fdc7ddb2bbd05750bfd" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt; uses &lt;code&gt;pickle&lt;/code&gt; module implicitly, which is known to be insecure. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never load data that could have come from an untrusted source, or that could have been tampered with. &lt;strong&gt;Only load data you trust&lt;/strong&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39095ef92eddbe168196b9ce0fa85d6423ada2ce" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt; uses Python&amp;rsquo;s unpickling facilities but treats storages, which underlie tensors, specially. They are first deserialized on the CPU and are then moved to the device they were saved from. If this fails (e.g. because the run time system doesn&amp;rsquo;t have certain devices), an exception is raised. However, storages can be dynamically remapped to an alternative set of devices using the &lt;code&gt;map_location&lt;/code&gt; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f0ecbf12445b44261c3ee23c22c3c4273a2d495" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; calculates each combined value in the resulting large tensor by summing all values from all containing blocks. &lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; extracts the values in the local blocks by copying from the large tensor. So, if the blocks overlap, they are not inverses of each other.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cae4bb324f2d4ff47c9bed2f3e3dc0f4b855e484" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; are very similar, but have some subtle differences. &lt;a href=&quot;#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt; is applied on each channel of channeled data like multidimensional time series, but &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; is usually applied on entire sample and often in NLP tasks. Additionally, &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; applies elementwise affine transform, while &lt;a href=&quot;#torch.nn.InstanceNorm1d&quot;&gt;&lt;code&gt;InstanceNorm1d&lt;/code&gt;&lt;/a&gt; usually don&amp;rsquo;t apply affine transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="16cf8b96076ea1dd5cc5964731b3e7bdf7c64dcc" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; are very similar, but have some subtle differences. &lt;a href=&quot;#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt; is applied on each channel of channeled data like RGB images, but &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; is usually applied on entire sample and often in NLP tasks. Additionally, &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; applies elementwise affine transform, while &lt;a href=&quot;#torch.nn.InstanceNorm2d&quot;&gt;&lt;code&gt;InstanceNorm2d&lt;/code&gt;&lt;/a&gt; usually don&amp;rsquo;t apply affine transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b054b91f845bd7b3268445d94a88b9c9374c4c96" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; are very similar, but have some subtle differences. &lt;a href=&quot;#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt; is applied on each channel of channeled data like 3D models with RGB color, but &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; is usually applied on entire sample and often in NLP tasks. Additionally, &lt;a href=&quot;torch.nn.layernorm#torch.nn.LayerNorm&quot;&gt;&lt;code&gt;LayerNorm&lt;/code&gt;&lt;/a&gt; applies elementwise affine transform, while &lt;a href=&quot;#torch.nn.InstanceNorm3d&quot;&gt;&lt;code&gt;InstanceNorm3d&lt;/code&gt;&lt;/a&gt; usually don&amp;rsquo;t apply affine transform.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4158670ded8c67d16a97dc88881575b1677f548d" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.MaxUnpool1d&quot;&gt;&lt;code&gt;MaxUnpool1d&lt;/code&gt;&lt;/a&gt; takes in as input the output of &lt;a href=&quot;torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt; including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67207dd4b1839ddb79ee3ffd6c6e4a26b7f0ab09" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.MaxUnpool2d&quot;&gt;&lt;code&gt;MaxUnpool2d&lt;/code&gt;&lt;/a&gt; takes in as input the output of &lt;a href=&quot;torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt; including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ab32dc26574a8ce406b7f947e1e9e2e9ef4ffc4" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;ModuleDict&lt;/code&gt;&lt;/a&gt; can be indexed like a regular Python dictionary, but modules it contains are properly registered, and will be visible by all &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b97d37248da5b44f62bc6b875bc3445fd90433a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;ModuleDict&lt;/code&gt;&lt;/a&gt; is an &lt;strong&gt;ordered&lt;/strong&gt; dictionary that respects</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="19b8bb8954ab442f8aae8ee4930f1b6a6af2d331" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.ModuleList&quot;&gt;&lt;code&gt;ModuleList&lt;/code&gt;&lt;/a&gt; can be indexed like a regular Python list, but modules it contains are properly registered, and will be visible by all &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5eb2cf09e780ce154b0a442bd6a1434dabeccbfd" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt;&lt;code&gt;ParameterDict&lt;/code&gt;&lt;/a&gt; is an &lt;strong&gt;ordered&lt;/strong&gt; dictionary that respects</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd48c494f4d2fd55bbae08488f8743d2b1e1c246" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.ParameterList&quot;&gt;&lt;code&gt;ParameterList&lt;/code&gt;&lt;/a&gt; can be indexed like a regular Python list, but parameters it contains are properly registered, and will be visible by all &lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;Module&lt;/code&gt;&lt;/a&gt; methods.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5224908d5602e24b796c4468c8e056d98e90754e" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.data&quot;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/a&gt; can be on arbitrary device and of arbitrary dtype. &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.sorted_indices&quot;&gt;&lt;code&gt;sorted_indices&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.unsorted_indices&quot;&gt;&lt;code&gt;unsorted_indices&lt;/code&gt;&lt;/a&gt; must be &lt;code&gt;torch.int64&lt;/code&gt; tensors on the same device as &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.data&quot;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8554ca7eacbea2190d2017dcaeb07c7d0790de50" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero(..., as_tuple=False)&lt;/code&gt;&lt;/a&gt; (default) returns a 2-D tensor where each row is the index for a nonzero value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c810c9977b00316a9d2861af68e4f39107945e7" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.nonzero&quot;&gt;&lt;code&gt;torch.nonzero(..., as_tuple=True)&lt;/code&gt;&lt;/a&gt; returns a tuple of 1-D index tensors, allowing for advanced indexing, so &lt;code&gt;x[x.nonzero(as_tuple=True)]&lt;/code&gt; gives all nonzero values of tensor &lt;code&gt;x&lt;/code&gt;. Of the returned tuple, each index tensor contains nonzero indices for a certain dimension.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7266b03d21e2473fc934436202fe609a76d6b5e4" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer&lt;/code&gt;&lt;/a&gt; s also support specifying per-parameter options. To do this, instead of passing an iterable of &lt;code&gt;Variable&lt;/code&gt; s, pass in an iterable of &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/a&gt; s. Each of them will define a separate parameter group, and should contain a &lt;code&gt;params&lt;/code&gt; key, containing a list of parameters belonging to it. Other keys should match the keyword arguments accepted by the optimizers, and will be used as optimization options for this group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef043997c841f612a483abc356651c1dcf28c77a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.real&quot;&gt;&lt;code&gt;real()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with complex dtypes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f60a41defebaac85a211c4985930ae619cdd0d33" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt; always copies &lt;code&gt;data&lt;/code&gt;. If you have a Tensor &lt;code&gt;data&lt;/code&gt; and want to avoid a copy, use &lt;a href=&quot;../tensors#torch.Tensor.requires_grad_&quot;&gt;&lt;code&gt;torch.Tensor.requires_grad_()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../autograd#torch.Tensor.detach&quot;&gt;&lt;code&gt;torch.Tensor.detach()&lt;/code&gt;&lt;/a&gt;. If you have a NumPy &lt;code&gt;ndarray&lt;/code&gt; and want to avoid a copy, use &lt;a href=&quot;torch.as_tensor#torch.as_tensor&quot;&gt;&lt;code&gt;torch.as_tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9cb67824d9b80bbfe017515a973db4889a0c270" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.tensordot&quot;&gt;&lt;code&gt;tensordot&lt;/code&gt;&lt;/a&gt; implements a generalized matrix product.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17ebb1f74a610a562f578de9008e55a9a436f59f" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; by default constructs a index sampler that yields integral indices. To make it work with a map-style dataset with non-integral indices/keys, a custom sampler must be provided.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f94a4a63e93a9f59f0a53b0a65d68bd9d5625180" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; supports automatically collating individual fetched data samples into batches via arguments &lt;code&gt;batch_size&lt;/code&gt;, &lt;code&gt;drop_last&lt;/code&gt;, and &lt;code&gt;batch_sampler&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58863f9acf428e51584715fba34e916217e7f2da" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt;&lt;code&gt;torch.utils.data.get_worker_info()&lt;/code&gt;&lt;/a&gt; returns various useful information in a worker process (including the worker id, dataset replica, initial seed, etc.), and returns &lt;code&gt;None&lt;/code&gt; in main process. Users may use this function in dataset code and/or &lt;code&gt;worker_init_fn&lt;/code&gt; to individually configure each dataset replica, and to determine whether the code is running in a worker process. For example, this can be particularly helpful in sharding the dataset.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="119d5a3a8ffe7b291e2458654e88d99910f4bfc9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.view_as_complex&quot;&gt;&lt;code&gt;view_as_complex()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;&lt;code&gt;torch.float64&lt;/code&gt; and &lt;code&gt;torch.float32&lt;/code&gt;. The input is expected to have the last dimension of &lt;code&gt;size&lt;/code&gt; 2. In addition, the tensor must have a &lt;code&gt;stride&lt;/code&gt; of 1 for its last dimension. The strides of all other dimensions must be even numbers.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f10fc7199496e9a03f2d38002c40d3994f3f471" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;#torch.view_as_real&quot;&gt;&lt;code&gt;view_as_real()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with &lt;code&gt;complex dtypes&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="776c24edf1c927d9c626caad923d6fbf77fd01f4" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.imag#torch.imag&quot;&gt;&lt;code&gt;imag()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with complex dtypes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="440d94fc260dab72d82bbf568ac7dfdea41de8d4" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.fork#torch.jit.fork&quot;&gt;&lt;code&gt;fork&lt;/code&gt;&lt;/a&gt;(func, *args, **kwargs)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db63c0c633d83bd03b957f05499b8c7b4801f147" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;ignore&lt;/code&gt;&lt;/a&gt;([drop])</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;ignore&lt;/code&gt;&lt;/a&gt;([drop])</target>
        </trans-unit>
        <trans-unit id="f679250b706e74847b219f68b84d699ccfe1ff13" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.load#torch.jit.load&quot;&gt;&lt;code&gt;load&lt;/code&gt;&lt;/a&gt;(f[, map_location, _extra_files])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe1d01604809d322e6d8c61f4b096ca14b0945cf" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;save&lt;/code&gt;&lt;/a&gt;(m, f[, _extra_files])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b88733fcd74c4a36b1ca9cf6460426ccc41a4cf" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt;(obj[, optimize, _frames_up, _rcb])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fece4feaa7970a11354aebdced6573e04b229b15" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;()</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;()</target>
        </trans-unit>
        <trans-unit id="d64c464dbe946ddcda127fb546a0b370948774d9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.trace#torch.jit.trace&quot;&gt;&lt;code&gt;trace&lt;/code&gt;&lt;/a&gt;(func, example_inputs[, optimize, &amp;hellip;])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d09b4ed2c24906a9ee352eebf494720575394488" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.trace_module#torch.jit.trace_module&quot;&gt;&lt;code&gt;trace_module&lt;/code&gt;&lt;/a&gt;(mod, inputs[, optimize, &amp;hellip;])</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="74b11974ed0a96a8e63d97482484d979a40f240d" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;unused&lt;/code&gt;&lt;/a&gt;(fn)</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;unused&lt;/code&gt;&lt;/a&gt;(fn)</target>
        </trans-unit>
        <trans-unit id="611c1fb072d5efa56294e92931164a72f4ea16d6" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.jit.wait#torch.jit.wait&quot;&gt;&lt;code&gt;wait&lt;/code&gt;&lt;/a&gt;(future)</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.wait#torch.jit.wait&quot;&gt;&lt;code&gt;wait&lt;/code&gt;&lt;/a&gt;(future)</target>
        </trans-unit>
        <trans-unit id="1d0c07059114b6cb336ebc4f403775c89fbac420" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.real#torch.real&quot;&gt;&lt;code&gt;real()&lt;/code&gt;&lt;/a&gt; is only supported for tensors with complex dtypes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7b59fdb5cfe3ad0f926809a05d02cfe3c4bcfc" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt; always copies &lt;code&gt;data&lt;/code&gt;. If you have a Tensor &lt;code&gt;data&lt;/code&gt; and just want to change its &lt;code&gt;requires_grad&lt;/code&gt; flag, use &lt;a href=&quot;#torch.Tensor.requires_grad_&quot;&gt;&lt;code&gt;requires_grad_()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;autograd#torch.Tensor.detach&quot;&gt;&lt;code&gt;detach()&lt;/code&gt;&lt;/a&gt; to avoid a copy. If you have a numpy array and want to avoid a copy, use &lt;a href=&quot;generated/torch.as_tensor#torch.as_tensor&quot;&gt;&lt;code&gt;torch.as_tensor()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3ad5b2b3bac21a8d88c5867ae3bbc9eccf76fafc" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://arxiv.org/abs/1505.00853&quot;&gt;Empirical Evaluation of Rectified Activations in Convolutional Network&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="601f468d02159264fa9f35e208655533da9be9a0" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://arxiv.org/abs/1512.00567&quot;&gt;Inception&lt;/a&gt; v3</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99e72072a486f49bd4aa90c38d1b92e0e7d06054" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://arxiv.org/abs/1801.04381&quot;&gt;MobileNet&lt;/a&gt; v2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6db36a670ea9a83c019acd35728acc942dca10cf" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://arxiv.org/abs/1807.11164&quot;&gt;ShuffleNet&lt;/a&gt; v2</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="62f6bea682d075c9adafd82fab8635e018bf9f67" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://arxiv.org/abs/1905.02244&quot;&gt;Searching for MobileNetV3&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a14af82224be8139bfab1a689ffbaf678da4ea" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#IndexError&quot;&gt;&lt;strong&gt;IndexError&lt;/strong&gt;&lt;/a&gt; &amp;ndash; if &lt;code&gt;self.dim &amp;gt;= len(t.shape)&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d6aae2d9bcabb651dbf9e4723ad8aa47a255245" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#NotImplementedError&quot;&gt;&lt;strong&gt;NotImplementedError&lt;/strong&gt;&lt;/a&gt; &amp;ndash; If the distribution types have not been registered via &lt;a href=&quot;#torch.distributions.kl.register_kl&quot;&gt;&lt;code&gt;register_kl()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9ca48e7ec9e5ebe01fcf06e5fef11b659813ab6" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#TypeError&quot;&gt;&lt;strong&gt;TypeError&lt;/strong&gt;&lt;/a&gt; &amp;ndash; if &lt;code&gt;PRUNING_TYPE != 'unstructured'&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c36516eb463d675c60da1fe193b337fb665bb3c8" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;(&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;, &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0359294aa3ceda1907b98f7ca20f49a319fbdef7" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/typing.html#typing.Any&quot;&gt;&lt;code&gt;typing.Any&lt;/code&gt;&lt;/a&gt; is currently in development but not yet released</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8718ce478d54a1434bd98a2f2971d96b076ce6af" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://docs.python.org/3/library/typing.html#typing.overload&quot;&gt;&lt;code&gt;typing.overload&lt;/code&gt;&lt;/a&gt; is currently in development but not yet released</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b56fefec7d4309d91a5656987c7aca2e9e352da" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback-Leibler_divergence&quot;&gt;Kullback-Leibler divergence&lt;/a&gt; is a useful distance measure for continuous distributions and is often useful when performing direct regression over the space of (discretely sampled) continuous output distributions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26ff290a5f33ee20860367d13ee98b7f7d39fec7" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-semantics&quot;&gt;CUDA semantics&lt;/a&gt; has more details about working with CUDA.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9cf4befe8fe895b98cc3a782ef371a47e7f7a973" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.bernoulli_&quot;&gt;&lt;code&gt;torch.Tensor.bernoulli_()&lt;/code&gt;&lt;/a&gt; - in-place version of &lt;a href=&quot;generated/torch.bernoulli#torch.bernoulli&quot;&gt;&lt;code&gt;torch.bernoulli()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5d79c8da790ab70c9b03c67b064080d93def436" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.cauchy_&quot;&gt;&lt;code&gt;torch.Tensor.cauchy_()&lt;/code&gt;&lt;/a&gt; - numbers drawn from the Cauchy distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b63d7cc373d882de1fa81d8e476e5e4b383cd873" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.exponential_&quot;&gt;&lt;code&gt;torch.Tensor.exponential_()&lt;/code&gt;&lt;/a&gt; - numbers drawn from the exponential distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e8d4fd35dc80bafed0620cfb9605afe07720d9f5" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.geometric_&quot;&gt;&lt;code&gt;torch.Tensor.geometric_()&lt;/code&gt;&lt;/a&gt; - elements drawn from the geometric distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c2f4410bc90bb53461ebaa9f0f26288619cf33a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.log_normal_&quot;&gt;&lt;code&gt;torch.Tensor.log_normal_()&lt;/code&gt;&lt;/a&gt; - samples from the log-normal distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="533e7b60a576da243b4010d04a0e8925f1e6872f" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.normal_&quot;&gt;&lt;code&gt;torch.Tensor.normal_()&lt;/code&gt;&lt;/a&gt; - in-place version of &lt;a href=&quot;generated/torch.normal#torch.normal&quot;&gt;&lt;code&gt;torch.normal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab43ce05db4cea3c4a0000c9007208cb5dcf31b7" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.random_&quot;&gt;&lt;code&gt;torch.Tensor.random_()&lt;/code&gt;&lt;/a&gt; - numbers sampled from the discrete uniform distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cc9fb3a69319048614670b4bed7b38380462feec" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;tensors#torch.Tensor.uniform_&quot;&gt;&lt;code&gt;torch.Tensor.uniform_()&lt;/code&gt;&lt;/a&gt; - numbers sampled from the continuous uniform distribution</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98f8e918225b273e7e14dd2ea3afad4a215ca6dc" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.bincount#torch.bincount&quot;&gt;&lt;code&gt;torch.bincount()&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4b55416084060dbfc7b6ef8302350c037295cd5c" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.bmm#torch.bmm&quot;&gt;&lt;code&gt;torch.bmm()&lt;/code&gt;&lt;/a&gt; when called on sparse-dense CUDA tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f23f1576296daffc3e2ac3d7559da3f1350428b9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.diagflat#torch.diagflat&quot;&gt;&lt;code&gt;torch.diagflat()&lt;/code&gt;&lt;/a&gt; always constructs a tensor with diagonal elements specified by the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bc06fc28ba4ede16c07f9dab0ab7421042dec9c" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;torch.diagonal()&lt;/code&gt;&lt;/a&gt; always returns the diagonal of its input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be055886621930beeac010b07aae1af642349065" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.fmod#torch.fmod&quot;&gt;&lt;code&gt;torch.fmod()&lt;/code&gt;&lt;/a&gt;, which computes the element-wise remainder of division equivalently to the C library function &lt;code&gt;fmod()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b89a6a8c32c2897c817f870da0431140f43c1605" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.histc#torch.histc&quot;&gt;&lt;code&gt;torch.histc()&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df4e127f27b61a982a530dab63e012a1918caf94" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.index_select#torch.index_select&quot;&gt;&lt;code&gt;torch.index_select()&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4f1d514b00f95b94c2656a92aeebd2a4e318927" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.adaptiveavgpool2d#torch.nn.AdaptiveAvgPool2d&quot;&gt;&lt;code&gt;torch.nn.AdaptiveAvgPool2d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584d4ef98a3e00460494963ecfa9b8be9bbc18e5" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.adaptiveavgpool3d#torch.nn.AdaptiveAvgPool3d&quot;&gt;&lt;code&gt;torch.nn.AdaptiveAvgPool3d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e92d7ab7e2996b4bf2fa5040d867c903b694bd3" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.adaptivemaxpool2d#torch.nn.AdaptiveMaxPool2d&quot;&gt;&lt;code&gt;torch.nn.AdaptiveMaxPool2d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a628a485101d210665d67b97311c73003b21d617" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.avgpool3d#torch.nn.AvgPool3d&quot;&gt;&lt;code&gt;torch.nn.AvgPool3d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c51fd69eee1eedc62f6980f0e1a28026cf329a1a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;torch.nn.Conv1d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e95d7ff45101f9a7207c96d9b25e072d6edd097d" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6be683a84f4953f3de5081248674cbe641a1bc76" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;torch.nn.Conv3d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c52485bd39e492d55aba4727dc60f9e16c78e230" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.convtranspose1d#torch.nn.ConvTranspose1d&quot;&gt;&lt;code&gt;torch.nn.ConvTranspose1d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51c62cc12fd6bfaa7061e5c0e30b4f32c591d3e9" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.convtranspose2d#torch.nn.ConvTranspose2d&quot;&gt;&lt;code&gt;torch.nn.ConvTranspose2d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e437b95b8e9417bcacdb20e63f21363ee507267b" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.convtranspose3d#torch.nn.ConvTranspose3d&quot;&gt;&lt;code&gt;torch.nn.ConvTranspose3d&lt;/code&gt;&lt;/a&gt; when called on CUDA tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8e8a260f578ac55407f58d11dec2c01cf557995e" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.ctcloss#torch.nn.CTCLoss&quot;&gt;&lt;code&gt;torch.nn.CTCLoss&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a4b108d106773c32b74a91b061f9c360ff08ec2" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.embeddingbag#torch.nn.EmbeddingBag&quot;&gt;&lt;code&gt;torch.nn.EmbeddingBag&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6527e2047df66247cfcd21195abe361e1739bbe3" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.fold#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; calculates each combined value in the resulting large tensor by summing all values from all containing blocks. &lt;a href=&quot;#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; extracts the values in the local blocks by copying from the large tensor. So, if the blocks overlap, they are not inverses of each other.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82a6fe983b346384016395ca0ad2ca9fd4724414" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.fractionalmaxpool2d#torch.nn.FractionalMaxPool2d&quot;&gt;&lt;code&gt;torch.nn.FractionalMaxPool2d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e721edc4d5b6f5ec43671c634c91f63e7c4d669" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt; can map several input sizes to the same output sizes. Hence, the inversion process can get ambiguous. To accommodate this, you can provide the needed output size as an additional argument &lt;code&gt;output_size&lt;/code&gt; in the forward call. See the Inputs and Example below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9c616e5295d3832a0de049925bba0be0593c3d2c" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool1d#torch.nn.MaxPool1d&quot;&gt;&lt;code&gt;MaxPool1d&lt;/code&gt;&lt;/a&gt; is not fully invertible, since the non-maximal values are lost.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbec9408268a4c7f950b7583dfb180d67db2a333" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt; can map several input sizes to the same output sizes. Hence, the inversion process can get ambiguous. To accommodate this, you can provide the needed output size as an additional argument &lt;code&gt;output_size&lt;/code&gt; in the forward call. See the Inputs and Example below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b24ae84d46ff76499dc9ccb0868add1c43bdbd9b" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool2d#torch.nn.MaxPool2d&quot;&gt;&lt;code&gt;MaxPool2d&lt;/code&gt;&lt;/a&gt; is not fully invertible, since the non-maximal values are lost.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4623da97fc3622bc5243bc8aa968bd48712ec6ea" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt; can map several input sizes to the same output sizes. Hence, the inversion process can get ambiguous. To accommodate this, you can provide the needed output size as an additional argument &lt;code&gt;output_size&lt;/code&gt; in the forward call. See the Inputs section below.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="772dc863d0403d02c74b2dd5bdd7da68a2a6974b" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt; is not fully invertible, since the non-maximal values are lost. &lt;a href=&quot;#torch.nn.MaxUnpool3d&quot;&gt;&lt;code&gt;MaxUnpool3d&lt;/code&gt;&lt;/a&gt; takes in as input the output of &lt;a href=&quot;torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;MaxPool3d&lt;/code&gt;&lt;/a&gt; including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fce82c27557c0fb4d9138799b2fb76b27b414426" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.maxpool3d#torch.nn.MaxPool3d&quot;&gt;&lt;code&gt;torch.nn.MaxPool3d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4fd141d306183af718423056c326ac85ae6fc547" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.nllloss#torch.nn.NLLLoss&quot;&gt;&lt;code&gt;torch.nn.NLLLoss&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577dbb9dcb7b6afc56db00880af5edaa43341631" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.reflectionpad1d#torch.nn.ReflectionPad1d&quot;&gt;&lt;code&gt;torch.nn.ReflectionPad1d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6547db7d372badbb40b629ea6825dcf5161b9c5a" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.reflectionpad2d#torch.nn.ReflectionPad2d&quot;&gt;&lt;code&gt;torch.nn.ReflectionPad2d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="954d85ddc938bdc9618e6d3309eb6a8a84b96747" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.replicationpad1d#torch.nn.ReplicationPad1d&quot;&gt;&lt;code&gt;torch.nn.ReplicationPad1d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cde94baada0cfecd330dc07bea7de12673a32f54" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.replicationpad2d#torch.nn.ReplicationPad2d&quot;&gt;&lt;code&gt;torch.nn.ReplicationPad2d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="92723be63aa35de179b24758cf8031a309b17221" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.nn.replicationpad3d#torch.nn.ReplicationPad3d&quot;&gt;&lt;code&gt;torch.nn.ReplicationPad3d&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ed8c429cbfdd96f07b0cc27321fc4dfa5844f464" translate="yes" xml:space="preserve">
          <source>&lt;a href=&quot;torch.repeat_interleave#torch.repeat_interleave&quot;&gt;&lt;code&gt;torch.repeat_interleave()&lt;/code&gt;&lt;/a&gt; when called on a CUDA tensor that requires grad</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0248ec1d401c9570e46adb2b77b82b90c7293ba2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;_growth_tracker&quot;&lt;/code&gt; - a Python int containing the number of recent consecutive unskipped steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6e90fc96cd3a30ba8855a8ccd4810ba258eb324" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;active.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: number of active memory blocks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d111d3a1ae860d6f3168c8b703cb3877915e4c7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;active_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: amount of active memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f8612e4a740af0888b3214b77f28fe3dad31dde" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;allocated.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: number of allocation requests received by the memory allocator.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a84c1ac847d390fccfec49f3b4ef3ab4ff1f8fa1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;allocated_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: amount of allocated memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d70188079ebeee376599ba39541c2c4204a880e2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;backoff_factor&quot;&lt;/code&gt; - a Python float containing the current backoff factor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0c5bf45712ae3fbb1c2e03474115ba0ac770d4e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;backward&quot;&lt;/code&gt; - no normalization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef6e7642caa8cdee8842ad92f01825e95aba7085" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;backward&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/n&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e468f09672a825b96d2164f58f0529720faac7ec" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;forward&quot;&lt;/code&gt; - no normalization</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eef6192194cc919b101e1a2ca733ec9e36dd811c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;forward&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/n&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d43bcc80c0b10846a0f9069b2e8ad9d2a9f0548" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;growth_factor&quot;&lt;/code&gt; - a Python float containing the current growth factor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c456fa5a42b5f1ffb059a990c3943cb4a5a1060b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;growth_interval&quot;&lt;/code&gt; - a Python int containing the current growth interval</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b6f320b9c1d66e120f3eeed4629515a82daca8f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;inactive_split.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: number of inactive, non-releasable memory blocks.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be7c6644d1e1bffd4761e84f6ae66f8c81eb07ed" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;inactive_split_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: amount of inactive, non-releasable memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15464bf5459f391b3e5ba1cb6e7bd444244af498" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;num_alloc_retries&quot;&lt;/code&gt;: number of failed &lt;code&gt;cudaMalloc&lt;/code&gt; calls that result in a cache flush and retry.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9dc4d6812ff718c2f490f3be671102e9611b7f83" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;num_ooms&quot;&lt;/code&gt;: number of out-of-memory errors thrown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc442e5c5df049b7d9cdc82bc762e9a20f6e97e3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;ortho&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/sqrt(n)&lt;/code&gt; (making the FFT orthonormal)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e3ccb556a8ab10bc20abe0583ef8beb7e0f60d0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;ortho&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/sqrt(n)&lt;/code&gt; (making the Hermitian FFT orthonormal)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2bb9eeccfc1d3902dcf006a95645ae4d8dba7d3c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;ortho&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/sqrt(n)&lt;/code&gt; (making the IFFT orthonormal)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd50a3feb45dcffa1005f9591700e218f2876c33" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;ortho&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/sqrt(n)&lt;/code&gt; (making the real FFT orthonormal)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e875512b00f7c28d9ecf06d8e31ccde053789758" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;ortho&quot;&lt;/code&gt; - normalize by &lt;code&gt;1/sqrt(n)&lt;/code&gt; (making the real IFFT orthonormal)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79dce7eb5c704090746c25a26482eeb79a677dcc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;reserved_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: amount of reserved memory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="788fd95a19e00fddd4d83cfe75d6b9330aeaa8c7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;scale&quot;&lt;/code&gt; - a Python float containing the current scale</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3faa8952431ced973b2ca4d4723cf09e8b40dda" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;&quot;segment.{all,large_pool,small_pool}.{current,peak,allocated,freed}&quot;&lt;/code&gt;: number of reserved segments from &lt;code&gt;cudaMalloc()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d4f38f3c3aadc9d6519f71c7bef51eeafb90b32" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;# test.py:9:10&lt;/code&gt; is the location in the original source file that generated this instruction. In this case, it is a file named &lt;code&gt;test.py&lt;/code&gt;, on line 9, and at character 10.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96c7f04b9fdc53cdbeeec808e3f809d643533f7b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;$TORCH_HOME/hub&lt;/code&gt;, if environment variable &lt;code&gt;TORCH_HOME&lt;/code&gt; is set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0639a59c49172f3275d60a3cf3ae2c71c2e17515" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;$XDG_CACHE_HOME/torch/hub&lt;/code&gt;, if environment variable &lt;code&gt;XDG_CACHE_HOME&lt;/code&gt; is set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9de75e162f4ef5c70403bccbe2584b9c7c90a68" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;%rv.1 : Tensor&lt;/code&gt; means we assign the output to a (unique) value named &lt;code&gt;rv.1&lt;/code&gt;, that value is of &lt;code&gt;Tensor&lt;/code&gt; type and that we do not know its concrete shape.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b611d0d87e1d9b2c049fe410e3628203bf689280" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; are forwarded to &lt;code&gt;optimizer.step()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="da7d5229a9f2d85e666041f2f6f94b560f2b53cb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;iK&lt;/code&gt; - input Tensor arguments.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1271f8308bdcd4990d963bb58443e53aaa99f98b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;AveragedModel&lt;/code&gt; class serves to compute the weights of the SWA model. You can create an averaged model by running:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6eb23d2c7d6f97150c57bf77bc38a6a5e21a5729" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;B&lt;/code&gt; is batch size. It is equal to the number of elements in &lt;code&gt;sequences&lt;/code&gt;. &lt;code&gt;T&lt;/code&gt; is length of the longest sequence. &lt;code&gt;L&lt;/code&gt; is length of the sequence. &lt;code&gt;*&lt;/code&gt; is any number of trailing dimensions, including none.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9ae44da45be84352cd48b70ad10106981502d20" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;DistributedDataParallel&lt;/code&gt; is proven to be significantly faster than &lt;a href=&quot;torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel&lt;/code&gt;&lt;/a&gt; for single-node multi-GPU data parallel training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4a602f28d6bef14b1221a7bbf9605d421f172c84" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;E&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;S&lt;/code&gt;, &lt;code&gt;R&lt;/code&gt; - iteration Tensor variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc31ddaf1e11bfef604f1511ea09f753a59c38fc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;L&lt;/code&gt;, &lt;code&gt;U&lt;/code&gt;, and &lt;code&gt;P&lt;/code&gt; can be derived using &lt;a href=&quot;torch.lu_unpack#torch.lu_unpack&quot;&gt;&lt;code&gt;torch.lu_unpack()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6dcb21d17e740012a201f3f64a93f87660becb12" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;LU&lt;/code&gt; contains &lt;code&gt;L&lt;/code&gt; and &lt;code&gt;U&lt;/code&gt; factors for LU factorization of &lt;code&gt;A&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebe26c141e8f093b473e3df24326c98f5e7a7e34" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;MASTER_ADDR&lt;/code&gt; - required (except for rank 0); address of rank 0 node</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ebf3c021bd393dec6d7da99964fd87e35068711" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;MASTER_PORT&lt;/code&gt; - required; has to be a free port on machine with rank 0</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="450c7fbb8bc62302eddb1613fed158b7be1f2450" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NamedTuple&lt;/code&gt; with &lt;code&gt;missing_keys&lt;/code&gt; and &lt;code&gt;unexpected_keys&lt;/code&gt; fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="be2e2fceda5619162a905f5973167bc8cc863df2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;NamedTuple&lt;/code&gt; with &lt;code&gt;output&lt;/code&gt; and &lt;code&gt;loss&lt;/code&gt; fields</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c32382e378ee20f4586221621243cfa5916f7c45" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;RANK&lt;/code&gt; - required; can be set either here, or in a call to init function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c003f2b072b0c834948a06d8cb5c45a93e4e4364" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ScriptModule``s wrap a C++ ``torch::jit::Module&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0a4eb14d9d23caeb63642035cd2698337656fb38" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;ScriptModule``s wrap a C++ ``torch::jit::Module&lt;/code&gt;. &lt;code&gt;ScriptModule``s
contain methods, attributes, parameters, and
constants. These can be accessed the same as on a normal ``nn.Module&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11b877b4caf86c459dccd2983ec018fa62fd03a8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Training&lt;/code&gt; argument in export API allows users to export models in a training-friendly mode. &lt;code&gt;TrainingMode.TRAINING&lt;/code&gt; exports model in a training-friendly mode that avoids certain model optimizations which might interfere with model parameter training. &lt;code&gt;TrainingMode.PRESERVE&lt;/code&gt; exports the model in inference mode if &lt;code&gt;model.training&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. Otherwise, it exports the model in a training-friendly mode. The default mode for this argument is &lt;code&gt;TrainingMode.EVAL&lt;/code&gt; which exports the model in inference mode.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f46721fdbd9785a05c6dbcd33341589a062d1f4c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;True&lt;/code&gt; if two tensors have the same size and elements, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c6fdb73d0977394f7b7b936a911f6ae1642033a5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;Variable(tensor)&lt;/code&gt; and &lt;code&gt;Variable(tensor, requires_grad)&lt;/code&gt; still work as expected, but they return Tensors instead of Variables.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f16d88cb83c6efadb3d7832531decef276e34d95" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;WORLD_SIZE&lt;/code&gt; - required; can be set either here, or in a call to init function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="70f05621464dd4fd6de4528a2a2c202320f2cb16" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;__init__(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.__init__&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4c76cbdc91a00dc35ee348b7759e1a43e21ee18" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;__matmul__&lt;/code&gt;, &lt;code&gt;addbmm&lt;/code&gt;, &lt;code&gt;addmm&lt;/code&gt;, &lt;code&gt;addmv&lt;/code&gt;, &lt;code&gt;addr&lt;/code&gt;, &lt;code&gt;baddbmm&lt;/code&gt;, &lt;code&gt;bmm&lt;/code&gt;, &lt;code&gt;chain_matmul&lt;/code&gt;, &lt;code&gt;conv1d&lt;/code&gt;, &lt;code&gt;conv2d&lt;/code&gt;, &lt;code&gt;conv3d&lt;/code&gt;, &lt;code&gt;conv_transpose1d&lt;/code&gt;, &lt;code&gt;conv_transpose2d&lt;/code&gt;, &lt;code&gt;conv_transpose3d&lt;/code&gt;, &lt;code&gt;GRUCell&lt;/code&gt;, &lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;LSTMCell&lt;/code&gt;, &lt;code&gt;matmul&lt;/code&gt;, &lt;code&gt;mm&lt;/code&gt;, &lt;code&gt;mv&lt;/code&gt;, &lt;code&gt;prelu&lt;/code&gt;, &lt;code&gt;RNNCell&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="043fba3b61be96d14fcea05937254d31656b61cc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;__pow__&lt;/code&gt;, &lt;code&gt;__rdiv__&lt;/code&gt;, &lt;code&gt;__rpow__&lt;/code&gt;, &lt;code&gt;__rtruediv__&lt;/code&gt;, &lt;code&gt;acos&lt;/code&gt;, &lt;code&gt;asin&lt;/code&gt;, &lt;code&gt;binary_cross_entropy_with_logits&lt;/code&gt;, &lt;code&gt;cosh&lt;/code&gt;, &lt;code&gt;cosine_embedding_loss&lt;/code&gt;, &lt;code&gt;cdist&lt;/code&gt;, &lt;code&gt;cosine_similarity&lt;/code&gt;, &lt;code&gt;cross_entropy&lt;/code&gt;, &lt;code&gt;cumprod&lt;/code&gt;, &lt;code&gt;cumsum&lt;/code&gt;, &lt;code&gt;dist&lt;/code&gt;, &lt;code&gt;erfinv&lt;/code&gt;, &lt;code&gt;exp&lt;/code&gt;, &lt;code&gt;expm1&lt;/code&gt;, &lt;code&gt;gelu&lt;/code&gt;, &lt;code&gt;group_norm&lt;/code&gt;, &lt;code&gt;hinge_embedding_loss&lt;/code&gt;, &lt;code&gt;kl_div&lt;/code&gt;, &lt;code&gt;l1_loss&lt;/code&gt;, &lt;code&gt;layer_norm&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;, &lt;code&gt;log_softmax&lt;/code&gt;, &lt;code&gt;log10&lt;/code&gt;, &lt;code&gt;log1p&lt;/code&gt;, &lt;code&gt;log2&lt;/code&gt;, &lt;code&gt;margin_ranking_loss&lt;/code&gt;, &lt;code&gt;mse_loss&lt;/code&gt;, &lt;code&gt;multilabel_margin_loss&lt;/code&gt;, &lt;code&gt;multi_margin_loss&lt;/code&gt;, &lt;code&gt;nll_loss&lt;/code&gt;, &lt;code&gt;norm&lt;/code&gt;, &lt;code&gt;normalize&lt;/code&gt;, &lt;code&gt;pdist&lt;/code&gt;, &lt;code&gt;poisson_nll_loss&lt;/code&gt;, &lt;code&gt;pow&lt;/code&gt;, &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;reciprocal&lt;/code&gt;, &lt;code&gt;rsqrt&lt;/code&gt;, &lt;code&gt;sinh&lt;/code&gt;, &lt;code&gt;smooth_l1_loss&lt;/code&gt;, &lt;code&gt;soft_margin_loss&lt;/code&gt;, &lt;code&gt;softmax&lt;/code&gt;, &lt;code&gt;softmin&lt;/code&gt;, &lt;code&gt;softplus&lt;/code&gt;, &lt;code&gt;sum&lt;/code&gt;, &lt;code&gt;renorm&lt;/code&gt;, &lt;code&gt;tan&lt;/code&gt;, &lt;code&gt;triplet_margin_loss&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9813c8c3a1bd58dfdfb29c4919a02be2e473ead" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;abstract compute_mask(t, default_mask)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.compute_mask&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66cb9bb3d32fd2ef26446e7bf26b435e1e3561f0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_audio(tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_audio&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db9102f49daf01e544d57df2247e77377b555dc3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_custom_scalars(layout)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_custom_scalars&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;add_custom_scalars(layout)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_custom_scalars&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e5111f5e2f5cf3dde197c5e96a2fcdf93456234f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_embedding&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c0d2b72dc71b6e1159a0cb1b283989d93c1af7f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_figure(tag, figure, global_step=None, close=True, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_figure&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="14feaae7a0aeff009ca9b7f48a42a75e117b0214" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_graph(model, input_to_model=None, verbose=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_graph&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="249155841c0e40b1a9ffbba2c464d395d3dc3ed4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_histogram&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ee36b184f1756bed6bb0f6f6726e7c67066c6c4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_hparams(hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_hparams&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c7de0b1454359ab1c51256d7a28160d5f54569b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_image&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea7e0257800c70201e599638dd8632d9d32d5de7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_images(tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_images&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6c0ef4317422aee596b32383f035cf007e2c5fc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_mesh(tag, vertices, colors=None, faces=None, config_dict=None, global_step=None, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_mesh&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="823148e3946dbb7fed25b7cda817bd5de3755c32" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_module(name: str, module: Optional[Module]) &amp;rarr; None&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.add_module&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="384b1ade4fd79723895b1a088b5cd0aa470cb112" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_param_group(param_group)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/optim/optimizer.html#Optimizer.add_param_group&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;add_param_group(param_group)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/optim/optimizer.html#Optimizer.add_param_group&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fa59f9a23ec919df9616aed8b04725acb325c58c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_pr_curve&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9bc8c43f4640a4b73beb699695913eba404b926" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_pruning_method(method)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#PruningContainer.add_pruning_method&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;add_pruning_method(method)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#PruningContainer.add_pruning_method&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="da1fef3c18062afbc3f24d1c0b7242b3931ee14e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_scalar(tag, scalar_value, global_step=None, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_scalar&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5aa3b1ad24b33ea8f41f06656f035ec33ad5b02e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_scalars&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae7e6b8a41be0e41ab50462e93de9e6a0b23c87d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_text(tag, text_string, global_step=None, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_text&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8adcf623e5c9be30d269698714643f30d4a0d12e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;add_video(tag, vid_tensor, global_step=None, fps=4, walltime=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_video&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cabbf98933b72f75c0f36c1b95ce7d2ddd482db" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;addcdiv&lt;/code&gt;, &lt;code&gt;addcmul&lt;/code&gt;, &lt;code&gt;atan2&lt;/code&gt;, &lt;code&gt;bilinear&lt;/code&gt;, &lt;code&gt;cat&lt;/code&gt;, &lt;code&gt;cross&lt;/code&gt;, &lt;code&gt;dot&lt;/code&gt;, &lt;code&gt;equal&lt;/code&gt;, &lt;code&gt;index_put&lt;/code&gt;, &lt;code&gt;stack&lt;/code&gt;, &lt;code&gt;tensordot&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c95b492426617e7ae546227f90f5e2fa1c1a4e9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;align_to(*names)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.align_to&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;align_to(*names)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.align_to&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cc55d64778e952605afd4c05848b59b6df0a3c2c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;all&lt;/code&gt;: combined statistics across all memory pools.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e0725138f22e5fdaa4b81d3519715d6c6938aa1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;all_to_all&lt;/code&gt; is a &lt;strong&gt;Prototype&lt;/strong&gt; function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1fa4bd9466522cc6d680e99bd01e89d5f437498e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;all_to_all&lt;/code&gt; is experimental and subject to change.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a024feedc4e6a36f6b9abd61d093cc7a622c2ffd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;allocated&lt;/code&gt;: historical total increase in this metric.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1a54bd126d79760ccda150f44d86d8fa1fc5fbf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; are scaling factors on matrix-vector product between &lt;code&gt;mat1&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt; and the added matrix &lt;code&gt;input&lt;/code&gt; respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d8a6c72fc4293957507efd3107b27872c6b0a70e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; are scaling factors on matrix-vector product between &lt;code&gt;mat&lt;/code&gt; and &lt;code&gt;vec&lt;/code&gt; and the added tensor &lt;code&gt;input&lt;/code&gt; respectively.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea5cc9dd66ae9f683d6dfa9533c7dbe35e6bcfd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;amax&lt;/code&gt;/&lt;code&gt;amin&lt;/code&gt; does not return indices,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc4c97581545b6a70990b09a09b7e5989df8fc87" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;amax&lt;/code&gt;/&lt;code&gt;amin&lt;/code&gt; evenly distributes gradient between equal values, while &lt;code&gt;max(dim)&lt;/code&gt;/&lt;code&gt;min(dim)&lt;/code&gt; propagates gradient only to a single index in the source tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbb454bbfcf98b32a97145b7b6fb858f58ca2bad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;amax&lt;/code&gt;/&lt;code&gt;amin&lt;/code&gt; supports reducing on multiple dimensions,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e14f35517f904145fe7169b7396b2e859c195c71" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;append(module: torch.nn.modules.module.Module) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleList.append&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="642d37f7fb0ee9832dd835d053060d3e063576f6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;append(parameter: Parameter) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterList.append&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="644cd43f152b23d22fec75e447e9f07c605e8b32" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;apply(fn: Callable[Module, None]) &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.apply&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cf6019c0b63df55c59383619c93bb653ae2c7ab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;apply_mask(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.apply_mask&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;apply_mask(module)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/utils/prune.html#BasePruningMethod.apply_mask&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0a3785922aa2fd3f4d4fca77fba8d6833f4c164e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;args&lt;/code&gt; and &lt;code&gt;kwargs&lt;/code&gt; are passed along to the real callable function.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdc63f7bf864aaaa131a689e9b1931efaac4d4ba" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;aten::zeros&lt;/code&gt; is the operator (equivalent to &lt;code&gt;torch.zeros&lt;/code&gt;) and the input list &lt;code&gt;(%4, %6, %6, %10, %12)&lt;/code&gt; specifies which values in scope should be passed as inputs. The schema for built-in functions like &lt;code&gt;aten::zeros&lt;/code&gt; can be found at &lt;a href=&quot;#builtin-functions&quot;&gt;Builtin Functions&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ad400dd2d8bbc754cde70e0be0a32c467d1020e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;autocast(enabled=False)&lt;/code&gt; subregions can be nested in autocast-enabled regions. Locally disabling autocast can be useful, for example, if you want to force a subregion to run in a particular &lt;code&gt;dtype&lt;/code&gt;. Disabling autocast gives you explicit control over the execution type. In the subregion, inputs from the surrounding region should be cast to &lt;code&gt;dtype&lt;/code&gt; before use:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d78a1d8a579fca92214881bf79cabd53ccfa7466" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;backward(gradient=None, retain_graph=None, create_graph=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/tensor.html#Tensor.backward&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3571941e1a6ce4aadab905a323a834f8151105d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt; must be 3-D tensors each containing the same number of matrices.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f9e3556fc8bb2cc0570864c9b6896c140f37a42" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;bfloat16() &amp;rarr; T&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.bfloat16&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cebe238cfb08becc903d230fbe5d24e0fe0c426b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;biject_to(constraint)&lt;/code&gt; looks up a bijective &lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt;&lt;code&gt;Transform&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;constraints.real&lt;/code&gt; to the given &lt;code&gt;constraint&lt;/code&gt;. The returned transform is guaranteed to have &lt;code&gt;.bijective = True&lt;/code&gt; and should implement &lt;code&gt;.log_abs_det_jacobian()&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e2d6a5ed7d506528920e77070497348c1ce08b4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;buffers(recurse: bool = True) &amp;rarr; Iterator[torch.Tensor]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.buffers&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cdbf002599a2a56ef1be89aa11973db7fa4939fb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/cauchy.html#Cauchy.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/cauchy.html#Cauchy.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a6b1a6ff683ea706e847531dec661595b3c4f9fe" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/continuous_bernoulli.html#ContinuousBernoulli.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/continuous_bernoulli.html#ContinuousBernoulli.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5f7a435d63b5074d363d44d59163bde927f1cecf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/distribution.html#Distribution.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/distribution.html#Distribution.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6902bf014dd07e3b481f4f5b550c91dcea805a65" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/exponential.html#Exponential.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/exponential.html#Exponential.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d490098d7a1d2b718451b2c8024d3ee813538d78" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_cauchy.html#HalfCauchy.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_cauchy.html#HalfCauchy.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d8edaf8fee3b82759d0bcd5ac196efac3ee1ff85" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_normal.html#HalfNormal.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_normal.html#HalfNormal.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b9ab2ef9b98f35a4e8dc3fe94d4d37666e34b108" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/laplace.html#Laplace.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/laplace.html#Laplace.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7d36f6f16d95f5633432a067aa0ee58d44d30da8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/normal.html#Normal.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/normal.html#Normal.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7d55d8cb3f2da57f674f22dad10cbbc1db941685" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="655b2dfb98ed3fb370a40fdf0d4dbaf4cf020ffd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/uniform.html#Uniform.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/uniform.html#Uniform.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5d7435f243e537fe4e9a1f44f5f2978ec3de9a2b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;cdf(x)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/mixture_same_family.html#MixtureSameFamily.cdf&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;cdf(x)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/mixture_same_family.html#MixtureSameFamily.cdf&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6f01a52826837c605b1ddcb5da3e87a450da0d14" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;check(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/constraints.html#Constraint.check&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;check(value)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/constraints.html#Constraint.check&quot;&gt;[source]&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6c2b0a9c6e6279c2eaacce0cb636a38535067dad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;children() &amp;rarr; Iterator[torch.nn.modules.module.Module]&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module.children&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29984cef8d152dd336e413150efa35c933326002" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.FloatStorage&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch.html#FloatStorage&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b36dbc3c11d88faa25a3f8b65106a74dc73767" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.Function&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/function.html#Function&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39cf725d79128cc559c32bea6326956c8fc9d2c1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.detect_anomaly&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/anomaly_mode.html#detect_anomaly&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0e26002d8f6552b35889a27c758cbb773776e7a1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.enable_grad&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/grad_mode.html#enable_grad&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58f27e9d24028778f84ab01c863eac24bae4d702" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.function._ContextMethodMixin&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/function.html#_ContextMethodMixin&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db232b6af788ed25a96e56ac375ac5e8dc6e96a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.no_grad&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/grad_mode.html#no_grad&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88f7860772f9598bf1216bca88739525162e7d06" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.profiler.emit_nvtx(enabled=True, record_shapes=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/profiler.html#emit_nvtx&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c94f0eb2f969c96f6d3e780f6736e00f60ddbdae" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.profiler.profile(enabled=True, use_cuda=False, record_shapes=False, profile_memory=False, with_stack=False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/profiler.html#profile&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a83d7fb220b25e7c5b5c46a3f5fab0651f91f156" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.set_detect_anomaly(mode: bool)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/anomaly_mode.html#set_detect_anomaly&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94fc7591b7a248933a9b222ae3d7a0be8785d9f6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.autograd.set_grad_enabled(mode: bool)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/grad_mode.html#set_grad_enabled&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0e9f21769c78110379c1d95c96214b038438007" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.Event&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda/streams.html#Event&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae68fd369ca11b1f011b50550e9028cfaedd599" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.Stream&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda/streams.html#Stream&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0d64b322012b395768e134767a14f0233f5faf08" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.amp.GradScaler(init_scale=65536.0, growth_factor=2.0, backoff_factor=0.5, growth_interval=2000, enabled=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda/amp/grad_scaler.html#GradScaler&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2071395987ecfd9cbef23ac42c26e125997f3a4d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.amp.autocast(enabled=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda/amp/autocast_mode.html#autocast&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1b465e752a114b8d7033e000f3119836d17af98" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.device(device)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda.html#device&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5a77db6008cbb32c5232b284cb91671ec8663d7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.cuda.device_of(obj)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/cuda.html#device_of&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a90a317ee29ee9577cb492a421b75369d7aab04" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.Backend&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#Backend&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="147ae10887cbb88a85291c537b9be2820a123ddb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.autograd.context&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/autograd.html#context&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37b369aa58ffe7ea70d10f5f81b83db6cdadbf62" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.optim.DistributedOptimizer(optimizer_class, params_rref, *args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/optim/optimizer.html#DistributedOptimizer&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="935b68f16cb672cc347918a331f1e7192e6d74af" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.reduce_op&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/distributed_c10d.html#reduce_op&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf20bcbc4d535795d32b9c4fddc3546a48eb8499" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.rpc.RRef&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/api.html#RRef&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac44743bde1d334833a049b34ebccc902b3cbdae" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributed.rpc.TensorPipeRpcBackendOptions(*, num_worker_threads: int = 16, rpc_timeout: float = 60.0, init_method: str = 'env://', _transports: List = None, _channels: List = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributed/rpc/options.html#TensorPipeRpcBackendOptions&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="efd100500a9c79798da47acf6386ac1220610a61" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/bernoulli.html#Bernoulli&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2aeb5895b8c36f341fe579aeb6fe4393695ea0c7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/beta.html#Beta&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b1b1cbbaf8a80df008543ba52f6f54628c5bddb7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/binomial.html#Binomial&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d811c9279b3fd446b67b16f5ec25c4fd462c65a2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/categorical.html#Categorical&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dbefa17225154b47ac7ee92132cf7fa71e46339f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/cauchy.html#Cauchy&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6d59525037de9a227be3a23a59b82321cc58e7e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.chi2.Chi2(df, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/chi2.html#Chi2&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d0b2d72f19d799206f71143c385edb83ffadbdad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.constraint_registry.ConstraintRegistry&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/constraint_registry.html#ConstraintRegistry&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4d4dfa38fccbd646345095d60561798f73593454" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.constraints.Constraint&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/constraints.html#Constraint&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1c886b444bad9cbce01f3b6e3f873ad4c85f1f1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.continuous_bernoulli.ContinuousBernoulli(probs=None, logits=None, lims=(0.499, 0.501), validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/continuous_bernoulli.html#ContinuousBernoulli&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85776bf962a4a57460c06c01ea4a6bf692af3e8f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/dirichlet.html#Dirichlet&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3d29e40792754f6c8cfe52b84af46aa1ec60f16c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.distribution.Distribution(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/distribution.html#Distribution&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f256c550343e65fa7aeaa5202573e6a1476ffb7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/exp_family.html#ExponentialFamily&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5898cdc9b98e9ea0553bbab179ac3ff748b7a521" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.exponential.Exponential(rate, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/exponential.html#Exponential&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32eb783d2965b43b93a0eb7075349a1e33be760f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/fishersnedecor.html#FisherSnedecor&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f14f8c1525cf5be313981ceb0e76e5b59cf398eb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/gamma.html#Gamma&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0c89b994a13ead6783375196a008cc3f7635e29" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/geometric.html#Geometric&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="975aa82bf81052d976e47d825f5f03abbd0fa985" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/gumbel.html#Gumbel&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="94f2ddc623408268a8c2ad3354b5e390521f36ad" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_cauchy.html#HalfCauchy&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8223c1a5b889dd9267bbf8238a230c464932ea2c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.half_normal.HalfNormal(scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/half_normal.html#HalfNormal&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4d64d5567d1b7caf1ecb46445b55f454f622a09" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/independent.html#Independent&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0a0113721701d03e625ecfe49dc7d4cd79de064" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.laplace.Laplace(loc, scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/laplace.html#Laplace&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c018e1484a302f9cf451c7347d67cac793ac16ae" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/log_normal.html#LogNormal&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1433b2e0b907220650158907787398d9959f03a2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/lowrank_multivariate_normal.html#LowRankMultivariateNormal&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="989055e294c8d83a3e4c9a9e0c1f152c3be1edd9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.mixture_same_family.MixtureSameFamily(mixture_distribution, component_distribution, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/mixture_same_family.html#MixtureSameFamily&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="337200b637e0541351faa30bc1c5404f0b42fc53" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/multinomial.html#Multinomial&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8389740c3ad99250d715163a801e11da1e1b390d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/multivariate_normal.html#MultivariateNormal&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e6a742f1636ea295c5880a57ca287ac1b2df469" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/negative_binomial.html#NegativeBinomial&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7127efa199dd3d7c112b1cf341529a57279f0783" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.normal.Normal(loc, scale, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/normal.html#Normal&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="059abd7934f84fa51516de61b771fb2d927553b7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="00ce1fa0628e77b34ef14851a0cce3b4ab04891e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/pareto.html#Pareto&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="07daa454ec7003f1ffa03c0120b6659f2c02708e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.poisson.Poisson(rate, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/poisson.html#Poisson&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc2aba33cd0ad8e23e871bdd97fd866ce04c7413" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/relaxed_bernoulli.html#LogitRelaxedBernoulli&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52ddfee246ce5d3354deec891b2188b14055cbe6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/relaxed_bernoulli.html#RelaxedBernoulli&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ad3dc79fafcf554b9bb175dc2e3eb0a5ebf32be" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/relaxed_categorical.html#RelaxedOneHotCategorical&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e6317ab2914c135093c03044f192e759159d941e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/studentT.html#StudentT&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f37317c8458eda270e9d6f2fd7e474a209cd679d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transformed_distribution.html#TransformedDistribution&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f85b1b6d53d649f83e72edc188f1cb590cf37ab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.AbsTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#AbsTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="450ece7d8ba17749d7e2870e7df380c37df7598e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#AffineTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8f61827f1951327f07688bab3f2abca2fb34ddb1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.CatTransform(tseq, dim=0, lengths=None, cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#CatTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f65484baa1ee92dbf8790b661c268168125c403f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.ComposeTransform(parts, cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#ComposeTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261d322e6163a3a32ccb436554770439402a0a25" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.ExpTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#ExpTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c3458614faf2f27502a6a313005d87701809be1" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#LowerCholeskyTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d45c4fec47f663918bf12faca0df4253d6c0252" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.PowerTransform(exponent, cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#PowerTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a57526fe255c01a01bd422a18364a85d67f1176" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.SigmoidTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#SigmoidTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="840d7f4736d018aa9bc1dea5c3e00b9181e92164" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.SoftmaxTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#SoftmaxTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cfe0f4f590ff1ad9fafcdcb69602bc896699ebf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.StackTransform(tseq, dim=0, cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#StackTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="86fd387a0593944129dd93cc9afbd0be0b2f9ca4" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.StickBreakingTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#StickBreakingTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dc82d5f2e1f649fa08da3a0d862fa4d0b8f03c5c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.TanhTransform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#TanhTransform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6fb1d371b327d68424753b52a7fffc1be642c06" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.transforms.Transform(cache_size=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/transforms.html#Transform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1841275f93c121879cc736e923b7eb24c1ba74c5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.uniform.Uniform(low, high, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/uniform.html#Uniform&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="163877605a779c787e247914106997b155090c9f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.von_mises.VonMises(loc, concentration, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/von_mises.html#VonMises&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e1ee0c29019d92d8fd46d94183150c6e0c22f4ef" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/distributions/weibull.html#Weibull&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b919ab18c4cec838f5d4d304e6567049cd6ec7e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.enable_grad&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/autograd/grad_mode.html#enable_grad&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30ce4352c80f971522d5f16eb1a3de9c4c0f1da2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.jit.ScriptModule&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/jit/_script.html#ScriptModule&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f45470abc1fd87f7be48cb24fc3e47be08b620c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.multiprocessing.SpawnContext&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/multiprocessing/spawn.html#SpawnContext&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="073ab9bfa5d693cd3579f9dffa71e79ed4cd3257" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveAvgPool1d(output_size: Union[T, Tuple[T, ...]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93653d8b6522ae7d2292bb855c309bb5d49edf5e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveAvgPool2d(output_size: Union[T, Tuple[T, ...]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a1fbea26cbda353592aedf5072dec72760b5b698" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveAvgPool3d(output_size: Union[T, Tuple[T, ...]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85af7854d85e9a2ccf0fa0911c3530f1e87a978d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveLogSoftmaxWithLoss(in_features: int, n_classes: int, cutoffs: Sequence[int], div_value: float = 4.0, head_bias: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb09bd13ecec52f1907c442a7236e7a1b21e54cf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveMaxPool1d(output_size: Union[T, Tuple[T, ...]], return_indices: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fd2af7381bb0b5f789815e725c7f8ef1806f232" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveMaxPool2d(output_size: Union[T, Tuple[T, ...]], return_indices: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9eca80f92b23edb1f89e42f49b98cfa3f9dce7f9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AdaptiveMaxPool3d(output_size: Union[T, Tuple[T, ...]], return_indices: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="133cd844a040047aa678718ba123a3dc94dadd71" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AlphaDropout(p: float = 0.5, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/dropout.html#AlphaDropout&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c42ccb6515be1bd17d1604c9751e9eebfc0b2061" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AvgPool1d(kernel_size: Union[T, Tuple[T]], stride: Union[T, Tuple[T]] = None, padding: Union[T, Tuple[T]] = 0, ceil_mode: bool = False, count_include_pad: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AvgPool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e5e0924b249284dd2bb798cf9916c8a9dfd72be5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AvgPool2d(kernel_size: Union[T, Tuple[T, T]], stride: Optional[Union[T, Tuple[T, T]]] = None, padding: Union[T, Tuple[T, T]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: bool = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AvgPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="85b8d26d8a55699727bdf69b406894c0edddfdb8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.AvgPool3d(kernel_size: Union[T, Tuple[T, T, T]], stride: Optional[Union[T, Tuple[T, T, T]]] = None, padding: Union[T, Tuple[T, T, T]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#AvgPool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfaade03d37c078db607e8da2b8d5a5d594e1baa" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.BCELoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#BCELoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad4e525bc5f13e1ac04c3bfcdf035efc0ef57dc3" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.BCEWithLogitsLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#BCEWithLogitsLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4cf81cfcd1704cc279d113145d4df4d011923600" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/batchnorm.html#BatchNorm1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e98bddfdb57a233aceb8fd6d2c188841bf9dfbb6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1dbae6b05f5348f5cb695c721edf8b20bed23063" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/batchnorm.html#BatchNorm3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90be40fcee326ebe5f1216f4b93e0a654b943c8b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Bilinear(in1_features: int, in2_features: int, out_features: int, bias: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/linear.html#Bilinear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="061ce19e5cbef7716d2fc55d0a3ea38fa76be1ab" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.CELU(alpha: float = 1.0, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#CELU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b172086162d6a62ebc3a52231dc321f8f677c5ee" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.CTCLoss(blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#CTCLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="694076712bb17e9e4a0a91233d91180ec05eeaa2" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConstantPad1d(padding: Union[T, Tuple[T, T]], value: float)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ConstantPad1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c61b762c1afcc48c83fc61278f77b3a415e984d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConstantPad2d(padding: Union[T, Tuple[T, T, T, T]], value: float)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ConstantPad2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="535a7a45a734f6d1972326b3d7b352315ec958bd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConstantPad3d(padding: Union[T, Tuple[T, T, T, T, T, T]], value: float)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ConstantPad3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e374bb5f75e1750e5cf0e7d7928bf106376dd52d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T]], stride: Union[T, Tuple[T]] = 1, padding: Union[T, Tuple[T]] = 0, dilation: Union[T, Tuple[T]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#Conv1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5edca55a022b53e28acefc73c4829c1a6222029f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T, T]], stride: Union[T, Tuple[T, T]] = 1, padding: Union[T, Tuple[T, T]] = 0, dilation: Union[T, Tuple[T, T]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#Conv2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1ca94611e13f5ef07d623871763711f7b8a6e40f" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T, T, T]], stride: Union[T, Tuple[T, T, T]] = 1, padding: Union[T, Tuple[T, T, T]] = 0, dilation: Union[T, Tuple[T, T, T]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#Conv3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d40f5191371e79dfa6475683bbc83358d81cb21" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T]], stride: Union[T, Tuple[T]] = 1, padding: Union[T, Tuple[T]] = 0, output_padding: Union[T, Tuple[T]] = 0, groups: int = 1, bias: bool = True, dilation: Union[T, Tuple[T]] = 1, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#ConvTranspose1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccc12b9fbeb65b3a7eb6f7f80394177e1831f532" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConvTranspose2d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T, T]], stride: Union[T, Tuple[T, T]] = 1, padding: Union[T, Tuple[T, T]] = 0, output_padding: Union[T, Tuple[T, T]] = 0, groups: int = 1, bias: bool = True, dilation: int = 1, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#ConvTranspose2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c71a2face6d187d80bd10983ef6ab7b2416071d9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ConvTranspose3d(in_channels: int, out_channels: int, kernel_size: Union[T, Tuple[T, T, T]], stride: Union[T, Tuple[T, T, T]] = 1, padding: Union[T, Tuple[T, T, T]] = 0, output_padding: Union[T, Tuple[T, T, T]] = 0, groups: int = 1, bias: bool = True, dilation: Union[T, Tuple[T, T, T]] = 1, padding_mode: str = 'zeros')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/conv.html#ConvTranspose3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5cdb2235bfa99d606e407f37b442f59df2cac791" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.CosineEmbeddingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#CosineEmbeddingLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="49184eb924a570d1dc7ace4e987f2597c0d2f299" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.CosineSimilarity(dim: int = 1, eps: float = 1e-08)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/distance.html#CosineSimilarity&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8451be4413c6ead165dae00751cafd557e25f481" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.CrossEntropyLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#CrossEntropyLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b9f2b9c4e6d5989858d42b934ba05c280ea9a9bf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/parallel/data_parallel.html#DataParallel&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58ef6a6509bdb9ec339493eb66430a783b3ddb37" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Dropout(p: float = 0.5, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/dropout.html#Dropout&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f67f2842d345ee750a3662109691c8973768e30b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Dropout2d(p: float = 0.5, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/dropout.html#Dropout2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="966e3431dc3def254cf2ef4e050fe7e3b988c432" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Dropout3d(p: float = 0.5, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/dropout.html#Dropout3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ac2a6f852a83dc0e67e5e263c30c4ba6812a964" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ELU(alpha: float = 1.0, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#ELU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1b350b51cc2f1485c9d28b85ec2fd9016c470c6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/sparse.html#Embedding&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9202738d6025eb71713d852db6410c61e0b49b68" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/sparse.html#EmbeddingBag&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="27ebc2e7465fedf01159c61b9d3edcc84f2e3018" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Flatten(start_dim: int = 1, end_dim: int = -1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/flatten.html#Flatten&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f146dfc7f1b3152c6add6d7d616a31c5942810a7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Fold(output_size: Union[T, Tuple[T, ...]], kernel_size: Union[T, Tuple[T, ...]], dilation: Union[T, Tuple[T, ...]] = 1, padding: Union[T, Tuple[T, ...]] = 0, stride: Union[T, Tuple[T, ...]] = 1)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/fold.html#Fold&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3600a0c3d30f93faac683f7292f8adc5dbfb431" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.FractionalMaxPool2d(kernel_size: Union[T, Tuple[T, T]], output_size: Optional[Union[T, Tuple[T, T]]] = None, output_ratio: Optional[Union[T, Tuple[T, T]]] = None, return_indices: bool = False, _random_samples=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#FractionalMaxPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9f3b24a4a3eb913d57414062265e467c95f8219" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.GELU&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#GELU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="75bfac6b9581492ff0cd675e63c778d260b1e1dd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.GRU(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#GRU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9768c448b67f4f25666c0f52c91476f9025bd5ee" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.GRUCell(input_size: int, hidden_size: int, bias: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#GRUCell&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78af5a56e72746004ce568915cbacb7a35c4bc64" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/normalization.html#GroupNorm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="46684cc157380e803cb700bfcf78beb65ecaa7e8" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Hardshrink(lambd: float = 0.5)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Hardshrink&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c77fe3ef39845e7ee1cb0ac15c94ff899f94775" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Hardsigmoid(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Hardsigmoid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60465477e31887d9a0b0f36355ecf8aa4bc76c22" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Hardswish(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Hardswish&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b14c71195c750bcf6765c41469cda7ef3de70ff" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Hardtanh(min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False, min_value: Optional[float] = None, max_value: Optional[float] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Hardtanh&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="de51d3a91f00ea88f7c5a81112969d3c01fb3481" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.HingeEmbeddingLoss(margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#HingeEmbeddingLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea58d0c5017a4dedd29bc8da0c8ee2cbe20466a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Identity(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/linear.html#Identity&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d49a85217995e350e0cd7a646ce55f34cac1205" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.InstanceNorm1d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/instancenorm.html#InstanceNorm1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db586e6da9764c27a41ccd911bfc817f3752e580" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.InstanceNorm2d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/instancenorm.html#InstanceNorm2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66208f944b685c4f77f6e621fc5c4424bfa23d38" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.InstanceNorm3d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/instancenorm.html#InstanceNorm3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1347bda922a421f391cb098f964a6c9c73833530" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#KLDivLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10c8f6bd6d1c3137fa50bc97a421cbfa95616e24" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.L1Loss(size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#L1Loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9677789a0ece166cde0db5d919c95c1d4fff3a6e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LPPool1d(norm_type: float, kernel_size: Union[T, Tuple[T, ...]], stride: Optional[Union[T, Tuple[T, ...]]] = None, ceil_mode: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#LPPool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f2b616de2f0a9b7847f7fdba19072da821bc0d7" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LPPool2d(norm_type: float, kernel_size: Union[T, Tuple[T, ...]], stride: Optional[Union[T, Tuple[T, ...]]] = None, ceil_mode: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#LPPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="270fcdf0c2dfe61233a2a01fed4217367556ce04" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LSTM(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#LSTM&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="092d59df042389204133ebe7c7bbe0e792d9f1a5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LSTMCell(input_size: int, hidden_size: int, bias: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#LSTMCell&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ac28f701569cecdd6b99ff5421b69e5542a774e5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/normalization.html#LayerNorm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29757ae631cea55f74e07402238f147f921491cd" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LeakyReLU(negative_slope: float = 0.01, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#LeakyReLU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58facce15c84501e7669627b7fcfc820b258c4b0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Linear(in_features: int, out_features: int, bias: bool = True)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/linear.html#Linear&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="131f0f764699d4940e00e61e9950116c64ce8aea" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LocalResponseNorm(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/normalization.html#LocalResponseNorm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="119ba5c8291ae016f96a66955614b7365982a1da" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LogSigmoid&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#LogSigmoid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1cb43628d7079ad630fa2d235490456a8b3b3957" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.LogSoftmax(dim: Optional[int] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#LogSoftmax&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a53a3beff84dfff211e4b5185cb49700443f0cf5" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MSELoss(size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#MSELoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="712fff45005ea62e8836c7f4bcabda9d53ae2eb0" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MarginRankingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#MarginRankingLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b5232a1d73273a88cdfceb315bde13cae02d3508" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxPool1d(kernel_size: Union[T, Tuple[T, ...]], stride: Optional[Union[T, Tuple[T, ...]]] = None, padding: Union[T, Tuple[T, ...]] = 0, dilation: Union[T, Tuple[T, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxPool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57e1ac3fa595094e7f9e447f57c864d791c889d6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxPool2d(kernel_size: Union[T, Tuple[T, ...]], stride: Optional[Union[T, Tuple[T, ...]]] = None, padding: Union[T, Tuple[T, ...]] = 0, dilation: Union[T, Tuple[T, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxPool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3c4261d0cf0f9beca45f5a92413578449a5e7c41" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxPool3d(kernel_size: Union[T, Tuple[T, ...]], stride: Optional[Union[T, Tuple[T, ...]]] = None, padding: Union[T, Tuple[T, ...]] = 0, dilation: Union[T, Tuple[T, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxPool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eaac7065030263c55631c662b183ccacf8ae7107" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxUnpool1d(kernel_size: Union[T, Tuple[T]], stride: Optional[Union[T, Tuple[T]]] = None, padding: Union[T, Tuple[T]] = 0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxUnpool1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4d0b181e653bf5dce3f0cb8c952370c1ea64f6d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxUnpool2d(kernel_size: Union[T, Tuple[T, T]], stride: Optional[Union[T, Tuple[T, T]]] = None, padding: Union[T, Tuple[T, T]] = 0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxUnpool2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad6476150987dfaf6e0204135334ddc1a4a3f91d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MaxUnpool3d(kernel_size: Union[T, Tuple[T, T, T]], stride: Optional[Union[T, Tuple[T, T, T]]] = None, padding: Union[T, Tuple[T, T, T]] = 0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pooling.html#MaxUnpool3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d60fa5c2e0ddc4da40f444a2bcd1c57da1dfc8ac" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Module&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/module.html#Module&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4341c600afe81b1a24c60562fafc9aaf16b1491c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ModuleDict(modules: Optional[Mapping[str, torch.nn.modules.module.Module]] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleDict&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d37e706b3ea2c418074e5b90281f3a0cca312741" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ModuleList&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf7ab0657c3c233330dba1ae2a544fb708809f93" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#MultiLabelMarginLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32c545f8db6daf2c7c8308beaf599010eebdfdaf" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#MultiLabelSoftMarginLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a476a7128875e4e0100667b40907e1f9fadc2637" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MultiMarginLoss(p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#MultiMarginLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="882b24c366e3d658b7e044fea4b73dc306af3146" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#MultiheadAttention&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45bb26889ac6bd9626771bdd699e57a9473051cb" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.NLLLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#NLLLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6bd6280b0a20de4878cc50c7c058a6e0581cd7ce" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.PReLU(num_parameters: int = 1, init: float = 0.25)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#PReLU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="24506e432652281896cde9cbe82ecfca523f7b55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.PairwiseDistance(p: float = 2.0, eps: float = 1e-06, keepdim: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/distance.html#PairwiseDistance&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6c1d422fd213a7806885a43076b8adac240c4181" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ParameterDict(parameters: Optional[Mapping[str, Parameter]] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterDict&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c02db37f008f23733a1ccbe103e29969cba381ee" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ParameterList(parameters: Optional[Iterable[Parameter]] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#ParameterList&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f820a404bf3078e5a5ff7b6e43751779ff275305" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.PixelShuffle(upscale_factor: int)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/pixelshuffle.html#PixelShuffle&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f11d86fcd9bde5ccfee0f855ca67a7a5a0a6ed9b" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#PoissonNLLLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="879b067eab3057db9d86d67efaaef006531a0615" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.RNN(*args, **kwargs)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#RNN&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4c863f6a28879f88f03313aef9dda16339e5b07e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.RNNBase(mode: str, input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#RNNBase&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="995c179fcc9cc6a5edfd349ea4a86c9687ee1fb6" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/rnn.html#RNNCell&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3bed690e5977d6bfcee5f3c28387245487c7a07a" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.RReLU(lower: float = 0.125, upper: float = 0.3333333333333333, inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#RReLU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec4a9a4f39de3bff9e40af43cfe63574d6610227" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReLU(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#ReLU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e3900720f834a2ef3634e0bcbe15a5d1f8612134" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReLU6(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#ReLU6&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="effef701c99ae23ad629d33abf170d47693cfd28" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReflectionPad1d(padding: Union[T, Tuple[T, T]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ReflectionPad1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db4b3666ec22eab766cece0696dcadb641806589" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReflectionPad2d(padding: Union[T, Tuple[T, T, T, T]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ReflectionPad2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c8c7829255f77582b64f1b1807ec0a298fae294" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReplicationPad1d(padding: Union[T, Tuple[T, T]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ReplicationPad1d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="684ede6c6ac65074a27346f69ec637958409aa55" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReplicationPad2d(padding: Union[T, Tuple[T, T, T, T]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ReplicationPad2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a27d5219b29189aea8759cbc92590cfeeb7a614" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.ReplicationPad3d(padding: Union[T, Tuple[T, T, T, T, T, T]])&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/padding.html#ReplicationPad3d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66cd1ac7d33154262fda78c5c37a028d1d31308e" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.SELU(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#SELU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eca0be4dc5e041ac904a9aa283287cbaa83de453" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Sequential(*args: Any)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/container.html#Sequential&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2a16032c93ecdec2ad82e9455ddb6080a0a3575" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.SiLU(inplace: bool = False)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#SiLU&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9caa54b17d3d046589f695c7591a5d3bb6776377" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Sigmoid&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Sigmoid&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bb1f939c94ee1b55835614a2ba6a3d55d470b650" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#SmoothL1Loss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51ea0fea37c2fda03586a59377a486de869d133d" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction: str = 'mean')&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/loss.html#SoftMarginLoss&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e05599202aab7ddb2b93bf0fa7ab9e06fb281536" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softmax(dim: Optional[int] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softmax&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e37781e53caf4a949c3371ce22c8ac9b2af0e54" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softmax2d&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softmax2d&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a926c36cef157bf0e8a85d0ccd5c5a94721fe03" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softmin(dim: Optional[int] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softmin&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df7a77484dcf23555e082769a166f40be6e5da94" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softplus(beta: int = 1, threshold: int = 20)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softplus&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e40bd8ded15b8189134cb6247d2bcc2643f59bc" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softshrink(lambd: float = 0.5)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softshrink&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b7498c7155d8060382895f4760011983e1a4fa9" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Softsign&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Softsign&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9202688c9f48a32f8a3d0d9c31bf64bb9b7ad59c" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.SyncBatchNorm(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = True, track_running_stats: bool = True, process_group: Optional[Any] = None)&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/batchnorm.html#SyncBatchNorm&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e543d350b6ce6e04d949da4117be597c2e896c49" translate="yes" xml:space="preserve">
          <source>&lt;code&gt;class torch.nn.Tanh&lt;/code&gt;&lt;a href=&quot;https://pytorch.org/docs/1.7.0/_modules/torch/nn/modules/activation.html#Tanh&quot;&gt;[source]&lt;/a&gt;</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
