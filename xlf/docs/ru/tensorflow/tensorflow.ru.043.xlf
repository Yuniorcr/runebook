<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ru" datatype="htmlbody" original="tensorflow">
    <body>
      <group id="tensorflow">
        <trans-unit id="587ea8c1cdf68f3aaebe6d4c8fb0dc04c9f49662" translate="yes" xml:space="preserve">
          <source>User-written layers and models can achieve the same behavior with code that looks like:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7076897558f527fd7b476c32a2d7999a7bce1794" translate="yes" xml:space="preserve">
          <source>Users can call this method to get some facts of the TPU system, like total number of cores, number of TPU workers and the devices. E.g.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="67147ed6d1d38b4f4b015cf112ec870c25df3f0b" translate="yes" xml:space="preserve">
          <source>Users can pass strategy specific options to &lt;code&gt;options&lt;/code&gt; argument. An example to enable bucketizing dynamic shapes in &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy#run&quot;&gt;&lt;code&gt;TPUStrategy.run&lt;/code&gt;&lt;/a&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f72b22db9ab4d4d8bbc6f80831bcd32ed79c81e6" translate="yes" xml:space="preserve">
          <source>Users can specify various options to control the behavior of snapshot, including how snapshots are read from and written to by passing in user-defined functions to the &lt;code&gt;reader_func&lt;/code&gt; and &lt;code&gt;shard_func&lt;/code&gt; parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="157f011efb63e43996c3b578c255e7d5545ba313" translate="yes" xml:space="preserve">
          <source>Users can write it to file for offline analysis by tfprof commandline or graphical interface.</source>
          <target state="translated">Пользователи могут записать его в файл для оффлайн-анализа с помощью командной строки tfprof или графического интерфейса.</target>
        </trans-unit>
        <trans-unit id="e5a32aab95198164a5ff787e69d28cbf95af2893" translate="yes" xml:space="preserve">
          <source>Users may want specify this function to control how snapshot files should be read from disk, including the amount of shuffling and parallelism.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6748ccb2ebd37a27cc38d08c0979684dcbf55e30" translate="yes" xml:space="preserve">
          <source>Users may want to specify this function to control how snapshot files should be written to disk. Below is an example of how a potential shard_func could be written.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7108f46888ed24215d4773b328e7e496d911304" translate="yes" xml:space="preserve">
          <source>Users may write the following code to asynchronuously invoke &lt;code&gt;train_step_fn&lt;/code&gt; and log the &lt;code&gt;loss&lt;/code&gt; metric for every &lt;code&gt;num_steps&lt;/code&gt; steps in a training loop. &lt;code&gt;train_step_fn&lt;/code&gt; internally consumes data using &lt;code&gt;iterator.get_next()&lt;/code&gt;, and may throw OutOfRangeError when running out of data. In the case:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0ec32691eaba97311f1cccd2dad97641a499fa1" translate="yes" xml:space="preserve">
          <source>Users must not modify any collections used in nest while this function is running.</source>
          <target state="translated">Пользователи не должны изменять никакие коллекции,используемые в гнезде,во время работы этой функции.</target>
        </trans-unit>
        <trans-unit id="06b0870bd9d2eea911ba0bf24a44afc23e3b6358" translate="yes" xml:space="preserve">
          <source>Users need to combine parsing spec of features with labels and weights (if any) since they are all parsed from same tf.Example instance. This utility combines these specs.</source>
          <target state="translated">Пользователи должны сочетать спецификацию анализатора функций с метками и весами (если таковые имеются),так как все они анализируются из одного и того же экземпляра tf.Example.Эта утилита сочетает в себе эти характеристики.</target>
        </trans-unit>
        <trans-unit id="182c1f1a391ebf26b9c0b763f027f3059f9e6bd2" translate="yes" xml:space="preserve">
          <source>Users of &lt;code&gt;step_fn&lt;/code&gt; may perform &lt;code&gt;run()&lt;/code&gt; calls without running hooks by accessing the &lt;code&gt;session&lt;/code&gt;. A &lt;code&gt;run()&lt;/code&gt; call with hooks may be performed using &lt;code&gt;run_with_hooks()&lt;/code&gt;. Computation flow can be interrupted using &lt;code&gt;request_stop()&lt;/code&gt;.</source>
          <target state="translated">Пользователи &lt;code&gt;step_fn&lt;/code&gt; могут выполнять вызовы &lt;code&gt;run()&lt;/code&gt; без запуска хуков, обращаясь к &lt;code&gt;session&lt;/code&gt; . &lt;code&gt;run()&lt;/code&gt; вызов с крючками может быть выполнен с использованием &lt;code&gt;run_with_hooks()&lt;/code&gt; . Поток вычислений можно прервать с помощью &lt;code&gt;request_stop()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2f188fa1f43efe8bdab97db20fb68ecadd592af6" translate="yes" xml:space="preserve">
          <source>Users will just instantiate a layer and then treat it as a callable.</source>
          <target state="translated">Пользователи просто инстанцируют слой,а затем относятся к нему как к вызываемому.</target>
        </trans-unit>
        <trans-unit id="c72c8f3ece626a4705405cb3a7b8af47ef729815" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy&lt;/code&gt; loss average over classes and weighted sum over the batch. Namely, if the input logits have shape &lt;code&gt;[batch_size, n_classes]&lt;/code&gt;, the loss is the average over &lt;code&gt;n_classes&lt;/code&gt; and the weighted sum over &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">Использует &lt;code&gt;sigmoid_cross_entropy&lt;/code&gt; потерь sigmoid_cross_entropy по классам и взвешенную сумму по партии. А именно, если входные логиты имеют форму &lt;code&gt;[batch_size, n_classes]&lt;/code&gt; , потеря - это среднее значение для &lt;code&gt;n_classes&lt;/code&gt; и взвешенная сумма для &lt;code&gt;batch_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="11a9b701f656adfafd6806eb9e7ef756d209ed2e" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss, which is the same as &lt;code&gt;BinaryClassHead&lt;/code&gt;. The differences compared to &lt;code&gt;BinaryClassHead&lt;/code&gt; are:</source>
          <target state="translated">Использует потерю &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; , что аналогично &lt;code&gt;BinaryClassHead&lt;/code&gt; . Отличия от &lt;code&gt;BinaryClassHead&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="3d8209fd0815d68d4830b41bd06d14a5cb947aa2" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; loss.</source>
          <target state="translated">Использует потерю &lt;code&gt;sigmoid_cross_entropy_with_logits&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e004400a6e3754313301e3fd9261a2c189b3474a" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;sparse_softmax_cross_entropy&lt;/code&gt; loss.</source>
          <target state="translated">Использует &lt;code&gt;sparse_softmax_cross_entropy&lt;/code&gt; loss.</target>
        </trans-unit>
        <trans-unit id="3e2b61f4b530febb6503deed927b41c373ddaaf3" translate="yes" xml:space="preserve">
          <source>Uses &lt;code&gt;str(value)&lt;/code&gt;, except for &lt;code&gt;bytes&lt;/code&gt; typed inputs, which are converted using &lt;code&gt;as_str&lt;/code&gt;.</source>
          <target state="translated">Использует &lt;code&gt;str(value)&lt;/code&gt; , за исключением вводимых &lt;code&gt;bytes&lt;/code&gt; , которые конвертируются с использованием &lt;code&gt;as_str&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="2973e6aa554e21daa4adef06a74539c445b14d95" translate="yes" xml:space="preserve">
          <source>Uses utf-8 encoding for text by default.</source>
          <target state="translated">По умолчанию используется кодировка utf-8 для текста.</target>
        </trans-unit>
        <trans-unit id="217a51c3037aab24f119676b38ba458afe249401" translate="yes" xml:space="preserve">
          <source>Using &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt;&lt;/a&gt; for sparse multiplication:</source>
          <target state="translated">Использование &lt;a href=&quot;../nn/embedding_lookup_sparse&quot;&gt; &lt;code&gt;tf.nn.embedding_lookup_sparse&lt;/code&gt; &lt;/a&gt; для разреженного умножения:</target>
        </trans-unit>
        <trans-unit id="159ac66854831fd41477c6614f26e3ff55888f88" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt; with same shape as &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="translated">Использование &lt;code&gt;pos&lt;/code&gt; и &lt;code&gt;len&lt;/code&gt; с той же формой, что и &lt;code&gt;input&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="20acdd8f39a8fcbb172a5237734f68ee0d2be386" translate="yes" xml:space="preserve">
          <source>Using float64 is similar to mixed precision. Either the global policy can be set to float64, or &lt;code&gt;dtype='float64'&lt;/code&gt; can be passed to individual layers. For example, to set the global policy:</source>
          <target state="translated">Использование float64 похоже на смешанную точность. Либо глобальная политика может быть установлена ​​на float64, либо &lt;code&gt;dtype='float64'&lt;/code&gt; может быть передана отдельным слоям. Например, чтобы установить глобальную политику:</target>
        </trans-unit>
        <trans-unit id="f6b2bb4ba02dab533aac4565623cbaf2d9684521" translate="yes" xml:space="preserve">
          <source>Using graphs directly (deprecated)</source>
          <target state="translated">Непосредственное использование графиков (устаревших)</target>
        </trans-unit>
        <trans-unit id="45c1897ccbe225e4b4bb0b5776304a91ccc424dd" translate="yes" xml:space="preserve">
          <source>Using scalar &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;len&lt;/code&gt;:</source>
          <target state="translated">Используя скалярные &lt;code&gt;pos&lt;/code&gt; и &lt;code&gt;len&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="55be0948f7db3ef4c4e1ab2c5b8f53c076ac5356" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TensorBoard&lt;/code&gt; callback will work when eager execution is enabled, with the restriction that outputting histogram summaries of weights and gradients is not supported. Consequently, &lt;code&gt;histogram_freq&lt;/code&gt; will be ignored.</source>
          <target state="translated">Использование обратного вызова &lt;code&gt;TensorBoard&lt;/code&gt; будет работать, когда включено активное выполнение, с ограничением, заключающимся в том, что вывод сводных данных гистограммы весов и градиентов не поддерживается. Следовательно, &lt;code&gt;histogram_freq&lt;/code&gt; будет проигнорирован.</target>
        </trans-unit>
        <trans-unit id="10b4feb7db468a7b136fb7eedc7778e772ed7977" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;Uniform&lt;/code&gt; distribution as an example:</source>
          <target state="translated">На примере &lt;code&gt;Uniform&lt;/code&gt; distribution:</target>
        </trans-unit>
        <trans-unit id="a70f4ea74dc28a0759892b77d899be11c4a630a4" translate="yes" xml:space="preserve">
          <source>Using the SavedModel format</source>
          <target state="translated">Использование формата SavedModel</target>
        </trans-unit>
        <trans-unit id="2d5a6c95117b542db8bf88cf405c6beac37d2a3c" translate="yes" xml:space="preserve">
          <source>Using the above module would produce &lt;a href=&quot;variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;s and &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s whose names included the module name:</source>
          <target state="translated">Использование вышеуказанного модуля приведет к созданию &lt;a href=&quot;variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; s и &lt;a href=&quot;tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; s, имена которых включают имя модуля:</target>
        </trans-unit>
        <trans-unit id="7ad33ae89a6d279a16ce6134859a442eac2581c4" translate="yes" xml:space="preserve">
          <source>Using the default job_name of worker, you can schedule ops to run remotely as follows:</source>
          <target state="translated">Используя имя_работника по умолчанию job_name,вы можете запланировать ops для удаленного запуска следующим образом:</target>
        </trans-unit>
        <trans-unit id="5a6462b40df0780171c71c9fb37d8c4d54d01a02" translate="yes" xml:space="preserve">
          <source>Using this strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; will also be placed on the specified device as well.</source>
          <target state="translated">При использовании этой стратегии любые переменные, созданные в ее области видимости, будут размещены на указанном устройстве. Входные данные, распространяемые с помощью этой стратегии, будут предварительно загружены на указанное устройство. Более того, любые функции, вызываемые через &lt;code&gt;strategy.experimental_run_v2&lt;/code&gt; , также будут размещены на указанном устройстве.</target>
        </trans-unit>
        <trans-unit id="0921ab75268541486ce05861f2d20fe9143695fe" translate="yes" xml:space="preserve">
          <source>Using this strategy will place any variables created in its scope on the specified device. Input distributed through this strategy will be prefetched to the specified device. Moreover, any functions called via &lt;code&gt;strategy.run&lt;/code&gt; will also be placed on the specified device as well.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="71b01f087dc4062f216f4b3e8e8c06a8b29e198c" translate="yes" xml:space="preserve">
          <source>Usually, this does not necessarily mean that the layer is run in inference mode (which is normally controlled by the &lt;code&gt;training&lt;/code&gt; argument that can be passed when calling a layer). &quot;Frozen state&quot; and &quot;inference mode&quot; are two separate concepts.</source>
          <target state="translated">Обычно это не обязательно означает, что уровень запускается в режиме вывода (который обычно контролируется аргументом &lt;code&gt;training&lt;/code&gt; который может быть передан при вызове уровня). &amp;laquo;Замороженное состояние&amp;raquo; и &amp;laquo;режим вывода&amp;raquo; - это два разных понятия.</target>
        </trans-unit>
        <trans-unit id="6cf4bb7b1492b783c6bc69633b0fe1693771c5d9" translate="yes" xml:space="preserve">
          <source>Utilities for ImageNet data preprocessing &amp;amp; prediction decoding.</source>
          <target state="translated">Утилиты для предварительной обработки данных ImageNet и предсказания декодирования.</target>
        </trans-unit>
        <trans-unit id="08fb7be2421c2bdf2a78c1776aba074edf57a478" translate="yes" xml:space="preserve">
          <source>Utilities for preprocessing sequence data.</source>
          <target state="translated">Утилиты для предварительной обработки данных последовательности.</target>
        </trans-unit>
        <trans-unit id="ae6bf25944794d7df424031b54eed9e8c6e9c537" translate="yes" xml:space="preserve">
          <source>Utilities for text input preprocessing.</source>
          <target state="translated">Утилиты для предварительной обработки ввода текста.</target>
        </trans-unit>
        <trans-unit id="41900282bff2287f65ac5f2919d6b167c32aa670" translate="yes" xml:space="preserve">
          <source>Utilities for writing compatible code</source>
          <target state="translated">Утилиты для написания совместимого кода</target>
        </trans-unit>
        <trans-unit id="4209295b2fe1eb250fb221ec6cd68f34f854faae" translate="yes" xml:space="preserve">
          <source>Utility class for generating batches of temporal data.</source>
          <target state="translated">Полезный класс для генерации пакетов временных данных.</target>
        </trans-unit>
        <trans-unit id="3f80dd65b77c781d8eb1f4f65d0db44d5b92a1de" translate="yes" xml:space="preserve">
          <source>Utility function to build TensorInfo proto from a Tensor. (deprecated)</source>
          <target state="translated">Функция утилиты для построения прототипа TensorInfo из тензора.(устаревший)</target>
        </trans-unit>
        <trans-unit id="d66171638f7d7dc0d33fb68081060b45caf826a1" translate="yes" xml:space="preserve">
          <source>Utility function to build a SignatureDef protocol buffer.</source>
          <target state="translated">Утилита для построения буфера протокола SignatureDef.</target>
        </trans-unit>
        <trans-unit id="a1fc6fdd2556af786588697b8b4da900e88da0b4" translate="yes" xml:space="preserve">
          <source>Utility functions for building and inspecting SignatureDef protos.</source>
          <target state="translated">Полезные функции для создания и проверки прототипов SignatureDef.</target>
        </trans-unit>
        <trans-unit id="41a205ecd48940b5d4f27244d92bd652c4f4f6d1" translate="yes" xml:space="preserve">
          <source>Utility functions to assist with setup and construction of the SavedModel proto.</source>
          <target state="translated">Полезные функции для помощи в настройке и построении прототипа SavedModel.</target>
        </trans-unit>
        <trans-unit id="25e1689ca50193bb7593b638ace3275be8fc9300" translate="yes" xml:space="preserve">
          <source>Utility methods to create simple input_fns.</source>
          <target state="translated">Утилитные методы создания простых input_fns.</target>
        </trans-unit>
        <trans-unit id="98c6a5322edf6827b19ea21d2e974ec573fb37d2" translate="yes" xml:space="preserve">
          <source>V2 Compatibility</source>
          <target state="translated">V2 Совместимость</target>
        </trans-unit>
        <trans-unit id="b45432e089497cb1e4b6a50a251afeb8f8ec8634" translate="yes" xml:space="preserve">
          <source>V2 format specific: merges the metadata files of sharded checkpoints. The</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f4dce99bbaf012216e610738a930ee809e1a1dd" translate="yes" xml:space="preserve">
          <source>VGG16 model for Keras.</source>
          <target state="translated">VGG16 модель для Keras.</target>
        </trans-unit>
        <trans-unit id="16578957bc13d8fcce797647de9c6287bbab95bd" translate="yes" xml:space="preserve">
          <source>VGG19 model for Keras.</source>
          <target state="translated">VGG19 модель для Keras.</target>
        </trans-unit>
        <trans-unit id="b2ac8a00dcd90f10a8f8eab14df7c47a44d8bc39" translate="yes" xml:space="preserve">
          <source>Valid keyword args are:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2b984695d87811bddc59458f1d995336a48f8d61" translate="yes" xml:space="preserve">
          <source>Valid values for whence are: 0: start of the file (default) 1: relative to the current position of the file 2: relative to the end of file. &lt;code&gt;offset&lt;/code&gt; is usually negative.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="35d73c1e3e748be7af4094274c7c669844f7b39a" translate="yes" xml:space="preserve">
          <source>Validate and return float type based on &lt;code&gt;tensors&lt;/code&gt; and &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="translated">Проверить и вернуть тип с плавающей запятой на основе &lt;code&gt;tensors&lt;/code&gt; и &lt;code&gt;dtype&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7cfbc94b8562d35a1a624063af44283471348553" translate="yes" xml:space="preserve">
          <source>Validated type.</source>
          <target state="translated">Проверенный тип.</target>
        </trans-unit>
        <trans-unit id="fbc4d5994f37368bc38796f9fcac6177e5b079ae" translate="yes" xml:space="preserve">
          <source>Value Error: If input contains string value</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b6107bdd0fa4996fbf7660de172ff5a7b7753b6" translate="yes" xml:space="preserve">
          <source>Value convertible to &lt;a href=&quot;dtypes/dtype&quot;&gt;&lt;code&gt;tf.DType&lt;/code&gt;&lt;/a&gt;. The type of the tensor values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15c75ed5285ab847c51c1d1b073c1ffd6af1e2d3" translate="yes" xml:space="preserve">
          <source>Value convertible to &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt;. The shape of the tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe02012fec01937ecf4625a4bb543d51186a14cc" translate="yes" xml:space="preserve">
          <source>Value of new time step. Can be a variable or a constant</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf813cf306f9fe6920d27a32a73e1a8ab0b8ac28" translate="yes" xml:space="preserve">
          <source>Value of tensor to set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0d2a5aeb6f41dd496d2ccf306df13e6658541ae" translate="yes" xml:space="preserve">
          <source>Value to return if flagname is not defined. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4123cacba8af0210e8bc3a45f165b7510fbe81e" translate="yes" xml:space="preserve">
          <source>Value to set for indices not specified in &lt;code&gt;self&lt;/code&gt;. Defaults to zero. &lt;code&gt;default_value&lt;/code&gt; must be broadcastable to &lt;code&gt;self.shape[self.ragged_rank + 1:]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c7617def04f30bf9e69162b03566ab37d2f02c8" translate="yes" xml:space="preserve">
          <source>Value to set the tensor to, as a Numpy array (of the same shape).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44cdd81777401755111de56bb90c9f9e4f31fb50" translate="yes" xml:space="preserve">
          <source>ValueError if &lt;code&gt;num_packs&lt;/code&gt; is negative.</source>
          <target state="translated">ValueError, если &lt;code&gt;num_packs&lt;/code&gt; отрицательно.</target>
        </trans-unit>
        <trans-unit id="b03333735384a88c2a20365a2ab9d19d0855bf6a" translate="yes" xml:space="preserve">
          <source>ValueError if data format is unrecognized, if &lt;code&gt;value&lt;/code&gt; has less than two dimensions when &lt;code&gt;data_format&lt;/code&gt; is 'N..C'/&lt;code&gt;None&lt;/code&gt; or &lt;code&gt;value&lt;/code&gt; has less then three dimensions when &lt;code&gt;data_format&lt;/code&gt; is &lt;code&gt;NC..&lt;/code&gt;, if &lt;code&gt;bias&lt;/code&gt; does not have exactly one dimension (is a vector), or if the size of &lt;code&gt;bias&lt;/code&gt; does not match the size of the channel dimension of &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">ValueError, если формат данных не распознан, если &lt;code&gt;value&lt;/code&gt; имеет менее двух измерений, когда &lt;code&gt;data_format&lt;/code&gt; равно 'N..C' / &lt;code&gt;None&lt;/code&gt; или &lt;code&gt;value&lt;/code&gt; имеет менее трех измерений, когда &lt;code&gt;data_format&lt;/code&gt; равно &lt;code&gt;NC..&lt;/code&gt; , если &lt;code&gt;bias&lt;/code&gt; не имеет ровно одного измерения (это vector), или если размер &lt;code&gt;bias&lt;/code&gt; не соответствует размеру измерения канала &lt;code&gt;value&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="28e00764e50e68a9e4b435811b832e1599c2d7ff" translate="yes" xml:space="preserve">
          <source>ValueError when attempting to use experimental_compile, but XLA support is not enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f7604a24858b57e5b1686ec99368d1d81fb1d5a4" translate="yes" xml:space="preserve">
          <source>ValueError: When set pad_to_max_output_size to False for batched input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d1cad1ac50b9d58fe699af8d3719130c04596c12" translate="yes" xml:space="preserve">
          <source>ValueRowIds(key,)</source>
          <target state="translated">ValueRowIds(key,)</target>
        </trans-unit>
        <trans-unit id="2aa729287cefae889cb308c2489e301fd72ddfcc" translate="yes" xml:space="preserve">
          <source>Values are generated when TensorFlow is compiled, and are static for each TensorFlow package. The return value is a dictionary with string keys such as:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9989c8b816fd103fa17ba450218cc3f655b85003" translate="yes" xml:space="preserve">
          <source>Values are merged in order, so if an index appears in both &lt;code&gt;indices[m][i]&lt;/code&gt; and &lt;code&gt;indices[n][j]&lt;/code&gt; for &lt;code&gt;(m,i) &amp;lt; (n,j)&lt;/code&gt; the slice &lt;code&gt;data[n][j]&lt;/code&gt; will appear in the merged result. If you do not need this guarantee, ParallelDynamicStitch might perform better on some devices.</source>
          <target state="translated">Значения объединяются по порядку, поэтому, если индекс появляется как в &lt;code&gt;indices[m][i]&lt;/code&gt; и в &lt;code&gt;indices[n][j]&lt;/code&gt; для &lt;code&gt;(m,i) &amp;lt; (n,j)&lt;/code&gt; &lt;code&gt;data[n][j]&lt;/code&gt; среза [n] [j] будут появятся в объединенном результате. Если вам не нужна эта гарантия, ParallelDynamicStitch может работать лучше на некоторых устройствах.</target>
        </trans-unit>
        <trans-unit id="31517cd57e02e0d5266cab70a1c38e47fcd19844" translate="yes" xml:space="preserve">
          <source>Values are not loaded immediately, but when the initializer is run (typically by running a &lt;a href=&quot;../global_variables_initializer&quot;&gt;&lt;code&gt;tf.compat.v1.global_variables_initializer&lt;/code&gt;&lt;/a&gt; op).</source>
          <target state="translated">Значения загружаются не сразу, а при запуске инициализатора (обычно с помощью &lt;a href=&quot;../global_variables_initializer&quot;&gt; &lt;code&gt;tf.compat.v1.global_variables_initializer&lt;/code&gt; &lt;/a&gt; ).</target>
        </trans-unit>
        <trans-unit id="c7b1102521bf7adb2b3f3d054e8e942970be2d94" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;../../../distribute/strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Значения также могут иметь ту же локальность, что и переменная, которая является зеркальным значением, но находится на тех же устройствах, что и переменная (в отличие от вычислительных устройств). Такие значения могут быть переданы в вызов &lt;a href=&quot;../../../distribute/strategyextended#update&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt; &lt;/a&gt; для обновления значения переменной. Вы можете использовать &lt;a href=&quot;../../../distribute/strategyextended#colocate_vars_with&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt; ,&lt;/a&gt; чтобы присвоить переменной то же местоположение, что и другой переменной. Это полезно, например, для переменных &quot;слота&quot;, используемых оптимизатором для отслеживания статистики, используемой для обновления первичной переменной / переменной модели. Вы можете преобразовать значение для каждой реплики в местоположение переменной, используя &lt;a href=&quot;../../../distribute/strategyextended#reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../../distribute/strategyextended#batch_reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="2143538d5a76006c2fb34d48a187c9999b4ce092" translate="yes" xml:space="preserve">
          <source>Values can also have the same locality as a variable, which is a mirrored value but residing on the same devices as the variable (as opposed to the compute devices). Such values may be passed to a call to &lt;a href=&quot;strategyextended#update&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt;&lt;/a&gt; to update the value of a variable. You may use &lt;a href=&quot;strategyextended#colocate_vars_with&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt;&lt;/a&gt; to give a variable the same locality as another variable. This is useful, for example, for &quot;slot&quot; variables used by an optimizer for keeping track of statistics used to update a primary/model variable. You may convert a per-replica value to a variable's locality by using &lt;a href=&quot;strategyextended#reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt;&lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Значения также могут иметь ту же локальность, что и переменная, которая является зеркальным значением, но находится на тех же устройствах, что и переменная (в отличие от вычислительных устройств). Такие значения могут быть переданы в вызов &lt;a href=&quot;strategyextended#update&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.update&lt;/code&gt; &lt;/a&gt; для обновления значения переменной. Вы можете использовать &lt;a href=&quot;strategyextended#colocate_vars_with&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.colocate_vars_with&lt;/code&gt; ,&lt;/a&gt; чтобы присвоить переменной то же местоположение, что и другой переменной. Это полезно, например, для переменных &quot;слота&quot;, используемых оптимизатором для отслеживания статистики, используемой для обновления первичной переменной / переменной модели. Вы можете преобразовать значение для каждой реплики в местоположение переменной, используя &lt;a href=&quot;strategyextended#reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.reduce_to&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;strategyextended#batch_reduce_to&quot;&gt; &lt;code&gt;tf.distribute.StrategyExtended.batch_reduce_to&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="ee2d365c74f97141598697d434a691d20762875a" translate="yes" xml:space="preserve">
          <source>Values in &lt;code&gt;arr&lt;/code&gt; outside of the range [0, size) are ignored.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="93fb0db8d97fc795e57ce06a9fa4d44911eba728" translate="yes" xml:space="preserve">
          <source>Values may be merged in parallel, so if an index appears in both &lt;code&gt;indices[m][i]&lt;/code&gt; and &lt;code&gt;indices[n][j]&lt;/code&gt;, the result may be invalid. This differs from the normal DynamicStitch operator that defines the behavior in that case.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d15a2f51d1f3c105d253f174b82490fef1d2d0a2" translate="yes" xml:space="preserve">
          <source>Values of the sparse gradient to be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="332770f6ea1035cc31b26b51a3ff43d26f36a8a6" translate="yes" xml:space="preserve">
          <source>Values returned by all methods, such as &lt;code&gt;matmul&lt;/code&gt; or &lt;code&gt;determinant&lt;/code&gt; will be cast to &lt;code&gt;DTYPE&lt;/code&gt;.</source>
          <target state="translated">Значения, возвращаемые всеми методами, такими как &lt;code&gt;matmul&lt;/code&gt; или &lt;code&gt;determinant&lt;/code&gt; будут преобразованы в &lt;code&gt;DTYPE&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="472814b4275e6a3c35876afc6f85f152eeb4868b" translate="yes" xml:space="preserve">
          <source>Values to be associated with keys. Must be a tensor of the same shape as &lt;code&gt;keys&lt;/code&gt; and match the table's value type.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7e1d325bbb77e43c2a2a39b8f1ed0e1639c81e61" translate="yes" xml:space="preserve">
          <source>Values to pad with, passed to &lt;a href=&quot;../dataset#padded_batch&quot;&gt;&lt;code&gt;tf.data.Dataset.padded_batch&lt;/code&gt;&lt;/a&gt;. Defaults to padding with 0.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="152b6b1ae03ca0564ec1afcfa23945d6679fe3af" translate="yes" xml:space="preserve">
          <source>Values to put in the TensorProto.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="771c4420b1aa778f676175f583b791c3f76deedd" translate="yes" xml:space="preserve">
          <source>VarHandleOp</source>
          <target state="translated">VarHandleOp</target>
        </trans-unit>
        <trans-unit id="ff83e8cfb2acccae7a99a5aa63151589e41e200d" translate="yes" xml:space="preserve">
          <source>VarIsInitializedOp</source>
          <target state="translated">VarIsInitializedOp</target>
        </trans-unit>
        <trans-unit id="19de69cb601f53a4ea7af22a65c71ae63251365c" translate="yes" xml:space="preserve">
          <source>Variable</source>
          <target state="translated">Variable</target>
        </trans-unit>
        <trans-unit id="8b550e406a084548380628fd2909bf25b85b7d1f" translate="yes" xml:space="preserve">
          <source>Variable Constraint</source>
          <target state="translated">Переменная сдержанность</target>
        </trans-unit>
        <trans-unit id="dc8c6831002ca69f6ebeab63140354a283153e34" translate="yes" xml:space="preserve">
          <source>Variable Constraints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="87bff689d1fa1dea41f1caabbfa56196f9dac995" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ebe6d40e82094b23daf6be3c6e12b5de702a887" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ad8c28ec75b4fb97533632feee539c8715d6500d" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56732160b0c125a3a8776369974b1d8fe83bf273" translate="yes" xml:space="preserve">
          <source>Variable creation inside &lt;code&gt;scope&lt;/code&gt; is intercepted by the strategy. Each strategy defines how it wants to affect the variable creation. Sync strategies like &lt;code&gt;MirroredStrategy&lt;/code&gt;, &lt;code&gt;TPUStrategy&lt;/code&gt; and &lt;code&gt;MultiWorkerMiroredStrategy&lt;/code&gt; create variables replicated on each replica, whereas &lt;code&gt;ParameterServerStrategy&lt;/code&gt; creates variables on the parameter servers. This is done using a custom &lt;a href=&quot;../variable_creator_scope&quot;&gt;&lt;code&gt;tf.variable_creator_scope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dd58eeb1186ca442949f2a63231fa7bc6934171" translate="yes" xml:space="preserve">
          <source>Variable name to use for the first structure in assertion messages.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4e78d0db2266afd0792266861e4c967b5ab1437" translate="yes" xml:space="preserve">
          <source>Variable name to use for the second structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66091c2f5a648f0c372811ab148bd71631287d1d" translate="yes" xml:space="preserve">
          <source>Variable name.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0be93ad0375437f556470057db6cb269fac15f01" translate="yes" xml:space="preserve">
          <source>Variable or tensor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d982c2fd72628882252beffffe7353608ac38df" translate="yes" xml:space="preserve">
          <source>Variable regularization tensors are created when this property is accessed, so it is eager safe: accessing &lt;code&gt;losses&lt;/code&gt; under a &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will propagate gradients back to the corresponding variables.</source>
          <target state="translated">При обращении к этому свойству создаются тензоры регуляризации переменных, поэтому это очень безопасно: доступ к &lt;code&gt;losses&lt;/code&gt; под &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; будет распространять градиенты обратно на соответствующие переменные.</target>
        </trans-unit>
        <trans-unit id="9becbe8191297fcb35681c2cb0fd8d5255180628" translate="yes" xml:space="preserve">
          <source>Variable scope allows you to create new variables and to share already created ones while providing checks to not create or share by accident. For details, see the &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Variable Scope How To&lt;/a&gt;, here we present only a few basic examples.</source>
          <target state="translated">Область видимости переменных позволяет вам создавать новые переменные и делиться уже созданными, обеспечивая при этом проверки, чтобы не создавать или не делиться случайно. Для получения дополнительной информации см. &lt;a href=&quot;https://tensorflow.org/guide/variables&quot;&gt;Практическое&lt;/a&gt; руководство по изменению области действия , здесь мы представляем только несколько основных примеров.</target>
        </trans-unit>
        <trans-unit id="78a94c97c2babdd8664aa38c452645afd7c11def" translate="yes" xml:space="preserve">
          <source>Variable scope object to carry defaults to provide to &lt;code&gt;get_variable&lt;/code&gt;.</source>
          <target state="translated">Объект области видимости переменной для переноса значений по умолчанию для предоставления &lt;code&gt;get_variable&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="656181555fa5b90a78a2907e7cdc150cdb7d9969" translate="yes" xml:space="preserve">
          <source>Variable semantics in TensorFlow 2 are eager execution friendly. The above code is roughly equivalent to:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31ae50eddd5315630d388c7fc7d3dd4ac0f0c588" translate="yes" xml:space="preserve">
          <source>Variable shape. Defaults to scalar if unspecified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c9c726ae1bb253cefd1f8e18cd504aa6e24e0e2b" translate="yes" xml:space="preserve">
          <source>Variable to set to a new value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2fa42dfef00dd6f5716bd283c68f5a7c3df717eb" translate="yes" xml:space="preserve">
          <source>Variable, possibly mirrored to multiple devices, to operate on.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fad16e163b18a5adad4a6b1f9bafad182b1fc5e8" translate="yes" xml:space="preserve">
          <source>Variable-size shapes are allowed by setting the corresponding shape dimensions to 0 in the shape attr. In this case DequeueMany will pad up to the maximum size of any given element in the minibatch. See below for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f736193c89669392caf0903ec1e19730e643644" translate="yes" xml:space="preserve">
          <source>Variable. The number of training steps this Optimizer has run.</source>
          <target state="translated">Переменная.Количество тренировочных шагов,выполненных этим Оптимизатором.</target>
        </trans-unit>
        <trans-unit id="fbd24bae4ab2c5fb1757b5c4452669855276459f" translate="yes" xml:space="preserve">
          <source>VariableScope for the created subgraph; defaults to &quot;bidirectional_rnn&quot;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a6f1a6e7f1ea3415ae9f018191ab201ea3b0fac" translate="yes" xml:space="preserve">
          <source>VariableScope for the created subgraph; defaults to &quot;rnn&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3580913cdba362b6cc2d19d6b7d1f9e9219c622d" translate="yes" xml:space="preserve">
          <source>VariableShape</source>
          <target state="translated">VariableShape</target>
        </trans-unit>
        <trans-unit id="751393cca20cc522b2f5c1a18350f77fe8d88bea" translate="yes" xml:space="preserve">
          <source>VariableV2</source>
          <target state="translated">VariableV2</target>
        </trans-unit>
        <trans-unit id="f628de42a66fa9f6ab10a5ed8f37f3bfec4938d4" translate="yes" xml:space="preserve">
          <source>Variables are assigned to local CPU or the only GPU. If there is more than one GPU, compute operations (other than variable update operations) will be replicated across all GPUs.</source>
          <target state="translated">Переменные назначаются локальному CPU или единственному GPU.Если имеется более одного GPU,вычислительные операции (кроме операций обновления переменных)будут реплицированы на всех GPU.</target>
        </trans-unit>
        <trans-unit id="70a30a529e57576d822cecd0f271a7b5d39f84b7" translate="yes" xml:space="preserve">
          <source>Variables are automatically tracked when assigned to attributes of types inheriting from &lt;a href=&quot;module&quot;&gt;&lt;code&gt;tf.Module&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Переменные автоматически отслеживаются при назначении атрибутов типов, унаследованных от &lt;a href=&quot;module&quot;&gt; &lt;code&gt;tf.Module&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="1655acbcc407ca5c5cc17d4daaba10766362006a" translate="yes" xml:space="preserve">
          <source>Variables are often captured and manipulated by &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s. This works the same way the un-decorated function would have:</source>
          <target state="translated">Переменные часто захватываются и обрабатываются &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; s. Это работает так же, как функция без декорирования:</target>
        </trans-unit>
        <trans-unit id="9422ebfe912588a94b4db8ceb623ec6943b8ae1a" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; must be owned outside the function and be created only once:</source>
          <target state="translated">Переменные, созданные внутри &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; ,&lt;/a&gt; должны принадлежать вне функции и создаваться только один раз:</target>
        </trans-unit>
        <trans-unit id="a4f9c7fa0b18154ca4691caf51f88ee40eea34cb" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;code&gt;MirroredStrategy&lt;/code&gt; which is wrapped with a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; are still &lt;code&gt;MirroredVariables&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="29e458106bb18014f5f1ce0d551df4f487281340" translate="yes" xml:space="preserve">
          <source>Variables created inside a &lt;code&gt;MirroredStrategy&lt;/code&gt; which is wrapped with a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; are still &lt;code&gt;MirroredVariables&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="198e5fbedc6e80bc4c09f5cf7cecc37f23ca5651" translate="yes" xml:space="preserve">
          <source>Variables created inside the strategy scope are &quot;owned&quot; by it:</source>
          <target state="translated">Переменные,созданные в рамках стратегии,&quot;принадлежат&quot; ей:</target>
        </trans-unit>
        <trans-unit id="ecf6360262e709b4fb787134a5207269f78afa79" translate="yes" xml:space="preserve">
          <source>Variables created outside the strategy are not owned by it:</source>
          <target state="translated">Переменные,созданные вне стратегии,не принадлежат ей:</target>
        </trans-unit>
        <trans-unit id="4e85b51c74744b26c07cb066853860450f1f5376" translate="yes" xml:space="preserve">
          <source>Variables must be tracked by assigning them to an attribute of a tracked object or to an attribute of &lt;code&gt;obj&lt;/code&gt; directly. TensorFlow objects (e.g. layers from &lt;a href=&quot;../keras/layers&quot;&gt;&lt;code&gt;tf.keras.layers&lt;/code&gt;&lt;/a&gt;, optimizers from &lt;a href=&quot;../train&quot;&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/a&gt;) track their variables automatically. This is the same tracking scheme that &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; uses, and an exported &lt;code&gt;Checkpoint&lt;/code&gt; object may be restored as a training checkpoint by pointing &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to the SavedModel's &quot;variables/&quot; subdirectory. Currently variables are the only stateful objects supported by &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, but others (e.g. tables) will be supported in the future.</source>
          <target state="translated">Переменные должны отслеживаться путем непосредственного присвоения их атрибуту отслеживаемого объекта или атрибуту &lt;code&gt;obj&lt;/code&gt; . Объекты &lt;a href=&quot;../keras/layers&quot;&gt; &lt;code&gt;tf.keras.layers&lt;/code&gt; &lt;/a&gt; (например, слои из tf.keras.layers , оптимизаторы из &lt;a href=&quot;../train&quot;&gt; &lt;code&gt;tf.train&lt;/code&gt; &lt;/a&gt; ) автоматически отслеживают свои переменные. Это та же схема отслеживания, что и &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , и экспортированный объект &lt;code&gt;Checkpoint&lt;/code&gt; может быть восстановлен как обучающая контрольная точка, указав &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; в подкаталог &amp;laquo;variables /&amp;raquo; SavedModel. В настоящее время переменные - единственные объекты с &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; состояния, поддерживаемые tf.saved_model.save , но другие (например, таблицы) будут поддерживаться в будущем.</target>
        </trans-unit>
        <trans-unit id="e84fa29887783568cfad44fb6f314a273a26c8b5" translate="yes" xml:space="preserve">
          <source>Variables must be tracked by assigning them to an attribute of a tracked object or to an attribute of &lt;code&gt;obj&lt;/code&gt; directly. TensorFlow objects (e.g. layers from &lt;a href=&quot;../keras/layers&quot;&gt;&lt;code&gt;tf.keras.layers&lt;/code&gt;&lt;/a&gt;, optimizers from &lt;a href=&quot;../train&quot;&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/a&gt;) track their variables automatically. This is the same tracking scheme that &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; uses, and an exported &lt;code&gt;Checkpoint&lt;/code&gt; object may be restored as a training checkpoint by pointing &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt; to the SavedModel's &quot;variables/&quot; subdirectory. Currently, variables are the only stateful objects supported by &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt;, but others (e.g. tables) will be supported in the future.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51a7e747ba069953d31cbdce4de5483d9446f49f" translate="yes" xml:space="preserve">
          <source>Variables, placeholders, and independent operations can also be stored, as shown in the following example.</source>
          <target state="translated">Также можно хранить переменные,закладные и независимые операции,как показано в следующем примере.</target>
        </trans-unit>
        <trans-unit id="612d2ee1679ef5637187e20c4629a406547bfef9" translate="yes" xml:space="preserve">
          <source>Variables:</source>
          <target state="translated">Variables:</target>
        </trans-unit>
        <trans-unit id="bb96e64e18e9a621cc7ceb2976a5e75548f771d4" translate="yes" xml:space="preserve">
          <source>Variance is defined as,</source>
          <target state="translated">Вариация определяется как,</target>
        </trans-unit>
        <trans-unit id="d282722043467708dfd05bebcd66f9f1d34aee3d" translate="yes" xml:space="preserve">
          <source>Variance of a tensor, alongside the specified axis.</source>
          <target state="translated">Вариация тензора,вдоль указанной оси.</target>
        </trans-unit>
        <trans-unit id="547d7dc902ba966407aa0728767694e953ad6b04" translate="yes" xml:space="preserve">
          <source>Variance of batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="99189c611d030a5281d712eaa2b886309eb67a6b" translate="yes" xml:space="preserve">
          <source>Variance.</source>
          <target state="translated">Variance.</target>
        </trans-unit>
        <trans-unit id="108fd2238efb49f633daf84e4120ae9f47cfdec6" translate="yes" xml:space="preserve">
          <source>Various libraries built on top of the core TensorFlow library take care of creating some or all of these pieces and storing them in well known collections in the graph. The &lt;code&gt;Scaffold&lt;/code&gt; class helps pick these pieces from the graph collections, creating and adding them to the collections if needed.</source>
          <target state="translated">Различные библиотеки, построенные на основе основной библиотеки TensorFlow, заботятся о создании некоторых или всех этих частей и сохранении их в хорошо известных коллекциях на графике. Класс &lt;code&gt;Scaffold&lt;/code&gt; помогает выбирать эти части из коллекций графов, создавая и добавляя их в коллекции при необходимости.</target>
        </trans-unit>
        <trans-unit id="a6a6801f04fd08c4cf3ed0c985c50e0b3cc573dd" translate="yes" xml:space="preserve">
          <source>Vector length = Maximum element in vector &lt;code&gt;values&lt;/code&gt; is 5. Adding 1, which is 6 will be the vector length.</source>
          <target state="translated">Длина вектора = Максимальный элемент в векторных &lt;code&gt;values&lt;/code&gt; равен 5. Добавление 1, которое равно 6, будет длиной вектора.</target>
        </trans-unit>
        <trans-unit id="f5115b80229d0ab74c010431ae650645a075fb17" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise logits.</source>
          <target state="translated">Вектор координат в кусочках.</target>
        </trans-unit>
        <trans-unit id="444c2b1f0bb53e9255195603b2fe9758758fc528" translate="yes" xml:space="preserve">
          <source>Vector of coordinatewise probabilities.</source>
          <target state="translated">Вектор кусочно-ориентированных вероятностей.</target>
        </trans-unit>
        <trans-unit id="ce1a5d4c90bdb53d4d10dd069e9eaa942f080fdb" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the exclusive upper limits for each range.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a3f9cb652ec383e8e638e09260439b3155ece9c8" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the first entry for each range if &lt;code&gt;limits&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;; otherwise, specifies the range limits, and the first entries default to &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6a78cb729e962d878d29fc681da48899c9408f1c" translate="yes" xml:space="preserve">
          <source>Vector or scalar &lt;code&gt;Tensor&lt;/code&gt;. Specifies the increment for each range. Defaults to &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca486267fdece68b69e71338f98f70bc8a117412" translate="yes" xml:space="preserve">
          <source>Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89f3f7fe4c1640033ee74781a079e4dad0989210" translate="yes" xml:space="preserve">
          <source>Verbosity mode, 0 or 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ec03954e111311ff95bd45ec3b8a12f4f9d9e291" translate="yes" xml:space="preserve">
          <source>Verifies whether all flags pass validation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf8d82dcaf9576f668b800d91e2cd8a9bd872212" translate="yes" xml:space="preserve">
          <source>Vertical coordinate of the top-left corner of the result in the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cbf1afdceff80dfc15073d9ab60779a3946f421" translate="yes" xml:space="preserve">
          <source>View aliases</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="31a7604a3c742ea454ff128dd267ca1e16472796" translate="yes" xml:space="preserve">
          <source>View source</source>
          <target state="translated">Источник просмотра</target>
        </trans-unit>
        <trans-unit id="a11a63ecf581d6810e65e62968e93200e384c05b" translate="yes" xml:space="preserve">
          <source>View source on GitHub</source>
          <target state="translated">Посмотреть источник на GitHub</target>
        </trans-unit>
        <trans-unit id="6737eca3bba31c47e227cdb4b10d88148b47097b" translate="yes" xml:space="preserve">
          <source>Visit the &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/input&quot;&gt;tutorial&lt;/a&gt; on distributed input for more examples and caveats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d07bb0bd533bc6a8f9cecf11b29b925415f286e8" translate="yes" xml:space="preserve">
          <source>Vocabulary information for warm-starting.</source>
          <target state="translated">Информация по словарю для горячего старта.</target>
        </trans-unit>
        <trans-unit id="1ec053f91b0e4f43b0ff9856f1f431195070e64b" translate="yes" xml:space="preserve">
          <source>WARNING: Experimental interface, subject to change.</source>
          <target state="translated">ПРЕДУПРЕЖДЕНИЕ:Экспериментальный интерфейс,может быть изменен.</target>
        </trans-unit>
        <trans-unit id="ec7aa071ac596c65b3d8973549288f00dd9060fe" translate="yes" xml:space="preserve">
          <source>WARNING: If &lt;code&gt;sloppy&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the order of produced elements is not deterministic.</source>
          <target state="translated">ВНИМАНИЕ: Если &lt;code&gt;sloppy&lt;/code&gt; имеет значение &lt;code&gt;True&lt;/code&gt; , порядок создаваемых элементов не детерминирован.</target>
        </trans-unit>
        <trans-unit id="20a9fc48c3697f74feddc8ad93eb4c90b0d2bc47" translate="yes" xml:space="preserve">
          <source>WARNING: This function is nondeterministic, since it starts a separate thread for each tensor.</source>
          <target state="translated">ПРЕДУПРЕЖДЕНИЕ:Эта функция не детерминистична,так как для каждого тензора она запускает отдельный поток.</target>
        </trans-unit>
        <trans-unit id="e747855abeb092a18ebf6b91688f8d9d0024a93d" translate="yes" xml:space="preserve">
          <source>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a &lt;a href=&quot;../../cond&quot;&gt;&lt;code&gt;tf.cond&lt;/code&gt;&lt;/a&gt; is dangerous and error-prone:</source>
          <target state="translated">ВНИМАНИЕ: объекты tf.Variable по умолчанию имеют неинтуитивную модель памяти. Переменная внутренне представлена ​​как изменяемый тензор, который может недетерминированно использовать псевдонимы других тензоров в графе. Набор операций, которые потребляют переменную и могут привести к сглаживанию, не определен и может изменяться в разных версиях TensorFlow. Избегайте написания кода, который полагается на то, что значение переменной либо изменяется, либо не изменяется по мере выполнения других операций. Например, использование объектов Variable или их простых функций в качестве предикатов в &lt;a href=&quot;../../cond&quot;&gt; &lt;code&gt;tf.cond&lt;/code&gt; &lt;/a&gt; опасно и подвержено ошибкам:</target>
        </trans-unit>
        <trans-unit id="1d2a3e7fd14becda3ad79ab623ee02dcfb3c4815" translate="yes" xml:space="preserve">
          <source>WRONG:</source>
          <target state="translated">WRONG:</target>
        </trans-unit>
        <trans-unit id="b55f8ed036408ccdecc6c75f53cbf2cbe602c833" translate="yes" xml:space="preserve">
          <source>Wait for threads to terminate.</source>
          <target state="translated">Подождите,пока нити не закончатся.</target>
        </trans-unit>
        <trans-unit id="480279e397ed207ff6dcb2138e6d19a402c6acab" translate="yes" xml:space="preserve">
          <source>Wait till the Coordinator is told to stop.</source>
          <target state="translated">Подождите,пока Координатору не скажут остановиться.</target>
        </trans-unit>
        <trans-unit id="fd3c945de3bbe026196979524e2513d29b8047c4" translate="yes" xml:space="preserve">
          <source>Wait until the thread terminates.</source>
          <target state="translated">Подождите,пока нить не закончится.</target>
        </trans-unit>
        <trans-unit id="5fcf196e2d36a225ff59aa7e988a3bab54a62688" translate="yes" xml:space="preserve">
          <source>Warm-start all TRAINABLE variables:</source>
          <target state="translated">Теплый запуск всех переменных TRAINABLE:</target>
        </trans-unit>
        <trans-unit id="77a75fce3b44ee7c1b7330f94b51f223f12aced8" translate="yes" xml:space="preserve">
          <source>Warm-start all variables (including non-TRAINABLE):</source>
          <target state="translated">Теплый запуск всех переменных (включая переменные,не относящиеся к TRAINABLE):</target>
        </trans-unit>
        <trans-unit id="385cb07f1382ec501efc556d03af6fccd0c3bc88" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the embedding parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in the current model:</source>
          <target state="translated">Горячий запуск всех весов, но параметры внедрения, соответствующие &lt;code&gt;sc_vocab_file&lt;/code&gt; , имеют другой словарь, чем тот, который используется в текущей модели:</target>
        </trans-unit>
        <trans-unit id="584c6949a375264781ffa7a3f30012c7d4ac99ba" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint and the parameters corresponding to &lt;code&gt;sc_vocab_list&lt;/code&gt; have a different name from the current checkpoint:</source>
          <target state="translated">Горячий запуск всех весов, но параметры, соответствующие &lt;code&gt;sc_vocab_file&lt;/code&gt; , имеют другой словарь, чем тот, который используется в текущей контрольной точке, а параметры, соответствующие &lt;code&gt;sc_vocab_list&lt;/code&gt; , имеют другое имя, чем текущая контрольная точка:</target>
        </trans-unit>
        <trans-unit id="aee3196d9918b3cb93e150d394afe537d71e12b7" translate="yes" xml:space="preserve">
          <source>Warm-start all weights but the parameters corresponding to &lt;code&gt;sc_vocab_file&lt;/code&gt; have a different vocab from the one used in current checkpoint, and only 100 of those entries were used:</source>
          <target state="translated">Горячий запуск всех весов, но параметры, соответствующие &lt;code&gt;sc_vocab_file&lt;/code&gt; , имеют другой словарь, чем тот, который используется в текущей контрольной точке, и было использовано только 100 из этих записей:</target>
        </trans-unit>
        <trans-unit id="cdac2057c8ebeb309f57754501e81125700d9646" translate="yes" xml:space="preserve">
          <source>Warm-start all weights in the model (input layer and hidden weights). Either the directory or a specific checkpoint can be provided (in the case of the former, the latest checkpoint will be used):</source>
          <target state="translated">Теплый запуск всех весов в модели (входной слой и скрытые веса).Может быть предусмотрен либо каталог,либо конкретный контрольно-пропускной пункт (в случае первого будет использоваться последний контрольно-пропускной пункт):</target>
        </trans-unit>
        <trans-unit id="5b13568e15d19ce108f966610dd72d6f433fdac5" translate="yes" xml:space="preserve">
          <source>Warm-start non-TRAINABLE variables &quot;v1&quot;, &quot;v1/Momentum&quot;, and &quot;v2&quot; but not &quot;v2/momentum&quot;:</source>
          <target state="translated">ТЕПЛОИЗЛУЧЕННЫЕ не-ТРЕЙНАЧАЛЬНЫЕ переменные &quot;v1&quot;,&quot;v1/Momentum&quot; и &quot;v2&quot;,но не &quot;v2/momentum&quot;:</target>
        </trans-unit>
        <trans-unit id="a2a6608bb90e8edcca0d24db3c7888d49894818d" translate="yes" xml:space="preserve">
          <source>Warm-start only &lt;code&gt;sc_vocab_file&lt;/code&gt; embeddings (and no other variables), which have a different vocab from the one used in the current model:</source>
          <target state="translated">Горячий запуск только встраивания &lt;code&gt;sc_vocab_file&lt;/code&gt; (и никаких других переменных), которые имеют другой словарь, чем тот, который используется в текущей модели:</target>
        </trans-unit>
        <trans-unit id="8454c4aaa6884d63b21f47b182bea32dff06b1d9" translate="yes" xml:space="preserve">
          <source>Warm-start only the embeddings (input layer):</source>
          <target state="translated">Теплый запуск только встраивания (входной слой):</target>
        </trans-unit>
        <trans-unit id="053dd1f00688a5e1c6f7bb11994384338437241d" translate="yes" xml:space="preserve">
          <source>Warm-starts a model using the given settings.</source>
          <target state="translated">Теплый запуск модели с помощью заданных настроек.</target>
        </trans-unit>
        <trans-unit id="a935669a6f94647cbab43dac31886ff159458161" translate="yes" xml:space="preserve">
          <source>Warning class expected to be triggered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="005fd2adc416b2f84c9268603969a31365422ae0" translate="yes" xml:space="preserve">
          <source>We add forget_bias (default: 1) to the biases of the forget gate in order to reduce the scale of forgetting in the beginning of the training.</source>
          <target state="translated">Мы добавляем forget_bias (по умолчанию:1)к пристрастиям ворот забывчивости,чтобы уменьшить масштаб забывчивости в начале тренировки.</target>
        </trans-unit>
        <trans-unit id="ea902771c0c609fef23987d09209f89de6ea6624" translate="yes" xml:space="preserve">
          <source>We assume that the word frequencies follow Zipf's law (s=1) to derive a numerical approximation of frequency(rank):</source>
          <target state="translated">Мы предполагаем,что частоты слов следуют закону Ципфа (s=1)для получения численного приближения частоты (ранга):</target>
        </trans-unit>
        <trans-unit id="ee7344fa99f19a3db805ed04f05f653d28a573dc" translate="yes" xml:space="preserve">
          <source>We call it an 'accidental hit' when one of the target classes matches one of the sampled classes. This operation reports accidental hits as triples &lt;code&gt;(index, id, weight)&lt;/code&gt;, where &lt;code&gt;index&lt;/code&gt; represents the row number in &lt;code&gt;true_classes&lt;/code&gt;, &lt;code&gt;id&lt;/code&gt; represents the position in &lt;code&gt;sampled_candidates&lt;/code&gt;, and weight is &lt;code&gt;-FLOAT_MAX&lt;/code&gt;.</source>
          <target state="translated">Мы называем это &amp;laquo;случайным попаданием&amp;raquo;, когда один из целевых классов соответствует одному из выбранных классов. Эта операция сообщает о случайных попаданиях в виде троек &lt;code&gt;(index, id, weight)&lt;/code&gt; , где &lt;code&gt;index&lt;/code&gt; представляет номер строки в &lt;code&gt;true_classes&lt;/code&gt; , &lt;code&gt;id&lt;/code&gt; представляет позицию в &lt;code&gt;sampled_candidates&lt;/code&gt; , а вес равен &lt;code&gt;-FLOAT_MAX&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3e90ccb70a2df6831216576e3e93ad8f84e29aaa" translate="yes" xml:space="preserve">
          <source>We can again draw the effect, this time using the symbols &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;o&lt;/code&gt; to distinguish the patches:</source>
          <target state="translated">Мы можем снова нарисовать эффект, на этот раз используя символы &lt;code&gt;*&lt;/code&gt; , &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;+&lt;/code&gt; и &lt;code&gt;o&lt;/code&gt; , чтобы различать патчи:</target>
        </trans-unit>
        <trans-unit id="3ec1d6719eaed84adca414b94403fe4b9bce8b6a" translate="yes" xml:space="preserve">
          <source>We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.</source>
          <target state="translated">Мы также можем,вставить целые ломтики тензора более высокого ранга сразу.Например,если мы хотим вставить два ломтика в первое измерение тензора ранга-3 с двумя матрицами новых значений.</target>
        </trans-unit>
        <trans-unit id="75a6bd3ac0e29b2d99ddde37882f73b9484c4c89" translate="yes" xml:space="preserve">
          <source>We can compute the mean and variance of the batch</source>
          <target state="translated">Мы можем вычислить среднее значение и дисперсию партии.</target>
        </trans-unit>
        <trans-unit id="141a486e547cdd8105ede80b487557001daeacfc" translate="yes" xml:space="preserve">
          <source>We can construct a CsvDataset from it as follows:</source>
          <target state="translated">Мы можем построить из него CsvDataset следующим образом:</target>
        </trans-unit>
        <trans-unit id="798032cd2519c55922a86a65a97aa8223721d2bf" translate="yes" xml:space="preserve">
          <source>We can use arguments:</source>
          <target state="translated">Мы можем использовать аргументы:</target>
        </trans-unit>
        <trans-unit id="bfe0a32bb694084e323bdf39d8ca5b3bf5acf3b4" translate="yes" xml:space="preserve">
          <source>We first define two int64 tensors &lt;code&gt;paddings&lt;/code&gt; and &lt;code&gt;crops&lt;/code&gt; of shape &lt;code&gt;[num_spatial_dims, 2]&lt;/code&gt; based on the value of &lt;code&gt;padding&lt;/code&gt; and the spatial dimensions of the &lt;code&gt;input&lt;/code&gt;:</source>
          <target state="translated">Сначала определит два int64 тензоров &lt;code&gt;paddings&lt;/code&gt; и &lt;code&gt;crops&lt;/code&gt; формы &lt;code&gt;[num_spatial_dims, 2]&lt;/code&gt; на основе значения &lt;code&gt;padding&lt;/code&gt; и пространственных размерах &lt;code&gt;input&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="c362e7cae577801d3a077b086c30ca6fb0a66da0" translate="yes" xml:space="preserve">
          <source>We first solve &lt;code&gt;x_0 = A_00.solve(y_0)&lt;/code&gt;. Proceeding inductively, we solve for &lt;code&gt;x_k&lt;/code&gt;, &lt;code&gt;k = 1..n&lt;/code&gt;, given &lt;code&gt;x_0..x_(k-1)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d6f96925005fe200b4a2292648a063218b208f4" translate="yes" xml:space="preserve">
          <source>We keep track of which flag is defined by which module so that we can later sort the flags by module.</source>
          <target state="translated">Мы следим за тем,какой флаг определен по какому модулю,чтобы в дальнейшем можно было сортировать флаги по модулям.</target>
        </trans-unit>
        <trans-unit id="e09363c49b193f1ac1770f115d6d8136f2ddc43c" translate="yes" xml:space="preserve">
          <source>We next use the scale_factor to adjust min_range and max_range as follows:</source>
          <target state="translated">Далее мы используем коэффициент scale_factor для настройки min_range и max_range следующим образом:</target>
        </trans-unit>
        <trans-unit id="6d1134ee5b3f5d2c7da4505ac717468ba6967616" translate="yes" xml:space="preserve">
          <source>We presuppose that the &lt;code&gt;sampled_candidates&lt;/code&gt; are unique.</source>
          <target state="translated">Мы предполагаем, что &lt;code&gt;sampled_candidates&lt;/code&gt; уникальны.</target>
        </trans-unit>
        <trans-unit id="f093997d3edad673438d9d10c06d984c5a8a5f76" translate="yes" xml:space="preserve">
          <source>We recommend that descendants of &lt;code&gt;Layer&lt;/code&gt; implement the following methods:</source>
          <target state="translated">Мы рекомендуем потомкам &lt;code&gt;Layer&lt;/code&gt; реализовать следующие методы:</target>
        </trans-unit>
        <trans-unit id="bd2045e3591e6b6a7950e1ad85e808c50d3fcbe0" translate="yes" xml:space="preserve">
          <source>We recommend using &lt;a href=&quot;https://github.com/tensorflow/io&quot;&gt;https://github.com/tensorflow/io&lt;/a&gt; to load your HDF5 data into a tf.data Dataset and passing that dataset to Keras.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="664f0b931d5bb248f3df03fa1a45aa162e8bb7fc" translate="yes" xml:space="preserve">
          <source>We recommend using https://github.com/tensorflow/io to load your HDF5 data into a tf.data Dataset and passing that dataset to Keras.</source>
          <target state="translated">Мы рекомендуем использовать https://github.com/tensorflow/io для загрузки данных HDF5 в набор данных tf.data и передачи этого набора данных в Keras.</target>
        </trans-unit>
        <trans-unit id="e6b1e174afc80b9d454ce2447d6b106dd858888d" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the GCE APIs every time this method is called.</source>
          <target state="translated">Мы получаем информацию из API GCE каждый раз при вызове этого метода.</target>
        </trans-unit>
        <trans-unit id="2e18048f9e04e3012f6199dfe11668988e00f3d9" translate="yes" xml:space="preserve">
          <source>We retrieve the information from the Kubernetes master every time this method is called.</source>
          <target state="translated">Мы получаем информацию от мастера Kubernetes каждый раз при вызове этого метода.</target>
        </trans-unit>
        <trans-unit id="ee86e3990a38d113aeda3e686a64aed6a6c21a17" translate="yes" xml:space="preserve">
          <source>We specify the size-related attributes as:</source>
          <target state="translated">Мы указываем атрибуты,связанные с размером как:</target>
        </trans-unit>
        <trans-unit id="88a4bbb7071448507fb5ea156b09b64279b62233" translate="yes" xml:space="preserve">
          <source>We use the following notation for (complex) matrix and right-hand sides in the batch:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d371d0dcdb3a29109c4aec0bd9662ca4cc225c96" translate="yes" xml:space="preserve">
          <source>We will assume that the input dataset is batched by the global batch size. With this assumption, we will make a best effort to divide each batch across all the replicas (one or more workers).</source>
          <target state="translated">Предположим,что набор входных данных имеет глобальный размер партии.Исходя из этого предположения,мы приложим все усилия,чтобы разделить каждую партию по всем репликам (один или несколько сотрудников).</target>
        </trans-unit>
        <trans-unit id="c1e896bf769945f02ba4270d6713548acfff861f" translate="yes" xml:space="preserve">
          <source>Web-safe means that the encoder uses - and _ instead of + and /.</source>
          <target state="translated">Web-безопасность означает,что кодировщик использует-и_вместо+и /.</target>
        </trans-unit>
        <trans-unit id="a5ecd420b68c6ca62b2880bcb67d127d7527fd45" translate="yes" xml:space="preserve">
          <source>Weight updates (for instance, the updates of the moving mean and variance in a BatchNormalization layer) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, some entries in &lt;code&gt;layer.updates&lt;/code&gt; may be dependent on &lt;code&gt;a&lt;/code&gt; and some on &lt;code&gt;b&lt;/code&gt;. This method automatically keeps track of dependencies.</source>
          <target state="translated">Обновления веса (например, обновления скользящего среднего и дисперсии в слое BatchNormalization) могут зависеть от входных данных, переданных при вызове слоя. Следовательно, при повторном использовании одного и того же уровня на разных входах &lt;code&gt;a&lt;/code&gt; и &lt;code&gt;b&lt;/code&gt; некоторые записи в &lt;code&gt;layer.updates&lt;/code&gt; могут зависеть от &lt;code&gt;a&lt;/code&gt; , а некоторые - от &lt;code&gt;b&lt;/code&gt; . Этот метод автоматически отслеживает зависимости.</target>
        </trans-unit>
        <trans-unit id="012994d31dee39cea10e34d13b123636095aef6d" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size]&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; взвешенных потерь того же типа, что и &lt;code&gt;logits&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не будет &lt;code&gt;NONE&lt;/code&gt; , это имеет форму &lt;code&gt;[batch_size]&lt;/code&gt; ; в противном случае - скаляр.</target>
        </trans-unit>
        <trans-unit id="9d1005c1318b48c01558d66a2ac013b81040339a" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; взвешенных потерь того же типа, что и &lt;code&gt;logits&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не является &lt;code&gt;NONE&lt;/code&gt; , это имеет такую же форму , как и &lt;code&gt;labels&lt;/code&gt; ; в противном случае - скаляр.</target>
        </trans-unit>
        <trans-unit id="834de6c05706f24229c420c387a2f8167f0b45d5" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;logits&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;logits&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; взвешенных потерь того же типа, что и &lt;code&gt;logits&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не будет &lt;code&gt;NONE&lt;/code&gt; , это имеет такую же форму , как и &lt;code&gt;logits&lt;/code&gt; ; в противном случае - скаляр.</target>
        </trans-unit>
        <trans-unit id="b075652dc6120aaf1d41f8a4dc2daf694ffa4a69" translate="yes" xml:space="preserve">
          <source>Weighted loss &lt;code&gt;Tensor&lt;/code&gt; of the same type as &lt;code&gt;losses&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;losses&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">&lt;code&gt;Tensor&lt;/code&gt; взвешенных убытков того же типа, что и &lt;code&gt;losses&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не будет &lt;code&gt;NONE&lt;/code&gt; , это имеет ту же форму, что и &lt;code&gt;losses&lt;/code&gt; ; в противном случае - скаляр.</target>
        </trans-unit>
        <trans-unit id="f8f11d4c7a3da229788db34932231d37e05fbe0b" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has shape &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt;; otherwise, it is scalar. (Note &lt;code&gt;dN-1&lt;/code&gt; because all loss functions reduce by 1 dimension, usually axis=-1.)</source>
          <target state="translated">Взвешенный убыток с плавающей запятой &lt;code&gt;Tensor&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не будет &lt;code&gt;NONE&lt;/code&gt; , это имеет форму &lt;code&gt;[batch_size, d0, .. dN-1]&lt;/code&gt; ; в противном случае - скаляр. (Обратите внимание на &lt;code&gt;dN-1&lt;/code&gt; , потому что все функции потерь уменьшаются на 1 измерение, обычно ось = -1.)</target>
        </trans-unit>
        <trans-unit id="37a14c45a506771a19d570992ffb74e2a8ababd3" translate="yes" xml:space="preserve">
          <source>Weighted loss float &lt;code&gt;Tensor&lt;/code&gt;. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;NONE&lt;/code&gt;, this has the same shape as &lt;code&gt;labels&lt;/code&gt;; otherwise, it is scalar.</source>
          <target state="translated">Взвешенный убыток с плавающей запятой &lt;code&gt;Tensor&lt;/code&gt; . Если &lt;code&gt;reduction&lt;/code&gt; не является &lt;code&gt;NONE&lt;/code&gt; , это имеет такую же форму , как и &lt;code&gt;labels&lt;/code&gt; ; в противном случае - скаляр.</target>
        </trans-unit>
        <trans-unit id="23f94c92282719a4052aebc7d476aba406e80f05" translate="yes" xml:space="preserve">
          <source>Weights values as a list of numpy arrays.</source>
          <target state="translated">Значения весов,как список нумерующих массивов.</target>
        </trans-unit>
        <trans-unit id="79699365f3dd7ea5c60a1201001103f0e4d8e414" translate="yes" xml:space="preserve">
          <source>What &lt;code&gt;master&lt;/code&gt; string to use</source>
          <target state="translated">Какую &lt;code&gt;master&lt;/code&gt; строку использовать</target>
        </trans-unit>
        <trans-unit id="8126fc60320a74dd637a7bb9a583488f0b14222c" translate="yes" xml:space="preserve">
          <source>What happens in &lt;code&gt;adapt&lt;/code&gt;: Compute mean and variance of the data and store them as the layer's weights. &lt;code&gt;adapt&lt;/code&gt; should be called before &lt;code&gt;fit&lt;/code&gt;, &lt;code&gt;evaluate&lt;/code&gt;, or &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">Что происходит при &lt;code&gt;adapt&lt;/code&gt; : вычисляет среднее значение и дисперсию данных и сохраняет их как веса слоя. &lt;code&gt;adapt&lt;/code&gt; должна вызываться до &lt;code&gt;fit&lt;/code&gt; , &lt;code&gt;evaluate&lt;/code&gt; или &lt;code&gt;predict&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f4112aa72544bbd54c25bceb58f7f58b932e32d8" translate="yes" xml:space="preserve">
          <source>What to return in test phase (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="17f24426650f12852c89205be844ef319f76644b" translate="yes" xml:space="preserve">
          <source>What to return in train phase (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="def8b9f5f06fb4c06699fb40ca04320258ae46d4" translate="yes" xml:space="preserve">
          <source>What to return otherwise (tensor or callable that returns a tensor).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e11f03a4f4c3dbc0b65542222647d127c17f0502" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6f8e0522d952680a4b2c6fbddea797a2677b1547" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a0d7396d4c78509ccd91f8c0cfaa89f6bac9680" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e73d3cb0a89b521b7e9847b33f0048e348f89d5" translate="yes" xml:space="preserve">
          <source>What's under the hood of this method, when we say the &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; instance - &lt;code&gt;dataset&lt;/code&gt; - gets distributed? It depends on how you set the &lt;a href=&quot;../data/experimental/autoshardpolicy&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy&lt;/code&gt;&lt;/a&gt; through &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;. By default, it is set to &lt;a href=&quot;../data/experimental/autoshardpolicy#AUTO&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.AUTO&lt;/code&gt;&lt;/a&gt;. In a multi-worker setting, we will first attempt to distribute &lt;code&gt;dataset&lt;/code&gt; by detecting whether &lt;code&gt;dataset&lt;/code&gt; is being created out of reader datasets (e.g. &lt;a href=&quot;../data/tfrecorddataset&quot;&gt;&lt;code&gt;tf.data.TFRecordDataset&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../data/textlinedataset&quot;&gt;&lt;code&gt;tf.data.TextLineDataset&lt;/code&gt;&lt;/a&gt;, etc.) and if so, try to shard the input files. Note that there has to be at least one input file per worker. If you have less than one input file per worker, we suggest that you disable dataset sharding across workers, by setting the &lt;a href=&quot;../data/experimental/distributeoptions#auto_shard_policy&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions.auto_shard_policy&lt;/code&gt;&lt;/a&gt; to be &lt;a href=&quot;../data/experimental/autoshardpolicy#OFF&quot;&gt;&lt;code&gt;tf.data.experimental.AutoShardPolicy.OFF&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4633647d41640957a472ab68c0262290690dfdb" translate="yes" xml:space="preserve">
          <source>When 'TF_CONFIG' environment variable is set, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multi-worker strategy which mirrored models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="97233c5c3c8d20a5e9ffbdbe3b7ccb6a51db597b" translate="yes" xml:space="preserve">
          <source>When 'TF_CONFIG' environment variable is set, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multi-worker strategy which mirrores models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.</source>
          <target state="translated">Когда переменная окружения 'TF_CONFIG' установлена,она разбирает cluster_spec,task_type и task_id из 'TF_CONFIG' и превращается в многопользовательскую стратегию,которая зеркально отражает модели на графических процессорах всех машин в кластере.В текущей реализации она использует все GPU в кластере и предполагает,что все рабочие имеют одинаковое количество GPU.</target>
        </trans-unit>
        <trans-unit id="f5e1d55c89f446271b947fe72a857c539201c7dc" translate="yes" xml:space="preserve">
          <source>When 'antialias' is true, the sampling filter will anti-alias the input image as well as interpolate. When downsampling an image with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;anti-aliasing&lt;/a&gt; the sampling filter kernel is scaled in order to properly anti-alias the input image signal. 'antialias' has no effect when upsampling an image.</source>
          <target state="translated">Когда &amp;laquo;сглаживание&amp;raquo; истинно, фильтр выборки будет сглаживать входное изображение, а также выполнять интерполяцию. При понижении разрешения изображения со &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;сглаживанием&lt;/a&gt; ядро фильтра дискретизации масштабируется, чтобы правильно сглаживать входной сигнал изображения. 'сглаживание' не действует при повышении дискретизации изображения.</target>
        </trans-unit>
        <trans-unit id="a125e391abcaadbe33801ab8eddcf23c35279113" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;True&lt;/code&gt;, additional assertions might be embedded in the graph. Default value: &lt;code&gt;False&lt;/code&gt; (i.e., no graph assertions are added).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="735a581f2af66e2fcb181fd57a9ddb799b2eb257" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;antialias&lt;/code&gt; is true, the sampling filter will anti-alias the input image as well as interpolate. When downsampling an image with &lt;a href=&quot;https://en.wikipedia.org/wiki/Spatial_anti-aliasing&quot;&gt;anti-aliasing&lt;/a&gt; the sampling filter kernel is scaled in order to properly anti-alias the input image signal. &lt;code&gt;antialias&lt;/code&gt; has no effect when upsampling an image:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aacbccc1a065c95aea812e79f50b9fb0809ae76" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;distribute&lt;/code&gt; or &lt;code&gt;experimental_distribute.train_distribute&lt;/code&gt; and &lt;code&gt;experimental_distribute.remote_cluster&lt;/code&gt; is set, this method will start a client running on the current host which connects to the &lt;code&gt;remote_cluster&lt;/code&gt; for training and evaluation.</source>
          <target state="translated">Если установлено &lt;code&gt;distribute&lt;/code&gt; или &lt;code&gt;experimental_distribute.train_distribute&lt;/code&gt; и &lt;code&gt;experimental_distribute.remote_cluster&lt;/code&gt; , этот метод запускает клиент, работающий на текущем хосте, который подключается к &lt;code&gt;remote_cluster&lt;/code&gt; для обучения и оценки.</target>
        </trans-unit>
        <trans-unit id="01497840225ce1bb0dcac0f82d53eb47485d512b" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;enable&lt;/code&gt; is set to None, an appropriate value will be picked automatically. The value picked may change between TensorFlow releases.</source>
          <target state="translated">Если для параметра &lt;code&gt;enable&lt;/code&gt; установлено значение None, соответствующее значение будет выбрано автоматически. Выбранное значение может меняться между выпусками TensorFlow.</target>
        </trans-unit>
        <trans-unit id="3a92e9802f62e2ea66187929bf4db58022152e26" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;nesterov=False&lt;/code&gt;, this rule becomes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c64f1c94124dc71ee97e99b0200e5f2b295d3204" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;queues&lt;/code&gt; is not a list of &lt;code&gt;QueueBase&lt;/code&gt; objects, or when the data types of &lt;code&gt;queues&lt;/code&gt; are not all the same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d965c5a7f6cd6a88315eeacabf229f5d784d0a97" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;rescale&lt;/code&gt; is set to a value, rescaling is applied to sample data before computing the internal data stats.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dda3a421cfde51cef62429c270613980d6f95f4a" translate="yes" xml:space="preserve">
          <source>When True, &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; may generate fewer, graphs that are less specialized on input shapes.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d2203660cd3c839935256a662d4fa7b611fae192" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a77de95801a4cff5844b758a2ad8179bb09d2c1a" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5bc23220d2b015520f09eca2cbd06a9bdbef9712" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8157664b0c676127bfe8a48270b035a599288e2e" translate="yes" xml:space="preserve">
          <source>When a &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; is created inside a &lt;code&gt;strategy.scope&lt;/code&gt;, we capture this information. When high level training frameworks methods such as &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt; etc are then called on this model, we automatically enter the scope, as well as use this strategy to distribute the training etc. See detailed example in &lt;a href=&quot;https://www.tensorflow.org/tutorials/distribute/keras&quot;&gt;distributed keras tutorial&lt;/a&gt;. Note that simply calling the &lt;code&gt;model(..)&lt;/code&gt; is not impacted - only high level training framework APIs are. &lt;code&gt;model.compile&lt;/code&gt;, &lt;code&gt;model.fit&lt;/code&gt;, &lt;code&gt;model.evaluate&lt;/code&gt;, &lt;code&gt;model.predict&lt;/code&gt; and &lt;code&gt;model.save&lt;/code&gt; can all be called inside or outside the scope.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5d3c29ba7c1915daf444dfa9480a120b9d259cc0" translate="yes" xml:space="preserve">
          <source>When a DistributionStrategy is used, this function may only be called in a cross-replica context.</source>
          <target state="translated">При использовании DistributionStrategy эта функция может быть вызвана только в межреспубликанском контексте.</target>
        </trans-unit>
        <trans-unit id="9ee3d0211a7961d1892863b309bfae8dc55d02c2" translate="yes" xml:space="preserve">
          <source>When a Summary op is instantiated, a SummaryDescription of associated metadata is stored in its NodeDef. This method retrieves the description.</source>
          <target state="translated">Когда итоговый опцион инстанцируется,SummaryDescription соответствующих метаданных хранится в NodeDef.Этот метод извлекает описание.</target>
        </trans-unit>
        <trans-unit id="468fae491a93893feb36e0fc65b7a7ac2c612355" translate="yes" xml:space="preserve">
          <source>When a global &lt;a href=&quot;../../../../keras/mixed_precision/experimental/policy&quot;&gt;&lt;code&gt;tf.keras.mixed_precision.experimental.Policy&lt;/code&gt;&lt;/a&gt; is set, a Keras layer's dtype will default to the global policy instead of floatx. Layers will automatically cast inputs to the policy's compute_dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="067c92a0436a2a055b3eb1915882349b4d833f6c" translate="yes" xml:space="preserve">
          <source>When a op's float-type output tensor contains any Infinity or NaN, an &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; will be thrown, with an error message that reveals the following information:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9e2c0bd0de968bcd753736a8da6d2db14223d5cf" translate="yes" xml:space="preserve">
          <source>When a op's float-type output tensor contains any Infinity or NaN, an &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt;&lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt;&lt;/a&gt; will be thrown, with an error message that reveals the following information: - The type of the op that generated the tensor with bad numerics. - Data type (dtype) of the tensor. - Shape of the tensor (to the extent known at the time of eager execution or graph construction). - Name of the containing graph (if available). - (Graph mode only): The stack trace of the intra-graph op's creation, with a stack-height limit and a path-length limit for visual clarity. The stack frames that belong to the user's code (as opposed to tensorflow's internal code) are highlighted with a text arrow (&quot;-&amp;gt;&quot;). - (Eager mode only): How many of the offending tensor's elements are &lt;code&gt;Infinity&lt;/code&gt; and &lt;code&gt;NaN&lt;/code&gt;, respectively.</source>
          <target state="translated">Когда выходной тензор операционного типа с плавающей запятой содержит любое значение Infinity или NaN, будет &lt;a href=&quot;../errors/invalidargumenterror&quot;&gt; &lt;code&gt;tf.errors.InvalidArgumentError&lt;/code&gt; &lt;/a&gt; с сообщением об ошибке, содержащим следующую информацию: - Тип операции, которая сгенерировала тензор с неверными числами. - Тип данных (dtype) тензора. - Форма тензора (насколько известно во время активного выполнения или построения графа). - Имя содержащего графа (если есть). - (Только в режиме графика): трассировка стека создания внутриграфической операции с ограничением высоты стека и ограничением длины пути для наглядности. Кадры стека, принадлежащие коду пользователя (в отличие от внутреннего кода tenorflow), выделяются текстовой стрелкой (&amp;laquo;-&amp;gt;&amp;raquo;). - (Только режим нетерпеливости): сколько тензора-нарушителя?s элементы - это &lt;code&gt;Infinity&lt;/code&gt; и &lt;code&gt;NaN&lt;/code&gt; соответственно.</target>
        </trans-unit>
        <trans-unit id="b898b5ad811100780dad4051c33f639fd70aa1be" translate="yes" xml:space="preserve">
          <source>When a tf.random operation is built with XLA, the implementation doesn't pass the user provided seed to the XLA compiler. As such, the XLA compiler generates a random number and uses it as a seed when compiling the operation. This implementation causes a violation of the Tensorflow defined semantics in two aspects. First, changing the value of the user defined seed doesn't change the numbers generated by the operation. Second, when a seed is not specified, running the program multiple times will generate the same numbers.</source>
          <target state="translated">Когда tf.random операция собирается с XLA,реализация не передает предоставленный пользователем посевной файл компилятору XLA.Таким образом,компилятор XLA генерирует случайное число и использует его в качестве посылки при компиляции операции.Эта реализация приводит к нарушению семантики,определенной Tensorflow,в двух аспектах.Во-первых,изменение значения пользовательского семени не изменяет числа,генерируемые операцией.Во-вторых,если семя не задано,то при многократном запуске программы будут генерироваться одни и те же числа.</target>
        </trans-unit>
        <trans-unit id="493652c7a3597db99acb0cc5aae0cc36b4d15e47" translate="yes" xml:space="preserve">
          <source>When a trackable object is exported via &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save()&lt;/code&gt;&lt;/a&gt;, all the &lt;code&gt;Asset&lt;/code&gt;s reachable from it are copied into the SavedModel assets directory. Upon loading, the assets and the serialized functions that depend on them will refer to the correct filepaths inside the SavedModel directory.</source>
          <target state="translated">Когда отслеживается объект экспортируются через &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save()&lt;/code&gt; &lt;/a&gt; , все &lt;code&gt;Asset&lt;/code&gt; s достижимы из него копируется в каталог SavedModel активов. При загрузке активы и сериализованные функции, которые от них зависят, будут ссылаться на правильные пути к файлам внутри каталога SavedModel.</target>
        </trans-unit>
        <trans-unit id="6f1183817b3726ec7266e15fa411e144c4d1a1bb" translate="yes" xml:space="preserve">
          <source>When accessing the value of a TensorShape dimension, use this utility, like this:</source>
          <target state="translated">При доступе к значению измерения TensorShape используйте данную утилиту:</target>
        </trans-unit>
        <trans-unit id="5eeff351258cc34299c1acc2c35d15d6a807f5fe" translate="yes" xml:space="preserve">
          <source>When arguments have invalid value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e15681c5c4d660d694d5dcc65f824f2819119a6a" translate="yes" xml:space="preserve">
          <source>When attempting to multiply a nD tensor with a nD tensor, it reproduces the Theano behavior. (e.g. &lt;code&gt;(2, 3) * (4, 3, 5) -&amp;gt; (2, 4, 5)&lt;/code&gt;)</source>
          <target state="translated">При попытке умножить тензор nD на тензор nD воспроизводится поведение Теано. (например, &lt;code&gt;(2, 3) * (4, 3, 5) -&amp;gt; (2, 4, 5)&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="c84b6c98a486c1f1ed40714b3413c2d05ebb290e" translate="yes" xml:space="preserve">
          <source>When attempting to normalize on an empty ensemble or an ensemble of trees which have no splits. Or when attempting to normalize and feature importances have negative values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c06f27a3b19deaf8176a82559892b7885f9b161" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines the CPU budget to use. Values greater than the number of schedulable CPU cores are allowed but may result in CPU contention. If None, defaults to the number of schedulable CPU cores.</source>
          <target state="translated">Когда автонастройка включена (посредством &lt;code&gt;autotune&lt;/code&gt; ), определяет используемый бюджет ЦП. Допускаются значения, превышающие количество ядер ЦП, которые можно запланировать, но это может привести к конфликту ЦП. Если Нет, по умолчанию используется количество ядер ЦП, которые можно запланировать.</target>
        </trans-unit>
        <trans-unit id="aa75a73b6c69b49d6e19ddace76d0dc9e6d20863" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), determines whether to also autotune buffer sizes for datasets with parallelism. If None, defaults to False.</source>
          <target state="translated">Когда автонастройка включена (посредством &lt;code&gt;autotune&lt;/code&gt; ), определяет, нужно ли также автонастраивать размеры буфера для наборов данных с параллелизмом. Если None, по умолчанию False.</target>
        </trans-unit>
        <trans-unit id="283f72551210c9459423ecb79011f0f8519629e6" translate="yes" xml:space="preserve">
          <source>When autotuning is enabled (through &lt;code&gt;autotune&lt;/code&gt;), identifies the algorithm to use for the autotuning optimization.</source>
          <target state="translated">Когда автонастройка включена (посредством &lt;code&gt;autotune&lt;/code&gt; ), определяет алгоритм, используемый для оптимизации автонастройки.</target>
        </trans-unit>
        <trans-unit id="e6deb11b689fcef12dab268b644289f6586fd39c" translate="yes" xml:space="preserve">
          <source>When both &lt;code&gt;squeeze_dims&lt;/code&gt; and &lt;code&gt;axis&lt;/code&gt; are specified.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="32eb733d84fe74265b206fb4da02dbc0b66960e1" translate="yes" xml:space="preserve">
          <source>When building a complex model that uses many queues it is often difficult to gather all the queue runners that need to be run. This convenience function allows you to add a queue runner to a well known collection in the graph.</source>
          <target state="translated">При построении сложной модели,использующей множество очередей,часто бывает трудно собрать всех бегунов очереди,которые необходимо запустить.Эта удобная функция позволяет добавить очередей бегунов в хорошо известную коллекцию на графе.</target>
        </trans-unit>
        <trans-unit id="e5bcf632e0c577d3a09737c01de056496ad7c080" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding the trainable model parameters and other variables such as a &lt;code&gt;global step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. If &lt;code&gt;True&lt;/code&gt;, the new variable is also added to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. The convenience function &lt;code&gt;trainable_variables()&lt;/code&gt; returns the contents of this collection. The various &lt;code&gt;Optimizer&lt;/code&gt; classes use this collection as the default list of variables to optimize.</source>
          <target state="translated">При построении модели машинного обучения часто бывает удобно различать переменные, содержащие параметры обучаемой модели, и другие переменные, такие как &lt;code&gt;global step&lt;/code&gt; переменная шага, используемая для подсчета шагов обучения. Чтобы упростить задачу, конструктор переменных поддерживает параметр &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; . Если &lt;code&gt;True&lt;/code&gt; , новая переменная также добавляется в коллекцию графов &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; . Удобная функция &lt;code&gt;trainable_variables()&lt;/code&gt; возвращает содержимое этой коллекции. Различные классы &lt;code&gt;Optimizer&lt;/code&gt; используют эту коллекцию в качестве списка переменных по умолчанию для оптимизации.</target>
        </trans-unit>
        <trans-unit id="68a44f742db33e692724433083d54a9691c316e1" translate="yes" xml:space="preserve">
          <source>When building a machine learning model it is often convenient to distinguish between variables holding trainable model parameters and other variables such as a &lt;code&gt;step&lt;/code&gt; variable used to count training steps. To make this easier, the variable constructor supports a &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; parameter. &lt;a href=&quot;gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; watches trainable variables by default:</source>
          <target state="translated">При построении модели машинного обучения часто бывает удобно различать переменные, содержащие параметры обучаемой модели, и другие переменные, такие как переменная &lt;code&gt;step&lt;/code&gt; используемая для подсчета шагов обучения. Чтобы упростить задачу, конструктор переменных поддерживает параметр &lt;code&gt;trainable=&amp;lt;bool&amp;gt;&lt;/code&gt; . &lt;a href=&quot;gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; по умолчанию наблюдает за обучаемыми переменными:</target>
        </trans-unit>
        <trans-unit id="5eef9f253a5e93ec36275a968646b63d028cda2b" translate="yes" xml:space="preserve">
          <source>When building an eager SparseTensor if &lt;code&gt;dense_shape&lt;/code&gt; is unknown or contains unknown elements (None or -1).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="13d3fbe26af35daa9bb0d8a47a6e4b1e39a6da13" translate="yes" xml:space="preserve">
          <source>When building ops to compute gradients, the TensorFlow gradient system will return an error when trying to lookup the gradient of this op, because no gradient must ever be registered for this function. This op exists to prevent subtle bugs from silently returning unimplemented gradients in some corner cases.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="11e07c6fbcce2a9ab5d49a2c9fc58743be530d36" translate="yes" xml:space="preserve">
          <source>When building ops to compute gradients, this op prevents the contribution of its inputs to be taken into account. Normally, the gradient generator adds ops to a graph to compute the derivatives of a specified 'loss' by recursively finding out inputs that contributed to its computation. If you insert this op in the graph it inputs are masked from the gradient generator. They are not taken into account for computing gradients.</source>
          <target state="translated">При построении опций для вычисления градиентов эта опция не позволяет учитывать вклад ее входов.Обычно генератор градиентов добавляет опсы к графику для вычисления производных заданного &quot;убытка&quot;,рекурсивно обнаруживая входы,которые внесли свой вклад в его вычисление.Если вы вставите эту опцию в граф,то ее входы будут замаскированы от генератора градиентов.Они не учитываются при вычислении градиентов.</target>
        </trans-unit>
        <trans-unit id="0d35f4de41040fd9e01e658fd5001879a66a9c2d" translate="yes" xml:space="preserve">
          <source>When caching to a file, the cached data will persist across runs. Even the first iteration through the data will read from the cache file. Changing the input pipeline before the call to &lt;code&gt;.cache()&lt;/code&gt; will have no effect until the cache file is removed or the filename is changed.</source>
          <target state="translated">При кэшировании в файл кэшированные данные сохраняются при выполнении. Даже первая итерация данных будет считываться из файла кеша. Изменение входного конвейера перед вызовом &lt;code&gt;.cache()&lt;/code&gt; будет иметь никакого эффекта до тех пор, пока файл кеша не будет удален или имя файла не будет изменено.</target>
        </trans-unit>
        <trans-unit id="b38df97ed344603f1f1650ff0bfe2600641ba555" translate="yes" xml:space="preserve">
          <source>When calculating the gradient of a weighted loss contributions from both &lt;code&gt;losses&lt;/code&gt; and &lt;code&gt;weights&lt;/code&gt; are considered. If your &lt;code&gt;weights&lt;/code&gt; depend on some model parameters but you do not want this to affect the loss gradient, you need to apply &lt;a href=&quot;../../../stop_gradient&quot;&gt;&lt;code&gt;tf.stop_gradient&lt;/code&gt;&lt;/a&gt; to &lt;code&gt;weights&lt;/code&gt; before passing them to &lt;code&gt;compute_weighted_loss&lt;/code&gt;.</source>
          <target state="translated">При расчете градиента взвешенного убытка учитываются как &lt;code&gt;losses&lt;/code&gt; и &lt;code&gt;weights&lt;/code&gt; . Если ваши &lt;code&gt;weights&lt;/code&gt; зависят от некоторых параметров модели, но вы не хотите, чтобы это повлияло на градиент потерь, вам необходимо применить &lt;a href=&quot;../../../stop_gradient&quot;&gt; &lt;code&gt;tf.stop_gradient&lt;/code&gt; &lt;/a&gt; к &lt;code&gt;weights&lt;/code&gt; перед их передачей в &lt;code&gt;compute_weighted_loss&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="05f81ef4361feddebda74fb8dc805bcdaf94d0cf" translate="yes" xml:space="preserve">
          <source>When called inside a strategy.run call and input is not directly taken from the args of the &lt;code&gt;strategy.run&lt;/code&gt; call. Also if the size of any sequence in &lt;code&gt;features&lt;/code&gt; does not match corresponding sequence in &lt;code&gt;feature_config&lt;/code&gt;. Similarly for &lt;code&gt;weights&lt;/code&gt;, if not &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ebd806d2188a9c9df38773d42df546a4427672df" translate="yes" xml:space="preserve">
          <source>When called inside a strategy.run call and inside XLA control flow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e31beadd763eb7afc2237f8c90a1ca311bfd077a" translate="yes" xml:space="preserve">
          <source>When called, the default graph is the one that will be launched in the session. The hook can modify the graph by adding new operations to it. After the &lt;code&gt;begin()&lt;/code&gt; call the graph will be finalized and the other callbacks can not modify the graph anymore. Second call of &lt;code&gt;begin()&lt;/code&gt; on the same graph, should not change the graph.</source>
          <target state="translated">При вызове график по умолчанию - это тот, который будет запущен в сеансе. Хук может изменять граф, добавляя к нему новые операции. После вызова &lt;code&gt;begin()&lt;/code&gt; граф будет завершен, и другие обратные вызовы больше не смогут изменять граф. Второй вызов &lt;code&gt;begin()&lt;/code&gt; на том же графе не должен изменять график.</target>
        </trans-unit>
        <trans-unit id="97ac3a446111c899472a5c5300f96b04aabb3a5c" translate="yes" xml:space="preserve">
          <source>When checkpointing your model, you should include your &lt;a href=&quot;tpuembedding&quot;&gt;&lt;code&gt;tf.tpu.experimental.embedding.TPUEmbedding&lt;/code&gt;&lt;/a&gt; object in the checkpoint. It is a trackable object and saving it will save the embedding tables and their optimizer slot variables:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0f92e2d94d9415d9d31e53c6519e2640ef5146f3" translate="yes" xml:space="preserve">
          <source>When combining specs, &lt;code&gt;dev&lt;/code&gt; will take precedence over the current spec. So for instance:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7d7e4d9de8d529939e37509a2b98e74b3e5ae079" translate="yes" xml:space="preserve">
          <source>When combining specs, &lt;code&gt;dev&lt;/code&gt; will take precidence over the current spec. So for instance:</source>
          <target state="translated">При объединении спецификаций &lt;code&gt;dev&lt;/code&gt; принимает во внимание текущую спецификацию. Так например:</target>
        </trans-unit>
        <trans-unit id="02d1051ddba9ce90040906dafc1d04ba61223ccf" translate="yes" xml:space="preserve">
          <source>When constructed with a &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; parameter, a &lt;code&gt;FileWriter&lt;/code&gt; instead forms a compatibility layer over new graph-based summaries (&lt;code&gt;tf.contrib.summary&lt;/code&gt;) to facilitate the use of new summary writing with pre-existing code that expects a &lt;code&gt;FileWriter&lt;/code&gt; instance.</source>
          <target state="translated">При создании с параметром &lt;a href=&quot;../session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; &lt;/a&gt; &lt;code&gt;FileWriter&lt;/code&gt; вместо этого формирует уровень совместимости над новыми сводками на основе графов ( &lt;code&gt;tf.contrib.summary&lt;/code&gt; ), чтобы облегчить использование нового сводного отчета с уже существующим кодом, который ожидает &lt;code&gt;FileWriter&lt;/code&gt; пример.</target>
        </trans-unit>
        <trans-unit id="e77d83f8aae8dd347eba34fe1096849a87e1d28d" translate="yes" xml:space="preserve">
          <source>When constructed with a &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; parameter, a &lt;code&gt;FileWriter&lt;/code&gt; instead forms a compatibility layer over new graph-based summaries to facilitate the use of new summary writing with pre-existing code that expects a &lt;code&gt;FileWriter&lt;/code&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aa47f312128ac2a3285768f283bc01e3ade90f81" translate="yes" xml:space="preserve">
          <source>When consuming SavedModels asynchronously (the producer is a separate process), the SavedModel directory will appear before all files have been written, and &lt;a href=&quot;load&quot;&gt;&lt;code&gt;tf.saved_model.load&lt;/code&gt;&lt;/a&gt; will fail if pointed at an incomplete SavedModel. Rather than checking for the directory, check for &quot;saved_model_dir/saved_model.pb&quot;. This file is written atomically as the last &lt;a href=&quot;save&quot;&gt;&lt;code&gt;tf.saved_model.save&lt;/code&gt;&lt;/a&gt; file operation.</source>
          <target state="translated">При асинхронном использовании SavedModels (производитель - это отдельный процесс), каталог SavedModel появится до того, как будут записаны все файлы, и &lt;a href=&quot;load&quot;&gt; &lt;code&gt;tf.saved_model.load&lt;/code&gt; &lt;/a&gt; завершится ошибкой, если будет указана неполная SavedModel. Вместо того, чтобы проверять каталог, проверьте &quot;сохраненный_модель_каталог / сохраненная_модель.pb&quot;. Этот файл записывается атомарно как последняя &lt;a href=&quot;save&quot;&gt; &lt;code&gt;tf.saved_model.save&lt;/code&gt; &lt;/a&gt; файлом tf.saved_model.save .</target>
        </trans-unit>
        <trans-unit id="b17afd826ceac8e996a7c85541a3c3196c1b6382" translate="yes" xml:space="preserve">
          <source>When creating a distributed dataset that is to be passed to the enqueue operation a special input option must be specified:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2db902f77ce37ed9d0c7614f639ced1da648ed42" translate="yes" xml:space="preserve">
          <source>When desired_channels is set, if the input contains fewer channels than this then the last channel will be duplicated to give the requested number, else if the input has more channels than requested then the additional channels will be ignored.</source>
          <target state="translated">При установке параметра desired_channels,если на входе меньше каналов,чем указано,то последний канал будет продублирован,чтобы дать запрашиваемый номер,в противном случае,если на входе больше каналов,чем указано,то дополнительные каналы будут проигнорированы.</target>
        </trans-unit>
        <trans-unit id="87468be68aa798b87299469214116a53bdacd212" translate="yes" xml:space="preserve">
          <source>When documenting the shape of a RaggedTensor, ragged dimensions can be indicated by enclosing them in parentheses. For example, the shape of a 3-D &lt;code&gt;RaggedTensor&lt;/code&gt; that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as &lt;code&gt;[num_sentences, (num_words), embedding_size]&lt;/code&gt;. The parentheses around &lt;code&gt;(num_words)&lt;/code&gt; indicate that dimension is ragged, and that the length of each element list in that dimension may vary for each item.</source>
          <target state="translated">При документировании формы RaggedTensor неровные размеры можно указать, заключив их в круглые скобки. Например, форма 3-D &lt;code&gt;RaggedTensor&lt;/code&gt; , который хранит встраивание слов фиксированного размера для каждого слова в предложении, для каждого предложения в пакете, может быть записана как &lt;code&gt;[num_sentences, (num_words), embedding_size]&lt;/code&gt; . &lt;code&gt;(num_words)&lt;/code&gt; скобки вокруг (num_words) указывают на то, что измерение является рваным и что длина каждого списка элементов в этом измерении может различаться для каждого элемента.</target>
        </trans-unit>
        <trans-unit id="933ca78b0f0aab236f7c30d0b7d8200f4284ead1" translate="yes" xml:space="preserve">
          <source>When doing broadcasted operations such as multiplying a tensor by a scalar, broadcasting (usually) confers some time or space benefit, as the broadcasted tensor is never materialized.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bac64cb9d33552a3e872e7c5fb90f9f381853ebe" translate="yes" xml:space="preserve">
          <source>When doing log-odds NCE, the result of this op should be passed through a SparseToDense op, then added to the logits of the sampled candidates. This has the effect of 'removing' the sampled labels that match the true labels by making the classifier sure that they are sampled labels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd3848450984baae9593cd8c988bd98ec36231eb" translate="yes" xml:space="preserve">
          <source>When each worker has more than one GPU, operations will be replicated on all GPUs. Even though operations may be replicated, variables are not and each worker shares a common view for which parameter server a variable is assigned to.</source>
          <target state="translated">Когда каждый работник имеет более одного GPU,операции будут реплицироваться на всех GPU.Несмотря на то,что операции могут быть реплицированы,переменных нет,и каждый работник имеет общее представление о том,для какого параметра серверу присваивается переменная.</target>
        </trans-unit>
        <trans-unit id="1dfe4b0bd2fe2cdea509ee0800c577901d8b6927" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, and &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; are ignored.</source>
          <target state="translated">Когда активировано &lt;code&gt;gate_gradients&lt;/code&gt; выполнение, gate_gradients , &lt;code&gt;aggregation_method&lt;/code&gt; и &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; игнорируются.</target>
        </trans-unit>
        <trans-unit id="148b464485213e809e25fd2427e6df10ddb7913a" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; and &lt;code&gt;momentum&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Когда активировано активное выполнение, каждая из этих функций &lt;code&gt;learning_rate&lt;/code&gt; и &lt;code&gt;momentum&lt;/code&gt; может быть вызываемой, которая не принимает аргументов и возвращает фактическое значение для использования. Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="6f483d1759bf06f09369c7c2c6504ed890b4f074" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt; can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Когда включено активное выполнение, &lt;code&gt;learning_rate&lt;/code&gt; может быть вызываемым, не принимающим аргументов и возвращающим фактическое значение для использования. Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="6eb0adbeafdc09876e4693f8ca8e165f9c0c0985" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;beta_1&lt;/code&gt;, &lt;code&gt;beta_2&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Когда активировано &lt;code&gt;beta_1&lt;/code&gt; , &lt;code&gt;beta_2&lt;/code&gt; этих функций &lt;code&gt;learning_rate&lt;/code&gt; , beta_1 , beta_2 и &lt;code&gt;epsilon&lt;/code&gt; может быть вызываемой, не принимающей аргументов и возвращающей фактическое значение для использования. Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="88cf25c3162efb5267e479cbb3ca75d9e84020c2" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;decay&lt;/code&gt;, &lt;code&gt;momentum&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Когда активировано нетерпеливое исполнение, каждая из таких функций , как &lt;code&gt;learning_rate&lt;/code&gt; , &lt;code&gt;decay&lt;/code&gt; , &lt;code&gt;momentum&lt;/code&gt; и &lt;code&gt;epsilon&lt;/code&gt; , может быть вызываемой, не принимающей аргументов и возвращающей фактическое значение для использования. Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="a51c69c938604c7d227cd40cf800aac6b43df507" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;learning_rate&lt;/code&gt;, &lt;code&gt;rho&lt;/code&gt;, and &lt;code&gt;epsilon&lt;/code&gt; can each be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">Когда включено &lt;code&gt;rho&lt;/code&gt; , каждая из этих функций &lt;code&gt;learning_rate&lt;/code&gt; , rho и &lt;code&gt;epsilon&lt;/code&gt; может быть вызываемой, не принимающей аргументов и возвращающей фактическое значение для использования. Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="78865de3a670b7422c397c1e12a0d6935fb3e356" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;loss&lt;/code&gt; should be a Python function that takes no arguments and computes the value to be minimized. Minimization (and gradient computation) is done with respect to the elements of &lt;code&gt;var_list&lt;/code&gt; if not None, else with respect to any trainable variables created during the execution of the &lt;code&gt;loss&lt;/code&gt; function. &lt;code&gt;gate_gradients&lt;/code&gt;, &lt;code&gt;aggregation_method&lt;/code&gt;, &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; and &lt;code&gt;grad_loss&lt;/code&gt; are ignored when eager execution is enabled.</source>
          <target state="translated">Когда включено активное выполнение, &lt;code&gt;loss&lt;/code&gt; должна быть функцией Python, которая не принимает аргументов и вычисляет значение, которое необходимо минимизировать. Минимизация (и вычисление градиента) выполняется в отношении элементов &lt;code&gt;var_list&lt;/code&gt; , если не None, иначе в отношении любых обучаемых переменных, созданных во время выполнения функции &lt;code&gt;loss&lt;/code&gt; . &lt;code&gt;gate_gradients&lt;/code&gt; , &lt;code&gt;aggregation_method&lt;/code&gt; , &lt;code&gt;colocate_gradients_with_ops&lt;/code&gt; и &lt;code&gt;grad_loss&lt;/code&gt; игнорируются при нетерпеливом исполнении включено.</target>
        </trans-unit>
        <trans-unit id="a739b33250bbc25214beaa9599eadabdb7bb4665" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, &lt;code&gt;var_list&lt;/code&gt; must specify a &lt;code&gt;list&lt;/code&gt; or &lt;code&gt;dict&lt;/code&gt; of variables to save. Otherwise, a &lt;code&gt;RuntimeError&lt;/code&gt; will be raised.</source>
          <target state="translated">Когда &lt;code&gt;var_list&lt;/code&gt; выполнение включено, var_list должен указывать &lt;code&gt;list&lt;/code&gt; или &lt;code&gt;dict&lt;/code&gt; переменных для сохранения. В противном случае &lt;code&gt;RuntimeError&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="58de3a1f5573eceefbc002055806cdf8a10b2832" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, any callable object in the &lt;code&gt;control_inputs&lt;/code&gt; list will be called.</source>
          <target state="translated">Когда активное выполнение включено, будет вызываться любой вызываемый объект в списке &lt;code&gt;control_inputs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91a58274042c41959ab2122ef94206a6a2a7792d" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, code inside an init_scope block runs with eager execution enabled even when tracing a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;. For example:</source>
          <target state="translated">Когда активное выполнение включено, код внутри блока init_scope выполняется с включенным нетерпеливым исполнением даже при отслеживании &lt;a href=&quot;function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; . Например:</target>
        </trans-unit>
        <trans-unit id="7644973d82350f411122d3333c3da0b3f33b32bb" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, executes ops specified by &lt;code&gt;fn&lt;/code&gt; on each replica. Otherwise, builds a graph to execute the ops on each replica.</source>
          <target state="translated">Когда активировано активное выполнение, выполняет операции, указанные с помощью &lt;code&gt;fn&lt;/code&gt; , на каждой реплике. В противном случае строит граф для выполнения операций на каждой реплике.</target>
        </trans-unit>
        <trans-unit id="f2c02abca5b8ce6f6c1965307850901a9a73db40" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, learning_rate can be a callable that takes no arguments and returns the actual value to use. This can be useful for changing these values across different invocations of optimizer functions.</source>
          <target state="translated">При включенной функции eager execution,функция learning_rate может быть вызываемой,не принимая аргументов и возвращая фактическое значение.Это может быть полезно для изменения этих значений при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="cfdc83fece145a8a3ec7bfd53296a084c4dce787" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, returns &lt;code&gt;True&lt;/code&gt; in most cases. However, this API might return &lt;code&gt;False&lt;/code&gt; in the following use cases.</source>
          <target state="translated">Когда активировано активное выполнение, в большинстве случаев возвращает &lt;code&gt;True&lt;/code&gt; . Однако этот API может возвращать значение &lt;code&gt;False&lt;/code&gt; в следующих случаях использования.</target>
        </trans-unit>
        <trans-unit id="fca6e6a28c0b1d4d30760e6ed2b604579bf812fc" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="translated">Когда активировано &lt;a href=&quot;../../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , перезапись графа со смешанной точностью включается только внутри tf.function , поскольку вне &lt;a href=&quot;../../../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; графа отсутствует.</target>
        </trans-unit>
        <trans-unit id="cd5cd16ed9249edf9d475e4c4f731cb6a6ee674b" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, as outside &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6892adfb044f1fdf15d846e00b609e83b202685" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, as outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, there is no graph.</source>
          <target state="translated">Когда активировано &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , перезапись графа со смешанной точностью включается только внутри tf.function , поскольку вне &lt;a href=&quot;../../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; графа отсутствует.</target>
        </trans-unit>
        <trans-unit id="530f59ba986dbe23a70377c034d053b8d4dc39ba" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, the mixed precision graph rewrite is only enabled within &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, as outside &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;s, there is no graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4ced4e377065fa4ed9d5e9a06ab2254081c3e07" translate="yes" xml:space="preserve">
          <source>When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor. This can be useful for changing the learning rate value across different invocations of optimizer functions.</source>
          <target state="translated">При включенной функции быстрого выполнения эта функция возвращает функцию,которая,в свою очередь,возвращает пониженный тензор скорости обучения.Это может быть полезно для изменения значения скорости обучения при различных вызовах функций оптимизатора.</target>
        </trans-unit>
        <trans-unit id="d2e71dc36f6cf8dc4084a1f274669076eb23a06d" translate="yes" xml:space="preserve">
          <source>When enabled, TensorFlow runtime will collection information that can later be exported and consumed by TensorBoard. The trace is activated across the entire TensorFlow runtime and affects all threads of execution.</source>
          <target state="translated">Когда эта функция включена,во время работы TensorFlow будет собираться информация,которая впоследствии может быть экспортирована и потреблена TensorBoard.Трасса активируется в течение всего времени выполнения TensorFlow и влияет на все потоки выполнения.</target>
        </trans-unit>
        <trans-unit id="4de00d923ffd1999737d2b1cd351b2302e234977" translate="yes" xml:space="preserve">
          <source>When enabled, the dtype of Keras layers defaults to floatx (which is typically float32) instead of None. In addition, layers will automatically cast floating-point inputs to the layer's dtype.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c296a7d5f98201bab11940527df0b91bbde60a8b" translate="yes" xml:space="preserve">
          <source>When enum_class is empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261d0f228aa5675f9d37b49b2a148dd964803430" translate="yes" xml:space="preserve">
          <source>When enum_class is not a subclass of Enum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2564a8f9143928f594ea2074e98db1c0c92dbe63" translate="yes" xml:space="preserve">
          <source>When enum_values is empty.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4382685a76810fa4eefafb6b927a319a12869925" translate="yes" xml:space="preserve">
          <source>When exactly one of &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; is non-None, or the shapes are not all broadcastable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="947feea8d5b04906f82595b03627acd7039c1568" translate="yes" xml:space="preserve">
          <source>When exactly one of &lt;code&gt;x&lt;/code&gt; or &lt;code&gt;y&lt;/code&gt; is non-None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f4e19c79dfb2ba307013a448936b4d81569267d0" translate="yes" xml:space="preserve">
          <source>When executed in a graph, this op outputs its input tensor as-is.</source>
          <target state="translated">При выполнении на графике эта операция выводит свой входной тензор как есть.</target>
        </trans-unit>
        <trans-unit id="4cecfcec22d59fa24fae039affcbd309fee3e65f" translate="yes" xml:space="preserve">
          <source>When executed, the Tensor &lt;code&gt;a&lt;/code&gt; will have the name &lt;code&gt;MyOp/a&lt;/code&gt;.</source>
          <target state="translated">При выполнении Tensor &lt;code&gt;a&lt;/code&gt; будет иметь имя &lt;code&gt;MyOp/a&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ae9202cb150768cbd21e4a56c23a5fe6d721d720" translate="yes" xml:space="preserve">
          <source>When executed, the Tensors &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, will have names &lt;code&gt;MyOp/a&lt;/code&gt;, &lt;code&gt;MyOp/b&lt;/code&gt;, and &lt;code&gt;MyOp/c&lt;/code&gt;.</source>
          <target state="translated">При выполнении тензоры &lt;code&gt;a&lt;/code&gt; , &lt;code&gt;b&lt;/code&gt; , &lt;code&gt;c&lt;/code&gt; будут иметь имена &lt;code&gt;MyOp/a&lt;/code&gt; , &lt;code&gt;MyOp/b&lt;/code&gt; и &lt;code&gt;MyOp/c&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fe804bdbbf36ce79d174e2e04fa5a4b653cbe404" translate="yes" xml:space="preserve">
          <source>When executing eagerly, &lt;code&gt;map_fn&lt;/code&gt; does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; decorator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b4b0c36f73c370281ff533b8718b05a1bf7fc23a" translate="yes" xml:space="preserve">
          <source>When executing eagerly, &lt;code&gt;map_fn&lt;/code&gt; does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; decorator:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="50bb271b7e16cf32dee4edabc5aa3fa56b53275c" translate="yes" xml:space="preserve">
          <source>When executing eagerly, either assigns values immediately if variables to restore have been created already, or defers restoration until the variables are created. Dependencies added after this call will be matched if they have a corresponding object in the checkpoint (the restore request will queue in any trackable object waiting for the expected dependency to be added).</source>
          <target state="translated">При активном выполнении либо назначает значения немедленно,если переменные для восстановления уже созданы,либо откладывает восстановление до тех пор,пока переменные не будут созданы.Зависимости,добавленные после этого вызова,будут сопоставлены,если в контрольной точке есть соответствующий объект (запрос на восстановление будет стоять в очереди на любой отслеживаемый объект,ожидающий добавления ожидаемой зависимости).</target>
        </trans-unit>
        <trans-unit id="9f2dc68be8f34aeff876ac6aadeee84459d20f11" translate="yes" xml:space="preserve">
          <source>When executing eagerly, map_fn does not execute in parallel even if &lt;code&gt;parallel_iterations&lt;/code&gt; is set to a value &amp;gt; 1. You can still get the performance benefits of running a function in parallel by using the &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; decorator,</source>
          <target state="translated">При активном выполнении map_fn не выполняется параллельно, даже если для &lt;code&gt;parallel_iterations&lt;/code&gt; установлено значение&amp;gt; 1. Вы все равно можете получить преимущества в производительности параллельного запуска функции, используя декоратор &lt;code&gt;tf.contrib.eager.defun&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="243113db76fb85d3b379322eb6df8fc099c87214" translate="yes" xml:space="preserve">
          <source>When executing in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt; or building a model using &lt;a href=&quot;keras/input&quot;&gt;&lt;code&gt;tf.keras.Input&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;tensor#shape&quot;&gt;&lt;code&gt;Tensor.shape&lt;/code&gt;&lt;/a&gt; may return a partial shape (including &lt;code&gt;None&lt;/code&gt; for unknown dimensions). See &lt;a href=&quot;tensorshape&quot;&gt;&lt;code&gt;tf.TensorShape&lt;/code&gt;&lt;/a&gt; for more details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ce10899f8aee013da9a14ad538ad1fde8148656" translate="yes" xml:space="preserve">
          <source>When executing in a &lt;a href=&quot;function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, or building a model using &lt;a href=&quot;keras/input&quot;&gt;&lt;code&gt;tf.keras.Input&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;tensor#set_shape&quot;&gt;&lt;code&gt;Tensor.set_shape&lt;/code&gt;&lt;/a&gt; will &lt;em&gt;merge&lt;/em&gt; the given &lt;code&gt;shape&lt;/code&gt; with the current shape of this tensor, and set the tensor's shape to the merged value (see &lt;a href=&quot;tensorshape#merge_with&quot;&gt;&lt;code&gt;tf.TensorShape.merge_with&lt;/code&gt;&lt;/a&gt; for details):</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="961e80919c470474bd25500c2cb03aaf480dc1f1" translate="yes" xml:space="preserve">
          <source>When feeding features into &lt;code&gt;embedding.enqueue&lt;/code&gt; they can be &lt;a href=&quot;../../../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;s, &lt;a href=&quot;../../../sparse/sparsetensor&quot;&gt;&lt;code&gt;tf.SparseTensor&lt;/code&gt;&lt;/a&gt;s or &lt;a href=&quot;../../../raggedtensor&quot;&gt;&lt;code&gt;tf.RaggedTensor&lt;/code&gt;&lt;/a&gt;s. When the argument &lt;code&gt;max_sequence_length&lt;/code&gt; is 0, the default, you should expect a output of &lt;code&gt;embedding.dequeue&lt;/code&gt; for this feature of shape &lt;code&gt;(batch_size, dim)&lt;/code&gt;. If &lt;code&gt;max_sequence_length&lt;/code&gt; is greater than 0, the feature is embedded as a sequence and padded up to the given length. The shape of the output for this feature will be &lt;code&gt;(batch_size, max_sequence_length, dim)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d5aadb062c18b16c150d95636430095568153cdb" translate="yes" xml:space="preserve">
          <source>When giving unsupported dtype and no initializer or when trainable has been set to True with synchronization set as &lt;code&gt;ON_READ&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f8e307109474cb2469b10f7555dc21ae2944eac" translate="yes" xml:space="preserve">
          <source>When graph building, &lt;code&gt;assert_consumed()&lt;/code&gt; indicates that all of the restore ops that will be created for this checkpoint have been created. They can be run via the &lt;code&gt;run_restore_ops()&lt;/code&gt; method of the status object:</source>
          <target state="translated">При построении графика &lt;code&gt;assert_consumed()&lt;/code&gt; указывает, что все операции восстановления, которые будут созданы для этой контрольной точки, созданы. Их можно запустить с помощью &lt;code&gt;run_restore_ops()&lt;/code&gt; объекта статуса:</target>
        </trans-unit>
        <trans-unit id="79f071b74a52cc1dc25696f12242191a62439461" translate="yes" xml:space="preserve">
          <source>When graph building, restoration ops are added to the graph but not run immediately.</source>
          <target state="translated">При построении графа на график добавляются опции восстановления,но не запускаются сразу.</target>
        </trans-unit>
        <trans-unit id="50bb22b935fa898c607810aea861b6f9cab61dc5" translate="yes" xml:space="preserve">
          <source>When in TF V1 mode (that is, outside &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;) Assert needs a control dependency on the output to ensure the assertion executes:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1c8e82ac3193c4ec5ccc1a2ed347b087c3eee96b" translate="yes" xml:space="preserve">
          <source>When indexing keyword argument is not one of &lt;code&gt;xy&lt;/code&gt; or &lt;code&gt;ij&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45d6ec71b2e803e49adc786399511f890dec3b98" translate="yes" xml:space="preserve">
          <source>When indices are not consistent.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3400d0e372dbb4d788999038a1fa59202da9146e" translate="yes" xml:space="preserve">
          <source>When indices is a 1D tensor, this operation is equivalent to &lt;a href=&quot;scatter_update&quot;&gt;&lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Когда индексы представляют собой одномерный тензор, эта операция эквивалентна &lt;a href=&quot;scatter_update&quot;&gt; &lt;code&gt;tf.compat.v1.scatter_update&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="d2e52528636ed4172136496c48a5c9c765f21cc1" translate="yes" xml:space="preserve">
          <source>When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. If the input is &lt;code&gt;x&lt;/code&gt; and the operation &lt;code&gt;x * W&lt;/code&gt;, and we want to initialize &lt;code&gt;W&lt;/code&gt; uniformly at random, we need to pick &lt;code&gt;W&lt;/code&gt; from</source>
          <target state="translated">При инициализации глубокой сети, в принципе, выгодно сохранять постоянный масштаб входной дисперсии, чтобы она не взрывалась или не уменьшалась при достижении последнего уровня. Если на входе &lt;code&gt;x&lt;/code&gt; , а операция &lt;code&gt;x * W&lt;/code&gt; , и мы хотим инициализировать &lt;code&gt;W&lt;/code&gt; равномерно и случайным образом, нам нужно выбрать &lt;code&gt;W&lt;/code&gt; из</target>
        </trans-unit>
        <trans-unit id="12f77eb406d2a652e408c888d240e8eb2d9cb755" translate="yes" xml:space="preserve">
          <source>When invoking a signature in an exported SavedModel, &lt;code&gt;Tensor&lt;/code&gt; arguments are identified by name. These names will come from the Python function's argument names by default. They may be overridden by specifying a &lt;code&gt;name=...&lt;/code&gt; argument in the corresponding &lt;a href=&quot;../tensorspec&quot;&gt;&lt;code&gt;tf.TensorSpec&lt;/code&gt;&lt;/a&gt; object. Explicit naming is required if multiple &lt;code&gt;Tensor&lt;/code&gt;s are passed through a single argument to the Python function.</source>
          <target state="translated">При вызове подписи в экспортированной модели SavedModel аргументы &lt;code&gt;Tensor&lt;/code&gt; идентифицируются по имени. Эти имена по умолчанию будут взяты из имен аргументов функции Python. Их можно переопределить, указав аргумент &lt;code&gt;name=...&lt;/code&gt; в соответствующем объекте &lt;a href=&quot;../tensorspec&quot;&gt; &lt;code&gt;tf.TensorSpec&lt;/code&gt; &lt;/a&gt; . Явное именование требуется, если несколько &lt;code&gt;Tensor&lt;/code&gt; передаются через один аргумент функции Python.</target>
        </trans-unit>
        <trans-unit id="aaecdf3e3e9d1409f6d5971a54eef9da389f9db7" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="translated">При загрузке файла веса в формате &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; возвращает тот же объект статуса, что и tf.train.Checkpoint.restore . При построении графа операции восстановления запускаются автоматически, как только сеть построена (при первом вызове определяемых пользователем классов, наследующих от &lt;code&gt;Model&lt;/code&gt; , немедленно, если она уже построена).</target>
        </trans-unit>
        <trans-unit id="ad0500aa71cc2e13561fbb9f3ccb38e89738eb04" translate="yes" xml:space="preserve">
          <source>When loading a weight file in TensorFlow format, returns the same status object as &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from &lt;code&gt;Model&lt;/code&gt;, immediately if it is already built).</source>
          <target state="translated">При загрузке файла веса в формате &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; возвращает тот же объект статуса, что и tf.train.Checkpoint.restore . При построении графа операции восстановления запускаются автоматически, как только сеть построена (при первом вызове определяемых пользователем классов, наследующих от &lt;code&gt;Model&lt;/code&gt; , немедленно, если она уже построена).</target>
        </trans-unit>
        <trans-unit id="a3a6d69d15b5f2b1e2641796ab481024196abbd1" translate="yes" xml:space="preserve">
          <source>When loading weights in HDF5 format, returns &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">При загрузке весов в формате HDF5 возвращает &lt;code&gt;None&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="279df71b03d4f1d2b500da71eaeb34af2e345a5e" translate="yes" xml:space="preserve">
          <source>When many instances of this Op are being run concurrently with the same container/shared_name in the same device, some will output zero-shaped Tensors and others will output Tensors of size up to max_batch_size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="caebbca103b05daa9db25a1f91ee52187b92666d" translate="yes" xml:space="preserve">
          <source>When mixed precision training is used, most layers will instead have a float16 or bfloat16 compute dtype and a float32 variable dtype, and so the layer does not have a single dtype. See &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;this link&lt;/a&gt; for more information on mixed precision training. When the variable dtype does not match the compute dtype, variables will be automatically casted to the compute dtype to avoid type errors. In this case, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt; refers to the variable dtype, not the compute dtype.</source>
          <target state="translated">Когда используется обучение со смешанной точностью, большинство слоев вместо этого будут иметь вычисляемый dtype float16 или bfloat16 и переменную dtype float32, поэтому у слоя нет единственного dtype. См. &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;Эту ссылку&lt;/a&gt; для получения дополнительной информации о тренировке смешанной точности. Когда переменная dtype не соответствует вычисляемому dtype, переменные будут автоматически преобразованы в вычисляемый dtype, чтобы избежать ошибок типа. В этом случае &lt;a href=&quot;../../layers/layer#dtype&quot;&gt; &lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt; &lt;/a&gt; относится к переменной dtype, а не к вычисляемому dtype.</target>
        </trans-unit>
        <trans-unit id="31e5d2d74d34d722ae24b0d3557c28c55ecaa6d6" translate="yes" xml:space="preserve">
          <source>When mixed precision training is used, most layers will instead have a float16 or bfloat16 compute dtype and a float32 variable dtype, and so the layer does not have a single dtype. When the variable dtype does not match the compute dtype, variables will be automatically casted to the compute dtype to avoid type errors. In this case, &lt;a href=&quot;../../layers/layer#dtype&quot;&gt;&lt;code&gt;tf.keras.layers.Layer.dtype&lt;/code&gt;&lt;/a&gt; refers to the variable dtype, not the compute dtype. See &lt;a href=&quot;https://www.tensorflow.org/guide/keras/mixed_precision&quot;&gt;the mixed precision guide&lt;/a&gt; for more information on how to use mixed precision.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12dfe9c646058fc3b646723517e40b30a435cf72" translate="yes" xml:space="preserve">
          <source>When mode is not one of &quot;CONSTANT&quot;, &quot;REFLECT&quot;, or &quot;SYMMETRIC&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e594a784be178d46ade99237614f3d81b376cb0c" translate="yes" xml:space="preserve">
          <source>When multiple identical random ops are wrapped in a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;, their behaviors change because the ops no long share the same counter. For example:</source>
          <target state="translated">Когда несколько одинаковых случайных операций заключены в функцию &lt;a href=&quot;../function&quot;&gt; &lt;code&gt;tf.function&lt;/code&gt; &lt;/a&gt; , их поведение меняется, потому что операции больше не используют один и тот же счетчик. Например:</target>
        </trans-unit>
        <trans-unit id="2fdc190461b8260acb4e4a0e40690fe99685019d" translate="yes" xml:space="preserve">
          <source>When multiple steps of profiles are available, select which step's profile to use. If -1, use average of all available steps.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbe07c906de9609ba47c0d5dc628f10d68cc6dd7" translate="yes" xml:space="preserve">
          <source>When no keyword arguments (kwargs) are passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5b5b5298719274d2e99620e5ca7a91daabe32b28" translate="yes" xml:space="preserve">
          <source>When not &lt;code&gt;None&lt;/code&gt;, the probability we will drop out a given coordinate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9f319b17be698e68a66d41691883dcc29fc7f9c6" translate="yes" xml:space="preserve">
          <source>When not None, the probability we will drop out a given coordinate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f589095e3d5fab094abecc7eb9696d68f8a9c36d" translate="yes" xml:space="preserve">
          <source>When operating in a v1-style graph context, ops are not executed in the same order as specified in the code; TensorFlow will attempt to execute ops in parallel or in an order convienient to the result it is computing. &lt;a href=&quot;group&quot;&gt;&lt;code&gt;tf.group&lt;/code&gt;&lt;/a&gt; allows you to request that one or more results finish before execution continues.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c3fc5b0a3b9961cb77e88c8942ce57281e9ad832" translate="yes" xml:space="preserve">
          <source>When passed &lt;code&gt;trainable=True&lt;/code&gt;, the &lt;code&gt;Variable()&lt;/code&gt; constructor automatically adds new variables to the graph collection &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt;. This convenience function returns the contents of that collection.</source>
          <target state="translated">Если передано значение &lt;code&gt;trainable=True&lt;/code&gt; , конструктор &lt;code&gt;Variable()&lt;/code&gt; автоматически добавляет новые переменные в коллекцию графов &lt;code&gt;GraphKeys.TRAINABLE_VARIABLES&lt;/code&gt; . Эта вспомогательная функция возвращает содержимое этой коллекции.</target>
        </trans-unit>
        <trans-unit id="5b6a28f5fad1b02dbaf2abf3b2bcae0d38a29c7b" translate="yes" xml:space="preserve">
          <source>When reading a single input file, you can shard elements as follows:</source>
          <target state="translated">При прочтении одного входного файла,элементы могут быть шарсированы следующим образом:</target>
        </trans-unit>
        <trans-unit id="5d6c412525d35ed49e0a016246bbab95a1ad4343" translate="yes" xml:space="preserve">
          <source>When run, it returns a 1-D tensor containing the names of uninitialized variables if there are any, or an empty array if there are none.</source>
          <target state="translated">При запуске возвращается 1-D тензор,содержащий имена неинициализированных переменных,если они есть,или пустой массив,если его нет.</target>
        </trans-unit>
        <trans-unit id="4cd96e8d064773862a00f08fa46097675a613f49" translate="yes" xml:space="preserve">
          <source>When run, reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if &lt;code&gt;tensor&lt;/code&gt; has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes &lt;code&gt;tensor&lt;/code&gt; as-is.</source>
          <target state="translated">При запуске сообщает об ошибке &lt;code&gt;InvalidArgument&lt;/code&gt; , если &lt;code&gt;tensor&lt;/code&gt; имеет какие-либо значения, не являющиеся числом (NaN) или бесконечностью (Inf). В противном случае &lt;code&gt;tensor&lt;/code&gt; передается как есть.</target>
        </trans-unit>
        <trans-unit id="9a7fb4ad12e1e9b24a4a905d1465aa8fe6223f81" translate="yes" xml:space="preserve">
          <source>When run, reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if &lt;code&gt;tensor&lt;/code&gt; has any values that are not a number (NaN) or infinity (Inf). Otherwise, passes &lt;code&gt;tensor&lt;/code&gt; as-is. Unlike CheckNumerics (V1), CheckNumericsV2 distinguishes -Inf and +Inf in the errors it throws.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a08b94134a846722329d59d0e06daaabf9e81c0e" translate="yes" xml:space="preserve">
          <source>When run, the returned Op will raise the exception &lt;code&gt;FailedPreconditionError&lt;/code&gt; if any of the variables has not yet been initialized.</source>
          <target state="translated">При запуске возвращенная &lt;code&gt;FailedPreconditionError&lt;/code&gt; исключение FailedPreconditionError, если какая-либо из переменных еще не была инициализирована.</target>
        </trans-unit>
        <trans-unit id="612235a5e3b2319598b46d42d78d5e3939c685ba" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you must evaluate the tensor returned by &lt;code&gt;tf.tables_initializer()&lt;/code&gt; before evaluating the tensor returned by this class's &lt;code&gt;lookup()&lt;/code&gt; method. Example usage in graph mode:</source>
          <target state="translated">При работе в графическом режиме вы должны оценить тензор, возвращаемый &lt;code&gt;tf.tables_initializer()&lt;/code&gt; перед тем, как оценивать тензор, возвращаемый методом &lt;code&gt;lookup()&lt;/code&gt; этого класса . Пример использования в графическом режиме:</target>
        </trans-unit>
        <trans-unit id="7eea4af19c3fd0977360ee69dfc63bed5794fb89" translate="yes" xml:space="preserve">
          <source>When running in graph mode, you should add a dependency on this operation to ensure that it runs. Example of adding a dependency to an operation:</source>
          <target state="translated">При работе в графическом режиме необходимо добавить зависимость от этой операции,чтобы убедиться,что она выполняется.Пример добавления зависимости к операции:</target>
        </trans-unit>
        <trans-unit id="83f395cc48e2b9d73bdec46f8abf442be27de226" translate="yes" xml:space="preserve">
          <source>When saving in HDF5 format, the weight file has:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23b4a5289feb34fa15683e70f83d2559b44972e8" translate="yes" xml:space="preserve">
          <source>When saving in HDF5 format, the weight file has: - &lt;code&gt;layer_names&lt;/code&gt; (attribute), a list of strings (ordered names of model layers). - For every layer, a &lt;code&gt;group&lt;/code&gt; named &lt;code&gt;layer.name&lt;/code&gt; - For every such layer group, a group attribute &lt;code&gt;weight_names&lt;/code&gt;, a list of strings (ordered names of weights tensor of the layer). - For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</source>
          <target state="translated">При сохранении в формате HDF5 весовой файл содержит: - &lt;code&gt;layer_names&lt;/code&gt; (атрибут), список строк (упорядоченные имена слоев модели). - Для каждого слоя &lt;code&gt;group&lt;/code&gt; именем &lt;code&gt;layer.name&lt;/code&gt; - Для каждой такой группы слоев - атрибут группы &lt;code&gt;weight_names&lt;/code&gt; , список строк (упорядоченные имена тензора весов слоя). - Для каждого веса в слое набор данных, в котором хранится значение веса, названное в честь тензора веса.</target>
        </trans-unit>
        <trans-unit id="c275f46f84d94fb1e86dc221ba0e2772a4b65944" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">При сохранении в формате TensorFlow все объекты, на которые ссылается сеть, сохраняются в том же формате, что и &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , включая любые экземпляры &lt;code&gt;Layer&lt;/code&gt; или экземпляры &lt;code&gt;Optimizer&lt;/code&gt; назначенные атрибутам объекта. Для сетей, построенных из входов и выходов с использованием &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt; , экземпляры &lt;code&gt;Layer&lt;/code&gt; используемые сетью, отслеживаются / сохраняются автоматически. Для определяемых пользователем классов, которые наследуются от &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; , экземпляры &lt;code&gt;Layer&lt;/code&gt; должны быть назначены атрибутам объекта, обычно в конструкторе. Подробности см. В документации &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="58ff97a8bb50647c4ab49957faee2741efb3b467" translate="yes" xml:space="preserve">
          <source>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;, including any &lt;code&gt;Layer&lt;/code&gt; instances or &lt;code&gt;Optimizer&lt;/code&gt; instances assigned to object attributes. For networks constructed from inputs and outputs using &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt;, &lt;code&gt;Layer&lt;/code&gt; instances used by the network are tracked/saved automatically. For user-defined classes which inherit from &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Layer&lt;/code&gt; instances must be assigned to object attributes, typically in the constructor. See the documentation of &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">При сохранении в формате TensorFlow все объекты, на которые ссылается сеть, сохраняются в том же формате, что и &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; , включая любые экземпляры &lt;code&gt;Layer&lt;/code&gt; или экземпляры &lt;code&gt;Optimizer&lt;/code&gt; назначенные атрибутам объекта. Для сетей, построенных из входов и выходов с использованием &lt;code&gt;tf.keras.Model(inputs, outputs)&lt;/code&gt; , экземпляры &lt;code&gt;Layer&lt;/code&gt; используемые сетью, отслеживаются / сохраняются автоматически. Для определяемых пользователем классов, которые наследуются от &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; , экземпляры &lt;code&gt;Layer&lt;/code&gt; должны быть назначены атрибутам объекта, обычно в конструкторе. Подробности см. В документации &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="784c3ca10c1f2c8309f633399d4061eef62d41bd" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are Tensors representing shapes (i.e. the result of calling tf.shape on another Tensor) this computes a Tensor which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="translated">Когда фигура_x и фигура_y-это тензоры,представляющие фигуры (т.е.результат вызова tf.shape на другом тензоре),это вычисляет тензор,который является формой результата широковещательного оптического воздействия,применяемого в тензорах фигур shape_x и shape_y.</target>
        </trans-unit>
        <trans-unit id="382f3819ea47b409f9da2d9eacd00a3f2dc7a1b2" translate="yes" xml:space="preserve">
          <source>When shape_x and shape_y are fully known TensorShapes this computes a TensorShape which is the shape of the result of a broadcasting op applied in tensors of shapes shape_x and shape_y.</source>
          <target state="translated">Когда фигуры shape_x и shape_y полностью известны TensorShapes,вычисляется TensorShape,которая является формой результата широковещательного оптического воздействия,применяемого в тензорах фигур shape_x и shape_y.</target>
        </trans-unit>
        <trans-unit id="b25a4e208695ca5ecbc4dac0901769cfec692d0d" translate="yes" xml:space="preserve">
          <source>When sparse_delta.indices is a 1D tensor, this operation is equivalent to &lt;code&gt;scatter_update&lt;/code&gt;.</source>
          <target state="translated">Когда sparse_delta.indices является одномерным тензором, эта операция эквивалентна &lt;code&gt;scatter_update&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d43e498906b2adf0ec7959c38a4a8cf0f9fa7d0b" translate="yes" xml:space="preserve">
          <source>When starting a dedicated tf.data dispatch process, use join() to block indefinitely after starting up the server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="934351906a686e71e8e5a944d6c4af715197c11e" translate="yes" xml:space="preserve">
          <source>When starting a dedicated tf.data worker process, use join() to block indefinitely after starting up the server.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5fee3dffe2d54b65ce0a85843a0d39fb34dec340" translate="yes" xml:space="preserve">
          <source>When that Op is run it tries to increment the variable by &lt;code&gt;1&lt;/code&gt;. If incrementing the variable would bring it above &lt;code&gt;limit&lt;/code&gt; then the Op raises the exception &lt;code&gt;OutOfRangeError&lt;/code&gt;.</source>
          <target state="translated">Когда эта операция выполняется, она пытается увеличить переменную на &lt;code&gt;1&lt;/code&gt; . Если увеличение переменной приведет к превышению &lt;code&gt;limit&lt;/code&gt; тогда Op вызывает исключение &lt;code&gt;OutOfRangeError&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a324d7f1e796820d05403b217fea01aa17af935a" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;GraphDef&lt;/code&gt; is larger than 2GB.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1856bfeda6ff30a3afd3efdbb33b44e8e2b972ce" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;LinearOperator&lt;/code&gt; is not hinted to be &lt;code&gt;non_singular&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56cd8af2612b32012d09c54f7e15310ad702ad5c" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;LinearOperator&lt;/code&gt; is not hinted to be positive definite and self adjoint.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ae5f82f4e0944c8fdd12da34fb5e45708d0e8f6" translate="yes" xml:space="preserve">
          <source>When the CrossShardOptimizer is constructed with &lt;code&gt;reduction == losses.Reduction.MEAN&lt;/code&gt; (default), this function scales the loss by &lt;code&gt;1.0 / num_shards&lt;/code&gt; before computing the gradients. Assuming the optimizer uses the default implementation of &lt;code&gt;compute_gradients()&lt;/code&gt;, the gradients of the scaled loss are scaled by &lt;code&gt;1.0 / num_shards&lt;/code&gt; compared to the gradients of the original loss. This scaling factor is important because &lt;code&gt;apply_gradients()&lt;/code&gt; sums gradients across shards, rather than averaging them. However, the scaling factor must be taken into account when clipping the norm of the gradients or performing other postprocessing.</source>
          <target state="translated">Когда CrossShardOptimizer сконструирован с &lt;code&gt;reduction == losses.Reduction.MEAN&lt;/code&gt; (по умолчанию), эта функция масштабирует потерю на &lt;code&gt;1.0 / num_shards&lt;/code&gt; перед вычислением градиентов. Предполагая, что оптимизатор использует реализацию &lt;code&gt;compute_gradients()&lt;/code&gt; по умолчанию , градиенты масштабированных потерь масштабируются на &lt;code&gt;1.0 / num_shards&lt;/code&gt; по сравнению с градиентами исходных потерь. Этот коэффициент масштабирования важен, потому что &lt;code&gt;apply_gradients()&lt;/code&gt; суммирует градиенты по шардам, а не усредняет их. Однако коэффициент масштабирования необходимо учитывать при отсечении нормы градиентов или выполнении другой постобработки.</target>
        </trans-unit>
        <trans-unit id="62b085231fa47179e1be16442d315153db83ffe4" translate="yes" xml:space="preserve">
          <source>When the Op is run, it reports an &lt;code&gt;InvalidArgument&lt;/code&gt; error if multiple values in the summaries to merge use the same tag.</source>
          <target state="translated">Когда &lt;code&gt;InvalidArgument&lt;/code&gt; выполняется, она сообщает об ошибке InvalidArgument, если несколько значений в сводках для слияния используют один и тот же тег.</target>
        </trans-unit>
        <trans-unit id="a17f60db047668212c07e424cf0f21e2e8e6e67e" translate="yes" xml:space="preserve">
          <source>When the RNN layer is not stateful.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8b5dd0fb66417bcf00267bf905ed39a50b9ed42" translate="yes" xml:space="preserve">
          <source>When the batch size of the RNN layer is unknown.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04c6456a46e3c6718694244e79e5c206d69bdf28" translate="yes" xml:space="preserve">
          <source>When the file to be loaded is not found.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c426d27facbfbf4fa665efb6cfbd82b969658b0" translate="yes" xml:space="preserve">
          <source>When the input numpy array is not compatible with the RNN layer state, either size wise or dtype wise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3584f2f08e6dde164e436c25cc19bcd86167e861" translate="yes" xml:space="preserve">
          <source>When the timeout argument is not present or None, the operation will block until the thread terminates.</source>
          <target state="translated">Когда аргумент таймаута отсутствует или Нет,операция будет блокироваться до тех пор,пока поток не завершит свою работу.</target>
        </trans-unit>
        <trans-unit id="93008cafbefd82e0878a6b1b3873678eb838ef6d" translate="yes" xml:space="preserve">
          <source>When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call isAlive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out.</source>
          <target state="translated">Когда аргумент таймаута присутствует,а не None,это должно быть число с плавающей точкой,указывающее таймаут операции в секундах (или долях).Поскольку функция join()всегда возвращает None,необходимо вызывать isAlive()после функции join(),чтобы решить,произошел ли таймаут --если поток все еще жив,то функция join()должна вызывать таймаут.</target>
        </trans-unit>
        <trans-unit id="df9a68fd13d29e9ba4462924730a99e7d6cbe88d" translate="yes" xml:space="preserve">
          <source>When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call is_alive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="df29949db6d12bcc6440a4ff55b2a3b63f98638c" translate="yes" xml:space="preserve">
          <source>When the underlying interpreter fails raise ValueError.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79079716d44440c95fa5813292d42c940b3c76a3" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. If gradients are instead computed with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, loss scaling will not be applied, which will likely cause your model not to converge due to float16 underflow problems. To apply lossing scaling with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer#get_scaled_loss&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_scaled_loss&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer#get_unscaled_gradients&quot;&gt;&lt;code&gt;LossScaleOptimizer.get_unscaled_gradients&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&quot;../../keras/mixed_precision/experimental/lossscaleoptimizer&quot;&gt;&lt;code&gt;keras.mixed_precision.experimental.LossScaleOptimizer&lt;/code&gt;&lt;/a&gt; for details how to do this.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5afcb3cf29a4af014bb340f2f0c516a9732b6d10" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="translated">Когда используется эта функция, градиенты должны вычисляться и применяться только с возвращенным оптимизатором, либо путем вызова &lt;code&gt;opt.minimize()&lt;/code&gt; или &lt;code&gt;opt.compute_gradients()&lt;/code&gt; последующим &lt;code&gt;opt.apply_gradients()&lt;/code&gt; . Градиенты не следует вычислять с помощью &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . Это связано с тем, что возвращенный оптимизатор будет применять масштабирование потерь, а &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; - нет. Если вы напрямую используете &lt;a href=&quot;../../../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; , ваша модель может не сходиться из-за проблем с переполнением float16.</target>
        </trans-unit>
        <trans-unit id="caac8e6b5e9c55ec72ae9a078f806e80238a5f0b" translate="yes" xml:space="preserve">
          <source>When this function is used, gradients should only be computed and applied with the returned optimizer, either by calling &lt;code&gt;opt.minimize()&lt;/code&gt; or &lt;code&gt;opt.compute_gradients()&lt;/code&gt; followed by &lt;code&gt;opt.apply_gradients()&lt;/code&gt;. Gradients should not be computed with &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;. This is because the returned optimizer will apply loss scaling, and &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt; will not. If you do directly use &lt;a href=&quot;../../gradients&quot;&gt;&lt;code&gt;tf.gradients&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../../gradienttape&quot;&gt;&lt;code&gt;tf.GradientTape&lt;/code&gt;&lt;/a&gt;, your model may not converge due to float16 underflow problems.</source>
          <target state="translated">Когда используется эта функция, градиенты должны вычисляться и применяться только с возвращенным оптимизатором, либо путем вызова &lt;code&gt;opt.minimize()&lt;/code&gt; или &lt;code&gt;opt.compute_gradients()&lt;/code&gt; последующим &lt;code&gt;opt.apply_gradients()&lt;/code&gt; . Градиенты не следует вычислять с помощью &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; . Это связано с тем, что возвращенный оптимизатор будет применять масштабирование потерь, а &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; - нет. Если вы напрямую используете &lt;a href=&quot;../../gradients&quot;&gt; &lt;code&gt;tf.gradients&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../../gradienttape&quot;&gt; &lt;code&gt;tf.GradientTape&lt;/code&gt; &lt;/a&gt; , ваша модель может не сходиться из-за проблем с переполнением float16.</target>
        </trans-unit>
        <trans-unit id="00a169e018bcf148a01078627fb468a85b4f57d1" translate="yes" xml:space="preserve">
          <source>When this is called, the graph is finalized and ops can no longer be added to the graph.</source>
          <target state="translated">Когда это называется,график завершается,и операторы больше не могут быть добавлены на график.</target>
        </trans-unit>
        <trans-unit id="69ace3a238de55ef5f17d0593a3426df7375ca43" translate="yes" xml:space="preserve">
          <source>When this is true, the Adam update formula is changed from &lt;code&gt;m / (sqrt(v) + epsilon)&lt;/code&gt; to &lt;code&gt;m / sqrt(v + epsilon**2)&lt;/code&gt;. This option improves the performance of TPU training and is not expected to harm model quality.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f06429721d1fc01498f2381f4946b62026a0283c" translate="yes" xml:space="preserve">
          <source>When this op finishes, all ops in &lt;code&gt;inputs&lt;/code&gt; have finished. This op has no output.</source>
          <target state="translated">Когда эта операция завершается, все операции во &lt;code&gt;inputs&lt;/code&gt; завершены. Эта операция не имеет вывода.</target>
        </trans-unit>
        <trans-unit id="e93fcaa76656fcbb53b75ad595ffb1773a2d63ac" translate="yes" xml:space="preserve">
          <source>When tracing a function, no ops are being executed, shapes may be unknown. See the &lt;a href=&quot;https://www.tensorflow.org/guide/concrete_function&quot;&gt;Concrete Functions Guide&lt;/a&gt; for details.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="db72b6d879a1722ab8b371aaaee80aaed3e96f22" translate="yes" xml:space="preserve">
          <source>When training a model, it is often beneficial to maintain moving averages of the trained parameters. Evaluations that use averaged parameters sometimes produce significantly better results than the final trained values.</source>
          <target state="translated">При обучении модели часто полезно поддерживать скользящие средние значения обученных параметров.Оценки,использующие усредненные параметры,иногда дают значительно лучшие результаты,чем окончательные обученные значения.</target>
        </trans-unit>
        <trans-unit id="927a8a21e9e3520f84a7ae9e37d363926dbaebe1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере обучения. Эта функция применяет функцию спада косинуса к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="8d86dcb91899a78227813e8c0d47037c6ee19dfd" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a cosine decay function with restarts to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Эта функция применяет функцию затухания косинуса с перезапусками до заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="90010651f41909cacf9403b614efcb8bd58e1369" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Эта функция применяет функцию затухания линейного косинуса к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="6a9c3656ff265f4bda198cf8e5dfd044fb933790" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies a noisy linear cosine decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере обучения. Эта функция применяет зашумленную функцию затухания линейного косинуса к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="64048e6ec72e37dd6f4daf26af9d33a56f72d8c7" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires a &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере обучения. Эта функция применяет функцию экспоненциального затухания к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="d181a155b50eadc32c09739aa94b40b51fe01a65" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an exponential decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Эта функция применяет функцию экспоненциального затухания к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="4f6fc97dc42e006ec89048c76f7f47de1eeb3d9a" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This function applies an inverse decay function to a provided initial learning rate. It requires an &lt;code&gt;global_step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Эта функция применяет функцию обратного затухания к заданной начальной скорости обучения. Для вычисления &lt;code&gt;global_step&lt;/code&gt; скорости обучения требуется значение global_step . Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="4ddff8c9e5ff83f95e35cc80fb672fdcfe082715" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Этот график применяет функцию затухания косинуса к шагу оптимизатора при заданной начальной скорости обучения. Требуется значение &lt;code&gt;step&lt;/code&gt; для вычисления снижающейся скорости обучения. Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="512b0ee6d1762189943ee9ddad5e78bda622dc14" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a cosine decay function with restarts to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере обучения. В этом расписании применяется функция косинусного затухания с перезапусками на шаг оптимизатора при заданной начальной скорости обучения. Требуется значение &lt;code&gt;step&lt;/code&gt; для вычисления снижающейся скорости обучения. Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="93d56e5e126f6377bdf1a06e2189c730d031c2b4" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Этот график применяет линейную функцию затухания косинуса к шагу оптимизатора при заданной начальной скорости обучения. Требуется значение &lt;code&gt;step&lt;/code&gt; для вычисления снижающейся скорости обучения. Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="57bf3cf4acea41746a7afc38b8058640564015fe" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies a noisy linear cosine decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере продвижения обучения. Этот график применяет функцию затухания линейного косинуса с шумом к шагу оптимизатора при заданной начальной скорости обучения. Требуется значение &lt;code&gt;step&lt;/code&gt; для вычисления снижающейся скорости обучения. Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="94deb77d4f75eb579f72f3db2e455ef2c44c44e1" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies an exponential decay function to an optimizer step, given a provided initial learning rate.</source>
          <target state="translated">При обучении по той или иной модели часто рекомендуется снижать скорость обучения по мере продвижения обучения.Этот график применяет функцию экспоненциального затухания к шагу оптимизатора при заданном начальном темпе обучения.</target>
        </trans-unit>
        <trans-unit id="fb18244719acd2825faa9890d721d54e05f0a037" translate="yes" xml:space="preserve">
          <source>When training a model, it is often recommended to lower the learning rate as the training progresses. This schedule applies the inverse decay function to an optimizer step, given a provided initial learning rate. It requires a &lt;code&gt;step&lt;/code&gt; value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.</source>
          <target state="translated">При обучении модели часто рекомендуется снижать скорость обучения по мере обучения. Этот график применяет функцию обратного затухания к шагу оптимизатора при заданной начальной скорости обучения. Требуется значение &lt;code&gt;step&lt;/code&gt; для вычисления снижающейся скорости обучения. Вы можете просто передать переменную TensorFlow, которую вы увеличиваете на каждом этапе обучения.</target>
        </trans-unit>
        <trans-unit id="0cf6ec8113a82c824118b19bb4f2d871de8f3f5d" translate="yes" xml:space="preserve">
          <source>When used with &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;, outside of built-in training loops such as &lt;a href=&quot;../../keras&quot;&gt;&lt;code&gt;tf.keras&lt;/code&gt;&lt;/a&gt;&lt;code&gt;compile&lt;/code&gt; and &lt;code&gt;fit&lt;/code&gt;, please use 'SUM' or 'NONE' reduction types, and reduce losses explicitly in your training loop. Using 'AUTO' or 'SUM_OVER_BATCH_SIZE' will raise an error.</source>
          <target state="translated">При использовании с &lt;a href=&quot;../../distribute/strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; , помимо встроенных циклов обучения, таких как &lt;code&gt;compile&lt;/code&gt; и &lt;code&gt;fit&lt;/code&gt; &lt;a href=&quot;../../keras&quot;&gt; &lt;code&gt;tf.keras&lt;/code&gt; &lt;/a&gt; , используйте типы сокращения &amp;laquo;SUM&amp;raquo; или &amp;laquo;NONE&amp;raquo; и явно уменьшайте потери в цикле обучения. Использование &amp;laquo;AUTO&amp;raquo; или &amp;laquo;SUM_OVER_BATCH_SIZE&amp;raquo; вызовет ошибку.</target>
        </trans-unit>
        <trans-unit id="c6a537963fdbb8e6b3429be0c961e7b0d2a0a449" translate="yes" xml:space="preserve">
          <source>When used, it overrides name_ and is not made unique. If a template of the same scope/unique_name already exists and reuse is false, an error is raised. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58c97e844aea42b09b6f861449f7ea173f99a04f" translate="yes" xml:space="preserve">
          <source>When using InputLayer with Keras Sequential model, it can be skipped by moving the input_shape parameter to the first layer after the InputLayer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ecb7ac1c54db33d719cbd8ca1f72cb0bec98edc" translate="yes" xml:space="preserve">
          <source>When using a custom callable for &lt;code&gt;split&lt;/code&gt;, the data received by the callable will have the 1st dimension squeezed out - instead of &lt;code&gt;[[&quot;string to split&quot;], [&quot;another string to split&quot;]]&lt;/code&gt;, the Callable will see &lt;code&gt;[&quot;string to split&quot;, &quot;another string to split&quot;]&lt;/code&gt;. The callable should return a Tensor with the first dimension containing the split tokens - in this example, we should see something like &lt;code&gt;[[&quot;string&quot;, &quot;to&quot;, &quot;split], [&quot;another&quot;, &quot;string&quot;, &quot;to&quot;, &quot;split&quot;]]&lt;/code&gt;. This makes the callable site natively compatible with &lt;a href=&quot;../../../../strings/split&quot;&gt;&lt;code&gt;tf.strings.split()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4658ae77687cb1c8967c8186bb04e6986f0779aa" translate="yes" xml:space="preserve">
          <source>When using a custom callable for &lt;code&gt;standardize&lt;/code&gt;, the data received by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e0724c7bfb29f8f0c6cdcbe1954184f010886b9c" translate="yes" xml:space="preserve">
          <source>When using multiple critical sections on the same resources, there is no guarantee of exclusive access to those resources. This behavior is disallowed by default (but see the kwarg &lt;code&gt;exclusive_resource_access&lt;/code&gt;).</source>
          <target state="translated">При использовании нескольких критических разделов на одних и тех же ресурсах нет гарантии монопольного доступа к этим ресурсам. Это поведение по умолчанию запрещено (но см. Kwarg &lt;code&gt;exclusive_resource_access&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="005ecd21a6428476fbceb142b210d5384fc2790a" translate="yes" xml:space="preserve">
          <source>When using the default, an appropriate policy will be picked automatically. The default policy may change over time.</source>
          <target state="translated">При использовании по умолчанию соответствующая политика будет выбрана автоматически.Политика по умолчанию может меняться со временем.</target>
        </trans-unit>
        <trans-unit id="67d49a53dc96e389873c164cb198f138ecc7ff2f" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">При использовании этих моментов для пакетной нормализации (см. &lt;a href=&quot;../../../nn/batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="591b74326af491d6abfab42a671eba7ebb5be83e" translate="yes" xml:space="preserve">
          <source>When using these moments for batch normalization (see &lt;a href=&quot;batch_normalization&quot;&gt;&lt;code&gt;tf.nn.batch_normalization&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">При использовании этих моментов для пакетной нормализации (см. &lt;a href=&quot;batch_normalization&quot;&gt; &lt;code&gt;tf.nn.batch_normalization&lt;/code&gt; &lt;/a&gt; ):</target>
        </trans-unit>
        <trans-unit id="ea3d2206487c99a74b50234d9380045457ab56b2" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide an &lt;code&gt;input_shape&lt;/code&gt; argument (tuple of integers or &lt;code&gt;None&lt;/code&gt;, e.g. &lt;code&gt;(10, 128)&lt;/code&gt; for sequences of 10 vectors of 128-dimensional vectors, or &lt;code&gt;(None, 128)&lt;/code&gt; for variable-length sequences of 128-dimensional vectors.</source>
          <target state="translated">При использовании этого уровня в качестве первого уровня в модели &lt;code&gt;input_shape&lt;/code&gt; аргумент input_shape (кортеж целых чисел или &lt;code&gt;None&lt;/code&gt; , например &lt;code&gt;(10, 128)&lt;/code&gt; для последовательностей из 10 векторов из 128-мерных векторов или &lt;code&gt;(None, 128)&lt;/code&gt; для переменной длины последовательности 128-мерных векторов.</target>
        </trans-unit>
        <trans-unit id="0a409624f20a1b12afa97b438af1e2c02851ec80" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 1)&lt;/code&gt; for 128x128x128 volumes with a single channel, in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">При использовании этого слоя в качестве первого слоя в модели &lt;code&gt;input_shape&lt;/code&gt; аргумент ключевого слова input_shape (кортеж целых чисел, не включает ось выборки), например &lt;code&gt;input_shape=(128, 128, 128, 1)&lt;/code&gt; для томов 128x128x128 с одним каналом, в &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="14d463d2a8afe47183522c1acdade8296e826653" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 128, 3)&lt;/code&gt; for a 128x128x128 volume with 3 channels if &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">При использовании этого слоя в качестве первого слоя в модели &lt;code&gt;input_shape&lt;/code&gt; аргумент ключевого слова input_shape (кортеж целых чисел, не включает ось выборки), например &lt;code&gt;input_shape=(128, 128, 128, 3)&lt;/code&gt; для объема 128x128x128 с 3 каналами, если &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b700c0ba9e5af2d79f0ea705fd60f2846a05cd69" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 128, 3)&lt;/code&gt; for 128x128 RGB pictures in &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt;.</source>
          <target state="translated">При использовании этого слоя в качестве первого слоя в модели &lt;code&gt;input_shape&lt;/code&gt; аргумент ключевого слова input_shape (кортеж целых чисел, не включает ось выборки), например &lt;code&gt;input_shape=(128, 128, 3)&lt;/code&gt; для изображений RGB 128x128 в &lt;code&gt;data_format=&quot;channels_last&quot;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="39c55fa13fdb10b59035551c9a262071686d849a" translate="yes" xml:space="preserve">
          <source>When using this layer as the first layer in a model, provide the keyword argument &lt;code&gt;input_shape&lt;/code&gt; (tuple of integers, does not include the sample axis), e.g. &lt;code&gt;input_shape=(128, 3)&lt;/code&gt; for data with 128 time steps and 3 channels.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="90420d916accea41b90f4795021da2ee04f4f6d6" translate="yes" xml:space="preserve">
          <source>When variables are assigned to multiple workers, each worker writes its own section of the checkpoint. These sections are then merged/re-indexed to behave as a single checkpoint. This avoids copying all variables to one worker, but does require that all workers see a common filesystem.</source>
          <target state="translated">При назначении переменных нескольким работникам каждый работник записывает свой участок контрольно-пропускного пункта.Затем эти секции объединяются/реиндексируются,чтобы вести себя как одна контрольно-пропускная точка.Это позволяет избежать копирования всех переменных на одного рабочего,но требует,чтобы все рабочие видели общую файловую систему.</target>
        </trans-unit>
        <trans-unit id="d43c37e91c1c99cab60a11a374e0ae141f677fad" translate="yes" xml:space="preserve">
          <source>When writing a TensorFlow program, the main object that is manipulated and passed around is the &lt;a href=&quot;tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5727fc2aeafda851fc9ab281a980ef4c906dc39b" translate="yes" xml:space="preserve">
          <source>When you build a model for training you usually need ops to initialize variables, a &lt;code&gt;Saver&lt;/code&gt; to checkpoint them, an op to collect summaries for the visualizer, and so on.</source>
          <target state="translated">Когда вы строите модель для обучения, вам обычно нужны операторы для инициализации переменных, &lt;code&gt;Saver&lt;/code&gt; для их проверки, операция для сбора сводок для визуализатора и так далее.</target>
        </trans-unit>
        <trans-unit id="2571f0d8bc64be0b275df26c714df2c7b618a158" translate="yes" xml:space="preserve">
          <source>When you iterate over a dataset containing the &lt;code&gt;distribute&lt;/code&gt; transformation, the tf.data service creates a &quot;job&quot; which produces data for the dataset iteration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="39d490a1a6c041251d0a268b335edd8cf95e7a4b" translate="yes" xml:space="preserve">
          <source>When you later call the &lt;code&gt;create_threads()&lt;/code&gt; method, the &lt;code&gt;QueueRunner&lt;/code&gt; will create one thread for each op in &lt;code&gt;enqueue_ops&lt;/code&gt;. Each thread will run its enqueue op in parallel with the other threads. The enqueue ops do not have to all be the same op, but it is expected that they all enqueue tensors in &lt;code&gt;queue&lt;/code&gt;.</source>
          <target state="translated">Когда вы позже &lt;code&gt;QueueRunner&lt;/code&gt; метод &lt;code&gt;create_threads()&lt;/code&gt; , QueueRunner создаст один поток для каждой операции в &lt;code&gt;enqueue_ops&lt;/code&gt; . Каждый поток будет запускать свою операцию постановки в очередь параллельно с другими потоками. Операции постановки в очередь не обязательно должны быть одними и теми же операциями, но ожидается, что все они ставят тензоры в &lt;code&gt;queue&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d3a2e77e985cdd0c4ca04ebfb7ec15ae2eed6e37" translate="yes" xml:space="preserve">
          <source>When you launch the graph, variables have to be explicitly initialized before you can run Ops that use their value. You can initialize a variable by running its &lt;em&gt;initializer op&lt;/em&gt;, restoring the variable from a save file, or simply running an &lt;code&gt;assign&lt;/code&gt; Op that assigns a value to the variable. In fact, the variable &lt;em&gt;initializer op&lt;/em&gt; is just an &lt;code&gt;assign&lt;/code&gt; Op that assigns the variable's initial value to the variable itself.</source>
          <target state="translated">Когда вы запускаете график, переменные должны быть явно инициализированы, прежде чем вы сможете запускать операции, использующие их значение. Вы можете инициализировать переменную, запустив ее &lt;em&gt;инициализатор op&lt;/em&gt; , восстановив переменную из файла сохранения или просто запустив операцию &lt;code&gt;assign&lt;/code&gt; , которая присваивает значение переменной. Фактически, &lt;em&gt;инициализатор&lt;/em&gt; переменной &lt;em&gt;op&lt;/em&gt; - это просто оператор &lt;code&gt;assign&lt;/code&gt; который присваивает начальное значение переменной самой переменной.</target>
        </trans-unit>
        <trans-unit id="36dcf90c997814649120f194530d033746d75e2c" translate="yes" xml:space="preserve">
          <source>Whenever &lt;code&gt;partial_pivoting&lt;/code&gt; is true and the backend is XLA.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2e2218d66173c9095f9d7c0c982dd0a7b7b1d0cb" translate="yes" xml:space="preserve">
          <source>Whenever possible, the session will raise a more specific subclass of &lt;code&gt;OpError&lt;/code&gt; from the &lt;a href=&quot;../errors&quot;&gt;&lt;code&gt;tf.errors&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">По возможности сеанс будет вызывать более конкретный подкласс &lt;code&gt;OpError&lt;/code&gt; из модуля &lt;a href=&quot;../errors&quot;&gt; &lt;code&gt;tf.errors&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="525f61b6729229b1a8854a9e50bcaa52ea96b131" translate="yes" xml:space="preserve">
          <source>Where</source>
          <target state="translated">Where</target>
        </trans-unit>
        <trans-unit id="a5a5757b0332ab74cd51749fc4f26f2282d43f68" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;j&lt;/code&gt; is the &lt;code&gt;i&lt;/code&gt;th &lt;code&gt;True&lt;/code&gt; entry of &lt;code&gt;mask[a1...aA]&lt;/code&gt;.</source>
          <target state="translated">Где &lt;code&gt;j&lt;/code&gt; является &lt;code&gt;i&lt;/code&gt; - й &lt;code&gt;True&lt;/code&gt; ввод &lt;code&gt;mask[a1...aA]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a9e5e6939cbf334efa1154ae5d005e3955d0f0b7" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;key&lt;/code&gt; is a feature key whose values are used to partition the values. Partitions are listed from outermost to innermost.</source>
          <target state="translated">Где &lt;code&gt;key&lt;/code&gt; - это функциональный ключ, значения которого используются для разделения значений. Разделы перечислены от самого внешнего до самого внутреннего.</target>
        </trans-unit>
        <trans-unit id="17e66517ae2fa6c4b3f8472462247a694203eb5e" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;year&lt;/code&gt;, &lt;code&gt;month&lt;/code&gt;, and &lt;code&gt;day&lt;/code&gt; specify the date beyond which binaries that consume a model are expected to have been updated to include the new operations. This date is typically at least 3 weeks beyond the date the code that adds the new operation is committed.</source>
          <target state="translated">Где &lt;code&gt;year&lt;/code&gt; , &lt;code&gt;month&lt;/code&gt; и &lt;code&gt;day&lt;/code&gt; указывают дату, после которой ожидается, что двоичные файлы, использующие модель, будут обновлены для включения новых операций. Эта дата обычно как минимум на 3 недели позже даты фиксации кода, добавляющего новую операцию.</target>
        </trans-unit>
        <trans-unit id="743987e43173da0b07d4299cc71758449720108f" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;, &lt;em&gt;M&lt;/em&gt; = &lt;code&gt;ndims(indices)&lt;/code&gt;, and &lt;em&gt;B&lt;/em&gt; = &lt;code&gt;batch_dims&lt;/code&gt;. Note that &lt;code&gt;params.shape[:batch_dims]&lt;/code&gt; must be identical to &lt;code&gt;indices.shape[:batch_dims]&lt;/code&gt;.</source>
          <target state="translated">Где &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt; , &lt;em&gt;M&lt;/em&gt; = &lt;code&gt;ndims(indices)&lt;/code&gt; и &lt;em&gt;B&lt;/em&gt; = &lt;code&gt;batch_dims&lt;/code&gt; . Обратите внимание, что &lt;code&gt;params.shape[:batch_dims]&lt;/code&gt; должен быть идентичен &lt;code&gt;indices.shape[:batch_dims]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="13aa13f1ced8020c65b238cd2e5743aaab5f6a97" translate="yes" xml:space="preserve">
          <source>Where &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt;.</source>
          <target state="translated">Где &lt;em&gt;N&lt;/em&gt; = &lt;code&gt;ndims(params)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="df5ee0a432194eaf058dafaec560ccdd5751f85a" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;../../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;../../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="translated">В то время как в &lt;a href=&quot;../../gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; &lt;code&gt;indices&lt;/code&gt; определяют ломтики в первое измерение &lt;code&gt;params&lt;/code&gt; , в &lt;a href=&quot;../../gather_nd&quot;&gt; &lt;code&gt;tf.gather_nd&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;indices&lt;/code&gt; определяют ломтики в первые &lt;code&gt;N&lt;/code&gt; размеры &lt;code&gt;params&lt;/code&gt; , где &lt;code&gt;N = indices.shape[-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="db72094af8e11b94ee83cae58cea0ebfb59e1a33" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;../gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the &lt;code&gt;axis&lt;/code&gt; dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;../gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="37006b5e3234b3a81d34b49c1399e20287f6f5fd" translate="yes" xml:space="preserve">
          <source>Whereas in &lt;a href=&quot;gather&quot;&gt;&lt;code&gt;tf.gather&lt;/code&gt;&lt;/a&gt;&lt;code&gt;indices&lt;/code&gt; defines slices into the first dimension of &lt;code&gt;params&lt;/code&gt;, in &lt;a href=&quot;gather_nd&quot;&gt;&lt;code&gt;tf.gather_nd&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;indices&lt;/code&gt; defines slices into the first &lt;code&gt;N&lt;/code&gt; dimensions of &lt;code&gt;params&lt;/code&gt;, where &lt;code&gt;N = indices.shape[-1]&lt;/code&gt;.</source>
          <target state="translated">В то время как в &lt;a href=&quot;gather&quot;&gt; &lt;code&gt;tf.gather&lt;/code&gt; &lt;/a&gt; &lt;code&gt;indices&lt;/code&gt; определяют ломтики в первое измерение &lt;code&gt;params&lt;/code&gt; , в &lt;a href=&quot;gather_nd&quot;&gt; &lt;code&gt;tf.gather_nd&lt;/code&gt; &lt;/a&gt; , &lt;code&gt;indices&lt;/code&gt; определяют ломтики в первые &lt;code&gt;N&lt;/code&gt; размеры &lt;code&gt;params&lt;/code&gt; , где &lt;code&gt;N = indices.shape[-1]&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d4b7353826912b9cec703766decc544dcf83f10b" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;output&lt;/code&gt; is expected to be a logits tensor. By default, we consider that &lt;code&gt;output&lt;/code&gt; encodes a probability distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47c0b61274d31e65caf92de4ae562ae2c5114355" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe485b5aa69407b2cec559631c713bb745bddf4c" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution. **Note - Using from_logits=True may be more numerically stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c8c9ab93a2df9a01da2c64742b40fc42d6c91dfb" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;y_pred&lt;/code&gt; is expected to be a logits tensor. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; encodes a probability distribution. &lt;strong&gt;Note - Using from_logits=True is more numerically stable.&lt;/strong&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fd73dec5012589d7460a67d8190f1604f4a14a8" translate="yes" xml:space="preserve">
          <source>Whether GPU-CPU memory swap is enabled for this loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6717cbbf5b0f27136d029a9a5a4fe644c3d0bdb" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;DType&lt;/code&gt; is unsigned.</source>
          <target state="translated">Является ли &lt;code&gt;DType&lt;/code&gt; беззнаковым.</target>
        </trans-unit>
        <trans-unit id="1e01d5432153fe1934c596d7a5942310bb55c381" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;History&lt;/code&gt; callback should be added, if one does not already exist in the &lt;code&gt;callbacks&lt;/code&gt; list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="224e3e261d520f419e922338344450c9f2dfc0d7" translate="yes" xml:space="preserve">
          <source>Whether a &lt;code&gt;ProgbarLogger&lt;/code&gt; callback should be added, if one does not already exist in the &lt;code&gt;callbacks&lt;/code&gt; list.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8aa3f3168594096d3d8b8e19131df9c4c2c6f451" translate="yes" xml:space="preserve">
          <source>Whether autograph should be applied on &lt;code&gt;func&lt;/code&gt; before tracing a graph. Data-dependent control flow requires &lt;code&gt;autograph=True&lt;/code&gt;. For more information, see the &lt;a href=&quot;https://www.tensorflow.org/guide/function&quot;&gt;tf.function and AutoGraph guide&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e52c3c2213cac47314d63bd666108cb982d0a526" translate="yes" xml:space="preserve">
          <source>Whether backprop is enabled for this while loop.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a906b7b12a6aaefca1bb38dbd9c872d24af6915" translate="yes" xml:space="preserve">
          <source>Whether bias centering needs to occur. Bias centering refers to the first node in the very first tree returning the prediction that is aligned with the original labels distribution. For example, for regression problems, the first node will return the mean of the labels. For binary classification problems, it will return a logit for a prior probability of label 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="43c8b1e245711e513da5fb3224a94014bfbd2ea6" translate="yes" xml:space="preserve">
          <source>Whether checkpointing is needed.</source>
          <target state="translated">Нужен ли контрольно-пропускной пункт.</target>
        </trans-unit>
        <trans-unit id="d4eda7288db97494a48ea76ccf902c7ac0f935a7" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensor_list&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95fd49cdfd4929bef2715197b8eb6fc30ab04a73" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensor_list_list&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ccb1e098286182b19dc3309570dc9cdd8118f6d3" translate="yes" xml:space="preserve">
          <source>Whether each tensor in &lt;code&gt;tensors&lt;/code&gt; is a single example.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6a6ce44ff2b603ee993694c9f88f39e13a58c1f" translate="yes" xml:space="preserve">
          <source>Whether initialization is needed.</source>
          <target state="translated">Необходима ли инициализация.</target>
        </trans-unit>
        <trans-unit id="b62856eef3b197086ffc08e6c1915a9c8bdb4a27" translate="yes" xml:space="preserve">
          <source>Whether only account the statistics of displayed profiler nodes.</source>
          <target state="translated">Учитывать ли только статистику отображаемых узлов профайлера.</target>
        </trans-unit>
        <trans-unit id="b2a9b9493710259f1453769c41e2339bd8290c9f" translate="yes" xml:space="preserve">
          <source>Whether only weights are saved, or the whole model is saved.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="369fdea0194aadd9a179680eb99f4f5771059465" translate="yes" xml:space="preserve">
          <source>Whether operations should be dispatched synchronously. Valid values:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584fa0c419a0180a4a9a48f62c36f8aa85cbba56" translate="yes" xml:space="preserve">
          <source>Whether or not the embedding is trainable. Default is True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd70d2454f94f5a5bd23acd3b6d8d74be52ad65b" translate="yes" xml:space="preserve">
          <source>Whether or not the enum is to be case-sensitive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5af2fcf03aaec3220bccfce000595207f5de5efd" translate="yes" xml:space="preserve">
          <source>Whether or not to clear the device field for an &lt;code&gt;Operation&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; during export.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="541b0e69634db2eb96093b9893572ce18575fde6" translate="yes" xml:space="preserve">
          <source>Whether or not to clear the device field for an &lt;code&gt;Operation&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt; during import.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f2329674feeb4db85ce54cddb74a65691271f9d8" translate="yes" xml:space="preserve">
          <source>Whether or not to close all open fd's in the child after forking.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c16fc5a5fb92977ae5605b686e098e91fe724b8" translate="yes" xml:space="preserve">
          <source>Whether saving summaries is needed.</source>
          <target state="translated">Нужно ли сохранять резюме.</target>
        </trans-unit>
        <trans-unit id="a67af11a445e7ad4ad271581ae16018da270fae5" translate="yes" xml:space="preserve">
          <source>Whether shape inference is enabled.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="213556493385771188ee3ad68ba9d0c3e3df86d3" translate="yes" xml:space="preserve">
          <source>Whether the &lt;code&gt;TensorArray&lt;/code&gt; can grow past its initial size.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b529b545844f1f5f6b86ac51e751e32c783eddaa" translate="yes" xml:space="preserve">
          <source>Whether the &lt;code&gt;input_bytes&lt;/code&gt; data is in little-endian format. Data will be converted into host byte order if necessary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="254e76001f48c136c6f2b62d065c4a944ffb37c6" translate="yes" xml:space="preserve">
          <source>Whether the Reader implementation can serialize its state.</source>
          <target state="translated">Может ли реализация Reader сериализовать свое состояние.</target>
        </trans-unit>
        <trans-unit id="8e46d69392dfbc82012e7be9a6824ef93b52a84b" translate="yes" xml:space="preserve">
          <source>Whether the layer is dynamic (eager-only); set in the constructor.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b6e0e7bc8fc1c73b7aaaf3cab72814f4b9d143dc" translate="yes" xml:space="preserve">
          <source>Whether the layer should be trained (boolean), i.e. whether its potentially-trainable weights should be returned as part of &lt;code&gt;layer.trainable_weights&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="decf851b03ac228e9313cade0b5957f7b666dae0" translate="yes" xml:space="preserve">
          <source>Whether the outputs need to be produced in deterministic order. If None, defaults to True.</source>
          <target state="translated">Нужно ли производить результаты в детерминистическом порядке.Если нет,то по умолчанию используется значение True.</target>
        </trans-unit>
        <trans-unit id="204afdb37d75d1615b12cbddd4b547cac2445374" translate="yes" xml:space="preserve">
          <source>Whether the resources required by &lt;code&gt;fn&lt;/code&gt; should be exclusive to this &lt;code&gt;CriticalSection&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;. You may want to set this to &lt;code&gt;False&lt;/code&gt; if you will be accessing a resource in read-only mode in two different CriticalSections.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6ca153ec1da7024d082dd6c5ca6490e0c9cc967f" translate="yes" xml:space="preserve">
          <source>Whether the scaling parameter of the layer should be trainable. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f124179378e71744cfb3660434035ba0a965f11a" translate="yes" xml:space="preserve">
          <source>Whether the strategy uses between-graph replication or not.</source>
          <target state="translated">Использует ли стратегия репликацию между графиками или нет.</target>
        </trans-unit>
        <trans-unit id="7b189cbeed35b5f550585a0be2719b6e1b80cbe7" translate="yes" xml:space="preserve">
          <source>Whether the threads should be marked as &lt;code&gt;daemons&lt;/code&gt;, meaning they don't block program exit.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ffa50da689f93e998f89852cb17efdd428d40e8f" translate="yes" xml:space="preserve">
          <source>Whether this is the last update for the progress bar. If &lt;code&gt;None&lt;/code&gt;, defaults to &lt;code&gt;current &amp;gt;= self.target&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="844772b73edafce629bee3e7ae25983a4b946d09" translate="yes" xml:space="preserve">
          <source>Whether this layer supports computing a mask using &lt;code&gt;compute_mask&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc8aa6f730bdacc1ba24ab5a192fd71d34266e12" translate="yes" xml:space="preserve">
          <source>Whether to L2-normalize samples along the dot product axis before taking the dot product. If set to True, then the output of the dot product is the cosine proximity between the two samples.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="25debb8437d8df1e4a47ad52d47cdffdeaed2fdb" translate="yes" xml:space="preserve">
          <source>Whether to add latency measurements on all edges. Defaults to False.</source>
          <target state="translated">Следует ли добавлять измерения задержки по всем краям.По умолчанию False.</target>
        </trans-unit>
        <trans-unit id="ea1060a10c23d0b7356e53c3f78b04cde7c784c6" translate="yes" xml:space="preserve">
          <source>Whether to add python code trace information. Used to support &quot;code&quot; view.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd79c6c27494dd0eff20142fcddaa9263851ca92" translate="yes" xml:space="preserve">
          <source>Whether to allow the expansion in the non-concat dimensions. Defaulted to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60ffb7d2f619b0cd73858e4eae2a324f1c86a19d" translate="yes" xml:space="preserve">
          <source>Whether to apply decay in a discrete staircase, as opposed to continuous, fashion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98be7901e41c6f7d3da8e520ead11178c148bd11" translate="yes" xml:space="preserve">
          <source>Whether to apply default graph optimizations. If False, only graph optimizations that have been explicitly enabled will be applied.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04a904d718701877a2e0c411c4fe23b4c4e3dd17" translate="yes" xml:space="preserve">
          <source>Whether to apply default static optimizations. If False, only static optimizations that have been explicitly enabled will be applied.</source>
          <target state="translated">Применять ли статические оптимизации по умолчанию.Если False,будут применяться только статические оптимизации,которые были явно включены.</target>
        </trans-unit>
        <trans-unit id="0dfe28cb36c9e4043cc3c258d3d2b5adbf5c6fcb" translate="yes" xml:space="preserve">
          <source>Whether to automatically tune performance knobs. If None, defaults to True.</source>
          <target state="translated">Автоматическая настройка ручек производительности.Если нет,по умолчанию параметр установлен на &quot;Верно&quot;.</target>
        </trans-unit>
        <trans-unit id="e49bbcda0833c641972e00b20f44fee93023536d" translate="yes" xml:space="preserve">
          <source>Whether to close the &lt;code&gt;summary_writer&lt;/code&gt;. Defaults to &lt;code&gt;True&lt;/code&gt; if the summary writer was created by the supervisor, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="48089f8ff308f6b2e1f3c7040fd63434bb0bf7a9" translate="yes" xml:space="preserve">
          <source>Whether to close the summary writer when closing the session. Defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="06ba131eb14ad989473a1a1d258716794efd0b30" translate="yes" xml:space="preserve">
          <source>Whether to convert the comparison operators, like equality. This is soon to be deprecated as support is being added to the Tensor class.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7f5fb7a744d7e22b32c2f61ab042329f9cf9f1e" translate="yes" xml:space="preserve">
          <source>Whether to eliminate no-op transformations. If None, defaults to True.</source>
          <target state="translated">Устранить ли нулевые трансформации.Если &quot;Нет&quot;,по умолчанию-&quot;Верно&quot;.</target>
        </trans-unit>
        <trans-unit id="55bb7493c6bec3c764e8919ffd2eed1794554953" translate="yes" xml:space="preserve">
          <source>Whether to enable JIT compilation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c98d9351c340a8a2394b518e7da0cf49c193b3a" translate="yes" xml:space="preserve">
          <source>Whether to enable or disable compilation in the scope. Either a Python bool, or a callable that accepts the parameter &lt;code&gt;node_def&lt;/code&gt; and returns a python bool.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f04c00e059b1defa60bb4eed8c8d8bfc3869da01" translate="yes" xml:space="preserve">
          <source>Whether to enable soft placement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f9d095bc84ce17a933a7edf15d114454108ce476" translate="yes" xml:space="preserve">
          <source>Whether to enabled device placement logging.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fa1073b5ec09137db6c46e9a17f5e29476dc90c4" translate="yes" xml:space="preserve">
          <source>Whether to expand nested models into clusters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="593fbed8bd96575db44e786eedbea4f61bf29dd7" translate="yes" xml:space="preserve">
          <source>Whether to follow symlinks inside class subdirectories (default: False).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ccd7cdfaf0055cafb944adeab223f3187d39f6f" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter dataset that predicts random_uniform &amp;lt; rate into a sampling dataset. If None, defaults to False.</source>
          <target state="translated">Следует ли объединить набор данных фильтра, который прогнозирует random_uniform &amp;lt;rate, в набор данных выборки. Если None, по умолчанию False.</target>
        </trans-unit>
        <trans-unit id="3d46b05c402499222a82d4000612dbe3e69e3543" translate="yes" xml:space="preserve">
          <source>Whether to fuse filter transformations. If None, defaults to False.</source>
          <target state="translated">Сделать ли плавким преобразование фильтра.Если нет,по умолчанию используется значение &quot;Ложно&quot;.</target>
        </trans-unit>
        <trans-unit id="14622b8d2b800d5545010933d2dce355f7878e20" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and batch transformations. If None, defaults to True.</source>
          <target state="translated">Сплавить карты и пакетные преобразования.Если нет,по умолчанию используется значение True.</target>
        </trans-unit>
        <trans-unit id="89d5416ec9ee3bbc766239f06ad6082f104072da" translate="yes" xml:space="preserve">
          <source>Whether to fuse map and filter transformations. If None, defaults to False.</source>
          <target state="translated">Необходимо ли плавить преобразования карт и фильтров.Если нет,по умолчанию используется значение &quot;Ложно&quot;.</target>
        </trans-unit>
        <trans-unit id="ed238b5a1a92f1cdcc3146430339e440df04eeef" translate="yes" xml:space="preserve">
          <source>Whether to fuse map transformations. If None, defaults to False.</source>
          <target state="translated">Сплавить ли преобразования карты.Если нет,по умолчанию используется значение &quot;Ложно&quot;.</target>
        </trans-unit>
        <trans-unit id="5bf1515795584c1b97bc7e2ce679a96ff89a3700" translate="yes" xml:space="preserve">
          <source>Whether to fuse shuffle and repeat transformations. If None, defaults to True.</source>
          <target state="translated">Сплавить ли перестановку и повторить ли преобразования.Если &quot;Нет&quot;,по умолчанию-&quot;Верно&quot;.</target>
        </trans-unit>
        <trans-unit id="5d8df6452e0ce74559d9d9e2cb01ae9313b462e1" translate="yes" xml:space="preserve">
          <source>Whether to hoist &lt;code&gt;tf.random_uniform()&lt;/code&gt; ops out of map transformations. If None, defaults to False.</source>
          <target state="translated">&lt;code&gt;tf.random_uniform()&lt;/code&gt; ли исключить tf.random_uniform () ops из преобразований карты. Если None, по умолчанию False.</target>
        </trans-unit>
        <trans-unit id="3d0ff5f97e1e7bc8d1a39a62cacd607bcbc343f6" translate="yes" xml:space="preserve">
          <source>Whether to include the constant &lt;code&gt;log(z!)&lt;/code&gt; term in computing the poisson loss. See &lt;a href=&quot;../nn/log_poisson_loss&quot;&gt;&lt;code&gt;tf.nn.log_poisson_loss&lt;/code&gt;&lt;/a&gt; for the full documentation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95573f5b8478c4ff858958db70f9484eb3ff2864" translate="yes" xml:space="preserve">
          <source>Whether to include the fully-connected layer at the top of the network.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b6d4f7d016891ba7c3664590ae67883c943bcc2" translate="yes" xml:space="preserve">
          <source>Whether to include the fully-connected layer at the top of the network. Defaults to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a96a6b7996a34915e32caf67d322039a64480302" translate="yes" xml:space="preserve">
          <source>Whether to interpret &lt;code&gt;y_pred&lt;/code&gt; as a tensor of &lt;a href=&quot;https://en.wikipedia.org/wiki/Logit&quot;&gt;logit&lt;/a&gt; values. By default, we assume that &lt;code&gt;y_pred&lt;/code&gt; contains probabilities (i.e., values in [0, 1]). **Note - Using from_logits=True may be more numerically stable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c54c4b54df643bc4abc643e55545e0c75e91b663" translate="yes" xml:space="preserve">
          <source>Whether to introduce 'slack' in the last &lt;code&gt;prefetch&lt;/code&gt; of the input pipeline, if it exists. This may reduce CPU contention with accelerator host-side activity at the start of a step. The slack frequency is determined by the number of devices attached to this input pipeline. If None, defaults to False.</source>
          <target state="translated">Следует ли вводить &quot;резерв&quot; в последнюю &lt;code&gt;prefetch&lt;/code&gt; входного конвейера, если он существует. Это может уменьшить конкуренцию за ЦП из-за активности ускорителя на стороне хоста в начале шага. Частота холостого хода определяется количеством устройств, подключенных к этому входному конвейеру. Если None, по умолчанию False.</target>
        </trans-unit>
        <trans-unit id="415f3117867c673985b61a262949466ab1564948" translate="yes" xml:space="preserve">
          <source>Whether to mark this name as being used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d1aefded232219f79087eafa756226ded0158a7" translate="yes" xml:space="preserve">
          <source>Whether to only keep the model that has achieved the &quot;best performance&quot; so far, or whether to save the model at the end of every epoch regardless of performance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="914df09e28d1c64c2b3ad87baeeb42bb6e13c04f" translate="yes" xml:space="preserve">
          <source>Whether to output all intermediates from functional control flow ops.</source>
          <target state="translated">Выводить ли все промежуточные продукты из потоков функционального управления.</target>
        </trans-unit>
        <trans-unit id="1dadddd88645b104b7d6bbaecaa2b1fda6cebd75" translate="yes" xml:space="preserve">
          <source>Whether to pad the end of &lt;code&gt;signal&lt;/code&gt; with &lt;code&gt;pad_value&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b76369cf9f1df3341ba7b7b298f504b7086664d1" translate="yes" xml:space="preserve">
          <source>Whether to pad the end of &lt;code&gt;signals&lt;/code&gt; with zeros when the provided frame length and step produces a frame that lies partially past its end.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="02821348292f56a84707e75ec632d05c62475235" translate="yes" xml:space="preserve">
          <source>Whether to parallelize copying of batch elements. If None, defaults to False.</source>
          <target state="translated">Распараллелить ли копирование элементов партии.Если нет,по умолчанию-&quot;Ложно&quot;.</target>
        </trans-unit>
        <trans-unit id="735760deb2a9c67ef0c7efaa6a50691fc4a6f0e0" translate="yes" xml:space="preserve">
          <source>Whether to parallelize stateless map transformations. If None, defaults to False.</source>
          <target state="translated">Распараллелить ли преобразования карт апатридов.Если нет,по умолчанию-Ложь.</target>
        </trans-unit>
        <trans-unit id="8eda9b273c93d039ba7a242609f9446311332c6d" translate="yes" xml:space="preserve">
          <source>Whether to preserve the aspect ratio. If this is set, then &lt;code&gt;images&lt;/code&gt; will be resized to a size that fits in &lt;code&gt;size&lt;/code&gt; while preserving the aspect ratio of the original image. Scales up the image if &lt;code&gt;size&lt;/code&gt; is bigger than the current size of the &lt;code&gt;image&lt;/code&gt;. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af633c59d5db9e3af600703e972fa65df59d21b3" translate="yes" xml:space="preserve">
          <source>Whether to recursively convert any functions that the converted function may call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="331d800dc7aa1366aba63d94549fbc90867f575a" translate="yes" xml:space="preserve">
          <source>Whether to replace the C0 control characters &lt;code&gt;(U+0000 - U+001F)&lt;/code&gt; with the &lt;code&gt;replacement_char&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1f08303e15a79462237d5a6f5ab69bc0d741f795" translate="yes" xml:space="preserve">
          <source>Whether to rescale image values to be within &lt;code&gt;[0, 255]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d631ffee25c1c8d5962cb92c91bc7155c1b86dbc" translate="yes" xml:space="preserve">
          <source>Whether to rescale image values to be within &lt;code&gt;[0, 255]&lt;/code&gt;. Defaults to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af90abadf38a68efbae5eab044cc111e83bae73f" translate="yes" xml:space="preserve">
          <source>Whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bf889dca2e1b92ac166e4e9099cdfdcbbe292012" translate="yes" xml:space="preserve">
          <source>Whether to save the GraphDef and MetaGraphDef to &lt;code&gt;checkpoint_dir&lt;/code&gt;. The GraphDef is saved after the session is created as &lt;code&gt;graph.pbtxt&lt;/code&gt;. MetaGraphDefs are saved out for every checkpoint as &lt;code&gt;model.ckpt-*.meta&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c75f3049cc336ca24bf2e733a248d74d9f9c0730" translate="yes" xml:space="preserve">
          <source>Whether to shuffle output samples, or instead draw them in chronological order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34ea722ba14f3f99938856c7d83cff00e23dae81" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="248b22a81980263fa482dd9c28f486987117fdb6" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbcae28d63feefddbed17928b77788494d83948d" translate="yes" xml:space="preserve">
          <source>Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="22ee2250a0c89ccf48c596cca64f08347b735454" translate="yes" xml:space="preserve">
          <source>Whether to start the standard services and the queue runners.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfad559685c1e01540d88fa4658891788a35c214" translate="yes" xml:space="preserve">
          <source>Whether to start the standard services, such as checkpoint, summary and step counter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4197ca406a3d4336b3bdffbd1a95b8c81b6a0d1" translate="yes" xml:space="preserve">
          <source>Whether to store intermediate values needed for gradients on the CPU instead of GPU.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f85068103e5372bea510e0ae9c69724c9d066b10" translate="yes" xml:space="preserve">
          <source>Whether to subtract &lt;code&gt;b&lt;/code&gt; from &lt;code&gt;a&lt;/code&gt;, vs vice versa.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10f6a87284583be6f6880d0e9062e36a3a101464" translate="yes" xml:space="preserve">
          <source>Whether to sum gradients from different replicas in the presense of &lt;a href=&quot;../../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;. If False, it's user responsibility to aggregate the gradients. Default to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="72847fae2b2b235f6c8342af13371de425b6b16d" translate="yes" xml:space="preserve">
          <source>Whether to sum gradients from different replicas in the presense of &lt;a href=&quot;../../distribute/strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt;. If False, it's user responsibility to aggregate the gradients. Default to True.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bcc78610692aa1b78a0b8fce45e7b1a35f60fedd" translate="yes" xml:space="preserve">
          <source>Whether to unroll the RNN or to use a symbolic &lt;code&gt;while_loop&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8319c980207aacd2a41a4c25d0f4519649627a11" translate="yes" xml:space="preserve">
          <source>Whether to use &lt;a href=&quot;https://arxiv.org/abs/1702.03275&quot;&gt;Batch Renormalization&lt;/a&gt;. This adds extra variables during training. The inference is the same for either value of this parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bd041b7a31c14b8f4c0154e4f0e31652d226ed84" translate="yes" xml:space="preserve">
          <source>Whether to use &lt;code&gt;ResourceVariable&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b32a3b0296e56c0857535ebb732043e2ca01eb48" translate="yes" xml:space="preserve">
          <source>Whether to use Batch Renormalization (Ioffe, 2017). This adds extra variables during training. The inference is the same for either value of this parameter.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b7ceb047bcc05fae84d262bcb0f0a4c42d80112e" translate="yes" xml:space="preserve">
          <source>Whether to use ChooseFastestBranchDataset with this transformation. If True, the pipeline picks between the vectorized and original segment at runtime based on their iterations speed. If None, defaults to False.</source>
          <target state="translated">Использовать ли ChooseFastestBranchDataset с этим преобразованием.Если True,то конвейер пикирует между векторизованным и исходным сегментами во время выполнения,основываясь на скорости их итераций.Если Нет,по умолчанию используется значение False.</target>
        </trans-unit>
        <trans-unit id="b41a583b4e8ecad70d2b783981605d5fb07b5daa" translate="yes" xml:space="preserve">
          <source>Whether to use an anti-aliasing filter when downsampling an image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d7f954867443ea6a778475601ca4e3cc6e2dabd" translate="yes" xml:space="preserve">
          <source>Whether to use anti-aliasing when resizing. See 'image.resize()'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c343c5190311c54955a31561f20b178e46089ae4" translate="yes" xml:space="preserve">
          <source>Whether to use autograph to compile python and eager style code for efficient graph-mode execution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ee94bf5c9ec84d6138e0ac95db29424ae3a5d6b" translate="yes" xml:space="preserve">
          <source>Whether to use batch normalization after each hidden layer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="66b047600fb7cdf1794d2271af3d1f8a45f50c04" translate="yes" xml:space="preserve">
          <source>Whether to validate the order and range of sparse indices in &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77a0de4187b80648dee2790bc3e0723da8ae8a3a" translate="yes" xml:space="preserve">
          <source>Whether to validate the order and range of sparse indices in &lt;code&gt;a&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4f7ae19a819559a645d06cbc4b8c196628f89ca" translate="yes" xml:space="preserve">
          <source>Whether to vectorize map transformations. If None, defaults to False.</source>
          <target state="translated">Векторизовать ли преобразования карты.Если нет,по умолчанию используется значение по умолчанию False.</target>
        </trans-unit>
        <trans-unit id="f123cab967534816dc9b84ddbe1b892a217e9a8b" translate="yes" xml:space="preserve">
          <source>Whether to visits subdirectories pointed to by symlinks. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="081ce8e1451357f99365d88262e4c58272efd31e" translate="yes" xml:space="preserve">
          <source>Whether to wait for checkpoint to become available.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69219f557de4f53ff935206788ba0bcdb1a1ab26" translate="yes" xml:space="preserve">
          <source>Whether we should overwrite any existing model at the target location, or instead ask the user with a manual prompt.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63419d87417ca59c7ed9321136943312244206c5" translate="yes" xml:space="preserve">
          <source>Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bbe339fdd2ca55a9615f6086f8ab79036c1a5e5d" translate="yes" xml:space="preserve">
          <source>Whether you are running on your machine or in the cluster you can use the following values for the --master flag:</source>
          <target state="translated">Независимо от того,работаете ли вы на вашей машине или в кластере,вы можете использовать следующие значения для флага --master:</target>
        </trans-unit>
        <trans-unit id="3c232ac685e13a6b93f5f74209d44fc6f31c57d9" translate="yes" xml:space="preserve">
          <source>Which axis to join along. The default behavior is to join all elements, producing a scalar.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f517d8a1e3e3925fb5d9497fd0a8aca7ed0a886e" translate="yes" xml:space="preserve">
          <source>Which profile step to use for profiling.</source>
          <target state="translated">Какой шаг профиля использовать для профилирования.</target>
        </trans-unit>
        <trans-unit id="d86a5675cc6478e7030415aaa83cd72801292548" translate="yes" xml:space="preserve">
          <source>While</source>
          <target state="translated">While</target>
        </trans-unit>
        <trans-unit id="1c51ff24d93bea432325c091aee3e33a6598af2c" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../../../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;../../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="translated">Хотя &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../../../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; сохраняются в том же формате, обратите внимание, что корень полученной контрольной точки - это объект, к которому прикреплен метод сохранения. Это означает, что сохранение &lt;a href=&quot;../../../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; с использованием &lt;code&gt;save_weights&lt;/code&gt; и загрузка в &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; с присоединенной &lt;code&gt;Model&lt;/code&gt; (или наоборот) не будут соответствовать переменным &lt;code&gt;Model&lt;/code&gt; . См. Подробности в &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;руководстве по тренировочным контрольным точкам&lt;/a&gt; . Предпочитайте &lt;a href=&quot;../../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; над &lt;a href=&quot;../../../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; для тренировочных контрольных точек.</target>
        </trans-unit>
        <trans-unit id="af5169034174d26fcbbcf3598b642bb6291299f0" translate="yes" xml:space="preserve">
          <source>While &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; save in the same format, note that the root of the resulting checkpoint is the object the save method is attached to. This means saving a &lt;a href=&quot;../keras/model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt; using &lt;code&gt;save_weights&lt;/code&gt; and loading into a &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; with a &lt;code&gt;Model&lt;/code&gt; attached (or vice versa) will not match the &lt;code&gt;Model&lt;/code&gt;'s variables. See the &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;guide to training checkpoints&lt;/a&gt; for details. Prefer &lt;a href=&quot;checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;a href=&quot;../keras/model#save_weights&quot;&gt;&lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt;&lt;/a&gt; for training checkpoints.</source>
          <target state="translated">Хотя &lt;a href=&quot;../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; &lt;/a&gt; сохраняются в том же формате, обратите внимание, что корень полученной контрольной точки - это объект, к которому прикреплен метод сохранения. Это означает, что сохранение &lt;a href=&quot;../keras/model&quot;&gt; &lt;code&gt;tf.keras.Model&lt;/code&gt; &lt;/a&gt; с использованием &lt;code&gt;save_weights&lt;/code&gt; и загрузка в &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; с присоединенной &lt;code&gt;Model&lt;/code&gt; (или наоборот) не будут соответствовать переменным &lt;code&gt;Model&lt;/code&gt; . См. Подробности в &lt;a href=&quot;https://www.tensorflow.org/guide/checkpoint&quot;&gt;руководстве по тренировочным контрольным точкам&lt;/a&gt; . Предпочитайте &lt;a href=&quot;checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; над &lt;a href=&quot;../keras/model#save_weights&quot;&gt; &lt;code&gt;tf.keras.Model.save_weights&lt;/code&gt; &lt;/a&gt; для тренировочных контрольных точек.</target>
        </trans-unit>
        <trans-unit id="df92ff2e348ec38c9d24bb6a65e3a867cbde6530" translate="yes" xml:space="preserve">
          <source>While &lt;code&gt;fn&lt;/code&gt; is running in the critical section, no other functions which wish to use this critical section may run.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="721826e30de58e9f292f39ea411e1bcf62df9289" translate="yes" xml:space="preserve">
          <source>While it is possible to use Variables with Lambda layers, this practice is discouraged as it can easily lead to bugs. For instance, consider the following layer:</source>
          <target state="translated">Хотя можно использовать Переменные со слоями Lambda,такая практика не рекомендуется,так как она может легко привести к ошибкам.Например,рассмотрим следующий слой:</target>
        </trans-unit>
        <trans-unit id="b7ab51f21fc0c3654c10e148c98ad2c3c102cbcf" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;../model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;../model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="translated">Хотя форматы одинаковы, не смешивайте &lt;code&gt;save_weights&lt;/code&gt; и &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; . Контрольные точки, сохраненные в &lt;a href=&quot;../model#save_weights&quot;&gt; &lt;code&gt;Model.save_weights&lt;/code&gt; ,&lt;/a&gt; следует загружать с помощью &lt;a href=&quot;../model#load_weights&quot;&gt; &lt;code&gt;Model.load_weights&lt;/code&gt; &lt;/a&gt; . Контрольные точки, сохраненные с помощью &lt;a href=&quot;../../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; ,&lt;/a&gt; необходимо восстановить с помощью соответствующего &lt;a href=&quot;../../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; . Предпочитайте &lt;a href=&quot;../../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; над &lt;code&gt;save_weights&lt;/code&gt; для тренировочных контрольных точек.</target>
        </trans-unit>
        <trans-unit id="4d3c899f37d2d7cda82e12e4a5abbb5d78c486a6" translate="yes" xml:space="preserve">
          <source>While the formats are the same, do not mix &lt;code&gt;save_weights&lt;/code&gt; and &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt;. Checkpoints saved by &lt;a href=&quot;model#save_weights&quot;&gt;&lt;code&gt;Model.save_weights&lt;/code&gt;&lt;/a&gt; should be loaded using &lt;a href=&quot;model#load_weights&quot;&gt;&lt;code&gt;Model.load_weights&lt;/code&gt;&lt;/a&gt;. Checkpoints saved using &lt;a href=&quot;../train/checkpoint#save&quot;&gt;&lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt;&lt;/a&gt; should be restored using the corresponding &lt;a href=&quot;../train/checkpoint#restore&quot;&gt;&lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt;&lt;/a&gt;. Prefer &lt;a href=&quot;../train/checkpoint&quot;&gt;&lt;code&gt;tf.train.Checkpoint&lt;/code&gt;&lt;/a&gt; over &lt;code&gt;save_weights&lt;/code&gt; for training checkpoints.</source>
          <target state="translated">Хотя форматы одинаковы, не смешивайте &lt;code&gt;save_weights&lt;/code&gt; и &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; . Контрольные точки, сохраненные в &lt;a href=&quot;model#save_weights&quot;&gt; &lt;code&gt;Model.save_weights&lt;/code&gt; ,&lt;/a&gt; следует загружать с помощью &lt;a href=&quot;model#load_weights&quot;&gt; &lt;code&gt;Model.load_weights&lt;/code&gt; &lt;/a&gt; . Контрольные точки, сохраненные с помощью &lt;a href=&quot;../train/checkpoint#save&quot;&gt; &lt;code&gt;tf.train.Checkpoint.save&lt;/code&gt; ,&lt;/a&gt; необходимо восстановить с помощью соответствующего &lt;a href=&quot;../train/checkpoint#restore&quot;&gt; &lt;code&gt;tf.train.Checkpoint.restore&lt;/code&gt; &lt;/a&gt; . Предпочитайте &lt;a href=&quot;../train/checkpoint&quot;&gt; &lt;code&gt;tf.train.Checkpoint&lt;/code&gt; &lt;/a&gt; над &lt;code&gt;save_weights&lt;/code&gt; для тренировочных контрольных точек.</target>
        </trans-unit>
        <trans-unit id="0b0e77019b80f4349b00c82de8efee158e5fc102" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, all the variable creation should be done within the strategy's scope. This will replicate the variables across all the replicas and keep them in sync using an all-reduce algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f64f547104eca8ffa08df75b0d127da08fb96ecc" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, the variables created within strategy's scope will be replicated across all the replicas and can be kept in sync using all-reduce algorithms.</source>
          <target state="translated">При использовании стратегий распределения,переменные,созданные в рамках стратегии,будут реплицироваться во всех репликах и могут быть синхронизированы с помощью полностью воспроизводимых алгоритмов.</target>
        </trans-unit>
        <trans-unit id="3d98a83dc2837ad96d068975c35687e2b85ed52c" translate="yes" xml:space="preserve">
          <source>While using distribution strategies, the variables created within the strategy's scope will be replicated across all the replicas and can be kept in sync using all-reduce algorithms.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1d21e39cec1dbe57a37b90b0658bf80c4c7b4e18" translate="yes" xml:space="preserve">
          <source>WholeFileReader</source>
          <target state="translated">WholeFileReader</target>
        </trans-unit>
        <trans-unit id="c10e00cc1061d25c1e75d6a6c9f37b8de149d520" translate="yes" xml:space="preserve">
          <source>WholeFileReaderV2</source>
          <target state="translated">WholeFileReaderV2</target>
        </trans-unit>
        <trans-unit id="4bc1c4e835b1b69225a6dcb4af4e28a2c06f52c5" translate="yes" xml:space="preserve">
          <source>Wide &amp;amp; Deep Model for regression and classification problems.</source>
          <target state="translated">Широкая и глубокая модель для задач регрессии и классификации.</target>
        </trans-unit>
        <trans-unit id="ce79ee760dc1e0dcf6f5314aeb909e856d4d894b" translate="yes" xml:space="preserve">
          <source>Width Multiplier (alpha) | ImageNet Acc | Multiply-Adds (M) | Params (M)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="681d52e4c1304a1ea24152480eaca88c3ee9ae33" translate="yes" xml:space="preserve">
          <source>Width of output image.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0c58a6d122599315399444067e820708cd4baecf" translate="yes" xml:space="preserve">
          <source>Width of the result.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="664add438097fbd4307f814de8e62a10f8905588" translate="yes" xml:space="preserve">
          <source>Wikipedia</source>
          <target state="translated">Wikipedia</target>
        </trans-unit>
        <trans-unit id="f1e4a70a64ee6594b6f0a462b10bce93878f9218" translate="yes" xml:space="preserve">
          <source>Will NOT work in 2.x:</source>
          <target state="translated">Не будет работать в 2.x:</target>
        </trans-unit>
        <trans-unit id="1c0b2946d9427a7aeee307da8f37197ad5dcc849" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).</source>
          <target state="translated">При необходимости (например,когда Читателю необходимо начать чтение из нового файла,так как он закончил с предыдущим файлом),рабочий блок будет выведен из очереди.</target>
        </trans-unit>
        <trans-unit id="a8c3a8bad2b347c018d978650b0ad1f0a7153646" translate="yes" xml:space="preserve">
          <source>Will dequeue a work unit from queue if necessary (e.g., when the Reader needs to start reading from a new file since it has finished with the previous file). It may return less than num_records even before the last batch.</source>
          <target state="translated">При необходимости (например,когда Читателю необходимо начать чтение из нового файла,так как он закончил с предыдущим файлом),он выведет рабочий блок из очереди.Он может возвращать меньше записей num_records даже перед последней партией.</target>
        </trans-unit>
        <trans-unit id="4ba78cccf43ec749a3b3f63b99ca41d71764e130" translate="yes" xml:space="preserve">
          <source>Will dequeue from the input queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f6ac5cb110e37a221155d9f3ad0cb5d4f454d263" translate="yes" xml:space="preserve">
          <source>Will dequeue from the input queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file). It may return less than &lt;code&gt;num_records&lt;/code&gt; even before the last batch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="261f27a1f3bf63caf50878a078d18d17744de09c" translate="yes" xml:space="preserve">
          <source>Will make devices on the cluster available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="translated">Сделает доступными для использования устройства на кластере.Обратите внимание,что вызов этой функции несколько раз сработает,но сделает недействительными любые тензорные ручки на старых удаленных устройствах.</target>
        </trans-unit>
        <trans-unit id="f6897db1eb6c38899798f94d9b426756d03b49e8" translate="yes" xml:space="preserve">
          <source>Will make devices on the remote host available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.</source>
          <target state="translated">Сделает устройства на удаленном хосте доступными для использования.Обратите внимание,что вызов этой функции несколько раз сработает,но сделает недействительными любые тензорные ручки на старых удаленных устройствах.</target>
        </trans-unit>
        <trans-unit id="b4a06c844340471315b54b0dfa65c9f440e60872" translate="yes" xml:space="preserve">
          <source>Will the SparseTensor &lt;code&gt;A&lt;/code&gt; fit in memory if densified?</source>
          <target state="translated">Поместится ли SparseTensor &lt;code&gt;A&lt;/code&gt; в память, если она будет уплотнена?</target>
        </trans-unit>
        <trans-unit id="0922711fb24b94894ef90c6a73b66b5cfaf62cb6" translate="yes" xml:space="preserve">
          <source>Will work in 1.x and 2.x (though deprecated in 2.x):</source>
          <target state="translated">Будет работать в 1.x и 2.x (хотя и устарело в 2.x):</target>
        </trans-unit>
        <trans-unit id="ce21a08c1a63e9b77f2a1c614615c252ca550863" translate="yes" xml:space="preserve">
          <source>WindowDataset</source>
          <target state="translated">WindowDataset</target>
        </trans-unit>
        <trans-unit id="7969fd6214a6335899a24dac6e8f7bd3aba9e39c" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;A&lt;/code&gt; the dense representation of this &lt;code&gt;Operator&lt;/code&gt;,</source>
          <target state="translated">С плотным представлением этого &lt;code&gt;Operator&lt;/code&gt; &lt;code&gt;A&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="ff9e0aefc629ac53bd25ea34ae417e2aeaf0766f" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; where n is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="234aca2d96fedfdf359061dabe09edd1bc5db7b3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; where n is: - number of input units in the weight tensor, if mode = &quot;fan_in&quot; - number of output units, if mode = &quot;fan_out&quot; - average of the numbers of input and output units, if mode = &quot;fan_avg&quot;</source>
          <target state="translated">При использовании &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt; выборки берутся из усеченного / неусеченного нормального распределения со средним нулевым средним и стандартным отклонением (после усечения, если используется) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt; где n: - количество входных единиц в тензоре весов, if mode = &quot;fan_in&quot; - количество выходных единиц, if mode = &quot;fan_out&quot; - среднее количество входных и выходных блоков, если mode = &quot;fan_avg&quot;</target>
        </trans-unit>
        <trans-unit id="4f723d75a7c2fa1bd113ada83e2655f70f9292fe" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;truncated_normal&quot; or &quot;untruncated_normal&quot;&lt;/code&gt;, samples are drawn from a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after truncation, if used) &lt;code&gt;stddev = sqrt(scale / n)&lt;/code&gt;, where &lt;code&gt;n&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ff32194c2a7d6162d325ca83d7afa7acc313404" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt;, samples are drawn from a uniform distribution within &lt;code&gt;[-limit, limit]&lt;/code&gt;, where &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f5835e02899f12405b436a06a34c5acc97b07515" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt;, samples are drawn from a uniform distribution within [-limit, limit], with &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt;.</source>
          <target state="translated">Если &lt;code&gt;distribution=&quot;uniform&quot;&lt;/code&gt; , образцы берутся из однородного распределения в пределах [-limit, limit], с &lt;code&gt;limit = sqrt(3 * scale / n)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f8c1f4cf8df7060458ea559fb96747e733cc6916" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;height_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;height_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;height_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="translated">С &lt;code&gt;height_shift_range=2&lt;/code&gt; возможными значениями являются целые числа &lt;code&gt;[-1, 0, +1]&lt;/code&gt; , как и с &lt;code&gt;height_shift_range=[-1, 0, +1]&lt;/code&gt; , а с &lt;code&gt;height_shift_range=1.0&lt;/code&gt; возможными значениями являются числа с плавающей запятой в интервале [-1.0, + 1.0).</target>
        </trans-unit>
        <trans-unit id="8d71d2aae030803f505395187c99c592d13d4623" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;preserve_aspect_ratio=True&lt;/code&gt;, the aspect ratio is preserved, so &lt;code&gt;size&lt;/code&gt; is the maximum for each dimension:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f0be93f34340dbd9dbce5872c897c11744e5be0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;width_shift_range=2&lt;/code&gt; possible values are integers &lt;code&gt;[-1, 0, +1]&lt;/code&gt;, same as with &lt;code&gt;width_shift_range=[-1, 0, +1]&lt;/code&gt;, while with &lt;code&gt;width_shift_range=1.0&lt;/code&gt; possible values are floats in the interval [-1.0, +1.0).</source>
          <target state="translated">При &lt;code&gt;width_shift_range=2&lt;/code&gt; возможными значениями являются целые числа &lt;code&gt;[-1, 0, +1]&lt;/code&gt; , как и при &lt;code&gt;width_shift_range=[-1, 0, +1]&lt;/code&gt; , а при &lt;code&gt;width_shift_range=1.0&lt;/code&gt; возможными значениями являются числа с плавающей запятой в интервале [-1.0, + 1.0).</target>
        </trans-unit>
        <trans-unit id="b3c5ce075d1d1fd6a0d1aad83b3d8c72b5bbfb7b" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the first dimension, which is &lt;code&gt;height&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="translated">С вероятностью 1 из 2 выводит содержимое &lt;code&gt;image&lt;/code&gt; перевернутое по первому измерению, то есть по &lt;code&gt;height&lt;/code&gt; . В противном случае выведите изображение как есть. При передаче пакета изображений каждое изображение будет произвольно переворачиваться независимо от других изображений.</target>
        </trans-unit>
        <trans-unit id="40d888cff933beb09db3d4f6596d9067e2878308" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the first dimension, which is &lt;code&gt;height&lt;/code&gt;. Otherwise, output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dafbf9ee96525bc588fdd1a819189c2c04be4c99" translate="yes" xml:space="preserve">
          <source>With a 1 in 2 chance, outputs the contents of &lt;code&gt;image&lt;/code&gt; flipped along the second dimension, which is &lt;code&gt;width&lt;/code&gt;. Otherwise output the image as-is. When passing a batch of images, each image will be randomly flipped independent of other images.</source>
          <target state="translated">С вероятностью 1 из 2 выводит содержимое &lt;code&gt;image&lt;/code&gt; перевернутое по второму измерению, то есть &lt;code&gt;width&lt;/code&gt; . В противном случае выведите изображение как есть. При передаче пакета изображений каждое изображение будет произвольно переворачиваться независимо от других изображений.</target>
        </trans-unit>
        <trans-unit id="eb0883b4bf2a7901f51949844c31237c43d86ecb" translate="yes" xml:space="preserve">
          <source>With a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are reported to the coordinator and forgotten by the &lt;code&gt;QueueRunner&lt;/code&gt;.</source>
          <target state="translated">При использовании &lt;code&gt;Coordinator&lt;/code&gt; исключения сообщаются координатору и забываются &lt;code&gt;QueueRunner&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bf97c0b53fe731e0899e5aa3d7d1c5c2588e5d9e" translate="yes" xml:space="preserve">
          <source>With default values, it returns element-wise &lt;code&gt;max(x, 0)&lt;/code&gt;.</source>
          <target state="translated">Со значениями по умолчанию он возвращает &lt;code&gt;max(x, 0)&lt;/code&gt; поэлементно .</target>
        </trans-unit>
        <trans-unit id="db85e495eb55636b020a2a32657d103899296f2f" translate="yes" xml:space="preserve">
          <source>With default values, this returns the standard ReLU activation: &lt;code&gt;max(x, 0)&lt;/code&gt;, the element-wise maximum of 0 and the input tensor.</source>
          <target state="translated">Со значениями по умолчанию это возвращает стандартную активацию ReLU: &lt;code&gt;max(x, 0)&lt;/code&gt; , поэлементный максимум 0 и входной тензор.</target>
        </trans-unit>
        <trans-unit id="8620f83bce4d323fd62431b72a3e3cd320c09979" translate="yes" xml:space="preserve">
          <source>With eager execution disabled (by default in TensorFlow 1.x and by calling disable_eager_execution() in TensorFlow 2.x), the following syntax can be used:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7517aaf4d18e2c4d14a26fcfe70e076851f68b1" translate="yes" xml:space="preserve">
          <source>With eager execution this is a shape assertion, that returns the input:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f568c7dfa8797dfe677f7dd6f0a4ee1b0b5cbdba" translate="yes" xml:space="preserve">
          <source>With eager execution this operates as a shape assertion. Here the shapes match:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8b2addb5c48d67261f0b9d05eab9810322d19c59" translate="yes" xml:space="preserve">
          <source>With forwardprop, we specify a length-three vector in advance which multiplies the Jacobian. The &lt;code&gt;primals&lt;/code&gt; constructor argument is the parameter (a &lt;a href=&quot;../tensor&quot;&gt;&lt;code&gt;tf.Tensor&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;../variable&quot;&gt;&lt;code&gt;tf.Variable&lt;/code&gt;&lt;/a&gt;) we're specifying a vector for, and the &lt;code&gt;tangents&lt;/code&gt; argument is the &quot;vector&quot; in Jacobian-vector product. If our goal is to compute the entire Jacobian matrix, forwardprop computes one column at a time while backprop computes one row at a time. Since the Jacobian in the linear regression example has only one row, backprop requires fewer invocations:</source>
          <target state="translated">С forwardprop мы заранее указываем вектор длины три, который умножает якобиан. &lt;code&gt;primals&lt;/code&gt; конструктор аргумент является параметром (а &lt;a href=&quot;../tensor&quot;&gt; &lt;code&gt;tf.Tensor&lt;/code&gt; &lt;/a&gt; или &lt;a href=&quot;../variable&quot;&gt; &lt;code&gt;tf.Variable&lt;/code&gt; &lt;/a&gt; ) мы указать вектор для, а &lt;code&gt;tangents&lt;/code&gt; аргумент является &amp;laquo;вектор&amp;raquo; в якобиан-векторное произведение. Если наша цель - вычислить всю матрицу Якоби, forwardprop вычисляет один столбец за раз, а backprop вычисляет одну строку за раз. Поскольку якобиан в примере линейной регрессии имеет только одну строку, обратное распространение требует меньше вызовов:</target>
        </trans-unit>
        <trans-unit id="81932d1ace29ea95c92392af364f6a28c2c74781" translate="yes" xml:space="preserve">
          <source>With this definition, the gradient at x=100 will be correctly evaluated as 1.0.</source>
          <target state="translated">При таком определении градиент при x=100 будет правильно оценен как 1.0.</target>
        </trans-unit>
        <trans-unit id="317a1dfdd7bd7e17378c7a66cabfcee42b3896df" translate="yes" xml:space="preserve">
          <source>With y = f(x), computes the theoretical and numeric Jacobian dy/dx.</source>
          <target state="translated">С помощью y=f(x)вычисляет теоретический и числовой якобианский dy/dx.</target>
        </trans-unit>
        <trans-unit id="659abe1496bd7876fc022d3e2b6b9cead33d30d8" translate="yes" xml:space="preserve">
          <source>Within a particular block, exactly one of these two things will be true:</source>
          <target state="translated">В пределах определенного блока,именно одна из этих двух вещей будет правдой:</target>
        </trans-unit>
        <trans-unit id="13fe9d84fb92bd3745e88227dc1de58a44afddd1" translate="yes" xml:space="preserve">
          <source>Within a training loop, this argument sets how often host calls are performed during training. Host calls will be evaluated every n steps within a training loop where n is the value of this argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e7aeeddf89020677af5b4472b077bda01df8909" translate="yes" xml:space="preserve">
          <source>Within each worker, we will also split the data among all the worker devices (if more than one a present), and this will happen even if multi-worker sharding is disabled using the method above.</source>
          <target state="translated">Внутри каждого рабочего мы также разделим данные между всеми рабочими устройствами (если их более одного в настоящее время),и это произойдет даже в том случае,если шардинг для нескольких рабочих будет отключен вышеописанным методом.</target>
        </trans-unit>
        <trans-unit id="4d99119d2f84477c4512754d5e0fcbfbe0f69b29" translate="yes" xml:space="preserve">
          <source>Within the &lt;code&gt;with sv.managed_session()&lt;/code&gt; block all variables in the graph have been initialized. In addition, a few services have been started to checkpoint the model and add summaries to the event log.</source>
          <target state="translated">В &lt;code&gt;with sv.managed_session()&lt;/code&gt; все переменные в графе были инициализированы. Кроме того, было запущено несколько сервисов для проверки модели и добавления сводок в журнал событий.</target>
        </trans-unit>
        <trans-unit id="ab6e550ba7dbaa5e409cc2c91f32bbe98623ef14" translate="yes" xml:space="preserve">
          <source>Without &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; but with a &lt;code&gt;seed&lt;/code&gt; argument is specified, small changes to function graphs or previously executed operations will change the returned value. See &lt;a href=&quot;set_seed&quot;&gt;&lt;code&gt;tf.random.set_seed&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">Без &lt;a href=&quot;set_seed&quot;&gt; &lt;code&gt;tf.random.set_seed&lt;/code&gt; ,&lt;/a&gt; но с заданным аргументом &lt;code&gt;seed&lt;/code&gt; , небольшие изменения в графах функций или ранее выполненных операциях изменят возвращаемое значение. Подробнее см. &lt;a href=&quot;set_seed&quot;&gt; &lt;code&gt;tf.random.set_seed&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="c8ccb2ad531bd87f8226e54b9b6a39a6b2307357" translate="yes" xml:space="preserve">
          <source>Without a &lt;code&gt;Coordinator&lt;/code&gt;, exceptions are captured by the &lt;code&gt;QueueRunner&lt;/code&gt; and made available in this &lt;code&gt;exceptions_raised&lt;/code&gt; property.</source>
          <target state="translated">Без &lt;code&gt;Coordinator&lt;/code&gt; исключения захватываются &lt;code&gt;QueueRunner&lt;/code&gt; и становятся доступными в этом свойстве &lt;code&gt;exceptions_raised&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e696e263864301b6aa5902a80a4d0bff70cd1786" translate="yes" xml:space="preserve">
          <source>Word embeddings</source>
          <target state="translated">Словесные вставки</target>
        </trans-unit>
        <trans-unit id="d98a4a13cdc22212a308bf1d89d6b7b049c03e2f" translate="yes" xml:space="preserve">
          <source>Worker devices vs. parameter devices: Most replica computations will happen on worker devices. Since we don't yet support model parallelism, there will be one worker device per replica. When using parameter servers or central storage, the set of devices holding variables may be different, otherwise the parameter devices might match the worker devices.</source>
          <target state="translated">Рабочие устройства в сравнении с параметрическими устройствами:Большинство вычислений реплик будет происходить на рабочих устройствах.Так как мы пока не поддерживаем параллельность моделей,на каждую копию будет приходиться по одному рабочему устройству.При использовании серверов с параметрами или центрального хранилища,набор устройств,содержащих переменные,может отличаться,в противном случае устройства с параметрами могут соответствовать рабочим устройствам.</target>
        </trans-unit>
        <trans-unit id="e84ec097b7a7143f51f1fbc334ced683171b4c6c" translate="yes" xml:space="preserve">
          <source>Worker heartbeat op.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d20a3ffc32dcd238f452807ec295544fb73ee86b" translate="yes" xml:space="preserve">
          <source>WorkerHeartbeat</source>
          <target state="translated">WorkerHeartbeat</target>
        </trans-unit>
        <trans-unit id="398f69182b10972e971055c07ca464bed84b735b" translate="yes" xml:space="preserve">
          <source>Working with Bounding Boxes</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="51eeae9fe36f031b9bbc4e7ce891844c997b1b08" translate="yes" xml:space="preserve">
          <source>WrapDatasetVariant</source>
          <target state="translated">WrapDatasetVariant</target>
        </trans-unit>
        <trans-unit id="7a41e51968848ca6ebbc48f555f3248a673bee90" translate="yes" xml:space="preserve">
          <source>Wrapped inputs (identity standins that have additional metadata). These are also are also tf.Tensor's.</source>
          <target state="translated">Обернутые входы (идентификационные стенды,имеющие дополнительные метаданные).Это также tf.Tensor's.</target>
        </trans-unit>
        <trans-unit id="384f837341c0fc0fa71de4eb8e929b11e7daf27f" translate="yes" xml:space="preserve">
          <source>Wrapped outputs (identity standins that have additional metadata). These are also tf.Tensor's.</source>
          <target state="translated">Обернутые выходы (идентификационные стенды,имеющие дополнительные метаданные).Это также tf.Tensor's.</target>
        </trans-unit>
        <trans-unit id="a298562930ec81f39bad36c204ae1b1059782591" translate="yes" xml:space="preserve">
          <source>Wrapped values: In order to represent values parallel across devices (either replicas or the devices associated with a particular value), we wrap them in a &quot;PerReplica&quot; or &quot;Mirrored&quot; object that contains a map from replica id to values. &quot;PerReplica&quot; is used when the value may be different across replicas, and &quot;Mirrored&quot; when the value are the same.</source>
          <target state="translated">Завернутые значения:Для того,чтобы представить параллельные значения по устройствам (либо репликам,либо устройствам,связанным с определенным значением),мы обертываем их в объект &quot;PerReplica&quot; или &quot;Mirrored&quot;,который содержит карту от идентификатора реплики до значений.&quot;PerReplica&quot; используется,когда значение может быть разным для разных копий,и &quot;Зеркальное&quot;,когда значение одинаково.</target>
        </trans-unit>
        <trans-unit id="890d066e219e9b18bb1c24edca8341903adbf397" translate="yes" xml:space="preserve">
          <source>Wrapper allowing a stack of RNN cells to behave as a single cell.</source>
          <target state="translated">Обертка,позволяющая стопке RNN ячеек вести себя как одна ячейка.</target>
        </trans-unit>
        <trans-unit id="b4013106a25f53b1f217b9c3881270bfb6839489" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collection&quot;&gt;&lt;code&gt;Graph.add_to_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#add_to_collection&quot;&gt; &lt;code&gt;Graph.add_to_collection()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="caa4198da3fc275ac76081f0b3d1bfe03cdd54fe" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#add_to_collections&quot;&gt;&lt;code&gt;Graph.add_to_collections()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#add_to_collections&quot;&gt; &lt;code&gt;Graph.add_to_collections()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="264584356d25721fe348ac95a81a23f4cca709f4" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#container&quot;&gt;&lt;code&gt;Graph.container()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#container&quot;&gt; &lt;code&gt;Graph.container()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="55f30bd6389eac4a761d1daf54731878db305f29" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#device&quot;&gt;&lt;code&gt;Graph.device()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#device&quot;&gt; &lt;code&gt;Graph.device()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="0d1e4b32d773cedbb0330530a2382ac0bddfaba8" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection&quot;&gt;&lt;code&gt;Graph.get_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#get_collection&quot;&gt; &lt;code&gt;Graph.get_collection()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="190d7f80a83427a732312702b0799aa4fd4270f6" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;../../graph#get_collection_ref&quot;&gt;&lt;code&gt;Graph.get_collection_ref()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">Обертка для &lt;a href=&quot;../../graph#get_collection_ref&quot;&gt; &lt;code&gt;Graph.get_collection_ref()&lt;/code&gt; &lt;/a&gt; с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="89aa6df88d5fbd573c88df4510194a5615a938d5" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;graph#control_dependencies&quot;&gt;&lt;code&gt;Graph.control_dependencies()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="translated">&lt;a href=&quot;graph#control_dependencies&quot;&gt; &lt;code&gt;Graph.control_dependencies()&lt;/code&gt; &lt;/a&gt; для Graph.control_dependencies () с использованием графика по умолчанию.</target>
        </trans-unit>
        <trans-unit id="495b2dd43c40b93e9963a63ddff35ea9979905aa" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collection&quot;&gt;&lt;code&gt;Graph.add_to_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d79bebe0b09c5426685f0e539708d5d444124cc5" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#add_to_collections&quot;&gt;&lt;code&gt;Graph.add_to_collections()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="128db28adf836bfc21dd5fc549881d12855001a9" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#container&quot;&gt;&lt;code&gt;Graph.container()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="189fdde0fe51377c9c7df91b00d623f673fa3f34" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#device&quot;&gt;&lt;code&gt;Graph.device()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="04af0f377456628e691bf3f85dc843ed001f5c1b" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection&quot;&gt;&lt;code&gt;Graph.get_collection()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bed252c3eb66e3bb7424c1c2a3122d3cfea4dfb8" translate="yes" xml:space="preserve">
          <source>Wrapper for &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph#get_collection_ref&quot;&gt;&lt;code&gt;Graph.get_collection_ref()&lt;/code&gt;&lt;/a&gt; using the default graph.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2f37a810bede5b1390f81fea4b6be44aec37fbe5" translate="yes" xml:space="preserve">
          <source>Wrapper for using the Scikit-Learn API with Keras models.</source>
          <target state="translated">Обертка для использования API Scikit-Learn с моделями Keras.</target>
        </trans-unit>
        <trans-unit id="1fff217e51e30156f66782f095344b6ef97a4794" translate="yes" xml:space="preserve">
          <source>Wrappers for primitive Neural Net (NN) Operations.</source>
          <target state="translated">Обертки для примитивных операций с нейронными сетями (NN).</target>
        </trans-unit>
        <trans-unit id="7837b0cc643e2f001702979a842efc255ca9da70" translate="yes" xml:space="preserve">
          <source>Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the &lt;code&gt;TimeDistributed&lt;/code&gt; and &lt;code&gt;Bidirectional&lt;/code&gt; wrappers.</source>
          <target state="translated">Обертки берут еще один слой и увеличивают его различными способами. Не используйте этот класс как слой, это всего лишь абстрактный базовый класс. Две используемые оболочки - это &lt;code&gt;TimeDistributed&lt;/code&gt; и &lt;code&gt;Bidirectional&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3381242ca6a26b413c24d45326c44a72bdf78124" translate="yes" xml:space="preserve">
          <source>Wraps &lt;code&gt;call&lt;/code&gt;, applying pre- and post-processing steps.</source>
          <target state="translated">Обертывание &lt;code&gt;call&lt;/code&gt; применением этапов предварительной и постобработки.</target>
        </trans-unit>
        <trans-unit id="c62cdbd485fcae9d06ca69b5b8397cfed846cb17" translate="yes" xml:space="preserve">
          <source>Wraps a given text to a maximum line length and returns it.</source>
          <target state="translated">Обертывает заданный текст на максимальную длину строки и возвращает его.</target>
        </trans-unit>
        <trans-unit id="8829b71bb0967a49348c7e7adf87bb1886403153" translate="yes" xml:space="preserve">
          <source>Wraps a python function and uses it as a TensorFlow op.</source>
          <target state="translated">Обертывает функцию питона и использует ее как операцию TensorFlow.</target>
        </trans-unit>
        <trans-unit id="8abaa30206e6292e5e70829b82947753e40ac335" translate="yes" xml:space="preserve">
          <source>Wraps a python function into a TensorFlow op that executes it eagerly.</source>
          <target state="translated">Обертывает питоновую функцию в операцию TensorFlow,которая выполняет ее с нетерпением.</target>
        </trans-unit>
        <trans-unit id="82ab6329b627d91bd83e44d4fe219ae9ac70441c" translate="yes" xml:space="preserve">
          <source>Wraps a value that may/may not be present at runtime.</source>
          <target state="translated">Обертывает значение,которое может отсутствовать/не присутствовать во время выполнения.</target>
        </trans-unit>
        <trans-unit id="19c9eb1de0862700ff8502bf5e2ae450855f9133" translate="yes" xml:space="preserve">
          <source>Wraps arbitrary expressions as a &lt;code&gt;Layer&lt;/code&gt; object.</source>
          <target state="translated">Оборачивает произвольные выражения как объект &lt;code&gt;Layer&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="352659d98f226f42ae5f9c0345757253d7e85e6e" translate="yes" xml:space="preserve">
          <source>Wraps the TF 1.x function fn into a graph function.</source>
          <target state="translated">Обертывает функцию TF 1.x fn в графическую функцию.</target>
        </trans-unit>
        <trans-unit id="20b643b52957c38a95449d4001fccba2e0bcd12a" translate="yes" xml:space="preserve">
          <source>Write &lt;code&gt;value&lt;/code&gt; into index &lt;code&gt;index&lt;/code&gt; of the TensorArray.</source>
          <target state="translated">Записать &lt;code&gt;value&lt;/code&gt; в индексный &lt;code&gt;index&lt;/code&gt; TensorArray.</target>
        </trans-unit>
        <trans-unit id="483cdae75a267d35fd6e83b5653511d5a80cff0f" translate="yes" xml:space="preserve">
          <source>Write a customized optimizer.</source>
          <target state="translated">Напишите индивидуальный оптимизатор.</target>
        </trans-unit>
        <trans-unit id="c8c630765322886f9847c22284b5fa8d2851f2ce" translate="yes" xml:space="preserve">
          <source>Write a histogram summary.</source>
          <target state="translated">Напишите сводку гистограммы.</target>
        </trans-unit>
        <trans-unit id="b0075d853115d3caa9b112367f26a9151c343826" translate="yes" xml:space="preserve">
          <source>Write a scalar summary.</source>
          <target state="translated">Напишите скалярное резюме.</target>
        </trans-unit>
        <trans-unit id="76fe5c36d30ae305e5a6503ba46502eb4a13331d" translate="yes" xml:space="preserve">
          <source>Write a string record to the file.</source>
          <target state="translated">Запишите в файл строковую запись.</target>
        </trans-unit>
        <trans-unit id="5b53b6d51e993b431470b37c217c59753ff1cc50" translate="yes" xml:space="preserve">
          <source>Write a text summary.</source>
          <target state="translated">Напишите текстовое резюме.</target>
        </trans-unit>
        <trans-unit id="d21f1a898ccfeda0fe2e731850a28cfafae9bb2b" translate="yes" xml:space="preserve">
          <source>Write an audio summary.</source>
          <target state="translated">Напишите аудио резюме.</target>
        </trans-unit>
        <trans-unit id="21a6eeb1ed26a2be90d3ee27390e8e2bda8c0962" translate="yes" xml:space="preserve">
          <source>Write an image summary.</source>
          <target state="translated">Напишите краткое описание изображения.</target>
        </trans-unit>
        <trans-unit id="61f330bc93ccdaf24823ff722556ec64642374a9" translate="yes" xml:space="preserve">
          <source>Write data via Write and read via Read or Pack.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0b36ad4c95f8d96567af24f9c3edf891e090ad84" translate="yes" xml:space="preserve">
          <source>Write the serialized data to one or more files</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2a6db3a59303fe109b5b5137b804a970c912e147" translate="yes" xml:space="preserve">
          <source>Write this:</source>
          <target state="translated">Напиши это:</target>
        </trans-unit>
        <trans-unit id="6226f3d4ff16e7406bb0cdaedd7746abc5236636" translate="yes" xml:space="preserve">
          <source>WriteAudioSummary</source>
          <target state="translated">WriteAudioSummary</target>
        </trans-unit>
        <trans-unit id="94dee2fafe1d10d5ce6db659eb0c0fcb3d5842be" translate="yes" xml:space="preserve">
          <source>WriteFile</source>
          <target state="translated">WriteFile</target>
        </trans-unit>
        <trans-unit id="1ea63605e83eb910f0b5d75fe28edb99127b24d1" translate="yes" xml:space="preserve">
          <source>WriteGraphSummary</source>
          <target state="translated">WriteGraphSummary</target>
        </trans-unit>
        <trans-unit id="e5637c5d46d26a2b2c82fac03d3b096952d4bf28" translate="yes" xml:space="preserve">
          <source>WriteHistogramSummary</source>
          <target state="translated">WriteHistogramSummary</target>
        </trans-unit>
        <trans-unit id="6b51491885b3d25ccb268be4c798a6b10e3d5b9d" translate="yes" xml:space="preserve">
          <source>WriteImageSummary</source>
          <target state="translated">WriteImageSummary</target>
        </trans-unit>
        <trans-unit id="4a572e40863e9455f5578aec02c3c8842448412b" translate="yes" xml:space="preserve">
          <source>WriteRawProtoSummary</source>
          <target state="translated">WriteRawProtoSummary</target>
        </trans-unit>
        <trans-unit id="88f81acb7e965e0b6b73b00739698ed9296482c6" translate="yes" xml:space="preserve">
          <source>WriteScalarSummary</source>
          <target state="translated">WriteScalarSummary</target>
        </trans-unit>
        <trans-unit id="cb73c41075bf3f01d3eb7791f75623bd77006f1a" translate="yes" xml:space="preserve">
          <source>WriteSummary</source>
          <target state="translated">WriteSummary</target>
        </trans-unit>
        <trans-unit id="29a4cf60a26ded7a2c3aed4855011f0c8495cfe3" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;MetaGraphDef&lt;/code&gt; to save_path/filename.</source>
          <target state="translated">Записывает &lt;code&gt;MetaGraphDef&lt;/code&gt; в save_path / filename.</target>
        </trans-unit>
        <trans-unit id="9fa9b02b6070f8899e280b451f66b6bd6b575f93" translate="yes" xml:space="preserve">
          <source>Writes &lt;code&gt;Summary&lt;/code&gt; protocol buffers to event files.</source>
          <target state="translated">Пишет &lt;code&gt;Summary&lt;/code&gt; буферов протокола для файлов событий.</target>
        </trans-unit>
        <trans-unit id="babca584f4aae5499f0f80472fec83895337e06c" translate="yes" xml:space="preserve">
          <source>Writes a &lt;code&gt;SavedModel&lt;/code&gt; protocol buffer to disk.</source>
          <target state="translated">Записывает &lt;code&gt;SavedModel&lt;/code&gt; протокола SavedModel на диск.</target>
        </trans-unit>
        <trans-unit id="ec531d54bcd6301e96265e18d2ce6d1e6c9a4e3b" translate="yes" xml:space="preserve">
          <source>Writes a dataset to a TFRecord file.</source>
          <target state="translated">Записывает набор данных в файл TFRecord.</target>
        </trans-unit>
        <trans-unit id="233cc84a3671355de983f6c125f1b2c0c8c7fc01" translate="yes" xml:space="preserve">
          <source>Writes a generic summary to the default SummaryWriter if one exists.</source>
          <target state="translated">Записывает общее резюме в итоговый записывающее устройство по умолчанию,если таковое существует.</target>
        </trans-unit>
        <trans-unit id="d15430e669e23755ec2b520aa11323169d62858a" translate="yes" xml:space="preserve">
          <source>Writes a graph proto to a file.</source>
          <target state="translated">Записывает протографию в файл.</target>
        </trans-unit>
        <trans-unit id="9976fe10182472bc6e870e0863e6f6d04fac02a5" translate="yes" xml:space="preserve">
          <source>Writes a set of weights into the opaque params buffer so they can be used in upcoming training or inferences.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0faccf4f9a4005aa59d77d68c1f6677070d11c1f" translate="yes" xml:space="preserve">
          <source>Writes a summary using raw &lt;a href=&quot;../../compat/v1/summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffers.</source>
          <target state="translated">Записывает сводку с использованием необработанных &lt;a href=&quot;../../compat/v1/summary&quot;&gt; &lt;code&gt;tf.compat.v1.Summary&lt;/code&gt; &lt;/a&gt; протокола tf.compat.v1.Summary .</target>
        </trans-unit>
        <trans-unit id="5adf0b1064881763cf04269a02e41a3ea90a5906" translate="yes" xml:space="preserve">
          <source>Writes a training checkpoint.</source>
          <target state="translated">Пишет учебный контрольно-пропускной пункт.</target>
        </trans-unit>
        <trans-unit id="f2b611268944160d96a5b9a8fcf79249e74eb83f" translate="yes" xml:space="preserve">
          <source>Writes contents to the file at input filename. Creates file and recursively</source>
          <target state="translated">Записывает содержимое в файл по имени входного файла.Создает файл и рекурсивно</target>
        </trans-unit>
        <trans-unit id="7fb1d95dfee1bc896877fefd9cbe8b4b9c44e0bf" translate="yes" xml:space="preserve">
          <source>Writes file_content to the file. Appends to the end of the file.</source>
          <target state="translated">Записывает в файл файл_контент.Добавляется в конец файла.</target>
        </trans-unit>
        <trans-unit id="a2ce6c85367b8678f1f61797d0dc74828b05ea19" translate="yes" xml:space="preserve">
          <source>Writes new value to variable's memory. Doesn't add ops to the graph.</source>
          <target state="translated">Записывает новое значение в память переменной.Не добавляет оп на граф.</target>
        </trans-unit>
        <trans-unit id="99b81ac6b0204ef18bee769984926a4ea6b12daf" translate="yes" xml:space="preserve">
          <source>Writes the given dataset to the given file using the TFRecord format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="45f84d521a5351104bc075acf3695dd6bad6898e" translate="yes" xml:space="preserve">
          <source>Writing custom layers and models with Keras</source>
          <target state="translated">Написание пользовательских слоев и моделей с помощью Keras</target>
        </trans-unit>
        <trans-unit id="c6a0c4f8b902d47bac80ddaf6bf34b2fbf4f9666" translate="yes" xml:space="preserve">
          <source>Xception V1 model for Keras.</source>
          <target state="translated">Xception V1 модель для Keras.</target>
        </trans-unit>
        <trans-unit id="1b60eef1486f042121cb1abb403bfa5983083402" translate="yes" xml:space="preserve">
          <source>Xdivy</source>
          <target state="translated">Xdivy</target>
        </trans-unit>
        <trans-unit id="9ed9396da589e127b120b5abc619086b34774295" translate="yes" xml:space="preserve">
          <source>Xlog1py</source>
          <target state="translated">Xlog1py</target>
        </trans-unit>
        <trans-unit id="12f9191163bb7e9e63172afc062b7b9642ca43a1" translate="yes" xml:space="preserve">
          <source>Xlogy</source>
          <target state="translated">Xlogy</target>
        </trans-unit>
        <trans-unit id="bccf09988d791dbda2da42e387167025b7d54ccb" translate="yes" xml:space="preserve">
          <source>YAML string or open file encoding a model configuration.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dfea80b5fe13bab375ae2dddcdd3dbb43f1a3633" translate="yes" xml:space="preserve">
          <source>Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset, which is a derivative work from original NIST datasets. MNIST dataset is made available under the terms of the &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/3.0/&quot;&gt;Creative Commons Attribution-Share Alike 3.0 license.&lt;/a&gt;</source>
          <target state="translated">Янн ЛеКун и Коринна Кортес владеют авторскими правами на набор данных MNIST, который является производным от исходных наборов данных NIST. Набор данных MNIST предоставляется в соответствии с условиями &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/3.0/&quot;&gt;лицензии Creative Commons Attribution-Share Alike 3.0.&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="f0d948a8bdb9eb6bb818e3240fb3b2534756d8f7" translate="yes" xml:space="preserve">
          <source>Yields predictions for given features.</source>
          <target state="translated">Дает прогнозы для заданных характеристик.</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e930f451f4aa0e180bfec9e3ca9b3c51172a0d23" translate="yes" xml:space="preserve">
          <source>You can access a layer's regularization penalties by calling &lt;code&gt;layer.losses&lt;/code&gt; after calling the layer on inputs.</source>
          <target state="translated">Вы можете получить доступ к штрафам за регуляризацию уровня, вызвав &lt;code&gt;layer.losses&lt;/code&gt; после вызова слоя на входах.</target>
        </trans-unit>
        <trans-unit id="59874a67ef5f7bd864b9ef3d3bb9393f8444ef02" translate="yes" xml:space="preserve">
          <source>You can access the raw &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt; object used by &lt;code&gt;SingularMonitoredSession&lt;/code&gt;, whereas in MonitoredSession the raw session is private. This can be used:</source>
          <target state="translated">Вы можете получить доступ к необработанному объекту &lt;a href=&quot;../session&quot;&gt; &lt;code&gt;tf.compat.v1.Session&lt;/code&gt; ,&lt;/a&gt; используемому &lt;code&gt;SingularMonitoredSession&lt;/code&gt; , тогда как в MonitoredSession необработанный сеанс является частным. Это можно использовать:</target>
        </trans-unit>
        <trans-unit id="6ccb3baa3a0cbd712e9c239e9968fd1fb9ad400a" translate="yes" xml:space="preserve">
          <source>You can add an outer &lt;code&gt;batch&lt;/code&gt; axis by passing &lt;code&gt;axis=0&lt;/code&gt;:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e7c18d1ca2444e96db7357ab3243c23ba7a401f2" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="translated">Вы также можете передать экземпляр &lt;a href=&quot;../../../../distribute/cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt; при создании экземпляра стратегии. Task_type, task_id и т. Д. Будут проанализированы из экземпляра преобразователя, а не из &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</target>
        </trans-unit>
        <trans-unit id="6e5fb70392b78f99083230f0a97aa193ef7fda3b" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="translated">Вы также можете передать экземпляр &lt;a href=&quot;../cluster_resolver/clusterresolver&quot;&gt; &lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt; &lt;/a&gt; при создании экземпляра стратегии. Task_type, task_id и т. Д. Будут проанализированы из экземпляра преобразователя, а не из &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</target>
        </trans-unit>
        <trans-unit id="5e1ab8575cb5168a5735bdcf646fbc24611fcf94" translate="yes" xml:space="preserve">
          <source>You can also pass a &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/ClusterResolver&quot;&gt;&lt;code&gt;distribute.cluster_resolver.ClusterResolver&lt;/code&gt;&lt;/a&gt; instance when instantiating the strategy. The task_type, task_id etc. will be parsed from the resolver instance instead of from the &lt;code&gt;TF_CONFIG&lt;/code&gt; env var.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ea8ecb649a2869edbe22ed0fa4b60b444f6b3240" translate="yes" xml:space="preserve">
          <source>You can also pass the following additional pieces to the constructor:</source>
          <target state="translated">Вы также можете передать конструктору следующие дополнительные детали:</target>
        </trans-unit>
        <trans-unit id="beae5b5e28d39839a95e5dcf5642d815e8f5ff5c" translate="yes" xml:space="preserve">
          <source>You can also specify &lt;code&gt;config&lt;/code&gt; of the loss to this function by passing dict containing &lt;code&gt;class_name&lt;/code&gt; and &lt;code&gt;config&lt;/code&gt; as an identifier. Also note that the &lt;code&gt;class_name&lt;/code&gt; must map to a &lt;code&gt;Loss&lt;/code&gt; class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c69555354a0bc222fe10d4f7bc39675e8b5f8158" translate="yes" xml:space="preserve">
          <source>You can also specify &lt;code&gt;config&lt;/code&gt; of the metric to this function by passing dict containing &lt;code&gt;class_name&lt;/code&gt; and &lt;code&gt;config&lt;/code&gt; as an identifier. Also note that the &lt;code&gt;class_name&lt;/code&gt; must map to a &lt;code&gt;Metric&lt;/code&gt; class</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="52dc5982a3012b85661499626a8a8038241b7ffd" translate="yes" xml:space="preserve">
          <source>You can also use &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt; to debug your models at runtime using Python tools, i.e., you can isolate portions of your code that you want to debug, wrap them in Python functions and insert &lt;code&gt;pdb&lt;/code&gt; tracepoints or print statements as desired, and wrap those functions in &lt;a href=&quot;py_function&quot;&gt;&lt;code&gt;tf.py_function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы также можете использовать &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; для отладки ваших моделей во время выполнения с помощью инструментов Python, то есть вы можете изолировать части вашего кода, которые вы хотите отлаживать, обернуть их в функции Python и вставить точки трассировки &lt;code&gt;pdb&lt;/code&gt; или операторы печати по желанию и обернуть их функции в &lt;a href=&quot;py_function&quot;&gt; &lt;code&gt;tf.py_function&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="6039b0dfd851cbc8275eabb888826394ae1b2ab1" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6714d05f3ec58957845e4e02d40676c59a816f4" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="153ea4bbc50ebf5e0a8403f29bb6788447deb11c" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9ac6704fae664e72c4f0645536563ff0de5afe80" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../../../distribute/distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dcaf3f8131e1ea14866dcfb7fa41b1b0194e1d80" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3385c4f6d32325dcf782cc9941db6f2f275241a0" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;../distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="68d5075223b70a3c64aec568d9f4b72b9521b3e8" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; instance returned by this API to query the &lt;a href=&quot;../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3234565ee9ebae226cb6498a83d504945b3da8d1" translate="yes" xml:space="preserve">
          <source>You can also use the &lt;code&gt;element_spec&lt;/code&gt; property of the &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; returned by this API to query the &lt;a href=&quot;../typespec&quot;&gt;&lt;code&gt;tf.TypeSpec&lt;/code&gt;&lt;/a&gt; of the elements returned by the iterator. This can be used to set the &lt;code&gt;input_signature&lt;/code&gt; property of a &lt;a href=&quot;../function&quot;&gt;&lt;code&gt;tf.function&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9bf7e26d5c0cf51e4e4917f1eb23c3d37328691" translate="yes" xml:space="preserve">
          <source>You can cast a Keras variable but it still returns a Keras tensor.</source>
          <target state="translated">Вы можете разыграть переменную Keras,но она все равно возвращает тензор Keras.</target>
        </trans-unit>
        <trans-unit id="3a3ea187f9997f3359ee54a5e203867aab3b8b27" translate="yes" xml:space="preserve">
          <source>You can create a &lt;a href=&quot;distributediterator&quot;&gt;&lt;code&gt;tf.distribute.DistributedIterator&lt;/code&gt;&lt;/a&gt; by calling &lt;code&gt;iter&lt;/code&gt; on a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt; or creating a python loop over a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c77d6bc9128a9a471ae009d158974ccffab599c2" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете отключить &lt;code&gt;auto_shard&lt;/code&gt; набора данных по рабочим процессам, используя параметр &lt;a href=&quot;../../../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; в tf.data.experimental.DistributeOptions .</target>
        </trans-unit>
        <trans-unit id="abcd404b6ec568dc3b6a192e74ff39fd2a467efc" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете отключить &lt;code&gt;auto_shard&lt;/code&gt; набора данных по рабочим процессам, используя параметр &lt;a href=&quot;../../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; в tf.data.experimental.DistributeOptions .</target>
        </trans-unit>
        <trans-unit id="755b5985c40de671a4eb4bfb403b9e1a2cab5a03" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете отключить &lt;code&gt;auto_shard&lt;/code&gt; набора данных по рабочим процессам, используя параметр &lt;a href=&quot;../../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; в tf.data.experimental.DistributeOptions .</target>
        </trans-unit>
        <trans-unit id="823e308b708edca072a13279a53e3cee2ec00199" translate="yes" xml:space="preserve">
          <source>You can disable dataset sharding across workers using the &lt;code&gt;auto_shard&lt;/code&gt; option in &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете отключить &lt;code&gt;auto_shard&lt;/code&gt; набора данных по рабочим процессам, используя параметр &lt;a href=&quot;../data/experimental/distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; в tf.data.experimental.DistributeOptions .</target>
        </trans-unit>
        <trans-unit id="77348208b8f388d909966c4b5fc03169d2df6ba3" translate="yes" xml:space="preserve">
          <source>You can find more information about TensorBoard &lt;a href=&quot;https://www.tensorflow.org/get_started/summaries_and_tensorboard&quot;&gt;here&lt;/a&gt;.</source>
          <target state="translated">Вы можете найти больше информации о TensorBoard &lt;a href=&quot;https://www.tensorflow.org/get_started/summaries_and_tensorboard&quot;&gt;здесь&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0be849f93096dd779e7a88c6ab36a4f32c9e43a7" translate="yes" xml:space="preserve">
          <source>You can implement 'SUM_OVER_BATCH_SIZE' using global batch size like:</source>
          <target state="translated">Вы можете реализовать 'SUM_OVER_BATCH_SIZE',используя глобальный размер партии,например:</target>
        </trans-unit>
        <trans-unit id="afa5195343dbaa120879b06f025ea84ad87e6a32" translate="yes" xml:space="preserve">
          <source>You can modify the operations in place, but modifications to the list such as inserts/delete have no effect on the list of operations known to the graph.</source>
          <target state="translated">Операции можно изменять на месте,но изменения в списке,такие как вставки/удаление,не влияют на список операций,известный графику.</target>
        </trans-unit>
        <trans-unit id="1c3d65193eb861cca9fdcde225478e0055db490e" translate="yes" xml:space="preserve">
          <source>You can now use table in functions like &lt;a href=&quot;../../../nn/embedding_lookup&quot;&gt;&lt;code&gt;tf.nn.embedding_lookup&lt;/code&gt;&lt;/a&gt; to perform your embedding lookup and pass to your model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2c02260f75018990666dbe2089789cfb29e9e718" translate="yes" xml:space="preserve">
          <source>You can pass None to clear the control dependencies:</source>
          <target state="translated">Вы можете пропустить &quot;Нет&quot;,чтобы очистить контрольные зависимости:</target>
        </trans-unit>
        <trans-unit id="215f1df4bc1261bbb6f65d825790eea599447ab5" translate="yes" xml:space="preserve">
          <source>You can pass any of the returned values to &lt;code&gt;restore()&lt;/code&gt;.</source>
          <target state="translated">Вы можете передать любое из возвращенных значений в &lt;code&gt;restore()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ac470d84ff347998661ececab5ea81ac9cc6a909" translate="yes" xml:space="preserve">
          <source>You can pass the result of evaluating any summary op, using &lt;code&gt;tf.Session.run&lt;/code&gt; or &lt;a href=&quot;../../../tensor#eval&quot;&gt;&lt;code&gt;tf.Tensor.eval&lt;/code&gt;&lt;/a&gt;, to this function. Alternatively, you can pass a &lt;a href=&quot;../summary&quot;&gt;&lt;code&gt;tf.compat.v1.Summary&lt;/code&gt;&lt;/a&gt; protocol buffer that you populate with your own data. The latter is commonly done to report evaluation results in event files.</source>
          <target state="translated">Вы можете передать результат оценки любой итоговой операции с помощью &lt;code&gt;tf.Session.run&lt;/code&gt; или &lt;a href=&quot;../../../tensor#eval&quot;&gt; &lt;code&gt;tf.Tensor.eval&lt;/code&gt; &lt;/a&gt; в эту функцию. В качестве альтернативы вы можете передать &lt;a href=&quot;../summary&quot;&gt; &lt;code&gt;tf.compat.v1.Summary&lt;/code&gt; &lt;/a&gt; протокола tf.compat.v1.Summary , который вы заполняете своими собственными данными. Последнее обычно делается для сообщения результатов оценки в файлах событий.</target>
        </trans-unit>
        <trans-unit id="69155a67a44012b4f51b2dc8d0ccd534aa7907a1" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a Keras model when decaying 1/t with a rate of 0.5:</source>
          <target state="translated">Вы можете передать это расписание прямо в &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; в качестве скорости обучения. Пример: подобрать модель Кераса при разложении 1 / т со скоростью 0,5:</target>
        </trans-unit>
        <trans-unit id="48f5a8f4038134ce54531b0e709a77dbf5681703" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using sqrt (i.e. power=0.5):</source>
          <target state="translated">Вы можете передать это расписание прямо в &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; в качестве скорости обучения. Пример: подобрать модель при уменьшении от 0,1 до 0,01 за 10000 шагов с использованием sqrt (т.е. power = 0,5):</target>
        </trans-unit>
        <trans-unit id="40b491f9b541bdf48952295bf5d5a0ca64ae94b3" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. Example: When fitting a Keras model, decay every 100000 steps with a base of 0.96:</source>
          <target state="translated">Вы можете передать это расписание прямо в &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; в качестве скорости обучения. Пример: при подборе модели Кераса затухание каждые 100000 шагов с базой 0,96:</target>
        </trans-unit>
        <trans-unit id="573311646e6161dd40916f132e58fdf271d90b7d" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете передать это расписание прямо в &lt;a href=&quot;../optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; в качестве скорости обучения. График скорости обучения также можно сериализовать и десериализовать с помощью &lt;a href=&quot;serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5458dcea309d742dc1ae87c297fbd433242a68c9" translate="yes" xml:space="preserve">
          <source>You can pass this schedule directly into a &lt;a href=&quot;../optimizers/optimizer&quot;&gt;&lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt;&lt;/a&gt; as the learning rate. The learning rate schedule is also serializable and deserializable using &lt;a href=&quot;../optimizers/schedules/serialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../optimizers/schedules/deserialize&quot;&gt;&lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете передать это расписание прямо в &lt;a href=&quot;../optimizers/optimizer&quot;&gt; &lt;code&gt;tf.keras.optimizers.Optimizer&lt;/code&gt; &lt;/a&gt; в качестве скорости обучения. График скорости обучения также можно сериализовать и десериализовать с помощью &lt;a href=&quot;../optimizers/schedules/serialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.serialize&lt;/code&gt; &lt;/a&gt; и &lt;a href=&quot;../optimizers/schedules/deserialize&quot;&gt; &lt;code&gt;tf.keras.optimizers.schedules.deserialize&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="154d72e5d23674ce441818a8ed845bb4df350073" translate="yes" xml:space="preserve">
          <source>You can provide logits of classes as &lt;code&gt;y_pred&lt;/code&gt;, since argmax of logits and probabilities are same.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0779a4d81e795874a050ef63a764491cc356c1c7" translate="yes" xml:space="preserve">
          <source>You can return from this call a &lt;code&gt;SessionRunArgs&lt;/code&gt; object indicating ops or tensors to add to the upcoming &lt;code&gt;run()&lt;/code&gt; call. These ops/tensors will be run together with the ops/tensors originally passed to the original run() call. The run args you return can also contain feeds to be added to the run() call.</source>
          <target state="translated">Вы можете вернуть из этого вызова объект &lt;code&gt;SessionRunArgs&lt;/code&gt; , указывающий операции или тензоры, которые нужно добавить к предстоящему вызову &lt;code&gt;run()&lt;/code&gt; . Эти операции / тензоры будут запускаться вместе с операциями / тензорами, первоначально переданными исходному вызову run (). Возвращаемые вами аргументы run также могут содержать каналы, которые нужно добавить к вызову run ().</target>
        </trans-unit>
        <trans-unit id="9ae0a59fa6ec6a5af526342b6817b045dd0db4e8" translate="yes" xml:space="preserve">
          <source>You can set the distribution options of a dataset through the &lt;code&gt;experimental_distribute&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;distributeoptions&quot;&gt;&lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете установить параметры распространения набора данных через свойство &lt;code&gt;experimental_distribute&lt;/code&gt; &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; свойство является экземпляром &lt;a href=&quot;distributeoptions&quot;&gt; &lt;code&gt;tf.data.experimental.DistributeOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="38287133e2e375cb065b8aff1223591e0429addd" translate="yes" xml:space="preserve">
          <source>You can set the optimization options of a dataset through the &lt;code&gt;experimental_optimization&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;optimizationoptions&quot;&gt;&lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете установить параметры оптимизации набора данных с помощью свойства &lt;code&gt;experimental_optimization&lt;/code&gt; &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; свойство является экземпляром &lt;a href=&quot;optimizationoptions&quot;&gt; &lt;code&gt;tf.data.experimental.OptimizationOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="a4942db36ae427216d9ed0a514b6b4124827857d" translate="yes" xml:space="preserve">
          <source>You can set the stats options of a dataset through the &lt;code&gt;experimental_stats&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;statsoptions&quot;&gt;&lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt;&lt;/a&gt;. For example, to collect latency stats on all dataset edges, use the following pattern:</source>
          <target state="translated">Вы можете установить параметры статистики для набора данных через свойство &lt;code&gt;experimental_stats&lt;/code&gt; объекта &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; свойство является экземпляром &lt;a href=&quot;statsoptions&quot;&gt; &lt;code&gt;tf.data.experimental.StatsOptions&lt;/code&gt; &lt;/a&gt; . Например, чтобы собрать статистику задержки на всех краях набора данных, используйте следующий шаблон:</target>
        </trans-unit>
        <trans-unit id="0286d405fc4b694404c86890a3b0233533e44d1a" translate="yes" xml:space="preserve">
          <source>You can set the threading options of a dataset through the &lt;code&gt;experimental_threading&lt;/code&gt; property of &lt;a href=&quot;../options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt;; the property is an instance of &lt;a href=&quot;threadingoptions&quot;&gt;&lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Вы можете установить параметры потоковой передачи набора данных с помощью свойства &lt;code&gt;experimental_threading&lt;/code&gt; &lt;a href=&quot;../options&quot;&gt; &lt;code&gt;tf.data.Options&lt;/code&gt; &lt;/a&gt; ; свойство является экземпляром &lt;a href=&quot;threadingoptions&quot;&gt; &lt;code&gt;tf.data.experimental.ThreadingOptions&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="5821880102274e82922a0313317c1a0e00262ef7" translate="yes" xml:space="preserve">
          <source>You can specify the initial state of RNN layers numerically by calling &lt;code&gt;reset_states&lt;/code&gt; with the keyword argument &lt;code&gt;states&lt;/code&gt;. The value of &lt;code&gt;states&lt;/code&gt; should be a numpy array or list of numpy arrays representing the initial state of the RNN layer.</source>
          <target state="translated">Вы можете указать начальное состояние слоев RNN численно, вызвав &lt;code&gt;reset_states&lt;/code&gt; с ключевым словом аргумент &lt;code&gt;states&lt;/code&gt; . Значение &lt;code&gt;states&lt;/code&gt; должно быть массивом numpy или списком массивов numpy, представляющих начальное состояние уровня RNN.</target>
        </trans-unit>
        <trans-unit id="7903e8eb7e3c0e1f135ecaca1aabba76f1186224" translate="yes" xml:space="preserve">
          <source>You can then use &lt;code&gt;TimeDistributed&lt;/code&gt; to apply a &lt;code&gt;Conv2D&lt;/code&gt; layer to each of the 10 timesteps, independently:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0934b024d096c8c6f1a29dcdebc76afd185fc96d" translate="yes" xml:space="preserve">
          <source>You can then use &lt;code&gt;TimeDistributed&lt;/code&gt; to apply a &lt;code&gt;Dense&lt;/code&gt; layer to each of the 10 timesteps, independently:</source>
          <target state="translated">Затем вы можете использовать &lt;code&gt;TimeDistributed&lt;/code&gt; для применения &lt;code&gt;Dense&lt;/code&gt; слоя к каждому из 10 временных шагов независимо:</target>
        </trans-unit>
        <trans-unit id="49b9bca1daa199f82797585539058cf0bff378d8" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;get_replica_context&quot;&gt;&lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt;&lt;/a&gt; to get an instance of &lt;code&gt;ReplicaContext&lt;/code&gt;. This should be inside your replicated step function, such as in a &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt;&lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="translated">Вы можете использовать &lt;a href=&quot;get_replica_context&quot;&gt; &lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt; ,&lt;/a&gt; чтобы получить экземпляр &lt;code&gt;ReplicaContext&lt;/code&gt; . Это должно быть внутри вашей реплицированной ступенчатой ​​функции, например, в вызове &lt;a href=&quot;strategy#experimental_run_v2&quot;&gt; &lt;code&gt;tf.distribute.Strategy.experimental_run_v2&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="f52e741d1756d64c06640ac0efef1ab8aa73c071" translate="yes" xml:space="preserve">
          <source>You can use &lt;a href=&quot;get_replica_context&quot;&gt;&lt;code&gt;tf.distribute.get_replica_context&lt;/code&gt;&lt;/a&gt; to get an instance of &lt;code&gt;ReplicaContext&lt;/code&gt;. This should be inside your replicated step function, such as in a &lt;a href=&quot;strategy#run&quot;&gt;&lt;code&gt;tf.distribute.Strategy.run&lt;/code&gt;&lt;/a&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="bdb676d9df499211a1b26621113c16cf595d42c7" translate="yes" xml:space="preserve">
          <source>You can use the &lt;code&gt;reduce&lt;/code&gt; API to aggregate results across replicas and use this as a return value from one iteration over a &lt;a href=&quot;distributeddataset&quot;&gt;&lt;code&gt;tf.distribute.DistributedDataset&lt;/code&gt;&lt;/a&gt;. Or you can use &lt;a href=&quot;../keras/metrics&quot;&gt;&lt;code&gt;tf.keras.metrics&lt;/code&gt;&lt;/a&gt; (such as loss, accuracy, etc.) to accumulate metrics across steps in a given epoch.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cbd80087e0ae69c397a70f9c2b3b4a4570f57c0a" translate="yes" xml:space="preserve">
          <source>You can use the &lt;code&gt;reduce&lt;/code&gt; API to aggregate results across replicas and use this as a return value from one iteration over the distributed dataset. Or you can use &lt;a href=&quot;../keras/metrics&quot;&gt;&lt;code&gt;tf.keras.metrics&lt;/code&gt;&lt;/a&gt; (such as loss, accuracy, etc.) to accumulate metrics across steps in a given epoch.</source>
          <target state="translated">Вы можете использовать API-интерфейс &lt;code&gt;reduce&lt;/code&gt; для агрегирования результатов по репликам и использовать это как возвращаемое значение от одной итерации по распределенному набору данных. Или вы можете использовать &lt;a href=&quot;../keras/metrics&quot;&gt; &lt;code&gt;tf.keras.metrics&lt;/code&gt; &lt;/a&gt; (например, потерю, точность и т. Д.), Чтобы накапливать метрики по шагам в заданную эпоху.</target>
        </trans-unit>
        <trans-unit id="849e0f628a638e3510c8fe215b32ce36d057b4e1" translate="yes" xml:space="preserve">
          <source>You can use the Dense layer as you would expect:</source>
          <target state="translated">Вы можете использовать Плотный слой,как и следовало ожидать:</target>
        </trans-unit>
        <trans-unit id="ffad7cddd33e66d73417586d2382f64196240d65" translate="yes" xml:space="preserve">
          <source>You can use this function to read events written to an event file. It returns a Python iterator that yields &lt;code&gt;Event&lt;/code&gt; protocol buffers.</source>
          <target state="translated">Вы можете использовать эту функцию для чтения событий, записанных в файл событий. Он возвращает итератор Python, который создает буферы протокола &lt;code&gt;Event&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8746f4908e5bf18e74cecb0263457015fb63a862" translate="yes" xml:space="preserve">
          <source>You could also use vocabulary lookup before crossing:</source>
          <target state="translated">Вы также можете использовать поиск по словарю перед пересечением:</target>
        </trans-unit>
        <trans-unit id="de365a46ec65ae586c7c15b2194ec9eca625cd28" translate="yes" xml:space="preserve">
          <source>You could simply do:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2314a9b2a621f208986f86ed4dc02fe23da32fe1" translate="yes" xml:space="preserve">
          <source>You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively.</source>
          <target state="translated">Вы можете переопределить этот метод в подклассе.Стандартный метод run()вызывает вызываемый объект,переданный конструктору объекта в качестве целевого аргумента,если таковой имеется,с последовательными аргументами и аргументами по ключевым словам,взятыми из аргументов args и kwargs соответственно.</target>
        </trans-unit>
        <trans-unit id="a9f39d075c01a25e9820f6a67df1a4ab21c825d3" translate="yes" xml:space="preserve">
          <source>You may pass descendant of &lt;a href=&quot;strategy&quot;&gt;&lt;code&gt;tf.distribute.Strategy&lt;/code&gt;&lt;/a&gt; to &lt;a href=&quot;../estimator/runconfig&quot;&gt;&lt;code&gt;tf.estimator.RunConfig&lt;/code&gt;&lt;/a&gt; to specify how a &lt;a href=&quot;../estimator/estimator&quot;&gt;&lt;code&gt;tf.estimator.Estimator&lt;/code&gt;&lt;/a&gt; should distribute its computation. See &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support&quot;&gt;guide&lt;/a&gt;.</source>
          <target state="translated">Вы можете передать потомка &lt;a href=&quot;strategy&quot;&gt; &lt;code&gt;tf.distribute.Strategy&lt;/code&gt; &lt;/a&gt; в &lt;a href=&quot;../estimator/runconfig&quot;&gt; &lt;code&gt;tf.estimator.RunConfig&lt;/code&gt; ,&lt;/a&gt; чтобы указать, как &lt;a href=&quot;../estimator/estimator&quot;&gt; &lt;code&gt;tf.estimator.Estimator&lt;/code&gt; &lt;/a&gt; должен распределять свои вычисления. См. &lt;a href=&quot;https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support&quot;&gt;Руководство&lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="4caa6c70be3989fa593907ab37426f9ba5e5385e" translate="yes" xml:space="preserve">
          <source>You may provide either a constant &lt;code&gt;window_size&lt;/code&gt; or a window size determined by the key through &lt;code&gt;window_size_func&lt;/code&gt;.</source>
          <target state="translated">Вы можете &lt;code&gt;window_size&lt;/code&gt; либо постоянный размер окна, либо размер окна, определяемый ключом через &lt;code&gt;window_size_func&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="246729df98351fdf262d7a7f6c3229e8ff176c5b" translate="yes" xml:space="preserve">
          <source>You must have set the task_type and task_id object properties before calling this function, or pass in the &lt;code&gt;task_type&lt;/code&gt; and &lt;code&gt;task_id&lt;/code&gt; parameters when using this function. If you do both, the function parameters will override the object properties.</source>
          <target state="translated">Вы должны установить свойства объекта task_type и task_id перед вызовом этой функции или передать параметры &lt;code&gt;task_type&lt;/code&gt; и &lt;code&gt;task_id&lt;/code&gt; при использовании этой функции. Если вы сделаете и то, и другое, параметры функции переопределят свойства объекта.</target>
        </trans-unit>
        <trans-unit id="843e6067b5e147efe5ecbea6ee6b24b54cc1cca5" translate="yes" xml:space="preserve">
          <source>You number checkpoint filenames by passing a value to the optional &lt;code&gt;global_step&lt;/code&gt; argument to &lt;code&gt;save()&lt;/code&gt;:</source>
          <target state="translated">Вы &lt;code&gt;global_step&lt;/code&gt; имена файлов контрольных точек, передавая значение необязательному аргументу global_step функции &lt;code&gt;save()&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="47945af2dd44ab9b9f3ac220d707a317fa8bb12b" translate="yes" xml:space="preserve">
          <source>You should not use this class directly, but instead instantiate one of its subclasses such as &lt;a href=&quot;sgd&quot;&gt;&lt;code&gt;tf.keras.optimizers.SGD&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;adam&quot;&gt;&lt;code&gt;tf.keras.optimizers.Adam&lt;/code&gt;&lt;/a&gt;, etc.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8d943ec0774ebc46f132a6e012d0ef8ae2735a29" translate="yes" xml:space="preserve">
          <source>You should use this instead of the variable itself to initialize another variable with a value that depends on the value of this variable.</source>
          <target state="translated">Вы должны использовать это вместо самой переменной,чтобы инициализировать другую переменную значением,зависящим от значения этой переменной.</target>
        </trans-unit>
        <trans-unit id="5bcb3cc3036b6c1787fd4b43072cd172e65fd9dd" translate="yes" xml:space="preserve">
          <source>You typically pass looper threads to the supervisor &lt;code&gt;Join()&lt;/code&gt; method.</source>
          <target state="translated">Обычно потоки петлителя передаются методу супервизора &lt;code&gt;Join()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="866c1e20e145360ff1c2d3fac51cd421f0959538" translate="yes" xml:space="preserve">
          <source>You usually do not need to call this method as all ops that need the value of the variable call it automatically through a &lt;code&gt;convert_to_tensor()&lt;/code&gt; call.</source>
          <target state="translated">Обычно вам не нужно вызывать этот метод, так как все операции, которым требуется значение переменной, вызывают его автоматически через &lt;code&gt;convert_to_tensor()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="28b1f658f43504f27e0b8dad06c688c5569a5b43" translate="yes" xml:space="preserve">
          <source>You want os.path.exists() to always return true during testing.</source>
          <target state="translated">Вы хотите,чтобы os.path.exists()всегда возвращал true во время тестирования.</target>
        </trans-unit>
        <trans-unit id="558865a16feb9f751b8bcebf46a954afbeba0b24" translate="yes" xml:space="preserve">
          <source>YouTube</source>
          <target state="translated">YouTube</target>
        </trans-unit>
        <trans-unit id="743b60db1fe7f2ede7836bb4e7bd6e58b1ef9754" translate="yes" xml:space="preserve">
          <source>Zeiler, 2012</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cf5dacc30bc54f166bd31cec0b947c674cc3e7e" translate="yes" xml:space="preserve">
          <source>Zero or more tensors to group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7c152968210a9e92278d1a3f141b891e56657c41" translate="yes" xml:space="preserve">
          <source>Zero-pad the start and end of dimensions &lt;code&gt;[1, ..., M]&lt;/code&gt; of the input according to &lt;code&gt;paddings&lt;/code&gt; to produce &lt;code&gt;padded&lt;/code&gt; of shape &lt;code&gt;padded_shape&lt;/code&gt;.</source>
          <target state="translated">Обнулить начало и конец размеров &lt;code&gt;[1, ..., M]&lt;/code&gt; ввода в соответствии с &lt;code&gt;paddings&lt;/code&gt; чтобы получить &lt;code&gt;padded&lt;/code&gt; формы &lt;code&gt;padded_shape&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ec7ae133fd762cea93146fc3c7001608432a59c7" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 1D input (e.g. temporal sequence).</source>
          <target state="translated">Слой с нулевой накладкой для 1D входа (например,временная последовательность).</target>
        </trans-unit>
        <trans-unit id="9b78ee89fd119fbc58af59c013afefa4ada9d7ed" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 2D input (e.g. picture).</source>
          <target state="translated">Нулевой слой для 2D-входа (например,изображение).</target>
        </trans-unit>
        <trans-unit id="81f93ad811573d34a01e1dda72548f7bcac0984e" translate="yes" xml:space="preserve">
          <source>Zero-padding layer for 3D data (spatial or spatio-temporal).</source>
          <target state="translated">Нулевой слой для 3D данных (пространственных или пространственно-временных).</target>
        </trans-unit>
        <trans-unit id="4650f7edf1724b78bd849b1c2cb32632cbf26f09" translate="yes" xml:space="preserve">
          <source>Zero-pads and then rearranges (permutes) blocks of spatial data into batch. More specifically, this op outputs a copy of the input tensor where values from the &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; dimensions are moved to the &lt;code&gt;batch&lt;/code&gt; dimension. After the zero-padding, both &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; of the input must be divisible by the block size.</source>
          <target state="translated">Обнуляет, а затем переставляет (переставляет) блоки пространственных данных в пакет. В частности, эта операция выводит копию входного тензора, в которой значения размеров &lt;code&gt;height&lt;/code&gt; и &lt;code&gt;width&lt;/code&gt; перемещаются в размер &lt;code&gt;batch&lt;/code&gt; . После заполнения нулями и &lt;code&gt;height&lt;/code&gt; и &lt;code&gt;width&lt;/code&gt; ввода должны делиться на размер блока.</target>
        </trans-unit>
        <trans-unit id="dfee31bddce3aa2ae0eb9ab0a81354d098ee985f" translate="yes" xml:space="preserve">
          <source>ZerosLike</source>
          <target state="translated">ZerosLike</target>
        </trans-unit>
        <trans-unit id="d4dde75ca731d6afffc873406bc9b30fd639401e" translate="yes" xml:space="preserve">
          <source>Zeta</source>
          <target state="translated">Zeta</target>
        </trans-unit>
        <trans-unit id="37a40c343b1c25e2aa4647448f2479d812035f3e" translate="yes" xml:space="preserve">
          <source>ZipDataset</source>
          <target state="translated">ZipDataset</target>
        </trans-unit>
        <trans-unit id="cbfaea632aa3eb5b0ee3bf0fe5b02a033aca96d1" translate="yes" xml:space="preserve">
          <source>Zone of the GCE instance group.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b808978f0a72336077098f027b8f727415da270" translate="yes" xml:space="preserve">
          <source>Zone where the TPUs are located. If omitted or empty, we will assume that the zone of the TPU is the same as the zone of the GCE VM, which we will try to discover from the GCE metadata service.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="690066f3139e111a254b9b22702420163ce9e6c3" translate="yes" xml:space="preserve">
          <source>[-128, 127] for signed, num_bits = 8, or</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f0f7b84b517d1011bde2787a1af440ee2991478" translate="yes" xml:space="preserve">
          <source>[0, 255] for unsigned, num_bits = 8.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd22950e542e583caceeef78dc9ae8586fc6a2c9" translate="yes" xml:space="preserve">
          <source>[1] Nicholas J. Higham (2002). Accuracy and Stability of Numerical Algorithms: Second Edition. SIAM. p. 175. ISBN 978-0-89871-802-7.</source>
          <target state="translated">[1] Николас Дж. Хайэм (2002). Точность и устойчивость численных алгоритмов: второе издание. СИАМ. п. 175. ISBN 978-0-89871-802-7.</target>
        </trans-unit>
        <trans-unit id="b99fc78b4d7545fcd138b54f0e14096e6f4551ca" translate="yes" xml:space="preserve">
          <source>[1] http://en.wikipedia.org/wiki/Gamma_correction</source>
          <target state="translated">[1] http://en.wikipedia.org/wiki/Gamma_correction</target>
        </trans-unit>
        <trans-unit id="8b402dbbbcbda420a8c8a62323dde3dbd63d7a5e" translate="yes" xml:space="preserve">
          <source>[1]: G. Strang. 'Linear Algebra and Its Applications, 2nd Ed.' Academic Press, Inc., 1980, pp. 139-142.</source>
          <target state="translated">[1]: Г. Стрэнг. &quot;Линейная алгебра и ее приложения, 2-е изд.&quot; Academic Press, Inc., 1980, стр. 139-142.</target>
        </trans-unit>
        <trans-unit id="3431dfde47f5f77802dc8c1e589fe801ed9dd223" translate="yes" xml:space="preserve">
          <source>[Flag], a new list of Flag instances. Caller may update this list as</source>
          <target state="translated">[Flag], новый список экземпляров Flag. Вызывающий может обновить этот список как</target>
        </trans-unit>
        <trans-unit id="8a492c08a6fb4ab5ad781dcaefb3c630980c2a92" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to &lt;a href=&quot;../../../estimator/vocabinfo&quot;&gt;&lt;code&gt;tf.estimator.VocabInfo&lt;/code&gt;&lt;/a&gt;. The variable names should be &quot;full&quot; variables, not the names of the partitions. If not explicitly provided, the variable is assumed to have no (changes to) vocabulary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="040ab6c4e7ceb839df30c29d661e2122a9ea0ad3" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to &lt;a href=&quot;vocabinfo&quot;&gt;&lt;code&gt;tf.estimator.VocabInfo&lt;/code&gt;&lt;/a&gt;. The variable names should be &quot;full&quot; variables, not the names of the partitions. If not explicitly provided, the variable is assumed to have no (changes to) vocabulary.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7ccfc72b7041b89963d68b36a1571281cdd9debc" translate="yes" xml:space="preserve">
          <source>[Optional] Dict of variable names (strings) to name of the previously-trained variable in &lt;code&gt;ckpt_to_initialize_from&lt;/code&gt;. If not explicitly provided, the name of the variable is assumed to be same between previous checkpoint and current model. Note that this has no effect on the set of variables that is warm-started, and only controls name mapping (use &lt;code&gt;vars_to_warm_start&lt;/code&gt; for controlling what variables to warm-start).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88dac723b45d7ec9ed5d2521d06d37e6754801f3" translate="yes" xml:space="preserve">
          <source>[Optional] One of the following:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56fcc4459de1190d856f1a05d4fa018ace19dfbd" translate="yes" xml:space="preserve">
          <source>[Required] A string specifying the directory with checkpoint file(s) or path to checkpoint from which to warm-start the model parameters.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8ee2e7d87ae9f9bdabd7b4bb725a904d7d206cb7" translate="yes" xml:space="preserve">
          <source>[[w(1, 0), w(1, 2), 0.5], [w(0, 0), w(0, 2), -0.5], [0.25, -0.25, 42]]</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7fbe9b43ff0aeb17fee44c25d05877c8cdce9b59" translate="yes" xml:space="preserve">
          <source>[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</source>
          <target state="translated">[пакет * prod (block_shape)] + [padded_shape [1] / block_shape [0], ..., padded_shape [M] / block_shape [M-1]] + оставшаяся форма</target>
        </trans-unit>
        <trans-unit id="cbf73d5213642961c32b5b788775c8bd0559cdc7" translate="yes" xml:space="preserve">
          <source>[batch, height - 2 * (filter_width - 1), width - 2 * (filter_height - 1), out_channels].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4f44d9fad75faea26dd9cc4bc783f18b2b9a3245" translate="yes" xml:space="preserve">
          <source>[batch, height, width, out_channels].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="69883aca3ab9b1512329fe1f31a31a2297068297" translate="yes" xml:space="preserve">
          <source>[batch&lt;em&gt;block_size&lt;/em&gt;block_size, height_pad/block_size, width_pad/block_size, depth]</source>
          <target state="translated">[batch &lt;em&gt;block_size&lt;/em&gt; block_size, height_pad / block_size, width_pad / block_size, depth]</target>
        </trans-unit>
        <trans-unit id="a99f9eae6edb2aeb1e4c6a1434cfbcae41146183" translate="yes" xml:space="preserve">
          <source>[batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape</source>
          <target state="translated">[пакет] + [padded_shape [1] / block_shape [0], block_shape [0], ..., padded_shape [M] / block_shape [M-1], block_shape [M-1]] + оставшаяся форма</target>
        </trans-unit>
        <trans-unit id="a018842c23398495c71954bf778c4b46f8056996" translate="yes" xml:space="preserve">
          <source>[batch_size, num_channels] + output_spatial_shape</source>
          <target state="translated">[batch_size, num_channels] + output_spatial_shape</target>
        </trans-unit>
        <trans-unit id="51a4c96f9f2ac53566fd73823e05a471562bcdfc" translate="yes" xml:space="preserve">
          <source>[filename1, filename2, ... filenameN] as strings</source>
          <target state="translated">[имя_файла1, имя_файла2, ... имя_файлаN] в виде строк</target>
        </trans-unit>
        <trans-unit id="d8a02b4024d1f91043f88e51a21c86cf6a2b1f8b" translate="yes" xml:space="preserve">
          <source>[input_min, input_max] are scalar floats that specify the range for the float interpretation of the 'input' data. For example, if input_min is -1.0f and input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0 value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143b12af78e15f28dfa0f3a68b2560666f6d5995" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the 'input' data. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents. The 'round_mode' attribute controls which rounding tie-breaking algorithm is used when rounding float values to their quantized equivalents.</source>
          <target state="translated">[min_range, max_range] - это скалярные числа с плавающей запятой, которые определяют диапазон для &amp;laquo;входных&amp;raquo; данных. Атрибут 'mode' контролирует, какие именно вычисления используются для преобразования значений с плавающей запятой в их квантованные эквиваленты. Атрибут round_mode управляет тем, какой алгоритм округления и разрешения конфликтов используется при округлении значений с плавающей запятой до их квантованных эквивалентов.</target>
        </trans-unit>
        <trans-unit id="1fa2da75f60f4f3a22685794db19c7508c0c1baa" translate="yes" xml:space="preserve">
          <source>[min_range, max_range] are scalar floats that specify the range for the output. The 'mode' attribute controls exactly which calculations are used to convert the float values to their quantized equivalents.</source>
          <target state="translated">[min_range, max_range] - это скалярные числа с плавающей запятой, которые определяют диапазон для вывода. Атрибут 'mode' контролирует, какие именно вычисления используются для преобразования значений с плавающей запятой в их квантованные эквиваленты.</target>
        </trans-unit>
        <trans-unit id="8bebaab027f4bff5b0c289cd914950701e571abd" translate="yes" xml:space="preserve">
          <source>[num_batches, input_spatial_shape[0], ..., input_spatial_shape[N-1], num_input_channels],</source>
          <target state="translated">[num_batches, input_spatial_shape [0], ..., input_spatial_shape [N-1], num_input_channels],</target>
        </trans-unit>
        <trans-unit id="8f8157d4fe8eda67ef4b3a3b791fa8bb98678ccc" translate="yes" xml:space="preserve">
          <source>[spatial_filter_shape[0], ..., spatial_filter_shape[N-1], num_input_channels, num_output_channels],</source>
          <target state="translated">[пространственный_фильтр [0], ..., пространственный_фильтр_shape [N-1], num_input_channels, num_output_channels],</target>
        </trans-unit>
        <trans-unit id="ccfaace27f3147695ce3d29304da376491a69186" translate="yes" xml:space="preserve">
          <source>[str], a list of strings, usually sys.argv[1:], which may contain one or more flagfile directives of the form --flagfile=&quot;./filename&quot;. Note that the name of the program (sys.argv[0]) should be omitted.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a05d1e5d9cec162aa920d1c81e7d248fa2814404" translate="yes" xml:space="preserve">
          <source>[str], a list of the flag names to be checked.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c26fe712edb3b507e5043f8b806fc26990923cd" translate="yes" xml:space="preserve">
          <source>[str], a non-empty list of string values in the enum.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cd81efe3c17628b43be50a6bfd943ed33227190" translate="yes" xml:space="preserve">
          <source>[str], a non-empty list of strings with the possible values for the flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7dbf8f891a3cf1f1fcd98f054581759232646314" translate="yes" xml:space="preserve">
          <source>[str], names of the flags.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0305e4e8314312d7aab76df54a2e11f81f096064" translate="yes" xml:space="preserve">
          <source>[str], the parsed flag value.</source>
          <target state="translated">[str], значение анализируемого флага.</target>
        </trans-unit>
        <trans-unit id="06a4ee1356819500657e1855f1838410080d3362" translate="yes" xml:space="preserve">
          <source>\( c_{jklm} = \sum_i a_{ijk} b_{lmi} \).</source>
          <target state="translated">\ (c_ {jklm} = \ sum_i a_ {ijk} b_ {lmi} \).</target>
        </trans-unit>
        <trans-unit id="7c88dd9089928bec50c06f1f5a9b847c1bc1189e" translate="yes" xml:space="preserve">
          <source>\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\)</source>
          <target state="translated">\ (B (x; a, b) = \ int_0 ^ xt ^ {a-1} (1 - t) ^ {b-1} dt \)</target>
        </trans-unit>
        <trans-unit id="5dd8170c96a11e0fac54775aa5e03b07d872abb3" translate="yes" xml:space="preserve">
          <source>\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\)</source>
          <target state="translated">\ (Гамма (a, x) = int_ {x} ^ {\ infty} t ^ {a-1} exp (-t) dt \)</target>
        </trans-unit>
        <trans-unit id="a4f68edbf74b4238178695327b403faa736fbba4" translate="yes" xml:space="preserve">
          <source>\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\)</source>
          <target state="translated">\ (I_x (a, b) = \ frac {B (x; a, b)} {B (a, b)} \)</target>
        </trans-unit>
        <trans-unit id="9b977890dfd27609aefecb3c22cf9edc2b5b6c7c" translate="yes" xml:space="preserve">
          <source>\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\)</source>
          <target state="translated">\ (P (a, x) = гамма (a, x) / Gamma (a) = 1 - Q (a, x) \)</target>
        </trans-unit>
        <trans-unit id="3c43fa9908d595b3f6dccdce0d125247c097b9f4" translate="yes" xml:space="preserve">
          <source>\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\)</source>
          <target state="translated">\ (Q (a, x) = Gamma (a, x) / Gamma (a) = 1 - P (a, x) \)</target>
        </trans-unit>
        <trans-unit id="37291deb0e6026c081430c96a800990fc3edcaa7" translate="yes" xml:space="preserve">
          <source>\(\beta\)</source>
          <target state="translated">\(\beta\)</target>
        </trans-unit>
        <trans-unit id="ff41b6103716ee7c998d6e81784bdf83320ba7f2" translate="yes" xml:space="preserve">
          <source>\(\ell_1\,\,penalty =\ell_1\sum_{i=0}^n|x_i|\)</source>
          <target state="translated">\ (\ ell_1 \, \, штраф = \ ell_1 \ sum_ {i = 0} ^ n | x_i | \)</target>
        </trans-unit>
        <trans-unit id="9335deefcc4fff06a8f47ea88b57b74222c6ee2a" translate="yes" xml:space="preserve">
          <source>\(\ell_2\,\,penalty =\ell_2\sum_{i=0}^nx_i^2\)</source>
          <target state="translated">\ (\ ell_2 \, \, штраф = \ ell_2 \ sum_ {i = 0} ^ nx_i ^ 2 \)</target>
        </trans-unit>
        <trans-unit id="c62e7aed7aab85e0bc7679b7b1654447c10071b7" translate="yes" xml:space="preserve">
          <source>\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</source>
          <target state="translated">\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</target>
        </trans-unit>
        <trans-unit id="4a0660a89253bc5ba688c6d45badc9f8ddf6380e" translate="yes" xml:space="preserve">
          <source>\(\psi^{(a)}(x) = \frac{d^a}{dx^a} \psi(x)\)</source>
          <target state="translated">\ (\ psi ^ {(a)} (x) = \ frac {d ^ a} {dx ^ a} \ psi (x) \)</target>
        </trans-unit>
        <trans-unit id="57cfcb3ce0118881ab066bb534ef79062b9ae613" translate="yes" xml:space="preserve">
          <source>\(\sigma_{t,i} = (\sqrt{n_{t,i}} - \sqrt{n_{t-1,i}}) / \alpha\)</source>
          <target state="translated">\ (\ sigma_ {t, i} = (\ sqrt {n_ {t, i}} - \ sqrt {n_ {t-1, i}}) / \ alpha \)</target>
        </trans-unit>
        <trans-unit id="c402d7a692489cd97ce624829b28b4af2556f395" translate="yes" xml:space="preserve">
          <source>\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\)</source>
          <target state="translated">\ (\ zeta (x, q) = \ sum_ {n = 0} ^ {\ infty} (q + n) ^ {- x} \)</target>
        </trans-unit>
        <trans-unit id="ea1119f555233a8d758e9686e809fbc51e48a520" translate="yes" xml:space="preserve">
          <source>\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\)</source>
          <target state="translated">\ (гамма (a, x) = \\ int_ {0} ^ {x} t ^ {a-1} exp (-t) dt \)</target>
        </trans-unit>
        <trans-unit id="553f6c65213b82afcc0c043d8233d0d411b11d70" translate="yes" xml:space="preserve">
          <source>\(i\)</source>
          <target state="translated">\(i\)</target>
        </trans-unit>
        <trans-unit id="cad97ed2e69a3cdad8082dd06f3ff6c16e2928db" translate="yes" xml:space="preserve">
          <source>\(lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)\)</source>
          <target state="translated">\ (lbeta (x) [i1, ..., in] = Log (| Beta (x [i1, ..., in,:]) |) \)</target>
        </trans-unit>
        <trans-unit id="e122b351d32a233056a0dc92eef090ec82833970" translate="yes" xml:space="preserve">
          <source>\(log(exp(A)) = A\)</source>
          <target state="translated">\ (журнал (ехр (A)) = A \)</target>
        </trans-unit>
        <trans-unit id="a6e6475c1d10a33b250fca653ee8cfd040c5e589" translate="yes" xml:space="preserve">
          <source>\(lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)\)</source>
          <target state="translated">\ (lr_t: = \ text {обучение \ _rate} * \ sqrt {1 - beta_2 ^ t} / (1 - beta_1 ^ t) \)</target>
        </trans-unit>
        <trans-unit id="9f6d1fd07abb052ec6fac4e52945c2c9c481cefa" translate="yes" xml:space="preserve">
          <source>\(m_0 := 0 \text{(Initialize initial 1st moment vector)}\)</source>
          <target state="translated">\ (m_0: = 0 \ text {(Инициализировать начальный вектор 1-го момента)} \)</target>
        </trans-unit>
        <trans-unit id="e3dada6e7ecd7d65376b81a16036f8e723616d85" translate="yes" xml:space="preserve">
          <source>\(m_t := beta_1 * m_{t-1} + (1 - beta_1) * g\)</source>
          <target state="translated">\ (m_t: = beta_1 * m_ {t-1} + (1 - beta_1) * g \)</target>
        </trans-unit>
        <trans-unit id="36cf9049b0822fc2658dd5393471d4a9bc14521f" translate="yes" xml:space="preserve">
          <source>\(n_{t,i} = n_{t-1,i} + g_{t,i}^{2}\)</source>
          <target state="translated">\ (п_ {т, я} = п_ {т-1, я} + g_ {т, я} ^ {2} \)</target>
        </trans-unit>
        <trans-unit id="e58cad3c2a2e7d2a68a0cec41e11be1d3da882e6" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/N_i \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="translated">\ (output_i = 1 / N_i \ sum_ {j ...} data [j ...] \), где сумма берется по кортежам &lt;code&gt;j...&lt;/code&gt; таким образом, что &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; с \ N_i \ число вхождений id \ i \.</target>
        </trans-unit>
        <trans-unit id="eff44ad7c5ba3196137c591dc7d87b8984229557" translate="yes" xml:space="preserve">
          <source>\(output_i = 1/sqrt(N_i) \sum_{j...} data[j...]\) where the sum is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; with \N_i\ being the number of occurrences of id \i\.</source>
          <target state="translated">\ (output_i = 1 / sqrt (N_i) \ sum_ {j ...} data [j ...] \) где сумма по кортежам &lt;code&gt;j...&lt;/code&gt; таким образом, что &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; с \ N_i \ - количество вхождений id \ i \.</target>
        </trans-unit>
        <trans-unit id="fd27c9aa6e45dbe63e023f46fe5fdca3d93fbc19" translate="yes" xml:space="preserve">
          <source>\(output_i = \max_{j...} data[j...]\) where max is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ max_ {j ...} data [j ...] \) где max превышает кортежи &lt;code&gt;j...&lt;/code&gt; такие, что &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="529b95e92276e5f1ac9b067c9474b5798a2da7c5" translate="yes" xml:space="preserve">
          <source>\(output_i = \min_{j...} data_[j...]\) where min is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ min_ {j ...} data_ [j ...] \), где min превышает кортежи &lt;code&gt;j...&lt;/code&gt; такие, что &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1bf71665be24061201465110b49af7b8c6429f1f" translate="yes" xml:space="preserve">
          <source>\(output_i = \prod_{j...} data[j...]\) where the product is over tuples &lt;code&gt;j...&lt;/code&gt; such that &lt;code&gt;segment_ids[j...] == i&lt;/code&gt;.</source>
          <target state="translated">\ (output_i = \ prod_ {j ...} data [j ...] \), где продукт превышает кортежи &lt;code&gt;j...&lt;/code&gt; такие, что &lt;code&gt;segment_ids[j...] == i&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="bcf88899f36fe32859ba4eebac881718864b3a68" translate="yes" xml:space="preserve">
          <source>\(predictions_i\) be the predictions for all classes for example &lt;code&gt;i&lt;/code&gt;, \(targets_i\) be the target class for example &lt;code&gt;i&lt;/code&gt;, \(out_i\) be the output for example &lt;code&gt;i&lt;/code&gt;,</source>
          <target state="translated">\ (predictions_i \) будет прогнозами для всех классов, например &lt;code&gt;i&lt;/code&gt; , \ (target_i \) будет целевым классом, например &lt;code&gt;i&lt;/code&gt; , \ (out_i \) будет выходом, например, &lt;code&gt;i&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="eb6c03745499b6a9eb903031a775345057a8d436" translate="yes" xml:space="preserve">
          <source>\(t := 0 \text{(Initialize timestep)}\)</source>
          <target state="translated">\ (t: = 0 \ text {(Инициализировать временной шаг)} \)</target>
        </trans-unit>
        <trans-unit id="467d92f4cfe1c3cd183f798d119891376eebfa6b" translate="yes" xml:space="preserve">
          <source>\(t := t + 1\)</source>
          <target state="translated">\ (t: = t + 1 \)</target>
        </trans-unit>
        <trans-unit id="e5334cf7b7c8be8a554d2684840ca9468e2d3597" translate="yes" xml:space="preserve">
          <source>\(t = t + 1\)</source>
          <target state="translated">\ (т = т + 1 \)</target>
        </trans-unit>
        <trans-unit id="1a4815b823d6a6bd996f5174a896a936100c82c4" translate="yes" xml:space="preserve">
          <source>\(v_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="translated">\ (v_0: = 0 \ text {(Инициализировать начальный вектор 2-го момента)} \)</target>
        </trans-unit>
        <trans-unit id="fe2806cab7064b169c451375ea09662f2387835c" translate="yes" xml:space="preserve">
          <source>\(v_hat_0 := 0 \text{(Initialize initial 2nd moment vector)}\)</source>
          <target state="translated">\ (v_hat_0: = 0 \ text {(Инициализировать начальный вектор 2-го момента)} \)</target>
        </trans-unit>
        <trans-unit id="95246ed68fccf6f4caddd1734e3779b6b21f4b80" translate="yes" xml:space="preserve">
          <source>\(v_hat_t := max(v_hat_{t-1}, v_t)\)</source>
          <target state="translated">\ (v_hat_t: = max (v_hat_ {t-1}, v_t) \)</target>
        </trans-unit>
        <trans-unit id="4f4d3c48642e5d2288a5d23ba51224f14bb68e11" translate="yes" xml:space="preserve">
          <source>\(v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g\)</source>
          <target state="translated">\ (v_t: = beta_2 * v_ {t-1} + (1 - beta_2) * g * g \)</target>
        </trans-unit>
        <trans-unit id="ceb29146344acce0db4068ea0c682c74bad08207" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_hat_t} + \epsilon)\)</source>
          <target state="translated">\ (переменная: = переменная - lr_t * m_t / (\ sqrt {v_hat_t} + \ epsilon) \)</target>
        </trans-unit>
        <trans-unit id="2a5065284239af79ffad5fd4634aca805131acd5" translate="yes" xml:space="preserve">
          <source>\(variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)\)</source>
          <target state="translated">\ (переменная: = переменная - lr_t * m_t / (\ sqrt {v_t} + \ epsilon) \)</target>
        </trans-unit>
        <trans-unit id="9c42d66b235e7446c048f4defb1b795d3ee38b09" translate="yes" xml:space="preserve">
          <source>\(w_{i}\)</source>
          <target state="translated">\(w_{i}\)</target>
        </trans-unit>
        <trans-unit id="3b25b3312f2ef7cacd25276352e73b5ab48846cf" translate="yes" xml:space="preserve">
          <source>\(w_{t,i} = - ((\beta+\sqrt{n+{t}}) / \alpha + \lambda_{2})^{-1} * (z_{i} - sgn(z_{i}) * \lambda_{1}) if \abs{z_{i}} &amp;gt; \lambda_{i} else 0\)</source>
          <target state="translated">\ (w_ {t, i} = - ((\ beta + \ sqrt {n + {t}}) / \ alpha + \ lambda_ {2}) ^ {- 1} * (z_ {i} - sgn (z_ {i }) * \ lambda_ {1}) if \ abs {z_ {i}}&amp;gt; \ lambda_ {i} else 0 \)</target>
        </trans-unit>
        <trans-unit id="ba90f7c8012e09317d8c902b37294fee9c1c8163" translate="yes" xml:space="preserve">
          <source>\(y = \beta + \sum_{i=1}^{N} w_{i} * x_{i}\)</source>
          <target state="translated">\ (y = \ beta + \ sum_ {i = 1} ^ {N} w_ {i} * x_ {i} \)</target>
        </trans-unit>
        <trans-unit id="2dec4db0fcb32e5c79e8ecb6c6414661d0289001" translate="yes" xml:space="preserve">
          <source>\(z_{t,i} = z_{t-1,i} + g_{t,i} - \sigma_{t,i} * w_{t,i}\)</source>
          <target state="translated">\ (z_ {t, i} = z_ {t-1, i} + g_ {t, i} - \ sigma_ {t, i} * w_ {t, i} \)</target>
        </trans-unit>
        <trans-unit id="31d5b9df6c8b26532e6975198879e8066c930cd4" translate="yes" xml:space="preserve">
          <source>], 'bias': [</source>
          <target state="translated">], 'bias': [</target>
        </trans-unit>
        <trans-unit id="ebb0f535eb870cf683880d2973390bc12e206de5" translate="yes" xml:space="preserve">
          <source>], _NumericColumn( key='numeric_feature2', shape=(2,)): [</source>
          <target state="translated">], _NumericColumn (key = 'numeric_feature2', shape = (2,)): [</target>
        </trans-unit>
        <trans-unit id="a961fbc1cc31eed81a5be94725a3b10dfcfb3f0e" translate="yes" xml:space="preserve">
          <source>]} If a column creates no variables, its value will be an empty list. Note that cols_to_vars will also contain a string key 'bias' that maps to a list of Variables.</source>
          <target state="translated">]} Если столбец не создает переменных, его значением будет пустой список. Обратите внимание, что cols_to_vars также будет содержать строковый ключ bias, который соответствует списку переменных.</target>
        </trans-unit>
        <trans-unit id="82253180c6e96af25f2a21fff7bcfa0218b5a1e9" translate="yes" xml:space="preserve">
          <source>_normal_initializer</source>
          <target state="translated">_normal_initializer</target>
        </trans-unit>
        <trans-unit id="87ea43bbd5b9352fbaeea30b2cc056ed63741cfd" translate="yes" xml:space="preserve">
          <source>_uniform_initializer</source>
          <target state="translated">_uniform_initializer</target>
        </trans-unit>
        <trans-unit id="d5a25e2ec3739e3d8ae17e7c5a3f6cbea4f5abd6" translate="yes" xml:space="preserve">
          <source>a (major,minor) pair that indicates the minimum CUDA compute capability required, or None if no requirement.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="dd7aed71c0916f4e514b1b87472e1aaec7a3d81c" translate="yes" xml:space="preserve">
          <source>a 1-D numpy array whose size depends on the algorithm.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="09cc8a0e53d6d87d6a7d95e6a2118c05a24fa639" translate="yes" xml:space="preserve">
          <source>a 1-D tensor whose size depends on the algorithm.</source>
          <target state="translated">1-D тензор,размер которого зависит от алгоритма.</target>
        </trans-unit>
        <trans-unit id="93178b091b08f4efbffb2adcc54e5c4fc936daed" translate="yes" xml:space="preserve">
          <source>a 1D tensor. Dimensions: out_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60f13d546f38be6d76d9d2976a24c54009d2eb5a" translate="yes" xml:space="preserve">
          <source>a 2D tensor. Dimensions typically: batch, in_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="abdaa4ef567c5801d72513ba2ff400234446d877" translate="yes" xml:space="preserve">
          <source>a 2D tensor. Dimensions typically: in_units, out_units</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0832663c1e8c4bc4a737a50ba43d01171dfb1b52" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;../dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; whose elements are to be written to a file</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="63da673dc60479d55d81b4dac49f99e2addfa764" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;../model&quot;&gt;&lt;code&gt;tf.keras.Model&lt;/code&gt;&lt;/a&gt;, its output must match the output of the linear model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="23a2b4256e67b7643d6e462770d9d1ceff2c6a95" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;layer&quot;&gt;&lt;code&gt;tf.keras.layers.Layer&lt;/code&gt;&lt;/a&gt; instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b7b7f1e42a3452df01c243bc4ff9f9c0a1e957a" translate="yes" xml:space="preserve">
          <source>a &lt;a href=&quot;options&quot;&gt;&lt;code&gt;tf.data.Options&lt;/code&gt;&lt;/a&gt; to merge with</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc2f84a127d1432687ba858bc82ffee5c3694cbb" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;DeviceSpec&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="532617217fec8780a205ebf785c1bcfcd14f51e0" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;DeviceSpec&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a0723a300b3e5a3037c5eec9b6314d294f925e8" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SavedModel&lt;/code&gt; proto containing the Tensorflow backend graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model has not been compiled, then only the graph computing predictions will be exported.</source>
          <target state="translated">&lt;code&gt;SavedModel&lt;/code&gt; прото , содержащий график бэкэнд Tensorflow. Отдельные графики сохраняются для прогнозирования (обслуживания), обучения и оценки. Если модель не была скомпилирована, будут экспортированы только прогнозы вычислений графа.</target>
        </trans-unit>
        <trans-unit id="2fe7e88159041491b684ee0b2eef3649a559ee4b" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SaverDef&lt;/code&gt; protocol buffer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe9334150fba500e634d08a0fd10f09c0e5c3458" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;SparseTensor&lt;/code&gt; operand whose dtype is real, and indices lexicographically ordered.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89fda5dd98ad8f5391967d857c89af91abadfb1e" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;sample_shape(x) + self.batch_shape&lt;/code&gt; with values of type &lt;code&gt;self.dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="814d7841b7f08b3882cd124daea00a4d94c3529b" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;tf.concat([shape, tf.shape(alpha + beta)], axis=0)&lt;/code&gt; with values of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28f44ad32a3986701c510c4b3dcbe94a32df1ffe" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; of shape &lt;code&gt;tf.concat([shape, tf.shape(lam)], axis=0)&lt;/code&gt; with values of type &lt;code&gt;dtype&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7a5aa938284d01a870254921f425995a35654dd9" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt; with prepended dimensions &lt;code&gt;sample_shape&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4c4f77ba88c28c41bf33a3d3025e3b1e6cda5e8" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;Tensor&lt;/code&gt;, or a dict of string to &lt;code&gt;Tensor&lt;/code&gt;, specifying input nodes that will be fed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfb18628ed3de27b4a1a234981f499e9dd433d38" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;str&lt;/code&gt; describing the contraction, in the same format as &lt;code&gt;numpy.einsum&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a4f5c14667db94a7f69f7b3c58a35864d1d15ebd" translate="yes" xml:space="preserve">
          <source>a &lt;code&gt;tf.ConfigProto&lt;/code&gt; object.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fd5e709c8e1b6963fd07bdd51f6a8e7d5b1a115e" translate="yes" xml:space="preserve">
          <source>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) a # 2-D tensor</source>
          <target state="translated">a=tf.constant([1,2,3,4,5,6],shape=[2,3])a#2-D тензор</target>
        </trans-unit>
        <trans-unit id="d3508e6212f2bb1a5bb507a6ad9f56dc1d60653b" translate="yes" xml:space="preserve">
          <source>a = tf.constant([[1, 2], [3, 4]]) tf.reduce_min(a)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b60dce959a5722be8d9ace37f6ea58387cc7a978" translate="yes" xml:space="preserve">
          <source>a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3]) a # 3-D tensor</source>
          <target state="translated">a=tf.constant(np.arange(1,13,dtype=np.int32),shape=[2,2,3])a#3-D тензор</target>
        </trans-unit>
        <trans-unit id="d5554b43b2c1e709f84d89ff59708b34ac43de5d" translate="yes" xml:space="preserve">
          <source>a ClusterResolver</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12fec67c34e62bc4fe609123ff4e68b7b09d5716" translate="yes" xml:space="preserve">
          <source>a ConfigProto used to set session parameters, or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cac282a286b145e90bbae0cb74e2d64c49b7f387" translate="yes" xml:space="preserve">
          <source>a GraphNodeProto that records the results.</source>
          <target state="translated">GraphNodeProto,который записывает результаты.</target>
        </trans-unit>
        <trans-unit id="02fdc18cf71e7d138c4670ddd2b89252810f0b7c" translate="yes" xml:space="preserve">
          <source>a Mirrored object.</source>
          <target state="translated">Зеркальный объект.</target>
        </trans-unit>
        <trans-unit id="6a65d1b63a2aa1329f486140387a944abe2d35ab" translate="yes" xml:space="preserve">
          <source>a MultiGraphNodeProto that records the results.</source>
          <target state="translated">MultiGraphNodeProto,который записывает результаты.</target>
        </trans-unit>
        <trans-unit id="3f756fe3a0f877dbf55d583613842de50b650bca" translate="yes" xml:space="preserve">
          <source>a Tensor or list of Tensors.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="44a87c17dbe409e98a432e4764a0ca67503ad529" translate="yes" xml:space="preserve">
          <source>a TrtConversionParams instance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6adb18be2c65016a8dd91dcca0917351f5c5ea50" translate="yes" xml:space="preserve">
          <source>a boolean indicating whether the input boxes and scores are sorted in descending order by the score.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae8444bacbe1b98ca2a1d9caa1bde03aa7aa8447" translate="yes" xml:space="preserve">
          <source>a callable taking two parameters, a variable and a list of slot names to create for it. This function should return a dict with the slot names as keys and the created variables as values. When set to None (the default), uses the built-in variable creation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7b5462387fade93b713b97cb5dd916b0db334352" translate="yes" xml:space="preserve">
          <source>a callable that takes a single &lt;code&gt;DType&lt;/code&gt; argument and returns a Python &lt;code&gt;boolean&lt;/code&gt; indicating whether the dtype is to be included in the data dumping. Examples:</source>
          <target state="translated">вызываемый объект, который принимает один аргумент &lt;code&gt;DType&lt;/code&gt; и возвращает &lt;code&gt;boolean&lt;/code&gt; Python, указывающее, должен ли dtype быть включен в дамп данных. Примеры:</target>
        </trans-unit>
        <trans-unit id="dadf9b05790e565e376db89427e055d3cb91682a" translate="yes" xml:space="preserve">
          <source>a checkpoint containing the model weights.</source>
          <target state="translated">контрольно-пропускной пункт с модельными весами.</target>
        </trans-unit>
        <trans-unit id="7cbfb1c56d61348ae16c7cd2face5f9db9cab352" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;Tensor&lt;/code&gt; or &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b740bb539e2724c4812a91601e69e1c90a91fbd" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="79c49bc5c338207d05434ecb9d28173a38bb6f68" translate="yes" xml:space="preserve">
          <source>a dict of string to &lt;code&gt;VarLenFeature&lt;/code&gt;/&lt;code&gt;FixedLenFeature&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="813fdedf351b9814fc880a7e57d9c99855ec1cd5" translate="yes" xml:space="preserve">
          <source>a dict of string to additional groups of receiver tensors, each of which may be a &lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;SparseTensor&lt;/code&gt;, or dict of string to &lt;code&gt;Tensor&lt;/code&gt; or&lt;code&gt;SparseTensor&lt;/code&gt;. These named receiver tensor alternatives generate additional serving signatures, which may be used to feed inputs at different points within the input receiver subgraph. A typical usage is to allow feeding raw feature &lt;code&gt;Tensor&lt;/code&gt;s &lt;em&gt;downstream&lt;/em&gt; of the tf.parse_example() op. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7bd9e9cef7c898d18e42b1f2f9c5375410bd03be" translate="yes" xml:space="preserve">
          <source>a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. &lt;a href=&quot;https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional&quot;&gt;Here are details&lt;/a&gt; about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8c591343285301a08eb1eb57b9c63187b713f4d7" translate="yes" xml:space="preserve">
          <source>a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. See the &lt;a href=&quot;https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional&quot;&gt;details&lt;/a&gt; about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8527fc8500abdc7bc32e70d3d9218debeaf5253f" translate="yes" xml:space="preserve">
          <source>a feature with &lt;code&gt;key=column.name&lt;/code&gt; whose &lt;code&gt;value&lt;/code&gt; is a &lt;code&gt;SparseTensor&lt;/code&gt;.</source>
          <target state="translated">функция с &lt;code&gt;key=column.name&lt;/code&gt; , &lt;code&gt;value&lt;/code&gt; которого является &lt;code&gt;SparseTensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="ded58018cf323ca8b228f31fb7eeecbe3e4bab57" translate="yes" xml:space="preserve">
          <source>a float &lt;code&gt;Tensor&lt;/code&gt; giving the predicted values. Required.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca1e3709c53c6fef2ab454a19e61ce4ffd76640f" translate="yes" xml:space="preserve">
          <source>a float &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8fa1eefb32219e9ccd295492ff2de693d41b5058" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of 2pi, or a tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. A positive values means rotating counter clock-wise, while a negative value means clock-wise. When represented as a single float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;factor=(-0.2, 0.3)&lt;/code&gt; results in an output rotation by a random amount in the range &lt;code&gt;[-20% * 2pi, 30% * 2pi]&lt;/code&gt;. &lt;code&gt;factor=0.2&lt;/code&gt; results in an output rotating by a random amount in the range &lt;code&gt;[-20% * 2pi, 20% * 2pi]&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7f704c1b4eddb94e2f57ea74f007a87f33d697ca" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting horizontally. A negative value means shifting image left, while a positive value means shifting image right. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;width_factor=(-0.2, 0.3)&lt;/code&gt; results in an output shifted left by 20%, and shifted right by 30%. &lt;code&gt;width_factor=0.2&lt;/code&gt; results in an output height shifted left or right by 20%.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91c973265bac7ff051653d0165345d52a97d0e23" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting vertically. A negative value means shifting image up, while a positive value means shifting image down. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;height_factor=(-0.2, 0.3)&lt;/code&gt; results in an output shifted by a random amount in the range [-20%, +30%]. &lt;code&gt;height_factor=0.2&lt;/code&gt; results in an output height shifted by a random amount in the range [-20%, +20%].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7049c0b7f85f9f5d90a665c9a2c18068cc1f50bb" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming horizontally. When represented as a single float, this value is used for both the upper and lower bound. For instance, &lt;code&gt;width_factor=(0.2, 0.3)&lt;/code&gt; result in an output zooming out between 20% to 30%. &lt;code&gt;width_factor=(-0.3, -0.2)&lt;/code&gt; result in an output zooming in between 20% to 30%. Defaults to &lt;code&gt;None&lt;/code&gt;, i.e., zooming vertical and horizontal directions by preserving the aspect ratio.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2ec50d28cf2adbe8d493bb972ad6ae6b32140707" translate="yes" xml:space="preserve">
          <source>a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming vertically. When represented as a single float, this value is used for both the upper and lower bound. A positive value means zooming out, while a negative value means zooming in. For instance, &lt;code&gt;height_factor=(0.2, 0.3)&lt;/code&gt; result in an output zoomed out by a random amount in the range [+20%, +30%]. &lt;code&gt;height_factor=(-0.3, -0.2)&lt;/code&gt; result in an output zoomed in by a random amount in the range [+20%, +30%].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="134107ca0c019b55908b80f4021d2430226ea2bd" translate="yes" xml:space="preserve">
          <source>a float representing the threshold for box scores. Boxes with a score that is not larger than this threshold will be suppressed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5f94882e30fda2ab68c451ff7e157ffcd9c9395b" translate="yes" xml:space="preserve">
          <source>a float representing the threshold for deciding whether boxes overlap too much with respect to IoU (intersection over union).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="eb70148942a0d807c9b8eab06234b1263dd9f73d" translate="yes" xml:space="preserve">
          <source>a float value.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="95a34729e004ba21708276447a0c52f66f075797" translate="yes" xml:space="preserve">
          <source>a float. The maximum absolute difference allowed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8cade3d579ad24100c211eef3761440915ebda65" translate="yes" xml:space="preserve">
          <source>a floating point value. The learning rate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="96653b90a10cbc5bd2bee44ca5eac4e329ab5a1e" translate="yes" xml:space="preserve">
          <source>a function that compares two evaluation results and returns true if current evaluation result is better. Follows the signature:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a9a62fd00059c46a517d9a5d09090fa30f1d118d" translate="yes" xml:space="preserve">
          <source>a function that does accumulation. If None, then &lt;a href=&quot;../math/add_n&quot;&gt;&lt;code&gt;tf.math.add_n&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e212799b3b3be2bf8bb202585b8b934660586c8" translate="yes" xml:space="preserve">
          <source>a function that takes an epoch index (integer, indexed from 0) and current learning rate (float) as inputs and returns a new learning rate as output (float).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e12532b57f71320a99fe67d455119ce2516227a2" translate="yes" xml:space="preserve">
          <source>a function that takes no arguments and returns a &lt;code&gt;ServingInputReceiver&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1bd914955f1635d519f5b5015a7943bdbe1e789c" translate="yes" xml:space="preserve">
          <source>a generator function that yields input data as a list or tuple, which will be used to execute the converted signature for calibration. All the returned input data should have the same shape. Example: &lt;code&gt;def input_fn(): yield input1, input2, input3&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b35ea09d187677febf5398dd21d3f485aef04a83" translate="yes" xml:space="preserve">
          <source>a generator function that yields input data as a list or tuple, which will be used to execute the converted signature to generate TRT engines. Example: `def input_fn():</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1862cc4d53bc4e8a702743354cc37627a768a2f8" translate="yes" xml:space="preserve">
          <source>a generator function which yields data</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="98c108f990a30bbb49abae38f009c82ac5f3a790" translate="yes" xml:space="preserve">
          <source>a generator to be copied from.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="420880ced69a6abdc0537ffab2bcb1d1ec757577" translate="yes" xml:space="preserve">
          <source>a handle to defined flag.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e9fc2e7b4a4a43e13919ca0d29891f8252c3bdeb" translate="yes" xml:space="preserve">
          <source>a keras.Model instance.</source>
          <target state="translated">Керас.Образцовый экземпляр.</target>
        </trans-unit>
        <trans-unit id="825f328ed6cb35d3a0907c277ea200144eea6b05" translate="yes" xml:space="preserve">
          <source>a list of Mirrored objects.</source>
          <target state="translated">список Зеркальных объектов.</target>
        </trans-unit>
        <trans-unit id="8af7fc543dbba60d65534412fdeec31fcf0fd35c" translate="yes" xml:space="preserve">
          <source>a list of Numpy arrays. The number of arrays and their shape must match number of the dimensions of the weights of the layer (i.e. it should match the output of &lt;code&gt;get_weights&lt;/code&gt;).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="64df7eba5e731a4dc70dbacc22e2fd9fd9e1d032" translate="yes" xml:space="preserve">
          <source>a list of checkpoint paths, typically the results of &lt;code&gt;Saver.save()&lt;/code&gt; or those of &lt;a href=&quot;../../../train/latest_checkpoint&quot;&gt;&lt;code&gt;tf.train.latest_checkpoint()&lt;/code&gt;&lt;/a&gt;, regardless of sharded/non-sharded or V1/V2.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cfa77622762529e62cce47be75b5d7ef8f04b09b" translate="yes" xml:space="preserve">
          <source>a list of checkpoint paths.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8652d1441c07c34c2491a5fef88f30f328252a67" translate="yes" xml:space="preserve">
          <source>a list of device strings such as &lt;code&gt;['/gpu:0', '/gpu:1']&lt;/code&gt;. If &lt;code&gt;None&lt;/code&gt;, all available GPUs are used. If no GPUs are found, CPU is used.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5dd923854fce47fe5a5fbe46663ed04995594696" translate="yes" xml:space="preserve">
          <source>a list of float values.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cae41a96c3b2e908d36cbc657c22fa2a8eb5b02" translate="yes" xml:space="preserve">
          <source>a list of gradients, one for each element of target. Defaults to None.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ca7a0932035e5c9de07f92110d3540ab4ff578d3" translate="yes" xml:space="preserve">
          <source>a list of loss tensors.</source>
          <target state="translated">список тензоров потерь.</target>
        </trans-unit>
        <trans-unit id="8466476c20c2b4575b81f48bbef14bb81277fd56" translate="yes" xml:space="preserve">
          <source>a list of names of layers to keep eye on. If None or empty list all the embedding layer will be watched.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f3cccd7e469ea448da74293963e6a99fb093741" translate="yes" xml:space="preserve">
          <source>a list of prediction keys. Key can be either the class variable of prediction_keys.PredictionKeys or its string value, such as: prediction_keys.PredictionKeys.LOGITS or 'logits'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fe1e44e58043e3bac62424bc232c0f828907d045" translate="yes" xml:space="preserve">
          <source>a list of tuples &lt;code&gt;(tensor, value)&lt;/code&gt;. &lt;code&gt;value&lt;/code&gt; should be a Numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2e03752a3549be3776b9abdbd4707084bba9047" translate="yes" xml:space="preserve">
          <source>a list of variables that need to be averaged. Only needed if variable_averages is passed in.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eb0f04e7fc6ee40cdb193ac62baee8bb1ca6431" translate="yes" xml:space="preserve">
          <source>a list of variables that require to use of the moving average variable name to be restored. If None, it will default to variables.moving_average_variables() + variables.trainable_variables()</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="91a77371e3824445e17865c21a8864e288e638bc" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors (or IndexedSlices, or None), one for each element in &lt;code&gt;sources&lt;/code&gt;. Returned structure is the same as the structure of &lt;code&gt;sources&lt;/code&gt;.</source>
          <target state="translated">список или вложенная структура Tensors (или IndexedSlices, или None), по одному для каждого элемента в &lt;code&gt;sources&lt;/code&gt; . Возвращенная структура такая же, как и у &lt;code&gt;sources&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7c876daa0f22003807573109c8a715b9d71802ff" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors or Variables to be differentiated.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4276967efbeb15913c139768efe32fe80016a5bd" translate="yes" xml:space="preserve">
          <source>a list or nested structure of Tensors or Variables. &lt;code&gt;target&lt;/code&gt; will be differentiated against elements in &lt;code&gt;sources&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2b8519688d6e08f0ef3f1f53563b370c82f252c" translate="yes" xml:space="preserve">
          <source>a list or tuple of &lt;code&gt;DType&lt;/code&gt; objects or strings that can be converted to &lt;code&gt;DType&lt;/code&gt; objects via &lt;a href=&quot;../../dtypes/as_dtype&quot;&gt;&lt;code&gt;tf.as_dtype()&lt;/code&gt;&lt;/a&gt;. Examples:</source>
          <target state="translated">список или кортеж &lt;code&gt;DType&lt;/code&gt; объектов или строк , которые могут быть преобразованы в &lt;code&gt;DType&lt;/code&gt; объекты через &lt;a href=&quot;../../dtypes/as_dtype&quot;&gt; &lt;code&gt;tf.as_dtype()&lt;/code&gt; &lt;/a&gt; . Примеры:</target>
        </trans-unit>
        <trans-unit id="4a6bdafb64b93a495b672af20865dc481b0ed23a" translate="yes" xml:space="preserve">
          <source>a list or tuple of prediction keys. Each key can be either the class variable of prediction_keys.PredictionKeys or its string value, such as: prediction_keys.PredictionKeys.CLASSES or 'classes'. If not specified, it will return the predictions for all valid keys.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e062962fff519e51826af13e2686d1b25c61f1c" translate="yes" xml:space="preserve">
          <source>a name for the op that creates the writer.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="82f9e1f9d52a6496cd6e1fbefeba7b546e34e817" translate="yes" xml:space="preserve">
          <source>a nest of NumPy input arrays that will be converted into a dataset. Note that the NumPy arrays are stacked, as that is normal &lt;a href=&quot;../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ef8e153138ea9a5535d4306bcbaa35a18fc052c8" translate="yes" xml:space="preserve">
          <source>a nest of NumPy input arrays that will be converted into a dataset. Note that the NumPy arrays are stacked, as that is normal &lt;a href=&quot;../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; behavior.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="beb20ec17e12b3a92d15870c8fb928b39be9384e" translate="yes" xml:space="preserve">
          <source>a new instance of &lt;code&gt;RunConfig&lt;/code&gt;.</source>
          <target state="translated">новый экземпляр &lt;code&gt;RunConfig&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="7ebfcefc6e47ac4ed9512e51f768d3cbe5c823cb" translate="yes" xml:space="preserve">
          <source>a numpy array.</source>
          <target state="translated">массив нумпи.</target>
        </trans-unit>
        <trans-unit id="583166dd6bf07228d6040841ccf402891050a5e4" translate="yes" xml:space="preserve">
          <source>a numpy ndarray.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d253db5a4761b53c7ffde3781cb4f03e7cb07091" translate="yes" xml:space="preserve">
          <source>a path relative to tensorflow root. e.g. &quot;core/platform&quot;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d434acfa4631c87791b616c82b7e6083ce9a28b9" translate="yes" xml:space="preserve">
          <source>a positive float represented as fraction of value, or a tuple of size 2 representing lower and upper bound. When represented as a single float, lower = upper. The contrast factor will be randomly picked between [1.0 - lower, 1.0 + upper].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b17aca81e79c7530a3bc5fdc0659c98cdbd45a6" translate="yes" xml:space="preserve">
          <source>a premade LinearModel, its output must match the output of the dnn model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="259c33a51ca2823379036c66fbe8b38a134e8892" translate="yes" xml:space="preserve">
          <source>a python scalar or a scalar tensor. Mean of the random values to generate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a5d4da2cd944c3f7f7ef6b9224fdc61a3e90e225" translate="yes" xml:space="preserve">
          <source>a python scalar or a scalar tensor. Standard deviation of the random values to generate.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3267c112f6d4d3c0519780ece91f770b5ea07cc2" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filter&lt;/code&gt; Tensor of shape</source>
          <target state="translated">ранговый (N + 2) &lt;code&gt;filter&lt;/code&gt; Тензор формы</target>
        </trans-unit>
        <trans-unit id="567bea64cd23153635d3d86fe4dc29e83b999e55" translate="yes" xml:space="preserve">
          <source>a rank (N+2) &lt;code&gt;filters&lt;/code&gt; Tensor of shape</source>
          <target state="translated">ранг (N + 2) &lt;code&gt;filters&lt;/code&gt; Тензор формы</target>
        </trans-unit>
        <trans-unit id="a9d06e247ca03db1069906ff93f237957d9b8b9a" translate="yes" xml:space="preserve">
          <source>a scalar integer &lt;code&gt;Tensor&lt;/code&gt; representing the maximum number of boxes to be selected by non max suppression.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3fca9faa64f5b46a4d7ce176156b7c88545b1baa" translate="yes" xml:space="preserve">
          <source>a shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1e3fab1cb04b3c63a683f54ad32d8e23b5b601ed" translate="yes" xml:space="preserve">
          <source>a single argument or a list of arguments (typically a list of default values); a single argument is converted internally into a list containing one item.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="7cbfc6ae061d8de0cb83e913ad03f6acad9950c0" translate="yes" xml:space="preserve">
          <source>a single data type (float32, int32, or string, for example)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d6b451769762c48595037c2a99820e1960c8d664" translate="yes" xml:space="preserve">
          <source>a single or a list the remote server addr in host-port format.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3b5a8f6cdc727f3954a46a20a08afdbba957f018" translate="yes" xml:space="preserve">
          <source>a size entry is interpreted as &lt;em&gt;any&lt;/em&gt; size if it is None or '.'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1598d219bbf50d48513b4d681ac2e664678a0fb2" translate="yes" xml:space="preserve">
          <source>a size entry is interpreted as an explicit size if it can be parsed as an integer primitive.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fc48ba5f69c2b3b1cd2c64475359fd4da8d724e2" translate="yes" xml:space="preserve">
          <source>a string added between each string being joined.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b3901c8cf09bba87b3019c11d2d00ae2d940cb1a" translate="yes" xml:space="preserve">
          <source>a string for the name of the executor to be used to execute functions defined by tf.contrib.eager.defun.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f317a91fbf6fd20ea76003a27e77d226e69d5e9f" translate="yes" xml:space="preserve">
          <source>a string of the form /job:</source>
          <target state="translated">строка формы/работы:</target>
        </trans-unit>
        <trans-unit id="592805594d7acec2e035ccb78cd57e76d0c89267" translate="yes" xml:space="preserve">
          <source>a string path indicating where to write the TFRecord data.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="28879ce16025e8aea78e0eed31c3828842400532" translate="yes" xml:space="preserve">
          <source>a string resource path relative to tensorflow/</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cf98d147fdc1a4586c1261348ed08e3ea9d55344" translate="yes" xml:space="preserve">
          <source>a string resource path relative to tensorflow/.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="382e66fb08d6f4af34d47af5189e64c302e25ab8" translate="yes" xml:space="preserve">
          <source>a string specifying the directory in which to write an event file.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8d4b27e20cdf3399f6ff473e703a75399bc6632" translate="yes" xml:space="preserve">
          <source>a string specifying the path to an existing SavedModel.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5c782ca359f58ff03f46b2cba60080dcab6928ea" translate="yes" xml:space="preserve">
          <source>a string specifying the path to the SavedModel directory.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e66ef56dd71685a637ed8bde76e00efab58fe5da" translate="yes" xml:space="preserve">
          <source>a string-type Tensor to summarize.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="56c95190656de2a73fe1c13de36287330da4d209" translate="yes" xml:space="preserve">
          <source>a string. The address of the master to use for eval. Defaults to master if not set.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c2db3d823dea26a64286f31522b26f56802a1985" translate="yes" xml:space="preserve">
          <source>a string. The address of the master to use for training.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9a00a84ed543b41fac41116a0ecb87c993c7cda7" translate="yes" xml:space="preserve">
          <source>a summary_pb2.SummaryDescription</source>
          <target state="translated">summary_pb2.summaryDescription</target>
        </trans-unit>
        <trans-unit id="45f3aa41e8ac0fd197acaacc063a6ad881fe4154" translate="yes" xml:space="preserve">
          <source>a tensor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e4ae58d9fb87a25f2deeed86b25ef281f7e84171" translate="yes" xml:space="preserve">
          <source>a tensor of rank 1 or higher with a shape of [..., num_boxes].</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1b4fd33d17d7c9e469c896528f1317da39655996" translate="yes" xml:space="preserve">
          <source>a tensor of rank 2 or higher with a shape of [..., num_boxes, 4]. Dimensions except the last two are batch dimensions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cb28536b86a99e6d9c4639674cb74b760427a486" translate="yes" xml:space="preserve">
          <source>a tensor or list of tensors</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="640aa7ca6a8766d889609357ce01db334a546544" translate="yes" xml:space="preserve">
          <source>a tuple of (&lt;code&gt;sampled_candidates&lt;/code&gt;, &lt;code&gt;true_expected_count&lt;/code&gt;, &lt;code&gt;sampled_expected_count&lt;/code&gt;) returned by a &lt;code&gt;*_candidate_sampler&lt;/code&gt; function. (if None, we default to &lt;code&gt;log_uniform_candidate_sampler&lt;/code&gt;)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fcfc12d63102b45a3e6037e53f6854edb7f5b381" translate="yes" xml:space="preserve">
          <source>a tuple of 2 integers, specifying the strides of the convolution along the width and height.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d183d11d0d54a060d7009b34542317f6fc714e19" translate="yes" xml:space="preserve">
          <source>a tuple of 2 integers, specifying the width and height of the 2D convolution window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="57a238277396d1dc9a17a850fb1ad6b9aa782459" translate="yes" xml:space="preserve">
          <source>a tuple of a single integer, specifying the length of the 1D convolution window.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="143bed0bba33eacbf68b60d1ca77684c689464bf" translate="yes" xml:space="preserve">
          <source>a tuple of a single integer, specifying the stride length of the convolution.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ab7dc476556d1061e224a2a7a8aa11501a5707ed" translate="yes" xml:space="preserve">
          <source>a tuple of strings, which describes all the TPU devices in the system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="aea224a6c5fec351ebdbae08e0bd3ba1b0c63d75" translate="yes" xml:space="preserve">
          <source>a tuple with (output_row, output_col).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8afd66969dd06ed1eba4fe64521e14d7727d738b" translate="yes" xml:space="preserve">
          <source>a tuple/list of strings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="47ed70eec68109426c23a40515035b914c0da955" translate="yes" xml:space="preserve">
          <source>a value which can either hold 'none' or 'zero' and alters the value which will be returned if the target and sources are unconnected. The possible values and effects are detailed in 'UnconnectedGradients' and it defaults to 'none'.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b8ebd3b7d7e693185180008e1a8aaa05435c3d8c" translate="yes" xml:space="preserve">
          <source>a vector of dtype STATE_TYPE representing the initial counter for the RNG, whose length is algorithm-specific.,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a0cfcb777f5630e0744dd02bb3be535bf23c0558" translate="yes" xml:space="preserve">
          <source>a vector of dtype STATE_TYPE representing the initial state of the RNG, whose length and semantics are algorithm-specific. If it's a variable, the generator will reuse it instead of creating a new variable.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="af97be5a0dcfe7dd967ed814e5c51b34d26e758a" translate="yes" xml:space="preserve">
          <source>a) If a loop variable is a SparseTensor, the shape invariant must be TensorShape([r]) where r is the rank of the dense tensor represented by the sparse tensor. It means the shapes of the three tensors of the SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here is the shape of the SparseTensor.dense_shape property. It must be the shape of a vector.</source>
          <target state="translated">a)Если переменная цикла является SparseTensor,то инвариантом формы должен быть TensorShape([r]),где r-ранг плотного тензора,представленного разреженным тензором.Это означает,что формами трех тензоров SparseTensor являются ([None],[None,r],[r]).ПРИМЕЧАНИЕ:Инвариантом формы здесь является форма свойства SparseTensor.dense_shape.Это должна быть форма вектора.</target>
        </trans-unit>
        <trans-unit id="addb12381e6be0fb67d7d9c7e9625d221a558d6e" translate="yes" xml:space="preserve">
          <source>a: A &lt;code&gt;CSRSparseMatrix&lt;/code&gt;. b: A &lt;code&gt;CSRSparseMatrix&lt;/code&gt; with the same type and rank as &lt;code&gt;a&lt;/code&gt;. type: The type of both &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;. transpose_a: If True, &lt;code&gt;a&lt;/code&gt; transposed before multiplication. transpose_b: If True, &lt;code&gt;b&lt;/code&gt; transposed before multiplication. adjoint_a: If True, &lt;code&gt;a&lt;/code&gt; adjointed before multiplication. adjoint_b: If True, &lt;code&gt;b&lt;/code&gt; adjointed before multiplication.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="a35ea6647dc95b90fe453d98f66e284fc5f0c506" translate="yes" xml:space="preserve">
          <source>a[0] = 0 : the first value of the sequence is 0</source>
          <target state="translated">a[0]=0:первое значение последовательности равно 0</target>
        </trans-unit>
        <trans-unit id="deda22cbcad48bb3a1413dc8ff28a54f1e5592e8" translate="yes" xml:space="preserve">
          <source>a[end] = input_row_length : the last value of the sequence is the size</source>
          <target state="translated">a[end]=input_row_length:последним значением последовательности является размер</target>
        </trans-unit>
        <trans-unit id="eb8f95bc156db1900a569b1735ddc3da656d19bc" translate="yes" xml:space="preserve">
          <source>about sharing states in tensorflow.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="f0f846898da4ec61cf83b3e2c8495d2978a0200c" translate="yes" xml:space="preserve">
          <source>absolute tolerance for bfloat16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ae04d0b7afda8def3fdb79e35983e0773b0864f" translate="yes" xml:space="preserve">
          <source>absolute tolerance for float16.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3cfa07cb0663ab1cde306433e352a29097f65419" translate="yes" xml:space="preserve">
          <source>absolute tolerance for float32.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4fd56eead7560ee583f1b8caad28fbd463bee25" translate="yes" xml:space="preserve">
          <source>absolute tolerance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3e1f32f51354c2febc7caaaf4ffeef8cbb8f07cf" translate="yes" xml:space="preserve">
          <source>accum += grad * grad prox_v = var - lr * grad * (1 / sqrt(accum)) var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="26c2261a427773f28da9c962c61401a44f52fafa" translate="yes" xml:space="preserve">
          <source>accum += grad * grad var -= lr * grad * (1 / (sqrt(accum) + epsilon))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9b39d4103e267bfff6b19f03a0c61954510b506e" translate="yes" xml:space="preserve">
          <source>accum += grad * grad var -= lr * grad * (1 / sqrt(accum))</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="fbdff22455472e83bbec28e270efc5acd84cec93" translate="yes" xml:space="preserve">
          <source>accum = accum * momentum + grad var -= lr * accum</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cabf3744d4cc537b306d1c2d4e5c98eab9321c1c" translate="yes" xml:space="preserve">
          <source>accum = accum * momentum - lr * grad var += accum</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77aa7bbfc2a1935f26fc03cc068c50ab9de9da1b" translate="yes" xml:space="preserve">
          <source>accum = rho() * accum + (1 - rho()) * grad.square(); update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad; update_accum = rho() * update_accum + (1 - rho()) * update.square(); var -= update;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="e072c3a42e30a463ae763379bfd4971f6786c3db" translate="yes" xml:space="preserve">
          <source>accum_new = accum + grad * grad linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2 var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0 accum = accum_new</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9207a4d89e0769ab8d4e61e6e2f82d2491a3631b" translate="yes" xml:space="preserve">
          <source>actual distribution of the values to maximize the usage of the lower bit depth and adjusting the output min and max ranges accordingly.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="336367a90c28a1ba840266e48935292b8c0ec99a" translate="yes" xml:space="preserve">
          <source>add and relu and requantize fusion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3eebca9963a4e9d6f0fcc02adef3bd6f1fb5966b" translate="yes" xml:space="preserve">
          <source>add and relu fusion.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="577f333710522bc0627398bf6ba75e178aa283d7" translate="yes" xml:space="preserve">
          <source>add.</source>
          <target state="translated">add.</target>
        </trans-unit>
        <trans-unit id="b1b7d0394cceca9bd35a4316061103e356401833" translate="yes" xml:space="preserve">
          <source>additional keyword arguments to be passed to the underlying &lt;code&gt;assertAllClose&lt;/code&gt; call.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9d0442ecdcd49f18c5f26a6c7ac65eb7852e6a16" translate="yes" xml:space="preserve">
          <source>adjoints (conjugate transposes).</source>
          <target state="translated">суставы (трансплантация конъюгата).</target>
        </trans-unit>
        <trans-unit id="f0e72c8db0ec39595db76cd9ab3ea0b01fa0a54e" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate is an int64 tensor of shape [max(spatial&lt;em&gt;dims)], adjusted&lt;/em&gt;{paddings,crops} are int64 tensors of shape [max(spatial_dims), 2]</source>
          <target state="translated">Adjust_dilation_rate - это тензор формы int64 [max (пространственное &lt;em&gt;затемнение)], откорректированные&lt;/em&gt; {paddings, crop} - это тензор формы int64 [max (пространственные_димс), 2]</target>
        </trans-unit>
        <trans-unit id="05ab368bb50c30f0ad36866b483ced3c24cef7fa" translate="yes" xml:space="preserve">
          <source>adjusted_dilation_rate[spatial_dims[i] - 1] = dilation_rate[i] adjusted_paddings[spatial_dims[i] - 1, :] = paddings[i, :] adjusted_crops[spatial_dims[i] - 1, :] = crops[i, :]</source>
          <target state="translated">adjust_dilation_rate[spatial_dims[i]-1]=dilation_rate[i]adjust_paddings[spatial_dims[i]-1,:]=отступы[i,:]adjust_crops[spatial_dims[i]-1,:]=сельскохозяйственные культуры[i,:]</target>
        </trans-unit>
        <trans-unit id="a4cbf8207b85c3ddcaf0003b5cf461ae49770af7" translate="yes" xml:space="preserve">
          <source>after each call to &lt;code&gt;Saver.save()&lt;/code&gt;</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="10582f7ebb86265685f2d94ac9bf45194c26c416" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;../../variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">агрегация: указывает, как будет агрегироваться распределенная переменная. Допустимые значения - это константы, определенные в классе &lt;a href=&quot;../../variableaggregation&quot;&gt; &lt;code&gt;tf.VariableAggregation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="95142e8db6f0e670c6cdd282ebda2a8dc3235286" translate="yes" xml:space="preserve">
          <source>aggregation: Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class &lt;a href=&quot;variableaggregation&quot;&gt;&lt;code&gt;tf.VariableAggregation&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">агрегация: указывает, как будет агрегироваться распределенная переменная. Допустимые значения - это константы, определенные в классе &lt;a href=&quot;variableaggregation&quot;&gt; &lt;code&gt;tf.VariableAggregation&lt;/code&gt; &lt;/a&gt; .</target>
        </trans-unit>
        <trans-unit id="0b9a9b6a555fda3290e62d85d68e6dc900f6aa72" translate="yes" xml:space="preserve">
          <source>alias for &quot;input&quot; argument.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="40ab33a302eea4103a7a9fe7699eb8c64bfbebd3" translate="yes" xml:space="preserve">
          <source>alias for expand_nonconcat_dim</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6b47a9fb6a6098b56fa005c9bf092d1ede95a90d" translate="yes" xml:space="preserve">
          <source>alpha = input_row_length / output_row_length : our reduction ratio</source>
          <target state="translated">alpha=input_row_length/output_row_length:наш коэффициент уменьшения</target>
        </trans-unit>
        <trans-unit id="13c37d0b0868b315be5754e60b93df3ddf6e1515" translate="yes" xml:space="preserve">
          <source>amount of weight decay to apply; None means that the weights are not decayed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="584cfc3585963e88777945fd0c74c8fed91e27d7" translate="yes" xml:space="preserve">
          <source>amount of weight decay to apply; None means that the weights are not decayed. Weights are decayed by multiplying the weight by this factor each step.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6be75b3f1c53a534ff3d3d88d27d62dd86a8b144" translate="yes" xml:space="preserve">
          <source>an &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt; scalar representing data to be folded in to the seed.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="21498301c88a4012ed64c1b4b7225d60e8644258" translate="yes" xml:space="preserve">
          <source>an &lt;code&gt;int&lt;/code&gt; shows until which global step should we wait.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="60271ab37cee858c4218f052e21a7603d914d273" translate="yes" xml:space="preserve">
          <source>an OrderedDict, where the keys are the feature column names and the values are importances. It is sorted by importance.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="5e7cd4b2e10dade102ff7156179e9913d87e9c02" translate="yes" xml:space="preserve">
          <source>an RNG seed (a tensor with shape [2] and dtype &lt;code&gt;int32&lt;/code&gt; or &lt;code&gt;int64&lt;/code&gt;). (When using XLA, only &lt;code&gt;int32&lt;/code&gt; is allowed.)</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f4a60ab5b3884b1dd6263e0c0406bab2fcc7011" translate="yes" xml:space="preserve">
          <source>an RNNCell, a projection to output_size is added to it.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4795fec293585f2b8f245ac28ac09c142cad999f" translate="yes" xml:space="preserve">
          <source>an approximation of the area under the P-R curve.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d4d758ce3efd3e79d82b2ead6ef75b7be77f612b" translate="yes" xml:space="preserve">
          <source>an arbitrarily nested structure.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4b9296a58496856781b45283ebf3905a9774cf6" translate="yes" xml:space="preserve">
          <source>an arbitrarily nested structure. Note, numpy arrays are considered atoms and are not flattened.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78bf9b0c50970fcea95462ac064c671c66592d16" translate="yes" xml:space="preserve">
          <source>an enum value of &lt;a href=&quot;../../../../distribute/inputreplicationmode&quot;&gt;&lt;code&gt;tf.distribute.InputReplicationMode&lt;/code&gt;&lt;/a&gt;. Only &lt;code&gt;PER_WORKER&lt;/code&gt; is supported currently, which means there will be a single call to &lt;code&gt;input_fn&lt;/code&gt; per worker. Replicas will dequeue from the local &lt;a href=&quot;../../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; on their worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c1d9638fbc99061f41f5f1718d95aa9d9b2ba446" translate="yes" xml:space="preserve">
          <source>an enum value of &lt;a href=&quot;../../../distribute/inputreplicationmode&quot;&gt;&lt;code&gt;tf.distribute.InputReplicationMode&lt;/code&gt;&lt;/a&gt;. Only &lt;code&gt;PER_WORKER&lt;/code&gt; is supported currently, which means there will be a single call to &lt;code&gt;input_fn&lt;/code&gt; per worker. Replicas will dequeue from the local &lt;a href=&quot;../../../data/dataset&quot;&gt;&lt;code&gt;tf.data.Dataset&lt;/code&gt;&lt;/a&gt; on their worker.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3759390b842509817496ad6964a87f97c5843a65" translate="yes" xml:space="preserve">
          <source>an input generator that can be used to generate input samples for the model. This must be a callable object that returns an object that supports the &lt;code&gt;iter()&lt;/code&gt; protocol (e.g. a generator function). The elements generated must have same type and shape as inputs to the model.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="8feb6baf60936cf60390ee049e7a07e3ffd4392a" translate="yes" xml:space="preserve">
          <source>an input sequence.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2d46e772e042b91ec9dff778f5110d720bafa374" translate="yes" xml:space="preserve">
          <source>an instance of &lt;a href=&quot;../configproto&quot;&gt;&lt;code&gt;tf.compat.v1.ConfigProto&lt;/code&gt;&lt;/a&gt; proto used to configure the session. It's the &lt;code&gt;config&lt;/code&gt; argument of constructor of &lt;a href=&quot;../session&quot;&gt;&lt;code&gt;tf.compat.v1.Session&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="1a37f2503f46094f2d360fd3f7fc596a57b2fd3f" translate="yes" xml:space="preserve">
          <source>an instance of &lt;a href=&quot;topology&quot;&gt;&lt;code&gt;tf.tpu.experimental.Topology&lt;/code&gt;&lt;/a&gt;, which describes the physical topology of TPU system.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cd841e8ca3fc9c05fb813b0d2f5d9103dc9c0ba8" translate="yes" xml:space="preserve">
          <source>an instance of &lt;code&gt;tf.train.experimental/ClusterDeviceFilters&lt;/code&gt; that specify device filters to the remote tasks in cluster.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6e2d70312bfddfcd3ddb72da0a20ed277ffcd67f" translate="yes" xml:space="preserve">
          <source>an integer or 1-D numpy array.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2085d387df6482fce1af122d6acdb0118638ce0b" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12a0347d0bf66b603b4cf339883f33c0d26b06b7" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="d3402e6e4b4d2964f62630d5d955c60e92608fd4" translate="yes" xml:space="preserve">
          <source>an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying any &lt;code&gt;strides&lt;/code&gt; value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="58266c81cd572b21187fd9645689ccfc5a6f9adf" translate="yes" xml:space="preserve">
          <source>an integer representing the number of boxes in a tile, i.e., the maximum number of boxes per image that can be used to suppress other boxes in parallel; larger tile_size means larger parallelism and potentially more redundant work.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="12f87a898c564b834112575d56e2166669cc6140" translate="yes" xml:space="preserve">
          <source>an integer, specifying the dilation rate to use for dilated convolution. Currently, specifying a &lt;code&gt;dilation_rate&lt;/code&gt; value != 1 is incompatible with specifying a stride value != 1.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="36442510bd24021bdca61b0550d53fc4b7f41549" translate="yes" xml:space="preserve">
          <source>an integer: 1 or 2. 1 corresponds to V1, 2 corresponds to V2. (Defaults to V1). With V1, &lt;code&gt;export_saved_model()&lt;/code&gt; adds rewrite() and TPUPartitionedCallOp() for user; while in v2, user is expected to add rewrite(), TPUPartitionedCallOp() etc in their model_fn. A helper function &lt;code&gt;inference_on_tpu&lt;/code&gt; is provided for V2. brn_tpu_estimator.py includes examples for both versions i.e. TPUEstimatorExportTest and TPUEstimatorExportV2Test.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="15bd4e656cd87110cb6d06a7f5b3f1e300030cdd" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilation_rate&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="translated">необязательный тензор &lt;code&gt;dilation_rate&lt;/code&gt; формы &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N,&lt;/a&gt; определяющий частоту повышения / понижения дискретизации входного сигнала, и необязательный список из N &lt;code&gt;strides&lt;/code&gt; (по умолчанию [1] * N), который вычисляется для каждой пространственной выходной позиции ND (x [0], ..., x [N-1]):</target>
        </trans-unit>
        <trans-unit id="0ee24f38b8e109fbd5639cc2b47bec50e32475ed" translate="yes" xml:space="preserve">
          <source>an optional &lt;code&gt;dilations&lt;/code&gt; tensor of shape &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N&lt;/a&gt; specifying the filter upsampling/input downsampling rate, and an optional list of N &lt;code&gt;strides&lt;/code&gt; (defaulting [1]*N), this computes for each N-D spatial output position (x[0], ..., x[N-1]):</source>
          <target state="translated">необязательный тензор &lt;code&gt;dilations&lt;/code&gt; формы &lt;a href=&quot;defaulting%20to%20%5b1%5d*n&quot;&gt;N,&lt;/a&gt; определяющий частоту повышения / понижения дискретизации входного сигнала, и необязательный список из N &lt;code&gt;strides&lt;/code&gt; (по умолчанию [1] * N), который вычисляется для каждой пространственной выходной позиции ND (x [0], ..., x [N-1]):</target>
        </trans-unit>
        <trans-unit id="ab989fce67e1a28670d6c810e49317fa6212a61a" translate="yes" xml:space="preserve">
          <source>an optional name for the operation.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3f33599b0487789dd89792f29c86c4b410cef6e4" translate="yes" xml:space="preserve">
          <source>an optional string of the form /job:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="cffa50a32cb13a240d705317bcec65dd1f31b6ad" translate="yes" xml:space="preserve">
          <source>and</source>
          <target state="translated">and</target>
        </trans-unit>
        <trans-unit id="ebd46f618c63c3e212b1d778f0a25f4660c23598" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;SparseFeature&lt;/code&gt; config with 2 &lt;code&gt;index_key&lt;/code&gt;s</source>
          <target state="translated">и конфигурация &lt;code&gt;SparseFeature&lt;/code&gt; с двумя &lt;code&gt;index_key&lt;/code&gt; s</target>
        </trans-unit>
        <trans-unit id="6140381926bf0d082343ace25ade2e3cf221f627" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;default_value&lt;/code&gt; is &lt;code&gt;x&lt;/code&gt;, then the output will be a dense &lt;code&gt;[3, 5]&lt;/code&gt; string tensor with values:</source>
          <target state="translated">а &lt;code&gt;default_value&lt;/code&gt; - &lt;code&gt;x&lt;/code&gt; , тогда на выходе будет плотный &lt;code&gt;[3, 5]&lt;/code&gt; строковый тензор со значениями:</target>
        </trans-unit>
        <trans-unit id="90e193944d6b8498e0257c00b2820369a0de3479" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;ids&lt;/code&gt; is:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b2d759c667e68226ece3acd5aa4e1cc6620b0ca0" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;max&lt;/code&gt; to 'outputs' tensor of same shape as &lt;code&gt;inputs&lt;/code&gt;.</source>
          <target state="translated">и &lt;code&gt;max&lt;/code&gt; для тензора 'output' той же формы, что и &lt;code&gt;inputs&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="78fbe88a4e8420d083776e826c4b0cd5bb232375" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;shape&lt;/code&gt; is &lt;code&gt;[9, -1]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[9, 4]&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt;:</source>
          <target state="translated">и &lt;code&gt;shape&lt;/code&gt; является &lt;code&gt;[9, -1]&lt;/code&gt; , то выходной сигнал будет &lt;code&gt;SparseTensor&lt;/code&gt; формы &lt;code&gt;[9, 4]&lt;/code&gt; и &lt;code&gt;indices&lt;/code&gt; / &lt;code&gt;values&lt;/code&gt; :</target>
        </trans-unit>
        <trans-unit id="23cce7bb518f569f4a001bd92a904ee1f95e7599" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;to_retain = [True, False, False, True]&lt;/code&gt;, then the output will be a &lt;code&gt;SparseTensor&lt;/code&gt; of shape &lt;code&gt;[4, 5]&lt;/code&gt; with 2 non-empty values:</source>
          <target state="translated">и &lt;code&gt;to_retain = [True, False, False, True]&lt;/code&gt; , то на выходе будет &lt;code&gt;SparseTensor&lt;/code&gt; формы &lt;code&gt;[4, 5]&lt;/code&gt; с двумя непустыми значениями:</target>
        </trans-unit>
        <trans-unit id="3b2da781f92810fe2701eb25993573d612b9c1c1" translate="yes" xml:space="preserve">
          <source>and &lt;code&gt;vocab_size = 200&lt;/code&gt;, then the output will be a &lt;code&gt;[2, 3, 200]&lt;/code&gt; dense bool tensor with False everywhere except at positions</source>
          <target state="translated">и &lt;code&gt;vocab_size = 200&lt;/code&gt; , тогда на выходе будет плотный логический тензор &lt;code&gt;[2, 3, 200]&lt;/code&gt; с False везде, кроме позиций</target>
        </trans-unit>
        <trans-unit id="fb47192727f17143a048825f4ab10f7ac6f7e0a3" translate="yes" xml:space="preserve">
          <source>and False elsewhere in &lt;code&gt;output&lt;/code&gt;.</source>
          <target state="translated">и False в другом месте &lt;code&gt;output&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="41290a0f5cbc0ce6a4dfe0924ac8b26a039d1f24" translate="yes" xml:space="preserve">
          <source>and concatenates them into a Tensor of shape:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c7d1a416a2e3a434f40699d9880f90f9fb160f7e" translate="yes" xml:space="preserve">
          <source>and having size</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="2223100c859ddb72353f03c35f828882929aa04b" translate="yes" xml:space="preserve">
          <source>and if &lt;code&gt;M = N&lt;/code&gt;,</source>
          <target state="translated">и если &lt;code&gt;M = N&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="1eb3d95c362b4e4d700bf804104fec0c967f459d" translate="yes" xml:space="preserve">
          <source>and process 2 prints</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="0ba895928ad073edb53326fb61cbb432a1464bec" translate="yes" xml:space="preserve">
          <source>and that &lt;code&gt;value&lt;/code&gt; has shape</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="34d19665daa7f1410ef46ef88c82079153b1d866" translate="yes" xml:space="preserve">
          <source>and then compute a normalized (x), including a small factor ({\epsilon}) for numerical stability.</source>
          <target state="translated">а затем вычислите нормализованный (x),включая малый коэффициент ({\epsilon})для числовой стабильности.</target>
        </trans-unit>
        <trans-unit id="d8047f0fdc4d1e4560c970ac0b82f51065da8044" translate="yes" xml:space="preserve">
          <source>and then compute a normalized &lt;code&gt;x_i_normalized&lt;/code&gt;, including a small factor &lt;code&gt;epsilon&lt;/code&gt; for numerical stability.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="6cc52111330674297a42724a1642fd203137a2d3" translate="yes" xml:space="preserve">
          <source>and therefore</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="78e8b25cc130b65509b44b60a2a5f53ed883a7db" translate="yes" xml:space="preserve">
          <source>append(self: tensorflow.python._tf_stack.StackSummary, x: tensorflow.python._tf_stack.FrameSummary) -&amp;gt; None</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="30ff52b5b667d11b2ffe908d3a6ddb3a80cc4c30" translate="yes" xml:space="preserve">
          <source>arbitrary function</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="9aafd247e69aac8e786d351d47d5cdf462d0745f" translate="yes" xml:space="preserve">
          <source>arithmetic_optimization: Simplify arithmetic ops with common sub-expression elimination and arithmetic simplification.</source>
          <target state="translated">арифметическая_оптимизация:Упрощение арифметических операционных с общим устранением подвыражений и арифметическим упрощением.</target>
        </trans-unit>
        <trans-unit id="25c002c4154dbe462f9f8f1755f73522b0671750" translate="yes" xml:space="preserve">
          <source>array([[ 0., 0., 0.], [ 0., 0., 0.]], dtype=float32)</source>
          <target state="translated">array([[0.,0.,0.],[0.,0.]],dtype=float32)</target>
        </trans-unit>
        <trans-unit id="50893921378b303e1550a97d489bc7de28064118" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_features)&lt;/code&gt; Test samples where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="89cdb649416fd6a0dc9e7f39d49b6ab03d5879e8" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_features)&lt;/code&gt; Training samples where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="850565e7e77632b17d2cc1ddc239a6bfe2cae1b3" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples, n_outputs)&lt;/code&gt; Class probability estimates. In the case of binary classification, to match the scikit-learn API, will return an array of shape &lt;code&gt;(n_samples, 2)&lt;/code&gt; (instead of &lt;code&gt;(n_sample, 1)&lt;/code&gt; as in Keras).</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="65baf57d96f3cc1470e57342810a1de5f6a27f59" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; Class predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ae0244ecc60195106b25820595b8db35a60ed5ec" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; Predictions.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="3416fc16abdc6956ef8e2ee3753937f82806270c" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; True labels for &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c4e9940ae53eb744fbac597e70feee59a95b69b8" translate="yes" xml:space="preserve">
          <source>array-like, shape &lt;code&gt;(n_samples,)&lt;/code&gt; or &lt;code&gt;(n_samples, n_outputs)&lt;/code&gt; True labels for &lt;code&gt;x&lt;/code&gt;.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c0c679f2bbcaf59c6d5d58d588516277aa10113f" translate="yes" xml:space="preserve">
          <source>as cpu and gpu are mutually exclusive. All entries are optional.</source>
          <target state="translated">так как КПП и ГПУ взаимно исключают друг друга.Все записи являются необязательными.</target>
        </trans-unit>
        <trans-unit id="d81b6defc8e7983d824c066efff71d103284c806" translate="yes" xml:space="preserve">
          <source>as inputs.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="307d5c7893e1f246cb5e563745a0402addd02464" translate="yes" xml:space="preserve">
          <source>assertSameElements([1, 1, 1, 0, 0, 0], [0, 1]) # Doesn't raise an AssertionError</source>
          <target state="translated">assertSameElements([1,1,1,0,0,0],[0,1])#Не поднимает ошибку AssertionError</target>
        </trans-unit>
        <trans-unit id="2454abb84d63a230ebc92ebe78cf3aff74dea1e0" translate="yes" xml:space="preserve">
          <source>assertSetEqual uses ducktyping to support different types of sets, and is optimized for sets specifically (parameters must support a difference method).</source>
          <target state="translated">assertSetEqual использует утконос для поддержки различных типов множеств и оптимизирован специально для множеств (параметры должны поддерживать разностный метод).</target>
        </trans-unit>
        <trans-unit id="223c6148b033dfedd56732627314f568565b952f" translate="yes" xml:space="preserve">
          <source>assertTotallyOrdered will check that instances can be ordered correctly. For example,</source>
          <target state="translated">assertTotallyOrdered проверит,что экземпляры могут быть заказаны правильно.Например,</target>
        </trans-unit>
        <trans-unit id="260d4f1366ba09adb6172ca8fd634126e0e09014" translate="yes" xml:space="preserve">
          <source>associative container. Elements are ordered by key.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="88d718f8abfa216a9d9fcc60c2c44acc25a8cb82" translate="yes" xml:space="preserve">
          <source>at &lt;code&gt;ckpt_path&lt;/code&gt; and potentially reorders its rows and columns using the specified remappings.</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="b644d3d1649aa456171b6c0036601fd209ffbd9d" translate="yes" xml:space="preserve">
          <source>at the end of session</source>
          <target state="new"/>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
