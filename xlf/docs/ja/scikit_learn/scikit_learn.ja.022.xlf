<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="21ade7db23177cbafdee1241d820ab218814e247" translate="yes" xml:space="preserve">
          <source>There are two ways to specify multiple scoring metrics for the &lt;code&gt;scoring&lt;/code&gt; parameter:</source>
          <target state="translated">&lt;code&gt;scoring&lt;/code&gt; パラメータに複数のスコアリングメトリックを指定するには、2つの方法があります。</target>
        </trans-unit>
        <trans-unit id="c9e248c64205afb9beabc74d09eccb0781bdceea" translate="yes" xml:space="preserve">
          <source>There exist several strategies to perform Bayesian ridge regression. This implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where updates of the regularization parameters are done as suggested in (MacKay, 1992). Note that according to A New View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these update rules do not guarantee that the marginal likelihood is increasing between two consecutive iterations of the optimization.</source>
          <target state="translated">ベイズ式リッジ回帰を実行するための戦略がいくつか存在する.この実装は、(MacKay,1992)で提案されているように正則化パラメータの更新が行われる(Tipping,2001)の付録Aで説明されているアルゴリズムに基づいている。A New View of Automatic Relevance Determination (Wipf and Nagarajan,2008)によると、これらの更新規則は、最適化の2回の連続した反復の間に限界尤度が増加することを保証しないことに注意されたい。</target>
        </trans-unit>
        <trans-unit id="cdf4947857438b0c51097ba679415b8309e576f2" translate="yes" xml:space="preserve">
          <source>There exists two types of MDS algorithm: metric and non metric. In the scikit-learn, the class &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; implements both. In Metric MDS, the input similarity matrix arises from a metric (and thus respects the triangular inequality), the distances between output two points are then set to be as close as possible to the similarity or dissimilarity data. In the non-metric version, the algorithms will try to preserve the order of the distances, and hence seek for a monotonic relationship between the distances in the embedded space and the similarities/dissimilarities.</source>
          <target state="translated">MDSアルゴリズムには、メトリックと非メトリックの2つのタイプがあります。scikit-learnでは、&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;クラスが両方を実装します。メトリックMDSでは、入力類似度行列はメトリックから生じ（したがって、三角形の不等式を尊重します）、出力の2点間の距離は、類似度または非類似度のデータにできるだけ近くなるように設定されます。非メトリックバージョンでは、アルゴリズムは距離の順序を維持しようとするため、埋め込み空間の距離と類似性/非類似性の間の単調な関係を求めます。</target>
        </trans-unit>
        <trans-unit id="9e945ec56932f8495741411aac1ef0391f41ea70" translate="yes" xml:space="preserve">
          <source>There is absolutely no guarantee of recovering a ground truth. First, choosing the right number of clusters is hard. Second, the algorithm is sensitive to initialization, and can fall into local minima, although scikit-learn employs several tricks to mitigate this issue.</source>
          <target state="translated">根拠のある真実を回収できる保証は絶対にありません。第一に、正しいクラスタ数を選択するのは難しいです。第二に、アルゴリズムは初期化に敏感であり、ローカルミニマムに陥る可能性があります。</target>
        </trans-unit>
        <trans-unit id="a5fa0b690cccf03ea1d32deadc1c15c3039ee96d" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparseで&lt;/a&gt;サポートされている形式のマトリックスで指定されたスパースデータの組み込みサポートがあります。ただし、最大の効率を得るには、&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrixで&lt;/a&gt;定義されているCSRマトリックス形式を使用します。</target>
        </trans-unit>
        <trans-unit id="46a0af0f073c85f45d179011b96dd0c21ed6963a" translate="yes" xml:space="preserve">
          <source>There is built-in support for sparse data given in any matrix in a format supported by &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparse&lt;/a&gt;. For maximum efficiency, however, use the CSR matrix format as defined in &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrix&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;scipy.sparseで&lt;/a&gt;サポートされている形式で、任意の行列で指定されたスパースデータのサポートが組み込まれています。ただし、効率を最大化するには、&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html&quot;&gt;scipy.sparse.csr_matrixで&lt;/a&gt;定義されているCSRマトリックス形式を使用します。</target>
        </trans-unit>
        <trans-unit id="7bf90eed7a42877d9e674dd4cae64f5ef3af07a9" translate="yes" xml:space="preserve">
          <source>There is no general rule to select an alpha parameter for recovery of non-zero coefficients. It can by set by cross-validation (&lt;code&gt;LassoCV&lt;/code&gt; or &lt;code&gt;LassoLarsCV&lt;/code&gt;), though this may lead to under-penalized models: including a small number of non-relevant variables is not detrimental to prediction score. BIC (&lt;code&gt;LassoLarsIC&lt;/code&gt;) tends, on the opposite, to set high values of alpha.</source>
          <target state="translated">ゼロ以外の係数を回復するためのアルファパラメーターを選択する一般的な規則はありません。クロス検証（ &lt;code&gt;LassoCV&lt;/code&gt; または &lt;code&gt;LassoLarsCV&lt;/code&gt; ）によって設定できますが、これはペナルティが不十分なモデルにつながる可能性があります。関連性のない変数を少数含めても、予測スコアに悪影響はありません。 BIC（ &lt;code&gt;LassoLarsIC&lt;/code&gt; ）は、逆にアルファの値を高く設定する傾向があります。</target>
        </trans-unit>
        <trans-unit id="ff0ab54a4c7a8a1cf35484dbae4d9dce95d5c026" translate="yes" xml:space="preserve">
          <source>There might be a difference in the scores obtained between &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;solver=liblinear&lt;/code&gt; or &lt;code&gt;LinearSVC&lt;/code&gt; and the external liblinear library directly, when &lt;code&gt;fit_intercept=False&lt;/code&gt; and the fit &lt;code&gt;coef_&lt;/code&gt; (or) the data to be predicted are zeroes. This is because for the sample(s) with &lt;code&gt;decision_function&lt;/code&gt; zero, &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;LinearSVC&lt;/code&gt; predict the negative class, while liblinear predicts the positive class. Note that a model with &lt;code&gt;fit_intercept=False&lt;/code&gt; and having many samples with &lt;code&gt;decision_function&lt;/code&gt; zero, is likely to be a underfit, bad model and you are advised to set &lt;code&gt;fit_intercept=True&lt;/code&gt; and increase the intercept_scaling.</source>
          <target state="translated">間で得られたスコアに差がある場合があります&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;で &lt;code&gt;solver=liblinear&lt;/code&gt; または &lt;code&gt;LinearSVC&lt;/code&gt; とき、直接外部liblinearライブラリ &lt;code&gt;fit_intercept=False&lt;/code&gt; とフィット &lt;code&gt;coef_&lt;/code&gt; （または）データがゼロをしていると予測されます。有する試料（S）のためだからである &lt;code&gt;decision_function&lt;/code&gt; ゼロ、&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;および &lt;code&gt;LinearSVC&lt;/code&gt; は liblinearが正のクラスを予測しながら、負のクラスを予測します。モデルのことを注意 &lt;code&gt;fit_intercept=False&lt;/code&gt; として多くのサンプル持つ &lt;code&gt;decision_function&lt;/code&gt; ゼロは、underfit、悪いモデルである可能性が高いですし、セットすることをお勧めします &lt;code&gt;fit_intercept=True&lt;/code&gt; にして、intercept_scalingを増やします。</target>
        </trans-unit>
        <trans-unit id="4a4216d2986ca1c413a45927f7f8dc07ca811204" translate="yes" xml:space="preserve">
          <source>Therefore, a logarithmic (&lt;code&gt;np.log1p&lt;/code&gt;) and an exponential function (&lt;code&gt;np.expm1&lt;/code&gt;) will be used to transform the targets before training a linear regression model and using it for prediction.</source>
          <target state="translated">したがって、線形回帰モデルをトレーニングして予測に使用する前に、対数（ &lt;code&gt;np.log1p&lt;/code&gt; ）と指数関数（ &lt;code&gt;np.expm1&lt;/code&gt; ）を使用してターゲットを変換します。</target>
        </trans-unit>
        <trans-unit id="6912f2dbecf0d873a7ad1021b00fc015a0232427" translate="yes" xml:space="preserve">
          <source>These are transformers that are not intended to be used on features, only on supervised learning targets. See also &lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;Transforming target in regression&lt;/a&gt; if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.</source>
          <target state="translated">これらは、監視対象の学習ターゲットでのみ機能で使用することを目的としたトランスフォーマーではありません。学習のために予測ターゲットを変換したいが、元の（変換されていない）空間でモデルを評価する場合は&lt;a href=&quot;compose#transformed-target-regressor&quot;&gt;、回帰でのターゲットの変換&lt;/a&gt;も参照してください。</target>
        </trans-unit>
        <trans-unit id="9c615abfdf912d61f49e70314e0bacb6d3789d48" translate="yes" xml:space="preserve">
          <source>These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.</source>
          <target state="translated">これらの分類器は,簡単に計算できる閉じた形の解を持ち,本質的に多クラスであり,実際にうまく動作することが証明されており,調整するハイパーパラメタがないことが魅力的です.</target>
        </trans-unit>
        <trans-unit id="fde55c65b8197fd0cbaa58300d107768af9ed389" translate="yes" xml:space="preserve">
          <source>These constraint are useful to impose a certain local structure, but they also make the algorithm faster, especially when the number of the samples is high.</source>
          <target state="translated">これらの制約は、特定の局所構造を課すのに便利ですが、特にサンプル数が多い場合にはアルゴリズムの高速化にもつながります。</target>
        </trans-unit>
        <trans-unit id="ebd210a6b7ae21f6cafc3c41203edaaa46e25728" translate="yes" xml:space="preserve">
          <source>These datasets are useful to quickly illustrate the behavior of the various algorithms implemented in scikit-learn. They are however often too small to be representative of real world machine learning tasks.</source>
          <target state="translated">これらのデータセットは、scikit-learnで実装された様々なアルゴリズムの動作を素早く説明するのに便利です。しかし、これらのデータセットは現実の機械学習タスクを代表するには小さすぎます。</target>
        </trans-unit>
        <trans-unit id="8d2ab26191aa60fb366e6a03a6fce9c7d01208ba" translate="yes" xml:space="preserve">
          <source>These environment variables should be set before importing scikit-learn.</source>
          <target state="translated">これらの環境変数は scikit-learn をインポートする前に設定しておく必要があります。</target>
        </trans-unit>
        <trans-unit id="b821932825baa77bb11f8b1f95c8cc38b1d75bf5" translate="yes" xml:space="preserve">
          <source>These estimators are called similarly to their counterparts, with &amp;lsquo;CV&amp;rsquo; appended to their name.</source>
          <target state="translated">これらの推定量は、対応するものと同様に呼び出され、名前に「CV」が追加されます。</target>
        </trans-unit>
        <trans-unit id="4895efc31f112ba17d5e8de5c88b9b84cbaac29a" translate="yes" xml:space="preserve">
          <source>These estimators are described in more detail below in &lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;Histogram-Based Gradient Boosting&lt;/a&gt;.</source>
          <target state="translated">これらの推定量については、以下の&lt;a href=&quot;#histogram-based-gradient-boosting&quot;&gt;ヒストグラムベースの勾配ブースティング&lt;/a&gt;で詳しく説明します。</target>
        </trans-unit>
        <trans-unit id="31d7d129bfc794bb111166051ddf1fbfd1e21090" translate="yes" xml:space="preserve">
          <source>These estimators are still &lt;strong&gt;experimental&lt;/strong&gt;: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="translated">これらの推定量はまだ&lt;strong&gt;実験&lt;/strong&gt;段階です。それらの予測とAPIは、非推奨のサイクルなしで変更される可能性があります。それらを使用するには、 &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt; を明示的にインポートする必要があります。</target>
        </trans-unit>
        <trans-unit id="bd57beb09d61462992a46fc07ecdff56e4d9c660" translate="yes" xml:space="preserve">
          <source>These estimators fit multiple regression problems (or tasks) jointly, while inducing sparse coefficients. While the inferred coefficients may differ between the tasks, they are constrained to agree on the features that are selected (non-zero coefficients).</source>
          <target state="translated">これらの推定器は、疎な係数を誘導しながら、複数の回帰問題(またはタスク)を共同で適合させる。推定された係数はタスク間で異なることがありますが、選択された特徴(非ゼロ係数)に一致するように制約されています。</target>
        </trans-unit>
        <trans-unit id="fac22fa1718df2cc93fd78246f559caa4e598cf3" translate="yes" xml:space="preserve">
          <source>These examples illustrate the main features of the releases of scikit-learn.</source>
          <target state="translated">これらの例は、scikit-learnのリリースの主な特徴を示しています。</target>
        </trans-unit>
        <trans-unit id="8bef6d4f1ba3e716c219b98d63998eb428a7438d" translate="yes" xml:space="preserve">
          <source>These families of algorithms are useful to find linear relations between two multivariate datasets: the &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; arguments of the &lt;code&gt;fit&lt;/code&gt; method are 2D arrays.</source>
          <target state="translated">これらのアルゴリズムファミリーは、2つの多変量データセット間の線形関係を見つけるのに役立ちます &lt;code&gt;fit&lt;/code&gt; メソッドの &lt;code&gt;X&lt;/code&gt; および &lt;code&gt;Y&lt;/code&gt; 引数は2D配列です。</target>
        </trans-unit>
        <trans-unit id="1f2f0c6c7df23095dba3fa00aa5227521de2ff47" translate="yes" xml:space="preserve">
          <source>These fast estimators first bin the input samples &lt;code&gt;X&lt;/code&gt; into integer-valued bins (typically 256 bins) which tremendously reduces the number of splitting points to consider, and allows the algorithm to leverage integer-based data structures (histograms) instead of relying on sorted continuous values when building the trees. The API of these estimators is slightly different, and some of the features from &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are not yet supported, for instance some loss functions.</source>
          <target state="translated">これらの高速推定器は、最初に入力サンプル &lt;code&gt;X&lt;/code&gt; を整数値のビン（通常は256ビン）にビニングします。これにより、考慮する分割ポイントの数が大幅に削減され、アルゴリズムは、並べ替えられた連続に依存する代わりに、整数ベースのデータ構造（ヒストグラム）を活用できます。木を構築するときの値。これらの推定器のAPIはわずかに異なり、&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; の&lt;/a&gt;一部の機能、たとえば一部の損失関数はまだサポートされていません。</target>
        </trans-unit>
        <trans-unit id="e90c7c20b495d718d6ee1761b52661a07d31f2ac" translate="yes" xml:space="preserve">
          <source>These figures aid in illustrating how a point cloud can be very flat in one direction&amp;ndash;which is where PCA comes in to choose a direction that is not flat.</source>
          <target state="translated">これらの図は、ポイントクラウドを一方向に非常に平坦にする方法を示しています。これは、PCAが平坦でない方向を選択する場所です。</target>
        </trans-unit>
        <trans-unit id="5b3c06102d71e9aa21ce3635f214fb7544bfe93e" translate="yes" xml:space="preserve">
          <source>These functions have an &lt;code&gt;multioutput&lt;/code&gt; keyword argument which specifies the way the scores or losses for each individual target should be averaged. The default is &lt;code&gt;'uniform_average'&lt;/code&gt;, which specifies a uniformly weighted mean over outputs. If an &lt;code&gt;ndarray&lt;/code&gt; of shape &lt;code&gt;(n_outputs,)&lt;/code&gt; is passed, then its entries are interpreted as weights and an according weighted average is returned. If &lt;code&gt;multioutput&lt;/code&gt; is &lt;code&gt;'raw_values'&lt;/code&gt; is specified, then all unaltered individual scores or losses will be returned in an array of shape &lt;code&gt;(n_outputs,)&lt;/code&gt;.</source>
          <target state="translated">これらの関数には複数の &lt;code&gt;multioutput&lt;/code&gt; キーワード引数があり、個々のターゲットのスコアまたは損失を平均化する方法を指定します。デフォルトは &lt;code&gt;'uniform_average'&lt;/code&gt; で、出力の均一な加重平均を指定します。場合 &lt;code&gt;ndarray&lt;/code&gt; 形状の &lt;code&gt;(n_outputs,)&lt;/code&gt; 渡され、そのエントリが重みとして解釈され、係る加重平均が返されます。場合 &lt;code&gt;multioutput&lt;/code&gt; ある &lt;code&gt;'raw_values'&lt;/code&gt; 指定されている、すべての不変の個々のスコアまたは損失は、形状の配列に返される &lt;code&gt;(n_outputs,)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8f744234c4fef479ca52103694dddbbb39569d67" translate="yes" xml:space="preserve">
          <source>These functions return a tuple &lt;code&gt;(X, y)&lt;/code&gt; consisting of a &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy array &lt;code&gt;X&lt;/code&gt; and an array of length &lt;code&gt;n_samples&lt;/code&gt; containing the targets &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">これらの関数は、 &lt;code&gt;n_samples&lt;/code&gt; * &lt;code&gt;n_features&lt;/code&gt; numpy配列 &lt;code&gt;X&lt;/code&gt; と、ターゲット &lt;code&gt;y&lt;/code&gt; を含む長さ &lt;code&gt;n_samples&lt;/code&gt; の配列で構成されるタプル &lt;code&gt;(X, y)&lt;/code&gt; 返します。</target>
        </trans-unit>
        <trans-unit id="7ea4b087a47ece8eb67eda1c13d069b3e5f40d70" translate="yes" xml:space="preserve">
          <source>These generators produce a matrix of features and corresponding discrete targets.</source>
          <target state="translated">これらの生成器は、特徴量の行列とそれに対応する離散ターゲットを生成します。</target>
        </trans-unit>
        <trans-unit id="ff830f502c3a30a0f4f3f842eff62f7849f20cad" translate="yes" xml:space="preserve">
          <source>These histogram-based estimators can be &lt;strong&gt;orders of magnitude faster&lt;/strong&gt; than &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; when the number of samples is larger than tens of thousands of samples.</source>
          <target state="translated">これらのヒストグラムベースの推定量は、サンプル数が数万サンプルを超える場合、&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;&lt;strong&gt;より&lt;/strong&gt;も&lt;strong&gt;桁違いに高速に&lt;/strong&gt;なる可能性があります。</target>
        </trans-unit>
        <trans-unit id="7870342f67a34d74383fe781d3e91593569275ef" translate="yes" xml:space="preserve">
          <source>These images how similar features are merged together using feature agglomeration.</source>
          <target state="translated">これらの画像は、特徴の凝集を利用して類似した特徴をどのように結合しているかを示しています。</target>
        </trans-unit>
        <trans-unit id="2f6550a6d877a222d311c7f7d2e4efbab68b15f3" translate="yes" xml:space="preserve">
          <source>These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;), but also to build precomputed kernels, or similarity matrices.</source>
          <target state="translated">これらの行列を使用して、ウォードクラスタリング（&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;階層的クラスタリング&lt;/a&gt;）などの接続性情報を使用する推定器に接続性を課すことができますが、事前計算されたカーネルまたは類似性行列を構築することもできます。</target>
        </trans-unit>
        <trans-unit id="f1476efa19922a5a7b34be362fc1e06a3ae81118" translate="yes" xml:space="preserve">
          <source>These metrics &lt;strong&gt;require the knowledge of the ground truth classes&lt;/strong&gt; while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).</source>
          <target state="translated">これらのメトリック&lt;strong&gt;は、グラウンドトゥルースクラスの知識を必要とし&lt;/strong&gt;ます&lt;strong&gt;が、&lt;/strong&gt;実際にはほとんど利用できません。または、教師付き学習設定のように、人間のアノテーターが手動で割り当てる必要があります。</target>
        </trans-unit>
        <trans-unit id="102278a50cfd01c3d7a2cbdc18b76a5ce6b39772" translate="yes" xml:space="preserve">
          <source>These models allow for response variables to have error distributions other than a normal distribution:</source>
          <target state="translated">これらのモデルは、応答変数が正規分布以外の誤差分布を持つことを可能にします。</target>
        </trans-unit>
        <trans-unit id="1b78634dcd7b938ef7f64bb3d2756751845f06a1" translate="yes" xml:space="preserve">
          <source>These objects take as input a scoring function that returns univariate scores and p-values (or only scores for &lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt;&lt;code&gt;SelectKBest&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt;&lt;code&gt;SelectPercentile&lt;/code&gt;&lt;/a&gt;):</source>
          <target state="translated">これらのオブジェクトは、一変量スコアとp値（または&lt;a href=&quot;generated/sklearn.feature_selection.selectkbest#sklearn.feature_selection.SelectKBest&quot;&gt; &lt;code&gt;SelectKBest&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.feature_selection.selectpercentile#sklearn.feature_selection.SelectPercentile&quot;&gt; &lt;code&gt;SelectPercentile&lt;/code&gt; の&lt;/a&gt;スコアのみ）を返すスコアリング関数を入力として受け取ります。</target>
        </trans-unit>
        <trans-unit id="7d570e698357345b9d25fb0f909251adbc540e40" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="translated">これらのパラメータは、属性を介してアクセスすることができ &lt;code&gt;dual_coef_&lt;/code&gt; 、 -の違いを保持する\（\ alpha_i ^ * \ \ alpha_i） &lt;code&gt;support_vectors_&lt;/code&gt; サポートベクトルを保持しており、 &lt;code&gt;intercept_&lt;/code&gt; 独立した用語\（Bを\）を保持します</target>
        </trans-unit>
        <trans-unit id="fc9887aaf0c2ed20eb0f603451b50a8d7e26af7c" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the attributes &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(b\)</source>
          <target state="translated">これらのパラメーターには、積\（y_i \ alpha_i \）を保持する属性 &lt;code&gt;dual_coef_&lt;/code&gt; 、サポートベクターを保持する &lt;code&gt;support_vectors_&lt;/code&gt; 、および独立項\（b \）を保持する &lt;code&gt;intercept_&lt;/code&gt; を介してアクセスできます。</target>
        </trans-unit>
        <trans-unit id="3403571e1d1dd77b054e08b8e749a4d9b5c4d316" translate="yes" xml:space="preserve">
          <source>These parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the difference \(\alpha_i - \alpha_i^*\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\)</source>
          <target state="translated">これらのパラメータは、メンバーを介してアクセスすることができ &lt;code&gt;dual_coef_&lt;/code&gt; 、 - （\ alpha_i ^ * \ \ alpha_i）の違いを保持する\ &lt;code&gt;support_vectors_&lt;/code&gt; サポートベクトルを保持しており、 &lt;code&gt;intercept_&lt;/code&gt; 独立した用語\（\ロー\）を保持しています</target>
        </trans-unit>
        <trans-unit id="9254aef96f1c8727db185406da2727e74822dda9" translate="yes" xml:space="preserve">
          <source>These quantities are also related to the (\(F_1\)) score, which is defined as the harmonic mean of precision and recall.</source>
          <target state="translated">これらの量は、精度とリコールの調和平均として定義される(F\(F_1_1))スコアにも関連しています。</target>
        </trans-unit>
        <trans-unit id="8ec6209edcb97e57d934d74900289c4f7467ca16" translate="yes" xml:space="preserve">
          <source>These represent the 14 features measured at each point of the map grid. The latitude/longitude values for the grid are discussed below. Missing data is represented by the value -9999.</source>
          <target state="translated">これらは、地図グリッドの各点で測定された 14 の特徴を表している。グリッドの緯度・経度の値は以下で説明します。不足しているデータは-9999で表されます。</target>
        </trans-unit>
        <trans-unit id="e11ef00d62661e429b4b798a345a9c8d62a348e6" translate="yes" xml:space="preserve">
          <source>These steps are performed either a maximum number of times (&lt;code&gt;max_trials&lt;/code&gt;) or until one of the special stop criteria are met (see &lt;code&gt;stop_n_inliers&lt;/code&gt; and &lt;code&gt;stop_score&lt;/code&gt;). The final model is estimated using all inlier samples (consensus set) of the previously determined best model.</source>
          <target state="translated">これらのステップは、最大回数（ &lt;code&gt;max_trials&lt;/code&gt; ）、または特別な停止基準の1つが満たされるまで実行されます（ &lt;code&gt;stop_n_inliers&lt;/code&gt; および &lt;code&gt;stop_score&lt;/code&gt; を参照）。最終モデルは、以前に決定された最良のモデルのすべてのインライアサンプル（コンセンサスセット）を使用して推定されます。</target>
        </trans-unit>
        <trans-unit id="ffccb4ceb37928160a8178b1e93c390573c106cb" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">これらの3つの距離は、ベータ発散ファミリの特殊なケースであり、それぞれ\（\ beta = 2、1、0 \）&lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;6&lt;/a&gt;です。ベータダイバージェンスは次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="eff89650d9905b662c6df80228e926f2f144c91b" translate="yes" xml:space="preserve">
          <source>These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively &lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;. The beta-divergence are defined by :</source>
          <target state="translated">これらの3つの距離は、それぞれ\（\ beta = 2、1、0 \）である&amp;beta;分岐ファミリーの特殊なケースです&lt;a href=&quot;#id15&quot; id=&quot;id8&quot;&gt;[6]&lt;/a&gt;。ベータダイバージェンスは次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="100dafc268c3e9d0b628da1715aed2440b14ba32" translate="yes" xml:space="preserve">
          <source>These throughputs are achieved on a single process. An obvious way to increase the throughput of your application is to spawn additional instances (usually processes in Python because of the &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GIL&lt;/a&gt;) that share the same model. One might also add machines to spread the load. A detailed explanation on how to achieve this is beyond the scope of this documentation though.</source>
          <target state="translated">これらのスループットは、単一のプロセスで実現されます。アプリケーションのスループットを向上させる明白な方法は、同じモデルを共有する追加のインスタンス（通常は&lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;GILの&lt;/a&gt;ためにPythonでプロセス）を生成することです。負荷を分散するためにマシンを追加することもできます。ただし、これを実現する方法の詳細な説明は、このドキュメントの範囲を超えています。</target>
        </trans-unit>
        <trans-unit id="b826ad64b72daa0458c9fdfb2862fce60b4db70b" translate="yes" xml:space="preserve">
          <source>They also have built-in support for missing values, which avoids the need for an imputer.</source>
          <target state="translated">また、欠損値のサポートも組み込まれているので、インパータの必要性を回避することができます。</target>
        </trans-unit>
        <trans-unit id="e63971597c4df5f2dc150f90b566e1219b6a632a" translate="yes" xml:space="preserve">
          <source>They are not sparse, i.e., they use the whole samples/features information to perform the prediction.</source>
          <target state="translated">彼らはスパースではない、すなわち、予測を実行するためにサンプル/特徴量全体の情報を使用しています。</target>
        </trans-unit>
        <trans-unit id="26f84bd6fe103542912ebb1fb588d29515a2fd6d" translate="yes" xml:space="preserve">
          <source>They can be loaded using the following functions:</source>
          <target state="translated">これらは、以下の関数を使用してロードすることができます。</target>
        </trans-unit>
        <trans-unit id="f7ddbd9f45ee3f137b5eb656135dce7584351da0" translate="yes" xml:space="preserve">
          <source>They expose a &lt;code&gt;split&lt;/code&gt; method which accepts the input dataset to be split and yields the train/test set indices for each iteration of the chosen cross-validation strategy.</source>
          <target state="translated">これらは、 &lt;code&gt;split&lt;/code&gt; する入力データセットを受け入れ、選択された交差検証戦略の各反復のトレーニング/テストセットインデックスを生成する分割メソッドを公開します。</target>
        </trans-unit>
        <trans-unit id="03bbcc98e1d567dd0afc112fe378a99851c98226" translate="yes" xml:space="preserve">
          <source>They lose efficiency in high dimensional spaces &amp;ndash; namely when the number of features exceeds a few dozens.</source>
          <target state="translated">それらは高次元空間で効率を失います&amp;ndash;つまり、特徴の数が数十を超えるとき。</target>
        </trans-unit>
        <trans-unit id="a673690dbc33eee17ee6f3995f817097918876ff" translate="yes" xml:space="preserve">
          <source>This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).</source>
          <target state="translated">このスケーラーは、中央値を削除し、分位範囲(デフォルトはIQR:Interquartile Range)に応じてデータをスケーリングします。IQRは、第1分位(25分位)と第3分位(75分位)の間の範囲です。</target>
        </trans-unit>
        <trans-unit id="d9994b645c162ae9e80a2c6bc1c81390f2e92325" translate="yes" xml:space="preserve">
          <source>This Warning is used in meta estimators GridSearchCV and RandomizedSearchCV and the cross-validation helper function cross_val_score to warn when there is an error while fitting the estimator.</source>
          <target state="translated">この警告は、メタ推定器GridSearchCVおよびRandomizedSearchCV、およびクロスバリデーションヘルパー関数 cross_val_scoreで使用され、推定器のフィッティング中にエラーが発生した場合に警告を発します。</target>
        </trans-unit>
        <trans-unit id="7f5e3d23312509826c13f1663d34b7e7912ac4af" translate="yes" xml:space="preserve">
          <source>This algorithm can be viewed as an instance or data reduction method, since it reduces the input data to a set of subclusters which are obtained directly from the leaves of the CFT. This reduced data can be further processed by feeding it into a global clusterer. This global clusterer can be set by &lt;code&gt;n_clusters&lt;/code&gt;. If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the subclusters from the leaves are directly read off, otherwise a global clustering step labels these subclusters into global clusters (labels) and the samples are mapped to the global label of the nearest subcluster.</source>
          <target state="translated">このアルゴリズムは、入力データをCFTのリーフから直接取得されるサブクラスターのセットに削減するため、インスタンスまたはデータ削減方法と見なすことができます。この削減されたデータは、グローバルクラスターにフィードすることでさらに処理できます。このグローバルクラスタは &lt;code&gt;n_clusters&lt;/code&gt; で設定できます。 &lt;code&gt;n_clusters&lt;/code&gt; がNoneに設定されている場合、リーフからのサブクラスターが直接読み取られます。それ以外の場合、グローバルクラスタリングステップはこれらのサブクラスターをグローバルクラスター（ラベル）にラベル付けし、サンプルは最も近いサブクラスターのグローバルラベルにマッピングされます。</target>
        </trans-unit>
        <trans-unit id="895ec6bb1e64f58ea59b9ae781fa620e703125a9" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">このアルゴリズムには、文献のいくつかの研究が含まれています。データセットのランダムなサブセットがサンプルのランダムなサブセットとして描画される場合、このアルゴリズムは貼り付けとして知られています&lt;a href=&quot;#r4d113ba76fc0-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。サンプルを交換して採取する場合、その方法はバギングとして知られています&lt;a href=&quot;#r4d113ba76fc0-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;。データセットのランダムサブセットがフィーチャのランダムサブセットとして描画される場合、この方法はランダムサブスペースとして知られています&lt;a href=&quot;#r4d113ba76fc0-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;。最後に、ベースエスティメータがサンプルと機能の両方のサブセットに基づいて構築される場合、この方法はランダムパッチとして知られています&lt;a href=&quot;#r4d113ba76fc0-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="870122c945d57891e89c2ba931542331f1b4afdb" translate="yes" xml:space="preserve">
          <source>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. If samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;.</source>
          <target state="translated">このアルゴリズムには、文献のいくつかの研究が含まれています。データセットのランダムなサブセットがサンプルのランダムなサブセットとして描画される場合、このアルゴリズムは貼り付けとして知られています&lt;a href=&quot;#rb1846455d0e5-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。サンプルを交換して採取する場合、その方法はバギングとして知られています&lt;a href=&quot;#rb1846455d0e5-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;。データセットのランダムサブセットがフィーチャのランダムサブセットとして描画される場合、この方法はランダムサブスペースとして知られています&lt;a href=&quot;#rb1846455d0e5-3&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;。最後に、ベースエスティメータがサンプルと機能の両方のサブセットに基づいて構築される場合、この方法はランダムパッチとして知られています&lt;a href=&quot;#rb1846455d0e5-4&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="866e774dfaaba96a720c3090067c49c13cac935f" translate="yes" xml:space="preserve">
          <source>This algorithm finds a (usually very good) approximate truncated singular value decomposition using randomization to speed up the computations. It is particularly fast on large matrices on which you wish to extract only a small number of components. In order to obtain further speed up, &lt;code&gt;n_iter&lt;/code&gt; can be set &amp;lt;=2 (at the cost of loss of precision).</source>
          <target state="translated">このアルゴリズムは、計算を高速化するためにランダム化を使用して、（通常は非常に良い）切り捨てられた特異値分解を見つけます。少数のコンポーネントのみを抽出したい大きな行列では特に高速です。さらに高速化するには、 &lt;code&gt;n_iter&lt;/code&gt; を&amp;lt;= 2に設定できます（精度が低下します）。</target>
        </trans-unit>
        <trans-unit id="c5eff13aab5e02ba6e328f932a803b28ba41ee60" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size * n_features&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.</source>
          <target state="translated">このアルゴリズムは、 &lt;code&gt;batch_size * n_features&lt;/code&gt; オーダーで一定のメモリの複雑さを持ち、ファイル全体をメモリにロードせずにnp.memmapファイルの使用を可能にします。スパース行列の場合、入力は（平均を減算できるようにするために）バッチで密行列に変換されます。これにより、密行列全体を一度に保存する必要がなくなります。</target>
        </trans-unit>
        <trans-unit id="77977d31f5357c834112cbb27bbc98b5c64c10d7" translate="yes" xml:space="preserve">
          <source>This algorithm has constant memory complexity, on the order of &lt;code&gt;batch_size&lt;/code&gt;, enabling use of np.memmap files without loading the entire file into memory.</source>
          <target state="translated">このアルゴリズムは、 &lt;code&gt;batch_size&lt;/code&gt; のオーダーで一定のメモリ複雑度を持ち、ファイル全体をメモリにロードせずにnp.memmapファイルを使用できるようにします。</target>
        </trans-unit>
        <trans-unit id="f443979a9a019e4d6947465617b7828e98c7b59f" translate="yes" xml:space="preserve">
          <source>This algorithm is illustrated below.</source>
          <target state="translated">このアルゴリズムを以下に説明します。</target>
        </trans-unit>
        <trans-unit id="9586aed3b1a5b6a2c44b32af5cc0558b6ad496a6" translate="yes" xml:space="preserve">
          <source>This algorithm solves the normalized cut for k=2: it is a normalized spectral clustering.</source>
          <target state="translated">このアルゴリズムは、k=2のための正規化カットを解く:それは正規化されたスペクトルクラスタリングである。</target>
        </trans-unit>
        <trans-unit id="01c65a021c885e4e00baaaa5c6652a314a97daa3" translate="yes" xml:space="preserve">
          <source>This algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues.</source>
          <target state="translated">このアルゴリズムは、外部からの手がかりがない場合に使用するコンポーネントの数を決定するために、ホールドアウトされたデータや情報の理論的な基準を必要とし、常にアクセス可能なすべてのコンポーネントを使用します。</target>
        </trans-unit>
        <trans-unit id="ddf04fe856314e7dd4ddddf49f4086029e04d842" translate="yes" xml:space="preserve">
          <source>This allows better model selection than probabilistic PCA in the presence of heteroscedastic noise:</source>
          <target state="translated">これにより、異種ノイズの存在下では、確率的PCAよりも優れたモデル選択が可能になります。</target>
        </trans-unit>
        <trans-unit id="3307a2458ebbefda8ea7fe8b898077ec4cadcf2c" translate="yes" xml:space="preserve">
          <source>This also works where final estimator is &lt;code&gt;None&lt;/code&gt;: all prior transformations are applied.</source>
          <target state="translated">これは、最終的な推定量が &lt;code&gt;None&lt;/code&gt; の場合にも機能します。以前のすべての変換が適用されます。</target>
        </trans-unit>
        <trans-unit id="c63b80512d8853cd76b24210ee07543da5c60fc4" translate="yes" xml:space="preserve">
          <source>This assumption is the base of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;Vector Space Model&lt;/a&gt; often used in text classification and clustering contexts.</source>
          <target state="translated">この仮定は、テキスト分類およびクラスタリングのコンテキストでよく使用される&lt;a href=&quot;https://en.wikipedia.org/wiki/Vector_Space_Model&quot;&gt;ベクトル空間モデルの&lt;/a&gt;ベースです。</target>
        </trans-unit>
        <trans-unit id="a8d2386009078ecaad8deb62662ebfbef6798072" translate="yes" xml:space="preserve">
          <source>This attribute is not available if &lt;code&gt;refit&lt;/code&gt; is a function.</source>
          <target state="translated">&lt;code&gt;refit&lt;/code&gt; が関数の場合、この属性は使用できません。</target>
        </trans-unit>
        <trans-unit id="8142b653ecd3322ad782e8a8807635d6c4c0325e" translate="yes" xml:space="preserve">
          <source>This calibration results in a lower log-loss. Note that an alternative would have been to increase the number of base estimators which would have resulted in a similar decrease in log-loss.</source>
          <target state="translated">このキャリブレーションの結果、ログロスが減少する。これに代わる方法として、基底推定量の数を増やすことも考えられるが、これはログロスを同様に減少させる結果になるだろう。</target>
        </trans-unit>
        <trans-unit id="3ba422e075fa10216e381bf46530abda4e719fab" translate="yes" xml:space="preserve">
          <source>This call requires the estimation of a p x q matrix, which may be an issue in high dimensional space.</source>
          <target state="translated">この呼び出しは,高次元空間では問題となるかもしれないp x q行列の推定を必要とします.</target>
        </trans-unit>
        <trans-unit id="345a3bd30c8553d3251f728b344d1bd100958670" translate="yes" xml:space="preserve">
          <source>This can be confirmed on a independent testing set with similar remarks:</source>
          <target state="translated">これは、似たような発言をした独立したテストセットで確認することができます。</target>
        </trans-unit>
        <trans-unit id="e60927eda9d0f07135f56fa39eaa1a8f1f9c2813" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#id2&quot;&gt;Ridge Regression&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the parameters \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">これは、モデルのハイパーパラメータに対して&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;情報のない事前分布&lt;/a&gt;を導入することで実行できます。&lt;a href=&quot;#id2&quot;&gt;リッジ回帰で&lt;/a&gt;使用される\（\ ell_ {2} \）正則化は、ガウス分布の下で最大の事後推定を、精度\（\ lambda ^ {-1} \）でパラメーター\（w \）よりも前に見つけることと同等です。 &lt;code&gt;lambda&lt;/code&gt; 手動で設定する代わりに、データから推定されるランダム変数として扱うことができます。</target>
        </trans-unit>
        <trans-unit id="bdd26b00d9d2e1f23dcd81c9f002391507919ff9" translate="yes" xml:space="preserve">
          <source>This can be done by introducing &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;uninformative priors&lt;/a&gt; over the hyper parameters of the model. The \(\ell_{2}\) regularization used in &lt;a href=&quot;#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the coefficients \(w\) with precision \(\lambda^{-1}\). Instead of setting &lt;code&gt;lambda&lt;/code&gt; manually, it is possible to treat it as a random variable to be estimated from the data.</source>
          <target state="translated">これは、モデルのハイパーパラメータに&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors&quot;&gt;情報のない事前分布&lt;/a&gt;を導入することで実行できます。&lt;a href=&quot;#ridge-regression&quot;&gt;リッジ回帰と分類で&lt;/a&gt;使用される\（\ ell_ {2} \）正則化は、精度\（\ lambda ^ {-1} \で係数\（w \）よりもガウス事前分布の下で最大事後推定を見つけることと同等です。 ）。 &lt;code&gt;lambda&lt;/code&gt; 手動で設定する代わりに、データから推定される確率変数として扱うことができます。</target>
        </trans-unit>
        <trans-unit id="aa181018cfeb3219e1e67073f9c58ca90a0c4faa" translate="yes" xml:space="preserve">
          <source>This can be done by using the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; utility function.</source>
          <target state="translated">これは、&lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt;ユーティリティ関数を使用して実行できます。</target>
        </trans-unit>
        <trans-unit id="821e5435b62e56a883478da64d6731f6479103d5" translate="yes" xml:space="preserve">
          <source>This can be set to a higher value than the actual number of features in any of the input files, but setting it to a lower value will cause an exception to be raised.</source>
          <target state="translated">これは、どの入力ファイルに含まれる実際の特徴量よりも高い値に設定することができますが、低い値に設定すると例外が発生します。</target>
        </trans-unit>
        <trans-unit id="4a0bd36c1ccd6d51b38a900236d58695657d5aff" translate="yes" xml:space="preserve">
          <source>This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data.</source>
          <target state="translated">このクラスでは,ガウス混合分布のパラメータに対する近似事後分布を推論することができます.データから有効成分の数を推測することができます。</target>
        </trans-unit>
        <trans-unit id="6130cf2c7564234b715447525f16ff596ebe842e" translate="yes" xml:space="preserve">
          <source>This class can be used to cross-validate time series data samples that are observed at fixed time intervals.</source>
          <target state="translated">このクラスは、一定の時間間隔で観測された時系列データサンプルのクロスバリデーションに使用することができます。</target>
        </trans-unit>
        <trans-unit id="88afb4091eb2a25b2e2017ee8508b1ff5c5ae125" translate="yes" xml:space="preserve">
          <source>This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</source>
          <target state="translated">このクラスは、データセットのさまざまなサブサンプルにランダム化された多数の決定木(別名エクストラツリー)を適合させ、平均化を使用して予測精度を向上させ、オーバーフィットを制御するメタ推定器を実装します。</target>
        </trans-unit>
        <trans-unit id="dd60f6580be8e1908408c4fbfd8d3915f46e55b1" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">このクラスは liblinear,newton-cg,sag,lbfgs オプティマイザを用いたロジスティック回帰を実装しています。newton-cg,sag,lbfgsソルバーは、L2正則化とプライマル定式化のみをサポートします。liblinearソルバーは、L1とL2の両方の正則化をサポートし、L2のペナルティに対してのみ二重定式化を行います。</target>
        </trans-unit>
        <trans-unit id="44487ffdb33876a6a42d281dea9cfa59f8e7af24" translate="yes" xml:space="preserve">
          <source>This class implements logistic regression using liblinear, newton-cg, sag of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2 regularization with primal formulation. The liblinear solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. Elastic-Net penalty is only supported by the saga solver.</source>
          <target state="translated">このクラスは liblinear,newton-cg,sag,lbfgs オプティマイザを用いたロジスティック回帰を実装しています。newton-cg,sag,lbfgsソルバーは、L2正則化とプライマル定式化のみをサポートします。liblinearソルバーは、L1とL2の両方の正則化をサポートし、L2ペナルティについてのみ二重定式化をサポートします。Elastic-Netペナルティはsagaソルバーのみサポートしています。</target>
        </trans-unit>
        <trans-unit id="350693d0493245dcbd676a8f10e001d5020f745e" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">このクラスは、「liblinear」ライブラリー、「newton-cg」、「sag」、および「lbfgs」ソルバーを使用して、正規化されたロジスティック回帰を実装します。密な入力と疎な入力の両方を処理できます。最適なパフォーマンスを得るには、Cビット配列または64ビットの浮動小数点を含むCSR行列を使用してください。他の入力フォーマットはすべて変換（およびコピー）されます。</target>
        </trans-unit>
        <trans-unit id="7a8a7622df62d8a1b619a206bf179dc5e9e851ab" translate="yes" xml:space="preserve">
          <source>This class implements regularized logistic regression using the &amp;lsquo;liblinear&amp;rsquo; library, &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers. &lt;strong&gt;Note that regularization is applied by default&lt;/strong&gt;. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).</source>
          <target state="translated">このクラスは、「liblinear」ライブラリ、「newton-cg」、「sag」、「saga」、および「lbfgs」ソルバーを使用して、正則化されたロジスティック回帰を実装します。&lt;strong&gt;正則化はデフォルトで適用されることに注意してください&lt;/strong&gt;。密な入力と疎な入力の両方を処理できます。最適なパフォーマンスを得るには、64ビットの浮動小数点数を含むC順序の配列またはCSR行列を使用します。その他の入力形式は変換（およびコピー）されます。</target>
        </trans-unit>
        <trans-unit id="2c107aea4a3526193efe1f31d97ccab92891d87f" translate="yes" xml:space="preserve">
          <source>This class implements the Graphical Lasso algorithm.</source>
          <target state="translated">このクラスはGraphical Lassoアルゴリズムを実装しています。</target>
        </trans-unit>
        <trans-unit id="456e7e6f7be68de425401d6f66fe28d8a1090538" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost-SAMME [2].</source>
          <target state="translated">このクラスは AdaBoost-SAMME として知られているアルゴリズムを実装しています [2]。</target>
        </trans-unit>
        <trans-unit id="003b6bf538c58eeda3c6fd28b21967bfd8b6c40e" translate="yes" xml:space="preserve">
          <source>This class implements the algorithm known as AdaBoost.R2 [2].</source>
          <target state="translated">このクラスは,AdaBoost.R2として知られているアルゴリズムを実装しています[2].</target>
        </trans-unit>
        <trans-unit id="63c4b52b10df12140782204ea7cf58fe0edab9de" translate="yes" xml:space="preserve">
          <source>This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.</source>
          <target state="translated">このクラスは、ディリクレ分布を用いた有限混合モデルとディリクレ過程を用いた無限混合モデルの2種類の優先順位を実装しています。実際には、ディリクレ過程の推論アルゴリズムは近似的であり、固定の最大成分数を持つ切り詰められた分布を使用します(棒切れ表現と呼ばれます)。実際に使用される成分の数は、ほとんどの場合、データに依存します。</target>
        </trans-unit>
        <trans-unit id="e15e7e7d8d04d41fdd2a4f34183baa0366e86dea" translate="yes" xml:space="preserve">
          <source>This class inherits from PLS with mode=&amp;rdquo;A&amp;rdquo; and deflation_mode=&amp;rdquo;canonical&amp;rdquo;, norm_y_weights=True and algorithm=&amp;rdquo;nipals&amp;rdquo;, but svd should provide similar results up to numerical errors.</source>
          <target state="translated">このクラスは、mode =&amp;rdquo; A&amp;rdquo;およびdeflation_mode =&amp;rdquo; canonical&amp;rdquo;、norm_y_weights = True、algorithm =&amp;rdquo; nipals&amp;rdquo;を使用してPLSから継承しますが、svdは数値エラーまで同様の結果を提供します。</target>
        </trans-unit>
        <trans-unit id="a0a1d1daa83e6ad727cb13fd589f28f37b44df20" translate="yes" xml:space="preserve">
          <source>This class inherits from both ValueError and AttributeError to help with exception handling and backward compatibility.</source>
          <target state="translated">このクラスは、例外処理と下位互換性を助けるために、ValueError と AttributeError の両方を継承します。</target>
        </trans-unit>
        <trans-unit id="d34b4e0a14d3a494edeba399329a47fb49b3ee6c" translate="yes" xml:space="preserve">
          <source>This class is a low-memory alternative to DictVectorizer and CountVectorizer, intended for large-scale (online) learning and situations where memory is tight, e.g. when running prediction code on embedded devices.</source>
          <target state="translated">このクラスは,DictVectorizerやCountVectorizerに代わる低メモリの代替クラスであり,大規模な(オンラインの)学習や,組み込み機器で予測コードを実行する場合など,メモリが逼迫している状況を想定しています.</target>
        </trans-unit>
        <trans-unit id="8e34d865883b535f68990f01a240eaab9f87f080" translate="yes" xml:space="preserve">
          <source>This class is hence suitable for use in the early steps of a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">したがって、このクラスは&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;初期段階での使用に適しています。</target>
        </trans-unit>
        <trans-unit id="eef0760dd6d25fd731b9abce61656453bb690cee" translate="yes" xml:space="preserve">
          <source>This class is useful when the behavior of &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt; is desired, but the number of groups is large enough that generating all possible partitions with \(P\) groups withheld would be prohibitively expensive. In such a scenario, &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; provides a random sample (with replacement) of the train / test splits generated by &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">このクラスは、&lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt;の動作が必要な場合に役立ちますが、グループの数が多すぎるため、\（P \）グループを保留にしてすべての可能なパーティションを生成すると、コストが非常に高くなります。そのようなシナリオでは、&lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; は&lt;/a&gt;によって生成された列車/試験分割の（置換を有する）のランダムサンプルを提供&lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9d924f7a026f05763f1c88ce464db057fdea146c" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt;&lt;code&gt;get_metric&lt;/code&gt;&lt;/a&gt; class method and the metric string identifier (see below).</source>
          <target state="translated">このクラスは、高速距離メトリック関数への統一されたインターフェイスを提供します。さまざまなメトリックには、&lt;a href=&quot;#sklearn.neighbors.DistanceMetric.get_metric&quot;&gt; &lt;code&gt;get_metric&lt;/code&gt; &lt;/a&gt;クラスメソッドとメトリック文字列識別子を介してアクセスできます（以下を参照）。</target>
        </trans-unit>
        <trans-unit id="edf4c29bfa2afe43016dc0b6660ad50132bd51ec" translate="yes" xml:space="preserve">
          <source>This class provides a uniform interface to fast distance metric functions. The various metrics can be accessed via the &lt;code&gt;get_metric&lt;/code&gt; class method and the metric string identifier (see below). For example, to use the Euclidean distance:</source>
          <target state="translated">このクラスは、高速距離メトリック関数への統一されたインターフェースを提供します。さまざまなメトリックには、 &lt;code&gt;get_metric&lt;/code&gt; クラスメソッドとメトリック文字列識別子を介してアクセスできます（以下を参照）。たとえば、ユークリッド距離を使用するには：</target>
        </trans-unit>
        <trans-unit id="336f533fd7cf96bc18f597ff7211d31f0cd62386" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.</source>
          <target state="translated">このクラスは,密な入力と疎な入力の両方をサポートし,マルチクラスのサポートは,onevs the-rest スキームに従って処理されます.</target>
        </trans-unit>
        <trans-unit id="aebcf6792861578bf4b4a69a0be71898d4023b6a" translate="yes" xml:space="preserve">
          <source>This class supports both dense and sparse input.</source>
          <target state="translated">このクラスは,密な入力と疎な入力の両方をサポートします.</target>
        </trans-unit>
        <trans-unit id="4042c6697e9df3310aa51f4f2bbe289c3d222c6e" translate="yes" xml:space="preserve">
          <source>This class turns sequences of symbolic feature names (strings) into scipy.sparse matrices, using a hash function to compute the matrix column corresponding to a name. The hash function employed is the signed 32-bit version of Murmurhash3.</source>
          <target state="translated">このクラスは,記号的特徴名(文字列)のシーケンスを scipy.sparse 行列に変換し,ハッシュ関数を用いて名前に対応する行列の列を計算します.採用されるハッシュ関数は,Murmurhash3の符号付き32ビット版です.</target>
        </trans-unit>
        <trans-unit id="afb2ca6e635ea8a6abf9d5cec38428c8ecdc147c" translate="yes" xml:space="preserve">
          <source>This classification dataset is constructed by taking a multi-dimensional standard normal distribution and defining classes separated by nested concentric multi-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">この分類データセットは、多次元の標準正規分布を用いて、同心円状の多次元球で区切られたクラスを定義し、各クラスのサンプル数がほぼ等しくなるようにしたものです(「\chi^2」分布の数列)。</target>
        </trans-unit>
        <trans-unit id="db081d4f3b8473550c6831dd235016867584f8ea" translate="yes" xml:space="preserve">
          <source>This classifier first converts the target values into &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task (multi-output regression in the multiclass case).</source>
          <target state="translated">この分類器は、最初にターゲット値を &lt;code&gt;{-1, 1}&lt;/code&gt; 変換し、次に問題を回帰タスク（マルチクラスの場合はマルチ出力回帰）として扱います。</target>
        </trans-unit>
        <trans-unit id="9c043eb0cb49ef78462962da4adb4099e130c09c" translate="yes" xml:space="preserve">
          <source>This classifier is sometimes referred to as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;Least Squares Support Vector Machines&lt;/a&gt; with a linear kernel.</source>
          <target state="translated">この分類器は、線形カーネルを備えた&lt;a href=&quot;https://en.wikipedia.org/wiki/Least-squares_support-vector_machine&quot;&gt;最小二乗サポートベクターマシン&lt;/a&gt;と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="a35e593acabc67ebdf8fae8d0484d5f85056d4a7" translate="yes" xml:space="preserve">
          <source>This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems.</source>
          <target state="translated">この分類器は,他の(実際の)分類器と比較するための単純なベースラインとして有用です.実際の問題には使用しないでください。</target>
        </trans-unit>
        <trans-unit id="4ceac36d1efc9bb429dd84350330a84101bb5c8c" translate="yes" xml:space="preserve">
          <source>This classifier lost over a lot of its F-score, just because we removed metadata that has little to do with topic classification. It loses even more if we also strip this metadata from the training data:</source>
          <target state="translated">この分類器は、トピックの分類とはほとんど関係のないメタデータを削除しただけで、そのFスコアの多くを失ってしまいました。訓練データからこのメタデータを削除した場合、この分類器はさらに多くのFスコアを失います。</target>
        </trans-unit>
        <trans-unit id="064e5da463cfecd3ca166c4023a79d0a6500160d" translate="yes" xml:space="preserve">
          <source>This combination is implementing in &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt;, a transformer class that is mostly API compatible with &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; is stateless, meaning that you don&amp;rsquo;t have to call &lt;code&gt;fit&lt;/code&gt; on it:</source>
          <target state="translated">この組み合わせは、ほとんどが&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;とAPI互換性のある変換クラスである&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt;で実装されています。&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; &lt;/a&gt;はステートレスです。つまり、それに &lt;code&gt;fit&lt;/code&gt; させる必要はありません。</target>
        </trans-unit>
        <trans-unit id="1d56591f4aa7f0ebb864c2d8835af7dfb7f8f26b" translate="yes" xml:space="preserve">
          <source>This combines the values of agglomerated features into a single value, and should accept an array of shape [M, N] and the keyword argument &lt;code&gt;axis=1&lt;/code&gt;, and reduce it to an array of size [M].</source>
          <target state="translated">これは、凝集した特徴の値を1つの値に結合し、形状[M、N]の配列とキーワード引数 &lt;code&gt;axis=1&lt;/code&gt; を受け入れ、サイズ[M]の配列に縮小します。</target>
        </trans-unit>
        <trans-unit id="26c788fe31e79bd1bbf24fbba8a1b8342ff15ce1" translate="yes" xml:space="preserve">
          <source>This consumes less memory than shuffling the data directly.</source>
          <target state="translated">これは、データを直接シャッフルするよりも少ないメモリ消費量です。</target>
        </trans-unit>
        <trans-unit id="9c8cf431c4f1299ae41612f84a50a597aa4a1059" translate="yes" xml:space="preserve">
          <source>This creates binary hashes of input data points by getting the dot product of input points and hash_function then transforming the projection into a binary string array based on the sign (positive/negative) of the projection. A sorted array of binary hashes is created.</source>
          <target state="translated">これは,入力点と hash_function のドット積を取得し,その射影を射影の符号(正/負)に基づいてバイナリ文字列配列に変換することで,入力データ点のバイナリハッシュを作成します.ソートされたバイナリハッシュの配列が作成されます。</target>
        </trans-unit>
        <trans-unit id="75f340063df2a6996986c297d7d4423dc4417e05" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">このクロスバリデーションオブジェクトは、StratifiedKFoldとShuffleSplitをマージしたもので、層化されたランダム化されたフォールドを返します。フォールドは、各クラスのサンプルのパーセンテージを保存して作られます。</target>
        </trans-unit>
        <trans-unit id="ab90d891a9b7f61040a0bd2fc78eae2488d53a3a" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;. In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.</source>
          <target state="translated">この交差検証オブジェクトは&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; の&lt;/a&gt;バリエーションです。k番目の分割では、最初のkフォールドを学習セットとして、（k + 1）フォールドをテストセットとして返します。</target>
        </trans-unit>
        <trans-unit id="c3d6a6171342c06e134b7087a7e83e3f80ba8a79" translate="yes" xml:space="preserve">
          <source>This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.</source>
          <target state="translated">このクロスバリデーションオブジェクトは、層化されたフォールドを返すKFoldのバリエーションです。各クラスのサンプルのパーセンテージを保持することでフォールドを作成します。</target>
        </trans-unit>
        <trans-unit id="2c34ca372157ddad0d3d18ffb66a8717775276f6" translate="yes" xml:space="preserve">
          <source>This data sets consists of 3 different types of irises&amp;rsquo; (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray</source>
          <target state="translated">このデータセットは、3つの異なるタイプのアイリス（Setosa、Versicolour、およびVirginica）の花びらとがく片の長さで構成され、150x4 numpy.ndarrayに保存されます</target>
        </trans-unit>
        <trans-unit id="158d23b76a72fb850a277110200a4b319b51d7f5" translate="yes" xml:space="preserve">
          <source>This database is also available through the UW CS ftp server:</source>
          <target state="translated">このデータベースは、UW CSのftpサーバーからも利用可能です。</target>
        </trans-unit>
        <trans-unit id="8f0ed5f875aa21e65ca9d6116dc0e918ff34c0ff" translate="yes" xml:space="preserve">
          <source>This dataset consists of 20,640 samples and 9 features.</source>
          <target state="translated">このデータセットは、20,640個のサンプルと9個の特徴量で構成されています。</target>
        </trans-unit>
        <trans-unit id="2e15d3adbea56bdf31e76cb4ee55fcf6dfb7c05f" translate="yes" xml:space="preserve">
          <source>This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:</source>
          <target state="translated">このデータセットは、インターネット上で収集された有名人のJPEG画像を集めたもので、すべての詳細は公式サイトに掲載されています。</target>
        </trans-unit>
        <trans-unit id="1c0b9129c637e05601004735cb7bfdbdba431796" translate="yes" xml:space="preserve">
          <source>This dataset is described in Celeux et al [1]. as:</source>
          <target state="translated">このデータセットは、Celeuxら[1]として記載されている。</target>
        </trans-unit>
        <trans-unit id="e92704f97c6e77c413a0405e7cf7dd2e32191660" translate="yes" xml:space="preserve">
          <source>This dataset is described in Friedman [1] and Breiman [2].</source>
          <target state="translated">このデータセットはFriedman [1]とBreiman [2]に記述されている.</target>
        </trans-unit>
        <trans-unit id="473d3b557a1c23b381f633c2c2acf0c38c2a328f" translate="yes" xml:space="preserve">
          <source>This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we&amp;rsquo;d have to first transform it into a feature vector with length 64.</source>
          <target state="translated">このデータセットは、1797個の8x8画像で構成されています。以下に示すような各画像は、手書きの数字です。このような8x8の図を使用するには、まず長さ64の特徴ベクトルに変換する必要があります。</target>
        </trans-unit>
        <trans-unit id="39a3f4ca0d0c444ed57d3ff159dafbaf0cf5d2c9" translate="yes" xml:space="preserve">
          <source>This dataset is suitable for multi-ouput regression tasks.</source>
          <target state="translated">このデータセットは多入力回帰タスクに適しています。</target>
        </trans-unit>
        <trans-unit id="73cdbbbbdb25af126933f658f4b065e86b9c1a55" translate="yes" xml:space="preserve">
          <source>This dataset represents the geographic distribution of species. The dataset is provided by Phillips et. al. (2006).</source>
          <target state="translated">このデータセットは種の地理的分布を表している。このデータセットは Phillips et al.(2006).</target>
        </trans-unit>
        <trans-unit id="e72397d5f7691c5c60df49442bb007cee4717786" translate="yes" xml:space="preserve">
          <source>This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).</source>
          <target state="translated">このデータセットは、1990 年の米国国勢調査から得られたもので、国勢調査のブロックグループごとに 1 行ずつのデータを用いている。ブロックグループとは、米国国勢調査局がサンプルデータを公表している最小の地理的単位である(ブロックグループの人口は通常600人から3,000人である)。</target>
        </trans-unit>
        <trans-unit id="47bf559cf1abc9fb33a96a120f583ad0bcd0f9f8" translate="yes" xml:space="preserve">
          <source>This dataset was obtained from the StatLib repository. &lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</source>
          <target state="translated">このデータセットは、StatLibリポジトリから取得されました。&lt;a href=&quot;http://lib.stat.cmu.edu/datasets/&quot;&gt;http://lib.stat.cmu.edu/datasets/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="4668c093fae272aec3196fc6d39e4e5a4eede980" translate="yes" xml:space="preserve">
          <source>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</source>
          <target state="translated">このデータセットは、カーネギーメロン大学で管理されているStatLibライブラリから取得したものです。</target>
        </trans-unit>
        <trans-unit id="9b1b90be23e0adb200134bcc2570822a79ae6e88" translate="yes" xml:space="preserve">
          <source>This demonstrates Label Propagation learning a good boundary even with a small amount of labeled data.</source>
          <target state="translated">これは、少量のラベル付きデータでもラベル伝搬が良好な境界を学習することを実証しています。</target>
        </trans-unit>
        <trans-unit id="33d36bf521beb70b7b2f4b7e5d24d58f96f46c86" translate="yes" xml:space="preserve">
          <source>This description can be vectorized into a sparse two-dimensional matrix suitable for feeding into a classifier (maybe after being piped into a &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; for normalization):</source>
          <target state="translated">この説明は、分類器へのフィードに適したスパースな2次元マトリックスにベクトル化できます（おそらく正規化のために&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;text.TfidfTransformer&lt;/code&gt; &lt;/a&gt;にパイプされた後）。</target>
        </trans-unit>
        <trans-unit id="12f7e332bc936dbb460a17349dda07780cab7782" translate="yes" xml:space="preserve">
          <source>This determines which warnings will be made in the case that this function is being used to return only one of its metrics.</source>
          <target state="translated">これは、この関数がそのメトリクスのうちの 1 つだけを返すために使用されている場合に、どの警告を出すかを決定します。</target>
        </trans-unit>
        <trans-unit id="a1a66d0ad9255f63c11b93170b95da4e6eeaea4f" translate="yes" xml:space="preserve">
          <source>This downscaling is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf&amp;ndash;idf&lt;/a&gt; for &amp;ldquo;Term Frequency times Inverse Document Frequency&amp;rdquo;.</source>
          <target state="translated">このダウンスケーリングは、「用語の頻度とドキュメントの逆数の頻度」の&lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;tf-idf&lt;/a&gt;と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="edeebc499fdf886cf2b1fe82f9cc25a148384f70" translate="yes" xml:space="preserve">
          <source>This early stopping strategy is activated if &lt;code&gt;early_stopping=True&lt;/code&gt;; otherwise the stopping criterion only uses the training loss on the entire input data. To better control the early stopping strategy, we can specify a parameter &lt;code&gt;validation_fraction&lt;/code&gt; which set the fraction of the input dataset that we keep aside to compute the validation score. The optimization will continue until the validation score did not improve by at least &lt;code&gt;tol&lt;/code&gt; during the last &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations. The actual number of iterations is available at the attribute &lt;code&gt;n_iter_&lt;/code&gt;.</source>
          <target state="translated">この早期停止戦略は、 &lt;code&gt;early_stopping=True&lt;/code&gt; の場合にアクティブになります。それ以外の場合、停止基準は入力データ全体のトレーニング損失のみを使用します。早期停止戦略をより適切に制御するために、検証スコアを計算するために確保しておく入力データセットの割合を設定するパラメーター &lt;code&gt;validation_fraction&lt;/code&gt; を指定できます。最適化は、最後の &lt;code&gt;n_iter_no_change&lt;/code&gt; の反復中に検証スコアが少なくとも &lt;code&gt;tol&lt;/code&gt; まで改善されなくなるまで続きます。実際の反復回数は、属性 &lt;code&gt;n_iter_&lt;/code&gt; で取得できます。</target>
        </trans-unit>
        <trans-unit id="6528dcf2523991bd357ca56474b42d537ada09b8" translate="yes" xml:space="preserve">
          <source>This embedding can also &amp;lsquo;work&amp;rsquo; even if the &lt;code&gt;adjacency&lt;/code&gt; variable is not strictly the adjacency matrix of a graph but more generally an affinity or similarity matrix between samples (for instance the heat kernel of a euclidean distance matrix or a k-NN matrix).</source>
          <target state="translated">この埋め込みは、 &lt;code&gt;adjacency&lt;/code&gt; 変数が厳密にはグラフの隣接行列ではなく、より一般的にはサンプル間の親和性または類似性行列（たとえば、ユークリッド距離行列またはk-NN行列の熱カーネル）であっても、「機能」します。</target>
        </trans-unit>
        <trans-unit id="ac8e43e8e0acd749c6d9f51af67c9e65cc70e9b4" translate="yes" xml:space="preserve">
          <source>This enables ducktyping by hasattr returning True according to the sub-estimator.</source>
          <target state="translated">これにより、サブエスティメーターに応じて、hasattrがTrueを返すことで、ダックタイピングが可能になります。</target>
        </trans-unit>
        <trans-unit id="662188aeeffeee289aab2f0d97150266d90c022d" translate="yes" xml:space="preserve">
          <source>This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.</source>
          <target state="translated">このエンコーディングは、多くの scikit-learn 推定器、特に標準カーネルを持つ線形モデルや SVM にカテゴリデータを供給するために必要です。</target>
        </trans-unit>
        <trans-unit id="752036d9bd5ae374e975c046f504e0b38de39538" translate="yes" xml:space="preserve">
          <source>This estimator</source>
          <target state="translated">この推定子</target>
        </trans-unit>
        <trans-unit id="f8a8301fe86e970315ab1f664d0852d178958868" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">この推定器を使用すると、入力の異なる列または列のサブセットを別々に変換し、各変換器によって生成された特徴を連結して単一の特徴空間を形成することができます。これは、複数の特徴抽出メカニズムまたは変換を1つの変換器に結合するために、異種データまたは柱状データの場合に有用である。</target>
        </trans-unit>
        <trans-unit id="36ceeb9f387752a577aeb048b3f21cd319ecfb48" translate="yes" xml:space="preserve">
          <source>This estimator allows different columns or column subsets of the input to be transformed separately and the results combined into a single feature space. This is useful for heterogeneous or columnar data, to combine several feature extraction mechanisms or transformations into a single transformer.</source>
          <target state="translated">この推定器を使用すると、入力の異なる列または列のサブセットを別々に変換し、その結果を1つの特徴空間に結合することができます。これは、複数の特徴抽出メカニズムまたは変換を1つの変換器に結合するために、異種データまたは柱状データに有用である。</target>
        </trans-unit>
        <trans-unit id="02199e2b9b2bd941c7464261eedf68a6fd2d82e2" translate="yes" xml:space="preserve">
          <source>This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer.</source>
          <target state="translated">この推定器は、入力データに並列にトランスフォーマーオブジェクトのリストを適用し、その結果を連結します。これは、複数の特徴抽出メカニズムを1つのトランスフォーマーに結合するのに便利です。</target>
        </trans-unit>
        <trans-unit id="a93ab3d6ae360c030a56bd4fabca46c42abdaf54" translate="yes" xml:space="preserve">
          <source>This estimator approximates a slightly different version of the additive chi squared kernel then &lt;code&gt;metric.additive_chi2&lt;/code&gt; computes.</source>
          <target state="translated">この推定器は、わずかに異なるバージョンの加法カイ二乗カーネルを近似し、次に &lt;code&gt;metric.additive_chi2&lt;/code&gt; が計算します。</target>
        </trans-unit>
        <trans-unit id="53ea424698dba4ed1ec741d2d0ce2fbd09225a41" translate="yes" xml:space="preserve">
          <source>This estimator can be used to model different GLMs depending on the &lt;code&gt;power&lt;/code&gt; parameter, which determines the underlying distribution.</source>
          <target state="translated">この推定量は、基礎となる分布を決定する &lt;code&gt;power&lt;/code&gt; パラメーターに応じて、さまざまなGLMをモデル化するために使用できます。</target>
        </trans-unit>
        <trans-unit id="57f1dab8dd3e838e06f9128461ff865667eb2891" translate="yes" xml:space="preserve">
          <source>This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">この推定器は、多変量回帰のサポートを内蔵している(すなわち、yが形状[n_samples,n_targets]の2次元配列の場合)。</target>
        </trans-unit>
        <trans-unit id="534f21211e3056d3896d05b949c661c4f992dd5f" translate="yes" xml:space="preserve">
          <source>This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="translated">この推定器は、欠損値(NaN)をネイティブにサポートしている。学習中、木育者は、各分割点で、欠落値を持つサンプルが左子に行くべきか右子に行くべきかを、潜在的な利得に基づいて学習します。予測の際には、値が欠落しているサンプルは結果的に左の子か右の子に割り当てられます。学習中に与えられた特徴に対して欠損値が見つからなかった場合、欠損値を持つサンプルは、サンプル数の多い方の子にマップされます。</target>
        </trans-unit>
        <trans-unit id="7130a824407818977c24f15960ee70da6f59d9ca" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the &lt;code&gt;partial_fit&lt;/code&gt; method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">この推定量は、確率的勾配降下法（SGD）学習を使用して正則化線形モデルを実装します。損失の勾配は一度に各サンプルで推定され、モデルは強度スケジュール（学習率）の減少とともに更新されます。SGDでは、 &lt;code&gt;partial_fit&lt;/code&gt; メソッドを介したミニバッチ（オンライン/アウトオブコア）学習が可能です。デフォルトの学習率スケジュールを使用して最良の結果を得るには、データの平均と単位分散がゼロである必要があります。</target>
        </trans-unit>
        <trans-unit id="ab45bcef3fd31ebffe9c4724334c2d64921dae44" translate="yes" xml:space="preserve">
          <source>This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.</source>
          <target state="translated">損失の勾配はサンプルごとに一度に推定され、モデルは途中で強度が低下するスケジュール(別名学習率)で更新されます。SGD ではミニバッチ (オンライン/アウトオブコア)学習が可能で、パーシャルフィット法を参照してください。デフォルトの学習率スケジュールを使用して最良の結果を得るには、データの平均値と単位分散がゼロである必要があります。</target>
        </trans-unit>
        <trans-unit id="7005478518d9bca348fcae966cb157ede91131ca" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="translated">この推定量は、大きなデータセット（n_samples&amp;gt; = 10000）の場合は&lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;よりもはるかに高速です。</target>
        </trans-unit>
        <trans-unit id="505ce7903463cb2537c439b476cf7830c59f9934" translate="yes" xml:space="preserve">
          <source>This estimator is much faster than &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; for big datasets (n_samples &amp;gt;= 10 000).</source>
          <target state="translated">この推定量は、大きなデータセット（n_samples&amp;gt; = 10000）の場合は&lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;よりもはるかに高速です。</target>
        </trans-unit>
        <trans-unit id="5fdb17bfdb14f498d9377f8ca9b7cc2199a41d7f" translate="yes" xml:space="preserve">
          <source>This estimator is stateless (besides constructor parameters), the fit method does nothing but is useful when used in a pipeline.</source>
          <target state="translated">この推定器はステートレスであり(コンストラクタのパラメータ以外に)、フィットメソッドは何もしませんが、パイプラインで使用する場合には便利です。</target>
        </trans-unit>
        <trans-unit id="b10e025b81eb3a8b5b21ad615292ad7338f1e2a3" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt;: convergence criteria (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;#14338&lt;/a&gt;), default estimators (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;#13286&lt;/a&gt;), and use of random state (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;#15611&lt;/a&gt;). To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;.</source>
          <target state="translated">この推定器は今のところまだ&lt;strong&gt;実験&lt;/strong&gt;段階です。デフォルトのパラメーターまたは動作の詳細は、非推奨のサイクルなしで変更される可能性があります。次の問題を解決することは安定化に役立つだろう&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; を&lt;/a&gt;：収束基準（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14338&quot;&gt;＃14338&lt;/a&gt;）、デフォルトの推定（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/13286&quot;&gt;＃13286&lt;/a&gt;）、およびランダムな状態の使用（&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/15611&quot;&gt;＃15611&lt;/a&gt;）。これを使用するには、 &lt;code&gt;enable_iterative_imputer&lt;/code&gt; を明示的にインポートする必要があります。</target>
        </trans-unit>
        <trans-unit id="3ba8a49b5a7145a75b81ed477df1577dc2f0d079" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt;:</source>
          <target state="translated">この推定量は今のところまだ&lt;strong&gt;実験&lt;/strong&gt;段階です。予測とAPIは、非推奨のサイクルなしで変更される可能性があります。これを使用するには、 &lt;code&gt;enable_hist_gradient_boosting&lt;/code&gt; を明示的にインポートする必要があります。</target>
        </trans-unit>
        <trans-unit id="7c7878b26bf7f32e88e4f83c2d2d772f7f3023cd" translate="yes" xml:space="preserve">
          <source>This estimator is still &lt;strong&gt;experimental&lt;/strong&gt; for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import &lt;code&gt;enable_iterative_imputer&lt;/code&gt;:</source>
          <target state="translated">この推定量は今のところまだ&lt;strong&gt;実験&lt;/strong&gt;段階です。予測とAPIは、非推奨のサイクルなしで変更される可能性があります。これを使用するには、 &lt;code&gt;enable_iterative_imputer&lt;/code&gt; を明示的にインポートする必要があります。</target>
        </trans-unit>
        <trans-unit id="d8c9fb1adc7eae2561c12b442ef315ae822391e8" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.</source>
          <target state="translated">この推定器は、各特徴が訓練セット上の所定の範囲内にあるように、各特徴を個別にスケーリングして変換します(例:0から1の間)。</target>
        </trans-unit>
        <trans-unit id="42d08f109b32ce107e9f058e7449521b0b6eab28" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.</source>
          <target state="translated">この推定器は、各特徴が訓練セット上の所定の範囲内にあるように、つまり0から1の間にあるように、各特徴を個別にスケーリングして変換します。</target>
        </trans-unit>
        <trans-unit id="ce7850baf5a7a3e7ef75716db2d2e4af71c92137" translate="yes" xml:space="preserve">
          <source>This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.</source>
          <target state="translated">この推定器は、訓練セットの各特徴の最大絶対値が1.0になるように、各特徴を個別にスケーリングして変換します。データのシフトやセンタリングを行わないため、疎分散を破壊しない。</target>
        </trans-unit>
        <trans-unit id="0ff92b3f8e56701f386ccbc5279ec5fdb2974bc0" translate="yes" xml:space="preserve">
          <source>This estimator scales each feature individually such that the maximal absolute value of each feature in the training set will be 1.0.</source>
          <target state="translated">この推定器は、訓練セットの各特徴の最大絶対値が1.0になるように、各特徴を個別にスケーリングする。</target>
        </trans-unit>
        <trans-unit id="354214ed410106228bbb593cd82a49f32a2508f8" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on (X * X.T) or (X.T * X), whichever is more efficient.</source>
          <target state="translated">この推定器は、2つのアルゴリズムをサポートします。高速ランダム化SVDソルバーと、（X * XT）または（XT * X）の固有ソルバーとしてARPACKを使用する「単純な」アルゴリズムのうち、どちらか効率的です。</target>
        </trans-unit>
        <trans-unit id="0a991e8d6eff0a5b7f5a276b54be6da66c4dae45" translate="yes" xml:space="preserve">
          <source>This estimator supports two algorithms: a fast randomized SVD solver, and a &amp;ldquo;naive&amp;rdquo; algorithm that uses ARPACK as an eigensolver on &lt;code&gt;X * X.T&lt;/code&gt; or &lt;code&gt;X.T * X&lt;/code&gt;, whichever is more efficient.</source>
          <target state="translated">この推定器は、高速ランダム化SVDソルバーと、 &lt;code&gt;X * X.T&lt;/code&gt; または &lt;code&gt;X.T * X&lt;/code&gt; どちらか効率の高い方で固有ソルバーとしてARPACKを使用する「ナイーブ」アルゴリズムの2つのアルゴリズムをサポートします。</target>
        </trans-unit>
        <trans-unit id="438c738ad18e280c91d7884cd24490873bfed375" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc, making sure that the estimator complies with &lt;code&gt;scikit-learn&lt;/code&gt; conventions as detailed in &lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;Rolling your own estimator&lt;/a&gt;. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">このEstimatorは、入力の検証や形状などの広範なテストスイートを実行し、Estimatorが &lt;code&gt;scikit-learn&lt;/code&gt; 規則に準拠していることを確認し&lt;a href=&quot;https://scikit-learn.org/0.23/developers/develop.html#rolling-your-own-estimator&quot;&gt;ます&lt;/a&gt;。Estimatorクラスがsklearn.baseの対応するミックスインから継承する場合、分類子、リグレッサー、クラスタリング、またはトランスフォーマーの追加のテストが実行されます。</target>
        </trans-unit>
        <trans-unit id="3ed5861f671a7b7a1c102cd9c37c8bf2e273de13" translate="yes" xml:space="preserve">
          <source>This estimator will run an extensive test-suite for input validation, shapes, etc. Additional tests for classifiers, regressors, clustering or transformers will be run if the Estimator class inherits from the corresponding mixin from sklearn.base.</source>
          <target state="translated">この推定器は、入力の検証や形状などの広範なテストスイートを実行します。Estimatorクラスがsklearn.baseの対応するmixinを継承している場合、分類器、回帰器、クラスタリング、変換器のための追加テストが実行されます。</target>
        </trans-unit>
        <trans-unit id="7011f5e2b484f266188acd0aba4f3d3175f11ed0" translate="yes" xml:space="preserve">
          <source>This example also shows the usefulness of applying Ridge regression to highly ill-conditioned matrices. For such matrices, a slight change in the target variable can cause huge variances in the calculated weights. In such cases, it is useful to set a certain regularization (alpha) to reduce this variation (noise).</source>
          <target state="translated">この事例は,高度に条件の悪い行列にリッジ回帰を適用することの有用性も示している.このような行列では、ターゲット変数のわずかな変化が、計算された重みに大きな分散を引き起こすことがあります。このような場合,この変動(ノイズ)を減らすために,ある種の正則化(アルファ)を設定することが有用である.</target>
        </trans-unit>
        <trans-unit id="66087b50dbc537ea3a892d00ee467bc12eeadd33" translate="yes" xml:space="preserve">
          <source>This example applies to &lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;The Olivetti faces dataset&lt;/a&gt; different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">この例は、モジュール&lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt;とは異なる教師なし行列分解（次元削減）メソッドであるOlivetti Faces&lt;a href=&quot;../../datasets/index#olivetti-faces-dataset&quot;&gt;データセットに&lt;/a&gt;適用されます（ドキュメントの章「&lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;コンポーネント内の信号の分解（行列因数分解の問題）」を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="7f82721c4674480adff4241dbcac8e543f16c868" translate="yes" xml:space="preserve">
          <source>This example applies to olivetti_faces different unsupervised matrix decomposition (dimension reduction) methods from the module &lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; (see the documentation chapter &lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;Decomposing signals in components (matrix factorization problems)&lt;/a&gt;) .</source>
          <target state="translated">この例は、モジュール&lt;a href=&quot;../../modules/classes#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; &lt;/a&gt;からのolivetti_facesのさまざまな教師なし行列分解（次元削減）メソッドに適用されます（ドキュメントの「&lt;a href=&quot;../../modules/decomposition#decompositions&quot;&gt;コンポーネント内の信号の分解（行列分解の問題）&lt;/a&gt;」の章を参照してください）。</target>
        </trans-unit>
        <trans-unit id="209229078f7e258d4985eec4947d8dca83616df9" translate="yes" xml:space="preserve">
          <source>This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1].</source>
          <target state="translated">この例では、PCA成分の数を最小限に抑えながら、最良の精度スコアの標準偏差1以内に適切な精度を見つけることで、モデルの複雑さと交差検証されたスコアのバランスをとっています[1]。</target>
        </trans-unit>
        <trans-unit id="33924f5409489cd3edd1b22f28ee011b17a585da" translate="yes" xml:space="preserve">
          <source>This example compares 2 dimensionality reduction strategies:</source>
          <target state="translated">この例では、2 次元削減戦略を比較しています。</target>
        </trans-unit>
        <trans-unit id="d2a9de2244899372ce613f7320d0c8868284b849" translate="yes" xml:space="preserve">
          <source>This example compares different (linear) dimensionality reduction methods applied on the Digits data set. The data set contains images of digits from 0 to 9 with approximately 180 samples of each class. Each image is of dimension 8x8 = 64, and is reduced to a two-dimensional data point.</source>
          <target state="translated">この例では,Digitsデータセットに適用された異なる(線形)次元削減方法を比較しています.このデータセットには,各クラスの約180サンプルの0から9までの数字の画像が含まれています.各画像の次元は8x8=64で、2次元のデータ点に縮小されます。</target>
        </trans-unit>
        <trans-unit id="1ba8c26b14d0dc5555ed6b18d75cbed15c385668" translate="yes" xml:space="preserve">
          <source>This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score.</source>
          <target state="translated">この例は、虹彩データセットの分類器での非入れ子と入れ子のクロスバリデーション戦略を比較する。ネストされたクロスバリデーション(CV)は,ハイパーパラメータも最適化する必要があるモデルを訓練するためによく使われる.入れ子になったCVは,基礎となるモデルとその(ハイパー)パラメータ探索の一般化誤差を推定する.非入れ子CVを最大化するパラメータを選択すると,モデルがデータセットに偏り,過度に最適化されたスコアが得られる.</target>
        </trans-unit>
        <trans-unit id="7ef1cb506f6769f9ea8f57cc850c6090d62898eb" translate="yes" xml:space="preserve">
          <source>This example compares the timing of Birch (with and without the global clustering step) and MiniBatchKMeans on a synthetic dataset having 100,000 samples and 2 features generated using make_blobs.</source>
          <target state="translated">この例では、10万サンプルとmake_blobsを使用して生成された2つの特徴量を持つ合成データセットについて、Birch(グローバルクラスタリングステップの有無に関わらず)とMiniBatchKMeansのタイミングを比較しています。</target>
        </trans-unit>
        <trans-unit id="8901e1f5225dc1b7e06d2fabb8f06f19a3753c45" translate="yes" xml:space="preserve">
          <source>This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of &lt;code&gt;GridSearchCV&lt;/code&gt; and &lt;code&gt;Pipeline&lt;/code&gt; to optimize over different classes of estimators in a single CV run &amp;ndash; unsupervised &lt;code&gt;PCA&lt;/code&gt; and &lt;code&gt;NMF&lt;/code&gt; dimensionality reductions are compared to univariate feature selection during the grid search.</source>
          <target state="translated">この例では、次元削減とそれに続くサポートベクター分類器による予測を行うパイプラインを構築します。これは、 &lt;code&gt;GridSearchCV&lt;/code&gt; と &lt;code&gt;Pipeline&lt;/code&gt; を使用して、1回のCV実行でさまざまなクラスの推定量を最適化する方法を示しています。教師なし &lt;code&gt;PCA&lt;/code&gt; および &lt;code&gt;NMF&lt;/code&gt; の次元削減は、グリッド検索中に単変量特徴選択と比較されます。</target>
        </trans-unit>
        <trans-unit id="ebd831df4448cf766c6eb0e33a12d358fbfa3057" translate="yes" xml:space="preserve">
          <source>This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">この例は、弱い予測モデルのアンサンブルから予測モデルを生成するための勾配ブースティングを示しています。勾配ブースティングは、回帰と分類の問題に使用できます。ここでは、糖尿病回帰タスクに取り組むためのモデルをトレーニングします。最小二乗損失と深さ4の500個の回帰ツリーを使用して&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;から結果を取得します。</target>
        </trans-unit>
        <trans-unit id="b084d11db0bc218128b35a7afe55ac9fa7c4daf1" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to approximate a function with a polynomial of degree n_degree by using ridge regression. Concretely, from n_samples 1d points, it suffices to build the Vandermonde matrix, which is n_samples x n_degree+1 and has the following form:</source>
          <target state="translated">この例では、リッジ回帰を用いて次数n_degreeの多項式を持つ関数を近似する方法を示します。具体的には、n_samples 1d点から、n_samples x n_degree+1で、以下の形式を持つVandermonde行列を構築すればよい。</target>
        </trans-unit>
        <trans-unit id="8509d7895b98e9b3d2d07ed03eae90baa68f1c72" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a checkerboard dataset and bicluster it using the Spectral Biclustering algorithm.</source>
          <target state="translated">この例では、Spectral Biclustering アルゴリズムを使用して、チェッカーボードデータセットを生成し、それを二重クラスタ化する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="fb9a20a0b6ffdb624c38c357324f211d180af27f" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to generate a dataset and bicluster it using the Spectral Co-Clustering algorithm.</source>
          <target state="translated">この例では、Spectral Co-Clustering アルゴリズムを使用してデータセットを生成し、それを二重クラスタリングする方法を示します。</target>
        </trans-unit>
        <trans-unit id="9b609f5368296ac180488994b6106bba8395b9b3" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. The choice of features is not particularly helpful, but serves to illustrate the technique.</source>
          <target state="translated">この例は、さまざまなタイプの機能を含むデータセットで&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt;を使用する方法を示しています。機能の選択は特に役立ちませんが、テクニックを説明するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="4e024e96a6e8109f327c2d890a3a85ee374e03bd" translate="yes" xml:space="preserve">
          <source>This example demonstrates how to use &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; on a dataset containing different types of features. We use the 20-newsgroups dataset and compute standard bag-of-words features for the subject line and body in separate pipelines as well as ad hoc features on the body. We combine them (with weights) using a ColumnTransformer and finally train a classifier on the combined set of features.</source>
          <target state="translated">この例は、さまざまなタイプの特徴を含むデータセットで&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;を使用する方法を示しています。20ニュースグループのデータセットを使用して、件名行と本文の標準的なBag-of-Words機能を別のパイプラインで計算し、本文のアドホック機能を計算します。ColumnTransformerを使用してそれらを（重み付きで）組み合わせ、最後に、組み合わせた機能のセットで分類子をトレーニングします。</target>
        </trans-unit>
        <trans-unit id="76d491fec0fed042e6d7927f2dc124b698f9bded" translate="yes" xml:space="preserve">
          <source>This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset. The &amp;lsquo;comp.os.ms-windows.misc&amp;rsquo; category is excluded because it contains many posts containing nothing but data.</source>
          <target state="translated">この例は、20のニュースグループデータセットのスペクトル共クラスタリングアルゴリズムを示しています。'comp.os.ms-windows.misc'カテゴリは、データのみを含む多くの投稿が含まれているため除外されます。</target>
        </trans-unit>
        <trans-unit id="6186f51b55d8cba756254a15fe651e5e8504791a" translate="yes" xml:space="preserve">
          <source>This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components.</source>
          <target state="translated">この例は、ガウシアン混合モデルが、ガウシアンランダム変数の混合物からサンプリングされなかったデータに適合したときの挙動を示しています。このデータセットは、ノイズの多いサイン曲線に沿って疎間隔に配置された100点によって形成されています。したがって、ガウス成分の数には基底真理値はありません。</target>
        </trans-unit>
        <trans-unit id="a1949f51dde2d60d7d4d1e707d145c1301537434" translate="yes" xml:space="preserve">
          <source>This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels.</source>
          <target state="translated">この例では、非常に少ないラベルのセットで手書きの数字を分類するためにラベル拡散モデルを訓練することで、半教師付き学習の威力を実証しています。</target>
        </trans-unit>
        <trans-unit id="c6020c6a7334e89ced3b2c5f4b02f4ed9989e37f" translate="yes" xml:space="preserve">
          <source>This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called &lt;strong&gt;underfitting&lt;/strong&gt;. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will &lt;strong&gt;overfit&lt;/strong&gt; the training data, i.e. it learns the noise of the training data. We evaluate quantitatively &lt;strong&gt;overfitting&lt;/strong&gt; / &lt;strong&gt;underfitting&lt;/strong&gt; by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data.</source>
          <target state="translated">この例では、アンダーフィットとオーバーフィットの問題と、多項式機能を使用して線形回帰を使用して非線形関数を近似する方法を示します。プロットは、コサイン関数の一部である、近似したい関数を示しています。さらに、実際の関数のサンプルとさまざまなモデルの近似値が表示されます。モデルには、次数の異なる多項式の特徴があります。線形関数（次数1の多項式）ではトレーニングサンプルを近似するのに十分ではないことがわかります。これは&lt;strong&gt;アンダーフィッティング&lt;/strong&gt;と呼ばれ&lt;strong&gt;ます&lt;/strong&gt;。次数4の多項式は、真の関数をほぼ完全に近似します。ただし、より高い次数の場合、モデルはトレーニングデータを&lt;strong&gt;オーバーフィット&lt;/strong&gt;します。つまり、トレーニングデータのノイズを学習します。定量的に評価&lt;strong&gt;&lt;/strong&gt;交差&lt;strong&gt;検定&lt;/strong&gt;を使用した&lt;strong&gt;過剰適合&lt;/strong&gt; / &lt;strong&gt;過適合&lt;/strong&gt;。検証セットの平均二乗誤差（MSE）を計算するほど、モデルがトレーニングデータから正しく一般化される可能性が低くなります。</target>
        </trans-unit>
        <trans-unit id="a2d558b6f5e9fa98f7c27a3a7352d216289c9012" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">この例は、&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; &lt;/a&gt;を介したBox-CoxおよびYeo-Johnson変換を使用して、さまざまな分布から正規分布にデータをマッピングする方法を示しています。</target>
        </trans-unit>
        <trans-unit id="ab8d51c9ac9762c2930c84a5a03c1c12345a6627" translate="yes" xml:space="preserve">
          <source>This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; to map data from various distributions to a normal distribution.</source>
          <target state="translated">この例は、 &lt;code&gt;preprocessing.PowerTransformer&lt;/code&gt; によるBox-CoxおよびYeo-Johnson変換の使用法を示し、さまざまな分布から正規分布にデータをマッピングします。</target>
        </trans-unit>
        <trans-unit id="9b62ef0be0bf7ce49acab00a23e04164c0becf9d" translate="yes" xml:space="preserve">
          <source>This example does not perform any learning over the data (see &lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of classification based on the attributes in this dataset). It simply shows the kernel density estimate of observed data points in geospatial coordinates.</source>
          <target state="translated">この例では、データの学習は行われません（このデータセットの属性に基づく分類の例については、&lt;a href=&quot;../applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;種分布モデリング&lt;/a&gt;を参照してください）。それは単に、地理空間座標で観測されたデータポイントのカーネル密度推定を示します。</target>
        </trans-unit>
        <trans-unit id="03eea75ae69c05ca0f9dc1a13d89bbd210d48145" translate="yes" xml:space="preserve">
          <source>This example doesn&amp;rsquo;t show it, as we&amp;rsquo;re in a low-dimensional space, but another advantage of the Dirichlet process model is that it can fit full covariance matrices effectively even when there are less examples per cluster than there are dimensions in the data, due to regularization properties of the inference algorithm.</source>
          <target state="translated">この例では、低次元空間にいるため、それを示していませんが、ディリクレプロセスモデルのもう1つの利点は、クラスターごとの例の数が推論アルゴリズムの正則化特性によるデータ。</target>
        </trans-unit>
        <trans-unit id="7b398c0b1dbb0f3edb9cc17097a9c9f8696a24cc" translate="yes" xml:space="preserve">
          <source>This example employs several unsupervised learning techniques to extract the stock market structure from variations in historical quotes.</source>
          <target state="translated">この例では、過去の相場の変動から株式市場の構造を抽出するために、いくつかの教師なし学習技術を採用しています。</target>
        </trans-unit>
        <trans-unit id="41937f256baaea1198c4d043d4bb81b61df0d50b" translate="yes" xml:space="preserve">
          <source>This example fits a Gradient Boosting model with least squares loss and 500 regression trees of depth 4.</source>
          <target state="translated">この例は、最小二乗損失と深さ4の500本の回帰木を持つ勾配ブーストモデルに適合します。</target>
        </trans-unit>
        <trans-unit id="e8121408498cf6fb8c886d50eef2580465ff3307" translate="yes" xml:space="preserve">
          <source>This example fits an AdaBoosted decision stump on a non-linearly separable classification dataset composed of two &amp;ldquo;Gaussian quantiles&amp;rdquo; clusters (see &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt;&lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt;&lt;/a&gt;) and plots the decision boundary and decision scores. The distributions of decision scores are shown separately for samples of class A and B. The predicted class label for each sample is determined by the sign of the decision score. Samples with decision scores greater than zero are classified as B, and are otherwise classified as A. The magnitude of a decision score determines the degree of likeness with the predicted class label. Additionally, a new dataset could be constructed containing a desired purity of class B, for example, by only selecting samples with a decision score above some value.</source>
          <target state="translated">この例では、2つの「ガウス分位点」クラスター（&lt;a href=&quot;../../modules/generated/sklearn.datasets.make_gaussian_quantiles#sklearn.datasets.make_gaussian_quantiles&quot;&gt; &lt;code&gt;sklearn.datasets.make_gaussian_quantiles&lt;/code&gt; を&lt;/a&gt;参照）で構成される非線形分離可能な分類データセットにAdaBoosted決定スタンプを適合させ、決定境界と決定スコアをプロットします。決定スコアの分布は、クラスAとクラスBのサンプルに対して別々に表示されます。各サンプルの予測クラスラベルは、決定スコアの符号によって決定されます。ゼロより大きい決定スコアを持つサンプルはBとして分類され、そうでない場合はAとして分類されます。決定スコアの大きさは、予測されたクラスラベルとの類似度を決定します。さらに、たとえば、ある値以上の決定スコアを持つサンプルのみを選択することにより、クラスBの望ましい純度を含む新しいデータセットを構築できます。</target>
        </trans-unit>
        <trans-unit id="02c230a18f98a72777c5f2652062014b16511fe8" translate="yes" xml:space="preserve">
          <source>This example has a fair amount of visualization-related code, as visualization is crucial here to display the graph. One of the challenge is to position the labels minimizing overlap. For this we use an heuristic based on the direction of the nearest neighbor along each axis.</source>
          <target state="translated">グラフを表示するには可視化が重要なので、この例にはかなりの量の可視化関連のコードが含まれています。課題の一つは、ラベルの重なりを最小限に抑えて配置することです。このために、各軸に沿った最も近い隣人の方向に基づくヒューリスティックを使用しています。</target>
        </trans-unit>
        <trans-unit id="6aeec4c0fd48150be3eb10918e11b6fbb03261c5" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">この例は、XORデータのGPCを示しています。比較されるのは、定常の等方性カーネル（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;）と非定常カーネル（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;）です。この特定のデータセットでは、クラス境界が線形で座標軸と一致するため、&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;カーネルはかなり良い結果を取得します。ただし、実際には、&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;などの固定カーネルの方が良い結果が得られることがよくあります。</target>
        </trans-unit>
        <trans-unit id="259139974bd9ca7304e763dff02af979bb7908e6" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt;) and a non-stationary kernel (&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt;). On this particular dataset, the &lt;code&gt;DotProduct&lt;/code&gt; kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; often obtain better results.</source>
          <target state="translated">この例は、XORデータのGPCを示しています。静止した等方性カーネル（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;）と非定常カーネル（&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;）を比較します。この特定のデータセットでは、クラス境界が線形で座標軸と一致しているため、 &lt;code&gt;DotProduct&lt;/code&gt; カーネルはかなり優れた結果を取得します。ただし、実際には、&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; &lt;/a&gt;などの固定カーネルがより良い結果を得ることがよくあります。</target>
        </trans-unit>
        <trans-unit id="a467b781e30c272f4f5e4645f1261bd726b14e8d" translate="yes" xml:space="preserve">
          <source>This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In general, stationary kernels often obtain better results.</source>
          <target state="translated">この例は、XORデータ上でのGPCを説明しています。比較されているのは、静止した等方性カーネル(RBF)と非静止カーネル(DotProduct)です。この特定のデータセットでは、クラス境界が線形で座標軸と一致しているため、DotProduct カーネルの方がかなり良い結果が得られます。一般的に,定常カーネルの方が良い結果が得られることが多いです.</target>
        </trans-unit>
        <trans-unit id="722f803000769d905ffb0b191f686c49464dc23e" translate="yes" xml:space="preserve">
          <source>This example illustrates a generic implementation of a meta-estimator which extends clustering by inducing a classifier from the cluster labels.</source>
          <target state="translated">この例は、クラスタラベルから分類器を誘導することでクラスタリングを拡張するメタ推定器の一般的な実装を示しています。</target>
        </trans-unit>
        <trans-unit id="397c051adb668f2e353216b8af31fde49c4b91b4" translate="yes" xml:space="preserve">
          <source>This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the &lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;User Guide&lt;/a&gt; for more information.</source>
          <target state="translated">この例は、最近傍分類の精度を最大化する学習距離メトリックを示しています。これは、元の点空間と比較したこのメトリックの視覚的表現を提供します。詳細については、&lt;a href=&quot;../../modules/neighbors#nca&quot;&gt;ユーザーガイド&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="b43f5231cb55a1a95a64bd8afe5472e7955fc98b" translate="yes" xml:space="preserve">
          <source>This example illustrates and compares the bias-variance decomposition of the expected mean squared error of a single estimator against a bagging ensemble.</source>
          <target state="translated">この例では、単一の推定器の期待平均2乗誤差のバイアス-分散分解と袋詰めアンサンブルの比較を説明しています。</target>
        </trans-unit>
        <trans-unit id="0a3450a632d656139c95a4f138b569cec22ba6ef" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise added to every fifth datapoint. The first figure compares the learned model of KRR and SVR when both complexity/regularization and bandwidth of the RBF kernel are optimized using grid-search. The learned functions are very similar; however, fitting KRR is approx. seven times faster than fitting SVR (both with grid-search). However, prediction of 100000 target values is more than tree times faster with SVR since it has learned a sparse model using only approx. 1/3 of the 100 training datapoints as support vectors.</source>
          <target state="translated">この例では、正弦波のターゲット関数と5つ目のデータポイントごとに強いノイズが追加された人工的なデータセットを用いて、両手法を説明しています。最初の図は、グリッドサーチを用いて複雑化/正則化とRBFカーネルの帯域幅の両方を最適化した場合のKRRとSVRの学習モデルを比較したものです。学習された関数は非常によく似ているが,KRRの方がSVRの方が約7倍速い(いずれもグリッドサーチを用いた場合).しかし,100個の学習データポイントのうち約1/3のデータポイントのみを支持ベクトルとして用いて疎なモデルを学習しているため,100000個の目標値の予測はSVRの方が木数倍以上高速である.</target>
        </trans-unit>
        <trans-unit id="bdbaaa805869c3c13d157f267aeffaf332ff1284" translate="yes" xml:space="preserve">
          <source>This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise. The figure compares the learned model of KRR and GPR based on a ExpSineSquared kernel, which is suited for learning periodic functions. The kernel&amp;rsquo;s hyperparameters control the smoothness (l) and periodicity of the kernel (p). Moreover, the noise level of the data is learned explicitly by GPR by an additional WhiteKernel component in the kernel and by the regularization parameter alpha of KRR.</source>
          <target state="translated">この例は、正弦波のターゲット関数と強いノイズで構成される人工データセットの両方の方法を示しています。この図は、周期関数の学習に適したExpSineSquaredカーネルに基づいて、KRRとGPRの学習モデルを比較します。カーネルのハイパーパラメータは、カーネルの滑らかさ（l）と周期性（p）を制御します。さらに、データのノイズレベルは、カーネル内の追加のWhiteKernelコンポーネントとKRRの正則化パラメーターalphaによってGPRによって明示的に学習されます。</target>
        </trans-unit>
        <trans-unit id="745a420beb7d4cfe3dcb516bc28a36f2576e5395" translate="yes" xml:space="preserve">
          <source>This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).</source>
          <target state="translated">この例は、シグモイド校正が、3クラスの分類問題の予測確率をどのように変化させるかを説明しています。図示されているのは、3つの角が3つのクラスに対応する標準の2-複素です。矢印は、校正されていない分類器によって予測された確率ベクトルから、ホールドアウト検証セットでのシグモイド校正後の同じ分類器によって予測された確率ベクトルを指しています。色は、インスタンスの真のクラスを示します(赤:クラス1、緑:クラス2、青:クラス3)。</target>
        </trans-unit>
        <trans-unit id="12c733d8527ccd2c1862324a52d9d453fa3717b9" translate="yes" xml:space="preserve">
          <source>This example illustrates how the Mahalanobis distances are affected by outlying data: observations drawn from a contaminating distribution are not distinguishable from the observations coming from the real, Gaussian distribution that one may want to work with. Using MCD-based Mahalanobis distances, the two populations become distinguishable. Associated applications are outliers detection, observations ranking, clustering, &amp;hellip; For visualization purpose, the cubic root of the Mahalanobis distances are represented in the boxplot, as Wilson and Hilferty suggest [2]</source>
          <target state="translated">この例は、マハラノビス距離が外れ値のデータによってどのように影響されるかを示しています。汚染分布から引き出された観測は、操作したい実際のガウス分布からの観測と区別できません。 MCDベースのマハラノビス距離を使用すると、2つの集団が区別できるようになります。関連するアプリケーションは、外れ値の検出、観測のランキング、クラスタリングなどです&amp;hellip;視覚化の目的で、マハラノビス距離の3次根は箱ひげ図で表されます。</target>
        </trans-unit>
        <trans-unit id="e6c2656adbcd3c5e59b375bc18300061f72c931d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping using many fewer estimators. This can significantly reduce training time, memory usage and prediction latency.</source>
          <target state="translated">この例は、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;モデルで早期停止を使用して、より少ない推定量を使用して早期停止なしで構築されたモデルと比較してほぼ同じ精度を達成する方法を示しています。これにより、トレーニング時間、メモリ使用量、予測待ち時間を大幅に削減できます。</target>
        </trans-unit>
        <trans-unit id="c9534999032b13d85edbba90f8420279af14435d" translate="yes" xml:space="preserve">
          <source>This example illustrates how the early stopping can used in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; model to achieve almost the same accuracy as compared to a model built without early stopping. This can significantly reduce training time. Note that scores differ between the stopping criteria even from early iterations because some of the training data is held out with the validation stopping criterion.</source>
          <target state="translated">この例は、早期停止を使用せずに構築されたモデルと比較して、ほぼ同じ精度を達成するために、&lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;モデルで早期停止を使用する方法を示しています。これにより、トレーニング時間が大幅に短縮されます。一部のトレーニングデータは検証の停止基準で保持されているため、初期の反復からでもスコアは停止基準間で異なることに注意してください。</target>
        </trans-unit>
        <trans-unit id="c861b8fa50d5165e1e9cdc8044114c0ba76be7f1" translate="yes" xml:space="preserve">
          <source>This example illustrates how to apply different preprocessing and feature extraction pipelines to different subsets of features, using &lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt;. This is particularly handy for the case of datasets that contain heterogeneous data types, since we may want to scale the numeric features and one-hot encode the categorical ones.</source>
          <target state="translated">この例では、&lt;a href=&quot;../../modules/generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;を使用して、さまざまな前処理パイプラインと特徴抽出パイプラインを特徴の異なるサブセットに適用する方法を示します。これは、異種のデータ型を含むデータセットの場合に特に便利です。これは、数値の特徴をスケーリングし、カテゴリの特徴をワンホットエンコードしたい場合があるためです。</target>
        </trans-unit>
        <trans-unit id="7688b615fac5133028d275260a50b4a9e7d6a213" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML.</source>
          <target state="translated">この例では、WhiteKernelを含む和カーネルを用いたGPRがデータのノイズレベルを推定できることを示しています。log-marginal-likelihood (LML)の図解は、LMLの局所的な最大値が2つ存在することを示しています。</target>
        </trans-unit>
        <trans-unit id="aab3b4258aabcd6bfe55c7c5adf04622c59229dc" translate="yes" xml:space="preserve">
          <source>This example illustrates that GPR with a sum-kernel including a WhiteKernel can estimate the noise level of data. An illustration of the log-marginal-likelihood (LML) landscape shows that there exist two local maxima of LML. The first corresponds to a model with a high noise level and a large length scale, which explains all variations in the data by noise. The second one has a smaller noise level and shorter length scale, which explains most of the variation by the noise-free functional relationship. The second model has a higher likelihood; however, depending on the initial value for the hyperparameters, the gradient-based optimization might also converge to the high-noise solution. It is thus important to repeat the optimization several times for different initializations.</source>
          <target state="translated">この例では、WhiteKernelを含む和カーネルを用いたGPRがデータのノイズレベルを推定できることを示しています。log-marginal-likelihood (LML)の図解では、LMLの局所的な最大値が2つ存在することが示されています。1つ目は、ノイズレベルが高く、長さスケールが大きいモデルに対応し、ノイズによるデータのすべての変動を説明します。2つ目は、ノイズレベルが小さく、長さスケールが短いモデルに対応し、ノイズのない関数関係によってほとんどの変動を説明します。2番目のモデルの方が尤度が高いですが、ハイパーパラメータの初期値によっては、勾配ベースの最適化も高ノイズ解に収束する可能性があります。そのため、異なる初期化に対して数回の最適化を繰り返すことが重要です。</target>
        </trans-unit>
        <trans-unit id="d19a1528c92e37a37fb4fd9cad2cad1ac3d91123" translate="yes" xml:space="preserve">
          <source>This example illustrates the differences between univariate F-test statistics and mutual information.</source>
          <target state="translated">この例は、一変量F-検定統計量と相互情報の違いを示しています。</target>
        </trans-unit>
        <trans-unit id="7867032d06fe0e647e7865e3d58419806006e425" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of monotonic constraints on a gradient boosting estimator.</source>
          <target state="translated">この例は、勾配ブースト推定器に対する単調制約の効果を示しています。</target>
        </trans-unit>
        <trans-unit id="b411e019157b9b0953b37eb36e27bc6a8ffb3f5f" translate="yes" xml:space="preserve">
          <source>This example illustrates the effect of the parameters &lt;code&gt;gamma&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt; of the Radial Basis Function (RBF) kernel SVM.</source>
          <target state="translated">この例は、放射基底関数（RBF）カーネルSVM のパラメーター &lt;code&gt;gamma&lt;/code&gt; と &lt;code&gt;C&lt;/code&gt; の効果を示しています。</target>
        </trans-unit>
        <trans-unit id="0f49634dcf1598fde3c403bd7ddd702e3816c634" translate="yes" xml:space="preserve">
          <source>This example illustrates the need for robust covariance estimation on a real data set. It is useful both for outlier detection and for a better understanding of the data structure.</source>
          <target state="translated">この例は、実データセットでのロバストな共分散推定の必要性を示しています。これは、外れ値の検出にも、データ構造の理解を深めるのにも役立ちます。</target>
        </trans-unit>
        <trans-unit id="dc09ff23a3cae32be328d47d0a0a7e64185cd75a" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).</source>
          <target state="translated">この例は、ハイパーパラメータの選択が異なる場合の RBF カーネルの GPC の予測確率を示しています。最初の図は、任意に選択されたハイパーパラメータと最大対数限界尤度(LML)に対応するハイパーパラメータを用いた場合のGPCの予測確率を示しています。</target>
        </trans-unit>
        <trans-unit id="d49b62c58d1a1ad4b52cfdb4df97043fcb25dfc7" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">この例は、虹彩データセットの 2 次元バージョンにおける等方性および異方性 RBF カーネルの GPC の予測確率を示している。異方性RBFカーネルは、2つの特徴次元に異なる長さのスケールを割り当てることで、わずかに高い対数限界尤度を得ることができます。</target>
        </trans-unit>
        <trans-unit id="f8e8b4dfa6bc8bbc237c34d26328609c3561c0d3" translate="yes" xml:space="preserve">
          <source>This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris-dataset. This illustrates the applicability of GPC to non-binary classification. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.</source>
          <target state="translated">この例は、虹彩データセットの2次元版における等方性と異方性のRBFカーネルに対するGPCの予測確率を示している。これは、非二元分類へのGPCの適用可能性を示している。異方性RBFカーネルは、2つの特徴次元に異なる長さスケールを割り当てることで、わずかに高い対数限界尤度を得ることができる。</target>
        </trans-unit>
        <trans-unit id="d60d503f722a9b87495f756d071794c2e2c52164" translate="yes" xml:space="preserve">
          <source>This example illustrates the prior and posterior of a GPR with different kernels. Mean, standard deviation, and 10 samples are shown for both prior and posterior.</source>
          <target state="translated">この例は、異なるカーネルを持つGPRの事前および事後を示しています。平均、標準偏差、および10サンプルが、先行と事後の両方で示されています。</target>
        </trans-unit>
        <trans-unit id="404891c56bd0f5f01fae61c2e12336745bf204d5" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Gaussian processes for regression and classification tasks on data that are not in fixed-length feature vector form. This is achieved through the use of kernel functions that operates directly on discrete structures such as variable-length sequences, trees, and graphs.</source>
          <target state="translated">この例では、固定長の特徴ベクトル形式ではないデータ上での回帰および分類タスクへのガウス過程の使用を説明しています。これは、可変長のシーケンス、木、グラフなどの離散構造に直接作用するカーネル関数を使用することで達成されます。</target>
        </trans-unit>
        <trans-unit id="b759d3b33b67e0716b08ee9d527244bce9326eed" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of Poisson, Gamma and Tweedie regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt;, and is inspired by an R tutorial &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">この例は、&lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;フランスのモーターサードパーティの責任請求データセット&lt;/a&gt;でのポアソン、ガンマ、およびトゥイーディー回帰の使用を示しており、Rチュートリアル&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1に&lt;/a&gt;触発されています。</target>
        </trans-unit>
        <trans-unit id="d658c6dcc61e946966ad0e8390aa06974df82a41" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of log-linear Poisson regression on the &lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;French Motor Third-Party Liability Claims dataset&lt;/a&gt; from &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and compares it with a linear model fitted with the usual least squared error and a non-linear GBRT model fitted with the Poisson loss (and a log-link).</source>
          <target state="translated">この例は、&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;からの&lt;a href=&quot;https://www.openml.org/d/41214&quot;&gt;フランスのモーターサードパーティ責任請求データセット&lt;/a&gt;での対数線形ポアソン回帰の使用を示し、通常の最小二乗誤差に適合した線形モデルおよびポアソン損失に適合した非線形GBRTモデルと比較します（およびログリンク）。</target>
        </trans-unit>
        <trans-unit id="7e4f09a45ae58596e6f6f82a5f372f88442c0679" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt; meta-estimator to perform multi-output regression. A random forest regressor is used, which supports multi-output regression natively, so the results can be compared.</source>
          <target state="translated">この例は、&lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;multioutput.MultiOutputRegressor&lt;/a&gt;メタ推定器を使用してマルチ出力回帰を実行する方法を示しています。ランダムフォレストリグレッサーが使用されます。これは、ネイティブにマルチ出力回帰をサポートするため、結果を比較できます。</target>
        </trans-unit>
        <trans-unit id="b7cdc524f76e4e3da39b555dc7fb49145ad1abf9" translate="yes" xml:space="preserve">
          <source>This example illustrates the use of the print_changed_only global parameter.</source>
          <target state="translated">この例では、グローバル・パラメータ print_changed_only の使用方法を説明します。</target>
        </trans-unit>
        <trans-unit id="8a4413b8994df2fb3a9be31d12e5c3eff453a657" translate="yes" xml:space="preserve">
          <source>This example illustrates visually in the feature space a comparison by results using two different component analysis techniques.</source>
          <target state="translated">この例では、2つの異なる成分分析手法を用いた結果による比較を特徴空間で視覚的に説明しています。</target>
        </trans-unit>
        <trans-unit id="a61e83a5c393fe6eb13b5e3a4d37f5a941d5abef" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">この例では、Hastieら、2009年図10.2に基づいて&lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;と離散SAMME間の性能の違い示す&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;ブースティングアルゴリズムと実SAMME.Rブースティングアルゴリズム。両方のアルゴリズムは、ターゲットYが10個の入力特徴の非線形関数である二項分類タスクで評価されます。</target>
        </trans-unit>
        <trans-unit id="2cd2616385e5968100e838cea35843639b5d4649" translate="yes" xml:space="preserve">
          <source>This example is based on Figure 10.2 from Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and illustrates the difference in performance between the discrete SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; boosting algorithm and real SAMME.R boosting algorithm. Both algorithms are evaluated on a binary classification task where the target Y is a non-linear function of 10 input features.</source>
          <target state="translated">この例は、Hastie et al 2009 &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]の&lt;/a&gt;図10.2に基づいており、離散SAMME &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;ブースティングアルゴリズムと実際のSAMME.Rブースティングアルゴリズムのパフォーマンスの違いを示しています。両方のアルゴリズムは、ターゲットYが10個の入力フィーチャの非線形関数であるバイナリ分類タスクで評価されます。</target>
        </trans-unit>
        <trans-unit id="f74f72b73b7f5fc12f50525ee3a073668f796ed6" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &amp;ldquo;Gaussian Processes for Machine Learning&amp;rdquo; [RW2006]. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 2001. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">この例は、「機械学習のためのガウス過程」[RW2006]のセクション5.4.3に基づいています。対数マージナル尤度での勾配上昇を使用した複雑なカーネルエンジニアリングとハイパーパラメーター最適化の例を示しています。データは、1958年から2001年の間にハワイのマウナロア天文台で収集された月間平均大気中CO2濃度（体積百万分の1（ppmv））で構成されています。CO2濃度を時間tの関数としてモデル化することが目的です。</target>
        </trans-unit>
        <trans-unit id="b3b5741f90375b259727a574f2a0488e7637e5bc" translate="yes" xml:space="preserve">
          <source>This example is based on Section 5.4.3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]&lt;/a&gt;. It illustrates an example of complex kernel engineering and hyperparameter optimization using gradient ascent on the log-marginal-likelihood. The data consists of the monthly average atmospheric CO2 concentrations (in parts per million by volume (ppmv)) collected at the Mauna Loa Observatory in Hawaii, between 1958 and 1997. The objective is to model the CO2 concentration as a function of the time t.</source>
          <target state="translated">この例は、&lt;a href=&quot;#rw2006&quot; id=&quot;id2&quot;&gt;[RW2006]の&lt;/a&gt;セクション5.4.3に基づいています。対数マージナル尤度で勾配上昇を使用した複雑なカーネルエンジニアリングとハイパーパラメーター最適化の例を示しています。データは、1958年から1997年の間にハワイのマウナロア天文台で収集された月間平均大気CO2濃度（体積百万分率（ppmv））で構成されています。CO2濃度を時間tの関数としてモデル化することが目的です。</target>
        </trans-unit>
        <trans-unit id="9ecc1c02a68f38d70271669af08df8c1497b1d98" translate="yes" xml:space="preserve">
          <source>This example is commented in the &lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;tutorial section of the user manual&lt;/a&gt;.</source>
          <target state="translated">この例は&lt;a href=&quot;../../tutorial/basic/tutorial#introduction&quot;&gt;、ユーザーマニュアルのチュートリアルセクションで&lt;/a&gt;コメントされています。</target>
        </trans-unit>
        <trans-unit id="9143eb314f05280f157b4081755ef4be5d0d1857" translate="yes" xml:space="preserve">
          <source>This example is meant to illustrate situations where k-means will produce unintuitive and possibly unexpected clusters. In the first three plots, the input data does not conform to some implicit assumption that k-means makes and undesirable clusters are produced as a result. In the last plot, k-means returns intuitive clusters despite unevenly sized blobs.</source>
          <target state="translated">この例は、k-meansが直感的でない、おそらく予想外のクラスタを生成する状況を説明することを意図しています。最初の3つのプロットでは、入力データがk-meansの暗黙の仮定に適合しておらず、結果として望ましくないクラスタが生成されています。最後のプロットでは、k-meansは不均一なサイズのブロブにもかかわらず、直感的なクラスタを返します。</target>
        </trans-unit>
        <trans-unit id="0549792fdb7404b1799803948805283b1004db4d" translate="yes" xml:space="preserve">
          <source>This example plots several randomly generated classification datasets. For easy visualization, all datasets have 2 features, plotted on the x and y axis. The color of each point represents its class label.</source>
          <target state="translated">この例は、ランダムに生成されたいくつかの分類データセットをプロットしています。簡単に可視化できるように、すべてのデータセットは2つの特徴量を持ち、x軸とy軸にプロットされています。各点の色は、そのクラス・ラベルを表しています。</target>
        </trans-unit>
        <trans-unit id="301c1da5ab62941da3ba93fb4d30f8869ad9b8b5" translate="yes" xml:space="preserve">
          <source>This example plots the corresponding dendrogram of a hierarchical clustering using AgglomerativeClustering and the dendrogram method available in scipy.</source>
          <target state="translated">この例では、AgglomerativeClusteringとscipyで利用可能なdendrogramメソッドを用いて、階層型クラスタリングの対応するデンドログラムをプロットしています。</target>
        </trans-unit>
        <trans-unit id="fb84e7488212d58818869cb1a848aafb46dc6573" translate="yes" xml:space="preserve">
          <source>This example plots the covariance ellipsoids of each class and decision boundary learned by LDA and QDA. The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.</source>
          <target state="translated">この例では、LDAとQDAで学習した各クラスと決定境界の共分散楕円体をプロットしています。楕円体は、各クラスの標準偏差を2倍にして表示しています。LDAでは、標準偏差はすべてのクラスで同じですが、QDAでは各クラスごとに標準偏差を持っています。</target>
        </trans-unit>
        <trans-unit id="61cf8846c08926de131cab630666b0d7a1ff4033" translate="yes" xml:space="preserve">
          <source>This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class models with a Dirichlet distribution prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt;) and a Dirichlet process prior (&lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt;). On each figure, we plot the results for three different values of the weight concentration prior.</source>
          <target state="translated">この例では、 &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; ガウス混合モデルモデルによって近似されたおもちゃのデータセット（3つのガウスの混合）から得られた楕円を、事前のディリクレ分布（ &lt;code&gt;weight_concentration_prior_type='dirichlet_distribution'&lt;/code&gt; ）と事前のディリクレプロセス（ &lt;code&gt;weight_concentration_prior_type='dirichlet_process'&lt;/code&gt; ）でプロットします。各図で、事前の重量濃度の3つの異なる値の結果をプロットします。</target>
        </trans-unit>
        <trans-unit id="e769643d14b1851635097bc926523b99ade21d56" translate="yes" xml:space="preserve">
          <source>This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages &lt;code&gt;annoy&lt;/code&gt; and &lt;code&gt;nmslib&lt;/code&gt; to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with &lt;code&gt;pip install annoy nmslib&lt;/code&gt;.</source>
          <target state="translated">この例は、パイプラインでKNeighborsTransformerとTSNEをチェーンする方法を示しています。また、パッケージ &lt;code&gt;nmslib&lt;/code&gt; とnmslibをラップし &lt;code&gt;annoy&lt;/code&gt; 、KNeighborsTransformerを置き換え、近似最近傍を実行する方法も示します。これらのパッケージは、 &lt;code&gt;pip install annoy nmslib&lt;/code&gt; できます。</target>
        </trans-unit>
        <trans-unit id="b0d46d4faf4d4d45c7ba844c05b8ff931d890d6c" translate="yes" xml:space="preserve">
          <source>This example presents the different strategies implemented in KBinsDiscretizer:</source>
          <target state="translated">この例では、KBinsDiscretizer で実装されているさまざまな戦略を紹介します。</target>
        </trans-unit>
        <trans-unit id="83f4e337d08dbc1524d014ed0118fe74e8fd5454" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">この例は、Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1の&lt;/a&gt;図1を再現し、ブースティングがマルチクラス問題の予測精度をどのように改善できるかを示しています。分類データセットは、10次元の標準正規分布を取り、ネストされた同心の10次元球で区切られた3つのクラスを定義して、各クラスにほぼ等しい数のサンプルが含まれるようにすることで構築されます（\（\ chi ^ 2 \）分布の分位数） ）。</target>
        </trans-unit>
        <trans-unit id="aff95617011fc0f39a1d4573107679df90fa3c83" translate="yes" xml:space="preserve">
          <source>This example reproduces Figure 1 of Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt; and shows how boosting can improve prediction accuracy on a multi-class problem. The classification dataset is constructed by taking a ten-dimensional standard normal distribution and defining three classes separated by nested concentric ten-dimensional spheres such that roughly equal numbers of samples are in each class (quantiles of the \(\chi^2\) distribution).</source>
          <target state="translated">この例では、Zhu et al &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;[1]の&lt;/a&gt;図1を再現し、ブースティングによってマルチクラス問題の予測精度を向上させる方法を示します。分類データセットは、10次元の標準正規分布を取り、入れ子になった同心の10次元の球で区切られた3つのクラスを定義することによって構築され、各クラス（\（\ chi ^ 2 \）分布の分位数）にサンプルの数がほぼ等しくなるようにします。 ）。</target>
        </trans-unit>
        <trans-unit id="f0193d5eae04ea4c45d1272eb8f24ceb76514e1e" translate="yes" xml:space="preserve">
          <source>This example serves as a visual check that IPCA is able to find a similar projection of the data to PCA (to a sign flip), while only processing a few samples at a time. This can be considered a &amp;ldquo;toy example&amp;rdquo;, as IPCA is intended for large datasets which do not fit in main memory, requiring incremental approaches.</source>
          <target state="translated">この例は、IPCAがPCAへの（サインフリップへの）データの同様の投影を検出できる一方で、一度にいくつかのサンプルのみを処理できることを視覚的に確認する役割を果たします。これは「おもちゃの例」と考えることができます。IPCAは、メインメモリに収まらず、インクリメンタルアプローチが必要な大規模なデータセットを対象としているためです。</target>
        </trans-unit>
        <trans-unit id="3dfa9a56451c107730b94ff094ad060fe6660b05" translate="yes" xml:space="preserve">
          <source>This example should be taken with a grain of salt, as the intuition conveyed does not necessarily carry over to real datasets. Particularly in high-dimensional spaces, data can more easily be separated linearly. Moreover, using feature discretization and one-hot encoding increases the number of features, which easily lead to overfitting when the number of samples is small.</source>
          <target state="translated">この例は、伝えられた直感が必ずしも実際のデータセットに反映されるとは限らないので、大目に見てください。特に高次元空間では、データはより簡単に線形に分離することができます。また、特徴量の離散化やワンホット符号化を用いると、特徴量が増えてしまい、サンプル数が少ない場合にはオーバーフィットを起こしやすくなります。</target>
        </trans-unit>
        <trans-unit id="ad21e470ff2bffe875ca12e50c6f8a883eaa0515" translate="yes" xml:space="preserve">
          <source>This example shows an example usage of the &lt;code&gt;split&lt;/code&gt; method.</source>
          <target state="translated">この例は、 &lt;code&gt;split&lt;/code&gt; メソッドの使用例を示しています。</target>
        </trans-unit>
        <trans-unit id="05321a1b8964aa5eaada463be8f8b6ab44686817" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.</source>
          <target state="translated">この例は、2Dデータセット上の異なる異常検出アルゴリズムの特徴を示しています。データセットには1つまたは2つのモード(高密度の領域)が含まれており、マルチモーダルデータに対処するアルゴリズムの能力を示しています。</target>
        </trans-unit>
        <trans-unit id="9671740bdc9e0f010272719df08d61d30b070724" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different clustering algorithms on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D. With the exception of the last dataset, the parameters of each of these dataset-algorithm pairs has been tuned to produce good clustering results. Some algorithms are more sensitive to parameter values than others.</source>
          <target state="translated">この例は、「興味深い」が2Dであるデータセットのさまざまなクラスタリングアルゴリズムの特性を示しています。最後のデータセットを除いて、これらのデータセットとアルゴリズムの各ペアのパラメーターは、適切なクラスタリング結果を生成するように調整されています。一部のアルゴリズムは、他のアルゴリズムよりもパラメーター値に敏感です。</target>
        </trans-unit>
        <trans-unit id="408c25df8162bc85c75adf89aefb6c4283aab313" translate="yes" xml:space="preserve">
          <source>This example shows characteristics of different linkage methods for hierarchical clustering on datasets that are &amp;ldquo;interesting&amp;rdquo; but still in 2D.</source>
          <target state="translated">この例は、「興味深い」が2Dのままであるデータセットの階層的クラスタリングのさまざまなリンケージメソッドの特性を示しています。</target>
        </trans-unit>
        <trans-unit id="ee904b77cbf769dbe7d1093eb852f864329f4bb5" translate="yes" xml:space="preserve">
          <source>This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset. With this generative model in place, new samples can be drawn. These new samples reflect the underlying model of the data.</source>
          <target state="translated">この例では、強力なノンパラメトリック密度推定技術であるカーネル密度推定(KDE)を使用して、データセットの生成モデルを学習する方法を示します。この生成モデルがあると、新しいサンプルを描くことができます。これらの新しいサンプルは、データの基礎となるモデルを反映しています。</target>
        </trans-unit>
        <trans-unit id="54102d8f78c42d496181e5bcdf5a40bdaee3e42d" translate="yes" xml:space="preserve">
          <source>This example shows how quantile regression can be used to create prediction intervals.</source>
          <target state="translated">この例では、クォンタイル回帰がどのようにして予測区間を作成するために使用できるかを示しています。</target>
        </trans-unit>
        <trans-unit id="682ea376dc5fd413204f119c7903367cc1b71149" translate="yes" xml:space="preserve">
          <source>This example shows how to build a classification pipeline with a BernoulliRBM feature extractor and a &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; classifier. The hyperparameters of the entire model (learning rate, hidden layer size, regularization) were optimized by grid search, but the search is not reproduced here because of runtime constraints.</source>
          <target state="translated">この例は、BernoulliRBM特徴抽出器と&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;分類器を使用して分類パイプラインを構築する方法を示しています。モデル全体のハイパーパラメータ（学習率、隠れ層サイズ、正則化）はグリッド検索によって最適化されましたが、実行時の制約のため、検索はここでは再現されません。</target>
        </trans-unit>
        <trans-unit id="e6287a37f5ab2f7e58b3aa65bfc9b371f8d2e434" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">この例は、カリフォルニアの住宅データセットでトレーニングされた&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;から部分依存プロットを取得する方法を示しています。例は&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;から取られています。</target>
        </trans-unit>
        <trans-unit id="acf93c17a79b2f475e2915043f3e806cbddc60a2" translate="yes" xml:space="preserve">
          <source>This example shows how to obtain partial dependence plots from a &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; trained on the California housing dataset. The example is taken from &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">部分的依存性プロットを入手する方法この例では、ショー&lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt; &lt;code&gt;MLPRegressor&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;カリフォルニアハウジングセットに訓練を受けました。例は&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;から取られています。</target>
        </trans-unit>
        <trans-unit id="dd4b844c3488b502b915a6b11d22b13911beaa74" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores.</source>
          <target state="translated">この例では、SVC(サポートベクター分類器)を実行する前に一変量の特徴選択を行い、分類スコアを向上させる方法を示しています。</target>
        </trans-unit>
        <trans-unit id="f7865c444403c29f04e970d66c2c5367cc834a8b" translate="yes" xml:space="preserve">
          <source>This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features.</source>
          <target state="translated">この例では、分類スコアを改善するためにSVC(サポートベクター分類器)を実行する前に一変量の特徴選択を実行する方法を示します。虹彩のデータセット(4つの特徴量)を使用し、36の非情報的特徴量を追加しています。特徴の10%程度を選択したときに、我々のモデルが最高のパフォーマンスを発揮することがわかります。</target>
        </trans-unit>
        <trans-unit id="47a26e628df959c3e5ed3ffe4f4f3490e8927a8d" translate="yes" xml:space="preserve">
          <source>This example shows how to plot some of the first layer weights in a MLPClassifier trained on the MNIST dataset.</source>
          <target state="translated">この例では,MNISTデータセット上で学習されたMLPClassifierの第1層の重みをプロットする方法を示しています.</target>
        </trans-unit>
        <trans-unit id="dd07bd7e7afed03f3c2a3c74458c42dc14028dfe" translate="yes" xml:space="preserve">
          <source>This example shows how to plot the decision surface for four SVM classifiers with different kernels.</source>
          <target state="translated">この例では、異なるカーネルを持つ4つのSVM分類器の決定面をプロットする方法を示しています。</target>
        </trans-unit>
        <trans-unit id="981971245cdda71fb264be7304dc1e201a08b23b" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt;&lt;code&gt;cross_val_predict&lt;/code&gt;&lt;/a&gt; to visualize prediction errors.</source>
          <target state="translated">この例は、&lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_predict#sklearn.model_selection.cross_val_predict&quot;&gt; &lt;code&gt;cross_val_predict&lt;/code&gt; &lt;/a&gt;を使用して予測エラーを視覚化する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="52dcf2b8bf47a153b3ba3beca30c9af85b850fad" translate="yes" xml:space="preserve">
          <source>This example shows how to use &lt;code&gt;cross_val_predict&lt;/code&gt; to visualize prediction errors.</source>
          <target state="translated">この例は、 &lt;code&gt;cross_val_predict&lt;/code&gt; を使用して予測エラーを視覚化する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="42d1610b65eff631d96069dbbdf35236afd1d573" translate="yes" xml:space="preserve">
          <source>This example shows how to use Permutation Importances as an alternative that can mitigate those limitations.</source>
          <target state="translated">この例では、これらの制限を緩和できる代替手段として、Permutation Importancesを使用する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="351c02b1031f149a08df70cbeed39cd2a6bb9ec7" translate="yes" xml:space="preserve">
          <source>This example shows that Kernel PCA is able to find a projection of the data that makes data linearly separable.</source>
          <target state="translated">この例では、カーネルPCAがデータを直線的に分離可能にするデータの射影を見つけることができることを示している。</target>
        </trans-unit>
        <trans-unit id="607fdb6fda0285694fd1dd982f83082f2f9a6687" translate="yes" xml:space="preserve">
          <source>This example shows that imputing the missing values can give better results than discarding the samples containing any missing value. Imputing does not always improve the predictions, so please check via cross-validation. Sometimes dropping rows or using marker values is more effective.</source>
          <target state="translated">この例では、欠損値を入力することで、欠損値を含むサンプルを破棄するよりも良い結果が得られることを示しています。インプットが必ずしも予測値を改善するとは限らないので、クロス・バリデーションで確認してください。行を削除したり、マーカー値を使用したりすると、より効果的な場合があります。</target>
        </trans-unit>
        <trans-unit id="b6045a3110197ccfd64402c3c879acac73bdaadb" translate="yes" xml:space="preserve">
          <source>This example shows that model selection can be performed with Gaussian Mixture Models using information-theoretic criteria (BIC). Model selection concerns both the covariance type and the number of components in the model. In that case, AIC also provides the right result (not shown to save time), but BIC is better suited if the problem is to identify the right model. Unlike Bayesian procedures, such inferences are prior-free.</source>
          <target state="translated">この例は、情報理論的基準(BIC)を使用してガウス混合モデルでモデル選択が実行できることを示しています。モデル選択は、共分散型とモデル内の成分数の両方に関係します。その場合、AICも正しい結果を提供しますが(時間を節約するために示されていません)、問題が正しいモデルを特定することであれば、BICの方が適しています。ベイズ的手続きとは異なり、そのような推論は事前に自由である。</target>
        </trans-unit>
        <trans-unit id="7ed4db944a196b1cb5ab23d8834c95cd5421c757" translate="yes" xml:space="preserve">
          <source>This example shows that you can do non-linear regression with a linear model, using a pipeline to add non-linear features. Kernel methods extend this idea and can induce very high (even infinite) dimensional feature spaces.</source>
          <target state="translated">この例は、非線形特徴量を追加するパイプラインを使用して、線形モデルで非線形回帰を行うことができることを示しています。カーネル法はこのアイデアを拡張し、非常に高い(無限であっても)次元の特徴空間を誘導することができます。</target>
        </trans-unit>
        <trans-unit id="48dcc848c2d6e1561f6c336d60b0fb518f9ab59a" translate="yes" xml:space="preserve">
          <source>This example shows the ROC response of different datasets, created from K-fold cross-validation. Taking all of these curves, it is possible to calculate the mean area under curve, and see the variance of the curve when the training set is split into different subsets. This roughly shows how the classifier output is affected by changes in the training data, and how different the splits generated by K-fold cross-validation are from one another.</source>
          <target state="translated">この例は、K-フォールド交差検証から作成された異なるデータセットのROC応答を示します。これらの曲線をすべて取ると、曲線下の平均面積を計算でき、訓練集合が異なるサブセットに分割されたときの曲線の分散を見ることができます。これは、分類器の出力が訓練データの変化によってどのように影響を受けるか、また、K-フォールド・クロス・バリデーションによって生成された分割が互いにどのように異なるかを大まかに示します。</target>
        </trans-unit>
        <trans-unit id="7b92e840bf44fca60c7edc394c5ccf3da0546857" translate="yes" xml:space="preserve">
          <source>This example shows the effect of imposing a connectivity graph to capture local structure in the data. The graph is simply the graph of 20 nearest neighbors.</source>
          <target state="translated">この例では、データの局所的な構造を捉えるために接続性グラフを課すことの効果を示しています。このグラフは、単純に20個の最も近い隣人のグラフです。</target>
        </trans-unit>
        <trans-unit id="a122bd5b47879a72d10715b2e2741901d74ebd5f" translate="yes" xml:space="preserve">
          <source>This example shows the reconstruction of an image from a set of parallel projections, acquired along different angles. Such a dataset is acquired in &lt;strong&gt;computed tomography&lt;/strong&gt; (CT).</source>
          <target state="translated">この例は、異なる角度に沿って取得された一連の平行投影からの画像の再構成を示しています。このようなデータセットは、&lt;strong&gt;コンピューター断層撮影&lt;/strong&gt;（CT）で取得されます。</target>
        </trans-unit>
        <trans-unit id="277c7e399c7f521a9367c3279ba6605ffa32bb5b" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">この例は、画像分類タスク(顔)のピクセルの重要度を評価するための木の森の使用を示しています。画素の温度が高いほど重要度が高いことを示しています。</target>
        </trans-unit>
        <trans-unit id="1fc99c46b3490d43b644ebffe104cba9573e1195" translate="yes" xml:space="preserve">
          <source>This example shows the use of forests of trees to evaluate the impurity-based importance of the pixels in an image classification task (faces). The hotter the pixel, the more important.</source>
          <target state="translated">この例は、画像分類タスク(顔)のピクセルの不純物に基づく重要度を評価するための木の森の使用を示しています。画素が熱いほど重要度が高いことを示しています。</target>
        </trans-unit>
        <trans-unit id="181df9c721e88b620fbcd3038af372d2bc17958d" translate="yes" xml:space="preserve">
          <source>This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half.</source>
          <target state="translated">この例は、画像を完成させるためのマルチ出力推定器の使用を示しています。目標は、顔の上半分を与えられた顔の下半分を予測することです。</target>
        </trans-unit>
        <trans-unit id="c194d9ad3fd820ff97a5b60a54a77ad5e096ac46" translate="yes" xml:space="preserve">
          <source>This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:</source>
          <target state="translated">この例では、マルチラベル文書分類問題をシミュレートしています。データセットは、以下の処理に基づいてランダムに生成される。</target>
        </trans-unit>
        <trans-unit id="beca62f6aeebe1ac71c16bdf04b277689fc51da6" translate="yes" xml:space="preserve">
          <source>This example uses &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; on a graph created from voxel-to-voxel difference on an image to break this image into multiple partly-homogeneous regions.</source>
          <target state="translated">この例では、画像のボクセルごとの差から作成されたグラフで&lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;スペクトルクラスタリング&lt;/a&gt;を使用して、この画像を複数の部分的に均一な領域に分割します。</target>
        </trans-unit>
        <trans-unit id="b1b3f16a0bb367262a72b24da0008ca16f86a096" translate="yes" xml:space="preserve">
          <source>This example uses a large dataset of faces to learn a set of 20 x 20 images patches that constitute faces.</source>
          <target state="translated">この例では、顔を構成する20×20の画像パッチのセットを学習するために、顔の大規模なデータセットを使用しています。</target>
        </trans-unit>
        <trans-unit id="0ad2a4281006cf2ce3833b3619a37abf58d678e0" translate="yes" xml:space="preserve">
          <source>This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range.</source>
          <target state="translated">この例では、さまざまなスケーラ、トランスフォーマ、およびノーマライザを使用して、データを事前に定義された範囲内に収めるようにしています。</target>
        </trans-unit>
        <trans-unit id="e1bfbae38c6acd2b8b362eacb6ca0227cf12cdc6" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; class to demonstrate the principles of Kernel Density Estimation in one dimension.</source>
          <target state="translated">この例では、&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt;クラスを使用して、カーネル密度推定の原理を1次元で示します。</target>
        </trans-unit>
        <trans-unit id="a99077db11e6455dfdf5d225265c8630cb316352" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;.</source>
          <target state="translated">この例では、 &lt;code&gt;scipy.stats&lt;/code&gt; モジュールを使用します。このモジュールには、 &lt;code&gt;expon&lt;/code&gt; 、 &lt;code&gt;gamma&lt;/code&gt; 、 &lt;code&gt;uniform&lt;/code&gt; 、 &lt;code&gt;randint&lt;/code&gt; などのサンプリングパラメーターに役立つ多くの分布が含まれています。</target>
        </trans-unit>
        <trans-unit id="1c91a9c343e9d52fecff06520d2432c55d78e2a0" translate="yes" xml:space="preserve">
          <source>This example uses the &lt;code&gt;scipy.stats&lt;/code&gt; module, which contains many useful distributions for sampling parameters, such as &lt;code&gt;expon&lt;/code&gt;, &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;uniform&lt;/code&gt; or &lt;code&gt;randint&lt;/code&gt;. In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="translated">この例では、 &lt;code&gt;scipy.stats&lt;/code&gt; モジュールを使用しています。このモジュールには、 &lt;code&gt;expon&lt;/code&gt; 、 &lt;code&gt;gamma&lt;/code&gt; 、 &lt;code&gt;uniform&lt;/code&gt; 、 &lt;code&gt;randint&lt;/code&gt; などのサンプリングパラメーターに役立つ多くの分布が含まれています。原則として、値をサンプリングする &lt;code&gt;rvs&lt;/code&gt; （ランダム変量サンプル）メソッドを提供する任意の関数を渡すことができます。 &lt;code&gt;rvs&lt;/code&gt; 関数の呼び出しは、連続する呼び出しで可能なパラメーター値から独立したランダムサンプルを提供する必要があります。</target>
        </trans-unit>
        <trans-unit id="d9381762b80079a0275cf5384c50652951b2c3b8" translate="yes" xml:space="preserve">
          <source>This example uses the only the first feature of the &lt;code&gt;diabetes&lt;/code&gt; dataset, in order to illustrate a two-dimensional plot of this regression technique. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.</source>
          <target state="translated">この例では、この回帰手法の2次元プロットを示すために、 &lt;code&gt;diabetes&lt;/code&gt; データセットの最初の機能のみを使用しています。プロットに直線が表示され、線形回帰が、データセットで観測された応答と線形近似によって予測された応答との間の残差二乗和を最適化する直線を描画しようとする様子を示しています。</target>
        </trans-unit>
        <trans-unit id="c6bb5d76743a81844f0fc5afc16345d399cae103" translate="yes" xml:space="preserve">
          <source>This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.</source>
          <target state="translated">この例は、SGDとAdamを含むさまざまな確率的学習戦略のトレーニング損失曲線を可視化したものです。時間的制約があるため、ここではいくつかの小さなデータセットを使用していますが、L-BFGS の方が適しているかもしれません。しかし、これらの例に示されている一般的な傾向は、より大きなデータセットにも当てはまるようです。</target>
        </trans-unit>
        <trans-unit id="65646a35859e04e16667e59a0e282463725f9c9e" translate="yes" xml:space="preserve">
          <source>This example visualizes the behavior of several common scikit-learn objects for comparison.</source>
          <target state="translated">この例では、比較のためにいくつかの一般的な scikit-learn オブジェクトの動作を視覚化しています。</target>
        </trans-unit>
        <trans-unit id="49dcb9492cd2c3de6ca468ca869fddbd4adf1109" translate="yes" xml:space="preserve">
          <source>This example visualizes the partitions given by several trees and shows how the transformation can also be used for non-linear dimensionality reduction or non-linear classification.</source>
          <target state="translated">この例は、いくつかの木によって与えられた分割を可視化し、変換が非線形次元削減や非線形分類にも使用できることを示しています。</target>
        </trans-unit>
        <trans-unit id="6942c7999112e031e7e9f390f17a63a6ea65b8dd" translate="yes" xml:space="preserve">
          <source>This example was inspired by the &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoost documentation&lt;/a&gt;.</source>
          <target state="translated">この例は、&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html&quot;&gt;XGBoostのドキュメント&lt;/a&gt;に触発されました。</target>
        </trans-unit>
        <trans-unit id="6888e16176d5ba984d30e5b2aecac9e36e3202eb" translate="yes" xml:space="preserve">
          <source>This example will also work by replacing &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; with &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt;. Setting the &lt;code&gt;loss&lt;/code&gt; parameter of the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; equal to &lt;code&gt;hinge&lt;/code&gt; will yield behaviour such as that of a SVC with a linear kernel.</source>
          <target state="translated">この例は、 &lt;code&gt;SVC(kernel=&quot;linear&quot;)&lt;/code&gt; を &lt;code&gt;SGDClassifier(loss=&quot;hinge&quot;)&lt;/code&gt; に置き換えることでも機能します。設定 &lt;code&gt;loss&lt;/code&gt; のパラメータ&lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; こと&lt;/a&gt;に等しい &lt;code&gt;hinge&lt;/code&gt; そのような線形カーネルを持つSVCのような挙動をもたらします。</target>
        </trans-unit>
        <trans-unit id="b7e7228e1bc6d35fed471b6c3015699404cca0fb" translate="yes" xml:space="preserve">
          <source>This example will generate three figures.</source>
          <target state="translated">この例では、3つの数字が生成されます。</target>
        </trans-unit>
        <trans-unit id="5d6705d9213c8c7167b6f8a12276b073092deeca" translate="yes" xml:space="preserve">
          <source>This example will provide some hints in interpreting coefficient in linear models, pointing at problems that arise when either the linear model is not appropriate to describe the dataset, or when features are correlated.</source>
          <target state="translated">この例は、線形モデルの係数を解釈する際のヒントを提供し、線形モデルがデータセットを記述するのに適切でない場合や、特徴量が相関している場合に発生する問題を指摘します。</target>
        </trans-unit>
        <trans-unit id="08633b59361c5b4332dffd09b9ac681bbe920080" translate="yes" xml:space="preserve">
          <source>This example, inspired from Chen&amp;rsquo;s publication [1], shows a comparison of the estimated MSE of the LW and OAS methods, using Gaussian distributed data.</source>
          <target state="translated">この例は、Chenの出版物[1]からヒントを得て、ガウス分布データを使用して、LWおよびOASメソッドの推定MSEの比較を示しています。</target>
        </trans-unit>
        <trans-unit id="8aeed7fa163e961c6e7fadbb3ef8c5a658c9cc15" translate="yes" xml:space="preserve">
          <source>This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations.</source>
          <target state="translated">この例では、KNeighborsClassifier で使用する前に k 個の最近傍値を事前に計算する方法を示します。KNeighborsClassifier は内部的に最近傍を計算することができますが、それを事前に計算することで、より細かいパラメータ制御、複数使用のためのキャッシュ、カスタム実装など、いくつかの利点を得ることができます。</target>
        </trans-unit>
        <trans-unit id="f9260a90e6c35e520398765702d07497fe04f1a8" translate="yes" xml:space="preserve">
          <source>This examples shows how a classifier is optimized by cross-validation, which is done using the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt; object on a development set that comprises only half of the available labeled data.</source>
          <target state="translated">この例は、利用可能なラベル付きデータの半分のみを含む開発セットで&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; &lt;/a&gt;オブジェクトを使用して行われる交差検証によって分類子が最適化される方法を示しています。</target>
        </trans-unit>
        <trans-unit id="e16048c7f7cf75798d53fe7e675cc81cd1d6af8b" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">この例は、人工的な分類タスクにおける特徴の重要性を評価するために、木の森を使用していることを示しています。赤い棒は、木の森の特徴の重要度と、その木間変動を示しています。</target>
        </trans-unit>
        <trans-unit id="cdab1575e5f24de85ab913b14f241e0bd17fea2d" translate="yes" xml:space="preserve">
          <source>This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. The red bars are the impurity-based feature importances of the forest, along with their inter-trees variability.</source>
          <target state="translated">この例は、人工的な分類タスクにおける特徴の重要性を評価するための木の森の使用を示しています。赤い棒は、不純物に基づいた森の特徴の重要度と、それらの木間変動を示しています。</target>
        </trans-unit>
        <trans-unit id="4fb4f14900902539137295018be0a0c7a07b1094" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;Cross-validated estimators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">この演習は、&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;モデル選択の&lt;/a&gt;「&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-estimators-tut&quot;&gt;相互検証&lt;/a&gt;された推定量」の部分で使用されます。「&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;科学データ処理のための統計学習に関するチュートリアル」&lt;/a&gt;の「推定量とそのパラメーターの選択」セクション。</target>
        </trans-unit>
        <trans-unit id="621b0c8349abb129c7bc150bd9745f46f49af3ab" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;Cross-validation generators&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;Model selection: choosing estimators and their parameters&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">この演習は、&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#model-selection-tut&quot;&gt;モデル選択&lt;/a&gt;の&lt;a href=&quot;../../tutorial/statistical_inference/model_selection#cv-generators-tut&quot;&gt;交差検証ジェネレーター&lt;/a&gt;部分で使用されます。「&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;科学データ処理のための統計学習に関するチュートリアル」&lt;/a&gt;の「推定量とそのパラメーターの選択」セクション。</target>
        </trans-unit>
        <trans-unit id="6915ba6643fea2f9e387885428a6e6189c7df3bf" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;Classification&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">この演習は、&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;「教師あり学習：&lt;/a&gt;&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;科学的データ処理のための統計学習に関するチュートリアル」&lt;/a&gt;の「高次元の観測からの出力変数の予測」の&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#clf-tut&quot;&gt;分類の&lt;/a&gt;部分で使用されます。</target>
        </trans-unit>
        <trans-unit id="421684adc1a996556d28fe46ff4c101c2f3063ef" translate="yes" xml:space="preserve">
          <source>This exercise is used in the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;Using kernels&lt;/a&gt; part of the &lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;Supervised learning: predicting an output variable from high-dimensional observations&lt;/a&gt; section of the &lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;A tutorial on statistical-learning for scientific data processing&lt;/a&gt;.</source>
          <target state="translated">この演習は、&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#supervised-learning-tut&quot;&gt;「教師あり学習：&lt;/a&gt;&lt;a href=&quot;../../tutorial/statistical_inference/index#stat-learn-tut-index&quot;&gt;科学的データ処理のための統計的学習に関するチュートリアル」&lt;/a&gt;の「高次元観測からの出力変数の予測」の&lt;a href=&quot;../../tutorial/statistical_inference/supervised_learning#using-kernels-tut&quot;&gt;カーネル&lt;/a&gt;の使用の部分で使用されます。</target>
        </trans-unit>
        <trans-unit id="dadb46eeaf7a2bf2f8f61dc107ba2d3f5d55d33a" translate="yes" xml:space="preserve">
          <source>This extends to the multiclass case as follows. Let the true labels for a set of samples be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(P\) be a matrix of probability estimates, with \(p_{i,k} = \operatorname{Pr}(t_{i,k} = 1)\). Then the log loss of the whole set is</source>
          <target state="translated">これは、マルチクラスの場合には、次のように拡張される。Let the true labels for a set of a samples is encoded as a 1-of-K binary indicator matrix ﾞ (Y\(Y)),i.e.e.if sample \(i))has label ﾞ (k)taken from a set of \(K)labels.\(P\)を確率推定行列とし、\(p_{i,k}=\operatorname{Pr}(t_{i,k}=1)とする。)とすると、集合全体の対数損失は</target>
        </trans-unit>
        <trans-unit id="826a67cf49f96f56e23921af61e52712fab61d33" translate="yes" xml:space="preserve">
          <source>This factory function wraps scoring functions for use in GridSearchCV and cross_val_score. It takes a score function, such as &lt;code&gt;accuracy_score&lt;/code&gt;, &lt;code&gt;mean_squared_error&lt;/code&gt;, &lt;code&gt;adjusted_rand_index&lt;/code&gt; or &lt;code&gt;average_precision&lt;/code&gt; and returns a callable that scores an estimator&amp;rsquo;s output.</source>
          <target state="translated">このファクトリー関数は、GridSearchCVおよびcross_val_scoreで使用するスコアリング関数をラップします。それは、次のような、スコア関数を取る &lt;code&gt;accuracy_score&lt;/code&gt; 、 &lt;code&gt;mean_squared_error&lt;/code&gt; 、 &lt;code&gt;adjusted_rand_index&lt;/code&gt; または &lt;code&gt;average_precision&lt;/code&gt; とそのスコア推定の出力呼び出し可能なを返します。</target>
        </trans-unit>
        <trans-unit id="5eb7a4eb6e2161d3d9f2a7b4c7010506ccf35ad1" translate="yes" xml:space="preserve">
          <source>This feature corresponds to the sepal length in cm. Once the quantile transformation applied, those landmarks approach closely the percentiles previously defined:</source>
          <target state="translated">この特徴は、cm単位のセパルの長さに対応しています。分位変換が適用されると、これらのランドマークは以前に定義されたパーセンタイルに近づきます。</target>
        </trans-unit>
        <trans-unit id="18a1d2c5a41fd4d57af7a6bb802060cade230322" translate="yes" xml:space="preserve">
          <source>This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.</source>
          <target state="translated">この特徴選択アルゴリズムは、目的の出力(y)ではなく、特徴(X)のみを見ているので、教師なし学習に使用することができます。</target>
        </trans-unit>
        <trans-unit id="677c582ff4a458e9dc8e636909bbbb985fe5cce6" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; preprocessor. This preprocessor transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">この図は、&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt;プリプロセッサを使用して作成されます。このプリプロセッサは、入力データマトリックスを指定された次数の新しいデータマトリックスに変換します。次のように使用できます。</target>
        </trans-unit>
        <trans-unit id="6faa801ac2c09333248247cbfc3515a179a790a8" translate="yes" xml:space="preserve">
          <source>This figure is created using the &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; transformer, which transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:</source>
          <target state="translated">この図は、入力データ行列を特定の次数の新しいデータ行列に変換する&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt;トランスフォーマーを使用して作成されています。次のように使用できます。</target>
        </trans-unit>
        <trans-unit id="adbd1df9acbf84e51fe5dc83e34aca6a9423eabf" translate="yes" xml:space="preserve">
          <source>This figure shows an example of such an ROC curve:</source>
          <target state="translated">この図は、このようなROC曲線の一例を示しています。</target>
        </trans-unit>
        <trans-unit id="e1207da0df5038f5f29891db83b7d5022ead8471" translate="yes" xml:space="preserve">
          <source>This folder is used by some large dataset loaders to avoid downloading the data several times.</source>
          <target state="translated">このフォルダは、いくつかの大規模なデータセットローダーが、データを何度もダウンロードしないようにするために使用します。</target>
        </trans-unit>
        <trans-unit id="697a12fdadac01e298b3e16a8634659c2b054014" translate="yes" xml:space="preserve">
          <source>This format is a text-based format, with one sample per line. It does not store zero valued features hence is suitable for sparse dataset.</source>
          <target state="translated">このフォーマットはテキストベースのフォーマットで、1行に1サンプルです。ゼロ値特徴量を格納しないので、疎なデータセットに適しています。</target>
        </trans-unit>
        <trans-unit id="a2fe6f0ee6734c2a60bcbb1d0d95dc9dfd886002" translate="yes" xml:space="preserve">
          <source>This format is used as the default format for both svmlight and the libsvm command line programs.</source>
          <target state="translated">このフォーマットは、svmlight と libsvm コマンドラインプログラムのデフォルトフォーマットとして使用されます。</target>
        </trans-unit>
        <trans-unit id="a2e505f490185afab8e1242d5832b6872eb9a667" translate="yes" xml:space="preserve">
          <source>This formulation has two advantages over other ways of computing distances. First, it is computationally efficient when dealing with sparse data. Second, if one argument varies but the other remains unchanged, then &lt;code&gt;dot(x, x)&lt;/code&gt; and/or &lt;code&gt;dot(y, y)&lt;/code&gt; can be pre-computed.</source>
          <target state="translated">この公式には、距離を計算する他の方法に比べて2つの利点があります。1つ目は、スパースデータを処理する場合の計算効率です。第2に、1つの引数が変化しても、他の引数は変化しない場合、 &lt;code&gt;dot(x, x)&lt;/code&gt; や &lt;code&gt;dot(y, y)&lt;/code&gt; を事前に計算できます。</target>
        </trans-unit>
        <trans-unit id="fd76e45c139161a6c2340aa524dcf0429afb583e" translate="yes" xml:space="preserve">
          <source>This function computes Cohen&amp;rsquo;s kappa &lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, a score that expresses the level of agreement between two annotators on a classification problem. It is defined as</source>
          <target state="translated">この関数は、コーエンのカッパ&lt;a href=&quot;#r219a3b9132e1-1&quot; id=&quot;id1&quot;&gt;[1]を&lt;/a&gt;計算します。これは、分類問題に関する2つのアノテーター間の一致のレベルを表すスコアです。次のように定義されます</target>
        </trans-unit>
        <trans-unit id="1a26f30c64bc915159ba37349551edb033f8db68" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance).</source>
          <target state="translated">この関数は,X の各行について,(指定された距離に応じて)最も近い Y の行のインデックスを計算します.</target>
        </trans-unit>
        <trans-unit id="40ca8ec3788866f2480b1619115207e644d05cac" translate="yes" xml:space="preserve">
          <source>This function computes for each row in X, the index of the row of Y which is closest (according to the specified distance). The minimal distances are also returned.</source>
          <target state="translated">この関数は,X の各行について,(指定された距離に応じて)最も近い Y の行のインデックスを求めます.最小距離も返されます.</target>
        </trans-unit>
        <trans-unit id="6e14f241e1c03d6b67a6c0f22515d375ae432487" translate="yes" xml:space="preserve">
          <source>This function crawls the module and gets all classes that inherit from BaseEstimator. Classes that are defined in test-modules are not included. By default meta_estimators such as GridSearchCV are also not included.</source>
          <target state="translated">この関数はモジュールをクロールし、BaseEstimatorを継承するすべてのクラスを取得します。テストモジュールで定義されているクラスは含まれません.デフォルトでは,GridSearchCVのようなmeta_estimatorも含まれません.</target>
        </trans-unit>
        <trans-unit id="311d27372cf5315019acfac7480657777c623446" translate="yes" xml:space="preserve">
          <source>This function does not try to extract features into a numpy array or scipy sparse matrix. In addition, if load_content is false it does not try to load the files in memory.</source>
          <target state="translated">この関数は,numpy配列やscipy疎行列に特徴を抽出しようとはしません.また,load_contentがfalseの場合は,メモリ上のファイルをロードしようとはしません.</target>
        </trans-unit>
        <trans-unit id="28042729acf4bf75d343c82f013b112dad91f4c8" translate="yes" xml:space="preserve">
          <source>This function generates a GraphViz representation of the decision tree, which is then written into &lt;code&gt;out_file&lt;/code&gt;. Once exported, graphical renderings can be generated using, for example:</source>
          <target state="translated">この関数は、決定木のGraphViz表現を生成し、それを &lt;code&gt;out_file&lt;/code&gt; に書き込みます。いったんエクスポートされると、グラフィックレンダリングは、たとえば以下を使用して生成できます。</target>
        </trans-unit>
        <trans-unit id="90af5dc07a0d6b1b987fbe6284966c35b8f7dbed" translate="yes" xml:space="preserve">
          <source>This function implements Test 1 in:</source>
          <target state="translated">この関数は、テスト1を実装しています。</target>
        </trans-unit>
        <trans-unit id="51510777ab8c25d02b45243629e172250d646e40" translate="yes" xml:space="preserve">
          <source>This function is called with the estimated model and the randomly selected data: &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped. Rejecting samples with this function is computationally costlier than with &lt;code&gt;is_data_valid&lt;/code&gt;. &lt;code&gt;is_model_valid&lt;/code&gt; should therefore only be used if the estimated model is needed for making the rejection decision.</source>
          <target state="translated">この関数は、推定モデルとランダムに選択されたデータで &lt;code&gt;is_model_valid(model, X, y)&lt;/code&gt; れます：is_model_valid（model、X、y）。戻り値がFalseの場合、ランダムに選択された現在のサブサンプルはスキップされます。この関数を使用したサンプルの拒否は、 &lt;code&gt;is_data_valid&lt;/code&gt; を使用する場合よりも計算コストがかかります。したがって、 &lt;code&gt;is_model_valid&lt;/code&gt; は、拒否の決定を行うために推定モデルが必要な場合にのみ使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="a4283f593950d3e9c84617d07a78fd011e78bfa4" translate="yes" xml:space="preserve">
          <source>This function is called with the randomly selected data before the model is fitted to it: &lt;code&gt;is_data_valid(X, y)&lt;/code&gt;. If its return value is False the current randomly chosen sub-sample is skipped.</source>
          <target state="translated">この関数は、モデルがフィットされる前にランダムに選択されたデータで呼び出されます： &lt;code&gt;is_data_valid(X, y)&lt;/code&gt; 。戻り値がFalseの場合、ランダムに選択された現在のサブサンプルはスキップされます。</target>
        </trans-unit>
        <trans-unit id="7289fd594a0de96a89a572bf0a7bd6e9501fda52" translate="yes" xml:space="preserve">
          <source>This function is equivalent to mapping load_svmlight_file over a list of files, except that the results are concatenated into a single, flat list and the samples vectors are constrained to all have the same number of features.</source>
          <target state="translated">この関数は,結果が単一のフラットリストに結合され,サンプルベクトルがすべて同じ数の特徴を持つように制約される点を除いては,ファイルのリスト上にload_svmlight_fileをマッピングするのと同等です.</target>
        </trans-unit>
        <trans-unit id="828fa7414b6e6676bd49f6624bf5ec1232d13777" translate="yes" xml:space="preserve">
          <source>This function makes it possible to compute this transformation for a fixed set of class labels known ahead of time.</source>
          <target state="translated">この関数は,事前に既知のクラスラベルの固定集合に対して,この変換を計算することを可能にします.</target>
        </trans-unit>
        <trans-unit id="910452d7cd5e91358a13a185cadee882cea17632" translate="yes" xml:space="preserve">
          <source>This function modifies the estimator in-place.</source>
          <target state="translated">この関数は、インプレースの推定器を変更します。</target>
        </trans-unit>
        <trans-unit id="3e0bd9f3948e27380d0112f277598d80d17269d2" translate="yes" xml:space="preserve">
          <source>This function requires the true binary value and the target scores, which can either be probability estimates of the positive class, confidence values, or binary decisions. Here is a small example of how to use the &lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt;&lt;code&gt;roc_curve&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">この関数には、真のバイナリ値とターゲットスコアが必要です。ターゲットスコアは、陽性クラスの確率推定、信頼値、またはバイナリ判定のいずれかです。&lt;a href=&quot;generated/sklearn.metrics.roc_curve#sklearn.metrics.roc_curve&quot;&gt; &lt;code&gt;roc_curve&lt;/code&gt; &lt;/a&gt;関数の使用例を次に示します。</target>
        </trans-unit>
        <trans-unit id="2ddc8c678c75b432a0f0fafa6490a9a69a784bf8" translate="yes" xml:space="preserve">
          <source>This function returns a score of the mean square difference between the actual outcome and the predicted probability of the possible outcome. The actual outcome has to be 1 or 0 (true or false), while the predicted probability of the actual outcome can be a value between 0 and 1.</source>
          <target state="translated">この関数は、実際の結果と予測される結果の確率との平均二乗差のスコアを返します。実際の結果は1か0(真か偽)でなければならず,実際の結果の予測確率は0から1の間の値をとることができます.</target>
        </trans-unit>
        <trans-unit id="fbdeef434a34fee928d2d9974f81cfc54768558d" translate="yes" xml:space="preserve">
          <source>This function returns posterior probabilities of classification according to each class on an array of test vectors X.</source>
          <target state="translated">この関数は,テストベクトルXの配列に対して,各クラスに応じた分類の事後確率を返します.</target>
        </trans-unit>
        <trans-unit id="f7adc46ef6325367984cfe5d6cabca879706d70d" translate="yes" xml:space="preserve">
          <source>This function returns the Silhouette Coefficient for each sample.</source>
          <target state="translated">この関数は、各サンプルのシルエット係数を返します。</target>
        </trans-unit>
        <trans-unit id="30221178098fdd3682a8c91454092d6226b25e4f" translate="yes" xml:space="preserve">
          <source>This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use &lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt;&lt;code&gt;silhouette_samples&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">この関数は、すべてのサンプルの平均シルエット係数を返します。各サンプルの値を取得するには、&lt;a href=&quot;sklearn.metrics.silhouette_samples#sklearn.metrics.silhouette_samples&quot;&gt; &lt;code&gt;silhouette_samples&lt;/code&gt; を&lt;/a&gt;使用します。</target>
        </trans-unit>
        <trans-unit id="bd812dc35d867d7152375e5009e2698c8db08fc0" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists to allow for a description of the mapping for each of the valid strings.</source>
          <target state="translated">この関数は,単に有効なペアワイズ距離メトリクスを返します.これは,有効な文字列のそれぞれに対するマッピングの記述を可能にするために存在します.</target>
        </trans-unit>
        <trans-unit id="fa4705a70e55596dcf2ace89a6d2a8d09a9fcccf" translate="yes" xml:space="preserve">
          <source>This function simply returns the valid pairwise distance metrics. It exists, however, to allow for a verbose description of the mapping for each of the valid strings.</source>
          <target state="translated">この関数は,単に有効なペアワイズ距離メトリクスを返します.しかし、有効な文字列ごとにマッピングの詳細な説明ができるようにするために存在します。</target>
        </trans-unit>
        <trans-unit id="d1a7a45215b31f0644d6e686c87b329e59419299" translate="yes" xml:space="preserve">
          <source>This function won&amp;rsquo;t compute the intercept.</source>
          <target state="translated">この関数は切片を計算しません。</target>
        </trans-unit>
        <trans-unit id="a808622a520f852134a2d8734b9e29ce0a669efe" translate="yes" xml:space="preserve">
          <source>This function works with dense 2D arrays only.</source>
          <target state="translated">この関数は,密な2次元配列のみで動作します.</target>
        </trans-unit>
        <trans-unit id="19a23bf41918ee91955f633ce4d818d45490ef26" translate="yes" xml:space="preserve">
          <source>This function&amp;rsquo;s formula is as follows:</source>
          <target state="translated">この関数の式は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="7541ac358f5bb3bc5dcdfc1193ff72d6ac233a66" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.</source>
          <target state="translated">この生成方法では、ブーストの各反復後にアンサンブル予測クラス確率が得られるため、各ブースト後にテストセットの予測クラス確率を決定するなどのモニタリングが可能になります。</target>
        </trans-unit>
        <trans-unit id="7c1ad29f5d19940cf714626cd821b0934b5bc400" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.</source>
          <target state="translated">この生成方法では、ブーストの各イテレーション後にアンサンブル予測が得られるため、ブースト後にテストセットの予測値を決定するなどのモニタリングが可能となる。</target>
        </trans-unit>
        <trans-unit id="acc74c06c673308a3e484c230b5ff2c8348cfe79" translate="yes" xml:space="preserve">
          <source>This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.</source>
          <target state="translated">この生成方法は、ブーストの各反復後にアンサンブルスコアを生成するため、ブースト後にテストセットのスコアを決定するなどのモニタリングが可能です。</target>
        </trans-unit>
        <trans-unit id="1fe14f98435d58bb1786320c156e4b531f66e48b" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt;&lt;code&gt;make_multilabel_classification&lt;/code&gt;&lt;/a&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">これは、&lt;a href=&quot;../../modules/generated/sklearn.datasets.make_multilabel_classification#sklearn.datasets.make_multilabel_classification&quot;&gt; &lt;code&gt;make_multilabel_classification&lt;/code&gt; &lt;/a&gt;データセットジェネレーターを示しています。各サンプルは、2つの機能（合計で最大50）のカウントで構成され、2つのクラスのそれぞれに異なる方法で分散されます。</target>
        </trans-unit>
        <trans-unit id="cb7462acd1f1e763247c87d170997bea5c436272" translate="yes" xml:space="preserve">
          <source>This illustrates the &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; dataset generator. Each sample consists of counts of two features (up to 50 in total), which are differently distributed in each of two classes.</source>
          <target state="translated">これは、 &lt;code&gt;datasets.make_multilabel_classification&lt;/code&gt; データセットジェネレーターを示しています。各サンプルは、2つの機能のカウント（合計50まで）で構成され、2つのクラスのそれぞれに異なる方法で分散されます。</target>
        </trans-unit>
        <trans-unit id="b80113eed9b4b9668cc4e8b638bede5d1f2cf638" translate="yes" xml:space="preserve">
          <source>This implementation bulk-computes all neighborhood queries, which increases the memory complexity to O(n.d) where d is the average number of neighbors, while original DBSCAN had memory complexity O(n). It may attract a higher memory complexity when querying these nearest neighborhoods, depending on the &lt;code&gt;algorithm&lt;/code&gt;.</source>
          <target state="translated">この実装はすべての近傍クエリを一括計算します。これにより、メモリの複雑度はO（nd）に増加します。ここで、dはネイバーの平均数ですが、元のDBSCANはメモリの複雑度O（n）を持ちました。 &lt;code&gt;algorithm&lt;/code&gt; によっては、これらの最近傍を照会するときに、メモリの複雑さが高くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="48627963240be2350bc0acdc732c6b5348961a90" translate="yes" xml:space="preserve">
          <source>This implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes, then computing only the distances to unprocessed points when constructing the cluster order. Note that we do not employ a heap to manage the expansion candidates, so the time complexity will be O(n^2).</source>
          <target state="translated">この実装はオリジナルのOPTICSとは異なり、まずすべての点についてk-nearest-neighborhood探索を行い、コアサイズを特定し、クラスタ順序を構築する際に未処理の点までの距離のみを計算します。なお、展開候補の管理にヒープを使用していないため、時間的な複雑さはO(n^2)となります。</target>
        </trans-unit>
        <trans-unit id="aed3668d0e58719270c1129ddb01322705c078e7" translate="yes" xml:space="preserve">
          <source>This implementation follows what is explained in the original paper &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1&lt;/a&gt;. For the optimisation method, it currently uses scipy&amp;rsquo;s L-BFGS-B with a full gradient computation at each iteration, to avoid to tune the learning rate and provide stable learning.</source>
          <target state="translated">この実装は、元の論文&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;1で&lt;/a&gt;説明されている内容に従います。最適化手法では、現在、scipyのL-BFGS-Bを使用しており、各反復で完全な勾配計算を行って、学習率の調整を回避し、安定した学習を提供しています。</target>
        </trans-unit>
        <trans-unit id="92eb61902d4dfd6571a464d87feff72fe7b32901" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">この実装は、Rubinstein、R.、Zibulevsky、M.とElad、M &lt;a href=&quot;http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;.に基づいています。&lt;/a&gt;バッチ直交マッチング追跡技術レポートを使用したK-SVDアルゴリズムの効率的な実装-CS Technion、2008年4月。http：//www.cs。 technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</target>
        </trans-unit>
        <trans-unit id="12813af32368fc3d74f568cdec1c9e38f408115a" translate="yes" xml:space="preserve">
          <source>This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. &lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</source>
          <target state="translated">この実装は、Rubinstein、R.、Zibulevsky、M。およびElad、M。、バッチ直交マッチング追跡テクニカルレポートを使用したK-SVDアルゴリズムの効率的な実装-CS Technion、2008年4月に&lt;a href=&quot;https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&quot;&gt;基づいています。https：//www.cs。 technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6fb112845601277f8931b295b857e73c1428c8fb" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g. with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">この実装は,kd-木やボールツリーが使用できない場合(例えば,疎な行列の場合)に完全なペアワイズ類似度行列を構築するため,デフォルトではメモリ効率が良くありません.この行列は,n^2個のフロートを消費します.これを回避するには,いくつかの方法があります.</target>
        </trans-unit>
        <trans-unit id="34d2660e23d61d989853bcf418296ddcc27d9606" translate="yes" xml:space="preserve">
          <source>This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g., with sparse matrices). This matrix will consume n^2 floats. A couple of mechanisms for getting around this are:</source>
          <target state="translated">この実装は,kd-木やボールツリーが使用できない場合(例えば,疎な行列の場合)に完全なペアワイズ類似度行列を構築するため,デフォルトではメモリ効率が良くありません.この行列は,n^2個のフロートを消費します.これを回避するには,いくつかの方法があります.</target>
        </trans-unit>
        <trans-unit id="5e691dc0883398091a16d8a17daee0ec7cd95f29" translate="yes" xml:space="preserve">
          <source>This implementation is inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt;.</source>
          <target state="translated">この実装は&lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBMに&lt;/a&gt;触発されています。</target>
        </trans-unit>
        <trans-unit id="cc51c30dcd01f51cada4be15777f17eb95eb7cbd" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">この実装は、大規模なアプリケーションを対象としたものではありません。特に、scikit-learnはGPUサポートを提供しません。より高速なGPUベースの実装と、ディープラーニングアーキテクチャを構築するためのはるかに高い柔軟性を提供するフレームワークについては、&lt;a href=&quot;http://scikit-learn.org/stable/related_projects.html#related-projects&quot;&gt;関連プロジェクトを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="228da043cb5452c21accbc429ac2d994bed0f4a9" translate="yes" xml:space="preserve">
          <source>This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see &lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;Related Projects&lt;/a&gt;.</source>
          <target state="translated">この実装は、大規模なアプリケーションを対象としていません。特に、scikit-learnはGPUサポートを提供していません。はるかに高速なGPUベースの実装、およびディープラーニングアーキテクチャを構築するためのはるかに高い柔軟性を提供するフレームワークについては、&lt;a href=&quot;https://scikit-learn.org/0.23/related_projects.html#related-projects&quot;&gt;関連プロジェクトを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0e30a130e6449e6025aca5fcf59ecb737e97cb91" translate="yes" xml:space="preserve">
          <source>This implementation is written in Cython and is reasonably fast. However, a faster API-compatible loader is also available at:</source>
          <target state="translated">この実装はCythonで書かれており、それなりに高速です。しかし、より高速な API 互換のローダも用意されています。</target>
        </trans-unit>
        <trans-unit id="b488dd9d3cb1238d47d93805595214963db6dd0c" translate="yes" xml:space="preserve">
          <source>This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.</source>
          <target state="translated">この実装では,scipy.sparse.csr_matrixを用いてカウントの疎な表現を生成します.</target>
        </trans-unit>
        <trans-unit id="42bc7bbc3f5bd0df8efbfbad62976f6ec6db583b" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that 3 PLS packages provided in the R language (R-project):</source>
          <target state="translated">この実装は、R言語(R-project)で提供されている3つのPLSパッケージと同じ結果を提供します。</target>
        </trans-unit>
        <trans-unit id="09c013dbb84b7e3d406ea0732bc3a8236ed37cbd" translate="yes" xml:space="preserve">
          <source>This implementation provides the same results that the &amp;ldquo;plspm&amp;rdquo; package provided in the R language (R-project), using the function plsca(X, Y). Results are equal or collinear with the function &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; of the &amp;ldquo;mixOmics&amp;rdquo; package. The difference relies in the fact that mixOmics implementation does not exactly implement the Wold algorithm since it does not normalize y_weights to one.</source>
          <target state="translated">この実装は、関数plsca（X、Y）を使用して、R言語（Rプロジェクト）で提供される「plspm」パッケージと同じ結果を提供します。結果は、「mixOmics」パッケージの関数 &lt;code&gt;pls(..., mode = &quot;canonical&quot;)&lt;/code&gt; と等しいか、同一線上にあります。違いは、mixOmics実装がy_weightsを1に正規化しないため、Woldアルゴリズムを正確に実装していないという事実に依存しています。</target>
        </trans-unit>
        <trans-unit id="36e4a374c505873717456a086d5c9ed44e5157f6" translate="yes" xml:space="preserve">
          <source>This implementation will refuse to center scipy.sparse matrices since it would make them non-sparse and would potentially crash the program with memory exhaustion problems.</source>
          <target state="translated">この実装では、scipy.sparse行列のセンタリングを拒否します。これは、行列を非疎にしてしまい、メモリ枯渇の問題でプログラムがクラッシュする可能性があるからです。</target>
        </trans-unit>
        <trans-unit id="6684c1532df5f751b6b61c242ea952621dc3f4e8" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense and sparse numpy arrays of floating point values.</source>
          <target state="translated">この実装は,浮動小数点値の密で疎なnumpy配列として表現されたデータで動作します.</target>
        </trans-unit>
        <trans-unit id="b0df3cb22108e4cd0ed0fcd534ed03e427412c64" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays of floating point values for the features.</source>
          <target state="translated">この実装では,特徴量の浮動小数点値の密なnumpy配列として表されるデータで動作します.</target>
        </trans-unit>
        <trans-unit id="4abb3ee00da8e0ef45c7b10f884f8d272712ca81" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.</source>
          <target state="translated">この実装は、浮動小数点値の密なnumpy配列または疎なscipy配列で表現されたデータで動作します。</target>
        </trans-unit>
        <trans-unit id="c3c22c958df17cff584f8c572beeb762a9a0290e" translate="yes" xml:space="preserve">
          <source>This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).</source>
          <target state="translated">この実装は,特徴量の浮動小数点値の密または疎な配列として表現されたデータで動作します.フィットするモデルは,損失パラメータで制御することができます.デフォルトでは,線形サポートベクターマシン(SVM)にフィットします.</target>
        </trans-unit>
        <trans-unit id="c43a7d8bb7931a79100804db2f074a29d45e4b6b" translate="yes" xml:space="preserve">
          <source>This improvement is not visible in the Silhouette Coefficient which is small for both as this measure seem to suffer from the phenomenon called &amp;ldquo;Concentration of Measure&amp;rdquo; or &amp;ldquo;Curse of Dimensionality&amp;rdquo; for high dimensional datasets such as text data. Other measures such as V-measure and Adjusted Rand Index are information theoretic based evaluation scores: as they are only based on cluster assignments rather than distances, hence not affected by the curse of dimensionality.</source>
          <target state="translated">テキストデータなどの高次元のデータセットの場合、このメジャーは「メジャーの集中」または「次元のカース」と呼ばれる現象に悩まされているように見えるため、この改善は両方に対して小さいシルエット係数では表示されません。V-measureやAdjusted Rand Indexなどの他のメジャーは、情報理論に基づく評価スコアです。これらは距離ではなくクラスター割り当てにのみ基づいているため、次元の呪いの影響を受けません。</target>
        </trans-unit>
        <trans-unit id="18d0a71ee91c72fbdd2b834782dff2f0f441f1d5" translate="yes" xml:space="preserve">
          <source>This index signifies the average &amp;lsquo;similarity&amp;rsquo; between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.</source>
          <target state="translated">このインデックスは、クラスター間の平均的な「類似性」を示します。類似性は、クラスター間の距離とクラスター自体のサイズを比較する尺度です。</target>
        </trans-unit>
        <trans-unit id="a0d4ffe805942e66e32866a4eb458e728074d78e" translate="yes" xml:space="preserve">
          <source>This initially creates clusters of points normally distributed (std=1) about vertices of an &lt;code&gt;n_informative&lt;/code&gt;-dimensional hypercube with sides of length &lt;code&gt;2*class_sep&lt;/code&gt; and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data.</source>
          <target state="translated">これは最初に、長さが &lt;code&gt;2*class_sep&lt;/code&gt; の辺を持つ &lt;code&gt;n_informative&lt;/code&gt; 次元の超立方体の頂点の周りに正規分布する点のクラスターを作成し（std = 1）、各クラスに同数のクラスターを割り当てます。これらの機能間の相互依存性を導入し、さまざまなタイプのノイズをデータに追加します。</target>
        </trans-unit>
        <trans-unit id="57108bb9f4ef70d6ebe6d73913a67e52e844d200" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">このインターフェースは&lt;strong&gt;実験的なもので&lt;/strong&gt;あり、後続のリリースでは予告なしに属性が変更される場合があります（ただし、 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; にはわずかな変更のみが必要です）。</target>
        </trans-unit>
        <trans-unit id="5b14c6be212126cf2e3bdc1fe1c6fe8f3c7dc46d" translate="yes" xml:space="preserve">
          <source>This interface is &lt;strong&gt;experimental&lt;/strong&gt; as at version 0.20 and subsequent releases may change attributes without notice (although there should only be minor changes to &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;).</source>
          <target state="translated">このインターフェースはバージョン0.20の&lt;strong&gt;実験的な&lt;/strong&gt;ものであり、後続のリリースでは通知なしに属性が変更される可能性があります（ただし、 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; にはわずかな変更しかありません）。</target>
        </trans-unit>
        <trans-unit id="7f6be37b4617684744b3ccc169d2c583b6e3ddc1" translate="yes" xml:space="preserve">
          <source>This is a convenience alias to &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; to do random permutations of the collections.</source>
          <target state="translated">これは、コレクションのランダム置換を行う &lt;code&gt;resample(*arrays, replace=False)&lt;/code&gt; 便利なエイリアスです。</target>
        </trans-unit>
        <trans-unit id="4632bc2ee98a17257db1d248b06f38b79a53d4ef" translate="yes" xml:space="preserve">
          <source>This is a convenience function; the transformation is done using the default settings for &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;. For more advanced usage (stopword filtering, n-gram extraction, etc.), combine fetch_20newsgroups with a custom &lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは便利な機能です。変換は&lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;のデフォルト設定を使用して行われます。より高度な使用法（ストップワードフィルタリング、n-gram抽出など）の場合は、fetch_20newsgroupsをカスタムの&lt;a href=&quot;sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.HashingVectorizer&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfTransformer&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.TfidfVectorizer&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2b3dbf5e1c5e08d66c77786f2bcbc632afc0312a" translate="yes" xml:space="preserve">
          <source>This is a convenience routine for the sake of testing. For many metrics, the utilities in scipy.spatial.distance.cdist and scipy.spatial.distance.pdist will be faster.</source>
          <target state="translated">これはテストのための便利なルーチンです。多くのメトリクスでは、scipy.spatial.distance.cdist と scipy.spatial.distance.pdist のユーティリティの方が高速です。</target>
        </trans-unit>
        <trans-unit id="7a67e0a846a2ab3c88cb06fc2b7950cd30914abe" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. &lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</source>
          <target state="translated">これは、UCI ML乳がんウィスコンシン（診断）データセットのコピーです。&lt;a href=&quot;https://goo.gl/U2Uwz2&quot;&gt;https://goo.gl/U2Uwz2&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="22bae61d9be3213577df5087cb01b12cfdf8dff4" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML Wine recognition datasets. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</source>
          <target state="translated">これは、UCI ML Wine認識データセットのコピーです。&lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c52f45448ee0e84b694b7c38bdbed7fd0e586461" translate="yes" xml:space="preserve">
          <source>This is a copy of UCI ML housing dataset. &lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</source>
          <target state="translated">これは、UCI MLハウジングデータセットのコピーです。&lt;a href=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&quot;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a6d742ac48191eb71d1c4aabf6003187f0d21a9d" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets</source>
          <target state="translated">これはUCI ML手書き数字データセットのテストセットのコピーです。</target>
        </trans-unit>
        <trans-unit id="3dee2146876159a5a0b048cd24a612fae4a810ca" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">これは、UCI ML手書き数字データセットのテストセットのコピーです&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;。http：//archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="60177910f782c7923853f8284b0287f57e3bf220" translate="yes" xml:space="preserve">
          <source>This is a copy of the test set of the UCI ML hand-written digits datasets &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</source>
          <target state="translated">これは、UCIML手書き数字データセットのテストセットのコピーです&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd4a60c08b29c6d6af237f8cfa14740252c7d04a" translate="yes" xml:space="preserve">
          <source>This is a general function, given points on a curve. For computing the area under the ROC-curve, see &lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;. For an alternative way to summarize a precision-recall curve, see &lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは、曲線上の点が与えられた場合の一般的な関数です。ROC曲線の下の面積の計算については、&lt;a href=&quot;sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; を&lt;/a&gt;参照してください。精度-再現率曲線を要約する別の方法については、&lt;a href=&quot;sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="3944e3eb8c8ea1f918637d2548f35fa74cd97d2a" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting with &lt;code&gt;transformer_weights&lt;/code&gt;.</source>
          <target state="translated">これは、ColumnTransformerコンストラクターの省略形です。変圧器に名前を付ける必要はなく、許可もしていません。代わりに、タイプに基づいて自動的に名前が付けられます。また、 &lt;code&gt;transformer_weights&lt;/code&gt; による重み付けも許可されていません。</target>
        </trans-unit>
        <trans-unit id="37510c6c60985c0ea76b5bcc4364db965e5a12fd" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the ColumnTransformer constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">これは ColumnTransformer コンストラクタの略語で、変換器の名前を付ける必要はありませんし、許可することもできません。代わりに、変換器の型に基づいて自動的に名前が付けられます。また、重み付けもできません。</target>
        </trans-unit>
        <trans-unit id="022d95ed0540e35ea0bdce867e9a502603bc5f51" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the FeatureUnion constructor; it does not require, and does not permit, naming the transformers. Instead, they will be given names automatically based on their types. It also does not allow weighting.</source>
          <target state="translated">これは FeatureUnion コンストラクタの略語で、変換器に名前を付ける必要はなく、許可もしていません。代わりに、変換器の型に基づいて自動的に名前が付けられます。また、重み付けもできません。</target>
        </trans-unit>
        <trans-unit id="52a890ca0cc5d284d366294db21e8c380349733e" translate="yes" xml:space="preserve">
          <source>This is a shorthand for the Pipeline constructor; it does not require, and does not permit, naming the estimators. Instead, their names will be set to the lowercase of their types automatically.</source>
          <target state="translated">これは、Pipeline コンストラクタの略語であり、エスティメー タに名前を付ける必要はなく、許可もされていません。代わりに、その名前は自動的にその型の小文字に設定されます。</target>
        </trans-unit>
        <trans-unit id="bcbf4cb6d3eb7ea12d02241a9a60f7a4e6044f4d" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.predict(X)&lt;/code&gt;.</source>
          <target state="translated">これは &lt;code&gt;estimator_.predict(X)&lt;/code&gt; のラッパーです。</target>
        </trans-unit>
        <trans-unit id="17ebe8027dbbfba976bb150f0e9172e06d0c02ec" translate="yes" xml:space="preserve">
          <source>This is a wrapper for &lt;code&gt;estimator_.score(X, y)&lt;/code&gt;.</source>
          <target state="translated">これは &lt;code&gt;estimator_.score(X, y)&lt;/code&gt; ラッパーです。</target>
        </trans-unit>
        <trans-unit id="602675ab661ad893c615b29b13c1d56146fcfa0b" translate="yes" xml:space="preserve">
          <source>This is an alternative to passing a &lt;code&gt;backend='backend_name'&lt;/code&gt; argument to the &lt;code&gt;Parallel&lt;/code&gt; class constructor. It is particularly useful when calling into library code that uses joblib internally but does not expose the backend argument in its own API.</source>
          <target state="translated">これは、 &lt;code&gt;Parallel&lt;/code&gt; クラスコンストラクターに &lt;code&gt;backend='backend_name'&lt;/code&gt; 引数を渡す代わりに使用できます。これは、joblibを内部で使用するライブラリコードを呼び出すときに特に役立ちますが、独自のAPIでバックエンド引数を公開しません。</target>
        </trans-unit>
        <trans-unit id="47f9c3947e84bb8a914aa6f2f19cb2c5e42e970f" translate="yes" xml:space="preserve">
          <source>This is an example of &lt;strong&gt;bias/variance tradeoff&lt;/strong&gt;: the larger the ridge &lt;code&gt;alpha&lt;/code&gt; parameter, the higher the bias and the lower the variance.</source>
          <target state="translated">これは、&lt;strong&gt;バイアスと分散のトレードオフの&lt;/strong&gt;例です。リッジ &lt;code&gt;alpha&lt;/code&gt; パラメータが大きいほど、バイアスが高くなり、分散が低くなります。</target>
        </trans-unit>
        <trans-unit id="d75c7c933c17fefbabe7c2e292b885d0ecac3a21" translate="yes" xml:space="preserve">
          <source>This is an example of applying &lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; on a corpus of documents and extract additive models of the topic structure of the corpus. The output is a list of topics, each represented as a list of terms (weights are not shown).</source>
          <target state="translated">これは、ドキュメントのコーパスに&lt;a href=&quot;../../modules/generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;sklearn.decomposition.NMF&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;../../modules/generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;sklearn.decomposition.LatentDirichletAllocation&lt;/code&gt; &lt;/a&gt;を適用し、コーパスのトピック構造の追加モデルを抽出する例です。出力はトピックのリストであり、それぞれが用語のリストとして表されます（重みは示されていません）。</target>
        </trans-unit>
        <trans-unit id="53176f2993974522405fa17c9a80a84e38a4969c" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&amp;rsquo;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch.</source>
          <target state="translated">これは、コア外のアプローチを使用した分類にscikit-learnを使用する方法を示す例です。メインメモリに適合しないデータから学習します。例のバッチが供給される、partial_fitメソッドをサポートするオンライン分類子を使用します。機能スペースが長期にわたって同じままであることを保証するために、各例を同じ機能スペースに投影するHashingVectorizerを利用します。これは、新しい機能（単語）が各バッチに表示されるテキスト分類の場合に特に役立ちます。</target>
        </trans-unit>
        <trans-unit id="1620bf9fc1f7795235eabc8e2a67657eca16390d" translate="yes" xml:space="preserve">
          <source>This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.</source>
          <target state="translated">これは、単語袋アプローチを使用してトピック別に文書を分類するために scikit-learn がどのように使用できるかを示す例です。この例では、特徴を格納するために scipy.sparse 行列を使用し、スパース行列を効率的に扱える様々な分類器を示しています。</target>
        </trans-unit>
        <trans-unit id="687fdb042e4ef171de769c4722977550577ec678" translate="yes" xml:space="preserve">
          <source>This is an example showing how the scikit-learn can be used to cluster documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features instead of standard numpy arrays.</source>
          <target state="translated">これは、scikit-learnを使って、bag-of-wordsアプローチを使ってトピック別に文書をクラスタリングする方法を示す例です。この例では、標準的なnumpy配列の代わりにscipy.sparse行列を用いて特徴を格納しています。</target>
        </trans-unit>
        <trans-unit id="c505c2f7b70a5aa0d5582bdc56a7d9627b32a4d8" translate="yes" xml:space="preserve">
          <source>This is an example showing the prediction latency of various scikit-learn estimators.</source>
          <target state="translated">様々なscikit-learn推定器の予測待ち時間を示した例です。</target>
        </trans-unit>
        <trans-unit id="9e4f7a05490ee1267f03d9980bace7147baa0b76" translate="yes" xml:space="preserve">
          <source>This is an extension of the algorithm in scipy.stats.mode.</source>
          <target state="translated">これは scipy.stats.mode のアルゴリズムを拡張したものです。</target>
        </trans-unit>
        <trans-unit id="375819c22c211b4c7fc97205acd724c3a575f620" translate="yes" xml:space="preserve">
          <source>This is an implementation that uses the result of the previous model to speed up computations along the set of solutions, making it faster than sequentially calling LogisticRegression for the different parameters. Note that there will be no speedup with liblinear solver, since it does not handle warm-starting.</source>
          <target state="translated">これは、前のモデルの結果を利用して、解の集合に沿った計算を高速化する実装で、異なるパラメータに対して逐次的にLogisticRegressionを呼び出すよりも高速になります。liblinearソルバーはウォームスタートを処理しないので、liblinearソルバーを使っても高速化はしないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="89098058da4c55a1db96b87aadaa162a0a15baba" translate="yes" xml:space="preserve">
          <source>This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a &lt;code&gt;score&lt;/code&gt; function, or &lt;code&gt;scoring&lt;/code&gt; must be passed.</source>
          <target state="translated">これは、scikit-learn Estimatorインターフェースを実装すると想定されています。推定器が &lt;code&gt;score&lt;/code&gt; 関数を提供するか、スコア &lt;code&gt;scoring&lt;/code&gt; 渡す必要があります。</target>
        </trans-unit>
        <trans-unit id="a9f1a5b0fa7d00ad69170d1ab81bf1031dee11a2" translate="yes" xml:space="preserve">
          <source>This is called a &lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; cross-validation.</source>
          <target state="translated">これは、&lt;a href=&quot;../../modules/generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;交差検証と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="2e974743bc0fdffbf7238debaf0ee76bb5a5d9b2" translate="yes" xml:space="preserve">
          <source>This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.</source>
          <target state="translated">これは、ユークリッド(L2)正規化によってベクトルが単位球に投影され、その点積がベクトルで示される点の間の角度の余弦となるため、余弦類似性と呼ばれています。</target>
        </trans-unit>
        <trans-unit id="9b01365512b47448f649e450ddd111360a73cfc3" translate="yes" xml:space="preserve">
          <source>This is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;curse of dimensionality&lt;/a&gt; and is a core problem that machine learning addresses.</source>
          <target state="translated">これは&lt;a href=&quot;https://en.wikipedia.org/wiki/Curse_of_dimensionality&quot;&gt;次元の呪い&lt;/a&gt;と呼ばれ、機械学習が対処する中心的な問題です。</target>
        </trans-unit>
        <trans-unit id="25e5e11d6a0e13a60841f1cb72db59989d03472f" translate="yes" xml:space="preserve">
          <source>This is currently implemented in the following classes:</source>
          <target state="translated">現在、以下のクラスで実装されています。</target>
        </trans-unit>
        <trans-unit id="a774a1be5070f83615f896d6d2ec16ebfbe92e4e" translate="yes" xml:space="preserve">
          <source>This is done in 2 steps:</source>
          <target state="translated">これは2つのステップで行います。</target>
        </trans-unit>
        <trans-unit id="0c564a0d4cfad247ff47792f5a12558130a84f0c" translate="yes" xml:space="preserve">
          <source>This is equivalent to fit followed by transform, but more efficiently implemented.</source>
          <target state="translated">これははめ込みに続いて変換を行うのと同じですが、より効率的に実装されています。</target>
        </trans-unit>
        <trans-unit id="831022bba18e9ed70a7a762cd8243e7523afeddb" translate="yes" xml:space="preserve">
          <source>This is especially useful when the whole dataset is too big to fit in memory at once.</source>
          <target state="translated">これは、データセット全体が大きすぎて一度にメモリに収まらない場合に特に便利です。</target>
        </trans-unit>
        <trans-unit id="75c0bef753e28aecf63e47221c52fe362a027981" translate="yes" xml:space="preserve">
          <source>This is implemented as &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.</source>
          <target state="translated">これは &lt;code&gt;argmax(decision_function(X), axis=1)&lt;/code&gt; として実装され、可能な各クラスペアの決定の結果を予測する推定量によって、最も投票数の多いクラスのラベルを返します。</target>
        </trans-unit>
        <trans-unit id="9b2a6723fed7b2d139e18e341020f963dc7f8450" translate="yes" xml:space="preserve">
          <source>This is implemented by linking the points X into the graph of geodesic distances of the training data. First the &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors of X are found in the training data, and from these the shortest geodesic distances from each point in X to each point in the training data are computed in order to construct the kernel. The embedding of X is the projection of this kernel onto the embedding vectors of the training set.</source>
          <target state="translated">これは、ポイントXをトレーニングデータの測地線距離のグラフにリンクすることによって実装されます。最初に、Xの最近傍の &lt;code&gt;n_neighbors&lt;/code&gt; がトレーニングデータで見つかり、カーネルからXの各ポイントからトレーニングデータの各ポイントまでの最短測地線距離が計算されます。Xの埋め込みは、このカーネルをトレーニングセットの埋め込みベクトルに投影したものです。</target>
        </trans-unit>
        <trans-unit id="51ae8a82b3eff6fb295f70aa28171d41c73ac3db" translate="yes" xml:space="preserve">
          <source>This is implemented in &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt;. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; constructor parameter. This parameter has no influence on &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; に&lt;/a&gt;実装されています。目的の次元は、 &lt;code&gt;n_components&lt;/code&gt; コンストラクター・パラメーターを使用して設定できます。このパラメーターは、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.fit&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.predict&lt;/code&gt; に&lt;/a&gt;影響を与えません。</target>
        </trans-unit>
        <trans-unit id="8989f9efb82b77a4f24da08f40263dc49964cf0b" translate="yes" xml:space="preserve">
          <source>This is implemented in the &lt;code&gt;transform&lt;/code&gt; method. The desired dimensionality can be set using the &lt;code&gt;n_components&lt;/code&gt; parameter. This parameter has no influence on the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods.</source>
          <target state="translated">これは、 &lt;code&gt;transform&lt;/code&gt; メソッドで実装されます。必要な次元は、 &lt;code&gt;n_components&lt;/code&gt; パラメーターを使用して設定できます。このパラメーターは、 &lt;code&gt;fit&lt;/code&gt; および &lt;code&gt;predict&lt;/code&gt; 方法に影響を与えません。</target>
        </trans-unit>
        <trans-unit id="de8220f3c95931fc4241bdd5334e66fca04da2f0" translate="yes" xml:space="preserve">
          <source>This is known as &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="1c0b6d6227299e9452904f2af6316a83adba923a" translate="yes" xml:space="preserve">
          <source>This is minimized if \(h(x_i)\) is fitted to predict a value that is proportional to the negative gradient \(-g_i\). Therefore, at each iteration, &lt;strong&gt;the estimator&lt;/strong&gt;\(h_m\)&lt;strong&gt;is fitted to predict the negative gradients of the samples&lt;/strong&gt;. The gradients are updated at each iteration. This can be considered as some kind of gradient descent in a functional space.</source>
          <target state="translated">\（h（x_i）\）が負の勾配\（-g_i \）に比例する値を予測するように適合されている場合、これは最小化されます。したがって、各反復で&lt;strong&gt;、推定量&lt;/strong&gt;\（h_m \）&lt;strong&gt;が適合され、サンプルの負の勾配が予測されます&lt;/strong&gt;。グラデーションは反復ごとに更新されます。これは、関数空間におけるある種の勾配降下法と見なすことができます。</target>
        </trans-unit>
        <trans-unit id="1d1ef16c8ffe6df8c7a1a81b132f67cdda1b92ea" translate="yes" xml:space="preserve">
          <source>This is more efficient than calling fit followed by transform.</source>
          <target state="translated">これは、はめ込みに続いて変換を呼び出すよりも効率的です。</target>
        </trans-unit>
        <trans-unit id="1dfb3afc660617ced3002fefa24847b5bb1a14dd" translate="yes" xml:space="preserve">
          <source>This is mostly equivalent to calling:</source>
          <target state="translated">これはほとんどの場合、呼び出しに相当します。</target>
        </trans-unit>
        <trans-unit id="bbd51f304b678a157464ff7ab03c52123d04218d" translate="yes" xml:space="preserve">
          <source>This is not a symmetric function.</source>
          <target state="translated">これは対称関数ではありません。</target>
        </trans-unit>
        <trans-unit id="0b5c42967b0e34c52656dd80a4e659c6f0fa2181" translate="yes" xml:space="preserve">
          <source>This is not exactly the same as &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt;. The authors of &lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt; prefer the version above as it is always positive definite. Since the kernel is additive, it is possible to treat all components \(x_i\) separately for embedding. This makes it possible to sample the Fourier transform in regular intervals, instead of approximating using Monte Carlo sampling.</source>
          <target state="translated">これは &lt;code&gt;sklearn.metrics.additive_chi2_kernel&lt;/code&gt; とまったく同じではありません。&lt;a href=&quot;#vz2010&quot; id=&quot;id4&quot;&gt;[VZ2010]&lt;/a&gt;の作者は、常に正定であるため、上記のバージョンを好みます。カーネルは追加的であるため、すべてのコンポーネントを\（x_i \）で個別に処理して埋め込むことができます。これにより、モンテカルロサンプリングを使用して近似する代わりに、フーリエ変換を一定の間隔でサンプリングできます。</target>
        </trans-unit>
        <trans-unit id="f7f802fcac19c1c8ed1c55f673312d761a2c94a7" translate="yes" xml:space="preserve">
          <source>This is not the case for &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt;: both are bound by the relationship:</source>
          <target state="translated">これは、&lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; の&lt;/a&gt;場合とは異なります。どちらも関係によってバインドされます。</target>
        </trans-unit>
        <trans-unit id="5d73f5b087f2ecb2dadb8778d3d18cfc19507034" translate="yes" xml:space="preserve">
          <source>This is not true for &lt;code&gt;mutual_info_score&lt;/code&gt;, which is therefore harder to judge:</source>
          <target state="translated">これは、 &lt;code&gt;mutual_info_score&lt;/code&gt; には当てはまりません。したがって、判断が難しくなります。</target>
        </trans-unit>
        <trans-unit id="982101a3d677907e48e034c807cde26531a0468b" translate="yes" xml:space="preserve">
          <source>This is only available if no vocabulary was given.</source>
          <target state="translated">これは、語彙が与えられなかった場合にのみ利用可能です。</target>
        </trans-unit>
        <trans-unit id="0ca1a333516e3b52907835d092958662636ea528" translate="yes" xml:space="preserve">
          <source>This is particularly important for doing grid searches:</source>
          <target state="translated">これは、グリッド検索を行うために特に重要です。</target>
        </trans-unit>
        <trans-unit id="2413be66af5e312ff97e484aff33c56868971fbe" translate="yes" xml:space="preserve">
          <source>This is perhaps the best known database to be found in the pattern recognition literature. Fisher&amp;rsquo;s paper is a classic in the field and is referenced frequently to this day. (See Duda &amp;amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.</source>
          <target state="translated">これはおそらく、パターン認識の文献にある最もよく知られているデータベースです。フィッシャーの論文は、この分野での古典であり、今日でも頻繁に参照されています。（たとえば、Duda＆Hartを参照してください。）データセットには、それぞれ50個のインスタンスの3つのクラスが含まれています。各クラスは、アイリス植物のタイプを示します。1つのクラスは他の2つのクラスから線形的に分離可能です。後者は互いに直線的に分離できません。</target>
        </trans-unit>
        <trans-unit id="32ef6d8e689e0cbccf726fb7a94339c2864c487f" translate="yes" xml:space="preserve">
          <source>This is present only if &lt;code&gt;refit&lt;/code&gt; is not False.</source>
          <target state="translated">これは、 &lt;code&gt;refit&lt;/code&gt; がFalseでない場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="717414c2af196799a3d1dc1aec1269a995318377" translate="yes" xml:space="preserve">
          <source>This is similar to the error set size, but weighted by the number of relevant and irrelevant labels. The best performance is achieved with a ranking loss of zero.</source>
          <target state="translated">これはエラーセットのサイズに似ていますが、関連ラベルと無関係ラベルの数で重み付けされています。ランク付けの損失がゼロになると、最高のパフォーマンスが得られます。</target>
        </trans-unit>
        <trans-unit id="00034266cafd87d919959c8134650d981f2c4466" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">これはscikit-learnのクラスと関数のリファレンスです。クラスと関数のraw仕様では、それらの使用に関する完全なガイドラインを提供するのに十分でない場合があるため、詳細については&lt;a href=&quot;http://scikit-learn.org/stable/user_guide.html#user-guide&quot;&gt;完全なユーザーガイド&lt;/a&gt;を参照してください。API全体で繰り返される概念のリファレンスについては、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;用語集とAPI要素の用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0706513e1a92902a9b1d8477404304aebd12678b" translate="yes" xml:space="preserve">
          <source>This is the class and function reference of scikit-learn. Please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;full user guide&lt;/a&gt; for further details, as the class and function raw specifications may not be enough to give full guidelines on their uses. For reference on concepts repeated across the API, see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt;.</source>
          <target state="translated">これはscikit-learnのクラスと関数のリファレンスです。クラスと関数の生の仕様では、それらの使用に関する完全なガイドラインを提供するのに十分でない場合があるため、詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/user_guide.html#user-guide&quot;&gt;完全なユーザーガイド&lt;/a&gt;を参照してください。API全体で繰り返される概念のリファレンスについては、「&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;一般的な用語とAPI要素の用語集」を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="486cb190a77f54ef106791f7b4834d94d87b42d4" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns &lt;code&gt;y_pred&lt;/code&gt; probabilities for its training data &lt;code&gt;y_true&lt;/code&gt;. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">これは、（多項）ロジスティック回帰およびニューラルネットワークなどの拡張で使用される損失関数であり、トレーニングデータ &lt;code&gt;y_true&lt;/code&gt; の &lt;code&gt;y_pred&lt;/code&gt; 確率を返すロジスティックモデルの負の対数尤度として定義されます。ログ損失は、2つ以上のラベルに対してのみ定義されます。{0,1}の真のラベルytとyt = 1の推定確率ypを持つ単一のサンプルの場合、対数損失は次のようになります。</target>
        </trans-unit>
        <trans-unit id="9c0b38fb17b983574b86706f2172c4c4bac1c6a5" translate="yes" xml:space="preserve">
          <source>This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier&amp;rsquo;s predictions. The log loss is only defined for two or more labels. For a single sample with true label yt in {0,1} and estimated probability yp that yt = 1, the log loss is</source>
          <target state="translated">これは、（多項）ロジスティック回帰とニューラルネットワークなどの拡張で使用される損失関数であり、確率的分類子の予測が与えられた真のラベルの負の対数尤度として定義されます。ログ損失は、2つ以上のラベルに対してのみ定義されます。真のラベルytが{0,1}であり、推定確率ypがyt = 1である単一のサンプルの場合、ログ損失は</target>
        </trans-unit>
        <trans-unit id="a9111de5c7f4d9db0e2dc4faf926c5c47ae0eb12" translate="yes" xml:space="preserve">
          <source>This is the result of calling &lt;code&gt;method&lt;/code&gt;</source>
          <target state="translated">これは &lt;code&gt;method&lt;/code&gt; を呼び出した結果です</target>
        </trans-unit>
        <trans-unit id="611492c50f944d397ce592f12eabee4801e28de1" translate="yes" xml:space="preserve">
          <source>This is the structured version, that takes into account some topological structure between samples.</source>
          <target state="translated">これは、サンプル間のトポロジカル構造を考慮した構造化バージョンです。</target>
        </trans-unit>
        <trans-unit id="eb0a6c68cdbb70ef7265210b8b8760243faa6912" translate="yes" xml:space="preserve">
          <source>This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.</source>
          <target state="translated">これは、他の方法では直接当てはめることができない実装で切片項を当てはめるのに便利です。</target>
        </trans-unit>
        <trans-unit id="1c420e62ce6697ac415dbca5798c0153080b025c" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">これは、以前に使用されたモデルの格納された属性を再利用する必要がある場合に役立ちます。Falseに設定すると、係数はすべての呼び出しに合わせて書き換えられます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="036c7996302f5b904a8b61c47c147a7a9733676a" translate="yes" xml:space="preserve">
          <source>This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">これは、以前に使用したモデルの保存された属性を再利用する必要がある場合に役立ちます。Falseに設定されている場合、係数はフィットするすべての呼び出しに対して書き換えられます。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="2abc93ddea964d3eb32a39867456d5dfe5ef9180" translate="yes" xml:space="preserve">
          <source>This is visible if we compare the standard deviations of different features.</source>
          <target state="translated">これは、異なる特徴の標準偏差を比較するとわかります。</target>
        </trans-unit>
        <trans-unit id="42f2c0052d88e51f5df6c26752c192f81040ec01" translate="yes" xml:space="preserve">
          <source>This kernel is a popular choice for computing the similarity of documents represented as tf-idf vectors. &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; accepts &lt;code&gt;scipy.sparse&lt;/code&gt; matrices. (Note that the tf-idf functionality in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; can produce normalized vectors, in which case &lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt;&lt;code&gt;cosine_similarity&lt;/code&gt;&lt;/a&gt; is equivalent to &lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt;&lt;code&gt;linear_kernel&lt;/code&gt;&lt;/a&gt;, only slower.)</source>
          <target state="translated">このカーネルは、tf-idfベクトルとして表されるドキュメントの類似性を計算するための一般的な選択です。&lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt;は &lt;code&gt;scipy.sparse&lt;/code&gt; 行列を受け入れます。（ &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; の tf-idf機能は正規化されたベクトルを生成できることに注意してください。この場合、&lt;a href=&quot;generated/sklearn.metrics.pairwise.cosine_similarity#sklearn.metrics.pairwise.cosine_similarity&quot;&gt; &lt;code&gt;cosine_similarity&lt;/code&gt; &lt;/a&gt;はlinear_kernelと同等で&lt;a href=&quot;generated/sklearn.metrics.pairwise.linear_kernel#sklearn.metrics.pairwise.linear_kernel&quot;&gt; &lt;code&gt;linear_kernel&lt;/code&gt; &lt;/a&gt;、遅くなります。）</target>
        </trans-unit>
        <trans-unit id="f1fbcea40cf4aba903be6eddf36c859a1718e3b8" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth.</source>
          <target state="translated">このカーネルは無限に微分可能であり、このカーネルを共分散関数とするGPはすべての次数の平均二乗導関数を持ち、したがって非常に滑らかであることを示唆している。</target>
        </trans-unit>
        <trans-unit id="ffa176d62610a7e6d304ab9efadadddacf7fa00e" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See &lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;, Chapter 4, Section 4.2, for further details of the RBF kernel.</source>
          <target state="translated">このカーネルは無限に微分可能です。これは、共分散関数としてこのカーネルを使用するGPは、すべての次数の平均二乗導関数を持ち、したがって非常に滑らかであることを意味します。参照&lt;a href=&quot;#redc669bcbe98-2&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt; RBFカーネルの詳細については、第4章、節4.2。</target>
        </trans-unit>
        <trans-unit id="6ad60f9f3ef06c9a3898414b0afc593eaff20c1d" translate="yes" xml:space="preserve">
          <source>This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. The prior and posterior of a GP resulting from an RBF kernel are shown in the following figure:</source>
          <target state="translated">このカーネルは無限に微分可能であり,このカーネルを共分散関数として持つGPはすべての次数の平均二乗導関数を持ち,したがって非常に滑らかであることを意味します.RBF カーネルから得られる GP の先行と事後を下図に示す.</target>
        </trans-unit>
        <trans-unit id="6cbded70a18b870dfff7fda8d59e204ebd77900f" translate="yes" xml:space="preserve">
          <source>This kind of singular profiles is often seen in practice, for instance:</source>
          <target state="translated">このような特異なプロファイルは、例えば、実際によく見られます。</target>
        </trans-unit>
        <trans-unit id="30529b10016c80d5c9ab1e213672fabc65487573" translate="yes" xml:space="preserve">
          <source>This last point is expected due to the nature of the problem: the occurrence of accidents is mostly dominated by circumstantial causes that are not captured in the columns of the dataset and can indeed be considered as purely random.</source>
          <target state="translated">この最後の点は、問題の性質から予想されるものです:事故の発生は、データセットの列に捕捉されていない状況要因がほとんどを占めており、実際には純粋にランダムであると考えることができます。</target>
        </trans-unit>
        <trans-unit id="1df4414d1e47e9ea41e98b8c6e13b5eeb49e06ac" translate="yes" xml:space="preserve">
          <source>This left out portion can be used to estimate the generalization error without having to rely on a separate validation set. This estimate comes &amp;ldquo;for free&amp;rdquo; as no additional data is needed and can be used for model selection.</source>
          <target state="translated">この省略された部分は、別の検証セットに依存する必要なく、汎化エラーを推定するために使用できます。追加のデータは必要なく、モデルの選択に使用できるため、この見積もりは「無料」で提供されます。</target>
        </trans-unit>
        <trans-unit id="4f52c7809ab985057ba93af9b88459b0d10b33a2" translate="yes" xml:space="preserve">
          <source>This makes sure that the loss function is not heavily influenced by the outliers while not completely ignoring their effect.</source>
          <target state="translated">これにより、損失関数が外れ値の影響を完全に無視することなく、外れ値の影響を大きく受けないようにしています。</target>
        </trans-unit>
        <trans-unit id="2fb338a66a8f54901bcaa2314035cd86710a7d6d" translate="yes" xml:space="preserve">
          <source>This means each coefficient \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">これは、各係数がガウス分布から 描かれていることを意味します。中心はゼロで、精度は</target>
        </trans-unit>
        <trans-unit id="4826ff4b754b03a246d73c38aa2c971ffdf335e1" translate="yes" xml:space="preserve">
          <source>This means each weight \(w_{i}\) is drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):</source>
          <target state="translated">これは、それぞれの重みが、ガウス分布から描かれ、ゼロを中心に、精度を持っていることを意味しています。</target>
        </trans-unit>
        <trans-unit id="de2308f740624c092eea038ac13deb5af2b1fa80" translate="yes" xml:space="preserve">
          <source>This means that any classifiers handling multi-output multiclass or multi-task classification tasks, support the multi-label classification task as a special case. Multi-task classification is similar to the multi-output classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">つまり、マルチ出力マルチクラスまたはマルチタスク分類タスクを扱う任意の分類器は、特殊なケースとしてマルチラベル分類タスクをサポートしています。マルチタスク分類は、モデルの定式化が異なるマルチ出力分類タスクに似ています。詳細については、関連する推定器のドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="6157bc0b8c2f67c8a593bf2d12852c000be43e72" translate="yes" xml:space="preserve">
          <source>This measure is not adjusted for chance. Therefore &lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt;&lt;code&gt;adjusted_mutual_info_score&lt;/code&gt;&lt;/a&gt; might be preferred.</source>
          <target state="translated">この指標は偶然に調整されていません。したがって、&lt;a href=&quot;sklearn.metrics.adjusted_mutual_info_score#sklearn.metrics.adjusted_mutual_info_score&quot;&gt; &lt;code&gt;adjusted_mutual_info_score&lt;/code&gt; &lt;/a&gt;が推奨される場合があります。</target>
        </trans-unit>
        <trans-unit id="cca48ea1404a91d2df7b18cac656df30067cb12b" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.</source>
          <target state="translated">この方法では、各ブースティング・イテレーションの後にモニタリング(テストセットのエラー判定)を行うことができます。</target>
        </trans-unit>
        <trans-unit id="778da8cdceb825f45e49260c13130972c415ba18" translate="yes" xml:space="preserve">
          <source>This method allows monitoring (i.e. determine error on testing set) after each stage.</source>
          <target state="translated">この方法では、各ステージの後にモニタリング(テストセットの誤差判定)を行うことができます。</target>
        </trans-unit>
        <trans-unit id="893e20b8eaafff147aad0ee519c22b2be0783798" translate="yes" xml:space="preserve">
          <source>This method allows to generalize prediction to &lt;em&gt;new observations&lt;/em&gt; (not in the training set). Only available for novelty detection (when novelty is set to True).</source>
          <target state="translated">この方法では、予測を（&lt;em&gt;観測&lt;/em&gt;セットではなく）&lt;em&gt;新しい観測&lt;/em&gt;に一般化できます。新規性検出にのみ使用できます（新規性がTrueに設定されている場合）。</target>
        </trans-unit>
        <trans-unit id="e13bbab31202d773dbd5b155d7e0b7799ca54f84" translate="yes" xml:space="preserve">
          <source>This method computes the least squares solution using a singular value decomposition of X. If X is a matrix of size (n, p) this method has a cost of \(O(n p^2)\), assuming that \(n \geq p\).</source>
          <target state="translated">この方法は、X の特異値分解を用いて最小二乗法を計算する方法である。</target>
        </trans-unit>
        <trans-unit id="dc0919b0c811a79ed295c00492df459fa5ab93e8" translate="yes" xml:space="preserve">
          <source>This method doesn&amp;rsquo;t do anything. It exists purely for compatibility with the scikit-learn transformer API.</source>
          <target state="translated">このメソッドは何もしません。scikit-learnトランスフォーマーAPIとの互換性のためだけに存在します。</target>
        </trans-unit>
        <trans-unit id="89035c0aee87e0125ffcf7bf5f0dbe56fcfb74a9" translate="yes" xml:space="preserve">
          <source>This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">この方法には性能と数値安定性のオーバーヘッドがあるので、オーバーヘッドを隠すために、できるだけ大きなデータの塊(メモリバジェット内に収まる限り)に対してpartial_fitを呼び出す方が良いでしょう。</target>
        </trans-unit>
        <trans-unit id="a344504140059db6f88458066c961354f795c6a7" translate="yes" xml:space="preserve">
          <source>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</source>
          <target state="translated">この方法はパフォーマンスのオーバーヘッドがあるので、オーバーヘッドを隠すために、できるだけ大きなデータの塊(メモリバジェットにフィットする限り)に対してpartial_fitを呼び出す方が良いでしょう。</target>
        </trans-unit>
        <trans-unit id="03d61ee68976e414aa4354d3a63287b0819f990d" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity as &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">この方法の複雑さは、&lt;a href=&quot;#ordinary-least-squares&quot;&gt;通常の最小二乗法&lt;/a&gt;と同じです。</target>
        </trans-unit>
        <trans-unit id="ceeeb1e178fb9959d4ffe786c9917a8fc68013bb" translate="yes" xml:space="preserve">
          <source>This method has the same order of complexity than an &lt;a href=&quot;#ordinary-least-squares&quot;&gt;Ordinary Least Squares&lt;/a&gt;.</source>
          <target state="translated">この方法の複雑さは、&lt;a href=&quot;#ordinary-least-squares&quot;&gt;通常の最小二乗法&lt;/a&gt;と同じです。</target>
        </trans-unit>
        <trans-unit id="8149d43c4db3023940e20ddee18dfd4caaeb24b1" translate="yes" xml:space="preserve">
          <source>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</source>
          <target state="translated">このメソッドは、アウトオブコアやオンライン学習を実装するために、データセットの異なるチャンクに対して複数回連続して呼び出されることが期待されています。</target>
        </trans-unit>
        <trans-unit id="7914e16bc2009e2d4fc76b2006a65a031a42eb76" translate="yes" xml:space="preserve">
          <source>This method is just there to implement the usual API and hence work in pipelines.</source>
          <target state="translated">このメソッドは通常のAPIを実装するためのものであり、パイプラインの中で動作します。</target>
        </trans-unit>
        <trans-unit id="53a4e9f6af590018ff1a37b6f68db2405dd79282" translate="yes" xml:space="preserve">
          <source>This method is just there to mark the fact that this transformer can work in a streaming setup.</source>
          <target state="translated">この方法は、このトランスフォーマーがストリーミングのセットアップで動作するという事実を示すために存在しているだけです。</target>
        </trans-unit>
        <trans-unit id="1ad1f3e2c791502dcf55d0ea0c930c86843ade76" translate="yes" xml:space="preserve">
          <source>This method is meant to be called concurrently by the multiprocessing callback. We rely on the thread-safety of dispatch_one_batch to protect against concurrent consumption of the unprotected iterator.</source>
          <target state="translated">このメソッドは、マルチプロセシングのコールバックから同時に呼び出されることを意図しています。保護されていないイテレータの同時消費を防ぐために、 dispatch_one_batch のスレッドセーフティーに依存しています。</target>
        </trans-unit>
        <trans-unit id="4e81340dab29281a8d6b3bd99833383bb408f46c" translate="yes" xml:space="preserve">
          <source>This method is not deterministic: it computes a quantity called the free energy on X, then on a randomly corrupted version of X, and returns the log of the logistic function of the difference.</source>
          <target state="translated">この方法は決定論的ではありません:それは、X上の自由エネルギーと呼ばれる量を計算し、次にXのランダムに破損したバージョンで計算し、その差のロジスティック関数の対数を返します。</target>
        </trans-unit>
        <trans-unit id="483c17ab697933f17e74386d9739e36cf3fc93e7" translate="yes" xml:space="preserve">
          <source>This method is only available for log loss and modified Huber loss.</source>
          <target state="translated">この方法は、対数損失と修正フーバー損失に対してのみ利用可能です。</target>
        </trans-unit>
        <trans-unit id="d7475ebc10f647671bee9a4be7afee1b81279276" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">このメソッドは,入力として距離行列を取る安全な方法を提供し,ベクトル配列を取る他の多くのアルゴリズムとの互換性を維持します.</target>
        </trans-unit>
        <trans-unit id="b5d8e2fef5ebecb0c66f96f2926a64438412f355" translate="yes" xml:space="preserve">
          <source>This method provides a safe way to take a kernel matrix as input, while preserving compatibility with many other algorithms that take a vector array.</source>
          <target state="translated">この方法は,入力としてカーネル行列を取る安全な方法を提供し,ベクトル配列を取る他の多くのアルゴリズムとの互換性を維持します.</target>
        </trans-unit>
        <trans-unit id="c662dd229414f848149c194436efac32b71db4c2" translate="yes" xml:space="preserve">
          <source>This method returns a Fortran-ordered array. To convert it to a C-ordered array, use &amp;lsquo;np.ascontiguousarray&amp;rsquo;.</source>
          <target state="translated">このメソッドは、Fortranで順序付けられた配列を返します。これをC順の配列に変換するには、「np.ascontiguousarray」を使用します。</target>
        </trans-unit>
        <trans-unit id="0fc2db598aaa9c1a0947d8f73a1238d30285a532" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed. If the input is a distances matrix, it is returned instead.</source>
          <target state="translated">このメソッドは,ベクトル配列または距離行列のいずれかを受け取り,距離行列を返します.入力がベクトル配列の場合,距離が計算されます.入力が距離行列の場合は,代わりに距離行列が返されます.</target>
        </trans-unit>
        <trans-unit id="924736c0bae89c3f4376281e6a105fa549739eb4" translate="yes" xml:space="preserve">
          <source>This method takes either a vector array or a kernel matrix, and returns a kernel matrix. If the input is a vector array, the kernels are computed. If the input is a kernel matrix, it is returned instead.</source>
          <target state="translated">このメソッドは,ベクトル配列またはカーネル行列のいずれかを受け取り,カーネル行列を返します.入力がベクトル配列の場合は,カーネルが計算されます.入力がカーネル行列の場合は,代わりにカーネル行列が返されます.</target>
        </trans-unit>
        <trans-unit id="b80df7fbbffdde8aff9c30af4a5bee17e602075b" translate="yes" xml:space="preserve">
          <source>This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.</source>
          <target state="translated">この方法は,特徴量を一様分布または正規分布に従うように変換します.したがって,与えられた特徴に対して,この変換は,最も頻度の高い値を分散させる傾向があります.また,(限界的な)外れ値の影響も軽減されます:これは,したがって,ロバストな前処理スキームです.</target>
        </trans-unit>
        <trans-unit id="88cc56a80a6739c5287afd3119dab66fa95d86a9" translate="yes" xml:space="preserve">
          <source>This method will raise a &lt;code&gt;ValueError&lt;/code&gt; if any of the estimators do not have &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">このメソッドは、いずれかの推定量に &lt;code&gt;predict_proba&lt;/code&gt; がない場合、 &lt;code&gt;ValueError&lt;/code&gt; を発生させます。</target>
        </trans-unit>
        <trans-unit id="4a6448f2646e45809baed97b35289a513191212b" translate="yes" xml:space="preserve">
          <source>This method works similarly to the builtin &lt;code&gt;apply&lt;/code&gt;, except that the function is called only if the cache is not up to date.</source>
          <target state="translated">このメソッドは、キャッシュが最新でない場合にのみ関数が呼び出されることを除いて、組み込みの &lt;code&gt;apply&lt;/code&gt; と同様に機能します。</target>
        </trans-unit>
        <trans-unit id="3b270b097c02b54b15c6706faba2a05992e48391" translate="yes" xml:space="preserve">
          <source>This metric is furthermore symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.</source>
          <target state="translated">このメトリックはさらに対称的です &lt;code&gt;label_true&lt;/code&gt; で &lt;code&gt;label_pred&lt;/code&gt; を切り替えると、同じスコア値が返されます。これは、実際のグラウンドトゥルースが不明な場合に、同じデータセット上の2つの独立したラベル割り当て戦略の一致を測定するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="b8da4b4fabd4786b82c03e2c15a17659173e15c8" translate="yes" xml:space="preserve">
          <source>This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score value in any way.</source>
          <target state="translated">この指標は、ラベルの絶対値とは無関係です。クラスまたはクラスターのラベル値の順列によって、スコア値が変更されることはありません。</target>
        </trans-unit>
        <trans-unit id="bfbb6fef2be45da43d1153172735208301268ab3" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">このメトリックは対称的ではありません &lt;code&gt;label_true&lt;/code&gt; を &lt;code&gt;label_pred&lt;/code&gt; で切り替えると、一般的に異なる&lt;a href=&quot;sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;が返されます。</target>
        </trans-unit>
        <trans-unit id="d6ecae2ce63387462768b5daf2f548b32eba4de4" translate="yes" xml:space="preserve">
          <source>This metric is not symmetric: switching &lt;code&gt;label_true&lt;/code&gt; with &lt;code&gt;label_pred&lt;/code&gt; will return the &lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; which will be different in general.</source>
          <target state="translated">このメトリックは対称的ではありません &lt;code&gt;label_true&lt;/code&gt; で &lt;code&gt;label_pred&lt;/code&gt; を切り替えると、一般的に異なる&lt;a href=&quot;sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt;が返されます。</target>
        </trans-unit>
        <trans-unit id="b4ddf27eda44a85481c7034e578198a043591cb2" translate="yes" xml:space="preserve">
          <source>This metric is not well-defined for single samples and will return a NaN value if n_samples is less than two.</source>
          <target state="translated">このメトリックは単一サンプルに対しては十分に定義されておらず、n_samplesが2よりも小さい場合にNaN値を返します。</target>
        </trans-unit>
        <trans-unit id="e3d29b108d9b9b14881da7a1115d336ab614cf19" translate="yes" xml:space="preserve">
          <source>This metric is used in multilabel ranking problem, where the goal is to give better rank to the labels associated to each sample.</source>
          <target state="translated">このメトリックは、各サンプルに関連付けられたラベルにより良いランクを与えることを目的としたマルチラベルランキング問題で使用されます。</target>
        </trans-unit>
        <trans-unit id="aca1523dd1402afa978fd168a95010ba6eea69bb" translate="yes" xml:space="preserve">
          <source>This might be clearer with an example: consider a three class problem with class 0 having three support vectors \(v^{0}_0, v^{1}_0, v^{2}_0\) and class 1 and 2 having two support vectors \(v^{0}_1, v^{1}_1\) and \(v^{0}_2, v^{1}_2\) respectively. For each support vector \(v^{j}_i\), there are two dual coefficients. Let&amp;rsquo;s call the coefficient of support vector \(v^{j}_i\) in the classifier between classes \(i\) and \(k\)\(\alpha^{j}_{i,k}\). Then &lt;code&gt;dual_coef_&lt;/code&gt; looks like this:</source>
          <target state="translated">これは例でより明確になるかもしれません：3つのサポートベクター\（v ^ {0} _0、v ^ {1} _0、v ^ {2} _0 \）を持つクラス0とクラス1と2を持つ3つのクラスの問題を考えてみましょう。それぞれ2つのサポートベクター\（v ^ {0} _1、v ^ {1} _1 \）と\（v ^ {0} _2、v ^ {1} _2 \）。サポートベクター\（v ^ {j} _i \）ごとに、2つの二重係数があります。クラス\（i \）と\（k \）\（\ alpha ^ {j} _ {i、k} \）の間の分類器でサポートの係数ベクトル\（v ^ {j} _i \）を呼び出しましょう。その場合、 &lt;code&gt;dual_coef_&lt;/code&gt; は次のようになります。</target>
        </trans-unit>
        <trans-unit id="70091de439c388c847d5db9bb63c11ef6af9aff3" translate="yes" xml:space="preserve">
          <source>This might be made more clear by an example:</source>
          <target state="translated">これは例によって、より明確になるかもしれません。</target>
        </trans-unit>
        <trans-unit id="a18c0c170fadd6145ebf30e97149394844cb89ac" translate="yes" xml:space="preserve">
          <source>This mixin provides a feature selector implementation with &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;inverse_transform&lt;/code&gt; functionality given an implementation of &lt;code&gt;_get_support_mask&lt;/code&gt;.</source>
          <target state="translated">このミックスインを用いて、特徴選択の実装を提供 &lt;code&gt;transform&lt;/code&gt; と &lt;code&gt;inverse_transform&lt;/code&gt; の実装所与機能 &lt;code&gt;_get_support_mask&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="87c35466b9ea86a2466ad7ff0fff224c499553d9" translate="yes" xml:space="preserve">
          <source>This model has many parameters, however the default values are quite reasonable (please see the &lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;reference documentation&lt;/a&gt; for the details):</source>
          <target state="translated">このモデルには多くのパラメーターがありますが、デフォルト値はかなり妥当です（詳細は&lt;a href=&quot;classes#text-feature-extraction-ref&quot;&gt;リファレンスドキュメント&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="a96824cdb923fbde7424d806cedfbff3d185c97a" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">このモデルは、 &lt;code&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/code&gt; Sequential Karhunen-Loeve変換の拡張であり、Sequential Karhunen-Loeveベーシス抽出とその画像への応用、画像処理に関するIEEEトランザクション、Volume 9、Number 8、pp。1371- 1374、2000年8月&lt;a href=&quot;http://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;。http：&lt;/a&gt;//www.cs.technion.ac.il/~mic/doc/skl-ip.pdfを参照</target>
        </trans-unit>
        <trans-unit id="22862405516241c579b3ee92c4c4e899025ea8d7" translate="yes" xml:space="preserve">
          <source>This model is an extension of the Sequential Karhunen-Loeve Transform from: &lt;em&gt;A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&lt;/a&gt;</source>
          <target state="translated">このモデルは、A。Levy&lt;em&gt;およびM. LindenbaumによるSequentialKarhunen&lt;/em&gt; -Loeve変換の拡張であり&lt;em&gt;、Sequential Karhunen-Loeve Basis Extraction and its Application to Images、IEEE Transactions on Image Processing、Volume 9、Number 8、pp.1371- 1374、2000年8月&lt;/em&gt;&lt;a href=&quot;https://www.cs.technion.ac.il/~mic/doc/skl-ip.pdf&quot;&gt;。https：&lt;/a&gt;&lt;em&gt;//www.cs.technion.ac.il/~mic/doc/skl-ip.pdfを&lt;/em&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5eaf31e8c5d94894f814f950dadb507546a62c7a" translate="yes" xml:space="preserve">
          <source>This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.</source>
          <target state="translated">このモデルは、基本的なラベル伝播アルゴリズムに似ていますが、正規化されたグラフのラプラシアンに基づく親和行列と、ラベル間のソフトクランプを使用しています。</target>
        </trans-unit>
        <trans-unit id="31cfc2556e1a899818d23b9328ee0744c892d322" translate="yes" xml:space="preserve">
          <source>This model optimizes the log-loss function using LBFGS or stochastic gradient descent.</source>
          <target state="translated">このモデルは、LBFGSまたは確率的勾配降下を用いて対数損失関数を最適化します。</target>
        </trans-unit>
        <trans-unit id="a4064d8d27531f23ac21cbcbd5928e344df2525d" translate="yes" xml:space="preserve">
          <source>This model optimizes the squared-loss using LBFGS or stochastic gradient descent.</source>
          <target state="translated">このモデルは、LBFGSまたは確率的勾配降下を用いて二乗損失を最適化します。</target>
        </trans-unit>
        <trans-unit id="5bcd7dedd8759fb896822dc89b59d5206ebfcc53" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).</source>
          <target state="translated">損失関数を線形最小二乗関数とし、正則化をl2ノルムで与える回帰モデルを解くモデルです。リッジ回帰またはティクホノフ正則化としても知られている。この推定器は、多変量回帰(すなわち、yが形状(n_samples,n_targets)の2次元配列の場合)をビルトインでサポートしています。</target>
        </trans-unit>
        <trans-unit id="5745ffae87fdf8e03232a3372f515cd928402ef0" translate="yes" xml:space="preserve">
          <source>This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</source>
          <target state="translated">損失関数を線形最小二乗関数とし、正則化をl2ノルムで与える回帰モデルを解くモデルです。リッジ回帰またはティクホノフ正則化としても知られている。この推定器は、多変量回帰(すなわち、yが形状[n_samples,n_targets]の2次元配列の場合)をビルトインでサポートしています。</target>
        </trans-unit>
        <trans-unit id="f19c01936c0bc27e43d782c2c60b0838b0f4894d" translate="yes" xml:space="preserve">
          <source>This module contains both distance metrics and kernels. A brief summary is given on the two here.</source>
          <target state="translated">このモジュールには、距離メトリクスとカーネルの両方が含まれています。ここでは、この2つについて簡単にまとめています。</target>
        </trans-unit>
        <trans-unit id="ea7156035377b3d98062532f66578932992ce326" translate="yes" xml:space="preserve">
          <source>This module contains two loaders. The first one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt;, returns a list of the raw texts that can be fed to text feature extractors such as &lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; with custom parameters so as to extract feature vectors. The second one, &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt;&lt;/a&gt;, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.</source>
          <target state="translated">このモジュールには2つのローダーが含まれています。最初の&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; は&lt;/a&gt;、特徴ベクトルを抽出するために、カスタムパラメーターを使用して&lt;a href=&quot;../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;などのテキスト特徴抽出器に供給することができる生のテキストのリストを返します。 2番目の&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized#sklearn.datasets.fetch_20newsgroups_vectorized&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups_vectorized&lt;/code&gt; は&lt;/a&gt;、すぐに使用できる機能を返します。つまり、機能抽出機能を使用する必要はありません。</target>
        </trans-unit>
        <trans-unit id="e5dbda685e3f3b6ebc21c265d6368ea8386c5f03" translate="yes" xml:space="preserve">
          <source>This module implements multiclass learning algorithms:</source>
          <target state="translated">このモジュールは、マルチクラス学習アルゴリズムを実装しています。</target>
        </trans-unit>
        <trans-unit id="40fee252ae7de928b5fc80e9416986beafe64ef4" translate="yes" xml:space="preserve">
          <source>This module implements multioutput regression and classification.</source>
          <target state="translated">このモジュールは、マルチ出力回帰と分類を実装しています。</target>
        </trans-unit>
        <trans-unit id="f4b5a1fcc345642615c5317116147407ee22511b" translate="yes" xml:space="preserve">
          <source>This module offers support for multi-output problems by implementing this strategy in both &lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt;&lt;code&gt;DecisionTreeRegressor&lt;/code&gt;&lt;/a&gt;. If a decision tree is fit on an output array Y of size &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; then the resulting estimator will:</source>
          <target state="translated">このモジュールは、この戦略を&lt;a href=&quot;generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.tree.decisiontreeregressor#sklearn.tree.DecisionTreeRegressor&quot;&gt; &lt;code&gt;DecisionTreeRegressor&lt;/code&gt; の&lt;/a&gt;両方に実装することにより、マルチ出力問題のサポートを提供します。決定木がサイズ &lt;code&gt;[n_samples, n_outputs]&lt;/code&gt; 出力配列Yに適合している場合、結果の推定量は次のようになります。</target>
        </trans-unit>
        <trans-unit id="69b4d83c7d3d58178d932db005c229bef475361e" translate="yes" xml:space="preserve">
          <source>This normalization is implemented by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; class:</source>
          <target state="translated">この正規化は、&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt;クラスによって実装されます。</target>
        </trans-unit>
        <trans-unit id="36bde3d3011eb8df53f7587f509f261b5588364f" translate="yes" xml:space="preserve">
          <source>This object uses workers to compute in parallel the application of a function to many different arguments. The main functionality it brings in addition to using the raw multiprocessing or concurrent.futures API are (see examples for details):</source>
          <target state="translated">このオブジェクトはワーカーを使用して、多くの異なる引数への関数の適用を並列に計算します。生のマルチプロセシングや concurrent.futures API を使用することに加えて、このオブジェクトがもたらす主な機能は以下の通りです (詳細は例を参照してください)。</target>
        </trans-unit>
        <trans-unit id="43f85d31a1122b5ce913b6ac1587dc97b9fac8c9" translate="yes" xml:space="preserve">
          <source>This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the &amp;lsquo;real world&amp;rsquo;.</source>
          <target state="translated">このパッケージには、機械学習コミュニティで一般的に使用されるより大きなデータセットをフェッチして、「実世界」からのデータのアルゴリズムをベンチマークするヘルパーも含まれています。</target>
        </trans-unit>
        <trans-unit id="8291d2ecf0ae6621cc55dbf9132ec6413177dbb1" translate="yes" xml:space="preserve">
          <source>This parameter does not have any effect. The components are always normalized.</source>
          <target state="translated">このパラメータは何の影響もありません。コンポーネントは常に正規化されます。</target>
        </trans-unit>
        <trans-unit id="f678792533c8ea573ae326139ccc463721df5e43" translate="yes" xml:space="preserve">
          <source>This parameter has been renamed to n_components and will be removed in version 0.21. .. deprecated:: 0.19</source>
          <target state="translated">このパラメータは n_components に名前が変更され、バージョン 0.21 で削除されます。0.19</target>
        </trans-unit>
        <trans-unit id="b9bd887348c693f73ff73c188c30554ec63931d0" translate="yes" xml:space="preserve">
          <source>This parameter has no effect on the matplotlib tree visualisation and it is kept here for backward compatibility.</source>
          <target state="translated">このパラメータはmatplotlibのツリー表示には何の影響もなく、下位互換性のためにここに保持されます。</target>
        </trans-unit>
        <trans-unit id="95ab9404db52634d7b16f5cf223dc53c5df9617b" translate="yes" xml:space="preserve">
          <source>This parameter has no effect, is deprecated, and will be removed.</source>
          <target state="translated">このパラメータは何の効果もなく、非推奨であり、削除される予定です。</target>
        </trans-unit>
        <trans-unit id="c3803345bcca4c293ec436fd5df6e0af3703aedc" translate="yes" xml:space="preserve">
          <source>This parameter is deprecated and will be removed in v0.24.</source>
          <target state="translated">このパラメータは非推奨であり、v0.24で削除されます。</target>
        </trans-unit>
        <trans-unit id="2008376a104f1f0d722babab4554d9900556a331" translate="yes" xml:space="preserve">
          <source>This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">このパラメータは、語彙が None でない場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="4896edc233b2b945e9bfe76cd7c644f9b147f395" translate="yes" xml:space="preserve">
          <source>This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use &lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">このパラメーターは、 &lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合は無視されます。Trueの場合、リグレッサXは、平均を差し引き、l2-ノルムで割ることにより、回帰前に正規化されます。標準化したい場合は、 &lt;code&gt;normalize=False&lt;/code&gt; を使用して推定器で &lt;code&gt;fit&lt;/code&gt; を呼び出す前に&lt;a href=&quot;sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;を使用してください。</target>
        </trans-unit>
        <trans-unit id="a954f8a244020c9f424e9822cfad5459a2f5fec4" translate="yes" xml:space="preserve">
          <source>This parameter is ignored.</source>
          <target state="translated">このパラメータは無視されます。</target>
        </trans-unit>
        <trans-unit id="74de1b86fb436972ff8b47352593daa33d35779f" translate="yes" xml:space="preserve">
          <source>This parameter is not needed to compute tfidf.</source>
          <target state="translated">このパラメータはtfidfの計算には必要ありません。</target>
        </trans-unit>
        <trans-unit id="18c6fb9267c5496a0a4415bd237b294d4f877c13" translate="yes" xml:space="preserve">
          <source>This parameter is required for multiclass/multilabel targets. If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">このパラメーターは、マルチクラス/マルチラベルターゲットに必要です。 &lt;code&gt;None&lt;/code&gt; の場合、各クラスのスコアが返されます。それ以外の場合、これはデータに対して実行される平均化のタイプを決定します。</target>
        </trans-unit>
        <trans-unit id="4b54c5323e385131687ecd8fe6362000ef5ec12b" translate="yes" xml:space="preserve">
          <source>This parameters can be accessed through the members &lt;code&gt;dual_coef_&lt;/code&gt; which holds the product \(y_i \alpha_i\), &lt;code&gt;support_vectors_&lt;/code&gt; which holds the support vectors, and &lt;code&gt;intercept_&lt;/code&gt; which holds the independent term \(\rho\) :</source>
          <target state="translated">このパラメータは、部材を介してアクセスすることができる &lt;code&gt;dual_coef_&lt;/code&gt; 製品\（Y_I \ alpha_i \）、保持する &lt;code&gt;support_vectors_&lt;/code&gt; サポートベクトルを保持し、 &lt;code&gt;intercept_&lt;/code&gt; 独立用語\（\ロー\）を保持します。</target>
        </trans-unit>
        <trans-unit id="f0e92a41ff311d2df395e780ee2f06d2a63e9cbc" translate="yes" xml:space="preserve">
          <source>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.</source>
          <target state="translated">このパスの長さは、そのようなランダムな木の森で平均化されたもので、正規性の尺度であり、我々の決定関数である。</target>
        </trans-unit>
        <trans-unit id="80dec09fc285dd6f9c561fc2931162bad1982cdb" translate="yes" xml:space="preserve">
          <source>This plot compares the decision surfaces learned by a decision tree classifier (first column), by a random forest classifier (second column), by an extra- trees classifier (third column) and by an AdaBoost classifier (fourth column).</source>
          <target state="translated">このプロットは、決定木分類器(1列目)、ランダムフォレスト分類器(2列目)、エクストラツリー分類器(3列目)、AdaBoost分類器(4列目)によって学習された決定面を比較しています。</target>
        </trans-unit>
        <trans-unit id="3b15144cc63de75145bd9b8c8333a27bef49a738" translate="yes" xml:space="preserve">
          <source>This plot is called a Lorenz curve and can be summarized by the Gini index:</source>
          <target state="translated">このプロットはローレンツ曲線と呼ばれ、ジニ指数でまとめることができます。</target>
        </trans-unit>
        <trans-unit id="8e05dc7c1a0ec44a96abb884d1ce621cca93db4e" translate="yes" xml:space="preserve">
          <source>This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. &lt;strong&gt;For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&lt;/strong&gt;.</source>
          <target state="translated">サンプルの数が1,000を超え、クラスターの数が10未満の場合、この問題は安全に無視できます。&lt;strong&gt;サンプルサイズが小さい場合やクラスターの数が多い場合は、Adjusted Rand Indexなどの調整済みインデックスを使用する方が安全です（ ARI）&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="432c2ac32bcc01f0466fb33da0cfef7067b741ad" translate="yes" xml:space="preserve">
          <source>This problem stems from two limitations of impurity-based feature importances:</source>
          <target state="translated">この問題は、不純物に基づく特徴量の2つの制限に起因しています。</target>
        </trans-unit>
        <trans-unit id="fcd7e110cbbcbd004685bcd45cf928dd3da1b5b1" translate="yes" xml:space="preserve">
          <source>This procedure (spectral clustering on an image) is an efficient approximate solution for finding normalized graph cuts.</source>
          <target state="translated">この手順(画像上でのスペクトルクラスタリング)は、正規化されたグラフカットを見つけるための効率的な近似解である。</target>
        </trans-unit>
        <trans-unit id="f7d25c0cd20cd8cb8daa937c60ac3edd0b2b2f75" translate="yes" xml:space="preserve">
          <source>This ranking metric yields a high value if true labels are ranked high by &lt;code&gt;y_score&lt;/code&gt;.</source>
          <target state="translated">真のラベルが &lt;code&gt;y_score&lt;/code&gt; によって上位にランク付けされている場合、このランキングメトリックは高い値を生成します。</target>
        </trans-unit>
        <trans-unit id="7a8651d966c336f363771d222433438f229cb5c2" translate="yes" xml:space="preserve">
          <source>This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.</source>
          <target state="translated">この回帰器は、他の(実際の)回帰器と比較するための単純なベースラインとして有用です。実際の問題には使用しないでください。</target>
        </trans-unit>
        <trans-unit id="566769fe300350777b617d7ceed39620171814da" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices by passing &lt;code&gt;with_mean=False&lt;/code&gt; to avoid breaking the sparsity structure of the data.</source>
          <target state="translated">このスケーラーは、 &lt;code&gt;with_mean=False&lt;/code&gt; を渡してデータのスパース構造を壊さないようにすることで、スパースCSRまたはCSCマトリックスにも適用できます。</target>
        </trans-unit>
        <trans-unit id="bf350412f5695ebe05a62d114269ff308d8edf9f" translate="yes" xml:space="preserve">
          <source>This scaler can also be applied to sparse CSR or CSC matrices.</source>
          <target state="translated">このスケーラは、疎なCSRやCSC行列にも適用できます。</target>
        </trans-unit>
        <trans-unit id="096cae15373bbc176ca80052b34794345347f334" translate="yes" xml:space="preserve">
          <source>This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.</source>
          <target state="translated">このスコアは、Xから検定カイ二乗統計量が最も高い値を持つn_features特徴量を選択するために使用できます。この特徴量は、クラスと比較して、ブーリアンや度数(例えば、文書分類における項数)などの非負の特徴のみを含まなければなりません。</target>
        </trans-unit>
        <trans-unit id="bc67f7a4c884a57cb8d65e3051862bc296a2adb5" translate="yes" xml:space="preserve">
          <source>This score is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;'arithmetic'&lt;/code&gt; option for averaging.</source>
          <target state="translated">このスコアは、平均化するための &lt;code&gt;'arithmetic'&lt;/code&gt; オプションを使用した&lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt;と同じです。</target>
        </trans-unit>
        <trans-unit id="81b377dd4306b3470c7efb10edcaa8d55b57210b" translate="yes" xml:space="preserve">
          <source>This section illustrates the use of a &lt;code&gt;Pipeline&lt;/code&gt; with &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">このセクションでは、使用説明 &lt;code&gt;Pipeline&lt;/code&gt; と &lt;code&gt;GridSearchCV&lt;/code&gt; を</target>
        </trans-unit>
        <trans-unit id="929a45e65dc1a0cd0b685d6194be9ae4708eb857" translate="yes" xml:space="preserve">
          <source>This should make it possible to check that the cross-validation score is in the same range as before.</source>
          <target state="translated">これにより、クロスバリデーションのスコアが以前と同じ範囲にあることが確認できるはずです。</target>
        </trans-unit>
        <trans-unit id="08af461e03baea2ad13f22a738ff3dde29c2a50f" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">これは、Haversine距離メトリックに基づいて構築されたBall Treeを使用して、地理空間データに関する近傍ベースのクエリ（特にカーネル密度推定）の例を示しています。つまり、緯度/経度のポイント間の距離です。データセットはフィリップスらによって提供されます。al。（2006）。可能な場合、この例では&lt;a href=&quot;http://matplotlib.org/basemap&quot;&gt;ベースマップ&lt;/a&gt;を使用して、南アメリカの海岸線と国境をプロットします。</target>
        </trans-unit>
        <trans-unit id="d9d5278cf29981ffe0af23942c116e835acd3587" translate="yes" xml:space="preserve">
          <source>This shows an example of a neighbors-based query (in particular a kernel density estimate) on geospatial data, using a Ball Tree built upon the Haversine distance metric &amp;ndash; i.e. distances over points in latitude/longitude. The dataset is provided by Phillips et. al. (2006). If available, the example uses &lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;basemap&lt;/a&gt; to plot the coast lines and national boundaries of South America.</source>
          <target state="translated">これは、Haversine距離メトリック（つまり、緯度/経度のポイント上の距離）に基づいて構築されたボールツリーを使用した、地理空間データに対するネイバーベースのクエリ（特にカーネル密度推定）の例を示しています。データセットはPhillipsらによって提供されています。al。（2006）。可能な場合、この例では&lt;a href=&quot;https://matplotlib.org/basemap/&quot;&gt;ベースマップ&lt;/a&gt;を使用して南アメリカの海岸線と国境をプロットします。</target>
        </trans-unit>
        <trans-unit id="38716491ad409e2f991bc1db8f7b1d944921bf99" translate="yes" xml:space="preserve">
          <source>This sort of preprocessing can be streamlined with the &lt;a href=&quot;compose#pipeline&quot;&gt;Pipeline&lt;/a&gt; tools. A single object representing a simple polynomial regression can be created and used as follows:</source>
          <target state="translated">この種の前処理は、&lt;a href=&quot;compose#pipeline&quot;&gt;パイプライン&lt;/a&gt;ツールを使用して効率化できます。単純な多項式回帰を表す単一のオブジェクトを作成して、次のように使用できます。</target>
        </trans-unit>
        <trans-unit id="4e6050ab2083fb67a848ffe7f83ae292a8f60f62" translate="yes" xml:space="preserve">
          <source>This strategy can also be used for multilabel learning, where a classifier is used to predict multiple labels for instance, by fitting on a 2-d matrix in which cell [i, j] is 1 if sample i has label j and 0 otherwise.</source>
          <target state="translated">この手法は、複数のラベルを予測するために分類器を使用するマルチラベル学習にも使用することができます。</target>
        </trans-unit>
        <trans-unit id="8cd6a64f79d725ef1cdd342315685305aab51887" translate="yes" xml:space="preserve">
          <source>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">この戦略は、クラスのペアごとに1つの分類子を当てはめることです。予測時に、最も票を獲得したクラスが選択されます。 &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 分類器に適合する必要があるため、このメソッドは通常、O（n_classes ^ 2）の複雑さのために、1対残りよりも遅くなります。ただし、このメソッドは、 &lt;code&gt;n_samples&lt;/code&gt; でうまくスケーリングしないカーネルアルゴリズムなどのアルゴリズムには有利な場合があります。これは、個々の学習問題に含まれるのはデータの小さなサブセットのみであるのに対し、残りと1対1では、完全なデータセットが &lt;code&gt;n_classes&lt;/code&gt; 回使用されるためです。</target>
        </trans-unit>
        <trans-unit id="de640b51f281cc0046c1a9e652c58d4e96ebef0b" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification</source>
          <target state="translated">この戦略は,1つのターゲットに対して1つの分類器を適合させることで構成されます.これは,マルチターゲット分類をネイティブにサポートしていない分類器を拡張するための単純な戦略です.</target>
        </trans-unit>
        <trans-unit id="7d6fb6c6a7f2b79b31f4627b09bbb93dcc2f3bc4" translate="yes" xml:space="preserve">
          <source>This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.</source>
          <target state="translated">この戦略は、ターゲットごとに1つの回帰器を適合させることからなる。これは,マルチターゲット回帰をネイティブにサポートしないリグレグレッサーを拡張するための単純な戦略である.</target>
        </trans-unit>
        <trans-unit id="27cbaceed22a6f90d5ae07c700825d27bfca1f78" translate="yes" xml:space="preserve">
          <source>This strategy has several advantages:</source>
          <target state="translated">この戦略にはいくつかの利点があります。</target>
        </trans-unit>
        <trans-unit id="91d49a77db9793bc904e6dbf1c0dda029b6c110b" translate="yes" xml:space="preserve">
          <source>This strategy is illustrated below.</source>
          <target state="translated">この戦略は以下のように説明されています。</target>
        </trans-unit>
        <trans-unit id="02849272fb07ed52ea9b00f7ccc02a748c971372" translate="yes" xml:space="preserve">
          <source>This strategy, also known as &lt;strong&gt;one-vs-all&lt;/strong&gt;, is implemented in &lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;OneVsRestClassifier&lt;/code&gt;&lt;/a&gt;. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only &lt;code&gt;n_classes&lt;/code&gt; classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.</source>
          <target state="translated">この戦略は&lt;strong&gt;one-vs-all&lt;/strong&gt;とも呼ばれ、&lt;a href=&quot;generated/sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;OneVsRestClassifier&lt;/code&gt; に&lt;/a&gt;実装されています。戦略は、クラスごとに1つの分類子を当てはめることです。各分類子について、クラスは他のすべてのクラスに対して適合されます。計算効率に加えて（ &lt;code&gt;n_classes&lt;/code&gt; 分類子のみが必要です）、このアプローチの1つの利点はその解釈可能性です。各クラスは1つだけの分類子で表されるため、対応する分類子を調べることにより、クラスに関する知識を得ることができます。これは最も一般的に使用される戦略であり、デフォルトの選択です。</target>
        </trans-unit>
        <trans-unit id="27ac94ab878e8b852843daf6fdc6644656d86a0e" translate="yes" xml:space="preserve">
          <source>This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see &lt;a href=&quot;svm#svm&quot;&gt;Support Vector Machines&lt;/a&gt;). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.</source>
          <target state="translated">このサブモジュールには、特定のカーネルに対応する機能マッピングを近似する関数が含まれています。これは、たとえばサポートベクターマシンで使用されるためです（&lt;a href=&quot;svm#svm&quot;&gt;サポートベクターマシンを&lt;/a&gt;参照）。次の機能関数は、入力の非線形変換を実行します。これは、線形分類または他のアルゴリズムの基礎として機能します。</target>
        </trans-unit>
        <trans-unit id="fcbae9cfcf0bd03c252edbce0ec54b00175fa149" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options.</source>
          <target state="translated">このテストは、クラスまたはインスタンスに適用することができます。現在のところ、クラスは構築に関連したいくつかの追加テストを持っていますが、インスタンスを渡すことで複数のオプションのテストが可能になります。</target>
        </trans-unit>
        <trans-unit id="1df76b4b8062cdd31b59f7b7a96f694c7a4a84f4" translate="yes" xml:space="preserve">
          <source>This test can be applied to classes or instances. Classes currently have some additional tests that related to construction, while passing instances allows the testing of multiple options. However, support for classes is deprecated since version 0.23 and will be removed in version 0.24 (class checks will still be run on the instances).</source>
          <target state="translated">このテストは、クラスまたはインスタンスに適用することができます。現在、クラスは構築に関連するいくつかの追加テストを持っていますが、インスタンスを渡すことで複数のオプションのテストが可能になります。しかし、クラスのサポートはバージョン 0.23 から非推奨となり、バージョン 0.24 で削除されます (クラスのチェックはまだインスタンスに対して実行されます)。</target>
        </trans-unit>
        <trans-unit id="fe4512e0330ee3f9d4d908b10acadfb35dcb4b46" translate="yes" xml:space="preserve">
          <source>This text vectorizer implementation uses the hashing trick to find the token string name to feature integer index mapping.</source>
          <target state="translated">このテキストベクタライザの実装は、整数インデックスマッピングを特徴とするトークン文字列名を見つけるためにハッシュトリックを使用しています。</target>
        </trans-unit>
        <trans-unit id="90704510327932a48fb3c52155398163f97475e2" translate="yes" xml:space="preserve">
          <source>This transformation is often used as an alternative to zero mean, unit variance scaling.</source>
          <target state="translated">この変換は、ゼロ平均、単位分散スケーリングの代替としてよく使用されます。</target>
        </trans-unit>
        <trans-unit id="6539f7aec79b7dc39bdc0281525ed4d20f3ca8db" translate="yes" xml:space="preserve">
          <source>This transformation will only be exact if n_components=n_features</source>
          <target state="translated">この変換は、n_components=n_featuresの場合にのみ正確になります。</target>
        </trans-unit>
        <trans-unit id="2f720ce11fea82f150f2e1314efc3b6e74d2aa65" translate="yes" xml:space="preserve">
          <source>This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).</source>
          <target state="translated">この変換器は,密な numpy 配列と scipy.sparse 行列の両方を扱うことができます(コピー/変換の負担を避けたい場合は CSR フォーマットを使用してください).</target>
        </trans-unit>
        <trans-unit id="22f51ce5936d304512713b7c2d6420a9339ed07c" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.</source>
          <target state="translated">この変換器は、切り捨て特異値分解(SVD)を用いて線形次元削減を行う。PCAとは異なり、この推定器は特異値分解を計算する前にデータを中心にしません。これは、scipy.sparse行列を効率的に扱うことができることを意味します。</target>
        </trans-unit>
        <trans-unit id="548ea059334e4b91f9c90aef5db25d9def754336" translate="yes" xml:space="preserve">
          <source>This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.</source>
          <target state="translated">この変換器は、切り捨て特異値分解(SVD)を用いて線形次元削減を行う。PCAとは異なり、この推定器は特異値分解を計算する前にデータのセンタリングを行いません。これは、疎な行列を効率的に扱うことができることを意味する。</target>
        </trans-unit>
        <trans-unit id="cbf82199a6ba754f7c0185042f3f4e595a8e8525" translate="yes" xml:space="preserve">
          <source>This transformer should be used to encode target values, &lt;em&gt;i.e.&lt;/em&gt;&lt;code&gt;y&lt;/code&gt;, and not the input &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">このトランスフォーマーは、入力 &lt;code&gt;X&lt;/code&gt; ではなく、ターゲット値、&lt;em&gt;つまり&lt;/em&gt; &lt;code&gt;y&lt;/code&gt; をエンコードするために使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="c058bdf39166834e7b3e02bee2a3dc32df1bea5c" translate="yes" xml:space="preserve">
          <source>This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.</source>
          <target state="translated">この変換器は,特徴名と特徴値のマッピング(辞書のようなオブジェクト)のリストをNumpy配列またはscipy.sparse行列に変換し,scikit-learnの推定器で使用します.</target>
        </trans-unit>
        <trans-unit id="6fa17f9065133747f6dee2c04fd6c387874c04ab" translate="yes" xml:space="preserve">
          <source>This tutorial will explore &lt;em&gt;statistical learning&lt;/em&gt;, the use of machine learning techniques with the goal of &lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;statistical inference&lt;/a&gt;: drawing conclusions on the data at hand.</source>
          <target state="translated">このチュートリアルでは、&lt;em&gt;統計学習&lt;/em&gt;、つまり&lt;a href=&quot;https://en.wikipedia.org/wiki/Statistical_inference&quot;&gt;統計的推論を&lt;/a&gt;目的とする機械学習手法の使用について説明します。</target>
        </trans-unit>
        <trans-unit id="d770164eec068c2686e18d9f67f7678a7fe3d2ab" translate="yes" xml:space="preserve">
          <source>This uses the Benjamini-Hochberg procedure. &lt;code&gt;alpha&lt;/code&gt; is an upper bound on the expected false discovery rate.</source>
          <target state="translated">これはBenjamini-Hochberg手順を使用します。 &lt;code&gt;alpha&lt;/code&gt; は、予想される誤検出率の上限です。</target>
        </trans-unit>
        <trans-unit id="25630de50e6415b67bb72ea47abf6e457ed32d31" translate="yes" xml:space="preserve">
          <source>This uses the score defined by &lt;code&gt;scoring&lt;/code&gt; where provided, and the &lt;code&gt;best_estimator_.score&lt;/code&gt; method otherwise.</source>
          <target state="translated">これは、提供された場合は &lt;code&gt;scoring&lt;/code&gt; によって定義されたスコアを使用し、それ以外の場合は &lt;code&gt;best_estimator_.score&lt;/code&gt; メソッドを使用します。</target>
        </trans-unit>
        <trans-unit id="28c90b747be44784ef68312c004db0e8049cba2c" translate="yes" xml:space="preserve">
          <source>This utility is documented, but &lt;strong&gt;private&lt;/strong&gt;. This means that backward compatibility might be broken without any deprecation cycle.</source>
          <target state="translated">このユーティリティは文書化されていますが、&lt;strong&gt;プライベート&lt;/strong&gt;です。これは、非推奨サイクルなしで下位互換性が失われる可能性があることを意味します。</target>
        </trans-unit>
        <trans-unit id="f6f06f080d161d82167224fa4f5455a90c3bc7e3" translate="yes" xml:space="preserve">
          <source>This utility is meant to be used internally by estimators themselves, typically in their own predict / transform methods.</source>
          <target state="translated">このユーティリティは、通常は独自の予測/変換メソッドで、推定者自身が内部的に使用することを目的としています。</target>
        </trans-unit>
        <trans-unit id="57e78bad29e459afb6f7e8e9a46e0b5e6e5f4fa9" translate="yes" xml:space="preserve">
          <source>This value is valid if class_weight parameter in fit() is not set.</source>
          <target state="translated">この値は、 fit()の class_weight パラ メ タ が設定 さ れていない と き に有効です。</target>
        </trans-unit>
        <trans-unit id="0973d55bbbd406d7d050b325e278935eae6a368e" translate="yes" xml:space="preserve">
          <source>This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of &amp;ldquo;mutual information&amp;rdquo; between the label assignments.</source>
          <target state="translated">相互情報と正規化バリアントのこの値は偶然に調整されておらず、ラベル割り当て間の「相互情報」の実際の量に関係なく、異なるラベル（クラスター）の数が増えるにつれて増加する傾向があります。</target>
        </trans-unit>
        <trans-unit id="ec27c204380d1bf1bec671104c4e5cc563667983" translate="yes" xml:space="preserve">
          <source>This visualization is an example of a &lt;em&gt;kernel density estimation&lt;/em&gt;, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</source>
          <target state="translated">この視覚化は、&lt;em&gt;カーネル密度推定の&lt;/em&gt;例であり、この場合はトップハットカーネル（つまり、各ポイントの正方形のブロック）を使用しています。より滑らかなカーネルを使用することで、より滑らかな分布を回復できます。右下のプロットは、ガウスカーネル密度推定値を示しています。各点は、ガウス曲線が合計に寄与しています。結果は、データから導出された滑らかな密度推定であり、ポイントの分布の強力なノンパラメトリックモデルとして機能します。</target>
        </trans-unit>
        <trans-unit id="1cad85e71e9b226b43b5778c8058de4fe70516a7" translate="yes" xml:space="preserve">
          <source>This warning is used to notify the user that BLAS was not used for dot operation and hence the efficiency may be affected.</source>
          <target state="translated">この警告は、ドット操作にBLASが使用されていないため、効率に影響を及ぼす可能性があることをユーザーに通知するために使用されます。</target>
        </trans-unit>
        <trans-unit id="7b4c8162b5298ba9d922a2200274b38ddddf44e8" translate="yes" xml:space="preserve">
          <source>This warning notifies the user that the efficiency may not be optimal due to some reason which may be included as a part of the warning message. This may be subclassed into a more specific Warning class.</source>
          <target state="translated">この警告は、警告メッセージの一部として含まれるかもしれない何らかの理由により、効率が最適ではないかもしれないことをユーザに通知します。これは、より特定の警告クラスにサブクラス化されることがあります。</target>
        </trans-unit>
        <trans-unit id="ec79da6e5e29f4afd0662e82ec298c39ed6dbabd" translate="yes" xml:space="preserve">
          <source>This warning occurs when some input data needs to be converted or interpreted in a way that may not match the user&amp;rsquo;s expectations.</source>
          <target state="translated">この警告は、一部の入力データをユーザーの期待と一致しない方法で変換または解釈する必要がある場合に発生します。</target>
        </trans-unit>
        <trans-unit id="14994b75958434504d6803fa4be46a86d6219fc9" translate="yes" xml:space="preserve">
          <source>This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.</source>
          <target state="translated">もともとは情報検索(検索エンジンの検索結果のランキング機能として)のために開発された用語重み付け方式で、文書の分類やクラスタリングにも利用されています。</target>
        </trans-unit>
        <trans-unit id="90d00e9f85af52e63288d2fca3d9f513dce9de12" translate="yes" xml:space="preserve">
          <source>This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.</source>
          <target state="translated">しかし,母集団の共分散が ID 行列の倍数である場合,これは Ledoit-Wolf 手法の場合ではない.この場合、標本数が増えるにつれて、Ledoit-Wolf の縮小推定値は 1 に近づきます。これは、Ledoit-Wolf の意味での共分散行列の最適な推定値が identity の倍数であることを示しています。母集団の共分散はすでに identity 行列の倍数なので、Ledoit-Wolf の解は確かに妥当な推定値です。</target>
        </trans-unit>
        <trans-unit id="e911226999d28ae4c4eb95cef049955b008548cf" translate="yes" xml:space="preserve">
          <source>Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won&amp;rsquo;t change the score values in any way.</source>
          <target state="translated">これら3つのメトリックは、ラベルの絶対値とは無関係です。クラスまたはクラスターのラベル値の順列は、スコア値を変更しません。</target>
        </trans-unit>
        <trans-unit id="a17151aff3f6e79d6bfb3bc3e7c5d30ff3b77b7d" translate="yes" xml:space="preserve">
          <source>Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.</source>
          <target state="translated">これらのメトリクスは、同じサンプルの接地真相クラスのラベルの知識を与えられた評価するためのクラスタリングラベリングの正規化された条件付きエントロピー尺度に基づいています。</target>
        </trans-unit>
        <trans-unit id="831e093286e91d34e1415d38600e7c8277f14a07" translate="yes" xml:space="preserve">
          <source>Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'ltsa'&lt;/code&gt;.</source>
          <target state="translated">技術的にはLLEのバリアントではありませんが、ローカルタンジェントスペースアライメント（LTSA）はアルゴリズム的にLLEによく似ているため、このカテゴリに分類できます。 LSAのように近傍距離を維持することに焦点を当てるのではなく、LTSAは接線空間を介して各近傍でローカルジオメトリを特徴付け、グローバル最適化を実行してこれらのローカル接線空間を位置合わせして埋め込みを学習します。 LTSAは、キーワード&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt; = &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;またはそのオブジェクト指向の対応物であるLocallyLinearEmbeddingで、キーワード &lt;code&gt;method = 'ltsa'&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="3dcfc8b5bdf930c1b66451c5dc30f486901100ee" translate="yes" xml:space="preserve">
          <source>Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially useful when the data-points are not linearly separable.</source>
          <target state="translated">以下に3種類のSVM-Kernelsを表示します。多項式とRBFは、データ点が線形に分離できない場合に特に有効です。</target>
        </trans-unit>
        <trans-unit id="2eb0d5d5e8d716a06a5bc42a652c1781cf721343" translate="yes" xml:space="preserve">
          <source>Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.</source>
          <target state="translated">サンプル特徴の2値化(ブーリアンへのマッピング)の閾値.Noneの場合,入力はすでに2値ベクトルで構成されていると推定されます.</target>
        </trans-unit>
        <trans-unit id="ac359cd376aaf3163dffdc564a92f8f55ebdbfe9" translate="yes" xml:space="preserve">
          <source>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</source>
          <target state="translated">木の成長を早期に停止させる閾値。ノードは、その不純物が閾値を超えていれば分裂し、そうでなければ葉となる。</target>
        </trans-unit>
        <trans-unit id="d2dde1e4fd07fa9e4ff99bf50a843f5c394281b4" translate="yes" xml:space="preserve">
          <source>Threshold for shrinking centroids to remove features.</source>
          <target state="translated">特徴を除去するためにセントロイドを縮小するためのしきい値。</target>
        </trans-unit>
        <trans-unit id="5b50eca69565a6240c9cb586697767c09ac4525e" translate="yes" xml:space="preserve">
          <source>Threshold on the size of arrays passed to the workers that triggers automated memory mapping in temp_folder. Can be an int in Bytes, or a human-readable string, e.g., &amp;lsquo;1M&amp;rsquo; for 1 megabyte. Use None to disable memmapping of large arrays. Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">temp_folderで自動メモリマッピングをトリガーする、ワーカーに渡される配列のサイズのしきい値。バイト単位の整数、または人間が読める文字列（1メガバイトの場合は「1M」など）を指定できます。大きな配列のマッピングを無効にするには、Noneを使用します。backend =&amp;rdquo; loky&amp;rdquo;または&amp;ldquo; multiprocessing&amp;rdquo;の場合のみアクティブです。</target>
        </trans-unit>
        <trans-unit id="3bf722c4ec04176f091be4d50fbd629d5b754a20" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation in SVD solver.</source>
          <target state="translated">SVDソルバーのランク推定に使用されるしきい値。</target>
        </trans-unit>
        <trans-unit id="0168a115989469a76c56e8c46c0d56b1a01f88c6" translate="yes" xml:space="preserve">
          <source>Threshold used for rank estimation.</source>
          <target state="translated">ランク推定に使用されるしきい値。</target>
        </trans-unit>
        <trans-unit id="558232b0add0e7cf1e4001c15b7a509781ecfb59" translate="yes" xml:space="preserve">
          <source>Threshold used in the binary and multi-label cases.</source>
          <target state="translated">バイナリおよびマルチラベルの場合に使用されるしきい値。</target>
        </trans-unit>
        <trans-unit id="d260a173cc06214ee3d2352996ea165371c17c29" translate="yes" xml:space="preserve">
          <source>Thresholding</source>
          <target state="translated">Thresholding</target>
        </trans-unit>
        <trans-unit id="8265a18b28c2cb3c5a28ceb45384d9a49c2f7715" translate="yes" xml:space="preserve">
          <source>Thresholding is clearly not useful for denoising, but it is here to show that it can produce a suggestive output with very high speed, and thus be useful for other tasks such as object classification, where performance is not necessarily related to visualisation.</source>
          <target state="translated">しきい値はノイズ除去には明らかに有用ではありませんが、ここでは、非常に高速で示唆に富んだ出力を生成できることを示しています。</target>
        </trans-unit>
        <trans-unit id="c4d29a75003891e7d5c5dbb3dea7166bf19f4ab9" translate="yes" xml:space="preserve">
          <source>Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.</source>
          <target state="translated">しきい値処理は非常に高速ですが、正確な再構成は得られません。これらの手法は、分類タスクに有用であることが文献で示されています。画像再構成では、直交マッチングの追求が最も正確で偏りのない再構成をもたらします。</target>
        </trans-unit>
        <trans-unit id="3904c870d9e800cc53a98ecb8acef59d010fad3d" translate="yes" xml:space="preserve">
          <source>Throw a ValueError if X contains NaN or infinity.</source>
          <target state="translated">X に NaN または無限大が含まれている場合に ValueError をスローします。</target>
        </trans-unit>
        <trans-unit id="8b8612c016401dc529cb09be5ddd6996fe872d9c" translate="yes" xml:space="preserve">
          <source>Thus in binary classification, the count of true negatives is \(C_{0,0}\), false negatives is \(C_{1,0}\), true positives is \(C_{1,1}\) and false positives is \(C_{0,1}\).</source>
          <target state="translated">このように、2値分類では、真の否定の数は \(C_{0,0}\)、偽の否定の数は \(C_{1,0}\)、真の陽性の数は ¶(C_{1,1})、偽の陽性の数は ¶(C_{0,1})であることになります。</target>
        </trans-unit>
        <trans-unit id="877864e25b035038afd6bbe5a72ca90fb8e0741e" translate="yes" xml:space="preserve">
          <source>Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input&amp;rsquo;s minimum and maximum &amp;mdash; corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively &amp;mdash; do not become infinite under the transformation.</source>
          <target state="translated">したがって、入力の中央値は0を中心とする出力の平均になります。通常の出力はクリップされ、入力の最小値と最大値（それぞれ1e-7および1-1e-7分位数に対応）が無限大にならないようにします。変換。</target>
        </trans-unit>
        <trans-unit id="911ea2c24698b41ad1167139365e2f911ee7efcc" translate="yes" xml:space="preserve">
          <source>Thus, among the considered estimators, &lt;code&gt;PoissonRegressor&lt;/code&gt; and &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; are a-priori better suited for modeling the long tail distribution of the non-negative data as compared to the &lt;code&gt;Ridge&lt;/code&gt; model which makes a wrong assumption on the distribution of the target variable.</source>
          <target state="translated">したがって、考慮される推定量の中で、 &lt;code&gt;PoissonRegressor&lt;/code&gt; と &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; は、ターゲット変数の分布について誤った仮定を行う &lt;code&gt;Ridge&lt;/code&gt; モデルと比較して、非負のデータのロングテール分布をモデル化するのに事前に適しています。</target>
        </trans-unit>
        <trans-unit id="0808b4cdf67452766c8c5389635c6458f9990f5b" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015</source>
          <target state="translated">このように、ターゲット信号(34.4ppm)の大部分は、長期的な上昇傾向(長さスケール41.8年)によって説明されています。周期的な成分は、振幅3.27ppm、減衰時間180年、長さ1.44年です。減衰時間が長いことから、局所的に非常に周期的な季節成分があることが分かります。相関したノイズの振幅は0.197ppmで、長さスケールは0.138年、白色ノイズの寄与は0.197ppmです。このように、全体的なノイズレベルは非常に小さく、データがモデルによって非常によく説明できることを示しています。図は、2015年頃までの予測が非常に自信を持ってできることを示しています。</target>
        </trans-unit>
        <trans-unit id="4ab3c0245825ab663f7197647adadf073e4b3e64" translate="yes" xml:space="preserve">
          <source>Thus, most of the target signal (34.4ppm) is explained by a long-term rising trend (length-scale 41.8 years). The periodic component has an amplitude of 3.27ppm, a decay time of 180 years and a length-scale of 1.44. The long decay time indicates that we have a locally very close to periodic seasonal component. The correlated noise has an amplitude of 0.197ppm with a length scale of 0.138 years and a white-noise contribution of 0.197ppm. Thus, the overall noise level is very small, indicating that the data can be very well explained by the model. The figure shows also that the model makes very confident predictions until around 2015.</source>
          <target state="translated">このように、ターゲット信号(34.4ppm)の大部分は、長期的な上昇傾向(長さスケール41.8年)によって説明されています。周期的な成分は、振幅3.27ppm、減衰時間180年、長さ1.44年です。減衰時間が長いことから、局所的に非常に周期的な季節成分があることが分かります。相関したノイズの振幅は0.197ppmで、長さスケールは0.138年、白色ノイズの寄与は0.197ppmです。このように、全体的なノイズレベルは非常に小さく、データがモデルによって非常によく説明できることを示しています。この図からも、2015年頃までは非常に信頼性の高い予測ができていることがわかります。</target>
        </trans-unit>
        <trans-unit id="af16f18f91308907d1dd8226e54112fa0bd29044" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">Tian Zhang、Raghu Ramakrishnan、Maron Livny BIRCH：大規模データベース向けの効率的なデータクラスタリング手法。&lt;a href=&quot;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d89b88657fcb13ceb20c877ea478d701717a393" translate="yes" xml:space="preserve">
          <source>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. &lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</source>
          <target state="translated">Tian Zhang、Raghu Ramakrishnan、Maron Livny BIRCH：大規模データベース向けの効率的なデータクラスタリング手法。&lt;a href=&quot;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&quot;&gt;https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="867d68dbf4c080ab9e706507919b510dbb556be3" translate="yes" xml:space="preserve">
          <source>Tianqi Chen, Carlos Guestrin, &lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;&amp;ldquo;XGBoost: A Scalable Tree Boosting System&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">Tianqi Chen、Carlos Guestrin、&lt;a href=&quot;https://arxiv.org/abs/1603.02754&quot;&gt;「XGBoost：スケーラブルなツリーブースティングシステム」&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d53cad37906f55db18b858cf86bfeef9ad9688eb" translate="yes" xml:space="preserve">
          <source>Tibshirani, R., Hastie, T., Narasimhan, B., &amp;amp; Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.</source>
          <target state="translated">Tibshirani、R.、Hastie、T.、Narasimhan、B.＆＆Chu、G.（2002）。遺伝子発現の縮んだ重心による複数の種類の癌の診断。アメリカ合衆国の全米科学アカデミーの議事録、99（10）、6567-6572。全米科学アカデミー。</target>
        </trans-unit>
        <trans-unit id="54643cfd9d395af8d03ef9fab4df1a2cdb437e0c" translate="yes" xml:space="preserve">
          <source>Tie breaking is costly if &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and therefore it is not enabled by default. This example illustrates the effect of the &lt;code&gt;break_ties&lt;/code&gt; parameter for a multiclass classification problem and &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; 場合、タイブレークはコストがかかるため、デフォルトでは有効になっていません。この例は、マルチクラス分類問題および &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; に対する &lt;code&gt;break_ties&lt;/code&gt; パラメーターの効果を示しています。</target>
        </trans-unit>
        <trans-unit id="a297f524f28779281bb4e53d7b6af672dcac3672" translate="yes" xml:space="preserve">
          <source>Ties are broken using the secondary method from Leeuw, 1977.</source>
          <target state="translated">同点は、Leeuw,1977からの二次法を用いて破られています。</target>
        </trans-unit>
        <trans-unit id="59976e05663a4d82c80a3273030c2c2f87094f4d" translate="yes" xml:space="preserve">
          <source>Ties between features with equal scores will be broken in an unspecified way.</source>
          <target state="translated">スコアが等しい特徴の間の同点は、不特定の方法で破棄されます。</target>
        </trans-unit>
        <trans-unit id="c41dd9e78b42392c90f4c6ddfb54f7863f5482f1" translate="yes" xml:space="preserve">
          <source>Ties in &lt;code&gt;y_scores&lt;/code&gt; are broken by giving maximal rank that would have been assigned to all tied values.</source>
          <target state="translated">&lt;code&gt;y_scores&lt;/code&gt; のタイは、すべてのタイの値に割り当てられていたであろう最大のランクを与えることによって壊れます。</target>
        </trans-unit>
        <trans-unit id="ba73dffe02601a1abd345b6200b276334877401b" translate="yes" xml:space="preserve">
          <source>Time Series cross-validator</source>
          <target state="translated">時系列クロスバリデータ</target>
        </trans-unit>
        <trans-unit id="bbad16d201e3f82cae87bba42e6286ebcef9d190" translate="yes" xml:space="preserve">
          <source>Time series data is characterised by the correlation between observations that are near in time (&lt;em&gt;autocorrelation&lt;/em&gt;). However, classical cross-validation techniques such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the &amp;ldquo;future&amp;rdquo; observations least like those that are used to train the model. To achieve this, one solution is provided by &lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt;&lt;code&gt;TimeSeriesSplit&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">時系列データは、時間的に近い観測間の相関（&lt;em&gt;自己相関&lt;/em&gt;）によって特徴付けられます。ただし、&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt;などの従来の相互検証手法では、サンプルが独立しており、まったく同じように分布していることが前提であり、時系列データのトレーニングインスタンスとテストインスタンスの間に不適切な相関（一般化誤差の不十分な推定値が生じる）が発生します。したがって、モデルのトレーニングに使用されるものとは最も似ていない「将来の」観測に関する時系列データについてモデルを評価することが非常に重要です。これを達成するために、1つのソリューションが&lt;a href=&quot;generated/sklearn.model_selection.timeseriessplit#sklearn.model_selection.TimeSeriesSplit&quot;&gt; &lt;code&gt;TimeSeriesSplit&lt;/code&gt; &lt;/a&gt;によって提供されます。</target>
        </trans-unit>
        <trans-unit id="a6268d75d578276d37dec9fce6dea804677e6b49" translate="yes" xml:space="preserve">
          <source>Timeout limit for each task to complete. If any task takes longer a TimeOutError will be raised. Only applied when n_jobs != 1</source>
          <target state="translated">各タスクが完了するまでのタイムアウト制限。いずれかのタスクにそれ以上の時間がかかる場合、TimeOutErrorが発生する。n_jobs !=1の時のみ適用される。</target>
        </trans-unit>
        <trans-unit id="f98ee87f52adb2c6f3aaf1f01bab51d0b9ae3622" translate="yes" xml:space="preserve">
          <source>Times spent for fitting in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="translated">フィッティングに費やされた時間（秒単位）。 &lt;code&gt;return_times&lt;/code&gt; がTrueの場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="3c46532137bb2ae8358c0137ca60928cd3434340" translate="yes" xml:space="preserve">
          <source>Times spent for scoring in seconds. Only present if &lt;code&gt;return_times&lt;/code&gt; is True.</source>
          <target state="translated">スコアリングに費やされた時間（秒単位）。 &lt;code&gt;return_times&lt;/code&gt; がTrueの場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="22c6faf6f7a1dbffed43da8c3c0a736a2f22b862" translate="yes" xml:space="preserve">
          <source>Timing and accuracy plots</source>
          <target state="translated">タイミングと精度のプロット</target>
        </trans-unit>
        <trans-unit id="834cbd0fedba36c3380f74ce91ef668820820b53" translate="yes" xml:space="preserve">
          <source>To achieve better accuracy, &lt;code&gt;X_norm_squared&lt;/code&gt; and &lt;code&gt;Y_norm_squared&lt;/code&gt; may be unused if they are passed as &lt;code&gt;float32&lt;/code&gt;.</source>
          <target state="translated">優れた精度を達成するために、 &lt;code&gt;X_norm_squared&lt;/code&gt; と &lt;code&gt;Y_norm_squared&lt;/code&gt; は、彼らがとして渡された場合、未使用のかもしれ &lt;code&gt;float32&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="8879146d32620a1e603bf26a188c9426e79a5ed0" translate="yes" xml:space="preserve">
          <source>To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, &lt;em&gt;without having to explicitly calculate their distance&lt;/em&gt;. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).</source>
          <target state="translated">ブルートフォースアプローチの計算の非効率性に対処するために、さまざまなツリーベースのデータ構造が発明されました。一般に、これらの構造は、サンプルの集約距離情報を効率的にエンコードすることにより、必要な距離計算の数を削減しようとします。基本的な考え方は、点\（A \）が点\（B \）から非常に離れていて、点\（B \）が点\（C \）に非常に近い場合、点\（A \ ）と\（C \）は非常に離れ&lt;em&gt;ているため、距離を明示的に計算する必要&lt;/em&gt;はありません。このようにして、最近傍探索の計算コストは​​\（O [DN \ log（N）] \）以上に削減できます。これは、大規模な\（N \）のブルートフォースに対する大幅な改善です。</target>
        </trans-unit>
        <trans-unit id="81ec528524d941df99755c9bb7fceaf80c6a8752" translate="yes" xml:space="preserve">
          <source>To address the inefficiencies of KD Trees in higher dimensions, the &lt;em&gt;ball tree&lt;/em&gt; data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.</source>
          <target state="translated">高次元でのKDツリーの非効率性に対処するために、&lt;em&gt;ボールツリー&lt;/em&gt;データ構造が開発されました。 KDツリーはデカルト軸に沿ってデータを分割しますが、ボールツリーは一連のネストした超球にデータを分割します。これにより、ツリーの構築はKDツリーよりもコストが高くなりますが、非常に高い次元でも、高度に構造化されたデータで非常に効率的なデータ構造になります。</target>
        </trans-unit>
        <trans-unit id="a11d5f0b5df4ea3ced24dc7521fb6d9f97740ba3" translate="yes" xml:space="preserve">
          <source>To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an &amp;ldquo;interesting&amp;rdquo; linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.</source>
          <target state="translated">この懸念に対処するために、主成分分析（PCA）、独立成分分析、線形判別分析など、多数の監視ありおよび監視なしの線形次元削減フレームワークが設計されています。これらのアルゴリズムは、特定のルーブリックを定義して、データの「興味深い」線形投影を選択します。これらの方法は強力ですが、多くの場合、データ内の重要な非線形構造を見落とします。</target>
        </trans-unit>
        <trans-unit id="c134b5f4c4fa3b034f915a1c4077d9f58401c669" translate="yes" xml:space="preserve">
          <source>To address this issue you can use &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;whiten=True&lt;/code&gt; to further remove the linear correlation across features.</source>
          <target state="translated">この問題に対処するには、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt; &lt;code&gt;whiten=True&lt;/code&gt; を指定したsklearn.decomposition.PCAを使用して、フィーチャ間の線形相関をさらに削除します。</target>
        </trans-unit>
        <trans-unit id="5dfb268e42cc748904256c70f6b80b2da01edce9" translate="yes" xml:space="preserve">
          <source>To also transform a test set \(X\), we multiply it with \(V_k\):</source>
          <target state="translated">また、テストセットを\(X\)に変換するには、\(V_k\)と掛け合わせます。</target>
        </trans-unit>
        <trans-unit id="6e914d8189fa250ac9b4b7ea3cf2e62431cbcccd" translate="yes" xml:space="preserve">
          <source>To apply an classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:</source>
          <target state="translated">このデータに分類器を適用するには,画像を平坦化して,データを(サンプル,特徴量)行列に変換する必要があります.</target>
        </trans-unit>
        <trans-unit id="8ef7600ab8e39fc13b7dc9585804325c8072844d" translate="yes" xml:space="preserve">
          <source>To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the &lt;code&gt;ridge_alpha&lt;/code&gt; parameter.</source>
          <target state="translated">システムが &lt;code&gt;ridge_alpha&lt;/code&gt; 決定されていない場合の不安定性の問題を回避するために、ridge_alphaパラメーターを介して正則化を適用できます（リッジ回帰）。</target>
        </trans-unit>
        <trans-unit id="622754a0a375aafa66f9d8336ffd00fcfc0a1948" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSC matrix.</source>
          <target state="translated">メモリコピーを避けるために、呼び出し側はCSC行列を渡す必要があります。</target>
        </trans-unit>
        <trans-unit id="21a05d95ccb73f51d245c302b02e9a8f32df0276" translate="yes" xml:space="preserve">
          <source>To avoid memory copy the caller should pass a CSR matrix.</source>
          <target state="translated">メモリコピーを避けるために、呼び出し元は CSR マトリクスを渡すべきです。</target>
        </trans-unit>
        <trans-unit id="e5ab0a4f687079cc593610e8d8c0f15b79824d4d" translate="yes" xml:space="preserve">
          <source>To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.</source>
          <target state="translated">メモリの再割り当てを避けるために、そのフォーマットを使用してメモリ内の初期データを直接割り当てることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="ee93c7e2ac06e08c1567b0ca209ad480ea5f1b80" translate="yes" xml:space="preserve">
          <source>To avoid the computation of global clustering, for every call of &lt;code&gt;partial_fit&lt;/code&gt; the user is advised</source>
          <target state="translated">グローバルクラスタリングの計算を回避するには、 &lt;code&gt;partial_fit&lt;/code&gt; を呼び出すたびに、ユーザーにアドバイスします。</target>
        </trans-unit>
        <trans-unit id="e81cbf7353acbc69eeae43ca8cf143e58e658d10" translate="yes" xml:space="preserve">
          <source>To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called &lt;code&gt;tf&lt;/code&gt; for Term Frequencies.</source>
          <target state="translated">これらの潜在的な不一致を回避するには、ドキュメント内の各単語の出現数をドキュメント内の単語の総数で除算すれば十分です。これらの新しい機能は、用語の頻度では &lt;code&gt;tf&lt;/code&gt; と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="39f01dfdcdf5847fd1935ba52ba9be2bfc80430b" translate="yes" xml:space="preserve">
          <source>To avoid this problem, nested CV effectively uses a series of train/validation/test set splits. In the inner loop (here executed by &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;), the score is approximately maximized by fitting a model to each training set, and then directly maximized in selecting (hyper)parameters over the validation set. In the outer loop (here in &lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt;), generalization error is estimated by averaging test set scores over several dataset splits.</source>
          <target state="translated">この問題を回避するために、ネストされたCVは一連のトレーニング、検証、テストセットの分割を効果的に使用します。内側のループ（ここでは&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;によって実行されます）では、モデルを各トレーニングセットに適合させることによってスコアがほぼ最大化され、検証セットで（ハイパー）パラメーターを選択する際に直接最大化されます。外側のループ（ここでは&lt;a href=&quot;../../modules/generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; にあります&lt;/a&gt;）では、一般化エラーは、複数のデータセット分割でテストセットのスコアを平均することによって推定されます。</target>
        </trans-unit>
        <trans-unit id="5ed52a0ba64199519b793ee9dad54a31d6d3eaed" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.</source>
          <target state="translated">不必要な メ モ リ の重複を避けるために、 fit メ ソ ッ ド の X ・ y 引数は Fortran 連続 numpy 配列 と し て直接渡す必要があ り ます。</target>
        </trans-unit>
        <trans-unit id="a37b39aad5fcf98e98548e781cdec5193cfe7b97" translate="yes" xml:space="preserve">
          <source>To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.</source>
          <target state="translated">不必要な メ モ リ の重複を避けるために、 fit メ ソ ッ ド の X 引数は Fortran 連続 numpy 配列 と し て直接渡す必要があ り ます。</target>
        </trans-unit>
        <trans-unit id="d9c2f7485084c926a2f68d8587d615406cc01649" translate="yes" xml:space="preserve">
          <source>To be in favorable recovery conditions, we sample the data from a model with a sparse inverse covariance matrix. In addition, we ensure that the data is not too much correlated (limiting the largest coefficient of the precision matrix) and that there a no small coefficients in the precision matrix that cannot be recovered. In addition, with a small number of observations, it is easier to recover a correlation matrix rather than a covariance, thus we scale the time series.</source>
          <target state="translated">好ましい回復条件になるように、我々は、疎な逆共分散行列を持つモデルからデータをサンプリングする。さらに,データがあまり相関していない(精度行列の最大係数を制限する)こと,および精度行列に回復できない小さな係数がないことを保証する.さらに,オブザベーションの数が少ないと,共分散よりも相関行列を回復する方が容易であるので,時系列をスケーリングする.</target>
        </trans-unit>
        <trans-unit id="f7fd313aae703eaa110952d34fbc2e74f81a873c" translate="yes" xml:space="preserve">
          <source>To be removed in 0.21</source>
          <target state="translated">0.21で削除予定</target>
        </trans-unit>
        <trans-unit id="b656a9f4366f6cbcc5b1e6914e7bc1a8d099ee57" translate="yes" xml:space="preserve">
          <source>To be removed in 0.22</source>
          <target state="translated">0.22で削除</target>
        </trans-unit>
        <trans-unit id="b622879f90e0f79392a411b5be4ae9945d5e85aa" translate="yes" xml:space="preserve">
          <source>To be removed in 0.24</source>
          <target state="translated">0.24で削除</target>
        </trans-unit>
        <trans-unit id="bc387423485c5a73576ae6f9089ec34a8b143ae6" translate="yes" xml:space="preserve">
          <source>To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:</source>
          <target state="translated">まず、「\(r\)」と「\(a\)」の値を全てゼロとし、収束するまで繰り返し計算を行います。上述したように、メッセージ更新時の数値振動を避けるために、反復処理にダンピング係数を導入している。</target>
        </trans-unit>
        <trans-unit id="ebc5cb56aa5d3da850d595b902c1384fa4142906" translate="yes" xml:space="preserve">
          <source>To begin, we&amp;rsquo;ll visualize our data.</source>
          <target state="translated">まず、データを視覚化します。</target>
        </trans-unit>
        <trans-unit id="57e47e513e200b11a216f9768279c1f81e7b3157" translate="yes" xml:space="preserve">
          <source>To benchmark different estimators for your case you can simply change the &lt;code&gt;n_features&lt;/code&gt; parameter in this example: &lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;Prediction Latency&lt;/a&gt;. This should give you an estimate of the order of magnitude of the prediction latency.</source>
          <target state="translated">ケースのさまざまな推定量をベンチマークするには、この例の &lt;code&gt;n_features&lt;/code&gt; パラメーターを変更するだけです：&lt;a href=&quot;../auto_examples/applications/plot_prediction_latency#sphx-glr-auto-examples-applications-plot-prediction-latency-py&quot;&gt;予測遅延&lt;/a&gt;。これにより、予測レイテンシの桁数の見積もりが得られます。</target>
        </trans-unit>
        <trans-unit id="892d831a9e807296347eacb2e8474830ca349663" translate="yes" xml:space="preserve">
          <source>To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.</source>
          <target state="translated">発見されたバイクラスターの集合を真のバイクラスターの集合と比較するためには、2つの類似度測定が必要です:個々のバイクラスターの類似度測定と、これらの個々の類似度を総合的なスコアに結合する方法です。</target>
        </trans-unit>
        <trans-unit id="f0ff37a06cd777b22ebe208ab3110388f720b201" translate="yes" xml:space="preserve">
          <source>To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:</source>
          <target state="translated">個々のバイクラスターを比較するために、いくつかの指標が使用されてきました。今のところ、Jaccard指数だけが実装されています。</target>
        </trans-unit>
        <trans-unit id="658de85a569a63b4d478720bcfaf7adeb72fbb36" translate="yes" xml:space="preserve">
          <source>To compare the 3 models from this perspective, one can plot the cumulative proportion of claims vs the cumulative proportion of exposure for the test samples order by the model predictions, from safest to riskiest according to each model.</source>
          <target state="translated">この観点から3つのモデルを比較するために、各モデルに応じて安全なものから危険なものまで、モデル予測の順に、累積請求割合と試験サンプルの累積被ばく割合をプロットすることができます。</target>
        </trans-unit>
        <trans-unit id="30a2aa60dabe3d1d8b8497c6228442c6c55454f4" translate="yes" xml:space="preserve">
          <source>To control display of warnings.</source>
          <target state="translated">警告の表示を制御します。</target>
        </trans-unit>
        <trans-unit id="6c3d05eecff544d238db6888c87daeb42794f44b" translate="yes" xml:space="preserve">
          <source>To control the verbosity of the procedure.</source>
          <target state="translated">手順の冗長性を制御するために。</target>
        </trans-unit>
        <trans-unit id="d66f891ca7bde7537002ad52d27fc9dd62dd5881" translate="yes" xml:space="preserve">
          <source>To convert categorical features to such integer codes, we can use the &lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):</source>
          <target state="translated">カテゴリー特徴をそのような整数コードに変換するには、&lt;a href=&quot;generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt;を使用できます。この推定器は、各カテゴリ特徴を整数（0からn_categories-1）の1つの新しい特徴に変換します。</target>
        </trans-unit>
        <trans-unit id="c4d6b75ae9bd1ab8a2aa45db1ede3ed88ee6cb4c" translate="yes" xml:space="preserve">
          <source>To correct this, the list of labels should be passed in as:</source>
          <target state="translated">これを修正するには、ラベルのリストをそのまま渡す必要があります。</target>
        </trans-unit>
        <trans-unit id="693e8d8ca1982fe1e279b5869b2b710976d06558" translate="yes" xml:space="preserve">
          <source>To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:</source>
          <target state="translated">この効果に対抗するために、調整されたRand指数を以下のように定義することで、ランダムなラベリングの期待値RI \(E[\text{RI}]\)を割り引くことができる。</target>
        </trans-unit>
        <trans-unit id="2ccfac714af4138a2df70ede11b2ff4e1963a414" translate="yes" xml:space="preserve">
          <source>To create positive examples click the left mouse button; to create negative examples click the right button.</source>
          <target state="translated">正の例を作成するにはマウスの左ボタンをクリックし、負の例を作成するには右ボタンをクリックします。</target>
        </trans-unit>
        <trans-unit id="3c7bf94a5fb077c325503613ed6e46ecc0fdb413" translate="yes" xml:space="preserve">
          <source>To decide on the importance of the features we are going to use LassoCV estimator. The features with the highest absolute &lt;code&gt;coef_&lt;/code&gt; value are considered the most important</source>
          <target state="translated">機能の重要性を判断するために、LassoCV推定器を使用します。絶対 &lt;code&gt;coef_&lt;/code&gt; 値が最も高い機能が最も重要であると見なされます</target>
        </trans-unit>
        <trans-unit id="91f3b8c70c19596fa3422a68b56ef8a0e44f9e91" translate="yes" xml:space="preserve">
          <source>To describe the dataset as a linear model we use a ridge regressor with a very small regularization and to model the logarithm of the WAGE.</source>
          <target state="translated">データセットを線形モデルとして記述するために、我々は非常に小さな正則化を持つリッジ回帰器を使用し、WAGEの対数をモデル化する。</target>
        </trans-unit>
        <trans-unit id="a890a65f7673c36b72863dcfff2db0d979bb71bc" translate="yes" xml:space="preserve">
          <source>To design our machine-learning pipeline, we first manually check the type of data that we are dealing with:</source>
          <target state="translated">機械学習パイプラインを設計するために、まず、扱っているデータの種類を手動でチェックします。</target>
        </trans-unit>
        <trans-unit id="d0bfc36f728f01d8f998e7e774b5cc731a5652d7" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on inertia, set max_no_improvement to None.</source>
          <target state="translated">慣性に基づく収束検出を無効にするには、max_no_improvementをNoneに設定します。</target>
        </trans-unit>
        <trans-unit id="644ea86209186f0b63818c18611416bf68aa348b" translate="yes" xml:space="preserve">
          <source>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</source>
          <target state="translated">正規化された中心変化に基づく収束検出を無効にするには、tolを0.0(デフォルト)に設定します。</target>
        </trans-unit>
        <trans-unit id="8f49411326bd4f684fb56ae33f90d4fd9150ab8c" translate="yes" xml:space="preserve">
          <source>To do the exercises, copy the content of the &amp;lsquo;skeletons&amp;rsquo; folder as a new folder named &amp;lsquo;workspace&amp;rsquo;:</source>
          <target state="translated">演習を行うには、「skeletons」フォルダの内容を「workspace」という名前の新しいフォルダとしてコピーします。</target>
        </trans-unit>
        <trans-unit id="79cf44a84fa8878b10f291a31335b47430451015" translate="yes" xml:space="preserve">
          <source>To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:</source>
          <target state="translated">各列に対して、前処理や特定の特徴抽出方法など、異なる変換を適用することができる。</target>
        </trans-unit>
        <trans-unit id="2e998c39435525bfb05b6223ee051590414cf95b" translate="yes" xml:space="preserve">
          <source>To ensure that estimators yield reasonable predictions for different policyholder types, we can bin test samples according to &lt;code&gt;y_pred&lt;/code&gt; returned by each model. Then for each bin, we compare the mean predicted &lt;code&gt;y_pred&lt;/code&gt;, with the mean observed target:</source>
          <target state="translated">推定量がさまざまな保険契約者タイプに対して妥当な予測を生成することを保証するために、各モデルによって返される &lt;code&gt;y_pred&lt;/code&gt; に従ってテストサンプルをビン化できます。次に、各ビンについて、予測された &lt;code&gt;y_pred&lt;/code&gt; の平均を、観測されたターゲットの平均と比較します。</target>
        </trans-unit>
        <trans-unit id="a0a5ce85df1e1aafd2ebf61b7efd7098beb62d7b" translate="yes" xml:space="preserve">
          <source>To estimate a probabilistic model (e.g. a Gaussian model), estimating the precision matrix, that is the inverse covariance matrix, is as important as estimating the covariance matrix. Indeed a Gaussian model is parametrized by the precision matrix.</source>
          <target state="translated">確率モデル(例えば,ガウスモデル)を推定するためには,精度行列,すなわち逆共分散行列を推定することが,共分散行列を推定するのと同じくらい重要である.実際,ガウスモデルは精度行列によってパラメトリック化されている.</target>
        </trans-unit>
        <trans-unit id="06985e50b51113b200d13cecad3eedd2a07fa798" translate="yes" xml:space="preserve">
          <source>To evaluate the impact of the scale of the dataset (&lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_features&lt;/code&gt;) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.</source>
          <target state="translated">データの統計的プロパティ（通常、特徴の相関と情報提供）を制御しながら、データセット（ &lt;code&gt;n_samples&lt;/code&gt; および &lt;code&gt;n_features&lt;/code&gt; ）のスケールの影響を評価するために、合成データを生成することもできます。</target>
        </trans-unit>
        <trans-unit id="fa6d485f0cac2ad780f34f2a0f500816dbb434b1" translate="yes" xml:space="preserve">
          <source>To evaluate the pertinence of the used metrics, we will consider as a baseline a &amp;ldquo;dummy&amp;rdquo; estimator that constantly predicts the mean frequency of the training sample.</source>
          <target state="translated">使用されたメトリックの適切性を評価するために、トレーニングサンプルの平均頻度を常に予測する「ダミー」推定量をベースラインと見なします。</target>
        </trans-unit>
        <trans-unit id="8b81da86f6a51388bf88e8748866dfbc1da10ddb" translate="yes" xml:space="preserve">
          <source>To fully specify a dataset, you need to provide a name and a version, though the version is optional, see &lt;a href=&quot;#openml-versions&quot;&gt;Dataset Versions&lt;/a&gt; below. The dataset contains a total of 1080 examples belonging to 8 different classes:</source>
          <target state="translated">データセットを完全に指定するには、名前とバージョンを指定する必要があります。&lt;a href=&quot;#openml-versions&quot;&gt;バージョン&lt;/a&gt;はオプションです。以下のデータセットのバージョンを参照してください。データセットには、8つの異なるクラスに属する合計1080の例が含まれています。</target>
        </trans-unit>
        <trans-unit id="eddbe44ecc236b178d14592239180b4231c2f462" translate="yes" xml:space="preserve">
          <source>To get a better measure of prediction accuracy (which we can use as a proxy for goodness of fit of the model), we can successively split the data in &lt;em&gt;folds&lt;/em&gt; that we use for training and testing:</source>
          <target state="translated">予測精度のより良い測定値（モデルの適合度のプロキシとして使用できます）を取得するために、トレーニングとテストに使用する&lt;em&gt;フォールドに&lt;/em&gt;データを連続的に分割できます。</target>
        </trans-unit>
        <trans-unit id="8f2c7c86e5d1b0f8592203b4a46517414e54ce05" translate="yes" xml:space="preserve">
          <source>To get identical results for each split, set &lt;code&gt;random_state&lt;/code&gt; to an integer.</source>
          <target state="translated">各分割で同じ結果を得るには、 &lt;code&gt;random_state&lt;/code&gt; を整数に設定します。</target>
        </trans-unit>
        <trans-unit id="0228140936e0aced4eaa7c77d90637025c4d0909" translate="yes" xml:space="preserve">
          <source>To get started with this tutorial, you must first install &lt;em&gt;scikit-learn&lt;/em&gt; and all of its required dependencies.</source>
          <target state="translated">このチュートリアルを開始するには、最初に&lt;em&gt;scikit-learn&lt;/em&gt;とそのすべての必要な依存関係をインストールする必要があります。</target>
        </trans-unit>
        <trans-unit id="8d91bad777aec839541c338ab9f11be081ee54c6" translate="yes" xml:space="preserve">
          <source>To get the signed distance to the hyperplane use &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt;&lt;code&gt;SGDClassifier.decision_function&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">超平面までの符号付き距離を取得するには、&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier.decision_function&quot;&gt; &lt;code&gt;SGDClassifier.decision_function&lt;/code&gt; を&lt;/a&gt;使用します。</target>
        </trans-unit>
        <trans-unit id="507e34b3976bcfaf958e1f0006102fdd2d8713ea" translate="yes" xml:space="preserve">
          <source>To go further we remove one of the 2 features and check what is the impact on the model stability.</source>
          <target state="translated">さらに進むために、2つの機能のうちの1つを削除し、モデルの安定性にどのような影響があるかを確認します。</target>
        </trans-unit>
        <trans-unit id="6ae2612052e54b7be6598947088a287fffd01403" translate="yes" xml:space="preserve">
          <source>To illustrate &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt;, first let&amp;rsquo;s create an imbalanced dataset:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; &lt;/a&gt;を説明するために、まず不均衡なデータセットを作成します。</target>
        </trans-unit>
        <trans-unit id="e7a02a8f3e922c68cd6ce64dca33ce54683ffb1b" translate="yes" xml:space="preserve">
          <source>To illustrate this with a simple example, let&amp;rsquo;s assume we have 3 classifiers and a 3-class classification problems where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.</source>
          <target state="translated">これを簡単な例で説明するために、3つの分類子と、すべての分類子に等しい重みを割り当てる3クラスの分類問題があると仮定しましょう：w1 = 1、w2 = 1、w3 = 1。</target>
        </trans-unit>
        <trans-unit id="27fe4060cc8aa9166cda2609863b9fdd12999baf" translate="yes" xml:space="preserve">
          <source>To illustrate this, PCA is performed comparing the use of data with &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;StandardScaler&lt;/code&gt;&lt;/a&gt; applied, to unscaled data. The results are visualized and a clear difference noted. The 1st principal component in the unscaled set can be seen. It can be seen that feature #13 dominates the direction, being a whole two orders of magnitude above the other features. This is contrasted when observing the principal component for the scaled version of the data. In the scaled version, the orders of magnitude are roughly the same across all the features.</source>
          <target state="translated">これを説明するために、&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;StandardScaler&lt;/code&gt; を&lt;/a&gt;適用したデータの使用とスケーリングされていないデータを比較するPCAを実行します。結果が視覚化され、明確な違いが示されます。スケーリングされていないセットの1番目の主成分を見ることができます。フィーチャー＃13が方向を支配し、他のフィーチャーよりも全体で2桁大きいことがわかります。これは、スケーリングされたバージョンのデータの主成分を観察する場合とは対照的です。スケーリングされたバージョンでは、桁数はすべての機能でほぼ同じです。</target>
        </trans-unit>
        <trans-unit id="952f60109f87198cc4767d483a08ad921abb5966" translate="yes" xml:space="preserve">
          <source>To improve the conditioning of the problem (i.e. mitigating the &lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The curse of dimensionality&lt;/a&gt;), it would be interesting to select only the informative features and set non-informative ones, like feature 2 to 0. Ridge regression will decrease their contribution, but not set them to zero. Another penalization approach, called &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; (least absolute shrinkage and selection operator), can set some coefficients to zero. Such methods are called &lt;strong&gt;sparse method&lt;/strong&gt; and sparsity can be seen as an application of Occam&amp;rsquo;s razor: &lt;em&gt;prefer simpler models&lt;/em&gt;.</source>
          <target state="translated">問題の条件付けを改善するには（つまり、&lt;a href=&quot;#curse-of-dimensionality&quot;&gt;The Curse of dimensionityを&lt;/a&gt;軽減するには）、有益な機能のみを選択し、機能2などの非情報的な機能を設定することは興味深いでしょう。リッジ回帰は、それらの寄与を減らしますが、設定しませんそれらをゼロにします。&lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;（最小絶対収縮および選択演算子）と呼ばれる別のペナルティアプローチでは、一部の係数をゼロに設定できます。そのようなメソッドは&lt;strong&gt;スパースメソッド&lt;/strong&gt;と呼ばれ、スパース性はOccamのかみそりのアプリケーションとして見ることができます：&lt;em&gt;より単純なモデルを好む&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="172f2bacd24a45cfb82f466d14d1d58833b9ee69" translate="yes" xml:space="preserve">
          <source>To install the latest version (with pip):</source>
          <target state="translated">最新版をインストールするには(pipで)。</target>
        </trans-unit>
        <trans-unit id="f028c20036ea78694db90136b8cb3004f099e0bf" translate="yes" xml:space="preserve">
          <source>To limit the memory consumption, we queue examples up to a fixed amount before feeding them to the learner.</source>
          <target state="translated">メモリ消費量を制限するために、例題を一定量までキューに入れてから学習者に送ります。</target>
        </trans-unit>
        <trans-unit id="61f860c325e06c4f97b9f4c7ced3d5279054856d" translate="yes" xml:space="preserve">
          <source>To load from an external dataset, please refer to &lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;loading external datasets&lt;/a&gt;.</source>
          <target state="translated">外部データセットからロードするには、外部データセットの&lt;a href=&quot;../../datasets/index#external-datasets&quot;&gt;ロード&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="d787fd22509da728f07846c2b5d3ecac1d6b4105" translate="yes" xml:space="preserve">
          <source>To load the data and visualize the images:</source>
          <target state="translated">データを読み込んで画像を可視化すること。</target>
        </trans-unit>
        <trans-unit id="b4be4dde535adc435619c6f0e295e0ce05bad72b" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance.</source>
          <target state="translated">この例を高速に動作させるために,隠れたユニットを非常に少なくして,非常に短い時間だけ訓練します.訓練時間を長くすると、より滑らかな空間的外観を持つ重みが得られます。</target>
        </trans-unit>
        <trans-unit id="c413b102ea3791278492eefc26d38700197d19c5" translate="yes" xml:space="preserve">
          <source>To make the example run faster, we use very few hidden units, and train only for a very short time. Training longer would result in weights with a much smoother spatial appearance. The example will throw a warning because it doesn&amp;rsquo;t converge, in this case this is what we want because of CI&amp;rsquo;s time constraints.</source>
          <target state="translated">例をより速く実行するために、非表示のユニットをほとんど使用せず、非常に短い時間だけトレーニングします。より長くトレーニングすると、より滑らかな空間的外観のウェイトが得られます。この例では、収束しないため警告がスローされます。この場合、CIの時間的制約のため、これが必要です。</target>
        </trans-unit>
        <trans-unit id="96ba992a3c5af68caa74d107191c5a3c32806c93" translate="yes" xml:space="preserve">
          <source>To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the &lt;code&gt;build_preprocessor&lt;/code&gt;, &lt;code&gt;build_tokenizer&lt;/code&gt; and &lt;code&gt;build_analyzer&lt;/code&gt; factory methods instead of passing custom functions.</source>
          <target state="translated">プリプロセッサー、 &lt;code&gt;build_preprocessor&lt;/code&gt; 、およびアナライザーにモデルパラメーターを認識させるには、カスタム関数を渡す代わりに、クラスから派生させ、build_preprocessor、 &lt;code&gt;build_tokenizer&lt;/code&gt; 、および &lt;code&gt;build_analyzer&lt;/code&gt; ファクトリーメソッドをオーバーライドすることができます。</target>
        </trans-unit>
        <trans-unit id="c0f08b8475e4b67e5147698ce9ccb818f0394d27" translate="yes" xml:space="preserve">
          <source>To make this more explicit, consider the following notation:</source>
          <target state="translated">これをより明確にするために、以下のような表記法を考えてみましょう。</target>
        </trans-unit>
        <trans-unit id="8ada09feb86f8f3751dffbeeaba0e1e4f69156a7" translate="yes" xml:space="preserve">
          <source>To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):</source>
          <target state="translated">完全確率モデルを得るために、出力は、Gaussian distributed around \(X w\)の周りに分布していると仮定する。</target>
        </trans-unit>
        <trans-unit id="65178eef58b048e690e1c210520e38da80789880" translate="yes" xml:space="preserve">
          <source>To perform classification with generalized linear models, see &lt;a href=&quot;#logistic-regression&quot;&gt;Logistic regression&lt;/a&gt;.</source>
          <target state="translated">一般化線形モデルで分類を実行するには、&lt;a href=&quot;#logistic-regression&quot;&gt;ロジスティック回帰を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="72dc32b7225454e8d7c0ec26f14d95b55df2c79a" translate="yes" xml:space="preserve">
          <source>To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates.</source>
          <target state="translated">推定誤差を定量化するために、収縮パラメータの値が異なる場合の未見データの尤度をプロットします。また、クロス・バリデーションによる選択、LedoitWolfとOASの推定値による選択も示す。</target>
        </trans-unit>
        <trans-unit id="397393d3de29d9ed57b4f231bd553afc264bafab" translate="yes" xml:space="preserve">
          <source>To return the corresponding classical subsets of kddcup 99. If None, return the entire kddcup 99 dataset.</source>
          <target state="translated">kddcup 99の対応する古典的な部分集合を返します。Noneの場合は、kddcup 99のデータセット全体を返します。</target>
        </trans-unit>
        <trans-unit id="b0e502baa68f0434bb574994337b41db58fa07c4" translate="yes" xml:space="preserve">
          <source>To run cross-validation on multiple metrics and also to return train scores, fit times and score times.</source>
          <target state="translated">複数のメトリクスでクロスバリデーションを実行し、列車のスコア、フィット時間、スコア時間を返す。</target>
        </trans-unit>
        <trans-unit id="2d79b95a40b4d1ea2f276f13509aebc984e2d932" translate="yes" xml:space="preserve">
          <source>To see how this generalizes the binary log loss given above, note that in the binary case, \(p_{i,0} = 1 - p_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.</source>
          <target state="translated">これが、上で与えられた2値の対数損失をどう一般化するかを見るために、2値の場合は、\(p_{i,0}=1-p_{i,1}\)と \(y_{i,0}=1-y_{i,1}\)のように、内和を拡大すると、2値の対数損失が得られることに注意してください。</target>
        </trans-unit>
        <trans-unit id="25684d8b1766d360b665e8498a44a626b2b5bd13" translate="yes" xml:space="preserve">
          <source>To set &lt;code&gt;n_clusters=None&lt;/code&gt; initially</source>
          <target state="translated">最初に &lt;code&gt;n_clusters=None&lt;/code&gt; を設定するには</target>
        </trans-unit>
        <trans-unit id="78f293aec6a6c458449c6dc3bcd71b696525a449" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.</source>
          <target state="translated">アルゴリズムを高速化するために,少なくとも min_bin_freq ポイントを持つビンのみをシードとして受け入れます.</target>
        </trans-unit>
        <trans-unit id="e1dfcbed698085a7ab462cf760bf24e65a9e8400" translate="yes" xml:space="preserve">
          <source>To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds. If not defined, set to 1.</source>
          <target state="translated">アルゴリズムを高速化するために,少なくとも min_bin_freq ポイントを持つビンのみをシードとして受け入れます.定義されていない場合は、1に設定します。</target>
        </trans-unit>
        <trans-unit id="d139a616dfe019ba73a251e6419e9ddac4a94c0f" translate="yes" xml:space="preserve">
          <source>To support imputation in inductive mode we store each feature&amp;rsquo;s estimator during the &lt;code&gt;fit&lt;/code&gt; phase, and predict without refitting (in order) during the &lt;code&gt;transform&lt;/code&gt; phase.</source>
          <target state="translated">帰納モードでの代入をサポートするために、 &lt;code&gt;fit&lt;/code&gt; フェーズ中に各特徴の推定量を保存し、 &lt;code&gt;transform&lt;/code&gt; フェーズ中に（順番に）再適合せずに予測します。</target>
        </trans-unit>
        <trans-unit id="d14a37b58107d5112ea5c1494d2809710215a276" translate="yes" xml:space="preserve">
          <source>To train the &lt;code&gt;estimators&lt;/code&gt; and &lt;code&gt;final_estimator&lt;/code&gt;, the &lt;code&gt;fit&lt;/code&gt; method needs to be called on the training data:</source>
          <target state="translated">訓練する &lt;code&gt;estimators&lt;/code&gt; と &lt;code&gt;final_estimator&lt;/code&gt; を、 &lt;code&gt;fit&lt;/code&gt; の方法は、学習データに呼び出される必要があります。</target>
        </trans-unit>
        <trans-unit id="fd2f04d7c6e080a2cce0d2e7339e598ba17acac5" translate="yes" xml:space="preserve">
          <source>To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call &lt;code&gt;transform&lt;/code&gt; instead of &lt;code&gt;fit_transform&lt;/code&gt; on the transformers, since they have already been fit to the training set:</source>
          <target state="translated">新しいドキュメントの結果を予測するには、以前とほぼ同じ特徴抽出チェーンを使用して特徴を抽出する必要があります。違いは、トランスフォーマがトレーニングセットに既に適合しているため、トランスフォーマで &lt;code&gt;fit_transform&lt;/code&gt; ではなく、 &lt;code&gt;transform&lt;/code&gt; を呼び出すことです。</target>
        </trans-unit>
        <trans-unit id="5da67914dc5314b6125944bb748e1a3d6c08f736" translate="yes" xml:space="preserve">
          <source>To understand the use of LDA in dimensionality reduction, it is useful to start with a geometric reformulation of the LDA classification rule explained above. We write \(K\) for the total number of target classes. Since in LDA we assume that all classes have the same estimated covariance \(\Sigma\), we can rescale the data so that this covariance is the identity:</source>
          <target state="translated">次元削減におけるLDAの使用を理解するためには,上で説明したLDA分類規則を幾何学的に再構成することから始めるのが有用である.対象となるクラスの総数を \(K)と書く.LDAでは,すべてのクラスが同じ推定共分散を持つと仮定しているので,この共分散が同一性を持つようにデータを再スケーリングすることができる.</target>
        </trans-unit>
        <trans-unit id="6df5e0eab0e1e02def9ae99e68c6ddf1a841d6d1" translate="yes" xml:space="preserve">
          <source>To use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator:</source>
          <target state="translated">新規性検出に&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;を使用する、つまりラベルを予測する、または新しい未確認データの異常スコアを計算するには、推定量をフィッティングする前に、 &lt;code&gt;novelty&lt;/code&gt; パラメーターを &lt;code&gt;True&lt;/code&gt; に設定して推定量をインスタンス化する必要があります。</target>
        </trans-unit>
        <trans-unit id="011ed6ad19bc2f123579a7e50ff8b4dad33bf360" translate="yes" xml:space="preserve">
          <source>To use joblib.Memory to cache the svmlight file:</source>
          <target state="translated">joblib.Memoryを使用してsvmlightファイルをキャッシュするため。</target>
        </trans-unit>
        <trans-unit id="e88dca9a24e84cd773e046a28a4daa4e8217f9da" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the :mod`~sklearn.feature_extraction.text` module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">テキストファイルをscikit-learnの分類やクラスタリングアルゴリズムで使用するには、 :mod`~sklearn.feature_extraction.text` モジュールを使用して、あなたの問題に合った特徴抽出トランスフォームを構築する必要があります。</target>
        </trans-unit>
        <trans-unit id="e11936ea84de206f18d8b708b6f4eca9fb6c8b59" translate="yes" xml:space="preserve">
          <source>To use text files in a scikit-learn classification or clustering algorithm, you will need to use the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; module to build a feature extraction transformer that suits your problem.</source>
          <target state="translated">scikit-learn分類またはクラスタリングアルゴリズムでテキストファイルを使用するには、 &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; モジュールを使用して、問題に合った特徴抽出トランスフォーマーを構築する必要があります。</target>
        </trans-unit>
        <trans-unit id="c7aa2d2ef894f356c354736ecb4235681bee95b2" translate="yes" xml:space="preserve">
          <source>To use this dataset with scikit-learn, we transform each 8x8 image into a feature vector of length 64</source>
          <target state="translated">このデータセットをscikit-learnで使用するために、8x8画像を長さ64の特徴ベクトルに変換します。</target>
        </trans-unit>
        <trans-unit id="f5d271c927cff9ea25de07089e51938b7e86a2a7" translate="yes" xml:space="preserve">
          <source>To use this model as a classifier, we just need to estimate from the training data the class priors \(P(y=k)\) (by the proportion of instances of class \(k\)), the class means \(\mu_k\) (by the empirical sample class means) and the covariance matrices (either by the empirical sample class covariance matrices, or by a regularized estimator: see the section on shrinkage below).</source>
          <target state="translated">このモデルを分類器として使用するには,訓練データから class priors \(P(y=k)\(k))(proportion of instances of class ✿),class means \(\mu_k)(experimical sample class means)および共分散行列 (experimical sample class covariance matrices,or regularized estimator:section on shrinkage below)を推定するだけでよい.</target>
        </trans-unit>
        <trans-unit id="54c39e1b5f1a8214dbbbffa4ce79accc0474a39a" translate="yes" xml:space="preserve">
          <source>To use this model for classification, one needs to combine a &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; instance that learns the optimal transformation with a &lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; instance that performs the classification in the projected space. Here is an example using the two classes:</source>
          <target state="translated">このモデルを分類に使用するには、最適な変換を学習する&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;インスタンスと、投影された空間で分類を実行する&lt;a href=&quot;generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt; &lt;code&gt;KNeighborsClassifier&lt;/code&gt; &lt;/a&gt;インスタンスを組み合わせる必要があります。 2つのクラスを使用した例を次に示します。</target>
        </trans-unit>
        <trans-unit id="6e5117e9f756d52dfb6878a7715bd7c9bf590353" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">モデルを検証するには、たとえば分類子の精度&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;などのスコア&lt;/a&gt;リング関数（メトリックとスコアリング：予測の品質の定量化を参照）が必要です。推定器の複数&lt;a href=&quot;grid_search#grid-search&quot;&gt;のハイパーパラメータ&lt;/a&gt;を選択する適切な方法は、もちろん、検証セットまたは複数の検証セットで最大スコアのハイパーパラメータを選択するグリッド検索または同様の方法（推定器のハイパーパラメータの調整を参照）です。検証スコアに基づいてハイパーパラメータを最適化した場合、検証スコアにバイアスがかかり、一般化の適切な推定値ではなくなることに注意してください。一般化の適切な推定値を取得するには、別のテストセットでスコアを計算する必要があります。</target>
        </trans-unit>
        <trans-unit id="5d015bfb570917361c4b4abaaa59f5e623d8c463" translate="yes" xml:space="preserve">
          <source>To validate a model we need a scoring function (see &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt;), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.</source>
          <target state="translated">モデルを検証するには、分類子の精度などのスコアリング関数（&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;モデル評価：予測の品質の定量化を&lt;/a&gt;参照）が必要です。推定器の複数&lt;a href=&quot;grid_search#grid-search&quot;&gt;のハイパーパラメーター&lt;/a&gt;を選択する適切な方法は、もちろんグリッド検索または同様の方法（推定器のハイパーパラメーターのチューニングを参照）であり、検証セットまたは複数の検証セットで最大スコアを持つハイパーパラメーターを選択します。検証スコアに基づいてハイパーパラメーターを最適化した場合、検証スコアには偏りがあり、汎化の適切な推定ではなくなります。汎化の適切な推定値を取得するには、別のテストセットのスコアを計算する必要があります。</target>
        </trans-unit>
        <trans-unit id="4f24d3986e58b34af3ea2c4b07af932b987ecc57" translate="yes" xml:space="preserve">
          <source>To verify this interpretation we plot the variability of the AGE and EXPERIENCE coefficient.</source>
          <target state="translated">この解釈を検証するために、AGEとEXPERIENCE係数の変動をプロットします。</target>
        </trans-unit>
        <trans-unit id="baa10199f999bc30e58b0035ac2f6e51132399ed" translate="yes" xml:space="preserve">
          <source>To visualize the probability weighting, we fit each classifier on the training set and plot the predicted class probabilities for the first sample in this example dataset.</source>
          <target state="translated">確率の重み付けを可視化するために、各分類器を訓練セットに適合させ、この例のデータセットの最初のサンプルの予測されたクラス確率をプロットします。</target>
        </trans-unit>
        <trans-unit id="ba234a16bb1a2ae4619585ca04988c1afd574060" translate="yes" xml:space="preserve">
          <source>Tokenize the documents and count the occurrences of token and return them as a sparse matrix</source>
          <target state="translated">ドキュメントをトークン化し、トークンの出現回数をカウントして疎な行列として返す</target>
        </trans-unit>
        <trans-unit id="e89caeb25fc24a274e225b242d49cc6fb7ddfa72" translate="yes" xml:space="preserve">
          <source>Tokenizing text with &lt;code&gt;scikit-learn&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;scikit-learn&lt;/code&gt; を使用したテキストのトークン化</target>
        </trans-unit>
        <trans-unit id="45d4a0ebe499a5d042ac0f7bc4284501d3667758" translate="yes" xml:space="preserve">
          <source>Tolerance for &amp;lsquo;arpack&amp;rsquo; method Not used if eigen_solver==&amp;rsquo;dense&amp;rsquo;.</source>
          <target state="translated">'arpack'メソッドの許容誤差eigen_solver == 'dense'の場合は使用されません。</target>
        </trans-unit>
        <trans-unit id="318dfc593e0123f93a8fe309f411532f48eea756" translate="yes" xml:space="preserve">
          <source>Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.</source>
          <target state="translated">ARPACKの公差です。0は機械精度を意味します。ランダム化されたSVDソルバーでは無視されます。</target>
        </trans-unit>
        <trans-unit id="13511570864a98fa2d61f43da929b11b4894937f" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if &lt;code&gt;method == 'hessian'&lt;/code&gt;</source>
          <target state="translated">ヘッセ固有マッピング法の許容誤差。 &lt;code&gt;method == 'hessian'&lt;/code&gt; 場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="e4c877ba267607a99e62c8b31f7891feda117cf7" translate="yes" xml:space="preserve">
          <source>Tolerance for Hessian eigenmapping method. Only used if method == &amp;lsquo;hessian&amp;rsquo;</source>
          <target state="translated">ヘッセ固有マッピング法の許容誤差。method == 'hessian'の場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="aeb25ea9c0101939a4336136b4e11db71f1bb1be" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if &lt;code&gt;method == 'modified'&lt;/code&gt;</source>
          <target state="translated">変更されたLLEメソッドの許容誤差。 &lt;code&gt;method == 'modified'&lt;/code&gt; 場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="b6502cfb6f414093cd5faf0376953824eae5e86f" translate="yes" xml:space="preserve">
          <source>Tolerance for modified LLE method. Only used if method == &amp;lsquo;modified&amp;rsquo;</source>
          <target state="translated">変更されたLLEメソッドの許容誤差。method == 'modified'の場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="40eaf2d9a188116c07595886d4a67c9121557ecf" translate="yes" xml:space="preserve">
          <source>Tolerance for singular values computed by svd_solver == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">svd_solver == 'arpack'によって計算された特異値の許容誤差。</target>
        </trans-unit>
        <trans-unit id="a495f50d68c5f0d21905244c442ac1ec46831c6d" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criteria.</source>
          <target state="translated">停止基準の許容範囲</target>
        </trans-unit>
        <trans-unit id="1f900b2be351c5e1d6397b25c9a2e6c5e5c36343" translate="yes" xml:space="preserve">
          <source>Tolerance for stopping criterion.</source>
          <target state="translated">停止基準の許容範囲</target>
        </trans-unit>
        <trans-unit id="4d73abe23fd3517118aa70ae58840719c14ae6a0" translate="yes" xml:space="preserve">
          <source>Tolerance for the early stopping. When the loss is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; iterations (if set to a number), the training stops.</source>
          <target state="translated">早期停止の許容。 &lt;code&gt;n_iter_no_change&lt;/code&gt; の繰り返し（数値に設定されている場合）で損失が少なくともtolまで改善されない場合、トレーニングは停止します。</target>
        </trans-unit>
        <trans-unit id="334a1d6597d473e85cc8725e20828e0c9824ea02" translate="yes" xml:space="preserve">
          <source>Tolerance for the optimization. When the loss or score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive iterations, unless &lt;code&gt;learning_rate&lt;/code&gt; is set to &amp;lsquo;adaptive&amp;rsquo;, convergence is considered to be reached and training stops.</source>
          <target state="translated">最適化の許容範囲。損失またはスコアは、少なくともによって改善されていない場合は &lt;code&gt;tol&lt;/code&gt; のため &lt;code&gt;n_iter_no_change&lt;/code&gt; の連続した反復のない限り、 &lt;code&gt;learning_rate&lt;/code&gt; は「適応」に設定され、収束が到達したとトレーニングが停止していると考えられます。</target>
        </trans-unit>
        <trans-unit id="6938a4dcb29969d15aaa6cafefb8f09b830ed305" translate="yes" xml:space="preserve">
          <source>Tolerance for the stopping condition.</source>
          <target state="translated">停止条件の許容範囲</target>
        </trans-unit>
        <trans-unit id="3a49445cc3e76e8c0deab47f4b10c5bd7dc33960" translate="yes" xml:space="preserve">
          <source>Tolerance of the stopping condition.</source>
          <target state="translated">停止条件の許容範囲</target>
        </trans-unit>
        <trans-unit id="48a48ded1ae1ed29a7ddaed19c15db301472918d" translate="yes" xml:space="preserve">
          <source>Tolerance on update at each iteration.</source>
          <target state="translated">各イテレーションでの更新の許容範囲。</target>
        </trans-unit>
        <trans-unit id="a2223ba588ac8a94dc6928512bbe1ae559b46f6b" translate="yes" xml:space="preserve">
          <source>Tolerance used in the iterative algorithm default 1e-06.</source>
          <target state="translated">反復アルゴ リ ズ ムで使用 さ れ る 許容範囲 デ フ ォル ト:1e-06。</target>
        </trans-unit>
        <trans-unit id="20a2955c412dcae35aa2ef964ce8c2d4b1c07dcb" translate="yes" xml:space="preserve">
          <source>Tolerance when calculating spatial median.</source>
          <target state="translated">空間中央値を計算するときの許容範囲</target>
        </trans-unit>
        <trans-unit id="f3d0c54c4b7882f5280f0492c26f2bf33d35d2a2" translate="yes" xml:space="preserve">
          <source>Tony Blair</source>
          <target state="translated">トニー・ブレア</target>
        </trans-unit>
        <trans-unit id="e1781cb6d03ccb2216639c1d54de7540b9fc2c2b" translate="yes" xml:space="preserve">
          <source>Tools for imputing missing values are discussed at &lt;a href=&quot;impute#impute&quot;&gt;Imputation of missing values&lt;/a&gt;.</source>
          <target state="translated">欠損値を補完するツールについては&lt;a href=&quot;impute#impute&quot;&gt;、欠損値の補完で&lt;/a&gt;説明しています。</target>
        </trans-unit>
        <trans-unit id="0d184ce2992ee425b9d4cc3d528da94fb4da399d" translate="yes" xml:space="preserve">
          <source>Tophat kernel (&lt;code&gt;kernel = 'tophat'&lt;/code&gt;)</source>
          <target state="translated">&lt;code&gt;kernel = 'tophat'&lt;/code&gt; カーネル（kernel = ' tophat '）</target>
        </trans-unit>
        <trans-unit id="0954aa60533f43dc3b2b9a9cbdee11a74f79eada" translate="yes" xml:space="preserve">
          <source>Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation</source>
          <target state="translated">非負行列因子分解と潜在ディリクレ配置を用いたトピック抽出</target>
        </trans-unit>
        <trans-unit id="97129616afbfcb01d33b44619c8bf267194395ac" translate="yes" xml:space="preserve">
          <source>Total Phenols:</source>
          <target state="translated">全フェノール類。</target>
        </trans-unit>
        <trans-unit id="b9c3723a92a74173bb8adb739559660c0010b476" translate="yes" xml:space="preserve">
          <source>Total impurity of leaves vs effective alphas of pruned tree</source>
          <target state="translated">葉の全不純物と剪定木の有効アルファの関係</target>
        </trans-unit>
        <trans-unit id="24a9e81269d05c734577a89440230faee238f7b2" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X.</source>
          <target state="translated">Xのデータの対数尤度の合計。</target>
        </trans-unit>
        <trans-unit id="1861e0049c1f17066ecafccd7b29a27b43a45cf0" translate="yes" xml:space="preserve">
          <source>Total log-likelihood of the data in X. This is normalized to be a probability density, so the value will be low for high-dimensional data.</source>
          <target state="translated">これは確率密度に正規化されているので、高次元データでは値が低くなります。</target>
        </trans-unit>
        <trans-unit id="0acc1077bbd3872347f5d4223b32bfa85b2dc24b" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">ドキュメントの総数。&lt;a href=&quot;#sklearn.decomposition.LatentDirichletAllocation.partial_fit&quot;&gt; &lt;code&gt;partial_fit&lt;/code&gt; &lt;/a&gt;メソッドでのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="4055747cee4593e58e4a6dcbfa7d6ccc61845cf0" translate="yes" xml:space="preserve">
          <source>Total number of documents. Only used in the &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">ドキュメントの総数。 &lt;code&gt;partial_fit&lt;/code&gt; メソッドでのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="aed40ed5719d059f29eba1177189a60b01059871" translate="yes" xml:space="preserve">
          <source>Total phenols</source>
          <target state="translated">全フェノール類</target>
        </trans-unit>
        <trans-unit id="babba0bc0e9a3e36ce98f362a62519c8eacb94cb" translate="yes" xml:space="preserve">
          <source>Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</source>
          <target state="translated">最適な前処理済み固有ソルバーに向けて：ローカル最適ブロック前処理付き共役勾配法Andrew V. Knyazev &lt;a href=&quot;https://doi.org/10.1137%2FS1064827500366124&quot;&gt;https://doi.org/10.1137%2FS1064827500366124&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e3ae1e8d052cc2d0c25bbda7e5d0370ec624b1e8" translate="yes" xml:space="preserve">
          <source>Toy example of 1D regression using linear, polynomial and RBF kernels.</source>
          <target state="translated">線形、多項式、RBFカーネルを用いた1次元回帰の玩具例。</target>
        </trans-unit>
        <trans-unit id="264fa08a131d6382d6715d8c951f2b5bea1c373c" translate="yes" xml:space="preserve">
          <source>Traceback example, note how the line of the error is indicated as well as the values of the parameter passed to the function that triggered the exception, even though the traceback happens in the child process:</source>
          <target state="translated">トレースバックの例では、トレースバックが子プロセスで発生しているにもかかわらず、例外のトリガーとなった関数に渡されたパラメータの値と同様に、エラーの行がどのように示されているかに注意してください。</target>
        </trans-unit>
        <trans-unit id="8718fa41b5577d15733c0d074d4e6ea2d5f88486" translate="yes" xml:space="preserve">
          <source>Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.</source>
          <target state="translated">トラッキング、国際コンピュータビジョンジャーナル、第77巻、1-3号、125-141頁、2008年5月。</target>
        </trans-unit>
        <trans-unit id="20662c705376209f11480639e3ee11e7bf62f8df" translate="yes" xml:space="preserve">
          <source>Traditional regression metrics such as Mean Squared Error and Mean Absolute Error are hard to meaningfully interpret on count values with many zeros.</source>
          <target state="translated">平均二乗誤差や平均絶対誤差などの従来の回帰メトリクスは、ゼロが多いカウント値では意味のある解釈が難しいです。</target>
        </trans-unit>
        <trans-unit id="6e4826fce9da6f5f03d1b11115df13e0bc514c4a" translate="yes" xml:space="preserve">
          <source>Train all data by multiple calls to partial_fit.</source>
          <target state="translated">partial_fitを複数回呼び出すことで、すべてのデータを学習します。</target>
        </trans-unit>
        <trans-unit id="bd98708380c7e60a9c0a687f254abca8478a36f8" translate="yes" xml:space="preserve">
          <source>Train and test sizes may be different in each fold, with a difference of at most &lt;code&gt;n_classes&lt;/code&gt;.</source>
          <target state="translated">トレインとテストのサイズは、フォールドごとに異なる場合があり、最大で &lt;code&gt;n_classes&lt;/code&gt; の違いがあります。</target>
        </trans-unit>
        <trans-unit id="1c08c1bee3835bcafdb50e8cdda68c68d71fa67e" translate="yes" xml:space="preserve">
          <source>Train error vs Test error</source>
          <target state="translated">列車誤差とテスト誤差</target>
        </trans-unit>
        <trans-unit id="357c94d50b669e3c60f0758a6140ed17dc81af61" translate="yes" xml:space="preserve">
          <source>Train l1-penalized logistic regression models on a binary classification problem derived from the Iris dataset.</source>
          <target state="translated">Irisデータセットから得られた二値分類問題に対して、l1ペナルティ付きロジスティック回帰モデルを学習する。</target>
        </trans-unit>
        <trans-unit id="5099d1b071bb02f5306e84c9c0e29bbe834adc72" translate="yes" xml:space="preserve">
          <source>Train models on the diabetes dataset</source>
          <target state="translated">糖尿病データセットでモデルを訓練する</target>
        </trans-unit>
        <trans-unit id="0cfcb0c276264df865da734aa7faab6c6b43fed6" translate="yes" xml:space="preserve">
          <source>Train the model using libsvm (low-level method)</source>
          <target state="translated">libsvmを使ってモデルを学習する (低レベルメソッド)</target>
        </trans-unit>
        <trans-unit id="b7dd566e0e9177f3a0300b3c2ac1d09a00aaeda2" translate="yes" xml:space="preserve">
          <source>Training a Random Forest and Plotting the ROC Curve</source>
          <target state="translated">ランダムフォレストの訓練とROC曲線のプロット</target>
        </trans-unit>
        <trans-unit id="ff5331ad7dc89bf5a9dd23c31ab738af7815c499" translate="yes" xml:space="preserve">
          <source>Training a classifier</source>
          <target state="translated">分類器のトレーニング</target>
        </trans-unit>
        <trans-unit id="8dcfc4ff7c1f7cc06878c0cf93f4198eb475ff8d" translate="yes" xml:space="preserve">
          <source>Training classifiers</source>
          <target state="translated">学習用分類器</target>
        </trans-unit>
        <trans-unit id="0f0630eb2ecfdd0ed6f7defc6642e6c0143bcbf3" translate="yes" xml:space="preserve">
          <source>Training data</source>
          <target state="translated">トレーニングデータ</target>
        </trans-unit>
        <trans-unit id="6c7c988c62ce8a65ab6394bf4f62bdef696bbe60" translate="yes" xml:space="preserve">
          <source>Training data, requires length = n_samples</source>
          <target state="translated">トレーニングデータ、必要な長さ=n_samples</target>
        </trans-unit>
        <trans-unit id="c0c6cec2e93954e8c33880af1baef2b15439d9d5" translate="yes" xml:space="preserve">
          <source>Training data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">トレーニングデータ &lt;code&gt;n_samples&lt;/code&gt; はサンプルの数、 &lt;code&gt;n_features&lt;/code&gt; は特徴の数です。</target>
        </trans-unit>
        <trans-unit id="70fa8e3174eef9a1ccfc0bda8b38c7cfbf09ffd6" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">学習データは、サンプル数のn_samples、n_featuresが特徴量の数である。</target>
        </trans-unit>
        <trans-unit id="1d999bb02f6364cf15c69e5533af993a3fc0fdd8" translate="yes" xml:space="preserve">
          <source>Training data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">トレーニングデータで、n_samplesはサンプル数、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="c4f931e6893a5565e07f4500ddfb86c154c8b1a3" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, of shape (n_samples, n_samples).</source>
          <target state="translated">予測にも必要なトレーニングデータ。kernel ==&amp;ldquo; precomputed&amp;rdquo;の場合、これは代わりに、形状（n_samples、n_samples）の事前計算されたトレーニング行列です。</target>
        </trans-unit>
        <trans-unit id="f12731d4ed32a02266da09997a2bf0e000555cf6" translate="yes" xml:space="preserve">
          <source>Training data, which is also required for prediction. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead the precomputed training matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">予測にも必要なトレーニングデータ。kernel ==&amp;ldquo; precomputed&amp;rdquo;の場合、これは代わりに事前計算されたトレーニング行列、shape = [n_samples、n_samples]です。</target>
        </trans-unit>
        <trans-unit id="c5441fed149296831061b9151bd71d563327dc0d" translate="yes" xml:space="preserve">
          <source>Training data.</source>
          <target state="translated">トレーニングデータ。</target>
        </trans-unit>
        <trans-unit id="4319dec91a5574f9382b1b679ba9c82bf44c0f15" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, shape [n_samples, n_features], or [n_samples, n_samples] if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">トレーニングデータ。配列または行列の場合、形状[n_samples、n_features]、またはmetric = 'precomputed'の場合[n_samples、n_samples]。</target>
        </trans-unit>
        <trans-unit id="744e21c8d62df0575ccae05fe593cde4f20f55b7" translate="yes" xml:space="preserve">
          <source>Training data. If array or matrix, the shape is (n_samples, n_features), or (n_samples, n_samples) if metric=&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">トレーニングデータ。配列または行列の場合、形状は（n_samples、n_features）、またはmetric = 'precomputed'の場合は（n_samples、n_samples）です。</target>
        </trans-unit>
        <trans-unit id="f6ee318ff46063d0c81310a68af0a95508a0a339" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).</source>
          <target state="translated">トレーニングデータ。kernel ==&amp;ldquo; precomputed&amp;rdquo;の場合、これは代わりに、形状（n_samples、n_samples）の事前計算されたカーネル行列です。</target>
        </trans-unit>
        <trans-unit id="3cc715a75ede17772899f7cc9ab69882475a79bc" translate="yes" xml:space="preserve">
          <source>Training data. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples].</source>
          <target state="translated">トレーニングデータ。kernel ==&amp;ldquo; precomputed&amp;rdquo;の場合、これは代わりに事前計算されたカーネル行列、shape = [n_samples、n_samples]です。</target>
        </trans-unit>
        <trans-unit id="6ea489741914be2912ee247eeaf800f3ba49e6d8" translate="yes" xml:space="preserve">
          <source>Training data. If using GCV, will be cast to float64 if necessary.</source>
          <target state="translated">トレーニングデータ。GCVを使用している場合は,必要に応じてfloat64にキャストされます.</target>
        </trans-unit>
        <trans-unit id="b12ede4c226e6e2f235813d30bce55744269c03f" translate="yes" xml:space="preserve">
          <source>Training data. Must fulfill input requirements of first step of the pipeline.</source>
          <target state="translated">トレーニングデータ。パイプラインの最初のステップの入力要件を満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="d5044fd4a2ac02d5a0b137f2f3b7fd6b8f65a006" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If &lt;code&gt;y&lt;/code&gt; is mono-output then &lt;code&gt;X&lt;/code&gt; can be sparse.</source>
          <target state="translated">トレーニングデータ。不要なメモリの重複を避けるために、Fortran連続データとして直接渡します。場合 &lt;code&gt;y&lt;/code&gt; 、モノ出力され、その後 &lt;code&gt;X&lt;/code&gt; は疎であることができます。</target>
        </trans-unit>
        <trans-unit id="8ed7855d8da328d2505a0bcd1c3302665b72cb3d" translate="yes" xml:space="preserve">
          <source>Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.</source>
          <target state="translated">トレーニングデータ。不必要なメモリの重複を避けるために、Fortran連続データとして直接渡します。yが単出力の場合、Xはスパースにすることができます。</target>
        </trans-unit>
        <trans-unit id="4c004afef287030c2dcb4a937f43adb06e1cdf0e" translate="yes" xml:space="preserve">
          <source>Training data. Shape [n_samples, n_features], or [n_samples, n_samples] if affinity==&amp;rsquo;precomputed&amp;rsquo;.</source>
          <target state="translated">トレーニングデータ。形状[n_samples、n_features]、または[n_samples、n_samples]（affinity == 'precomputed'の場合）。</target>
        </trans-unit>
        <trans-unit id="30765b444b768ceb7d6bccc7cc4dd80dd79e1fcb" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;.</source>
          <target state="translated">クラスター化するインスタンスのトレーニング、または &lt;code&gt;affinity='precomputed'&lt;/code&gt; 場合はインスタンス間の距離。</target>
        </trans-unit>
        <trans-unit id="c7fd3fb257a793666a84757ce13a7e7b97d84277" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or distances between instances if &lt;code&gt;metric='precomputed'&lt;/code&gt;. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">クラスター化するインスタンスのトレーニング、または &lt;code&gt;metric='precomputed'&lt;/code&gt; の場合はインスタンス間の距離。スパース行列が提供されている場合、それはスパース &lt;code&gt;csr_matrix&lt;/code&gt; に変換されます。</target>
        </trans-unit>
        <trans-unit id="106fdf378e3c73e01e49b8eb92780c5d664680e0" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse feature matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">クラスター化するインスタンスのトレーニング、または &lt;code&gt;affinity='precomputed'&lt;/code&gt; 場合のインスタンス間の類似性/アフィニティ。スパース特徴行列が提供されている場合、それはスパース &lt;code&gt;csr_matrix&lt;/code&gt; に変換されます。</target>
        </trans-unit>
        <trans-unit id="e31b10426b1248f84a44c65b36e8acd0e5e7589c" translate="yes" xml:space="preserve">
          <source>Training instances to cluster, or similarities / affinities between instances if &lt;code&gt;affinity='precomputed'&lt;/code&gt;. If a sparse matrix is provided in a format other than &lt;code&gt;csr_matrix&lt;/code&gt;, &lt;code&gt;csc_matrix&lt;/code&gt;, or &lt;code&gt;coo_matrix&lt;/code&gt;, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">クラスター化するインスタンスのトレーニング、または &lt;code&gt;affinity='precomputed'&lt;/code&gt; 場合のインスタンス間の類似性/アフィニティ。スパース行列が &lt;code&gt;csr_matrix&lt;/code&gt; 、 &lt;code&gt;csc_matrix&lt;/code&gt; 、または &lt;code&gt;coo_matrix&lt;/code&gt; 以外の形式で提供されている場合、スパース行列はスパース &lt;code&gt;csr_matrix&lt;/code&gt; に変換されます。</target>
        </trans-unit>
        <trans-unit id="be8959fb1d08ac2482d5adecb9cc6d42cd3487ff" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.</source>
          <target state="translated">クラスタ化するインスタンスを訓練します。与えられたデータがC順に変換されるので、与えられたデータがC連続でない場合はメモリコピーが発生することに注意しなければなりません。</target>
        </trans-unit>
        <trans-unit id="eed67f947767b8d48d69b1a746024e52c70765e3" translate="yes" xml:space="preserve">
          <source>Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it&amp;rsquo;s not in CSR format.</source>
          <target state="translated">クラスター化するインスタンスのトレーニング。データはC順序に変換されることに注意する必要があります。これにより、指定されたデータがC連続でない場合、メモリコピーが発生します。スパース行列が渡された場合、CSR形式でない場合はコピーが作成されます。</target>
        </trans-unit>
        <trans-unit id="1fb973e1446d09c43085a14e14217bfa82f35fac" translate="yes" xml:space="preserve">
          <source>Training set and testing set</source>
          <target state="translated">トレーニングセットとテストセット</target>
        </trans-unit>
        <trans-unit id="ea59a824d416e7ea0dc63df33b1afa59cdb64566" translate="yes" xml:space="preserve">
          <source>Training set.</source>
          <target state="translated">トレーニングセット。</target>
        </trans-unit>
        <trans-unit id="3c518c488676e60e90ca53bcc0aa7271b669fe4d" translate="yes" xml:space="preserve">
          <source>Training set: only the shape is used to find optimal random matrix dimensions based on the theory referenced in the afore mentioned papers.</source>
          <target state="translated">学習セット:前述の論文で参照された理論に基づき、形状のみを用いて最適なランダム行列の次元を求める。</target>
        </trans-unit>
        <trans-unit id="68d52cda6c0756d21c2527d22eda07d7e45f55d9" translate="yes" xml:space="preserve">
          <source>Training target.</source>
          <target state="translated">訓練目標。</target>
        </trans-unit>
        <trans-unit id="32e48bd3169f82f98b7879700514da5daba97549" translate="yes" xml:space="preserve">
          <source>Training targets. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">トレーニングの目標。パイプラインのすべてのステップのラベル要件を満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="bc89d708a926da60c1e855065f294a150e4844da" translate="yes" xml:space="preserve">
          <source>Training vector, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the total number of features.</source>
          <target state="translated">トレーニングベクトル。ここで、 &lt;code&gt;n_samples&lt;/code&gt; はサンプルの数、 &lt;code&gt;n_features&lt;/code&gt; は特徴の総数です。</target>
        </trans-unit>
        <trans-unit id="325dc392b957558d0accbc4c288eabf85d0d476c" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">学習ベクトルであり、サンプル数のn_samples、n_featuresは特徴量の数である。</target>
        </trans-unit>
        <trans-unit id="01000b19ae19a1d02ea4ceb374852ca509745c92" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples in the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">学習ベクトルで、サンプル数のn_samples、n_featuresは特徴量の数です。セントロイド縮小は,疎な行列では使用できないことに注意してください.</target>
        </trans-unit>
        <trans-unit id="6a8354ff2f178d04d8fd18ac8502cba6a9d2e53e" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">学習ベクトルであり、n_samplesはサンプル数、n_featuresは特徴量の数である。</target>
        </trans-unit>
        <trans-unit id="d6cf7c60af251621aaa911db11caacf9c4de19a4" translate="yes" xml:space="preserve">
          <source>Training vector, where n_samples is the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.</source>
          <target state="translated">学習ベクトル,ここで n_samples はサンプル数,n_features は特徴量の数です.セントロイド縮小は,疎な行列では使用できないことに注意してください.</target>
        </trans-unit>
        <trans-unit id="23811d7edf5d74f8278700a3182a9d6e499aa68e" translate="yes" xml:space="preserve">
          <source>Training vectors, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">トレーニングベクトル。ここで、 &lt;code&gt;n_samples&lt;/code&gt; はサンプルの数、 &lt;code&gt;n_features&lt;/code&gt; は特徴の数です。</target>
        </trans-unit>
        <trans-unit id="66e0bce9861c05444da85a9795d5edcc3de5cb5e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">学習ベクトルは、n_samplesがサンプル数、n_featuresが特徴量の数である。</target>
        </trans-unit>
        <trans-unit id="f64b8abd734d5648613b346b4bb3c97a56c66bbf" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples, n_samples).</source>
          <target state="translated">トレーニングベクトル。ここで、n_samplesはサンプルの数、n_featuresは特徴の数です。kernel =&amp;rdquo; precomputed&amp;rdquo;の場合、Xの予想される形状は（n_samples、n_samples）です。</target>
        </trans-unit>
        <trans-unit id="f07e6c81521ffea6a563851833abed1de8063cb9" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, &amp;hellip;, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</source>
          <target state="translated">トレーニングベクトル。ここで、n_samplesはサンプルの数、n_featuresは特徴の数です。ここで、Xの各特徴は、異なるカテゴリ分布からのものであると想定されています。さらに、各機能のすべてのカテゴリが番号0、&amp;hellip;、n -1で表されると想定されます。ここで、nは特定の機能のカテゴリの総数を示します。これは、たとえば、OrdinalEncoderを使用して実現できます。</target>
        </trans-unit>
        <trans-unit id="d1d0a9d845fc3b099041b2d0f31be0d050a7001e" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.</source>
          <target state="translated">学習ベクトル.ここで,n_samples はサンプル数,n_features は特徴量の数です.GCV を利用する場合,必要に応じて float64 にキャストされます.</target>
        </trans-unit>
        <trans-unit id="ee5e82a19ba6d9a5b4fc8f431028f4e0ae5cae2a" translate="yes" xml:space="preserve">
          <source>Training vectors, where n_samples is the number of samples and n_features is the number of predictors.</source>
          <target state="translated">学習ベクトルで、n_samplesはサンプル数、n_featuresは予測変数の数です。</target>
        </trans-unit>
        <trans-unit id="3dbb8cbc3c8d093280069e8e889d1e0c62e1afde" translate="yes" xml:space="preserve">
          <source>Transform X back to its original space.</source>
          <target state="translated">Xを元の空間に戻す。</target>
        </trans-unit>
        <trans-unit id="dbfeebba6e53c937056143e8cf1258378ae1c26d" translate="yes" xml:space="preserve">
          <source>Transform X back to original space.</source>
          <target state="translated">Xを元の空間に戻す。</target>
        </trans-unit>
        <trans-unit id="aad161b5ffd8fb6722cd74d5621a58697eead90e" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of k nearest neighbors</source>
          <target state="translated">X を k 個の最近の隣人の(重み付けされた)グラフに変換する</target>
        </trans-unit>
        <trans-unit id="063b3e20cfa017691e75a65bb052691ed38fc79c" translate="yes" xml:space="preserve">
          <source>Transform X into a (weighted) graph of neighbors nearer than a radius</source>
          <target state="translated">Xを半径よりも近い隣人の(重み付けされた)グラフに変換する</target>
        </trans-unit>
        <trans-unit id="2fcdcd20eec681f04cc400d1e7a3d3a35f46ced9" translate="yes" xml:space="preserve">
          <source>Transform X into subcluster centroids dimension.</source>
          <target state="translated">Xをサブクラスターのセントロイド次元に変換します。</target>
        </trans-unit>
        <trans-unit id="da3379264043ea94358e5b4b01ce80967c41f1a5" translate="yes" xml:space="preserve">
          <source>Transform X separately by each transformer, concatenate results.</source>
          <target state="translated">Xを各変換器で個別に変換し、結果を連結する。</target>
        </trans-unit>
        <trans-unit id="054e9dc484301382a53ef7807c44414f413c3b43" translate="yes" xml:space="preserve">
          <source>Transform X to a cluster-distance space.</source>
          <target state="translated">Xをクラスタ距離空間に変換します。</target>
        </trans-unit>
        <trans-unit id="9340d4e978871cfc2faf3772609beb4370b76837" translate="yes" xml:space="preserve">
          <source>Transform X to ordinal codes.</source>
          <target state="translated">Xを順序コードに変換します。</target>
        </trans-unit>
        <trans-unit id="d750cda6e828d45a370fec4538601ee99b5443be" translate="yes" xml:space="preserve">
          <source>Transform X using one-hot encoding.</source>
          <target state="translated">ワンショットエンコーディングを使用してXを変換します。</target>
        </trans-unit>
        <trans-unit id="f9e88a65d85f54852f98655b3f250fdbf7750c92" translate="yes" xml:space="preserve">
          <source>Transform X using the forward function.</source>
          <target state="translated">順方向関数を使ってXを変換します。</target>
        </trans-unit>
        <trans-unit id="fb06535ce9222390887b51d0862f28eec382f495" translate="yes" xml:space="preserve">
          <source>Transform X using the inverse function.</source>
          <target state="translated">逆関数を使ってXを変換します。</target>
        </trans-unit>
        <trans-unit id="55b2dc92fd17631d37a113cafae1257246c63b9f" translate="yes" xml:space="preserve">
          <source>Transform X.</source>
          <target state="translated">Xを変換します。</target>
        </trans-unit>
        <trans-unit id="df5b966033d10ab5ffd4498c25f3563581fac3a4" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a normalized tf or tf-idf representation</source>
          <target state="translated">カウント行列を正規化された tf または tf-idf 表現に変換します.</target>
        </trans-unit>
        <trans-unit id="c6579300b554475d257c93a2551d1e7ac8d00f29" translate="yes" xml:space="preserve">
          <source>Transform a count matrix to a tf or tf-idf representation</source>
          <target state="translated">カウント行列を tf または tf-idf 表現に変換します.</target>
        </trans-unit>
        <trans-unit id="cfe77beec60d283a1ae2557849fffc568b20c2b6" translate="yes" xml:space="preserve">
          <source>Transform a new matrix using the built clustering</source>
          <target state="translated">ビルトインされたクラスタリングを用いて,新しい行列を変換します.</target>
        </trans-unit>
        <trans-unit id="eb758f2f9f4d3b4a21a0f5aa711d86b7f433cb44" translate="yes" xml:space="preserve">
          <source>Transform a sequence of documents to a document-term matrix.</source>
          <target state="translated">文書のシーケンスを文書-タームマトリックスに変換します。</target>
        </trans-unit>
        <trans-unit id="90d7961623626a54873e65ae75f5e5aedaf80a7d" translate="yes" xml:space="preserve">
          <source>Transform a sequence of instances to a scipy.sparse matrix.</source>
          <target state="translated">一連のインスタンスをscipy.sparse行列に変換します.</target>
        </trans-unit>
        <trans-unit id="482237f55f57c5ab1436ea9ad6e0ca3a5497f2c8" translate="yes" xml:space="preserve">
          <source>Transform a signal as a sparse combination of Ricker wavelets. This example visually compares different sparse coding methods using the &lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt;&lt;/a&gt; estimator. The Ricker (also known as Mexican hat or the second derivative of a Gaussian) is not a particularly good kernel to represent piecewise constant signals like this one. It can therefore be seen how much adding different widths of atoms matters and it therefore motivates learning the dictionary to best fit your type of signals.</source>
          <target state="translated">信号をリッカーウェーブレットの疎な組み合わせとして変換します。この例では、&lt;a href=&quot;../../modules/generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;sklearn.decomposition.SparseCoder&lt;/code&gt; &lt;/a&gt;推定器を使用して、さまざまなスパースコーディング手法を視覚的に比較しています。リッカー（メキシカンハットまたはガウスの2次導関数とも呼ばれます）は、このような区分的に一定の信号を表すのに特に適したカーネルではありません。したがって、さまざまな幅の原子を追加することがどれほど重要であるかがわかるため、信号のタイプに最もよく適合するように辞書を学習する動機付けになります。</target>
        </trans-unit>
        <trans-unit id="3c3158f9e95a76dac9ab046600d246dc683b1322" translate="yes" xml:space="preserve">
          <source>Transform array or sparse matrix X back to feature mappings.</source>
          <target state="translated">配列または疎な行列 X を特徴マッピングに変換します.</target>
        </trans-unit>
        <trans-unit id="43aed443a30ff04a0a7d38cae0c2e3f2c765ad45" translate="yes" xml:space="preserve">
          <source>Transform between iterable of iterables and a multilabel format</source>
          <target state="translated">イテラーブルのイテラーブルとマルチラベル形式の間の変換</target>
        </trans-unit>
        <trans-unit id="8428b18b095eb02611727f6a1283e0146f4aea18" translate="yes" xml:space="preserve">
          <source>Transform binary labels back to multi-class labels</source>
          <target state="translated">バイナリラベルをマルチクラスラベルに戻す</target>
        </trans-unit>
        <trans-unit id="2d5fb2d774241a80b97c22822072a1cd5822cad7" translate="yes" xml:space="preserve">
          <source>Transform data X according to the fitted model.</source>
          <target state="translated">フィットしたモデルに従ってデータXを変換します。</target>
        </trans-unit>
        <trans-unit id="e993947ab9336eb409d6a8eb55c55e2b5b858d46" translate="yes" xml:space="preserve">
          <source>Transform data back to its original space.</source>
          <target state="translated">データを元の空間に戻して変換します。</target>
        </trans-unit>
        <trans-unit id="b922af176e5b4295d0d766cd496f7523d4754428" translate="yes" xml:space="preserve">
          <source>Transform data to polynomial features</source>
          <target state="translated">データを多項式特徴量に変換</target>
        </trans-unit>
        <trans-unit id="f1a4a6b05048c3643e26b0d505b52199b7895296" translate="yes" xml:space="preserve">
          <source>Transform dataset.</source>
          <target state="translated">データセットを変換します。</target>
        </trans-unit>
        <trans-unit id="00a7e9f2b3e643cac0fe08c5b1d0d59cfff5c504" translate="yes" xml:space="preserve">
          <source>Transform discretized data back to original feature space.</source>
          <target state="translated">離散化されたデータを元の特徴空間に変換します。</target>
        </trans-unit>
        <trans-unit id="0146265304f248a8c03f040ea5d584981839ec0b" translate="yes" xml:space="preserve">
          <source>Transform documents to document-term matrix.</source>
          <target state="translated">文書を文書-タームマトリックスに変換します。</target>
        </trans-unit>
        <trans-unit id="778e7579ae52504e167839efee081ba3167de93f" translate="yes" xml:space="preserve">
          <source>Transform feature-&amp;gt;value dicts to array or sparse matrix.</source>
          <target state="translated">機能-&amp;gt;値辞書を配列または疎行列に変換します。</target>
        </trans-unit>
        <trans-unit id="8fde1456e50a374e1e8877ac2d0ea9941a580f00" translate="yes" xml:space="preserve">
          <source>Transform features by scaling each feature to a given range.</source>
          <target state="translated">各特徴量を所定の範囲にスケーリングして特徴量を変換します。</target>
        </trans-unit>
        <trans-unit id="c8f4f5c3bee4bfd8c782321e0d4eb227c2d3191b" translate="yes" xml:space="preserve">
          <source>Transform features using quantiles information.</source>
          <target state="translated">量化情報を用いて特徴量を変換する。</target>
        </trans-unit>
        <trans-unit id="ace4ae2489dd9688eddb3a58e732664d39d28a92" translate="yes" xml:space="preserve">
          <source>Transform labels back to original encoding.</source>
          <target state="translated">ラベルを元のエンコーディングに戻す。</target>
        </trans-unit>
        <trans-unit id="76c682df30bb4975f2641f2e89f16cc0b5f2d625" translate="yes" xml:space="preserve">
          <source>Transform labels to normalized encoding.</source>
          <target state="translated">ラベルを正規化されたエンコーディングに変換します。</target>
        </trans-unit>
        <trans-unit id="e6d8f7568400d53b2f444fa6cbf018c08b09552e" translate="yes" xml:space="preserve">
          <source>Transform multi-class labels to binary labels</source>
          <target state="translated">マルチクラスラベルをバイナリラベルに変換</target>
        </trans-unit>
        <trans-unit id="ec1f3a72d306387b537de1b3b116fbdf51b17550" translate="yes" xml:space="preserve">
          <source>Transform new data by linear interpolation</source>
          <target state="translated">線形補間による新しいデータの変換</target>
        </trans-unit>
        <trans-unit id="7e25dbc81754715628745ec728c6c249ac9d1737" translate="yes" xml:space="preserve">
          <source>Transform new points into embedding space.</source>
          <target state="translated">新しいポイントを埋め込み空間に変換します。</target>
        </trans-unit>
        <trans-unit id="17e15b65d999776fc7cb047cfc38d87f9b340eec" translate="yes" xml:space="preserve">
          <source>Transform the data X according to the fitted NMF model</source>
          <target state="translated">フィットしたNMFモデルに従ってデータXを変換する</target>
        </trans-unit>
        <trans-unit id="28a4737ac1d13b4e451237dc699b89c49f7fb862" translate="yes" xml:space="preserve">
          <source>Transform the given indicator matrix into label sets</source>
          <target state="translated">与えられた指標行列をラベルセットに変換する</target>
        </trans-unit>
        <trans-unit id="38739bda11e07f48ac023acb8323ed328f115bd5" translate="yes" xml:space="preserve">
          <source>Transform the given label sets</source>
          <target state="translated">与えられたラベルセットを変換する</target>
        </trans-unit>
        <trans-unit id="92a052e88a019f5aca9bb96a9137d202560617b4" translate="yes" xml:space="preserve">
          <source>Transform the sources back to the mixed data (apply mixing matrix).</source>
          <target state="translated">ソースを混合データに戻して変換します(混合行列を適用します)。</target>
        </trans-unit>
        <trans-unit id="6414c408546f181e607c3ec28647dd72e64872ea" translate="yes" xml:space="preserve">
          <source>Transform your features into a higher dimensional, sparse space. Then train a linear model on these features.</source>
          <target state="translated">特徴量を高次元の疎な空間に変換します。そして、これらの特徴量に対して線形モデルを訓練します。</target>
        </trans-unit>
        <trans-unit id="d3709f378c935401f6b259df9cce5a50135da098" translate="yes" xml:space="preserve">
          <source>Transformed array.</source>
          <target state="translated">変換された配列。</target>
        </trans-unit>
        <trans-unit id="4a8a97e010ec7ac27b50257ef7ee542c13ba8846" translate="yes" xml:space="preserve">
          <source>Transformed data</source>
          <target state="translated">変換されたデータ</target>
        </trans-unit>
        <trans-unit id="d460e113769e190612a2b959c1c729d7e8676439" translate="yes" xml:space="preserve">
          <source>Transformed data in the binned space.</source>
          <target state="translated">ビン化された空間で変換されたデータ。</target>
        </trans-unit>
        <trans-unit id="14642329121567cf9f5775d8a6512d3b978fccd2" translate="yes" xml:space="preserve">
          <source>Transformed data matrix</source>
          <target state="translated">変換されたデータ行列</target>
        </trans-unit>
        <trans-unit id="0d3a338b719647431757293955a1513d13c572f4" translate="yes" xml:space="preserve">
          <source>Transformed data.</source>
          <target state="translated">変換されたデータ。</target>
        </trans-unit>
        <trans-unit id="08b12f8aaa8632b66a6a22bc4de550a469c3cc9c" translate="yes" xml:space="preserve">
          <source>Transformed dataset.</source>
          <target state="translated">変換されたデータセット。</target>
        </trans-unit>
        <trans-unit id="eeb85e59603c1cea29acb31c92a29204737376ea" translate="yes" xml:space="preserve">
          <source>Transformed input.</source>
          <target state="translated">変換された入力。</target>
        </trans-unit>
        <trans-unit id="0a6145f06a4913811002ff339bc5284d2892e790" translate="yes" xml:space="preserve">
          <source>Transformed samples</source>
          <target state="translated">変換されたサンプル</target>
        </trans-unit>
        <trans-unit id="a40fe3e47da3940e6c654b4aca4fd3b4db53b382" translate="yes" xml:space="preserve">
          <source>Transformed values.</source>
          <target state="translated">変形した価値観。</target>
        </trans-unit>
        <trans-unit id="0b6f242e80f2185c5234be3f41a48f40589d58f3" translate="yes" xml:space="preserve">
          <source>Transformer instance.</source>
          <target state="translated">トランスフォーマーのインスタンス。</target>
        </trans-unit>
        <trans-unit id="dd414e8652819a2c899c58cada9c3dd8cc66e071" translate="yes" xml:space="preserve">
          <source>Transformer mixin that performs feature selection given a support mask</source>
          <target state="translated">サポートマスクを指定して特徴の選択を行うトランスミキシン</target>
        </trans-unit>
        <trans-unit id="6d517e36599e67ec967c7be2afac6d7777579d1a" translate="yes" xml:space="preserve">
          <source>Transformer used in &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; と &lt;code&gt;predict&lt;/code&gt; 使用されるトランスフォーマー。</target>
        </trans-unit>
        <trans-unit id="43471a7ace97310a9577002aa9803e00d83e6192" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">トランスフォーマーは通常、分類子、リグレッサ、またはその他の推定量と組み合わされて、複合推定量を構築します。最も一般的なツールは&lt;a href=&quot;#pipeline&quot;&gt;パイプライン&lt;/a&gt;です。パイプラインは、トランスフォーマーの出力を複合特徴空間に連結する&lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt;と組み合わせて使用​​されることがよくあります。&lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt;は、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-target&quot;&gt;ターゲットの&lt;/a&gt;変換を扱います（つまり、対数変換&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-171&quot;&gt;y&lt;/a&gt;）。対照的に、パイプラインは観測データ（&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-x&quot;&gt;X&lt;/a&gt;）のみを変換します。</target>
        </trans-unit>
        <trans-unit id="021fd2002f82b7c8da7b92d01fe659fdcbdaeb82" translate="yes" xml:space="preserve">
          <source>Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a &lt;a href=&quot;#pipeline&quot;&gt;Pipeline&lt;/a&gt;. Pipeline is often used in combination with &lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt; which concatenates the output of transformers into a composite feature space. &lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt; deals with transforming the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;target&lt;/a&gt; (i.e. log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;). In contrast, Pipelines only transform the observed data (&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;).</source>
          <target state="translated">トランスフォーマーは通常、分類器、回帰子、またはその他の推定量と組み合わせて、複合推定量を構築します。最も一般的なツールは&lt;a href=&quot;#pipeline&quot;&gt;パイプライン&lt;/a&gt;です。パイプラインは、トランスフォーマーの出力を複合特徴空間に連結する&lt;a href=&quot;#feature-union&quot;&gt;FeatureUnion&lt;/a&gt;と組み合わせて使用​​されることがよくあります。&lt;a href=&quot;#transformed-target-regressor&quot;&gt;TransformedTargetRegressor&lt;/a&gt;は、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-target&quot;&gt;ターゲットの&lt;/a&gt;変換（つまり、log-transform &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-177&quot;&gt;y&lt;/a&gt;）を処理します。対照的に、パイプラインは観測されたデータ（&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-x&quot;&gt;X&lt;/a&gt;）のみを変換します。</target>
        </trans-unit>
        <trans-unit id="b69fe15775501662a569d2ed632ddbe970e558ef" translate="yes" xml:space="preserve">
          <source>Transformers for missing value imputation</source>
          <target state="translated">欠損値入力のための変圧器</target>
        </trans-unit>
        <trans-unit id="4804df5ca1652cab2567ab10e41eae2d30b7e99a" translate="yes" xml:space="preserve">
          <source>Transforming Classifier Scores into Accurate Multiclass Probability Estimates, B. Zadrozny &amp;amp; C. Elkan, (KDD 2002)</source>
          <target state="translated">分類子スコアを正確なマルチクラス確率推定に変換する、B。Zadrozny＆C. Elkan、（KDD 2002）</target>
        </trans-unit>
        <trans-unit id="74f517360774a680819178109aa2b52b87d4fd99" translate="yes" xml:space="preserve">
          <source>Transforming distance to well-behaved similarities</source>
          <target state="translated">距離をよく似たものに変換する</target>
        </trans-unit>
        <trans-unit id="87156c340b6aec33fafb3545fc791ff4187014aa" translate="yes" xml:space="preserve">
          <source>Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.</source>
          <target state="translated">クラスラベルの存在を示す(サンプル×クラス)バイナリ行列など、イテレート可能なイテレートとマルチラベル形式の間で変換します。</target>
        </trans-unit>
        <trans-unit id="dfe17b4b683a10ef2eafef30897d9c629bf96dd6" translate="yes" xml:space="preserve">
          <source>Transforms discretized data back to original feature space.</source>
          <target state="translated">離散化されたデータを元の特徴空間に戻します。</target>
        </trans-unit>
        <trans-unit id="5bd7a9a7032f01002afe1d21dc1635e87bd5dbc6" translate="yes" xml:space="preserve">
          <source>Transforms features by scaling each feature to a given range.</source>
          <target state="translated">各特徴量を所定の範囲にスケーリングして特徴量を変換します.</target>
        </trans-unit>
        <trans-unit id="45675a7235910659531092f94ca2cac1226cb6a9" translate="yes" xml:space="preserve">
          <source>Transforms lists of feature-value mappings to vectors.</source>
          <target state="translated">特徴-値のマッピングのリストをベクトルに変換します.</target>
        </trans-unit>
        <trans-unit id="18a051a7877c1a9e6b194ac68c49193ac689d698" translate="yes" xml:space="preserve">
          <source>Transforms text into a sparse matrix of n-gram counts.</source>
          <target state="translated">テキストをn-gramカウントの疎な行列に変換します.</target>
        </trans-unit>
        <trans-unit id="ff596a653686d4986dda1851c66682d846f4bf4d" translate="yes" xml:space="preserve">
          <source>Transforms the image samples in X into a matrix of patch data.</source>
          <target state="translated">Xの画像サンプルをパッチデータの行列に変換します.</target>
        </trans-unit>
        <trans-unit id="aff42f13a1dfe3735469a5dd26ab12a5bac4a9ad" translate="yes" xml:space="preserve">
          <source>Tree pruning</source>
          <target state="translated">樹木の剪定</target>
        </trans-unit>
        <trans-unit id="dda8f4221caceb0e1b9d09350500616b39f0c3c5" translate="yes" xml:space="preserve">
          <source>Tree&amp;rsquo;s Feature Importance from Mean Decrease in Impurity (MDI)</source>
          <target state="translated">不純物の平均減少（MDI）からのツリーの特徴の重要性</target>
        </trans-unit>
        <trans-unit id="d6a25d0e3691aa7e7e60fcc1d61ee6046c7d09b3" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">ツリーベースの推定量は、（参照&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt;における樹木のモジュール及び森林&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;に結合されたときにモジュール）を順番に無関係な機能を破棄するために使用することができる計算機能重要度、（に使用することができる&lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt;メタトランスフォーマー）：</target>
        </trans-unit>
        <trans-unit id="ccdf4aec1fccb56109a1e3945469e98a8d62aca9" translate="yes" xml:space="preserve">
          <source>Tree-based estimators (see the &lt;a href=&quot;classes#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module and forest of trees in the &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module) can be used to compute impurity-based feature importances, which in turn can be used to discard irrelevant features (when coupled with the &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; meta-transformer):</source>
          <target state="translated">ツリーベースの推定器（参照&lt;a href=&quot;classes#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt;における樹木のモジュール及び森林&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;モジュール）を順にと組み合わせると無関係な機能を（破棄するために使用することができる計算不純物基づく特徴重要度、に使用することができる&lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt;メタトランスフォーマー）：</target>
        </trans-unit>
        <trans-unit id="3629b84a13698bd03a810f8a682027a82e4a7e42" translate="yes" xml:space="preserve">
          <source>Tree-based models provide an alternative measure of &lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;feature importances based on the mean decrease in impurity&lt;/a&gt; (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data.</source>
          <target state="translated">ツリーベースのモデルは、&lt;a href=&quot;ensemble#random-forest-feature-importance&quot;&gt;不純物の平均減少&lt;/a&gt;（MDI）に基づいて、機能の重要性の代替手段を提供します。不純物は、決定木の分割基準（ジニ、エントロピー、または平均二乗誤差）によって定量化されます。ただし、この方法は、モデルが過剰適合している場合に、見えないデータを予測できない可能性のある機能を非常に重要視する可能性があります。一方、順列ベースの特徴の重要性は、見えないデータで計算できるため、この問題を回避します。</target>
        </trans-unit>
        <trans-unit id="81d8ac0c0739336d0bbd6f8053b2fde8039cdb1c" translate="yes" xml:space="preserve">
          <source>Triangle Inequality: d(x, y) + d(y, z) &amp;gt;= d(x, z)</source>
          <target state="translated">三角形の不等式：d（x、y）+ d（y、z）&amp;gt; = d（x、z）</target>
        </trans-unit>
        <trans-unit id="331d2c199452ae22aa8941c5bcbe6a7fe41c68b5" translate="yes" xml:space="preserve">
          <source>Tristan Fletcher: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Relevance Vector Machines explained&lt;/a&gt;</source>
          <target state="translated">トリスタンフレッチャー：&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.8603&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;関連性ベクトルマシンの説明&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3b19d80cd81c13647ace615b9d73da08b4d8c61b" translate="yes" xml:space="preserve">
          <source>True : always precompute distances</source>
          <target state="translated">True:常に距離を事前に計算する</target>
        </trans-unit>
        <trans-unit id="27f22be4c5a651c1c27cbdc4b85cf77c839d3ddd" translate="yes" xml:space="preserve">
          <source>True : always precompute distances.</source>
          <target state="translated">True:常に距離を事前に計算します。</target>
        </trans-unit>
        <trans-unit id="ebac1d7d68472a848a069828ba36b6b2dd6227bb" translate="yes" xml:space="preserve">
          <source>True binary labels in binary indicator format.</source>
          <target state="translated">バイナリーインジケーター形式の真のバイナリーラベル。</target>
        </trans-unit>
        <trans-unit id="94ad072572f1b0d8a6896ff3fd5d5269c3006cce" translate="yes" xml:space="preserve">
          <source>True binary labels or binary label indicators.</source>
          <target state="translated">真のバイナリーラベルやバイナリーラベルインジケーター。</target>
        </trans-unit>
        <trans-unit id="173029937373f6d16ed7438491b1a8131b2bc4cb" translate="yes" xml:space="preserve">
          <source>True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.</source>
          <target state="translated">真のバイナリラベル。ラベルが {-1,1}または {0,1}のいずれでもない場合は、明示的に pos_label を与えなければなりません。</target>
        </trans-unit>
        <trans-unit id="394534b1dcaf25753dd90ddcd321d6ef1b441d87" translate="yes" xml:space="preserve">
          <source>True if a fixed vocabulary of term to indices mapping is provided by the user</source>
          <target state="translated">用語とインデックスのマッピングの固定語彙がユーザによって提供されている場合は真</target>
        </trans-unit>
        <trans-unit id="cba1cd7ae39f91f6d0e2908d3956200bdf94de07" translate="yes" xml:space="preserve">
          <source>True if estimator is a classifier and False otherwise.</source>
          <target state="translated">推定器が分類器であれば真、そうでなければ偽。</target>
        </trans-unit>
        <trans-unit id="7e34070b9f977933411df9b814860396cade02bb" translate="yes" xml:space="preserve">
          <source>True if estimator is a regressor and False otherwise.</source>
          <target state="translated">推定値が回帰器の場合はTrue、そうでない場合はFalse。</target>
        </trans-unit>
        <trans-unit id="d039a95b006860b5b92d23f84015c0458d6fdb1a" translate="yes" xml:space="preserve">
          <source>True if the array returned from predict is to be in sparse CSC format. Is automatically set to True if the input y is passed in sparse format.</source>
          <target state="translated">predict から返される配列が疎な CSC 形式であれば真。入力 y が疎なフォーマットで渡された場合は自動的に True に設定されます。</target>
        </trans-unit>
        <trans-unit id="018f28ffd2c7241c63be51b46bba3e8aa528d907" translate="yes" xml:space="preserve">
          <source>True if the input data to transform is given as a sparse matrix, False otherwise.</source>
          <target state="translated">変換する入力データが疎な行列として与えられている場合は真、そうでない場合は偽です。</target>
        </trans-unit>
        <trans-unit id="06236e43536e8bd62b7d950e36ddd9dca022a999" translate="yes" xml:space="preserve">
          <source>True if the output at fit is 2d, else false.</source>
          <target state="translated">はめ込み時の出力が 2d であれば真、 そうでなければ偽。</target>
        </trans-unit>
        <trans-unit id="abda54d00232aa3c71419926e38966e372a6e200" translate="yes" xml:space="preserve">
          <source>True if the returned array from transform is desired to be in sparse CSR format.</source>
          <target state="translated">トランスフォームから返された配列をスパースな CSR 形式にしたい場合は True。</target>
        </trans-unit>
        <trans-unit id="b3f5d1c4b9aeea8d97315ada02d3f0f3b6e0dbc5" translate="yes" xml:space="preserve">
          <source>True labels for X.</source>
          <target state="translated">Xの真のラベル。</target>
        </trans-unit>
        <trans-unit id="d40646e12c6271d621333c3801ded96344098308" translate="yes" xml:space="preserve">
          <source>True labels or binary label indicators. The binary and multiclass cases expect labels with shape (n_samples,) while the multilabel case expects binary label indicators with shape (n_samples, n_classes).</source>
          <target state="translated">真のラベルまたはバイナリラベルインジケータ。バイナリとマルチクラスの場合は、形状(n_samples,)を持つラベルを期待し、マルチラベルの場合は、形状(n_samples,n_classes)を持つバイナリラベルインジケータを期待します。</target>
        </trans-unit>
        <trans-unit id="24a7816a0ae25d0715f83e367246b56738200fc8" translate="yes" xml:space="preserve">
          <source>True mutual information can&amp;rsquo;t be negative. If its estimate turns out to be negative, it is replaced by zero.</source>
          <target state="translated">真の相互情報は否定的であってはなりません。その推定値が負であることが判明した場合は、ゼロに置き換えられます。</target>
        </trans-unit>
        <trans-unit id="1086f49a3e748a59792d8342e65dffdfa18d8ff5" translate="yes" xml:space="preserve">
          <source>True positive rate.</source>
          <target state="translated">真の陽性率。</target>
        </trans-unit>
        <trans-unit id="e857c90bead41164c28f265fe201e3c7a69f5d75" translate="yes" xml:space="preserve">
          <source>True target, consisting of integers of two values. The positive label must be greater than the negative label.</source>
          <target state="translated">2つの値の整数で構成される真のターゲット。正のラベルは負のラベルよりも大きくなければなりません。</target>
        </trans-unit>
        <trans-unit id="5f6f5563a268706baa91536cfcd1565c453cd8e7" translate="yes" xml:space="preserve">
          <source>True targets of binary classification in range {-1, 1} or {0, 1}.</source>
          <target state="translated">範囲{-1,1}または{0,1}の二値分類の真のターゲット。</target>
        </trans-unit>
        <trans-unit id="308caeb8e2723647ce2ad06a73f50c7b1bd2b781" translate="yes" xml:space="preserve">
          <source>True targets of multilabel classification, or true scores of entities to be ranked.</source>
          <target state="translated">マルチラベル分類の真の対象、またはランク付けされるエンティティの真のスコア。</target>
        </trans-unit>
        <trans-unit id="6e2bbfc40bf0e63b31fb5b0351be961b49cc74be" translate="yes" xml:space="preserve">
          <source>True targets.</source>
          <target state="translated">真の目標。</target>
        </trans-unit>
        <trans-unit id="18dd5ee40d70767a2f6629e8ff8969a87290115e" translate="yes" xml:space="preserve">
          <source>True values for X</source>
          <target state="translated">X の真の値</target>
        </trans-unit>
        <trans-unit id="81e3774c236b4c61a22388a1a822b3e69fb3e5a6" translate="yes" xml:space="preserve">
          <source>True values for X.</source>
          <target state="translated">Xの真の値。</target>
        </trans-unit>
        <trans-unit id="7e4dee4cabccdb0d80fb65794484e70b177b35d1" translate="yes" xml:space="preserve">
          <source>True values of target.</source>
          <target state="translated">ターゲットの真の値。</target>
        </trans-unit>
        <trans-unit id="0d7ce48badf2f0a91a36bec7511768633417749f" translate="yes" xml:space="preserve">
          <source>True when convergence was reached in fit(), False otherwise.</source>
          <target state="translated">fit()で収束したときは True、そうでないときは False。</target>
        </trans-unit>
        <trans-unit id="d333cd18e174fe06286d776d55b1b9eaf760ce1b" translate="yes" xml:space="preserve">
          <source>True: Force all values of X to be finite.</source>
          <target state="translated">真:Xのすべての値を有限にするように強制します。</target>
        </trans-unit>
        <trans-unit id="42eef53fc6823568b56bf4bf254799ea2d7766d8" translate="yes" xml:space="preserve">
          <source>True: Force all values of array to be finite.</source>
          <target state="translated">True:配列のすべての値を有限にします。</target>
        </trans-unit>
        <trans-unit id="260b9ffda14105c1fd2ffa31d36eae7c83268ddd" translate="yes" xml:space="preserve">
          <source>True: the results is casted to an unsigned int</source>
          <target state="translated">True:結果は符号なし整数にキャストされます。</target>
        </trans-unit>
        <trans-unit id="e67782a583f6700ced58a8f740875b4358d4fb58" translate="yes" xml:space="preserve">
          <source>Trustworthiness of the low-dimensional embedding.</source>
          <target state="translated">低次元埋め込みの信頼性。</target>
        </trans-unit>
        <trans-unit id="00b6f6ebc7b7070cf35772b16b427811573346a1" translate="yes" xml:space="preserve">
          <source>Try classifying classes 1 and 2 from the iris dataset with SVMs, with the 2 first features. Leave out 10% of each class and test prediction performance on these observations.</source>
          <target state="translated">2つの最初の特徴を持つSVMで、虹彩データセットからクラス1と2を分類してみてください。各クラスの10%を残して、これらのオブザベーションで予測性能をテストしてください。</target>
        </trans-unit>
        <trans-unit id="5449ae93c54cf3f8e79ab0ee95bb4ee118bd4f84" translate="yes" xml:space="preserve">
          <source>Try classifying the digits dataset with nearest neighbors and a linear model. Leave out the last 10% and test prediction performance on these observations.</source>
          <target state="translated">直近の隣人と線形モデルを用いて、桁のデータセットを分類してみてください。最後の10%を残して、これらのオブザベーションで予測性能をテストしてください。</target>
        </trans-unit>
        <trans-unit id="7a783eca4388b1c7b8c830f476caa080328ba3c3" translate="yes" xml:space="preserve">
          <source>Try playing around with the &lt;code&gt;analyzer&lt;/code&gt; and &lt;code&gt;token normalisation&lt;/code&gt; under &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; で&lt;/a&gt; &lt;code&gt;analyzer&lt;/code&gt; と &lt;code&gt;token normalisation&lt;/code&gt; をいじってみてください。</target>
        </trans-unit>
        <trans-unit id="b7e468fa3f6cfdfb33fa6bf28dcdf3165bf89507" translate="yes" xml:space="preserve">
          <source>Try to differentiate the two first classes of the iris data</source>
          <target state="translated">虹彩データの2つの最初のクラスを区別してみる</target>
        </trans-unit>
        <trans-unit id="1bc09af6523c25787ea3631aac8c3f52f8bc29dc" translate="yes" xml:space="preserve">
          <source>Try using &lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;Truncated SVD&lt;/a&gt; for &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;latent semantic analysis&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;潜在セマンティック分析に&lt;/a&gt;&lt;a href=&quot;../../modules/decomposition#lsa&quot;&gt;切り捨てSVD&lt;/a&gt;を使用してみてください。</target>
        </trans-unit>
        <trans-unit id="126c548fa4d4a4c65c7759b8f0eb82ce5677dab5" translate="yes" xml:space="preserve">
          <source>Tsoumakas, G., Katakis, I., &amp;amp; Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</source>
          <target state="translated">Tsoumakas、G.、Katakis、I.、＆Vlahavas、I.（2010）。マルチラベルデータのマイニング。データマイニングと知識発見のハンドブック（pp。667-685）。スプリンガー米国。</target>
        </trans-unit>
        <trans-unit id="0d016a3ee3141a6ebd01b9c31169fb6ec8d37fd6" translate="yes" xml:space="preserve">
          <source>Tuning the hyper-parameters of an estimator</source>
          <target state="translated">推定器のハイパーパラメータの調整</target>
        </trans-unit>
        <trans-unit id="2e926727653886b165b872a4b6b2a62bf90f0bd1" translate="yes" xml:space="preserve">
          <source>Tuple of row and column indicators for a set of biclusters.</source>
          <target state="translated">バイクラスターの集合の行と列のインジケータのタプル。</target>
        </trans-unit>
        <trans-unit id="a813118f879d8793b6336ef94325f8c8d09426be" translate="yes" xml:space="preserve">
          <source>Tuples of the form (transformer, columns) specifying the transformer objects to be applied to subsets of the data.</source>
          <target state="translated">データのサブセットに適用する変換器オブジェクトを指定する形式のタプル(transformer,columns)。</target>
        </trans-unit>
        <trans-unit id="c054700312acf34cbacbc98d115120c76da3a6d5" translate="yes" xml:space="preserve">
          <source>Turn seed into a np.random.RandomState instance</source>
          <target state="translated">seedをnp.random.Random.RandomStateインスタンスに変換します。</target>
        </trans-unit>
        <trans-unit id="4b18a115e0842d6d0ba3a4ec2ed7b07c665b5f56" translate="yes" xml:space="preserve">
          <source>Tutorial exercises</source>
          <target state="translated">チュートリアル演習</target>
        </trans-unit>
        <trans-unit id="007a671747688cedb01751baca6545483f05de7a" translate="yes" xml:space="preserve">
          <source>Tutorial setup</source>
          <target state="translated">チュートリアルの設定</target>
        </trans-unit>
        <trans-unit id="025f75efad84ed2b985f2818a53e81aa77abca7c" translate="yes" xml:space="preserve">
          <source>Tutorial: A tutorial on statistical-learning for scientific data processing</source>
          <target state="translated">チュートリアル 科学的データ処理のための統計学習のチュートリアル</target>
        </trans-unit>
        <trans-unit id="e7df3b5ebbaf2fd3b4b4579edbd7ce42f46db699" translate="yes" xml:space="preserve">
          <source>Tutorial: An introduction to machine learning with scikit-learn</source>
          <target state="translated">チュートリアル scikit-learnを使った機械学習の紹介</target>
        </trans-unit>
        <trans-unit id="8682fb6c27e32858369b74e47f829fad6c8d3a68" translate="yes" xml:space="preserve">
          <source>Tutorial: Choosing the right estimator</source>
          <target state="translated">チュートリアル.正しい推定量の選択</target>
        </trans-unit>
        <trans-unit id="2865c0d93493065de0c34da92792e35a845226d3" translate="yes" xml:space="preserve">
          <source>Tutorial: Model selection</source>
          <target state="translated">チュートリアル:モデルの選択</target>
        </trans-unit>
        <trans-unit id="b7709b919b68974b71489ceb95a00ef31c4eda72" translate="yes" xml:space="preserve">
          <source>Tutorial: Putting it all together</source>
          <target state="translated">チュートリアル。すべてをまとめる</target>
        </trans-unit>
        <trans-unit id="b0b3bc4bbf4e62230750bf24baeb122d7a994298" translate="yes" xml:space="preserve">
          <source>Tutorial: Statistical learning</source>
          <target state="translated">チュートリアル 統計的学習</target>
        </trans-unit>
        <trans-unit id="a149365421f01d98250256737c350c42a4cd4b82" translate="yes" xml:space="preserve">
          <source>Tutorial: Supervised learning</source>
          <target state="translated">チュートリアル。教師付き学習</target>
        </trans-unit>
        <trans-unit id="4353f067a68843e09ae0691ab9f9c44ef2e6db23" translate="yes" xml:space="preserve">
          <source>Tutorial: Unsupervised learning</source>
          <target state="translated">チュートリアル.教師なし学習</target>
        </trans-unit>
        <trans-unit id="206fac7baeed5ee14f8990630b6607a7c33e8644" translate="yes" xml:space="preserve">
          <source>Tutorial: Working With Text Data</source>
          <target state="translated">チュートリアル テキストデータを使った作業</target>
        </trans-unit>
        <trans-unit id="b919de3c63710fd07133db7062fb5a1fbffa0bfe" translate="yes" xml:space="preserve">
          <source>Tutorial: scikit-learn Tutorials</source>
          <target state="translated">チュートリアル:scikit-learn チュートリアル</target>
        </trans-unit>
        <trans-unit id="654171647baa6be8557a5d627cf35c7075ebb257" translate="yes" xml:space="preserve">
          <source>Tutorials</source>
          <target state="translated">Tutorials</target>
        </trans-unit>
        <trans-unit id="b9f0efb9bc5f86b33edfdb893732e46d86a776bd" translate="yes" xml:space="preserve">
          <source>Tweedie deviance is a homogeneous function of degree &lt;code&gt;2-power&lt;/code&gt;. Thus, Gamma distribution with &lt;code&gt;power=2&lt;/code&gt; means that simultaneously scaling &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has no effect on the deviance. For Poisson distribution &lt;code&gt;power=1&lt;/code&gt; the deviance scales linearly, and for Normal distribution (&lt;code&gt;power=0&lt;/code&gt;), quadratically. In general, the higher &lt;code&gt;power&lt;/code&gt; the less weight is given to extreme deviations between true and predicted targets.</source>
          <target state="translated">Tweedieの逸脱度は、 &lt;code&gt;2-power&lt;/code&gt; 次の同次関数です。したがって、 &lt;code&gt;power=2&lt;/code&gt; のガンマ分布は、 &lt;code&gt;y_true&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; を同時にスケーリングしても逸脱度に影響がないことを意味します。ポアソン分布の &lt;code&gt;power=1&lt;/code&gt; 、逸脱度は線形にスケーリングし、正規分布（ &lt;code&gt;power=0&lt;/code&gt; ）の場合は二次関数的にスケーリングします。一般に、 &lt;code&gt;power&lt;/code&gt; が高いほど、真のターゲットと予測されたターゲットの間の極端な偏差に与えられる重みは小さくなります。</target>
        </trans-unit>
        <trans-unit id="b534d41a45e4c1bc7da48b9a62fdc9565da97cac" translate="yes" xml:space="preserve">
          <source>Tweedie power parameter. Either power &amp;lt;= 0 or power &amp;gt;= 1.</source>
          <target state="translated">Tweedieパワーパラメータ。電力&amp;lt;= 0または電力&amp;gt; = 1のいずれか。</target>
        </trans-unit>
        <trans-unit id="25d7747a25958e3f10fc9c93bbab44d13248adbd" translate="yes" xml:space="preserve">
          <source>Tweedie regression on insurance claims</source>
          <target state="translated">保険金のツイーディー回帰</target>
        </trans-unit>
        <trans-unit id="995550b74403db560a3a2ea8d3906cd56b901336" translate="yes" xml:space="preserve">
          <source>Two algorithms are demoed: ordinary k-means and its more scalable cousin minibatch k-means.</source>
          <target state="translated">通常のk-meansと、よりスケーラブルないとこのminibatch k-meansの2つのアルゴリズムがデモされています。</target>
        </trans-unit>
        <trans-unit id="3b934d458351995534fed7d234de7b14c38f4cd4" translate="yes" xml:space="preserve">
          <source>Two approaches for performing calibration of probabilistic predictions are provided: a parametric approach based on Platt&amp;rsquo;s sigmoid model and a non-parametric approach based on isotonic regression (&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt;&lt;code&gt;sklearn.isotonic&lt;/code&gt;&lt;/a&gt;). Probability calibration should be done on new data not used for model fitting. The class &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; uses a cross-validation generator and estimates for each split the model parameter on the train samples and the calibration of the test samples. The probabilities predicted for the folds are then averaged. Already fitted classifiers can be calibrated by &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; via the parameter cv=&amp;rdquo;prefit&amp;rdquo;. In this case, the user has to take care manually that data for model fitting and calibration are disjoint.</source>
          <target state="translated">確率的予測のキャリブレーションを実行するための2つのアプローチが提供されます：プラットのシグモイドモデルに基づくパラメトリックアプローチと等張回帰に基づくノンパラメトリックアプローチ（&lt;a href=&quot;classes#module-sklearn.isotonic&quot;&gt; &lt;code&gt;sklearn.isotonic&lt;/code&gt; &lt;/a&gt;）。確率キャリブレーションは、モデルのフィッティングに使用されていない新しいデータに対して行う必要があります。&lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt;クラスは、交差検定ジェネレーターを使用し、トレーニングサンプルのモデルパラメーターとテストサンプルのキャリブレーションの分割ごとに推定します。次に、フォールドに対して予測された確率が平均化されます。適合済みの分類子は、パラメーターcv =&amp;rdquo; prefit&amp;rdquo;を介して&lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; &lt;/a&gt;で較正できます。この場合、ユーザーは手動でモデルのフィッティングとキャリブレーションのデータがばらばらになるように注意する必要があります。</target>
        </trans-unit>
        <trans-unit id="de7e8d6ad699213a292d0c528c5ddad33bca14ae" translate="yes" xml:space="preserve">
          <source>Two consequences of imposing a connectivity can be seen. First clustering with a connectivity matrix is much faster.</source>
          <target state="translated">接続性を課すことの2つの結果が見られます。第一に,接続性行列を用いたクラスタリングは,はるかに高速である.</target>
        </trans-unit>
        <trans-unit id="73ece4ca1e1779fbf5110031e848f2313deac958" translate="yes" xml:space="preserve">
          <source>Two cross-validation loops are performed in parallel: one by the &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; estimator to set &lt;code&gt;gamma&lt;/code&gt; and the other one by &lt;code&gt;cross_val_score&lt;/code&gt; to measure the prediction performance of the estimator. The resulting scores are unbiased estimates of the prediction score on new data.</source>
          <target state="translated">2つの交差検証ループが並行して実行されます。1つは &lt;code&gt;gamma&lt;/code&gt; を設定するための&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;推定器によるもので、もう1つは推定器の予測パフォーマンスを測定するための &lt;code&gt;cross_val_score&lt;/code&gt; によるものです。結果のスコアは、新しいデータの予測スコアの不偏推定値です。</target>
        </trans-unit>
        <trans-unit id="d467efdd44bf60415fc895b8589d9d81d46d02ec" translate="yes" xml:space="preserve">
          <source>Two families of ensemble methods are usually distinguished:</source>
          <target state="translated">アンサンブル法の2つのファミリーは通常区別されます。</target>
        </trans-unit>
        <trans-unit id="e8ac95de27d48015555c5b981483208d51b8f268" translate="yes" xml:space="preserve">
          <source>Two feature extraction methods can be used in this example:</source>
          <target state="translated">本実施例では、2つの特徴抽出方法を用いることができる。</target>
        </trans-unit>
        <trans-unit id="ebb2ce8305b879c94bfe5ff4f307e7a35d679e99" translate="yes" xml:space="preserve">
          <source>Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the side of the scatter plot.</source>
          <target state="translated">各スケーラ/正規化器/変換器について2つのプロットが表示されます。左の図はデータセット全体の散布図を示し、右の図は限界外れ値を除いたデータセットの99%のみを考慮して極端な値を除外します。さらに、散布図の側面には、各特徴の限界分布が表示されます。</target>
        </trans-unit>
        <trans-unit id="d08300d20f1b41587441de06b29a0ea2e0345c8c" translate="yes" xml:space="preserve">
          <source>Two regions are populated: when the EXPERIENCE coefficient is positive the AGE one is negative and viceversa.</source>
          <target state="translated">2つの領域が存在します:EXPERIENCE係数が正の場合、AGE係数は負であり、その逆もあります。</target>
        </trans-unit>
        <trans-unit id="348f286c4d7d6b276984cd38d102dc527023a237" translate="yes" xml:space="preserve">
          <source>Two separate datasets are used for the two different plots. The reason behind this is the &lt;code&gt;l1&lt;/code&gt; case works better on sparse data, while &lt;code&gt;l2&lt;/code&gt; is better suited to the non-sparse case.</source>
          <target state="translated">2つの異なるデータセットが2つの異なるプロットに使用されます。これの背後にある理由は、 &lt;code&gt;l2&lt;/code&gt; が非スパースの場合により適しているのに対して、 &lt;code&gt;l1&lt;/code&gt; のケースはスパースデータでより適切に機能するためです。</target>
        </trans-unit>
        <trans-unit id="77c4595f573f3df24ff0cb3827f75f6aed496412" translate="yes" xml:space="preserve">
          <source>Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.</source>
          <target state="translated">変換には,分位変換と乗数変換の2種類があります.分位変換も乗数変換も,特徴量の単調変換に基づいているため,各特徴量に沿った値のランクを保持します.</target>
        </trans-unit>
        <trans-unit id="32895c2e5eacd1283051e2d5a4f1fd3f826fb6ed" translate="yes" xml:space="preserve">
          <source>Two-class AdaBoost</source>
          <target state="translated">2クラスAdaBoost</target>
        </trans-unit>
        <trans-unit id="b8fde32df7d701e50fc79883cdf21005c9469e51" translate="yes" xml:space="preserve">
          <source>Type casting</source>
          <target state="translated">タイプ鋳造</target>
        </trans-unit>
        <trans-unit id="7b90464c9a3a0593a486a1facdfd06e25cac2162" translate="yes" xml:space="preserve">
          <source>Type of SVM: C SVC, nu SVC, one class, epsilon SVR, nu SVR</source>
          <target state="translated">SVMの種類。C SVC,nu SVC,1クラス,epsilon SVR,nu SVR</target>
        </trans-unit>
        <trans-unit id="fb24034e0a15fdb11753c4c561fec377a847eca1" translate="yes" xml:space="preserve">
          <source>Type of SVM: C_SVC, NuSVC, OneClassSVM, EpsilonSVR or NuSVR respectively. 0 by default.</source>
          <target state="translated">SVMの種類。それぞれ C_SVC,NuSVC,OneClassSVM,EpsilonSVR,NuSVR。デフォルトでは0。</target>
        </trans-unit>
        <trans-unit id="05734831eef4f60aabd73eed1535149e1780b49e" translate="yes" xml:space="preserve">
          <source>Type of kernel.</source>
          <target state="translated">カーネルの種類。</target>
        </trans-unit>
        <trans-unit id="7784bde958a1d323776ea14d0478698cc397c040" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, and &amp;lsquo;distance&amp;rsquo; will return the distances between neighbors according to the given metric.</source>
          <target state="translated">返される行列のタイプ： 'connectivity'は1と0の接続性行列を返し、 'distance'は指定されたメトリックに従って近隣間の距離を返します。</target>
        </trans-unit>
        <trans-unit id="029a83801426f186d4049ef92d5f3d3590b1d125" translate="yes" xml:space="preserve">
          <source>Type of returned matrix: &amp;lsquo;connectivity&amp;rsquo; will return the connectivity matrix with ones and zeros, in &amp;lsquo;distance&amp;rsquo; the edges are Euclidean distance between points.</source>
          <target state="translated">返される行列のタイプ：「接続性」は、1と0の接続性行列を返します。「距離」では、エッジは点間のユークリッド距離です。</target>
        </trans-unit>
        <trans-unit id="e2af4c36790c9137ba49cdb815accc60f6f75311" translate="yes" xml:space="preserve">
          <source>Type of store backend for reading/writing cache files. Default: &amp;lsquo;local&amp;rsquo;. The &amp;lsquo;local&amp;rsquo; backend is using regular filesystem operations to manipulate data (open, mv, etc) in the backend.</source>
          <target state="translated">キャッシュファイルの読み取り/書き込み用のストアバックエンドのタイプ。デフォルト： 'local'。「ローカル」バックエンドは、通常のファイルシステム操作を使用して、バックエンドのデータ（open、mvなど）を操作します。</target>
        </trans-unit>
        <trans-unit id="858cba7a97e85950fd69a9661ce88f3dff1bf729" translate="yes" xml:space="preserve">
          <source>Type of the matrix returned by fit_transform() or transform().</source>
          <target state="translated">fit_transform()または transform()が返す行列の型。</target>
        </trans-unit>
        <trans-unit id="b6e792a3d08a7bd144dac10e42edb461fd3dd2e3" translate="yes" xml:space="preserve">
          <source>Type to use in computing the mean. For integer inputs, the default is &lt;code&gt;float64&lt;/code&gt;; for floating point inputs, it is the same as the input dtype.</source>
          <target state="translated">平均の計算に使用するタイプ。整数入力の場合、デフォルトは &lt;code&gt;float64&lt;/code&gt; です。浮動小数点入力の場合、入力dtypeと同じです。</target>
        </trans-unit>
        <trans-unit id="9af8f14bd15271db0f113f7c146e7fa9294b1caa" translate="yes" xml:space="preserve">
          <source>TypeError</source>
          <target state="translated">TypeError</target>
        </trans-unit>
        <trans-unit id="363cb5cb9b015bf8fe75ee8f6f3ad675ca5618cc" translate="yes" xml:space="preserve">
          <source>UNION</source>
          <target state="translated">UNION</target>
        </trans-unit>
        <trans-unit id="d609f86a64dc993cf97b5c1696e70d121d69089c" translate="yes" xml:space="preserve">
          <source>UNION_not_member</source>
          <target state="translated">UNION_not_member</target>
        </trans-unit>
        <trans-unit id="5c8cdf8bfe08e7fa632507cd27d7c4593fc32d5d" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">データがガウス分布であるという仮定の下で、Chen etal。&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;2&lt;/a&gt;は、LedoitとWolfの式で与えられたものよりも小さい平均二乗誤差を生成する収縮係数を選択することを目的とした式を導き出しました。結果として得られる推定量は、共分散のOracle ShrinkageApproximating推定量として知られています。</target>
        </trans-unit>
        <trans-unit id="f77afa338a167babd59a76b7f498d6550ba586ff" translate="yes" xml:space="preserve">
          <source>Under the assumption that the data are Gaussian distributed, Chen et al. &lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf&amp;rsquo;s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.</source>
          <target state="translated">データがガウス分布であるという仮定の下で、Chen et al。&lt;a href=&quot;#id6&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;は、レドイトとウルフの式で与えられるものよりも小さい平均二乗誤差をもたらす収縮係数を選択することを目的とした式を導き出しました。結果の推定量は、共分散のOracle Shrinkage Approximating推定量として知られています。</target>
        </trans-unit>
        <trans-unit id="b57ce0246b95ca0ff3d95c499722ea513c24180d" translate="yes" xml:space="preserve">
          <source>Underfitting vs. Overfitting</source>
          <target state="translated">アンダーフィッティングとオーバーフィッティング</target>
        </trans-unit>
        <trans-unit id="10dab5fb240281c20bb10ad043cbba82ec3b0bd6" translate="yes" xml:space="preserve">
          <source>Understanding the decision tree structure</source>
          <target state="translated">意思決定木の構造を理解する</target>
        </trans-unit>
        <trans-unit id="a381b476a1bdd0042346ffd8d02655a7131aa344" translate="yes" xml:space="preserve">
          <source>Undo the scaling of X according to feature_range.</source>
          <target state="translated">feature_rangeに応じたXのスケーリングを元に戻します。</target>
        </trans-unit>
        <trans-unit id="11b4a2e4a2b6531b9e75ad23f03f25fd4f8ecde0" translate="yes" xml:space="preserve">
          <source>Uniform weights are used by default.</source>
          <target state="translated">デフォルトでは一様な重みが使用されます。</target>
        </trans-unit>
        <trans-unit id="9421754583ed6d327fe582bef2d0e2d0f17ba0c4" translate="yes" xml:space="preserve">
          <source>Unique class labels.</source>
          <target state="translated">ユニークなクラスラベル。</target>
        </trans-unit>
        <trans-unit id="6efd4cf40567c19c24a13e3421a6d1109a47da44" translate="yes" xml:space="preserve">
          <source>Uniquely holds the label for each class.</source>
          <target state="translated">各クラスのラベルを一意に保持します。</target>
        </trans-unit>
        <trans-unit id="78bd370935302db3cfb593c9af76aeb130eb71c4" translate="yes" xml:space="preserve">
          <source>Unit Deviance \(d(y, \hat{y})\)</source>
          <target state="translated">Unit Deviance ¶(Unit Deviance)</target>
        </trans-unit>
        <trans-unit id="15f758514c6db2ef9033ee5636e4d09d40ce9747" translate="yes" xml:space="preserve">
          <source>Univariate Feature Selection</source>
          <target state="translated">一変量特徴選択</target>
        </trans-unit>
        <trans-unit id="820dda4dd874419c514343cc2737763cc18b33d1" translate="yes" xml:space="preserve">
          <source>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">一変量特徴選択は、一変量統計検定に基づいて最良の特徴を選択することによって機能します。これは、推定器の前処理ステップと見なすことができます。Scikit-learnは、機能選択ルーチンを、 &lt;code&gt;transform&lt;/code&gt; メソッドを実装するオブジェクトとして公開します。</target>
        </trans-unit>
        <trans-unit id="b943e7c2ae0f248f889b02c7d797d243c0d56e6a" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable mode.</source>
          <target state="translated">設定可能なモードを持つ一変量フィーチャセレクタ。</target>
        </trans-unit>
        <trans-unit id="05b44ce5dcc153b8702db1e0eab0c9af1fb62f9c" translate="yes" xml:space="preserve">
          <source>Univariate feature selector with configurable strategy.</source>
          <target state="translated">設定可能なストラテジーを持つ一変量特徴量セレクタ。</target>
        </trans-unit>
        <trans-unit id="049ea86cb7534beee7ca7abb3073edcde3e3d399" translate="yes" xml:space="preserve">
          <source>Univariate imputation of missing values.</source>
          <target state="translated">欠損値の一変量インputation。</target>
        </trans-unit>
        <trans-unit id="d9b7ebeeb7d99a7c69a9087085473be1721215ee" translate="yes" xml:space="preserve">
          <source>Univariate linear regression tests.</source>
          <target state="translated">一変量線形回帰検定。</target>
        </trans-unit>
        <trans-unit id="833fdc74927caa030c0f5f51bade98d55541b93d" translate="yes" xml:space="preserve">
          <source>Unlabeled entries in &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; のラベルなしエントリ</target>
        </trans-unit>
        <trans-unit id="d5f2b47c1710490958929f8f01f5858025c133e1" translate="yes" xml:space="preserve">
          <source>Unless otherwise specified, input will be cast to &lt;code&gt;float64&lt;/code&gt;:</source>
          <target state="translated">特に指定がない限り、入力は &lt;code&gt;float64&lt;/code&gt; にキャストされます。</target>
        </trans-unit>
        <trans-unit id="6027b38892a9b0df12f36988c98a41a4655ff464" translate="yes" xml:space="preserve">
          <source>Unlike &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;とは異なり、ベクトルの表現は、減算することなく、コンポーネントを重ね合わせることにより、加算的に取得されます。このような加法モデルは、画像やテキストを表現するのに効率的です。</target>
        </trans-unit>
        <trans-unit id="5817d589292c98298ab95a877d7595e724495088" translate="yes" xml:space="preserve">
          <source>Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC.</source>
          <target state="translated">SVC (LIBSVM ベース)とは異なり、LinearSVC (LIBLINEAR ベース)はサポートベクタを提供しません。この例では、LinearSVCでサポートベクトルを取得する方法を示します。</target>
        </trans-unit>
        <trans-unit id="f73d55c7488edaa74f7dc85966062a8a5be2b94b" translate="yes" xml:space="preserve">
          <source>Unlike most other scores, R^2 score may be negative (it need not actually be the square of a quantity R).</source>
          <target state="translated">他のほとんどのスコアとは異なり、R^2スコアは負の値になることがあります(実際には量Rの二乗である必要はありません)。</target>
        </trans-unit>
        <trans-unit id="fb0dd07f15380472f302743b85f6d7c3f60efb9d" translate="yes" xml:space="preserve">
          <source>Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).</source>
          <target state="translated">以前のスケーラーとは異なり、このスケーラーのセンタリングとスケーリングの統計量はパーセンタイルに基づいているため、少数の非常に大きな限界外れ値の影響を受けません。その結果、変換された特徴値の範囲は以前のスケーラーよりも大きく、より重要なことは、ほぼ同じです:両方の特徴について、ズームインされた図で見られるように、変換された値のほとんどは[-2,3]の範囲にあります。外れ値自体は、変換されたデータにまだ存在していることに注意してください。別個の外れ値のクリッピングが望ましい場合は、非線形変換が必要です(下記参照)。</target>
        </trans-unit>
        <trans-unit id="be4091e1f0941887f57bdebf1b1a9b607356f1f1" translate="yes" xml:space="preserve">
          <source>Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation.</source>
          <target state="translated">以前の変換とは異なり、正規化は特徴毎の変換ではなく、サンプル毎の変換を指します。</target>
        </trans-unit>
        <trans-unit id="1e78af54fb2d86af104fdf7cb3b33ae0e42d69f8" translate="yes" xml:space="preserve">
          <source>Unmarried</source>
          <target state="translated">Unmarried</target>
        </trans-unit>
        <trans-unit id="d6efdeaf0fd8663d7b74628a841a2a21988919e0" translate="yes" xml:space="preserve">
          <source>Unregularized graph based semi-supervised learning</source>
          <target state="translated">非正規化グラフに基づく半教師付き学習</target>
        </trans-unit>
        <trans-unit id="27bee227769f6c4dd6bbb550e3dab104adba94bb" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF)</source>
          <target state="translated">局所外れ値因子(LOF)を用いた教師なし外れ値検出</target>
        </trans-unit>
        <trans-unit id="3cf71ccf2a88f28c3a0cfcb75adfc8979981d7f4" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection using Local Outlier Factor (LOF).</source>
          <target state="translated">局所外れ値因子(LOF)を用いた教師なし外れ値検出。</target>
        </trans-unit>
        <trans-unit id="7b5353048e77b9864be0e146d8fe78c3034a09d3" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection.</source>
          <target state="translated">教師なし外れ値検出</target>
        </trans-unit>
        <trans-unit id="a2eb50b9e0078078696dd41ce50d788a5cac282f" translate="yes" xml:space="preserve">
          <source>Unsupervised Outlier Detection. Estimate the support of a high-dimensional distribution. The implementation is based on libsvm.</source>
          <target state="translated">教師なし外れ値検出 高次元分布のサポートを推定します。実装はlibsvmをベースにしています。</target>
        </trans-unit>
        <trans-unit id="091dbb252c60dafbec16ee540eb9588c7d736a5b" translate="yes" xml:space="preserve">
          <source>Unsupervised learner for implementing neighbor searches.</source>
          <target state="translated">隣接探索を実装するための教師なし学習器</target>
        </trans-unit>
        <trans-unit id="336bcbb510eed89e13ba021c352635cdc0677016" translate="yes" xml:space="preserve">
          <source>Unsupervised learning: seeking representations of the data</source>
          <target state="translated">教師なし学習:データの表現を求める</target>
        </trans-unit>
        <trans-unit id="568c5820f9e5362ca266c9125e695403019435a8" translate="yes" xml:space="preserve">
          <source>Unused parameter.</source>
          <target state="translated">未使用のパラメータです。</target>
        </trans-unit>
        <trans-unit id="207a5be036cc811b3313bce86d86c7d5b4302176" translate="yes" xml:space="preserve">
          <source>Update k means estimate on a single mini-batch X.</source>
          <target state="translated">更新kは、単一のミニバッチXでの推定を意味します。</target>
        </trans-unit>
        <trans-unit id="08230ffcab1953eb1050f05815a03e0d48694ae9" translate="yes" xml:space="preserve">
          <source>Update the model with a single iteration over the given data.</source>
          <target state="translated">与えられたデータに対して1回の反復でモデルを更新します。</target>
        </trans-unit>
        <trans-unit id="718430f889e80a3494a47ee7bec5ca3329673e5e" translate="yes" xml:space="preserve">
          <source>Updated feature-wise means.</source>
          <target state="translated">機能的に更新されたということ。</target>
        </trans-unit>
        <trans-unit id="4f10d24907ba29eca99bd941c7ead98539a4f5b4" translate="yes" xml:space="preserve">
          <source>Updated feature-wise variances.</source>
          <target state="translated">機能別の差異を更新しました。</target>
        </trans-unit>
        <trans-unit id="693a7de21c7466734e7ffa03c5ae997209e7997d" translate="yes" xml:space="preserve">
          <source>Updated number of seen samples.</source>
          <target state="translated">見られたサンプル数を更新しました。</target>
        </trans-unit>
        <trans-unit id="410e0e09369f3d862bca36022b47e478be0933f7" translate="yes" xml:space="preserve">
          <source>Updates the model using the data in X as a mini-batch.</source>
          <target state="translated">Xのデータをミニバッチとして使用してモデルを更新します。</target>
        </trans-unit>
        <trans-unit id="93ec1aa11f1be18275b029134004fd1ab02c997f" translate="yes" xml:space="preserve">
          <source>Upper bound on a uniform noise parameter to be added to the &lt;code&gt;y&lt;/code&gt; values, to satisfy the model&amp;rsquo;s assumption of one-at-a-time computations. Might help with stability.</source>
          <target state="translated">モデルの一度に1つずつの計算の仮定を満たすために、 &lt;code&gt;y&lt;/code&gt; 値に追加される均一なノイズパラメーターの上限。安定性に役立つ可能性があります。</target>
        </trans-unit>
        <trans-unit id="07333ba49211f5c72e60dfd1b7f4f04d69ceed93" translate="yes" xml:space="preserve">
          <source>Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.</source>
          <target state="translated">予測値の最大値の上限(最大値はまだ低いかもしれません)。設定されていない場合、デフォルトは+inf.</target>
        </trans-unit>
        <trans-unit id="48b5dd5eaa54e931a34dd1d6396ec1c9d66da80b" translate="yes" xml:space="preserve">
          <source>Urbanowicz R.J., Moore, J.H. &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0: description and evaluation of a scalable learning classifier system&lt;/a&gt;, Evol. Intel. (2015) 8: 89.</source>
          <target state="translated">Urbanowicz RJ、ムーア、JH &lt;a href=&quot;https://doi.org/10.1007/s12065-015-0128-8&quot;&gt;ExSTraCS 2.0：スケーラブルな学習分類システム&lt;/a&gt; Evolの説明と評価。インテル。（2015）8：89。</target>
        </trans-unit>
        <trans-unit id="fec43ce445f974147bd0eb223a50147e7fb7202d" translate="yes" xml:space="preserve">
          <source>Usage example:</source>
          <target state="translated">使用例。</target>
        </trans-unit>
        <trans-unit id="173610cb31251b28e80fadc258036215d99d7128" translate="yes" xml:space="preserve">
          <source>Usage examples:</source>
          <target state="translated">使用例。</target>
        </trans-unit>
        <trans-unit id="272998fc40498f57127bf4e7cf71805cd53c9500" translate="yes" xml:space="preserve">
          <source>Use 0 when &lt;code&gt;Y&lt;/code&gt; contains the output of decision_function (classifier). Use 0.5 when &lt;code&gt;Y&lt;/code&gt; contains the output of predict_proba.</source>
          <target state="translated">&lt;code&gt;Y&lt;/code&gt; にDecision_function（分類器）の出力が含まれている場合は0を使用します。 &lt;code&gt;Y&lt;/code&gt; にpredict_probaの出力が含まれる場合は、0.5を使用します。</target>
        </trans-unit>
        <trans-unit id="cf1718d68df5d7e88cb5c515bd9f0d9c1cb19546" translate="yes" xml:space="preserve">
          <source>Use &lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt; clustering in conjunction with the &lt;code&gt;extract_dbscan&lt;/code&gt; method. OPTICS clustering also calculates the full pairwise matrix, but only keeps one row in memory at a time (memory complexity n).</source>
          <target state="translated">&lt;code&gt;extract_dbscan&lt;/code&gt; メソッドと組み合わせて&lt;a href=&quot;#optics&quot;&gt;OPTICS&lt;/a&gt;クラスタリングを使用します。OPTICSクラスタリングも完全なペアワイズ行列を計算しますが、一度に1行のみをメモリに保持します（メモリの複雑さn）。</target>
        </trans-unit>
        <trans-unit id="f7e4377e83d25be8830adecce4de8c2384ca00b7" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by data types</source>
          <target state="translated">データ型で列を選択して &lt;code&gt;ColumnTransformer&lt;/code&gt; を使用する</target>
        </trans-unit>
        <trans-unit id="e21d1ee32a85ffa963b44a044a8fb65d4d276f52" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;ColumnTransformer&lt;/code&gt; by selecting column by names</source>
          <target state="translated">名前で列を選択して &lt;code&gt;ColumnTransformer&lt;/code&gt; を使用する</target>
        </trans-unit>
        <trans-unit id="e620712d1a8872ff21d8a3d8ca61cf7867c4f8c8" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;min_samples_split&lt;/code&gt; or &lt;code&gt;min_samples_leaf&lt;/code&gt; to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try &lt;code&gt;min_samples_leaf=5&lt;/code&gt; as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While &lt;code&gt;min_samples_split&lt;/code&gt; can create arbitrarily small leaves, &lt;code&gt;min_samples_leaf&lt;/code&gt; guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, &lt;code&gt;min_samples_leaf=1&lt;/code&gt; is often the best choice.</source>
          <target state="translated">&lt;code&gt;min_samples_split&lt;/code&gt; または &lt;code&gt;min_samples_leaf&lt;/code&gt; を使用して、どのスプリットが考慮されるかを制御することにより、複数のサンプルがツリー内のすべての決定に通知するようにします。非常に小さい数は、通常、ツリーがオーバーフィットすることを意味しますが、大きい数は、ツリーがデータを学習するのを妨げます。初期値として &lt;code&gt;min_samples_leaf=5&lt;/code&gt; を試してください。サンプルサイズが大きく異なる場合、これらの2つのパラメーターで浮動小数点数をパーセンテージとして使用できます。一方で &lt;code&gt;min_samples_split&lt;/code&gt; は、任意の小さな葉を作成することができ、 &lt;code&gt;min_samples_leaf&lt;/code&gt; は、各リーフは、低分散、回帰問題におけるオーバーフィットリーフノードを避け、最小サイズを持っていることを保証します。クラスが少ない分類の場合、 &lt;code&gt;min_samples_leaf=1&lt;/code&gt; 多くの場合、最良の選択です。</target>
        </trans-unit>
        <trans-unit id="3429b333ce93c8bae91a85fe794f080132090825" translate="yes" xml:space="preserve">
          <source>Use &lt;code&gt;negative_outlier_factor_&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;negative_outlier_factor_&lt;/code&gt; を使用します</target>
        </trans-unit>
        <trans-unit id="7760fd58346bed0a2b559e055012bd8a21868552" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the Boston dataset.</source>
          <target state="translated">SelectFromModelメタ変換器をLassoと一緒に使用して、ボストンのデータセットから最良の特徴のカップルを選択します。</target>
        </trans-unit>
        <trans-unit id="054f12ffb2d5e13349a9508049b7a257d7468dbe" translate="yes" xml:space="preserve">
          <source>Use SelectFromModel meta-transformer along with Lasso to select the best couple of features from the diabetes dataset.</source>
          <target state="translated">SelectFromModelメタ変換器をLassoと一緒に使用して、糖尿病データセットから最も良い特徴のカップルを選択します。</target>
        </trans-unit>
        <trans-unit id="71685d673fcc400f8aa4ec7ef3e4a61bf3bbf5f7" translate="yes" xml:space="preserve">
          <source>Use approximate bound as score.</source>
          <target state="translated">近似境界をスコアとして使用します。</target>
        </trans-unit>
        <trans-unit id="400d526bc775314ded26ebb1519045ccc0979588" translate="yes" xml:space="preserve">
          <source>Use density = 1 / 3.0 if you want to reproduce the results from Achlioptas, 2001.</source>
          <target state="translated">Achlioptas,2001の結果を再現したい場合は、密度=1/3.0を使用してください。</target>
        </trans-unit>
        <trans-unit id="38fb3c866f165060e0d95ec1a873c702ff2c91dc" translate="yes" xml:space="preserve">
          <source>Use only on new data</source>
          <target state="translated">新しいデータのみに使用</target>
        </trans-unit>
        <trans-unit id="0eb6d7f6360fc3b257840e6d0ece909142d961e3" translate="yes" xml:space="preserve">
          <source>Use splitting criteria that compute the average reduction across all n outputs.</source>
          <target state="translated">すべての n 出力の平均削減量を計算する分割基準を使用します。</target>
        </trans-unit>
        <trans-unit id="d4a5711bd46bd2a4542a66497bb7f3342ea23a7f" translate="yes" xml:space="preserve">
          <source>Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the &lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; estimator.</source>
          <target state="translated">赤池情報量基準（AIC）、ベイズ情報量基準（BIC）および交差&lt;a href=&quot;../../modules/linear_model#lasso&quot;&gt;検定&lt;/a&gt;を使用して、ラッソ推定器の正則化パラメーターalphaの最適値を選択します。</target>
        </trans-unit>
        <trans-unit id="35f6c244b8fd2da4794beb17214246bc1c30610f" translate="yes" xml:space="preserve">
          <source>Usecase</source>
          <target state="translated">Usecase</target>
        </trans-unit>
        <trans-unit id="4ea5661d3bd8912bbf2723a42ab4c0cf1ece7994" translate="yes" xml:space="preserve">
          <source>Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">辞書学習中に使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="1bc010bd367bf6cb9590a9c8e8bd3ff37b7e270c" translate="yes" xml:space="preserve">
          <source>Used during randomized svd. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">ランダム化されたsvd中に使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="85ae15952ef1b8cedfa1ed0f0a5091e5742f9b4a" translate="yes" xml:space="preserve">
          <source>Used for NMF initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">NMFの初期化（ &lt;code&gt;init&lt;/code&gt; == 'nndsvdar'または 'random'の場合）、および座標降下法で使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="15383d0945f438ddc1d77fc1ae0921de1e717777" translate="yes" xml:space="preserve">
          <source>Used for VotingClassifier</source>
          <target state="translated">VotingClassifier に使用されます。</target>
        </trans-unit>
        <trans-unit id="06c1133b6cf5dee9bc1f27b86d9cca1c046fd5c1" translate="yes" xml:space="preserve">
          <source>Used for initialisation (when &lt;code&gt;init&lt;/code&gt; == &amp;lsquo;nndsvdar&amp;rsquo; or &amp;lsquo;random&amp;rsquo;), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">初期化（ &lt;code&gt;init&lt;/code&gt; == 'nndsvdar'または 'random'の場合）および座標降下法で使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="a4845a789add1f32681ae6a68b7dba0e6bdbe2af" translate="yes" xml:space="preserve">
          <source>Used for initializing the dictionary when &lt;code&gt;dict_init&lt;/code&gt; is not specified, randomly shuffling the data when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;dict_init&lt;/code&gt; が指定されていない場合の辞書の初期化、 &lt;code&gt;shuffle&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合のデータのランダムなシャッフル、および辞書の更新に使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="2d6d1bb4bf090f9031a078f80f81b5cfa346c5fb" translate="yes" xml:space="preserve">
          <source>Used for internal caching. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">内部キャッシュに使用します。デフォルトでは、キャッシュは行われません。文字列が与えられた場合は、それがキャッシュディレクトリへのパスとなります。</target>
        </trans-unit>
        <trans-unit id="78a755bf17a9d084d2f5bc3468af8892921b3298" translate="yes" xml:space="preserve">
          <source>Used for random shuffling when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">オンライン辞書学習中に、 &lt;code&gt;shuffle&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合のランダムシャッフルに使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="a659f5ae4cfedf0686976ca2f311fa3c53dbc2ce" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">特異値分解とk-means初期化をランダム化するために使用されます。intを使用して、ランダム性を決定論的にします。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="b3bb1fd38ab7b6b511c90e9e3f961817f7b29fe6" translate="yes" xml:space="preserve">
          <source>Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">特異値分解とk-means初期化をランダム化するために使用されます。intを使用して、ランダム性を決定論的にします。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="ad6bfb2aef10b93bd4ad8fd792d19a69ba0f50a9" translate="yes" xml:space="preserve">
          <source>Used for randomly initializing the dictionary. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">辞書をランダムに初期化するために使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="e0ee2dc12a427741bfbfa29dc3b32d1b1d854da3" translate="yes" xml:space="preserve">
          <source>Used for shuffling the data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;shuffle&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合に、データをシャッフルするために使用されます。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="04206996c9eca941c8da97d474cf5a147f4b8713" translate="yes" xml:space="preserve">
          <source>Used to cache the fitted transformers of the pipeline. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute &lt;code&gt;named_steps&lt;/code&gt; or &lt;code&gt;steps&lt;/code&gt; to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming.</source>
          <target state="translated">パイプラインの取り付けられたトランスフォーマーをキャッシュするために使用されます。デフォルトでは、キャッシングは実行されません。文字列が指定されている場合、それはキャッシュディレクトリへのパスです。キャッシングを有効にすると、フィッティングの前にトランスフォーマーのクローンがトリガーされます。したがって、パイプラインに渡されたトランスフォーマーインスタンスを直接検査することはできません。属性 &lt;code&gt;named_steps&lt;/code&gt; または &lt;code&gt;steps&lt;/code&gt; を使用して、パイプライン内の推定量を検査します。フィッティングに時間がかかる場合は、トランスフォーマーのキャッシングが有利です。</target>
        </trans-unit>
        <trans-unit id="b831b0ccc618367ad6990c063d4f6b68c21b54a0" translate="yes" xml:space="preserve">
          <source>Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.</source>
          <target state="translated">ツリーの計算の出力をキャッシュするために使用します。デフォルトでは、キャッシュは行われません。文字列が与えられた場合は、キャッシュディレクトリへのパスとなります。</target>
        </trans-unit>
        <trans-unit id="5b58434a86ea5888954537c341361956c0e8c395" translate="yes" xml:space="preserve">
          <source>Used to determine when to &amp;ldquo;early stop&amp;rdquo;. The fitting process is stopped when none of the last &lt;code&gt;n_iter_no_change&lt;/code&gt; scores are better than the &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; -th-to-last one, up to some tolerance. Only used if early stopping is performed.</source>
          <target state="translated">「早期停止」の時期を決定するために使用されます。最後の &lt;code&gt;n_iter_no_change&lt;/code&gt; スコアのいずれもn_iter_no_change（最後から &lt;code&gt;n_iter_no_change - 1&lt;/code&gt; 番目のスコア）よりも優れている場合は、ある程度の許容範囲まで、フィッティングプロセスが停止します。早期停止が実行された場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="9462556717c7577fff4ef47d9f5dcd20523f1516" translate="yes" xml:space="preserve">
          <source>Used to initialize &lt;code&gt;w_init&lt;/code&gt; when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">指定されていない場合、正規分布で &lt;code&gt;w_init&lt;/code&gt; を初期化するために使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るために、intを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="f19cda342b4acf0d93861aea53bc9a6ea559de82" translate="yes" xml:space="preserve">
          <source>Used to pick randomly the &lt;code&gt;max_features&lt;/code&gt; used at each split. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">各分割で使用される &lt;code&gt;max_features&lt;/code&gt; をランダムに選択するために使用されます。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="605a4bcc1f5d9a0fe3ef69215d05c4963e05e516" translate="yes" xml:space="preserve">
          <source>Used to shuffle the training data, when &lt;code&gt;shuffle&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;shuffle&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合に、トレーニングデータをシャッフルするために使用されます。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="ec2d1021c796c8396406488bdd5b004de6014166" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties.</source>
          <target state="translated">ペナルティで使用される基準を指定するために使用されます。'newton-cg'、 'sag'、および 'lbfgs'ソルバーは、l2ペナルティのみをサポートします。</target>
        </trans-unit>
        <trans-unit id="5860deefa3fd6b4c16483df037c0ad7cd840b1dc" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="translated">ペナルティで使用される基準を指定するために使用されます。'newton-cg'、 'sag'、および 'lbfgs'ソルバーは、l2ペナルティのみをサポートします。「elasticnet」は「saga」ソルバーでのみサポートされます。</target>
        </trans-unit>
        <trans-unit id="f2cadba66c38ca766b85abc4b1e03568d1fa6dab" translate="yes" xml:space="preserve">
          <source>Used to specify the norm used in the penalization. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers support only l2 penalties. &amp;lsquo;elasticnet&amp;rsquo; is only supported by the &amp;lsquo;saga&amp;rsquo; solver. If &amp;lsquo;none&amp;rsquo; (not supported by the liblinear solver), no regularization is applied.</source>
          <target state="translated">ペナルティで使用される基準を指定するために使用されます。'newton-cg'、 'sag'、および 'lbfgs'ソルバーは、l2ペナルティのみをサポートします。「elasticnet」は「saga」ソルバーでのみサポートされます。'none'（liblinearソルバーでサポートされていない）の場合、正則化は適用されません。</target>
        </trans-unit>
        <trans-unit id="90efd63a8d51063de92a896b88cf64deaa03a244" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;eigen_solver&lt;/code&gt; == 'arpack'の場合に使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="27dcb202bde84d98eaa9b02f62b647ecce32aaba" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;shuffle&lt;/code&gt; is True. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;shuffle&lt;/code&gt; がTrueの場合に使用されます。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="8694b55c04737ba18ec4ec98388e9997e16f39ac" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo; or &amp;lsquo;saga&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">&lt;code&gt;solver&lt;/code&gt; == 'sag'または 'saga'の場合に使用して、データをシャッフルします。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="59bf45c1d50e7570f6107bdd3616f32c93f002ed" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">ときに使用し &lt;code&gt;solver&lt;/code&gt; ==「サグ」、「サガ」や「liblinear」のデータをシャッフルします。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e6070822f60356161845953fee6c5bfe74cf5d59" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;solver='sag'&lt;/code&gt;, &amp;lsquo;saga&amp;rsquo; or &amp;lsquo;liblinear&amp;rsquo; to shuffle the data. Note that this only applies to the solver and not the cross-validation generator. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">&lt;code&gt;solver='sag'&lt;/code&gt; 、 'saga'、または 'liblinear'の場合に使用して、データをシャッフルします。これはソルバーにのみ適用され、相互検証ジェネレーターには適用されないことに注意してください。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="f152cc191601223884f2e892b0e88e2ae399e550" translate="yes" xml:space="preserve">
          <source>Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;svd_solver&lt;/code&gt; == 'arpack'または 'randomized'の場合に使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5a789f5832dbb34972e6ab11f85f2125e32dddce" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">回帰問題で非線形変換を適用するのに役立ちます。この変換は、QuantileTransformerなどのTransformerとして、または &lt;code&gt;log&lt;/code&gt; や &lt;code&gt;exp&lt;/code&gt; などの関数とその逆として指定できます。</target>
        </trans-unit>
        <trans-unit id="74349d111804f80e1a38097923f8879dfbcca7b0" translate="yes" xml:space="preserve">
          <source>Useful for applying a non-linear transformation to the target &lt;code&gt;y&lt;/code&gt; in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;exp&lt;/code&gt;.</source>
          <target state="translated">回帰問題でターゲット &lt;code&gt;y&lt;/code&gt; に非線形変換を適用するのに役立ちます。この変換は、QuantileTransformerなどのTransformerとして、または関数と &lt;code&gt;log&lt;/code&gt; や &lt;code&gt;exp&lt;/code&gt; などの逆関数として指定できます。</target>
        </trans-unit>
        <trans-unit id="665be16622d5dce4c265443eced33f5309efed0f" translate="yes" xml:space="preserve">
          <source>Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.</source>
          <target state="translated">newton-cg,sag,lbfgsソルバーでのみ有効です。ソルバーが収束するために必要な最大反復回数.</target>
        </trans-unit>
        <trans-unit id="1f7081fc6e8837c157dbcac4dfe150624d77daa3" translate="yes" xml:space="preserve">
          <source>Useful only when the solver &amp;lsquo;liblinear&amp;rsquo; is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt;.</source>
          <target state="translated">ソルバー「liblinear」が使用され、self.fit_interceptがTrueに設定されている場合にのみ役立ちます。この場合、xは[x、self.intercept_scaling]になります。つまり、intercept_scalingに等しい定数値を持つ「合成」機能がインスタンスベクトルに追加されます。切片は &lt;code&gt;intercept_scaling * synthetic_feature_weight&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="cb4f9242d2c5bef801309a7b11564e9f2917779f" translate="yes" xml:space="preserve">
          <source>Useful tutorials for developing a feel for some of scikit-learn's applications in the machine learning field.</source>
          <target state="translated">機械学習分野でのscikit-learnのアプリケーションのいくつかの使用感を開発するための有用なチュートリアルです。</target>
        </trans-unit>
        <trans-unit id="bec249e659662f7d5947bf09a1ea1d4a552885b0" translate="yes" xml:space="preserve">
          <source>User Guide</source>
          <target state="translated">ユーザーガイド</target>
        </trans-unit>
        <trans-unit id="221a6dc59fa62390ffe53703a42fa985bbe3d0ea" translate="yes" xml:space="preserve">
          <source>Uses &lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt;&lt;code&gt;ParameterGrid&lt;/code&gt;&lt;/a&gt; to perform a full parallelized parameter search.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.model_selection.ParameterGrid&quot;&gt; &lt;code&gt;ParameterGrid&lt;/code&gt; &lt;/a&gt;を使用して、完全に並列化されたパラメーター検索を実行します。</target>
        </trans-unit>
        <trans-unit id="32b4edc9350cb6d93cc0316d635ce26e35fa63d2" translate="yes" xml:space="preserve">
          <source>Uses BLAS GEMM as replacement for numpy.dot where possible to avoid unnecessary copies.</source>
          <target state="translated">不必要なコピーを避けるため、可能な限り numpy.dot の代わりに BLAS GEMM を使用します。</target>
        </trans-unit>
        <trans-unit id="ac4bd4f4f631e790604905794abbd6ed09d66803" translate="yes" xml:space="preserve">
          <source>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.</source>
          <target state="translated">決定関数(サポートベクタと呼ばれる)で訓練点のサブセットを使用するので、メモリ効率も良い。</target>
        </trans-unit>
        <trans-unit id="4a4b56e0bea50fff706430a1a94289a4e5e03040" translate="yes" xml:space="preserve">
          <source>Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.</source>
          <target state="translated">ホワイトボックスモデルを使用しています。モデルの中で、ある状況が観測可能な場合、条件の説明はブール論理で簡単に説明できる。対照的に、ブラックボックスモデル(人工ニューラルネットワークなど)では、結果を解釈するのが難しい場合があります。</target>
        </trans-unit>
        <trans-unit id="ced5d25baa7aaf39837296d764096d52eb67f5ca" translate="yes" xml:space="preserve">
          <source>Uses sampling the fourier transform of the kernel characteristic at regular intervals.</source>
          <target state="translated">カーネル特性のフーリエ変換のサンプリングを一定間隔で使用します。</target>
        </trans-unit>
        <trans-unit id="2c633fc259072170ae02b4cf8b2266258b09ddc5" translate="yes" xml:space="preserve">
          <source>Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).</source>
          <target state="translated">はめ込み (または fit_transform)で学習した語彙 ・ 文書度数 (df)を用います。</target>
        </trans-unit>
        <trans-unit id="cdea6e25f0fe24b03bf907dbf26253d4f40a11df" translate="yes" xml:space="preserve">
          <source>Using &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; or &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; enables the &lt;code&gt;predict_proba&lt;/code&gt; method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):</source>
          <target state="translated">使用 &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; 又は &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; 可能 &lt;code&gt;predict_proba&lt;/code&gt; の確率推定\（P（Y | X）\）のベクトルが得られる方法であって、サンプルあたり\（xは\）。</target>
        </trans-unit>
        <trans-unit id="4072d118d17ebbe341d060ec8f347bb287543668" translate="yes" xml:space="preserve">
          <source>Using FunctionTransformer to select columns</source>
          <target state="translated">FunctionTransformerを使用して列を選択する</target>
        </trans-unit>
        <trans-unit id="af570039f4e6335c176e5a0ced20f61ade37ec58" translate="yes" xml:space="preserve">
          <source>Using KBinsDiscretizer to discretize continuous features</source>
          <target state="translated">KBinsDiscretizerを使用して連続的な特徴を離散化する</target>
        </trans-unit>
        <trans-unit id="58dd6560cd1dd1ff16a956c31444ffff4530a294" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more feature are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; 提供されるL1 ペナルティを使用すると、スパースソリューションが得られます。つまり、フィーチャの重みのサブセットのみがゼロとは異なり、決定関数に寄与します。 &lt;code&gt;C&lt;/code&gt; を増やすと、より複雑なモデルが生成されます（より多くの機能が選択されます）。 &lt;code&gt;C&lt;/code&gt; の「ヌル」モデルが得られる値は（すべての重みがゼロに等しい）を用いて算出することができる&lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="927a462bb89282ccdc19c70530472008783e5ed5" translate="yes" xml:space="preserve">
          <source>Using L1 penalization as provided by &lt;code&gt;LinearSVC(loss='l2', penalty='l1',
dual=False)&lt;/code&gt; yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing &lt;code&gt;C&lt;/code&gt; yields a more complex model (more features are selected). The &lt;code&gt;C&lt;/code&gt; value that yields a &amp;ldquo;null&amp;rdquo; model (all weights equal to zero) can be calculated using &lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt;&lt;code&gt;l1_min_c&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;LinearSVC(loss='l2', penalty='l1', dual=False)&lt;/code&gt; によって提供されるL1ペナルティを使用すると、スパース解が得られます。つまり、特徴の重みのサブセットのみがゼロとは異なり、決定関数に寄与します。 &lt;code&gt;C&lt;/code&gt; を増やすと、より複雑なモデルが生成されます（より多くの機能が選択されます）。 &lt;code&gt;C&lt;/code&gt; の「ヌル」モデルが得られる値は（すべての重みがゼロに等しい）を用いて算出することができる&lt;a href=&quot;generated/sklearn.svm.l1_min_c#sklearn.svm.l1_min_c&quot;&gt; &lt;code&gt;l1_min_c&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="757f15a3dfafa1d1e98a6f1f457c43151b4efe0d" translate="yes" xml:space="preserve">
          <source>Using LDA and QDA requires computing the log-posterior which depends on the class priors \(P(y=k)\), the class means \(\mu_k\), and the covariance matrices.</source>
          <target state="translated">LDAとQDAを使用するには、クラスの前任者とクラスの手段と共分散行列に依存する log-posteriorを計算する必要があります。</target>
        </trans-unit>
        <trans-unit id="0033ecf2999fee9c8f71baf5ea186698e26a6aa1" translate="yes" xml:space="preserve">
          <source>Using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; without cache enabled, it is possible to inspect the original instance such as:</source>
          <target state="translated">使用して&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;キャッシュが有効にせずに、そのような元のインスタンスを検査することができます。</target>
        </trans-unit>
        <trans-unit id="8841876aa584e88fcc31f689448303a79af806c4" translate="yes" xml:space="preserve">
          <source>Using a first-order Taylor approximation, the value of \(l\) can be approximated as follows:</source>
          <target state="translated">一次テイラー近似を用いると、\(l\)の値は次のように近似できる。</target>
        </trans-unit>
        <trans-unit id="4b38a6f3576ed137cc4e9a9f59798fb707d4dde4" translate="yes" xml:space="preserve">
          <source>Using a single underlying feature the model learns both the x and y coordinate as output.</source>
          <target state="translated">1つの基本的な特徴量を使用して、モデルは出力としてxとyの両方の座標を学習します。</target>
        </trans-unit>
        <trans-unit id="6d5ea28ea8efb863c08e76177dc50acce9324f64" translate="yes" xml:space="preserve">
          <source>Using a small &lt;code&gt;max_features&lt;/code&gt; value can significantly decrease the runtime.</source>
          <target state="translated">小さい &lt;code&gt;max_features&lt;/code&gt; 値を使用すると、実行時間を大幅に短縮できます。</target>
        </trans-unit>
        <trans-unit id="07d5b2f6d48114d6bc5306f53b2bbecb12f93559" translate="yes" xml:space="preserve">
          <source>Using a sub-pipeline, the fitted coefficients can be mapped back into the original feature space.</source>
          <target state="translated">サブパイプラインを使用して、フィットした係数を元の特徴空間にマッピングし直すことができます。</target>
        </trans-unit>
        <trans-unit id="03c1a9468c05dba06aec630e70cb3912379c2cb0" translate="yes" xml:space="preserve">
          <source>Using its &lt;code&gt;partial_fit&lt;/code&gt; method on chunks of data fetched sequentially from the local hard drive or a network database.</source>
          <target state="translated">ローカルハードドライブまたはネットワークデータベースから順次フェッチされたデータのチャンクに対して、 &lt;code&gt;partial_fit&lt;/code&gt; メソッドを使用します。</target>
        </trans-unit>
        <trans-unit id="ee5e8e298a940fdf98e8e52d2f16edd9327907f7" translate="yes" xml:space="preserve">
          <source>Using kernels</source>
          <target state="translated">カーネルの使用</target>
        </trans-unit>
        <trans-unit id="9cfba89ca182507cccdcf4094af12bc5a4c62801" translate="yes" xml:space="preserve">
          <source>Using orthogonal matching pursuit for recovering a sparse signal from a noisy measurement encoded with a dictionary</source>
          <target state="translated">辞書で符号化されたノイズの多い測定値から疎な信号を回復するための直交マッチング追求の利用</target>
        </trans-unit>
        <trans-unit id="24a0ae926e510d4f01c040899e37f954b1d9b717" translate="yes" xml:space="preserve">
          <source>Using pre_dispatch in a producer/consumer situation, where the data is generated on the fly. Note how the producer is first called 3 times before the parallel loop is initiated, and then called to generate new data on the fly:</source>
          <target state="translated">プロデューサ/消費者の状況でpre_dispatchを使用して、データをオンザフライで生成します。並列ループが開始される前に、プロデューサーが最初に3回呼び出され、次に呼び出されて新しいデータがオンザフライで生成されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="efd1182f39233190c4734b5ce34b9cfcf1bbe0bb" translate="yes" xml:space="preserve">
          <source>Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.</source>
          <target state="translated">t-SNEの利用.機械学習研究 9:2579-2605,2008.</target>
        </trans-unit>
        <trans-unit id="52758be5ab8f6ab028b2bf9ad6db5d2b69896663" translate="yes" xml:space="preserve">
          <source>Using the &lt;code&gt;TfidfTransformer&lt;/code&gt;&amp;rsquo;s default settings, &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as</source>
          <target state="translated">&lt;code&gt;TfidfTransformer&lt;/code&gt; のデフォルト設定を使用して、 &lt;code&gt;TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)&lt;/code&gt; 用語の頻度、特定のドキュメントで用語が出現する回数、にidfコンポーネントが乗算されます。これは次のように計算されます</target>
        </trans-unit>
        <trans-unit id="95d62a973e97428e1fb3d7b86f3a392143b00b8c" translate="yes" xml:space="preserve">
          <source>Using the GraphicalLasso estimator to learn a covariance and sparse precision from a small number of samples.</source>
          <target state="translated">GraphicalLasso estimatorを使用して、少ないサンプル数から共分散と疎な精度を学習します。</target>
        </trans-unit>
        <trans-unit id="f9e94a3c6c72e38b7c72fe500879db6b6bb31872" translate="yes" xml:space="preserve">
          <source>Using the Iris dataset, we can construct a tree as follows:</source>
          <target state="translated">Irisデータセットを用いて、以下のようなツリーを構築することができる。</target>
        </trans-unit>
        <trans-unit id="99fdc1f5bc1cbf237a61e42fe43157752d29d604" translate="yes" xml:space="preserve">
          <source>Using the Poisson loss with a log-link can correct these problems and lead to a well-calibrated linear model.</source>
          <target state="translated">ポアソン損失を対数リンクで使用することで、これらの問題を修正し、十分に校正された線形モデルを得ることができます。</target>
        </trans-unit>
        <trans-unit id="f990799abb31a15673ef02f50b5506399075290a" translate="yes" xml:space="preserve">
          <source>Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:</source>
          <target state="translated">この期待値を用いて、調整後の相互情報は、調整後のランド指数と同様の形式で算出することができます。</target>
        </trans-unit>
        <trans-unit id="525fdffa79943fda791ea83f2bc571cbb29e45c1" translate="yes" xml:space="preserve">
          <source>Using the naive conditional independence assumption that</source>
          <target state="translated">というナイーブな条件独立性の仮定を用いて</target>
        </trans-unit>
        <trans-unit id="ded2353583b49d229cc248063161251fcd75da59" translate="yes" xml:space="preserve">
          <source>Using the prediction pipeline in a grid search</source>
          <target state="translated">グリッド検索での予測パイプラインの使用</target>
        </trans-unit>
        <trans-unit id="4b65de55e2dd198ac6e2aecd67614d2f3e1d68d9" translate="yes" xml:space="preserve">
          <source>Using the results of the previous exercises and the &lt;code&gt;cPickle&lt;/code&gt; module of the standard library, write a command line utility that detects the language of some text provided on &lt;code&gt;stdin&lt;/code&gt; and estimate the polarity (positive or negative) if the text is written in English.</source>
          <target state="translated">前の演習の結果と標準ライブラリの &lt;code&gt;cPickle&lt;/code&gt; モジュールを使用して、 &lt;code&gt;stdin&lt;/code&gt; で提供されるテキストの言語を検出し、テキストが英語で書かれている場合は極性（正または負）を推定するコマンドラインユーティリティを記述します。</target>
        </trans-unit>
        <trans-unit id="271df6087c1c40487d3dd610dcce2afcb5a005f8" translate="yes" xml:space="preserve">
          <source>Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:</source>
          <target state="translated">この修正を用いて、文書1の第3項のtf-idfは1.8473に変更される。</target>
        </trans-unit>
        <trans-unit id="a81923715d05cfae1b7290021e8d9f8915c03011" translate="yes" xml:space="preserve">
          <source>Usually the Normalized Discounted Cumulative Gain (NDCG, computed by ndcg_score) is preferred.</source>
          <target state="translated">通常、正規化割引累積利得(NDCG、NDCG_scoreによって計算される)が好ましい。</target>
        </trans-unit>
        <trans-unit id="35033b7b1c0300bd76803da2e755fdbe07a7c28b" translate="yes" xml:space="preserve">
          <source>Utilities from joblib:</source>
          <target state="translated">joblibのユーティリティ。</target>
        </trans-unit>
        <trans-unit id="c9ee5681d3c59f7541c27a38b67edf46259e187b" translate="yes" xml:space="preserve">
          <source>V</source>
          <target state="translated">V</target>
        </trans-unit>
        <trans-unit id="8d1950c14bc870de437b37f806aaa51c635a9ec3" translate="yes" xml:space="preserve">
          <source>V measure</source>
          <target state="translated">Vメジャー</target>
        </trans-unit>
        <trans-unit id="a6ed7787c295565530f8c589d9ab12370f5f5b3d" translate="yes" xml:space="preserve">
          <source>V or VI</source>
          <target state="translated">VまたはVI</target>
        </trans-unit>
        <trans-unit id="e659ac0cd03fda8c2776727471548e055d6ecaa7" translate="yes" xml:space="preserve">
          <source>V-Measure (NMI with arithmetic mean option.)</source>
          <target state="translated">Vメジャー (算術平均オプション付きNMI)</target>
        </trans-unit>
        <trans-unit id="893c35d89ea6a5c89935fd8eeed462af4410524f" translate="yes" xml:space="preserve">
          <source>V-Measure is furthermore symmetric: swapping &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;label_pred&lt;/code&gt; will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to &lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt;&lt;code&gt;normalized_mutual_info_score&lt;/code&gt;&lt;/a&gt; with the arithmetic averaging method.</source>
          <target state="translated">V-Measureはさらに対称的です &lt;code&gt;labels_true&lt;/code&gt; と &lt;code&gt;label_pred&lt;/code&gt; を入れ替えても同じスコアになります。これは、均質性と完全性を保持しません。V-Measureは、算術平均法を使用した&lt;a href=&quot;sklearn.metrics.normalized_mutual_info_score#sklearn.metrics.normalized_mutual_info_score&quot;&gt; &lt;code&gt;normalized_mutual_info_score&lt;/code&gt; &lt;/a&gt;れたミューチュアル情報コアと同じです。</target>
        </trans-unit>
        <trans-unit id="47faeee4990a814efec079e593cccd036ad6778a" translate="yes" xml:space="preserve">
          <source>V-measure cluster labeling given a ground truth.</source>
          <target state="translated">基底真理を与えられたVメジャークラスタのラベリング。</target>
        </trans-unit>
        <trans-unit id="a4fd517acce42be80ab9791260ae88f5cbdf1a52" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Spam filtering with Naive Bayes &amp;ndash; Which Naive Bayes?&lt;/a&gt; 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis、I。AndroutsopoulosおよびG. Paliouras（2006）。&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.5542&quot;&gt;Naive Bayesによるスパムフィルタリング&amp;ndash;どのNaive Bayesですか？&lt;/a&gt;第3会議 電子メールとスパム対策（CEAS）。</target>
        </trans-unit>
        <trans-unit id="942786415758a60976a047b84669d53dbc12ecc2" translate="yes" xml:space="preserve">
          <source>V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes &amp;ndash; Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).</source>
          <target state="translated">V. Metsis、I。AndroutsopoulosおよびG. Paliouras（2006）。単純ベイズによるスパムフィルタリング&amp;ndash;単純ベイズ 第3会議 電子メールとスパム対策（CEAS）。</target>
        </trans-unit>
        <trans-unit id="a4d9f3d16f166bfe390c3f0be94b7a7169e9ff69" translate="yes" xml:space="preserve">
          <source>Valid &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; representations for &lt;code&gt;type_of_target&lt;/code&gt; (&lt;code&gt;y&lt;/code&gt;) are:</source>
          <target state="translated">&lt;code&gt;type_of_target&lt;/code&gt; （ &lt;code&gt;y&lt;/code&gt; ）の有効な&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;マルチクラス&lt;/a&gt;表現は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="c9c007aafb4123183734854c6075f37be2b0eaac" translate="yes" xml:space="preserve">
          <source>Valid &lt;code&gt;type_of_target&lt;/code&gt;</source>
          <target state="translated">有効な &lt;code&gt;type_of_target&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ca4c1a38268237e7698432accf1a9a5a48b6fb08" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_distances.</source>
          <target state="translated">pairwise_distancesの有効なメトリクス。</target>
        </trans-unit>
        <trans-unit id="26700c8a25eea6fd902a0bb4963f14783c982650" translate="yes" xml:space="preserve">
          <source>Valid metrics for pairwise_kernels</source>
          <target state="translated">pairwise_kernels の有効なメトリクス</target>
        </trans-unit>
        <trans-unit id="850c962c3f063b586578621ee12bbb84d6f38bb7" translate="yes" xml:space="preserve">
          <source>Valid options:</source>
          <target state="translated">有効なオプションです。</target>
        </trans-unit>
        <trans-unit id="493108de26f61e3b76acfe363b14fa409e1fdc9a" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with &lt;code&gt;get_params()&lt;/code&gt;.</source>
          <target state="translated">有効なパラメータキーは、 &lt;code&gt;get_params()&lt;/code&gt; でリストできます。</target>
        </trans-unit>
        <trans-unit id="1a791ec45bdf21e7b9592679ed5472b3c5ab8093" translate="yes" xml:space="preserve">
          <source>Valid parameter keys can be listed with get_params().</source>
          <target state="translated">有効なパラメータキーは get_params()で一覧表示することができます。</target>
        </trans-unit>
        <trans-unit id="90d9fefcb561047bbbd742b13c3608c6fcf1e657" translate="yes" xml:space="preserve">
          <source>Valid values for metric are:</source>
          <target state="translated">メトリックの有効な値は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="47edea5ff3c24dcb16dc15647447ec5c4a9d77c2" translate="yes" xml:space="preserve">
          <source>Valid values for metric are::</source>
          <target state="translated">メトリックの有効な値は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="21601426cfbdf9a26553c2613d8f13b5c8a0699e" translate="yes" xml:space="preserve">
          <source>Validate scalar parameters type and value.</source>
          <target state="translated">スカラーパラメータの型と値を検証します。</target>
        </trans-unit>
        <trans-unit id="ec59a2a93f21b1aa3fbc16cd26b3b2dbab6fa78b" translate="yes" xml:space="preserve">
          <source>Validation curve.</source>
          <target state="translated">バリデーションカーブ。</target>
        </trans-unit>
        <trans-unit id="675b8482a7f9f38fa965a1efe10c6a6ee6ec5cdb" translate="yes" xml:space="preserve">
          <source>Value added to the diagonal of the kernel matrix during fitting. Larger values correspond to increased noise level in the observations. This can also prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Note that this is equivalent to adding a WhiteKernel with c=alpha. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge.</source>
          <target state="translated">フィット中にカーネル行列の対角線に加えられる値。より大きな値は,オブザベーションのノイズレベルの増加に対応する.これはまた、計算された値が正定値行列を形成することを確実にすることで、フィッティング中の潜在的な数値的な問題を防ぐことができます。配列が渡される場合、それはフィットに使用されるデータと同じエントリ数を持たなければならず、データポイント依存のノイズレベルとして使用されます。これは、c=αでWhiteKernelを追加することと同等であることに注意してください。パラメータとしてノイズレベルを直接指定できるようにしたのは、主に利便性とRidgeとの整合性のためです。</target>
        </trans-unit>
        <trans-unit id="cdffc29f88adeffd4bcff100fb7aa53a66956d52" translate="yes" xml:space="preserve">
          <source>Value for numerical stability in adam. Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">adamの数値安定性の値。solver = 'adam'の場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="c6350d6ef6528ee88ef12a12465bebefd1891dd8" translate="yes" xml:space="preserve">
          <source>Value of the pseudo-likelihood (proxy for likelihood).</source>
          <target state="translated">擬似尤度(尤度の代理)の値。</target>
        </trans-unit>
        <trans-unit id="7a1b051ea7b4e31aba2ba2519e8c31958f649214" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.</source>
          <target state="translated">推定量フィッティングでエラーが発生した場合にスコアに割り当てる値。 'raise'に設定すると、エラーが発生します。数値を指定すると、FitFailedWarningが発生します。このパラメータは、常にエラーを発生させる再調整ステップには影響しません。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
