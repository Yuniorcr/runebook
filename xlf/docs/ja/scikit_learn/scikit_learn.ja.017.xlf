<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="78bd06a1d3ff24b26b2d2d7bba48b35d89d447f8" translate="yes" xml:space="preserve">
          <source>NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective. The desired dimensionality can be set using the parameter &lt;code&gt;n_components&lt;/code&gt;. For instance, the following figure shows a comparison of dimensionality reduction with Principal Component Analysis (&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/a&gt;), Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Neighborhood Component Analysis (&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) on the Digits dataset, a dataset with size \(n_{samples} = 1797\) and \(n_{features} = 64\). The data set is split into a training and a test set of equal size, then standardized. For evaluation the 3-nearest neighbor classification accuracy is computed on the 2-dimensional projected points found by each method. Each data sample belongs to one of 10 classes.</source>
          <target state="translated">NCAは、教師あり次元削減を実行するために使用できます。入力データは、NCAの目的を最小化する方向で構成される線形部分空間に投影されます。パラメータ &lt;code&gt;n_components&lt;/code&gt; を使用して、目的の次元を設定できます。たとえば、次の図は、主成分分析（&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt; &lt;/a&gt;）、線形判別分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）、および近傍成分分析（&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;）による次元削減の比較を示しています。）Digitsデータセットで、サイズが\（n_ {samples} = 1797 \）および\（n_ {features} = 64 \）のデータセット。データセットは、同じサイズのトレーニングセットとテストセットに分割され、標準化されます。評価のために、3最近傍分類の精度は、各方法で検出された2次元の投影点で計算されます。各データサンプルは、10のクラスのいずれかに属しています。</target>
        </trans-unit>
        <trans-unit id="178c8cecc0d6623e23a76bbb064f3967dc7aa43a" translate="yes" xml:space="preserve">
          <source>NCA classification has been shown to work well in practice for data sets of varying size and difficulty. In contrast to related methods such as Linear Discriminant Analysis, NCA does not make any assumptions about the class distributions. The nearest neighbor classification can naturally produce highly irregular decision boundaries.</source>
          <target state="translated">NCA分類は、サイズや難易度が異なるデータセットに対して、実際にうまく機能することが示されています。線形判別分析などの関連する手法とは対照的に、NCAはクラス分布についての仮定を行いません。最近傍分類は、当然のことながら、非常に不規則な決定境界を生成することができます。</target>
        </trans-unit>
        <trans-unit id="a288a9444d289c6327b252974b74e26d9ed71a92" translate="yes" xml:space="preserve">
          <source>NCA stores a matrix of pairwise distances, taking &lt;code&gt;n_samples ** 2&lt;/code&gt; memory. Time complexity depends on the number of iterations done by the optimisation algorithm. However, one can set the maximum number of iterations with the argument &lt;code&gt;max_iter&lt;/code&gt;. For each iteration, time complexity is &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt;.</source>
          <target state="translated">NCAは、 &lt;code&gt;n_samples ** 2&lt;/code&gt; メモリを使用して、ペアワイズ距離の行列を格納します。時間計算量は、最適化アルゴリズムによって実行される反復回数によって異なります。ただし、引数 &lt;code&gt;max_iter&lt;/code&gt; を使用して最大反復回数を設定できます。反復ごとに、時間計算量は &lt;code&gt;O(n_components x n_samples x min(n_samples, n_features))&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="235c4fdc295d941494351e73dad0edc432affd04" translate="yes" xml:space="preserve">
          <source>NFF : number of dims in which both values are False</source>
          <target state="translated">NFF:両方の値が False の時のディム数</target>
        </trans-unit>
        <trans-unit id="f242d8e1cdbbc8cb628621d8d57f10327047707d" translate="yes" xml:space="preserve">
          <source>NFT : number of dims in which the first value is False, second is True</source>
          <target state="translated">NFT:1つ目の値がFalse、2つ目の値がTrueであるdimsの数</target>
        </trans-unit>
        <trans-unit id="ced12bb5137dbf26fd788e77cae54623cdb8b2e8" translate="yes" xml:space="preserve">
          <source>NMF is best used with the &lt;code&gt;fit_transform&lt;/code&gt; method, which returns the matrix W. The matrix H is stored into the fitted model in the &lt;code&gt;components_&lt;/code&gt; attribute; the method &lt;code&gt;transform&lt;/code&gt; will decompose a new matrix X_new based on these stored components:</source>
          <target state="translated">NMFは最良で使用され &lt;code&gt;fit_transform&lt;/code&gt; の行列Hは、でフィットされたモデルの中に格納される行列Wを返すメソッド、 &lt;code&gt;components_&lt;/code&gt; の属性を、メソッド &lt;code&gt;transform&lt;/code&gt; は、これらの格納されたコンポーネントに基づいて新しい行列X_newを分解します。</target>
        </trans-unit>
        <trans-unit id="9546ef450bf032f2a099e2b8894066e314108bcc" translate="yes" xml:space="preserve">
          <source>NMI and MI are not adjusted against chance.</source>
          <target state="translated">NMIとMIは偶然性に対して調整されていない。</target>
        </trans-unit>
        <trans-unit id="ec8506cc20e415f16975d43b2c6e163b63b7c223" translate="yes" xml:space="preserve">
          <source>NNEQ / (NNEQ + 0.5 * NTT)</source>
          <target state="translated">NNEQ/(NNEQ+0.</target>
        </trans-unit>
        <trans-unit id="64142d93685b184d0f4668dd2d38de67d364504a" translate="yes" xml:space="preserve">
          <source>NNEQ / (NTT + NNZ)</source>
          <target state="translated">NNEQ/(NTT+NNZ)</target>
        </trans-unit>
        <trans-unit id="9e2ca45598fef4852f298770d7c7037071a195c1" translate="yes" xml:space="preserve">
          <source>NNEQ / N</source>
          <target state="translated">NNEQ/N</target>
        </trans-unit>
        <trans-unit id="bd22d441438dd8339012b8925c55919834498020" translate="yes" xml:space="preserve">
          <source>NNEQ / NNZ</source>
          <target state="translated">NNEQ/NNZ</target>
        </trans-unit>
        <trans-unit id="a4e22ff89a7f8daef1da10b2c311e81f8eb57054" translate="yes" xml:space="preserve">
          <source>NNEQ : number of non-equal dimensions, NNEQ = NTF + NFT</source>
          <target state="translated">NNEQ:非等次元数、NNEQ=NTF+NFT</target>
        </trans-unit>
        <trans-unit id="80bfd3623c0e507836f83286688a2ee41b18b00e" translate="yes" xml:space="preserve">
          <source>NNZ / N</source>
          <target state="translated">NNZ/N</target>
        </trans-unit>
        <trans-unit id="93209a2edd337e6dc4e7c870a3c72537cea28fdf" translate="yes" xml:space="preserve">
          <source>NNZ : number of nonzero dimensions, NNZ = NTF + NFT + NTT</source>
          <target state="translated">NNZ:非ゼロ次元数、NNNZ=NTF+NFT+NTT</target>
        </trans-unit>
        <trans-unit id="a8ad860c15810cce0e7beac1c91da3ab2cb22c47" translate="yes" xml:space="preserve">
          <source>NOTE</source>
          <target state="translated">NOTE</target>
        </trans-unit>
        <trans-unit id="b81cbdff62e50c72d48e4feea8a9ed88bea18bef" translate="yes" xml:space="preserve">
          <source>NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each.</source>
          <target state="translated">注:カスタムスコアラーを使用する場合、各スコアラーは 1 つの値を返す必要があります。値のリスト/配列を返すメトリック関数は、それぞれ1つの値を返す複数のスコアラーにラップすることができます。</target>
        </trans-unit>
        <trans-unit id="9764dfb854390dc404102ac64200b55e363e83df" translate="yes" xml:space="preserve">
          <source>NOX nitric oxides concentration (parts per 10 million)</source>
          <target state="translated">NOX 硝酸態窒素酸化物濃度(千万分の一</target>
        </trans-unit>
        <trans-unit id="99542bc2231d38286b9a1dbe4685e8690203b845" translate="yes" xml:space="preserve">
          <source>NTF : number of dims in which the first value is True, second is False</source>
          <target state="translated">NTF:1つ目の値が真、2つ目の値が偽の場合のdims数</target>
        </trans-unit>
        <trans-unit id="d7aff2fba38c5d47fc1d509779237efeccf9cd66" translate="yes" xml:space="preserve">
          <source>NTT : number of dims in which both values are True</source>
          <target state="translated">NTT:両方の値がTrueの場合のdims数</target>
        </trans-unit>
        <trans-unit id="f7fd9c68f804acda665d2ab082217bb1583318f2" translate="yes" xml:space="preserve">
          <source>NaN</source>
          <target state="translated">NaN</target>
        </trans-unit>
        <trans-unit id="6e2518fe965a665a40ec6f1bf71cbacd3d7014df" translate="yes" xml:space="preserve">
          <source>NaNs are ignored in the algorithm.</source>
          <target state="translated">アルゴリズムではNaNは無視されます。</target>
        </trans-unit>
        <trans-unit id="bce02ea83698a345c8e67696ff8bdcc86ad6e774" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in &lt;code&gt;fit&lt;/code&gt;, and maintained in &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">NaNをは欠損値として扱われます：に無視 &lt;code&gt;fit&lt;/code&gt; 、そして内に維持 &lt;code&gt;transform&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7b2cc2bc3bfa4ab2fba6e73cce899558220dd79a" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded in fit, and maintained in transform.</source>
          <target state="translated">NaN は欠損値として扱われます:適合時には無視され、変換時には維持されます。</target>
        </trans-unit>
        <trans-unit id="d13d7452647efb26ab0d2b1a3596526a7f4ca5d6" translate="yes" xml:space="preserve">
          <source>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</source>
          <target state="translated">NaNは欠損値として扱われます:統計量を計算するために無視され、データ変換中に維持されます。</target>
        </trans-unit>
        <trans-unit id="d5c044a4b683787e1d22f3d89c2071d25a271b09" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for categorical features</source>
          <target state="translated">カテゴリ特徴量に対するナイーブベイズ分類器</target>
        </trans-unit>
        <trans-unit id="80d8f13b4e334c4342adf34b360ad118e5e25aa3" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multinomial models</source>
          <target state="translated">多項モデルのためのナイーブベイズ分類器</target>
        </trans-unit>
        <trans-unit id="92990e6c1a566f0d055f974e25026ec604b9ccd9" translate="yes" xml:space="preserve">
          <source>Naive Bayes classifier for multivariate Bernoulli models.</source>
          <target state="translated">多変量ベルヌーイモデルのためのナイーブベイズ分類器。</target>
        </trans-unit>
        <trans-unit id="c95f9acb4985f23ad6962fd01ae91dec549e7273" translate="yes" xml:space="preserve">
          <source>Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.</source>
          <target state="translated">ナイーブベイズ学習器と分類器は、より洗練された手法と比較して非常に高速である。クラスの条件付き特徴量分布のデカップリングは,各分布が独立して1次元分布として推定できることを意味する.これは,次元性の呪いに起因する問題を軽減するのに役立ちます.</target>
        </trans-unit>
        <trans-unit id="bb7ceea48fd3728ed03cf0ba21b4839b323fc974" translate="yes" xml:space="preserve">
          <source>Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes&amp;rsquo; theorem with the &amp;ldquo;naive&amp;rdquo; assumption of conditional independence between every pair of features given the value of the class variable. Bayes&amp;rsquo; theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :</source>
          <target state="translated">単純ベイズ法は、クラス変数の値が与えられた特徴のすべてのペア間の条件付き独立性の「単純な」仮定でベイズの定理を適用することに基づく監視付き学習アルゴリズムのセットです。ベイズの定理は、クラス変数\（y \）と従属特徴ベクトル\（x_1 \）から\（x_n \）が与えられた場合、次の関係を示します。</target>
        </trans-unit>
        <trans-unit id="f65600325bc091b7b293639582ad70691e2ac960" translate="yes" xml:space="preserve">
          <source>Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;MultinomialNB&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt;&lt;code&gt;BernoulliNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt; expose a &lt;code&gt;partial_fit&lt;/code&gt; method that can be used incrementally as done with other classifiers as demonstrated in &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. All naive Bayes classifiers support sample weighting.</source>
          <target state="translated">単純ベイズモデルは、完全なトレーニングセットがメモリに収まらない可能性がある大規模な分類問題に取り組むために使用できます。このケースを処理するために、&lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;MultinomialNB&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.naive_bayes.bernoullinb#sklearn.naive_bayes.BernoulliNB&quot;&gt; &lt;code&gt;BernoulliNB&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;は、テキストドキュメントのコア外&lt;/a&gt;分類で示されているように、他の分類子で行われるように段階的に使用できる &lt;code&gt;partial_fit&lt;/code&gt; メソッドを公開します。すべての単純ベイズ分類器は、サンプルの重み付けをサポートしています。</target>
        </trans-unit>
        <trans-unit id="f07ca99358e3e69c28471fb128e9c221473a78cf" translate="yes" xml:space="preserve">
          <source>Name for labeling curve. If &lt;code&gt;None&lt;/code&gt;, the name of the estimator is used.</source>
          <target state="translated">ラベル付け曲線の名前。 &lt;code&gt;None&lt;/code&gt; の場合、推定量の名前が使用されます。</target>
        </trans-unit>
        <trans-unit id="44b4a8733a267298aba42ed906f0510d314435b0" translate="yes" xml:space="preserve">
          <source>Name of ROC Curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="translated">ラベル付け用のROC曲線の名前。 &lt;code&gt;None&lt;/code&gt; の場合、推定量の名前を使用します。</target>
        </trans-unit>
        <trans-unit id="048c56c2b44d92cd1c41343db29430d22afe211f" translate="yes" xml:space="preserve">
          <source>Name of columns containing this regex pattern will be included. If None, column selection will not be selected based on pattern.</source>
          <target state="translated">この正規表現パターンを含む列の名前が含まれます。Noneの場合は、パターンに基づいてカラムの選択は行われません。</target>
        </trans-unit>
        <trans-unit id="7f39a3bd9bee33098b86f18fcaf23fc1b1f211a0" translate="yes" xml:space="preserve">
          <source>Name of dataset</source>
          <target state="translated">データセット名</target>
        </trans-unit>
        <trans-unit id="325b56c17b8389991fec124de840a19f36bc1993" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i.</source>
          <target state="translated">feature_names[i]はインデックスiの特徴量の名前を保持する。</target>
        </trans-unit>
        <trans-unit id="f379c68cd7abf28a38376a7f9401ab9de0d511e5" translate="yes" xml:space="preserve">
          <source>Name of each feature; feature_names[i] holds the name of the feature with index i. By default, the name of the feature corresponds to their numerical index for NumPy array and their column name for pandas dataframe.</source>
          <target state="translated">feature_names[i]はインデックスiを持つ特徴の名前を保持します。デフォルトでは、特徴の名前はNumPy配列の数値インデックスとpandas dataframeのカラム名に対応しています。</target>
        </trans-unit>
        <trans-unit id="1ea3134d139c317d0bc4edf673307764ffe8b0cd" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, the estimator name is not shown.</source>
          <target state="translated">見積もり担当者の名前。None の場合は、見積もり担当者名は表示されません。</target>
        </trans-unit>
        <trans-unit id="b8c1daded10cddfabf9a6fd7ee9e2ee679e1adbf" translate="yes" xml:space="preserve">
          <source>Name of estimator. If None, then the estimator name is not shown.</source>
          <target state="translated">見積もり担当者の名前。None の場合は、エスティメー タ名は表示されません。</target>
        </trans-unit>
        <trans-unit id="ed7e838c9509fe0de6c00e0d7bd5bf221ec76bc1" translate="yes" xml:space="preserve">
          <source>Name of precision recall curve for labeling. If &lt;code&gt;None&lt;/code&gt;, use the name of the estimator.</source>
          <target state="translated">ラベル付けの適合率再現率曲線の名前。 &lt;code&gt;None&lt;/code&gt; の場合、推定量の名前を使用します。</target>
        </trans-unit>
        <trans-unit id="1d63bfd9357f039d867c5652a85ab61996c87f94" translate="yes" xml:space="preserve">
          <source>Name of the data set on mldata.org, e.g.: &amp;ldquo;leukemia&amp;rdquo;, &amp;ldquo;Whistler Daily Snowfall&amp;rdquo;, etc. The raw name is automatically converted to a mldata.org URL .</source>
          <target state="translated">mldata.orgのデータセットの名前。例：「leukemia」、「Whistler Daily Snowfall」など。生の名前は自動的にmldata.org URLに変換されます。</target>
        </trans-unit>
        <trans-unit id="866f4401ef93cfed3b044fff6753dc1e913659b2" translate="yes" xml:space="preserve">
          <source>Name of the output activation function.</source>
          <target state="translated">出力活性化機能の名前。</target>
        </trans-unit>
        <trans-unit id="5a3a86d298c7e4314e724bb2623d8c6979ee2b6e" translate="yes" xml:space="preserve">
          <source>Name of the parameter that will be varied.</source>
          <target state="translated">変化させるパラメータの名前。</target>
        </trans-unit>
        <trans-unit id="d08ba4e92bc82e0b0eddb2db204950ac5386e156" translate="yes" xml:space="preserve">
          <source>Name of the sub-estimator that can be accessed as an attribute of the base object. If a list or a tuple of names are provided, the first sub-estimator that is an attribute of the base object will be used.</source>
          <target state="translated">ベースオブジェクトの属性としてアクセス可能なサブエスティメーターの名前。リストまたは名前のタプルが提供された場合、ベースオブジェクトの属性である最初のサブエスティメータが使用されます。</target>
        </trans-unit>
        <trans-unit id="ce3ec81584fa2d87df12f144e2480deecc5a975a" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the data.</source>
          <target state="translated">データを含む列の名前またはインデックス。</target>
        </trans-unit>
        <trans-unit id="0ae5e537b1c061ee0b3ccea7c63ace2088ca02dd" translate="yes" xml:space="preserve">
          <source>Name or index of the column containing the target values.</source>
          <target state="translated">対象となる値を含む列の名前またはインデックス。</target>
        </trans-unit>
        <trans-unit id="3170e49e906772d2e2d83c510613a736bad3f541" translate="yes" xml:space="preserve">
          <source>Named features not encountered during fit or fit_transform will be silently ignored.</source>
          <target state="translated">はめ込み中やはめ込み変換中に出会わなかった名前付き特徴量は、 無視されます。</target>
        </trans-unit>
        <trans-unit id="dd3283d9f71127c2e2cb8ea6f07a41ece4a049ce" translate="yes" xml:space="preserve">
          <source>Names of each of the features.</source>
          <target state="translated">各機能の名前。</target>
        </trans-unit>
        <trans-unit id="99983f06243c41c70b7f7a98a21b26cf2a2ec6a9" translate="yes" xml:space="preserve">
          <source>Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If &lt;code&gt;True&lt;/code&gt;, shows a symbolic representation of the class name.</source>
          <target state="translated">昇順の各ターゲットクラスの名前。分類にのみ関連し、マルチ出力ではサポートされません。 &lt;code&gt;True&lt;/code&gt; の場合、クラス名の記号表現を表示します。</target>
        </trans-unit>
        <trans-unit id="e9e6ba24a1711383d87f42cc11bb29b29e568b73" translate="yes" xml:space="preserve">
          <source>Names of each target (RCV1 topics), as ordered in dataset.target.</source>
          <target state="translated">各ターゲット(RCV1トピック)の名前をdataset.targetで順番に並べたもの。</target>
        </trans-unit>
        <trans-unit id="5ee798b80fce1c26ac31847940e2cbb9594ee08b" translate="yes" xml:space="preserve">
          <source>Names of the features produced by transform.</source>
          <target state="translated">変換によって生成された特徴量の名前。</target>
        </trans-unit>
        <trans-unit id="8769733c023d80ccc969e39d7e721f7eef2c8e42" translate="yes" xml:space="preserve">
          <source>Native support for missing values for gradient boosting</source>
          <target state="translated">勾配ブーストのための欠損値のネイティブサポート</target>
        </trans-unit>
        <trans-unit id="4aded465f8c4c45d7d7ec8d437901909b15f0b3f" translate="yes" xml:space="preserve">
          <source>Natural handling of data of mixed type (= heterogeneous features)</source>
          <target state="translated">混合型のデータの自然な取り扱い(=異質な特徴</target>
        </trans-unit>
        <trans-unit id="0a4d2a1303aed1ff654767155d9269907f0d020c" translate="yes" xml:space="preserve">
          <source>Nearest Centroid Classification</source>
          <target state="translated">近接セントロイド分類</target>
        </trans-unit>
        <trans-unit id="bfa0969ff4ed25d459c6eac3badc5bf9f79ee3f4" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors</source>
          <target state="translated">ご近所の方へ</target>
        </trans-unit>
        <trans-unit id="fa1459036257eab60db8e1afe6d9886bbc5e8a42" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors Classification</source>
          <target state="translated">近接者区分</target>
        </trans-unit>
        <trans-unit id="c7b70d3a90c9b413590f1c3fdfeae8dc16304398" translate="yes" xml:space="preserve">
          <source>Nearest Neighbors regression</source>
          <target state="translated">ニアレストネイバー回帰</target>
        </trans-unit>
        <trans-unit id="cc8575a20e3e28eef4bfc70e48146f9994bd7318" translate="yes" xml:space="preserve">
          <source>Nearest centroid classifier.</source>
          <target state="translated">ニアレストセントロイド分類器。</target>
        </trans-unit>
        <trans-unit id="8b02ae7bd0e5dc3ad9885f92e92e8dfc0759e655" translate="yes" xml:space="preserve">
          <source>Nearest neighbor and the curse of dimensionality</source>
          <target state="translated">近傍の隣人と次元性の呪い</target>
        </trans-unit>
        <trans-unit id="5db95950f32dda99cc2cb722bb90ec8e1106f00f" translate="yes" xml:space="preserve">
          <source>Needless to say, the cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores, in the sense that the &amp;ldquo;argmax&amp;rdquo; of the scores may not be the argmax of the probabilities. (E.g., in binary classification, a sample may be labeled by &lt;code&gt;predict&lt;/code&gt; as belonging to a class that has probability &amp;lt;&amp;frac12; according to &lt;code&gt;predict_proba&lt;/code&gt;.) Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">言うまでもなく、Plattスケーリングに含まれる交差検証は、大規模なデータセットの場合、負荷の高い操作です。さらに、スコアの「argmax」が確率のargmaxではない場合があるという意味で、確率推定値はスコアと一致しない場合があります。 （例えば、バイナリ分類では、サンプルはによって標識することができる &lt;code&gt;predict&lt;/code&gt; に係る確率&amp;lt;半持つクラスに属するものとして &lt;code&gt;predict_proba&lt;/code&gt; を。）プラットの方法はまた、理論的な問題があることが知られています。信頼スコアが必要であるが、これらが確率である必要はない場合は、 &lt;code&gt;probability=False&lt;/code&gt; を設定し、 &lt;code&gt;predict_proba&lt;/code&gt; の代わりに &lt;code&gt;decision_function&lt;/code&gt; を使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="5040421db1ecb4c2ff96e24808174eee959aab93" translate="yes" xml:space="preserve">
          <source>Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space.</source>
          <target state="translated">近傍成分分析(NCA)は、メトリック学習のための機械学習アルゴリズムです。教師付きの方法で線形変換を学習し、変換された空間における確率的最近傍ルールの分類精度を向上させます。</target>
        </trans-unit>
        <trans-unit id="e58fc95c9278805803f18a9db5fe3ea3f42040b6" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis</source>
          <target state="translated">近隣成分分析</target>
        </trans-unit>
        <trans-unit id="ba8f206becb6fe0a43da0c0c40642a7520c206e1" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA) tries to find a feature space such that a stochastic nearest neighbor algorithm will give the best accuracy. Like LDA, it is a supervised method.</source>
          <target state="translated">近傍成分分析(NCA)は、確率的最近傍アルゴリズムが最高の精度を与えるような特徴空間を見つけようとします。LDAと同様に、教師付き手法です。</target>
        </trans-unit>
        <trans-unit id="aee814d8b405edd4d076224daf37938472d0e4bb" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis (NCA, &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt;) is a distance metric learning algorithm which aims to improve the accuracy of nearest neighbors classification compared to the standard Euclidean distance. The algorithm directly maximizes a stochastic variant of the leave-one-out k-nearest neighbors (KNN) score on the training set. It can also learn a low-dimensional linear projection of data that can be used for data visualization and fast classification.</source>
          <target state="translated">Neighborhood Components Analysis（NCA、&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;）は、標準のユークリッド距離と比較して最近傍分類の精度を向上させることを目的とした距離メトリック学習アルゴリズムです。アルゴリズムは、トレーニングセットのLeave-one-out k-nearest neighbors（KNN）スコアの確率的バリアントを直接最大化します。また、データの視覚化と高速分類に使用できるデータの低次元線形射影を学習することもできます。</target>
        </trans-unit>
        <trans-unit id="e267b3659f7643549165a2fa213a97174cdd61c0" translate="yes" xml:space="preserve">
          <source>Neighborhood Components Analysis Illustration</source>
          <target state="translated">近隣成分分析イラスト</target>
        </trans-unit>
        <trans-unit id="5d2390b5dea0fabfaec001753e4e7ab98989a540" translate="yes" xml:space="preserve">
          <source>Neighborhoods are restricted the points at a distance lower than radius.</source>
          <target state="translated">近所は半径よりも低い距離でポイントが制限されています。</target>
        </trans-unit>
        <trans-unit id="71b4c3c0886885b3bdb78dd9feb31a745b98d96e" translate="yes" xml:space="preserve">
          <source>Neighbors-based classification is a type of &lt;em&gt;instance-based learning&lt;/em&gt; or &lt;em&gt;non-generalizing learning&lt;/em&gt;: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</source>
          <target state="translated">近傍ベースの分類は、&lt;em&gt;インスタンスベースの学習&lt;/em&gt;または&lt;em&gt;非一般化学習の&lt;/em&gt;一種です&lt;em&gt;。&lt;/em&gt;一般的な内部モデルを構築しようとするのではなく、トレーニングデータのインスタンスを格納するだけです。分類は、各ポイントの最近傍の単純多数決から計算されます。クエリポイントには、ポイントの最近傍内で最も代表的なデータクラスが割り当てられます。</target>
        </trans-unit>
        <trans-unit id="f556f4d2d6fabe3a4b78772a04d1d08bf693d3a1" translate="yes" xml:space="preserve">
          <source>Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.</source>
          <target state="translated">隣人ベースの回帰は、データ・ラベルが離散変数ではなく連続変数である場合に使用できます。クエリ点に割り当てられたラベルは、その最も近い隣人のラベルの平均に基づいて計算されます。</target>
        </trans-unit>
        <trans-unit id="f17c48105fdd248ad2de1f1ac3f1cabb43429cec" translate="yes" xml:space="preserve">
          <source>Nested cross-validation</source>
          <target state="translated">入れ子になったクロスバリデーション</target>
        </trans-unit>
        <trans-unit id="029453980f1f56140cec84a6516b88cf4da43353" translate="yes" xml:space="preserve">
          <source>Nested versus non-nested cross-validation</source>
          <target state="translated">入れ子にしたものと非入れ子にしたものの交差検証</target>
        </trans-unit>
        <trans-unit id="3991fd2dc72259103c5d9e42cbe59d2a7e448f31" translate="yes" xml:space="preserve">
          <source>Neural Networks</source>
          <target state="translated">ニューラルネットワーク</target>
        </trans-unit>
        <trans-unit id="8c7edd0d2fdd43b38d35974fe3274794c4023842" translate="yes" xml:space="preserve">
          <source>Never unpickle untrusted data as it could lead to malicious code being executed upon loading.</source>
          <target state="translated">読み込み時に悪意のあるコードが実行される可能性があるため、信頼されていないデータを決してアンピクルしてはいけません。</target>
        </trans-unit>
        <trans-unit id="5a7c69a057920dae02f0ceb2f6458cca465cc67b" translate="yes" xml:space="preserve">
          <source>New data point to be inserted into the LSH Forest.</source>
          <target state="translated">LSHフォレストに挿入される新しいデータポイント。</target>
        </trans-unit>
        <trans-unit id="48ff6f532fccde3a69a322cc1151c107ad295ffd" translate="yes" xml:space="preserve">
          <source>New data to predict.</source>
          <target state="translated">予測するための新しいデータ。</target>
        </trans-unit>
        <trans-unit id="b9599b4d9149cfd51951922f7155a3dc95944ff0" translate="yes" xml:space="preserve">
          <source>New data to predict. If a sparse matrix is provided, it will be converted into a sparse &lt;code&gt;csr_matrix&lt;/code&gt;.</source>
          <target state="translated">予測する新しいデータ。スパース行列が提供されている場合、それはスパース &lt;code&gt;csr_matrix&lt;/code&gt; に変換されます。</target>
        </trans-unit>
        <trans-unit id="e461db7b42b4e1d723a59598bcca510859163aef" translate="yes" xml:space="preserve">
          <source>New data to transform.</source>
          <target state="translated">新しいデータを変換します。</target>
        </trans-unit>
        <trans-unit id="329a026b697f0ae2b6fcf5ede884e3254ea37650" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features.</source>
          <target state="translated">新しいデータで、サンプル数のn_samples、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="68d214f5c1780f5e1075a93cc2054064839f0ca3" translate="yes" xml:space="preserve">
          <source>New data, where n_samples in the number of samples and n_features is the number of features. All values of X must be strictly greater than &amp;ldquo;-skewedness&amp;rdquo;.</source>
          <target state="translated">新しいデータ。サンプル数のn_samplesとn_featuresは特徴の数です。Xのすべての値は、「-歪度」より厳密に大きい必要があります。</target>
        </trans-unit>
        <trans-unit id="6e6bacb37aec6214dc7bc345656e9fc6be9d8645" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">新しいデータで、n_samplesはサンプル数、n_componentsはコンポーネント数です。</target>
        </trans-unit>
        <trans-unit id="ed0f15ab3ccef84bd24b03af80dd2d8f760b3551" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_components is the number of pls components.</source>
          <target state="translated">新しいデータで、n_samples はサンプル数、n_components は pls コンポーネントの数です。</target>
        </trans-unit>
        <trans-unit id="9774ac05294602db6164b128c08e5838d8dd2c30" translate="yes" xml:space="preserve">
          <source>New data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">新しいデータで、n_samplesはサンプル数、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="2cec1d1d13a623e2cead9e687223c0b43410804e" translate="yes" xml:space="preserve">
          <source>New data.</source>
          <target state="translated">新しいデータです。</target>
        </trans-unit>
        <trans-unit id="2dcde8ec0560b6129ac7ceb94e6b76437cebda2e" translate="yes" xml:space="preserve">
          <source>New in version 0.10.</source>
          <target state="translated">バージョン0.10の新機能。</target>
        </trans-unit>
        <trans-unit id="d68d01022d3e4f6b4abc88815d154b4b27565257" translate="yes" xml:space="preserve">
          <source>New in version 0.12.</source>
          <target state="translated">バージョン0.12の新機能。</target>
        </trans-unit>
        <trans-unit id="dc28b70929f839a69ed3e45ea011105ea33d52a9" translate="yes" xml:space="preserve">
          <source>New in version 0.13.</source>
          <target state="translated">バージョン0.13の新機能。</target>
        </trans-unit>
        <trans-unit id="52ebd0001be9ad2ddaeba3e98fe57c162ffbf813" translate="yes" xml:space="preserve">
          <source>New in version 0.14.</source>
          <target state="translated">バージョン0.14の新機能。</target>
        </trans-unit>
        <trans-unit id="73af4998c8d20c7743147253e8c7d8a51d34634f" translate="yes" xml:space="preserve">
          <source>New in version 0.15.</source>
          <target state="translated">バージョン0.15の新機能。</target>
        </trans-unit>
        <trans-unit id="81c56a91b55dc7fbe4322466c0b6b3d2def29380" translate="yes" xml:space="preserve">
          <source>New in version 0.16.</source>
          <target state="translated">バージョン0.16の新機能。</target>
        </trans-unit>
        <trans-unit id="b2a489d3a2d4dc51668c693a83253f531fff88d5" translate="yes" xml:space="preserve">
          <source>New in version 0.16: If the input is sparse, the output will be a &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;. Else, output type is the same as the input type.</source>
          <target state="translated">バージョン0.16の新機能：入力がスパースの場合、出力は &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; になります。それ以外の場合、出力タイプは入力タイプと同じです。</target>
        </trans-unit>
        <trans-unit id="60b69c65bf1a3241e15d0d894ba32eab25d7cdd7" translate="yes" xml:space="preserve">
          <source>New in version 0.17.</source>
          <target state="translated">バージョン0.17の新機能。</target>
        </trans-unit>
        <trans-unit id="21cf2264569599d5dcc312306fa70dfc0eda22f5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;code&gt;random_state&lt;/code&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">バージョン0.17の新機能：確率的平均勾配をサポートする &lt;code&gt;random_state&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="dc470080fe5f5c357c2ad73809b92faa7362d9a9" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;LinearDiscriminantAnalysis&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="abf887094b036a443ef8f8f3b6efb216ee34cd24" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;QuadraticDiscriminantAnalysis&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="6b2ff85ecc2a1a01962dd33b1e34753285ca0790" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;alpha&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される&lt;em&gt;アルファ&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="6808fe2d57e6aeef92c976187ce0a06abf1ebec1" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">バージョン0.17の新機能：速度を向上させる&lt;em&gt;CD&lt;/em&gt;座標降下法。</target>
        </trans-unit>
        <trans-unit id="7b66bf990e4010a15f9d64925c054de502637170" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;class_weight=&amp;rsquo;balanced&amp;rsquo;&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;class_weight = 'balanced'&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="ea86dc59df4308dd8eeb6d9e2ae15359239ba528" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_max_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_max_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="1f6c1c10d870e8e7d70fedf31cf3a9ee8c7d746d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_min_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_min_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e853c35f6d282db32a11152441252fd53da7f57f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;data_range_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;data_range_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="edb88b5a13c967ddfdc52fb30c87cf6cd8e55cef" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;decision_function_shape=&amp;rsquo;ovr&amp;rsquo;&lt;/em&gt; is recommended.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;Decision_function_shape = 'ovr'&lt;/em&gt;が推奨されます。</target>
        </trans-unit>
        <trans-unit id="18bd409dbab688800dc645ecf6dc2d319b6dc274" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;lasso_cd&lt;/em&gt; coordinate descent method to improve speed.</source>
          <target state="translated">バージョン0.17の新機能：速度を改善する&lt;em&gt;lasso_cd&lt;/em&gt;座標降下法。</target>
        </trans-unit>
        <trans-unit id="5c5696058be6bc7e1f1d8d04441e99d3b67a5a9d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;minmax_scale&lt;/em&gt; function interface to &lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;sklearn.preprocessing.MinMaxScaler&lt;/em&gt;への&lt;a href=&quot;sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; &lt;/a&gt;関数インターフェース。</target>
        </trans-unit>
        <trans-unit id="61491e91a5cc882c8d0472b81b77bf74b7ea4e3d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;presort&lt;/em&gt; parameter.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;presort&lt;/em&gt;パラメータ。</target>
        </trans-unit>
        <trans-unit id="b2b731bdc9bf8dfc47673f8abfcc6c2c7f1f838c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;random_state&lt;/em&gt; to support Stochastic Average Gradient.</source>
          <target state="translated">バージョン0.17の新機能：確率平均勾配をサポートする&lt;em&gt;random_state&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="727acdfec60aa8d5fe01b0fab35aa36437da02bb" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to Classifier.</source>
          <target state="translated">バージョン0.17の新機能：分類&lt;em&gt;子&lt;/em&gt;に対する&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="6a9e702e6dde8c5e083d3061949d66f0c1cd0a95" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;sample_weight&lt;/em&gt; support to LogisticRegression.</source>
          <target state="translated">バージョン0.17の新機能：LogisticRegressionの&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="8bf7c72c906a46e4bafab411161accafb9f3258f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;scale_&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="26b994b5337cbc66d9e87cecbe064dc645c2d9c5" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;scale_&lt;/em&gt; attribute.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;scale_&lt;/em&gt;属性。</target>
        </trans-unit>
        <trans-unit id="acaea6c314c50f12e63f6a31caa95dae9a93cb16" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;shuffle&lt;/em&gt; parameter used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される&lt;em&gt;シャッフル&lt;/em&gt;パラメーター。</target>
        </trans-unit>
        <trans-unit id="3c9ad8ece37a0ad66c0695ab197f051fc5c4f74b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; constructor parameter.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;warm_start&lt;/em&gt;コンストラクターパラメーター。</target>
        </trans-unit>
        <trans-unit id="5d7ee9d78ae5139184086665f72ad9adc489e60f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: &lt;em&gt;warm_start&lt;/em&gt; to support &lt;em&gt;lbfgs&lt;/em&gt;, &lt;em&gt;newton-cg&lt;/em&gt;, &lt;em&gt;sag&lt;/em&gt;, &lt;em&gt;saga&lt;/em&gt; solvers.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;warm_startは&lt;/em&gt;、&lt;em&gt;lbfgs&lt;/em&gt;、&lt;em&gt;newton-cg&lt;/em&gt;、&lt;em&gt;sag&lt;/em&gt;、&lt;em&gt;saga&lt;/em&gt;ソルバーをサポートします。</target>
        </trans-unit>
        <trans-unit id="6005792b774eeae7e9401b712800c9c602a22ebe" translate="yes" xml:space="preserve">
          <source>New in version 0.17: A function &lt;em&gt;label_ranking_loss&lt;/em&gt;</source>
          <target state="translated">バージョン0.17の新機能：関数&lt;em&gt;label_ranking_loss&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e93da6946e01b1e23cbc1e7009a23425c993a384" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Approximate optimization &lt;em&gt;method&lt;/em&gt; via the Barnes-Hut.</source>
          <target state="translated">バージョン0.17の新機能：Barnes-Hutによる近似最適化&lt;em&gt;手法&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="9365f66e13f87cb3bbf8aaf0ec5863c643029aff" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能:座標降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="c589f3a156d1562e5e258c1483b29eaa7a3bb671" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Dummy Classifier now supports prior fitting strategy using parameter &lt;em&gt;prior&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：ダミー分類子は、パラメーター&lt;em&gt;previous&lt;/em&gt;を使用した以前のフィッティング戦略をサポートするようになり&lt;em&gt;ました&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="4c1ba1a9df4e3f1eda2057a3d8675352ba0c6105" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Gaussian Naive Bayes supports fitting with &lt;em&gt;sample_weight&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：Gaussian Naive Bayesは、&lt;em&gt;sample_weightによる&lt;/em&gt;フィッティングをサポートしてい&lt;em&gt;ます&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="b94e1008bb6bd8880b48f9c93c89015eb39cf414" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Parallel Execution using &lt;em&gt;n_jobs&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;n_jobs&lt;/em&gt;を使用した並列実行。</target>
        </trans-unit>
        <trans-unit id="56295350a01a04673ce10a1274f3f2850857660f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Regularization parameter &lt;em&gt;l1_ratio&lt;/em&gt; used in the Coordinate Descent solver.</source>
          <target state="translated">バージョン0.17の新機能：座標降下ソルバーで使用される正則化パラメーター&lt;em&gt;l1_ratio&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="bfb15daea388e7bc4652a64e3ee368ec3ef32e45" translate="yes" xml:space="preserve">
          <source>New in version 0.17: Stochastic Average Gradient descent solver.</source>
          <target state="translated">バージョン0.17の新機能:確率的平均勾配降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="90ee93ad6b0e53eed26b86779c90b9633cb9848b" translate="yes" xml:space="preserve">
          <source>New in version 0.17: class_weight == &amp;lsquo;balanced&amp;rsquo;</source>
          <target state="translated">バージョン0.17の新機能：class_weight == 'balanced'</target>
        </trans-unit>
        <trans-unit id="db422a34a0885d2d1033db36affb13affc0d2065" translate="yes" xml:space="preserve">
          <source>New in version 0.17: metric &lt;em&gt;precomputed&lt;/em&gt; to accept precomputed sparse matrix.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;事前計算さ&lt;/em&gt;れた疎行列を受け入れるように事前&lt;em&gt;計算さ&lt;/em&gt;れたメトリック。</target>
        </trans-unit>
        <trans-unit id="545f1d599ea32d73544f4951073f7ce5e1f64bf6" translate="yes" xml:space="preserve">
          <source>New in version 0.17: optional parameter &lt;em&gt;presort&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：オプションのパラメーター&lt;em&gt;presort&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="1c0b7964a491c4c8234983325c356450f442446c" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;code&gt;dense_output&lt;/code&gt; for dense output.</source>
          <target state="translated">バージョン0.17の新機能：稠密な出力用のパラメーター &lt;code&gt;dense_output&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="46c6419997a8eb39c61c2c50456a363282489838" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;class_weight&lt;/em&gt; to automatically weight samples.</source>
          <target state="translated">バージョン0.17の新機能：サンプルを自動的に重み付けするためのパラメーター&lt;em&gt;class_weight&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="e8cbf38ab0cedfa95f7fc33391f9602285bd6e17" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;drop_intermediate&lt;/em&gt;.</source>
          <target state="translated">バージョン0.17の新機能：パラメータ&lt;em&gt;drop_intermediate&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="960c43bc8538ca35574a01cc68a5f2b510105d22" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;multilabel&lt;/em&gt; to support multilabel datasets.</source>
          <target state="translated">バージョン0.17の新機能：マルチラベルデータセットをサポートするパラメーター&lt;em&gt;マルチラベル&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="3788b38f2b10aab217952de3365bf7b88f170f8d" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;n_iter_without_progress&lt;/em&gt; to control stopping criteria.</source>
          <target state="translated">バージョン0.17の新機能：停止基準を制御するパラメーター&lt;em&gt;n_iter_without_progress&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="8db0c53c524e84f302dbc1a0dbd534321460f08f" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to LinearRegression.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;LinearRegression&lt;/em&gt;へのパラメーター&lt;em&gt;sample_weight&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="2a05312b3a418ca739af1c2a1750981f3df80101" translate="yes" xml:space="preserve">
          <source>New in version 0.17: parameter to allow &lt;em&gt;sparse&lt;/em&gt; output.</source>
          <target state="translated">バージョン0.17の新機能：&lt;em&gt;スパース&lt;/em&gt;出力を許可するパラメーター。</target>
        </trans-unit>
        <trans-unit id="8550f8dcfdefc5ee2595ff5a932287ae10047927" translate="yes" xml:space="preserve">
          <source>New in version 0.18.</source>
          <target state="translated">バージョン0.18の新機能。</target>
        </trans-unit>
        <trans-unit id="bc1978fea309e92ee1923ea481a6fd1eab915379" translate="yes" xml:space="preserve">
          <source>New in version 0.18.0.</source>
          <target state="translated">バージョン0.18.0の新機能。</target>
        </trans-unit>
        <trans-unit id="f6899efa546ca366fb803a6a6fcb7b4b47706e4f" translate="yes" xml:space="preserve">
          <source>New in version 0.18: ..</source>
          <target state="translated">バージョン0.18の新機能:...</target>
        </trans-unit>
        <trans-unit id="11462cefb53316ba0a8e0880815bfa04af36466b" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Mean Absolute Error (MAE) criterion.</source>
          <target state="translated">バージョン0.18の新機能:平均絶対誤差(MAE)基準。</target>
        </trans-unit>
        <trans-unit id="f3588d83291a2be20994392c7201429910c5a8e9" translate="yes" xml:space="preserve">
          <source>New in version 0.18: Stochastic Average Gradient descent solver for &amp;lsquo;multinomial&amp;rsquo; case.</source>
          <target state="translated">バージョン0.18の新機能：「多項式」の場合の確率的平均勾配降下ソルバー。</target>
        </trans-unit>
        <trans-unit id="0eb4d3b4907b28878c6666a16cc5abd9e36f4f00" translate="yes" xml:space="preserve">
          <source>New in version 0.19.</source>
          <target state="translated">バージョン0.19の新機能。</target>
        </trans-unit>
        <trans-unit id="e10489dae5e0fb6aa174b77a26bd312889388c1d" translate="yes" xml:space="preserve">
          <source>New in version 0.19: Multiplicative Update solver.</source>
          <target state="translated">バージョン0.19の新機能:乗算更新ソルバー。</target>
        </trans-unit>
        <trans-unit id="c260a9e7caaac82377fee1bfeace2cf2272b4b1a" translate="yes" xml:space="preserve">
          <source>New in version 0.19: SAGA solver.</source>
          <target state="translated">バージョン0.19の新機能:SAGAソルバー。</target>
        </trans-unit>
        <trans-unit id="d56c2d84411d9a6c91bdf6681efc0b4e653d1de5" translate="yes" xml:space="preserve">
          <source>New in version 0.19: l1 penalty with SAGA solver (allowing &amp;lsquo;multinomial&amp;rsquo; + L1)</source>
          <target state="translated">バージョン0.19の新機能：SAGAソルバーでのl1ペナルティ（「多項式」+ L1を許可）</target>
        </trans-unit>
        <trans-unit id="69d687c70a1657bfe591a19056b06b9f07dd4b5e" translate="yes" xml:space="preserve">
          <source>New in version 0.19: parameter &lt;em&gt;average&lt;/em&gt; to use weights averaging in SGD</source>
          <target state="translated">バージョン0.19の新機能：SGDで加重&lt;em&gt;平均&lt;/em&gt;を使用するパラメーター&lt;em&gt;平均&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e6570e8764c255a027de40e9e3eb2d1c722d495c" translate="yes" xml:space="preserve">
          <source>New in version 0.20.</source>
          <target state="translated">バージョン0.20の新機能。</target>
        </trans-unit>
        <trans-unit id="6c617d40b81d2b01909932fc5a27e561e533ba93" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;SimpleImputer&lt;/code&gt; replaces the previous &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; estimator which is now removed.</source>
          <target state="translated">バージョン0.20の新機能： &lt;code&gt;SimpleImputer&lt;/code&gt; は、現在削除されている以前の &lt;code&gt;sklearn.preprocessing.Imputer&lt;/code&gt; 推定量を置き換えます。</target>
        </trans-unit>
        <trans-unit id="92da9b59ee8f1aee40e76bd7e7f9a69e15158836" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;behaviour&lt;/code&gt; is added in 0.20 for back-compatibility purpose.</source>
          <target state="translated">バージョン0.20の新機能： &lt;code&gt;behaviour&lt;/code&gt; は0.20で後方互換性のために追加されています。</target>
        </trans-unit>
        <trans-unit id="89ff3bd96af64e1a70d0744f65ccf966040b095d" translate="yes" xml:space="preserve">
          <source>New in version 0.20: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">バージョン0.20の新機能： &lt;code&gt;force_all_finite&lt;/code&gt; は文字列 &lt;code&gt;'allow-nan'&lt;/code&gt; を受け入れます。</target>
        </trans-unit>
        <trans-unit id="fe256f44bbbbc2bd0c867a8e63ec681a6240ed59" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;adaptive&amp;rsquo; option</source>
          <target state="translated">バージョン0.20の新機能：「適応」オプションが追加されました</target>
        </trans-unit>
        <trans-unit id="c29982d75481689af02d31b620cd5f76c827f04a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;early_stopping&amp;rsquo; option</source>
          <target state="translated">バージョン0.20の新機能：「early_stopping」オプションが追加されました</target>
        </trans-unit>
        <trans-unit id="383b2bc5e9967f26e0b4b20cd947fb1316e6616a" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;n_iter_no_change&amp;rsquo; option</source>
          <target state="translated">バージョン0.20の新機能：「n_iter_no_change」オプションが追加されました</target>
        </trans-unit>
        <trans-unit id="5896f9ff4dd021dab607afd66ed0a221195a00c5" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added &amp;lsquo;validation_fraction&amp;rsquo; option</source>
          <target state="translated">バージョン0.20の新機能：「validation_fraction」オプションが追加されました</target>
        </trans-unit>
        <trans-unit id="646e72bed85791f997c7991fa5af303d05883478" translate="yes" xml:space="preserve">
          <source>New in version 0.20: Added the &amp;lsquo;single&amp;rsquo; option</source>
          <target state="translated">バージョン0.20の新機能：「single」オプションが追加されました</target>
        </trans-unit>
        <trans-unit id="1468919e56b56c4ded7ab6dba66d158a1002d5be" translate="yes" xml:space="preserve">
          <source>New in version 0.20: parameter &lt;em&gt;sample_weight&lt;/em&gt; support to BayesianRidge.</source>
          <target state="translated">バージョン0.20の新機能：BayesianRidgeに対するパラメーター&lt;em&gt;sample_weightの&lt;/em&gt;サポート。</target>
        </trans-unit>
        <trans-unit id="7c256855a0d81868bca650e3f1d5676a1f0ae5da" translate="yes" xml:space="preserve">
          <source>New in version 0.20: strategy=&amp;rdquo;constant&amp;rdquo; for fixed value imputation.</source>
          <target state="translated">バージョン0.20の新機能：固定値補完のためのstrategy =&amp;rdquo; constant&amp;rdquo;。</target>
        </trans-unit>
        <trans-unit id="6371a324a0f9b28d52fcce7a713bd8acc7b321e0" translate="yes" xml:space="preserve">
          <source>New in version 0.21.</source>
          <target state="translated">バージョン0.21の新機能。</target>
        </trans-unit>
        <trans-unit id="28bbafe212871917c1ae23be319d534da486ed2c" translate="yes" xml:space="preserve">
          <source>New in version 0.21: &lt;code&gt;n_connected_components_&lt;/code&gt; was added to replace &lt;code&gt;n_components_&lt;/code&gt;.</source>
          <target state="translated">バージョン0.21の新機能： &lt;code&gt;n_connected_components_&lt;/code&gt; を置き換えるために &lt;code&gt;n_components_&lt;/code&gt; が追加されました。</target>
        </trans-unit>
        <trans-unit id="be8b989c4868c5bd7f2040240742c5509b13b840" translate="yes" xml:space="preserve">
          <source>New in version 0.22.</source>
          <target state="translated">バージョン0.22の新機能。</target>
        </trans-unit>
        <trans-unit id="69cdaee84ba92c12f0c1ee7d5ea78cec5fb3129d" translate="yes" xml:space="preserve">
          <source>New in version 0.22: &lt;code&gt;force_all_finite&lt;/code&gt; accepts the string &lt;code&gt;'allow-nan'&lt;/code&gt;.</source>
          <target state="translated">バージョン0.22の新機能： &lt;code&gt;force_all_finite&lt;/code&gt; は文字列 &lt;code&gt;'allow-nan'&lt;/code&gt; を受け入れます。</target>
        </trans-unit>
        <trans-unit id="1fed47321851e7513d73e52b53e589471c95ed14" translate="yes" xml:space="preserve">
          <source>New in version 0.23.</source>
          <target state="translated">バージョン0.23の新機能。</target>
        </trans-unit>
        <trans-unit id="3131ca254bc6ccc53b97a121b7c7087eb729d9ad" translate="yes" xml:space="preserve">
          <source>New in version 0.23: this parameter was previously hardcoded as 0.</source>
          <target state="translated">バージョン 0.23 の新機能:このパラメータは以前は 0 としてハードコードされていました。</target>
        </trans-unit>
        <trans-unit id="1c41c95cafce09fc00bdb02d31fa4b185ade21eb" translate="yes" xml:space="preserve">
          <source>New in version 0.5.</source>
          <target state="translated">バージョン0.5の新機能。</target>
        </trans-unit>
        <trans-unit id="48e2833e629833b7582fc86a591171cccb4a2aa1" translate="yes" xml:space="preserve">
          <source>New in version 0.8.</source>
          <target state="translated">バージョン0.8の新機能。</target>
        </trans-unit>
        <trans-unit id="e0798e2f31cc8f6f05534a395874ff516c037ea2" translate="yes" xml:space="preserve">
          <source>New in version 0.9.</source>
          <target state="translated">バージョン0.9の新機能。</target>
        </trans-unit>
        <trans-unit id="3dcb523c8b35ef7bba188a1b72a37583d73585c0" translate="yes" xml:space="preserve">
          <source>New in version 1.7.0.</source>
          <target state="translated">バージョン1.7.0の新機能。</target>
        </trans-unit>
        <trans-unit id="382bf23b05f69ca7724427a219843811ca7f86bf" translate="yes" xml:space="preserve">
          <source>New plotting API</source>
          <target state="translated">新しいプロットAPI</target>
        </trans-unit>
        <trans-unit id="58fbaea601eebe84b9d8f8508a33c9a4b3025541" translate="yes" xml:space="preserve">
          <source>New to Scientific Python?</source>
          <target state="translated">Scientific Pythonは初めてですか?</target>
        </trans-unit>
        <trans-unit id="9f6a58e9ea6f2ce3d4a15836e22f7c6b8aed6e50" translate="yes" xml:space="preserve">
          <source>Next we create 10 classifier chains. Each classifier chain contains a logistic regression model for each of the 14 labels. The models in each chain are ordered randomly. In addition to the 103 features in the dataset, each model gets the predictions of the preceding models in the chain as features (note that by default at training time each model gets the true labels as features). These additional features allow each chain to exploit correlations among the classes. The Jaccard similarity score for each chain tends to be greater than that of the set independent logistic models.</source>
          <target state="translated">次に、10個の分類器チェーンを作成します。各分類器チェーンは、14個のラベルのそれぞれについてのロジスティック回帰モデルを含みます。各チェーンのモデルはランダムに順序付けされています。データセットの103個の特徴量に加えて、各モデルは、チェーン内の先行モデルの予測値を特徴量として取得します(学習時のデフォルトでは、各モデルは真のラベルを特徴量として取得することに注意してください)。これらの追加の特徴により、各チェーンはクラス間の相関を利用することができます。各連鎖のJaccard類似度スコアは,集合の独立したロジスティック・モデルの類似度スコアよりも大きくなる傾向があります.</target>
        </trans-unit>
        <trans-unit id="d753c88a8af3a7221324f1f115e965ef2e7003fc" translate="yes" xml:space="preserve">
          <source>Next we fit the Poisson regressor on the target variable. We set the regularization strength &lt;code&gt;alpha&lt;/code&gt; to approximately 1e-6 over number of samples (i.e. &lt;code&gt;1e-12&lt;/code&gt;) in order to mimic the Ridge regressor whose L2 penalty term scales differently with the number of samples.</source>
          <target state="translated">次に、ポアソン回帰子をターゲット変数に適合させます。正則化強度 &lt;code&gt;alpha&lt;/code&gt; をサンプル数（つまり &lt;code&gt;1e-12&lt;/code&gt; ）で約1e-6に設定して、L2ペナルティ項がサンプル数に応じて異なるリッジリグレッサを模倣します。</target>
        </trans-unit>
        <trans-unit id="1ae340c010af24c68842322aa72c1a3f11d7dacf" translate="yes" xml:space="preserve">
          <source>Next, let&amp;rsquo;s compare the accuracy of &lt;code&gt;SVC&lt;/code&gt; and &lt;code&gt;most_frequent&lt;/code&gt;:</source>
          <target state="translated">次に、 &lt;code&gt;SVC&lt;/code&gt; と &lt;code&gt;most_frequent&lt;/code&gt; 精度を比較してみましょう。</target>
        </trans-unit>
        <trans-unit id="c6c64a04d2e12fed93b98d6c01ec2531f747d55c" translate="yes" xml:space="preserve">
          <source>Next, we manually pick a threshold by visual inspection of the dendrogram to group our features into clusters and choose a feature from each cluster to keep, select those features from our dataset, and train a new random forest. The test accuracy of the new random forest did not change much compared to the random forest trained on the complete dataset.</source>
          <target state="translated">次に、デンドログラムの目視検査で閾値を手動で選択して特徴をクラスタにグループ化し、各クラスタから保持する特徴を選択し、データセットからそれらの特徴を選択し、新しいランダムフォレストを訓練した。新しいランダムフォレストのテスト精度は、完全なデータセットで訓練したランダムフォレストと比較してあまり変化しませんでした。</target>
        </trans-unit>
        <trans-unit id="60abf98c19bebf728f6b765cf9ba6a0bbf19fa43" translate="yes" xml:space="preserve">
          <source>Next, we plot the ROC curve with a single call to &lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt;&lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt;&lt;/a&gt;. The returned &lt;code&gt;svc_disp&lt;/code&gt; object allows us to continue using the already computed ROC curve for the SVC in future plots.</source>
          <target state="translated">次に、&lt;a href=&quot;../../modules/generated/sklearn.metrics.plot_roc_curve#sklearn.metrics.plot_roc_curve&quot;&gt; &lt;code&gt;sklearn.metrics.plot_roc_curve&lt;/code&gt; を&lt;/a&gt;1回呼び出すだけで、ROC曲線をプロットします。返された &lt;code&gt;svc_disp&lt;/code&gt; オブジェクトを使用すると、将来のプロットでSVCに対してすでに計算されたROC曲線を引き続き使用できます。</target>
        </trans-unit>
        <trans-unit id="0e2a2edce50f17d924871b306d2618d9b3454954" translate="yes" xml:space="preserve">
          <source>Next, we plot the tree based feature importance and the permutation importance. The permutation importance plot shows that permuting a feature drops the accuracy by at most &lt;code&gt;0.012&lt;/code&gt;, which would suggest that none of the features are important. This is in contradiction with the high test accuracy computed above: some feature must be important. The permutation importance is calculated on the training set to show how much the model relies on each feature during training.</source>
          <target state="translated">次に、ツリーベースの特徴の重要性と順列の重要性をプロットします。順列の重要度プロットは、特徴を並べ替えると精度が最大で &lt;code&gt;0.012&lt;/code&gt; 低下することを示しています。これは、どの特徴も重要ではないことを示しています。これは、上記で計算された高いテスト精度と矛盾しています。いくつかの機能が重要である必要があります。順列の重要度は、トレーニングセットで計算され、トレーニング中にモデルが各機能にどの程度依存しているかを示します。</target>
        </trans-unit>
        <trans-unit id="4301caa6a55515044571ecdaaa2f60c152ef3c59" translate="yes" xml:space="preserve">
          <source>Next, we train a decision tree using the effective alphas. The last value in &lt;code&gt;ccp_alphas&lt;/code&gt; is the alpha value that prunes the whole tree, leaving the tree, &lt;code&gt;clfs[-1]&lt;/code&gt;, with one node.</source>
          <target state="translated">次に、有効なアルファを使用して決定木をトレーニングします。 &lt;code&gt;ccp_alphas&lt;/code&gt; の最後の値は、ツリー全体を &lt;code&gt;clfs[-1]&lt;/code&gt; 、ツリーclfs [-1]に1つのノードを残すアルファ値です。</target>
        </trans-unit>
        <trans-unit id="19146388ab896a5ab7b0d5fd5a0ecbdbda416e05" translate="yes" xml:space="preserve">
          <source>Next, we will split our dataset to use 90% for training and leave the rest for testing. We will also set the regression model parameters. You can play with these parameters to see how the results change.</source>
          <target state="translated">次に、データセットを分割して、90%を学習に使用し、残りをテストに残します。また、回帰モデルのパラメータを設定します。これらのパラメータを使って、結果がどのように変化するかを見ることができます。</target>
        </trans-unit>
        <trans-unit id="cedfa60674e3afd543975ecc551b601711fc3043" translate="yes" xml:space="preserve">
          <source>Nick Street</source>
          <target state="translated">ニックストリート</target>
        </trans-unit>
        <trans-unit id="91b4478e43e149a2b1b071a76d13f7593530f726" translate="yes" xml:space="preserve">
          <source>No measurement errors, only modelling errors (fitting a sine with a polynomial)</source>
          <target state="translated">測定誤差はなく,モデリング誤差のみ(多項式を用いた正弦波のフィット</target>
        </trans-unit>
        <trans-unit id="53e801c8ef7a5f95a28c0516586238c464a24031" translate="yes" xml:space="preserve">
          <source>No penalty (&amp;lsquo;none&amp;rsquo;)</source>
          <target state="translated">ペナルティなし（「なし」）</target>
        </trans-unit>
        <trans-unit id="ea249cedbd757dbfa8a8d6da523734c90b706a5c" translate="yes" xml:space="preserve">
          <source>No-op.</source>
          <target state="translated">No-op.</target>
        </trans-unit>
        <trans-unit id="91eb5693ecb00a7deb087fb78e26bb4414167d8c" translate="yes" xml:space="preserve">
          <source>Noisy (non informative) features are added to the iris data and univariate feature selection is applied. For each feature, we plot the p-values for the univariate feature selection and the corresponding weights of an SVM. We can see that univariate feature selection selects the informative features and that these have larger SVM weights.</source>
          <target state="translated">虹彩データにノイズの多い(非情報的な)特徴が追加され、一変量特徴選択が適用される。各特徴について、一変量特徴選択のp値とSVMの対応する重みをプロットします。一変量特徴選択では情報量の多い特徴が選択され、SVMの重みが大きくなることがわかります。</target>
        </trans-unit>
        <trans-unit id="7bfbed76958c0127f9523f9a22b3af54ca060586" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{jk}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非計量&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;は、データの順序付けに焦点を合わせています。\（S_ {ij} &amp;lt;S_ {jk} \）の場合、埋め込みは\（d_ {ij} &amp;lt;d_ {jk} \）を強制する必要があります。\（S_ {ij} \）で\（d_ {ij} \）の単調回帰を使用して、同じ順序で視差\（\ hat {d} _ {ij} \）を生成する、強制する簡単なアルゴリズム\（S_ {ij} \）として。</target>
        </trans-unit>
        <trans-unit id="79474361fd46a8f4ede8053ea7e6b01fe3e41cb6" translate="yes" xml:space="preserve">
          <source>Non metric &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; focuses on the ordination of the data. If \(S_{ij} &amp;lt; S_{kl}\), then the embedding should enforce \(d_{ij} &amp;lt; d_{jk}\). A simple algorithm to enforce that is to use a monotonic regression of \(d_{ij}\) on \(S_{ij}\), yielding disparities \(\hat{d}_{ij}\) in the same order as \(S_{ij}\).</source>
          <target state="translated">非メトリック&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;は、データの順序に焦点を当てています。\（S_ {ij} &amp;lt;S_ {kl} \）の場合、埋め込みは\（d_ {ij} &amp;lt;d_ {jk} \）を強制する必要があります。これを強制する単純なアルゴリズムは、\（S_ {ij} \）に対して\（d_ {ij} \）の単調回帰を使用し、同じ順序で視差\（\ hat {d} _ {ij} \）を生成することです。 \（S_ {ij} \）として。</target>
        </trans-unit>
        <trans-unit id="cde06657a13db59e2826469e9066556199cf0756" translate="yes" xml:space="preserve">
          <source>Non-Negative Matrix Factorization (NMF)</source>
          <target state="translated">非負行列因数分解(NMF)</target>
        </trans-unit>
        <trans-unit id="68976e33a3c8d43b10cc9525f441a8468ba55fa6" translate="yes" xml:space="preserve">
          <source>Non-adjusted measures such as the V-Measure show a dependency between the number of clusters and the number of samples: the mean V-Measure of random labeling increases significantly as the number of clusters is closer to the total number of samples used to compute the measure.</source>
          <target state="translated">Vメジャーのような非調整メジャーは、クラスタ数とサンプル数の間に依存性を示します:ランダムラベリングの平均Vメジャーは、クラスタ数がメジャーの計算に使用されるサンプル数の合計に近づくにつれて有意に増加します。</target>
        </trans-unit>
        <trans-unit id="f88076515287321d1c6a383215ea60241a35e283" translate="yes" xml:space="preserve">
          <source>Non-categorical features are always stacked to the right of the matrix.</source>
          <target state="translated">カテゴライズされていない特徴は、常に行列の右側に積み上げられています。</target>
        </trans-unit>
        <trans-unit id="24a06b494b2c3f21a83a9f0f9fdd0eb49c7e8dca" translate="yes" xml:space="preserve">
          <source>Non-deterministic iterable over random candidate combinations for hyper- parameter search. If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">超パラメータ探索のためのランダムな候補の組み合わせに対する非決定論的な反復可能性。すべてのパラメータがリストとして提示された場合、置換なしのサンプリングが実行されます。少なくとも1つのパラメータが分布として与えられた場合、置換を伴うサンプリングが使用される。連続パラメータには連続分布を使用することが強く推奨されます。</target>
        </trans-unit>
        <trans-unit id="aed22ef611faa3f82d0b12f8491e5be1b5315c9c" translate="yes" xml:space="preserve">
          <source>Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.</source>
          <target state="translated">非平坦形状クラスタリングは、クラスタが特定の形状、すなわち非平坦な多様体を持ち、標準的なユークリッド距離が正しいメトリックではない場合に有用である。このケースは、上の図の上の2つの行に現れます。</target>
        </trans-unit>
        <trans-unit id="d81a98cb7a8247dec56f2cf029b08c2754ab68be" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes</source>
          <target state="translated">非フラット形状、不均一なクラスターサイズ</target>
        </trans-unit>
        <trans-unit id="e75d67cb225b885154dd48c75a213bc3e9636016" translate="yes" xml:space="preserve">
          <source>Non-flat geometry, uneven cluster sizes, variable cluster density</source>
          <target state="translated">非フラット形状、不均一なクラスターサイズ、可変クラスター密度</target>
        </trans-unit>
        <trans-unit id="7b7727887cb8285fcb9cde529e76207a2b5daf47" translate="yes" xml:space="preserve">
          <source>Non-linear SVM</source>
          <target state="translated">非線形SVM</target>
        </trans-unit>
        <trans-unit id="71ce2ef9edaad67f892b761574c731b5860fa36a" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through Isometric Mapping</source>
          <target state="translated">アイソメトリックマッピングによる非線形次元削減</target>
        </trans-unit>
        <trans-unit id="ca7d812e2ac6b7f89b19c50d5270fc422c0be019" translate="yes" xml:space="preserve">
          <source>Non-linear dimensionality reduction through the use of kernels (see &lt;a href=&quot;../metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt;).</source>
          <target state="translated">カーネルの使用による非線形の次元削減（&lt;a href=&quot;../metrics#metrics&quot;&gt;ペアワイズメトリック、アフィニティとカーネルを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="69451865a7cd1607229864b3445a0d944d36c962" translate="yes" xml:space="preserve">
          <source>Non-negative Matrix Factorization is applied with two different objective functions: the Frobenius norm, and the generalized Kullback-Leibler divergence. The latter is equivalent to Probabilistic Latent Semantic Indexing.</source>
          <target state="translated">非負行列因子分解は、2つの異なる目的関数、すなわち、フロベニウスノルムと一般化されたKullback-Leibler発散を用いて適用される。後者は、確率的潜在的意味索引付けに相当する。</target>
        </trans-unit>
        <trans-unit id="049d9a61285421f1af788bdccc4c4d917a5eaaf1" translate="yes" xml:space="preserve">
          <source>Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.</source>
          <target state="translated">共分散の対角線に追加される非負の正則化.共分散行列がすべて正であることを保証することができます.</target>
        </trans-unit>
        <trans-unit id="e703a00863d9d81a02bf7dd7a3e8359867bf5db3" translate="yes" xml:space="preserve">
          <source>Non-negativity: d(x, y) &amp;gt;= 0</source>
          <target state="translated">非負性：d（x、y）&amp;gt; = 0</target>
        </trans-unit>
        <trans-unit id="8ae68d0948137da9bc3c21e9e27af7e4326ecb8c" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that assign all classes members to the same clusters are still complete:</source>
          <target state="translated">すべてのクラスのメンバーを同じクラスタに割り当てる非完全なラベリングはまだ完成しています。</target>
        </trans-unit>
        <trans-unit id="3eebc1d955c5491410d251396ee4489d9155e3cb" translate="yes" xml:space="preserve">
          <source>Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:</source>
          <target state="translated">クラスをさらに多くのクラスタに分割する非完全なラベリングは、完全に均質なものにすることができます。</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="cc144a8b86207cd903656d8b31d75d721fe9dfb7" translate="yes" xml:space="preserve">
          <source>None : retain all features (the default).</source>
          <target state="translated">None:すべての機能を保持します(デフォルト)。</target>
        </trans-unit>
        <trans-unit id="ff2ddb49167696f5a698e9f0e7cdd839b8eb8d6f" translate="yes" xml:space="preserve">
          <source>None : when any outlier is detected, ValueError will be raised.</source>
          <target state="translated">None :外れ値が検出された場合、ValueErrorを発生させます。</target>
        </trans-unit>
        <trans-unit id="a7d85d18152a49d1da74509ce25fde6fe11019f7" translate="yes" xml:space="preserve">
          <source>None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs</source>
          <target state="translated">Noneの場合、すべてのジョブが即座に作成され、スポーンされます。軽量で高速に実行されるジョブに使用し、ジョブのオンデマンドスポーンによる遅延を回避します。</target>
        </trans-unit>
        <trans-unit id="bbd7e8e517d8f43bda3aa20760641b5d7e8f9cfa" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross validation,</source>
          <target state="translated">なし、デフォルトの3つ折りのクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="888271bd46afcca7669b4e3985d515e3c7e7f9d8" translate="yes" xml:space="preserve">
          <source>None, to use the default 3-fold cross-validation,</source>
          <target state="translated">なし、デフォルトの3-foldクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="13182ccf32b1d9cf4c4c76a99a35a2cf619a1e90" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross validation,</source>
          <target state="translated">なし、デフォルトの5倍のクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="93be41b6686f4cc42a91be2da8610759134def66" translate="yes" xml:space="preserve">
          <source>None, to use the default 5-fold cross-validation,</source>
          <target state="translated">なし、デフォルトの5倍のクロスバリデーションを使用します。</target>
        </trans-unit>
        <trans-unit id="701ee91f692f57554848e1c6f0edff54e4f7d839" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation</source>
          <target state="translated">なし、効率的なLeave-One-Outクロスバリデーションを使用するには</target>
        </trans-unit>
        <trans-unit id="d7a547edfb07309939d3c23d0b3c605eac4c310a" translate="yes" xml:space="preserve">
          <source>None, to use the efficient Leave-One-Out cross-validation (also known as Generalized Cross-Validation).</source>
          <target state="translated">なし、効率的なLeave-One-Outクロスバリデーション(一般化クロスバリデーションとしても知られている)を使用する。</target>
        </trans-unit>
        <trans-unit id="eb8094c10799533f02930dac24b80933c23d4beb" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt; n_features, otherwise &amp;lsquo;random&amp;rsquo;.</source>
          <target state="translated">なし：「nndsvd」（n_components &amp;lt;n_featuresの場合）、それ以外の場合は「ランダム」。</target>
        </trans-unit>
        <trans-unit id="ac08cb5e83064548a9a5dbf3f70202653e682537" translate="yes" xml:space="preserve">
          <source>None: &amp;lsquo;nndsvd&amp;rsquo; if n_components &amp;lt;= min(n_samples, n_features),</source>
          <target state="translated">なし： 'nndsvd' if n_components &amp;lt;= min（n_samples、n_features）、</target>
        </trans-unit>
        <trans-unit id="64b167835d86e0f7a116b1ea8c9009b09567d9bf" translate="yes" xml:space="preserve">
          <source>None: no shrinkage (default).</source>
          <target state="translated">なし:収縮なし(デフォルト)。</target>
        </trans-unit>
        <trans-unit id="147e773e8ccd784cf7c8200779acc5978ecfc7ee" translate="yes" xml:space="preserve">
          <source>Nonflavanoid Phenols:</source>
          <target state="translated">ノンフラバノイドフェノール類。</target>
        </trans-unit>
        <trans-unit id="906dd4b97159051d3691e718b04ffdc7a18ebb83" translate="yes" xml:space="preserve">
          <source>Nonflavanoid phenols</source>
          <target state="translated">ノンフラバノイドフェノール</target>
        </trans-unit>
        <trans-unit id="c5cf58c1ab6a436b96c0b6790ce2675b3d6917ee" translate="yes" xml:space="preserve">
          <source>Norm used to normalize term vectors. None for no normalization.</source>
          <target state="translated">項ベクトルの正規化に使用されるノルム。正規化を行わない場合は None。</target>
        </trans-unit>
        <trans-unit id="45e118d0563ea8581f830f46e85b60ae714faae4" translate="yes" xml:space="preserve">
          <source>Normal</source>
          <target state="translated">Normal</target>
        </trans-unit>
        <trans-unit id="baeabcda0198bd70ffaabb333ee49b38a8e0ee34" translate="yes" xml:space="preserve">
          <source>Normal and Shrinkage Linear Discriminant Analysis for classification</source>
          <target state="translated">分類のための正規および収縮線形判別分析</target>
        </trans-unit>
        <trans-unit id="1c651aee92e671db7fa9048c6cdacbd12ea197da" translate="yes" xml:space="preserve">
          <source>Normalization matrix needed for embedding. Square root of the kernel matrix on &lt;code&gt;components_&lt;/code&gt;.</source>
          <target state="translated">埋め込みに必要な正規化行列。 &lt;code&gt;components_&lt;/code&gt; のカーネル行列の平方根。</target>
        </trans-unit>
        <trans-unit id="b2dd009a742549bee9ad100542b0f67ba3a05708" translate="yes" xml:space="preserve">
          <source>Normalize samples individually to unit norm.</source>
          <target state="translated">サンプルを個別に単位ノルムに正規化します。</target>
        </trans-unit>
        <trans-unit id="1cc78071dce653cdb1a895ced93da41b36798ab2" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information</source>
          <target state="translated">正規化相互情報</target>
        </trans-unit>
        <trans-unit id="6d15c4ae0d04e936f901929872b9ad476ca9800b" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of &lt;code&gt;H(labels_true)&lt;/code&gt; and &lt;code&gt;H(labels_pred))&lt;/code&gt;, defined by the &lt;code&gt;average_method&lt;/code&gt;.</source>
          <target state="translated">正規化相互情報量（NMI）は、相互情報量（MI）スコアを正規化して、結果を0（相互情報なし）と1（完全相関）の間でスケーリングします。この関数では、相互情報は、 &lt;code&gt;average_method&lt;/code&gt; で定義される &lt;code&gt;H(labels_true)&lt;/code&gt; および &lt;code&gt;H(labels_pred))&lt;/code&gt; のいくつかの一般化された平均によって正規化されます。</target>
        </trans-unit>
        <trans-unit id="2009d38e6ab058cf38d5f44a4aa1fda0316b3372" translate="yes" xml:space="preserve">
          <source>Normalized Mutual Information between two clusterings.</source>
          <target state="translated">2つのクラスタリング間の正規化された相互情報。</target>
        </trans-unit>
        <trans-unit id="4f7979e77b9a0db2d6d4f14823a6b0012cc9a130" translate="yes" xml:space="preserve">
          <source>Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</source>
          <target state="translated">正規化されたカットと画像の分割、2000 Jianbo Shi、Jitendra Malik &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="bcdc09e5b38e3433007fe04c41bf1718c142c846" translate="yes" xml:space="preserve">
          <source>Normalized input X.</source>
          <target state="translated">正規化された入力X。</target>
        </trans-unit>
        <trans-unit id="cf0305ad6a5172727382b32897870cffde3ce433" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels</source>
          <target state="translated">クラスラベルにまたがる正規化された確率分布</target>
        </trans-unit>
        <trans-unit id="53f158b7f3551b0f974a1547fdea15ef3000e7be" translate="yes" xml:space="preserve">
          <source>Normalized probability distributions across class labels.</source>
          <target state="translated">クラスラベルにまたがる正規化された確率分布。</target>
        </trans-unit>
        <trans-unit id="3dd51ff507e0ed7c736dd049baf65846cc243ec4" translate="yes" xml:space="preserve">
          <source>Normalized total reduction of criteria by feature (Gini importance).</source>
          <target state="translated">特徴(ジニ重要度)による基準の正規化された総削減。</target>
        </trans-unit>
        <trans-unit id="f4b126cd68b1eba9b799b0ffccc1898e8bfe924f" translate="yes" xml:space="preserve">
          <source>Normalizer</source>
          <target state="translated">Normalizer</target>
        </trans-unit>
        <trans-unit id="2b3ec4d083535b907de33251ab28d9b72b55d74b" translate="yes" xml:space="preserve">
          <source>Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.</source>
          <target state="translated">混同行列を,真の条件(行),予測された条件(列),または全母集団に対して正規化します.Noneの場合,混同行列は正規化されません.</target>
        </trans-unit>
        <trans-unit id="a19366221588f526c166820c530dd8f2268ea2b7" translate="yes" xml:space="preserve">
          <source>Not all models benefit from optimized BLAS and Lapack implementations. For instance models based on (randomized) decision trees typically do not rely on BLAS calls in their inner loops, nor do kernel SVMs (&lt;code&gt;SVC&lt;/code&gt;, &lt;code&gt;SVR&lt;/code&gt;, &lt;code&gt;NuSVC&lt;/code&gt;, &lt;code&gt;NuSVR&lt;/code&gt;). On the other hand a linear model implemented with a BLAS DGEMM call (via &lt;code&gt;numpy.dot&lt;/code&gt;) will typically benefit hugely from a tuned BLAS implementation and lead to orders of magnitude speedup over a non-optimized BLAS.</source>
          <target state="translated">すべてのモデルが、最適化されたBLASおよびLapack実装の恩恵を受けるわけではありません。たとえば、（ランダム化された）決定木に基づくインスタンスモデルは、通常、内部ループのBLAS呼び出しに依存せず、カーネルSVM（ &lt;code&gt;SVC&lt;/code&gt; 、 &lt;code&gt;SVR&lt;/code&gt; 、 &lt;code&gt;NuSVC&lt;/code&gt; 、 &lt;code&gt;NuSVR&lt;/code&gt; ）にも依存しません。一方、BLAS DGEMM呼び出し（ &lt;code&gt;numpy.dot&lt;/code&gt; を介して）で実装された線形モデルは、通常、調整されたBLAS実装から大きな恩恵を受け、最適化されていないBLASよりも桁違いに高速化されます。</target>
        </trans-unit>
        <trans-unit id="d1a17af19f5388af9d6596cc0ea7dbb1d739e255" translate="yes" xml:space="preserve">
          <source>Not available</source>
          <target state="translated">利用できません。</target>
        </trans-unit>
        <trans-unit id="2f1306ffef95e5ddbb8f4b2f3a60c6ede1c9a1f3" translate="yes" xml:space="preserve">
          <source>Not scalable</source>
          <target state="translated">スケーラブルではない</target>
        </trans-unit>
        <trans-unit id="6671bcf801635373715efa03216b0f9d13f34c22" translate="yes" xml:space="preserve">
          <source>Not scalable with &lt;code&gt;n_samples&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; ではスケーラブルではありません</target>
        </trans-unit>
        <trans-unit id="d70eb56b501fa2ef808df1c818502bbb5b800d19" translate="yes" xml:space="preserve">
          <source>Not scalable with n_samples</source>
          <target state="translated">n_samplesではスケーラブルではない</target>
        </trans-unit>
        <trans-unit id="5f0f2378acb52b70e08107dc0bdd42ae2edf4fdf" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistence purpose.</source>
          <target state="translated">使用されず、APIの整合性のために存在します。</target>
        </trans-unit>
        <trans-unit id="3c8ec850c7c26d11c7ae99e5fae0ce11ac404b3f" translate="yes" xml:space="preserve">
          <source>Not used, present for API consistency by convention.</source>
          <target state="translated">使用されていません。APIの一貫性を保つために規約に基づいて存在します。</target>
        </trans-unit>
        <trans-unit id="abfeb2bc66d46ae118c694d4f663b42a0b277b39" translate="yes" xml:space="preserve">
          <source>Not used, present here for API consistency by convention.</source>
          <target state="translated">使用されていませんが、規約によるAPIの一貫性のためにここに存在します。</target>
        </trans-unit>
        <trans-unit id="3f8740a7ea28a56477d25ad1aaaf52d864b49a7d" translate="yes" xml:space="preserve">
          <source>NotFittedError</source>
          <target state="translated">NotFittedError</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="14ba06ae5f3993adde2848620bcf508016c9c617" translate="yes" xml:space="preserve">
          <source>Note : Laplacian Eigenmaps is the actual algorithm implemented here.</source>
          <target state="translated">注:ラプラシアン固有マップは、ここで実装されている実際のアルゴリズムです。</target>
        </trans-unit>
        <trans-unit id="21546711de316cf946ba53a498f41ae0550616cc" translate="yes" xml:space="preserve">
          <source>Note how some use the group/class information while others do not.</source>
          <target state="translated">グループ/クラス情報を使用している人もいれば、使用していない人もいることに注意してください。</target>
        </trans-unit>
        <trans-unit id="c3c271844b997675d3bb1a8d39599227fbe7b490" translate="yes" xml:space="preserve">
          <source>Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data.</source>
          <target state="translated">アルファの最適値が、各フォールドについてどのように変化するかに注意してください。これは、クロスバリデーションによってパラメータが選択された手法の性能を評価しようとするときに、なぜ入れ子交差バリデーションが必要なのかを説明しています:このパラメータの選択は、見えないデータに対して最適ではないかもしれません。</target>
        </trans-unit>
        <trans-unit id="92e53ea7bdcc226c7bc1da5197dd56da468b26d1" translate="yes" xml:space="preserve">
          <source>Note on inappropriate usage of cross_val_predict</source>
          <target state="translated">cross_val_predictの不適切な使い方についての注意点</target>
        </trans-unit>
        <trans-unit id="b437e168efe2a06e08f52a3ad3a931f217ecf431" translate="yes" xml:space="preserve">
          <source>Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):</source>
          <target state="translated">上記のグラフモデルで提示された表記法についての注意点は、Hoffmanら(2013)に記載されている。</target>
        </trans-unit>
        <trans-unit id="029f2db65bc50c936edb77149f903f8d03abd995" translate="yes" xml:space="preserve">
          <source>Note on the lookup process: depending on the type of name_or_id, will choose between integer id lookup or metadata name lookup by looking at the unzipped archives and metadata file.</source>
          <target state="translated">検索処理に関する注意事項:name_or_id のタイプに応じて、解凍されたアーカイブとメタデータファイルを見て、整数 ID 検索かメタデータ名検索のどちらかを選択します。</target>
        </trans-unit>
        <trans-unit id="637677b94f16fb377d9bcfbae4602956aad7da33" translate="yes" xml:space="preserve">
          <source>Note that &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.</source>
          <target state="translated">「サグ」と「サガ」の高速収束は、ほぼ同じスケールの機能でのみ保証されることに注意してください。sklearn.preprocessingのスケーラーを使用してデータを前処理できます。</target>
        </trans-unit>
        <trans-unit id="92f3fcd7326295f6a74b7d0528bb22c0cf404ba4" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt;&lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;&lt;/a&gt; is different from KNN imputation, which learns from samples with missing values by using a distance metric that accounts for missing values, rather than imputing them.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsregressor#sklearn.neighbors.KNeighborsRegressor&quot;&gt; &lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt; &lt;/a&gt;は、欠測値を代入するのではなく、欠測値を説明する距離メトリックを使用して欠測値のあるサンプルから学習するKNN代入とは異なることに注意してください。</target>
        </trans-unit>
        <trans-unit id="bfc6f56d0d9af5825aa3c5bc1de0fcc87a2bde36" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; calculates unadjusted R&amp;sup2; without correcting for bias in sample variance of y.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt;は、yのサンプル分散のバイアスを補正せずに未調整のR&amp;sup2;を計算することに注意してください。</target>
        </trans-unit>
        <trans-unit id="fb2d865fbf24560bc423d4932883d3877000a02a" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; does not support &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods by default but only a &lt;code&gt;fit_predict&lt;/code&gt; method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">注意&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; が&lt;/a&gt;サポートされていない &lt;code&gt;predict&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; と &lt;code&gt;score_samples&lt;/code&gt; デフォルトだけでメソッドを &lt;code&gt;fit_predict&lt;/code&gt; のこの推定は、もともと外れ値検出に適用されることを意図したように、方法。トレーニングサンプルの異常スコアには、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を介してアクセスできます。</target>
        </trans-unit>
        <trans-unit id="c2b0ede00caa9f24f249766b854d734ce8a77594" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;estimators_&lt;/code&gt; are fitted on the full &lt;code&gt;X&lt;/code&gt; while &lt;code&gt;final_estimator_&lt;/code&gt; is trained using cross-validated predictions of the base estimators using &lt;code&gt;cross_val_predict&lt;/code&gt;.</source>
          <target state="translated">そのノート &lt;code&gt;estimators_&lt;/code&gt; が完全に装着されている &lt;code&gt;X&lt;/code&gt; ながら &lt;code&gt;final_estimator_&lt;/code&gt; を用いて基地推定の交差検定予測使用して訓練される &lt;code&gt;cross_val_predict&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="9cc23e915eab7d76b355d3d788a42c200a9cfa75" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;fit_predict&lt;/code&gt; is not available in this case.</source>
          <target state="translated">この場合、 &lt;code&gt;fit_predict&lt;/code&gt; は使用できません。</target>
        </trans-unit>
        <trans-unit id="a64277fe0445c7a49bb63f1b3128c36db8f44687" translate="yes" xml:space="preserve">
          <source>Note that &lt;strong&gt;early-stopping is enabled by default if the number of samples is larger than 10,000&lt;/strong&gt;. The early-stopping behaviour is controlled via the &lt;code&gt;early-stopping&lt;/code&gt;, &lt;code&gt;scoring&lt;/code&gt;, &lt;code&gt;validation_fraction&lt;/code&gt;, &lt;code&gt;n_iter_no_change&lt;/code&gt;, and &lt;code&gt;tol&lt;/code&gt; parameters. It is possible to early-stop using an arbitrary &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;scorer&lt;/a&gt;, or just the training or validation loss. Note that for technical reasons, using a scorer is significantly slower than using the loss. By default, early-stopping is performed if there are at least 10,000 samples in the training set, using the validation loss.</source>
          <target state="translated">&lt;strong&gt;サンプル数が10,000を超える場合、デフォルト&lt;/strong&gt;で&lt;strong&gt;早期停止が有効になっ&lt;/strong&gt;ていることに注意してください。早期停止の動作は、 &lt;code&gt;early-stopping&lt;/code&gt; 、 &lt;code&gt;scoring&lt;/code&gt; 、 &lt;code&gt;validation_fraction&lt;/code&gt; 、 &lt;code&gt;n_iter_no_change&lt;/code&gt; 、および &lt;code&gt;tol&lt;/code&gt; パラメーターを介して制御されます。任意の&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scorer&quot;&gt;スコアラー&lt;/a&gt;を使用して早期停止することも、トレーニングや検証の損失だけを停止することもできます。技術的な理由から、スコアラーの使用は損失の使用よりも大幅に遅いことに注意してください。デフォルトでは、トレーニングセットに少なくとも10,000のサンプルがある場合、検証損失を使用して早期停止が実行されます。</target>
        </trans-unit>
        <trans-unit id="05da1e73517821e307ab23620f26a2cb5cf58320" translate="yes" xml:space="preserve">
          <source>Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.</source>
          <target state="translated">スパースPCA成分の直交性はPCAのように強制されないので、単純な線形射影を使用できないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="6d11171b334a15c9f3a0ed71d47a8e76e15de782" translate="yes" xml:space="preserve">
          <source>Note that a call to the &lt;code&gt;transform&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;transform&lt;/code&gt; メソッドを呼び出しても、サンプル数を変更できないことに注意してください。したがって、 &lt;code&gt;transform&lt;/code&gt; の1回の呼び出しで複数の代入を実行することはできません。</target>
        </trans-unit>
        <trans-unit id="38919ec8aa75d45b22406b99670380fbc01ee90e" translate="yes" xml:space="preserve">
          <source>Note that all classifiers handling multioutput-multiclass (also known as multitask classification) tasks, support the multilabel classification task as a special case. Multitask classification is similar to the multioutput classification task with different model formulations. For more information, see the relevant estimator documentation.</source>
          <target state="translated">マルチ出力-マルチクラス(マルチタスク分類とも呼ばれる)タスクを扱うすべての分類器は、特殊なケースとしてマルチラベル分類タスクをサポートしていることに注意してください。マルチタスク分類は、モデルの定式化が異なるマルチ出力分類タスクに似ています。詳細については、関連する推定器のドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="3a04205581b19a745020f7a71bf7734034b648ca" translate="yes" xml:space="preserve">
          <source>Note that backwards compatibility may not be supported.</source>
          <target state="translated">下位互換性はサポートされていない場合がありますのでご注意ください。</target>
        </trans-unit>
        <trans-unit id="8a36ac6808e625c8a29705bcc1d1fb6cf63760b8" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space.</source>
          <target state="translated">SciPy 0.16より前では、 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; はカスタムRNGインスタンスを受け入れず、常に &lt;code&gt;numpy.random&lt;/code&gt; のシングルトンRNGを使用することに注意してください。したがって、 &lt;code&gt;random_state&lt;/code&gt; を設定しても、 &lt;code&gt;scipy.stats&lt;/code&gt; 分布を使用してパラメーターサーチスペースを定義する場合は常に、確定的な反復が保証されません。</target>
        </trans-unit>
        <trans-unit id="9a716693e5778e1463e7644515aedc4c9b2a1b82" translate="yes" xml:space="preserve">
          <source>Note that before SciPy 0.16, the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; do not accept a custom RNG instance and always use the singleton RNG from &lt;code&gt;numpy.random&lt;/code&gt;. Hence setting &lt;code&gt;random_state&lt;/code&gt; will not guarantee a deterministic iteration whenever &lt;code&gt;scipy.stats&lt;/code&gt; distributions are used to define the parameter search space. Deterministic behavior is however guaranteed from SciPy 0.16 onwards.</source>
          <target state="translated">SciPy 0.16以前は、 &lt;code&gt;scipy.stats.distributions&lt;/code&gt; はカスタムRNGインスタンスを受け入れず、常に &lt;code&gt;numpy.random&lt;/code&gt; からのシングルトンRNGを使用することに注意してください。したがって、 &lt;code&gt;random_state&lt;/code&gt; を設定しても、 &lt;code&gt;scipy.stats&lt;/code&gt; 分布を使用してパラメーターサーチスペースを定義する場合は常に、確定的な反復が保証されません。ただし、確定的な動作はSciPy 0.16以降で保証されています。</target>
        </trans-unit>
        <trans-unit id="8803233984e598253564c68adac3c470cc868526" translate="yes" xml:space="preserve">
          <source>Note that even for a classification task, the \(h_m\) sub-estimator is still a regressor, not a classifier. This is because the sub-estimators are trained to predict (negative) &lt;em&gt;gradients&lt;/em&gt;, which are always continuous quantities.</source>
          <target state="translated">分類タスクの場合でも、\（h_m \）サブ推定量は依然としてリグレッサーであり、分類子ではないことに注意してください。これは、サブ推定量が（負の）&lt;em&gt;勾配&lt;/em&gt;を予測するようにトレーニングされているためです。&lt;em&gt;勾配&lt;/em&gt;は常に連続量です。</target>
        </trans-unit>
        <trans-unit id="45e5cb26ef2b019b9c0f33d27cd0fca50cc9bb8f" translate="yes" xml:space="preserve">
          <source>Note that for any single value of &lt;code&gt;eps&lt;/code&gt;, DBSCAN will tend to have a shorter run time than OPTICS; however, for repeated runs at varying &lt;code&gt;eps&lt;/code&gt; values, a single run of OPTICS may require less cumulative runtime than DBSCAN. It is also important to note that OPTICS&amp;rsquo; output is close to DBSCAN&amp;rsquo;s only if &lt;code&gt;eps&lt;/code&gt; and &lt;code&gt;max_eps&lt;/code&gt; are close.</source>
          <target state="translated">&lt;code&gt;eps&lt;/code&gt; の単一の値の場合、DBSCANの実行時間はOPTICSよりも短くなる傾向があることに注意してください。ただし、さまざまな &lt;code&gt;eps&lt;/code&gt; 値で繰り返し実行する場合、OPTICSを1回実行すると、DBSCANよりも累積実行時間が少なくて済みます。 &lt;code&gt;eps&lt;/code&gt; と &lt;code&gt;max_eps&lt;/code&gt; が近い場合にのみ、OPTICSの出力がDBSCANの出力に近いことに注意することも重要です。</target>
        </trans-unit>
        <trans-unit id="8c441ea193159e43e5ae4f2f43b7cd455bbc50a0" translate="yes" xml:space="preserve">
          <source>Note that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for &lt;code&gt;float32&lt;/code&gt; (see example below). Specifying a higher-precision accumulator using the &lt;code&gt;dtype&lt;/code&gt; keyword can alleviate this issue.</source>
          <target state="translated">浮動小数点入力の場合、平均は入力と同じ精度を使用して計算されることに注意してください。入力データによっては、特に &lt;code&gt;float32&lt;/code&gt; の場合、結果が不正確になる可能性があります（以下の例を参照）。 &lt;code&gt;dtype&lt;/code&gt; キーワードを使用してより精度の高いアキュムレータを指定すると、この問題を軽減できます。</target>
        </trans-unit>
        <trans-unit id="1c1b3dcae0a3cdb049378b61a52e8a6e218b843e" translate="yes" xml:space="preserve">
          <source>Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].</source>
          <target state="translated">マルチ出力(マルチラベルを含む)では、各列の各クラスごとに重みを定義しなければならないことに注意してください。例えば、4クラスのマルチラベル分類の場合、重みは[{1:1},{2:5},{3:1},{4:1}]ではなく、[{0:1,1:1},{0:1,1:5},{0:1,1},{0:1,1:1}]とする必要があります。</target>
        </trans-unit>
        <trans-unit id="7f057f4a3cfb222efbfc3fdf93e59924824aafce" translate="yes" xml:space="preserve">
          <source>Note that if features have very different scaling or statistical properties, &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; may not be able to capture the links between related features. Using a &lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt;&lt;code&gt;preprocessing.StandardScaler&lt;/code&gt;&lt;/a&gt; can be useful in these settings.</source>
          <target state="translated">フィーチャのスケーリングまたは統計プロパティが大きく異なる場合、&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;cluster.FeatureAgglomeration&lt;/code&gt; &lt;/a&gt;は関連するフィーチャ間のリンクをキャプチャできない場合があることに注意してください。これらの設定では、&lt;a href=&quot;generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler&quot;&gt; &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; &lt;/a&gt;を使用すると便利です。</target>
        </trans-unit>
        <trans-unit id="daa34c655040f11fbac2193226735416d5ff6724" translate="yes" xml:space="preserve">
          <source>Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:</source>
          <target state="translated">類似度行列の値がよく分布していない場合、例えば負の値を持つ場合や、類似度ではなく距離行列を持つ場合、スペクトルの問題は特異であり、解けないことに注意してください。この場合,行列のエントリに変換を適用することをお勧めします.例えば,符号付き距離行列の場合,ヒートカーネルを適用するのが一般的です.</target>
        </trans-unit>
        <trans-unit id="82c5d12dd2770bc5d00d9e0fd296f522b36a2aec" translate="yes" xml:space="preserve">
          <source>Note that in binary classification, recall of the positive class is also known as &amp;ldquo;sensitivity&amp;rdquo;; recall of the negative class is &amp;ldquo;specificity&amp;rdquo;.</source>
          <target state="translated">バイナリ分類では、陽性クラスの再現は「感度」とも呼ばれます。否定的なクラスの想起は「特異性」です。</target>
        </trans-unit>
        <trans-unit id="56700fbea0a4382f56515fac76889ee512c8d3cb" translate="yes" xml:space="preserve">
          <source>Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path</source>
          <target state="translated">特定のケースでは、この機能を実装するにはLarsソルバーの方が大幅に高速である可能性があることに注意してください。特に、線形補間を使用して、lars_path</target>
        </trans-unit>
        <trans-unit id="c065b9ad388e273aa3b214ab1297a55e0496eb57" translate="yes" xml:space="preserve">
          <source>Note that in general, robust fitting in high-dimensional setting (large &lt;code&gt;n_features&lt;/code&gt;) is very hard. The robust models here will probably not work in these settings.</source>
          <target state="translated">一般に、高次元の設定（大きな &lt;code&gt;n_features&lt;/code&gt; ）でのロバストなフィッティングは非常に難しいことに注意してください。ここでのロバストモデルは、おそらくこれらの設定では機能しません。</target>
        </trans-unit>
        <trans-unit id="64011c56ebca18074907020d8d3e99112269576a" translate="yes" xml:space="preserve">
          <source>Note that in practice, one would not search over this many different parameters simultaneously using grid search, but pick only the ones deemed most important.</source>
          <target state="translated">実際には、グリッド検索を使ってこのように多くの異なるパラメータを同時に検索するのではなく、最も重要と思われるものだけを選択することに注意してください。</target>
        </trans-unit>
        <trans-unit id="b7d16723edd6b0c8a445c16934e7dfaedb2752ae" translate="yes" xml:space="preserve">
          <source>Note that in the case of &amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo; and &amp;lsquo;euclidean&amp;rsquo; (which are valid scipy.spatial.distance metrics), the scikit-learn implementation will be used, which is faster and has support for sparse matrices (except for &amp;lsquo;cityblock&amp;rsquo;). For a verbose description of the metrics from scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics function.</source>
          <target state="translated">'cityblock'、 'cosine'、および 'euclidean'（有効なscipy.spatial.distanceメトリックス）の場合、scikit-learn実装が使用されることに注意してください。これはより高速で、スパース行列をサポートしています（ただし、 「cityblock」）。 scikit-learnからのメトリックの詳細な説明については、sklearn.pairwise.distance_metrics関数の__doc__を参照してください。</target>
        </trans-unit>
        <trans-unit id="81154799705dfac8836df66f3a0269041db1173b" translate="yes" xml:space="preserve">
          <source>Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.</source>
          <target state="translated">マルチラベルの場合,各標本は任意の数のラベルを持つことができることに注意してください.これは,与えられた標本が問題のラベルを持つ限界確率を返します.例えば、2つのラベルが与えられた標本に適用される確率が90%であることは完全に一致しています。</target>
        </trans-unit>
        <trans-unit id="01d7bf1a38a1f2f757397967cae9b7d66ce2602c" translate="yes" xml:space="preserve">
          <source>Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):</source>
          <target state="translated">前のコーパスでは、最初の文書と最後の文書は全く同じ単語を持っているので、等しいベクトルでエンコードされていることに注意してください。特に、最後の文書が質問形式であるという情報が失われています。局所的な順序情報の一部を保存するために、1-gram(個々の単語)に加えて、2-gramの単語を抽出することができます。</target>
        </trans-unit>
        <trans-unit id="61d12fb0837cc546c2865fefff8f9a5fb5f27798" translate="yes" xml:space="preserve">
          <source>Note that it is also possible to get the output of the stacked &lt;code&gt;estimators&lt;/code&gt; using the &lt;code&gt;transform&lt;/code&gt; method:</source>
          <target state="translated">&lt;code&gt;transform&lt;/code&gt; 方法を使用して、スタックされた &lt;code&gt;estimators&lt;/code&gt; 出力を取得することも可能であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="8dcb354ad6f05344d318f25389a442779bd42bda" translate="yes" xml:space="preserve">
          <source>Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.</source>
          <target state="translated">これらのパラメータの小さなサブセットがモデルの予測性能や計算性能に大きな影響を与える一方で、他のパラメータはデフォルト値のままにしておくのが一般的であることに注意してください。予測クラスのdocstringを読んで、それらの期待される動作をより詳しく理解することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="e39d258640f71b07567efcd3611fa0f4dfc35df8" translate="yes" xml:space="preserve">
          <source>Note that it is important to check that the model is accurate enough on a test set before plotting the partial dependence since there would be little use in explaining the impact of a given feature on the prediction function of a poor model.</source>
          <target state="translated">部分依存性をプロットする前に,そのモデルがテスト集合上で十分に正確であることをチェックすることが重要であることに注意してください.</target>
        </trans-unit>
        <trans-unit id="38e7c6473cb1417f0189c236d54733065555b837" translate="yes" xml:space="preserve">
          <source>Note that it maximizes both the correlations between the scores and the intra-block variances.</source>
          <target state="translated">スコアとブロック内分散の相関を最大化することに注意してください。</target>
        </trans-unit>
        <trans-unit id="7fe083a60697e58d27f138d9ea26d77a87096c53" translate="yes" xml:space="preserve">
          <source>Note that it maximizes only the correlations between the scores.</source>
          <target state="translated">スコア間の相関関係のみを最大化することに注意してください。</target>
        </trans-unit>
        <trans-unit id="4ad685eaf7c64ded5f9210b1f3461deac7d47f1a" translate="yes" xml:space="preserve">
          <source>Note that monotonic constraints only constraint the output &amp;ldquo;all else being equal&amp;rdquo;. Indeed, the following relation &lt;strong&gt;is not enforced&lt;/strong&gt; by a positive constraint: \(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2')\).</source>
          <target state="translated">単調制約は、「他のすべてが等しい」出力のみを制約することに注意してください。実際、次の関係&lt;strong&gt;は&lt;/strong&gt;正の制約によって&lt;strong&gt;強制さ&lt;/strong&gt;れ&lt;strong&gt;ません&lt;/strong&gt;：\（x_1 \ leq x_1 '\ implies F（x_1、x_2）\ leq F（x_1'、x_2 '）\）。</target>
        </trans-unit>
        <trans-unit id="9b4460fdb66af9bc149af45e106adc5f1d493bbf" translate="yes" xml:space="preserve">
          <source>Note that noisy data can &amp;ldquo;short-circuit&amp;rdquo; the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.</source>
          <target state="translated">ノイズの多いデータは、本質的にマニホールドの「短絡」につながる可能性があることに注意してください。本質的には、そうでなければ十分に分離されるマニホールドのパーツ間のブリッジとして機能します。ノイズの多いデータや不完全なデータの多様体学習は、活発な研究分野です。</target>
        </trans-unit>
        <trans-unit id="cf4033d0f4ffad84f5c58c4e0d89634a33d57e14" translate="yes" xml:space="preserve">
          <source>Note that on this tabular dataset, Gradient Boosting Machines are both significantly faster to train and more accurate than neural networks. It is also significantly cheaper to tune their hyperparameters (the default tend to work well while this is not often the case for neural networks).</source>
          <target state="translated">この表形式のデータセットでは、勾配ブーストマシンはニューラルネットワークに比べて、訓練が非常に速く、精度が高いことに注意してください。また、ハイパーパラメタを調整するのも非常に安価です(デフォルトではうまく機能する傾向がありますが、ニューラルネットワークではそうではないことが多いです)。</target>
        </trans-unit>
        <trans-unit id="67d5dd89ca82637aa1c574ab8cabbf8ba39e4cb8" translate="yes" xml:space="preserve">
          <source>Note that pickle has some security and maintainability issues. Please refer to section &lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;Model persistence&lt;/a&gt; for more detailed information about model persistence with scikit-learn.</source>
          <target state="translated">pickleにはセキュリティと保守性の問題があることに注意してください。scikit-learnを使用したモデルの永続化の詳細については、セクション&lt;a href=&quot;../../modules/model_persistence#model-persistence&quot;&gt;モデルの永続化&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="23cd95765d94c327b5282b4a1fe3e5dffe405a3a" translate="yes" xml:space="preserve">
          <source>Note that polynomial features are used implicitly in &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel methods&lt;/a&gt; (e.g., &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt;&lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt;&lt;/a&gt;) when using polynomial &lt;a href=&quot;svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">多項式&lt;a href=&quot;svm#svm-kernels&quot;&gt;カーネル関数&lt;/a&gt;を使用する場合、多項式機能は&lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;カーネルメソッド&lt;/a&gt;（たとえば、&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;sklearn.svm.SVC&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.decomposition.kernelpca#sklearn.decomposition.KernelPCA&quot;&gt; &lt;code&gt;sklearn.decomposition.KernelPCA&lt;/code&gt; &lt;/a&gt;）で暗黙的に使用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="675c6d53180ed2915c2b59bf4a0a0e8fbac69215" translate="yes" xml:space="preserve">
          <source>Note that providing &lt;code&gt;y&lt;/code&gt; is sufficient to generate the splits and hence &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; may be used as a placeholder for &lt;code&gt;X&lt;/code&gt; instead of actual training data.</source>
          <target state="translated">提供することに留意されたい &lt;code&gt;y&lt;/code&gt; 、したがって分割及び生成するのに十分である &lt;code&gt;np.zeros(n_samples)&lt;/code&gt; がプレースホルダとして使用することができる &lt;code&gt;X&lt;/code&gt; の代わりに実際のトレーニングデータ。</target>
        </trans-unit>
        <trans-unit id="df4d1f63cde2c26d664594a284ce306040d06cfb" translate="yes" xml:space="preserve">
          <source>Note that shrinkage works only with &amp;lsquo;lsqr&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">収縮は「lsqr」および「eigen」ソルバーでのみ機能することに注意してください。</target>
        </trans-unit>
        <trans-unit id="dd7adf0d494ffc5bcd4e70266fd05b000aa00dcc" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;関数はバイナリの場合に制限されていることに注意してください。&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数は、バイナリ分類とマルチラベル表示形式で動作します。</target>
        </trans-unit>
        <trans-unit id="8d400c4e81cd0336ee43fd779c1c25e212117f34" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; function is restricted to the binary case. The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function works only in binary classification and multilabel indicator format. The &lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt;&lt;code&gt;plot_precision_recall_curve&lt;/code&gt;&lt;/a&gt; function plots the precision recall as follows.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; &lt;/a&gt;関数はバイナリの場合に制限されていることに注意してください。&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数は、バイナリ分類とマルチラベル表示形式で動作します。&lt;a href=&quot;generated/sklearn.metrics.plot_precision_recall_curve#sklearn.metrics.plot_precision_recall_curve&quot;&gt; &lt;code&gt;plot_precision_recall_curve&lt;/code&gt; の&lt;/a&gt;関数は、以下のように精密なリコールをプロットします。</target>
        </trans-unit>
        <trans-unit id="651372cf76a2e0eca2cd0e2ced075f5cfd44a313" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt;&lt;code&gt;Binarizer&lt;/code&gt;&lt;/a&gt; is similar to the &lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt;&lt;code&gt;KBinsDiscretizer&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;k = 2&lt;/code&gt;, and when the bin edge is at the value &lt;code&gt;threshold&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.preprocessing.binarizer#sklearn.preprocessing.Binarizer&quot;&gt; &lt;code&gt;Binarizer&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;k = 2&lt;/code&gt; とき、およびビンの端が &lt;code&gt;threshold&lt;/code&gt; とき、&lt;a href=&quot;generated/sklearn.preprocessing.kbinsdiscretizer#sklearn.preprocessing.KBinsDiscretizer&quot;&gt; &lt;code&gt;KBinsDiscretizer&lt;/code&gt; &lt;/a&gt;に似ていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="96049a1871e8f004cea40c870be340fc85046579" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">そのノート&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; は&lt;/a&gt;また、別のマルチクラスの戦略を実装し、嘘や歌手によって処方いわゆるマルチクラスSVM &lt;a href=&quot;#id18&quot; id=&quot;id1&quot;&gt;16&lt;/a&gt;オプションの使用によって、 &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; 。実際には、結果はほとんど同じであるため、通常は1対残りの分類が推奨されますが、実行時間は大幅に短くなります。</target>
        </trans-unit>
        <trans-unit id="b78ef718e6ed1cb354d8ff189ba4de9e4443cf71" translate="yes" xml:space="preserve">
          <source>Note that the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt;. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;は、オプション &lt;code&gt;multi_class='crammer_singer'&lt;/code&gt; を使用して、代替のマルチクラス戦略、CrammerとSingerによって定式化されたいわゆるマルチクラスSVMも実装することに注意してください。この方法は一貫しており、1対休憩の分類には当てはまりません。実際には、結果はほとんど同じなので、通常は1対休憩の分類が推奨されますが、実行時間は大幅に短くなります。</target>
        </trans-unit>
        <trans-unit id="6d0f75c58b62c96c540e90be5dd6446b78869fb4" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__add__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; is equivalent to using the + operator with &lt;code&gt;RBF() + RBF()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;__add__&lt;/code&gt; マジックメソッドはオーバーライドされるため、 &lt;code&gt;Sum(RBF(), RBF())&lt;/code&gt; は、 &lt;code&gt;RBF() + RBF()&lt;/code&gt; +演算子を使用するのと同じであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="acd06ce9a0926c4eda997a94789bc82988610943" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__mul__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; is equivalent to using the * operator with &lt;code&gt;RBF() * RBF()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;__mul__&lt;/code&gt; マジックメソッドはオーバーライドされるため、 &lt;code&gt;Product(RBF(), RBF())&lt;/code&gt; は、 &lt;code&gt;RBF() * RBF()&lt;/code&gt; *演算子を使用するのと同じであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="d495fb41e55b7018b37ac27eeb250fbaf347d05a" translate="yes" xml:space="preserve">
          <source>Note that the &lt;code&gt;__pow__&lt;/code&gt; magic method is overridden, so &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; is equivalent to using the ** operator with &lt;code&gt;RBF() ** 2&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;__pow__&lt;/code&gt; マジックメソッドはオーバーライドされるため、 &lt;code&gt;Exponentiation(RBF(), 2)&lt;/code&gt; は、 &lt;code&gt;RBF() ** 2&lt;/code&gt; **演算子を使用するのと同じであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="3a88b0087b5b199ea4beb800b3ce5a1f6c9022a8" translate="yes" xml:space="preserve">
          <source>Note that the Gini index only characterize the ranking performance of the model but not its calibration: any monotonic transformation of the predictions leaves the Gini index of the model unchanged.</source>
          <target state="translated">ジニ指数はモデルのランキング性能を特徴づけるだけで、キャリブレーションではないことに注意してください:予測値の単調な変換は、モデルのジニ指数を変更せずに残します。</target>
        </trans-unit>
        <trans-unit id="4b2885ce1a0d54c6be5b37dba1e7a9bea3c67ec1" translate="yes" xml:space="preserve">
          <source>Note that the Multiplicative Update (&amp;lsquo;mu&amp;rsquo;) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.</source>
          <target state="translated">乗算更新（ 'mu'）ソルバーは初期化に存在するゼロを更新できないため、多くのゼロを導入する基本的なNNDSVDアルゴリズムと組み合わせて使用​​すると結果が悪くなることに注意してください。この場合、NNDSVDaまたはNNDSVDarが推奨されます。</target>
        </trans-unit>
        <trans-unit id="542b5d2a5a3926264004f7807400969fe48d422d" translate="yes" xml:space="preserve">
          <source>Note that the current implementation only supports regression estimators.</source>
          <target state="translated">現在の実装では、回帰推定子のみをサポートしていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="7ac1e23398a8f2960b2ec6ee5eea4c00d3f041dd" translate="yes" xml:space="preserve">
          <source>Note that the dataset contains categorical and numerical variables. We will need to take this into account when preprocessing the dataset thereafter.</source>
          <target state="translated">このデータセットには,カテゴリカル変数と数値変数が含まれていることに注意してください.この後,データセットを前処理するときには,これを考慮に入れる必要があります.</target>
        </trans-unit>
        <trans-unit id="5878ce2fa9f81f5b0b2794d8ccb7e40e7db1917d" translate="yes" xml:space="preserve">
          <source>Note that the dict values can either be scorer functions or one of the predefined metric strings.</source>
          <target state="translated">dict値はスコアラー関数または定義済みメトリック文字列のいずれかであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="a97f1f4d24f812e6f4b824a150b492f876f8dbe2" translate="yes" xml:space="preserve">
          <source>Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (&lt;code&gt;LinearSVC(dual=True)&lt;/code&gt;, &lt;code&gt;Perceptron&lt;/code&gt;, &lt;code&gt;SGDClassifier&lt;/code&gt;, &lt;code&gt;PassiveAggressive&lt;/code&gt;) but it does for algorithms that work with CSC matrices (&lt;code&gt;LinearSVC(dual=False)&lt;/code&gt;, &lt;code&gt;Lasso()&lt;/code&gt;, etc).</source>
          <target state="translated">注次元は（CSR行列を操作するアルゴリズムのCPUのトレーニング時間に影響を与えないこと &lt;code&gt;LinearSVC(dual=True)&lt;/code&gt; 、 &lt;code&gt;Perceptron&lt;/code&gt; 、 &lt;code&gt;SGDClassifier&lt;/code&gt; 、 &lt;code&gt;PassiveAggressive&lt;/code&gt; を）それはアルゴリズムのためにすることCSC行列と仕事（ &lt;code&gt;LinearSVC(dual=False)&lt;/code&gt; 、 &lt;code&gt;Lasso()&lt;/code&gt; など）。</target>
        </trans-unit>
        <trans-unit id="435cce9f843df9a5bdcdf7f7022599966bcaee8d" translate="yes" xml:space="preserve">
          <source>Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.</source>
          <target state="translated">estimate_bandwidth関数は、平均シフトアルゴリズムよりもはるかにスケーラブルではなく、使用するとボトルネックになることに注意してください。</target>
        </trans-unit>
        <trans-unit id="bce829a8923d634c66b8b2d36d28916cd48e0ab9" translate="yes" xml:space="preserve">
          <source>Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels &lt;code&gt;fit&lt;/code&gt; upon. With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:</source>
          <target state="translated">第四及び第五のインスタンスは、彼らは3つのラベルのどれもマッチしていないことを示す、すべてゼロを返したことをノート &lt;code&gt;fit&lt;/code&gt; するとは。マルチラベル出力では、インスタンスに複数のラベルを割り当てることも同様に可能です。</target>
        </trans-unit>
        <trans-unit id="21f39572b525862541f5e3b74bb03e06aac617ef" translate="yes" xml:space="preserve">
          <source>Note that the heat map plot has a special colorbar with a midpoint value close to the score values of the best performing models so as to make it easy to tell them apart in the blink of an eye.</source>
          <target state="translated">ヒートマッププロットには、最高の性能を持つモデルのスコア値に近い中間点の値を持つ特別なカラーバーがあり、一瞬で見分けがつくようになっていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="8c847c9ef93d363951399eb5e5ddd91d785490b8" translate="yes" xml:space="preserve">
          <source>Note that the importance values for the top features represent a large fraction of the reference score of 0.356.</source>
          <target state="translated">上位特徴の重要度の値は、参照スコア0.356の大きな割合を表していることに注意してください。</target>
        </trans-unit>
        <trans-unit id="3f19bf1a17574ce6b7f5a8199cbb6b2ed04a3916" translate="yes" xml:space="preserve">
          <source>Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly.</source>
          <target state="translated">最尤推定値は収縮がないことに対応しているため、パフォーマンスが低いことに注意してください。Ledoit-Wolfの推定値は、最適値に近く、計算コストがかからないため、非常によく動作します。この例では、OAS 推定値はもう少し離れています。興味深いことに、どちらのアプローチもクロス・バリデーションを上回りますが、クロス・バリデーションは最も計算コストがかかります。</target>
        </trans-unit>
        <trans-unit id="be3cea96be539a6f36c7349851efbc1b4f539ceb" translate="yes" xml:space="preserve">
          <source>Note that the number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.</source>
          <target state="translated">次元数は,元の特徴量の数に依存せず,データセットのサイズに依存することに注意してください:データセットが大きいほど,EPS-embeddingの最小次元数は高くなります.</target>
        </trans-unit>
        <trans-unit id="1426a0972df2ef3ae4847218faa4ab1a45e2a26b" translate="yes" xml:space="preserve">
          <source>Note that the parameter &lt;code&gt;alpha&lt;/code&gt; is applied as a Tikhonov regularization of the assumed covariance between the training points.</source>
          <target state="translated">パラメータ &lt;code&gt;alpha&lt;/code&gt; は、トレーニングポイント間の仮定された共分散のTikhonov正則化として適用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="57bfd4549eb4e4a76c8eb0b9ddf20a2f4a52c8d2" translate="yes" xml:space="preserve">
          <source>Note that the precision may not decrease with recall. The definition of precision (\(\frac{T_p}{T_p + F_p}\)) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.</source>
          <target state="translated">精度はリコールでは低下しないかもしれないことに注意してください.精度の定義 (\(T_p}{T_p+F_p}\)))は,分類器の閾値を下げると,返される結果の数を増やすことで分母を増やすことができることを示しています.以前の閾値が高すぎた場合,新しい結果はすべて真の陽性であるかもしれません.以前の閾値がほぼ正しいか、低すぎた場合、さらに閾値を下げると偽陽性が発生し、精度が低下します。</target>
        </trans-unit>
        <trans-unit id="07e181d114b5848fdd4cb0661edb49154d99e027" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the &lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt; is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space. Here the manifold problem matches fairly that of representing a flat map of the Earth, as with &lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;map projection&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../modules/manifold#multidimensional-scaling&quot;&gt;MDS&lt;/a&gt;の目的は、他の多様体学習アルゴリズムとは異なり、距離が元の高次元空間の距離をよく尊重するデータ（ここでは2D）の低次元表現を見つけることであることに注意してください。低次元空間でのデータの等方性表現。ここで、多様体問題は、&lt;a href=&quot;https://en.wikipedia.org/wiki/Map_projection&quot;&gt;地図投影&lt;/a&gt;と同様に、地球の平らな地図を表す問題とかなり一致しています</target>
        </trans-unit>
        <trans-unit id="951ad93c2b6a49b38a3c4a8dabf905c9019bf128" translate="yes" xml:space="preserve">
          <source>Note that the purpose of the MDS is to find a low-dimensional representation of the data (here 2D) in which the distances respect well the distances in the original high-dimensional space, unlike other manifold-learning algorithms, it does not seeks an isotropic representation of the data in the low-dimensional space.</source>
          <target state="translated">MDSの目的は、距離が元の高次元空間の距離をよく尊重するデータの低次元表現(ここでは2次元)を見つけることであり、他のマニホールド学習アルゴリズムとは異なり、低次元空間でのデータの等方性表現を求めないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="6c07e8b80629c5d24a4c78874f28fde4e1598ff3" translate="yes" xml:space="preserve">
          <source>Note that the resulting model is the average claim amount per claim. As such, it is conditional on having at least one claim, and cannot be used to predict the average claim amount per policy in general.</source>
          <target state="translated">結果として得られるモデルは、保険金1件あたりの平均保険金額であることに注意してください。このように、それは少なくとも1つのクレームを持っていることを条件としており、一般的に保険契約ごとの平均クレーム額を予測するために使用することはできません。</target>
        </trans-unit>
        <trans-unit id="faff2f13ccab498a5068027cb2f2891a11c4c2ca" translate="yes" xml:space="preserve">
          <source>Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; and &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt;). Any other sparse input will be &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt;. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.</source>
          <target state="translated">スケーラーは圧縮スパース行と圧縮スパース列の両方の形式を受け入れることに注意してください（ &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; と &lt;code&gt;scipy.sparse.csc_matrix&lt;/code&gt; を参照）。その他のスパース入力は&lt;strong&gt;、圧縮スパース行表現に変換され&lt;/strong&gt;ます。不要なメモリコピーを回避するために、上流でCSRまたはCSC表現を選択することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="0ac4948c4f86990406e6391d28cab3438b2d6038" translate="yes" xml:space="preserve">
          <source>Note that the transformations successfully map the data to a normal distribution when applied to certain datasets, but are ineffective with others. This highlights the importance of visualizing the data before and after transformation.</source>
          <target state="translated">変換は、特定のデータセットに適用した場合、データを正規分布にマッピングすることに成功しますが、他のデータセットでは効果がないことに注意してください。このことは、変換前と変換後のデータを可視化することの重要性を強調しています。</target>
        </trans-unit>
        <trans-unit id="c025c974076c003b893079ae24539cfe87c45c45" translate="yes" xml:space="preserve">
          <source>Note that the use of &lt;code&gt;memory&lt;/code&gt; to enable caching becomes interesting when the fitting of a transformer is costly.</source>
          <target state="translated">トランスフォーマーの取り付けにコストがかかる場合、キャッシングを有効にするための &lt;code&gt;memory&lt;/code&gt; の使用が興味深いことに注意してください。</target>
        </trans-unit>
        <trans-unit id="e3bd8ce7db50d77dd828df23ba8a7913ea07b656" translate="yes" xml:space="preserve">
          <source>Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on &lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]&lt;/a&gt; . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:</source>
          <target state="translated">スパースPCA問題には多くの異なる定式化があることに注意してください。ここで実装されているものは&lt;a href=&quot;#mrl09&quot; id=&quot;id3&quot;&gt;[Mrl09]に&lt;/a&gt;基づいています。解決された最適化問題は、コンポーネントに\（\ ell_1 \）ペナルティがあるPCA問題（辞書学習）です。</target>
        </trans-unit>
        <trans-unit id="3533aed52b9c93cbfd7c732492e759ef81f9eff6" translate="yes" xml:space="preserve">
          <source>Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is &lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K-means&lt;/a&gt;.</source>
          <target state="translated">多くの異なるクラスタリング基準と関連するアルゴリズムが存在することに注意してください。最も単純なクラスタリングアルゴリズムは&lt;a href=&quot;../../modules/clustering#k-means&quot;&gt;K平均法&lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="7a1a308b56337fe667b4a60765401b66807cafaf" translate="yes" xml:space="preserve">
          <source>Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.</source>
          <target state="translated">sample_weight が指定 さ れている と き は、 こ れ ら の重みは sample_weight と 乗算 さ れます (はめ込み方式で渡されます)。</target>
        </trans-unit>
        <trans-unit id="523c4300803e2407441df32761d9ac234d32f175" translate="yes" xml:space="preserve">
          <source>Note that theta are typically the log-transformed values of the kernel&amp;rsquo;s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</source>
          <target state="translated">シータは通常、カーネルのハイパーパラメーターの対数変換された値であることに注意してください。長さスケールのようなハイパーパラメーターは自然に対数スケールで存在するため、検索スペースのこの表現はハイパーパラメーター検索により適しています。</target>
        </trans-unit>
        <trans-unit id="18d756a791b41973e0843ab0a78a9e37c703da28" translate="yes" xml:space="preserve">
          <source>Note that this accuracy of this l1-penalized linear model is significantly below what can be reached by an l2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.</source>
          <target state="translated">このl1ペナライズされた線形モデルの精度は、このデータセットのl2ペナライズされた線形モデルや非線形多層パーセプトロンモデルの精度を大きく下回っていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="fe64330213465e1693b793ed059df249f5fb9ff2" translate="yes" xml:space="preserve">
          <source>Note that this component typically should not be used in a vanilla &lt;code&gt;Pipeline&lt;/code&gt; consisting of transformers and a classifier, but rather could be added using a &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt;.</source>
          <target state="translated">このコンポーネントは通常、トランスフォーマーと分類子で構成されるバニラ &lt;code&gt;Pipeline&lt;/code&gt; では使用しないで &lt;code&gt;ColumnTransformer&lt;/code&gt; 。むしろ、 &lt;code&gt;FeatureUnion&lt;/code&gt; またはColumnTransformerを使用して追加できます。</target>
        </trans-unit>
        <trans-unit id="d1586f7c06fc3985d60451a7a19048e48e062430" translate="yes" xml:space="preserve">
          <source>Note that this compound kernel returns the results of all simple kernel stacked along an additional axis.</source>
          <target state="translated">この複合カーネルは、追加の軸に沿ってスタックされたすべての単純なカーネルの結果を返すことに注意してください。</target>
        </trans-unit>
        <trans-unit id="31acdd30123a3b6dcbfca492a99f8cbc9dc2455a" translate="yes" xml:space="preserve">
          <source>Note that this computation of feature importance is based on entropy, and it is distinct from &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; which is based on permutation of the features.</source>
          <target state="translated">この特徴の重要性の計算はエントロピーに基づいており、特徴の順列に基づく&lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;とは異なることに注意してください。</target>
        </trans-unit>
        <trans-unit id="70f8f8292a30b78b7e2885afabc408eef407b785" translate="yes" xml:space="preserve">
          <source>Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.</source>
          <target state="translated">なお、この定義は、この定義が成立しない場合には、「\(0;1)\)」となりますが、「\(d_{KL})」と「\(d_{IS})」のそれぞれの定義に継続的に拡張することができます。</target>
        </trans-unit>
        <trans-unit id="7550e059eb4d092ae42a40cda726bb20131c9e24" translate="yes" xml:space="preserve">
          <source>Note that this estimator is different from the R implementation of Robust Regression (&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;) because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.</source>
          <target state="translated">この推定量は、ロバスト回帰のR実装（&lt;a href=&quot;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&quot;&gt;http://www.ats.ucla.edu/stat/r/dae/rreg.htm&lt;/a&gt;）とは異なることに注意してください。これは、R実装が加重最小二乗実装を実行し、残差が特定のしきい値よりどれだけ大きいかに基づいて、各サンプル。</target>
        </trans-unit>
        <trans-unit id="5472d869ea9e0f8e4cfcc121937d62eb4599c58a" translate="yes" xml:space="preserve">
          <source>Note that this example is, however, only an illustration since for this specific case fitting PCA is not necessarily slower than loading the cache. Hence, use the &lt;code&gt;memory&lt;/code&gt; constructor parameter when the fitting of a transformer is costly.</source>
          <target state="translated">ただし、この特定のケースでは、PCAのフィッティングがキャッシュのロードよりも遅いとは限らないため、この例は単なる図であることに注意してください。したがって、トランスフォーマーの取り付けにコストがかかる場合は、 &lt;code&gt;memory&lt;/code&gt; コンストラクターパラメーターを使用します。</target>
        </trans-unit>
        <trans-unit id="1b5bac58d61d7142976dd586739448ed8787f73e" translate="yes" xml:space="preserve">
          <source>Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.</source>
          <target state="translated">このフォーマットは,変換時に行列を高密度化してしまうため,行列の欠損値を暗黙的に格納するためには使用されないことに注意してください.0 でエンコードされた欠損値は,密な入力で使用しなければなりません.</target>
        </trans-unit>
        <trans-unit id="ceed59ec0d8d185c9512413b150620f381e9c0c0" translate="yes" xml:space="preserve">
          <source>Note that this function does not regenerate the original data due to discretization rounding.</source>
          <target state="translated">この関数は離散化丸めのため、元のデータを再生しませんのでご注意ください。</target>
        </trans-unit>
        <trans-unit id="90f3882ef5e6cb2ec08d6d3659b834d53aaa84d9" translate="yes" xml:space="preserve">
          <source>Note that this gives us a different indication than the graph, as the graph reflects conditional relations between variables, while the clustering reflects marginal properties: variables clustered together can be considered as having a similar impact at the level of the full stock market.</source>
          <target state="translated">これは、グラフが変数間の条件付き関係を反映しているのに対し、クラスタリングは限界特性を反映しているので、グラフとは異なる表示を与えていることに注意してください:一緒にクラスタリングされた変数は、株式市場全体のレベルで同様の影響を持っていると考えることができます。</target>
        </trans-unit>
        <trans-unit id="29fe04606c06b888c8ec9e6f0120963e08f606ce" translate="yes" xml:space="preserve">
          <source>Note that this is always a dense array.</source>
          <target state="translated">これは常に密な配列であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="8400da57b096333e7a778582f2569282a236fe34" translate="yes" xml:space="preserve">
          <source>Note that this is stochastic, and that if random_state is not fixed, repeated calls, or permuted input, will yield different results.</source>
          <target state="translated">これは確率的なものであり、random_stateが固定されていない場合は、繰り返し呼び出したり、入力を変更したりすると、異なる結果が得られることに注意してください。</target>
        </trans-unit>
        <trans-unit id="426217e7254990be151f425ed53a8b743a92e13d" translate="yes" xml:space="preserve">
          <source>Note that this two-dimensional example is very degenerate: generally the number of features would be much greater than the &amp;ldquo;document length&amp;rdquo;, while here we have much larger documents than vocabulary. Similarly, with &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt;, it is much less likely that a feature distinguishes a particular class.</source>
          <target state="translated">この2次元の例は非常に縮退していることに注意してください。一般に、特徴の数は「ドキュメントの長さ」よりはるかに大きくなりますが、ここではボキャブラリーよりもはるかに大きなドキュメントがあります。同様に、 &lt;code&gt;n_classes &amp;gt; n_features&lt;/code&gt; 場合、機能が特定のクラスを区別する可能性ははるかに低くなります。</target>
        </trans-unit>
        <trans-unit id="dcf3e0855a66eb55e0eddd9daaf862dddfda1dac" translate="yes" xml:space="preserve">
          <source>Note that this type is the most specific type that can be inferred. For example:</source>
          <target state="translated">この型は推論できる最も具体的な型であることに注意してください。例えば</target>
        </trans-unit>
        <trans-unit id="1fefb84f794ce8a86674757b08d8dabfe97347de" translate="yes" xml:space="preserve">
          <source>Note that this will affect all uses of &lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt;&lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt;&lt;/a&gt; within the context.</source>
          <target state="translated">これは、コンテキスト内での&lt;a href=&quot;generated/sklearn.utils.assert_all_finite#sklearn.utils.assert_all_finite&quot;&gt; &lt;code&gt;sklearn.utils.assert_all_finite&lt;/code&gt; の&lt;/a&gt;すべての使用に影響することに注意してください。</target>
        </trans-unit>
        <trans-unit id="ab32001c49d58b4f0c9d94bbfb77f7ddeaf05601" translate="yes" xml:space="preserve">
          <source>Note that those results can be highly dependent on the value of &lt;code&gt;learning_rate_init&lt;/code&gt;.</source>
          <target state="translated">これらの結果は &lt;code&gt;learning_rate_init&lt;/code&gt; の値に大きく依存する可能性があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="aa786acd948a782d7b514486d406120e9b9bf46a" translate="yes" xml:space="preserve">
          <source>Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.</source>
          <target state="translated">標準的なクロスバリデーション法とは異なり、連続したトレーニングセットは、その前に来るもののスーパーセットであることに注意してください。</target>
        </trans-unit>
        <trans-unit id="be1d5d21cf434df3c562c8f7229d77ef9e790ff3" translate="yes" xml:space="preserve">
          <source>Note that we could have used the least squares loss for the &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; model. This would wrongly assume a normal distributed response variable as does the &lt;code&gt;Ridge&lt;/code&gt; model, and possibly also lead to slightly negative predictions. However the gradient boosted trees would still perform relatively well and in particular better than &lt;code&gt;PoissonRegressor&lt;/code&gt; thanks to the flexibility of the trees combined with the large number of training samples.</source>
          <target state="translated">&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; モデルに最小二乗損失を使用できた可能性があることに注意してください。これは、 &lt;code&gt;Ridge&lt;/code&gt; モデルのように正規分布の応答変数を誤って想定し、わずかに負の予測につながる可能性があります。ただし、勾配ブーストされたツリーは、ツリーの柔軟性と多数のトレーニングサンプルのおかげで、比較的良好に、特に &lt;code&gt;PoissonRegressor&lt;/code&gt; よりも優れたパフォーマンスを発揮します。</target>
        </trans-unit>
        <trans-unit id="b632488ec02d373b59188cfae81036b1d7135a34" translate="yes" xml:space="preserve">
          <source>Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; estimator is computationally efficient and implements on-line learning with a &lt;code&gt;partial_fit&lt;/code&gt; method.</source>
          <target state="translated">辞書学習を使用して表現を抽出する場合（スパースコーディングなど）、クラスタリングは辞書を学習するための適切なプロキシになることに注意してください。たとえば、&lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; &lt;/a&gt;推定器は計算効率が高く、 &lt;code&gt;partial_fit&lt;/code&gt; メソッドを使用したオンライン学習を実装しています。</target>
        </trans-unit>
        <trans-unit id="b38cc6be43472cae197ca98a60df5eafaa29d73f" translate="yes" xml:space="preserve">
          <source>Note that with all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data!</source>
          <target state="translated">これらすべての戦略で、 &lt;code&gt;predict&lt;/code&gt; メソッドは入力データを完全に無視することに注意してください！</target>
        </trans-unit>
        <trans-unit id="75c6be4694b9eabe59018390268fd820a052b7d5" translate="yes" xml:space="preserve">
          <source>Note that, by default, scikit-learn uses its embedded (vendored) version of joblib. A configuration switch (documented below) controls this behavior.</source>
          <target state="translated">デフォルトでは、scikit-learnはjoblibの組み込み版(ベンダー版)を使用することに注意してください。設定スイッチ(以下で説明します)はこの動作を制御します。</target>
        </trans-unit>
        <trans-unit id="ae98ee9bcd2e5d0854b3eaebde47d02a011f815f" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the observation \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\).</source>
          <target state="translated">この表記では、観測\（y_i \）が試行\（i \）でセット\（{-1、1} ​​\）の値を取ると仮定されていることに注意してください。</target>
        </trans-unit>
        <trans-unit id="e6bd4762fd372de20f9b98cd74d805456dc39e3e" translate="yes" xml:space="preserve">
          <source>Note that, in this notation, it&amp;rsquo;s assumed that the target \(y_i\) takes values in the set \({-1, 1}\) at trial \(i\). We can also see that Elastic-Net is equivalent to \(\ell_1\) when \(\rho = 1\) and equivalent to \(\ell_2\) when \(\rho=0\).</source>
          <target state="translated">この表記法では、ターゲット\（y_i \）が試行\（i \）でセット\（{-1、1} ​​\）の値を取ると想定されていることに注意してください。また、Elastic-Netは\（\ rho = 1 \）の場合は\（\ ell_1 \）と同等であり、\（\ rho = 0 \）の場合は\（\ ell_2 \）と同等であることがわかります。</target>
        </trans-unit>
        <trans-unit id="79d7c15c2a930f99c60199078ea59a499e19fbc8" translate="yes" xml:space="preserve">
          <source>Note that, the color range of the precision matrices is tweaked to improve readability of the figure. The full range of values of the empirical precision is not displayed.</source>
          <target state="translated">なお、図の読みやすさを向上させるために、精度行列の色の範囲を調整しています。経験的精度の全範囲の値は表示されません。</target>
        </trans-unit>
        <trans-unit id="285f98e8d01e4962eff6724b78a3c6724d0931e6" translate="yes" xml:space="preserve">
          <source>Note that:</source>
          <target state="translated">そのことに注意してください。</target>
        </trans-unit>
        <trans-unit id="5bd74df6988f671f3aaedf9864231e7cb14cad2a" translate="yes" xml:space="preserve">
          <source>Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.</source>
          <target state="translated">特徴抽出に怠惰さを導入するジェネレータ内包の使用に注意してください。</target>
        </trans-unit>
        <trans-unit id="1984eb2d93c7fabc5820f74c1a6deb67cdefe2d3" translate="yes" xml:space="preserve">
          <source>Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">注意!合成特徴量は、他のすべての特徴量と同様にl1/l2正則化の影響を受けます。合成特徴量(したがって切片)に対する正則化の影響を軽減するために、 intercept_scaling を大きくしなければなりません。</target>
        </trans-unit>
        <trans-unit id="83423c198b6099edba08f185f940042d5dba3b79" translate="yes" xml:space="preserve">
          <source>Note:</source>
          <target state="translated">Note:</target>
        </trans-unit>
        <trans-unit id="b85cf8e5cd9762e5dd866d246742bbab950fd9b8" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeaveOneOut()&lt;/code&gt; is equivalent to &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; and &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is the number of samples.</source>
          <target state="translated">注： &lt;code&gt;LeaveOneOut()&lt;/code&gt; は、と等価である &lt;code&gt;KFold(n_splits=n)&lt;/code&gt; と &lt;code&gt;LeavePOut(p=1)&lt;/code&gt; ここで、 &lt;code&gt;n&lt;/code&gt; はサンプル数です。</target>
        </trans-unit>
        <trans-unit id="31e8baf167adcc23a2adc9382a5f1918c617d9e9" translate="yes" xml:space="preserve">
          <source>Note: &lt;code&gt;LeavePOut(p)&lt;/code&gt; is NOT equivalent to &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; which creates non-overlapping test sets.</source>
          <target state="translated">注： &lt;code&gt;LeavePOut(p)&lt;/code&gt; は、重複しないテストセットを作成する &lt;code&gt;KFold(n_splits=n_samples // p)&lt;/code&gt; と同等ではありません。</target>
        </trans-unit>
        <trans-unit id="bea1be387c131c6f224a4e72fba375bf5b015ed7" translate="yes" xml:space="preserve">
          <source>Note: Currently &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; does not modify the precomputed distances, and thus assumes that precomputed euclidean distances are squared. In future versions, a parameter in TSNE will control the optional squaring of precomputed distances (see #12401).</source>
          <target state="translated">注：現在、 &lt;code&gt;TSNE(metric='precomputed')&lt;/code&gt; は事前計算された距離を変更しないため、事前計算されたユークリッド距離は2乗であると想定しています。将来のバージョンでは、TSNEのパラメーターが、事前に計算された距離のオプションの2乗を制御します（＃12401を参照）。</target>
        </trans-unit>
        <trans-unit id="432e1c4e6e288e7db18e2c42d6e410c6adeb71c8" translate="yes" xml:space="preserve">
          <source>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times &lt;code&gt;n_samples&lt;/code&gt; (i.e. the sum of squares of each column totals 1).</source>
          <target state="translated">注：これらの10個の特徴変数はそれぞれ、平均が中央に配置され、標準偏差 &lt;code&gt;n_samples&lt;/code&gt; （つまり、各列の平方和の合計が1）でスケーリングされています。</target>
        </trans-unit>
        <trans-unit id="02b388a51976f4b3884d316ec9ed343cbbaf27f0" translate="yes" xml:space="preserve">
          <source>Note: Evaluation of eval_gradient is not analytic but numeric and all</source>
          <target state="translated">注意:eval_gradient の評価は解析的なものではなく数値的なものであり、すべての</target>
        </trans-unit>
        <trans-unit id="f97fa8efa81cc34898992868ec31edd01fe1abf9" translate="yes" xml:space="preserve">
          <source>Note: For larger datasets (n_samples &amp;gt;= 10000), please refer to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">注：より大きなデータセット（n_samples&amp;gt; = 10000）については、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="a5290473efc5984775f303f01f61e6c7775623f5" translate="yes" xml:space="preserve">
          <source>Note: If a lambda is used as the function, then the resulting transformer will not be pickleable.</source>
          <target state="translated">注意:ラムダが関数として使用されている場合、結果として得られる変換器はピクル可能ではありません。</target>
        </trans-unit>
        <trans-unit id="78c3e35dab7ccbe33bae1787c55dabbd050c5a91" translate="yes" xml:space="preserve">
          <source>Note: In KNeighborsTransformer we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;, and for compatibility reasons, one extra neighbor is computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. Please note that we do the same in the proposed wrappers.</source>
          <target state="translated">注： &lt;code&gt;n_neighbors&lt;/code&gt; では、n_neighborsのカウントに各トレーニングポイントを独自のネイバーとして含める定義を使用します。互換性の理由から、 &lt;code&gt;mode == 'distance'&lt;/code&gt; 場合に1つの追加のネイバーが計算されます。提案されたラッパーでも同じことを行うことに注意してください。</target>
        </trans-unit>
        <trans-unit id="ab7df665871a4d2a9feffe69dfea4e192c2cd75e" translate="yes" xml:space="preserve">
          <source>Note: L2 normalization is also known as spatial sign preprocessing.</source>
          <target state="translated">注:L2正規化は、空間符号前処理としても知られています。</target>
        </trans-unit>
        <trans-unit id="09a1c78e2b9dafeb4ae2773774e2099dbe747a0e" translate="yes" xml:space="preserve">
          <source>Note: Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">注：実装のスコアはTsoumakas et al。、2010で与えられたスコアよりも1大きくなっています。これにより、インスタンスの真のラベルが0である縮退ケースを処理するように拡張されます。</target>
        </trans-unit>
        <trans-unit id="956d1e2ca58f2ab0bdb4afea5546244c422bc323" translate="yes" xml:space="preserve">
          <source>Note: See the &lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;Introduction to machine learning with scikit-learn Tutorial&lt;/a&gt; for a quick run-through on the basic machine learning vocabulary used within scikit-learn.</source>
          <target state="translated">注：scikit-learnで使用される基本的な機械学習ボキャブラリーの&lt;a href=&quot;../basic/tutorial#introduction&quot;&gt;概要&lt;/a&gt;については、scikit-learnチュートリアルによる機械学習の概要を参照してください。</target>
        </trans-unit>
        <trans-unit id="7a9381252d0555984c45c1d913a85b0a19a4797d" translate="yes" xml:space="preserve">
          <source>Note: The default solver &amp;lsquo;adam&amp;rsquo; works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, &amp;lsquo;lbfgs&amp;rsquo; can converge faster and perform better.</source>
          <target state="translated">注：デフォルトのソルバー「adam」は、トレーニング時間と検証スコアの両方の点で、比較的大規模なデータセット（数千以上のトレーニングサンプルを含む）でかなりうまく機能します。ただし、小さなデータセットの場合、「lbfgs」は収束が速く、パフォーマンスが向上します。</target>
        </trans-unit>
        <trans-unit id="271df9bc769d4f6f6224f70e1c75a6c3d0d4e15f" translate="yes" xml:space="preserve">
          <source>Note: The parameters &lt;code&gt;test_size&lt;/code&gt; and &lt;code&gt;train_size&lt;/code&gt; refer to groups, and not to samples, as in ShuffleSplit.</source>
          <target state="translated">注：パラメーター &lt;code&gt;test_size&lt;/code&gt; および &lt;code&gt;train_size&lt;/code&gt; はグループを参照し、ShuffleSplitのようにサンプルを参照しません。</target>
        </trans-unit>
        <trans-unit id="d9b8539222215de6f9b7a2dc0d47dad55ab9503a" translate="yes" xml:space="preserve">
          <source>Note: a one-hot encoding of y labels should use a LabelBinarizer instead.</source>
          <target state="translated">注意:y ラベルのワンホットエンコーディングでは、代わりに LabelBinarizer を使うべきです。</target>
        </trans-unit>
        <trans-unit id="1ed0914b13c92897638e72f9758df4b91ef77876" translate="yes" xml:space="preserve">
          <source>Note: although we will make new pipelines with the processors which we wrote in the previous section for the 3 learners, the final estimator RidgeCV() does not need preprocessing of the data as it will be fed with the already preprocessed output from the 3 learners.</source>
          <target state="translated">注意:3つの学習者のために前のセクションで書いたプロセッサを用いて新しいパイプラインを作成しますが、最終的な推定量RidgeCV()は、3つの学習者からの既に前処理された出力で与えられるので、データの前処理は必要ありません。</target>
        </trans-unit>
        <trans-unit id="af48a21921f21ca5ba4feec03dc7cfdb83d643b6" translate="yes" xml:space="preserve">
          <source>Note: as k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Several runs with independent random init might be necessary to get a good convergence.</source>
          <target state="translated">注意:k-meansは非凸の対物関数を最適化しているので、局所的な最適化になる可能性が高いです。良い収束を得るためには、独立したランダムなinitで数回実行する必要があるかもしれません。</target>
        </trans-unit>
        <trans-unit id="3bb7791854593a3b717f90311f25871cac16570c" translate="yes" xml:space="preserve">
          <source>Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:他のクロスバリデーション戦略とは反対に、ランダム分割はすべてのフォールドが異なることを保証しないが、これはサイズの大きいデータセットではまだ可能性が高い。</target>
        </trans-unit>
        <trans-unit id="ec23f8c549cab8298e97ba96412d8acd5b97a819" translate="yes" xml:space="preserve">
          <source>Note: fitting on sparse input will override the setting of this parameter, using brute force.</source>
          <target state="translated">注意:疎な入力に対するフィッティングは、このパラメータの設定を上書きし、ブルートフォースを使用します。</target>
        </trans-unit>
        <trans-unit id="f2a5a8b06402f76d2a1b1f28ad2e90efb04ea841" translate="yes" xml:space="preserve">
          <source>Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format.</source>
          <target state="translated">注:数値データを自分で管理する場合は、データのロード時間を短縮するためにHDF5などの最適化されたファイル形式を使用することをお勧めします。H5PyやPyTables、pandasなどの各種ライブラリは、そのフォーマットでデータを読み書きするためのPythonインターフェースを提供しています。</target>
        </trans-unit>
        <trans-unit id="cb39d5746d1ab528272657961084b4241cfe3f85" translate="yes" xml:space="preserve">
          <source>Note: in the plot, &amp;ldquo;unlabeled samples&amp;rdquo; does not mean that we don&amp;rsquo;t know the labels (as in semi-supervised learning) but that the samples simply do &lt;em&gt;not&lt;/em&gt; have a label.</source>
          <target state="translated">注：プロットに、「非標識サンプルは、」我々は（半教師付き学習のように）ラベルを知らないという意味ではありませんが、サンプルは単にないこと&lt;em&gt;ではない&lt;/em&gt;ラベルを持っています。</target>
        </trans-unit>
        <trans-unit id="403fd153dcfc1c72561472b5e34372d5de58734f" translate="yes" xml:space="preserve">
          <source>Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.</source>
          <target state="translated">注意:ShuffleSplitストラテジーのように,層別ランダムスプリットは,すべてのフォールドが異なることを保証するものではないが,サイズの大きいデータセットではまだ可能性が高い.</target>
        </trans-unit>
        <trans-unit id="12964c4f090e67fee00edc80b29c8ee9b28b7b3b" translate="yes" xml:space="preserve">
          <source>Note: the implementation of &lt;code&gt;inverse_transform&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;svd_solver='randomized'&lt;/code&gt; is not the exact inverse transform of &lt;code&gt;transform&lt;/code&gt; even when &lt;code&gt;whiten=False&lt;/code&gt; (default).</source>
          <target state="translated">注：の実装 &lt;code&gt;inverse_transform&lt;/code&gt; における&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;と &lt;code&gt;svd_solver='randomized'&lt;/code&gt; 正確な逆の変換ではありません &lt;code&gt;transform&lt;/code&gt; しても &lt;code&gt;whiten=False&lt;/code&gt; （デフォルト）。</target>
        </trans-unit>
        <trans-unit id="f5990a880094bfe59d250a6cb72959923dee6858" translate="yes" xml:space="preserve">
          <source>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</source>
          <target state="translated">注意:サンプリングデータを保存しないことでオブジェクトのメモリフットプリントを削減するために、プロパティを呼び出すたびにリストが再作成されます。そのため、プロパティの取得は予想よりも遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="b4fa4a5f4c66fdf91fefb2f5d8a9d04622e730f8" translate="yes" xml:space="preserve">
          <source>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">注： &lt;code&gt;max_features&lt;/code&gt; 以外の機能を効果的に検査する必要がある場合でも、ノードサンプルの有効なパーティションが少なくとも1つ見つかるまで、分割の検索は停止しません。</target>
        </trans-unit>
        <trans-unit id="4064827fd69033d32661395cc63853ae193f7d3a" translate="yes" xml:space="preserve">
          <source>Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply (see Parameters).</source>
          <target state="translated">注意:この実装はバイナリ、マルチクラス、マルチラベル分類で使用できますが、いくつかの制限が適用されます(「パラメータ」を参照)。</target>
        </trans-unit>
        <trans-unit id="5af1722805bd08a73be9d8b2f383c0eb417bbdd9" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.</source>
          <target state="translated">注意:この実装は、ラベルインジケータ形式のバイナリ分類タスクまたはマルチラベル分類タスクに限定されます。</target>
        </trans-unit>
        <trans-unit id="2dab9af505b98147ed8303644f1fce8db17174c7" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task or multilabel classification task.</source>
          <target state="translated">注意:この実装は、バイナリ分類タスクまたはマルチラベル分類タスクに限定されます。</target>
        </trans-unit>
        <trans-unit id="229c71e40bdbb475df5a5f3c46414bb1e9fb11cf" translate="yes" xml:space="preserve">
          <source>Note: this implementation is restricted to the binary classification task.</source>
          <target state="translated">注意:この実装はバイナリ分類タスクに限定されています。</target>
        </trans-unit>
        <trans-unit id="77503a53930a4c6773bcfd9900ee0500aa085f94" translate="yes" xml:space="preserve">
          <source>Note: with the optional parameter &lt;code&gt;svd_solver='randomized'&lt;/code&gt;, we also need to give &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; the size of the lower-dimensional space &lt;code&gt;n_components&lt;/code&gt; as a mandatory input parameter.</source>
          <target state="translated">注：オプションのパラメーター &lt;code&gt;svd_solver='randomized'&lt;/code&gt; を使用して、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; に&lt;/a&gt;必須の入力パラメーターとして低次元空間 &lt;code&gt;n_components&lt;/code&gt; のサイズを指定する必要もあります。</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="8365e7c537a7bde197e775fc685e729bf7dcde79" translate="yes" xml:space="preserve">
          <source>Notice that this class does not support sparse input. See &lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; for an alternative with sparse data.</source>
          <target state="translated">このクラスはスパース入力をサポートしていないことに注意してください。スパースデータの代替案については、&lt;a href=&quot;sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="24a6d73ad577eece3a7c4a8079ee0685b19c5eef" translate="yes" xml:space="preserve">
          <source>Novelty detection</source>
          <target state="translated">新規性の検出</target>
        </trans-unit>
        <trans-unit id="0c6ce6f3a8c7f0ac9123407bf644e00c93b8a85c" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor (LOF)</source>
          <target state="translated">局所外れ値因子(LOF)による新規性検出</target>
        </trans-unit>
        <trans-unit id="d039fa812c1beff75961eedb7fd0d56d4bd6cef8" translate="yes" xml:space="preserve">
          <source>Novelty detection with Local Outlier Factor is illustrated below.</source>
          <target state="translated">Local Outlier Factorを用いた新規性検出の例を以下に示します。</target>
        </trans-unit>
        <trans-unit id="0baacee2d29c362912e19aeae2a56e9b5de18251" translate="yes" xml:space="preserve">
          <source>November, 1995</source>
          <target state="translated">1995年11月</target>
        </trans-unit>
        <trans-unit id="f56b60fb36ba6e7108f33fd204674d75974c9ca0" translate="yes" xml:space="preserve">
          <source>Now looking at the computation time of the different parts, we see that the vectorization is much more expensive than learning itself. From the different algorithms, &lt;code&gt;MultinomialNB&lt;/code&gt; is the most expensive, but its overhead can be mitigated by increasing the size of the mini-batches (exercise: change &lt;code&gt;minibatch_size&lt;/code&gt; to 100 and 10000 in the program and compare).</source>
          <target state="translated">さまざまな部分の計算時間を見ると、ベクトル化はそれ自体を学習するよりもはるかに高価であることがわかります。さまざまなアルゴリズムから、 &lt;code&gt;MultinomialNB&lt;/code&gt; は最も高価ですが、そのオーバーヘッドは &lt;code&gt;minibatch_size&lt;/code&gt; のサイズを増やすことで軽減できます（演習：プログラムでminibatch_sizeを100および10000に変更して比較します）。</target>
        </trans-unit>
        <trans-unit id="e921254526b0e2e9cacf92a70632a272e818cfb0" translate="yes" xml:space="preserve">
          <source>Now that the coefficients have been scaled, we can safely compare them.</source>
          <target state="translated">係数がスケーリングされたので、安全に比較することができます。</target>
        </trans-unit>
        <trans-unit id="703648eec6ac2a9ecd5332ac2370f3cbb5d40c50" translate="yes" xml:space="preserve">
          <source>Now that we have our features, we can train a classifier to try to predict the category of a post. Let&amp;rsquo;s start with a &lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;na&amp;iuml;ve Bayes&lt;/a&gt; classifier, which provides a nice baseline for this task. &lt;code&gt;scikit-learn&lt;/code&gt; includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:</source>
          <target state="translated">これで機能が用意できたので、投稿のカテゴリを予測するように分類子をトレーニングできます。まず、このタスクの適切なベースラインを提供する&lt;a href=&quot;../../modules/naive_bayes#naive-bayes&quot;&gt;単純なベイズ&lt;/a&gt;分類器から始めましょう。 &lt;code&gt;scikit-learn&lt;/code&gt; には、この分類子のいくつかのバリアントが含まれています。単語数に最適なのは多項式バリアントです。</target>
        </trans-unit>
        <trans-unit id="88e8cd01d787ca5c585c186900aea23cd932893c" translate="yes" xml:space="preserve">
          <source>Now we can use Ames Housing dataset to make the predictions. We check the performance of each individual predictor as well as of the stack of the regressors.</source>
          <target state="translated">これで、Ames Housingのデータセットを使って予測を行うことができます。個々の予測器の性能と、回帰器のスタックの性能を確認します。</target>
        </trans-unit>
        <trans-unit id="c77da09ad9df95918caa9589e1cfa5804c7aace6" translate="yes" xml:space="preserve">
          <source>Now we create a &lt;code&gt;FeatureUnion&lt;/code&gt;. All features will be imputed using &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt;, in order to enable classifiers to work with this data. Additionally, it adds the the indicator variables from &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">次に、 &lt;code&gt;FeatureUnion&lt;/code&gt; を作成します。分類子がこのデータを処理できるようにするために、すべての機能は&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt;を使用して代入されます。さらに、&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;からインジケーター変数を追加します。</target>
        </trans-unit>
        <trans-unit id="0e66fc30e8519d1cd12806317bc82ad0b2345f16" translate="yes" xml:space="preserve">
          <source>Now we want to select the two features which are the most important. SelectFromModel() allows for setting the threshold. Only the features with the &lt;code&gt;coef_&lt;/code&gt; higher than the threshold will remain. Here, we want to set the threshold slightly above the third highest &lt;code&gt;coef_&lt;/code&gt; calculated by LassoCV() from our data.</source>
          <target state="translated">ここで、最も重要な2つの機能を選択します。SelectFromModel（）を使用すると、しきい値を設定できます。 &lt;code&gt;coef_&lt;/code&gt; がしきい値よりも高いフィーチャのみが残ります。ここでは、データからLassoCV（）によって計算された3番目に高い &lt;code&gt;coef_&lt;/code&gt; をわずかに超えるしきい値を設定します。</target>
        </trans-unit>
        <trans-unit id="6c18c8137b5b9d8aae8dc57c26f7d6b41951afd4" translate="yes" xml:space="preserve">
          <source>Now we will estimate the score on the data where the missing values are replaced by 0:</source>
          <target state="translated">今度は、欠損値を0に置き換えたデータ上でスコアを推定します。</target>
        </trans-unit>
        <trans-unit id="2b6f8334bd6af42d0add5e2131513b016d9f6e6d" translate="yes" xml:space="preserve">
          <source>Now we will initiate the gradient boosting regressors and fit it with our training data. Let&amp;rsquo;s also look and the mean squared error on the test data.</source>
          <target state="translated">次に、勾配ブースティングリグレッサーを開始し、トレーニングデータに適合させます。また、テストデータの平均二乗誤差も見てみましょう。</target>
        </trans-unit>
        <trans-unit id="2c5cf2d42930f189f93938b87f35b21f55ff5f6c" translate="yes" xml:space="preserve">
          <source>Now we will use each of the regressors to make the 20 first predictions.</source>
          <target state="translated">では、それぞれの回帰子を使って、20個の最初の予測をしていきます。</target>
        </trans-unit>
        <trans-unit id="936a8dbed55baf9b2e1ebda09b75843de98173ab" translate="yes" xml:space="preserve">
          <source>Now we will write a function which will score the results on the differently imputed data. Let&amp;rsquo;s look at each imputer separately:</source>
          <target state="translated">次に、異なる代入データの結果をスコアリングする関数を記述します。各代入子を個別に見てみましょう。</target>
        </trans-unit>
        <trans-unit id="39c382cf98b09c769e0ece49478f8e5a21269790" translate="yes" xml:space="preserve">
          <source>Now you can &lt;em&gt;predict&lt;/em&gt; new values. In this case, you&amp;rsquo;ll predict using the last image from &lt;code&gt;digits.data&lt;/code&gt;. By predicting, you&amp;rsquo;ll determine the image from the training set that best matches the last image.</source>
          <target state="translated">これで、新しい値を&lt;em&gt;予測&lt;/em&gt;できます。この場合、 &lt;code&gt;digits.data&lt;/code&gt; の最後の画像を使用して予測します。予測することにより、最後の画像に最もよく一致するトレーニングセットから画像を決定します。</target>
        </trans-unit>
        <trans-unit id="4bde0a1195bac7469e935b78a194104a68da7a29" translate="yes" xml:space="preserve">
          <source>Now, if we repeat this computation for the remaining 2 terms in the document, we get</source>
          <target state="translated">さて、この計算をドキュメントの残りの2つの用語について繰り返すと、次のようになります。</target>
        </trans-unit>
        <trans-unit id="ece88bcd9ec161c2a2872c2fb61e36a0d64c7a18" translate="yes" xml:space="preserve">
          <source>Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous &amp;ndash; \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):</source>
          <target state="translated">これで、これ以上の仮定がなければ、潜在変数\（h \）を使用するという考えは不要になります。\（x \）は、平均と共分散で完全にモデル化できます。これら2つのパラメーターの1つに、より具体的な構造を課す必要があります。簡単な追加の仮定は、エラー共分散\（\ Psi \）の構造に関係します：</target>
        </trans-unit>
        <trans-unit id="a31389fe4ff0ebc6e5c5d38e5dab56436f6bc483" translate="yes" xml:space="preserve">
          <source>Nu Support Vector Regression.</source>
          <target state="translated">ニューサポートベクトル回帰。</target>
        </trans-unit>
        <trans-unit id="a9b51312b4e809b61f7b24f233552372d8a4d343" translate="yes" xml:space="preserve">
          <source>Nu-Support Vector Classification.</source>
          <target state="translated">ニューサポートベクトル分類。</target>
        </trans-unit>
        <trans-unit id="3fd1d9cda92e08af6fee8cba19fd970cf1f0632b" translate="yes" xml:space="preserve">
          <source>Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). &lt;code&gt;l1_ratio=1&lt;/code&gt; corresponds to the Lasso.</source>
          <target state="translated">エラスティックネットに渡される0から1までの数値（l1からl2までのペナルティのスケーリング）。 &lt;code&gt;l1_ratio=1&lt;/code&gt; はラッソに対応します。</target>
        </trans-unit>
        <trans-unit id="7957f8886c98fbf5a70e65a8ee06b411dfa2ec9d" translate="yes" xml:space="preserve">
          <source>Number of Attributes</source>
          <target state="translated">属性の数</target>
        </trans-unit>
        <trans-unit id="28831313b9efda1fb2d5e62ae541d82eeaf2e628" translate="yes" xml:space="preserve">
          <source>Number of Attributes:</source>
          <target state="translated">属性の数。</target>
        </trans-unit>
        <trans-unit id="2bbc98640e09a456dee6d19b3fcc0a288b212310" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証ループ中に使用されたCPUコアの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e0f96f6f23ce740144b8c92df340b8480f6b786d" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used during the cross-validation loop. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証ループ中に使用されたCPUコアの数。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e056a5a70210c137f261290dad04190fbc9ce82b" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">multi_class = 'ovr'&amp;rdquo;の場合、クラスを並列化するときに使用されるCPUコアの数。'multi_class'が指定されているかどうかに関係なく、 &lt;code&gt;solver&lt;/code&gt; が 'liblinear'に設定されている場合、このパラメーターは無視されます。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ba00da4689fb46c7f1453ab4c4d840dda819bf30" translate="yes" xml:space="preserve">
          <source>Number of CPU cores used when parallelizing over classes if multi_class=&amp;rsquo;ovr&amp;rsquo;&amp;rdquo;. This parameter is ignored when the &lt;code&gt;solver&lt;/code&gt; is set to &amp;lsquo;liblinear&amp;rsquo; regardless of whether &amp;lsquo;multi_class&amp;rsquo; is specified or not. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">multi_class = 'ovr'&amp;rdquo;の場合、クラスを並列化するときに使用されるCPUコアの数。'multi_class'が指定されているかどうかに関係なく、 &lt;code&gt;solver&lt;/code&gt; が 'liblinear'に設定されている場合、このパラメーターは無視されます。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="044a045266785f2237c066206c338baa3e1d5bb2" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="299b1e18443f4440c97e32fcbc5b33894e6807aa" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="aaf36da587212084529abec535211c954c2e7c01" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。これは、l1_ratioに複数の値が指定されている場合にのみ使用されることに注意してください。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="abb87aba72afe118ccbcfcbd98130537908df821" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">相互検証中に使用するCPUの数。これは、l1_ratioに複数の値が指定されている場合にのみ使用されることに注意してください。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="52783b9f963f3f1690dd5d40572b3875e2a7ade7" translate="yes" xml:space="preserve">
          <source>Number of CPUs to use during the resampling. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">リサンプリング中に使用するCPUの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="9b0888ca0284a2c854ae8715c4ccbdf2a4510807" translate="yes" xml:space="preserve">
          <source>Number of Instances</source>
          <target state="translated">インスタンス数</target>
        </trans-unit>
        <trans-unit id="a2666336978a0f4e8c547b7534c07249ba6000fd" translate="yes" xml:space="preserve">
          <source>Number of Instances:</source>
          <target state="translated">インスタンス数。</target>
        </trans-unit>
        <trans-unit id="0bc3461e8033920222bec6b216692137eee9c091" translate="yes" xml:space="preserve">
          <source>Number of Monte Carlo samples per original feature. Equals the dimensionality of the computed feature space.</source>
          <target state="translated">元の特徴量あたりのモンテカルロ法のサンプル数.計算された特徴空間の次元数に等しい.</target>
        </trans-unit>
        <trans-unit id="3262f2b1a48253ff0690a8a75cfdd12aae481720" translate="yes" xml:space="preserve">
          <source>Number of active features across every target for the model refit with the best hyperparameters got by cross-validating across all folds.</source>
          <target state="translated">すべてのフォールドでクロスバリデーションを行って得られた最高のハイパーパラメータを持つモデルのリフィットについて、すべてのターゲットでアクティブな特徴の数。</target>
        </trans-unit>
        <trans-unit id="4cbf5cb47ecd9996ec380ef5f0f19c258c9e11e4" translate="yes" xml:space="preserve">
          <source>Number of active features across every target.</source>
          <target state="translated">すべてのターゲットでアクティブな機能の数。</target>
        </trans-unit>
        <trans-unit id="4d39e5d8b3efa9d6f8372f94e39a5395c837b600" translate="yes" xml:space="preserve">
          <source>Number of active features across every target. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">すべてのターゲットにわたるアクティブな機能の数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="e0c8a9190fa0a6b6567e6260a08bbc16ad38e0e1" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path</source>
          <target state="translated">正則化パスに沿ったアルファの数</target>
        </trans-unit>
        <trans-unit id="21389bf92cd8e8648f186478c091bf8c596c9371" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path, used for each l1_ratio.</source>
          <target state="translated">各 l1_ratio に使用される正則化パスに沿ったアルファの数.</target>
        </trans-unit>
        <trans-unit id="cbe7afb5599ad451cab3f599179a64fd19bd9311" translate="yes" xml:space="preserve">
          <source>Number of alphas along the regularization path.</source>
          <target state="translated">正則化パスに沿ったアルファの数.</target>
        </trans-unit>
        <trans-unit id="cb76f13b1ca274d0ac0509e0599ee9f88692f95e" translate="yes" xml:space="preserve">
          <source>Number of best singular vectors to which to project the data for clustering.</source>
          <target state="translated">クラスタリングのためにデータを投影するための最高の特異ベクトルの数.</target>
        </trans-unit>
        <trans-unit id="669eddc43c369820a90c37333994758dabadb237" translate="yes" xml:space="preserve">
          <source>Number of binary hidden units.</source>
          <target state="translated">2値の隠れた単位の数。</target>
        </trans-unit>
        <trans-unit id="df5056a6b08a72e6eb298ef5a65870b5ddc8c698" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. An ignored feature at index &lt;code&gt;i&lt;/code&gt; will have &lt;code&gt;n_bins_[i] == 0&lt;/code&gt;.</source>
          <target state="translated">機能ごとのビンの数。インデックス &lt;code&gt;i&lt;/code&gt; で無視された機能は &lt;code&gt;n_bins_[i] == 0&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="d7a7f2e004236d911cb66cf34176f3d71e43ecca" translate="yes" xml:space="preserve">
          <source>Number of bins per feature. Bins whose width are too small (i.e., &amp;lt;= 1e-8) are removed with a warning.</source>
          <target state="translated">機能ごとのビンの数。幅が小さすぎる（つまり、&amp;lt;= 1e-8）ビンは、警告とともに削除されます。</target>
        </trans-unit>
        <trans-unit id="a230a570a7b298a4731493b5111f06efb3bd3e1c" translate="yes" xml:space="preserve">
          <source>Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in &lt;code&gt;y_prob&lt;/code&gt;) will not be returned, thus the returned arrays may have less than &lt;code&gt;n_bins&lt;/code&gt; values.</source>
          <target state="translated">[0、1]間隔を離散化するビンの数。数値が大きいほど、より多くのデータが必要になります。サンプルがない（つまり、 &lt;code&gt;y_prob&lt;/code&gt; に対応する値がない）ビンは返されません。したがって、返される配列の値は &lt;code&gt;n_bins&lt;/code&gt; 未満である可能性があります。</target>
        </trans-unit>
        <trans-unit id="9e19457800c5864e1fbdcc0291b0ef620abfd78c" translate="yes" xml:space="preserve">
          <source>Number of bins. A bigger number requires more data.</source>
          <target state="translated">ビンの数。数が多いと、より多くのデータが必要になります。</target>
        </trans-unit>
        <trans-unit id="0c552ab63ca0f87bf2127208daa3692ef5597992" translate="yes" xml:space="preserve">
          <source>Number of classes</source>
          <target state="translated">クラス数</target>
        </trans-unit>
        <trans-unit id="fbe9989009b56729007d1b9895a9883c9be1c338" translate="yes" xml:space="preserve">
          <source>Number of classes.</source>
          <target state="translated">クラスの数。</target>
        </trans-unit>
        <trans-unit id="f70f556044c9d189136c9439d7b869763e660892" translate="yes" xml:space="preserve">
          <source>Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.</source>
          <target state="translated">葉からのサブクラスタを新しいサンプルとして扱う最終クラスタリングステップの後のクラスタ数.</target>
        </trans-unit>
        <trans-unit id="d93f166299b2fe351648697f50539b771bbcab5f" translate="yes" xml:space="preserve">
          <source>Number of clusters to extract.</source>
          <target state="translated">抽出するクラスターの数。</target>
        </trans-unit>
        <trans-unit id="eb68d1899db83f395f515eac11a92a2f39369f2a" translate="yes" xml:space="preserve">
          <source>Number of combinations taken into account from &amp;lsquo;n choose k&amp;rsquo;, where n is the number of samples and k is the number of subsamples.</source>
          <target state="translated">'n choose k'から考慮される組み合わせの数。nはサンプルの数、kはサブサンプルの数です。</target>
        </trans-unit>
        <trans-unit id="7fdc37b73d2c326edb84e2aac0aaad0a3921fc6b" translate="yes" xml:space="preserve">
          <source>Number of components</source>
          <target state="translated">部品点数</target>
        </trans-unit>
        <trans-unit id="cd12f5ccc87c2314d1a7462c1838eb4fba879a35" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt; n_classes - 1) for dimensionality reduction.</source>
          <target state="translated">次元削減のためのコンポーネントの数（&amp;lt;n_classes-1）。</target>
        </trans-unit>
        <trans-unit id="dfb009c80642e429ebd085f522e99f9888546747" translate="yes" xml:space="preserve">
          <source>Number of components (&amp;lt;= min(n_classes - 1, n_features)) for dimensionality reduction. If None, will be set to min(n_classes - 1, n_features). This parameter only affects the &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">次元削減のためのコンポーネントの数（&amp;lt;= min（n_classes-1、n_features））。Noneの場合、min（n_classes-1、n_features）に設定されます。このパラメーターは、 &lt;code&gt;transform&lt;/code&gt; メソッドにのみ影響します。</target>
        </trans-unit>
        <trans-unit id="678dcaccd382015a606461223e75a521f8c270e3" translate="yes" xml:space="preserve">
          <source>Number of components to keep</source>
          <target state="translated">保持する部品の数</target>
        </trans-unit>
        <trans-unit id="209051725a6de8e5e1e5fa7a1e74f7eb06a44fec" translate="yes" xml:space="preserve">
          <source>Number of components to keep.</source>
          <target state="translated">残すべき部品の数。</target>
        </trans-unit>
        <trans-unit id="d04623123bcfd2ce2b9c37b5c1e9535768de28a7" translate="yes" xml:space="preserve">
          <source>Number of components to keep. If &lt;code&gt;n_components `` is ``None&lt;/code&gt;, then &lt;code&gt;n_components&lt;/code&gt; is set to &lt;code&gt;min(n_samples, n_features)&lt;/code&gt;.</source>
          <target state="translated">保持するコンポーネントの数。もし &lt;code&gt;n_components `` is ``None&lt;/code&gt; 、その後、 &lt;code&gt;n_components&lt;/code&gt; がに設定されている &lt;code&gt;min(n_samples, n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="864a5ed4a409c99b07b3c02fc85e293c54d58811" translate="yes" xml:space="preserve">
          <source>Number of components to keep. if n_components is not set all components are kept:</source>
          <target state="translated">n_componentsが設定されていない場合、すべてのコンポーネントが保持されます。</target>
        </trans-unit>
        <trans-unit id="b681f0aabf7a4e88ff6e07d02e6d3053416c7e30" translate="yes" xml:space="preserve">
          <source>Number of components to use. If none is passed, all are used.</source>
          <target state="translated">使用するコンポーネントの数。何も渡されない場合は、すべてのコンポーネントが使用されます。</target>
        </trans-unit>
        <trans-unit id="a4c9442f9290e02b19f88b85f02bacea3cfec6f7" translate="yes" xml:space="preserve">
          <source>Number of components, if n_components is not set all features are kept.</source>
          <target state="translated">コンポーネントの数、n_componentsが設定されていない場合はすべての機能が保持されます。</target>
        </trans-unit>
        <trans-unit id="cd25fc9de4a04b081f0b9a2b60926bce89997152" translate="yes" xml:space="preserve">
          <source>Number of components. If None, all non-zero components are kept.</source>
          <target state="translated">コンポーネントの数。Noneの場合、0以外の成分はすべて保持されます。</target>
        </trans-unit>
        <trans-unit id="45f800ea0c8bd716a5f59f6d34dd8fdf95b8f22e" translate="yes" xml:space="preserve">
          <source>Number of components:</source>
          <target state="translated">コンポーネントの数。</target>
        </trans-unit>
        <trans-unit id="08ad46845beb5661bae33c15135ad1635029f790" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">フォールド全体にフィットしながら並列実行するコアの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="858edfcde96e4df6617cbdeba5e365378b873cbb" translate="yes" xml:space="preserve">
          <source>Number of cores to run in parallel while fitting across folds. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">折り目を横切ってフィットしながら並行して実行するコアの数。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="8c854de6ce1141c59e336a0d697b5a2d467a137a" translate="yes" xml:space="preserve">
          <source>Number of decimal digits to display.</source>
          <target state="translated">表示する10進数を指定します。</target>
        </trans-unit>
        <trans-unit id="0da9d602da12f13ca29bd75af12cc8c869e57a9f" translate="yes" xml:space="preserve">
          <source>Number of dictionary atoms to extract.</source>
          <target state="translated">抽出する辞書の原子数。</target>
        </trans-unit>
        <trans-unit id="5227337d1c8f00f0cc5985a46091828c912745d3" translate="yes" xml:space="preserve">
          <source>Number of digits for formatting output floating point values. When &lt;code&gt;output_dict&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this will be ignored and the returned values will not be rounded.</source>
          <target state="translated">出力浮動小数点値をフォーマットするための桁数。 &lt;code&gt;output_dict&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、これは無視され、戻り値は丸められません。</target>
        </trans-unit>
        <trans-unit id="393e0ab0962f61be4ea05f66f75cf83a58c8acb8" translate="yes" xml:space="preserve">
          <source>Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.</source>
          <target state="translated">各ノードの不純物属性、閾値、値属性の値の浮動小数点精度の桁数</target>
        </trans-unit>
        <trans-unit id="857511ca3ff53ac74c7a9a64491518f8a98aa57b" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities.</source>
          <target state="translated">異質さに浸る次元の数。</target>
        </trans-unit>
        <trans-unit id="60a7a9ccef477eb7d360b15d4ec93323fc3722cf" translate="yes" xml:space="preserve">
          <source>Number of dimensions in which to immerse the dissimilarities. If an &lt;code&gt;init&lt;/code&gt; array is provided, this option is overridden and the shape of &lt;code&gt;init&lt;/code&gt; is used to determine the dimensionality of the embedding space.</source>
          <target state="translated">非類似度を埋め込む次元の数。場合 &lt;code&gt;init&lt;/code&gt; アレイが提供され、このオプションは無効にされ、形状 &lt;code&gt;init&lt;/code&gt; 埋め込み空間の次元を決定するために使用されます。</target>
        </trans-unit>
        <trans-unit id="f601fdb82b970f8ccae9e3060c9f42a8faed55c3" translate="yes" xml:space="preserve">
          <source>Number of documents to use in each EM iteration. Only used in online learning.</source>
          <target state="translated">EMの各反復で使用する文書の数。オンライン学習でのみ使用。</target>
        </trans-unit>
        <trans-unit id="25fead66533b3559387b2fcbff51a361b6ce623f" translate="yes" xml:space="preserve">
          <source>Number of eigen vectors to use for the spectral embedding</source>
          <target state="translated">スペクトル埋め込みに使用する固有ベクトルの数</target>
        </trans-unit>
        <trans-unit id="70fb7e9ad9dffd747feff757e8b6b2c3b8c3ad21" translate="yes" xml:space="preserve">
          <source>Number of examples per minibatch.</source>
          <target state="translated">ミニバッチあたりの例の数。</target>
        </trans-unit>
        <trans-unit id="f3a87cabcd8ae2a3f47b41980367db8a154ace86" translate="yes" xml:space="preserve">
          <source>Number of features</source>
          <target state="translated">特徴の数</target>
        </trans-unit>
        <trans-unit id="c43d2150a87097029c4596d560aaf86e8bb6b759" translate="yes" xml:space="preserve">
          <source>Number of features in the training data.</source>
          <target state="translated">学習データに含まれる特徴量の数</target>
        </trans-unit>
        <trans-unit id="577fe93a084a93466c74dd6388a400050adba06b" translate="yes" xml:space="preserve">
          <source>Number of features of each sample.</source>
          <target state="translated">各サンプルの特徴量の数。</target>
        </trans-unit>
        <trans-unit id="48c9c477edb63770940bc1b8209cb208de55d13b" translate="yes" xml:space="preserve">
          <source>Number of features seen during &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;フィット&lt;/a&gt;中に見られる特徴の数。</target>
        </trans-unit>
        <trans-unit id="f26773f39b3b679c0daff789f714ad69f2880ea0" translate="yes" xml:space="preserve">
          <source>Number of features to construct. How many data points will be used to construct the mapping.</source>
          <target state="translated">構築する特徴量の数。マッピングを構築するために使用するデータポイントの数。</target>
        </trans-unit>
        <trans-unit id="d56ef4ad6a94ab0bc79a9c8a295f26cabf4e9608" translate="yes" xml:space="preserve">
          <source>Number of features with missing values.</source>
          <target state="translated">欠損値を持つ特徴量の数。</target>
        </trans-unit>
        <trans-unit id="8bfcb7d61331a9745e723fb4ee723054b5ce91e8" translate="yes" xml:space="preserve">
          <source>Number of folds. Must be at least 2.</source>
          <target state="translated">フォールドの数。2以上である必要があります。</target>
        </trans-unit>
        <trans-unit id="37148505c5ccd477f2cd9888510233bf49ab48d7" translate="yes" xml:space="preserve">
          <source>Number of grid points. The path is linearly reinterpolated on a grid between 0 and 1 before computing the scores.</source>
          <target state="translated">グリッド点の数。スコアを計算する前に、パスは0と1の間のグリッド上で線形に再補間されます。</target>
        </trans-unit>
        <trans-unit id="609fe53affef0db7e95afe01e9b3b2b42cfee225" translate="yes" xml:space="preserve">
          <source>Number of groups (&lt;code&gt;p&lt;/code&gt;) to leave out in the test split.</source>
          <target state="translated">テスト分割で除外するグループの数（ &lt;code&gt;p&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="7836a44e33451a2adc5e90b29cc50de43f4df6df" translate="yes" xml:space="preserve">
          <source>Number of iteration done before the next print.</source>
          <target state="translated">次の印刷までに行われた反復の数。</target>
        </trans-unit>
        <trans-unit id="58ef557aa3516e101a9370d2bf015690817ac32f" translate="yes" xml:space="preserve">
          <source>Number of iteration rounds that occurred. Will be less than &lt;code&gt;self.max_iter&lt;/code&gt; if early stopping criterion was reached.</source>
          <target state="translated">発生した反復ラウンドの数。早期停止基準に達した場合、 &lt;code&gt;self.max_iter&lt;/code&gt; よりも小さくなります。</target>
        </trans-unit>
        <trans-unit id="c7ee7fcff30c38dbe60673fcfaba39d5dcac363e" translate="yes" xml:space="preserve">
          <source>Number of iterations corresponding to the best results. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">最良の結果に対応する反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="b6dedae4e35c925119d2eb7b698bd022b8304ae7" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">ランダム化されたSVDソルバーの反復回数。ARPACKでは使用されません。デフォルトは&lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;randomized_svd&lt;/code&gt; &lt;/a&gt;のデフォルトよりも大きく、ゆっくりと減衰する大きなスペクトルを持つ可能性のあるスパース行列を処理します。</target>
        </trans-unit>
        <trans-unit id="b89cf5a40a3578805b3d3e22f18c4e3365baf655" translate="yes" xml:space="preserve">
          <source>Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in &lt;code&gt;randomized_svd&lt;/code&gt; to handle sparse matrices that may have large slowly decaying spectrum.</source>
          <target state="translated">ランダム化されたSVDソルバーの反復回数。ARPACKでは使用されません。デフォルトは、 &lt;code&gt;randomized_svd&lt;/code&gt; のデフォルトより大きく、ゆっくりと減衰する大きなスペクトルを持つ可能性のあるスパース行列を処理します。</target>
        </trans-unit>
        <trans-unit id="b158b03d08af1b718d3d75c350a03244a2d1a76a" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method computed by svd_solver == &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">svd_solver == 'randomized'によって計算されたpowerメソッドの反復回数。</target>
        </trans-unit>
        <trans-unit id="ea8482c683ec2d466d38eba89e78f2c408d93dba" translate="yes" xml:space="preserve">
          <source>Number of iterations for the power method. 3 by default. Only used if &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;</source>
          <target state="translated">べき乗法の反復回数。デフォルトでは3。 &lt;code&gt;svd_method&lt;/code&gt; が 'randomized'に等しい場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="e2a3f7897a04130ec9ab6e8a06f184c73a2db962" translate="yes" xml:space="preserve">
          <source>Number of iterations needed for the spatial median.</source>
          <target state="translated">空間中央値に必要な反復回数。</target>
        </trans-unit>
        <trans-unit id="0a6f367644c8353f5e90ff32f9e722b8b3c35762" translate="yes" xml:space="preserve">
          <source>Number of iterations of the EM step.</source>
          <target state="translated">EMステップの反復回数。</target>
        </trans-unit>
        <trans-unit id="ca85b057132e8737cc9bd5d9895d1c2f0a3952a0" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component.</source>
          <target state="translated">各コンポーネントのNIPALS内ループの反復回数。</target>
        </trans-unit>
        <trans-unit id="38592412005a60e12235ac166647e6d24941d551" translate="yes" xml:space="preserve">
          <source>Number of iterations of the NIPALS inner loop for each component. Not useful if the algorithm provided is &amp;ldquo;svd&amp;rdquo;.</source>
          <target state="translated">各コンポーネントのNIPALS内部ループの反復回数。提供されたアルゴリズムが「svd」の場合は役に立ちません。</target>
        </trans-unit>
        <trans-unit id="b3f0661f5b6a537d1cfcf27ec4e37f08f53a4a65" translate="yes" xml:space="preserve">
          <source>Number of iterations run for the optimal alpha.</source>
          <target state="translated">最適なアルファのために実行された反復回数.</target>
        </trans-unit>
        <trans-unit id="c9d82135ee15642aa7ae8817dc570334ab80622b" translate="yes" xml:space="preserve">
          <source>Number of iterations run.</source>
          <target state="translated">実行された反復回数。</target>
        </trans-unit>
        <trans-unit id="cc453132656fb5fe083f1f7f5f3c0a7066108d51" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">実行された反復の数。 &lt;code&gt;return_n_iter&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="346838eb1c236609499116f6804a1aeab6029a68" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">実行された反復の数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="bae285cae0e2d21ef6dbbaa8dd54db30234b47e0" translate="yes" xml:space="preserve">
          <source>Number of iterations run. Returned only if return_n_iter is set to True.</source>
          <target state="translated">実行された反復回数。return_n_iterがTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="6e040a3af3a9255e0d8c4455bc3543184ccbc3ff" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to an invalid model defined by &lt;code&gt;is_model_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_model_valid&lt;/code&gt; で定義された無効なモデルのためにスキップされた反復の数。</target>
        </trans-unit>
        <trans-unit id="51f697c488b6017321338ddb492864c9436800d7" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to finding zero inliers.</source>
          <target state="translated">インライアがゼロであることが判明したためにスキップされた反復回数。</target>
        </trans-unit>
        <trans-unit id="6eebd535eebcad36fc18ca23295141a0bc8384b3" translate="yes" xml:space="preserve">
          <source>Number of iterations skipped due to invalid data defined by &lt;code&gt;is_data_valid&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;is_data_valid&lt;/code&gt; で定義された無効なデータのためにスキップされた反復の数。</target>
        </trans-unit>
        <trans-unit id="2b48b7f3d47c667152c7041a648c896ae52b12ff" translate="yes" xml:space="preserve">
          <source>Number of iterations taken to converge.</source>
          <target state="translated">収束するまでの反復回数。</target>
        </trans-unit>
        <trans-unit id="63b22566940c8c05aad34ed364e32e6bea85ba5f" translate="yes" xml:space="preserve">
          <source>Number of iterations that &lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; has run for.</source>
          <target state="translated">&lt;code&gt;scipy.optimize.minimize(method=&quot;L-BFGS-B&quot;)&lt;/code&gt; が実行された反復の数。</target>
        </trans-unit>
        <trans-unit id="e35e76f80d1bcb32a849fe5cd7421a6593683d9d" translate="yes" xml:space="preserve">
          <source>Number of iterations that fmin_l_bfgs_b has run for.</source>
          <target state="translated">fmin_l_bfgs_bが実行した反復回数。</target>
        </trans-unit>
        <trans-unit id="e6fe9562687f3b9f37db26e9dd5d7295821884aa" translate="yes" xml:space="preserve">
          <source>Number of iterations to perform.</source>
          <target state="translated">実行する反復回数。</target>
        </trans-unit>
        <trans-unit id="744edb5cd8af9d3cbdec3cef824f76ed36468258" translate="yes" xml:space="preserve">
          <source>Number of iterations with no change in the number of estimated clusters that stops the convergence.</source>
          <target state="translated">収束が止まる推定クラスター数が変化しない反復回数</target>
        </trans-unit>
        <trans-unit id="1bb6572e9c67b7f2e1d3c0099c8130bc63fa4d36" translate="yes" xml:space="preserve">
          <source>Number of iterations with no improvement to wait before early stopping.</source>
          <target state="translated">早期停止前の待ち時間が改善されていない反復回数</target>
        </trans-unit>
        <trans-unit id="427bd42a1575036c8163feb881b5305713a1194a" translate="yes" xml:space="preserve">
          <source>Number of iterations. Returned only if &lt;code&gt;return_n_iter&lt;/code&gt; is set to True.</source>
          <target state="translated">反復回数。 &lt;code&gt;return_n_iter&lt;/code&gt; がTrueに設定されている場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="20dbe7868d12b42e72b8007b758b8aa006423eb6" translate="yes" xml:space="preserve">
          <source>Number of iterations/sweeps over the training dataset to perform during training.</source>
          <target state="translated">訓練中に実行する訓練データセットに対する反復/スイープの数.</target>
        </trans-unit>
        <trans-unit id="805e89de9bc259ba0d4faba86a9892d5aeb2c894" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">並行して実行するジョブの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="f64638965b4156e5561d4f1aeb7b5023899255aa" translate="yes" xml:space="preserve">
          <source>Number of jobs to run in parallel. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">並行して実行するジョブの数。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="68e07911a64110ae2d25f4573c1be042d5d1283e" translate="yes" xml:space="preserve">
          <source>Number of label for each output.</source>
          <target state="translated">各出力のラベルの数。</target>
        </trans-unit>
        <trans-unit id="bd419af7c37c78ed35cd8f556746c5d780f24447" translate="yes" xml:space="preserve">
          <source>Number of layers.</source>
          <target state="translated">レイヤーの数。</target>
        </trans-unit>
        <trans-unit id="4192e6479d3e36a298ef5ede4c2274eeba61eb5b" translate="yes" xml:space="preserve">
          <source>Number of leaves in the hierarchical tree.</source>
          <target state="translated">階層木の葉の数。</target>
        </trans-unit>
        <trans-unit id="ba1aa7966ff18979251514a0f2aad7e015769458" translate="yes" xml:space="preserve">
          <source>Number of leaves.</source>
          <target state="translated">葉の数。</target>
        </trans-unit>
        <trans-unit id="cfcbfd1023f8a82de0be1bdb45b84e4fb92fdade" translate="yes" xml:space="preserve">
          <source>Number of mini-batch iterations to perform.</source>
          <target state="translated">実行するミニバッチの反復回数。</target>
        </trans-unit>
        <trans-unit id="4bc27955a0ba30e7799dd7d637ec50bb558a2a01" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors effectively used.</source>
          <target state="translated">有効に使用されている最寄の数</target>
        </trans-unit>
        <trans-unit id="eff81c828ce86aeb5087b71b68182742b417d4b0" translate="yes" xml:space="preserve">
          <source>Number of nearest neighbors for nearest_neighbors graph building.</source>
          <target state="translated">nearest_neighborsグラフの建物の最寄りの隣人の数。</target>
        </trans-unit>
        <trans-unit id="f4b6da30fa273de202c93a0a24f9b983a9a2a207" translate="yes" xml:space="preserve">
          <source>Number of neighboring samples to use for imputation.</source>
          <target state="translated">インプットに使用する隣接サンプルの数。</target>
        </trans-unit>
        <trans-unit id="216e3472c822df844cda9519c2636b73cd479f24" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample in the transformed sparse graph. For compatibility reasons, as each sample is considered as its own neighbor, one extra neighbor will be computed when mode == &amp;lsquo;distance&amp;rsquo;. In this case, the sparse graph contains (n_neighbors + 1) neighbors.</source>
          <target state="translated">変換されたスパースグラフの各サンプルの近傍の数。互換性の理由から、各サンプルはそれ自体のネイバーと見なされるため、mode == 'distance'の場合、1つの追加のネイバーが計算されます。この場合、スパースグラフには（n_neighbors + 1）個のネイバーが含まれます。</target>
        </trans-unit>
        <trans-unit id="37fe95cfc748f25efeacf97021fc7a2313be0b5a" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample.</source>
          <target state="translated">各サンプルの隣人の数。</target>
        </trans-unit>
        <trans-unit id="51b538d5b2a3f95b9485557e25d620a9a782f3b4" translate="yes" xml:space="preserve">
          <source>Number of neighbors for each sample. (default is value passed to the constructor).</source>
          <target state="translated">各サンプルの隣人の数。(デフォルトはコンストラクタに渡される値)。</target>
        </trans-unit>
        <trans-unit id="efd458290903df55801a7ce6bf62f9ba73dd0009" translate="yes" xml:space="preserve">
          <source>Number of neighbors k that will be considered.</source>
          <target state="translated">考慮される隣人の数 k。</target>
        </trans-unit>
        <trans-unit id="d3cee20cf7566ae95a6af940493b4c430f93d3a6" translate="yes" xml:space="preserve">
          <source>Number of neighbors required. If not provided, this will return the number specified at the initialization.</source>
          <target state="translated">必要な隣人の数。指定しない場合は、初期化時に指定した数を返します。</target>
        </trans-unit>
        <trans-unit id="1e55799760cfa2d3bdbd572fe607c1fc4b77b9d7" translate="yes" xml:space="preserve">
          <source>Number of neighbors to be returned from query function when it is not provided to the &lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LSHForest.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;メソッドに提供されていない場合にクエリ関数から返されるネイバーの数。</target>
        </trans-unit>
        <trans-unit id="3262363328a422de3ed07567136a319deb9ad271" translate="yes" xml:space="preserve">
          <source>Number of neighbors to get (default is the value passed to the constructor).</source>
          <target state="translated">取得する隣人の数 (デフォルトはコンストラクタに渡される値)。</target>
        </trans-unit>
        <trans-unit id="02076e172db6b5e77d67d9ae83e2b88dc66a094e" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsClassifier.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="e28eb76463a74cc573864c82f5c8b8d60708a92f" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.KNeighborsRegressor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="4a844d73b7e4afd6cea1487cf59defb5c0385114" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries. If n_neighbors is larger than the number of samples provided, all samples will be used.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.LocalOutlierFactor.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。n_neighborsが提供されたサンプルの数より大きい場合、すべてのサンプルが使用されます。</target>
        </trans-unit>
        <trans-unit id="7e98c15b26d0846d8c1e878d641afc0e3d115b38" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use by default for &lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt;&lt;code&gt;kneighbors&lt;/code&gt;&lt;/a&gt; queries.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.neighbors.NearestNeighbors.kneighbors&quot;&gt; &lt;code&gt;kneighbors&lt;/code&gt; &lt;/a&gt;クエリにデフォルトで使用するネイバーの数。</target>
        </trans-unit>
        <trans-unit id="70cd89c4110a42556e2c733194f1c90f3d647ddb" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">連続変数のMI推定に使用する近傍の数。&lt;a href=&quot;#r37d39d7589e2-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;および&lt;a href=&quot;#r37d39d7589e2-3&quot; id=&quot;id6&quot;&gt;[3]を&lt;/a&gt;参照してください。値を大きくすると、推定の分散が減少しますが、バイアスが生じる可能性があります。</target>
        </trans-unit>
        <trans-unit id="237e706a6f5317f1b4ad85e94d1e882cb7b24021" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use for MI estimation for continuous variables, see &lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt; and &lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]&lt;/a&gt;. Higher values reduce variance of the estimation, but could introduce a bias.</source>
          <target state="translated">連続変数のMI推定に使用する近傍の数。&lt;a href=&quot;#r50b872b699c4-2&quot; id=&quot;id5&quot;&gt;[2]&lt;/a&gt;および&lt;a href=&quot;#r50b872b699c4-3&quot; id=&quot;id6&quot;&gt;[3]を&lt;/a&gt;参照してください。値を大きくすると、推定の分散が減少しますが、バイアスが生じる可能性があります。</target>
        </trans-unit>
        <trans-unit id="9f8819cc7687f8afeb7c24c0200033a234d0c39c" translate="yes" xml:space="preserve">
          <source>Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for &lt;code&gt;affinity='rbf'&lt;/code&gt;.</source>
          <target state="translated">最近傍法を使用してアフィニティマトリックスを作成するときに使用する近傍の数。 &lt;code&gt;affinity='rbf'&lt;/code&gt; の場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="c37287ec818bb6dad17b995ed5729153d9a8118d" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; and &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">解の各列で対象とする非ゼロ係数の数。これは、 &lt;code&gt;algorithm=&amp;rsquo;lars&amp;rsquo;&lt;/code&gt; および &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; でのみ使用され、 &lt;code&gt;omp&lt;/code&gt; の場合は &lt;code&gt;alpha&lt;/code&gt; によってオーバーライドされます。</target>
        </trans-unit>
        <trans-unit id="3d8a9b81dd6bc7c054449c6745360802b0f076b9" translate="yes" xml:space="preserve">
          <source>Number of nonzero coefficients to target in each column of the solution. This is only used by &lt;code&gt;algorithm='lars'&lt;/code&gt; and &lt;code&gt;algorithm='omp'&lt;/code&gt; and is overridden by &lt;code&gt;alpha&lt;/code&gt; in the &lt;code&gt;omp&lt;/code&gt; case.</source>
          <target state="translated">ソリューションの各列でターゲットとする非ゼロ係数の数。これは、 &lt;code&gt;algorithm='lars'&lt;/code&gt; および &lt;code&gt;algorithm='omp'&lt;/code&gt; によってのみ使用され、 &lt;code&gt;omp&lt;/code&gt; の場合は &lt;code&gt;alpha&lt;/code&gt; によってオーバーライドされます。</target>
        </trans-unit>
        <trans-unit id="0be2c79389c0a56a89ad2014f6366b3f95d2bca8" translate="yes" xml:space="preserve">
          <source>Number of other features to use to estimate the missing values of each feature column. Nearness between features is measured using the absolute correlation coefficient between each feature pair (after initial imputation). To ensure coverage of features throughout the imputation process, the neighbor features are not necessarily nearest, but are drawn with probability proportional to correlation for each imputed target feature. Can provide significant speed-up when the number of features is huge. If &lt;code&gt;None&lt;/code&gt;, all features will be used.</source>
          <target state="translated">各特徴列の欠落値を推定するために使用する他の特徴の数。特徴間の近さは、各特徴ペア間の絶対相関係数を使用して測定されます（最初の代入後）。代入プロセス全体で特徴を確実にカバーするために、隣接する特徴は必ずしも最も近いとは限りませんが、代入された各ターゲット特徴の相関に比例する確率で描画されます。機能の数が膨大な場合、大幅なスピードアップを実現できます。 &lt;code&gt;None&lt;/code&gt; の場合、すべての機能が使用されます。</target>
        </trans-unit>
        <trans-unit id="27f9bf5a85bc89aa70ea3dbacba13e73a444a9f8" translate="yes" xml:space="preserve">
          <source>Number of outputs.</source>
          <target state="translated">出力数。</target>
        </trans-unit>
        <trans-unit id="a01758eccae198371ad1fbda71e0227c6924ab24" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">実行する並列ジョブの数。 &lt;code&gt;None&lt;/code&gt; は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="aec9eb1029d40469b12f590579b2421b0ac783c2" translate="yes" xml:space="preserve">
          <source>Number of parallel jobs to run. &lt;code&gt;None&lt;/code&gt; means 1 unless in a &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt;&lt;code&gt;joblib.parallel_backend&lt;/code&gt;&lt;/a&gt; context. &lt;code&gt;-1&lt;/code&gt; means using all processors. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;Glossary&lt;/a&gt; for more details.</source>
          <target state="translated">実行する並列ジョブの数。&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend&quot;&gt; &lt;code&gt;joblib.parallel_backend&lt;/code&gt; &lt;/a&gt;コンテキストでない限り、 &lt;code&gt;None&lt;/code&gt; は1を意味します。 &lt;code&gt;-1&lt;/code&gt; は、すべてのプロセッサを使用することを意味します。詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-jobs&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="89260d16706c6571daecae9b230dfb394e4f8e34" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are produced.</source>
          <target state="translated">生成されるパラメータ設定の数。</target>
        </trans-unit>
        <trans-unit id="26680dedc0c193794be077118d1d33ec7cee22de" translate="yes" xml:space="preserve">
          <source>Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.</source>
          <target state="translated">サンプリングされるパラメータ設定の数。 n_iterは実行時間とソリューションの品質をトレードオフにします。</target>
        </trans-unit>
        <trans-unit id="9b3af5a87173ff58737497b2a7b2dff4ac22b716" translate="yes" xml:space="preserve">
          <source>Number of passes over the dataset.</source>
          <target state="translated">データセットを通過する回数.</target>
        </trans-unit>
        <trans-unit id="e919298382f2b30ec9254222b02df5121a7447b9" translate="yes" xml:space="preserve">
          <source>Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified &lt;code&gt;leaf_size&lt;/code&gt;, a leaf node is guaranteed to satisfy &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt;, except in the case that &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt;.</source>
          <target state="translated">ブルートフォースに切り替えるポイントの数。leaf_sizeを変更してもクエリの結果には影響しませんが、クエリの速度と、構築されたツリーを格納するために必要なメモリに大きな影響を与える可能性があります。ツリーを格納するために必要なメモリ量は、およそn_samples / leaf_sizeとしてスケーリングします。指定された &lt;code&gt;leaf_size&lt;/code&gt; の場合、リーフノードは、 &lt;code&gt;n_samples &amp;lt; leaf_size&lt;/code&gt; 場合を除いて、 &lt;code&gt;leaf_size &amp;lt;= n_points &amp;lt;= 2 * leaf_size&lt;/code&gt; を満たすことが保証されます。</target>
        </trans-unit>
        <trans-unit id="74f0e4f1324b195e40b6b67840245cc6639acde5" translate="yes" xml:space="preserve">
          <source>Number of power iterations used to stabilize the result</source>
          <target state="translated">結果の安定化に使用したパワー反復回数</target>
        </trans-unit>
        <trans-unit id="3af0fded49ca0f3c99c5f4242edefb1980f1ee1e" translate="yes" xml:space="preserve">
          <source>Number of power iterations. It can be used to deal with very noisy problems. When &amp;lsquo;auto&amp;rsquo;, it is set to 4, unless &lt;code&gt;n_components&lt;/code&gt; is small (&amp;lt; .1 * min(X.shape)) &lt;code&gt;n_iter&lt;/code&gt; in which case is set to 7. This improves precision with few components.</source>
          <target state="translated">パワー反復の数。非常に騒々しい問題を処理するために使用できます。「オート」、それは4に設定されている場合がない限り、 &lt;code&gt;n_components&lt;/code&gt; が小さい（&amp;lt;0.1 *分（X.shape）） &lt;code&gt;n_iter&lt;/code&gt; が、その場合には7に設定されているこれは、いくつかのコンポーネントと精度を向上させることができます。</target>
        </trans-unit>
        <trans-unit id="01905db27e1b09268197900ceb99a1346e890115" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The str can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">並列実行のために事前にディスパッチされたジョブの数（デフォルトはすべて）。このオプションは、割り当てられたメモリを減らすことができます。strは、「2 * n_jobs」のような式にすることができます。</target>
        </trans-unit>
        <trans-unit id="7c2b5ab18e2bf242894b9a2ecca14a388d432f49" translate="yes" xml:space="preserve">
          <source>Number of predispatched jobs for parallel execution (default is all). The option can reduce the allocated memory. The string can be an expression like &amp;lsquo;2*n_jobs&amp;rsquo;.</source>
          <target state="translated">並列実行のための事前ディスパッチされたジョブの数（デフォルトはすべて）。このオプションは、割り当てられたメモリを減らすことができます。文字列は、「2 * n_jobs」のような式にすることができます。</target>
        </trans-unit>
        <trans-unit id="344e1da2c8fa0e4b376ce3e457a99189b911e25a" translate="yes" xml:space="preserve">
          <source>Number of previous iterations completed on the dictionary used for initialization.</source>
          <target state="translated">初期化に使用された辞書で完了した前回の反復回数。</target>
        </trans-unit>
        <trans-unit id="20853d9102158a366a61d28a6b2cb29c20c98681" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative density function.</source>
          <target state="translated">計算される量点の数。累積密度関数を離散化するために使用されるランドマークの数に対応する.</target>
        </trans-unit>
        <trans-unit id="548caec42d172e8575f71a33916af24287471704" translate="yes" xml:space="preserve">
          <source>Number of quantiles to be computed. It corresponds to the number of landmarks used to discretize the cumulative distribution function. If n_quantiles is larger than the number of samples, n_quantiles is set to the number of samples as a larger number of quantiles does not give a better approximation of the cumulative distribution function estimator.</source>
          <target state="translated">計算される量点の数。これは,累積分布関数を離散化するために使用されるランドマークの数に対応する.n_quantilesが標本数よりも大きい場合,n_quantilesは標本数に設定されます.これは量点の数が大きいほど累積分布関数の推定値の近似がうまくいかないためです.</target>
        </trans-unit>
        <trans-unit id="e4aaf1e86836dfafd99ac1220487fd647e794f84" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried with the k-means algorithm.</source>
          <target state="translated">k-meansアルゴリズムで試行されるランダムな初期化の数。</target>
        </trans-unit>
        <trans-unit id="b43bc8af90e8df6a17a3d2db5f152fc9e0f7509e" translate="yes" xml:space="preserve">
          <source>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the &lt;code&gt;n_init&lt;/code&gt; initializations as measured by inertia.</source>
          <target state="translated">試行されたランダムな初期化の数。KMeansとは対照的に、アルゴリズムは1回だけ実行され、慣性によって測定された &lt;code&gt;n_init&lt;/code&gt; の初期化のうち最良のものを使用します。</target>
        </trans-unit>
        <trans-unit id="2a775249dab61ada8ba714fbef3fe2a6cd5e7f9a" translate="yes" xml:space="preserve">
          <source>Number of random selection trials until one of the stop criteria is met. It is always &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt;.</source>
          <target state="translated">停止基準の1つが満たされるまでのランダム選択試行の回数。常に &lt;code&gt;&amp;lt;= max_trials&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="ddb00b53d153c760e3c244cb1587828c964053be" translate="yes" xml:space="preserve">
          <source>Number of randomized models.</source>
          <target state="translated">無作為化モデルの数。</target>
        </trans-unit>
        <trans-unit id="6e7920a40024bb45accfba5d3a9412bad8885ccd" translate="yes" xml:space="preserve">
          <source>Number of re-shuffling &amp;amp; splitting iterations.</source>
          <target state="translated">再シャッフルと分割の反復回数。</target>
        </trans-unit>
        <trans-unit id="8c1de77526ac5586c3170ef35d398449f2b6a01e" translate="yes" xml:space="preserve">
          <source>Number of rows and columns (resp.) in the bicluster.</source>
          <target state="translated">バイクラスター内の行と列の数(レスポンダ)。</target>
        </trans-unit>
        <trans-unit id="ad1b9067ab876b7409a0c802cf769015719aca95" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各(クラス,特徴量)で遭遇したサンプルの数.この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="c92a24738a539e752aec89fe917078bdb81b48d8" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各クラスで遭遇したサンプルの数。この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="7d9434e4be81d003217d0ff99bec2958d6cf8f1c" translate="yes" xml:space="preserve">
          <source>Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.</source>
          <target state="translated">フィッティング中に各特徴に遭遇したサンプルの数。この値は,指定された場合には,サンプルの重みで重み付けされます.</target>
        </trans-unit>
        <trans-unit id="4189046e920c071a46d31153d30f2c5546e5d75d" translate="yes" xml:space="preserve">
          <source>Number of samples in a subcluster.</source>
          <target state="translated">サブクラスター内のサンプル数。</target>
        </trans-unit>
        <trans-unit id="d6a1b136f66f610a4896adec7fc65cb72260eca1" translate="yes" xml:space="preserve">
          <source>Number of samples in the training data.</source>
          <target state="translated">学習データのサンプル数。</target>
        </trans-unit>
        <trans-unit id="b1b8d68fdf55246f42bd4140ab8cdd3ea5232e3c" translate="yes" xml:space="preserve">
          <source>Number of samples seen so far, excluded X.</source>
          <target state="translated">これまでに見られたサンプル数、除外されたX.</target>
        </trans-unit>
        <trans-unit id="f3eb4ebcff443a5740a69d115e4c7d66ed2b7058" translate="yes" xml:space="preserve">
          <source>Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.</source>
          <target state="translated">パラメータを計算するためのサンプル数。これは、 少なくとも特徴量の数(fit_intercept=True の場合はプラス 1)と、 最大値としてのサンプル数です。数値が低い と 破断点が高 く 効率が低 く な り 、 数値が高い と 破断点が低 く 効率が高 く な り ます。None の場合、ロバスト性が最大になるサブサンプル数の最小値を取ります。n_subsamples が n_samples に設定されている場合、Theil-Sen は最小二乗と同じです。</target>
        </trans-unit>
        <trans-unit id="fc350dda13f5c287c8548b6575ceb1d2c780f61c" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. Defaults to 1.</source>
          <target state="translated">生成するサンプル数。デフォルトは1です。</target>
        </trans-unit>
        <trans-unit id="e94e897f1bb653d4e0feaefd5987d4a553f8af8b" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays.</source>
          <target state="translated">生成するサンプル数。Noneのままにしておくと,これは自動的に配列の1次元目に設定されます.</target>
        </trans-unit>
        <trans-unit id="1a167b23f9bb21704b10da0ef2fc738d507dce40" translate="yes" xml:space="preserve">
          <source>Number of samples to generate. If left to None this is automatically set to the first dimension of the arrays. If replace is False it should not be larger than the length of arrays.</source>
          <target state="translated">生成するサンプル数。None のままにしておくと,これは自動的に配列の1次元目に設定されます.replace が False の場合は,配列の長さよりも大きくしてはいけません.</target>
        </trans-unit>
        <trans-unit id="37b65d0e64d2d03034e5f2f5fa109bac79447708" translate="yes" xml:space="preserve">
          <source>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</source>
          <target state="translated">初期化を高速化するために(時には精度を犠牲にして)ランダムにサンプリングするサンプル数:唯一のアルゴリズムは,データのランダムなサブセットでバッチKMeansを実行することによって初期化される.これは,n_clustersよりも大きくする必要がある.</target>
        </trans-unit>
        <trans-unit id="79fd133ee683290a8c4b438718235e4555547cff" translate="yes" xml:space="preserve">
          <source>Number of samples. If an array is given, it will compute a safe number of components array-wise.</source>
          <target state="translated">サンプル数。配列が与えられた場合,配列ごとに安全な数の成分を計算します.</target>
        </trans-unit>
        <trans-unit id="ea4ca73ab41ec6033a853674e7fbc815a311d3cf" translate="yes" xml:space="preserve">
          <source>Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays.</source>
          <target state="translated">サンプル数.n_samples を渡すと,スライスが疎な行列のインデックス作成に使用される場合に使用されます.</target>
        </trans-unit>
        <trans-unit id="a75d9ceb8c321c78e9909168b2356ee01f06d1c4" translate="yes" xml:space="preserve">
          <source>Number of singular values and vectors to extract.</source>
          <target state="translated">抽出する特異値とベクトルの数。</target>
        </trans-unit>
        <trans-unit id="9259a302604f8c3d052d9766a0665f74598f4a66" translate="yes" xml:space="preserve">
          <source>Number of singular vectors to check.</source>
          <target state="translated">チェックする特異ベクトルの数。</target>
        </trans-unit>
        <trans-unit id="4e03fb606fcab969781bb42da4618d24e54a8291" translate="yes" xml:space="preserve">
          <source>Number of slices to generate.</source>
          <target state="translated">生成するスライスの数。</target>
        </trans-unit>
        <trans-unit id="2834c0f8a56b1dcfce6f6e78db200759bce6dd7b" translate="yes" xml:space="preserve">
          <source>Number of spaces between edges. The higher it is, the wider the result.</source>
          <target state="translated">辺と辺の間のスペースの数。高いほど結果は広くなります。</target>
        </trans-unit>
        <trans-unit id="c55cc369cb9552b44b4a575f3aae7b0b751a97c8" translate="yes" xml:space="preserve">
          <source>Number of sparse atoms to extract.</source>
          <target state="translated">抽出する疎な原子の数。</target>
        </trans-unit>
        <trans-unit id="133c33b7f976c18813a243c5632b24f2c8e81111" translate="yes" xml:space="preserve">
          <source>Number of splits. Must be at least 2.</source>
          <target state="translated">分割数。2以上である必要があります。</target>
        </trans-unit>
        <trans-unit id="a6bce09538dcde7e7ff60020a73de4974cae38ac" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of EM to reach the convergence.</source>
          <target state="translated">収束に到達するためにEMのベストフィットで使用されるステップ数。</target>
        </trans-unit>
        <trans-unit id="aec50834e9d4a500ee385c37d29d58bdc624bb7e" translate="yes" xml:space="preserve">
          <source>Number of step used by the best fit of inference to reach the convergence.</source>
          <target state="translated">推論のベストフィットが収束に到達するために使用するステップ数。</target>
        </trans-unit>
        <trans-unit id="ef96b42c053cf6cd51d23012a0a52b84b2a07604" translate="yes" xml:space="preserve">
          <source>Number of support vectors for each class.</source>
          <target state="translated">各クラスのサポートベクトルの数.</target>
        </trans-unit>
        <trans-unit id="424ae2b2f85d63b5b83778ea64c14167e1acf984" translate="yes" xml:space="preserve">
          <source>Number of targets</source>
          <target state="translated">対象者数</target>
        </trans-unit>
        <trans-unit id="abc9da602c481111cdc9cad2b9a2ec618fddfb11" translate="yes" xml:space="preserve">
          <source>Number of test samples in this split.</source>
          <target state="translated">このスプリットのテストサンプル数。</target>
        </trans-unit>
        <trans-unit id="35ccbd0ed91056f0b431a8e36f769a8655c75e9b" translate="yes" xml:space="preserve">
          <source>Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</source>
          <target state="translated">異なるセントロイドシードを用いて k-means アルゴリズムを実行する回数。最終的な結果は,慣性の観点から,n_init 連続実行の最良の出力となります.</target>
        </trans-unit>
        <trans-unit id="f584f00fb96d0392221b2f107adcb2345328d3b9" translate="yes" xml:space="preserve">
          <source>Number of times cross-validator needs to be repeated.</source>
          <target state="translated">クロスバリデータを繰り返す必要がある回数。</target>
        </trans-unit>
        <trans-unit id="5d2e8dfe07ab898c902f4c479175b6b09037f98d" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.</source>
          <target state="translated">SMACOFアルゴリズムが異なる初期化で実行される回数。最終的な結果は、最終的な応力が最も小さい実行によって決定され、実行の中で最高の出力となります。</target>
        </trans-unit>
        <trans-unit id="61d47a44584bfde40c1396e5d7fc8603c469e589" translate="yes" xml:space="preserve">
          <source>Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress. If &lt;code&gt;init&lt;/code&gt; is provided, this option is overridden and a single run is performed.</source>
          <target state="translated">異なる初期化でSMACOFアルゴリズムが実行される回数。最終結果は、最小の最終応力を持つ実行によって決定される、実行の最良の出力になります。 &lt;code&gt;init&lt;/code&gt; が指定されている場合、このオプションはオーバーライドされ、単一の実行が実行されます。</target>
        </trans-unit>
        <trans-unit id="279a7d188f8d456ddd160319a5480a2db5aa1c81" translate="yes" xml:space="preserve">
          <source>Number of times to permute &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;y&lt;/code&gt; を置換する回数。</target>
        </trans-unit>
        <trans-unit id="463dac0c15a56b554ec940dbcedbd42982c379fb" translate="yes" xml:space="preserve">
          <source>Number of times to permute a feature.</source>
          <target state="translated">フィーチャーをパーミュートする回数。</target>
        </trans-unit>
        <trans-unit id="69631a318e07c7e122bb29c914f2e0417bbb3ea3" translate="yes" xml:space="preserve">
          <source>Number of top features to select. The &amp;ldquo;all&amp;rdquo; option bypasses selection, for use in a parameter search.</source>
          <target state="translated">選択する上位の機能の数。「all」オプションは、パラメーター検索で使用するために、選択をバイパスします。</target>
        </trans-unit>
        <trans-unit id="da4c15da76668749b2d08dac7e93fa89fa01cae3" translate="yes" xml:space="preserve">
          <source>Number of topics.</source>
          <target state="translated">話題の数。</target>
        </trans-unit>
        <trans-unit id="fbddcfb20eac49b636d0567ae2783e45f24d5db9" translate="yes" xml:space="preserve">
          <source>Number of trees in the LSH Forest.</source>
          <target state="translated">LSHの森の木の数。</target>
        </trans-unit>
        <trans-unit id="f59a66952049f5c09c592626a93864184fb52de6" translate="yes" xml:space="preserve">
          <source>Number of trees in the forest.</source>
          <target state="translated">森の木の数。</target>
        </trans-unit>
        <trans-unit id="883143c355bb70d9c124548ac182b0a674cf4c90" translate="yes" xml:space="preserve">
          <source>Number of values per feature.</source>
          <target state="translated">フィーチャーごとの値の数。</target>
        </trans-unit>
        <trans-unit id="3d3c8a841ea2fec708f92a22e6cb69db77e1725b" translate="yes" xml:space="preserve">
          <source>Number of vectors to use in calculating the SVD. Corresponds to &lt;code&gt;ncv&lt;/code&gt; when &lt;code&gt;svd_method=arpack&lt;/code&gt; and &lt;code&gt;n_oversamples&lt;/code&gt; when &lt;code&gt;svd_method&lt;/code&gt; is &amp;lsquo;randomized`.</source>
          <target state="translated">SVDの計算に使用するベクトルの数。対応 &lt;code&gt;ncv&lt;/code&gt; &lt;code&gt;svd_method=arpack&lt;/code&gt; と &lt;code&gt;n_oversamples&lt;/code&gt; &lt;code&gt;svd_method&lt;/code&gt; は「randomized`です。</target>
        </trans-unit>
        <trans-unit id="16bf53dde5c63fb6777b19bf3ca8bb646d21ca57" translate="yes" xml:space="preserve">
          <source>Number of weight updates performed during training. Same as &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt;.</source>
          <target state="translated">トレーニング中に実行された体重更新の数。 &lt;code&gt;(n_iter_ * n_samples)&lt;/code&gt; 同じです。</target>
        </trans-unit>
        <trans-unit id="cfc2be0c624984ee3eedecc63144bb2eb0e00cd3" translate="yes" xml:space="preserve">
          <source>Numbers of training examples that has been used to generate the learning curve. Note that the number of ticks might be less than n_ticks because duplicate entries will be removed.</source>
          <target state="translated">学習曲線を生成するために使用された学習例の数。重複したエントリは削除されるので、tick数はn_ticksよりも少ないかもしれないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="a28c04c9b4b005997c9b362ad026f41b8cd86540" translate="yes" xml:space="preserve">
          <source>Numeric Features:</source>
          <target state="translated">数値的特徴。</target>
        </trans-unit>
        <trans-unit id="89c43bf4b62114e4d6b82aa7a39bcd64acde71ea" translate="yes" xml:space="preserve">
          <source>Numeric stopping criterion (WRITEME). 1e-3 by default.</source>
          <target state="translated">数値的な停止基準(WRITEME)。デフォルトでは1e-3。</target>
        </trans-unit>
        <trans-unit id="546b4b9a9bb1a271c23a369b5102c7b719bb257b" translate="yes" xml:space="preserve">
          <source>Numerical solver to use.</source>
          <target state="translated">使用する数値ソルバー</target>
        </trans-unit>
        <trans-unit id="e91bee1467e40de4d946ed662375c173925b59f5" translate="yes" xml:space="preserve">
          <source>Numerical solver to use:</source>
          <target state="translated">使用する数値ソルバー</target>
        </trans-unit>
        <trans-unit id="1bda3e35c6cc189118f551c9ef807d4c37dc07f6" translate="yes" xml:space="preserve">
          <source>Numerical solver to use: &amp;lsquo;cd&amp;rsquo; is a Coordinate Descent solver. &amp;lsquo;mu&amp;rsquo; is a Multiplicative Update solver.</source>
          <target state="translated">使用する数値ソルバー： 'cd'は座標降下ソルバーです。'mu'は乗法更新ソルバーです。</target>
        </trans-unit>
        <trans-unit id="c42d401e991cba0a784aff1388e26ed9b57a65e8" translate="yes" xml:space="preserve">
          <source>O. Ledoit and M. Wolf, &amp;ldquo;A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices&amp;rdquo;, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.</source>
          <target state="translated">O. LedoitとM. Wolf、「大規模共分散行列のための条件の整った推定量」、多変量解析ジャーナル、88巻、2号、2004年2月、ページ365-411。</target>
        </trans-unit>
        <trans-unit id="e39d7c7a6dfc71c75f7fd3b1688e4255ab0569b5" translate="yes" xml:space="preserve">
          <source>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.</source>
          <target state="translated">O.L.マンガサリアン、W.N.ストリート、W.H.ウォルバーグ。線形計画法による乳がん診断と予後.オペレーションズリサーチ,43(4),570-577 ページ,1995 年 7-8 月.</target>
        </trans-unit>
        <trans-unit id="dea6ae2f186812bc2bf8114a674ec0e8c8de8039" translate="yes" xml:space="preserve">
          <source>OAS is a particular form of shrinkage described in &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">OASは、「MMSE共分散推定のための縮小アルゴリズム」Chen et al。、IEEE Trans。サインオン。Proc。、Volume 58、Issue 10、2010年10月。</target>
        </trans-unit>
        <trans-unit id="516f97783bd415e3a50d6dad8302febb07d2e198" translate="yes" xml:space="preserve">
          <source>OCCUPATION</source>
          <target state="translated">OCCUPATION</target>
        </trans-unit>
        <trans-unit id="d588c2d5cad6e344a9a328bc0dcc94f63bfe1c53" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Clerical</source>
          <target state="translated">OCCUPATION_Clerical</target>
        </trans-unit>
        <trans-unit id="b725bc8de0a483c5d88499d9e7c87c7ae4685ba8" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Management</source>
          <target state="translated">OCCUPATION_Management</target>
        </trans-unit>
        <trans-unit id="0e54eeff266f2a17bed8c69e66148a30421390e0" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Other</source>
          <target state="translated">OCCUPATION_Other</target>
        </trans-unit>
        <trans-unit id="d50ba20894189c3830106f0cfb4a70b0e6554b4e" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Professional</source>
          <target state="translated">OCCUPATION_Professional</target>
        </trans-unit>
        <trans-unit id="d9264bc2d4c97fd3584da75ee0731d202c6b28fe" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Sales</source>
          <target state="translated">OCCUPATION_Sales</target>
        </trans-unit>
        <trans-unit id="7c720959f75a9b22fee1afe843481ec6692d4aa6" translate="yes" xml:space="preserve">
          <source>OCCUPATION_Service</source>
          <target state="translated">OCCUPATION_Service</target>
        </trans-unit>
        <trans-unit id="f3fd8009dd2433d1a63abbabb480a18d05e74108" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines</source>
          <target state="translated">希釈ワインのOD280/OD315</target>
        </trans-unit>
        <trans-unit id="2f76e133c144664f6ceed4509b6ad3d9fe14a67d" translate="yes" xml:space="preserve">
          <source>OD280/OD315 of diluted wines:</source>
          <target state="translated">希釈ワインのOD280/OD315。</target>
        </trans-unit>
        <trans-unit id="9ce3bd4224c8c1780db56b4125ecf3f24bf748b7" translate="yes" xml:space="preserve">
          <source>OK</source>
          <target state="translated">OK</target>
        </trans-unit>
        <trans-unit id="8e8565eb895a4e523ac266f2a6f2af45cda869f8" translate="yes" xml:space="preserve">
          <source>OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.</source>
          <target state="translated">OMPは、各ステップで現在の残差と最も相関の高い原子を含む貪欲なアルゴリズムに基づいています。これは、より単純なマッチング追求(MP)法に似ていますが、各反復で、以前に選択された辞書要素の空間への直交投影を使用して残差が再計算されるという点で優れています。</target>
        </trans-unit>
        <trans-unit id="702567365ae2f6da8d5fc9650aab7f68f2e2b4bd" translate="yes" xml:space="preserve">
          <source>OOB Errors for Random Forests</source>
          <target state="translated">ランダムフォレストのOOB誤差</target>
        </trans-unit>
        <trans-unit id="7556880ffb905f4996fa16b161902fde13e5d1be" translate="yes" xml:space="preserve">
          <source>OPTICS</source>
          <target state="translated">OPTICS</target>
        </trans-unit>
        <trans-unit id="3921b01080f70880ca169ee2dd262001f08a9a03" translate="yes" xml:space="preserve">
          <source>OPTICS (Ordering Points To Identify the Clustering Structure), closely related to DBSCAN, finds core sample of high density and expands clusters from them &lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;. Unlike DBSCAN, keeps cluster hierarchy for a variable neighborhood radius. Better suited for usage on large datasets than the current sklearn implementation of DBSCAN.</source>
          <target state="translated">DBSCANに密接に関連するOPTICS（クラスタリング構造を特定するための順序付けポイント）は、高密度のコアサンプルを見つけ、それらからクラスターを拡張します&lt;a href=&quot;#r2c55e37003fe-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。DBSCANとは異なり、可変近傍半径のクラスター階層を維持します。DBSCANの現在のsklearn実装よりも、大規模なデータセットでの使用に適しています。</target>
        </trans-unit>
        <trans-unit id="3657cfede2d1ca1450e1e96704c7fe1e79174b7f" translate="yes" xml:space="preserve">
          <source>OPTICS ordered point indices (&lt;code&gt;ordering_&lt;/code&gt;)</source>
          <target state="translated">OPTICS順序付きポイントインデックス（ &lt;code&gt;ordering_&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="2b77a29777f0317be507e501f5c60c74e4daaff5" translate="yes" xml:space="preserve">
          <source>OR, if affinity==`precomputed`, a precomputed affinity matrix of shape (n_samples, n_samples)</source>
          <target state="translated">OR,affinity==`precomputed`の場合、事前に計算された形状のアフィニティ行列(n_samples,n_samples)</target>
        </trans-unit>
        <trans-unit id="c8f36dd22506f2db935605e7016ba4725ee8d954" translate="yes" xml:space="preserve">
          <source>OVR + L1 penalty</source>
          <target state="translated">OVR+L1ペナルティ</target>
        </trans-unit>
        <trans-unit id="6fb4b4e4f3901ecb1795e224abe18919de690335" translate="yes" xml:space="preserve">
          <source>OVR + L2 penalty</source>
          <target state="translated">OVR+L2ペナルティ</target>
        </trans-unit>
        <trans-unit id="cb5d65d3f62b5d33c694bb026fc2cc2e2c9008af" translate="yes" xml:space="preserve">
          <source>Object that mocks the urlopen function to fake requests to mldata.</source>
          <target state="translated">urlopen関数をモックしてmldataへのリクエストを偽装するオブジェクト。</target>
        </trans-unit>
        <trans-unit id="e59a9b80a8b5844a54b21160c3e6341a042b77f2" translate="yes" xml:space="preserve">
          <source>Object that stores computed values.</source>
          <target state="translated">計算された値を格納するオブジェクト。</target>
        </trans-unit>
        <trans-unit id="04c754a9ec758f22d2ae91b0fe2718c4051ca8ed" translate="yes" xml:space="preserve">
          <source>Object used to transform multiclass labels to binary labels and vice-versa.</source>
          <target state="translated">マルチクラスラベルをバイナリラベルに変換したり、逆にバイナリラベルに変換したりするために使用されるオブジェクトです。</target>
        </trans-unit>
        <trans-unit id="cdd1673e245cacca55f04fb3561b4eb5194072ad" translate="yes" xml:space="preserve">
          <source>Objects that will be checked for consistent length.</source>
          <target state="translated">長さが一貫しているかどうかチェックされるオブジェクト。</target>
        </trans-unit>
        <trans-unit id="ca9385c00c56b402f0d7c8ffd3817a9453089565" translate="yes" xml:space="preserve">
          <source>Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, B. Zadrozny &amp;amp; C. Elkan, ICML 2001</source>
          <target state="translated">決定木と素朴なベイズ分類器から較正された確率推定値を取得、B。Zadrozny＆C. Elkan、ICML 2001</target>
        </trans-unit>
        <trans-unit id="e90a2c57a395bd5ca1744a90561d5ec67c512ffb" translate="yes" xml:space="preserve">
          <source>Obviously when the number of features increases so does the memory consumption of each example. Indeed, for a matrix of \(M\) instances with \(N\) features, the space complexity is in \(O(NM)\). From a computing perspective it also means that the number of basic operations (e.g., multiplications for vector-matrix products in linear models) increases too. Here is a graph of the evolution of the prediction latency with the number of features:</source>
          <target state="translated">明らかに、特徴の数が増えれば、各例のメモリ消費量も増える。実際、\(M\(M)instances with \(N\)features の行列の場合、空間の複雑さは、\(O(NM)\)になります。計算の観点からは,基本的な演算(例えば,線形モデルにおけるベクトル行列の積の乗算など)の数が増えることも意味している.以下は、特徴量の増加に伴う予測待ち時間の変化のグラフです。</target>
        </trans-unit>
        <trans-unit id="215c08c61e401481973fc6ab07ef3f7e0eb253cc" translate="yes" xml:space="preserve">
          <source>Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If we give this parameter a value of &lt;code&gt;-1&lt;/code&gt;, grid search will detect how many cores are installed and use them all:</source>
          <target state="translated">明らかに、このような徹底的な検索は高価になる可能性があります。複数のCPUコアを自由に使用できる場合は、グリッドサーチャーにこれらの8つのパラメーターの組み合わせを &lt;code&gt;n_jobs&lt;/code&gt; パラメーターと並行して試すように指示できます。このパラメーターに &lt;code&gt;-1&lt;/code&gt; の値を指定すると、グリッド検索はインストールされているコアの数を検出し、それらをすべて使用します。</target>
        </trans-unit>
        <trans-unit id="b4b9ad57c64718cb6c7c5d4cbab51ee018de2ade" translate="yes" xml:space="preserve">
          <source>Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.</source>
          <target state="translated">発生カウントは良いスタートですが、問題があります:同じトピックについて話していても、長い文書は短い文書よりも平均カウント値が高くなります。</target>
        </trans-unit>
        <trans-unit id="ca59a1039148105183d8291ca83a4fbed4483e6f" translate="yes" xml:space="preserve">
          <source>Of course, we cannot use the transformer to make any predictions. We should wrap this in a &lt;code&gt;Pipeline&lt;/code&gt; with a classifier (e.g., a &lt;code&gt;DecisionTreeClassifier&lt;/code&gt;) to be able to make predictions.</source>
          <target state="translated">もちろん、トランスフォーマーを使用して予測を行うことはできません。予測を行うことができるように、これを分類子（たとえば、 &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; ）を使用して &lt;code&gt;Pipeline&lt;/code&gt; でラップする必要があります。</target>
        </trans-unit>
        <trans-unit id="d31e6b35c3a4fbda0c959d2368ee4f77d248cc70" translate="yes" xml:space="preserve">
          <source>Of particular interest is the ability of &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; to mimic the behavior of missForest, a popular imputation package for R. In this example, we have chosen to use &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; instead of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt;&lt;/a&gt; (as in missForest) due to its increased speed.</source>
          <target state="translated">特に興味深いのは、Rの一般的な代入パッケージであるmissForestの動作を模倣する&lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt; &lt;/a&gt;の機能です。この例では、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt;代わりに&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestRegressor&lt;/code&gt; &lt;/a&gt;を使用することを選択しました（ missForest）は、速度が向上したためです。</target>
        </trans-unit>
        <trans-unit id="d2bfdaca8f6fadc90e32a081ace94f3ad9884e84" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります： &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。 &lt;code&gt;offset_&lt;/code&gt; は次のように定義されます。汚染パラメータが「自動」に設定されている場合、インライアのスコアが0に近く、外れ値のスコアが-1に近いため、オフセットは-0.5に等しくなります。 「自動」とは異なる汚染パラメーターが指定されている場合、オフセットは、トレーニングで予想される外れ値（決定関数&amp;lt;0のサンプル）の数を取得するように定義されます。</target>
        </trans-unit>
        <trans-unit id="64b2af0bc2328de785be4029344182e16e12fcc6" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. Assuming behaviour == &amp;lsquo;new&amp;rsquo;, &lt;code&gt;offset_&lt;/code&gt; is defined as follows. When the contamination parameter is set to &amp;ldquo;auto&amp;rdquo;, the offset is equal to -0.5 as the scores of inliers are close to 0 and the scores of outliers are close to -1. When a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided, the offset is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training. Assuming the behaviour parameter is set to &amp;lsquo;old&amp;rsquo;, we always have &lt;code&gt;offset_ = -0.5&lt;/code&gt;, making the decision function independent from the contamination parameter.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。動作== 'new'の場合、 &lt;code&gt;offset_&lt;/code&gt; は次のように定義されます。汚染パラメータが「自動」に設定されている場合、インライアのスコアが0に近く、外れ値のスコアが-1に近いため、オフセットは-0.5になります。 「auto」以外の汚染パラメータが指定されている場合、トレーニングで予測される外れ値（決定関数&amp;lt;0のサンプル）の予想数を取得するようにオフセットが定義されます。動作パラメーターが 'old'に設定されていると仮定すると、常に &lt;code&gt;offset_ = -0.5&lt;/code&gt; があり、決定関数が汚染パラメーターから独立しています。</target>
        </trans-unit>
        <trans-unit id="bbd227107da9d921e8bc12d3a3ca7fd4c0bd101f" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt;. The offset depends on the contamination parameter and is defined in such a way we obtain the expected number of outliers (samples with decision function &amp;lt; 0) in training.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります &lt;code&gt;decision_function = score_samples - offset_&lt;/code&gt; 。オフセットは汚染パラメータに依存し、トレーニングで外れ値（決定関数&amp;lt;0のサンプル）の予想数を取得する方法で定義されます。</target>
        </trans-unit>
        <trans-unit id="4f4356395ebd6023fbdce24e12feab7e5ca80606" translate="yes" xml:space="preserve">
          <source>Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - &lt;code&gt;offset_&lt;/code&gt;. The offset is the opposite of &lt;code&gt;intercept_&lt;/code&gt; and is provided for consistency with other outlier detection algorithms.</source>
          <target state="translated">生のスコアから決定関数を定義するために使用されるオフセット。次の関係があります。decision_function= score_samples- &lt;code&gt;offset_&lt;/code&gt; 。オフセットは &lt;code&gt;intercept_&lt;/code&gt; の反対であり、他の外れ値検出アルゴリズムとの一貫性のために提供されています。</target>
        </trans-unit>
        <trans-unit id="9195b75fbc020bb9db88d8b131967914e6de2adf" translate="yes" xml:space="preserve">
          <source>Offset used to obtain binary labels from the raw scores. Observations having a negative_outlier_factor smaller than &lt;code&gt;offset_&lt;/code&gt; are detected as abnormal. The offset is set to -1.5 (inliers score around -1), except when a contamination parameter different than &amp;ldquo;auto&amp;rdquo; is provided. In that case, the offset is defined in such a way we obtain the expected number of outliers in training.</source>
          <target state="translated">生のスコアからバイナリラベルを取得するために使用されるオフセット。 negative_outlier_factorが &lt;code&gt;offset_&lt;/code&gt; より小さい観測値は異常として検出されます。 「auto」以外の汚染パラメータが指定されている場合を除いて、オフセットは-1.5（インライアスコアは約-1）に設定されます。その場合、オフセットは、トレーニングで予想される外れ値の数を取得するように定義されます。</target>
        </trans-unit>
        <trans-unit id="36fd88d1882973048dccc0ac8ca74e6c4f6b2ec1" translate="yes" xml:space="preserve">
          <source>Often features are not given as continuous values but categorical. For example a person could have features &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt;. Such features can be efficiently coded as integers, for instance &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; could be expressed as &lt;code&gt;[0, 1, 3]&lt;/code&gt; while &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; would be &lt;code&gt;[1, 2, 1]&lt;/code&gt;.</source>
          <target state="translated">多くの場合、特徴は連続的な値としてではなく、カテゴリ型として与えられます。たとえば、人は機能 &lt;code&gt;[&quot;male&quot;, &quot;female&quot;]&lt;/code&gt; 、 &lt;code&gt;[&quot;from Europe&quot;, &quot;from US&quot;, &quot;from Asia&quot;]&lt;/code&gt; 、 &lt;code&gt;[&quot;uses Firefox&quot;, &quot;uses Chrome&quot;, &quot;uses Safari&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; 。このような機能は整数として効率的にコーディングできます。たとえば、 &lt;code&gt;[&quot;male&quot;, &quot;from US&quot;, &quot;uses Internet Explorer&quot;]&lt;/code&gt; は &lt;code&gt;[0, 1, 3]&lt;/code&gt; ]と表現できますが、 &lt;code&gt;[&quot;female&quot;, &quot;from Asia&quot;, &quot;uses Chrome&quot;]&lt;/code&gt; は &lt;code&gt;[1, 2, 1]&lt;/code&gt; 1、2、1]になります。</target>
        </trans-unit>
        <trans-unit id="3d1f21e77b74fb7449c1f9b0570088bab1bd6c20" translate="yes" xml:space="preserve">
          <source>Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contributing in predicting the target response?</source>
          <target state="translated">多くの場合、特徴はターゲットの反応を予測するのに均等に寄与しないことがあります;多くの状況では、多くの特徴の大部分は実際には無関係です。モデルを解釈するとき、通常、最初の質問は次のようなものです:それらの重要な特徴は何であり、それらは目標応答を予測する際にどのように貢献しているのか?</target>
        </trans-unit>
        <trans-unit id="cd4e41585434180ead957592fb3bbf7ed399aaf1" translate="yes" xml:space="preserve">
          <source>Often it&amp;rsquo;s useful to add complexity to the model by considering nonlinear features of the input data. A simple and common method to use is polynomial features, which can get features&amp;rsquo; high-order and interaction terms. It is implemented in &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">多くの場合、入力データの非線形特徴を考慮することにより、モデルに複雑さを追加すると便利です。使用する簡単で一般的な方法は、多項式特徴です。これは、特徴の高次項と交互作用項を取得できます。&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; に&lt;/a&gt;実装されています。</target>
        </trans-unit>
        <trans-unit id="e408c9080a80cd5dee3de8b66c635dedc13aaef1" translate="yes" xml:space="preserve">
          <source>Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.</source>
          <target state="translated">機械学習の問題を解決するための最も困難な部分は、仕事のための正しい見積もりを見つけることであることがよくあります。</target>
        </trans-unit>
        <trans-unit id="7b3890ce47285c29340d329412b63023825aa83a" translate="yes" xml:space="preserve">
          <source>Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt;. For example, to build a transformer that applies a log transformation in a pipeline, do:</source>
          <target state="translated">多くの場合、既存のPython関数をトランスフォーマーに変換して、データのクリーンアップまたは処理を支援します。&lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; を使用&lt;/a&gt;すると、任意の関数からトランスフォーマーを実装できます。たとえば、パイプラインでログ変換を適用するトランスフォーマーを構築するには、次のようにします。</target>
        </trans-unit>
        <trans-unit id="3a99e53e60f11cdf73347e45ac4d6a8ace6059f3" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11</source>
          <target state="translated">OjalaとGarriga.分類器の性能を調べるための順列検定.機械学習研究誌 (2010)vol.11</target>
        </trans-unit>
        <trans-unit id="4a78f8007754f084c0abbe2f8fe08318ed671586" translate="yes" xml:space="preserve">
          <source>Ojala and Garriga. Permutation Tests for Studying Classifier Performance. The Journal of Machine Learning Research (2010) vol. 11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;.</source>
          <target state="translated">オジャラとガリーガ。分類器の性能を研究するための並べ替え検定。Journal of Machine Learning Research（2010）vol。11 &lt;a href=&quot;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&quot;&gt;[pdf]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d82f7d71018bfffc818f9af5a47b640ae31345cd" translate="yes" xml:space="preserve">
          <source>Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. 6, 2001 Pages 520-525.</source>
          <target state="translated">このように、このような研究では、DNA マイクロアレイの欠測値推定手法の開発が重要な課題となっています。</target>
        </trans-unit>
        <trans-unit id="f9aa2dba7b6fd084ffccc78f5a1359dabe654fd3" translate="yes" xml:space="preserve">
          <source>On &amp;ldquo;small&amp;rdquo; datasets (less than a few hundred points), the quantile transformer is prone to overfitting. The use of the power transform is then recommended.</source>
          <target state="translated">「小さな」データセット（数百ポイント未満）では、変位値変換器は過剰適合しがちです。その後、パワー変換の使用が推奨されます。</target>
        </trans-unit>
        <trans-unit id="d0f97ce49fc19f915019c9855a072a57bec1774a" translate="yes" xml:space="preserve">
          <source>On L2-normalized data, this function is equivalent to linear_kernel.</source>
          <target state="translated">L2正規化されたデータでは、この関数はlinear_kernelと同等です。</target>
        </trans-unit>
        <trans-unit id="d978bf78cd4e4a7f593a82a72e7f97f769b529af" translate="yes" xml:space="preserve">
          <source>On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</source>
          <target state="translated">スペクトルクラスタリングについて：分析とアルゴリズム、2001 Andrew Y. Ng、Michael I. Jordan、Yair Weiss &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c042431c0ae0ab161c8569f0669e312480d87b4b" translate="yes" xml:space="preserve">
          <source>On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640&amp;ndash;650., Wilks, D. S., 1990a</source>
          <target state="translated">連続する降水期間の予測確率の組み合わせについて。あぁ。予測、5、640〜650、ウィルクス、DS、1990a</target>
        </trans-unit>
        <trans-unit id="05fe02625303adf1ec7a757f80f079f0cfb615a5" translate="yes" xml:space="preserve">
          <source>On the contrary the classical finite mixture model with a Dirichlet distribution prior will favor more uniformly weighted components and therefore tends to divide natural clusters into unnecessary sub-components.</source>
          <target state="translated">逆に、ディリクレ分布の先行を持つ古典的な有限混合モデルは、より一様に重み付けされた成分を好むため、自然なクラスターを不必要な下位成分に分割する傾向があります。</target>
        </trans-unit>
        <trans-unit id="a881270be1f0c36e65b4d9407272c7539d9eb831" translate="yes" xml:space="preserve">
          <source>On the diabetes dataset, find the optimal regularization parameter alpha.</source>
          <target state="translated">糖尿病データセットについて,最適な正則化パラメータαを求めよ.</target>
        </trans-unit>
        <trans-unit id="d20d94e86b214eba2d2a083bdeb7805cae8a5dbd" translate="yes" xml:space="preserve">
          <source>On the digits dataset, plot the cross-validation score of a &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; estimator with an linear kernel as a function of parameter &lt;code&gt;C&lt;/code&gt; (use a logarithmic grid of points, from 1 to 10).</source>
          <target state="translated">数字データセットで、&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;推定器の交差検定スコアを線形カーネルでパラメーター &lt;code&gt;C&lt;/code&gt; の関数としてプロットします（1から10までの点の対数グリッドを使用）。</target>
        </trans-unit>
        <trans-unit id="70934046ec7198c15e5255a457f5b5f8aad47e7d" translate="yes" xml:space="preserve">
          <source>On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from &lt;code&gt;predict_proba&lt;/code&gt; are not to be taken too seriously.</source>
          <target state="translated">反対に、ナイーブベイズはまともな分類子として知られていますが、悪い推定子であることがわかっているため、 &lt;code&gt;predict_proba&lt;/code&gt; からの確率出力はあまり真剣に受け取られません。</target>
        </trans-unit>
        <trans-unit id="11ff999f3cb9557f779d2d870e0da3265a08df2a" translate="yes" xml:space="preserve">
          <source>On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the &lt;code&gt;weight_concentration_prior&lt;/code&gt;, parameter of the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.</source>
          <target state="translated">次の図では、ガウス混合では十分に表現されていないデータセットをフィッティングしています。&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; の&lt;/a&gt;パラメータである &lt;code&gt;weight_concentration_prior&lt;/code&gt; を調整すると、このデータの近似に使用されるコンポーネントの数が制御されます。最後の2つのプロットには、結果として得られた2つの混合物から生成されたランダムサンプリングも示します。</target>
        </trans-unit>
        <trans-unit id="e0986e74679be65bf8af00d65ae0c2feb9ddbaaf" translate="yes" xml:space="preserve">
          <source>On the graph of webpages and links those values are called the PageRank scores by Google.</source>
          <target state="translated">ウェブページとリンクのグラフ上で、これらの値をGoogleのPageRankスコアと呼びます。</target>
        </trans-unit>
        <trans-unit id="56dda47abffe67d113799c44a62fa9885afd300e" translate="yes" xml:space="preserve">
          <source>On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. On the right side we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples.</source>
          <target state="translated">左側には、数字のデータセットに対するナイーブ・ベイズ分類器の学習曲線が示されています。学習スコアと交差検証スコアの両方が、最後にはあまり良くないことに注意してください。しかし、この曲線の形状は、より複雑なデータセットではよく見られます:学習スコアは最初に非常に高く、その後減少し、交差検証スコアは最初に非常に低く、その後増加します。右側には、RBFカーネルを用いたSVMの学習曲線があります。学習スコアはまだ最大値付近にあり、検証スコアはより多くの学習サンプルで増加させることができることがわかります。</target>
        </trans-unit>
        <trans-unit id="8734edc10a3853b319869c6d2b6c4a8a8cc0d2c2" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training &lt;code&gt;n_classes&lt;/code&gt; models.</source>
          <target state="translated">一方、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;は、「one-vs-the-rest」マルチクラス戦略を &lt;code&gt;n_classes&lt;/code&gt; いるため、n_classesモデルをトレーニングします。</target>
        </trans-unit>
        <trans-unit id="f954522d1ed09b2ae8779aaabe3dfa6c3ae4de4e" translate="yes" xml:space="preserve">
          <source>On the other hand, &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; implements &amp;ldquo;one-vs-the-rest&amp;rdquo; multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:</source>
          <target state="translated">一方、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;は「one-vs-the-rest」マルチクラス戦略を実装し、n_classモデルをトレーニングします。クラスが2つしかない場合、トレーニングされるモデルは1つだけです。</target>
        </trans-unit>
        <trans-unit id="b6899866fd2175cc1abac032537947b3dc26ecc5" translate="yes" xml:space="preserve">
          <source>On the other hand, the weights obtained with regularization are more stable (see the &lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;Ridge regression and classification&lt;/a&gt; User Guide section). This increased stability is visible from the plot, obtained from data perturbations, in a cross validation. This plot can be compared with the &lt;a href=&quot;#covariation&quot;&gt;previous one&lt;/a&gt;.</source>
          <target state="translated">一方、正則化で得られた重みはより安定しています（&lt;a href=&quot;../../modules/linear_model#ridge-regression&quot;&gt;リッジ回帰と分類の&lt;/a&gt;ユーザーガイドのセクションを参照）。この安定性の向上は、交差検定でデータの摂動から得られたプロットからわかります。このプロットは、&lt;a href=&quot;#covariation&quot;&gt;前の&lt;/a&gt;プロットと比較できます。</target>
        </trans-unit>
        <trans-unit id="86b28d625cb14fb5485ff23b3eca337a06cecaf2" translate="yes" xml:space="preserve">
          <source>On the plots, train data is shown as dots, while test data is shown as crosses. The iris dataset is four-dimensional. Only the first two dimensions are shown here, and thus some points are separated in other dimensions.</source>
          <target state="translated">プロット上では、訓練データは点で、テストデータは十字で示されている。虹彩のデータセットは4次元である。ここでは最初の2次元のみを示しているため、いくつかの点は他の次元で区切られている。</target>
        </trans-unit>
        <trans-unit id="fc82fddedc10b52f931e2d57575d5196e2c6dd2d" translate="yes" xml:space="preserve">
          <source>On the twenty newsgroups on the other hand the dimensionality can be decreased from 56436 down to 10000 while reasonably preserving pairwise distances.</source>
          <target state="translated">一方、20のニュースグループでは、対の距離を合理的に維持しながら、次元数を56436から10000まで下げることができます。</target>
        </trans-unit>
        <trans-unit id="43f757b33d0dc72835f44fdaffe6492249fea14f" translate="yes" xml:space="preserve">
          <source>On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison.</source>
          <target state="translated">この例では、最初の2行は線形に分離できないデータセット(月と同心円)を表し、3行目はほぼ線形に分離できるデータセットを表しています。線形的に分離できない2つのデータセットでは、特徴量を離散化することで線形分類器の性能が大きく向上します。線形的に分離可能なデータセットでは、特徴量を離散化すると線形分類器の性能は低下する。比較のために、2つの非線形分類器を示します。</target>
        </trans-unit>
        <trans-unit id="3162e7b183de96ba6bf8f8587d34db62edc4b217" translate="yes" xml:space="preserve">
          <source>Once the optimization problem is solved, the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; for a given sample \(x\) becomes:</source>
          <target state="translated">最適化問題が解決されると、特定のサンプル\（x \）の&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;の出力は次のようになります。</target>
        </trans-unit>
        <trans-unit id="07aa293f8032a091371331fd78ad762690098968" translate="yes" xml:space="preserve">
          <source>Once trained, we can export the tree in &lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with</source>
          <target state="translated">トレーニングが完了すると、&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;エクスポーターを使用して、&lt;a href=&quot;http://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;形式でツリーをエクスポートできます。&lt;a href=&quot;http://conda.io&quot;&gt;conda&lt;/a&gt;パッケージマネージャを使用する場合、graphvizバイナリとpythonパッケージは次のようにインストールできます。</target>
        </trans-unit>
        <trans-unit id="ed70a2ff6fe86d781de8936cfd7e74b27161e201" translate="yes" xml:space="preserve">
          <source>Once trained, you can plot the tree with the &lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt;&lt;code&gt;plot_tree&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">トレーニングが完了したら、&lt;a href=&quot;generated/sklearn.tree.plot_tree#sklearn.tree.plot_tree&quot;&gt; &lt;code&gt;plot_tree&lt;/code&gt; &lt;/a&gt;関数を使用してツリーをプロットできます。</target>
        </trans-unit>
        <trans-unit id="28066560ad38f3f5dad45c5652f6a508803ee2c3" translate="yes" xml:space="preserve">
          <source>One can always drop the first column for each feature:</source>
          <target state="translated">1つは、各機能の最初のカラムを常にドロップすることができます。</target>
        </trans-unit>
        <trans-unit id="0471206705323c6d53e55b1c35697675c16b2c95" translate="yes" xml:space="preserve">
          <source>One can discard categories not seen during &lt;code&gt;fit&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; 中に見られないカテゴリーを破棄することができます：</target>
        </trans-unit>
        <trans-unit id="e1a30cbb2660486e3a34f97fc6f2ebc285138723" translate="yes" xml:space="preserve">
          <source>One can observe here that logistic regression is well calibrated as its curve is nearly diagonal. Linear SVC&amp;rsquo;s calibration curve or reliability diagram has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors). Both kinds of calibration can fix this issue and yield nearly identical results. The next figure shows the calibration curve of Gaussian naive Bayes on the same data, with both kinds of calibration and also without calibration.</source>
          <target state="translated">曲線がほぼ対角線であるため、ロジスティック回帰が適切に調整されていることがわかります。線形SVCの検量線または信頼性図には、シグモイド曲線があり、これは信頼性の低い分類器で一般的です。 LinearSVCの場合、これはヒンジ損失のマージンプロパティが原因で発生します。これにより、モデルは決定境界（サポートベクトル）に近いハードサンプルに焦点を合わせることができます。どちらの種類のキャリブレーションでもこの問題を修正でき、ほぼ同じ結果が得られます。次の図は、両方の種類のキャリブレーションとキャリブレーションなしの、同じデータに対するガウスナイーブベイズの検量線を示しています。</target>
        </trans-unit>
        <trans-unit id="cce2911ccedb3667eaee804d61905917155ff5c2" translate="yes" xml:space="preserve">
          <source>One can observe that with homoscedastic noise both FA and PCA succeed in recovering the size of the low rank subspace. The likelihood with PCA is higher than FA in this case. However PCA fails and overestimates the rank when heteroscedastic noise is present. Under appropriate circumstances the low rank models are more likely than shrinkage models.</source>
          <target state="translated">同種ノイズでは、FAとPCAの両方が低ランク部分空間のサイズを回復することに成功していることがわかります。この場合、PCAの尤度はFAよりも高い。しかし、異種混合ノイズが存在する場合、PCAは失敗し、ランクを過大評価します。適切な状況下では,低ランクモデルは収縮モデルよりも可能性が高い.</target>
        </trans-unit>
        <trans-unit id="5282642c4183bcd75159c8592f0d08e21bceb6b2" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:</source>
          <target state="translated">予測されたラベルの0と1をパーミュレートし、2を3に変更し、同じスコアを得ることができます。</target>
        </trans-unit>
        <trans-unit id="f2e197fb258bad312502ac44a4234fe5a6877692" translate="yes" xml:space="preserve">
          <source>One can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:</source>
          <target state="translated">予測されたラベルの0と1をミュートし、2の名前を3に変更し、同じスコアを得ることができます。</target>
        </trans-unit>
        <trans-unit id="e33d3feeafd2b2e6157812f722f3e7fb8358ba7c" translate="yes" xml:space="preserve">
          <source>One can see that Gaussian naive Bayes performs very badly but does so in an other way than linear SVC: While linear SVC exhibited a sigmoid calibration curve, Gaussian naive Bayes&amp;rsquo; calibration curve has a transposed-sigmoid shape. This is typical for an over-confident classifier. In this case, the classifier&amp;rsquo;s overconfidence is caused by the redundant features which violate the naive Bayes assumption of feature-independence.</source>
          <target state="translated">ガウスナイーブベイズのパフォーマンスは非常に悪いが、線形SVCとは異なる方法で実行することがわかります。線形SVCはシグモイドキャリブレーション曲線を示しましたが、ガウスナイーブベイズのキャリブレーション曲線は転置シグモイド形状をしています。これは、自信過剰の分類器では一般的です。この場合、分類器の自信過剰は、機能に依存しないという単純なベイズの仮定に違反する冗長な機能によって引き起こされます。</target>
        </trans-unit>
        <trans-unit id="15c1fc9ad0e4ecc150e99497720122e04673bd38" translate="yes" xml:space="preserve">
          <source>One can see that NCA enforces a clustering of the data that is visually meaningful despite the large reduction in dimension.</source>
          <target state="translated">NCAは、次元が大きく減少しているにもかかわらず、視覚的に意味のあるデータのクラスタリングを強制していることがわかります。</target>
        </trans-unit>
        <trans-unit id="82900035fe0f11887cd04ee23edd3ee0d6e6bf18" translate="yes" xml:space="preserve">
          <source>One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.</source>
          <target state="translated">機械学習における一般的なパターンの1つは、データの非線形関数で訓練された線形モデルを使用することです。このアプローチは、線形手法の一般的に高速な性能を維持しつつ、より広範囲のデータに適合させることを可能にしています。</target>
        </trans-unit>
        <trans-unit id="fa0690f9f0e7bd840855247cda57999b3e6dd175" translate="yes" xml:space="preserve">
          <source>One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the &amp;ldquo;shape&amp;rdquo; of the data, and can define outlying observations as observations which stand far enough from the fit shape.</source>
          <target state="translated">外れ値の検出を実行する一般的な方法の1つは、通常のデータが既知の分布に由来すると想定することです（たとえば、データはガウス分布である）。この仮定から、一般にデータの「形状」を定義しようとしますが、範囲外の観測を、適合形状から十分に離れた観測として定義できます。</target>
        </trans-unit>
        <trans-unit id="9d03fc67e51edb11ba912aa95289c786040f1c20" translate="yes" xml:space="preserve">
          <source>One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.</source>
          <target state="translated">カーネル法の欠点としては,最適化の際に多くのカーネル値を記憶しておく必要があることがある.カーネル化された分類器を新しいデータに適用した場合には,予測を行うためには,学習データの中の多くの異なる \(x_i,y_j)を計算しなければならない可能性がある.</target>
        </trans-unit>
        <trans-unit id="cdf9b1d4485b82e7ed1999a3fb7fb5adb4dbca12" translate="yes" xml:space="preserve">
          <source>One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; &amp;lsquo;isolates&amp;rsquo; observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</source>
          <target state="translated">高次元のデータセットで外れ値を検出する効率的な方法の1つは、ランダムフォレストを使用することです。&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;ランダム機能を選択し、ランダムに選択されたフィーチャの最大値と最小値との間の分割値を選択することにより、「単離物」の観測。</target>
        </trans-unit>
        <trans-unit id="b5c13007d70aa1a0e4a2816404f0d61b9e0ac135" translate="yes" xml:space="preserve">
          <source>One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape &lt;code&gt;[n_samples, n_features]&lt;/code&gt;. These can be obtained from the classes in the &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module. For &lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt;&lt;code&gt;AffinityPropagation&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt;&lt;code&gt;SpectralClustering&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; one can also input similarity matrices of shape &lt;code&gt;[n_samples, n_samples]&lt;/code&gt;. These can be obtained from the functions in the &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; module.</source>
          <target state="translated">注意すべき重要な点の1つは、このモジュールに実装されているアルゴリズムは、入力としてさまざまな種類の行列を取ることができるということです。すべてのメソッドは、形状 &lt;code&gt;[n_samples, n_features]&lt;/code&gt; 標準データ行列を受け入れます。これらは、&lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; &lt;/a&gt;モジュールのクラスから取得できます。用&lt;a href=&quot;generated/sklearn.cluster.affinitypropagation#sklearn.cluster.AffinityPropagation&quot;&gt; &lt;code&gt;AffinityPropagation&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.cluster.spectralclustering#sklearn.cluster.SpectralClustering&quot;&gt; &lt;code&gt;SpectralClustering&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt;一つは缶形状の、入力類似性行列 &lt;code&gt;[n_samples, n_samples]&lt;/code&gt; 。これらは、&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; &lt;/a&gt;モジュールの関数から取得できます。</target>
        </trans-unit>
        <trans-unit id="deab058e87e7d8cac343ed7483a7cf721eca4119" translate="yes" xml:space="preserve">
          <source>One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of &lt;em&gt;modified locally linear embedding&lt;/em&gt; (MLLE). MLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'modified'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt;.</source>
          <target state="translated">正則化問題に対処する1つの方法は、各近傍で複数の重みベクトルを使用することです。これは、&lt;em&gt;修正されたローカル線形埋め込み&lt;/em&gt;（MLLE）の本質です。 MLLEは、ローカルに関数&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;またはオブジェクト指向の対応する&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;を使用して、キーワード &lt;code&gt;method = 'modified'&lt;/code&gt; ます。 &lt;code&gt;n_neighbors &amp;gt; n_components&lt;/code&gt; が必要です。</target>
        </trans-unit>
        <trans-unit id="8b0abef56ded5ecf131b35733971a4004aa542f0" translate="yes" xml:space="preserve">
          <source>One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.</source>
          <target state="translated">別の方法として、文字のn-gramのコレクション、スペルミスや派生に強い表現を考えることもできます。</target>
        </trans-unit>
        <trans-unit id="9787d541696df0f6a8e4fd9ada866862db9e0d0c" translate="yes" xml:space="preserve">
          <source>One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the parameter &lt;code&gt;drop='if_binary'&lt;/code&gt;.</source>
          <target state="translated">2つのカテゴリを持つ機能についてのみ、2つの列の1つを削除することをお勧めします。この場合、パラメータ &lt;code&gt;drop='if_binary'&lt;/code&gt; を設定できます。</target>
        </trans-unit>
        <trans-unit id="61c492958dc81c1a6d9f632bafd3909d2bb143b8" translate="yes" xml:space="preserve">
          <source>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</source>
          <target state="translated">ここで直面する課題の1つは、ソルバーが条件付きの推定値に収束できないことです。アルファの対応する値は欠損値として出てきますが、最適値はこの欠損値に近いかもしれません。</target>
        </trans-unit>
        <trans-unit id="70a04d887115ca6d6700f00cd1afa9bf1cffed38" translate="yes" xml:space="preserve">
          <source>One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object &lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt;&lt;code&gt;Isomap&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">多様性学習への最も初期のアプローチの1つは、アイソマップマッピングの略であるIsomapアルゴリズムです。Isomapは、多次元スケーリング（MDS）またはカーネルPCAの拡張機能と見なすことができます。Isomapは、すべてのポイント間の測地線距離を維持する低次元の埋め込みを求めます。Isomapは、オブジェクト&lt;a href=&quot;generated/sklearn.manifold.isomap#sklearn.manifold.Isomap&quot;&gt; &lt;code&gt;Isomap&lt;/code&gt; を使用&lt;/a&gt;して実行できます。</target>
        </trans-unit>
        <trans-unit id="8d30b63915c687687af955c31a96ac094f06cb9f" translate="yes" xml:space="preserve">
          <source>One of the most straight-forward concerns one may have when using/choosing a machine learning toolkit is the latency at which predictions can be made in a production environment.</source>
          <target state="translated">機械学習ツールキットを使用/選択する際に最も簡単な懸念事項の1つは、本番環境での予測が可能な待ち時間です。</target>
        </trans-unit>
        <trans-unit id="e3967d3ba22f4ac7f4c1ab09bac9634bd847ca9c" translate="yes" xml:space="preserve">
          <source>One of:</source>
          <target state="translated">の一つです。</target>
        </trans-unit>
        <trans-unit id="d25b0126083dd51df31e94af07b51bd893fc80ee" translate="yes" xml:space="preserve">
          <source>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</source>
          <target state="translated">カーネル密度推定のもう一つの有用なアプリケーションは、この生成モデルから新しいサンプルを効率的に引くために、データセットのノンパラメトリック生成モデルを学習することです。このプロセスを用いて、データのPCA投影で学習したガウスカーネルを用いて、手書きの数字の新しいセットを作成した例を示します。</target>
        </trans-unit>
        <trans-unit id="fee8a97f6bc38e5962a611f176ea8084294905c7" translate="yes" xml:space="preserve">
          <source>One possible difference with the &lt;code&gt;glasso&lt;/code&gt; R package is that the diagonal coefficients are not penalized.</source>
          <target state="translated">&lt;code&gt;glasso&lt;/code&gt; Rパッケージとの考えられる違いの1つは、対角係数にペナルティが課されないことです。</target>
        </trans-unit>
        <trans-unit id="a927f9db65135d8f0443d271707e3494a0dc3ae7" translate="yes" xml:space="preserve">
          <source>One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. &lt;code&gt;impute.SimpleImputer&lt;/code&gt;). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. &lt;code&gt;impute.IterativeImputer&lt;/code&gt;).</source>
          <target state="translated">代入アルゴリズムの1つのタイプは単変量であり、i番目の特徴次元の値を、その特徴次元の欠落していない値のみを使用して代入します（例： &lt;code&gt;impute.SimpleImputer&lt;/code&gt; ）。対照的に、多変量代入アルゴリズムは、利用可能な特徴次元のセット全体を使用して、欠落している値を推定します（例： &lt;code&gt;impute.IterativeImputer&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="ea6c78b875e9abbb9afb65361c14c4ab4fe517e5" translate="yes" xml:space="preserve">
          <source>One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the &lt;code&gt;beta&lt;/code&gt; parameter for the &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">1つの典型的な使用例は、&lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt;関数の &lt;code&gt;beta&lt;/code&gt; パラメーターなど、パラメーターの非デフォルト値でライブラリーから既存のメトリック関数をラップすることです。</target>
        </trans-unit>
        <trans-unit id="d21d62671a1a16508e611633019b29f0b4ceb760" translate="yes" xml:space="preserve">
          <source>One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using &lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;mode='distance'&lt;/code&gt;, then using &lt;code&gt;metric='precomputed'&lt;/code&gt; here.</source>
          <target state="translated">クエリの複雑さを回避する1つの方法は、 &lt;code&gt;mode='distance'&lt;/code&gt; で&lt;a href=&quot;sklearn.neighbors.nearestneighbors#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;NearestNeighbors.radius_neighbors_graph&lt;/code&gt; &lt;/a&gt;を使用し、次に &lt;code&gt;metric='precomputed'&lt;/code&gt; precomputed 'を使用してチャンク内の疎な近傍を事前計算することです。</target>
        </trans-unit>
        <trans-unit id="cfb9ef5c0f82cd02b0fe2a37197cc7c17a10edff" translate="yes" xml:space="preserve">
          <source>One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example: &lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;Permutation Importance with Multicollinear or Correlated Features&lt;/a&gt;.</source>
          <target state="translated">これを処理する1つの方法は、相関している機能をクラスター化し、各クラスターから1つの機能のみを保持することです。この戦略は、次の例で検討されています。&lt;a href=&quot;../auto_examples/inspection/plot_permutation_importance_multicollinear#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py&quot;&gt;多重共線性または相関特徴を使用した順列の重要性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b4307d41eb1bb94d21cc13cd8d41c0af8c2af52b" translate="yes" xml:space="preserve">
          <source>One way to plot the curves is to place them in the same figure, with the curves of each model on each row. First, we create a figure with two axes within two rows and one column. The two axes are passed to the &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; functions of &lt;code&gt;tree_disp&lt;/code&gt; and &lt;code&gt;mlp_disp&lt;/code&gt;. The given axes will be used by the plotting function to draw the partial dependence. The resulting plot places the decision tree partial dependence curves in the first row of the multi-layer perceptron in the second row.</source>
          <target state="translated">曲線をプロットする1つの方法は、各モデルの曲線を各行に配置して、それらを同じ図に配置することです。まず、2行1列に2軸の図形を作成します。2つの軸は、 &lt;code&gt;tree_disp&lt;/code&gt; と &lt;code&gt;mlp_disp&lt;/code&gt; の&lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay.plot&quot;&gt; &lt;code&gt;plot&lt;/code&gt; &lt;/a&gt;関数に渡されます。指定された軸は、部分的な依存関係を描画するためにプロット関数によって使用されます。結果のプロットは、2行目の多層パーセプトロンの最初の行に決定木部分依存曲線を配置します。</target>
        </trans-unit>
        <trans-unit id="7904a0df31dead1d3d1a1bdda9b6baa78b3e3ac4" translate="yes" xml:space="preserve">
          <source>One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r &amp;gt; 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.</source>
          <target state="translated">LLEのよく知られた問題の1つは、正則化の問題です。近傍の数が入力次元の数より大きい場合、各局所近傍を定義する行列はランクが不足しています。これに対処するために、標準のLLEは、任意の正則化パラメーター\（r \）を適用します。これは、ローカルの重み行列のトレースに関連して選択されます。正式には\（r \ to 0 \）として解を求めることができますが、解は目的の埋め込みに収束しますが、\（r&amp;gt; 0 \）に対して最適解が見つかる保証はありません。この問題は、多様体の基本的なジオメトリを歪める埋め込みに現れます。</target>
        </trans-unit>
        <trans-unit id="4a89ac2f620199dd99f97fe1ad98300bc4f72269" translate="yes" xml:space="preserve">
          <source>One-class SVM with non-linear kernel (RBF)</source>
          <target state="translated">非線形カーネル(RBF)を用いた1クラスSVM</target>
        </trans-unit>
        <trans-unit id="a699b63cc6020c9e087bddfc75a6724c5b45ee5c" translate="yes" xml:space="preserve">
          <source>One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models.</source>
          <target state="translated">ワンホット・コード化された離散化された特徴は、解釈可能性を維持しながら、モデルをより表現力のあるものにすることができます。例えば、離散化器を用いた前処理は、線形モデルに非線形性を導入することができます。</target>
        </trans-unit>
        <trans-unit id="b4a3aede9df40da523f973c7487f254218f78511" translate="yes" xml:space="preserve">
          <source>One-vs-one multiclass strategy</source>
          <target state="translated">1対1のマルチクラス戦略</target>
        </trans-unit>
        <trans-unit id="ee528cbd4b4f2e2829af351b64b6eb8bfd42a4f6" translate="yes" xml:space="preserve">
          <source>One-vs-the-rest (OvR) multiclass/multilabel strategy</source>
          <target state="translated">ワンバイザレスト(OvR)マルチクラス/マルチラベル戦略</target>
        </trans-unit>
        <trans-unit id="64ecee535f4fdc8be570462551ed8105268af715" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above Figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them.</source>
          <target state="translated">一方向PDPは、対象反応と対象特徴との間の相互作用(例えば、線形、非線形)について教えてくれます。上の図の左上のプロットは、ある地区の所得の中央値が住宅価格の中央値に与える影響を示していますが、両者の間には明らかに線形の関係が見られます。</target>
        </trans-unit>
        <trans-unit id="0d4f461fa5ad14a45b8d87efade862b196a923a9" translate="yes" xml:space="preserve">
          <source>One-way PDPs tell us about the interaction between the target response and the target feature (e.g. linear, non-linear). The upper left plot in the above figure shows the effect of the median income in a district on the median house price; we can clearly see a linear relationship among them. Note that PDPs assume that the target features are independent from the complement features, and this assumption is often violated in practice.</source>
          <target state="translated">一方向PDPは、対象反応と対象特徴との間の相互作用(例えば、線形、非線形)を教えてくれます。上図の左上のプロットは、ある地域の所得の中央値が住宅価格の中央値に与える影響を示しており、これらの間には明らかに線形の関係が見て取れます。なお、PDPでは、目標特徴と補完特徴が独立していることを前提としており、実際にはこの前提に反していることが多いことに注意が必要である。</target>
        </trans-unit>
        <trans-unit id="624143e59cce6d91c0d6bbc328865a41ed589524" translate="yes" xml:space="preserve">
          <source>OneHotEncoder</source>
          <target state="translated">OneHotEncoder</target>
        </trans-unit>
        <trans-unit id="aae2ee6c9851c7a4ce4cd6cfb817bfde607325bf" translate="yes" xml:space="preserve">
          <source>Online Passive-Aggressive Algorithms &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt;&amp;gt; K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)</source>
          <target state="translated">オンラインパッシブアグレッシブアルゴリズム&amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&lt;/a&gt; &amp;gt; K.クランマー、O。デケル、J。ケシャット、S。シャレフシュワルツ、Y。シンガー- JMLR（2006）</target>
        </trans-unit>
        <trans-unit id="59363dcf6a532d4c72655a5346d2c500295612f8" translate="yes" xml:space="preserve">
          <source>Online VB with Mini-Batch update.</source>
          <target state="translated">オンラインVBでミニバッチ更新。</target>
        </trans-unit>
        <trans-unit id="829e73254cb47c834763ade46578341830688d18" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling.</source>
          <target state="translated">後でスケーリングするためのXの最大絶対値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="1dffcf7d5a055d764cfb2adb13901c054d8691b3" translate="yes" xml:space="preserve">
          <source>Online computation of max absolute value of X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXの最大絶対値のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="5b59fd4b2594ce8e5c7bbe150a07e7588723c96b" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling.</source>
          <target state="translated">後のスケーリングのためにXの平均値と標準値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="98a787216e7563ac11e03cf3274711f17911c2c2" translate="yes" xml:space="preserve">
          <source>Online computation of mean and std on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXでの平均と標準のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="3a0a40bed8a368eb74567adc0b902d5438bbb233" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling.</source>
          <target state="translated">後のスケーリングのためにXの最小値と最大値をオンラインで計算します。</target>
        </trans-unit>
        <trans-unit id="245a52e0e0da8fa60b8bd0ab73c4b352a71c8d4a" translate="yes" xml:space="preserve">
          <source>Online computation of min and max on X for later scaling. All of X is processed as a single batch. This is intended for cases when &lt;code&gt;fit&lt;/code&gt; is not feasible due to very large number of &lt;code&gt;n_samples&lt;/code&gt; or because X is read from a continuous stream.</source>
          <target state="translated">後でスケーリングするためのXでの最小値と最大値のオンライン計算。Xはすべて1つのバッチとして処理されます。これは、 &lt;code&gt;n_samples&lt;/code&gt; の数が非常に多いため、またはXが連続ストリームから読み取られるために、 &lt;code&gt;fit&lt;/code&gt; が実現できない場合を対象としています。</target>
        </trans-unit>
        <trans-unit id="3bdeb493aeece54b83eea920715d4b7167b710bb" translate="yes" xml:space="preserve">
          <source>Online learning of a dictionary of parts of faces</source>
          <target state="translated">顔のパーツ辞書のオンライン学習</target>
        </trans-unit>
        <trans-unit id="afbac89ba6ac8bba06d8e8f00f8db1d633c505b3" translate="yes" xml:space="preserve">
          <source>Online learning.</source>
          <target state="translated">オンライン学習。</target>
        </trans-unit>
        <trans-unit id="e15bae968fe9434653919edecb56e181cf3bdca0" translate="yes" xml:space="preserve">
          <source>Online learning. Prevents rebuilding of CFTree from scratch.</source>
          <target state="translated">オンライン学習。CFTreeの一からの再構築を防ぎます。</target>
        </trans-unit>
        <trans-unit id="fba366205dda8a9f9c620fa8147677029ec02688" translate="yes" xml:space="preserve">
          <source>Only active when backend=&amp;rdquo;loky&amp;rdquo; or &amp;ldquo;multiprocessing&amp;rdquo;.</source>
          <target state="translated">backend =&amp;rdquo; loky&amp;rdquo;または&amp;ldquo; multiprocessing&amp;rdquo;の場合のみアクティブです。</target>
        </trans-unit>
        <trans-unit id="302203b3b2bd4b6979838ea661e3dedb562a6303" translate="yes" xml:space="preserve">
          <source>Only adjusted measures can hence safely be used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.</source>
          <target state="translated">したがって、調整された測定値のみが、データセットの様々なオーバーラップしたサブサンプルにおいて、与えられた値kに対するクラスタリングアルゴリズムの平均安定性を評価するためのコンセンサス指標として安全に使用することができます。</target>
        </trans-unit>
        <trans-unit id="b41ade38f91e30c61b5c1030ad80447ac59509af" translate="yes" xml:space="preserve">
          <source>Only applies to sparse matrices. If True, the sparse entries of the matrix are discarded to compute the quantile statistics. If False, these entries are treated as zeros.</source>
          <target state="translated">疎な行列にのみ適用されます.True の場合,行列の疎なエントリは,分位統計量を計算するために破棄されます.False の場合,これらのエントリはゼロとして扱われます.</target>
        </trans-unit>
        <trans-unit id="6239790ca1ea503b946542f5fd11362f9a8d181e" translate="yes" xml:space="preserve">
          <source>Only available for novelty detection (when novelty is set to True). The argument X is supposed to contain &lt;em&gt;new data&lt;/em&gt;: if X contains a point from training, it considers the later in its own neighborhood. Also, the samples in X are not considered in the neighborhood of any point. The score_samples on training data is available by considering the the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">新規性検出にのみ使用できます（新規性がTrueに設定されている場合）。引数Xには&lt;em&gt;新しいデータ&lt;/em&gt;が含まれることになっています。Xにトレーニングからのポイントが含まれている場合、Xは自身の近傍の後者を考慮します。また、Xのサンプルは、どの点の近傍でも考慮されません。トレーニングデータのscore_samplesは、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を考慮することで利用できます。</target>
        </trans-unit>
        <trans-unit id="42065a31e81b2581624e9d29e5e9b175fb835b62" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;decision_function&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; で、基礎となる推定器が &lt;code&gt;decision_function&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="b5f87bbc5994209afe765ecb3d4b6e3e28348b8b" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">場合にのみ利用可能 &lt;code&gt;refit=True&lt;/code&gt; 基礎となる推定サポートを &lt;code&gt;predict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d2e232f30b7c8c685e1c17116e7dcb136df3f8ad" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_log_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; で、基になる推定器が &lt;code&gt;predict_log_proba&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="590883a61b4915ecfb6720c62deaa2c81b9eda84" translate="yes" xml:space="preserve">
          <source>Only available if &lt;code&gt;refit=True&lt;/code&gt; and the underlying estimator supports &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;refit=True&lt;/code&gt; で、基になる推定器が &lt;code&gt;predict_proba&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="3fd90433c474723d07589bf28196170034c8822e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator implements &lt;code&gt;inverse_transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">基礎となる推定器が &lt;code&gt;inverse_transform&lt;/code&gt; と &lt;code&gt;refit=True&lt;/code&gt; を実装している場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="5b6ee95bb2d64ff7d78caebfb3e0ee07b947d80e" translate="yes" xml:space="preserve">
          <source>Only available if the underlying estimator supports &lt;code&gt;transform&lt;/code&gt; and &lt;code&gt;refit=True&lt;/code&gt;.</source>
          <target state="translated">基になる推定器が &lt;code&gt;transform&lt;/code&gt; および &lt;code&gt;refit=True&lt;/code&gt; をサポートしている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="551c945d5055fc75c52f88f345bac01b44b1a207" translate="yes" xml:space="preserve">
          <source>Only consider the highest k scores in the ranking. If None, use all outputs.</source>
          <target state="translated">ランキングの中で最も高い k 点のみを考慮します。Noneの場合は、すべての出力を使用します。</target>
        </trans-unit>
        <trans-unit id="91571ddad0f13d4b107795b8172bb8b9e0e57731" translate="yes" xml:space="preserve">
          <source>Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.</source>
          <target state="translated">類似度スコア(類似度に応じて増加する非負の値)を生成するカーネルのみを使用する必要があります。このプロパティはクラスタリングアルゴリズムによってチェックされません。</target>
        </trans-unit>
        <trans-unit id="78ed917f99bf2dac895a03ac7d7777a9a2c30e89" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;as_frame=True&lt;/code&gt;. DataFrame with &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;as_frame=True&lt;/code&gt; の場合にのみ存在します。 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; を含むDataFrame 。</target>
        </trans-unit>
        <trans-unit id="0fcc91c5ac8dfa2c9d74fba74f9744bbfabacd86" translate="yes" xml:space="preserve">
          <source>Only present when &lt;code&gt;load_content=True&lt;/code&gt;. The raw text data to learn.</source>
          <target state="translated">&lt;code&gt;load_content=True&lt;/code&gt; の場合にのみ存在します。学習する生のテキストデータ。</target>
        </trans-unit>
        <trans-unit id="91f57910319c7032022a687ad833db0e0811e172" translate="yes" xml:space="preserve">
          <source>Only report results for the class specified by &lt;code&gt;pos_label&lt;/code&gt;. This is applicable only if targets (&lt;code&gt;y_{true,pred}&lt;/code&gt;) are binary.</source>
          <target state="translated">&lt;code&gt;pos_label&lt;/code&gt; で指定されたクラスの結果のみを報告します。これは、ターゲット（ &lt;code&gt;y_{true,pred}&lt;/code&gt; ）がバイナリの場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="aa7683d2cc754187a7839c7481d51d4e421e244f" translate="yes" xml:space="preserve">
          <source>Only returned if return_distance is set to True (for compatibility). The distances between the centers of the nodes. &lt;code&gt;distances[i]&lt;/code&gt; corresponds to a weighted euclidean distance between the nodes &lt;code&gt;children[i, 1]&lt;/code&gt; and &lt;code&gt;children[i, 2]&lt;/code&gt;. If the nodes refer to leaves of the tree, then &lt;code&gt;distances[i]&lt;/code&gt; is their unweighted euclidean distance. Distances are updated in the following way (from scipy.hierarchy.linkage):</source>
          <target state="translated">return_distanceがTrueに設定されている場合にのみ返されます（互換性のため）。ノードの中心間の距離。 &lt;code&gt;distances[i]&lt;/code&gt; は、ノード &lt;code&gt;children[i, 1]&lt;/code&gt; と &lt;code&gt;children[i, 2]&lt;/code&gt; 間の重み付きユークリッド距離に対応します。ノードがツリーの葉を参照する場合、 &lt;code&gt;distances[i]&lt;/code&gt; は重み付けされていないユークリッド距離です。距離は次の方法で更新されます（scipy.hierarchy.linkageから）：</target>
        </trans-unit>
        <trans-unit id="76cbc59243676edd420339801c25adc86e4aefb2" translate="yes" xml:space="preserve">
          <source>Only set if whiten is &amp;lsquo;True&amp;rsquo;. This is the pre-whitening matrix that projects data onto the first &lt;code&gt;n_components&lt;/code&gt; principal components.</source>
          <target state="translated">whitenが「True」の場合にのみ設定されます。これは、データを最初の &lt;code&gt;n_components&lt;/code&gt; 主成分に投影する事前ホワイトニングマトリックスです。</target>
        </trans-unit>
        <trans-unit id="b2ff6162a14531590c3fe05f5c4da22c170a731e" translate="yes" xml:space="preserve">
          <source>Only the first 4 features are informative. The remaining features are useless.</source>
          <target state="translated">最初の4つの機能だけが参考になります。残りの機能は役に立たない。</target>
        </trans-unit>
        <trans-unit id="9ccbc07fdd81d8170c7e3632973044099dfe4b4c" translate="yes" xml:space="preserve">
          <source>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with &amp;ldquo;&amp;hellip;&amp;rdquo;.</source>
          <target state="translated">ツリーの最初のmax_depthレベルのみがエクスポートされます。切り捨てられたブランチには「&amp;hellip;」のマークが付けられます。</target>
        </trans-unit>
        <trans-unit id="ccdb28c17d5d885e725cff4c70b04cf05f415c05" translate="yes" xml:space="preserve">
          <source>Only used if method=&amp;rsquo;barnes_hut&amp;rsquo; This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. &amp;lsquo;angle&amp;rsquo; is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below &amp;lsquo;angle&amp;rsquo; then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.</source>
          <target state="translated">method = 'barnes_hut'の場合にのみ使用されます。これは、Barnes-Hut T-SNEの速度と精度のトレードオフです。'angle'は、ポイントから測定した遠方ノードの角度サイズ（[3]ではシータと呼ばれます）です。このサイズが「角度」未満の場合、その中に含まれるすべてのポイントのサマリーノードとして使用されます。この方法は、このパラメーターの0.2〜0.8の範囲の変化にあまり敏感ではありません。角度が0.2未満の場合、計算時間が急速に増加し、角度が0.8より大きい場合、エラーが急速に増加します。</target>
        </trans-unit>
        <trans-unit id="feeded53201cd1098b357f2543d3cc3ddaf2bc59" translate="yes" xml:space="preserve">
          <source>Only used in edge case with a single class in the training set.</source>
          <target state="translated">学習セットに単一のクラスがある場合のエッジケースでのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="e51e92f95034c804fc0810fdbc5d315daca2beb0" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;solver='sgd'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;solver='sgd'&lt;/code&gt; の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="593a45b59b3c39f850f6d06cebef909401c1e524" translate="yes" xml:space="preserve">
          <source>Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;. Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;svd_method&lt;/code&gt; が「randomized」と等しい場合にのみ使用されます。複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="da0ee672f8455720f39dadc83f429b90e16b4655" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of function calls. Note that number of function calls will be greater than or equal to the number of iterations for the MLPRegressor.</source>
          <target state="translated">ソルバー= 'lbfgs'の場合​​にのみ使用されます。関数呼び出しの最大数。ソルバーは、収束（ 'tol'で決定）、反復回数がmax_iterに達するまで、またはこの関数呼び出しの数まで反復します。関数呼び出しの数は、MLPRegressorの反復回数以上になることに注意してください。</target>
        </trans-unit>
        <trans-unit id="f33d0ac38f880719381151e0f77c153552e9c099" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;lbfgs&amp;rsquo;. Maximum number of loss function calls. The solver iterates until convergence (determined by &amp;lsquo;tol&amp;rsquo;), number of iterations reaches max_iter, or this number of loss function calls. Note that number of loss function calls will be greater than or equal to the number of iterations for the &lt;code&gt;MLPClassifier&lt;/code&gt;.</source>
          <target state="translated">ソルバー= 'lbfgs'の場合​​にのみ使用されます。損失関数呼び出しの最大数。ソルバーは、収束（ 'tol'で決定）、反復回数がmax_iterに達するまで、またはこの損失関数呼び出しの数まで反復します。損失関数呼び出しの数は、 &lt;code&gt;MLPClassifier&lt;/code&gt; の反復数以上になることに注意してください。</target>
        </trans-unit>
        <trans-unit id="3466b805d384e470c3d1ee2beb1b9b317ac5cc22" translate="yes" xml:space="preserve">
          <source>Only used when solver=&amp;rsquo;sgd&amp;rsquo;.</source>
          <target state="translated">solver = 'sgd'の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="04fb050fa307025a8b877f9d2c83069449f7ca94" translate="yes" xml:space="preserve">
          <source>Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">&lt;code&gt;rows_&lt;/code&gt; および &lt;code&gt;columns_&lt;/code&gt; 属性が存在する場合にのみ機能します。</target>
        </trans-unit>
        <trans-unit id="516478ad62f05e00111ddd57ddd26de9d50efa29" translate="yes" xml:space="preserve">
          <source>Open problem: Stock Market Structure</source>
          <target state="translated">公開問題:株式市場の構造</target>
        </trans-unit>
        <trans-unit id="988a0621a69f95c126d429edd6ad72b8b9753d30" translate="yes" xml:space="preserve">
          <source>OpenBLAS</source>
          <target state="translated">OpenBLAS</target>
        </trans-unit>
        <trans-unit id="01e06dfe8463084e545b7490a5b6cab212cacc1b" translate="yes" xml:space="preserve">
          <source>OpenML ID of the dataset. The most specific way of retrieving a dataset. If data_id is not given, name (and potential version) are used to obtain a dataset.</source>
          <target state="translated">データセットのOpenML ID。データセットを取得するための最も具体的な方法。data_idが与えられていない場合は、データセットを取得するために名前(および潜在的なバージョン)が用いられる。</target>
        </trans-unit>
        <trans-unit id="b73a248fb134eb9cb2d0288db81a01291423c17b" translate="yes" xml:space="preserve">
          <source>OpenMP is used to parallelize code written in Cython or C, relying on multi-threading exclusively. By default (and unless joblib is trying to avoid oversubscription), the implementation will use as many threads as possible.</source>
          <target state="translated">OpenMP は Cython や C で書かれたコードを並列化するために使用され、マルチスレッドのみに依存します。デフォルトでは (joblib がオーバーサブスクリプションを避けようとしていない限り)、実装は可能な限り多くのスレッドを使用します。</target>
        </trans-unit>
        <trans-unit id="3c0cb6e8849966972823d3a411e3fa85cccc3662" translate="yes" xml:space="preserve">
          <source>Opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Xの局所的な外れ要因の反対側。</target>
        </trans-unit>
        <trans-unit id="5e68f725eeef777e12b4d3a454a6208991fd24e6" translate="yes" xml:space="preserve">
          <source>Opposite of the Mahalanobis distances.</source>
          <target state="translated">マハラノビスの距離の反対側。</target>
        </trans-unit>
        <trans-unit id="b5fb56d4ea090bc2e90702500456ef35c8c80910" translate="yes" xml:space="preserve">
          <source>Opposite of the anomaly score defined in the original paper.</source>
          <target state="translated">原著で定義されたアノマリースコアの反対側。</target>
        </trans-unit>
        <trans-unit id="8d0235738e36c010f5cce0e1d51d26583f4fbd2f" translate="yes" xml:space="preserve">
          <source>Opposite of the value of X on the K-means objective.</source>
          <target state="translated">K-means目的語のXの値の反対側。</target>
        </trans-unit>
        <trans-unit id="d4790d7d59a93c4896ec3d473b252d9c8e90d50a" translate="yes" xml:space="preserve">
          <source>Optimal choices for the sampling interval for certain data ranges can be computed (see the reference). The default values should be reasonable.</source>
          <target state="translated">特定のデータ範囲のサンプリング間隔の最適な選択を計算することができます(参考文献を参照)。デフォルト値は妥当な値でなければなりません。</target>
        </trans-unit>
        <trans-unit id="ce024d3ab746293c4c12993e7780e537aaab5bd3" translate="yes" xml:space="preserve">
          <source>Optimized BLAS / LAPACK implementations include:</source>
          <target state="translated">最適化されたBLAS/LAPACKの実装には以下のようなものがあります。</target>
        </trans-unit>
        <trans-unit id="e7a4cb55708bbb7494e2613ab1d6bd3cf5f4ed80" translate="yes" xml:space="preserve">
          <source>Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:</source>
          <target state="translated">KLダイバージェンスの最適化は、時として少し厄介なことがあります。t-SNEの最適化を制御する5つのパラメータがあり、結果として得られる埋め込みの品質を制御することができます。</target>
        </trans-unit>
        <trans-unit id="59b7edea35dae0ba7f04b93972cd416b8729437e" translate="yes" xml:space="preserve">
          <source>Option to scale data</source>
          <target state="translated">データのスケーリングオプション</target>
        </trans-unit>
        <trans-unit id="b448cb50c967f57d438352622bd92cc83d5cd21c" translate="yes" xml:space="preserve">
          <source>Optional display names matching the labels (same order).</source>
          <target state="translated">オプションでラベルにマッチする表示名(同じ順番)。</target>
        </trans-unit>
        <trans-unit id="f7746b3179890337eeaaee24d3cefbf3e21f4716" translate="yes" xml:space="preserve">
          <source>Optional list of label indices to include in the report.</source>
          <target state="translated">レポートに含めるラベルインデックスのオプションリスト。</target>
        </trans-unit>
        <trans-unit id="444d0152ba1b6a9d2f83b135dcad3591aef4140b" translate="yes" xml:space="preserve">
          <source>Optionally, weights can be provided for the individual classifiers:</source>
          <target state="translated">オプションとして、個々の分類器に重みを与えることができる。</target>
        </trans-unit>
        <trans-unit id="53297f66af025e9af455b9620b74f88cfef40f7b" translate="yes" xml:space="preserve">
          <source>Or a confusion matrix can be constructed for each sample&amp;rsquo;s labels:</source>
          <target state="translated">または、各サンプルのラベルに対して混同行列を作成できます。</target>
        </trans-unit>
        <trans-unit id="bdffb8593fdda1fb06f464d41401bd543c75d539" translate="yes" xml:space="preserve">
          <source>Or as a dict mapping scorer name to a predefined or custom scoring function:</source>
          <target state="translated">または、定義済みまたはカスタムのスコアリング関数にスコアラー名をマッピングするディクショナリとしても使用できます。</target>
        </trans-unit>
        <trans-unit id="568b3f93d3d74f4712d93109fe9bc1b3579dc2ff" translate="yes" xml:space="preserve">
          <source>Or drop a column for feature only having 2 categories:</source>
          <target state="translated">または、2つのカテゴリしかない機能のためのカラムを削除します。</target>
        </trans-unit>
        <trans-unit id="2919d9f2f1803bd27d88cb6979d8731b9671873d" translate="yes" xml:space="preserve">
          <source>Or, the Itakura-Saito (IS) divergence:</source>
          <target state="translated">あるいは、板倉-斎藤(IS)の発散。</target>
        </trans-unit>
        <trans-unit id="2eae1790c8b18065a4e4be5e643bf49617d7e481" translate="yes" xml:space="preserve">
          <source>Oracle Approximating Shrinkage Estimator</source>
          <target state="translated">オラクル近似収縮推定器</target>
        </trans-unit>
        <trans-unit id="09fb6aaba7940a7b7ffdbc9cbb9b3498303c1bad" translate="yes" xml:space="preserve">
          <source>Orange</source>
          <target state="translated">Orange</target>
        </trans-unit>
        <trans-unit id="1b5910554dc9c47445df182faeace08d47d3ef72" translate="yes" xml:space="preserve">
          <source>Order of output array in the dense case. &amp;lsquo;F&amp;rsquo; order is faster to compute, but may slow down subsequent estimators.</source>
          <target state="translated">密な場合の出力配列の順序。「F」次数は計算が高速ですが、後続の推定量が遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="61e854a8201b91e00e8fdcbd770fb61bc8a83663" translate="yes" xml:space="preserve">
          <source>Order of the norm used to filter the vectors of coefficients below &lt;code&gt;threshold&lt;/code&gt; in the case where the &lt;code&gt;coef_&lt;/code&gt; attribute of the estimator is of dimension 2.</source>
          <target state="translated">推定器の &lt;code&gt;coef_&lt;/code&gt; 属性が2次元である場合に、 &lt;code&gt;threshold&lt;/code&gt; を下回る係数のベクトルをフィルター処理するために使用されるノルムの次数。</target>
        </trans-unit>
        <trans-unit id="04f01a5d4b5e2de7c5bc38f04fe789073a85e1a0" translate="yes" xml:space="preserve">
          <source>Ordinary Least Squares and Ridge Regression Variance</source>
          <target state="translated">常用最小二乗とリッジ回帰の分散</target>
        </trans-unit>
        <trans-unit id="69dfb38c02d49acfa60317532da350814008c91b" translate="yes" xml:space="preserve">
          <source>Ordinary least squares Linear Regression.</source>
          <target state="translated">普通の最小二乗線形回帰。</target>
        </trans-unit>
        <trans-unit id="c6a26fb9333dc9c04fcf0b8a8d439bec3529ccb6" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the book &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; by Radford M. Neal</source>
          <target state="translated">元のアルゴリズムは、Radford M. Neal 著の本「 &lt;code&gt;Bayesian learning for neural networks&lt;/code&gt; 」で詳しく説明されています。</target>
        </trans-unit>
        <trans-unit id="285a92205b1ae0ee38089b09c3441dcd00669592" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">元のアルゴリズムは、論文に詳述されている&lt;a href=&quot;http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;最小角度回帰&lt;/a&gt; Hastieら。</target>
        </trans-unit>
        <trans-unit id="b56fc3a445b7bdb3d075f8c4b435d8408f7cbd6d" translate="yes" xml:space="preserve">
          <source>Original Algorithm is detailed in the paper &lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;Least Angle Regression&lt;/a&gt; by Hastie et al.</source>
          <target state="translated">元のアルゴリズムは、論文に詳述されている&lt;a href=&quot;https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;最小角度回帰&lt;/a&gt;Hastieら。</target>
        </trans-unit>
        <trans-unit id="40e1a40682f2197d130d7160c72b099cf6445896" translate="yes" xml:space="preserve">
          <source>Original Owners:</source>
          <target state="translated">元の所有者</target>
        </trans-unit>
        <trans-unit id="7ad091e9d90ec0296b62c3e5e44ac8d89a063912" translate="yes" xml:space="preserve">
          <source>Original data</source>
          <target state="translated">オリジナルデータ</target>
        </trans-unit>
        <trans-unit id="e08c8e7e7ce9b41fa431a10c664db0046193d186" translate="yes" xml:space="preserve">
          <source>Original indices of sorted hashed values in the fitted index.</source>
          <target state="translated">フィットインデックスでソートされたハッシュ化された値の元のインデックス。</target>
        </trans-unit>
        <trans-unit id="7bcdd254a48ca093c51f99fbea960c8ba5abba3d" translate="yes" xml:space="preserve">
          <source>Original points</source>
          <target state="translated">オリジナルポイント</target>
        </trans-unit>
        <trans-unit id="d62335c307cfd6338409df5c3eb510c3da387b07" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit</source>
          <target state="translated">直交一致追求</target>
        </trans-unit>
        <trans-unit id="4b43e1fc477a65c488f6b885c65608062bcdd067" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">直交一致追求(OMP)</target>
        </trans-unit>
        <trans-unit id="6f8635fe08116f66d41828127f270123a3daf2dc" translate="yes" xml:space="preserve">
          <source>Orthogonal Matching Pursuit model (OMP)</source>
          <target state="translated">直交マッチング追求モデル(OMP)</target>
        </trans-unit>
        <trans-unit id="b4cea4b2e1d94206efdd2c81ac084782051e04a0" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit (&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit (OMP)&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡（&lt;a href=&quot;linear_model#omp&quot;&gt;Orthogonal Matching Pursuit（OMP）&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="2d35a4350f19547a1df08de9c97e28d5eb4c4c18" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡は、G。Mallat、Z。Zhang、時間周波数辞書によるマッチング追跡、IEEE Transactions on Signal Processing、Vol。41、No。12（1993年12月）、3397-3415ページ。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="5e7d9b3e4cebb5843b9125c6b797beb3832d1f95" translate="yes" xml:space="preserve">
          <source>Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;)</source>
          <target state="translated">直交マッチング追跡は、S。Mallat、Z。Zhang、時間周波数辞書によるマッチング追跡、IEEE Transactions on Signal Processing、Vol。41、No。12（1993年12月）、3397-3415ページ。（&lt;a href=&quot;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&quot;&gt;http://blanche.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="708bf6f62e354ff314651598e7eebc62fd8d2bb2" translate="yes" xml:space="preserve">
          <source>Other Parameters</source>
          <target state="translated">その他のパラメータ</target>
        </trans-unit>
        <trans-unit id="0faa321ae463cf423d057b0fb19c09b0142f3c2a" translate="yes" xml:space="preserve">
          <source>Other Parameters:</source>
          <target state="translated">その他のパラメータ</target>
        </trans-unit>
        <trans-unit id="f7488409b393eaa19a207155b56a3606cc42d9c5" translate="yes" xml:space="preserve">
          <source>Other Versions</source>
          <target state="translated">その他のバージョン</target>
        </trans-unit>
        <trans-unit id="bf60b2f111b62bfaee7623785937d680b71fe343" translate="yes" xml:space="preserve">
          <source>Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:</source>
          <target state="translated">他の距離関数は、例えば、(一般化された)Kullback-Leibler(KL)発散(I発散とも呼ばれる)としてNMFで使用することができます。</target>
        </trans-unit>
        <trans-unit id="7ba50765d1cae4c4ed89d4ff332ed3b825d08abc" translate="yes" xml:space="preserve">
          <source>Other features match the names and e-mail addresses of particular people who were posting at the time.</source>
          <target state="translated">他にも、その時に投稿していた特定の人の名前やメールアドレスを一致させる機能があります。</target>
        </trans-unit>
        <trans-unit id="51c966edfa7d64a0b7dcf68b92d77cfd5b366772" translate="yes" xml:space="preserve">
          <source>Other machine learning packages for Python and related projects. Also algorithms that are slightly out of scope or not well established enough for scikit-learn.</source>
          <target state="translated">Pythonや関連プロジェクトのための他の機械学習パッケージ。また、scikit-learnとしてはやや範囲外だったり、十分に確立されていないアルゴリズムも。</target>
        </trans-unit>
        <trans-unit id="2ea8bcd548fe9ec11d17cc82aea4ab0fbdf7f8f3" translate="yes" xml:space="preserve">
          <source>Other regression generators generate functions deterministically from randomized features. &lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt;&lt;code&gt;make_sparse_uncorrelated&lt;/code&gt;&lt;/a&gt; produces a target as a linear combination of four features with fixed coefficients. Others encode explicitly non-linear relations: &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt;&lt;code&gt;make_friedman1&lt;/code&gt;&lt;/a&gt; is related by polynomial and sine transforms; &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt;&lt;code&gt;make_friedman2&lt;/code&gt;&lt;/a&gt; includes feature multiplication and reciprocation; and &lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt;&lt;code&gt;make_friedman3&lt;/code&gt;&lt;/a&gt; is similar with an arctan transformation on the target.</source>
          <target state="translated">他の回帰ジェネレーターは、ランダム化された特徴から決定論的に関数を生成します。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_sparse_uncorrelated#sklearn.datasets.make_sparse_uncorrelated&quot;&gt; &lt;code&gt;make_sparse_uncorrelated&lt;/code&gt; &lt;/a&gt;は、固定係数を持つ4つの機能の線形結合としてターゲットを生成します。その他は、明示的に非線形の関係をエンコードします&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman1#sklearn.datasets.make_friedman1&quot;&gt; &lt;code&gt;make_friedman1&lt;/code&gt; &lt;/a&gt;は、多項式変換と正弦変換によって関連付けられます。&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman2#sklearn.datasets.make_friedman2&quot;&gt; &lt;code&gt;make_friedman2&lt;/code&gt; に&lt;/a&gt;は、特徴の乗算と往復が含まれます。そして&lt;a href=&quot;../modules/generated/sklearn.datasets.make_friedman3#sklearn.datasets.make_friedman3&quot;&gt; &lt;code&gt;make_friedman3&lt;/code&gt; は、&lt;/a&gt;ターゲット上の逆正接変換と同様です。</target>
        </trans-unit>
        <trans-unit id="756226f83bdd3199110bcb639e6fbe93b81b2b14" translate="yes" xml:space="preserve">
          <source>Others also work in the multiclass case:</source>
          <target state="translated">他にも、マルチクラスのケースで活躍しています。</target>
        </trans-unit>
        <trans-unit id="31c4dae2edc1b6ad8f22c0a6f68a8f7ab2bd8316" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be a sequence of items that can be of type string or byte.</source>
          <target state="translated">それ以外の場合は、入力は文字列またはバイト型のアイテムのシーケンスであることが期待されます。</target>
        </trans-unit>
        <trans-unit id="bce48a0cb0a5e5960a4a35ec10cf25f56bf2f60b" translate="yes" xml:space="preserve">
          <source>Otherwise the input is expected to be the sequence strings or bytes items are expected to be analyzed directly.</source>
          <target state="translated">それ以外の場合は、入力はシーケンス文字列またはバイト項目が直接分析されることが期待されます。</target>
        </trans-unit>
        <trans-unit id="1eb83bd09e16b910ee3986257ed6e80732bc066a" translate="yes" xml:space="preserve">
          <source>Our definition: &lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;, &lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt; and &lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;, where &lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt; adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\)..</source>
          <target state="translated">私たちの定義：&lt;a href=&quot;#mosley2013&quot; id=&quot;id5&quot;&gt;[Mosley2013]&lt;/a&gt;、&lt;a href=&quot;#kelleher2015&quot; id=&quot;id6&quot;&gt;[Kelleher2015]&lt;/a&gt;、&lt;a href=&quot;#guyon2015&quot; id=&quot;id7&quot;&gt;[Guyon2015]&lt;/a&gt;、ここで&lt;a href=&quot;#guyon2015&quot; id=&quot;id8&quot;&gt;[Guyon2015]&lt;/a&gt;は調整されたバージョンを採用して、ランダムな予測のスコアが\（0 \）で完全な予測のスコアが\（1 \）になるようにします。 。</target>
        </trans-unit>
        <trans-unit id="4dd148768e9c37b7c74e1f4e4e0bf60f2fa1ec4e" translate="yes" xml:space="preserve">
          <source>Our goal is to predict the expected frequency of claims following car accidents for a new policyholder given the historical data over a population of policyholders.</source>
          <target state="translated">私たちの目標は、過去のデータをもとに、新規契約者の交通事故後のクレームの頻度を予測することです。</target>
        </trans-unit>
        <trans-unit id="51a30e97a793068228d5bb8b3efc1038cb1f9689" translate="yes" xml:space="preserve">
          <source>Our implementation of &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; was inspired by the R MICE package (Multivariate Imputation by Chained Equations) &lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;, but differs from it by returning a single imputation instead of multiple imputations. However, &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when &lt;code&gt;sample_posterior=True&lt;/code&gt;. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;, chapter 4 for more discussion on multiple vs. single imputations.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; の&lt;/a&gt;実装は、R MICEパッケージ（連鎖方程式による多変量代入）&lt;a href=&quot;#id3&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;に触発されましたが、複数の代入ではなく単一の代入を返すという点で異なります。ただし、&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;sample_posterior=True&lt;/code&gt; の場合に、異なるランダムシードを使用して同じデータセットに繰り返し適用することにより、複数の代入に使用することもできます。複数の代入と単一の代入の詳細については、&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;2&lt;/a&gt;、第4章を参照してください。</target>
        </trans-unit>
        <trans-unit id="a60ce8fd0b60aee8ad7f5d9f917babe62e72b491" translate="yes" xml:space="preserve">
          <source>Our implementation&amp;rsquo;s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.</source>
          <target state="translated">私たちの実装のスコアは、Tsoumakas et al。、2010で与えられたスコアより1大きくなっています。これにより、インスタンスの真のラベルが0である縮退ケースを処理するように拡張されます。</target>
        </trans-unit>
        <trans-unit id="fe0259b257120510b76da78ac976bdfb1e816c30" translate="yes" xml:space="preserve">
          <source>Our target for prediction: the wage. Wages are described as floating-point number in dollars per hour.</source>
          <target state="translated">予測の対象は賃金である。賃金は、1時間あたりのドル単位の浮動小数点数で表されます。</target>
        </trans-unit>
        <trans-unit id="c3f0fa9ade6f943d608603fdef87384f7f12b49b" translate="yes" xml:space="preserve">
          <source>Out of the &lt;code&gt;n_features&lt;/code&gt; features, only 5 are actually used to compute &lt;code&gt;y&lt;/code&gt;. The remaining features are independent of &lt;code&gt;y&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;n_features&lt;/code&gt; 機能のうち、実際に &lt;code&gt;y&lt;/code&gt; の計算に使用されるのは5つだけです。残りの機能は &lt;code&gt;y&lt;/code&gt; から独立しています。</target>
        </trans-unit>
        <trans-unit id="de345f1c1e8c124d63c9ee465bc413813ba2423e" translate="yes" xml:space="preserve">
          <source>Out-of-bag (OOB) estimates can be a useful heuristic to estimate the &amp;ldquo;optimal&amp;rdquo; number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt;), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.</source>
          <target state="translated">Out-of-bag（OOB）推定は、ブースティング反復の「最適な」数を推定するための有用なヒューリスティックになります。OOB推定値は交差検証推定値とほぼ同じですが、繰り返しモデルフィッティングを行わなくてもオンザフライで計算できます。OOB推定は、確率的勾配ブースティング（つまり、 &lt;code&gt;subsample &amp;lt; 1.0&lt;/code&gt; ）でのみ使用できます。推定は、ブートストラップサンプルに含まれていない例（いわゆるout-of-bagの例）に基づく損失の改善から得られます。OOBエスティメータは、真のテストロスの悲観的なエスティメータですが、少数のツリーに対してはかなり良い近似のままです。</target>
        </trans-unit>
        <trans-unit id="0edae687594f6a8a4aaab025d755be89c91cf6e0" translate="yes" xml:space="preserve">
          <source>Out-of-core (or &amp;ldquo;external memory&amp;rdquo;) learning is a technique used to learn from data that cannot fit in a computer&amp;rsquo;s main memory (RAM).</source>
          <target state="translated">コア外（または「外部メモリ」）の学習は、コンピュータのメインメモリ（RAM）に収まらないデータから学習するために使用される手法です。</target>
        </trans-unit>
        <trans-unit id="9961951956a78a655327742f08dd6b72dea1283f" translate="yes" xml:space="preserve">
          <source>Out-of-core classification of text documents</source>
          <target state="translated">テキスト文書のアウトオブコア分類</target>
        </trans-unit>
        <trans-unit id="1ee8fea1697e4d708569e4bb179873c92ff19379" translate="yes" xml:space="preserve">
          <source>Out:</source>
          <target state="translated">Out:</target>
        </trans-unit>
        <trans-unit id="5dd0aa388360b95626a38da9b18844d684c8d25b" translate="yes" xml:space="preserve">
          <source>Outlier detection</source>
          <target state="translated">外れ値検出</target>
        </trans-unit>
        <trans-unit id="875f738eb0e68cda4066331e25fac5af4c71d682" translate="yes" xml:space="preserve">
          <source>Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.</source>
          <target state="translated">外れ値検出と新規性検出は、異常または異常な観察を検出することに関心がある場合の異常検出に使用されます。外れ値検出は教師なし異常検出として、新規性検出は半教師付き異常検出としても知られています。外れ値検出の文脈では、利用可能な推定器は外れ値/異常が低密度領域にあると仮定しているため、外れ値/異常は密なクラスターを形成することができません。逆に、新規性検出の文脈では、新規性/異常は、学習データの低密度領域にある限り、密なクラスタを形成することができます(この文脈では正常と考えられます)。</target>
        </trans-unit>
        <trans-unit id="e16ebe52f017c4437fca8210daa352b7f7a34559" translate="yes" xml:space="preserve">
          <source>Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt;.</source>
          <target state="translated">共分散推定からの異常値の検出は、高次元の設定では機能しないか、うまく機能しない可能性があります。特に、 &lt;code&gt;n_samples &amp;gt; n_features ** 2&lt;/code&gt; を使用する場合は常に注意が必要です。</target>
        </trans-unit>
        <trans-unit id="eb5776745abd0907a25a2d19ca27c92845132829" translate="yes" xml:space="preserve">
          <source>Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called &lt;em&gt;outliers&lt;/em&gt;. Yet, in the case of outlier detection, we don&amp;rsquo;t have a clean data set representing the population of regular observations that can be used to train any tool.</source>
          <target state="translated">外れ値の検出は、目標が&lt;em&gt;外れ値&lt;/em&gt;と呼ばれるいくつかの汚染されたものから定期的な観測のコアを分離することであるという意味で、新規性の検出に似ています。しかし、異常値検出の場合、ツールをトレーニングするために使用できる定期的な観測の母集団を表す明確なデータセットはありません。</target>
        </trans-unit>
        <trans-unit id="1d8881b6614c5c1d87283378baf1dfbd30d62aa2" translate="yes" xml:space="preserve">
          <source>Outlier detection on a real data set</source>
          <target state="translated">実データセットでの外れ値検出</target>
        </trans-unit>
        <trans-unit id="4567caf33a07f033c1e56ef9d81272da195ec4e4" translate="yes" xml:space="preserve">
          <source>Outlier detection with Local Outlier Factor (LOF)</source>
          <target state="translated">局所外れ値因子(LOF)による外れ値検出</target>
        </trans-unit>
        <trans-unit id="fd5effe3fc538ea2a8eadf46c1fdeca372b53b13" translate="yes" xml:space="preserve">
          <source>Outlier-robust regressors</source>
          <target state="translated">異常値-頑健な回帰子</target>
        </trans-unit>
        <trans-unit id="1d4ae6e212657597b75c35cebf362553af1f6b83" translate="yes" xml:space="preserve">
          <source>Outliers in the X direction</source>
          <target state="translated">X方向の外れ値</target>
        </trans-unit>
        <trans-unit id="1280eb8e6f7378d868cfa7fd24acb5cb10594078" translate="yes" xml:space="preserve">
          <source>Outliers in the y direction</source>
          <target state="translated">y方向の外れ値</target>
        </trans-unit>
        <trans-unit id="fd162763a0f66a902211a2d40da7afdfc74ea634" translate="yes" xml:space="preserve">
          <source>Output a list of n_output arrays of class probabilities upon &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;predict_proba&lt;/code&gt; でクラス確率のn_output配列のリストを出力します。</target>
        </trans-unit>
        <trans-unit id="8298d7fc7f7d06e9b0287b5d9b7af6acdbad01e4" translate="yes" xml:space="preserve">
          <source>Output n_output values upon &lt;code&gt;predict&lt;/code&gt;;</source>
          <target state="translated">&lt;code&gt;predict&lt;/code&gt; 時にn_output値を出力します。</target>
        </trans-unit>
        <trans-unit id="c9a682f0f812fa2f90e0a2d7878d2c9702a9c510" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">出力コードベースの戦略は、one-vs-the-restおよびone-vs-oneとはかなり異なります。これらの戦略では、各クラスはユークリッド空間で表され、各次元は0または1のみになります。別の言い方をすれば、各クラスはバイナリコード（0と1の配列）で表されます。各クラスの場所/コードを追跡するマトリックスは、コードブックと呼ばれます。コードサイズは、前述の空間の次元です。直感的には、各クラスは可能な限り一意のコードで表す必要があり、分類の精度を最適化するために優れたコードブックを設計する必要があります。この実装では、&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;3で&lt;/a&gt;提唱されているように、ランダムに生成されたコードブックを使用するだけですが、将来、より複雑なメソッドが追加される可能性があります。</target>
        </trans-unit>
        <trans-unit id="0c950fe98702d8e76b55b31a01ec26c58021324c" translate="yes" xml:space="preserve">
          <source>Output-code based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; although more elaborate methods may be added in the future.</source>
          <target state="translated">出力コードベースの戦略は、one-vs-the-restやone-vs-oneとはかなり異なります。これらの戦略では、各クラスはユークリッド空間で表されます。各次元は0または1のみです。別の言い方をすると、各クラスはバイナリコード（0と1の配列）で表されます。各クラスの場所/コードを追跡するマトリックスは、コードブックと呼ばれます。コードサイズは、前述の空間の次元数です。直感的には、各クラスはできるだけ一意のコードで表す必要があり、分類精度を最適化するために適切なコードブックを設計する必要があります。この実装では、&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]で&lt;/a&gt;提唱されているように、ランダムに生成されたコードブックを使用するだけですが、より複雑なメソッドが将来追加される可能性があります。</target>
        </trans-unit>
        <trans-unit id="ce947ff733c2ff6c4c204d57e36546e6961c8fdc" translate="yes" xml:space="preserve">
          <source>Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 &amp;lt; code_size &amp;lt; 1) or for making the model more robust to errors (code_size &amp;gt; 1). See the documentation for more details.</source>
          <target state="translated">出力コードベースの戦略は、各クラスをバイナリコード（0と1の配列）で表すことで構成されます。フィッティング時に、コードブックのビットごとに1つのバイナリ分類器がフィッティングされます。予測時に、分類器を使用してクラス空間に新しいポイントが投影され、ポイントに最も近いクラスが選択されます。これらの戦略の主な利点は、モデルを圧縮する（0 &amp;lt;code_size &amp;lt;1）か、モデルをエラーに対してより堅牢にする（code_size&amp;gt; 1）ために、使用される分類子の数をユーザーが制御できることです。詳細については、ドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="a7e6bae7017e237617a86072aea77d9c980daf13" translate="yes" xml:space="preserve">
          <source>Overall mean.</source>
          <target state="translated">全体の平均値。</target>
        </trans-unit>
        <trans-unit id="870624bf4593bb4fe243ffdc55690c0daf6811c5" translate="yes" xml:space="preserve">
          <source>Overall mean. Only present if solver is &amp;lsquo;svd&amp;rsquo;.</source>
          <target state="translated">全体的な平均。ソルバーが「svd」の場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="39400cd6ec0520b5a4505f75497b844c4371060d" translate="yes" xml:space="preserve">
          <source>Overall you can expect the prediction time to increase at least linearly with the number of features (non-linear cases can happen depending on the global memory footprint and estimator).</source>
          <target state="translated">全体的に、予測時間は特徴量の数に応じて少なくとも線形に増加すると予想できます(グローバルメモリフットプリントと推定器によっては非線形のケースが発生することがあります)。</target>
        </trans-unit>
        <trans-unit id="3ee1d3fb4e75cd6c2d707958304caf7e92bfaa8b" translate="yes" xml:space="preserve">
          <source>Overall, the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;) has a weak impact on the claim severity, both in observed and predicted data.</source>
          <target state="translated">全体として、ドライバーの年齢（ &lt;code&gt;DrivAge&lt;/code&gt; ）は、観測データと予測データの両方で、クレームの重大度に弱い影響を及ぼします。</target>
        </trans-unit>
        <trans-unit id="91bd96083d98dc97930a239b87544217767aceaf" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps.</source>
          <target state="translated">トークン化とn-gram生成のステップを維持したまま、前処理(文字列変換)の段階をオーバーライドします。</target>
        </trans-unit>
        <trans-unit id="acdc2f08598a5d995bb4a299bbeb6695fc569906" translate="yes" xml:space="preserve">
          <source>Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps. Only applies if &lt;code&gt;analyzer is not callable&lt;/code&gt;.</source>
          <target state="translated">トークン化とn-gramの生成ステップを維持しながら、前処理（文字列変換）ステージをオーバーライドします。 &lt;code&gt;analyzer is not callable&lt;/code&gt; 場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="abd6316e00c26c25837bba2d69b86f216194acd8" translate="yes" xml:space="preserve">
          <source>Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">前処理とn-gram生成ステップを保持しながら、文字列トークン化ステップをオーバーライドします。 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="33411261f8481ce8d25af4edfb3eb882b6e66f99" translate="yes" xml:space="preserve">
          <source>Oversubscription can arise in the exact same fashion with parallelized routines from MKL, OpenBLAS or BLIS that are nested in joblib calls.</source>
          <target state="translated">オーバーサブスクリプションは、joblibコールに入れ子になっているMKL、OpenBLAS、BLISの並列化されたルーチンでも全く同じ方法で発生します。</target>
        </trans-unit>
        <trans-unit id="9ed28a68908d4cdeb1448490b897df73855c6566" translate="yes" xml:space="preserve">
          <source>P. Geurts, D. Ernst., and L. Wehenkel, &amp;ldquo;Extremely randomized trees&amp;rdquo;, Machine Learning, 63(1), 3-42, 2006.</source>
          <target state="translated">P. Geurts、D。Ernst。、およびL. Wehenkel、「Extremely randomized trees」、機械学習、63（1）、3-42、2006。</target>
        </trans-unit>
        <trans-unit id="12d77ff2c2e2faf889fa68d60f9acbbdadb178db" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw.二乗回帰の最小中央値.J.Am Stat Ass,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="915eb2720a9af992fe72961a5e439fc3997b7b8e" translate="yes" xml:space="preserve">
          <source>P. J. Rousseeuw. Least median of squares regression. Journal of American Statistical Ass., 79:871, 1984.</source>
          <target state="translated">P.J.Rousseeuw.二乗回帰の最小中央値.Journal of American Statistical Ass.,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="b9c25cc16ba020ea92289241ec3d659cb7a5c1ce" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach、M。Kull 、&lt;a href=&quot;http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves：PR Analysis Done Right&lt;/a&gt;、NIPS 2015。</target>
        </trans-unit>
        <trans-unit id="6732b8c3c2862c9a25623cf97fcdcc10a13cb40d" translate="yes" xml:space="preserve">
          <source>P.A. Flach, M. Kull, &lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;Precision-Recall-Gain Curves: PR Analysis Done Right&lt;/a&gt;, NIPS 2015.</source>
          <target state="translated">PA Flach、M。Kull、適合率-再現率&lt;a href=&quot;https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf&quot;&gt;-ゲイン曲線：PR分析&lt;/a&gt;は正しく行われた、NIPS2015。</target>
        </trans-unit>
        <trans-unit id="df9f68f22da202cd6a48417661656eae814961f2" translate="yes" xml:space="preserve">
          <source>PCA centers but does not scale the input data for each feature before applying the SVD. The optional parameter &lt;code&gt;whiten=True&lt;/code&gt; makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.</source>
          <target state="translated">PCAは中央に配置されますが、SVDを適用する前に各機能の入力データをスケーリングしません。オプションのパラメーター &lt;code&gt;whiten=True&lt;/code&gt; を使用すると、各コンポーネントを単位分散にスケーリングしながら、データを特異空間に投影できます。これは、下流のモデルが信号の等方性について強い仮定をしている場合に役立つことがよくあります。これは、たとえば、RBFカーネルとK-Meansクラスタリングアルゴリズムを備えたサポートベクターマシンの場合です。</target>
        </trans-unit>
        <trans-unit id="492b92fdeb678aa5ea0a0b2e24c313120c5ad6a0" translate="yes" xml:space="preserve">
          <source>PCA example with Iris Data-set</source>
          <target state="translated">アイリスデータセットを用いたPCAの例</target>
        </trans-unit>
        <trans-unit id="e783d8dc6810fed89a1dbeb972c615c5d6fa683c" translate="yes" xml:space="preserve">
          <source>PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is implemented as a &lt;em&gt;transformer&lt;/em&gt; object that learns \(n\) components in its &lt;code&gt;fit&lt;/code&gt; method, and can be used on new data to project it on these components.</source>
          <target state="translated">PCAは、分散の最大量を説明する一連の直交成分の多変量データセットを分解するために使用されます。scikit-learnでは、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;はその &lt;code&gt;fit&lt;/code&gt; メソッドで\（n \）コンポーネントを学習する&lt;em&gt;変換&lt;/em&gt;オブジェクトとして実装され、これらのコンポーネントに投影するために新しいデータで使用できます。</target>
        </trans-unit>
        <trans-unit id="a8428e4319c22658665567a92df72d0be42ed589" translate="yes" xml:space="preserve">
          <source>PCA, on the other hand, finds orthogonal directions in the raw feature space that correspond to directions accounting for maximum variance.</source>
          <target state="translated">一方、PCAは、最大分散を占める方向に対応する生の特徴空間の直交方向を見つけます。</target>
        </trans-unit>
        <trans-unit id="daf6b41a17ad64437397807edf4249f5c767d4f8" translate="yes" xml:space="preserve">
          <source>PDF documentation</source>
          <target state="translated">PDFドキュメント</target>
        </trans-unit>
        <trans-unit id="39addbbc6b853c00475e9525bae3e13c16a88c57" translate="yes" xml:space="preserve">
          <source>PDF of a random variable Y following Poisson, Tweedie (power=1.5) and Gamma distributions with different mean values (\(\mu\)). Observe the point mass at \(Y=0\) for the Poisson distribution and the Tweedie (power=1.5) distribution, but not for the Gamma distribution which has a strictly positive target domain.</source>
          <target state="translated">平均値の異なるPoisson,Tweedie (power=1.5)and Gamma分布に従うランダム変数YのPDFです。Poisson分布とTweedie (power=1.5)分布では,点質量が \(Y=0\)で観測されますが,厳密に正の目標領域を持つGamma分布では観測されません.</target>
        </trans-unit>
        <trans-unit id="83a2c673c060675dd48fb711d1c30c7deadadba5" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above Figure shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">2つの対象特徴を持つPDPは,2つの特徴間の相互作用を示している。例えば,上図の2変数PDPは,住宅価格の中央値の築年数と世帯あたりの平均居住者数の共同値への依存性を示しています。この2つの特徴の間には,明らかに相互作用が見てとれる。世帯当たりの平均入居者数が2以上の場合,住宅価格は築年数にほぼ依存しないのに対し,2未満の場合は築年数への強い依存性が見られる。</target>
        </trans-unit>
        <trans-unit id="eb9628323c2e00c334e5176712c96c9098e56078" translate="yes" xml:space="preserve">
          <source>PDPs with two target features show the interactions among the two features. For example, the two-variable PDP in the above figure shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than 2 there is a strong dependence on age.</source>
          <target state="translated">2つの対象特徴を持つPDPは,2つの特徴間の相互作用を示している。例えば,上図の2変数PDPは,住宅価格の中央値の,住宅年齢と世帯あたりの平均入居者数の共同値への依存性を示しています。平均入居者数が2以上の場合,住宅価格は築年数にほぼ依存しないのに対し,2未満の場合は築年数に強い依存性があることがわかります。</target>
        </trans-unit>
        <trans-unit id="818b23313a5fe3e3ead33eeac95b3f83aefbbeb6" translate="yes" xml:space="preserve">
          <source>PLS regression</source>
          <target state="translated">PLS回帰</target>
        </trans-unit>
        <trans-unit id="256d47be93e9a1da4b73eeee064926026bfad0da" translate="yes" xml:space="preserve">
          <source>PLSCanonical implements the 2 blocks canonical PLS of the original Wold algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</source>
          <target state="translated">PLSCanonical は、オリジナルの Wold アルゴリズム [Tenenhaus 1998]p.204 の 2 ブロック正準 PLS を実装したもので、 [Wegelin 2000]では PLS-C2A と呼ばれています。</target>
        </trans-unit>
        <trans-unit id="cbfe13649cb0f1ff547f98c2537765f522c1604e" translate="yes" xml:space="preserve">
          <source>PLSRegression implements the PLS 2 blocks regression known as PLS2 or PLS1 in case of one dimensional response. This class inherits from _PLS with mode=&amp;rdquo;A&amp;rdquo;, deflation_mode=&amp;rdquo;regression&amp;rdquo;, norm_y_weights=False and algorithm=&amp;rdquo;nipals&amp;rdquo;.</source>
          <target state="translated">PLSRegressionは、1次元応答の場合にPLS2またはPLS1と呼ばれるPLS 2ブロック回帰を実装します。このクラスは、mode =&amp;rdquo; A&amp;rdquo;、deflation_mode =&amp;rdquo; regression&amp;rdquo;、norm_y_weights = Falseおよびalgorithm =&amp;rdquo; nipals&amp;rdquo;の_PLSから継承します。</target>
        </trans-unit>
        <trans-unit id="5bd004de10b3be3d62af4c772e0a783e4c8d0cf7" translate="yes" xml:space="preserve">
          <source>PTRATIO pupil-teacher ratio by town</source>
          <target state="translated">PTRATIO 町の生徒数と教師数の比率</target>
        </trans-unit>
        <trans-unit id="41c1bb8d3d0929f28ded963b3c507fc9ad31e847" translate="yes" xml:space="preserve">
          <source>Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions, Statistics and Probability Letters, 33 (1997) 291-297</source>
          <target state="translated">Pace,R.Kelley and Ronald Barry,Sparse Spatial Autoregressions,Statistics and Probability Letters,33 (1997)291-297</target>
        </trans-unit>
        <trans-unit id="839107cb8051c220f3fa3546dd66b100d0cfaf46" translate="yes" xml:space="preserve">
          <source>Pairwise Euclidean distances between points in the dataset.</source>
          <target state="translated">データセット内の点間のユークリッド距離を対にしたもの.</target>
        </trans-unit>
        <trans-unit id="91ced6bbdf313e062ca8a5307f468c6f86bd6aab" translate="yes" xml:space="preserve">
          <source>Pairwise dissimilarities between the points. Must be symmetric.</source>
          <target state="translated">点の間のペアワイズ的な非類似性。対称的でなければならない。</target>
        </trans-unit>
        <trans-unit id="d8020c04569a536923cc79cf93520b90edece8e9" translate="yes" xml:space="preserve">
          <source>Pairwise metrics</source>
          <target state="translated">ペアワイズ・メトリクス</target>
        </trans-unit>
        <trans-unit id="0f7f7966f9f80e85baa6445a47b9d7c8941de99f" translate="yes" xml:space="preserve">
          <source>Parameter &lt;code&gt;nu&lt;/code&gt; in &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;OneClassSVM&lt;/code&gt;&lt;/a&gt;/&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;NuSVR&lt;/code&gt;&lt;/a&gt; approximates the fraction of training errors and support vectors.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;OneClassSVM&lt;/code&gt; &lt;/a&gt; / &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;NuSVR&lt;/code&gt; の&lt;/a&gt;パラメーター &lt;code&gt;nu&lt;/code&gt; は、トレーニングエラーの割合とサポートベクトルを近似します。</target>
        </trans-unit>
        <trans-unit id="539d705b4d5ce5e51b178019bd7f151f362e066d" translate="yes" xml:space="preserve">
          <source>Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogenous.</source>
          <target state="translated">カーネルの非均質性を制御するパラメータ。sigma_0=0の場合、カーネルは均質である。</target>
        </trans-unit>
        <trans-unit id="2462327ecfe7c5d6548ffb2d6d2c9cd234dbc30c" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level</source>
          <target state="translated">ノイズレベルを制御するパラメータ</target>
        </trans-unit>
        <trans-unit id="c00b33b8475549fd87f899268c585bfb7eff3c97" translate="yes" xml:space="preserve">
          <source>Parameter controlling the noise level (variance)</source>
          <target state="translated">ノイズレベル(分散)を制御するパラメータ</target>
        </trans-unit>
        <trans-unit id="4958bb8c16cafb2697226165d2c132d7ac8dc77e" translate="yes" xml:space="preserve">
          <source>Parameter estimation using grid search with cross-validation</source>
          <target state="translated">クロスバリデーションを用いたグリッド探索を用いたパラメータ推定</target>
        </trans-unit>
        <trans-unit id="c2428812e57708220766f99c6be2b35f70d17ffd" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel</source>
          <target state="translated">KNNカーネルのパラメータ</target>
        </trans-unit>
        <trans-unit id="3b0d1a590649f050970c31b6418be3790d6a82df" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which is a strictly positive integer.</source>
          <target state="translated">厳密には正の整数であるknnカーネルのパラメータ。</target>
        </trans-unit>
        <trans-unit id="849fb657e2772ba4166207f98cd952ea68adf842" translate="yes" xml:space="preserve">
          <source>Parameter for knn kernel which need to be strictly positive.</source>
          <target state="translated">厳密に正である必要があるknnカーネルのパラメータ。</target>
        </trans-unit>
        <trans-unit id="1fe064660ce73ee246b908fe6ec0781ebb1b98a2" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel</source>
          <target state="translated">rbfカーネルのパラメータ</target>
        </trans-unit>
        <trans-unit id="deecb0cfdd93d212c57e43f85e54500d3ea12cc6" translate="yes" xml:space="preserve">
          <source>Parameter for rbf kernel.</source>
          <target state="translated">rbf カーネルのパラメータ。</target>
        </trans-unit>
        <trans-unit id="766ac73c1e3445a4aa75bd4ec364753f58d7ba1c" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt;&lt;/a&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;a href=&quot;sklearn.metrics.pairwise_distances#sklearn.metrics.pairwise_distances&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise_distances&lt;/code&gt; &lt;/a&gt;からのミンコフスキー計量のパラメーター。p = 1の場合、これはmanhattan_distance（l1）を使用するのと同じであり、p = 2の場合はeucliden_distance（l2）を使用します。任意のpの場合、minkowski_distance（l_p）が使用されます。</target>
        </trans-unit>
        <trans-unit id="79b884107bc3e783bfcd688080df4a673a9117bc" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from &lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt;. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">&lt;code&gt;sklearn.metrics.pairwise.pairwise_distances&lt;/code&gt; からのMinkowskiメトリックのパラメーター。p = 1の場合、これはmanhattan_distance（l1）を使用することと同等であり、p = 2の場合はeuclidean_distance（l2）を使用します。任意のpの場合、minkowski_distance（l_p）が使用されます。</target>
        </trans-unit>
        <trans-unit id="2987673c5e2227c54e84a4c36c70d874959de513" translate="yes" xml:space="preserve">
          <source>Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.</source>
          <target state="translated">sklearn.metrics.pairwise.pairwise_distancesのミンコフスキーメトリックのパラメータ。p=1の場合はmanhattan_distance (l1)、p=2の場合はeuclidean_distance (l2)を使うのと同じです。任意のpについては、minkowski_distance (l_p)が用いられる。</target>
        </trans-unit>
        <trans-unit id="76b1a424a6610c92a4ff7dfc12b9deaa7fadd9d4" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric</source>
          <target state="translated">メトリックで指定されたペアワイズカーネルのパラメータガンマ</target>
        </trans-unit>
        <trans-unit id="1a54a92f7211f800d04136c5d7139c5f372c6e37" translate="yes" xml:space="preserve">
          <source>Parameter gamma of the pairwise kernel specified by metric. It should be positive.</source>
          <target state="translated">メトリックで指定されたペアワイズカーネルのパラメータガンマ。正の値でなければなりません。</target>
        </trans-unit>
        <trans-unit id="5f182d859d9049c92f489a6a5f8f861f198a0672" translate="yes" xml:space="preserve">
          <source>Parameter names mapped to their values.</source>
          <target state="translated">パラメータ名を値にマッピングしたものです。</target>
        </trans-unit>
        <trans-unit id="6c7eaceb91dd3f01e9a6c5c6273381eb8837898b" translate="yes" xml:space="preserve">
          <source>Parameter of RBF kernel: exp(-gamma * x^2)</source>
          <target state="translated">RBFカーネルのパラメータ:exp(-gamma*x^2)</target>
        </trans-unit>
        <trans-unit id="0a55d1c3b23ce41ff45285111de0d234bf72191c" translate="yes" xml:space="preserve">
          <source>Parameter of the corresponding mode.</source>
          <target state="translated">対応するモードのパラメータ。</target>
        </trans-unit>
        <trans-unit id="bd306dfafa0f09eb6ebeeb4165e12648835ffbc7" translate="yes" xml:space="preserve">
          <source>Parameter setting that gave the best results on the hold out data.</source>
          <target state="translated">ホールドアウトデータで最も良い結果が得られたパラメータ設定</target>
        </trans-unit>
        <trans-unit id="feb33995ff27df7648c2862697f9ab2d916fc6ad" translate="yes" xml:space="preserve">
          <source>Parameter to control the quality of the embedding according to the Johnson-Lindenstrauss lemma when n_components is set to &amp;lsquo;auto&amp;rsquo;.</source>
          <target state="translated">n_componentsが 'auto'に設定されている場合、Johnson-Lindenstrauss補題に従って埋め込みの品質を制御するパラメーター。</target>
        </trans-unit>
        <trans-unit id="9ebea54f905d700d979affa38d92638bb2ef6e53" translate="yes" xml:space="preserve">
          <source>Parameter tuning using grid search</source>
          <target state="translated">グリッドサーチを用いたパラメータ調整</target>
        </trans-unit>
        <trans-unit id="025546b75e4d071d18ff381aef96422930bc33e9" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), &lt;code&gt;coef_&lt;/code&gt; is then a 1D array. Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">パラメータベクトル（コスト関数式のW）。1D yがフィットで渡される場合（マルチタスク以外の使用法）、 &lt;code&gt;coef_&lt;/code&gt; は1D配列になります。 &lt;code&gt;coef_&lt;/code&gt; は &lt;code&gt;W&lt;/code&gt; 、 &lt;code&gt;W.T&lt;/code&gt; 転置を格納することに注意してください。</target>
        </trans-unit>
        <trans-unit id="fe2cd82aa0b85722f1fb3f2651910fd5a1cb8bc3" translate="yes" xml:space="preserve">
          <source>Parameter vector (W in the cost function formula). Note that &lt;code&gt;coef_&lt;/code&gt; stores the transpose of &lt;code&gt;W&lt;/code&gt;, &lt;code&gt;W.T&lt;/code&gt;.</source>
          <target state="translated">パラメータベクトル（コスト関数式のW）。 &lt;code&gt;coef_&lt;/code&gt; は &lt;code&gt;W&lt;/code&gt; 、 &lt;code&gt;W.T&lt;/code&gt; 転置を格納することに注意してください。</target>
        </trans-unit>
        <trans-unit id="40a18e293fedd48b8399b301e107b7d0fd89c55d" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the cost function formula),</source>
          <target state="translated">パラメータベクトル(コスト関数式ではw)。</target>
        </trans-unit>
        <trans-unit id="f2cc602f72e28952a1109943af93a6b27340c9a5" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the formulation formula).</source>
          <target state="translated">パラメータベクトル(式中のw)。</target>
        </trans-unit>
        <trans-unit id="b98d4ebc4de7e076498469fbea1e480d774d01d2" translate="yes" xml:space="preserve">
          <source>Parameter vector (w in the problem formulation).</source>
          <target state="translated">パラメータベクトル(問題の定式化ではw)。</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="561ad54783e422872a1f3fe4a9c36ebd61273494" translate="yes" xml:space="preserve">
          <source>Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.</source>
          <target state="translated">呼び出し可能なオブジェクトとして渡されるカーネルのパラメータ (キーワード引数)と値。他のカーネルでは無視されます。</target>
        </trans-unit>
        <trans-unit id="80f07c17ffcb9ce6c39eaf0025d7648367dfab02" translate="yes" xml:space="preserve">
          <source>Parameters for the metric used to compute distances to neighbors.</source>
          <target state="translated">隣人との距離を計算するために使用されるメトリックのパラメータ。</target>
        </trans-unit>
        <trans-unit id="89febd358321017f18d670418f2852c0de1ee9c6" translate="yes" xml:space="preserve">
          <source>Parameters of the estimators in the pipeline can be accessed using the &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; syntax:</source>
          <target state="translated">パイプライン内の推定量のパラメーターには、 &lt;code&gt;&amp;lt;estimator&amp;gt;__&amp;lt;parameter&amp;gt;&lt;/code&gt; 構文を使用してアクセスできます。</target>
        </trans-unit>
        <trans-unit id="da0d463840d0f1c86c777dbae23f9ad6731982e6" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo; or &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">トランスフォーマーのパラメーターは、その名前と「__」で区切られたパラメーター名を使用して設定できます。トランスフォーマーは、その名前のパラメーターを別のトランスフォーマーに設定することで完全に置き換えるか、または「drop」または &lt;code&gt;None&lt;/code&gt; に設定することで削除できます。</target>
        </trans-unit>
        <trans-unit id="689a87c23200ec6fa5f83b0f33b09b3222cdab89" translate="yes" xml:space="preserve">
          <source>Parameters of the transformers may be set using its name and the parameter name separated by a &amp;lsquo;__&amp;rsquo;. A transformer may be replaced entirely by setting the parameter with its name to another transformer, or removed by setting to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="translated">トランスフォーマーのパラメーターは、その名前と「__」で区切られたパラメーター名を使用して設定できます。トランスフォーマーは、その名前のパラメーターを別のトランスフォーマーに設定することで完全に置き換えるか、「ドロップ」に設定することで削除できます。</target>
        </trans-unit>
        <trans-unit id="fc1660202c57ce270668effe7d8743477471db0d" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;estimator.fit&lt;/code&gt; method of each step.</source>
          <target state="translated">各ステップの &lt;code&gt;estimator.fit&lt;/code&gt; メソッドに渡されるパラメーター。</target>
        </trans-unit>
        <trans-unit id="cdc9ca5309db0dd08f8314e5e5818e96afcd9144" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method at each step of the regressor chain.</source>
          <target state="translated">リグレッサチェーンの各ステップで &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメータ。</target>
        </trans-unit>
        <trans-unit id="b076b9abb4a3e4211d375c7fba667486c4754cb9" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of each step, where each parameter name is prefixed such that parameter &lt;code&gt;p&lt;/code&gt; for step &lt;code&gt;s&lt;/code&gt; has key &lt;code&gt;s__p&lt;/code&gt;.</source>
          <target state="translated">各ステップの &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメーター。各パラメーター名には、ステップ &lt;code&gt;s&lt;/code&gt; のパラメーター &lt;code&gt;p&lt;/code&gt; がキー &lt;code&gt;s__p&lt;/code&gt; を持つようにプレフィックスが付けられます。</target>
        </trans-unit>
        <trans-unit id="1ab85e076de8886205c489db8ed7843daa19517c" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the estimator</source>
          <target state="translated">推定器の &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメーター</target>
        </trans-unit>
        <trans-unit id="6dde0ba4e8565b39355c42aec6126c1947540a58" translate="yes" xml:space="preserve">
          <source>Parameters passed to the &lt;code&gt;fit&lt;/code&gt; method of the underlying regressor.</source>
          <target state="translated">基になるリグレッサーの &lt;code&gt;fit&lt;/code&gt; メソッドに渡されるパラメーター。</target>
        </trans-unit>
        <trans-unit id="0e8067debf1488481c61a1eaa4a0a76867521e4f" translate="yes" xml:space="preserve">
          <source>Parameters to be set on estimator for this grid point.</source>
          <target state="translated">この格子点の推定器に設定するパラメータ。</target>
        </trans-unit>
        <trans-unit id="191e3e986e6964fefdb746bdbd32d026ac54732c" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method of the estimator.</source>
          <target state="translated">推定子のはめ込み方式に渡すパラメータ。</target>
        </trans-unit>
        <trans-unit id="80e379dd51d34ce2dbedd57a975596631a95d883" translate="yes" xml:space="preserve">
          <source>Parameters to pass to the fit method.</source>
          <target state="translated">はめ込み方式に渡すパラ メーター。</target>
        </trans-unit>
        <trans-unit id="36ccb38b123600d9fbc78ab0cd9b6b307a008e1c" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called at the end of all transformations in the pipeline. Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.</source>
          <target state="translated">パイプライン内のすべての変換の最後に呼び出される &lt;code&gt;predict&lt;/code&gt; パラメーター。これは、return_stdまたはreturn_covを使用する一部のモデルから不確実性を返すために使用される場合がありますが、パイプラインの変換によって生成される不確実性は最終推定器に伝播されないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="b3a7c9dd881e64a7f41aafeb58e4f8bfcc6a5b4f" translate="yes" xml:space="preserve">
          <source>Parameters to the &lt;code&gt;predict&lt;/code&gt; called by the &lt;code&gt;final_estimator&lt;/code&gt;. Note that this may be used to return uncertainties from some estimators with &lt;code&gt;return_std&lt;/code&gt; or &lt;code&gt;return_cov&lt;/code&gt;. Be aware that it will only accounts for uncertainty in the final estimator.</source>
          <target state="translated">パラメータは、 &lt;code&gt;predict&lt;/code&gt; によって呼び出さ &lt;code&gt;final_estimator&lt;/code&gt; 。これは、 &lt;code&gt;return_std&lt;/code&gt; または &lt;code&gt;return_cov&lt;/code&gt; を使用して一部の推定量から不確実性を返すために使用される場合があることに注意してください。最終的な推定量の不確実性のみを説明することに注意してください。</target>
        </trans-unit>
        <trans-unit id="381c775599d6e4185d4410725809e360928357cd" translate="yes" xml:space="preserve">
          <source>Parameters:</source>
          <target state="translated">Parameters:</target>
        </trans-unit>
        <trans-unit id="99be92c9a2dedb3674880d6acb8f2dcdcbd96ff3" translate="yes" xml:space="preserve">
          <source>Parsing a text based source can be expensive. When working on repeatedly on the same dataset, it is recommended to wrap this loader with joblib.Memory.cache to store a memmapped backup of the CSR results of the first call and benefit from the near instantaneous loading of memmapped structures for the subsequent calls.</source>
          <target state="translated">テキストベースのソースを解析するのはコストがかかります。同じデータセットで繰り返し作業する場合、最初の呼び出しのCSR結果のメモマップされたバックアップを保存するために、このローダーをjoblib.Memory.cacheでラップし、その後の呼び出しのためにメモマップされた構造体をほぼ瞬時にロードすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="9dffe51138babd8f1ead215ce660a1e946197066" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plot (PDP) visualization.</source>
          <target state="translated">部分依存性プロット(PDP)の可視化。</target>
        </trans-unit>
        <trans-unit id="f8d5f258416422c57466cd67cc8a02c6b05a80fd" translate="yes" xml:space="preserve">
          <source>Partial Dependence Plots</source>
          <target state="translated">部分依存性プロット</target>
        </trans-unit>
        <trans-unit id="07df4cbd5294e07465f804b7c9b36c5d5a43e82b" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for Gradient Boosting</source>
          <target state="translated">勾配ブーストのための部分依存性計算</target>
        </trans-unit>
        <trans-unit id="b282664cc1d0ff2c6d0b320162703f3341719289" translate="yes" xml:space="preserve">
          <source>Partial Dependence computation for multi-layer perceptron</source>
          <target state="translated">多層パーセプトロンのための部分依存性計算</target>
        </trans-unit>
        <trans-unit id="e9c89f964f1a01a36b42f3fe4848b74ccc63e0e6" translate="yes" xml:space="preserve">
          <source>Partial Least Square SVD</source>
          <target state="translated">部分最小二乗SVD</target>
        </trans-unit>
        <trans-unit id="0af696b5fd6af6b13c25a86aed283f8f2b249126" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; 部分的な依存。</target>
        </trans-unit>
        <trans-unit id="93cbd804a6e8e51bf70182f90134157ea23f1138" translate="yes" xml:space="preserve">
          <source>Partial dependence of &lt;code&gt;target_variables&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;target_variables&lt;/code&gt; の部分的な依存関係。</target>
        </trans-unit>
        <trans-unit id="abf44f40a8ead68e3c71b46bec075211dc75d783" translate="yes" xml:space="preserve">
          <source>Partial dependence of a feature (or a set of features) corresponds to the average response of an estimator for each possible value of the feature.</source>
          <target state="translated">特徴(または特徴のセット)の部分依存性は、特徴の各可能な値に対する推定器の平均応答に対応します。</target>
        </trans-unit>
        <trans-unit id="c99d4545385034142f3b81de241245acbbd2acd6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response as a function of the &amp;lsquo;target&amp;rsquo; features.</source>
          <target state="translated">部分依存プロット（PDP）は、ターゲット応答&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;と一連の「ターゲット」特徴の間の依存関係を示し、他のすべての特徴（「補数」特徴）の値を無視します。直感的には、部分的な依存関係を、「ターゲット」機能の関数として期待されるターゲット応答として解釈できます。</target>
        </trans-unit>
        <trans-unit id="8a65d01c56b56d7e6904a157392f75eb71dc3b44" translate="yes" xml:space="preserve">
          <source>Partial dependence plots (PDP) show the dependence between the target response and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the &amp;lsquo;complement&amp;rsquo; features). Intuitively, we can interpret the partial dependence as the expected target response &lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt; as a function of the &amp;lsquo;target&amp;rsquo; features &lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;.</source>
          <target state="translated">部分依存プロット（PDP）は、ターゲット応答と「ターゲット」機能のセット間の依存関係を示し、他のすべての機能（「補数」機能）の値を取り除きます。直感的に、部分的な依存関係を「ターゲット」機能の関数として期待されるターゲット応答&lt;a href=&quot;#id23&quot; id=&quot;id21&quot;&gt;[1]&lt;/a&gt;として解釈できます&lt;a href=&quot;#id24&quot; id=&quot;id22&quot;&gt;[2]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9fe71a24f95abe640c27c0bbf2214ad816fa5b2e" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; 部分依存プロット。</target>
        </trans-unit>
        <trans-unit id="652e656223f58b0f5fc37309adb1b1ac47d155cf" translate="yes" xml:space="preserve">
          <source>Partial dependence plots for tree ensembles.</source>
          <target state="translated">木のアンサンブルの部分依存性プロット。</target>
        </trans-unit>
        <trans-unit id="c1a7be74107eb23fd9bfcd8698a88bc718aa4772" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the joint values of the &lt;code&gt;target_variables&lt;/code&gt; and the function represented by the &lt;code&gt;gbrt&lt;/code&gt;.</source>
          <target state="translated">部分的に依存プロットは、関節の値の間の依存性を示し &lt;code&gt;target_variables&lt;/code&gt; で表される関数 &lt;code&gt;gbrt&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="fc1161112f98108492921350df0f600984c6b3b0" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception, the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features.</source>
          <target state="translated">部分的な依存関係のプロットは、ターゲット関数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;2&lt;/a&gt;と「ターゲット」機能のセットの間の依存関係を示し、他のすべての機能（補集合機能）の値を無視しています。人間の知覚の限界により、ターゲット機能セットのサイズは小さくする必要があり（通常は1つまたは2つ）、通常、ターゲット機能は最も重要な機能の中から選択されます。</target>
        </trans-unit>
        <trans-unit id="04afc172d4359535322f4eeb08a601341437662b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots show the dependence between the target function &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; and a set of &amp;lsquo;target&amp;rsquo; features, marginalizing over the values of all other features (the complement features). Due to the limits of human perception the size of the target feature set must be small (usually, one or two) thus the target features are usually chosen among the most important features (see &lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt;&lt;code&gt;feature_importances_&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">部分依存プロットは、ターゲット関数&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;と「ターゲット」フィーチャのセットの間の依存関係を示し、他のすべてのフィーチャ（補数フィーチャ）の値を取り除きます。人間の知覚の制限により、ターゲットフィーチャセットのサイズは小さくなければならず（通常、1つまたは2つ）、ターゲットフィーチャは通常、最も重要なフィーチャから選択されます（&lt;a href=&quot;../../modules/generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor.feature_importances_&quot;&gt; &lt;code&gt;feature_importances_&lt;/code&gt; を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="a4a9c59e85db7b4787e5c0d6935be7408b0e1749" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and average occupants per household. We can clearly see an interaction between the two features: for an average occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">2つの対象特徴を持つ部分依存プロットを用いることで,それらの間の相互作用を可視化することができる。この二元偏依存プロットは,住宅価格の中央値の築年数と世帯あたりの平均入居者数の共同値への依存性を示している。平均入居者数が2人以上の場合、住宅価格は築年数にほぼ依存しないのに対し、2人未満の場合は築年数に強い依存性があることがわかります。</target>
        </trans-unit>
        <trans-unit id="27028d4e93727066aec3e2e83aa74954e7719a8b" translate="yes" xml:space="preserve">
          <source>Partial dependence plots with two target features enable us to visualize interactions among them. The two-way partial dependence plot shows the dependence of median house price on joint values of house age and avg. occupants per household. We can clearly see an interaction between the two features: For an avg. occupancy greater than two, the house price is nearly independent of the house age, whereas for values less than two there is a strong dependence on age.</source>
          <target state="translated">世帯あたりの平均居住者数は,住宅価格の中央値と世帯あたりの平均居住者数との間の相互作用を可視化することができる。世帯あたりの平均居住者数と築年数の共同値に対する住宅価格の中央値の依存性を示したものである。世帯当たりの平均入居者数が多いほど,住宅価格は上昇する。世帯当たりの平均入居者数が2人以上の場合,住宅価格は年齢とほぼ独立しているのに対し,2人未満の場合は年齢への強い依存性が見られる。</target>
        </trans-unit>
        <trans-unit id="b6af299fa9b94db48e98129e260b1eeb813719a6" translate="yes" xml:space="preserve">
          <source>Partial dependence plots.</source>
          <target state="translated">部分依存性プロット。</target>
        </trans-unit>
        <trans-unit id="6e99bc5cb78022b1555bc70fa32795dba1ae5f4f" translate="yes" xml:space="preserve">
          <source>Partially fit underlying estimators</source>
          <target state="translated">基礎となる推定量を部分的に適合させる</target>
        </trans-unit>
        <trans-unit id="0a5bfb5dfddbf187589aac0e6c6f726ea3a56e0f" translate="yes" xml:space="preserve">
          <source>Particularly in high-dimensional spaces, data can more easily be separated linearly and the simplicity of classifiers such as naive Bayes and linear SVMs might lead to better generalization than is achieved by other classifiers.</source>
          <target state="translated">特に高次元空間では、データをより簡単に線形に分離することができ、ナイーブベイズや線形SVMのような分類器のシンプルさは、他の分類器で達成されるよりも優れた一般化につながるかもしれません。</target>
        </trans-unit>
        <trans-unit id="ee5c2f652fa0ba7331b6add7547b0b3f663aedd3" translate="yes" xml:space="preserve">
          <source>Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.</source>
          <target state="translated">データが市松模様の構造を持つと仮定して、行と列を分割します。例えば、2つの行の分割と3つの列の分割がある場合、各行は3つのバイクラスタに属し、各列は2つのバイクラスタに属します。対応する行と列のラベルベクトルの外積が、このチェッカーボード構造を与えます。</target>
        </trans-unit>
        <trans-unit id="364b4c71a5c83a360f4fe86b4c60a48d2e33f726" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible output for permutation of &lt;code&gt;y&lt;/code&gt; values among samples. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">サンプル間で &lt;code&gt;y&lt;/code&gt; 値を並べ替えるための再現可能な出力のintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="fa828ddb159ddfa77238aad6f870c00db1af477d" translate="yes" xml:space="preserve">
          <source>Pass an int for reproducible results across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">複数の関数呼び出しにわたって再現可能な結果を​​得るためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="d9f564dc265e98a01f24f70d1576b62ca3b43bd3" translate="yes" xml:space="preserve">
          <source>Passing a 2D matrix for multilabel classification</source>
          <target state="translated">マルチラベル分類のための2次元行列を渡す</target>
        </trans-unit>
        <trans-unit id="cd2bb1a7aa8efcc1bd63306134f3100f91fc6ef3" translate="yes" xml:space="preserve">
          <source>Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; unless all tests sets have equal size and the metric decomposes over samples.</source>
          <target state="translated">これらの予測を評価メトリックに渡すことは、一般化のパフォーマンスを測定するための有効な方法ではない場合があります。結果が異なることが&lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt;すべてのテスト・セットは、サンプルの上に同じ大きさとメトリックが分解しない限り。</target>
        </trans-unit>
        <trans-unit id="144adab066cd5c92a6778f61a4778ef74c72b2a0" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Classifier</source>
          <target state="translated">受動的攻撃的分類器</target>
        </trans-unit>
        <trans-unit id="d61635eec17c853d9d6e1ff234afe50660f92701" translate="yes" xml:space="preserve">
          <source>Passive Aggressive Regressor</source>
          <target state="translated">パッシブアグレッシブリプレッサー</target>
        </trans-unit>
        <trans-unit id="291afa1da61effaacff4bf3e40a8045b9b8d343b" translate="yes" xml:space="preserve">
          <source>Patches are assumed to overlap and the image is constructed by filling in the patches from left to right, top to bottom, averaging the overlapping regions.</source>
          <target state="translated">パッチは重なっていると仮定して、左から右、上から下にパッチを埋め、重なっている領域を平均化することで画像を構築します。</target>
        </trans-unit>
        <trans-unit id="18a1699e2836ba2addd008ee2015c4e0ca5931f6" translate="yes" xml:space="preserve">
          <source>Path to the main folder holding one subfolder per category</source>
          <target state="translated">カテゴリごとに1つのサブフォルダを保持するメインフォルダへのパス</target>
        </trans-unit>
        <trans-unit id="98ee95181d901b366d1fe1c0df5a309cc7a3de65" translate="yes" xml:space="preserve">
          <source>Penalization parameter selected.</source>
          <target state="translated">ペナルティパラメータを選択しました。</target>
        </trans-unit>
        <trans-unit id="269c93d9d03f37f0d0341535ce102e3bd06fa60f" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad)</source>
          <target state="translated">インターセプトにペナルティを課す(悪い</target>
        </trans-unit>
        <trans-unit id="3bbf431b41c522bd1eb1b65ea50fc21584275d87" translate="yes" xml:space="preserve">
          <source>Penalize the intercept (bad) yes no no no no Faster for large datasets no no no yes yes Robust to unscaled datasets yes yes yes no no ============================ =========== ======= =========== ===== ======</source>
          <target state="translated">切片を罰則化する(不良)yes no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no no ==============================================================================</target>
        </trans-unit>
        <trans-unit id="64a00002571bc14aac9e57cf087ec95ea0663632" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term.</source>
          <target state="translated">誤差項のペナルティパラメータC。</target>
        </trans-unit>
        <trans-unit id="78e16aaecb446c766536c888cb2ab681d45d227a" translate="yes" xml:space="preserve">
          <source>Penalty parameter C of the error term. The penalty is a squared l2 penalty. The bigger this parameter, the less regularization is used.</source>
          <target state="translated">誤差項のペナルティパラメータC。ペナルティはl2の2乗のペナルティです。このパラメータが大きいほど、正則化の使用量が少なくなります。</target>
        </trans-unit>
        <trans-unit id="92dc577567bc10903722a0cd6bc84fd8cb538ac8" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BFGS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">デフォルトでは、scipy.optimize.minimizeの「L-BFGS-B」アルゴリズムが使用されます。Noneが渡された場合、カーネルのパラメーターは固定されたままになります。使用可能な内部オプティマイザは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="36c27027dd1d6e2db082fc2d8518ad5ddec8cac4" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;L-BGFS-B&amp;rsquo; algorithm from scipy.optimize.minimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">デフォルトでは、scipy.optimize.minimizeの「L-BGFS-B」アルゴリズムが使用されます。Noneが渡された場合、カーネルのパラメーターは固定されたままになります。使用可能な内部オプティマイザは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="f4b4203fc28ce6d3a674721e39c00d5f8047107a" translate="yes" xml:space="preserve">
          <source>Per default, the &amp;lsquo;fmin_l_bfgs_b&amp;rsquo; algorithm from scipy.optimize is used. If None is passed, the kernel&amp;rsquo;s parameters are kept fixed. Available internal optimizers are:</source>
          <target state="translated">デフォルトでは、scipy.optimizeの「fmin_l_bfgs_b」アルゴリズムが使用されます。Noneが渡されると、カーネルのパラメータは固定されたままになります。利用可能な内部オプティマイザは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="6244b7856d25c3c666d36fccf077f85fa1982ad7" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum.</source>
          <target state="translated">最小限の機能ごとに調整します。</target>
        </trans-unit>
        <trans-unit id="3b00bbffe150e7b8c58881b0f3768ad4c9012a12" translate="yes" xml:space="preserve">
          <source>Per feature adjustment for minimum. Equivalent to &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt;</source>
          <target state="translated">最小の機能ごとの調整。 &lt;code&gt;min - X.min(axis=0) * self.scale_&lt;/code&gt; 同等-X.min（axis = 0）* self.scale_</target>
        </trans-unit>
        <trans-unit id="d1fcc9536b36965b70f539451057ec6f4f433503" translate="yes" xml:space="preserve">
          <source>Per feature maximum absolute value.</source>
          <target state="translated">フィーチャーごとの最大絶対値。</target>
        </trans-unit>
        <trans-unit id="c5e7199d590adbeaea5c7d5a6fd8bd4755090a1c" translate="yes" xml:space="preserve">
          <source>Per feature maximum seen in the data</source>
          <target state="translated">データで見た特徴の最大値あたり</target>
        </trans-unit>
        <trans-unit id="102581d144872704eb291cec69ea6b75f7b2f4ae" translate="yes" xml:space="preserve">
          <source>Per feature minimum seen in the data</source>
          <target state="translated">データに見られる最小の特徴あたり</target>
        </trans-unit>
        <trans-unit id="9af0de5bb3d05f02ad6ecd6ef96e244722359bc9" translate="yes" xml:space="preserve">
          <source>Per feature range &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt; seen in the data</source>
          <target state="translated">データ内に見られる特徴ごとの範囲 &lt;code&gt;(data_max_ - data_min_)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3041c95c2bc4cf499751cc15dcfa6079b79d0c01" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data.</source>
          <target state="translated">フィーチャーごとにデータの相対的なスケーリングを行います。</target>
        </trans-unit>
        <trans-unit id="2aca96873ba30a1f44a2ea13c9cca023c862496e" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">データのフィーチャごとの相対的なスケーリング。 &lt;code&gt;with_std=False&lt;/code&gt; の場合は &lt;code&gt;None&lt;/code&gt; と同じです。</target>
        </trans-unit>
        <trans-unit id="add1f6f8b0508a85231ee2c9d67b3d85e4b4574a" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. Equivalent to &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</source>
          <target state="translated">データの機能ごとの相対的なスケーリング。相当する &lt;code&gt;(max - min) / (X.max(axis=0) - X.min(axis=0))&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1f0850ba910ca1120662899ac545a63448e94c53" translate="yes" xml:space="preserve">
          <source>Per feature relative scaling of the data. This is calculated using &lt;code&gt;np.sqrt(var_)&lt;/code&gt;. Equal to &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;with_std=False&lt;/code&gt;.</source>
          <target state="translated">データの機能ごとの相対的なスケーリング。これは、 &lt;code&gt;np.sqrt(var_)&lt;/code&gt; を使用して計算されます。 &lt;code&gt;with_std=False&lt;/code&gt; の場合、 &lt;code&gt;None&lt;/code&gt; に等しくなります。</target>
        </trans-unit>
        <trans-unit id="03c5a380bfcbdfa271df31ac8e5033140b3c462f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">機能ごとの経験的平均 &lt;code&gt;partial_fit&lt;/code&gt; 呼び出しを介して集計します。</target>
        </trans-unit>
        <trans-unit id="9b69855eee3f3bb7b79cdf586195cf71da93449f" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set.</source>
          <target state="translated">訓練セットから推定された特徴毎の経験的平均。</target>
        </trans-unit>
        <trans-unit id="78b2f336c949583f3bdffdc9a030b0f9e6170c47" translate="yes" xml:space="preserve">
          <source>Per-feature empirical mean, estimated from the training set. Equal to &lt;code&gt;X.mean(axis=0)&lt;/code&gt;.</source>
          <target state="translated">トレーニングセットから推定された、機能ごとの経験的平均。 &lt;code&gt;X.mean(axis=0)&lt;/code&gt; と同じです。</target>
        </trans-unit>
        <trans-unit id="a8c85c36120ad4d7e0ffc8553bf9d9bb4f653d40" translate="yes" xml:space="preserve">
          <source>Per-feature empirical variance, aggregate over calls to &lt;code&gt;partial_fit&lt;/code&gt;.</source>
          <target state="translated">機能ごとの経験的分散、 &lt;code&gt;partial_fit&lt;/code&gt; の呼び出しの集計。</target>
        </trans-unit>
        <trans-unit id="bb6e9ff3187e622eed5823426c5d8cc8b9a5e66d" translate="yes" xml:space="preserve">
          <source>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</source>
          <target state="translated">サンプルごとの重み。サンプルごとにCのスケールを変更します.より高い重みは,分類器がこれらの点をより強調することを強制します.</target>
        </trans-unit>
        <trans-unit id="022818083764d59bc1c545a8df2dfc49cf87ec2a" translate="yes" xml:space="preserve">
          <source>Per-topic word distributions are independently drawn, where in reality all would be affected by a sparse base distribution, and would be correlated.</source>
          <target state="translated">トピックごとの単語分布は独立して描かれていますが、実際にはすべての単語は疎な基底分布の影響を受け、相関関係にあるでしょう。</target>
        </trans-unit>
        <trans-unit id="508100893e29e053d40024965b139e71658b7b80" translate="yes" xml:space="preserve">
          <source>Percent of features to keep.</source>
          <target state="translated">残すべき機能の割合。</target>
        </trans-unit>
        <trans-unit id="510c90c1028713db83438ed3b7d7b97622c046bb" translate="yes" xml:space="preserve">
          <source>Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.</source>
          <target state="translated">コードブックの作成に使用するクラスの数の割合。0から1の間の数値は、1対1よりも少ない分類子を必要とします。1よりも大きい数値は、1対1よりも多くの分類子を必要とします。</target>
        </trans-unit>
        <trans-unit id="ab474311418f716aa90a18ba4aac10d5e0126b01" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components.</source>
          <target state="translated">選択された各成分によって説明された分散の割合。</target>
        </trans-unit>
        <trans-unit id="6b606c4b3521608268acaf8a83daf1d705edec66" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</source>
          <target state="translated">選択した各コンポーネントによって説明される分散のパーセンテージ。 &lt;code&gt;n_components&lt;/code&gt; が設定されていない場合、すべてのコンポーネントが保存され、説明された分散の合計は1.0になります。固有値またはsvdソルバーが使用されている場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="d93d3d6b53ae20e2e020e6bfd5f07bc4328ff552" translate="yes" xml:space="preserve">
          <source>Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.</source>
          <target state="translated">選択された成分のそれぞれによって説明された分散の割合。すべての成分が格納されている場合、説明された分散の合計は1.0に等しい。</target>
        </trans-unit>
        <trans-unit id="b76d05a7855a1137343582656ace6f381d34c7bd" translate="yes" xml:space="preserve">
          <source>Perceptron: \(L(y_i, f(x_i)) = \max(0, - y_i f(x_i))\).</source>
          <target state="translated">Perceptron.\(L(y_i,f(x_i))=\max(0,-y_i f(x_i))</target>
        </trans-unit>
        <trans-unit id="5ae537dc31ff6e276137ba1f3f08f14e2d75b135" translate="yes" xml:space="preserve">
          <source>Perfect labeling is scored 1.0:</source>
          <target state="translated">パーフェクトラベリングは1.0点です。</target>
        </trans-unit>
        <trans-unit id="e0246cf8e59488c8ec6f2dd495c80e88ab5e2c38" translate="yes" xml:space="preserve">
          <source>Perfect labelings are both homogeneous and complete, hence have score 1.0:</source>
          <target state="translated">完全なラベリングは均質かつ完全であるため、スコアは1.0です。</target>
        </trans-unit>
        <trans-unit id="0b6e6a15e84a2c0c2b67bd408293381d6bde8086" translate="yes" xml:space="preserve">
          <source>Perfect labelings are complete:</source>
          <target state="translated">完璧なラベリングが完成しました。</target>
        </trans-unit>
        <trans-unit id="c929d898b15ba46b39cbe3a578cc048974dbb0f3" translate="yes" xml:space="preserve">
          <source>Perfect labelings are homogeneous:</source>
          <target state="translated">完璧なラベリングは同質です。</target>
        </trans-unit>
        <trans-unit id="158762f0fcedf70ff27743eef2b9fe2391aaecf5" translate="yes" xml:space="preserve">
          <source>Perfectly matching labelings have a score of 1 even</source>
          <target state="translated">完全に一致するラベリングには、1の偶数のスコアがあります。</target>
        </trans-unit>
        <trans-unit id="689d4751e15d0ca03ac4490cb60697622e5a7435" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data</source>
          <target state="translated">データの親和伝播クラスタリングを実行する</target>
        </trans-unit>
        <trans-unit id="dee861689c2a0a2296c4bb43119e58f854cfe756" translate="yes" xml:space="preserve">
          <source>Perform Affinity Propagation Clustering of data.</source>
          <target state="translated">データの親和伝播クラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="5a1975729819b04264272cf944b37eeff6c54bb5" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix, and return cluster labels.</source>
          <target state="translated">特徴量または距離行列からDBSCANクラスタリングを実行し、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="463c2804b4b2c3d108889b17acd479af4436cc72" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features or distance matrix.</source>
          <target state="translated">特徴量や距離行列からDBSCANクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="b65b6612279cd3a62fed32683d01c69787a97da2" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from features, or distance matrix.</source>
          <target state="translated">特徴量や距離行列からDBSCANクラスタリングを行います。</target>
        </trans-unit>
        <trans-unit id="458d7c0c2b90dff326f89ad767c75f6a1812b730" translate="yes" xml:space="preserve">
          <source>Perform DBSCAN clustering from vector array or distance matrix.</source>
          <target state="translated">ベクトル配列や距離行列からDBSCANクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="959d910f7763a2ffdb63e2da58508fc0266c6120" translate="yes" xml:space="preserve">
          <source>Perform Fast Independent Component Analysis.</source>
          <target state="translated">高速な独立成分分析を実行します。</target>
        </trans-unit>
        <trans-unit id="c424661559fd4111ae395a81a440da23c2d8b00f" translate="yes" xml:space="preserve">
          <source>Perform OPTICS clustering.</source>
          <target state="translated">OPTICSクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="b44047366aaa6bbf25bda0720c2b9955136f4c83" translate="yes" xml:space="preserve">
          <source>Perform a Locally Linear Embedding analysis on the data.</source>
          <target state="translated">データの局所的な線形埋め込み分析を実行します。</target>
        </trans-unit>
        <trans-unit id="ac1255795fd03e9f556426224dcbfbd70ca25e88" translate="yes" xml:space="preserve">
          <source>Perform a shortest-path graph search on a positive directed or undirected graph.</source>
          <target state="translated">正の有向または無向グラフで最短パスのグラフ探索を行います.</target>
        </trans-unit>
        <trans-unit id="5913acb65bcb3cfc0407c274e6a0ae6c08f54988" translate="yes" xml:space="preserve">
          <source>Perform binary classification using non-linear SVC with RBF kernel. The target to predict is a XOR of the inputs.</source>
          <target state="translated">RBFカーネルを用いた非線形SVCを用いて2値分類を行う。予測対象は入力のXORです。</target>
        </trans-unit>
        <trans-unit id="a259ca5c38306ae844a312467fcf634f7a4c4cb8" translate="yes" xml:space="preserve">
          <source>Perform classification on an array of test vectors X.</source>
          <target state="translated">テストベクトルXの配列で分類を行います.</target>
        </trans-unit>
        <trans-unit id="1af0f015c949bd1c16d805fdf5523bbcd5119678" translate="yes" xml:space="preserve">
          <source>Perform classification on samples in X.</source>
          <target state="translated">Xのサンプルで分類を実行します。</target>
        </trans-unit>
        <trans-unit id="b3b3f491b55f8b579a228793b65f99ca8d0d1a92" translate="yes" xml:space="preserve">
          <source>Perform classification on test vectors X.</source>
          <target state="translated">テストベクトルXで分類を行う。</target>
        </trans-unit>
        <trans-unit id="2cc5f65a2c2c90fbeebd06f8fc6c4b4510abcc97" translate="yes" xml:space="preserve">
          <source>Perform clustering on X and returns cluster labels.</source>
          <target state="translated">Xに対してクラスタリングを実行し、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="db94ca6613eef6e933177aeabe20672ae9208bdf" translate="yes" xml:space="preserve">
          <source>Perform clustering.</source>
          <target state="translated">クラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="f9f7c30d76f5b933404ebf4eb86819fed33be90a" translate="yes" xml:space="preserve">
          <source>Perform dimensionality reduction on X.</source>
          <target state="translated">Xの次元削減を行う。</target>
        </trans-unit>
        <trans-unit id="ea3d4bd6b3c1842187bced8b218fbec04eb7bd42" translate="yes" xml:space="preserve">
          <source>Perform fit on X and returns labels for X.</source>
          <target state="translated">X にはめ込みを行い、X のラベルを返します。</target>
        </trans-unit>
        <trans-unit id="6d24d9dcbe2141c7b30ceff371628950cd7ca425" translate="yes" xml:space="preserve">
          <source>Perform is_fitted validation for estimator.</source>
          <target state="translated">推計子の is_fitted 検証を実行します。</target>
        </trans-unit>
        <trans-unit id="28c6ac8c77fceae308f63cb91c2fe135b4f5904f" translate="yes" xml:space="preserve">
          <source>Perform mapping to a normal distribution using a power transform.</source>
          <target state="translated">冪変換を用いて正規分布へのマッピングを行います。</target>
        </trans-unit>
        <trans-unit id="f154e55e13cfe215c964ae2fb4c3f06da46b83fe" translate="yes" xml:space="preserve">
          <source>Perform mean shift clustering of data using a flat kernel.</source>
          <target state="translated">フラットカーネルを使用してデータの平均シフトクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="5d74999037a10ebb61d14a38ac3c1f58c8d3eb1c" translate="yes" xml:space="preserve">
          <source>Perform one Gibbs sampling step.</source>
          <target state="translated">ギブスサンプリングを1回行います。</target>
        </trans-unit>
        <trans-unit id="a608c191f0cb8597865dd893c202fb7da2ab975c" translate="yes" xml:space="preserve">
          <source>Perform one epoch of stochastic gradient descent on given samples.</source>
          <target state="translated">与えられたサンプルに対して確率的勾配降下の1エポックを実行します。</target>
        </trans-unit>
        <trans-unit id="b97c414705aa3f4f9199ddb08da830ac54e8fe97" translate="yes" xml:space="preserve">
          <source>Perform regression on samples in X.</source>
          <target state="translated">Xのサンプルで回帰を実行します。</target>
        </trans-unit>
        <trans-unit id="dd51e0250263d470cb8a4effc410185e24e99d6f" translate="yes" xml:space="preserve">
          <source>Perform robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">外れ値の影響を除去しつつ、外れ値と外れ値を同じ尺度にしないロバストな標準化を行う。</target>
        </trans-unit>
        <trans-unit id="1506956d6558b19c7df6e1dc69b0a99dea667d55" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix, and return cluster labels.</source>
          <target state="translated">特徴量、またはアフィニティ行列からスペクトルクラスタリングを実行し、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="557e6799397c88d4bc14664b365f9609412e8548" translate="yes" xml:space="preserve">
          <source>Perform spectral clustering from features, or affinity matrix.</source>
          <target state="translated">特徴量、またはアフィニティマトリクスからスペクトルクラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="ebef79dfac2e65b8c25ad9bb7fdce83cd9513504" translate="yes" xml:space="preserve">
          <source>Perform standardization by centering and scaling</source>
          <target state="translated">センタリングやスケーリングによる標準化を行う</target>
        </trans-unit>
        <trans-unit id="4bc7fa7479a101fbc87b729f92b16086a341ed9e" translate="yes" xml:space="preserve">
          <source>Perform standardization that is faster, but less robust to outliers.</source>
          <target state="translated">標準化を実行すると、より高速になりますが、外れ値にはあまりロバストではありません。</target>
        </trans-unit>
        <trans-unit id="3c9e3951bcb75f5ea77167c7144b5b5a81bd6690" translate="yes" xml:space="preserve">
          <source>Performs DBSCAN extraction for an arbitrary epsilon.</source>
          <target state="translated">任意のイプシロンに対してDBSCAN抽出を実行します。</target>
        </trans-unit>
        <trans-unit id="b688f62a3ad12b1d7c84b19ede9050b44271064d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of categorical features.</source>
          <target state="translated">カテゴリ特徴量のワンショットエンコーディングを実行します。</target>
        </trans-unit>
        <trans-unit id="8d75208cdd518398a274b5c66a99a07cd1c4674d" translate="yes" xml:space="preserve">
          <source>Performs a one-hot encoding of dictionary items (also handles string-valued features).</source>
          <target state="translated">辞書項目のワンショットエンコーディングを実行します (文字列値機能も扱います)。</target>
        </trans-unit>
        <trans-unit id="c8a1451466ddb25587dffc5d4da05875ebb74725" translate="yes" xml:space="preserve">
          <source>Performs a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615 unique colors to 64, while preserving the overall appearance quality.</source>
          <target state="translated">夏の宮殿(中国)の画像をピクセル単位のベクトル量子化(VQ)を行い、全体の外観品質を維持しながら、画像を表示するために必要な色数を96,615色の固有色から64色に削減します。</target>
        </trans-unit>
        <trans-unit id="b9ac5dd9fc2e45481e3dd5c8a6199a86e1da0656" translate="yes" xml:space="preserve">
          <source>Performs an approximate one-hot encoding of dictionary items or strings.</source>
          <target state="translated">辞書項目または文字列の近似ワンホットエンコーディングを実行します。</target>
        </trans-unit>
        <trans-unit id="d01f1a997cf8a75714d83a10021fc81a3a7d1f94" translate="yes" xml:space="preserve">
          <source>Performs an ordinal (integer) encoding of the categorical features.</source>
          <target state="translated">カテゴリ特徴量の順序(整数)エンコーディングを実行します。</target>
        </trans-unit>
        <trans-unit id="7945877a79ee9606b9df91e80330316ac1099e28" translate="yes" xml:space="preserve">
          <source>Performs approximate nearest neighbor search using LSH forest.</source>
          <target state="translated">LSHフォレストを用いて近似最近傍探索を行います。</target>
        </trans-unit>
        <trans-unit id="9bab7093aa44c52b527bcacee82e15ab827f7949" translate="yes" xml:space="preserve">
          <source>Performs binarization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して2値化を実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="9334db1899f0bba94453f1ee6fbd171b507e5ed1" translate="yes" xml:space="preserve">
          <source>Performs centering and scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して、センタリングとスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="506256c7ae18c8053ecaa6445590a98acf36aa0e" translate="yes" xml:space="preserve">
          <source>Performs clustering on X and returns cluster labels.</source>
          <target state="translated">Xのクラスタリングを実行し、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="38545772bd4529f41bf4bec322ebc7f80ab61f41" translate="yes" xml:space="preserve">
          <source>Performs inductive inference across the model.</source>
          <target state="translated">モデル間で帰納的推論を実行します。</target>
        </trans-unit>
        <trans-unit id="de7dc9fb5a771d54ea7fadc4d86dd2f8269f14e4" translate="yes" xml:space="preserve">
          <source>Performs normalization using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して正規化を実行します（たとえば、前処理の一部として&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;）。</target>
        </trans-unit>
        <trans-unit id="72f57dd0021b24f09da3fde633d42235df9baa52" translate="yes" xml:space="preserve">
          <source>Performs outlier detection on X.</source>
          <target state="translated">Xの外れ値検出を実行します。</target>
        </trans-unit>
        <trans-unit id="c032681b9d32a5a7daa554f673be122edd3ede2b" translate="yes" xml:space="preserve">
          <source>Performs power transformation using the &lt;code&gt;Transformer&lt;/code&gt; API (as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して電源変換を実行します（前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="9b0d235575d753630f72f479dd595fb051616b74" translate="yes" xml:space="preserve">
          <source>Performs quantile-based scaling using the &lt;code&gt;Transformer&lt;/code&gt; API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Transformer&lt;/code&gt; API を使用して、&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;ベースのスケーリングを実行します（たとえば、前処理sklearn.pipeline.Pipelineの一部として）。</target>
        </trans-unit>
        <trans-unit id="b88ebf81bb1a4e07e575709aa3160fcbaf33439c" translate="yes" xml:space="preserve">
          <source>Performs robust standardization that removes the influence of outliers but does not put outliers and inliers on the same scale.</source>
          <target state="translated">外れ値の影響を除去するロバストな標準化を実行しますが、外れ値と外れ値を同じ尺度に置かないようにします。</target>
        </trans-unit>
        <trans-unit id="269796266e3e34d93d181d30bdc48e574f3c9af7" translate="yes" xml:space="preserve">
          <source>Performs scaling to a given range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して、指定された範囲へのスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="bd68fa80cce73218da8c0d7af21a3e3a79fd9429" translate="yes" xml:space="preserve">
          <source>Performs scaling to the [-1, 1] range using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して[-1、1]範囲へのスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="a6c272533c048656769d2922baf310f99127bfa0" translate="yes" xml:space="preserve">
          <source>Performs scaling to unit variance using the``Transformer`` API (e.g. as part of a preprocessing &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">`` Transformer`` APIを使用して単位分散へのスケーリングを実行します（たとえば、前処理&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;一部として）。</target>
        </trans-unit>
        <trans-unit id="ac7c14a68907c3e1c4fe02a23cc6348fd68ae158" translate="yes" xml:space="preserve">
          <source>Performs standardization that is faster, but less robust to outliers.</source>
          <target state="translated">標準化を実行することで、より高速になりますが、外れ値にはあまりロバストではありません。</target>
        </trans-unit>
        <trans-unit id="1607c75c65b63f50e007f7f133bc5dda8dc230b2" translate="yes" xml:space="preserve">
          <source>Performs the TF-IDF transformation from a provided matrix of counts.</source>
          <target state="translated">指定されたカウントの行列からTF-IDF変換を行います。</target>
        </trans-unit>
        <trans-unit id="d1ac21bb0cdcd78e01860cf682da905f50be135c" translate="yes" xml:space="preserve">
          <source>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</source>
          <target state="translated">データが生成された真のモデルによってその仮定が多少破られていても、十分な性能を発揮します。</target>
        </trans-unit>
        <trans-unit id="692363e79545ccc206eddd0f61af20f5fd6d3794" translate="yes" xml:space="preserve">
          <source>Permutation Importance vs Random Forest Feature Importance (MDI)</source>
          <target state="translated">並べ替え重要度とランダムフォレスト特徴重要度(MDI)の比較</target>
        </trans-unit>
        <trans-unit id="2dbaba5e5cc669da918a57d2be9cb7dc2cc9dadb" translate="yes" xml:space="preserve">
          <source>Permutation Importance with Multicollinear or Correlated Features</source>
          <target state="translated">多重共線または相関のある特徴を持つ並べ替えの重要度</target>
        </trans-unit>
        <trans-unit id="9a4bc8d95c0343a8677dd56e966704c1868adf4a" translate="yes" xml:space="preserve">
          <source>Permutation feature importance is a model inspection technique that can be used for any &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;fitted&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; when the data is tabular. This is especially useful for non-linear or opaque &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt;. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.</source>
          <target state="translated">順列特徴の重要性は、データが表形式である場合に、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fitted&quot;&gt;適合した&lt;/a&gt;&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;推定量&lt;/a&gt;に使用できるモデル検査手法です。これは、非線形または不透明な&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;推定量に&lt;/a&gt;特に役立ちます。順列特徴の重要性は、単一の特徴値がランダムにシャッフルされたときのモデルスコアの減少として定義されます&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;。この手順により、フィーチャとターゲットの関係が壊れます。したがって、モデルスコアの低下は、モデルがフィーチャにどの程度依存しているかを示します。この手法は、モデルにとらわれないという利点があり、機能のさまざまな順列を使用して何度も計算できます。</target>
        </trans-unit>
        <trans-unit id="3fc1a156ae6d2a8be8ad1b31632c3738303816a9" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;.</source>
          <target state="translated">機能評価のための順列の重要性&lt;a href=&quot;#rd9e56ef97513-bre&quot; id=&quot;id1&quot;&gt;[BRE]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="dcae56d3241bbe2509401411f131fd455126611a" translate="yes" xml:space="preserve">
          <source>Permutation importance for feature evaluation &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;.</source>
          <target state="translated">機能評価のための順列の重要性&lt;a href=&quot;generated/sklearn.inspection.permutation_importance#rd9e56ef97513-bre&quot; id=&quot;id2&quot;&gt;[Rd9e56ef97513-BRE]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0604878bcce5e380bc3c27303af860b5876e2620" translate="yes" xml:space="preserve">
          <source>Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.</source>
          <target state="translated">並べ替えのインポータンスは、訓練セット、またはホールドアウトされたテストセットまたは検証セットのいずれかで計算できる。ホールドアウト・セットを使用することで、検査されたモデルの一般化力に最も寄与する特徴を強調することができます。トレーニング・セットでは重要でホールドアウト・セットでは重要でない特徴は、モデルがオーバーフィットする原因となることがあります。</target>
        </trans-unit>
        <trans-unit id="ff7711423fb41bb0ca16132a11855fff8a63fa44" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importance</source>
          <target state="translated">パーミュテーションに基づく特徴の重要性</target>
        </trans-unit>
        <trans-unit id="2babb881bd9df0cbbe32387aebb8f1fc14de7576" translate="yes" xml:space="preserve">
          <source>Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed performance metric on the model predictions predictions and can be used to analyze any model class (not just tree-based models).</source>
          <target state="translated">順列に基づく特徴の重要度は、そのようなバイアスを示さない。さらに、並べ替えに基づく特徴の重要度は、モデルの予測予測に対して計算された性能指標であり、任意のモデルクラス(ツリーベースのモデルだけでなく)の分析に使用することができます。</target>
        </trans-unit>
        <trans-unit id="1a9a31609b061b9c4c3ea5164d451f2cf664e34b" translate="yes" xml:space="preserve">
          <source>Perplexity is defined as exp(-1. * log-likelihood per word)</source>
          <target state="translated">錯乱度は exp(-1.*単語あたりの対数尤度)として定義されます。</target>
        </trans-unit>
        <trans-unit id="80863d8aea17a1c5fba5bee33e10fcfe3c3b5254" translate="yes" xml:space="preserve">
          <source>Perplexity score.</source>
          <target state="translated">錯乱のスコア。</target>
        </trans-unit>
        <trans-unit id="25e7450397b385690390d4cb490d54af7bb7f613" translate="yes" xml:space="preserve">
          <source>Perplexity tolerance in batch learning. Only used when &lt;code&gt;evaluate_every&lt;/code&gt; is greater than 0.</source>
          <target state="translated">バッチ学習における複雑さの許容度。 &lt;code&gt;evaluate_every&lt;/code&gt; が0より大きい場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="bed69aed128c6d53c076bf23b1786ba34af67dfd" translate="yes" xml:space="preserve">
          <source>Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.</source>
          <target state="translated">Persistent Contrastive Divergenceはこれに対応しています。勾配が必要とされるたびに新しいチェーンを開始し、ギブスサンプリングステップを1回だけ実行する代わりに、PCDでは、各ウェイトの更新後にギブスステップを更新するチェーン(ファンタジーパーティクル)をいくつか保持します。これにより、粒子は空間をより徹底的に探索することができる。</target>
        </trans-unit>
        <trans-unit id="d4d9d12e88278335e6c824e88af73f55a763004e" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti,Robust Statistics Concomitant scale estimates,pg 172</target>
        </trans-unit>
        <trans-unit id="977cdb0f1102753846469a4e3ab78497c359fae5" translate="yes" xml:space="preserve">
          <source>Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, pg 172</source>
          <target state="translated">Peter J.Huber,Helvetius M.Ronchetti:Robust Statistics,Concomitant scale estimates,pg 172</target>
        </trans-unit>
        <trans-unit id="f869e193262fa2d8e1a9ddde0485aa49aaa656aa" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53&amp;ndash;65. &lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi:10.1016/0377-0427(87)90125-7&lt;/a&gt;.</source>
          <target state="translated">Peter J. Rousseeuw（1987）。「シルエット：クラスター分析の解釈と検証に対するグラフィカル支援」。計算および応用数学20：53&amp;ndash;65。&lt;a href=&quot;https://doi.org/10.1016/0377-0427(87)90125-7&quot;&gt;doi：10.1016 / 0377-0427（87）90125-7&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="801ff1e5ba061302f2ef13b831a12ef30f616d52" translate="yes" xml:space="preserve">
          <source>Peter J. Rousseeuw (1987). &amp;ldquo;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&amp;rdquo;. Computational and Applied Mathematics 20: 53-65.</source>
          <target state="translated">Peter J. Rousseeuw（1987）。「シルエット：クラスター分析の解釈と検証に対するグラフィカル支援」。計算および応用数学20：53-65。</target>
        </trans-unit>
        <trans-unit id="6884db0930152b7581421b9e7df37cdc709bc0ae" translate="yes" xml:space="preserve">
          <source>Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.</source>
          <target state="translated">ツリーのピックルとアンピックル。ツリーの状態は pickle 操作で保存されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="4a6d28315bc21af0edd71a7862fc9db5f7a4917f" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">Ping Li、T。HastieおよびKW Church、2006年、「Very Sparse Random Projections」。&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fb3d4adf8ec429eb640cc1eefb0227abf08a6683" translate="yes" xml:space="preserve">
          <source>Ping Li, T. Hastie and K. W. Church, 2006, &amp;ldquo;Very Sparse Random Projections&amp;rdquo;. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</source>
          <target state="translated">Ping Li、T。HastieおよびKW Church、2006年、「Very SparseRandomProjections」。&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3462e562173cab76115a1fabd23d03498a615dda" translate="yes" xml:space="preserve">
          <source>Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;Very sparse random projections.&lt;/a&gt; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD &amp;lsquo;06). ACM, New York, NY, USA, 287-296.</source>
          <target state="translated">Ping Li、Trevor J. Hastie、およびKenneth W. Church。2006. &lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf&quot;&gt;非常にまばらなランダム予測。&lt;/a&gt;第12回ACM SIGKDD国際会議のプロシーディングスで、知識の発見とデータマイニング（KDD '06）。ACM、ニューヨーク、ニューヨーク、アメリカ、287-296。</target>
        </trans-unit>
        <trans-unit id="32b1d5a78493496dd5152fd2d504f7e21009e3f2" translate="yes" xml:space="preserve">
          <source>Pipeline</source>
          <target state="translated">Pipeline</target>
        </trans-unit>
        <trans-unit id="5fcec2c4630ab50971732249756f691f50ae9f29" translate="yes" xml:space="preserve">
          <source>Pipeline Anova SVM</source>
          <target state="translated">パイプライン Anova SVM</target>
        </trans-unit>
        <trans-unit id="a041187d94eb589a1ba5ff98293ef896e00c97e7" translate="yes" xml:space="preserve">
          <source>Pipeline of transforms with a final estimator.</source>
          <target state="translated">最終推定器を用いた変換のパイプライン。</target>
        </trans-unit>
        <trans-unit id="b728ae3e883ea99a9d120fc06880b19e80fef86a" translate="yes" xml:space="preserve">
          <source>Pipeline&amp;rsquo;s &lt;code&gt;named_steps&lt;/code&gt; attribute allows accessing steps by name with tab completion in interactive environments:</source>
          <target state="translated">Pipelineの &lt;code&gt;named_steps&lt;/code&gt; 属性を使用すると、インタラクティブ環境でタブ補完を使用して名前でステップにアクセスできます。</target>
        </trans-unit>
        <trans-unit id="73de4ddfaf9a511a59191faaa0679d43b9d9c3eb" translate="yes" xml:space="preserve">
          <source>Pipelines and composite estimators</source>
          <target state="translated">パイプラインと複合見積もり</target>
        </trans-unit>
        <trans-unit id="52761af283a0d9e614a4e2ba9d4a353d3fd70a7b" translate="yes" xml:space="preserve">
          <source>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.</source>
          <target state="translated">パイプラインは、トランスフォーマと予測子の訓練に同じサンプルが使用されることを保証することで、クロスバリデーションにおいて、テストデータから訓練されたモデルへの統計量の漏れを防ぐのに役立つ。</target>
        </trans-unit>
        <trans-unit id="3d31223cfe1830200469a76812f595efba107474" translate="yes" xml:space="preserve">
          <source>Pipelining</source>
          <target state="translated">Pipelining</target>
        </trans-unit>
        <trans-unit id="04ae27026f61a0e2fe9396849cac7271f4f56e69" translate="yes" xml:space="preserve">
          <source>Pipelining: chaining a PCA and a logistic regression</source>
          <target state="translated">パイプライン:PCAとロジスティック回帰の連結</target>
        </trans-unit>
        <trans-unit id="4d2bb7a399ca2f416aedb250a1c02b6dbddd98f5" translate="yes" xml:space="preserve">
          <source>Pixel importances with a parallel forest of trees</source>
          <target state="translated">並木の森でのピクセルインポータンス</target>
        </trans-unit>
        <trans-unit id="2ca4493c014c6673344a97eb7b5e5aaa17897b68" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">プラット&lt;a href=&quot;http://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;「SVMの確率的出力と正則化された尤度法との比較」&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="94b48515f27c2ba66dc001876eed954b37962189" translate="yes" xml:space="preserve">
          <source>Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;&amp;ldquo;Probabilistic outputs for SVMs and comparisons to regularized likelihood methods&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">Platt &lt;a href=&quot;https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf&quot;&gt;「SVMの確率的出力と正則化された尤度法との比較」&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="6cd3fc864a17260622e839224271f277841ca1af" translate="yes" xml:space="preserve">
          <source>Platt&amp;rsquo;s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set &lt;code&gt;probability=False&lt;/code&gt; and use &lt;code&gt;decision_function&lt;/code&gt; instead of &lt;code&gt;predict_proba&lt;/code&gt;.</source>
          <target state="translated">プラットの方法には理論的な問題があることも知られています。信頼スコアが必要であるが、これらが確率である必要がない場合は、 &lt;code&gt;probability=False&lt;/code&gt; を設定し、 &lt;code&gt;predict_proba&lt;/code&gt; の代わりに &lt;code&gt;decision_function&lt;/code&gt; を使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="70c63a8d9604c9bbaac5b8d8c1c0f788b01f994f" translate="yes" xml:space="preserve">
          <source>Platt, John (1999). &amp;ldquo;Probabilistic outputs for support vector machines and comparison to regularizedlikelihood methods.&amp;rdquo;</source>
          <target state="translated">プラット、ジョン（1999）。「サポートベクターマシンの確率的出力と正規化された可能性の方法との比較。」</target>
        </trans-unit>
        <trans-unit id="0765f4dfcff27a39498ebd734357c5eb178852a5" translate="yes" xml:space="preserve">
          <source>Please note that in this example the data is non-noisy, hence it is possible to extract the exact coefficients.</source>
          <target state="translated">この例では、データが非ノイズであるため、正確な係数を抽出することが可能であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="d5ef05af023849c89b4ecfb2ae2cb84ee4a80076" translate="yes" xml:space="preserve">
          <source>Please note that scikit-learn has no direct control over these implementations. Scikit-learn solely relies on Numpy and Scipy.</source>
          <target state="translated">scikit-learnはこれらの実装を直接制御していないことに注意してください。Scikit-learnはNumpyとScipyのみに依存しています。</target>
        </trans-unit>
        <trans-unit id="60f5c599778dc38cb8638a819c878af82379b06d" translate="yes" xml:space="preserve">
          <source>Please note that the dataset here is not large enough to show the benefits of kernel approximation, as the exact SVM is still reasonably fast.</source>
          <target state="translated">ここのデータセットはカーネル近似の利点を示すには十分な大きさではないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="bd47c9cedab12c75fd43c458d1842b3e68fe1e8f" translate="yes" xml:space="preserve">
          <source>Please note that when &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; and &lt;code&gt;n_classes &amp;gt; 2&lt;/code&gt;, unlike &lt;code&gt;decision_function&lt;/code&gt;, the &lt;code&gt;predict&lt;/code&gt; method does not try to break ties by default. You can set &lt;code&gt;break_ties=True&lt;/code&gt; for the output of &lt;code&gt;predict&lt;/code&gt; to be the same as &lt;code&gt;np.argmax(clf.decision_function(...), axis=1)&lt;/code&gt;, otherwise the first class among the tied classes will always be returned; but have in mind that it comes with a computational cost. See &lt;a href=&quot;../auto_examples/svm/plot_svm_tie_breaking#sphx-glr-auto-examples-svm-plot-svm-tie-breaking-py&quot;&gt;SVM Tie Breaking Example&lt;/a&gt; for an example on tie breaking.</source>
          <target state="translated">ときがありますのでご注意ください &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; と &lt;code&gt;n_classes &amp;gt; 2&lt;/code&gt; とは異なり &lt;code&gt;decision_function&lt;/code&gt; 、 &lt;code&gt;predict&lt;/code&gt; 方法は、デフォルトではネクタイを破るしようとしません。 &lt;code&gt;predict&lt;/code&gt; の出力が &lt;code&gt;np.argmax(clf.decision_function(...), axis=1)&lt;/code&gt; と同じになるように &lt;code&gt;break_ties=True&lt;/code&gt; を設定できます。そうしないと、結合されたクラスの最初のクラスが常に返されます。ただし、計算コストがかかることを覚えておいてください。&lt;a href=&quot;../auto_examples/svm/plot_svm_tie_breaking#sphx-glr-auto-examples-svm-plot-svm-tie-breaking-py&quot;&gt;タイブレークの例&lt;/a&gt;については、SVMタイブレークの例を参照してください。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
