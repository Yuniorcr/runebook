<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="7c9f9f5dcfc8aebd4eea110198ededa32c4b1278" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">推定器のフィッティングでエラーが発生した場合にスコアに割り当てる値。「raise」に設定すると、エラーが発生します。数値を指定すると、FitFailedWarningが発生します。このパラメータは、常にエラーを発生させる再フィットステップには影響しません。デフォルトは「raise」ですが、バージョン0.22からnp.nanに変更されます。</target>
        </trans-unit>
        <trans-unit id="51fe27463b1bbffac6c175b98fff3a09a8ef007a" translate="yes" xml:space="preserve">
          <source>Value to assign to the score if an error occurs in estimator fitting. If set to &amp;lsquo;raise&amp;rsquo;, the error is raised. If set to &amp;lsquo;raise-deprecating&amp;rsquo;, a FutureWarning is printed before the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error. Default is &amp;lsquo;raise-deprecating&amp;rsquo; but from version 0.22 it will change to np.nan.</source>
          <target state="translated">推定器のフィッティングでエラーが発生した場合にスコアに割り当てる値。「raise」に設定すると、エラーが発生します。「raise-deprecating」に設定すると、エラーが発生する前にFutureWarningが出力されます。数値を指定すると、FitFailedWarningが発生します。このパラメータは、常にエラーを発生させる再フィットステップには影響しません。デフォルトは「raise-deprecating」ですが、バージョン0.22からnp.nanに変更されます。</target>
        </trans-unit>
        <trans-unit id="402a4cfb84a22d3670431b1576518e6587de93b8" translate="yes" xml:space="preserve">
          <source>Value to use for the dummy feature.</source>
          <target state="translated">ダミー機能に使用する値</target>
        </trans-unit>
        <trans-unit id="82321dd8f607145fb8d2875c3e367d82d45dfc71" translate="yes" xml:space="preserve">
          <source>Value with which negative labels must be encoded.</source>
          <target state="translated">負のラベルがエンコードされなければならない値。</target>
        </trans-unit>
        <trans-unit id="4e0758fceaa4f106e89501aa7c196eea7d1ad1c2" translate="yes" xml:space="preserve">
          <source>Value with which positive labels must be encoded.</source>
          <target state="translated">正のラベルがエンコードされなければならない値。</target>
        </trans-unit>
        <trans-unit id="ca5e1888f7ff9f4679a3377b455596a48d014681" translate="yes" xml:space="preserve">
          <source>ValueError</source>
          <target state="translated">ValueError</target>
        </trans-unit>
        <trans-unit id="6a7ed2e67e56dace630120ac5c7bd01e4d032523" translate="yes" xml:space="preserve">
          <source>Values greater than the threshold map to 1, while values less than or equal to the threshold map to 0. With the default threshold of 0, only positive values map to 1.</source>
          <target state="translated">しきい値より大きい値は 1 にマップされ、しきい値以下の値は 0 にマップされます。 デフォルトのしきい値 0 では、正の値のみが 1 にマップされます。</target>
        </trans-unit>
        <trans-unit id="0a659f48fb09b2c2dd949774cc3bd6b7ffd6fd87" translate="yes" xml:space="preserve">
          <source>Values in each bin have the same nearest center of a 1D k-means cluster.</source>
          <target state="translated">各ビンの値は、1次元のk-meansクラスターの同じ最近接中心を持つ。</target>
        </trans-unit>
        <trans-unit id="c67d763b94a97115ba7ee9d49115a272cb508cf6" translate="yes" xml:space="preserve">
          <source>Values of n_samples samples drawn from Gaussian process and evaluated at query points.</source>
          <target state="translated">ガウス過程から引き出されたn_samplesサンプルの値で、クエリポイントで評価されます。</target>
        </trans-unit>
        <trans-unit id="1cd1b62dfd3b6a63572d1bf631789bd088451d1d" translate="yes" xml:space="preserve">
          <source>Values of the visible layer after one Gibbs step.</source>
          <target state="translated">ギブスステップ後の可視レイヤーの値。</target>
        </trans-unit>
        <trans-unit id="c9500aef779ad4ab4355590ca05b9c0de0aa083a" translate="yes" xml:space="preserve">
          <source>Values of the visible layer to start from.</source>
          <target state="translated">開始する可視レイヤーの値。</target>
        </trans-unit>
        <trans-unit id="d9ca5115511a5b00d878e1de5b9daa8f530b632c" translate="yes" xml:space="preserve">
          <source>Values of the visible layer. Must be all-boolean (not checked).</source>
          <target state="translated">可視レイヤーの値。全ブーリアンでなければなりません(チェックしていません)。</target>
        </trans-unit>
        <trans-unit id="35e8d31773dfd80568909d00a3100d73e50de4e1" translate="yes" xml:space="preserve">
          <source>Values predicted by each regressor.</source>
          <target state="translated">各回帰子によって予測された値。</target>
        </trans-unit>
        <trans-unit id="445d09e482944669dc8a6e893591f45bda28254b" translate="yes" xml:space="preserve">
          <source>Vanschoren, van Rijn, Bischl and Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;&amp;ldquo;OpenML: networked science in machine learning&amp;rdquo;&lt;/a&gt;, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014.</source>
          <target state="translated">Vanschoren、van Rijn、Bischl、Torgo &lt;a href=&quot;https://arxiv.org/pdf/1407.7722.pdf&quot;&gt;「OpenML：networked science in machine learning」&lt;/a&gt;、ACM SIGKDD Explorations Newsletter、15（2）、49-60、2014。</target>
        </trans-unit>
        <trans-unit id="ba47c39bbafea14cc75438e6420272a547d1a3e3" translate="yes" xml:space="preserve">
          <source>Variance explained by each of the selected components.</source>
          <target state="translated">選択された各成分によって説明される分散。</target>
        </trans-unit>
        <trans-unit id="17b5cb397e6ad9830d59b5fc66bebb45024c7ef4" translate="yes" xml:space="preserve">
          <source>Variances of individual features.</source>
          <target state="translated">個々の特徴のバリエーション。</target>
        </trans-unit>
        <trans-unit id="7933f72bf76c6cfbc1dde87498522f5e833878e6" translate="yes" xml:space="preserve">
          <source>Variational Bayesian estimation of a Gaussian mixture.</source>
          <target state="translated">ガウス混合物の変分ベイズ推定.</target>
        </trans-unit>
        <trans-unit id="e459652719d6e0edf38bb3c9f14dba040888c62f" translate="yes" xml:space="preserve">
          <source>Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.</source>
          <target state="translated">変分推論は、データの尤度の代わりにモデルの証拠(プリオールを含む)の下限を最大化する期待最大化の拡張である。変分法の背後にある原理は、期待値最大化と同じです(つまり、どちらも、各混合物によって生成される各点の確率を見つけることと、これらの割り当てられた点に混合物を適合させることを交互に行う反復アルゴリズムです)が、変分法では、事前分布からの情報を統合することによって正則化を追加します。これは、期待値最大化解でよく見られる特異点を回避しますが、モデルに微妙なバイアスを導入します。推論はしばしば顕著に遅くなりますが、通常は実用的でないほどではありません。</target>
        </trans-unit>
        <trans-unit id="009e019794c4b5a288d65b8e0eabe9064e298c81" translate="yes" xml:space="preserve">
          <source>Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the &amp;ldquo;true&amp;rdquo; number of components, affects only algorithmic complexity, not the actual number of components used).</source>
          <target state="translated">ディリクレプロセスの変分推論手法は、この無限混合モデルの有限近似でも機能しますが、使用したい成分の数を事前に指定する代わりに、濃度パラメーターと混合数の上限を指定するだけです。コンポーネント（この上限は、コンポーネントの「真の」数よりも多いと想定すると、アルゴリズムの複雑さだけに影響し、使用されるコンポーネントの実際の数には影響しません）。</target>
        </trans-unit>
        <trans-unit id="bfc42eb1bb86ce5f62b086e9ffd3c67a080b0730" translate="yes" xml:space="preserve">
          <source>Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, &lt;code&gt;components_[i, j]&lt;/code&gt; can be viewed as pseudocount that represents the number of times word &lt;code&gt;j&lt;/code&gt; was assigned to topic &lt;code&gt;i&lt;/code&gt;. It can also be viewed as distribution over the words for each topic after normalization: &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt;.</source>
          <target state="translated">トピックの単語分布の変分パラメーター。トピックの単語分布の完全な条件はディリクレであるため、 &lt;code&gt;components_[i, j]&lt;/code&gt; は、単語 &lt;code&gt;j&lt;/code&gt; がトピック &lt;code&gt;i&lt;/code&gt; に割り当てられた回数を表す疑似カウントと見なすことができます。また、正規化後の各トピックの単語の分布として表示することもできます： &lt;code&gt;model.components_ / model.components_.sum(axis=1)[:, np.newaxis]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="65cb8d21f19957f8f56d7ec3aeccadf0c1efbc6f" translate="yes" xml:space="preserve">
          <source>Various Agglomerative Clustering on a 2D embedding of digits</source>
          <target state="translated">桁の二次元埋め込みにおける多様な凝集クラスタリング</target>
        </trans-unit>
        <trans-unit id="ddbf21d472ec4b83f538c33f12eb263b69f44ca0" translate="yes" xml:space="preserve">
          <source>Various improvements were made to &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. On top of the Poisson loss mentionned above, these estimators now support &lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;sample weights&lt;/a&gt;. Also, an automatic early-stopping criterion was added: early-stopping is enabled by default when the number of samples exceeds 10k. Finally, users can now define &lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;monotonic constraints&lt;/a&gt; to constrain the predictions based on the variations of specific features. In the following example, we construct a target that is generally positively correlated with the first feature, with some noise. Applying monotoinc constraints allows the prediction to capture the global effect of the first feature, instead of fitting the noise.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; に&lt;/a&gt;さまざまな改善が加えられました。上記のポアソン損失に加えて、これらの推定量は&lt;a href=&quot;../../modules/ensemble#sw-hgbdt&quot;&gt;サンプルの重みを&lt;/a&gt;サポートするようになりました。また、自動早期停止基準が追加されました。サンプル数が10kを超えると、デフォルトで早期停止が有効になります。最後に、ユーザーは&lt;a href=&quot;../../modules/ensemble#monotonic-cst-gbdt&quot;&gt;単調な制約&lt;/a&gt;を定義して、特定の機能のバリエーションに基づいて予測を制約できるようになりました。次の例では、最初の特徴と一般的に正の相関があり、ノイズがいくらかあるターゲットを作成します。モノトインク制約を適用すると、ノイズをフィッティングする代わりに、予測で最初の特徴のグローバル効果をキャプチャできます。</target>
        </trans-unit>
        <trans-unit id="b1e276370580ceeca94d9a25d3b75abf89a69938" translate="yes" xml:space="preserve">
          <source>Varying regularization in Multi-layer Perceptron</source>
          <target state="translated">多層パーセプトロンにおける可変正則化</target>
        </trans-unit>
        <trans-unit id="1e178759402bc070ae202c1ae1b1666da0dd6a9c" translate="yes" xml:space="preserve">
          <source>Vector Quantization Example</source>
          <target state="translated">ベクトル量子化の例</target>
        </trans-unit>
        <trans-unit id="ba8b3829eecac2c5ad85a64a161b0e7f2fae54cf" translate="yes" xml:space="preserve">
          <source>Vector of errors at each iteration.</source>
          <target state="translated">各反復時のエラーのベクトル.</target>
        </trans-unit>
        <trans-unit id="4e8912fa819c195ed09c153115c88939fa1f2e3c" translate="yes" xml:space="preserve">
          <source>Vector to be scored, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">スコアリングされるベクトル。ここで、 &lt;code&gt;n_samples&lt;/code&gt; はサンプルの数、 &lt;code&gt;n_features&lt;/code&gt; は特徴の数です。</target>
        </trans-unit>
        <trans-unit id="cf31e021601b7cdd3aba8ca6f6502b2543cdeb94" translate="yes" xml:space="preserve">
          <source>VehAge</source>
          <target state="translated">VehAge</target>
        </trans-unit>
        <trans-unit id="ea3a474961d1b758addd0978141f5ebc1f6f2b70" translate="yes" xml:space="preserve">
          <source>VehBrand</source>
          <target state="translated">VehBrand</target>
        </trans-unit>
        <trans-unit id="fda6c72b6cabb64878498cd55268cca04e8d770b" translate="yes" xml:space="preserve">
          <source>VehGas</source>
          <target state="translated">VehGas</target>
        </trans-unit>
        <trans-unit id="9e0c38e996b000566fa359d3ed449ba796915a3e" translate="yes" xml:space="preserve">
          <source>VehPower</source>
          <target state="translated">VehPower</target>
        </trans-unit>
        <trans-unit id="93c6f0903309fd539ceb7d4710cf07f7db8cb1d8" translate="yes" xml:space="preserve">
          <source>Verbose mode when fitting the model.</source>
          <target state="translated">モデルのフィッティングを行う際にVerboseモードを使用します。</target>
        </trans-unit>
        <trans-unit id="ee5731f921bfe2d1197cd007f006306ad3328112" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations.</source>
          <target state="translated">PD計算中に冗長な出力を行います。</target>
        </trans-unit>
        <trans-unit id="eeb343db47ab9124ef417c41d9bdb92839772dc0" translate="yes" xml:space="preserve">
          <source>Verbose output during PD computations. Defaults to 0.</source>
          <target state="translated">PD計算中に冗長な出力を出力します。デフォルトは0です。</target>
        </trans-unit>
        <trans-unit id="65d3f9d357c8217e4b4161cc31c9983e755e9511" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated.</source>
          <target state="translated">Verbosity フラグは、関数が評価される際に発行されるデバッグメッセージを制御します。</target>
        </trans-unit>
        <trans-unit id="66d100e92da285b9102a10ebf1825a4d7ce2d91c" translate="yes" xml:space="preserve">
          <source>Verbosity flag, controls the debug messages that are issued as functions are evaluated. The higher, the more verbose. Can be 0, 1, or 2.</source>
          <target state="translated">Verbosity フラグは、関数が評価されたときに発行されるデバッグメッセージを制御します。高いほど冗長になります。0、1、または 2 を指定できます。</target>
        </trans-unit>
        <trans-unit id="a606460a9db19f2456900341e545d542d386dcd0" translate="yes" xml:space="preserve">
          <source>Verbosity level.</source>
          <target state="translated">冗長性のレベル。</target>
        </trans-unit>
        <trans-unit id="9cadb350a887ea26b759cec53fba259b94be0b70" translate="yes" xml:space="preserve">
          <source>Verbosity level. Setting verbose &amp;gt; 0 will display additional information depending on the solver used.</source>
          <target state="translated">冗長レベル。verbose&amp;gt; 0に設定すると、使用するソルバーに応じて追加情報が表示されます。</target>
        </trans-unit>
        <trans-unit id="c09635f4883cd7798a06597eead68509e08bef52" translate="yes" xml:space="preserve">
          <source>Verbosity mode.</source>
          <target state="translated">冗長モード。</target>
        </trans-unit>
        <trans-unit id="4ee9c427e0cc678ca91bc7294708dc43db03512b" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#gp-kernels&quot;&gt;kernels&lt;/a&gt; can be specified. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">汎用性：異なる&lt;a href=&quot;#gp-kernels&quot;&gt;カーネル&lt;/a&gt;を指定できます。共通のカーネルが提供されていますが、カスタムカーネルを指定することもできます。</target>
        </trans-unit>
        <trans-unit id="4b16fac84e3102257e26d97dc6bcc2775a76c275" translate="yes" xml:space="preserve">
          <source>Versatile: different &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</source>
          <target state="translated">汎用性：意思決定関数にさまざまな&lt;a href=&quot;#svm-kernels&quot;&gt;カーネル関数&lt;/a&gt;を指定できます。共通のカーネルが提供されていますが、カスタムカーネルを指定することもできます。</target>
        </trans-unit>
        <trans-unit id="102caab3d934ebf62d9240e41edbdfb96ec830ff" translate="yes" xml:space="preserve">
          <source>Version of the dataset. Can only be provided if also &lt;code&gt;name&lt;/code&gt; is given. If &amp;lsquo;active&amp;rsquo; the oldest version that&amp;rsquo;s still active is used. Since there may be more than one active version of a dataset, and those versions may fundamentally be different from one another, setting an exact version is highly recommended.</source>
          <target state="translated">データセットのバージョン。 &lt;code&gt;name&lt;/code&gt; も指定されている場合にのみ提供できます。「アクティブ」の場合、まだアクティブな最も古いバージョンが使用されます。データセットには複数のアクティブなバージョンがあり、それらのバージョンは根本的に異なる可能性があるため、正確なバージョンを設定することを強くお勧めします。</target>
        </trans-unit>
        <trans-unit id="2d0ab9e3d9a896817cdfc684c77fbf9f0c4f1aac" translate="yes" xml:space="preserve">
          <source>Version: RCV1-v2, vectors, full sets, topics multilabels.</source>
          <target state="translated">バージョン.RCV1-v2,ベクトル,フルセット,トピックマルチラベル.</target>
        </trans-unit>
        <trans-unit id="dfb46f94f7d77a5ddeabfd408748577e450d338b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">非常に大きな &lt;code&gt;n_samples&lt;/code&gt; 、大きな &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3496b8ff284f2499d5b89bafe815a9579d5a779b" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;</source>
          <target state="translated">非常に大きい &lt;code&gt;n_samples&lt;/code&gt; 、中程度の &lt;code&gt;n_clusters&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90edfe52a065a045edbdd25bf2f2316a234658ac" translate="yes" xml:space="preserve">
          <source>Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with &lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatch code&lt;/a&gt;</source>
          <target state="translated">非常に大きい &lt;code&gt;n_samples&lt;/code&gt; 、中程度の &lt;code&gt;n_clusters&lt;/code&gt; 、&lt;a href=&quot;#mini-batch-kmeans&quot;&gt;MiniBatchコード&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="56b71e89fb1079caaadefd0889e9a22e8b0560e3" translate="yes" xml:space="preserve">
          <source>Videos</source>
          <target state="translated">Videos</target>
        </trans-unit>
        <trans-unit id="644cc701dadc9ddd9912f1b11b35ead35737260b" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method &lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh etal。（2010）平均化方法&lt;a href=&quot;#veb2010&quot; id=&quot;id15&quot;&gt;[VEB2010]&lt;/a&gt;によってNMIとAMIのバリアントに名前を付けました。それらの「sqrt」および「sum」平均は、幾何学的および算術平均です。これらのより広く一般的な名前を使用します。</target>
        </trans-unit>
        <trans-unit id="f74a22805e87ed187a5bf75da0c74d88f9fc4e05" translate="yes" xml:space="preserve">
          <source>Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their &amp;lsquo;sqrt&amp;rsquo; and &amp;lsquo;sum&amp;rsquo; averages are the geometric and arithmetic means; we use these more broadly common names.</source>
          <target state="translated">Vinh et al。（2010）NMIとAMIの名前付きバリアントは、それらの平均方法[VEB2010]によって。それらの 'sqrt'および 'sum'平均は、幾何学的および算術平均です。これらのより一般的な名前を使用します。</target>
        </trans-unit>
        <trans-unit id="3e1bb17ff94c0af1df416cfea07d80b830f06013" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">Vinh、Epps、およびBailey、（2009）。「クラスタリング比較のための情報理論的尺度」。機械学習に関する第26回年次国際会議の議事録-ICML'09。&lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi：10.1145 /1553374.1553511&lt;/a&gt;。ISBN9781605585161。</target>
        </trans-unit>
        <trans-unit id="aa05fa0b125b1736672a1d80de8273f7659ae9f5" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">Vinh、Epps、およびBailey、（2010）。「クラスタリング比較のための情報理論的尺度：バリアント、プロパティ、正規化、およびチャンスの修正」。JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="40fdfddfc4699e8e891d021e6ce4e4252243f9c7" translate="yes" xml:space="preserve">
          <source>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR</source>
          <target state="translated">Vinh,Epps,and Bailey,(2010).クラスタリング比較のための情報理論的尺度.バリアント、特性、正規化と偶然性の補正,JMLR</target>
        </trans-unit>
        <trans-unit id="64eeb8915eff8290b0627c8aa96dd46ee4bda6f1" translate="yes" xml:space="preserve">
          <source>Visualise your tree as you are training by using the &lt;code&gt;export&lt;/code&gt; function. Use &lt;code&gt;max_depth=3&lt;/code&gt; as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.</source>
          <target state="translated">&lt;code&gt;export&lt;/code&gt; 機能を使用して、トレーニングしながらツリーを視覚化します。 &lt;code&gt;max_depth=3&lt;/code&gt; を初期ツリーの深さとして使用して、ツリーがデータにどのように適合しているかの感触をつかみ、深さを増やします。</target>
        </trans-unit>
        <trans-unit id="d175985b87dd9f620aa960059c730b4a35e3bcb5" translate="yes" xml:space="preserve">
          <source>Visualization</source>
          <target state="translated">Visualization</target>
        </trans-unit>
        <trans-unit id="38623835e09f3cd243cdf966707dad9de4ecfeda" translate="yes" xml:space="preserve">
          <source>Visualization of MLP weights on MNIST</source>
          <target state="translated">MNIST上でのMLP重みの可視化</target>
        </trans-unit>
        <trans-unit id="a291ff40a157c9afd67fb01fd3c6b6d368d78978" translate="yes" xml:space="preserve">
          <source>Visualization of predictions obtained from different models.</source>
          <target state="translated">異なるモデルから得られた予測値の可視化。</target>
        </trans-unit>
        <trans-unit id="94a741e26bd8d9bfdacbab90c67da4753dcabca8" translate="yes" xml:space="preserve">
          <source>Visualizations with Display Objects</source>
          <target state="translated">表示オブジェクトを使った可視化</target>
        </trans-unit>
        <trans-unit id="a6c65fa336dc53edc04e670583358fb288a99997" translate="yes" xml:space="preserve">
          <source>Visualize cross-validation indices for many CV objects</source>
          <target state="translated">多くのCVオブジェクトのクロスバリデーションインデックスを可視化する</target>
        </trans-unit>
        <trans-unit id="4a2bddc914855cb9100c33fc5e346e89e1926136" translate="yes" xml:space="preserve">
          <source>Visualize our data</source>
          <target state="translated">データの可視化</target>
        </trans-unit>
        <trans-unit id="28ba2de8813583360eb0588f62cb6dc19a1f4072" translate="yes" xml:space="preserve">
          <source>Visualize the resulting regions</source>
          <target state="translated">結果として得られる領域を可視化する</target>
        </trans-unit>
        <trans-unit id="b77da1f257213eacf5971ec98d2f34c8fe910374" translate="yes" xml:space="preserve">
          <source>Visualizing cross-validation behavior in scikit-learn</source>
          <target state="translated">scikit-learnでのクロスバリデーション動作の可視化</target>
        </trans-unit>
        <trans-unit id="e6614e53d3137ea4329f7b88a52f014060c402bb" translate="yes" xml:space="preserve">
          <source>Visualizing the stock market structure</source>
          <target state="translated">株式市場の構造を可視化する</target>
        </trans-unit>
        <trans-unit id="3e1e0ef10e7a115946f530e934380438421c5b34" translate="yes" xml:space="preserve">
          <source>Vocabulary: classification and regression</source>
          <target state="translated">語彙:分類と回帰</target>
        </trans-unit>
        <trans-unit id="9b3e588521f2631086f0d4ea61248bd80936e042" translate="yes" xml:space="preserve">
          <source>VotingRegressor</source>
          <target state="translated">VotingRegressor</target>
        </trans-unit>
        <trans-unit id="dd7b37acd93acaf11b82a9ebbc3eea819b85e0ef" translate="yes" xml:space="preserve">
          <source>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.</source>
          <target state="translated">W.H.ウォルバーグ、W.N.ストリート、およびO.L.マンガサリアン。細針吸引から乳がんを診断するための機械学習技術。Cancer Letters 77 (1994)163-171。</target>
        </trans-unit>
        <trans-unit id="985d7c09beb3a8622b6c063b009de9296fdb89ed" translate="yes" xml:space="preserve">
          <source>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.</source>
          <target state="translated">WN Street、WH Wolberg、OL Mangasarian。乳房腫瘍診断のための核特徴抽出。IS＆T / SPIE 1993 Electronic Imaging on International Imaging：Science and Technology、volume 1905、pages 861-870、San Jose、CA、1993。</target>
        </trans-unit>
        <trans-unit id="0525374f4c7331dc5d256feba32a265d327160ed" translate="yes" xml:space="preserve">
          <source>WDBC-Benign</source>
          <target state="translated">WDBC-Benign</target>
        </trans-unit>
        <trans-unit id="fd630df285b07b6076d3b38d88445f6031d3902e" translate="yes" xml:space="preserve">
          <source>WDBC-Malignant</source>
          <target state="translated">WDBC-Malignant</target>
        </trans-unit>
        <trans-unit id="9b852a8108b3e892136da9e7da9f0a5bb56540ea" translate="yes" xml:space="preserve">
          <source>WMinkowskiDistance</source>
          <target state="translated">WMinkowskiDistance</target>
        </trans-unit>
        <trans-unit id="c3600a53fe931326fad0ec5abc0f593830220f56" translate="yes" xml:space="preserve">
          <source>Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp;amp; Liu, T. Y. (2013, May). A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)</source>
          <target state="translated">Wang、Y.、Wang、L.、Li、Y.、He、D.、Chen、W。、＆Liu、TY（2013年5月）。NDCGランキング指標の理論的分析。学習理論に関する第26回年次会議（COLT 2013）の議事録</target>
        </trans-unit>
        <trans-unit id="4e8ee595c7db5dd5f284f8fb603cc66c6c8287ae" translate="yes" xml:space="preserve">
          <source>Ward clustering based on a Feature matrix.</source>
          <target state="translated">特徴行列に基づく病棟クラスタリング。</target>
        </trans-unit>
        <trans-unit id="1af684513cf70467c9307765e01677f8970cff6e" translate="yes" xml:space="preserve">
          <source>Ward hierarchical clustering</source>
          <target state="translated">区の階層的クラスタリング</target>
        </trans-unit>
        <trans-unit id="d2173ac976f5809b703436c0de33dab1598b674c" translate="yes" xml:space="preserve">
          <source>Ward is the most effective method for noisy data.</source>
          <target state="translated">ワードは、ノイズの多いデータに最も効果的な方法です。</target>
        </trans-unit>
        <trans-unit id="e9c45563358e813f157ba81b33143542165ba84e" translate="yes" xml:space="preserve">
          <source>Warning</source>
          <target state="translated">Warning</target>
        </trans-unit>
        <trans-unit id="44d79cfceaac3d6c963709a9f443a7578dfdd3fa" translate="yes" xml:space="preserve">
          <source>Warning class used if there is an error while fitting the estimator.</source>
          <target state="translated">推定器の適合中にエラーが発生した場合に使用される警告クラス。</target>
        </trans-unit>
        <trans-unit id="c56f46b7e83e71f0bcaf54dacd8cfc15c71ef274" translate="yes" xml:space="preserve">
          <source>Warning class used to notify the user of any change in the behavior.</source>
          <target state="translated">動作の変更をユーザに通知するために使用される警告クラス。</target>
        </trans-unit>
        <trans-unit id="43a2ad1c4144ef567b3006486da55db4df5bcce7" translate="yes" xml:space="preserve">
          <source>Warning used to notify implicit data conversions happening in the code.</source>
          <target state="translated">コード内で暗黙のデータ変換が行われていることを通知するために使用される警告。</target>
        </trans-unit>
        <trans-unit id="69bb37448a64e3ca58327c210b042b57b19259a7" translate="yes" xml:space="preserve">
          <source>Warning used to notify the user of inefficient computation.</source>
          <target state="translated">非効率な計算をユーザに通知するために使用される警告。</target>
        </trans-unit>
        <trans-unit id="95fde5bcc048210bdd2da0e9628c10dadee1ce1e" translate="yes" xml:space="preserve">
          <source>Warning used when the dot operation does not use BLAS.</source>
          <target state="translated">ドット操作でBLASを使用しない場合に使用される警告。</target>
        </trans-unit>
        <trans-unit id="77d4a9d6a0a46436c153d66828a62d378a7e1f5d" translate="yes" xml:space="preserve">
          <source>Warning used when the metric is invalid</source>
          <target state="translated">メトリックが無効な場合に使用される警告</target>
        </trans-unit>
        <trans-unit id="d0aaba5d13d0d7235d440530a46ccfa6343b56ff" translate="yes" xml:space="preserve">
          <source>Warning: Extra-trees should only be used within ensemble methods.</source>
          <target state="translated">警告。余分な木はアンサンブル手法の中でのみ使用してください。</target>
        </trans-unit>
        <trans-unit id="c083bc8548c03dc08f53c7e8a611e5699830557a" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="translated">警告：不純物ベースの特徴の重要性は、カーディナリティの高い特徴（多くの固有の値）に対して誤解を招く可能性があります。別の方法として、&lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="a70a0040ebdf5db3cf497e998d5844dc921e921b" translate="yes" xml:space="preserve">
          <source>Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See &lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; as an alternative.</source>
          <target state="translated">警告：不純物ベースの特徴の重要性は、カーディナリティの高い特徴（多くの固有の値）に対して誤解を招く可能性があります。別の方法として、&lt;a href=&quot;sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;sklearn.inspection.permutation_importance&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="c2eb6fdf9d13ab34884681ef0c66f41e16b52aad" translate="yes" xml:space="preserve">
          <source>Warning: this function is experimental and subject to change in a future version of joblib.</source>
          <target state="translated">警告:この機能は実験的なものであり、将来のバージョンのjoblibで変更される可能性があります。</target>
        </trans-unit>
        <trans-unit id="b33d3bb4e4bfe5e80c2407f4ead429c7fa466ef0" translate="yes" xml:space="preserve">
          <source>We achieved 83.5% accuracy. Let&amp;rsquo;s see if we can do better with a linear &lt;a href=&quot;../../modules/svm#svm&quot;&gt;support vector machine (SVM)&lt;/a&gt;, which is widely regarded as one of the best text classification algorithms (although it&amp;rsquo;s also a bit slower than na&amp;iuml;ve Bayes). We can change the learner by simply plugging a different classifier object into our pipeline:</source>
          <target state="translated">83.5％の精度を達成しました。最高のテキスト分類アルゴリズムの1つと広く見なされている線形&lt;a href=&quot;../../modules/svm#svm&quot;&gt;サポートベクターマシン（SVM）&lt;/a&gt;でもっとうまくできるかどうかを見てみましょう（ただし、ナイーブベイズよりも少し遅いです）。別の分類子オブジェクトをパイプラインに接続するだけで、学習者を変更できます。</target>
        </trans-unit>
        <trans-unit id="5e4234559a6f8eb7829d45ed1528d4d2b014e858" translate="yes" xml:space="preserve">
          <source>We achieved 91.3% accuracy using the SVM. &lt;code&gt;scikit-learn&lt;/code&gt; provides further utilities for more detailed performance analysis of the results:</source>
          <target state="translated">SVMを使用して91.3％の精度を達成しました。 &lt;code&gt;scikit-learn&lt;/code&gt; は、結果のより詳細なパフォーマンス分析のためのユーティリティを提供します。</target>
        </trans-unit>
        <trans-unit id="4073bf855ec3741a8d17116f66549a3127ee1b52" translate="yes" xml:space="preserve">
          <source>We add observation noise to these waveforms. We generate very sparse noise: only 6% of the time points contain noise. As a result, the l1 norm of this noise (ie &amp;ldquo;cityblock&amp;rdquo; distance) is much smaller than it&amp;rsquo;s l2 norm (&amp;ldquo;euclidean&amp;rdquo; distance). This can be seen on the inter-class distance matrices: the values on the diagonal, that characterize the spread of the class, are much bigger for the Euclidean distance than for the cityblock distance.</source>
          <target state="translated">これらの波形に観測ノイズを追加します。非常にまばらなノイズが生成されます。ノイズが含まれるのは6％の時点のみです。その結果、このノイズのl1ノルム（「シティブロック」距離）は、l2ノルム（「ユークリッド」距離）よりもはるかに小さくなります。これは、クラス間の距離行列で見ることができます。クラスの広がりを特徴付ける対角線上の値は、ユークリッド距離の方が都市ブロック距離よりもはるかに大きくなっています。</target>
        </trans-unit>
        <trans-unit id="0408d5d268f82423b1624837fe33bcd8dd7f81b2" translate="yes" xml:space="preserve">
          <source>We also observe that &lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt;&lt;code&gt;MLPRegressor&lt;/code&gt;&lt;/a&gt; has much smoother predictions than &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;. For the plots to be comparable, it is necessary to subtract the average value of the target &lt;code&gt;y&lt;/code&gt;: The &amp;lsquo;recursion&amp;rsquo; method, used by default for &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, does not account for the initial predictor (in our case the average target). Setting the target average to 0 avoids this bias.</source>
          <target state="translated">また、&lt;a href=&quot;../../modules/generated/sklearn.neural_network.mlpregressor#sklearn.neural_network.MLPRegressor&quot;&gt; &lt;code&gt;MLPRegressor&lt;/code&gt; の&lt;/a&gt;予測は&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;よりもはるかにスムーズであることがわかります。プロットを比較できるようにするには、ターゲット &lt;code&gt;y&lt;/code&gt; の平均値を差し引く必要があります&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;にデフォルトで使用される「再帰」メソッドは、初期予測子（この場合は平均ターゲット）を考慮していません。ターゲット平均を0に設定すると、このバイアスを回避できます。</target>
        </trans-unit>
        <trans-unit id="5fc281c3e8b120a8bce90f392d5367731bdfa8e6" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for ARD for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">また、多項式特徴展開を用いた1次元回帰のARDの予測値と不確かさをプロットします。プロットの右側で不確かさが上昇し始めていることに注意してください。これは、これらのテスト・サンプルが学習サンプルの範囲外にあるためです。</target>
        </trans-unit>
        <trans-unit id="bda5a1ba58eab4f9acd36ef763104051f247918e" translate="yes" xml:space="preserve">
          <source>We also plot predictions and uncertainties for Bayesian Ridge Regression for one dimensional regression using polynomial feature expansion. Note the uncertainty starts going up on the right side of the plot. This is because these test samples are outside of the range of the training samples.</source>
          <target state="translated">また、多項式特徴展開を用いた1次元回帰のベイズリッジ回帰の予測値と不確かさをプロットします。プロットの右側で不確かさが上がり始めていることに注意してください。これは、これらのテストサンプルが訓練サンプルの範囲外にあるためです。</target>
        </trans-unit>
        <trans-unit id="796db2c0bddee3a97c873bf6deae5d571e22b022" translate="yes" xml:space="preserve">
          <source>We also show the tree structure of a model built on all of the features.</source>
          <target state="translated">また、すべての特徴に基づいて構築されたモデルのツリー構造を示しています。</target>
        </trans-unit>
        <trans-unit id="b29f4bff482ccd99c1af96e146d78b516ea318aa" translate="yes" xml:space="preserve">
          <source>We also use warm_start=True which means that the coefficients of the models are reused to initialize the next model fit to speed-up the computation of the full-path.</source>
          <target state="translated">また、フルパスの計算を高速化するために、モデルの係数が次のモデル適合の初期化に再利用されることを意味するwarm_start=Trueを使用しています。</target>
        </trans-unit>
        <trans-unit id="58db9129e28b6367a4c4b1cf6dbdf62e7e4b259e" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="translated">多くのバグ修正と新機能が付属するscikit-learn0.22のリリースを発表できることを嬉しく思います！このリリースの主な機能のいくつかを以下に詳しく説明します。すべての変更の完全なリストについては、&lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.22.html#changes-0-22&quot;&gt;リリースノート&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="85e7dd24e85e9c4275de753975b0d57e773f0b77" translate="yes" xml:space="preserve">
          <source>We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. &lt;strong&gt;For an exhaustive list of all the changes&lt;/strong&gt;, please refer to the &lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;release notes&lt;/a&gt;.</source>
          <target state="translated">scikit-learn 0.23のリリースを発表できることを嬉しく思います！多くのバグ修正と改善、およびいくつかの新しい主要機能が追加されました。このリリースの主な機能のいくつかを以下に詳しく説明します。&lt;strong&gt;すべての変更の完全なリスト&lt;/strong&gt;については、&lt;a href=&quot;https://scikit-learn.org/0.23/whats_new/v0.23.html#changes-0-23&quot;&gt;リリースノート&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="0f24896ee5efd7713cddd30b90821fa31665d4c0" translate="yes" xml:space="preserve">
          <source>We assume that the observations are independent and identically distributed (i.i.d.).</source>
          <target state="translated">我々は、オブザベーションが独立しており、同一分布(i.i.d.)であると仮定する。</target>
        </trans-unit>
        <trans-unit id="1552999210b3502aaea38a27415ef28fc1fbf44a" translate="yes" xml:space="preserve">
          <source>We build an artificial dataset where the target value is in general positively correlated with the first feature (with some random and non-random variations), and in general negatively correlated with the second feature.</source>
          <target state="translated">我々は人工的なデータセットを構築する。ここでは、目標値は一般的に第1の特徴量と正の相関を持ち(ランダムで非ランダムな変動もある)、第2の特徴量とは一般的に負の相関を持つ。</target>
        </trans-unit>
        <trans-unit id="b19a456f973e90e2b4e21cdba9f00b15173fd0ef" translate="yes" xml:space="preserve">
          <source>We call &lt;strong&gt;vectorization&lt;/strong&gt; the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the &lt;strong&gt;Bag of Words&lt;/strong&gt; or &amp;ldquo;Bag of n-grams&amp;rdquo; representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.</source>
          <target state="translated">テキストドキュメントのコレクションを数値の特徴ベクトルに変換する一般的なプロセスを、&lt;strong&gt;ベクトル化&lt;/strong&gt;と呼びます。この特定の戦略（トークン化、カウント、正規化）は、&lt;strong&gt;Bag of Words&lt;/strong&gt;または &quot;Bag of n-grams&quot;表現と呼ばれます。ドキュメントは、ドキュメント内の単語の相対的な位置情報を完全に無視しながら、単語の出現によって記述されます。</target>
        </trans-unit>
        <trans-unit id="c42f4b562ec41f92f6f2792dcf47013aca7ffcc1" translate="yes" xml:space="preserve">
          <source>We can additionally validate these models by comparing observed and predicted total claim amount over the test and train subsets. We see that, on average, both model tend to underestimate the total claim (but this behavior depends on the amount of regularization).</source>
          <target state="translated">さらに、テストサブセットと訓練サブセットで観測された総クレーム額と予測された総クレーム額を比較することで、これらのモデルを検証することができます。平均して、どちらのモデルもクレーム総額を過小評価する傾向があることがわかります(ただし、この動作は正則化の量に依存します)。</target>
        </trans-unit>
        <trans-unit id="63503e35b14a81c8aca7c86c612044cbc5b560d3" translate="yes" xml:space="preserve">
          <source>We can also export the tree in &lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt; format using the &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter. If you use the &lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt; package manager, the graphviz binaries and the python package can be installed with &lt;code&gt;conda install python-graphviz&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; &lt;/a&gt;エクスポーターを使用して、ツリーを&lt;a href=&quot;https://www.graphviz.org/&quot;&gt;Graphviz&lt;/a&gt;形式でエクスポートすることもできます。&lt;a href=&quot;https://conda.io&quot;&gt;conda&lt;/a&gt;パッケージマネージャーを使用する場合、graphvizバイナリとpythonパッケージは &lt;code&gt;conda install python-graphviz&lt;/code&gt; できます。</target>
        </trans-unit>
        <trans-unit id="096029ae48dbb08bf7baa8066a510ed0e5cf55ab" translate="yes" xml:space="preserve">
          <source>We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.</source>
          <target state="translated">また,GP事前分布を使用して,適合していないモデルに基づいて予測することもできる.予測分布の平均に加えて,標準偏差 (return_std=True)または共分散 (return_cov=True)も求められる.最大でも2つのうちの1つが要求されることに注意されたい。</target>
        </trans-unit>
        <trans-unit id="c4674ccfad638384c25bbb5d0cf26d42218171fa" translate="yes" xml:space="preserve">
          <source>We can check the coefficient variability through cross-validation: it is a form of data perturbation (related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;resampling&lt;/a&gt;).</source>
          <target state="translated">相互検証を通じて係数の変動性を確認できます。これは、データ摂動の形式です（&lt;a href=&quot;https://en.wikipedia.org/wiki/Resampling_(statistics)&quot;&gt;リサンプリングに&lt;/a&gt;関連します）。</target>
        </trans-unit>
        <trans-unit id="7f60df7f123136fa11f4ddf222fab31a6a72d17d" translate="yes" xml:space="preserve">
          <source>We can choose &lt;code&gt;alpha&lt;/code&gt; to minimize left out error, this time using the diabetes dataset rather than our synthetic data:</source>
          <target state="translated">今回は、合成データではなく糖尿病データセットを使用して、欠落したエラーを最小限に抑えるために &lt;code&gt;alpha&lt;/code&gt; を選択できます。</target>
        </trans-unit>
        <trans-unit id="a7e4da902c37585f80154c204f27a006746ba8cb" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the average occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">住宅価格の中央値は所得の中央値と直線的な関係を示し(左上)、一世帯当たりの平均居住者数が増加すると住宅価格が下落することがわかります(中上)。右上のプロットでは、築年数は住宅価格(中央値)に大きな影響を及ぼさず、一世帯当たりの平均部屋数も影響していることがわかる。x軸上の目盛りは、学習データの特徴量の階数を表しています。</target>
        </trans-unit>
        <trans-unit id="469d4e6eabf44c56eec1620cbb6087744c30d3f6" translate="yes" xml:space="preserve">
          <source>We can clearly see that the median house price shows a linear relationship with the median income (top left) and that the house price drops when the avg. occupants per household increases (top middle). The top right plot shows that the house age in a district does not have a strong influence on the (median) house price; so does the average rooms per household. The tick marks on the x-axis represent the deciles of the feature values in the training data.</source>
          <target state="translated">住宅価格の中央値は所得の中央値と直線的な関係を示し(左上)、一世帯当たりの平均居住者数が増加すると住宅価格が下落することがわかる(中上)。右上のプロットは、築年数は住宅価格(中央値)に大きな影響を及ぼさないことを示しており、一世帯当たりの平均部屋数も同様である。x軸上の目盛りは、学習データの特徴量の階数を表しています。</target>
        </trans-unit>
        <trans-unit id="c32b4a200d58f731852c3f4a8eefb32ef18f31ed" translate="yes" xml:space="preserve">
          <source>We can keep the remaining rating columns by setting &lt;code&gt;remainder='passthrough'&lt;/code&gt;. The values are appended to the end of the transformation:</source>
          <target state="translated">残りの評価列を保持するには、 &lt;code&gt;remainder='passthrough'&lt;/code&gt; 設定します。値は変換の最後に追加されます。</target>
        </trans-unit>
        <trans-unit id="a59ff6e4288992e31a9513b51da5a036927e8ec8" translate="yes" xml:space="preserve">
          <source>We can now load the list of files matching those categories as follows:</source>
          <target state="translated">これで、以下のようにそれらのカテゴリに一致するファイルのリストをロードすることができます。</target>
        </trans-unit>
        <trans-unit id="f1f864cfbdff004081b5667459fd9c49d8fcf703" translate="yes" xml:space="preserve">
          <source>We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:</source>
          <target state="translated">今では、我々の分類器をテスト(評価)するためにデータの40%を保持しながら、訓練セットを素早くサンプリングすることができます。</target>
        </trans-unit>
        <trans-unit id="6d11b97d462683ffa27a678189fc90fddb4a8ee5" translate="yes" xml:space="preserve">
          <source>We can observe that the &lt;code&gt;embarked&lt;/code&gt; and &lt;code&gt;sex&lt;/code&gt; columns were tagged as &lt;code&gt;category&lt;/code&gt; columns when loading the data with &lt;code&gt;fetch_openml&lt;/code&gt;. Therefore, we can use this information to dispatch the categorical columns to the &lt;code&gt;categorical_transformer&lt;/code&gt; and the remaining columns to the &lt;code&gt;numerical_transformer&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fetch_openml&lt;/code&gt; を使用してデータをロードすると、 &lt;code&gt;embarked&lt;/code&gt; 列と &lt;code&gt;sex&lt;/code&gt; 列が &lt;code&gt;category&lt;/code&gt; 列としてタグ付けされていることがわかります。したがって、我々はにカテゴリ列を派遣するために、この情報を使用することができます &lt;code&gt;categorical_transformer&lt;/code&gt; へと残りの列 &lt;code&gt;numerical_transformer&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="850dcea5aea59348ecbdc161cc86fe56ad9b64b5" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">射影後の\（\ mu ^ * _ k \）の分散を最大化する線形部分空間\（H_L \）に射影することにより、選択した\（L \）にさらに次元を減らすことができます（実際には、変換されたクラスのPCAの形式を実行していることは、\（\ mu ^ * _ k \）を意味します。この\（L \）は、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis.transform&lt;/code&gt; &lt;/a&gt;メソッドで使用される &lt;code&gt;n_components&lt;/code&gt; パラメータに対応します。詳細については、&lt;a href=&quot;#id4&quot; id=&quot;id2&quot;&gt;[3]&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="92db19023b735fef317e25e1a918af44df264854" translate="yes" xml:space="preserve">
          <source>We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the &lt;code&gt;n_components&lt;/code&gt; parameter used in the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; method. See &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="translated">射影後の\（\ mu ^ * _ k \）の分散を最大化する線形部分空間\（H_L \）に射影することにより、選択した\（L \）に次元をさらに縮小できます（実際には、変換されたクラスに対してPCAの形式を実行しているということは、\（\ mu ^ * _ k \））を意味します。この\（L \）は、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform&quot;&gt; &lt;code&gt;transform&lt;/code&gt; &lt;/a&gt;メソッドで使用される &lt;code&gt;n_components&lt;/code&gt; パラメーターに対応します。詳細については、&lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;1&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="32e64fece84cec61516540c9bc9ea581152251c6" translate="yes" xml:space="preserve">
          <source>We can see that &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; preserves the class ratios (approximately 1 / 10) in both train and test dataset.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;は、トレインデータセットとテストデータセットの両方でクラス比（約1/10）を保持していることがわかります。</target>
        </trans-unit>
        <trans-unit id="bee45302ee9842b9e6d2e72404b6369d8b7e97cc" translate="yes" xml:space="preserve">
          <source>We can see that for low values of &lt;code&gt;n_components&lt;/code&gt; the distribution is wide with many distorted pairs and a skewed distribution (due to the hard limit of zero ratio on the left as distances are always positives) while for larger values of n_components the distortion is controlled and the distances are well preserved by the random projection.</source>
          <target state="translated">&lt;code&gt;n_components&lt;/code&gt; の値が低い場合、分布は広く、多くの歪んだペアと歪んだ分布（距離は常に正であるため、左側のゼロ比のハード制限により）が広く、一方、n_componentsの値が大きい場合、歪みは制御され、距離は、ランダムな投影によって適切に保持されます。</target>
        </trans-unit>
        <trans-unit id="d51b2a4e76fb7eb99807202c5234812c15585e4c" translate="yes" xml:space="preserve">
          <source>We can see that if the maximum depth of the tree (controlled by the &lt;code&gt;max_depth&lt;/code&gt; parameter) is set too high, the decision trees learn too fine details of the training data and learn from the noise, i.e. they overfit.</source>
          <target state="translated">ツリーの最大深度（ &lt;code&gt;max_depth&lt;/code&gt; パラメーターで制御）の設定が高すぎると、決定木が学習データの細部を学習しすぎてノイズから学習する、つまりオーバーフィットすることがわかります。</target>
        </trans-unit>
        <trans-unit id="5bc27bfd8c709ab5505734b2124db3dbd09e7af4" translate="yes" xml:space="preserve">
          <source>We can see that, although feature 2 has a strong coefficient on the full model, it conveys little information on &lt;code&gt;y&lt;/code&gt; when considered with feature 1.</source>
          <target state="translated">特徴2はモデル全体で強い係数を持っていますが、特徴1と &lt;code&gt;y&lt;/code&gt; するとyに関する情報がほとんどないことがわかります。</target>
        </trans-unit>
        <trans-unit id="208e5f1f40787dd5dcd62a253128bd90d5a3414b" translate="yes" xml:space="preserve">
          <source>We can turn those concept as scores &lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt;&lt;code&gt;homogeneity_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt;&lt;code&gt;completeness_score&lt;/code&gt;&lt;/a&gt;. Both are bounded below by 0.0 and above by 1.0 (higher is better):</source>
          <target state="translated">これらの概念を、スコア&lt;a href=&quot;generated/sklearn.metrics.homogeneity_score#sklearn.metrics.homogeneity_score&quot;&gt; &lt;code&gt;homogeneity_score&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.metrics.completeness_score#sklearn.metrics.completeness_score&quot;&gt; &lt;code&gt;completeness_score&lt;/code&gt; &lt;/a&gt;として変換できます。どちらも、0.0未満および1.0を超える境界にあります（高いほど優れています）。</target>
        </trans-unit>
        <trans-unit id="592289b1a6fdac7a6256bbd4a62b88701d16e505" translate="yes" xml:space="preserve">
          <source>We can use the function &lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt;&lt;code&gt;learning_curve&lt;/code&gt;&lt;/a&gt; to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):</source>
          <target state="translated">関数&lt;a href=&quot;generated/sklearn.model_selection.learning_curve#sklearn.model_selection.learning_curve&quot;&gt; &lt;code&gt;learning_curve&lt;/code&gt; &lt;/a&gt;を使用して、そのような学習曲線をプロットするために必要な値（使用されたサンプルの数、トレーニングセットの平均スコアと検証セットの平均スコア）を生成できます。</target>
        </trans-unit>
        <trans-unit id="36de20f1638d2356805015f502415f93be57efc5" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated by the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;), vehicle age (&lt;code&gt;VehAge&lt;/code&gt;) and the insurance bonus/malus (&lt;code&gt;BonusMalus&lt;/code&gt;).</source>
          <target state="translated">私たちは、視覚的にドライバーの年齢（によって集約観測値と予測値、比較することができ &lt;code&gt;DrivAge&lt;/code&gt; ）、車両の年齢（ &lt;code&gt;VehAge&lt;/code&gt; ）と保険のボーナス/マルス（ &lt;code&gt;BonusMalus&lt;/code&gt; を）。</target>
        </trans-unit>
        <trans-unit id="b0507ecbdf9b58dd0986ef6194b95f4c79d58f52" translate="yes" xml:space="preserve">
          <source>We can visually compare observed and predicted values, aggregated for the drivers age (&lt;code&gt;DrivAge&lt;/code&gt;).</source>
          <target state="translated">ドライバーの年齢（ &lt;code&gt;DrivAge&lt;/code&gt; ）ごとに集計された観測値と予測値を視覚的に比較できます。</target>
        </trans-unit>
        <trans-unit id="3c55a99ecafce9d11edefa5f7981438b525c546b" translate="yes" xml:space="preserve">
          <source>We classify 8x8 images of digits into two classes: 0-4 against 5-9. The visualization shows coefficients of the models for varying C.</source>
          <target state="translated">桁の8x8画像を2つのクラスに分類しています。5-9に対して0-4です。可視化は、Cを変化させた場合のモデルの係数を示しています。</target>
        </trans-unit>
        <trans-unit id="523600239bb64c3dc717f02d73255329247ddc08" translate="yes" xml:space="preserve">
          <source>We configured a pipeline to scale the numerical input features and tuned the neural network size and learning rate to get a reasonable compromise between training time and predictive performance on a test set.</source>
          <target state="translated">数値入力特徴量をスケーリングするためのパイプラインを構成し、ニューラルネットワークのサイズと学習率を調整することで、テストセット上での学習時間と予測性能の間に妥当な妥協点が得られるようにした。</target>
        </trans-unit>
        <trans-unit id="4c2ceff57e3b51d317fe78664f4ea8312ed35966" translate="yes" xml:space="preserve">
          <source>We consider 3 features x_1, x_2, x_3 distributed uniformly over [0, 1], the target depends on them as follows:</source>
          <target state="translated">3つの特徴x_1,x_2,x_3が[0,1]上に一様に分布しているとすると,以下のようになります.</target>
        </trans-unit>
        <trans-unit id="f5f452641b4c7cde04f8f2f3146b6f807ae80e50" translate="yes" xml:space="preserve">
          <source>We construct the freMTPL2 dataset by joining the freMTPL2freq table, containing the number of claims (&lt;code&gt;ClaimNb&lt;/code&gt;), with the freMTPL2sev table, containing the claim amount (&lt;code&gt;ClaimAmount&lt;/code&gt;) for the same policy ids (&lt;code&gt;IDpol&lt;/code&gt;).</source>
          <target state="translated">クレームの数（ &lt;code&gt;ClaimNb&lt;/code&gt; ）を含むfreMTPL2freqテーブルを、同じポリシーID（ &lt;code&gt;IDpol&lt;/code&gt; ）のクレーム量（ &lt;code&gt;ClaimAmount&lt;/code&gt; ）を含むfreMTPL2sevテーブルと結合することにより、freMTPL2データセットを構築します。</target>
        </trans-unit>
        <trans-unit id="8b738423194ebf355d81c34c5848e446f6f25c86" translate="yes" xml:space="preserve">
          <source>We create a multi-label dataset, to illustrate the precision-recall in multi-label settings</source>
          <target state="translated">マルチラベルデータセットを作成し、マルチラベル設定での精度-リコールを説明します。</target>
        </trans-unit>
        <trans-unit id="2b472a5c2bccac31b45ff227b2c9930cbabaf64f" translate="yes" xml:space="preserve">
          <source>We create the preprocessing pipelines for both numeric and categorical data.</source>
          <target state="translated">数値データとカテゴリデータの前処理パイプラインを作成します。</target>
        </trans-unit>
        <trans-unit id="6395abe83d6b6a4aa4bc2a531d4a8a4bd65d8620" translate="yes" xml:space="preserve">
          <source>We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in &lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12&lt;/a&gt;.</source>
          <target state="translated">ここでは、SGD手順の数学的詳細について説明します。収束率の概要は&lt;a href=&quot;#id16&quot; id=&quot;id4&quot;&gt;12にあり&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="5f9ff80fbe7d3d20607821a1978395dad8f7243a" translate="yes" xml:space="preserve">
          <source>We describe these 3 scenarios in the following subsections.</source>
          <target state="translated">これら3つのシナリオについては、以下のサブセクションで説明します。</target>
        </trans-unit>
        <trans-unit id="7df3a30efca0a13e3a362147c9be1fa02a3e02fd" translate="yes" xml:space="preserve">
          <source>We don&amp;rsquo;t allow:</source>
          <target state="translated">以下は許可されません。</target>
        </trans-unit>
        <trans-unit id="484dbca389e5beb12ba95d531ed59ac647119de0" translate="yes" xml:space="preserve">
          <source>We fetch the data from &lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;. Note that setting the parameter &lt;code&gt;as_frame&lt;/code&gt; to True will retrieve the data as a pandas dataframe.</source>
          <target state="translated">&lt;a href=&quot;http://openml.org/&quot;&gt;OpenML&lt;/a&gt;からデータをフェッチします。パラメータ &lt;code&gt;as_frame&lt;/code&gt; をTrueに設定すると、データがpandasデータフレームとして取得されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="43167795aabd351e0317ac3702c4dd940441044a" translate="yes" xml:space="preserve">
          <source>We filter out &lt;code&gt;ClaimAmount == 0&lt;/code&gt; as the Gamma distribution has support on \((0, \infty)\), not \([0, \infty)\).</source>
          <target state="translated">ガンマ分布は\（[0、\ infty）\）ではなく\（（0、\ infty）\）をサポートしているため、 &lt;code&gt;ClaimAmount == 0&lt;/code&gt; を除外します。</target>
        </trans-unit>
        <trans-unit id="c17cba12ad6e5c2f931d1de0fcadd712e7bb0a0a" translate="yes" xml:space="preserve">
          <source>We first find the separating plane with a plain SVC and then plot (dashed) the separating hyperplane with automatically correction for unbalanced classes.</source>
          <target state="translated">まず、平板なSVCで分離平面を求め、次に、アンバランスなクラスを自動的に補正した分離超平面をプロットします(破線)。</target>
        </trans-unit>
        <trans-unit id="1b6887ebea04d51a67698037588b0795f4c76e3a" translate="yes" xml:space="preserve">
          <source>We first present GBRT for regression, and then detail the classification case.</source>
          <target state="translated">まず、回帰のためのGBRTを提示し、その後、分類のケースを詳しく説明します。</target>
        </trans-unit>
        <trans-unit id="916afde7457af1caed530318ff87e1a7a139918e" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">私たちは、ことがわかっ &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; はに匹敵する結果を与える &lt;code&gt;max_depth=k-1&lt;/code&gt; が、わずかに高い訓練誤差を犠牲にして大幅に高速訓練することです。パラメータ &lt;code&gt;max_leaf_nodes&lt;/code&gt; は、&lt;a href=&quot;#f2001&quot; id=&quot;id14&quot;&gt;[F2001]の&lt;/a&gt;勾配ブースティングに関する章の変数 &lt;code&gt;J&lt;/code&gt; に対応し、Rのgbmパッケージのパラメータ &lt;code&gt;interaction.depth&lt;/code&gt; に関連しています。ここで、 &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9a42cbe6e58382c593ff38ee7701bfc70bcd66e4" translate="yes" xml:space="preserve">
          <source>We found that &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; gives comparable results to &lt;code&gt;max_depth=k-1&lt;/code&gt; but is significantly faster to train at the expense of a slightly higher training error. The parameter &lt;code&gt;max_leaf_nodes&lt;/code&gt; corresponds to the variable &lt;code&gt;J&lt;/code&gt; in the chapter on gradient boosting in &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; and is related to the parameter &lt;code&gt;interaction.depth&lt;/code&gt; in R&amp;rsquo;s gbm package where &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; .</source>
          <target state="translated">私たちは、ことがわかっ &lt;code&gt;max_leaf_nodes=k&lt;/code&gt; はに匹敵する結果を与える &lt;code&gt;max_depth=k-1&lt;/code&gt; が、わずかに高い訓練誤差を犠牲にして大幅に高速訓練することです。パラメータ &lt;code&gt;max_leaf_nodes&lt;/code&gt; は、&lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id15&quot;&gt;[F2001]の&lt;/a&gt;勾配ブースティングに関する章の変数 &lt;code&gt;J&lt;/code&gt; に対応し、 &lt;code&gt;max_leaf_nodes == interaction.depth + 1&lt;/code&gt; であるRのgbmパッケージのパラメータ &lt;code&gt;interaction.depth&lt;/code&gt; に関連しています。</target>
        </trans-unit>
        <trans-unit id="72f7189dc223c470430f67b7332d9ced78363339" translate="yes" xml:space="preserve">
          <source>We found that Averaged SGD works best with a larger number of features and a higher eta0</source>
          <target state="translated">平均化された SGD は、より多くのフィーチャ数とより高い eta0 があれば最もよく機能することがわかりました。</target>
        </trans-unit>
        <trans-unit id="2147828a070acc191399f3a8049f6a914fdacd22" translate="yes" xml:space="preserve">
          <source>We further include two random variables that are not correlated in any way with the target variable (&lt;code&gt;survived&lt;/code&gt;):</source>
          <target state="translated">さらに、ターゲット変数とはまったく相関していない（ &lt;code&gt;survived&lt;/code&gt; ）2つの確率変数を含めます。</target>
        </trans-unit>
        <trans-unit id="ecc641e4f0c3be544f8ba1b6978d12b64c778e22" translate="yes" xml:space="preserve">
          <source>We generate data from three groups of waveforms. Two of the waveforms (waveform 1 and waveform 2) are proportional one to the other. The cosine distance is invariant to a scaling of the data, as a result, it cannot distinguish these two waveforms. Thus even with no noise, clustering using this distance will not separate out waveform 1 and 2.</source>
          <target state="translated">3つのグループの波形からデータを生成します。そのうちの2つの波形(波形1と波形2)は互いに比例しています。余弦距離はデータのスケーリングに不変であるため、この2つの波形を区別することができません。したがって,ノイズがなくても,この距離を用いたクラスタリングでは,波形1と波形2を分離することはできません.</target>
        </trans-unit>
        <trans-unit id="03835cacd7901d07f747c14f209b80543758c4fd" translate="yes" xml:space="preserve">
          <source>We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators:</source>
          <target state="translated">推定量の中にはデータを変換できるものがあり、推定量の中には変数を予測できるものがあることを見てきました。また、結合された推定量を作成することもできます。</target>
        </trans-unit>
        <trans-unit id="996013b3c282443801da622c65fee1deca3cef01" translate="yes" xml:space="preserve">
          <source>We have seen that sparsity could be used to mitigate the curse of dimensionality, &lt;em&gt;i.e&lt;/em&gt; an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: &lt;strong&gt;feature agglomeration&lt;/strong&gt;. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data.</source>
          <target state="translated">希薄性を使用して、次元の呪い、&lt;em&gt;すなわち&lt;/em&gt;、特徴の数と比較して不十分な量の観測を緩和できることがわかりました。別のアプローチは、同様の機能を統合することです：&lt;strong&gt;機能の集積&lt;/strong&gt;。このアプローチは、特徴方向のクラスタリング、つまり転置されたデータのクラスタリングによって実装できます。</target>
        </trans-unit>
        <trans-unit id="f70b46435230cf70b0b3d749ceef620b9bcdee9d" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">特に、SVDのアルゴリズムの複雑さを軽減するために特定の状況で使用されるQR分解は、両方の論文の著者が使用する最適化を避けています。この手法のソースは、 &lt;code&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/code&gt; 。この手法は、 &lt;code&gt;n_samples&lt;/code&gt; （行）&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; （列）で行列を分解する場合にのみ有利であり、実装されたアルゴリズムの可読性を損なうため、省略されています。必要と思われる場合、これは将来の最適化の良い機会です。</target>
        </trans-unit>
        <trans-unit id="ac54e4e32d1eea16ad8753f857ea27f0962cb421" translate="yes" xml:space="preserve">
          <source>We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is &lt;em&gt;Matrix Computations, Third Edition, G. Holub and C. Van Loan, Chapter 5, section 5.4.4, pp 252-253.&lt;/em&gt;. This technique has been omitted because it is advantageous only when decomposing a matrix with &lt;code&gt;n_samples&lt;/code&gt; (rows) &amp;gt;= 5/3 * &lt;code&gt;n_features&lt;/code&gt; (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.</source>
          <target state="translated">両方の論文の著者が使用した最適化、SVDのアルゴリズムの複雑さを軽減するために特定の状況で使用されるQR分解を特に控えました。この手法のソースは、&lt;em&gt;Matrix Computations、第3版、G。HolubおよびC. Van Loan、第5章、セクション5.4.4、pp252-253です。&lt;/em&gt;。この手法は、 &lt;code&gt;n_samples&lt;/code&gt; （行）&amp;gt; = 5/3 * &lt;code&gt;n_features&lt;/code&gt; （列）の行列を分解する場合にのみ有利であり、実装されたアルゴリズムの可読性を損なうため、省略されています。これは、必要と思われる場合、将来の最適化の良い機会になります。</target>
        </trans-unit>
        <trans-unit id="db298eced453f06f8efed43be73a03415c98ca01" translate="yes" xml:space="preserve">
          <source>We have to reconstruct model and parameters to make sure we stay in sync with the python object.</source>
          <target state="translated">モデルとパラメータを再構築して、Pythonオブジェクトと同期していることを確認しなければなりません。</target>
        </trans-unit>
        <trans-unit id="ca5f08fcacf0548e5e0c637b82c4414e44704050" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) (instead of \(C\)) which controls the number of support vectors and &lt;em&gt;margin errors&lt;/em&gt;: \(\nu \in (0, 1]\) is an upper bound on the fraction of margin errors and a lower bound of the fraction of support vectors. A margin error corresponds to a sample that lies on the wrong side of its margin boundary: it is either misclassified, or it is correctly classified but does not lie beyond the margin.</source>
          <target state="translated">サポートベクターと&lt;em&gt;マージンエラーの&lt;/em&gt;数を制御する新しいパラメーター\（\ nu \）（\（C \）の代わりに）を導入します：\（\ nu \ in（0、1] \）はの上限ですマージンエラーの割合とサポートベクターの割合の下限マージンエラーは、マージン境界の反対側にあるサンプルに対応します：誤分類されているか、正しく分類されているがマージンを超えていない。</target>
        </trans-unit>
        <trans-unit id="f2683785e1f3e3ccb40d3941fed7d5fa67a33cfc" translate="yes" xml:space="preserve">
          <source>We introduce a new parameter \(\nu\) which controls the number of support vectors and training errors. The parameter \(\nu \in (0, 1]\) is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</source>
          <target state="translated">サポートベクタの数と学習誤差を制御するパラメータを導入する。\(\nu \in (0,1]\)は、学習エラーの割合の上限と、サポートベクタの割合の下限である。</target>
        </trans-unit>
        <trans-unit id="60ccb05e0b7446f76670a424f0fabb01d1ca71b3" translate="yes" xml:space="preserve">
          <source>We need a vectorized version of the image. &lt;code&gt;'rescaled_coins'&lt;/code&gt; is a down-scaled version of the coins image to speed up the process:</source>
          <target state="translated">画像のベクトル化されたバージョンが必要です。 &lt;code&gt;'rescaled_coins'&lt;/code&gt; は、プロセスを高速化するためのコイン画像の縮小版です。</target>
        </trans-unit>
        <trans-unit id="284f00654c2880797bacd24e85e3bc2f5ec8be8d" translate="yes" xml:space="preserve">
          <source>We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.</source>
          <target state="translated">もはや衝突は得られませんが、これは出力空間の次元性をはるかに大きくすることを犠牲にしています。もちろん,ここで使用されている19の用語以外の用語は,まだお互いに衝突する可能性があります.</target>
        </trans-unit>
        <trans-unit id="a19ee5584b95e367f6c768452e1c513e3bb433ea" translate="yes" xml:space="preserve">
          <source>We now inspect the coefficients across several cross-validation folds.</source>
          <target state="translated">今、いくつかのクロスバリデーションのひだにまたがる係数を検査します。</target>
        </trans-unit>
        <trans-unit id="9d37726e46e38fa3806c6050ccef5f0b5ccde0ad" translate="yes" xml:space="preserve">
          <source>We now provide a &lt;code&gt;pytest&lt;/code&gt; specific decorator which allows &lt;code&gt;pytest&lt;/code&gt; to run all checks independently and report the checks that are failing.</source>
          <target state="translated">&lt;code&gt;pytest&lt;/code&gt; がすべてのチェックを個別に実行し、失敗したチェックを報告できるようにする &lt;code&gt;pytest&lt;/code&gt; 固有のデコレータを提供するようになりました。</target>
        </trans-unit>
        <trans-unit id="b22fff2428986dd4d9e25659e5099f6fa799f31a" translate="yes" xml:space="preserve">
          <source>We now support imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="translated">我々は、k-Nearest Neighborsを用いて欠損値を補完するためのインputationをサポートするようになった。</target>
        </trans-unit>
        <trans-unit id="3b146f434972f2182b845909391decf90277ad41" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the perplexity value increases.</source>
          <target state="translated">錯乱度が高くなるほど、形状が明確になる傾向が見られます。</target>
        </trans-unit>
        <trans-unit id="0e7a6d4d2e128e719f76bf1799c4515162612bfb" translate="yes" xml:space="preserve">
          <source>We observe a tendency towards clearer shapes as the preplexity value increases.</source>
          <target state="translated">プレプレプレキシシティの値が大きくなるほど、形状が明確になる傾向が見られます。</target>
        </trans-unit>
        <trans-unit id="3705c31d0fb66694929007b0cdad834fbbaf06c2" translate="yes" xml:space="preserve">
          <source>We plot partial dependence curves for features &amp;ldquo;age&amp;rdquo; and &amp;ldquo;bmi&amp;rdquo; (body mass index) for the decision tree. With two features, &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; expects to plot two curves. Here the plot function place a grid of two plots using the space defined by &lt;code&gt;ax&lt;/code&gt; .</source>
          <target state="translated">デシジョンツリーの特徴「年齢」と「bmi」（ボディマス指数）の部分依存曲線をプロットします。2つの機能により、&lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt; &lt;code&gt;plot_partial_dependence&lt;/code&gt; &lt;/a&gt;は2つの曲線をプロットすることを想定しています。ここで、プロット関数は、 &lt;code&gt;ax&lt;/code&gt; で定義されたスペースを使用して2つのプロットのグリッドを配置します。</target>
        </trans-unit>
        <trans-unit id="b4e7d2188aa62b346706f6bd2a1ae94095756883" translate="yes" xml:space="preserve">
          <source>We plot predicted labels on both training and held out test data using a variety of GMM covariance types on the iris dataset. We compare GMMs with spherical, diagonal, full, and tied covariance matrices in increasing order of performance. Although one would expect full covariance to perform best in general, it is prone to overfitting on small datasets and does not generalize well to held out test data.</source>
          <target state="translated">我々は、虹彩データセット上で様々なGMM共分散タイプを用いて、訓練データとテストデータの両方で予測ラベルをプロットした。我々は、性能の高い順に、球状共分散、対角共分散、完全共分散、結束共分散行列とGMMを比較している。一般的には完全共分散が最も優れた性能を発揮すると予想されるが、小さなデータセットではオーバーフィットしやすく、ホールドアウトされたテストデータでは一般化しにくい。</target>
        </trans-unit>
        <trans-unit id="7ead9de71a0f24e08ddaae8aaa6dd6470443d3a2" translate="yes" xml:space="preserve">
          <source>We recommend &lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt; and &lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt; as good references for the theory and practicalities of SVMs.</source>
          <target state="translated">SVMの理論と実用性の良い参考資料として&lt;a href=&quot;#id15&quot; id=&quot;id6&quot;&gt;13&lt;/a&gt;と&lt;a href=&quot;#id16&quot; id=&quot;id7&quot;&gt;14&lt;/a&gt;をお勧めします。</target>
        </trans-unit>
        <trans-unit id="8a444360e57dc0870f14b3c959a7b626922e7571" translate="yes" xml:space="preserve">
          <source>We see that &lt;code&gt;SVC&lt;/code&gt; doesn&amp;rsquo;t do much better than a dummy classifier. Now, let&amp;rsquo;s change the kernel:</source>
          <target state="translated">&lt;code&gt;SVC&lt;/code&gt; はダミーの分類子ほど優れていないことがわかります。さて、カーネルを変更しましょう：</target>
        </trans-unit>
        <trans-unit id="9619f66671fbeb88bbee2c1b3d850c22bdb6ab25" translate="yes" xml:space="preserve">
          <source>We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the &lt;a href=&quot;cross_validation#cross-validation&quot;&gt;Cross-validation: evaluating estimator performance&lt;/a&gt; section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the &lt;a href=&quot;grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt; section for details.</source>
          <target state="translated">精度がほぼ100％に向上したことがわかります。 CPUコストがかかりすぎない場合は、精度をより正確に見積もるために相互検証戦略をお勧めします。詳細については、「&lt;a href=&quot;cross_validation#cross-validation&quot;&gt;相互検証：推定器のパフォーマンスの評価」&lt;/a&gt;セクションを参照してください。さらに、パラメーター空間全体を最適化する場合は、適切な方法を使用することを強くお勧めします。詳細について&lt;a href=&quot;grid_search#grid-search&quot;&gt;は、推定器のハイパーパラメータの調整&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="b05b900d7824680be8b5fe4195a1e87507494a4c" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">結果として得られる&lt;em&gt;多項式回帰&lt;/em&gt;は、上記で検討したのと同じクラスの線形モデルにあり（つまり、モデルは\（w \）で線形である）、同じ手法で解くことができます。これらの基底関数で構築された高次元空間内の線形フィットを考慮することにより、モデルははるかに広い範囲のデータにフィットする柔軟性を備えています。</target>
        </trans-unit>
        <trans-unit id="d680bb4e5101fe3a9df93911d26cfa982767e679" translate="yes" xml:space="preserve">
          <source>We see that the resulting &lt;em&gt;polynomial regression&lt;/em&gt; is in the same class of linear models we&amp;rsquo;d considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.</source>
          <target state="translated">結果の&lt;em&gt;多項式回帰&lt;/em&gt;は、上記で検討したものと同じクラスの線形モデル（つまり、モデルは\（w \）で線形）にあり、同じ手法で解くことができます。これらの基底関数を使用して構築された高次元空間内での線形近似を考慮することにより、モデルはより広範囲のデータに適合する柔軟性を備えています。</target>
        </trans-unit>
        <trans-unit id="1a0e7af8231b7a460dcfd9acf44c6323ad1ea844" translate="yes" xml:space="preserve">
          <source>We selected two sets of two variables from the Boston housing data set as an illustration of what kind of analysis can be done with several outlier detection tools. For the purpose of visualization, we are working with two-dimensional examples, but one should be aware that things are not so trivial in high-dimension, as it will be pointed out.</source>
          <target state="translated">我々は、いくつかの外れ値検出ツールでどのような分析ができるかの説明として、ボストンの住宅データセットから2つの変数の2つのセットを選択しました。可視化のために、我々は2次元の例を使っていますが、指摘されるように、高次元ではそれほど些細なことではないことに注意しなければなりません。</target>
        </trans-unit>
        <trans-unit id="940e7a9289cb117779f9b0e089fc6f41ec456057" translate="yes" xml:space="preserve">
          <source>We should also note that small differences in scores results from the random splits of the cross-validation procedure. Those spurious variations can be smoothed out by increasing the number of CV iterations &lt;code&gt;n_splits&lt;/code&gt; at the expense of compute time. Increasing the value number of &lt;code&gt;C_range&lt;/code&gt; and &lt;code&gt;gamma_range&lt;/code&gt; steps will increase the resolution of the hyper-parameter heat map.</source>
          <target state="translated">スコアの小さな違いは、相互検証手順のランダムな分割から生じることにも注意する必要があります。これらのスプリアス変動は、計算時間を犠牲にしてCV反復数 &lt;code&gt;n_splits&lt;/code&gt; を増やすことによって平滑化できます。 &lt;code&gt;C_range&lt;/code&gt; および &lt;code&gt;gamma_range&lt;/code&gt; ステップの値の数を増やすと、ハイパーパラメーターヒートマップの解像度が上がります。</target>
        </trans-unit>
        <trans-unit id="1cbc5d306e08afa1d68b1045fc6a567611cf26d2" translate="yes" xml:space="preserve">
          <source>We show that linear_model.Lasso provides the same results for dense and sparse data and that in the case of sparse data the speed is improved.</source>
          <target state="translated">linear_model.Lassoが密なデータでも疎なデータでも同じ結果を提供し、疎なデータの場合は速度が向上することを示しています。</target>
        </trans-unit>
        <trans-unit id="971fe5258bb92dd314d2f061a23d12526523f329" translate="yes" xml:space="preserve">
          <source>We split the sample into a train and a test dataset. Only the train dataset will be used in the following exploratory analysis. This is a way to emulate a real situation where predictions are performed on an unknown target, and we don&amp;rsquo;t want our analysis and decisions to be biased by our knowledge of the test data.</source>
          <target state="translated">サンプルをトレインとテストデータセットに分割します。以下の探索的分析では、列車データセットのみが使用されます。これは、未知のターゲットで予測が実行される実際の状況をエミュレートする方法であり、テストデータの知識によって分析と決定にバイアスがかかることは望ましくありません。</target>
        </trans-unit>
        <trans-unit id="9729e48da1dbe46bc3dec3ab22ad1f98a7a56bb9" translate="yes" xml:space="preserve">
          <source>We start by modeling the target variable with the (l2 penalized) least squares linear regression model, more comonly known as Ridge regression. We use a low penalization &lt;code&gt;alpha&lt;/code&gt;, as we expect such a linear model to under-fit on such a large dataset.</source>
          <target state="translated">まず、（l2ペナルティ付き）最小二乗線形回帰モデルを使用してターゲット変数をモデル化します。これは、リッジ回帰としてのみ知られています。このような線形モデルはこのような大規模なデータセットに適合しないと予想されるため、ペナルティの低い &lt;code&gt;alpha&lt;/code&gt; を使用します。</target>
        </trans-unit>
        <trans-unit id="efbf964638e7ca0fbdc3e1bd2a5029a9cbed6b8c" translate="yes" xml:space="preserve">
          <source>We start by training a label propagation model with only 10 labeled points, then we select the top five most uncertain points to label. Next, we train with 15 labeled points (original 10 + 5 new ones). We repeat this process four times to have a model trained with 30 labeled examples. Note you can increase this to label more than 30 by changing &lt;code&gt;max_iterations&lt;/code&gt;. Labeling more than 30 can be useful to get a sense for the speed of convergence of this active learning technique.</source>
          <target state="translated">まず、10個のラベル付けされたポイントのみでラベル伝播モデルをトレーニングし、次にラベル付けする最も不確実な上位5ポイントを選択します。次に、15のラベル付きポイント（元の10 + 5つの新しいポイント）でトレーニングします。このプロセスを4回繰り返して、30のラベル付きの例でトレーニングされたモデルを作成します。 &lt;code&gt;max_iterations&lt;/code&gt; を変更することにより、これを30以上のラベルに増やすことができます。30を超えるラベルは、このアクティブな学習手法の収束の速さを理解するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="b926aa4a7c89ca684b4dc714781356e70fac60ed" translate="yes" xml:space="preserve">
          <source>We thus transform the KDD Data set into two different data sets: SA and SF.</source>
          <target state="translated">このようにして、KDDデータセットを2つの異なるデータセットに変換する。SAとSFです。</target>
        </trans-unit>
        <trans-unit id="c5856ddc1b1774be0ac4aef6a043703c4e71a274" translate="yes" xml:space="preserve">
          <source>We train a random forest classifier and create a plot comparing it to the SVC ROC curve. Notice how &lt;code&gt;svc_disp&lt;/code&gt; uses &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt;&lt;code&gt;plot&lt;/code&gt;&lt;/a&gt; to plot the SVC ROC curve without recomputing the values of the roc curve itself. Furthermore, we pass &lt;code&gt;alpha=0.8&lt;/code&gt; to the plot functions to adjust the alpha values of the curves.</source>
          <target state="translated">ランダムフォレスト分類器をトレーニングし、それをSVCROC曲線と比較するプロットを作成します。 &lt;code&gt;svc_disp&lt;/code&gt; が&lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay.plot&quot;&gt; &lt;code&gt;plot&lt;/code&gt; &lt;/a&gt;を使用して、roc曲線自体の値を再計算せずにSVCROC曲線をプロットする方法に注目してください。さらに、 &lt;code&gt;alpha=0.8&lt;/code&gt; をプロット関数に渡して、曲線のアルファ値を調整します。</target>
        </trans-unit>
        <trans-unit id="38d99d5f10e1040b13651031a8f4b3d74d91ef9a" translate="yes" xml:space="preserve">
          <source>We train and test the datasets with 15 different classification models and get performance results for each model.</source>
          <target state="translated">15種類の分類モデルを用いてデータセットを学習・テストし、各モデルの性能結果を得る。</target>
        </trans-unit>
        <trans-unit id="f695efb4e75bb85159c9142762a64409b0330558" translate="yes" xml:space="preserve">
          <source>We use &lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt;&lt;/a&gt; to learn an embedding and plot the points after the transformation. We then take the embedding and find the nearest neighbors.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis&lt;/code&gt; &lt;/a&gt;を使用して、埋め込みを学習し、変換後のポイントをプロットします。次に、埋め込みを取得して、最近傍を見つけます。</target>
        </trans-unit>
        <trans-unit id="0b8cd078987f149b454cdac8f89f7fb050617be5" translate="yes" xml:space="preserve">
          <source>We use &lt;code&gt;ClaimNb&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt; to account for policies that contain more than one claim.</source>
          <target state="translated">複数のクレームを含むポリシーを説明するために、 &lt;code&gt;ClaimNb&lt;/code&gt; として &lt;code&gt;sample_weight&lt;/code&gt; を使用します。</target>
        </trans-unit>
        <trans-unit id="13122bf873819e99a4ec7d32c926bbee95474f9b" translate="yes" xml:space="preserve">
          <source>We use a GridSearchCV to set the dimensionality of the PCA</source>
          <target state="translated">PCAの次元性を設定するために,GridSearchCVを用いる.</target>
        </trans-unit>
        <trans-unit id="61efd119ac2fcb7bb96489a56e2c262d1e964f20" translate="yes" xml:space="preserve">
          <source>We use a biased estimator for the standard deviation, equivalent to &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt;. Note that the choice of &lt;code&gt;ddof&lt;/code&gt; is unlikely to affect model performance.</source>
          <target state="translated">標準偏差には、 &lt;code&gt;numpy.std(x, ddof=0)&lt;/code&gt; と同等のバイアス推定量を使用します。 &lt;code&gt;ddof&lt;/code&gt; の選択がモデルのパフォーマンスに影響を与える可能性は低いことに注意してください。</target>
        </trans-unit>
        <trans-unit id="83c28baded6fcaa48849ef740f04075945b33344" translate="yes" xml:space="preserve">
          <source>We use clustering to group together quotes that behave similarly. Here, amongst the &lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;various clustering techniques&lt;/a&gt; available in the scikit-learn, we use &lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;Affinity Propagation&lt;/a&gt; as it does not enforce equal-size clusters, and it can choose automatically the number of clusters from the data.</source>
          <target state="translated">クラスタリングを使用して、同様に動作する引用符をグループ化します。ここでは、scikit-learnで使用可能&lt;a href=&quot;../../modules/clustering#clustering&quot;&gt;なさまざまなクラスタリング手法の&lt;/a&gt;中で、&lt;a href=&quot;../../modules/clustering#affinity-propagation&quot;&gt;アフィニティ伝播&lt;/a&gt;を使用しています。これは、同じサイズのクラスターを強制せず、データからクラスターの数を自動的に選択できるためです。</target>
        </trans-unit>
        <trans-unit id="78d7bc0e66fad92fa188a5bbaa0a7aaa581101c6" translate="yes" xml:space="preserve">
          <source>We use sparse inverse covariance estimation to find which quotes are correlated conditionally on the others. Specifically, sparse inverse covariance gives us a graph, that is a list of connection. For each symbol, the symbols that it is connected too are those useful to explain its fluctuations.</source>
          <target state="translated">どの引用符が他の引用符と条件付きで相関しているかを見つけるために、スパース逆共分散推定を使用します。具体的には、疎な逆共分散は、接続のリストであるグラフを与えてくれます。各記号について、それが接続されている記号は、その揺らぎを説明するのに有用な記号である。</target>
        </trans-unit>
        <trans-unit id="0bc034dd2aa1865c002d495e95115e5b8c709a84" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the 20 newsgroups text document (TF-IDF word frequencies) dataset or on the digits dataset:</source>
          <target state="translated">20個のニュースグループテキスト文書(TF-IDF単語頻度)データセットと数字データセットについて、上記の境界を検証する。</target>
        </trans-unit>
        <trans-unit id="4e3f49993eefd3c100d45584ffc552355d0d52e7" translate="yes" xml:space="preserve">
          <source>We validate the above bounds on the digits dataset or on the 20 newsgroups text document (TF-IDF word frequencies) dataset:</source>
          <target state="translated">我々は、数字データセットまたは20のニュースグループテキスト文書(TF-IDF単語頻度)データセットについて、上記の境界を検証する。</target>
        </trans-unit>
        <trans-unit id="63b1da5381eb76c29e4f139b0a4a0f6fa6f76bca" translate="yes" xml:space="preserve">
          <source>We want to calculate the distance between the Ezeiza Airport (Buenos Aires, Argentina) and the Charles de Gaulle Airport (Paris, France)</source>
          <target state="translated">エゼイザ空港(アルゼンチン・ブエノスアイレス)からシャルル・ド・ゴール空港(フランス・パリ)までの距離を計算してみたいと思います。</target>
        </trans-unit>
        <trans-unit id="4bd2e73735072e414ab7c853666f3b851cc359c1" translate="yes" xml:space="preserve">
          <source>We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is faster, but gives slightly different results (see &lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;Mini Batch K-Means&lt;/a&gt;).</source>
          <target state="translated">MiniBatchKMeansとKMeansのパフォーマンスを比較します。MiniBatchKMeansの方が高速ですが、結果が少し異なります（ミニバッチ&lt;a href=&quot;../../modules/clustering#mini-batch-kmeans&quot;&gt;K-Meansを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="76b3c7c02e156a1d558e413ab95dd6c124236bdc" translate="yes" xml:space="preserve">
          <source>We will also create a transformer that extracts the length of the text and the number of sentences.</source>
          <target state="translated">また、文章の長さや文章の数を抽出するトランスを作成します。</target>
        </trans-unit>
        <trans-unit id="b8ae1ec8b6dd301757e7e59be0a9aeff645f7f18" translate="yes" xml:space="preserve">
          <source>We will cluster a set of data, first with KMeans and then with MiniBatchKMeans, and plot the results. We will also plot the points that are labelled differently between the two algorithms.</source>
          <target state="translated">我々は、最初にKMeansを用いて、次にMiniBatchKMeansを用いて、データのセットをクラスタリングし、結果をプロットします。また、2つのアルゴリズムの間でラベルが異なる点をプロットします。</target>
        </trans-unit>
        <trans-unit id="de730c276ad64150c605a83740871002db6683ff" translate="yes" xml:space="preserve">
          <source>We will compare the performance of both approaches. To quantify the performance of both models, one can compute the mean deviance of the train and test data assuming a Compound Poisson-Gamma distribution of the total claim amount. This is equivalent to a Tweedie distribution with a &lt;code&gt;power&lt;/code&gt; parameter between 1 and 2.</source>
          <target state="translated">両方のアプローチのパフォーマンスを比較します。両方のモデルのパフォーマンスを定量化するために、総請求額の複合ポアソン-ガンマ分布を想定して、列車の平均逸脱度とテストデータを計算できます。これは、 &lt;code&gt;power&lt;/code&gt; パラメータが1〜2のTweedie分布に相当します。</target>
        </trans-unit>
        <trans-unit id="b4cfcf9a2f9d6095c0707be11ca996fe9017bf9d" translate="yes" xml:space="preserve">
          <source>We will probably have to use an estimator or a parametrization of the current estimator that can learn more complex concepts (i.e. has a lower bias). If the training score is much greater than the validation score for the maximum number of training samples, adding more training samples will most likely increase generalization. In the following plot you can see that the SVM could benefit from more training examples.</source>
          <target state="translated">おそらく、より複雑な概念を学習できる(つまりバイアスが低い)現在の推定器の推定器またはパラメトリック化を使用する必要があるでしょう。訓練スコアが最大訓練サンプル数に対する検証スコアよりもはるかに大きい場合、訓練サンプルを追加することで、一般化が増加する可能性が高いです。次のプロットでは、SVMがより多くの訓練例から恩恵を受けていることがわかります。</target>
        </trans-unit>
        <trans-unit id="3f09acb611dde4d0822059b7dd910a6bf0d4be22" translate="yes" xml:space="preserve">
          <source>We will review here the orders of magnitude you can expect from a number of scikit-learn estimators in different contexts and provide some tips and tricks for overcoming performance bottlenecks.</source>
          <target state="translated">ここでは、さまざまな文脈で多くの scikit-learn 推定器に期待できる桁数をレビューし、パフォーマンスのボトルネックを克服するためのヒントとコツを提供します。</target>
        </trans-unit>
        <trans-unit id="7c06ec0897b21dbb460bd6d56256bf3c61c9d6ea" translate="yes" xml:space="preserve">
          <source>We will train our classifier with the following features:</source>
          <target state="translated">以下の特徴量を用いて分類器を訓練します。</target>
        </trans-unit>
        <trans-unit id="3be1dd4cfac1d63b4ce361f8740d86e98582c7b5" translate="yes" xml:space="preserve">
          <source>We will use &lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;Ames Housing&lt;/a&gt; dataset which was first compiled by Dean De Cock and became better known after it was used in Kaggle challenge. It is a set of 1460 residential homes in Ames, Iowa, each described by 80 features. We will use it to predict the final logarithmic price of the houses. In this example we will use only 20 most interesting features chosen using GradientBoostingRegressor() and limit number of entries (here we won&amp;rsquo;t go into the details on how to select the most interesting features).</source>
          <target state="translated">私たちは、使用する&lt;a href=&quot;http://jse.amstat.org/v19n3/decock.pdf&quot;&gt;エイムズ住宅&lt;/a&gt;最初のディーン・デ・巨根でコンパイルされ、それがKaggleチャレンジで使用された後に、より良い知られるようになったデータセットを。アイオワ州エイムズにある1460戸の住宅のセットで、それぞれ80の特徴で説明されています。これを使用して、住宅の最終的な対数価格を予測します。この例では、GradientBoostingRegressor（）を使用して選択された20の最も興味深い機能のみを使用し、エントリ数を制限します（ここでは、最も興味深い機能を選択する方法の詳細については説明しません）。</target>
        </trans-unit>
        <trans-unit id="037b81bcdb33690797b74b53d8be309b975609a6" translate="yes" xml:space="preserve">
          <source>We will use data from the &lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;&amp;ldquo;Current Population Survey&amp;rdquo;&lt;/a&gt; from 1985 to predict wage as a function of various features such as experience, age, or education.</source>
          <target state="translated">1985年の&lt;a href=&quot;https://www.openml.org/d/534&quot;&gt;「人口動態調査」の&lt;/a&gt;データを使用して、経験、年齢、教育などのさまざまな特徴の関数として賃金を予測します。</target>
        </trans-unit>
        <trans-unit id="66b44f9dbf66aa535fbabfa2d804ce4636c53d36" translate="yes" xml:space="preserve">
          <source>We will use the &lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20 newsgroups dataset&lt;/a&gt;, which comprises posts from newsgroups on 20 topics. This dataset is split into train and test subsets based on messages posted before and after a specific date. We will only use posts from 2 categories to speed up running time.</source>
          <target state="translated">20のトピックに関するニュースグループからの投稿で構成される&lt;a href=&quot;../../datasets/index#newsgroups-dataset&quot;&gt;20のニュースグループデータセット&lt;/a&gt;を使用します。このデータセットは、特定の日付の前後に投稿されたメッセージに基づいて、トレーニングとテストのサブセットに分割されます。実行時間を短縮するために、2つのカテゴリの投稿のみを使用します。</target>
        </trans-unit>
        <trans-unit id="889d3befa932d46595e6941bb656f25678ccbe94" translate="yes" xml:space="preserve">
          <source>We will use two datasets: Diabetes dataset which consists of 10 feature variables collected from diabetes patients with an aim to predict disease progression and California Housing dataset for which the target is the median house value for California districts.</source>
          <target state="translated">我々は2つのデータセットを使用する。糖尿病患者から収集した10個の特徴量からなる糖尿病データセットと、カリフォルニア州の住宅価格の中央値を対象としたカリフォルニア住宅データセットである。</target>
        </trans-unit>
        <trans-unit id="7968cd3ef765f8c808b9f8985bbceb6fcebbccfc" translate="yes" xml:space="preserve">
          <source>We will work with the diabetes dataset which consists of 10 features collected from a cohort of diabetes patients. The target is a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">糖尿病患者のコホートから収集した10の特徴からなる糖尿病データセットを用いて作業を行う。ターゲットは、ベースラインから1年後の疾患進行を定量的に測定するものです。</target>
        </trans-unit>
        <trans-unit id="5ab95440492dec088ab7d086a3622b86acadc7e7" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ll define a function that lets us visualize the behavior of each cross-validation object. We&amp;rsquo;ll perform 4 splits of the data. On each split, we&amp;rsquo;ll visualize the indices chosen for the training set (in blue) and the test set (in red).</source>
          <target state="translated">各相互検証オブジェクトの動作を視覚化できる関数を定義します。データの4つの分割を実行します。各分割で、トレーニングセット（青）とテストセット（赤）に対して選択されたインデックスを視覚化します。</target>
        </trans-unit>
        <trans-unit id="70c023ae490fc71ae664cdd80527ab708a5db4b9" translate="yes" xml:space="preserve">
          <source>We&amp;rsquo;ve already encountered some parameters such as &lt;code&gt;use_idf&lt;/code&gt; in the &lt;code&gt;TfidfTransformer&lt;/code&gt;. Classifiers tend to have many parameters as well; e.g., &lt;code&gt;MultinomialNB&lt;/code&gt; includes a smoothing parameter &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;SGDClassifier&lt;/code&gt; has a penalty parameter &lt;code&gt;alpha&lt;/code&gt; and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python &lt;code&gt;help&lt;/code&gt; function to get a description of these).</source>
          <target state="translated">&lt;code&gt;use_idf&lt;/code&gt; などのいくつかのパラメーターはすでに検出されてい &lt;code&gt;TfidfTransformer&lt;/code&gt; 。分類子には多くのパラメーターも含まれる傾向があります。例えば、 &lt;code&gt;MultinomialNB&lt;/code&gt; は平滑化パラメータが含ま &lt;code&gt;alpha&lt;/code&gt; と &lt;code&gt;SGDClassifier&lt;/code&gt; はペナルティパラメータ持つ &lt;code&gt;alpha&lt;/code&gt; 目的関数で、設定可能損失とペナルティ条項を（モジュールのマニュアルを参照してください、またはPythonの使用 &lt;code&gt;help&lt;/code&gt; これらの説明を取得する機能）。</target>
        </trans-unit>
        <trans-unit id="e255008aad692a93735d4b63680bd4a96fdd74f7" translate="yes" xml:space="preserve">
          <source>Weight function used in prediction. Possible values:</source>
          <target state="translated">予測に使用される重み関数。可能な値。</target>
        </trans-unit>
        <trans-unit id="96df76d7fa199e301349be570d5ef4d0bb6a7f3d" translate="yes" xml:space="preserve">
          <source>Weight given to each sample.</source>
          <target state="translated">各サンプルに与えられた重み。</target>
        </trans-unit>
        <trans-unit id="a7a3ce3e7a16ef99378bfef64690454462da25e9" translate="yes" xml:space="preserve">
          <source>Weight matrix, where n_features in the number of visible units and n_components is the number of hidden units.</source>
          <target state="translated">ここで,重み行列は,可視ユニットの数である n_features と,隠れユニットの数である n_components を表します.</target>
        </trans-unit>
        <trans-unit id="77c7b393c2f516d7fd42969c3e5ce51aceb4c82c" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">各サンプルの重み。少なくとも &lt;code&gt;min_samples&lt;/code&gt; の重みを持つサンプルは、それ自体がコアサンプルになります。負の重みを持つサンプルは、そのeps-neighborがコアになるのを妨げる可能性があります。重みは絶対値であり、デフォルトは1であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="d0664e46a183d0a2a2e3afcbc3b6c5ba30a9d4ef" translate="yes" xml:space="preserve">
          <source>Weight of each sample, such that a sample with a weight of at least &lt;code&gt;min_samples&lt;/code&gt; is by itself a core sample; a sample with negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.</source>
          <target state="translated">各サンプルの重み。少なくとも &lt;code&gt;min_samples&lt;/code&gt; の重みを持つサンプル自体がコアサンプルになるようにします。負の重みを持つサンプルは、そのepsネイバーがコアになるのを妨げる可能性があります。重みは絶対値であり、デフォルトは1であることに注意してください。</target>
        </trans-unit>
        <trans-unit id="5cc536fd8cf249ec4c2e295665e0070f1b9cec67" translate="yes" xml:space="preserve">
          <source>Weight of precision in harmonic mean.</source>
          <target state="translated">調和平均の精度の重み。</target>
        </trans-unit>
        <trans-unit id="6cd90e03c276712f974984f65620519bcea49500" translate="yes" xml:space="preserve">
          <source>Weight vector(s).</source>
          <target state="translated">重みベクトル(複数可)。</target>
        </trans-unit>
        <trans-unit id="ac0d2c9a738f9c54a5d208ddac8f22019ff9c627" translate="yes" xml:space="preserve">
          <source>Weight, Waist and Pulse.</source>
          <target state="translated">体重、ウエスト、脈拍。</target>
        </trans-unit>
        <trans-unit id="c74e4e7c5caf95682fb65872b5814741f06c7fac" translate="yes" xml:space="preserve">
          <source>Weighted average</source>
          <target state="translated">加重平均</target>
        </trans-unit>
        <trans-unit id="39392047d0260b6fc1e042825fdae9116d630e28" translate="yes" xml:space="preserve">
          <source>Weighted average probability for each class per sample.</source>
          <target state="translated">サンプルごとの各クラスの加重平均確率。</target>
        </trans-unit>
        <trans-unit id="62deefeab258040887cdf6743a94e11a29168c6f" translate="yes" xml:space="preserve">
          <source>Weighted within-class covariance matrix. It corresponds to &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; where &lt;code&gt;C_k&lt;/code&gt; is the covariance matrix of the samples in class &lt;code&gt;k&lt;/code&gt;. The &lt;code&gt;C_k&lt;/code&gt; are estimated using the (potentially shrunk) biased estimator of covariance. If solver is &amp;lsquo;svd&amp;rsquo;, only exists when &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="translated">重み付けされたクラス内共分散行列。それ相当に &lt;code&gt;sum_k prior_k * C_k&lt;/code&gt; &lt;code&gt;C_k&lt;/code&gt; は、クラス内のサンプルの共分散行列である &lt;code&gt;k&lt;/code&gt; 。 &lt;code&gt;C_k&lt;/code&gt; は、共分散の（潜在的に縮小）バイアスされた推定を用いて推定されます。ソルバーが「svd」の場合、 &lt;code&gt;store_covariance&lt;/code&gt; がTrueの場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="ec852c96538aadaa4b0b959b23f492c546aedd45" translate="yes" xml:space="preserve">
          <source>Weighting type to calculate the score. None means no weighted; &amp;ldquo;linear&amp;rdquo; means linear weighted; &amp;ldquo;quadratic&amp;rdquo; means quadratic weighted.</source>
          <target state="translated">スコアを計算するための重み付けタイプ。なしは加重なしを意味します。「線形」とは、線形加重を意味します。「二次」とは、二次加重を意味します。</target>
        </trans-unit>
        <trans-unit id="9a702ae7f12a23bf0cde9786ae821e6b340d4991" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples (1. for unweighted).</source>
          <target state="translated">個々のサンプルに適用された重み(1.</target>
        </trans-unit>
        <trans-unit id="0c68217fe30f051f7b997da07ad569653cfdb104" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed.</source>
          <target state="translated">個々のサンプルに適用される重み。提供されていない場合は、一様な重みを想定しています。</target>
        </trans-unit>
        <trans-unit id="3070fe087be2b6fbe15f65d4db644297c1112686" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified</source>
          <target state="translated">個々のサンプルに適用される重み。指定されていない場合は,一様な重みが想定されます.class_weight が指定されている場合,これらの重みは class_weight と掛け合わされます(コンストラクタで渡されます).</target>
        </trans-unit>
        <trans-unit id="479d03c6533edea4de55367d8593a7974391f281" translate="yes" xml:space="preserve">
          <source>Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.</source>
          <target state="translated">個々のサンプルに適用される重み。指定されていない場合は,一様な重みが想定されます.class_weight が指定されている場合,これらの重みは class_weight と乗算されます(コンストラクタで渡されます).</target>
        </trans-unit>
        <trans-unit id="86b1d5826d4836f8e129b6346c9e9e60976aafee" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</source>
          <target state="translated">特徴(原始問題の係数)に割り当てられた重み。これは線形カーネルの場合にのみ利用可能です.</target>
        </trans-unit>
        <trans-unit id="4b149f5e057b5bff95048ebeff46bfac0e7a368d" translate="yes" xml:space="preserve">
          <source>Weights assigned to the features.</source>
          <target state="translated">フィーチャーに割り当てられた重み。</target>
        </trans-unit>
        <trans-unit id="4094f309127a892ba2564eecc3f5264343e18998" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">&lt;code&gt;{class_label: weight}&lt;/code&gt; 形式のクラスに関連付けられた重み。Noneの場合、すべてのクラスの重みが1であると想定されます。マルチ出力の問題の場合、dictのリストをyの列と同じ順序で提供できます。</target>
        </trans-unit>
        <trans-unit id="8064bf8d5d6b0c15f7ed813823cc0da43a8bc7e6" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">&lt;code&gt;{class_label: weight}&lt;/code&gt; 形式でクラスに関連付けられた重み。指定されていない場合、すべてのクラスの重みは1になるはずです。</target>
        </trans-unit>
        <trans-unit id="96f3238c530c2df09403ab213fee9515feb36c99" translate="yes" xml:space="preserve">
          <source>Weights associated with classes in the form &lt;code&gt;{class_label: weight}&lt;/code&gt;. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.</source>
          <target state="translated">&lt;code&gt;{class_label: weight}&lt;/code&gt; 形式でクラスに関連付けられた重み。指定されていない場合、すべてのクラスの重みは1になるはずです。複数出力の問題では、辞書のリストをyの列と同じ順序で提供できます。</target>
        </trans-unit>
        <trans-unit id="4a87f3dd4dfb432aa1a51752552e165c9cc23301" translate="yes" xml:space="preserve">
          <source>Weights associated with classes. If not given, all classes are supposed to have weight one.</source>
          <target state="translated">クラスに関連付けられた重さ。与えられていない場合は、すべてのクラスが重み1を持つことになります。</target>
        </trans-unit>
        <trans-unit id="4837ab63e8195a91fca82bbd82590df1bbe7fcc4" translate="yes" xml:space="preserve">
          <source>Weights for each estimator in the boosted ensemble.</source>
          <target state="translated">ブーストされたアンサンブルの各推定器の重み。</target>
        </trans-unit>
        <trans-unit id="5f0089227653fec68913be1b7a199c273e750b44" translate="yes" xml:space="preserve">
          <source>Weights of training data.</source>
          <target state="translated">トレーニングデータの重さ。</target>
        </trans-unit>
        <trans-unit id="55ddc90a49d39d4b40d722b720afa82441019829" translate="yes" xml:space="preserve">
          <source>Weights on each point of the regression. If None, weight is set to 1 (equal weights).</source>
          <target state="translated">回帰の各点の重み。Noneの場合、重みは1に設定される(重みは等しい)。</target>
        </trans-unit>
        <trans-unit id="0946f675292deb36a2ff9f4a33806ccd9e9e1833" translate="yes" xml:space="preserve">
          <source>Weights. If set to None, all weights will be set to 1 (equal weights).</source>
          <target state="translated">重み。Noneに設定すると、すべてのウェイトが1に設定されます(同じウェイト)。</target>
        </trans-unit>
        <trans-unit id="c1f521c553b00dab458900dd1fb3f949a6ba99ab" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class.</source>
          <target state="translated">十分に校正された分類器は,predict_proba 法の出力が信頼度として直接解釈できる確率的な分類器である.例えば,よく校正された(バイナリ)分類器は,predict_proba の値が0.8に近いサンプルの中で,約80%が実際に正のクラスに属するようなサンプルを分類しなければならない.</target>
        </trans-unit>
        <trans-unit id="8b629519ceaa09dd1767dbc350008d2ef28e9249" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.</source>
          <target state="translated">十分に校正された分類器は,predict_proba 法の出力が信頼度として直接解釈できる確率的分類器である.例えば,よく校正された(バイナリ)分類器は,predict_proba の値が0.8に近いサンプルの中で,約80%が実際に正のクラスに属するようなサンプルを分類しなければならない.</target>
        </trans-unit>
        <trans-unit id="6db2509535d857954c618d97c17994b5d42574ae" translate="yes" xml:space="preserve">
          <source>Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:</source>
          <target state="translated">十分に校正された分類器は,predict_proba 法の出力が信頼度として直接解釈できる確率的分類器である.例えば,よくキャリブレーションされた(バイナリ)分類器は,predict_proba値が0.8に近いサンプルの中で,約80%が実際に正のクラスに属するようなサンプルを分類しなければなりません.次のプロットは、異なる分類器の確率的予測がどの程度校正されているかを比較したものです。</target>
        </trans-unit>
        <trans-unit id="830bc34728ca0799f710b4883d58631c6dfded76" translate="yes" xml:space="preserve">
          <source>Wether to include meta-estimators that are somehow special and can not be default-constructed sensibly. These are currently Pipeline, FeatureUnion and GridSearchCV</source>
          <target state="translated">何らかの特殊なメタ推定器を含めるかどうか。これらは現在 Pipeline,FeatureUnion,GridSearchCV です。</target>
        </trans-unit>
        <trans-unit id="d4f157bc9962e4b0dc2a197ed14e50902555d749" translate="yes" xml:space="preserve">
          <source>What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?</source>
          <target state="translated">様々な決定木アルゴリズムにはどのようなものがあり、どのような違いがあるのでしょうか?どれがscikit-learnで実装されていますか?</target>
        </trans-unit>
        <trans-unit id="a1f5f9cd3d06157b8582b1ca4000a5bc395e765a" translate="yes" xml:space="preserve">
          <source>What this example shows us is the behavior &amp;ldquo;rich getting richer&amp;rdquo; of agglomerative clustering that tends to create uneven cluster sizes. This behavior is pronounced for the average linkage strategy, that ends up with a couple of singleton clusters, while in the case of single linkage we get a single central cluster with all other clusters being drawn from noise points around the fringes.</source>
          <target state="translated">この例が示すのは、不均一なクラスターサイズを作成する傾向がある、凝集クラスタリングの「リッチになる」動作です。この動作は、いくつかのシングルトンクラスターで終わる平均リンケージ戦略で顕著ですが、シングルリンケージの場合、フリンジの周囲のノイズポイントから他のすべてのクラスターが描画された単一の中央クラスターが得られます。</target>
        </trans-unit>
        <trans-unit id="32580ac608fcdadc1c2050695a6c24cae1fcef1f" translate="yes" xml:space="preserve">
          <source>What we can see that:</source>
          <target state="translated">それがわかるもの。</target>
        </trans-unit>
        <trans-unit id="bd10ebd98b3e733be938ffeb72efbd3793589a2c" translate="yes" xml:space="preserve">
          <source>When &lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt;&lt;code&gt;LatentDirichletAllocation&lt;/code&gt;&lt;/a&gt; is applied on a &amp;ldquo;document-term&amp;rdquo; matrix, the matrix will be decomposed into a &amp;ldquo;topic-term&amp;rdquo; matrix and a &amp;ldquo;document-topic&amp;rdquo; matrix. While &amp;ldquo;topic-term&amp;rdquo; matrix is stored as &lt;code&gt;components_&lt;/code&gt; in the model, &amp;ldquo;document-topic&amp;rdquo; matrix can be calculated from &lt;code&gt;transform&lt;/code&gt; method.</source>
          <target state="translated">とき&lt;a href=&quot;generated/sklearn.decomposition.latentdirichletallocation#sklearn.decomposition.LatentDirichletAllocation&quot;&gt; &lt;code&gt;LatentDirichletAllocation&lt;/code&gt; は&lt;/a&gt;、「ドキュメント用語」マトリックスに適用され、行列は「トピック用語」マトリックスと「ドキュメントのトピック」行列に分解されます。「topic-term」マトリックスはモデル内の &lt;code&gt;components_&lt;/code&gt; として保存されますが、「document-topic」マトリックスは &lt;code&gt;transform&lt;/code&gt; メソッドから計算できます。</target>
        </trans-unit>
        <trans-unit id="0c7daae89d35601e80a373ec7022d580692d615d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;False&lt;/code&gt;, checks are evaluated when &lt;code&gt;check_estimator&lt;/code&gt; is called. When &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;check_estimator&lt;/code&gt; returns a generator that yields (estimator, check) tuples. The check is run by calling &lt;code&gt;check(estimator)&lt;/code&gt;.</source>
          <target state="translated">場合は &lt;code&gt;False&lt;/code&gt; のとき、チェックが評価され &lt;code&gt;check_estimator&lt;/code&gt; が呼ばれています。 &lt;code&gt;True&lt;/code&gt; の場合、 &lt;code&gt;check_estimator&lt;/code&gt; は（estimator、check）タプルを生成するジェネレーターを返します。チェックは、 &lt;code&gt;check(estimator)&lt;/code&gt; を呼び出すことによって実行されます。</target>
        </trans-unit>
        <trans-unit id="d35c02f0322e905eb57e225a27ca83f7c5f6cc47" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=0&lt;/code&gt;, columns which only contained missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">とき &lt;code&gt;axis=0&lt;/code&gt; 、のみで欠損値が含まれていた列 &lt;code&gt;fit&lt;/code&gt; 時に破棄されている &lt;code&gt;transform&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7cf98e7188203ecb0d30e3564b161d5393433799" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;axis=1&lt;/code&gt;, an exception is raised if there are rows for which it is not possible to fill in the missing values (e.g., because they only contain missing values).</source>
          <target state="translated">とき &lt;code&gt;axis=1&lt;/code&gt; （彼らは唯一の欠損値が含まれているため、例えば）欠けている値を入力することはできませんされている行がある場合は、例外が発生します。</target>
        </trans-unit>
        <trans-unit id="efffb9d033635c3e5b63e6f6f527201ab0e206e9" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;ccp_alpha&lt;/code&gt; is set to zero and keeping the other default parameters of &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. In this example, setting &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; maximizes the testing accuracy.</source>
          <target state="translated">とき &lt;code&gt;ccp_alpha&lt;/code&gt; をゼロに設定し、他のデフォルトパラメータ保っている&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; を&lt;/a&gt;、ツリーoverfits、100％のトレーニングの精度と88％の検査精度につながります。アルファが増加すると、より多くのツリーが枝刈りされるため、より一般化された決定木が作成されます。この例では、 &lt;code&gt;ccp_alpha=0.015&lt;/code&gt; を設定すると、テストの精度が最大になります。</target>
        </trans-unit>
        <trans-unit id="4bce6b6fbd4b9fe79bfc7468f7df9f938d3ce841" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;fit&lt;/code&gt; does not converge, &lt;code&gt;cluster_centers_&lt;/code&gt; becomes an empty array and all training samples will be labelled as &lt;code&gt;-1&lt;/code&gt;. In addition, &lt;code&gt;predict&lt;/code&gt; will then label every sample as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; が収束しない場合、 &lt;code&gt;cluster_centers_&lt;/code&gt; は空の配列になり、すべてのトレーニングサンプルには &lt;code&gt;-1&lt;/code&gt; のラベルが付けられます。さらに、 &lt;code&gt;predict&lt;/code&gt; はすべてのサンプルに &lt;code&gt;-1&lt;/code&gt; のラベルを付けます。</target>
        </trans-unit>
        <trans-unit id="f7c77c5939a6b7b3a7ed9ce47827d49725522a57" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;gamma&lt;/code&gt; is very small, the model is too constrained and cannot capture the complexity or &amp;ldquo;shape&amp;rdquo; of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.</source>
          <target state="translated">とき &lt;code&gt;gamma&lt;/code&gt; 非常に小さく、モデルがあまりにも制約さと複雑さやデータの「形状」をキャプチャすることはできません。選択したサポートベクトルの影響範囲には、トレーニングセット全体が含まれます。結果のモデルは、2つのクラスの任意のペアの高密度の中心を分離する超平面のセットを持つ線形モデルと同様に動作します。</target>
        </trans-unit>
        <trans-unit id="6579a89bba02e2aa5596acf0a356de3285b5831f" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;learning_method&lt;/code&gt; is &amp;lsquo;online&amp;rsquo;, use mini-batch update. Otherwise, use batch update.</source>
          <target state="translated">とき &lt;code&gt;learning_method&lt;/code&gt; が「オンライン」で、ミニバッチ更新を使用します。それ以外の場合は、バッチ更新を使用します。</target>
        </trans-unit>
        <trans-unit id="1789662661fe322dc45828ec3c3eb62749643034" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;novelty&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; be aware that you must only use &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; on new unseen data and not on the training samples as this would lead to wrong results. The scores of abnormality of the training samples are always accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute.</source>
          <target state="translated">ときに &lt;code&gt;novelty&lt;/code&gt; に設定されている &lt;code&gt;True&lt;/code&gt; あなただけの使用がなければならないことに注意して &lt;code&gt;predict&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; と &lt;code&gt;score_samples&lt;/code&gt; 、これは間違った結果につながるとして、学習サンプルにない新しい見えないデータにします。トレーニングサンプルの異常スコアには、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を介して常にアクセスできます。</target>
        </trans-unit>
        <trans-unit id="6539967754248da8802fa11e92b0d1b2532b93b8" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;predict_proba&lt;/code&gt; is used by each estimator (i.e. most of the time for &lt;code&gt;stack_method='auto'&lt;/code&gt; or specifically for &lt;code&gt;stack_method='predict_proba'&lt;/code&gt;), The first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.</source>
          <target state="translated">場合 &lt;code&gt;predict_proba&lt;/code&gt; がそれぞれ推定（すなわち、ほとんどの時間で使用される &lt;code&gt;stack_method='auto'&lt;/code&gt; または特異的のため &lt;code&gt;stack_method='predict_proba'&lt;/code&gt; ）、各推定器によって予測された最初の列は、バイナリ分類問題の場合には削除されます。実際、両方の機能は完全に同一線上にあります。</target>
        </trans-unit>
        <trans-unit id="380c86407d2b15e6e735d8a020999525510d4000" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold for each class. Otherwise, leave &lt;code&gt;random_state&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;shuffle&lt;/code&gt; がTrueの場合、 &lt;code&gt;random_state&lt;/code&gt; はインデックスの順序に影響を与え、各クラスの各フォールドのランダム性を制御します。それ以外の場合は、 &lt;code&gt;random_state&lt;/code&gt; を &lt;code&gt;None&lt;/code&gt; のままにします。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="dba0ae97777bf9e3aca974d6ebb1591964b94b4e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;shuffle&lt;/code&gt; is True, &lt;code&gt;random_state&lt;/code&gt; affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;shuffle&lt;/code&gt; がTrueの場合、 &lt;code&gt;random_state&lt;/code&gt; はインデックスの順序に影響を与え、各フォールドのランダム性を制御します。それ以外の場合、このパラメーターは効果がありません。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="2f36c5dece71799d4edbabcfff5ea8ed2f825b4d" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">ときに &lt;code&gt;true positive + false negative == 0&lt;/code&gt; 、リコールは0を返し、上げ &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; を。この動作は &lt;code&gt;zero_division&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="43540f9f914266a4b6caeeeeef53fc90c0648c6e" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt; or &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, f-score returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;true positive + false positive == 0&lt;/code&gt; 又は &lt;code&gt;true positive + false negative == 0&lt;/code&gt; 、F-スコアが0を返し、上げる &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; を。この動作は &lt;code&gt;zero_division&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="ba4ca3b8ef57a04587026d0caa7a41ba81b60463" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision is undefined; When &lt;code&gt;true positive + false negative == 0&lt;/code&gt;, recall is undefined. In such cases, by default the metric will be set to 0, as will f-score, and &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; will be raised. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">ときに &lt;code&gt;true positive + false positive == 0&lt;/code&gt; 、精度が定義されていません。ときに &lt;code&gt;true positive + false negative == 0&lt;/code&gt; 、リコールが定義されていません。このような場合、デフォルトでは、メトリックはfスコアと同様に0に設定され、 &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; が発生します。この動作は &lt;code&gt;zero_division&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="c54bb2862f6516891f7056fa35777ac8bd097188" translate="yes" xml:space="preserve">
          <source>When &lt;code&gt;true positive + false positive == 0&lt;/code&gt;, precision returns 0 and raises &lt;code&gt;UndefinedMetricWarning&lt;/code&gt;. This behavior can be modified with &lt;code&gt;zero_division&lt;/code&gt;.</source>
          <target state="translated">ときに &lt;code&gt;true positive + false positive == 0&lt;/code&gt; 、精度は0を返し、上げ &lt;code&gt;UndefinedMetricWarning&lt;/code&gt; を。この動作は &lt;code&gt;zero_division&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="70168d4d772dfaf9b58be440f7660f3adf7f21be" translate="yes" xml:space="preserve">
          <source>When False, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; both being sparse will yield sparse output. When True, output will always be a dense array.</source>
          <target state="translated">Falseの場合、 &lt;code&gt;a&lt;/code&gt; と &lt;code&gt;b&lt;/code&gt; の両方がスパースであると、スパース出力が生成されます。Trueの場合、出力は常に密な配列になります。</target>
        </trans-unit>
        <trans-unit id="f3329fe0cead2a208482794593628ff4dce53789" translate="yes" xml:space="preserve">
          <source>When False, either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;b&lt;/code&gt; being sparse will yield sparse output. When True, output will always be an array.</source>
          <target state="translated">Falseの場合、 &lt;code&gt;a&lt;/code&gt; または &lt;code&gt;b&lt;/code&gt; のいずれかがスパースになると、スパース出力が生成されます。Trueの場合、出力は常に配列になります。</target>
        </trans-unit>
        <trans-unit id="1bb4bf21b8d21fdceb61000bf23d6624de5a3ca6" translate="yes" xml:space="preserve">
          <source>When False, only the predictions of estimators will be used as training data for &lt;code&gt;final_estimator&lt;/code&gt;. When True, the &lt;code&gt;final_estimator&lt;/code&gt; is trained on the predictions as well as the original training data.</source>
          <target state="translated">Falseの場合、推定量の予測のみが &lt;code&gt;final_estimator&lt;/code&gt; のトレーニングデータとして使用されます。Trueの場合、 &lt;code&gt;final_estimator&lt;/code&gt; は、元のトレーニングデータだけでなく予測についてもトレーニングされます。</target>
        </trans-unit>
        <trans-unit id="0baad85c0e4d647371baa109869739d44cb0f600" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are divided by &lt;code&gt;n_samples&lt;/code&gt; times &lt;code&gt;components_&lt;/code&gt; to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">Trueの場合（デフォルトはfalse） &lt;code&gt;components_&lt;/code&gt; のベクトルがで分割されている &lt;code&gt;n_samples&lt;/code&gt; 時間が &lt;code&gt;components_&lt;/code&gt; 単位の成分ごとの分散と相関のない出力を確保するために。</target>
        </trans-unit>
        <trans-unit id="3eaa2881688032030c765cb871d4c787aff03fe7" translate="yes" xml:space="preserve">
          <source>When True (False by default) the &lt;code&gt;components_&lt;/code&gt; vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.</source>
          <target state="translated">True（デフォルトはFalse）の場合、 &lt;code&gt;components_&lt;/code&gt; ベクトルはn_samplesの平方根で乗算され、特異値で除算されて、コンポーネントごとの分散が無相関の出力を保証します。</target>
        </trans-unit>
        <trans-unit id="afb8087ad0f4a499dd14f72be9807792c351ecd8" translate="yes" xml:space="preserve">
          <source>When True, an absolute value is applied to the features matrix prior to returning it. When used in conjunction with alternate_sign=True, this significantly reduces the inner product preservation property.</source>
          <target state="translated">True の場合、特徴量行列を返す前に絶対値が適用されます。alternate_sign=True と組み合わせて使用すると、内部積保存プロパティが大幅に削減されます。</target>
        </trans-unit>
        <trans-unit id="204d5c48d22bd9cd74d36182840231c3ecac4f55" translate="yes" xml:space="preserve">
          <source>When True, an alternating sign is added to the features as to approximately conserve the inner product in the hashed space even for small n_features. This approach is similar to sparse random projection.</source>
          <target state="translated">真の場合、小さな n_特徴量でもハッシュ化空間の内積をほぼ保存するように、特徴量に交互符号を追加します。このアプローチは,疎なランダム射影に似ています.</target>
        </trans-unit>
        <trans-unit id="e4283276989a341cb6ca6bb94564d0f53f92318b" translate="yes" xml:space="preserve">
          <source>When X and/or Y are CSR sparse matrices and they are not already in canonical format, this function modifies them in-place to make them canonical.</source>
          <target state="translated">X および/または Y が CSR の疎な行列であり,それらがまだ正準化されていない場合,この関数はそれらを正準化するためにその場で修正します.</target>
        </trans-unit>
        <trans-unit id="e08ec276d8bba6d4be8a6e677715ca1a35d4dd15" translate="yes" xml:space="preserve">
          <source>When a grouped cross-validator is used, the group labels are also passed on to the &lt;code&gt;split&lt;/code&gt; method of the cross-validator. The cross-validator uses them for grouping the samples while splitting the dataset into train/test set.</source>
          <target state="translated">グループ化されたクロスバリデーターを使用すると、グループラベルもクロスバリデーターの &lt;code&gt;split&lt;/code&gt; メソッドに渡されます。クロスバリデーターは、データセットをトレーニング/テストセットに分割しながら、サンプルをグループ化するためにそれらを使用します。</target>
        </trans-unit>
        <trans-unit id="96fd8c38f0f9978d89774efb70a7d42aee5d30ee" translate="yes" xml:space="preserve">
          <source>When a specific number of neighbors is queried (using &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt;), the definition of &lt;code&gt;n_neighbors&lt;/code&gt; is ambiguous since it can either include each training point as its own neighbor, or exclude them. Neither choice is perfect, since including them leads to a different number of non-self neighbors during training and testing, while excluding them leads to a difference between &lt;code&gt;fit(X).transform(X)&lt;/code&gt; and &lt;code&gt;fit_transform(X)&lt;/code&gt;, which is against scikit-learn API. In &lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt;&lt;code&gt;KNeighborsTransformer&lt;/code&gt;&lt;/a&gt; we use the definition which includes each training point as its own neighbor in the count of &lt;code&gt;n_neighbors&lt;/code&gt;. However, for compatibility reasons with other estimators which use the other definition, one extra neighbor will be computed when &lt;code&gt;mode == 'distance'&lt;/code&gt;. To maximise compatibility with all estimators, a safe choice is to always include one extra neighbor in a custom nearest neighbors estimator, since unnecessary neighbors will be filtered by following estimators.</source>
          <target state="translated">隣人の特定の番号は（使用して照会すると&lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt; &lt;code&gt;KNeighborsTransformer&lt;/code&gt; を&lt;/a&gt;）、の定義 &lt;code&gt;n_neighbors&lt;/code&gt; それがいずれかの独自の隣人として、各トレーニングのポイントを含めるか、またはそれらを除外することができますので、あいまいです。どちらの選択も完璧ではありません。なぜなら、それらを含めると、トレーニングとテスト中に非自己ネイバーの数が異なり、それらを除外すると、 &lt;code&gt;fit(X).transform(X)&lt;/code&gt; と &lt;code&gt;fit_transform(X)&lt;/code&gt; の間に違いが生じ、scikitに反するからです。 -APIを学びます。で&lt;a href=&quot;generated/sklearn.neighbors.kneighborstransformer#sklearn.neighbors.KNeighborsTransformer&quot;&gt; &lt;code&gt;KNeighborsTransformer&lt;/code&gt; &lt;/a&gt;我々は数に独自の隣人として、各トレーニングのポイントを含んでいる定義を使用 &lt;code&gt;n_neighbors&lt;/code&gt; 。ただし、他の定義を使用する他の推定量との互換性の理由から、 &lt;code&gt;mode == 'distance'&lt;/code&gt; 場合、1つの追加のネイバーが計算されます。すべての推定量との互換性を最大化するために、安全な選択は、カスタム最近傍推定量に常に1つの追加の近傍を含めることです。これは、不要な近傍が次の推定量によってフィルタリングされるためです。</target>
        </trans-unit>
        <trans-unit id="6c0f90cdc44694d62adb6ac9bccd5513d6bf148f" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, &lt;code&gt;fit&lt;/code&gt; will result in a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">すべてのトレーニングサンプルの類似性と設定が等しい場合、クラスターの中心とラベルの割り当ては設定に依存します。設定が類似度よりも小さい場合、 &lt;code&gt;fit&lt;/code&gt; は単一のクラスター中心となり、すべてのサンプルに対してラベル &lt;code&gt;0&lt;/code&gt; になります。それ以外の場合は、すべてのトレーニングサンプルが独自のクラスターセンターになり、一意のラベルが割り当てられます。</target>
        </trans-unit>
        <trans-unit id="c440a8e563c9cc7b9752f14072284d81697bdfcd" translate="yes" xml:space="preserve">
          <source>When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, a single cluster center and label &lt;code&gt;0&lt;/code&gt; for every sample will be returned. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.</source>
          <target state="translated">すべてのトレーニングサンプルの類似性と設定が等しい場合、クラスターの中心とラベルの割り当ては設定に依存します。設定が類似点よりも小さい場合、単一のクラスター中心とすべてのサンプルのラベル &lt;code&gt;0&lt;/code&gt; が返されます。それ以外の場合は、すべてのトレーニングサンプルが独自のクラスターセンターになり、一意のラベルが割り当てられます。</target>
        </trans-unit>
        <trans-unit id="2494d11b03713922afdad3fa1bc52bb7064577b4" translate="yes" xml:space="preserve">
          <source>When alpha is very large, the regularization effect dominates the squared loss function and the coefficients tend to zero. At the end of the path, as alpha tends toward zero and the solution tends towards the ordinary least squares, coefficients exhibit big oscillations. In practise it is necessary to tune alpha in such a way that a balance is maintained between both.</source>
          <target state="translated">アルファが非常に大きい場合、正則化効果が二乗損失関数を支配し、係数はゼロになる傾向があります。パスの終点では、アルファがゼロに傾き、解が通常の最小二乗に傾くと、係数は大きな振動を示します。実際には、両方のバランスが維持されるようにアルファを調整する必要があります。</target>
        </trans-unit>
        <trans-unit id="e93a4fdf68d407dc869190eca6cd7dfaf57ad986" translate="yes" xml:space="preserve">
          <source>When applying LOF for outlier detection, there are no &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; methods but only a &lt;code&gt;fit_predict&lt;/code&gt; method. The scores of abnormality of the training samples are accessible through the &lt;code&gt;negative_outlier_factor_&lt;/code&gt; attribute. Note that &lt;code&gt;predict&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;score_samples&lt;/code&gt; can be used on new unseen data when LOF is applied for novelty detection, i.e. when the &lt;code&gt;novelty&lt;/code&gt; parameter is set to &lt;code&gt;True&lt;/code&gt;. See &lt;a href=&quot;#novelty-with-lof&quot;&gt;Novelty detection with Local Outlier Factor&lt;/a&gt;.</source>
          <target state="translated">外れ値検出のためのLOFを適用する場合、何も存在しない &lt;code&gt;predict&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; と &lt;code&gt;score_samples&lt;/code&gt; 方法だけ &lt;code&gt;fit_predict&lt;/code&gt; の方法を。トレーニングサンプルの異常スコアには、 &lt;code&gt;negative_outlier_factor_&lt;/code&gt; 属性を介してアクセスできます。注 &lt;code&gt;predict&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; と &lt;code&gt;score_samples&lt;/code&gt; をするとき、すなわち、LOFは、ノベルティ検出に適用した場合に、新たな目に見えないデータに使用することができ &lt;code&gt;novelty&lt;/code&gt; パラメータに設定されて &lt;code&gt;True&lt;/code&gt; 。&lt;a href=&quot;#novelty-with-lof&quot;&gt;ローカル異常値因子による新規性検出を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="2ec6d5a6d0d8178f2ec5cc1ea59ce167ddd0a98a" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">語彙を構築する際に、文書の頻度が指定された閾値よりも厳密に高い単語(コーパス固有の停止語)を無視します。floatで範囲[0.0,1.0]の場合、パラメータは文書の割合を表し、整数の絶対数を表します。語彙がNoneでない場合、このパラメータは無視されます。</target>
        </trans-unit>
        <trans-unit id="869141a5ff3e1444543cdaec8c9968684d76b66e" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">語彙を構築する際に、文書の頻度が指定された閾値よりも厳密に高い単語(コーパス固有の停止語)を無視します。floatの場合、このパラメータは文書の割合を表し、整数の絶対数を表します。語彙が None でない場合、このパラメータは無視されます。</target>
        </trans-unit>
        <trans-unit id="d83f4236f3f25a9891417b446059c6cca3f6ec76" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">語彙を構築する際には、文書の頻度が与えられたしきい値よりも厳密に低い用語を無視します。この値は、文献ではカットオフとも呼ばれています。floatを[0.0,1.0]の範囲で指定すると、このパラメータは文書の割合を表し、整数の絶対数を表します。語彙がNoneでない場合、このパラメータは無視されます。</target>
        </trans-unit>
        <trans-unit id="1f13ad80586b74ad6fdc521fde036c051cf6e0e7" translate="yes" xml:space="preserve">
          <source>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</source>
          <target state="translated">語彙を構築する際には、文書の頻度が与えられたしきい値よりも厳密に低い用語を無視します。この値は、文献ではカットオフとも呼ばれています。floatの場合、このパラメータは文書の割合を表し、整数の絶対数を表します。語彙がNoneでない場合、このパラメータは無視されます。</target>
        </trans-unit>
        <trans-unit id="757013c910e6b4628ced11d689b0016d8c17e540" translate="yes" xml:space="preserve">
          <source>When calculating class-wise multilabel confusion matrix \(C\), the count of true negatives for class \(i\) is \(C_{i,0,0}\), false negatives is \(C_{i,1,0}\), true positives is \(C_{i,1,1}\) and false positives is \(C_{i,0,1}\).</source>
          <target state="translated">class-wise multilabel confusion matrix \(C)を計算すると、class ﾞの真偽の数は、(C\(i)の場合は、(C_{i,0,0}\)、偽の数は、(C_{i,1,0}\)、真の陽性は、(C_{i,1,1})、偽の陽性は、(C_{i,0,1})となる。</target>
        </trans-unit>
        <trans-unit id="8ed788b8f95069d89dcb15b1bea5b5e7da9a9648" translate="yes" xml:space="preserve">
          <source>When calling &lt;code&gt;fit&lt;/code&gt;, an affinity matrix is constructed using either kernel function such the Gaussian (aka RBF) kernel of the euclidean distanced &lt;code&gt;d(X, X)&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; を呼び出すと、ユークリッド距離 &lt;code&gt;d(X, X)&lt;/code&gt; のガウス（別名RBF）カーネルなどのカーネル関数を使用して、親和性行列が構築されます。</target>
        </trans-unit>
        <trans-unit id="5c5941b79e3bd733fe2a806a66f459a87c19af32" translate="yes" xml:space="preserve">
          <source>When dealing with a cleaned dataset, the preprocessing can be automatic by using the data types of the column to decide whether to treat a column as a numerical or categorical feature. &lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt;&lt;/a&gt; gives this possibility. First, let&amp;rsquo;s only select a subset of columns to simplify our example.</source>
          <target state="translated">クリーンアップされたデータセットを処理する場合、列のデータ型を使用して列を数値またはカテゴリの特徴として扱うかどうかを決定することにより、前処理を自動化できます。&lt;a href=&quot;../../modules/generated/sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt; &lt;code&gt;sklearn.compose.make_column_selector&lt;/code&gt; &lt;/a&gt;はこの可能性を提供します。まず、例を単純化するために、列のサブセットのみを選択しましょう。</target>
        </trans-unit>
        <trans-unit id="da9c4333516559f145c3dcae1d1fd9f5e0da891d" translate="yes" xml:space="preserve">
          <source>When doing classification in scikit-learn, &lt;code&gt;y&lt;/code&gt; is a vector of integers or strings.</source>
          <target state="translated">scikit-learnで分類を行う場合、 &lt;code&gt;y&lt;/code&gt; は整数または文字列のベクトルです。</target>
        </trans-unit>
        <trans-unit id="fb08dbb1ad477236e66b72b0cef9bccfd1ceec61" translate="yes" xml:space="preserve">
          <source>When doing supervised learning, a simple sanity check consists of comparing one&amp;rsquo;s estimator against simple rules of thumb. &lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt;&lt;code&gt;DummyClassifier&lt;/code&gt;&lt;/a&gt; implements several such simple strategies for classification:</source>
          <target state="translated">教師あり学習を行う場合、単純な健全性チェックでは、推定量と単純な経験則を比較します。&lt;a href=&quot;generated/sklearn.dummy.dummyclassifier#sklearn.dummy.DummyClassifier&quot;&gt; &lt;code&gt;DummyClassifier&lt;/code&gt; は&lt;/a&gt;、分類のためのいくつかのそのような単純な戦略を実装します。</target>
        </trans-unit>
        <trans-unit id="3bf9748662d1dbe365a15ba24b002d016f11408b" translate="yes" xml:space="preserve">
          <source>When evaluating different settings (&amp;ldquo;hyperparameters&amp;rdquo;) for estimators, such as the &lt;code&gt;C&lt;/code&gt; setting that must be manually set for an SVM, there is still a risk of overfitting &lt;em&gt;on the test set&lt;/em&gt; because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can &amp;ldquo;leak&amp;rdquo; into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called &amp;ldquo;validation set&amp;rdquo;: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.</source>
          <target state="translated">SVMに対して手動で設定する必要がある &lt;code&gt;C&lt;/code&gt; 設定など、推定器のさまざまな設定（「ハイパーパラメーター」）を評価する場合、推定器が最適に機能するまでパラメーターを微調整できるため、&lt;em&gt;テストセット&lt;/em&gt;に過剰適合のリスクがあります。このようにして、テストセットに関する知識がモデルに「漏れ」、評価メトリックが汎化パフォーマンスについて報告しなくなります。この問題を解決するために、データセットのさらに別の部分をいわゆる「検証セット」として提示できます。トレーニングはトレーニングセットで続行され、その後、検証セットで評価が行われ、実験が成功したように見えます。 、テストセットで最終評価を行うことができます。</target>
        </trans-unit>
        <trans-unit id="b6d52e3adfb55f9048c5ef57545d77d640ae7db4" translate="yes" xml:space="preserve">
          <source>When evaluating text classifiers on the 20 Newsgroups data, you should strip newsgroup-related metadata. In scikit-learn, you can do this by setting &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt;. The F-score will be lower because it is more realistic.</source>
          <target state="translated">20のニュースグループデータのテキスト分類子を評価するときは、ニュースグループ関連のメタデータを削除する必要があります。scikit-learnでは、 &lt;code&gt;remove=('headers', 'footers', 'quotes')&lt;/code&gt; 設定することでこれを行うことができます。より現実的であるため、Fスコアは低くなります。</target>
        </trans-unit>
        <trans-unit id="b44ace677df67ec762b5f7d213266d4181953b1c" translate="yes" xml:space="preserve">
          <source>When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a &lt;strong&gt;development set&lt;/strong&gt; (to be fed to the &lt;code&gt;GridSearchCV&lt;/code&gt; instance) and an &lt;strong&gt;evaluation set&lt;/strong&gt; to compute performance metrics.</source>
          <target state="translated">結果のモデルを評価するときは、グリッド検索プロセス中に見られなかった保留​​されたサンプルでそれを行うことが重要です。データを&lt;strong&gt;開発セット&lt;/strong&gt;（ &lt;code&gt;GridSearchCV&lt;/code&gt; インスタンスに供給する）と&lt;strong&gt;評価セット&lt;/strong&gt;に分割することをお勧めしますパフォーマンス指標を計算します。</target>
        </trans-unit>
        <trans-unit id="1a86b5b9ee94c593acad1b7968fd00ab3b487df9" translate="yes" xml:space="preserve">
          <source>When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature &amp;ldquo;f&amp;rdquo; that can take on the values &amp;ldquo;ham&amp;rdquo; and &amp;ldquo;spam&amp;rdquo; will become two features in the output, one signifying &amp;ldquo;f=ham&amp;rdquo;, the other &amp;ldquo;f=spam&amp;rdquo;.</source>
          <target state="translated">フィーチャー値が文字列の場合、このトランスフォーマーはバイナリーワンホット（別名one-of-K）コーディングを実行します。1つのブール値フィーチャーが、そのフィーチャーが取り得る可能なストリング値ごとに作成されます。たとえば、値「ham」と「spam」をとることができる機能「f」は、出力で2つの機能になります。1つは「f = ham」を意味し、もう1つは「f = spam」を意味します。</target>
        </trans-unit>
        <trans-unit id="81d685e408d1bc940e50f235a77cb7283ea2909d" translate="yes" xml:space="preserve">
          <source>When features are collinear, permutating one feature will have little effect on the models performance because it can get the same information from a correlated feature. One way to handle multicollinear features is by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster. First, we plot a heatmap of the correlated features:</source>
          <target state="translated">特徴がコリニアな場合、1つの特徴を並べ替えても、相関のある特徴から同じ情報を得ることができるので、モデルの性能にはほとんど影響を与えません。複数の共線性特徴を扱う方法の1つは、スピアマン順位相関で階層的クラスタリングを実行し、しきい値を選択し、各クラスタから1つの特徴を保持することです。まず、相関した特徴のヒートマップをプロットします。</target>
        </trans-unit>
        <trans-unit id="e3d8c3576d6baaf6f77dc4e34223e91a48a8c662" translate="yes" xml:space="preserve">
          <source>When fitting a model to a matrix X_train and evaluating it against a matrix X_test, it is essential that X_train and X_test have the same number of features (X_train.shape[1] == X_test.shape[1]). This may not be the case if you load the files individually with load_svmlight_file.</source>
          <target state="translated">モデルを行列 X_train にフィットし,それを行列 X_test に対して評価する場合,X_train と X_test が同じ数の特徴量を持つことが必須です(X_train.shape[1]==X_test.shape[1]).load_svmlight_file を使って個別にロードした場合はそうはいかないかもしれません。</target>
        </trans-unit>
        <trans-unit id="618912ddd6add9bc398f8cf8343e255bb5f0ac59" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;</source>
          <target state="translated">疑問がある場合は、&lt;a href=&quot;#ransac-regression&quot;&gt;RANSACを&lt;/a&gt;使用してください</target>
        </trans-unit>
        <trans-unit id="4150d19b2bd7fadd0941f6ca06455157d317e492" translate="yes" xml:space="preserve">
          <source>When in doubt, use &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;.</source>
          <target state="translated">疑わしい場合は、&lt;a href=&quot;#ransac-regression&quot;&gt;RANSACを&lt;/a&gt;使用してください。</target>
        </trans-unit>
        <trans-unit id="7ebc317e66e94c9c3ce7d1b975021eefa97b880b" translate="yes" xml:space="preserve">
          <source>When individual estimators are fast to train or predict using &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; can result in slower performance due to the overhead of spawning processes.</source>
          <target state="translated">個々の推定器が &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; を使用して高速にトレーニングまたは予測すると、プロセスの生成のオーバーヘッドによりパフォーマンスが低下する可能性があります。</target>
        </trans-unit>
        <trans-unit id="5223d409a8ec7650bd8559a52e22ddb32a950ada" translate="yes" xml:space="preserve">
          <source>When loss=&amp;rdquo;modified_huber&amp;rdquo;, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.</source>
          <target state="translated">loss =&amp;rdquo; modified_huber&amp;rdquo;の場合、確率推定はハードなゼロと1になる可能性があるため、対数を取ることはできません。</target>
        </trans-unit>
        <trans-unit id="3169e6d4a043a16249e2b124b1d248f9aac1b1e2" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics, with \(K\) corresponding to &lt;code&gt;n_components&lt;/code&gt; in the API:</source>
          <target state="translated">テキストコーパスをモデル化する場合、モデルは、\（D \）ドキュメントと\（K \）トピックを持ち、\（K \）がAPIの &lt;code&gt;n_components&lt;/code&gt; に対応するコーパスに対して次の生成プロセスを想定しています。</target>
        </trans-unit>
        <trans-unit id="63fb46936ec9f0c71e69b897d1f9d91941d422e3" translate="yes" xml:space="preserve">
          <source>When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics:</source>
          <target state="translated">テキストコーパスをモデル化する際には、コーパスが \(D\)documents and \(K\)topics の場合、以下のような生成過程を想定している。</target>
        </trans-unit>
        <trans-unit id="744347c999c68da3080dd50ae1b985e4b97e385e" translate="yes" xml:space="preserve">
          <source>When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.</source>
          <target state="translated">混合物あたりの点数が不十分な場合、共分散行列の推定が困難になり、共分散を人為的に正則化しない限り、アルゴリズムは発散し、無限の尤度で解を見つけることが知られています。</target>
        </trans-unit>
        <trans-unit id="e24f09e860711fd3a63a21415134601f90e4efc0" translate="yes" xml:space="preserve">
          <source>When parametrized by error using the parameter &lt;code&gt;tol&lt;/code&gt;: argmin ||gamma||_0 subject to ||y - Xgamma||^2 &amp;lt;= tol</source>
          <target state="translated">パラメーター &lt;code&gt;tol&lt;/code&gt; を使用してエラーによってパラメーター化された場合：argmin || gamma || _0は|| y-Xgamma || ^ 2 &amp;lt;= tolの影響を受ける</target>
        </trans-unit>
        <trans-unit id="70b3334d846e26366c45a04fb1a4a39af8e3ec45" translate="yes" xml:space="preserve">
          <source>When parametrized by the number of non-zero coefficients using &lt;code&gt;n_nonzero_coefs&lt;/code&gt;: argmin ||y - Xgamma||^2 subject to ||gamma||_0 &amp;lt;= n_{nonzero coefs}</source>
          <target state="translated">&lt;code&gt;n_nonzero_coefs&lt;/code&gt; を使用して非ゼロ係数の数でパラメーター化した場合：argmin || y-Xgamma || ^ 2は|| gamma || _0 &amp;lt;= n_ {nonzero coefs}の影響を受ける</target>
        </trans-unit>
        <trans-unit id="10d326cee514d3b967129b254954126bcda90793" translate="yes" xml:space="preserve">
          <source>When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier.</source>
          <target state="translated">分類を行う際には、クラス・ラベルだけでなく、関連する確率も予測したいと思うことがよくあります。この確率は、予測にある種の信頼性を与えます。この例は、予測された確率がどの程度校正されているかを表示する方法と、校正されていない分類器を校正する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="533cc79868c5585705042f97bd64dbf9b1c6133f" translate="yes" xml:space="preserve">
          <source>When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction. The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.</source>
          <target state="translated">分類を実行するときには、クラスのラベルを予測するだけでなく、それぞれのラベルの確率を得たいと思うことがよくあります。この確率は、予測に対するある種の信頼性を与えます。モデルによっては、クラス確率の推定値が悪く、確率予測をサポートしていないものもあります。キャリブレーション・モジュールは、与えられたモデルの確率をより良くキャリブレーションしたり、確率予測のサポートを追加したりすることができます。</target>
        </trans-unit>
        <trans-unit id="ede14543224daf4bd7da97ebebdbcb4bdb8fe514" translate="yes" xml:space="preserve">
          <source>When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&amp;rsquo;s score (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_score&lt;/a&gt;).</source>
          <target state="translated">分類を実行するとき、クラスラベルだけでなく、関連する確率も予測することがよくあります。この確率は、予測に対するある種の信頼を与えます。ただし、すべての分類子が十分に調整された確率を提供するわけではありません。したがって、予測された確率の個別のキャリブレーションが後処理として望ましい場合がよくあります。この例では、このキャリブレーションの2つの異なる方法を示し、ブライアのスコアを使用して返される確率の品質を評価します（&lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;https://en.wikipedia.org/wiki/Brier_scoreを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="47397daaf8d579706c38eeae4f614a41b7464779" translate="yes" xml:space="preserve">
          <source>When performing cross-validation for the &lt;code&gt;power&lt;/code&gt; parameter of &lt;code&gt;TweedieRegressor&lt;/code&gt;, it is advisable to specify an explicit &lt;code&gt;scoring&lt;/code&gt; function, because the default scorer &lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt;&lt;code&gt;TweedieRegressor.score&lt;/code&gt;&lt;/a&gt; is a function of &lt;code&gt;power&lt;/code&gt; itself.</source>
          <target state="translated">&lt;code&gt;TweedieRegressor&lt;/code&gt; の検出 &lt;code&gt;power&lt;/code&gt; パラメーターの相互検証を実行する場合、デフォルトのスコアラー&lt;a href=&quot;generated/sklearn.linear_model.tweedieregressor#sklearn.linear_model.TweedieRegressor.score&quot;&gt; &lt;code&gt;TweedieRegressor.score&lt;/code&gt; &lt;/a&gt;は検出 &lt;code&gt;power&lt;/code&gt; 自体の関数であるため、明示的な &lt;code&gt;scoring&lt;/code&gt; 関数を指定することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="e99cb78745b2020137c83400ee3d8d22f37293c0" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.</source>
          <target state="translated">距離を事前に計算する場合は、最初にデータを中心に置いた方が数値的に正確です。copy_x が True (デフォルト)の場合、元のデータは変更されず、X が C-連続であることが保証されます。Falseの場合、元のデータは修正され、関数が戻る前に戻されますが、データの平均値を減算してから加算することで小さな数値的な差異が生じる場合があり、この場合もデータがC-連続であることが保証されず、大幅な速度低下を引き起こす可能性があります。</target>
        </trans-unit>
        <trans-unit id="785dafae54d31c04c4a974bc00da768d9cfae46f" translate="yes" xml:space="preserve">
          <source>When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.</source>
          <target state="translated">事前に距離を計算する場合は、最初にデータを中心に置いた方が数値的に正確です。copy_x が True (デフォルト)の場合、元のデータは変更されません。Falseの場合、元のデータは修正され、関数が戻る前に戻されますが、データの平均値を減算してから加算することで、小さな数値的な差異が生じる可能性があります。元のデータがC-連続していない場合、 copy_xがFalseであってもコピーが行われることに注意してください。元のデータが疎でCSR形式ではない場合、 copy_xがFalseであってもコピーが作成されます。</target>
        </trans-unit>
        <trans-unit id="55ac178846c6596090a6f8d0133ba62fcd26aebb" translate="yes" xml:space="preserve">
          <source>When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.</source>
          <target state="translated">予測を行う場合、真のラベルは利用できません。その代わりに、各モデルの予測値がチェーン内の後続のモデルに渡され、特徴量として使用されます。</target>
        </trans-unit>
        <trans-unit id="441463f4c28b96b4ca0739417ce251a6d1637336" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces &lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;.</source>
          <target state="translated">データセットのランダムサブセットがフィーチャのランダムサブセットとして描画される場合、この方法はランダムサブスペース&lt;a href=&quot;#h1998&quot; id=&quot;id3&quot;&gt;[H1998]&lt;/a&gt;と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="ed3a388f4c5d9809937b1b2fceecd5d5d41437fc" translate="yes" xml:space="preserve">
          <source>When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting &lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;[B1999]&lt;/a&gt;.</source>
          <target state="translated">データセットのランダムなサブセットがサンプルのランダムなサブセットとして描画される場合、このアルゴリズムは貼り&lt;a href=&quot;#b1999&quot; id=&quot;id1&quot;&gt;付け&lt;/a&gt;として知られています[B1999]。</target>
        </trans-unit>
        <trans-unit id="f494cf947867cf3181ff2c5eaa996adc8d0ce783" translate="yes" xml:space="preserve">
          <source>When requesting a dataset with a name that is in mock_datasets, this object creates a fake dataset in a StringIO object and returns it. Otherwise, it raises an HTTPError.</source>
          <target state="translated">mock_datasetsにある名前のデータセットを要求すると、このオブジェクトはStringIOオブジェクト内に偽のデータセットを作成し、それを返します。それ以外の場合はHTTPErrorを発生させます。</target>
        </trans-unit>
        <trans-unit id="f6f6725ccb736a3cf59a107563029dd1f92b7eb9" translate="yes" xml:space="preserve">
          <source>When sample_weight is provided, the selected hyperparameter may depend on whether we use generalized cross-validation (cv=None or cv=&amp;rsquo;auto&amp;rsquo;) or another form of cross-validation, because only generalized cross-validation takes the sample weights into account when computing the validation score.</source>
          <target state="translated">sample_weightが指定されている場合、選択されたハイパーパラメータは、一般化交差検定（cv = Noneまたはcv = 'auto'）を使用するか、別の形式の交差検定を使用するかによって異なります。これは、一般化交差検定のみがサンプルの重みを考慮に入れるためです。検証スコアの計算。</target>
        </trans-unit>
        <trans-unit id="d66c9681351cfa02a7cc3145d8e8cc7e7a3877b3" translate="yes" xml:space="preserve">
          <source>When samples are drawn with replacement, then the method is known as Bagging &lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;.</source>
          <target state="translated">サンプルを置換して描画する場合、その方法はバギングとして知られています&lt;a href=&quot;#b1996&quot; id=&quot;id2&quot;&gt;[B1996]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b67d588266cee585b7c0608db5b116728771921f" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt;, i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">self.fit_interceptがTrueの場合、インスタンスベクトルxは &lt;code&gt;[x, self.intercept_scaling]&lt;/code&gt; なります。つまり、intercept_scalingに等しい定数値を持つ「合成」機能がインスタンスベクトルに追加されます。切片は、intercept_scaling *合成機能の重みになります注！合成機能の重みは、他のすべての機能と同様にl1 / l2正則化の対象になります。合成フィーチャの重みに対する（したがって、切片に対する）正規化の影響を減らすには、intercept_scalingを増やす必要があります。</target>
        </trans-unit>
        <trans-unit id="339fba0d20ce2052ad9daa9e3c6cc55589d832bc" translate="yes" xml:space="preserve">
          <source>When self.fit_intercept is True, instance vector x becomes [x, self.intercept_scaling], i.e. a &amp;ldquo;synthetic&amp;rdquo; feature with constant value equals to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.</source>
          <target state="translated">self.fit_interceptがTrueの場合、インスタンスベクトルxは[x、self.intercept_scaling]になります。つまり、intercept_scalingに等しい定数値を持つ「合成」機能がインスタンスベクトルに追加されます。切片は、intercept_scaling *合成機能の重みになります注！合成機能の重みは、他のすべての機能と同様にl1 / l2正則化の対象になります。合成フィーチャの重みに対する（したがって、切片に対する）正規化の影響を減らすには、intercept_scalingを増やす必要があります。</target>
        </trans-unit>
        <trans-unit id="ad06c0ce7c1fc91387cf888768a953ddfc43c4b6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;False&lt;/code&gt;, ignore special characters for PostScript compatibility.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; に設定すると、PostScript互換性のために特殊文字を無視します。</target>
        </trans-unit>
        <trans-unit id="d1b93df55570608a785000a0ebdde0c1a478b680" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, change the display of &amp;lsquo;values&amp;rsquo; and/or &amp;lsquo;samples&amp;rsquo; to be proportions and percentages respectively.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合、「値」または「サンプル」、あるいはその両方の表示をそれぞれ比率およびパーセントに変更します。</target>
        </trans-unit>
        <trans-unit id="3843d20a53a1ef3b59460be1fa7cb77d3c2ee1f6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw all leaf nodes at the bottom of the tree.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、すべてのリーフノードがツリーの下部に描画されます。</target>
        </trans-unit>
        <trans-unit id="1dd8441b2d9ea649f69d55eb070005c43dff3ea1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、角が丸いノードボックスを描画し、Times-RomanではなくHelveticaフォントを使用します。</target>
        </trans-unit>
        <trans-unit id="37e5e7c90dcc2881b20280bd58a636a2601aa0c6" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, forces the coefficients to be positive.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、係数が強制的に正になります。</target>
        </trans-unit>
        <trans-unit id="a556178389cf10e9a8f97ab94b5cbc137168d877" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, orient tree left to right rather than top-down.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、ツリーを上から下ではなく左から右に向けます。</target>
        </trans-unit>
        <trans-unit id="db2d0a81092e78238cdb916143e482a964d5a789" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合、ノードをペイントして、分類の過半数クラス、回帰の値の極値、またはマルチ出力のノードの純度を示します。</target>
        </trans-unit>
        <trans-unit id="387704ecb7f5fc4e8c941c08ae18f72e58104663" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合、前の呼び出しの解を再利用して、アンサンブルにフィットして推定器を追加します。そうでない場合は、前の解を消去します。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="42b61336d9e93453cd22782ddee266aae253af56" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合は、前の呼び出しの解を再利用してアンサンブルに適合させ、推定量を追加します。それ以外の場合は、前の解を消去します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="e08becb1d7f3dabb059c61e3163efbfc5e9d6bd5" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合、前の呼び出しのソリューションを再利用して適合させ、アンサンブルにさらに推定量を追加します。そうでない場合は、まったく新しいフォレストに適合させます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="4ca94f8cc22fb05a614eaf938146928a9cad01e1" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合は、前の呼び出しのソリューションを再利用して、アンサンブルにフィットし、推定量を追加します。それ以外の場合は、まったく新しいフォレストにフィットします。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="b034ef6cd843a9c71bbf2f16594203b3e34675bd" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、前の呼び出しのソリューションを再利用して、アンサンブルに推定量を適合させ、追加します。結果を有効にするには、推定量を同じデータでのみ再トレーニングする必要があります。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="1ddb18c96e1fca0312edb00f224f2db160c80a30" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、以前の呼び出しのソリューションを再利用して初期化として適合します。それ以外の場合は、以前のソリューションを消去します。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="06f93e3e87621fa903e7cdd20131cea02e9878ba" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、前の呼び出しのソリューションを再利用して初期化として適合させます。それ以外の場合は、前のソリューションを消去します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="303e5cc9af6656c2592224b864d50a2e7f014b54" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the ID number on each node.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、各ノードのID番号が表示されます。</target>
        </trans-unit>
        <trans-unit id="d19057d05dc608969ed0862b9054b2defc3fb482" translate="yes" xml:space="preserve">
          <source>When set to &lt;code&gt;True&lt;/code&gt;, show the impurity at each node.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定すると、各ノードの不純物を表示します。</target>
        </trans-unit>
        <trans-unit id="ee8efaddcdb7929ada76230c032dd700897cd47f" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights accross all updates and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches &lt;code&gt;average&lt;/code&gt;. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">Trueに設定すると、すべての更新の平均SGD重みが計算され、その結果が &lt;code&gt;coef_&lt;/code&gt; 属性に格納されます。1より大きいintに設定すると、表示されるサンプルの総数が &lt;code&gt;average&lt;/code&gt; 達すると、平均化が開始されます。したがって、 &lt;code&gt;average=10&lt;/code&gt; は、10個のサンプルを見た後に平均化を開始します。</target>
        </trans-unit>
        <trans-unit id="0199409f1eeb1aa7581c717d5c23e182af166761" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So &lt;code&gt;average=10&lt;/code&gt; will begin averaging after seeing 10 samples.</source>
          <target state="translated">Trueに設定すると、平均されたSGDの重みを計算し、その結果を &lt;code&gt;coef_&lt;/code&gt; 属性に格納します。1より大きいintに設定すると、見られるサンプルの総数が平均に達すると、平均化が始まります。したがって、 &lt;code&gt;average=10&lt;/code&gt; は、10個のサンプルを見た後に平均化を開始します。</target>
        </trans-unit>
        <trans-unit id="19c4ca669b90d48df2f3aa161b89103ea08c0cbd" translate="yes" xml:space="preserve">
          <source>When set to True, computes the averaged SGD weights and stores the result in the &lt;code&gt;coef_&lt;/code&gt; attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.</source>
          <target state="translated">Trueに設定すると、平均されたSGDの重みを計算し、その結果を &lt;code&gt;coef_&lt;/code&gt; 属性に格納します。1より大きいintに設定すると、見られるサンプルの総数が平均に達すると、平均化が始まります。したがって、average = 10は、10個のサンプルを見た後に平均化を開始します。</target>
        </trans-unit>
        <trans-unit id="e60b70114bd43f63c876204c608aaaaca2e5c6d2" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定されている場合、前の呼び出しのソリューションを再利用して、アンサンブルに適合させ、さらに推定量を追加します。それ以外の場合は、まったく新しいアンサンブルに適合させます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="fb1187119affc46cd36d1e1403f76ef562249b84" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定されている場合は、前の呼び出しのソリューションを再利用して、アンサンブルに推定量を適合させて追加します。それ以外の場合は、まったく新しいアンサンブルを適合させます。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0615ecfccfe9c12eea86adfdd92570d0b3a6f9cf" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定すると、以前の呼び出しのソリューションを再利用して初期化として適合します。それ以外の場合は、以前のソリューションを消去します。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="b9ddbc0f60da434a4d403c500c89b585a3aeef7d" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定すると、前の呼び出しのソリューションを再利用して初期化として適合させます。それ以外の場合は、前のソリューションを消去します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="869683b3c71be56286e995de01f21c989fc735d8" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定すると、以前の呼び出しのソリューションを再利用して初期化として適合します。それ以外の場合は、以前のソリューションを消去します。liblinearソルバーには役に立たない。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="90df9a75b07a1010dc74b460f30a26d769910e81" translate="yes" xml:space="preserve">
          <source>When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">Trueに設定すると、前の呼び出しのソリューションを再利用して初期化として適合させます。それ以外の場合は、前のソリューションを消去します。liblinearソルバーには役に立ちません。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="61362ce0a02977970071e88e9dc71d066251fcde" translate="yes" xml:space="preserve">
          <source>When specifying multiple metrics, the &lt;code&gt;refit&lt;/code&gt; parameter must be set to the metric (string) for which the &lt;code&gt;best_params_&lt;/code&gt; will be found and used to build the &lt;code&gt;best_estimator_&lt;/code&gt; on the whole dataset. If the search should not be refit, set &lt;code&gt;refit=False&lt;/code&gt;. Leaving refit to the default value &lt;code&gt;None&lt;/code&gt; will result in an error when using multiple metrics.</source>
          <target state="translated">複数のメトリックを指定する場合、 &lt;code&gt;refit&lt;/code&gt; パラメータは、 &lt;code&gt;best_params_&lt;/code&gt; が検出され、データセット全体で &lt;code&gt;best_estimator_&lt;/code&gt; を構築するために使用されるメトリック（文字列）に設定する必要があります。検索を再フィットしない場合は、 &lt;code&gt;refit=False&lt;/code&gt; を設定します。refitをデフォルト値 &lt;code&gt;None&lt;/code&gt; のままにすると、複数のメトリックを使用するときにエラーが発生します。</target>
        </trans-unit>
        <trans-unit id="8303fa1cd1689a65bba6fc9b59c3502d4f370e6f" translate="yes" xml:space="preserve">
          <source>When starting from the default values (alpha_init = 1.90, lambda_init = 1.), the bias of the resulting curve is large, and the variance is small. So, lambda_init should be relatively small (1.e-3) so as to reduce the bias.</source>
          <target state="translated">デフォルト値(alpha_init=1.90,lambda_init=1.)から始めると、結果として得られる曲線のバイアスが大きく、分散が小さくなってしまいます。そのため、Lambda_initを比較的小さく(1.e-3)してバイアスを小さくする必要があります。</target>
        </trans-unit>
        <trans-unit id="765386eefc1dd2e9ed203024ee007c99e07f6618" translate="yes" xml:space="preserve">
          <source>When strategy == &amp;ldquo;constant&amp;rdquo;, fill_value is used to replace all occurrences of missing_values. If left to the default, fill_value will be 0 when imputing numerical data and &amp;ldquo;missing_value&amp;rdquo; for strings or object data types.</source>
          <target state="translated">戦略==「定数」の場合、fill_valueを使用して、missing_valuesのすべての出現箇所を置き換えます。デフォルトのままにすると、数値データを代入するときのfill_valueは0になり、文字列またはオブジェクトデータタイプの場合は「missing_value」になります。</target>
        </trans-unit>
        <trans-unit id="234c27f3e17ce7a8cf496679483a69e65bcabb05" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;Pipeline&lt;/code&gt; is printed out in a jupyter notebook an HTML representation of the estimator is displayed as follows:</source>
          <target state="translated">ときに &lt;code&gt;Pipeline&lt;/code&gt; jupyterノートに印刷され、以下のように推定のHTML表現が表示されます。</target>
        </trans-unit>
        <trans-unit id="b3973bbeeefced2bd7eb8aaa05fcc0fadc5e600b" translate="yes" xml:space="preserve">
          <source>When the &lt;code&gt;cv&lt;/code&gt; argument is an integer, &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; uses the &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; strategies by default, the latter being used if the estimator derives from &lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt;&lt;code&gt;ClassifierMixin&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">場合 &lt;code&gt;cv&lt;/code&gt; 引数は整数であり、&lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; が&lt;/a&gt;使用&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;又は&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;デフォルト戦略を、後者は、から推定得る場合に使用&lt;a href=&quot;generated/sklearn.base.classifiermixin#sklearn.base.ClassifierMixin&quot;&gt; &lt;code&gt;ClassifierMixin&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="c7d238875ff93bafa2620f7a2d7675b937a2183b" translate="yes" xml:space="preserve">
          <source>When the algorithm does not converge, it returns an empty array as &lt;code&gt;cluster_center_indices&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt; as label for each training sample.</source>
          <target state="translated">アルゴリズムが収束しない場合は、各トレーニングサンプルのラベルとして &lt;code&gt;cluster_center_indices&lt;/code&gt; および &lt;code&gt;-1&lt;/code&gt; として空の配列を返します。</target>
        </trans-unit>
        <trans-unit id="b4fdfb364ee084bf57bd04a0f7c8f0c41739edf4" translate="yes" xml:space="preserve">
          <source>When the data is not initially in the &lt;code&gt;(n_samples, n_features)&lt;/code&gt; shape, it needs to be preprocessed in order to be used by scikit-learn.</source>
          <target state="translated">データが最初は &lt;code&gt;(n_samples, n_features)&lt;/code&gt; 形状になっていない場合、scikit-learnで使用するために前処理する必要があります。</target>
        </trans-unit>
        <trans-unit id="4b1639b675f158aa2d42c71150242e159f59e266" translate="yes" xml:space="preserve">
          <source>When the missingness pattern is predictive, the splits can be done on whether the feature value is missing or not:</source>
          <target state="translated">欠落パターンが予測可能な場合には、特徴量が欠落しているかどうかで分割を行うことができる。</target>
        </trans-unit>
        <trans-unit id="90e4401cde0f238342524a25385b7071cd57b4a0" translate="yes" xml:space="preserve">
          <source>When the underlying implementation uses joblib, the number of workers (threads or processes) that are spawned in parallel can be controlled via the &lt;code&gt;n_jobs&lt;/code&gt; parameter.</source>
          <target state="translated">基盤となる実装でjoblibを使用する場合、並列に生成されるワーカー（スレッドまたはプロセス）の数は、 &lt;code&gt;n_jobs&lt;/code&gt; パラメーターを介して制御できます。</target>
        </trans-unit>
        <trans-unit id="aaeec02a52e8579f06c37808c9e18fa50d637a08" translate="yes" xml:space="preserve">
          <source>When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground true labels. The maximum value is always +1.</source>
          <target state="translated">2つ以上のラベルがある場合、MCCの値は-1から+1の間の範囲ではなくなります。その代わり、最小値は-1から0の間のどこかになります。最大値は常に+1です。</target>
        </trans-unit>
        <trans-unit id="5c69ffd1e0dc71befa67c00726bc6370582b5df5" translate="yes" xml:space="preserve">
          <source>When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.</source>
          <target state="translated">出力間に相関がない場合、この種の問題を解決する非常に単純な方法は、n個の独立したモデル、すなわち各出力ごとに1つのモデルを構築し、それらのモデルを使用してn個の出力のそれぞれを独立して予測することである。しかし、同じ入力に関連する出力値はそれ自体が相関している可能性が高いので、多くの場合、より良い方法は、すべてのn個の出力を同時に予測することができる単一のモデルを構築することです。第一に、単一の推定器のみが構築されるため、訓練時間が短くて済む。第2に、結果として得られる推定器の一般化精度が高まることが多い。</target>
        </trans-unit>
        <trans-unit id="ebcc7b732996f47559f9fb2cca7527f873584d5f" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikit-learn and joblib need to be compatible. Currently, joblib 0.11+ is supported. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">この環境変数が0以外の値に設定されている場合、scikit-learnはそのベンダード版ではなく、サイトのjoblibを使用します。その結果、scikit-learnが動作するためにはjoblibがインストールされていなければなりません。scikit-learnとjoblibのバージョンは互換性が必要です。現在、joblib 0.11+がサポートされています。さらに、joblib.Memoryからのダンプは互換性がなく、いくつかのキャッシュを失い、いくつかのデータセットを再ダウンロードしなければならないかもしれません。</target>
        </trans-unit>
        <trans-unit id="8c7fa59e2b8c1ce3abb542d1d5f76caddd1816f1" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, scikit-learn uses the site joblib rather than its vendored version. Consequently, joblib must be installed for scikit-learn to run. Note that using the site joblib is at your own risks: the versions of scikt-learn and joblib need to be compatible. In addition, dumps from joblib.Memory might be incompatible, and you might loose some caches and have to redownload some datasets.</source>
          <target state="translated">この環境変数が0以外の値に設定されている場合、scikit-learnはそのベンダード版ではなく、サイトのjoblibを使用します。その結果、scikit-learnが動作するためにはjoblibがインストールされていなければなりません。scikt-learnとjoblibのバージョンは互換性が必要です。さらに、joblib.Memoryからのダンプは互換性がなく、いくつかのキャッシュを失い、いくつかのデータセットを再ダウンロードしなければならないかもしれません。</target>
        </trans-unit>
        <trans-unit id="743d4762d28a3d61488ddf12d10bce762b152657" translate="yes" xml:space="preserve">
          <source>When this environment variable is set to a non zero value, the tests that need network access are skipped.</source>
          <target state="translated">この環境変数がゼロ以外の値に設定されている場合、ネットワークアクセスを必要とするテストはスキップされます。</target>
        </trans-unit>
        <trans-unit id="beb3490e0a85d3bcf9f4888cb75a6b1ea2e1e6a8" translate="yes" xml:space="preserve">
          <source>When training an SVM with the &lt;em&gt;Radial Basis Function&lt;/em&gt; (RBF) kernel, two parameters must be considered: &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. The parameter &lt;code&gt;C&lt;/code&gt;, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low &lt;code&gt;C&lt;/code&gt; makes the decision surface smooth, while a high &lt;code&gt;C&lt;/code&gt; aims at classifying all training examples correctly. &lt;code&gt;gamma&lt;/code&gt; defines how much influence a single training example has. The larger &lt;code&gt;gamma&lt;/code&gt; is, the closer other examples must be to be affected.</source>
          <target state="translated">&lt;em&gt;放射基底関数&lt;/em&gt;（RBF）カーネルを使用してSVMをトレーニングする場合、 &lt;code&gt;C&lt;/code&gt; と &lt;code&gt;gamma&lt;/code&gt; の 2つのパラメーターを考慮する必要があります。すべてのSVMカーネルに共通のパラメーター &lt;code&gt;C&lt;/code&gt; は、決定面の単純さに対してトレーニング例の誤分類をトレードオフします。低い &lt;code&gt;C&lt;/code&gt; は決定面を滑らかにし、高い &lt;code&gt;C&lt;/code&gt; はすべてのトレーニング例を正しく分類することを目的としています。 &lt;code&gt;gamma&lt;/code&gt; は、単一のトレーニング例が与える影響の大きさを定義します。 &lt;code&gt;gamma&lt;/code&gt; が大きいほど、影響を受ける他の例に近いはずです。</target>
        </trans-unit>
        <trans-unit id="4f5d7a3d8a7ab119798fbec5ead8471db219e63d" translate="yes" xml:space="preserve">
          <source>When true, the result is adjusted for chance, so that random performance would score 0, and perfect performance scores 1.</source>
          <target state="translated">真の場合、結果は偶然性を考慮して調整され、ランダムなパフォーマンスはスコア0、完璧なパフォーマンスはスコア1となります。</target>
        </trans-unit>
        <trans-unit id="7dbd1175230450ef2444fe8de9e5557001f2473c" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt;), this transformation is known as &lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">切り捨てられたSVDが用語ドキュメント行列（&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt;によって返される）に適用される場合、この変換は&lt;a href=&quot;https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;潜在意味解析&lt;/a&gt;（LSA）と呼ばれます。これは、そのような行列を低次元の「意味」空間に変換するためです。特に、LSAは、同義語と多義語（どちらも単語ごとに複数の意味があることを大まかに意味します）の影響に対抗することが知られています。</target>
        </trans-unit>
        <trans-unit id="a756308318fb23f07be0498c8c83a0d088f9279a" translate="yes" xml:space="preserve">
          <source>When truncated SVD is applied to term-document matrices (as returned by &lt;code&gt;CountVectorizer&lt;/code&gt; or &lt;code&gt;TfidfVectorizer&lt;/code&gt;), this transformation is known as &lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;latent semantic analysis&lt;/a&gt; (LSA), because it transforms such matrices to a &amp;ldquo;semantic&amp;rdquo; space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.</source>
          <target state="translated">切り捨てられたSVDが（ &lt;code&gt;CountVectorizer&lt;/code&gt; または &lt;code&gt;TfidfVectorizer&lt;/code&gt; によって返される）用語ドキュメントマトリックスに適用される場合、この変換はそのようなマトリックスを低次元の「セマンティック」空間に変換するため、&lt;a href=&quot;http://nlp.stanford.edu/IR-book/pdf/18lsi.pdf&quot;&gt;潜在セマンティック分析&lt;/a&gt;（LSA）と呼ばれます。特に、LSAは、同義語と多義語（どちらもおおまかに単語ごとに複数の意味があることを意味します）の影響に対抗することが知られており、用語ドキュメントマトリックスが疎になり、余弦類似度などの測定では類似性が低くなります。</target>
        </trans-unit>
        <trans-unit id="38dbd2ff8901fd68988a77a08c59409f80468575" translate="yes" xml:space="preserve">
          <source>When two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might &lt;em&gt;actually&lt;/em&gt; be important.</source>
          <target state="translated">2つの特徴が相関していて、特徴の1つが並べ替えられている場合でも、モデルは相関している特徴を介してその特徴にアクセスできます。これにより、両方の機能の重要度の値が低くなり、&lt;em&gt;実際&lt;/em&gt;に重要&lt;em&gt;に&lt;/em&gt;なる可能性&lt;em&gt;があり&lt;/em&gt;ます。</target>
        </trans-unit>
        <trans-unit id="726430099b436b4edbed2772b4e46aec59296fe0" translate="yes" xml:space="preserve">
          <source>When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.</source>
          <target state="translated">tf-idf ベクトルを用いたテキスト分類に使用する場合、この分類器は、Rocchio 分類器としても知られています。</target>
        </trans-unit>
        <trans-unit id="b1373e66b4937bbac8defef2fa925bed61a8d596" translate="yes" xml:space="preserve">
          <source>When used to &lt;em&gt;transform&lt;/em&gt; data, PCA can reduce the dimensionality of the data by projecting on a principal subspace.</source>
          <target state="translated">PCAをデータの&lt;em&gt;変換に&lt;/em&gt;使用すると、主要な部分空間に射影することにより、データの次元を削減できます。</target>
        </trans-unit>
        <trans-unit id="93429c223efcd8d6622a4c8e5f0e71f13358e226" translate="yes" xml:space="preserve">
          <source>When using &lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;multiclass classifiers&lt;/code&gt;&lt;/a&gt;, the learning and prediction task that is performed is dependent on the format of the target data fit upon:</source>
          <target state="translated">&lt;a href=&quot;../../modules/classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;multiclass classifiers&lt;/code&gt; &lt;/a&gt;を使用する場合、実行される学習と予測のタスクは、対象となるターゲットデータの形式に依存します。</target>
        </trans-unit>
        <trans-unit id="bf430655a414d830d0ddbbfedf78ab7c208919a9" translate="yes" xml:space="preserve">
          <source>When using Averaged SGD (with the &lt;code&gt;average&lt;/code&gt; parameter), &lt;code&gt;coef_&lt;/code&gt; is set to the average weight across all updates: &lt;code&gt;coef_&lt;/code&gt;\(= \frac{1}{T} \sum_{t=0}^{T-1} w^{(t)}\), where \(T\) is the total number of updates, found in the &lt;code&gt;t_&lt;/code&gt; attribute.</source>
          <target state="translated">平均化SGD（ &lt;code&gt;average&lt;/code&gt; パラメーターを使用）を使用する場合、 &lt;code&gt;coef_&lt;/code&gt; はすべての更新の平均重みに設定されます： &lt;code&gt;coef_&lt;/code&gt; \（= \ frac {1} {T} \ sum_ {t = 0} ^ {T-1} w ^ { （t）} \）、ここで\（T \）は、 &lt;code&gt;t_&lt;/code&gt; 属性で見つかった更新の総数です。</target>
        </trans-unit>
        <trans-unit id="cb56aa339cbb48c9a75d42d2c7bf7e7858b3170b" translate="yes" xml:space="preserve">
          <source>When using ensemble methods base upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.</source>
          <target state="translated">バギングに基づくアンサンブル手法を使用する場合,すなわち,置換を伴うサンプリングを使用して新しい訓練セットを生成する場合,訓練セットの一部は未使用のままである.アンサンブル内の各分類器に対して,訓練セットの異なる部分が残されます.</target>
        </trans-unit>
        <trans-unit id="7a60d247990a32a468cae00d5ed7b0c825a81e35" translate="yes" xml:space="preserve">
          <source>When using the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; in a &lt;code&gt;Pipeline&lt;/code&gt;, be sure to use the &lt;code&gt;FeatureUnion&lt;/code&gt; or &lt;code&gt;ColumnTransformer&lt;/code&gt; to add the indicator features to the regular features. First we obtain the &lt;code&gt;iris&lt;/code&gt; dataset, and add some missing values to it.</source>
          <target state="translated">使用している場合&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;で &lt;code&gt;Pipeline&lt;/code&gt; 、使用することを必ず &lt;code&gt;FeatureUnion&lt;/code&gt; または &lt;code&gt;ColumnTransformer&lt;/code&gt; をインジケータが通常の機能に備えて追加します。まず、 &lt;code&gt;iris&lt;/code&gt; データセットを取得し、いくつかの欠落値を追加します。</target>
        </trans-unit>
        <trans-unit id="a9696826aefafecc5b32845bc270f3c2cabe6664" translate="yes" xml:space="preserve">
          <source>When using these images, please give credit to AT&amp;amp;T Laboratories Cambridge.</source>
          <target state="translated">これらの画像を使用する場合は、AT＆T Laboratories Cambridgeにクレジットを付与してください。</target>
        </trans-unit>
        <trans-unit id="5a6f9e7437ff7d6762455e24a46c4771dc2e0a37" translate="yes" xml:space="preserve">
          <source>When using, for example, &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;, to set the amount of regularization with &lt;code&gt;C&lt;/code&gt;, there will be a different amount of samples between the main problem and the smaller problems within the folds of the cross validation.</source>
          <target state="translated">たとえば、&lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;相互検証&lt;/a&gt;を使用して &lt;code&gt;C&lt;/code&gt; による正則化の量を設定する場合、主な問題と、相互検証の範囲内の小さな問題との間で異なる量のサンプルが存在します。</target>
        </trans-unit>
        <trans-unit id="5dae0cb2a4d8c33bb8e68ee9ffd452db73e27eb2" translate="yes" xml:space="preserve">
          <source>When we apply clustering to the data, we find that the clustering reflects what was in the distance matrices. Indeed, for the Euclidean distance, the classes are ill-separated because of the noise, and thus the clustering does not separate the waveforms. For the cityblock distance, the separation is good and the waveform classes are recovered. Finally, the cosine distance does not separate at all waveform 1 and 2, thus the clustering puts them in the same cluster.</source>
          <target state="translated">データにクラスタリングを適用すると、クラスタリングは距離行列の内容を反映していることがわかりました。実際,ユークリッド距離では,ノイズのためにクラスが分離されておらず,クラスタリングでは波形が分離されていません.市街地距離では,分離は良好であり,波形のクラスは回復している.最後に,余弦距離では,波形1と波形2は全く分離されず,クラスタリングにより同じクラスタに入る.</target>
        </trans-unit>
        <trans-unit id="8975b7dd097c19a6af3c2b4b090f357f96aab52d" translate="yes" xml:space="preserve">
          <source>When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the &lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in &lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off.</source>
          <target state="translated">共分散推定を使用する場合、通常のアプローチは、&lt;a href=&quot;../../modules/generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;sklearn.covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;などの最尤推定量を使用することです。これは不偏です。つまり、多くの観測値が与えられると、真の（母集団）共分散に収束します。ただし、その分散を減らすために、正規化することも有益です。これにより、ある程度のバイアスが生じます。この例は、&lt;a href=&quot;../../modules/covariance#shrunk-covariance&quot;&gt;Shrunk Covariance&lt;/a&gt; Estimatorで使用される単純な正則化を示しています。特に、正則化の量を設定する方法、つまりバイアスと分散のトレードオフを選択する方法に焦点を当てています。</target>
        </trans-unit>
        <trans-unit id="17b704aa73a46ef6f9edddecff620d33c0b705d7" translate="yes" xml:space="preserve">
          <source>When you want to apply different transformations to each field of the data, see the related class &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; (see &lt;a href=&quot;#column-transformer&quot;&gt;user guide&lt;/a&gt;).</source>
          <target state="translated">データの各フィールドに異なる変換を適用する場合は、関連クラス&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; を&lt;/a&gt;参照してください（&lt;a href=&quot;#column-transformer&quot;&gt;ユーザーガイドを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="8d5450715de6c511faca4e5034a6c5d189b2299d" translate="yes" xml:space="preserve">
          <source>Where (and how) parallelization happens in the estimators is currently poorly documented. Please help us by improving our docs and tackle &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;issue 14228&lt;/a&gt;!</source>
          <target state="translated">推定器で並列化が発生する場所（および方法）は、現在十分に文書化されていません。ドキュメントを改善し、&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/issues/14228&quot;&gt;問題14228に&lt;/a&gt;取り組むことで私たちを助けてください！</target>
        </trans-unit>
        <trans-unit id="ffd889b6ef09600260c419603787a00c67ae551d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in both the true labels and the predicted labels), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belong to the same clusters in the true labels and not in the predicted labels) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in the predicted labels and not in the true labels).</source>
          <target state="translated">ここで、 &lt;code&gt;TP&lt;/code&gt; は、数ある&lt;strong&gt;真陽性が&lt;/strong&gt;（すなわち真のラベルと予測ラベルの両方で同じクラスタに属しているポイントのペアの数）は、 &lt;code&gt;FP&lt;/code&gt; は、数ある&lt;strong&gt;偽陽性&lt;/strong&gt;（所属ポイントのペアの数は、すなわち予測ラベルではなく、真のラベルの同じクラスターに）および &lt;code&gt;FN&lt;/code&gt; は&lt;strong&gt;偽陰性&lt;/strong&gt;の数（つまり、真のラベルではなく予測ラベルの同じクラスターに属する点のペアの数）です。</target>
        </trans-unit>
        <trans-unit id="276f699fa82da6208d110c0a23b40d61550922dd" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;TP&lt;/code&gt; is the number of &lt;strong&gt;True Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in both &lt;code&gt;labels_true&lt;/code&gt; and &lt;code&gt;labels_pred&lt;/code&gt;), &lt;code&gt;FP&lt;/code&gt; is the number of &lt;strong&gt;False Positive&lt;/strong&gt; (i.e. the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_true&lt;/code&gt; and not in &lt;code&gt;labels_pred&lt;/code&gt;) and &lt;code&gt;FN&lt;/code&gt; is the number of &lt;strong&gt;False Negative&lt;/strong&gt; (i.e the number of pair of points that belongs in the same clusters in &lt;code&gt;labels_pred&lt;/code&gt; and not in &lt;code&gt;labels_True&lt;/code&gt;).</source>
          <target state="translated">どこ &lt;code&gt;TP&lt;/code&gt; は数れる&lt;strong&gt;真の陽性&lt;/strong&gt;（両方で同じクラスタに属するポイントのペアの数すなわち &lt;code&gt;labels_true&lt;/code&gt; と &lt;code&gt;labels_pred&lt;/code&gt; 、） &lt;code&gt;FP&lt;/code&gt; は、数ある&lt;strong&gt;偽陽性&lt;/strong&gt;（同じクラスタに属するポイントのペアの数すなわち &lt;code&gt;labels_true&lt;/code&gt; でなく &lt;code&gt;labels_pred&lt;/code&gt; ）及び &lt;code&gt;FN&lt;/code&gt; は、数ある&lt;strong&gt;偽陰性&lt;/strong&gt;（同じクラスタに属する点の組の数すなわち &lt;code&gt;labels_pred&lt;/code&gt; でなく &lt;code&gt;labels_True&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="e78195e2eb2711f3bb8a0d7f4e3c56eea492c48d" translate="yes" xml:space="preserve">
          <source>Where &lt;code&gt;delta&lt;/code&gt; is a free parameter representing the width of the Gaussian kernel.</source>
          <target state="translated">ここで、 &lt;code&gt;delta&lt;/code&gt; はガウスカーネルの幅を表す自由パラメーターです。</target>
        </trans-unit>
        <trans-unit id="6d88fb8179777bb060d39d8e880a1a6ec89efb59" translate="yes" xml:space="preserve">
          <source>Where C is the number of permutations whose score &amp;gt;= the true score.</source>
          <target state="translated">ここで、Cは、スコアが真のスコアである順列の数です。</target>
        </trans-unit>
        <trans-unit id="0426d1b8d26623c0079356962f68cf2595f6d67a" translate="yes" xml:space="preserve">
          <source>Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:</source>
          <target state="translated">ここで、D は入力データ X の距離の行列、D_fit は出力埋め込み X_fit の距離の行列、K はアイソマップカーネルである。</target>
        </trans-unit>
        <trans-unit id="77844a8258430d31f41a5c27fd5c3c817a4c46f5" translate="yes" xml:space="preserve">
          <source>Where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset (without ordering).</source>
          <target state="translated">ここで,\(C_2^{n_{samples}}})は,データセット内の可能なペアの総数である (順序付けなし).</target>
        </trans-unit>
        <trans-unit id="45f9706f8e40bfee3b8f4082279b7c1694d8aead" translate="yes" xml:space="preserve">
          <source>Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R &lt;code&gt;glasso&lt;/code&gt; package.</source>
          <target state="translated">ここで、\（K \）は推定される精度行列であり、\（S \）はサンプル共分散行列です。\（\ | K \ | _1 \）は、\（K \）の非対角係数の絶対値の合計です。この問題を解決するために採用されたアルゴリズムは、Friedman 2008 BiostatisticsペーパーのGLassoアルゴリズムです。これは、R &lt;code&gt;glasso&lt;/code&gt; パッケージと同じアルゴリズムです。</target>
        </trans-unit>
        <trans-unit id="23038cc6fb25ab648004d5485267f6db76cb9eda" translate="yes" xml:space="preserve">
          <source>Where \(N(x_i)\) is the neighborhood of samples within a given distance around \(x_i\) and \(m\) is the &lt;em&gt;mean shift&lt;/em&gt; vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. This is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:</source>
          <target state="translated">ここで、\（N（x_i）\）は、\（x_i \）の周りの特定の距離内のサンプルの近傍であり、\（m \）は、最大の増加の領域を指す各重心について計算される&lt;em&gt;平均シフト&lt;/em&gt;ベクトルです。ポイントの密度で。これは、次の方程式を使用して計算され、その近傍内のサンプルの平均になるように重心を効果的に更新します。</target>
        </trans-unit>
        <trans-unit id="c4be16a40b65a723b122e1219966e4db066c1f56" translate="yes" xml:space="preserve">
          <source>Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).</source>
          <target state="translated">Where \(R\)は 対角線上の行列で、項目 i\(i\)equal to \(I)equal to {{\(i)}A_{ij}}and {C\(C)は 対角線上の行列で、項目 j\(j)equal to {\(j)}equal to {\(i)A_{ij}}}である。</target>
        </trans-unit>
        <trans-unit id="06bd15907339a321f45a7707ee037e3bf4bb294c" translate="yes" xml:space="preserve">
          <source>Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.</source>
          <target state="translated">Where \(\langle 》は、Hilbert空間の内積を表す。</target>
        </trans-unit>
        <trans-unit id="b505305e3f68e0055136674f6671623549265da7" translate="yes" xml:space="preserve">
          <source>Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.</source>
          <target state="translated">ここで、「\(x)の自然対数」とは、「\(x)の自然対数」を意味します。この指標は、人口や商品の平均売上高などの指数関数的な成長を目標とする場合に最適です。この指標は、過小予測よりも過大予測の方がペナルティを課すことに注意してください。</target>
        </trans-unit>
        <trans-unit id="dc652afd01d2a671ac597240d27fcb8fb6f2cb88" translate="yes" xml:space="preserve">
          <source>Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:</source>
          <target state="translated">Where Where\(s(i,k)Available)is the similarity between sample \(i\)and \(k)Available.Sample \(k)to be the exemplar of sample 模範となる可能性は、次のように与えられる。</target>
        </trans-unit>
        <trans-unit id="9fa1e5b532b4ed4720d23061371103281dda3d83" translate="yes" xml:space="preserve">
          <source>Where r is defined per sample, we need to make use of &lt;code&gt;start&lt;/code&gt;:</source>
          <target state="translated">サンプルごとにrが定義されている場合、 &lt;code&gt;start&lt;/code&gt; を使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="c16b06fa7e959786262fbf5823a1d1a66514be0c" translate="yes" xml:space="preserve">
          <source>Where the step length \(\gamma_m\) is chosen using line search:</source>
          <target state="translated">Where is choose the step length of step(It's step length)in line search.</target>
        </trans-unit>
        <trans-unit id="096f899281fbd2d32d659004bce326784eacf79e" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given &lt;code&gt;cv_results_&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="translated">最良の推定量を選択する際の最大スコア以外の考慮事項がある場合は、 &lt;code&gt;refit&lt;/code&gt; 選ば返す関数に設定することができます &lt;code&gt;best_index_&lt;/code&gt; 与え &lt;code&gt;cv_results_&lt;/code&gt; 。その場合、 &lt;code&gt;best_estimator_&lt;/code&gt; および &lt;code&gt;best_params_&lt;/code&gt; は、返された &lt;code&gt;best_index_&lt;/code&gt; に従って設定されますが、 &lt;code&gt;best_score_&lt;/code&gt; 属性は使用できません。</target>
        </trans-unit>
        <trans-unit id="be446fd5f2cab9d9132f73b7df79724fa271f7f8" translate="yes" xml:space="preserve">
          <source>Where there are considerations other than maximum score in choosing a best estimator, &lt;code&gt;refit&lt;/code&gt; can be set to a function which returns the selected &lt;code&gt;best_index_&lt;/code&gt; given the &lt;code&gt;cv_results&lt;/code&gt;. In that case, the &lt;code&gt;best_estimator_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; will be set according to the returned &lt;code&gt;best_index_&lt;/code&gt; while the &lt;code&gt;best_score_&lt;/code&gt; attribute will not be available.</source>
          <target state="translated">最良の推定量を選択する際の最大スコア以外の考慮事項がある場合は、 &lt;code&gt;refit&lt;/code&gt; 選ば返す関数に設定することができます &lt;code&gt;best_index_&lt;/code&gt; 与え &lt;code&gt;cv_results&lt;/code&gt; を。その場合、 &lt;code&gt;best_estimator_&lt;/code&gt; および &lt;code&gt;best_params_&lt;/code&gt; は、返された &lt;code&gt;best_index_&lt;/code&gt; に従って設定されますが、 &lt;code&gt;best_score_&lt;/code&gt; 属性は使用できません。</target>
        </trans-unit>
        <trans-unit id="1e4c7785f80a06d28d2e2b965c377764abc1c026" translate="yes" xml:space="preserve">
          <source>Where to from here</source>
          <target state="translated">ここからどこまで</target>
        </trans-unit>
        <trans-unit id="17eb390ca1dec9880beb722610077dafb8edc9ac" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features] and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">ここで,u と v は形状 [n_samples,n_features]のデータセットから取得された任意の行であり,p は形状 [n_components,n_features]のランダムガウス N(0,1)行列(または疎な Achlioptas 行列)による射影です.</target>
        </trans-unit>
        <trans-unit id="c5759c4abe89df832c23e0269eba38e4f1ad0ad7" translate="yes" xml:space="preserve">
          <source>Where u and v are any rows taken from a dataset of shape [n_samples, n_features], eps is in ]0, 1[ and p is a projection by a random Gaussian N(0, 1) matrix with shape [n_components, n_features] (or a sparse Achlioptas matrix).</source>
          <target state="translated">ここで,u と v は形状 [n_samples,n_features]のデータセットから取得された任意の行であり,eps は [0,1]にあり,p は形状 [n_components,n_features]のランダムガウス N(0,1)行列(または疎な Achlioptas 行列)による射影です.</target>
        </trans-unit>
        <trans-unit id="7e741bc3dcef0123eeda11543758853be2aac149" translate="yes" xml:space="preserve">
          <source>Where:</source>
          <target state="translated">Where:</target>
        </trans-unit>
        <trans-unit id="16270a9447d061ffaba6de4c25d0370619ae5579" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting.</source>
          <target state="translated">&lt;code&gt;feature_names_&lt;/code&gt; と &lt;code&gt;vocabulary_&lt;/code&gt; をフィッティング時にソートする必要があるかどうか。</target>
        </trans-unit>
        <trans-unit id="07f1abf8acdb3dcd49bde3ee8a201c3421831b31" translate="yes" xml:space="preserve">
          <source>Whether &lt;code&gt;feature_names_&lt;/code&gt; and &lt;code&gt;vocabulary_&lt;/code&gt; should be sorted when fitting. True by default.</source>
          <target state="translated">適合時に &lt;code&gt;feature_names_&lt;/code&gt; と &lt;code&gt;vocabulary_&lt;/code&gt; をソートするかどうか。デフォルトではTrue。</target>
        </trans-unit>
        <trans-unit id="e61b5eefa6a0d8caaa65c0cf06600523e6eded8c" translate="yes" xml:space="preserve">
          <source>Whether a forced copy will be triggered. If copy=False, a copy might be triggered by a conversion.</source>
          <target state="translated">強制コピーがトリガされるかどうか。copy=Falseの場合、コピーは変換によってトリガされるかもしれません。</target>
        </trans-unit>
        <trans-unit id="6817dee267fec06b200988a35092c9fafdb28df4" translate="yes" xml:space="preserve">
          <source>Whether a prefit model is expected to be passed into the constructor directly or not. If True, &lt;code&gt;transform&lt;/code&gt; must be called directly and SelectFromModel cannot be used with &lt;code&gt;cross_val_score&lt;/code&gt;, &lt;code&gt;GridSearchCV&lt;/code&gt; and similar utilities that clone the estimator. Otherwise train the model using &lt;code&gt;fit&lt;/code&gt; and then &lt;code&gt;transform&lt;/code&gt; to do feature selection.</source>
          <target state="translated">事前適合モデルがコンストラクターに直接渡されることが期待されるかどうか。Trueの場合、 &lt;code&gt;transform&lt;/code&gt; 直接呼び出す必要があり、SelectFromModelは &lt;code&gt;cross_val_score&lt;/code&gt; 、 &lt;code&gt;GridSearchCV&lt;/code&gt; 、および推定器を複製する同様のユーティリティでは使用できません。それ以外の場合は、 &lt;code&gt;fit&lt;/code&gt; を使用してモデルをトレーニングし、 &lt;code&gt;transform&lt;/code&gt; して特徴選択を行います。</target>
        </trans-unit>
        <trans-unit id="e67f675f1639113224879739e0229eb2671df0d3" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style.</source>
          <target state="translated">配列を強制的にFortran形式にするか、c形式にするか。</target>
        </trans-unit>
        <trans-unit id="57d1f88164d54372295bc307285273118c662089" translate="yes" xml:space="preserve">
          <source>Whether an array will be forced to be fortran or c-style. When order is None (default), then if copy=False, nothing is ensured about the memory layout of the output array; otherwise (copy=True) the memory layout of the returned array is kept as close as possible to the original array.</source>
          <target state="translated">配列を強制的に fortran スタイルにするか c スタイルにするか。order が None (デフォルト)の場合,copy=False の場合,出力配列のメモリレイアウトは何も保証されず,そうでなければ (copy=True)返された配列のメモリレイアウトは,元の配列にできるだけ近づけられます.</target>
        </trans-unit>
        <trans-unit id="f6541283616583040ce3e73f070cbb436dbc5da9" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees.</source>
          <target state="translated">木を構築する際にブートストラップサンプルを使用するかどうか。</target>
        </trans-unit>
        <trans-unit id="1349327857b1cdc30e7f508422cffd4b74a570bf" translate="yes" xml:space="preserve">
          <source>Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.</source>
          <target state="translated">木を構築する際にブートストラップサンプルを使用するかどうか。Falseの場合,各木を構築する際にデータセット全体を使用する.</target>
        </trans-unit>
        <trans-unit id="344e324f858395af07d0534305d3cd485a522869" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; is passed. If &lt;code&gt;offset&lt;/code&gt; or &lt;code&gt;length&lt;/code&gt; are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to &lt;code&gt;zero_based=True&lt;/code&gt; to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">fの列インデックスがゼロベース（True）か1ベース（False）か。列のインデックスが1ベースの場合、それらは0ベースに変換され、Python / NumPyの規則に一致します。 「auto」に設定すると、ヒューリスティックチェックが適用され、ファイルの内容からこれを判別します。どちらの種類のファイルも「自然界で」発生しますが、残念ながら自己識別はできません。 「auto」またはTrueを使用すると、 &lt;code&gt;offset&lt;/code&gt; または &lt;code&gt;length&lt;/code&gt; が渡されない場合は常に安全です。場合は &lt;code&gt;offset&lt;/code&gt; または &lt;code&gt;length&lt;/code&gt; 渡され、「オート」モードでは、バックにフォール &lt;code&gt;zero_based=True&lt;/code&gt; ファイルの異なるセグメント上のヒューリスティックチェック歩留まり一貫性のない結果を避けるために。</target>
        </trans-unit>
        <trans-unit id="f00bfe1387e4927051573cb3d574287560206c66" translate="yes" xml:space="preserve">
          <source>Whether column indices in f are zero-based (True) or one-based (False). If column indices are one-based, they are transformed to zero-based to match Python/NumPy conventions. If set to &amp;ldquo;auto&amp;rdquo;, a heuristic check is applied to determine this from the file contents. Both kinds of files occur &amp;ldquo;in the wild&amp;rdquo;, but they are unfortunately not self-identifying. Using &amp;ldquo;auto&amp;rdquo; or True should always be safe when no offset or length is passed. If offset or length are passed, the &amp;ldquo;auto&amp;rdquo; mode falls back to zero_based=True to avoid having the heuristic check yield inconsistent results on different segments of the file.</source>
          <target state="translated">fの列インデックスがゼロベース（True）か1ベース（False）か。列のインデックスが1ベースの場合、それらは0ベースに変換され、Python / NumPyの規則に一致します。「auto」に設定すると、ヒューリスティックチェックが適用され、ファイルの内容からこれを判別します。どちらの種類のファイルも「自然界で」発生しますが、残念ながら自己識別はできません。「auto」またはTrueを使用すると、オフセットまたは長さが渡されない場合は常に安全です。オフセットまたは長さが渡された場合、「自動」モードはzero_based = Trueにフォールバックし、ファイルの異なるセグメントでのヒューリスティックチェックの結果に一貫性のない結果が生じるのを防ぎます。</target>
        </trans-unit>
        <trans-unit id="be05ee9a303aba9073e602f5af4606db8dba467c" translate="yes" xml:space="preserve">
          <source>Whether column indices should be written zero-based (True) or one-based (False).</source>
          <target state="translated">列のインデックスをゼロベース(True)またはワンベース(False)で記述するかどうか。</target>
        </trans-unit>
        <trans-unit id="426c392bb98aa08b186e867710abfa024378fa01" translate="yes" xml:space="preserve">
          <source>Whether features are drawn with replacement.</source>
          <target state="translated">特徴が交換で描かれているかどうか。</target>
        </trans-unit>
        <trans-unit id="b1153e9c8e50c0d286811aaf218a31fa047ae93d" translate="yes" xml:space="preserve">
          <source>Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.</source>
          <target state="translated">重みの2回目の正規化を行うかどうか。デフォルトの動作は,論文の表9で説明されている完全なアルゴリズムに従わない Mahout や Weka の実装を反映しています.</target>
        </trans-unit>
        <trans-unit id="1500a013d74d8899d6c67c8489e35470d425474d" translate="yes" xml:space="preserve">
          <source>Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter &lt;code&gt;fit_intercept&lt;/code&gt;.</source>
          <target state="translated">モデルが切片、つまりバイアスされた超平面を使用するかどうかは、パラメータ &lt;code&gt;fit_intercept&lt;/code&gt; によって制御されます。</target>
        </trans-unit>
        <trans-unit id="c17699d69c93a1c9674665b22c836f689e7a71a8" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch.</source>
          <target state="translated">各エポックの後に学習データをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="2f96d4cd24a907c94c91a597b369db5ae9d183fe" translate="yes" xml:space="preserve">
          <source>Whether or not the training data should be shuffled after each epoch. Defaults to True.</source>
          <target state="translated">学習データを各エポック後にシャッフルするかどうか。デフォルトはTrueです。</target>
        </trans-unit>
        <trans-unit id="21e287c040da0ab9f7612eda4a9df397d21447be" translate="yes" xml:space="preserve">
          <source>Whether or not to compute labels for each fit.</source>
          <target state="translated">各はめ込みに対するラベルを計算するかどうか。</target>
        </trans-unit>
        <trans-unit id="ae7627e3aed47d9187a8dde354d4bd8908f66e18" translate="yes" xml:space="preserve">
          <source>Whether or not to consider raw Mahalanobis distances as the decision function. Must be False (default) for compatibility with the others outlier detection tools.</source>
          <target state="translated">生のマハラノビス距離を決定関数として考慮するかどうか。他の外れ値検出ツールとの互換性のため、False(デフォルト)にする必要があります。</target>
        </trans-unit>
        <trans-unit id="d7d36162415efc2dece0359749393df764e8f212" translate="yes" xml:space="preserve">
          <source>Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.</source>
          <target state="translated">切片に合わせるかどうか。データが既に原点を中心にしている場合はFalseに設定できます。</target>
        </trans-unit>
        <trans-unit id="99ecd63bc30b233e173e08d6a58d2b609112b08a" translate="yes" xml:space="preserve">
          <source>Whether or not to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">与えられたデータをコピーするかどうか。Falseに設定すると、初期データが上書きされます。</target>
        </trans-unit>
        <trans-unit id="95950f270865da71d578c03fd7275708de2f1edb" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &amp;lsquo;auto&amp;rsquo;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="translated">各サンプルをそれ自体に最も近い最初の近傍としてマークするかどうか。'auto'の場合、mode = 'connectivity'にはTrueが使用され、mode = 'distance'にはFalseが使用されます。</target>
        </trans-unit>
        <trans-unit id="0d8aa347bdbdfa6dd79051c8fee2f95fc5666522" translate="yes" xml:space="preserve">
          <source>Whether or not to mark each sample as the first nearest neighbor to itself. If &lt;code&gt;None&lt;/code&gt;, then True is used for mode=&amp;rsquo;connectivity&amp;rsquo; and False for mode=&amp;rsquo;distance&amp;rsquo; as this will preserve backwards compatibility.</source>
          <target state="translated">各サンプルをそれ自体の最初の最近傍としてマークするかどうか。 &lt;code&gt;None&lt;/code&gt; の場合、後方互換性が維持されるため、mode = 'connectivity'にはTrueが、mode = 'distance'にはFalseが使用されます。</target>
        </trans-unit>
        <trans-unit id="a1d6eb056f01f6a77d40d6f787612d8008f1be4b" translate="yes" xml:space="preserve">
          <source>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</source>
          <target state="translated">デフォルトの動作として、疎なCSR行列を返すか、密なパイプライン演算子と互換性のある密な配列を返すか。</target>
        </trans-unit>
        <trans-unit id="8f592bf838896fb605ecc15c063970bf58250eab" translate="yes" xml:space="preserve">
          <source>Whether or not to return the number of iterations.</source>
          <target state="translated">反復回数を返すかどうか。</target>
        </trans-unit>
        <trans-unit id="3433b032133d6a741db0a6ccce9ce8005a84877d" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.</source>
          <target state="translated">分割前にデータをシャッフルするかどうか。shuffle=Falseの場合、stratifyはNoneでなければなりません。</target>
        </trans-unit>
        <trans-unit id="d797771ee8d7ac8a664344b3d1655c54bf4a7c5a" translate="yes" xml:space="preserve">
          <source>Whether or not to shuffle the data: might be important for models that make the assumption that the samples are independent and identically distributed (i.i.d.), such as stochastic gradient descent.</source>
          <target state="translated">データをシャッフルするかどうか:サンプルが独立しており、確率的勾配降下のように、サンプルが独立しており、同一に分布している(i.i.d.)と仮定しているモデルでは、重要かもしれません。</target>
        </trans-unit>
        <trans-unit id="169aa17090e9b82766c818a4a09acd1cb51fcb24" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement.</source>
          <target state="translated">サンプルが交換で描かれているかどうか。</target>
        </trans-unit>
        <trans-unit id="11994582207268a83009eceee1185d13dd22bd86" translate="yes" xml:space="preserve">
          <source>Whether samples are drawn with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">置換を伴うサンプリングを行うかどうか。Falseの場合、置換なしのサンプリングが行われます。</target>
        </trans-unit>
        <trans-unit id="b61c81ce74fc75ce6a90c790bfafe984d14c7994" translate="yes" xml:space="preserve">
          <source>Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.</source>
          <target state="translated">score_func がスコア関数 (デフォルト)であるかどうか (高ければ良いという意味)、あるいは損失関数であるかどうか (低ければ良いという意味)。後者の場合、スコアラーオブジェクトは score_func の結果を符号反転します。</target>
        </trans-unit>
        <trans-unit id="01c7a3b4947bb7aed2272a78dd753a14b9e24fdc" translate="yes" xml:space="preserve">
          <source>Whether score_func requires predict_proba to get probability estimates out of a classifier.</source>
          <target state="translated">score_funcが分類器から確率推定値を得るために predict_probaを必要とするかどうか。</target>
        </trans-unit>
        <trans-unit id="e86601bb1c2db478564381eb9b1a33fc72f3ad69" translate="yes" xml:space="preserve">
          <source>Whether score_func takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method.</source>
          <target state="translated">score_funcが連続的な決定の確実性を取るかどうか。これは、decision_functionまたはpredict_probaメソッドのいずれかを持つ推定器を用いた二値分類に対してのみ動作します。</target>
        </trans-unit>
        <trans-unit id="62e384e32324c7d8c05ac06534cda98d3cbc0def" translate="yes" xml:space="preserve">
          <source>Whether support is a list of indices.</source>
          <target state="translated">サポートがインデックスのリストであるかどうか。</target>
        </trans-unit>
        <trans-unit id="970ea0e030e6e4be6469b0282edfb558e0e9066d" translate="yes" xml:space="preserve">
          <source>Whether the algorithm should be applied to M.T instead of M. The result should approximately be the same. The &amp;lsquo;auto&amp;rsquo; mode will trigger the transposition if M.shape[1] &amp;gt; M.shape[0] since this implementation of randomized SVD tend to be a little faster in that case.</source>
          <target state="translated">アルゴリズムをMではなくMTに適用するかどうか。結果はほぼ同じになるはずです。M.shape [1]&amp;gt; M.shape [0]の場合、ランダム化されたSVDのこの実装の方が少し高速になる傾向があるため、「auto」モードは転置をトリガーします。</target>
        </trans-unit>
        <trans-unit id="3226951d2ead1297a694651602f8538f5e93757c" translate="yes" xml:space="preserve">
          <source>Whether the covariance vector Xy must be copied by the algorithm. If False, it may be overwritten.</source>
          <target state="translated">共分散ベクトルXyがアルゴリズムによってコピーされなければならないかどうか。Falseの場合、上書きされる可能性があります。</target>
        </trans-unit>
        <trans-unit id="d2b667c3b7746e3e678455d8b2d703997aeb5e60" translate="yes" xml:space="preserve">
          <source>Whether the deflation be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effects</source>
          <target state="translated">デフレがコピーで行われるかどうか。副作用を気にしない限り、デフォルト値をTrueにします。</target>
        </trans-unit>
        <trans-unit id="1cba92780e42c1ebe55ada467260206516898de8" translate="yes" xml:space="preserve">
          <source>Whether the deflation should be done on a copy. Let the default value to True unless you don&amp;rsquo;t care about side effect</source>
          <target state="translated">デフレをコピーで行うかどうか。副作用を気にしない限り、デフォルト値をTrueにします。</target>
        </trans-unit>
        <trans-unit id="99f0df0508624fcfafef99671905c951f197a398" translate="yes" xml:space="preserve">
          <source>Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">デザイン行列Xがアルゴリズムによってコピーされなければならないかどうか。false の値は,X が既に Fortran でオーダーされている場合にのみ有用であり,そうでない場合には,とにかくコピーが行われます.</target>
        </trans-unit>
        <trans-unit id="6f829dc8dcc41b94f325536e7999d7feb34a89f1" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word n-gram or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">機能を単語n-gramまたは文字n-gramのどちらで作成するか。オプション 'char_wb'は、単語境界内のテキストからのみ文字n-gramを作成します。単語の端にあるn-gramにはスペースが埋め込まれます。</target>
        </trans-unit>
        <trans-unit id="f62ef19aafedabcbf9aa2a6c1cbcccaa900e840f" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams.</source>
          <target state="translated">特徴を単語や文字のn-gramにするかどうか。</target>
        </trans-unit>
        <trans-unit id="9c1354d44a66effd212e821b1aba74fe08612248" translate="yes" xml:space="preserve">
          <source>Whether the feature should be made of word or character n-grams. Option &amp;lsquo;char_wb&amp;rsquo; creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.</source>
          <target state="translated">特徴を単語または文字のNグラムで作成するかどうか。オプション 'char_wb'は、単語の境界内のテキストからのみ文字n-gramを作成します。単語の端にあるn-gramにはスペースが埋め込まれます。</target>
        </trans-unit>
        <trans-unit id="824ad07968fefbc8aa1fba0ade7c849f0d099562" translate="yes" xml:space="preserve">
          <source>Whether the gram matrix must be copied by the algorithm. A false value is only helpful if it is already Fortran-ordered, otherwise a copy is made anyway.</source>
          <target state="translated">グラム行列がアルゴリズムによってコピーされなければならないかどうか。false の値は,それが既に Fortran でオーダーされている場合にのみ有用で,そうでない場合はとにかくコピーが行われます.</target>
        </trans-unit>
        <trans-unit id="23571fa5c9f0e8d5b2ce0915807aa480e23639d3" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask format should be sparse or dense.</source>
          <target state="translated">インピュターマスクのフォーマットを疎にするか密にするか。</target>
        </trans-unit>
        <trans-unit id="b70758cdff0513f8822d9fb7393f16dda3f13af9" translate="yes" xml:space="preserve">
          <source>Whether the imputer mask should represent all or a subset of features.</source>
          <target state="translated">インパマスクがすべての特徴を表すべきか、特徴のサブセットを表すべきか。</target>
        </trans-unit>
        <trans-unit id="11709e37813efd2480c1d891188cf0d8201c8a69" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If &lt;code&gt;False&lt;/code&gt;, the data is assumed to be already centered.</source>
          <target state="translated">切片を推定する必要があるかどうか。場合 &lt;code&gt;False&lt;/code&gt; 、データが既にセンタリングされているものとします。</target>
        </trans-unit>
        <trans-unit id="0ccd5f6458ed970eecf03c787120d2831e50f140" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.</source>
          <target state="translated">切片を推定するかどうか。Falseの場合は、データが既に中央にあると仮定します。</target>
        </trans-unit>
        <trans-unit id="2fafec857734808cd372cb104d91a568d25acbf6" translate="yes" xml:space="preserve">
          <source>Whether the intercept should be estimated or not. If False, the data is assumed to be already centered. Defaults to True.</source>
          <target state="translated">切片を推定するかどうか。Falseの場合、データはすでに中央にあるとみなされます。デフォルトはTrueです。</target>
        </trans-unit>
        <trans-unit id="1369ea0f90c1ab8c31f4e5d5e2b327950f322e67" translate="yes" xml:space="preserve">
          <source>Whether the kernel works only on fixed-length feature vectors.</source>
          <target state="translated">カーネルが固定長の特徴ベクトルのみで動作するかどうか。</target>
        </trans-unit>
        <trans-unit id="efe887a2120302f3ddf508ce39115dacb905298c" translate="yes" xml:space="preserve">
          <source>Whether the parameter was found to be a named parameter of the estimator&amp;rsquo;s fit method.</source>
          <target state="translated">パラメーターが推定器のfitメソッドの名前付きパラメーターであることが判明したかどうか。</target>
        </trans-unit>
        <trans-unit id="e3e6070e7b1bf06bd46c63ade906ee83f84569ff" translate="yes" xml:space="preserve">
          <source>Whether the power iterations are normalized with step-by-step QR factorization (the slowest but most accurate), &amp;lsquo;none&amp;rsquo; (the fastest but numerically unstable when &lt;code&gt;n_iter&lt;/code&gt; is large, e.g. typically 5 or larger), or &amp;lsquo;LU&amp;rsquo; factorization (numerically stable but can lose slightly in accuracy). The &amp;lsquo;auto&amp;rsquo; mode applies no normalization if &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2 and switches to LU otherwise.</source>
          <target state="translated">ステップごとのQR因数分解（最も遅いが最も正確）、 'none'（ &lt;code&gt;n_iter&lt;/code&gt; が大きい場合（通常、5以上など）が最も速いが数値的に不安定）、または 'LU'因数分解（数値的に）安定していますが、精度が少し低下する可能性があります）。'auto'モードは、 &lt;code&gt;n_iter&lt;/code&gt; &amp;lt;= 2の場合は正規化を適用せず、それ以外の場合はLUに切り替えます。</target>
        </trans-unit>
        <trans-unit id="00c2bc5048e0182a905dad0c4dec40740dd521b8" translate="yes" xml:space="preserve">
          <source>Whether the relationship is increasing or decreasing.</source>
          <target state="translated">関係性が増えているのか減っているのか。</target>
        </trans-unit>
        <trans-unit id="dc0314689b038e45038d5534e1499b2766f8b916" translate="yes" xml:space="preserve">
          <source>Whether the return value is an array of sparse matrix depends on the type of the input X.</source>
          <target state="translated">戻り値が疎な行列の配列であるかどうかは,入力Xの型に依存します.</target>
        </trans-unit>
        <trans-unit id="ed44b1dc96dab239fb6ac2dc375f2ee5fe3ae793" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, i.e., the mean of the observed target values become zero. This parameter should be set to True if the target values&amp;rsquo; mean is expected to differ considerable from zero. When enabled, the normalization effectively modifies the GP&amp;rsquo;s prior based on the data, which contradicts the likelihood principle; normalization is thus disabled per default.</source>
          <target state="translated">ターゲット値yが正規化されているかどうか、つまり、観測されたターゲット値の平均がゼロになるかどうか。ターゲット値の平均がゼロとかなり異なることが予想される場合、このパラメーターはTrueに設定する必要があります。有効にすると、正規化はデータに基づいてGPの事前分布を効果的に変更しますが、これは尤度原理と矛盾します。したがって、正規化はデフォルトで無効になっています。</target>
        </trans-unit>
        <trans-unit id="cb8d2af32f6e15f6d8381b5609652e77d17356c4" translate="yes" xml:space="preserve">
          <source>Whether the target values y are normalized, the mean and variance of the target values are set equal to 0 and 1 respectively. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.</source>
          <target state="translated">目標値yが正規化されているかどうかは、目標値の平均値と分散がそれぞれ0と1に等しく設定されています。これは、ゼロ平均、単位分散のプライオが使用される場合に推奨される。この実装では、GP予測値が報告される前に正規化が逆になることに注意してください。</target>
        </trans-unit>
        <trans-unit id="4d56de522c2f2c8fa83698a0d6921644d35a5428" translate="yes" xml:space="preserve">
          <source>Whether the task is a classification task, in which case stratified KFold will be used.</source>
          <target state="translated">タスクが分類タスクであるかどうか、その場合は層化KFoldが使用されます。</target>
        </trans-unit>
        <trans-unit id="667f96156fffe3e4c7c8342ead32f8ae00d3d84f" translate="yes" xml:space="preserve">
          <source>Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If None is passed, the &amp;ldquo;fixed&amp;rdquo; is derived based on the given bounds.</source>
          <target state="translated">このハイパーパラメータの値が固定されているかどうか、つまり、ハイパーパラメータの調整中に変更できないかどうか。Noneが渡された場合、「fixed」は指定された境界に基づいて導出されます。</target>
        </trans-unit>
        <trans-unit id="6cb255093bce0eff775d5414b35fcd6fbd07931b" translate="yes" xml:space="preserve">
          <source>Whether this is a multilabel classifier</source>
          <target state="translated">これがマルチラベル分類器であるかどうか</target>
        </trans-unit>
        <trans-unit id="b1be5efdade94da8e67722b4ba2f983efa0225c5" translate="yes" xml:space="preserve">
          <source>Whether to allow 2-d y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">2次元のy(配列か疎な行列)を許可するかどうか。falseの場合、yはベクトルとして検証されます。 multi_output=Trueの場合、yはnp.nanやnp.infの値を持つことはできません。</target>
        </trans-unit>
        <trans-unit id="110cd422886570c5a4fe2834aa70ff221b2cdcaf" translate="yes" xml:space="preserve">
          <source>Whether to allow 2D y (array or sparse matrix). If false, y will be validated as a vector. y cannot have np.nan or np.inf values if multi_output=True.</source>
          <target state="translated">2次元のy(配列か疎な行列)を許可するかどうか。falseの場合、yはベクトルとして検証されます。 multi_output=Trueの場合、yはnp.nanやnp.infの値を持つことはできません。</target>
        </trans-unit>
        <trans-unit id="8ecc2d4e014d3f2172c25597969963bd34e18f05" translate="yes" xml:space="preserve">
          <source>Whether to allow X.ndim &amp;gt; 2.</source>
          <target state="translated">X.ndim&amp;gt; 2を許可するかどうか。</target>
        </trans-unit>
        <trans-unit id="7a4a847db3917eeca38ca476c1ad3e57930cf992" translate="yes" xml:space="preserve">
          <source>Whether to allow array.ndim &amp;gt; 2.</source>
          <target state="translated">array.ndim&amp;gt; 2を許可するかどうか。</target>
        </trans-unit>
        <trans-unit id="d5dcbf9253f384309cfbc4a594ef7b057c1cb7e6" translate="yes" xml:space="preserve">
          <source>Whether to also return the code U or just the dictionary V.</source>
          <target state="translated">コードUも返すか、辞書Vだけ返すか。</target>
        </trans-unit>
        <trans-unit id="c6289192e1f815e2a760fe289e8841e73f51c42c" translate="yes" xml:space="preserve">
          <source>Whether to be verbose.</source>
          <target state="translated">饒舌になるかどうか。</target>
        </trans-unit>
        <trans-unit id="ccada94fe77cfa7bf4094a2aaa2265ce9f9f4e5f" translate="yes" xml:space="preserve">
          <source>Whether to cache downloaded datasets using joblib.</source>
          <target state="translated">joblibを使用してダウンロードしたデータセットをキャッシュするかどうか。</target>
        </trans-unit>
        <trans-unit id="86614eccba121d18979d29b5e6a1aceed9dc9343" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。Falseに設定されている場合、切片は計算に使用されません(例:データが既に中央にあると予想される)。</target>
        </trans-unit>
        <trans-unit id="7285fa12a56fc9f408db5bd27934d6f0654e6093" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。Falseに設定されている場合、切片は計算に使用されません(つまり、データが中心になると予想されます)。</target>
        </trans-unit>
        <trans-unit id="943768cddf06aea5cdead26cd3dff69cb74196ef" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。falseに設定されている場合、切片は計算に使用されません(例:データが既に中央にあると予想される)。</target>
        </trans-unit>
        <trans-unit id="27f8a383f138130dd1f45baee7b1d68ad4ce59f4" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be already centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。falseに設定されている場合、切片は計算に使用されません(つまり、データはすでに中央にあると予想されます)。</target>
        </trans-unit>
        <trans-unit id="34dd726eec26b92f0d7e507bd65e8b16cfaec4c8" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。falseに設定されている場合、切片は計算に使用されません(つまり、データが中心になると予想されます)。</target>
        </trans-unit>
        <trans-unit id="0336ff17d311b84566800e5cf35b415ab2b27f38" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.</source>
          <target state="translated">このモデルの切片を計算するかどうか。falseに設定すると、切片は計算に使用されません。</target>
        </trans-unit>
        <trans-unit id="7c201504f17506a2291f5d939998458e72428d3b" translate="yes" xml:space="preserve">
          <source>Whether to calculate the intercept for this model. The intercept is not treated as a probabilistic parameter and thus has no associated variance. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).</source>
          <target state="translated">このモデルの切片を計算するかどうか。切片は確率的パラメータとしては扱われないので、関連する分散はありません。Falseに設定すると、切片は計算に使用されません(つまり、データが中心になると予想されます)。</target>
        </trans-unit>
        <trans-unit id="471ed2aff4494fad57e380482ee0a58232333b20" translate="yes" xml:space="preserve">
          <source>Whether to check that &lt;code&gt;transform&lt;/code&gt; followed by &lt;code&gt;inverse_transform&lt;/code&gt; or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original targets.</source>
          <target state="translated">&lt;code&gt;transform&lt;/code&gt; 後に &lt;code&gt;inverse_transform&lt;/code&gt; が続くか、または &lt;code&gt;func&lt;/code&gt; の後に &lt;code&gt;inverse_func&lt;/code&gt; が続くかをチェックするかどうかは、元のターゲットにつながります。</target>
        </trans-unit>
        <trans-unit id="3c61d748141856e990caff79c0b01fd8a4086321" translate="yes" xml:space="preserve">
          <source>Whether to check that or &lt;code&gt;func&lt;/code&gt; followed by &lt;code&gt;inverse_func&lt;/code&gt; leads to the original inputs. It can be used for a sanity check, raising a warning when the condition is not fulfilled.</source>
          <target state="translated">それをチェックするか、 &lt;code&gt;inverse_func&lt;/code&gt; が後に続く &lt;code&gt;func&lt;/code&gt; が元の入力につながります。健全性チェックに使用でき、条件が満たされない場合に警告を発します。</target>
        </trans-unit>
        <trans-unit id="50850a0df7fa2328560b0d7ebe31ee1142901517" translate="yes" xml:space="preserve">
          <source>Whether to compute &lt;code&gt;y_&lt;/code&gt; is increasing (if set to True) or decreasing (if set to False)</source>
          <target state="translated">&lt;code&gt;y_&lt;/code&gt; を計算するかどうかは増加（Trueに設定されている場合）または減少（Falseに設定されている場合）</target>
        </trans-unit>
        <trans-unit id="5fbe7e9ef9385d70942ace9201de11e6cead8f8d" translate="yes" xml:space="preserve">
          <source>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</source>
          <target state="translated">二乗誤差ノルムを計算するか、誤差ノルムを計算するかを指定します。True (デフォルト)の場合、エラーノルムの二乗値を返します。Falseの場合は、エラーノルムを返します。</target>
        </trans-unit>
        <trans-unit id="01086dba4779bb032a62d90a9f9152dc1b833baf" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place computations.</source>
          <target state="translated">XとYをコピーするか、インプレース計算を行うか。</target>
        </trans-unit>
        <trans-unit id="725302de0fd34aabdbfc0e0affbd4f4fb754127c" translate="yes" xml:space="preserve">
          <source>Whether to copy X and Y, or perform in-place normalization.</source>
          <target state="translated">XとYをコピーするか、インプレース正規化を行うか。</target>
        </trans-unit>
        <trans-unit id="7462b314a4fe2fff7847f10014abb6b1183fa84f" translate="yes" xml:space="preserve">
          <source>Whether to copy X and operate on the copy or perform in-place operations.</source>
          <target state="translated">Xをコピーして操作するか、インプレイス操作をするか。</target>
        </trans-unit>
        <trans-unit id="3692936737114d51a6bb410cb3531454c9ad1d68" translate="yes" xml:space="preserve">
          <source>Whether to copy the precomputed covariance matrix; if False, it may be overwritten.</source>
          <target state="translated">事前に計算された共分散行列をコピーするかどうか。</target>
        </trans-unit>
        <trans-unit id="324d6fe1307968790ddbb142ded331e1979517da" translate="yes" xml:space="preserve">
          <source>Whether to create a copy of X and operate on it or to perform inplace computation (default behaviour).</source>
          <target state="translated">Xのコピーを作成してその上で操作するか、インプレース計算を行うか(デフォルトの動作)。</target>
        </trans-unit>
        <trans-unit id="62527ff1b5ed50e080e833b6d4fd94a862b78590" translate="yes" xml:space="preserve">
          <source>Whether to drop some suboptimal thresholds which would not appear on a plotted ROC curve. This is useful in order to create lighter ROC curves.</source>
          <target state="translated">プロットされたROC曲線上に表示されないいくつかの最適以下のしきい値を削除するかどうか。これは、より軽いROC曲線を作成するのに便利です。</target>
        </trans-unit>
        <trans-unit id="9851e7fdf1748b99ff7c24c940b7ce5f334a6a27" translate="yes" xml:space="preserve">
          <source>Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.</source>
          <target state="translated">第一固有ベクトルを削除するかどうか。スペクトル埋め込みの場合は、接続されたグラフでは第一固有ベクトルが一定のベクトルになるはずなのでTrueにすべきですが、スペクトルクラスタリングの場合は第一固有ベクトルを保持するためにFalseにしておく必要があります。</target>
        </trans-unit>
        <trans-unit id="5f99ffcc1bc3b15acf95363130c37cd5b381a91e" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, and will slow down that method.</source>
          <target state="translated">確率推定を有効にするかどうか。これは、 &lt;code&gt;fit&lt;/code&gt; を呼び出す前に有効にする必要があり、そのメソッドの速度が低下します。</target>
        </trans-unit>
        <trans-unit id="1a58ce6c20ca7e5e36327e21b19b4ffc278a0174" translate="yes" xml:space="preserve">
          <source>Whether to enable probability estimates. This must be enabled prior to calling &lt;code&gt;fit&lt;/code&gt;, will slow down that method as it internally uses 5-fold cross-validation, and &lt;code&gt;predict_proba&lt;/code&gt; may be inconsistent with &lt;code&gt;predict&lt;/code&gt;. Read more in the &lt;a href=&quot;../svm#scores-probabilities&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">確率推定を有効にするかどうか。これは、従来の呼び出しに有効にする必要があり &lt;code&gt;fit&lt;/code&gt; 、それが内部的に5倍クロスバリデーションを使用し、として、その方法が遅くなります &lt;code&gt;predict_proba&lt;/code&gt; はと一致しないことが &lt;code&gt;predict&lt;/code&gt; 。詳細については、&lt;a href=&quot;../svm#scores-probabilities&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4a4497ffca40d00ae7a4f4bda08e5dece2337700" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the code.</source>
          <target state="translated">コードを見つけるときに積極性を強制するかどうか。</target>
        </trans-unit>
        <trans-unit id="2920a1115fbc090ce8de93fb299e0d53a98e0404" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary</source>
          <target state="translated">辞書を見つけるときに積極性を強制するかどうか</target>
        </trans-unit>
        <trans-unit id="cc323427a6369f3d4c345df0c7eab9b613a4b184" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the dictionary.</source>
          <target state="translated">辞書を探すときに積極性を強制するかどうか。</target>
        </trans-unit>
        <trans-unit id="0c86815e9d15a8d79f49100b7de99ab0894ffb4b" translate="yes" xml:space="preserve">
          <source>Whether to enforce positivity when finding the encoding.</source>
          <target state="translated">エンコーディングを見つけるときにポジティブを強制するかどうか。</target>
        </trans-unit>
        <trans-unit id="67962e408072673f64867d41053d2df5bd8ffd92" translate="yes" xml:space="preserve">
          <source>Whether to ensure that y has a numeric type. If dtype of y is object, it is converted to float64. Should only be used for regression algorithms.</source>
          <target state="translated">yが数値型であることを保証するかどうか。yのdtypeがオブジェクトの場合、float64に変換されます。回帰アルゴリズムにのみ使用してください。</target>
        </trans-unit>
        <trans-unit id="a89a89f1fbc0cff73f883e4748e4c43034f0361e" translate="yes" xml:space="preserve">
          <source>Whether to filter invalid parameters or not.</source>
          <target state="translated">無効なパラメータをフィルタリングするかどうか。</target>
        </trans-unit>
        <trans-unit id="8bd7eb051fe8793acf6505d7ff57ac8a40be3e89" translate="yes" xml:space="preserve">
          <source>Whether to fit an intercept for the model. In this case the shape of the returned array is (n_cs, n_features + 1).</source>
          <target state="translated">モデルの切片をフィットさせるかどうか。この場合,返される配列の形状は (n_cs,n_features+1)です.</target>
        </trans-unit>
        <trans-unit id="86604814c1d6f6dc79ece6e1aa0e214e981e58a5" translate="yes" xml:space="preserve">
          <source>Whether to fit the intercept for this model. If set to false, no intercept will be used in calculations (i.e. &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are expected to be centered).</source>
          <target state="translated">このモデルの切片に合わせるかどうか。falseに設定すると、切片は計算に使用されません（つまり、 &lt;code&gt;X&lt;/code&gt; と &lt;code&gt;y&lt;/code&gt; は中央に配置されると予想されます）。</target>
        </trans-unit>
        <trans-unit id="8e39ad37924100e174516b8fe05585ae0c11a660" translate="yes" xml:space="preserve">
          <source>Whether to include &amp;ldquo;special&amp;rdquo; label estimator or test processors.</source>
          <target state="translated">「特別な」ラベル推定器またはテストプロセッサを含めるかどうか。</target>
        </trans-unit>
        <trans-unit id="84818ba086581abd044063f9dd3c5b2beb12eda7" translate="yes" xml:space="preserve">
          <source>Whether to include meta-estimators that can be constructed using an estimator as their first argument. These are currently BaseEnsemble, OneVsOneClassifier, OutputCodeClassifier, OneVsRestClassifier, RFE, RFECV.</source>
          <target state="translated">推定子を第一引数として使用して構築できるメタ推定子を含めるかどうか。これらは現在、BaseEnsemble、OneVsOneClassifier、OutputCodeClassifier、OneVsRestClassifier、RFE、RFECVです。</target>
        </trans-unit>
        <trans-unit id="74d7014a87bc3e04b7cb4d5881013af41aaf9d5f" translate="yes" xml:space="preserve">
          <source>Whether to include train scores.</source>
          <target state="translated">電車のスコアを入れるかどうか。</target>
        </trans-unit>
        <trans-unit id="5a33027c8dd2a3a26ddc387706fe4e97d00f5eae" translate="yes" xml:space="preserve">
          <source>Whether to include train scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="translated">トレーニングスコアを含めるかどうか。訓練スコアの計算は、異なるパラメータ設定がオーバーフィッティング/アンダーフィッティングのトレードオフにどのような影響を与えるかを知るために使用されます。しかし、トレーニングセットのスコアを計算するのは計算コストが高く、最高の一般化性能をもたらすパラメータを選択するためには厳密には必要ではありません。</target>
        </trans-unit>
        <trans-unit id="b770fc1f2ccfc02ef3107a2ecac741b2276c37e8" translate="yes" xml:space="preserve">
          <source>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</source>
          <target state="translated">クラスの先行確率を学習するかどうか。falseの場合、一様な先行確率が使用されます。</target>
        </trans-unit>
        <trans-unit id="8606bf192804810fba78c6bd2b8805fda4483156" translate="yes" xml:space="preserve">
          <source>Whether to load only 10 percent of the data.</source>
          <target state="translated">10%だけロードするかどうか。</target>
        </trans-unit>
        <trans-unit id="3156faf4c491e77c08d3500dd2b8c76947137632" translate="yes" xml:space="preserve">
          <source>Whether to load or not the content of the different files. If true a &amp;lsquo;data&amp;rsquo; attribute containing the text information is present in the data structure returned. If not, a filenames attribute gives the path to the files.</source>
          <target state="translated">異なるファイルのコンテンツをロードするかどうか。trueの場合、テキスト情報を含む 'data'属性が、返されるデータ構造に存在します。そうでない場合は、filenames属性でファイルへのパスを指定します。</target>
        </trans-unit>
        <trans-unit id="81f8d6a01f7cffb7f53496e9cfd84f1ce27de740" translate="yes" xml:space="preserve">
          <source>Whether to make X at least 2d.</source>
          <target state="translated">Xを少なくとも2dにするかどうか。</target>
        </trans-unit>
        <trans-unit id="2a578215f5e1bceb4eddd518c894532f84a10916" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of X. If &lt;code&gt;False&lt;/code&gt;, the input X gets overwritten during fitting.</source>
          <target state="translated">場合かどうかは、Xのコピーを作成するために &lt;code&gt;False&lt;/code&gt; 、入力Xは、フィッティングの際に上書きされます。</target>
        </trans-unit>
        <trans-unit id="e2abdc017941ef25090c0789fe34541086dc5677" translate="yes" xml:space="preserve">
          <source>Whether to make a copy of the given data. If set to False, the initial data will be overwritten.</source>
          <target state="translated">与えられたデータをコピーするかどうか。Falseに設定すると、初期データが上書きされます。</target>
        </trans-unit>
        <trans-unit id="df62a350cab30808585d28e267100de2daf97811" translate="yes" xml:space="preserve">
          <source>Whether to normalize the output matrix to make the leading diagonal elements all 1</source>
          <target state="translated">出力行列を正規化して,対角線の先頭の要素がすべて 1 になるようにするかどうか.</target>
        </trans-unit>
        <trans-unit id="ba6415e4db38e5cea33cf7fab1a514fcf5285867" translate="yes" xml:space="preserve">
          <source>Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.</source>
          <target state="translated">事前計算を行うかどうか。n_targetsやn_samplesが非常に大きい場合のパフォーマンスを向上させる。</target>
        </trans-unit>
        <trans-unit id="4010b2bff9133aaf08486f7fb645e8e39634583e" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. Auto mode by default will use presorting on dense data and default to normal sorting on sparse data. Setting presort to true on sparse data will raise an error.</source>
          <target state="translated">フィッティングでの最適なスプリットの発見を高速化するために、データをプリソートするかどうかを指定します。デフォルトのAutoモードは、密なデータではプリソートを使用し、疎なデータでは通常のソートを使用します。疎なデータでプリソートをtrueに設定すると、エラーが発生します。</target>
        </trans-unit>
        <trans-unit id="29f75c6794195c888ce8399680c96d5b14e65048" translate="yes" xml:space="preserve">
          <source>Whether to presort the data to speed up the finding of best splits in fitting. For the default settings of a decision tree on large datasets, setting this to true may slow down the training process. When using either a smaller dataset or a restricted depth, this may speed up the training.</source>
          <target state="translated">フィッティングでの最適なスプリットの発見を高速化するために、データをプレソートするかどうかを指定します。大きなデータセットでの決定木のデフォルト設定では、これをtrueに設定すると、学習処理が遅くなるかもしれません。より小さなデータセットや深さが制限されているデータセットを使用している場合には、これをtrueに設定すると、訓練が速くなるかもしれません。</target>
        </trans-unit>
        <trans-unit id="cc4d3f96c9bc487e50b4fc4701212f323c65bca6" translate="yes" xml:space="preserve">
          <source>Whether to print progress messages to stdout.</source>
          <target state="translated">プログレスメッセージを標準出力に出力するかどうか。</target>
        </trans-unit>
        <trans-unit id="1ef1345441f84cbc6b06cbfc2b69b730789a6079" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2D.</source>
          <target state="translated">Xが2Dでない場合に値のエラーを発生させるかどうか。</target>
        </trans-unit>
        <trans-unit id="b44ea19ee67df3ef30c54f3be25f24e67c4f3a60" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if X is not 2d.</source>
          <target state="translated">Xが2dでない場合に値エラーを発生させるかどうか。</target>
        </trans-unit>
        <trans-unit id="64b755e00dbefa679127012ca837c554b0c217d7" translate="yes" xml:space="preserve">
          <source>Whether to raise a value error if array is not 2D.</source>
          <target state="translated">配列が2次元でない場合に値のエラーを発生させるかどうか。</target>
        </trans-unit>
        <trans-unit id="b5d06b3c83946e2cd2c05192b834ad6e01c6a1d5" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. The possibilities are:</source>
          <target state="translated">X の np.inf と np.nan でエラーを発生させるかどうか。</target>
        </trans-unit>
        <trans-unit id="eaa329f6263ead71ba810671bba1e6a99379040d" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf and np.nan in X. This parameter does not influence whether y can have np.inf or np.nan values. The possibilities are:</source>
          <target state="translated">Xのnp.infとnp.nanでエラーを発生させるかどうか。このパラメータはyがnp.infとnp.nanの値を持つことができるかどうかには影響しません。可能性は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="ec8573b1162223970fd6725eca010725203428e3" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. The possibilities are:</source>
          <target state="translated">X の np.inf,np.nan,pd.NA でエラーを発生させるかどうか。</target>
        </trans-unit>
        <trans-unit id="68ace26fa0c8880f45dfa331c844e7939329fec1" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in X. This parameter does not influence whether y can have np.inf, np.nan, pd.NA values. The possibilities are:</source>
          <target state="translated">Xのnp.inf,np.nan,pd.NAでエラーを発生させるかどうか。このパラメータは、yがnp.inf,np.nan,pd.NAの値を持つことができるかどうかには影響しません。可能性は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="3bbeec18546bd2f3b8cccf2897d9a3a9aee68173" translate="yes" xml:space="preserve">
          <source>Whether to raise an error on np.inf, np.nan, pd.NA in array. The possibilities are:</source>
          <target state="translated">配列内のnp.inf,np.nan,pd.NAでエラーを発生させるかどうか。可能性は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="c551edd4edb4cf1081c3e3d3eb3a36ad8f839a51" translate="yes" xml:space="preserve">
          <source>Whether to raise an error or ignore if an unknown categorical feature is present during transform (default is to raise). When this parameter is set to &amp;lsquo;ignore&amp;rsquo; and an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.</source>
          <target state="translated">エラーが発生するか、変換中に不明なカテゴリ機能が存在する場合は無視するか（デフォルトでは発生）。このパラメーターが 'ignore'に設定されていて、変換中に不明なカテゴリが検出されると、この機能の結果として生じるワンホットエンコードされた列はすべてゼロになります。逆変換では、不明なカテゴリはなしと表示されます。</target>
        </trans-unit>
        <trans-unit id="55b5cf4021bca4319afc6cff07e1e1c5a8e21c80" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).</source>
          <target state="translated">形状（n_samples、n_classes）の1対rest（ 'ovr'）決定関数を他のすべての分類子として返すか、形状（n_samples）を持つlibsvmの元の1対1（ 'ovo'）決定関数を返すか、n_classes *（n_classes-1）/ 2）。</target>
        </trans-unit>
        <trans-unit id="3e008ca3901c2f4656b69b334cd2bbf88df838cc" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy.</source>
          <target state="translated">形状（n_samples、n_classes）の1対rest（ 'ovr'）決定関数を他のすべての分類子として返すか、形状（n_samples）を持つlibsvmの元の1対1（ 'ovo'）決定関数を返すか、n_classes *（n_classes-1）/ 2）。ただし、1対1（ 'ovo'）は常にマルチクラス戦略として使用されます。</target>
        </trans-unit>
        <trans-unit id="7af50893420dd3e6c393c168dece6ee3ddea82a0" translate="yes" xml:space="preserve">
          <source>Whether to return a one-vs-rest (&amp;lsquo;ovr&amp;rsquo;) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (&amp;lsquo;ovo&amp;rsquo;) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (&amp;lsquo;ovo&amp;rsquo;) is always used as multi-class strategy. The parameter is ignored for binary classification.</source>
          <target state="translated">形状（n_samples、n_classes）のone-vs-rest（ 'ovr'）決定関数を他のすべての分類子として返すか、形状（n_samples）を持つlibsvmの元のone-vs-one（ 'ovo'）決定関数を返すか、n_classes *（n_classes-1）/ 2）。ただし、one-vs-one（ 'ovo'）は常にマルチクラス戦略として使用されます。二項分類では、パラメーターは無視されます。</target>
        </trans-unit>
        <trans-unit id="ebccc28d7f21db5d9325894eec5fc9e6d02d15c3" translate="yes" xml:space="preserve">
          <source>Whether to return dense output even when the input is sparse. If &lt;code&gt;False&lt;/code&gt;, the output is sparse if both input arrays are sparse.</source>
          <target state="translated">入力がスパースの場合でも密な出力を返すかどうか。場合は &lt;code&gt;False&lt;/code&gt; の両方の入力配列がスパースであれば、出力はまばらです。</target>
        </trans-unit>
        <trans-unit id="12da7a3ff0421b885caca94ef2caa65b1b016c5f" translate="yes" xml:space="preserve">
          <source>Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.</source>
          <target state="translated">順方向のパスに沿って、ゼロではない係数のすべての値を返すかどうか。クロスバリデーションに便利。</target>
        </trans-unit>
        <trans-unit id="6a16a084b2e44866fb8e9c04ea892f46ef9407d0" translate="yes" xml:space="preserve">
          <source>Whether to return the estimators fitted on each split.</source>
          <target state="translated">各分割でフィットした推定値を返すかどうか。</target>
        </trans-unit>
        <trans-unit id="5e04c1a3b3a800f3b607834e4028e06fab1a7b16" translate="yes" xml:space="preserve">
          <source>Whether to return the fit and score times.</source>
          <target state="translated">フィットとスコアタイムを返すかどうか。</target>
        </trans-unit>
        <trans-unit id="a0296def7d7feccd7f063d12d572b0bb6de2b0cd" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations or not.</source>
          <target state="translated">反復回数を返すかどうか。</target>
        </trans-unit>
        <trans-unit id="642c6fa9e4316671c7770b59f9d72b6641ef628f" translate="yes" xml:space="preserve">
          <source>Whether to return the number of iterations.</source>
          <target state="translated">反復回数を返すかどうか。</target>
        </trans-unit>
        <trans-unit id="b549a24da790409f4ec3623e7b38a8b83191c416" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction.</source>
          <target state="translated">事後予測の標準偏差を返すかどうか。</target>
        </trans-unit>
        <trans-unit id="b33ff2a27948731af021590a907c614a500fc29d" translate="yes" xml:space="preserve">
          <source>Whether to return the standard deviation of posterior prediction. All zeros in this case.</source>
          <target state="translated">事後予測の標準偏差を返すかどうか。この場合はすべてゼロ。</target>
        </trans-unit>
        <trans-unit id="7f1c62ca9183e80a5d93cc97ae0f6b09aa7ca43f" translate="yes" xml:space="preserve">
          <source>Whether to sample from the (Gaussian) predictive posterior of the fitted estimator for each imputation. Estimator must support &lt;code&gt;return_std&lt;/code&gt; in its &lt;code&gt;predict&lt;/code&gt; method if set to &lt;code&gt;True&lt;/code&gt;. Set to &lt;code&gt;True&lt;/code&gt; if using &lt;code&gt;IterativeImputer&lt;/code&gt; for multiple imputations.</source>
          <target state="translated">各代入について、近似推定量の（ガウス）予測事後予測からサンプリングするかどうか。見積もりはサポートされている必要があり &lt;code&gt;return_std&lt;/code&gt; その中で &lt;code&gt;predict&lt;/code&gt; に設定した場合の方法 &lt;code&gt;True&lt;/code&gt; 。複数の代入に &lt;code&gt;IterativeImputer&lt;/code&gt; を使用する場合は、 &lt;code&gt;True&lt;/code&gt; に設定します。</target>
        </trans-unit>
        <trans-unit id="ef9a1d5fe208dc604ffba3d0e60394e32f61bdb0" translate="yes" xml:space="preserve">
          <source>Whether to scale X and Y.</source>
          <target state="translated">XとYの目盛りをつけるかどうか。</target>
        </trans-unit>
        <trans-unit id="06ccde346dfb7273af2d0810793b1fb5e47df0dc" translate="yes" xml:space="preserve">
          <source>Whether to show informative labels for impurity, etc. Options include &amp;lsquo;all&amp;rsquo; to show at every node, &amp;lsquo;root&amp;rsquo; to show only at the top root node, or &amp;lsquo;none&amp;rsquo; to not show at any node.</source>
          <target state="translated">不純などの情報ラベルを表示するかどうか。オプションには、すべてのノードで表示する「すべて」、最上位のルートノードのみで表示する「ルート」、どのノードでも表示しない「なし」などがあります。</target>
        </trans-unit>
        <trans-unit id="bcd035c2f558018eebfd4e5534f5df5bef89069a" translate="yes" xml:space="preserve">
          <source>Whether to shuffle dataset.</source>
          <target state="translated">データセットをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="9ebdad6142b719150be2c8f67618dba47007c5fd" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each class&amp;rsquo;s samples before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="translated">バッチに分割する前に、各クラスのサンプルをシャッフルするかどうか。各スプリット内のサンプルはシャッフルされないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="8704d580bb26c2f6617363a0297f26abfb9fda30" translate="yes" xml:space="preserve">
          <source>Whether to shuffle each stratification of the data before splitting into batches.</source>
          <target state="translated">バッチに分割する前に、データの各層別をシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="5de7b9303caa771da78304a93ebeac224ba77f9b" translate="yes" xml:space="preserve">
          <source>Whether to shuffle samples in each iteration. Only used when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;.</source>
          <target state="translated">各反復でサンプルをシャッフルするかどうか。solver = 'sgd'または 'adam'の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="3558a0c3a77b9ce3c242cc621a2d776c46a133af" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches.</source>
          <target state="translated">バッチに分割する前にデータをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="2b23f04bb0d66dad8fab9e868398f1780b26b6ed" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.</source>
          <target state="translated">バッチに分割する前にデータをシャッフルするかどうか。各分割内のサンプルはシャッフルされないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="ddc8f26baf73b311e3fd82ce49af7a5449330660" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the data before splitting it in batches.</source>
          <target state="translated">一括で分割する前にデータをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="f23a63355a4e388bf6ee14cbad5c7c9c8b8c8007" translate="yes" xml:space="preserve">
          <source>Whether to shuffle the samples.</source>
          <target state="translated">サンプルをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="a5c75421672ae29d738aa02687f5d9f3ec0cf20c" translate="yes" xml:space="preserve">
          <source>Whether to shuffle training data before taking prefixes of it based on``train_sizes``.</source>
          <target state="translated">訓練データの接頭辞を取る前に、``train_size``に基づいて訓練データをシャッフルするかどうか。</target>
        </trans-unit>
        <trans-unit id="ce33fd98a79a5db67d420efb6fcabed70acb96c4" translate="yes" xml:space="preserve">
          <source>Whether to sort x before computing. If False, assume that x must be either monotonic increasing or monotonic decreasing. If True, y is used to break ties when sorting x. Make sure that y has a monotonic relation to x when setting reorder to True.</source>
          <target state="translated">計算前に x をソートするかどうか。False の場合、x は単調増加または単調減少のいずれかでなければならないと仮定します。True の場合、x をソートする際に y が使用されます。</target>
        </trans-unit>
        <trans-unit id="5091491cac888f3972a1197cfef1256978c18b5f" translate="yes" xml:space="preserve">
          <source>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</source>
          <target state="translated">疎な特徴ベクトルを、その負の部分と正の部分の連結に分割するかどうか。これにより,下流の分類器の性能を向上させることができる.</target>
        </trans-unit>
        <trans-unit id="8b58e41338c55eaf50346244bd6082e4f3c1a628" translate="yes" xml:space="preserve">
          <source>Whether to use Nesterov&amp;rsquo;s momentum. Only used when solver=&amp;rsquo;sgd&amp;rsquo; and momentum &amp;gt; 0.</source>
          <target state="translated">ネステロフの勢いを使うかどうか。solver = 'sgd'かつモーメンタム&amp;gt; 0の場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="6cb6c1fd9950933ec2b1bd309d3cbc04da69eccd" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">計算を高速化するために、事前に計算されたグラムおよびXy行列を使用するかどうか。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-targets&quot;&gt;n_targets&lt;/a&gt;または&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-n-samples&quot;&gt;n_samples&lt;/a&gt;が非常に大きい場合のパフォーマンスが向上します。そのような行列がすでにある場合は、それらを直接fitメソッドに渡すことができることに注意してください。</target>
        </trans-unit>
        <trans-unit id="d97545296a16ed9ee24e38ded3551b9344d66c64" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when &lt;code&gt;n_targets&lt;/code&gt; or &lt;code&gt;n_samples&lt;/code&gt; is very large. Note that if you already have such matrices, you can pass them directly to the fit method.</source>
          <target state="translated">事前計算されたグラムとXy行列を使用して計算を高速化するかどうか。 &lt;code&gt;n_targets&lt;/code&gt; または &lt;code&gt;n_samples&lt;/code&gt; が非常に大きい場合のパフォーマンスを改善します。すでにそのような行列がある場合は、それらをfitメソッドに直接渡すことができます。</target>
        </trans-unit>
        <trans-unit id="7dc600168d6ae4c500452eb14badcdfddafb11ff" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &amp;lsquo;auto&amp;rsquo; let us decide. The Gram matrix can also be passed as argument, but it will be used only for the selection of parameter alpha, if alpha is &amp;lsquo;aic&amp;rsquo; or &amp;lsquo;bic&amp;rsquo;.</source>
          <target state="translated">事前計算されたグラム行列を使用して計算を高速化するかどうか。「auto」に設定されている場合は、決定してみましょう。グラム行列も引数として渡すことができますが、alphaが 'aic'または 'bic'の場合、パラメーターalphaの選択にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="0057a82fcc5e3ed086a2d1961e27e45b3f58597f" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument.</source>
          <target state="translated">事前計算されたグラム行列を使用して計算を高速化するかどうか。 &lt;code&gt;'auto'&lt;/code&gt; 設定されている場合は、決定してみましょう。グラム行列も引数として渡すことができます。</target>
        </trans-unit>
        <trans-unit id="419f7e60c7c4f4f84360a1078ab4b36ce5bf208a" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">事前計算されたグラム行列を使用して計算を高速化するかどうか。 &lt;code&gt;'auto'&lt;/code&gt; 設定されている場合は、決定してみましょう。グラム行列も引数として渡すことができます。スパース入力の場合、スパース性を維持するために、このオプションは常に &lt;code&gt;True&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="18cfe378dd4d6390fca460de4e70af73f097cdf4" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. If set to &lt;code&gt;'auto'&lt;/code&gt; let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</source>
          <target state="translated">事前計算されたグラム行列を使用して計算を高速化するかどうか。 &lt;code&gt;'auto'&lt;/code&gt; 設定されている場合は、決定してみましょう。Xのサブセットのみを使用するため、グラム行列を引数として渡すことはできません。</target>
        </trans-unit>
        <trans-unit id="2bc24bd08e69b99e2a7b63ee3e5ac92e16a75bc1" translate="yes" xml:space="preserve">
          <source>Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always &lt;code&gt;True&lt;/code&gt; to preserve sparsity.</source>
          <target state="translated">事前計算されたグラム行列を使用して計算を高速化するかどうか。グラム行列も引数として渡すことができます。スパース入力の場合、スパース性を維持するために、このオプションは常に &lt;code&gt;True&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="1efc80d653c0b8715eb15bdf1b19f3becd74a957" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">検証スコアが改善していない場合に早期停止を使用してトレーニングを終了するかどうかを指定します。Trueに設定されている場合、学習データの一部を自動的にバリデーションとして設定し、連続するn_iter_no_changeエポックに対して少なくともtolだけバリデーションスコアが改善されていない場合に学習を終了します。</target>
        </trans-unit>
        <trans-unit id="46750b1ddce70e8be53fc930ce5b9a753b67b8f6" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs.</source>
          <target state="translated">検証スコアが改善されていないときに、早期停止を使用してトレーニングを終了するかどうか。Trueに設定すると、トレーニングデータの一部が検証として自動的に確保され、 &lt;code&gt;score&lt;/code&gt; メソッドによって返される検証スコアが &lt;code&gt;n_iter_no_change&lt;/code&gt; の連続するエポックで少なくとも &lt;code&gt;tol&lt;/code&gt; 向上しない場合に、トレーニングが終了します。</target>
        </trans-unit>
        <trans-unit id="febff6e36a4dd65c498e48c75789d34dc34067ef" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the &lt;code&gt;score&lt;/code&gt; method is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">検証スコアが改善されていないときに、早期停止を使用してトレーニングを終了するかどうか。Trueに設定すると、トレーニングデータの階層化された部分が検証として自動的に確保され、 &lt;code&gt;score&lt;/code&gt; メソッドによって返される検証スコアがn_iter_no_changeの連続するエポックで少なくともtol向上しない場合、トレーニングが終了します。</target>
        </trans-unit>
        <trans-unit id="9af303ba091050935df1b1843777cae63d69ca4c" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least &lt;code&gt;tol&lt;/code&gt; for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">検証スコアが向上しない場合に、早期停止を使用してトレーニングを終了するかどうか。trueに設定すると、トレーニングデータの10％が検証として自動的に確保され、検証スコアが &lt;code&gt;n_iter_no_change&lt;/code&gt; の連続したエポックに対して少なくとも &lt;code&gt;tol&lt;/code&gt; 改善されない場合、トレーニングが終了します。solver = 'sgd'または 'adam'の場合にのみ有効</target>
        </trans-unit>
        <trans-unit id="998484dc55c21823abb36e2b54f5b8f623a0a41f" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">検証スコアが向上しない場合に、早期停止を使用してトレーニングを終了するかどうか。trueに設定すると、トレーニングデータの10％が検証として自動的に確保され、検証スコアが &lt;code&gt;n_iter_no_change&lt;/code&gt; の連続したエポックに対して少なくともtol改善されない場合、トレーニングが終了します。solver = 'sgd'または 'adam'の場合にのみ有効</target>
        </trans-unit>
        <trans-unit id="87617bcbcc672722844a1d3a57de3b252ff02aa0" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for &lt;code&gt;n_iter_no_change&lt;/code&gt; consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver=&amp;rsquo;sgd&amp;rsquo; or &amp;lsquo;adam&amp;rsquo;</source>
          <target state="translated">検証スコアが改善されていないときに、早期停止を使用してトレーニングを終了するかどうか。trueに設定すると、トレーニングデータの10％が検証として自動的に確保され、 &lt;code&gt;n_iter_no_change&lt;/code&gt; の連続するエポックで検証スコアが少なくともtol向上しない場合、トレーニングが終了します。マルチラベル設定を除いて、分割は階層化されます。ソルバー= 'sgd'または 'adam'の場合にのみ有効</target>
        </trans-unit>
        <trans-unit id="cec695b146ca339e70be6934dce1a5005aa741f4" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">スコアが改善していない場合に早期停止を使用してトレーニングを終了するかどうかを指定します。Trueに設定されている場合、学習データの一部を自動的にバリデーションとして設定し、連続するn_iter_no_changeエポックに対して、バリデーションスコアが少なくともtolだけ改善されていない場合に学習を終了します。</target>
        </trans-unit>
        <trans-unit id="09b2b6c8cb36dc98a800b35af81d1805bc50fee1" translate="yes" xml:space="preserve">
          <source>Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.</source>
          <target state="translated">スコアが改善していない場合に早期停止を使用してトレーニングを終了するかどうかを指定します。Trueに設定されている場合、自動的に層化されたトレーニングデータの一部をバリデーションとして設定し、連続するn_iter_no_changeエポックに対してバリデーションスコアが少なくともtolだけ改善されていない場合にトレーニングを終了します。</target>
        </trans-unit>
        <trans-unit id="aad0324e5e5b11eda436b08ef9513e34456be6fd" translate="yes" xml:space="preserve">
          <source>Whether to use mini-batch k-means, which is faster but may get different results.</source>
          <target state="translated">ミニバッチk-meansを使用するかどうか、どちらが速いが、異なる結果を得ることができるかもしれない。</target>
        </trans-unit>
        <trans-unit id="098e9f05a9707c21daca2709c375c5f67a6fc326" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</source>
          <target state="translated">袋外サンプルを使用して未見データ上のR^2を推定するかどうか。</target>
        </trans-unit>
        <trans-unit id="cf1378e2f07c46392b05b68a8d3fb4a1b87de256" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization accuracy.</source>
          <target state="translated">一般化精度を推定するためにアウトオブバッグサンプルを使用するかどうか。</target>
        </trans-unit>
        <trans-unit id="b9d7a8d80bd713aecc3b75a6342d626d4ac28b69" translate="yes" xml:space="preserve">
          <source>Whether to use out-of-bag samples to estimate the generalization error.</source>
          <target state="translated">一般化誤差を推定するためにアウトオブバッグサンプルを使用するかどうか。</target>
        </trans-unit>
        <trans-unit id="3aa24f38e2caae33363ee03e7cecc2915d7b4a6e" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic.</source>
          <target state="translated">縮小ヒューリスティックを使うかどうか。</target>
        </trans-unit>
        <trans-unit id="f030250afefd9a8186bdcbf55c79f9c30e8d6a17" translate="yes" xml:space="preserve">
          <source>Whether to use the shrinking heuristic. See the &lt;a href=&quot;../svm#shrinking-svm&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">縮小ヒューリスティックを使用するかどうか。&lt;a href=&quot;../svm#shrinking-svm&quot;&gt;ユーザーガイドを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0fcee6cb3493ee9e39e4cf5b70ffc63bc5b7fc72" translate="yes" xml:space="preserve">
          <source>Whether to zip the stored data on disk. If an integer is given, it should be between 1 and 9, and sets the amount of compression. Note that compressed arrays cannot be read by memmapping.</source>
          <target state="translated">保存されたデータをディスクにzip圧縮するかどうかを指定します。整数が与えられた場合は、1 から 9 の間の値を指定し、圧縮の量を設定します。圧縮された配列はmemmappingでは読み込めないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="67c666eda0eb6c9f89cf06ca0fe8ba3d19260935" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices.</source>
          <target state="translated">変換して scipy.sparse matrices を生成するかどうか.</target>
        </trans-unit>
        <trans-unit id="a8c18609d5573425cb13e22e1562611896bad931" translate="yes" xml:space="preserve">
          <source>Whether transform should produce scipy.sparse matrices. True by default.</source>
          <target state="translated">scipy.sparse行列を生成するかどうかを指定します。デフォルトではTrue。</target>
        </trans-unit>
        <trans-unit id="a2a2f7408a4ab356f12406498e7b656415a8f8e4" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the [0, 1] interval, i.e. is not a proper probability. If True, the smallest value in y_prob is linearly mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">y_prob を [0,1]区間に正規化する必要があるかどうか、つまり適切な確率ではないかどうか。True の場合、y_prob の最小値は 0 に、最大値は 1 に線形マッピングされます。</target>
        </trans-unit>
        <trans-unit id="96e3c213b0373954a6f42c2953a288bf58e9c8e1" translate="yes" xml:space="preserve">
          <source>Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not a proper probability. If True, the smallest value in y_prob is mapped onto 0 and the largest one onto 1.</source>
          <target state="translated">y_prob を bin [0,1]に正規化する必要があるかどうか、つまり適切な確率ではないかどうか。True の場合、y_prob の最小値は 0 に、最大値は 1 にマップされます。</target>
        </trans-unit>
        <trans-unit id="673ccf9c3156ee120e948d124a09a8f79d0986df" translate="yes" xml:space="preserve">
          <source>Which SVD method to use. If &amp;lsquo;lapack&amp;rsquo; use standard SVD from scipy.linalg, if &amp;lsquo;randomized&amp;rsquo; use fast &lt;code&gt;randomized_svd&lt;/code&gt; function. Defaults to &amp;lsquo;randomized&amp;rsquo;. For most applications &amp;lsquo;randomized&amp;rsquo; will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for &lt;code&gt;iterated_power&lt;/code&gt;. If this is not sufficient, for maximum precision you should choose &amp;lsquo;lapack&amp;rsquo;.</source>
          <target state="translated">使用するSVDメソッド。「lapack」の場合はscipy.linalgからの標準SVDを使用し、「randomized」の場合は高速 &lt;code&gt;randomized_svd&lt;/code&gt; 関数を使用します。デフォルトは「ランダム」です。ほとんどのアプリケーションでは、「ランダム化」は十分に正確であり、速度が大幅に向上します。 &lt;code&gt;iterated_power&lt;/code&gt; に高い値を設定することで、精度を向上させることもできます。これでは不十分な場合、最大の精度を得るには「lapack」を選択する必要があります。</target>
        </trans-unit>
        <trans-unit id="3f4bd36722594cddb9c4f04fa1feac290cb2c703" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &amp;lsquo;precomputed&amp;rsquo; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &amp;lsquo;euclidean&amp;rsquo; uses the negative squared euclidean distance between points.</source>
          <target state="translated">使用するアフィニティ。現時点では、「事前計算済み」と &lt;code&gt;euclidean&lt;/code&gt; がサポートされています。「ユークリッド」は、ポイント間の負の2乗ユークリッド距離を使用します。</target>
        </trans-unit>
        <trans-unit id="f51286fa5438dabdb2fdc9e6a35c79244bd208d2" translate="yes" xml:space="preserve">
          <source>Which affinity to use. At the moment &lt;code&gt;precomputed&lt;/code&gt; and &lt;code&gt;euclidean&lt;/code&gt; are supported. &lt;code&gt;euclidean&lt;/code&gt; uses the negative squared euclidean distance between points.</source>
          <target state="translated">使用する親和性。現時点では、 &lt;code&gt;precomputed&lt;/code&gt; および &lt;code&gt;euclidean&lt;/code&gt; がサポートされています。 &lt;code&gt;euclidean&lt;/code&gt; は、ポイント間の負の2乗ユークリッド距離を使用します。</target>
        </trans-unit>
        <trans-unit id="0a291d7f5d694ce4dae77d370f938e385f2f41cf" translate="yes" xml:space="preserve">
          <source>Which kind of estimators should be returned. If None, no filter is applied and all estimators are returned. Possible values are &amp;lsquo;classifier&amp;rsquo;, &amp;lsquo;regressor&amp;rsquo;, &amp;lsquo;cluster&amp;rsquo; and &amp;lsquo;transformer&amp;rsquo; to get estimators only of these specific types, or a list of these to get the estimators that fit at least one of the types.</source>
          <target state="translated">返される推定器の種類。Noneの場合、フィルターは適用されず、すべての推定量が返されます。可能な値は、「classifier」、「regressor」、「cluster」、「transformer」で、これらの特定のタイプの推定量のみを取得するか、これらのリストを使用して、少なくとも1つのタイプに適合する推定量を取得します。</target>
        </trans-unit>
        <trans-unit id="9ab873abc046d5e79c6628d1e73d15a9a8c8a011" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">どの連結基準を使用するか。連結基準は、特徴のセット間で使用する距離を決定します。アルゴリズムは,この基準を最小化するクラスタのペアをマージします.</target>
        </trans-unit>
        <trans-unit id="17ba6fc895d15866ea1e60a4db791726755dc58f" translate="yes" xml:space="preserve">
          <source>Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.</source>
          <target state="translated">どの連結基準を使用するか。連結基準は、観測のセット間で使用する距離を決定します。アルゴリズムはこの基準を最小化するクラスタのペアをマージします。</target>
        </trans-unit>
        <trans-unit id="7c032065ee1e199d65a12de581955d2510001155" translate="yes" xml:space="preserve">
          <source>Which metric to use for computing pairwise distances between samples from the original input space. If metric is &amp;lsquo;precomputed&amp;rsquo;, X must be a matrix of pairwise distances or squared distances. Otherwise, see the documentation of argument metric in sklearn.pairwise.pairwise_distances for a list of available metrics.</source>
          <target state="translated">元の入力空間からのサンプル間のペアワイズ距離を計算するために使用するメトリック。メトリックが「事前計算」されている場合、Xはペアワイズ距離または2乗距離の行列である必要があります。それ以外の場合は、利用可能なメトリックのリストについて、sklearn.pairwise.pairwise_distancesの引数メトリックのドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="7ca40022d1c5dcd68056f855d9cb29fbb48c9062" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgement: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">どのモデルが最も良いかは主観的な判断の問題です:詳細を無視してデータの構造の大部分を要約して説明するために全体像だけを捉えたモデルを好むのか、それとも信号の高密度領域に密着したモデルを好むのか。</target>
        </trans-unit>
        <trans-unit id="3bad9460d63c46d91cb72ce5e70c801fdf7d8e5b" translate="yes" xml:space="preserve">
          <source>Which model is the best is a matter of subjective judgment: do we want to favor models that only capture the big picture to summarize and explain most of the structure of the data while ignoring the details or do we prefer models that closely follow the high density regions of the signal?</source>
          <target state="translated">どのモデルが最も良いかは主観的な判断の問題です:詳細を無視してデータの構造の大部分を要約して説明するために全体像を捉えるだけのモデルを好むのか、それとも信号の高密度領域に密接に追従するモデルを好むのか。</target>
        </trans-unit>
        <trans-unit id="f9b07db46ccf2aab5a3f471f9311e28ace0c3658" translate="yes" xml:space="preserve">
          <source>Which strategy to use to initialize the missing values. Same as the &lt;code&gt;strategy&lt;/code&gt; parameter in &lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt;&lt;/a&gt; Valid values: {&amp;ldquo;mean&amp;rdquo;, &amp;ldquo;median&amp;rdquo;, &amp;ldquo;most_frequent&amp;rdquo;, or &amp;ldquo;constant&amp;rdquo;}.</source>
          <target state="translated">欠落している値を初期化するために使用する戦略。&lt;a href=&quot;sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;sklearn.impute.SimpleImputer&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;strategy&lt;/code&gt; パラメーターと同じ有効な値：{&quot;mean&quot;、 &quot;median&quot;、 &quot;most_frequent&quot;、または &quot;constant&quot;}。</target>
        </trans-unit>
        <trans-unit id="e8cddae54ed0b1b16ee030ff58543e83ff547ded" translate="yes" xml:space="preserve">
          <source>While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.</source>
          <target state="translated">Isomap、LLE、およびバリアントは、単一の連続的な低次元多様体を展開するのに最適ですが、t-SNEはデータの局所構造に焦点を当て、S字カーブの例で強調されているように、サンプルのクラスタ化された局所的なグループを抽出する傾向があります。局所構造に基づいてサンプルをグループ化するこの能力は、数字データセットの場合のように、複数の多様体からなるデータセットを一度に視覚的に分離するのに有益かもしれません。</target>
        </trans-unit>
        <trans-unit id="d80a7676bafb31f5f9bcb99f7aed7e1817a9d535" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;および&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;から派生したSVMモデルは &lt;code&gt;C&lt;/code&gt; を正則化パラメーターとして使用しますが、他のほとんどの推定量は &lt;code&gt;alpha&lt;/code&gt; を使用します。2つのモデルの正則化の量の正確な等価性は、モデルによって最適化された正確な目的関数によって異なります。たとえば、使用される推定量が &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; 回帰である場合、それらの間の関係は\（C = \ frac {1} {alpha} \）として与えられます。</target>
        </trans-unit>
        <trans-unit id="e19b90ac75c89776c8025a4fe5ef49998061f2d2" translate="yes" xml:space="preserve">
          <source>While SVM models derived from &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; and &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; use &lt;code&gt;C&lt;/code&gt; as regularization parameter, most other estimators use &lt;code&gt;alpha&lt;/code&gt;. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; regression, the relation between them is given as \(C = \frac{1}{alpha}\).</source>
          <target state="translated">&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;および&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;から派生したSVMモデルは正則化パラメーターとして &lt;code&gt;C&lt;/code&gt; を使用しますが、他のほとんどの推定量は &lt;code&gt;alpha&lt;/code&gt; を使用します。 2つのモデルの正則化の量の正確な同等性は、モデルによって最適化された正確な目的関数に依存します。たとえば、使用される推定量が &lt;code&gt;sklearn.linear_model.Ridge&lt;/code&gt; 回帰である場合、それらの間の関係は\（C = \ frac {1} {alpha} \）として与えられます。</target>
        </trans-unit>
        <trans-unit id="b688dd0a76a7a11c780bc8304b263ca13e9c529b" translate="yes" xml:space="preserve">
          <source>While both methods should be close in general, they might differ in some specific settings. The &amp;lsquo;brute&amp;rsquo; method assumes the existence of the data points \((x_S, x_C^{(i)})\). When the features are correlated, such artificial samples may have a very low probability mass. The &amp;lsquo;brute&amp;rsquo; and &amp;lsquo;recursion&amp;rsquo; methods will likely disagree regarding the value of the partial dependence, because they will treat these unlikely samples differently. Remember, however, that the primary assumption for interpreting PDPs is that the features should be independent.</source>
          <target state="translated">どちらの方法も一般的には近いはずですが、特定の設定によっては異なる場合があります。 'brute'メソッドは、データポイント\（（x_S、x_C ^ {（i）}）\）の存在を前提としています。特徴が相関している場合、そのような人工サンプルは非常に低い確率質量を持つ可能性があります。 'brute'メソッドと 'recursion'メソッドは、これらのありそうもないサンプルを異なる方法で処理するため、部分依存の値に関して意見が一致しない可能性があります。ただし、PDPを解釈するための主な前提は、機能が独立している必要があることです。</target>
        </trans-unit>
        <trans-unit id="fb6c7d447c33735b14bfab3f939085b49d50d551" translate="yes" xml:space="preserve">
          <source>While defining the custom scoring function alongside the calling function should work out of the box with the default joblib backend (loky), importing it from another module will be a more robust approach and work independently of the joblib backend.</source>
          <target state="translated">呼び出し関数と一緒にカスタムスコアリング関数を定義すると、デフォルトのjoblibバックエンド(loky)ですぐに動作するはずですが、別のモジュールからインポートすると、より堅牢なアプローチとなり、joblibバックエンドとは独立して動作するようになります。</target>
        </trans-unit>
        <trans-unit id="c20daeb41107431c48223b43ad4fe138aa4845d5" translate="yes" xml:space="preserve">
          <source>While experimenting with any learning algorithm, it is important not to test the prediction of an estimator on the data used to fit the estimator as this would not be evaluating the performance of the estimator on &lt;strong&gt;new data&lt;/strong&gt;. This is why datasets are often split into &lt;em&gt;train&lt;/em&gt; and &lt;em&gt;test&lt;/em&gt; data.</source>
          <target state="translated">学習アルゴリズムを試しながら、&lt;strong&gt;新しいデータ&lt;/strong&gt;での推定器のパフォーマンスを評価しないため、推定器の適合に使用されるデータで推定器の予測をテストしないことが重要です。これが、データセットが&lt;em&gt;トレーニング&lt;/em&gt;データと&lt;em&gt;テスト&lt;/em&gt;データに分割されることが多い理由です。</target>
        </trans-unit>
        <trans-unit id="f8808630553e3f4de197fcbd8d96757a9a769400" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt;. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">iidデータは機械学習理論では一般的な仮定ですが、実際にはほとんど当てはまりません。サンプルが時間依存プロセスを使用して生成されていることがわかっている場合は、&lt;a href=&quot;#timeseries-cv&quot;&gt;時系列対応の交差検定スキーム&lt;/a&gt;を使用する方が安全です。同様に、生成プロセスがグループ構造（さまざまな被験者、実験、測定デバイスから収集されたサンプル）を持っていることがわかっている場合は、グループ&lt;a href=&quot;#group-cv&quot;&gt;ごとの相互検証&lt;/a&gt;を使用する方が安全です。</target>
        </trans-unit>
        <trans-unit id="d04cd5b9d0463d9bc89f841d571873fec4953569" translate="yes" xml:space="preserve">
          <source>While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it&amp;rsquo;s safer to use a &lt;a href=&quot;#timeseries-cv&quot;&gt;time-series aware cross-validation scheme&lt;/a&gt; Similarly if we know that the generative process has a group structure (samples from collected from different subjects, experiments, measurement devices) it safer to use &lt;a href=&quot;#group-cv&quot;&gt;group-wise cross-validation&lt;/a&gt;.</source>
          <target state="translated">iidデータは機械学習理論では一般的な仮定ですが、実際にはほとんど当てはまりません。サンプルが時間依存プロセスを使用して生成されたことがわかっている場合は、&lt;a href=&quot;#timeseries-cv&quot;&gt;時系列対応の相互検証スキーム&lt;/a&gt;を使用する方が安全です。同様に、生成プロセスがグループ構造（異なる被験者から収集されたサンプル、実験、測定デバイス）&lt;a href=&quot;#group-cv&quot;&gt;グループごとの相互検証&lt;/a&gt;を使用する方が安全です。</target>
        </trans-unit>
        <trans-unit id="0526a7a936d1a8c691dcdaa23691304fc8ebc7ef" translate="yes" xml:space="preserve">
          <source>While in the spirit of an online algorithm, the class &lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt;&lt;code&gt;MiniBatchSparsePCA&lt;/code&gt;&lt;/a&gt; does not implement &lt;code&gt;partial_fit&lt;/code&gt; because the algorithm is online along the features direction, not the samples direction.</source>
          <target state="translated">オンラインアルゴリズムの精神では、アルゴリズムはサンプルの方向ではなく特徴の方向に沿ってオンラインであるため、クラス&lt;a href=&quot;generated/sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA&quot;&gt; &lt;code&gt;MiniBatchSparsePCA&lt;/code&gt; &lt;/a&gt;は &lt;code&gt;partial_fit&lt;/code&gt; を実装していません。</target>
        </trans-unit>
        <trans-unit id="c8d4a37562dd2bb8e9910fd82f43df80f682c63a" translate="yes" xml:space="preserve">
          <source>While many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, intuitively we can think of Principle Component Analysis (PCA) as being a prime example of when normalization is important. In PCA we are interested in the components that maximize the variance. If one component (e.g. human height) varies less than another (e.g. weight) because of their respective scales (meters vs. kilos), PCA might determine that the direction of maximal variance more closely corresponds with the &amp;lsquo;weight&amp;rsquo; axis, if those features are not scaled. As a change in height of one meter can be considered much more important than the change in weight of one kilogram, this is clearly incorrect.</source>
          <target state="translated">多くのアルゴリズム（SVM、K最近傍、ロジスティック回帰など）では機能を正規化する必要がありますが、直感的に、主成分分析（PCA）は正規化が重要な場合の主要な例であると考えることができます。 PCAでは、分散を最大化するコンポーネントに関心があります。 1つのコンポーネント（たとえば、人間の身長）がそれぞれのスケール（メートル対キロ）のために別のコンポーネント（たとえば、体重）よりも変化が少ない場合、PCAは、最大分散の方向が「体重」軸とより密接に対応していると判断する場合があります（これらの機能の場合）。スケーリングされていません。 1メートルの高さの変化は1キログラムの重量の変化よりもはるかに重要であると考えることができるので、これは明らかに正しくありません。</target>
        </trans-unit>
        <trans-unit id="3e272f5577ff59f34cc0835d41b4f8bd0e7fa207" translate="yes" xml:space="preserve">
          <source>While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.</source>
          <target state="translated">あるバージョンのscikit-learnを使って保存されたモデルは他のバージョンで読み込まれるかもしれませんが、これは完全にサポートされておらず、お勧めできません。また、そのようなデータに対して実行される操作は、異なる結果や予期せぬ結果をもたらす可能性があることを覚えておく必要があります。</target>
        </trans-unit>
        <trans-unit id="5cdd1c0f02e03a5a1b156076678017404f8561ab" translate="yes" xml:space="preserve">
          <source>While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell &lt;code&gt;[i, j]&lt;/code&gt; has value 1 if sample &lt;code&gt;i&lt;/code&gt; has label &lt;code&gt;j&lt;/code&gt; and value 0 otherwise.</source>
          <target state="translated">マルチクラスデータは、バイナリターゲットのようにクラスラベルの配列としてメトリックスに提供されますが、マルチラベルデータはインジケーターマトリックスとして指定されます。サンプル &lt;code&gt;i&lt;/code&gt; にラベル &lt;code&gt;j&lt;/code&gt; があり、それ以外の場合は値0の場合 &lt;code&gt;[i, j]&lt;/code&gt; セル[i、j]の値は1です。 。</target>
        </trans-unit>
        <trans-unit id="ed422f68a65d31027201e13d55d1a7c59ba06f45" translate="yes" xml:space="preserve">
          <source>While not particularly fast to process, Python&amp;rsquo;s &lt;code&gt;dict&lt;/code&gt; has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.</source>
          <target state="translated">Pythonの &lt;code&gt;dict&lt;/code&gt; は、処理が特に高速ではありませんが、使いやすく、まばらで（存在しない機能を保存する必要がない）、値に加えて機能名を保存できるという利点があります。</target>
        </trans-unit>
        <trans-unit id="6575e62afd8d9d86f5e5759f0c1f4bf12add49e4" translate="yes" xml:space="preserve">
          <source>While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.</source>
          <target state="translated">個々の単語の代わりにn-gramを抽出することで、いくつかの局所的な位置情報を保存することができますが、単語の袋とn-gramの袋は、文書の内部構造の大部分を破壊し、したがって、その内部構造によって運ばれる意味の大部分を破壊します。</target>
        </trans-unit>
        <trans-unit id="f9eb71a899b2efe02a5e86463ae919f1b60ed0f7" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any (sparse) feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">ながら&lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; TF-IDF行列にそれを使用して、任意の（疎）特徴マトリックスと連動トランスLSA /文書処理設定生頻度カウントにわたって推奨されます。特に、サブリニアスケーリングと逆ドキュメントの頻度をオンにして（ &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ）、特徴値をガウス分布に近づけ、テキストデータに関するLSAの誤った仮定を補正する必要があります。</target>
        </trans-unit>
        <trans-unit id="f9e8e04743afddc659f8d58efbc124813976ac9e" translate="yes" xml:space="preserve">
          <source>While the &lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt;&lt;code&gt;TruncatedSVD&lt;/code&gt;&lt;/a&gt; transformer works with any feature matrix, using it on tf&amp;ndash;idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (&lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt;) to bring the feature values closer to a Gaussian distribution, compensating for LSA&amp;rsquo;s erroneous assumptions about textual data.</source>
          <target state="translated">一方で&lt;a href=&quot;generated/sklearn.decomposition.truncatedsvd#sklearn.decomposition.TruncatedSVD&quot;&gt; &lt;code&gt;TruncatedSVD&lt;/code&gt; &lt;/a&gt; TF-IDF行列にそれを使用して、任意の特徴行列と連携し、変圧器は、LSA /文書処理の設定で、生の頻度カウント上で推奨されます。特に、劣線形スケーリングと逆ドキュメント頻度をオンにして（ &lt;code&gt;sublinear_tf=True, use_idf=True&lt;/code&gt; ）、特徴値をガウス分布に近づけ、テキストデータに関するLSAの誤った仮定を補正する必要があります。</target>
        </trans-unit>
        <trans-unit id="29a2650e25fbd5181744282ce886a2b96e4ac93d" translate="yes" xml:space="preserve">
          <source>While the above example sets the &lt;code&gt;standardize&lt;/code&gt; option to &lt;code&gt;False&lt;/code&gt;, &lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt;&lt;code&gt;PowerTransformer&lt;/code&gt;&lt;/a&gt; will apply zero-mean, unit-variance normalization to the transformed output by default.</source>
          <target state="translated">上記の例では &lt;code&gt;standardize&lt;/code&gt; オプションを &lt;code&gt;False&lt;/code&gt; に設定していますが、&lt;a href=&quot;generated/sklearn.preprocessing.powertransformer#sklearn.preprocessing.PowerTransformer&quot;&gt; &lt;code&gt;PowerTransformer&lt;/code&gt; &lt;/a&gt;はデフォルトで変換された出力にゼロ平均の単位分散正規化を適用します。</target>
        </trans-unit>
        <trans-unit id="e50cabfff84e84e9590f53c8299406f023e4e46d" translate="yes" xml:space="preserve">
          <source>While the hyperparameters chosen by optimizing LML have a considerable larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad) This undesirable effect is caused by the Laplace approximation used internally by GPC.</source>
          <target state="translated">LMLを最適化して選ばれたハイパーパラメタは,かなり大きなLMLを持っていますが,テストデータのlog-lossによると,性能はわずかに悪くなります.図に示すように,これは,クラス境界ではクラス確率の急峻な変化を示す(これは良い)が,クラス境界から遠く離れたところでは0.5に近い予測確率を示す(これは悪い)ためである.</target>
        </trans-unit>
        <trans-unit id="2c9458b61e67bda12a1df752c0cc6921b6ff30dd" translate="yes" xml:space="preserve">
          <source>While the parameter &lt;code&gt;min_samples&lt;/code&gt; primarily controls how tolerant the algorithm is towards noise (on noisy and large data sets it may be desirable to increase this parameter), the parameter &lt;code&gt;eps&lt;/code&gt; is &lt;em&gt;crucial to choose appropriately&lt;/em&gt; for the data set and distance function and usually cannot be left at the default value. It controls the local neighborhood of the points. When chosen too small, most data will not be clustered at all (and labeled as &lt;code&gt;-1&lt;/code&gt; for &amp;ldquo;noise&amp;rdquo;). When chosen too large, it causes close clusters to be merged into one cluster, and eventually the entire data set to be returned as a single cluster. Some heuristics for choosing this parameter have been discussed in the literature, for example based on a knee in the nearest neighbor distances plot (as discussed in the references below).</source>
          <target state="translated">パラメータ &lt;code&gt;min_samples&lt;/code&gt; は、主にアルゴリズムがノイズに対してどの程度耐性があるかを制御しますが（ノイズの多い大きなデータセットでは、このパラメータを増やすことが望ましい場合があります）、パラメータ &lt;code&gt;eps&lt;/code&gt; は、データセットと距離関数に&lt;em&gt;適切に選択すること&lt;/em&gt;が&lt;em&gt;重要で&lt;/em&gt;あり、通常はそのままにすることはできません。デフォルト値で。ポイントのローカル近隣を制御します。選択が小さすぎると、ほとんどのデータはまったくクラスター化されません（ &lt;code&gt;-1&lt;/code&gt; とラベル付けされます）「ノイズ」の場合）。選択が大きすぎると、近いクラスターが1つのクラスターにマージされ、最終的にデータセット全体が単一のクラスターとして返されます。このパラメータを選択するためのいくつかのヒューリスティックは、たとえば、最近傍距離プロットの膝に基づいて、文献で説明されています（以下の参考文献で説明されています）。</target>
        </trans-unit>
        <trans-unit id="17e6df329175ba9fee759ed839a4afe469b184fd" translate="yes" xml:space="preserve">
          <source>While the tf&amp;ndash;idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the &lt;code&gt;binary&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;. In particular, some estimators such as &lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt; explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf&amp;ndash;idf values while the binary occurrence info is more stable.</source>
          <target state="translated">tf-idfの正規化は非常に便利ですが、バイナリオカレンスマーカーがより優れた機能を提供する場合もあります。これは、&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; の&lt;/a&gt; &lt;code&gt;binary&lt;/code&gt; パラメータを使用して実現できます。特に、&lt;a href=&quot;naive_bayes#bernoulli-naive-bayes&quot;&gt;Bernoulli Naive Bayes&lt;/a&gt;などの一部の推定量は、離散ブール確率変数を明示的にモデル化します。また、非常に短いテキストは、バイナリオカレンス情報がより安定している一方で、ノイズの多いtf-idf値を含む可能性があります。</target>
        </trans-unit>
        <trans-unit id="ed181b0221327c005991b804ef6da84808fa6b75" translate="yes" xml:space="preserve">
          <source>While these examples give some intuition about the algorithms, this intuition might not apply to very high dimensional data.</source>
          <target state="translated">これらの例はアルゴリズムについてある程度の直観を与えていますが、この直観は非常に高い次元のデータには適用されないかもしれません。</target>
        </trans-unit>
        <trans-unit id="20e141fdf1f5d5d16051f029790d3b9e841c723d" translate="yes" xml:space="preserve">
          <source>While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:</source>
          <target state="translated">パラメータ設定のグリッドを使用することは、現在、パラメータ最適化に最も広く使用されている方法ですが、他の検索方法にはより好ましい特性があります。&lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt;は、パラメータのランダム検索を実装します。各設定は、可能なパラメータ値の分布からサンプリングされます。これには、徹底的な検索に比べて2つの主な利点があります。</target>
        </trans-unit>
        <trans-unit id="37619fc13053f82b7cb7da3d24ceb1598ab6d05c" translate="yes" xml:space="preserve">
          <source>White</source>
          <target state="translated">White</target>
        </trans-unit>
        <trans-unit id="ae7c1638fd1917cb535ca7c68b4bd5f19a47ea30" translate="yes" xml:space="preserve">
          <source>White kernel.</source>
          <target state="translated">白いカーネル。</target>
        </trans-unit>
        <trans-unit id="6eaf9e8193566018ccba0d72a95d7647c23f2585" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.</source>
          <target state="translated">ホワイトニングは、変換された信号からいくつかの情報(成分の相対的な分散スケール)を除去しますが、下流の推定器のデータをハードワイヤードされた仮定に従うようにすることで、下流の推定器の予測精度を向上させることができる場合があります。</target>
        </trans-unit>
        <trans-unit id="07aaa00ad7b994406ce70b8bd7598f7e15e6859a" translate="yes" xml:space="preserve">
          <source>Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.</source>
          <target state="translated">ホワイトニングは、変換された信号からいくつかの情報(成分の相対的な分散スケール)を除去しますが、データをいくつかのハードワイヤード仮定を尊重するようにすることで、下流の推定器の予測精度を向上させることができる場合があります。</target>
        </trans-unit>
        <trans-unit id="c6caecec2578a0de52910be667f4fa7e322f3d31" translate="yes" xml:space="preserve">
          <source>Why does the plot above suggest that an increase in age leads to a decrease in wage? Why the &lt;a href=&quot;#marginal-dependencies&quot;&gt;initial pairplot&lt;/a&gt; is telling the opposite?</source>
          <target state="translated">上記のプロットが、年齢の増加が賃金の低下につながることを示唆しているのはなぜですか？&lt;a href=&quot;#marginal-dependencies&quot;&gt;最初のペアプロット&lt;/a&gt;が反対のことを言っているのはなぜですか？</target>
        </trans-unit>
        <trans-unit id="b5ed864ec9d16ad31c6639d1d4c3bf64e3372001" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Davies-Bouldin index.</source>
          <target state="translated">デイヴィーズ=ボルダンインデックスのWikipediaエントリー。</target>
        </trans-unit>
        <trans-unit id="3ce8e9b9f756deae78c09a314c4cf49a1aacdb66" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for Discounted Cumulative Gain</source>
          <target state="translated">ウィキペディアの「割引累積利得」のエントリ</target>
        </trans-unit>
        <trans-unit id="a0184957526e21d06d99d8f077fe30eb4aaec4f9" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for contingency matrix</source>
          <target state="translated">ウィキペディアの「コンティンジェンシーマトリックス」のエントリ</target>
        </trans-unit>
        <trans-unit id="55a3b17abc1268c1d436ba897c97b456b993b4ea" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the (normalized) Mutual Information</source>
          <target state="translated">(正規化された)相互情報のウィキペディアエントリ</target>
        </trans-unit>
        <trans-unit id="1f069c9fec7504cb4f8a493de2e1b54ffc547081" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Adjusted Mutual Information</source>
          <target state="translated">調整済み相互情報」のウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="8030a2f6eb81271b3b56dfad08af7aaea7fcfc10" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Average precision</source>
          <target state="translated">平均精度」に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="ca2fe3eff096e2c0ff94d3c0f6ce61af74cc646f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Brier score.</source>
          <target state="translated">ウィキペディアの「ブリア譜」のエントリー</target>
        </trans-unit>
        <trans-unit id="ffd655e9eb3a21416da69aac696bc5ce043a000f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Cohen&amp;rsquo;s kappa.</source>
          <target state="translated">コーエンのカッパのウィキペディアエントリ。</target>
        </trans-unit>
        <trans-unit id="8d8ae14fc3bcf00321ca2d4b9c37c609195c6275" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the F1-score</source>
          <target state="translated">F1スコアに関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="0d85777073541b6f8aecb3488f1962f6903fd77c" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Fowlkes-Mallows Index</source>
          <target state="translated">フォウルケス-マロウズインデックス」のウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="738fb31d9583a6207339f58c0335e89437aa096f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Jaccard index</source>
          <target state="translated">ジャカードインデックスのWikipediaエントリー</target>
        </trans-unit>
        <trans-unit id="d69dce297a7e32abae3549494346594b424875bc" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Matthews Correlation Coefficient</source>
          <target state="translated">マシューズ相関係数 のWikipediaエントリ</target>
        </trans-unit>
        <trans-unit id="d1c0692994293b3fef98ac5de7dd74e23175c8d1" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Precision and recall</source>
          <target state="translated">精度とリコール」に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="6c2dd7ccbd3afed766d1ee6ce92b068445c27bbb" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the Receiver operating characteristic</source>
          <target state="translated">受信機の動作特性に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="caae1d529b64ebeb0d4804273e9107122a389ac6" translate="yes" xml:space="preserve">
          <source>Wikipedia entry for the adjusted Rand index</source>
          <target state="translated">調整済みランド指数のウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="ccc412d2bb1bb2397fbce7363889e5816eda01a2" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis</source>
          <target state="translated">近隣成分分析」に関するウィキペディアの記事</target>
        </trans-unit>
        <trans-unit id="3b36309de0386ff9491f5f72624bcd77d6a05e19" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on Neighborhood Components Analysis &lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</source>
          <target state="translated">近隣コンポーネント分析に関するウィキペディアのエントリ&lt;a href=&quot;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&quot;&gt;https://en.wikipedia.org/wiki/Neighbourhood_components_analysis&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="af0472efa729237e92d89bb05e9ca0c8e7f37b5f" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Coefficient of determination</source>
          <target state="translated">決定係数」に関するWikipediaのエントリ</target>
        </trans-unit>
        <trans-unit id="e345be5719f19335870d8d3a8cdd20b6bd307aa0" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hamming distance</source>
          <target state="translated">ハミング距離」に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="1857fa6b095ad66d104ea60f4be3df45f12529a3" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Hinge loss</source>
          <target state="translated">ヒンジロス」に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="d4ccd1b47442c7552ebe73794cdd38515c5ffdef" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Lasso</source>
          <target state="translated">ウィキペディアの「ラッソ」に関するエントリ</target>
        </trans-unit>
        <trans-unit id="8751f23b19110bb289e70c6d8c900548f6c9b761" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Least-angle regression</source>
          <target state="translated">ウィキペディアの「最小角回帰」に関するエントリ</target>
        </trans-unit>
        <trans-unit id="ed8f4a303fe71f9ad0ec1e1b74ef6fe644dad80d" translate="yes" xml:space="preserve">
          <source>Wikipedia entry on the Silhouette Coefficient</source>
          <target state="translated">シルエット係数」に関するウィキペディアのエントリ</target>
        </trans-unit>
        <trans-unit id="0b665174747365aef367583fb0c32fb021d06a22" translate="yes" xml:space="preserve">
          <source>Wikipedia principal eigenvector</source>
          <target state="translated">ウィキペディアの主な固有ベクトル</target>
        </trans-unit>
        <trans-unit id="713348b23d025b202ea7f033591c046a82a1973b" translate="yes" xml:space="preserve">
          <source>Will be ignored when &lt;code&gt;y_true&lt;/code&gt; is binary.</source>
          <target state="translated">&lt;code&gt;y_true&lt;/code&gt; がバイナリの場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="af498f4dd6f24dbc1f93745e77fe6ed29d0b9d0c" translate="yes" xml:space="preserve">
          <source>Will return sparse matrix if set True else will return an array.</source>
          <target state="translated">True に設定されていない場合は配列を返します。</target>
        </trans-unit>
        <trans-unit id="f02c359862a5df44abc185413e06bdb77cfc5770" translate="yes" xml:space="preserve">
          <source>Williams, C.K.I. and Seeger, M. &amp;ldquo;Using the Nystroem method to speed up kernel machines&amp;rdquo;, Advances in neural information processing systems 2001</source>
          <target state="translated">ウィリアムズ、CKI、シーガー、M。「Nystroemメソッドを使用してカーネルマシンを高速化する」、神経情報処理システムの進歩2001</target>
        </trans-unit>
        <trans-unit id="a20af0cf6ba0496377888d152bfba536fcfdefc1" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{\text{n\_classes}}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">で &lt;code&gt;adjusted=True&lt;/code&gt; 、バランス精度は\（\ texttt {バランス精度}（Y、\ mathbf {0}、W）= \ FRAC {1} {\テキスト{N \ _Classes}} \）からの相対的な増加を報告しています。バイナリの場合、これは&lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* YoudenのJ統計*&lt;/a&gt;または&lt;em&gt;インフォームド&lt;/em&gt;ネスとも呼ば&lt;em&gt;れ&lt;/em&gt;ます。</target>
        </trans-unit>
        <trans-unit id="ad0e52061072794be72972cbf40b994abb34f953" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;adjusted=True&lt;/code&gt;, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{n\_classes}\). In the binary case, this is also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;*Youden&amp;rsquo;s J statistic*&lt;/a&gt;, or &lt;em&gt;informedness&lt;/em&gt;.</source>
          <target state="translated">で &lt;code&gt;adjusted=True&lt;/code&gt; 、バランス精度は\（\ texttt {バランス精度}（Y、\ mathbf {0}、W）= \ FRAC {1} {N \ _Classes} \）からの相対的な増加を報告しています。バイナリの場合、これは&lt;a href=&quot;https://en.wikipedia.org/wiki/Youden%27s_J_statistic&quot;&gt;* YoudenのJ統計*&lt;/a&gt;、または&lt;em&gt;インフォームド&lt;/em&gt;ネスとも呼ば&lt;em&gt;れ&lt;/em&gt;ます。</target>
        </trans-unit>
        <trans-unit id="8a7d860e7dc8979710329f97e747eaff0d3415d3" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the input data.</source>
          <target state="translated">&lt;code&gt;early_stopping=False&lt;/code&gt; の場合、モデルは、全入力データに装着され、停止基準は、入力データを計算の目的関数に基づいています。</target>
        </trans-unit>
        <trans-unit id="3fe735414475494b49457f76f31eea3026d08560" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=False&lt;/code&gt;, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the training data.</source>
          <target state="translated">&lt;code&gt;early_stopping=False&lt;/code&gt; のは、モデルが全体の入力データに装着され、停止基準は、学習データに計算された目的関数に基づいています。</target>
        </trans-unit>
        <trans-unit id="5515c693f110557bb04dd8dc133e8927dc9c68e0" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score (using the &lt;code&gt;score&lt;/code&gt; method) computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;early_stopping=True&lt;/code&gt; 、入力されたデータは、訓練セットと検証セットに分割されます。次に、モデルがトレーニングセットに適合され、停止基準は、検証セットで計算された予測スコア（ &lt;code&gt;score&lt;/code&gt; 法を使用）に基づいています。検証セットのサイズは、パラメーター &lt;code&gt;validation_fraction&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="4ceb9e226f3e04a8a66252e3801eed93f740afd9" translate="yes" xml:space="preserve">
          <source>With &lt;code&gt;early_stopping=True&lt;/code&gt;, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score computed on the validation set. The size of the validation set can be changed with the parameter &lt;code&gt;validation_fraction&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;early_stopping=True&lt;/code&gt; 、入力されたデータは、訓練セットと検証セットに分割されます。次に、モデルはトレーニングセットに適合され、停止基準は検証セットで計算された予測スコアに基づいています。検証セットのサイズは、パラメーター &lt;code&gt;validation_fraction&lt;/code&gt; で変更できます。</target>
        </trans-unit>
        <trans-unit id="318aced6d4dfc924ad223bd54e79ede301143b06" translate="yes" xml:space="preserve">
          <source>With SGD or Adam, training supports online and mini-batch learning.</source>
          <target state="translated">SGD またはアダムを使用すると、トレーニングはオンラインおよびミニバッチ学習をサポートします。</target>
        </trans-unit>
        <trans-unit id="bebfaf6a5f7ee4311c7425773ef87a0b1b61dcc0" translate="yes" xml:space="preserve">
          <source>With SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.</source>
          <target state="translated">SVM とロジスティック回帰では,パラメータ C がスパース度を制御する:C が小さいほど,選択される特徴が少ない.Lassoでは、アルファ・パラメータが高いほど、選択される特徴が少なくなります。</target>
        </trans-unit>
        <trans-unit id="2e07775067fbbb8cee792ed1d4b4b0282fd223be" translate="yes" xml:space="preserve">
          <source>With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:</source>
          <target state="translated">With \(P'(j)=|V_j|/N\)。\(U\)とV\(V\)の相互情報(MI)は、次のように計算されます。</target>
        </trans-unit>
        <trans-unit id="2042997590ba0f656467c3f6df43427a875d6409" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image.</source>
          <target state="translated">凝集型クラスタリングでは、接続性グラフを与えることで、どのサンプルを一緒にクラスタリングするかを指定することができます。scikit-learnでは、グラフは隣接行列で表現されます。多くの場合、疎な行列が使用されます。これは,例えば,画像のクラスタリングを行う際に,連結された領域(連結成分と呼ばれることもあります)を取得するのに便利です.</target>
        </trans-unit>
        <trans-unit id="5313dd287c9c493fc21b86c81282cea7d0608304" translate="yes" xml:space="preserve">
          <source>With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image:</source>
          <target state="translated">凝集型クラスタリングでは、接続性グラフを与えることで、どのサンプルを一緒にクラスタリングするかを指定することができます。scikit-learnでは、グラフは隣接行列で表現されます。多くの場合、疎な行列が使用されます。これは,例えば,画像のクラスタリングを行う際に,連結された領域(連結成分と呼ばれることもあります)を取得するのに便利です.</target>
        </trans-unit>
        <trans-unit id="ebae629f7af13ae26b867ab75161458173d10bdc" translate="yes" xml:space="preserve">
          <source>With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:</source>
          <target state="translated">決定木に関しては、この戦略は多出力問題をサポートするために容易に使用することができる。そのためには、以下の変更が必要である。</target>
        </trans-unit>
        <trans-unit id="d6eab2b8513179355ba20cab88473d0665849027" translate="yes" xml:space="preserve">
          <source>With such an abundance of clues that distinguish newsgroups, the classifiers barely have to identify topics from text at all, and they all perform at the same high level.</source>
          <target state="translated">ニュースグループを区別する手がかりが豊富にあるため、分類器はテキストからトピックを識別する必要がほとんどなく、すべての分類器が同じ高レベルのパフォーマンスを発揮します。</target>
        </trans-unit>
        <trans-unit id="ba25a12704b8225df22eb5cee35ebe73afb76c8b" translate="yes" xml:space="preserve">
          <source>With sum_over_features equal to False it returns the componentwise distances.</source>
          <target state="translated">sum_over_featuresをFalseにすると,成分ごとの距離を返します.</target>
        </trans-unit>
        <trans-unit id="54cc29b6387240d37c6717d5c94b33d650c1152c" translate="yes" xml:space="preserve">
          <source>With the &amp;lsquo;brute&amp;rsquo; method, the parameter &lt;code&gt;X&lt;/code&gt; is used both for generating the grid of values \(x_S\) and the complement feature values \(x_C\). However with the &amp;lsquo;recursion&amp;rsquo; method, &lt;code&gt;X&lt;/code&gt; is only used for the grid values: implicitly, the \(x_C\) values are those of the training data.</source>
          <target state="translated">'brute'メソッドでは、パラメーター &lt;code&gt;X&lt;/code&gt; は、値のグリッド\（x_S \）と補集合の特徴値\（x_C \）の両方を生成するために使用されます。ただし、「再帰」メソッドでは、 &lt;code&gt;X&lt;/code&gt; はグリッド値にのみ使用されます。暗黙的に、\（x_C \）値はトレーニングデータの値です。</target>
        </trans-unit>
        <trans-unit id="67616371d2f2a0ec7fd27c8038627dc9ef441900" translate="yes" xml:space="preserve">
          <source>With the fitted model, we compute the predictions of the model on the test dataset. These predictions are used to compute the confustion matrix which is plotted with the &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">近似モデルを使用して、テストデータセットでモデルの予測を計算します。これらの予測は、&lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt; &lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt; で&lt;/a&gt;プロットされる混同行列を計算するために使用されます</target>
        </trans-unit>
        <trans-unit id="03d84c3da120d3c6633bcd8017a1f00e1bb6dad8" translate="yes" xml:space="preserve">
          <source>With this class, the base_estimator is fit on the train set of the cross-validation generator and the test set is used for calibration. The probabilities for each of the folds are then averaged for prediction. In case that cv=&amp;rdquo;prefit&amp;rdquo; is passed to __init__, it is assumed that base_estimator has been fitted already and all data is used for calibration. Note that data for fitting the classifier and for calibrating it must be disjoint.</source>
          <target state="translated">このクラスでは、base_estimatorが交差検定ジェネレーターのトレインセットに適合し、テストセットがキャリブレーションに使用されます。次に、各フォールドの確率が予測のために平均化されます。cv =&amp;rdquo; prefit&amp;rdquo;が__init__に渡される場合、base_estimatorはすでに適合しており、すべてのデータがキャリブレーションに使用されていると想定されます。分類器を適合させるためのデータとそれを較正するためのデータはばらばらでなければならないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="07ec442186310e3d4d8de1ef730f033183a12d2a" translate="yes" xml:space="preserve">
          <source>With this re-labeling of the data, our problem can be written</source>
          <target state="translated">このようにデータを再ラベル化すると、問題は次のように書けます。</target>
        </trans-unit>
        <trans-unit id="bb9dc2936468de0109f9958206c68ba68552df6f" translate="yes" xml:space="preserve">
          <source>With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a &lt;em&gt;KD-tree&lt;/em&gt; in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt;, and are computed using the class &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt;&lt;/a&gt;. Alternatively, the user can work with the &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; class directly.</source>
          <target state="translated">この設定では、テストポイントと重心の間の単一の距離計算で、ノード内のすべてのポイントまでの距離の下限と上限を決定できます。実際のパフォーマンスはトレーニングデータの構造に大きく依存しますが、ボールツリーノードの球形ジオメトリのため、高次元で&lt;em&gt;KDツリー&lt;/em&gt;よりも優れたパフォーマンスを発揮できます。 scikit-learnでは、ball-treeベースの近傍検索はキーワード &lt;code&gt;algorithm = 'ball_tree'&lt;/code&gt; を使用して指定され、クラス&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;sklearn.neighbors.BallTree&lt;/code&gt; &lt;/a&gt;を使用して計算されます。または、ユーザーは&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt;クラスを直接操作することもできます。</target>
        </trans-unit>
        <trans-unit id="c5b891d6db4b2b53f2c329c62187e665d9759f8a" translate="yes" xml:space="preserve">
          <source>Without any prior information on the sample, the number of projections required to reconstruct the image is of the order of the linear size &lt;code&gt;l&lt;/code&gt; of the image (in pixels). For simplicity we consider here a sparse image, where only pixels on the boundary of objects have a non-zero value. Such data could correspond for example to a cellular material. Note however that most images are sparse in a different basis, such as the Haar wavelets. Only &lt;code&gt;l/7&lt;/code&gt; projections are acquired, therefore it is necessary to use prior information available on the sample (its sparsity): this is an example of &lt;strong&gt;compressive sensing&lt;/strong&gt;.</source>
          <target state="translated">サンプルに関する事前の情報がない場合、画像の再構成に必要な投影の数は、画像の線形サイズ &lt;code&gt;l&lt;/code&gt; （ピクセル単位）のオーダーになります。ここでは簡単にするために、オブジェクトの境界にあるピクセルのみがゼロ以外の値を持つスパース画像を考えます。そのようなデータは、例えば、細胞材料に対応し得る。ただし、ほとんどの画像は、Haarウェーブレットなど、別の基準でスパースであることに注意してください。唯一 &lt;code&gt;l/7&lt;/code&gt; 突起が取得され、したがって、サンプル（そのスパース）上で利用可能な事前情報を使用することが必要である：これは一例である&lt;strong&gt;圧縮センシング&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="087783a9ac4373b41b03a4f66d5eaf61d7d47ff1" translate="yes" xml:space="preserve">
          <source>Without reduce_func:</source>
          <target state="translated">reduce_funcなし。</target>
        </trans-unit>
        <trans-unit id="e6002e635270be50830b0534ba0aafc304922d8b" translate="yes" xml:space="preserve">
          <source>Without shuffling, &lt;code&gt;X&lt;/code&gt; horizontally stacks features in the following order: the primary &lt;code&gt;n_informative&lt;/code&gt; features, followed by &lt;code&gt;n_redundant&lt;/code&gt; linear combinations of the informative features, followed by &lt;code&gt;n_repeated&lt;/code&gt; duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt;.</source>
          <target state="translated">シャッフルせずに、 &lt;code&gt;X&lt;/code&gt; は次の順序で機能を水平方向に積み上げます：主要な &lt;code&gt;n_informative&lt;/code&gt; 機能、それに続く &lt;code&gt;n_redundant&lt;/code&gt; 線形の情報提供機能の組み合わせ、それに続く &lt;code&gt;n_repeated&lt;/code&gt; 重複、情報提供機能と冗長機能からの置換でランダムに描画されます。残りの機能はランダムノイズで満たされます。したがって、シャッフルせずに、すべての有用な機能が列 &lt;code&gt;X[:, :n_informative + n_redundant + n_repeated]&lt;/code&gt; 含まれています。</target>
        </trans-unit>
        <trans-unit id="6943d5826611d6c30be0d7d32e8882ddb2f3e560" translate="yes" xml:space="preserve">
          <source>Wolpert, David H. &amp;ldquo;Stacked generalization.&amp;rdquo; Neural networks 5.2 (1992): 241-259.</source>
          <target state="translated">Wolpert、DavidH。「スタックされた一般化」。ニューラルネットワーク5.2（1992）：241-259。</target>
        </trans-unit>
        <trans-unit id="d2a146386973596d64e5c0f348ec45ab36bab658" translate="yes" xml:space="preserve">
          <source>Working With Text Data</source>
          <target state="translated">テキストデータを使った作業</target>
        </trans-unit>
        <trans-unit id="61f49f0587c5992cc8f414bbf22889f09b8f3976" translate="yes" xml:space="preserve">
          <source>Working with text documents</source>
          <target state="translated">テキスト文書での作業</target>
        </trans-unit>
        <trans-unit id="5b5ef6667bd92ea247084ea267c265251f4aa7de" translate="yes" xml:space="preserve">
          <source>Works with sparse matrices. Only works if &lt;code&gt;rows_&lt;/code&gt; and &lt;code&gt;columns_&lt;/code&gt; attributes exist.</source>
          <target state="translated">スパース行列で動作します。 &lt;code&gt;rows_&lt;/code&gt; および &lt;code&gt;columns_&lt;/code&gt; 属性が存在する場合にのみ機能します。</target>
        </trans-unit>
        <trans-unit id="926da419b9cc98b9060a6d00fb8d48cd55be86f9" translate="yes" xml:space="preserve">
          <source>Wrapper for kernels in sklearn.metrics.pairwise.</source>
          <target state="translated">sklearn.metrics.pairwiseのカーネル用ラッパー。</target>
        </trans-unit>
        <trans-unit id="f986c2ac1f7dce99239d5b1ba2c2c97de265f3fa" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline to classify movie reviews as either positive or negative.</source>
          <target state="translated">映画のレビューをポジティブかネガティブかで分類するためのテキスト分類パイプラインを書きます。</target>
        </trans-unit>
        <trans-unit id="c1b32a0493a32a44864910f6b6b9c9398af4b20e" translate="yes" xml:space="preserve">
          <source>Write a text classification pipeline using a custom preprocessor and &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; using data from Wikipedia articles as training set.</source>
          <target state="translated">カスタムプリプロセッサを使用してテキスト分類パイプラインを作成し、Wikipediaの記事のデータをトレーニングセットとして使用して &lt;code&gt;CharNGramAnalyzer&lt;/code&gt; を作成します。</target>
        </trans-unit>
        <trans-unit id="c72e193d2469d6cfb2918ba7a00dbc8ed1d451d6" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Wu、LinおよびWeng、&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;「ペアワイズカップリングによるマルチクラス分類の確率推定」&lt;/a&gt;、JMLR 5：975-1005、2004年。</target>
        </trans-unit>
        <trans-unit id="11ab439af4c255f5f8d3594c0dad27bd31f9055a" translate="yes" xml:space="preserve">
          <source>Wu, Lin and Weng, &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;&amp;ldquo;Probability estimates for multi-class classification by pairwise coupling&amp;rdquo;&lt;/a&gt;, JMLR 5:975-1005, 2004.</source>
          <target state="translated">Wu、Lin、Weng、&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/svmprob/svmprob.pdf&quot;&gt;「ペアワイズカップリングによるマルチクラス分類の確率推定」&lt;/a&gt;、JMLR 5：975-1005、2004。</target>
        </trans-unit>
        <trans-unit id="c8c1574205d07b839af62817660ba2b78f320cd0" translate="yes" xml:space="preserve">
          <source>X block loadings vectors.</source>
          <target state="translated">Xブロックの負荷ベクトル。</target>
        </trans-unit>
        <trans-unit id="b8076ad410e1a569012d16107ff003e5d358439f" translate="yes" xml:space="preserve">
          <source>X block to latents rotations.</source>
          <target state="translated">潜伏回転にXブロック。</target>
        </trans-unit>
        <trans-unit id="a6b8640132f42899bc713ee5acc307439a5b7049" translate="yes" xml:space="preserve">
          <source>X block weights vectors.</source>
          <target state="translated">X ブロック重みベクトル.</target>
        </trans-unit>
        <trans-unit id="51ee8a5ebc2ecb45284445a844d1c86426452ff9" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set, using minibatches of size batch_size if X is sparse.</source>
          <target state="translated">X は,X が疎な場合には,サイズ batch_size のミニバッチを用いて,訓練セットから以前に抽出された最初の主成分に投影されます.</target>
        </trans-unit>
        <trans-unit id="e6bc2e58339df2a473a9897261f25e31780f738c" translate="yes" xml:space="preserve">
          <source>X is projected on the first principal components previously extracted from a training set.</source>
          <target state="translated">Xは、訓練セットから事前に抽出された第1主成分に投影されます。</target>
        </trans-unit>
        <trans-unit id="81850902f59e77236b068c4b29af3fcf5c8ba36f" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt;&lt;code&gt;transform&lt;/code&gt;&lt;/a&gt; needs X to interpolate new input data.</source>
          <target state="translated">&lt;a href=&quot;#sklearn.isotonic.IsotonicRegression.transform&quot;&gt; &lt;code&gt;transform&lt;/code&gt; &lt;/a&gt;は新しい入力データを補間するためにXが必要なため、Xは将来の使用のために保存されます。</target>
        </trans-unit>
        <trans-unit id="7228d382c859d348525ccb5bce51e5752c38bc04" translate="yes" xml:space="preserve">
          <source>X is stored for future use, as &lt;code&gt;transform&lt;/code&gt; needs X to interpolate new input data.</source>
          <target state="translated">&lt;code&gt;transform&lt;/code&gt; は新しい入力データを補間するためにXを必要とするため、Xは将来の使用のために保存されます。</target>
        </trans-unit>
        <trans-unit id="3074bef8d8da5f206ce501f5438e3d5abb038064" translate="yes" xml:space="preserve">
          <source>X must have been produced by this DictVectorizer&amp;rsquo;s transform or fit_transform method; it may only have passed through transformers that preserve the number of features and their order.</source>
          <target state="translated">Xは、このDictVectorizerの変換またはfit_transformメソッドによって生成されたものでなければなりません。機能の数とその順序を保持するトランスフォーマーのみを通過した可能性があります。</target>
        </trans-unit>
        <trans-unit id="d0ad8e13f68af13dec8ad59c4f3a6a0df7a4de08" translate="yes" xml:space="preserve">
          <source>X scores.</source>
          <target state="translated">Xのスコア。</target>
        </trans-unit>
        <trans-unit id="28a3e4c54c0fde2f1aaa67a11fe405d430c2fe41" translate="yes" xml:space="preserve">
          <source>X transformed in the new space.</source>
          <target state="translated">新しい空間で変身したX。</target>
        </trans-unit>
        <trans-unit id="ae3643384dc9ac54889b85ea1da357f34b173e6e" translate="yes" xml:space="preserve">
          <source>X_embedded: ndarray of shape (n_samples, n_components)</source>
          <target state="translated">X_embedded:形状のndarray (n_samples,n_components)</target>
        </trans-unit>
        <trans-unit id="d925cac037a82cae915e8a0893b59ac5a4590490" translate="yes" xml:space="preserve">
          <source>X_new array, shape (n_samples, n_components)</source>
          <target state="translated">X_new 配列,形状 (n_samples,n_components)</target>
        </trans-unit>
        <trans-unit id="b0e804c93132e5ef73393b841ae090d872aa2191" translate="yes" xml:space="preserve">
          <source>X_original array-like, shape (n_samples, n_features)</source>
          <target state="translated">X_original 配列のような形状 (n_samples,n_features)</target>
        </trans-unit>
        <trans-unit id="feedfda54d7431e28acb98075b2c2bd9cf8331f2" translate="yes" xml:space="preserve">
          <source>Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 &lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</source>
          <target state="translated">Xiaojin ZhuとZoubin Ghahramani。ラベル伝播を使用して、ラベル付きデータとラベルなしデータから学習します。テクニカルレポートCMU-CALD-02-107、カーネギーメロン大学、2002年&lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&quot;&gt;http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5c986ee528dd9bdf7a6c8d0101f77976c47ae9d2" translate="yes" xml:space="preserve">
          <source>Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: &lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;Theil-Sen Estimators in a Multiple Linear Regression Model.&lt;/a&gt;</source>
          <target state="translated">Xin Dang、Hanxiang Peng、Xueqin Wang、Heping Zhang：&lt;a href=&quot;http://home.olemiss.edu/~xdang/papers/MTSE.pdf&quot;&gt;多重線形回帰モデルのTheil-Sen推定量。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3674e6b71697b8f4a5e14e694db26daa53371e84" translate="yes" xml:space="preserve">
          <source>Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.</source>
          <target state="translated">Xt[i,j]には i と j を結ぶ辺の重みが代入される.対角線は常に明示的である.行列は CSR 形式である.</target>
        </trans-unit>
        <trans-unit id="c93217dd923de34853280b8058e56203ef9ee737" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</source>
          <target state="translated">Xy=事前に計算できるnp.dot(X.T,y)。グラム行列が事前計算されている場合にのみ有用です。</target>
        </trans-unit>
        <trans-unit id="700502aa71883c1784c7b4df71f7526cabc3833b" translate="yes" xml:space="preserve">
          <source>Xy = np.dot(X.T, y).</source>
          <target state="translated">Xy=np.dot(X.T,y)。</target>
        </trans-unit>
        <trans-unit id="23eb4d3f4155395a74e9d534f97ff4c1908f5aac" translate="yes" xml:space="preserve">
          <source>Y</source>
          <target state="translated">Y</target>
        </trans-unit>
        <trans-unit id="aac13ced89d2b311880e53ba16f36f4513402a98" translate="yes" xml:space="preserve">
          <source>Y block loadings vectors.</source>
          <target state="translated">Yブロック負荷ベクトル。</target>
        </trans-unit>
        <trans-unit id="148708c0aec99251158277d2fc4d038d62f32551" translate="yes" xml:space="preserve">
          <source>Y block to latents rotations.</source>
          <target state="translated">Yブロックから潜伏回転へ。</target>
        </trans-unit>
        <trans-unit id="8f4ded8aca1a84f4452774f8bc622751045ade48" translate="yes" xml:space="preserve">
          <source>Y block weights vectors.</source>
          <target state="translated">Y ブロック重みベクトル。</target>
        </trans-unit>
        <trans-unit id="780dd8f1641062cfc0af001d2fcfedba3262be26" translate="yes" xml:space="preserve">
          <source>Y scores.</source>
          <target state="translated">Yの得点。</target>
        </trans-unit>
        <trans-unit id="93b5936ef31b077aecad8b961838c412166e9fd0" translate="yes" xml:space="preserve">
          <source>Y. Freund, R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting&amp;rdquo;, 1995.</source>
          <target state="translated">Y.フロイント、R。シャピレ、「オンライン学習の決定論的一般化とブースティングへの応用」、1995年。</target>
        </trans-unit>
        <trans-unit id="bf931371fe813e68af145bc28f1f0c59ead42876" translate="yes" xml:space="preserve">
          <source>Y. Freund, and R. Schapire, &amp;ldquo;A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting&amp;rdquo;, 1997.</source>
          <target state="translated">Y.フロイント、およびR.シャピレ、「オンライン学習の決定論的一般化とブースティングへの応用」、1997年。</target>
        </trans-unit>
        <trans-unit id="982b5c305af507a5853864a0280fe0330e5fb9d9" translate="yes" xml:space="preserve">
          <source>Y[argmin[i], :] is the row in Y that is closest to X[i, :].</source>
          <target state="translated">Y[argmin[i],:]は、X[i,:]に最も近いYの行です。</target>
        </trans-unit>
        <trans-unit id="6cc2acee87fd2b4d368d7294a14e1666de3c66f0" translate="yes" xml:space="preserve">
          <source>Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">ヤン、アルゲスハイマー、およびテッソーネ、（2016）。「人工ネットワーク上のコミュニティ検出アルゴリズムの比較分析」。Scientific Reports 6：30750。doi &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;：10.1038 / srep30750&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="3526f607bcd4f51ad0bc05f814579a42c2c0ba57" translate="yes" xml:space="preserve">
          <source>Yellow</source>
          <target state="translated">Yellow</target>
        </trans-unit>
        <trans-unit id="738a2b66281e5ca4973cbceebc923d1996e03dad" translate="yes" xml:space="preserve">
          <source>Yields</source>
          <target state="translated">Yields</target>
        </trans-unit>
        <trans-unit id="44e848b37858df8125129ee3d3911783b05fb21f" translate="yes" xml:space="preserve">
          <source>Yields indices to split data into training and test sets.</source>
          <target state="translated">データをトレーニングセットとテストセットに分割するための指標を生成します。</target>
        </trans-unit>
        <trans-unit id="c970e3f1e790a2a4cd28b40401902501b9bc2d74" translate="yes" xml:space="preserve">
          <source>Yields:</source>
          <target state="translated">Yields:</target>
        </trans-unit>
        <trans-unit id="e285a8203a02b899c727c909bb971f8a5290d1a9" translate="yes" xml:space="preserve">
          <source>You can &lt;a href=&quot;grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; over parameters of all estimators in the pipeline at once.</source>
          <target state="translated">パイプライン内のすべての推定量のパラメーターを一度に&lt;a href=&quot;grid_search#grid-search&quot;&gt;グリッド検索&lt;/a&gt;できます。</target>
        </trans-unit>
        <trans-unit id="afc09f41b74c7e769c70223fd4fc6ea043be4f9a" translate="yes" xml:space="preserve">
          <source>You can access the newly created figure and Axes objects using &lt;code&gt;plt.gcf()&lt;/code&gt; and &lt;code&gt;plt.gca()&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;plt.gcf()&lt;/code&gt; および &lt;code&gt;plt.gca()&lt;/code&gt; を使用して、新しく作成されたFigureおよびAxesオブジェクトにアクセスできます。</target>
        </trans-unit>
        <trans-unit id="e4f0eb08d1e594cb4ba39dda583b2124c29e8d3e" translate="yes" xml:space="preserve">
          <source>You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them.</source>
          <target state="translated">カテゴリの数を調整するには、カテゴリの名前をデータセットローダに与えるか、カテゴリの数をNoneに設定して、20個のカテゴリを取得することができます。</target>
        </trans-unit>
        <trans-unit id="d6a91645b832623d5d5110588ef04aebdc451880" translate="yes" xml:space="preserve">
          <source>You can already copy the skeletons into a new folder somewhere on your hard-drive named &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; where you will edit your own files for the exercises while keeping the original skeletons intact:</source>
          <target state="translated">スケルトンは、ハードドライブの &lt;code&gt;sklearn_tut_workspace&lt;/code&gt; という名前の新しいフォルダーのどこかに既にコピーできます。元のスケルトンはそのままに、エクササイズ用の独自のファイルを編集します。</target>
        </trans-unit>
        <trans-unit id="1cf0d94595a131d36f8236532aeafb049eaa6dbc" translate="yes" xml:space="preserve">
          <source>You can also specify both the name and the version, which also uniquely identifies the dataset:</source>
          <target state="translated">また、名前とバージョンの両方を指定することもでき、これはデータセットを一意に識別します。</target>
        </trans-unit>
        <trans-unit id="ae5f0da778f6ff8c0d5d1c2ccd6f86bebea3d9e0" translate="yes" xml:space="preserve">
          <source>You can also use your own defined kernels by passing a function to the keyword &lt;code&gt;kernel&lt;/code&gt; in the constructor.</source>
          <target state="translated">コンストラクタでキーワード &lt;code&gt;kernel&lt;/code&gt; に関数を渡すことにより、独自に定義したカーネルを使用することもできます。</target>
        </trans-unit>
        <trans-unit id="c90fd70bc9584ad72350fadce865213cd8c472be" translate="yes" xml:space="preserve">
          <source>You can combine &lt;code&gt;KBinsDiscretizer&lt;/code&gt; with &lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; if you only want to preprocess part of the features.</source>
          <target state="translated">あなたは組み合わせることができ &lt;code&gt;KBinsDiscretizer&lt;/code&gt; をし&lt;a href=&quot;sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;sklearn.compose.ColumnTransformer&lt;/code&gt; &lt;/a&gt;あなただけの機能の前処理部分にしたい場合。</target>
        </trans-unit>
        <trans-unit id="b37a62ca838923df55452889a68156ed8900e3e5" translate="yes" xml:space="preserve">
          <source>You can control the exact number of threads that are used via the &lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; environment variable:</source>
          <target state="translated">&lt;code&gt;OMP_NUM_THREADS&lt;/code&gt; 環境変数を介して、使用されるスレッドの正確な数を制御できます。</target>
        </trans-unit>
        <trans-unit id="579522a3d8d5bf3b4958e7c2d681266388521dce" translate="yes" xml:space="preserve">
          <source>You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.</source>
          <target state="translated">カーネルを python の関数として与えるか、グラム行列を事前に計算することで、独自のカーネルを定義することができます。</target>
        </trans-unit>
        <trans-unit id="5a14b3f83e3bd81fa3adef5b677dc7c591d450db" translate="yes" xml:space="preserve">
          <source>You can display the BLAS / LAPACK implementation used by your NumPy / SciPy / scikit-learn install with the following commands:</source>
          <target state="translated">NumPy/SciPy/scikit-learnで使用しているBLAS/LAPACKの実装を以下のコマンドで表示することができます。</target>
        </trans-unit>
        <trans-unit id="929abd63168ac2d721d4708b8ef8be3cd51b08a0" translate="yes" xml:space="preserve">
          <source>You can ensure that &lt;code&gt;func&lt;/code&gt; and &lt;code&gt;inverse_func&lt;/code&gt; are the inverse of each other by setting &lt;code&gt;check_inverse=True&lt;/code&gt; and calling &lt;code&gt;fit&lt;/code&gt; before &lt;code&gt;transform&lt;/code&gt;. Please note that a warning is raised and can be turned into an error with a &lt;code&gt;filterwarnings&lt;/code&gt;:</source>
          <target state="translated">あなたはそれを保証することができ &lt;code&gt;func&lt;/code&gt; と &lt;code&gt;inverse_func&lt;/code&gt; を設定することで、互いの逆である &lt;code&gt;check_inverse=True&lt;/code&gt; して呼び出す &lt;code&gt;fit&lt;/code&gt; 前に &lt;code&gt;transform&lt;/code&gt; 。警告が発生し、 &lt;code&gt;filterwarnings&lt;/code&gt; でエラーになる可能性があることに注意してください：</target>
        </trans-unit>
        <trans-unit id="8fe8cd91261eb27750ae7b2f82fa15c24077f346" translate="yes" xml:space="preserve">
          <source>You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the &lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt;&lt;code&gt;make_scorer&lt;/code&gt;&lt;/a&gt; factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.make_scorer#sklearn.metrics.make_scorer&quot;&gt; &lt;code&gt;make_scorer&lt;/code&gt; &lt;/a&gt;ファクトリを使用せずに、独自のスコアリングオブジェクトを最初から作成することで、さらに柔軟なモデルスコアラーを生成できます。呼び出し可能オブジェクトがスコアラーになるには、次の2つのルールで指定されたプロトコルを満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="cb07d258c61c328d902779de990b642f82ba2beb" translate="yes" xml:space="preserve">
          <source>You can get more information on the dataset by looking at the &lt;code&gt;DESCR&lt;/code&gt; and &lt;code&gt;details&lt;/code&gt; attributes:</source>
          <target state="translated">&lt;code&gt;DESCR&lt;/code&gt; および &lt;code&gt;details&lt;/code&gt; 属性を調べることにより、データセットに関する詳細情報を取得できます。</target>
        </trans-unit>
        <trans-unit id="316dc294ff0e2890db335b30189c691f1a723809" translate="yes" xml:space="preserve">
          <source>You can now see many things that these features have overfit to:</source>
          <target state="translated">これらの機能がオーバーフィットしていることを多く見ることができるようになりました。</target>
        </trans-unit>
        <trans-unit id="e2cf6b0ce385c4e9fb3f4b5189c83feb905d92cf" translate="yes" xml:space="preserve">
          <source>You can pass pre-computed kernels by using the &lt;code&gt;kernel='precomputed'&lt;/code&gt; option. You should then pass Gram matrix instead of X to the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods. The kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided:</source>
          <target state="translated">&lt;code&gt;kernel='precomputed'&lt;/code&gt; オプションを使用すると、事前に計算されたカーネルを渡すことができます。次に、Xの代わりにグラム行列を &lt;code&gt;fit&lt;/code&gt; および &lt;code&gt;predict&lt;/code&gt; メソッドに渡す必要があります。&lt;em&gt;すべての&lt;/em&gt;トレーニングベクトルとテストベクトルの間のカーネル値を指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="ee86b8b814976ee239ecfc8e86907133be9d3afc" translate="yes" xml:space="preserve">
          <source>You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the &lt;code&gt;n_features&lt;/code&gt; parameter.</source>
          <target state="translated">ベクトル出力で16個のゼロ以外の機能トークンが抽出されたことがわかります。これは、同じおもちゃコーパスの&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;によって以前に抽出された19個のゼロ以外の値よりも小さいです。 &lt;code&gt;n_features&lt;/code&gt; パラメータの値が低いため、ハッシュ関数の衝突により不一致が生じます。</target>
        </trans-unit>
        <trans-unit id="6b3885cd10ec182cb98af7964ed686cdd6c77762" translate="yes" xml:space="preserve">
          <source>You can specify a monotonic constraint on each feature using the &lt;code&gt;monotonic_cst&lt;/code&gt; parameter. For each feature, a value of 0 indicates no constraint, while -1 and 1 indicate a negative and positive constraint, respectively:</source>
          <target state="translated">&lt;code&gt;monotonic_cst&lt;/code&gt; パラメーターを使用して、各フィーチャーに単調な制約を指定できます。各機能について、値0は制約がないことを示し、-1と1はそれぞれ負と正の制約を示します。</target>
        </trans-unit>
        <trans-unit id="c31033fd31d22147ea7534b97a7d63f646fe3e48" translate="yes" xml:space="preserve">
          <source>You can then edit the content of the workspace without fear of losing the original exercise instructions.</source>
          <target state="translated">そうすれば、元のエクササイズの指示を失う心配なく、ワークスペースの内容を編集することができます。</target>
        </trans-unit>
        <trans-unit id="bc5b6b055370779ded34375c059372bbad8d8da3" translate="yes" xml:space="preserve">
          <source>You can use your own defined kernels by passing a function to the &lt;code&gt;kernel&lt;/code&gt; parameter.</source>
          <target state="translated">関数を &lt;code&gt;kernel&lt;/code&gt; パラメーターに渡すことにより、独自に定義したカーネルを使用できます。</target>
        </trans-unit>
        <trans-unit id="e21dcf7dc4d8353d8949b3e6ddc2c35c364a9b4a" translate="yes" xml:space="preserve">
          <source>You cannot nest objects with parallel computing (&lt;code&gt;n_jobs&lt;/code&gt; different than 1).</source>
          <target state="translated">並列計算（1と異なる &lt;code&gt;n_jobs&lt;/code&gt; ）でオブジェクトをネストすることはできません。</target>
        </trans-unit>
        <trans-unit id="d086a1b811e8ad563a3cd7d98758c535aff811c7" translate="yes" xml:space="preserve">
          <source>You could try UTF-8 and disregard the errors. You can decode byte strings with &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; to replace all decoding errors with a meaningless character, or set &lt;code&gt;decode_error='replace'&lt;/code&gt; in the vectorizer. This may damage the usefulness of your features.</source>
          <target state="translated">UTF-8を試して、エラーを無視することができます。バイト文字列を &lt;code&gt;bytes.decode(errors='replace')&lt;/code&gt; でデコードして、すべてのデコードエラーを意味のない文字に &lt;code&gt;decode_error='replace'&lt;/code&gt; か、ベクトライザーでdecode_error = 'replace'を設定できます。これにより、機能の有用性が損なわれる可能性があります。</target>
        </trans-unit>
        <trans-unit id="c0d5a5afa92ed6aa301d13299623473f530c94ba" translate="yes" xml:space="preserve">
          <source>You may also load two (or more) datasets at once:</source>
          <target state="translated">また、2つ(またはそれ以上)のデータセットを一度にロードすることもできます。</target>
        </trans-unit>
        <trans-unit id="a822ec525f0ce269b9b885feec474e1f8b512e04" translate="yes" xml:space="preserve">
          <source>You may also retain the estimator fitted on each training set by setting &lt;code&gt;return_estimator=True&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;return_estimator=True&lt;/code&gt; を設定することにより、各トレーニングセットに適合した推定量を保持することもできます。</target>
        </trans-unit>
        <trans-unit id="c9bcd37e9efb4d07a927274f7ad017afc3f094c8" translate="yes" xml:space="preserve">
          <source>You may be able to find out what kind of encoding it is in general using the UNIX command &lt;code&gt;file&lt;/code&gt;. The Python &lt;code&gt;chardet&lt;/code&gt; module comes with a script called &lt;code&gt;chardetect.py&lt;/code&gt; that will guess the specific encoding, though you cannot rely on its guess being correct.</source>
          <target state="translated">UNIXコマンド &lt;code&gt;file&lt;/code&gt; を使用して、一般的にどのようなエンコーディングであるかを確認できる場合があります。Pythonの &lt;code&gt;chardet&lt;/code&gt; モジュールには、特定のエンコーディングを推測する &lt;code&gt;chardetect.py&lt;/code&gt; というスクリプトが付属していますが、その推測が正しいかどうかに依存することはできません。</target>
        </trans-unit>
        <trans-unit id="04405b99190799597dab92e2ef615219d1447404" translate="yes" xml:space="preserve">
          <source>You may load a dataset like as follows:</source>
          <target state="translated">以下のようにデータセットを読み込むことができます。</target>
        </trans-unit>
        <trans-unit id="f9f71500b978e09c529098f893f05269c79caaff" translate="yes" xml:space="preserve">
          <source>You may want to include the parameters of the preprocessors in a &lt;a href=&quot;grid_search#grid-search&quot;&gt;parameter search&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;grid_search#grid-search&quot;&gt;パラメータ検索に&lt;/a&gt;プリプロセッサのパラメータを含めることができます。</target>
        </trans-unit>
        <trans-unit id="4cbe0908270a3a4effe7f03ed10c6fc1b573bdb1" translate="yes" xml:space="preserve">
          <source>You might get slightly different results with the solver liblinear than with the others since this uses LIBLINEAR which penalizes the intercept.</source>
          <target state="translated">このソルバーは切片にペナルティを与えるLIBLINEARを使用しているので、他のソルバーとは少し異なる結果が得られるかもしれません。</target>
        </trans-unit>
        <trans-unit id="eacc5e93bbce61c3d762f60af9c0b85d6ab90006" translate="yes" xml:space="preserve">
          <source>You might have noticed that the samples were shuffled randomly when we called &lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt;: this is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later.</source>
          <target state="translated">&lt;code&gt;fetch_20newsgroups(..., shuffle=True, random_state=42)&lt;/code&gt; を呼び出したときに、サンプルがランダムにシャッフルされていることに気づいたかもしれません。これは、サンプルのサブセットのみを選択してモデルをすばやくトレーニングし、最初に取得する場合に便利です後で完全なデータセットを再トレーニングする前の結果のアイデア。</target>
        </trans-unit>
        <trans-unit id="c8c03561e45bae9c49c8b8f096417e119a986f38" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;fit&lt;/a&gt; and &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">あなただけのコールに持ち&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-fit&quot;&gt;合う&lt;/a&gt;と&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;予測&lt;/a&gt;推定量の全配列に合わせて、あなたのデータに一度。</target>
        </trans-unit>
        <trans-unit id="1c0c1bb33d891f47deca1c516d19aa08bd8443b9" translate="yes" xml:space="preserve">
          <source>You only have to call &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; once on your data to fit a whole sequence of estimators.</source>
          <target state="translated">あなただけのコールに持ち &lt;code&gt;fit&lt;/code&gt; と &lt;code&gt;predict&lt;/code&gt; 推定量の全配列に合わせて、あなたのデータに一度。</target>
        </trans-unit>
        <trans-unit id="8f00f0e599f4c3a7b71dcab47e41c43fc685f526" translate="yes" xml:space="preserve">
          <source>You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is split into &lt;em&gt;we&lt;/em&gt; and &lt;em&gt;ve&lt;/em&gt; by CountVectorizer&amp;rsquo;s default tokenizer, so if &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; is in &lt;code&gt;stop_words&lt;/code&gt;, but &lt;em&gt;ve&lt;/em&gt; is not, &lt;em&gt;ve&lt;/em&gt; will be retained from &lt;em&gt;we&amp;rsquo;ve&lt;/em&gt; in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.</source>
          <target state="translated">また、ストップワードリストに、ベクトライザーで使用されているものと同じ前処理とトークン化が適用されていることを確認する必要があります。言葉&lt;em&gt;私たちがしましたが&lt;/em&gt;に分割され&lt;em&gt;、私たち&lt;/em&gt;と&lt;em&gt;VEの&lt;/em&gt;そうならば、CountVectorizerのデフォルトのトークナイザで&lt;em&gt;私たちはき&lt;/em&gt;ている &lt;code&gt;stop_words&lt;/code&gt; が、&lt;em&gt;VEの&lt;/em&gt;ではない、&lt;em&gt;VEの&lt;/em&gt;から保持されます&lt;em&gt;、我々はしまし&lt;/em&gt;変換テキストで。私たちのベクトライザーは、ある種の矛盾を特定して警告しようとします。</target>
        </trans-unit>
        <trans-unit id="c05eee82bc79ecab0104c0f165ab54dde97d70eb" translate="yes" xml:space="preserve">
          <source>You will find additional details about joblib mitigation of oversubscription in &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblib documentation&lt;/a&gt;.</source>
          <target state="translated">オーバーサブスクリプションのjoblib軽減に関する追加の詳細は、&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-ressources&quot;&gt;joblibドキュメントにあります&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="03e4dbf3891b38cb2bcd04772f91e994b5e9c01b" translate="yes" xml:space="preserve">
          <source>Your dataset consists of heterogeneous data types (e.g. raster images and text captions)</source>
          <target state="translated">あなたのデータセットは、異種データタイプ(ラスタ画像やテキストキャプションなど)で構成されています。</target>
        </trans-unit>
        <trans-unit id="7b0a68e70dc900bed821b4c342a07edfa667e451" translate="yes" xml:space="preserve">
          <source>Your dataset is stored in a Pandas DataFrame and different columns require different processing pipelines.</source>
          <target state="translated">データセットはPandas DataFrameに保存され、列ごとに異なる処理パイプラインが必要です。</target>
        </trans-unit>
        <trans-unit id="cf246e4fd612425ede440737acf49a3220f42916" translate="yes" xml:space="preserve">
          <source>Your kernel must take as arguments two matrices of shape &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt;, &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; and return a kernel matrix of shape &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt;.</source>
          <target state="translated">あなたのカーネルは引数形状の二つの行列として取る必要があります &lt;code&gt;(n_samples_1, n_features)&lt;/code&gt; 、 &lt;code&gt;(n_samples_2, n_features)&lt;/code&gt; と形状のカーネル行列を返す &lt;code&gt;(n_samples_1, n_samples_2)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a97cec9f16597107c699027a6e02cf1c0426b74a" translate="yes" xml:space="preserve">
          <source>ZN proportion of residential land zoned for lots over 25,000 sq.ft.</source>
          <target state="translated">25,000平方フィートを超える土地のために区画整理された住宅地の割合。</target>
        </trans-unit>
        <trans-unit id="712d097b167e76a6e9d59b3e5e274cb4dc4edfe4" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;lsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">ZadroznyおよびElkan、「分類子スコアのマルチクラス確率推定への変換」、SIGKDD'02、&lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http：//www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2a3a7f6ae69d75cdee1953a2daa7e044766fcafc" translate="yes" xml:space="preserve">
          <source>Zadrozny and Elkan, &amp;ldquo;Transforming classifier scores into multiclass probability estimates&amp;rdquo;, SIGKDD&amp;rsquo;02, &lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</source>
          <target state="translated">ZadroznyおよびElkan、「分類子スコアのマルチクラス確率推定への変換」、SIGKDD'02、&lt;a href=&quot;http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&quot;&gt;http：//www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f05a65af97509516c00dcac126500e3f1415b5be" translate="yes" xml:space="preserve">
          <source>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">多項式およびシグモイドカーネルのためのゼロ係数.他のカーネルでは無視されます。</target>
        </trans-unit>
        <trans-unit id="e35caa5ca631cf4323249c1e10ca37b600a29376" translate="yes" xml:space="preserve">
          <source>Zero is the lowest possible score. Values closer to zero indicate a better partition.</source>
          <target state="translated">ゼロは可能な限り低いスコアです。ゼロに近い値は、より良いパーティションを示します。</target>
        </trans-unit>
        <trans-unit id="4196df3003bc4705f3359c145eca39ac9042a13b" translate="yes" xml:space="preserve">
          <source>Zero-one classification loss.</source>
          <target state="translated">ゼロワンの分類損失。</target>
        </trans-unit>
        <trans-unit id="ee137211a128584365e4b492f8f1e31e317a831d" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Zhang、J.およびMarszalek、M.およびLazebnik、S.およびSchmid、C.テクスチャおよびオブジェクトカテゴリの分類のためのローカル機能およびカーネル：包括的な研究International Journal of Computer Vision 2007 &lt;a href=&quot;http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;http://research.microsoft.com/ en-us / um / people / manik / projects / trade-off / papers / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="78f8c38e7e05f7b4f27cc97ecbaeea34135ce110" translate="yes" xml:space="preserve">
          <source>Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&lt;/a&gt;</source>
          <target state="translated">Zhang、J。とMarszalek、M。とLazebnik、S。とSchmid、C。テクスチャとオブジェクトカテゴリの分類のためのローカル機能とカーネル：包括的な調査International Journal of Computer Vision 2007 &lt;a href=&quot;https://research.microsoft.com/en-us/um/people/manik/projects/trade-off/papers/ZhangIJCV06.pdf&quot;&gt;https://research.microsoft.com/ en-us / um / people / manik / projects / trade-off / papers / ZhangIJCV06.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0c6fefb0786b59f4ca28434a9adf73a14f912b16" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</source>
          <target state="translated">Zhang、Z。＆Wang、J。MLLE：複数の重みを使用して修正されたローカル線形埋め込み。&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e40887e48b748aeda9c07d81d6206e919ed1f726" translate="yes" xml:space="preserve">
          <source>Zhang, Z. &amp;amp; Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)</source>
          <target state="translated">Zhang、Z。＆Zha、H。主多様体と接空間整列による非線形次元削減。上海大学ジャーナル 8：406（2004）</target>
        </trans-unit>
        <trans-unit id="2f2ef1b5180fd57b17245a5c505519733d35270d" translate="yes" xml:space="preserve">
          <source>Zhu, H. Zou, S. Rosset, T. Hastie, &amp;ldquo;Multi-class AdaBoost&amp;rdquo;, 2009.</source>
          <target state="translated">Zhu、H。Zou、S。Rosset、T。Hastie、「Multi-class AdaBoost」、2009年。</target>
        </trans-unit>
        <trans-unit id="8ce45cc584babf565a133f667c041638840fdfd3" translate="yes" xml:space="preserve">
          <source>Zoubir A., Koivunen V., Chakhchoukh Y. and Muma M. (2012). Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts. IEEE Signal Processing Magazine 29(4), 61-80.</source>
          <target state="translated">Zoubir A.,Koivunen V.,Chakhchoukh Y.and Muma M.(2012).信号処理におけるロバスト推定。基本的な概念をチュートリアル形式で解説しています。IEEE Signal Processing Magazine 29(4),61-80.</target>
        </trans-unit>
        <trans-unit id="e2b89a96fcf50192e8235c2260c291f63c7f4fa9" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;additive_chi2&amp;rsquo;, &amp;lsquo;chi2&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;laplacian&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['additive_chi2'、 'chi2'、 'linear'、 'poly'、 'polynomial'、 'rbf'、 'laplacian'、 'sigmoid'、 'cosine']</target>
        </trans-unit>
        <trans-unit id="cd3417b4282b09dc45879fe7c77bee8859983780" translate="yes" xml:space="preserve">
          <source>[&amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;polynomial&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;]</source>
          <target state="translated">['rbf'、 'sigmoid'、 'polynomial'、 'poly'、 'linear'、 'cosine']</target>
        </trans-unit>
        <trans-unit id="7c0453b88eaf6a5b1a0ac2faa1dec6c20e0dda6a" translate="yes" xml:space="preserve">
          <source>[1, x_2, x_2 ** 2, x_2 ** 3, &amp;hellip;], &amp;hellip;]</source>
          <target state="translated">[1、x_2、x_2 ** 2、x_2 ** 3、&amp;hellip;]、&amp;hellip;]</target>
        </trans-unit>
        <trans-unit id="af237073ca841ce40d3b1c3f9ec3b84ba9e8c1ce" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Online Learning for Latent Dirichlet Allocation&amp;rdquo;, Matthew D. Hoffman,</source>
          <target state="translated">[1]「潜在的ディリクレ配分のオンライン学習」、マシューD.ホフマン、</target>
        </trans-unit>
        <trans-unit id="a5828c16246e11e0eda2596d27fdd402ee57d009" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Shrinkage Algorithms for MMSE Covariance Estimation&amp;rdquo; Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</source>
          <target state="translated">[1]「MMSE共分散推定のための収縮アルゴリズム」Chen et al。、IEEE Trans。サインオン。Proc。、Volume 58、Issue 10、2010年10月。</target>
        </trans-unit>
        <trans-unit id="c5ae55965c66d78c700f954c5d28c9832964e702" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] A. RahimiおよびBenjamin Rechtによる「ランダムキッチンシンクの加重和：学習における最小化からランダム化への置き換え」。（&lt;a href=&quot;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;http://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="4bdc516c4c0b901726d527e6df8200cdc4a8acc8" translate="yes" xml:space="preserve">
          <source>[1] &amp;ldquo;Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning&amp;rdquo; by A. Rahimi and Benjamin Recht. (&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;)</source>
          <target state="translated">[1] A.RahimiとBenjaminRechtによる「ランダムキッチンシンクの加重和：学習における最小化のランダム化への置き換え」。（&lt;a href=&quot;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&quot;&gt;https://people.eecs.berkeley.edu/~brecht/papers/08.rah.rec.nips.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="066cf0134c1716b5ce53bcaba6c6b8d7e86263f5" translate="yes" xml:space="preserve">
          <source>[1] Hastie, T., Tibshirani, R.,, Friedman, J. (2001). Model Assessment and Selection. The Elements of Statistical Learning (pp. 219-260). New York, NY, USA: Springer New York Inc..</source>
          <target state="translated">[1] Hastie、T.、Tibshirani、R.、Friedman、J。（2001）。モデルの評価と選択。統計的学習の要素（pp.219-260）。米国ニューヨーク州ニューヨーク：Springer New YorkInc.。</target>
        </trans-unit>
        <trans-unit id="851ede0920efe80a8308115ddfdc22058d99b224" translate="yes" xml:space="preserve">
          <source>[1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for</source>
          <target state="translated">[1] Hinton、GE、Osindero、S。およびTeh、Y。高速学習アルゴリズム</target>
        </trans-unit>
        <trans-unit id="3208128766e3298f0714b3eacb4e2ecfc88475e9" translate="yes" xml:space="preserve">
          <source>[1] L. Breiman, &amp;ldquo;Random Forests&amp;rdquo;, Machine Learning, 45(1), 5-32,</source>
          <target state="translated">[1] L. Breiman、「ランダムフォレスト」、機械学習、45（1）、5-32、</target>
        </trans-unit>
        <trans-unit id="c4ab6918e1971671fbb440a7f8e61bfcc4315791" translate="yes" xml:space="preserve">
          <source>[1] P. J. Rousseeuw. Least median of squares regression. J. Am</source>
          <target state="translated">[1] PJ Rousseeuw。最小二乗回帰の中央値。混雑する</target>
        </trans-unit>
        <trans-unit id="4becf43125cdaf0ec29f63ac1f954b679ab8e6bc" translate="yes" xml:space="preserve">
          <source>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</source>
          <target state="translated">[1]ヨシュアベンジオ、オリビエデラロー、ニコラスルルー。半教師あり学習（2006）、pp。193-216</target>
        </trans-unit>
        <trans-unit id="9a201577697a06c9ac689a946ae70d44d48c0e7c" translate="yes" xml:space="preserve">
          <source>[1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data</source>
          <target state="translated">[1]ファンデルマーテン、LJP; ヒントン、GE、高次元データの可視化</target>
        </trans-unit>
        <trans-unit id="8eeff125eef3cfca1ff3f8b3157054b95e0b3509" translate="yes" xml:space="preserve">
          <source>[2] &amp;ldquo;Stochastic Variational Inference&amp;rdquo;, Matthew D. Hoffman, David M. Blei,</source>
          <target state="translated">[2]「確率的変分推論」、Matthew D. Hoffman、David M. Blei、</target>
        </trans-unit>
        <trans-unit id="ea3c887d7b7624a41f686043b166f388d3617ff3" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2] Olivier Delalleau、Yoshua Bengio、Nicolas Le Roux。半教師あり学習における効率的なノンパラメトリック関数の誘導。AISTAT 2005 &lt;a href=&quot;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73434047889c8334ffffe648547654fa2862e107" translate="yes" xml:space="preserve">
          <source>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</source>
          <target state="translated">[2]オリヴィエ・デラロー、ヨシュア・ベンジオ、ニコラス・ル・ルー。半教師あり学習における効率的なノンパラメトリック関数の帰納。AISTAT 2005 &lt;a href=&quot;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&quot;&gt;https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="390f7912993134abee39b500fe8ff987c558bcc7" translate="yes" xml:space="preserve">
          <source>[2] Tieleman, T. Training Restricted Boltzmann Machines using</source>
          <target state="translated">[2] Tieleman、T。を使用して制限付きボルツマンマシンをトレーニング</target>
        </trans-unit>
        <trans-unit id="936e8131576c3002ff436671f77d81f6c95e71d7" translate="yes" xml:space="preserve">
          <source>[2] Wilson, E. B., &amp;amp; Hilferty, M. M. (1931). The distribution of chi-square.</source>
          <target state="translated">[2] Wilson、EB、＆Hilferty、MM（1931）。カイ二乗の分布。</target>
        </trans-unit>
        <trans-unit id="5cccbf6c7fe7c1f50410b68e37c12f00b67f9330" translate="yes" xml:space="preserve">
          <source>[2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding</source>
          <target state="translated">[2] van der Maaten、LJP t-Distributed Stochastic Neighbor Embedding</target>
        </trans-unit>
        <trans-unit id="740947d1c8302c56dc8a9209234aab173f75acad" translate="yes" xml:space="preserve">
          <source>[3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.</source>
          <target state="translated">[3] LJPファンデルマーテン。ツリーベースのアルゴリズムを使用したt-SNEの高速化。</target>
        </trans-unit>
        <trans-unit id="a16dde9090b3c419b1ba6d8027b90785ddf73263" translate="yes" xml:space="preserve">
          <source>[3] Matthew D. Hoffman&amp;rsquo;s onlineldavb code. Link:</source>
          <target state="translated">[3]マシューD.ホフマンのonlineldavbコード。リンク：</target>
        </trans-unit>
        <trans-unit id="2091fb37b7afd77ae2e8e60855d4cad2538ba378" translate="yes" xml:space="preserve">
          <source>[B1996]</source>
          <target state="translated">[B1996]</target>
        </trans-unit>
        <trans-unit id="66fa89cedf249bba6f8bbd7ca59a6edba1eb2520" translate="yes" xml:space="preserve">
          <source>[B1998]</source>
          <target state="translated">[B1998]</target>
        </trans-unit>
        <trans-unit id="7665023d9511c3ea5a7a3e7baca06057eba900d6" translate="yes" xml:space="preserve">
          <source>[B1999]</source>
          <target state="translated">[B1999]</target>
        </trans-unit>
        <trans-unit id="5c075f95c1e65a7e49dec5ad30ee36d1fb13b2b6" translate="yes" xml:space="preserve">
          <source>[B2001]</source>
          <target state="translated">[B2001]</target>
        </trans-unit>
        <trans-unit id="04bec92cc809290da2bf608da574e1877293633f" translate="yes" xml:space="preserve">
          <source>[B2011]</source>
          <target state="translated">[B2011]</target>
        </trans-unit>
        <trans-unit id="2b6c9f7f2623b948c281da789073abc37bb7f8fa" translate="yes" xml:space="preserve">
          <source>[ButlerDavies]</source>
          <target state="translated">[ButlerDavies]</target>
        </trans-unit>
        <trans-unit id="1d442f2d1661e89f1bc869a582a8d649d24881e4" translate="yes" xml:space="preserve">
          <source>[D1997]</source>
          <target state="translated">[D1997]</target>
        </trans-unit>
        <trans-unit id="20e70caf2f764d35f0c5f51eb6c2cc52a6f947f2" translate="yes" xml:space="preserve">
          <source>[Davis2006]</source>
          <target state="translated">[Davis2006]</target>
        </trans-unit>
        <trans-unit id="3b0f17e8250c1e7b54512123b77c31bb0899ae7a" translate="yes" xml:space="preserve">
          <source>[Everingham2010]</source>
          <target state="translated">[Everingham2010]</target>
        </trans-unit>
        <trans-unit id="e5ff04dac92d8d5710e2d4ade54a4899d9a01662" translate="yes" xml:space="preserve">
          <source>[F1999]</source>
          <target state="translated">[F1999]</target>
        </trans-unit>
        <trans-unit id="ddfaba8b68f822d387eefcc49dbcf89bee83fcbe" translate="yes" xml:space="preserve">
          <source>[F2001]</source>
          <target state="translated">[F2001]</target>
        </trans-unit>
        <trans-unit id="5712ff07224dea2f09976ad1b5f9060cea098ee8" translate="yes" xml:space="preserve">
          <source>[FS1995]</source>
          <target state="translated">[FS1995]</target>
        </trans-unit>
        <trans-unit id="111b120f6e2f3a7d9723c16133fcfb1ce7b7557b" translate="yes" xml:space="preserve">
          <source>[Flach2015]</source>
          <target state="translated">[Flach2015]</target>
        </trans-unit>
        <trans-unit id="0be1b91bf292e6f295e73f8ba1626aa315ca1709" translate="yes" xml:space="preserve">
          <source>[Guyon2015]</source>
          <target state="translated">[Guyon2015]</target>
        </trans-unit>
        <trans-unit id="16deff704a4f867ca18d98b22e63afcb70ec96d2" translate="yes" xml:space="preserve">
          <source>[H1998]</source>
          <target state="translated">[H1998]</target>
        </trans-unit>
        <trans-unit id="346ddc10d1a23f1ff0ba05ea1da881f4666595c5" translate="yes" xml:space="preserve">
          <source>[HTF2009]</source>
          <target state="translated">[HTF2009]</target>
        </trans-unit>
        <trans-unit id="2b6bce181ae06e6796d39628b4dc12ca65767e20" translate="yes" xml:space="preserve">
          <source>[HTF]</source>
          <target state="translated">[HTF]</target>
        </trans-unit>
        <trans-unit id="8f4756ba18c793a637ad7568fd4450479f47b718" translate="yes" xml:space="preserve">
          <source>[Hubert1985]</source>
          <target state="translated">[Hubert1985]</target>
        </trans-unit>
        <trans-unit id="1c2acae56920363d695dc395b30aa0dac0656aa7" translate="yes" xml:space="preserve">
          <source>[Jen09]</source>
          <target state="translated">[Jen09]</target>
        </trans-unit>
        <trans-unit id="52833f723be6af6645b6622da4d471b65e89d942" translate="yes" xml:space="preserve">
          <source>[Kelleher2015]</source>
          <target state="translated">[Kelleher2015]</target>
        </trans-unit>
        <trans-unit id="8d63f432cd9715591fb04662784fbed01426124f" translate="yes" xml:space="preserve">
          <source>[L2014]</source>
          <target state="translated">[L2014]</target>
        </trans-unit>
        <trans-unit id="e6f810474b9d9bf1966e66d024bfd2d0d9af7983" translate="yes" xml:space="preserve">
          <source>[LG2012]</source>
          <target state="translated">[LG2012]</target>
        </trans-unit>
        <trans-unit id="4108a351bec333bc41371d8be81bbf1f0bd216a0" translate="yes" xml:space="preserve">
          <source>[LS2010]</source>
          <target state="translated">[LS2010]</target>
        </trans-unit>
        <trans-unit id="36c1f9470816b8da81a8ed80471ace8df2456c31" translate="yes" xml:space="preserve">
          <source>[M2012]</source>
          <target state="translated">[M2012]</target>
        </trans-unit>
        <trans-unit id="536dc6f43e65eedbc7dcd92d64ef850b0a7951d3" translate="yes" xml:space="preserve">
          <source>[MRS2008]</source>
          <target state="translated">[MRS2008]</target>
        </trans-unit>
        <trans-unit id="350f14f810397ce0cd7520f35f0fae7d54d72023" translate="yes" xml:space="preserve">
          <source>[Manning2008]</source>
          <target state="translated">[Manning2008]</target>
        </trans-unit>
        <trans-unit id="0cc214a1564fbbf90b4daa0b0972b6f8408e3afc" translate="yes" xml:space="preserve">
          <source>[Mosley2013]</source>
          <target state="translated">[Mosley2013]</target>
        </trans-unit>
        <trans-unit id="73be0b37b87d3c88f49438b3a7ca251dc3d3c1d2" translate="yes" xml:space="preserve">
          <source>[Mrl09]</source>
          <target state="translated">[Mrl09]</target>
        </trans-unit>
        <trans-unit id="690e639d5d468ec30ab9e54cb03287a1d07d286f" translate="yes" xml:space="preserve">
          <source>[NQY18]</source>
          <target state="translated">[NQY18]</target>
        </trans-unit>
        <trans-unit id="95849b59dfe0de62fa4f930bc19ca3b64ad51c5b" translate="yes" xml:space="preserve">
          <source>[R2007]</source>
          <target state="translated">[R2007]</target>
        </trans-unit>
        <trans-unit id="d27f89b25dd2806ef3b69d37ac341ea761b1f775" translate="yes" xml:space="preserve">
          <source>[RR2007]</source>
          <target state="translated">[RR2007]</target>
        </trans-unit>
        <trans-unit id="99aae3a9e5135b3c3c9e6f81c5583f53ea54b161" translate="yes" xml:space="preserve">
          <source>[RVD]</source>
          <target state="translated">[RVD]</target>
        </trans-unit>
        <trans-unit id="7fc4fd0834c6c78f63966f47416f1e672a05b032" translate="yes" xml:space="preserve">
          <source>[RVDriessen]</source>
          <target state="translated">[RVDriessen]</target>
        </trans-unit>
        <trans-unit id="9a3d290ec7e0cf466e2e530b732c430fd93742e5" translate="yes" xml:space="preserve">
          <source>[RW2006]</source>
          <target state="translated">[RW2006]</target>
        </trans-unit>
        <trans-unit id="ab40883d6ce3b576febad86ad20a220ae60fc722" translate="yes" xml:space="preserve">
          <source>[Rouseeuw1984]</source>
          <target state="translated">[Rouseeuw1984]</target>
        </trans-unit>
        <trans-unit id="f4ff5aad65e1461e94ef70a659337011d0c58126" translate="yes" xml:space="preserve">
          <source>[Rousseeuw]</source>
          <target state="translated">[Rousseeuw]</target>
        </trans-unit>
        <trans-unit id="74f2d2c5b044f5dc96afc1e0482d2495c57d5370" translate="yes" xml:space="preserve">
          <source>[Urbanowicz2015]</source>
          <target state="translated">[Urbanowicz2015]</target>
        </trans-unit>
        <trans-unit id="34cb3f1593778c84c25ed6665ee9a323140a68d9" translate="yes" xml:space="preserve">
          <source>[VEB2009] Vinh, Epps, and Bailey, (2009). &amp;ldquo;Information theoretic measures for clusterings comparison&amp;rdquo;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &amp;lsquo;09. &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi:10.1145/1553374.1553511&lt;/a&gt;. ISBN 9781605585161.</source>
          <target state="translated">[VEB2009] Vinh、Epps、およびBailey、（2009）。「クラスタリング比較のための情報理論的測度」。第26回機械学習に関する年次国際会議の議事録-ICML '09。&lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=1553374.1553511&quot;&gt;doi：10.1145 / 1553374.1553511&lt;/a&gt;。ISBN 9781605585161。</target>
        </trans-unit>
        <trans-unit id="48a5d15f42b24744d500812bf01a83ad55ecae83" translate="yes" xml:space="preserve">
          <source>[VEB2010] Vinh, Epps, and Bailey, (2010). &amp;ldquo;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&amp;rdquo;. JMLR &amp;lt;&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt;&amp;gt;</source>
          <target state="translated">[VEB2010] Vinh、Epps、およびBailey、（2010）。「クラスタリング比較のための情報理論的測度：変種、特性、正規化、およびチャンスの修正」。JMLR &amp;lt; &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&quot;&gt;http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf&lt;/a&gt; &amp;gt;</target>
        </trans-unit>
        <trans-unit id="0cb878c6eb08bc32d947d6ddc4baaa42377cefd9" translate="yes" xml:space="preserve">
          <source>[VVZ2010]</source>
          <target state="translated">[VVZ2010]</target>
        </trans-unit>
        <trans-unit id="3db6db2379703ce194c034f1bb123b847f702832" translate="yes" xml:space="preserve">
          <source>[VZ2010]</source>
          <target state="translated">[VZ2010]</target>
        </trans-unit>
        <trans-unit id="4f385f25921c7c64a43d9b5e0a8904686fbad4ed" translate="yes" xml:space="preserve">
          <source>[X1, y1, &amp;hellip;, Xn, yn]</source>
          <target state="translated">[X1, y1, &amp;hellip;, Xn, yn]</target>
        </trans-unit>
        <trans-unit id="70b15e6dab0cb6917fd158eac29a9ddf08fcef21" translate="yes" xml:space="preserve">
          <source>[YAT2016] Yang, Algesheimer, and Tessone, (2016). &amp;ldquo;A comparative analysis of community detection algorithms on artificial networks&amp;rdquo;. Scientific Reports 6: 30750. &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;doi:10.1038/srep30750&lt;/a&gt;.</source>
          <target state="translated">[YAT2016] Yang、Algesheimer、およびTessone、（2016）。「人工ネットワーク上のコミュニティ検出アルゴリズムの比較分析」。科学レポート6：30750。doi &lt;a href=&quot;https://www.nature.com/articles/srep30750&quot;&gt;：10.1038 / srep30750&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="652e235b7dc2f3d75c7f909152b3819c6c97a6ec" translate="yes" xml:space="preserve">
          <source>[Yates2011]</source>
          <target state="translated">[Yates2011]</target>
        </trans-unit>
        <trans-unit id="e3b9ec6790a1b2a9d7bcca67037f67b282ccc4ee" translate="yes" xml:space="preserve">
          <source>[ZZRH2009]</source>
          <target state="translated">[ZZRH2009]</target>
        </trans-unit>
        <trans-unit id="96b76160e0ad993ba5f0d18a67c96f386933b35a" translate="yes" xml:space="preserve">
          <source>[[1, x_1, x_1 ** 2, x_1 ** 3, &amp;hellip;],</source>
          <target state="translated">[[1、x_1、x_1 ** 2、x_1 ** 3、&amp;hellip;]、</target>
        </trans-unit>
        <trans-unit id="2eab98aedd6e4787cc1b6ed7c5288a5a2279237c" translate="yes" xml:space="preserve">
          <source>[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.</source>
          <target state="translated">[呼び出し可能]：距離の配列を受け入れ、重みを含む同じ形状の配列を返すユーザー定義関数。</target>
        </trans-unit>
        <trans-unit id="b622702bcf4592f09f68d731f0a4b9f486da53eb" translate="yes" xml:space="preserve">
          <source>[n_samples_a, n_features] otherwise Array of pairwise distances between samples, or a feature array.</source>
          <target state="translated">[n_samples_a、n_features]それ以外の場合は、サンプル間のペアワイズ距離の配列、または特徴配列。</target>
        </trans-unit>
        <trans-unit id="361169bda90a02e4e54f39ff838115b39a75d83d" translate="yes" xml:space="preserve">
          <source>[wk]</source>
          <target state="translated">[wk]</target>
        </trans-unit>
        <trans-unit id="a4fcb5a87f4e322ea14fa74b5213a00a6d8c1551" translate="yes" xml:space="preserve">
          <source>\((y-\hat{y})^2\)</source>
          <target state="translated">\((y-\hat{y})^2\)</target>
        </trans-unit>
        <trans-unit id="b66b6613ed1a2db616d592d66bc160b7abcc7139" translate="yes" xml:space="preserve">
          <source>\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</source>
          <target state="translated">\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)</target>
        </trans-unit>
        <trans-unit id="764bb49b144ee69e8d51ad0d7a5cedd15acf75d9" translate="yes" xml:space="preserve">
          <source>\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</source>
          <target state="translated">\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)</target>
        </trans-unit>
        <trans-unit id="cade30b6baa03b8bc431f6cb3586bc5b1d642a6f" translate="yes" xml:space="preserve">
          <source>\(C\) is used to set the amount of regularization</source>
          <target state="translated">\（C \）は、正則化の量を設定するために使用されます</target>
        </trans-unit>
        <trans-unit id="ad93e4d23ea1b4d81a2b3f3c3d29dff7d49b5d27" translate="yes" xml:space="preserve">
          <source>\(D\) : input dimension</source>
          <target state="translated">\（D \）：入力次元</target>
        </trans-unit>
        <trans-unit id="a32e93d880aaba8a860e59edd1cb39f288e59537" translate="yes" xml:space="preserve">
          <source>\(F1 = 2\frac{P \times R}{P+R}\)</source>
          <target state="translated">\（F1 = 2 \ frac {P \ times R} {P + R} \）</target>
        </trans-unit>
        <trans-unit id="6e8b3587e80a2131c2360cdeb81572614017e523" translate="yes" xml:space="preserve">
          <source>\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</source>
          <target state="translated">\（F_ \ beta（A、B）：= \ left（1 + \ beta ^ 2 \ right）\ frac {P（A、B）\ times R（A、B）} {\ beta ^ 2 P（A 、B）+ R（A、B）} \）</target>
        </trans-unit>
        <trans-unit id="9a350d9475f7eafeffa8a9835bca28d431bee93e" translate="yes" xml:space="preserve">
          <source>\(F_\beta(y, \hat{y})\)</source>
          <target state="translated">\（F_ \ beta（y、\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="09eb5f139bd0c207766706ffe3b5d171a556d4ec" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - \frac{x^2}{h^2}\)</source>
          <target state="translated">\（K（x; h）\ propto 1-\ frac {x ^ 2} {h ^ 2} \）</target>
        </trans-unit>
        <trans-unit id="95dfc8e81899d8cb940cb0df0bfaa1052ffb36d2" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1 - x/h\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto 1-x / h \）\（x &amp;lt;h \）の場合</target>
        </trans-unit>
        <trans-unit id="2a910118bdbf495d82747952ba6971367b93dfac" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto 1\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto 1 \）\（x &amp;lt;h \）の場合</target>
        </trans-unit>
        <trans-unit id="4b298d5bd2fdf7182db10bf076925db3745527a8" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \cos(\frac{\pi x}{2h})\) if \(x &amp;lt; h\)</source>
          <target state="translated">\（K（x; h）\ propto \ cos（\ frac {\ pi x} {2h}）\）\（x &amp;lt;h \）の場合</target>
        </trans-unit>
        <trans-unit id="a4443829e2c48ab72daedb9b74f9dc8debc9681a" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(- \frac{x^2}{2h^2} )\)</source>
          <target state="translated">\（K（x; h）\ propto \ exp（-\ frac {x ^ 2} {2h ^ 2}）\）</target>
        </trans-unit>
        <trans-unit id="c70853c06adf6986de8dcbc5a8f801fc0502ae1b" translate="yes" xml:space="preserve">
          <source>\(K(x; h) \propto \exp(-x/h)\)</source>
          <target state="translated">\（K（x; h）\ propto \ exp（-x / h）\）</target>
        </trans-unit>
        <trans-unit id="7d9776eac061dd7f197e8155c6784a047082de92" translate="yes" xml:space="preserve">
          <source>\(L\) the set of labels</source>
          <target state="translated">\（L \）ラベルのセット</target>
        </trans-unit>
        <trans-unit id="f0f78908f9cef66c5c39e39b004aba794a24d223" translate="yes" xml:space="preserve">
          <source>\(N\) : number of training data points</source>
          <target state="translated">\（N \）：トレーニングデータポイントの数</target>
        </trans-unit>
        <trans-unit id="85d811223bbd2564d928a5184adabae9693a9903" translate="yes" xml:space="preserve">
          <source>\(P = \frac{T_p}{T_p+F_p}\)</source>
          <target state="translated">\（P = \ frac {T_p} {T_p + F_p} \）</target>
        </trans-unit>
        <trans-unit id="5c7b5d8ee367861eab9617a9df8debede099fe4a" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</source>
          <target state="translated">\（P（A、B）：= \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \）</target>
        </trans-unit>
        <trans-unit id="b2e10949fc710189ed8a464185eb0fbad995ab8d" translate="yes" xml:space="preserve">
          <source>\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\) for some sets \(A\) and \(B\)</source>
          <target state="translated">\（P（A、B）：= \ frac {\ left | A \ cap B \ right |} {\ left | A \ right |} \）一部のセット\（A \）および\（B \）</target>
        </trans-unit>
        <trans-unit id="c180cdb6205e02ec243b8a0c392cb71991d0a3d0" translate="yes" xml:space="preserve">
          <source>\(P(y, \hat{y})\)</source>
          <target state="translated">\（P（y、\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="c753c8fc287915fbc16c3d512099716031e38eb4" translate="yes" xml:space="preserve">
          <source>\(R = \frac{T_p}{T_p + F_n}\)</source>
          <target state="translated">\（R = \ frac {T_p} {T_p + F_n} \）</target>
        </trans-unit>
        <trans-unit id="2d1e6161821a7c78dd1e8cc86ac7329f67bfcf0c" translate="yes" xml:space="preserve">
          <source>\(R(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\) (Conventions vary on handling \(B = \emptyset\); this implementation uses \(R(A, B):=0\), and similar for \(P\).)</source>
          <target state="translated">\（R（A、B）：= \ frac {\ left | A \ cap B \ right |} {\ left | B \ right |} \）（慣例は取り扱いによって異なります\（B = \ emptyset \）; this実装は\（R（A、B）：= 0 \）を使用し、\（P \）も同様です。）</target>
        </trans-unit>
        <trans-unit id="76e12b53dc747a452508648de37b3bbf1292886a" translate="yes" xml:space="preserve">
          <source>\(R(y, \hat{y})\)</source>
          <target state="translated">\（R（y、\ hat {y}）\）</target>
        </trans-unit>
        <trans-unit id="fe30e7d28d145393d116de8ccfdb95f1930cc647" translate="yes" xml:space="preserve">
          <source>\(S\) the set of samples</source>
          <target state="translated">\（S \）サンプルのセット</target>
        </trans-unit>
        <trans-unit id="4d975b6c5632f1c81d6cf8cc9f674c8e0d143548" translate="yes" xml:space="preserve">
          <source>\(X\): data</source>
          <target state="translated">\（X \）：データ</target>
        </trans-unit>
        <trans-unit id="59b5b0f07758a431bbb7dbf6ebe63bc98b0cd7dd" translate="yes" xml:space="preserve">
          <source>\(\Omega\) is a &lt;code&gt;penalty&lt;/code&gt; function of our model parameters</source>
          <target state="translated">\（\ Omega \）は、モデルパラメータの &lt;code&gt;penalty&lt;/code&gt; 関数です</target>
        </trans-unit>
        <trans-unit id="d82693345c0acee22512b8f82f5807d2eafe4d72" translate="yes" xml:space="preserve">
          <source>\(\Psi = \mathrm{diag}(\psi_1, \psi_2, \dots, \psi_n)\): This model is called &lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt;&lt;code&gt;FactorAnalysis&lt;/code&gt;&lt;/a&gt;, a classical statistical model. The matrix W is sometimes called the &amp;ldquo;factor loading matrix&amp;rdquo;.</source>
          <target state="translated">\（\ Psi = \ mathrm {diag}（\ psi_1、\ psi_2、\ dots、\ psi_n）\）：このモデルは、古典的な統計モデルである&lt;a href=&quot;generated/sklearn.decomposition.factoranalysis#sklearn.decomposition.FactorAnalysis&quot;&gt; &lt;code&gt;FactorAnalysis&lt;/code&gt; &lt;/a&gt;と呼ばれます。行列Wは、「因子負荷行列」と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="fbd9ea497a59df8b22d9aee98766b15298f6f7b0" translate="yes" xml:space="preserve">
          <source>\(\Psi = \sigma^2 \mathbf{I}\): This assumption leads to the probabilistic model of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">\（\ Psi = \ sigma ^ 2 \ mathbf {I} \）：この仮定により、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; の&lt;/a&gt;確率モデルが導かれます。</target>
        </trans-unit>
        <trans-unit id="01f8f0e3a7f60922aad934db70b43f4626579a4f" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,1}\)</source>
          <target state="translated">\(\alpha^{0}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="51f4c7f6d4e230692f7f7ca95d3a951f2ccb6900" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{0,2}\)</source>
          <target state="translated">\(\alpha^{0}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="fc59eea930c0650810949c61616237e10d7608e7" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,0}\)</source>
          <target state="translated">\(\alpha^{0}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="b7a1987ec2f1ae255445b9203ba76dab46f8180e" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{1,2}\)</source>
          <target state="translated">\(\alpha^{0}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="ddda7bd4dda2cccb6220d08cd96b97d2564703fc" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,0}\)</source>
          <target state="translated">\(\alpha^{0}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="cd76d3a6ac27cf4608fdba8c1bcefea98e40a082" translate="yes" xml:space="preserve">
          <source>\(\alpha^{0}_{2,1}\)</source>
          <target state="translated">\(\alpha^{0}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="670a0c506ecd80ad22241edc90899b4ca5a65063" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,1}\)</source>
          <target state="translated">\(\alpha^{1}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="715b85177f34a3aec41f1d6aca5ea943c045452d" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{0,2}\)</source>
          <target state="translated">\(\alpha^{1}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="9bafd2e8e2343917301e41ef344db246b60c40d3" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,0}\)</source>
          <target state="translated">\(\alpha^{1}_{1,0}\)</target>
        </trans-unit>
        <trans-unit id="bd6409137f75a05bb280bc5000840c3e16f9d850" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{1,2}\)</source>
          <target state="translated">\(\alpha^{1}_{1,2}\)</target>
        </trans-unit>
        <trans-unit id="e31f66e6ca63dbde84a383e5d61ebb97f39d2fa6" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,0}\)</source>
          <target state="translated">\(\alpha^{1}_{2,0}\)</target>
        </trans-unit>
        <trans-unit id="603e33877eb24d9878fa7efb61a9c926fb80dd71" translate="yes" xml:space="preserve">
          <source>\(\alpha^{1}_{2,1}\)</source>
          <target state="translated">\(\alpha^{1}_{2,1}\)</target>
        </trans-unit>
        <trans-unit id="9ffe8c9fb6dee2771ab0ca39575e1df479c8a1ca" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,1}\)</source>
          <target state="translated">\(\alpha^{2}_{0,1}\)</target>
        </trans-unit>
        <trans-unit id="7f0fc3efbc7900034a8626635972b65d78e7a257" translate="yes" xml:space="preserve">
          <source>\(\alpha^{2}_{0,2}\)</source>
          <target state="translated">\(\alpha^{2}_{0,2}\)</target>
        </trans-unit>
        <trans-unit id="69166f5380836f7b04cceea34acce5263efbceff" translate="yes" xml:space="preserve">
          <source>\(\beta\): Coefficients</source>
          <target state="translated">\（\ beta \）：係数</target>
        </trans-unit>
        <trans-unit id="fec074bbf7d22c3b3d841bc5e89270a0a2f32779" translate="yes" xml:space="preserve">
          <source>\(\epsilon\): Observation noise</source>
          <target state="translated">\（\ epsilon \）：観測ノイズ</target>
        </trans-unit>
        <trans-unit id="12791ef36495d018e1daf82140fd4c3db8180c28" translate="yes" xml:space="preserve">
          <source>\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</source>
          <target state="translated">\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)</target>
        </trans-unit>
        <trans-unit id="08cc56772d86f4dfece03ec8003aba4f776d2aab" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} F_ \ beta（y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="8c4693b66d3ba7a40d8a9abfe000616818f55aaf" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} P（y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="52e6ce52e9b8ae2877c124e769de40084f5638d9" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ left | L \ right |} \ sum_ {l \ in L} R（y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="7f2d1bc16a43e60170cc4d3e4429f1eaefb3b9b2" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} F_ \ beta（y_s、\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="301209259a59426be923af21027651f698a1adbb" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} P（y_s、\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="76d3b6c7bb7266c85c29df970c85d63d00762934" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)</source>
          <target state="translated">\（\ frac {1} {\ left | S \ right |} \ sum_ {s \ in S} R（y_s、\ hat {y} _s）\）</target>
        </trans-unit>
        <trans-unit id="771a76dcfeccc7d1c5c81729270313804a1579cd" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| F_\beta(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | F_ \ beta（y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="8c17ed8e7ab856a74c9c5ce2466ffe22f7bfd45b" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| P(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | P （y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="084995f248284e6186e09f61b6402476e717eb20" translate="yes" xml:space="preserve">
          <source>\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| R(y_l, \hat{y}_l)\)</source>
          <target state="translated">\（\ frac {1} {\ sum_ {l \ in L} \ left | \ hat {y} _l \ right |} \ sum_ {l \ in L} \ left | \ hat {y} _l \ right | R （y_l、\ hat {y} _l）\）</target>
        </trans-unit>
        <trans-unit id="6e89e30113ce1a3053ff34b9257e3d282abe2f88" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 1.8473]}{\sqrt{\big(3^2 + 0^2 + 1.8473^2\big)}} = [0.8515, 0, 0.5243]\):</source>
          <target state="translated">\（\ frac {[3、0、1.8473]} {\ sqrt {\ big（3 ^ 2 + 0 ^ 2 + 1.8473 ^ 2 \ big）}} = [0.8515、0、0.5243] \）：</target>
        </trans-unit>
        <trans-unit id="673551b6d125b3cd94d7674f49f994c6afdd6f65" translate="yes" xml:space="preserve">
          <source>\(\frac{[3, 0, 2.0986]}{\sqrt{\big(3^2 + 0^2 + 2.0986^2\big)}} = [ 0.819, 0, 0.573].\)</source>
          <target state="translated">\（\ frac {[3、0、2.0986]} {\ sqrt {\ big（3 ^ 2 + 0 ^ 2 + 2.0986 ^ 2 \ big）}} = [0.819、0、0.573]。\）</target>
        </trans-unit>
        <trans-unit id="1a5082b9d05f10e66dae95fed7849c72d0a8cfc1" translate="yes" xml:space="preserve">
          <source>\(\gamma\) is known as slope</source>
          <target state="translated">\（\ gamma \）はスロープとして知られています</target>
        </trans-unit>
        <trans-unit id="126898e7757cd77e4cefb87e42f683763bf54571" translate="yes" xml:space="preserve">
          <source>\(\hat{y}\) the set of &lt;em&gt;true&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\（\ hat {y} \）&lt;em&gt;真の&lt;/em&gt; \（（sample、label）\）ペアのセット</target>
        </trans-unit>
        <trans-unit id="9f39f60cd1f2428420af5f2dec2780245432c521" translate="yes" xml:space="preserve">
          <source>\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle F_ \ beta（y_l、\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="f3dc3b8f8243a37f6cfc63694bfee10bbc8dbb16" translate="yes" xml:space="preserve">
          <source>\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle P（y_l、\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="1c6337bdf58558dfa45a337181a8da415d8b489c" translate="yes" xml:space="preserve">
          <source>\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)</source>
          <target state="translated">\（\ langle R（y_l、\ hat {y} _l）| l \ in L \ rangle \）</target>
        </trans-unit>
        <trans-unit id="825ca6208fb0c99a89fb31d3479b162477b3c1b6" translate="yes" xml:space="preserve">
          <source>\(\mathcal{L}\) is a &lt;code&gt;loss&lt;/code&gt; function of our samples and our model parameters.</source>
          <target state="translated">\（\ mathcal {L} \）は、サンプルとモデルパラメーターの &lt;code&gt;loss&lt;/code&gt; 関数です。</target>
        </trans-unit>
        <trans-unit id="2a02f90f2b2001d6562373a7ae2a2e1dfb4565e2" translate="yes" xml:space="preserve">
          <source>\(\text{AP} = \sum_n (R_n - R_{n-1}) P_n\)</source>
          <target state="translated">\（\ text {AP} = \ sum_n（R_n-R_ {n-1}）P_n \）</target>
        </trans-unit>
        <trans-unit id="db505c609ecce8b6164765bd7848f3b41ea35f0d" translate="yes" xml:space="preserve">
          <source>\(\text{df}(d, t)_{\text{term1}} = 6\)</source>
          <target state="translated">\（\ text {df}（d、t）_ {\ text {term1}} = 6 \）</target>
        </trans-unit>
        <trans-unit id="e0997db48a8d87bf8ee1c7a8fcaa36916a54e707" translate="yes" xml:space="preserve">
          <source>\(\text{df}(t)_{\text{term1}} = 6\)</source>
          <target state="translated">\(\text{df}(t)_{\text{term1}} = 6\)</target>
        </trans-unit>
        <trans-unit id="3761c41a5e61f125696abaab3d6ab5e6c9467a9a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(d, t)_{\text{term1}} = log \frac{n_d}{\text{df}(d, t)} + 1 = log(1)+1 = 1\)</source>
          <target state="translated">\（\ text {idf}（d、t）_ {\ text {term1}} = log \ frac {n_d} {\ text {df}（d、t）} + 1 = log（1）+1 = 1 \）</target>
        </trans-unit>
        <trans-unit id="aa5a67b1ed0374bd72cf6f0e10b3fe3a74615260" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)</target>
        </trans-unit>
        <trans-unit id="528e4287e895ebbf7910677616d1f6077d104040" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),</target>
        </trans-unit>
        <trans-unit id="61843849cf83ac9cc60022c827bcec315d11ec03" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)</target>
        </trans-unit>
        <trans-unit id="3943a22b1a933b8cec2e621f9da837d0f8e0bccb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</source>
          <target state="translated">\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)</target>
        </trans-unit>
        <trans-unit id="418ed87bb3a9ff83d64cef6c0afed152e2ce9063" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {1 + n_d} {1+ \ text {df}（d、t）}} + 1 \）</target>
        </trans-unit>
        <trans-unit id="cbf2fa82ddd1456d42b5d1023dd8e97cfb8e3a89" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{1 + n_d}{1+\text{df}(d,t)}} + 1\),</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {1 + n_d} {1+ \ text {df}（d、t）}} + 1 \）、</target>
        </trans-unit>
        <trans-unit id="4b7b756caf347e71181dfa1202016ab8356f261a" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{1+\text{df}(d,t)}}.\)</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {n_d} {1+ \ text {df}（d、t）}}。\）</target>
        </trans-unit>
        <trans-unit id="4034a1550b8c7d630dbd8eba4c06d1a4f1d30dc5" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t) = log{\frac{n_d}{\text{df}(d,t)}} + 1\)</source>
          <target state="translated">\（\ text {idf}（t）= log {\ frac {n_d} {\ text {df}（d、t）}} + 1 \）</target>
        </trans-unit>
        <trans-unit id="96edf4cb5b96d644ba339f4099a39ef286ca85fb" translate="yes" xml:space="preserve">
          <source>\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</source>
          <target state="translated">\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)</target>
        </trans-unit>
        <trans-unit id="f18c6689111b29d4354e7fffcee7cc0802b481a5" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{raw}} = [3, 0, 2.0986].\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {raw}} = [3、0、2.0986]。\）</target>
        </trans-unit>
        <trans-unit id="80aba8c317a078e4609ae8bd36660d65edad7083" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term1}} = \text{tf} \times \text{idf} = 3 \times 1 = 3\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term1}} = \ text {tf} \ times \ text {idf} = 3 \ times 1 = 3 \）</target>
        </trans-unit>
        <trans-unit id="1d70946637e51aace1378ca1a204825107f21cdf" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)</target>
        </trans-unit>
        <trans-unit id="7f8322f95350f60ce08c7cdd3032f22e074bd2b1" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term2}} = 0 \times (log(6/1)+1) = 0\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term2}} = 0 \ times（log（6/1）+1）= 0 \）</target>
        </trans-unit>
        <trans-unit id="a326be18c218e6683afc2f56f1612584e40eaa79" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)</target>
        </trans-unit>
        <trans-unit id="dcd228feb463195495d0b530544c87a8f5f36307" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times (log(6/2)+1) \approx 2.0986\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term3}} = 1 \ times（log（6/2）+1）\約2.0986 \）</target>
        </trans-unit>
        <trans-unit id="9c4af8e7df634860beafeba835d8777813396030" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)</target>
        </trans-unit>
        <trans-unit id="a8c4b99bd2ff2af3e5f2b8ace2008c6e0a9ef2e7" translate="yes" xml:space="preserve">
          <source>\(\text{tf-idf}_{\text{term3}} = 1 \times log(7/3)+1 \approx 1.8473\)</source>
          <target state="translated">\（\ text {tf-idf} _ {\ text {term3}} = 1 \ times log（7/3）+1 \約1.8473 \）</target>
        </trans-unit>
        <trans-unit id="b1e424267dd17efa4321c87fe24219eaad1c3249" translate="yes" xml:space="preserve">
          <source>\(a\), the number of pairs of elements that are in the same set in C and in the same set in K</source>
          <target state="translated">\（a \）、Cの同じセットとKの同じセットにある要素のペアの数</target>
        </trans-unit>
        <trans-unit id="ffa07cceebbfadc52e2be9cdf6b9599e34083b82" translate="yes" xml:space="preserve">
          <source>\(b\), the number of pairs of elements that are in different sets in C and in different sets in K</source>
          <target state="translated">\（b \）、Cの異なるセットとKの異なるセットにある要素のペアの数</target>
        </trans-unit>
        <trans-unit id="9634b82eb2f3a1a53f10d0105fa96b96683012b1" translate="yes" xml:space="preserve">
          <source>\(c=\sum_{k}^{K} C_{kk}\) the total number of samples correctly predicted,</source>
          <target state="translated">\（c = \ sum_ {k} ^ {K} C_ {kk} \）正しく予測されたサンプルの総数、</target>
        </trans-unit>
        <trans-unit id="e0b006e0f953d2967208fad0e101db9a95b1773e" translate="yes" xml:space="preserve">
          <source>\(c_0\) is known as intercept</source>
          <target state="translated">\（c_0 \）はインターセプトとして知られています</target>
        </trans-unit>
        <trans-unit id="20f463b5231561db0d1529b308e8cd1a67579869" translate="yes" xml:space="preserve">
          <source>\(d\) : output dimension</source>
          <target state="translated">\（d \）：出力ディメンション</target>
        </trans-unit>
        <trans-unit id="3c2644dcb6baee3a2f0954ec1f4febb35c2c968e" translate="yes" xml:space="preserve">
          <source>\(d_{ij}\), the distance between cluster centroids \(i\) and \(j\).</source>
          <target state="translated">\（d_ {ij} \）、クラスター重心\（i \）と\（j \）の間の距離。</target>
        </trans-unit>
        <trans-unit id="464de6af9c88cdb5c8c4a2137401febf7a5e41c7" translate="yes" xml:space="preserve">
          <source>\(k\) : number of nearest neighbors</source>
          <target state="translated">\（k \）：最近傍の数</target>
        </trans-unit>
        <trans-unit id="ded29692d567c68006b5e22274ae992999727d77" translate="yes" xml:space="preserve">
          <source>\(n = 6\)</source>
          <target state="translated">\(n = 6\)</target>
        </trans-unit>
        <trans-unit id="8f8783323f752c7593ada8acf8c4d67282a83607" translate="yes" xml:space="preserve">
          <source>\(n_{d} = 6\)</source>
          <target state="translated">\（n_ {d} = 6 \）</target>
        </trans-unit>
        <trans-unit id="13e265f7db3a9509d50f014f7170db211a73f394" translate="yes" xml:space="preserve">
          <source>\(p_k=\sum_{i}^{K} C_{ki}\) the number of times class \(k\) was predicted,</source>
          <target state="translated">\（p_k = \ sum_ {i} ^ {K} C_ {ki} \）クラス\（k \）が予測された回数、</target>
        </trans-unit>
        <trans-unit id="cc4e2c50ba94767cc02eead7002753560f0219c2" translate="yes" xml:space="preserve">
          <source>\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\) the total number of samples.</source>
          <target state="translated">\（s = \ sum_ {i} ^ {K} \ sum_ {j} ^ {K} C_ {ij} \）サンプルの総数。</target>
        </trans-unit>
        <trans-unit id="6eb93fac640cf512d1e63922116e7722c92fabe0" translate="yes" xml:space="preserve">
          <source>\(s_i\), the average distance between each point of cluster \(i\) and the centroid of that cluster &amp;ndash; also know as cluster diameter.</source>
          <target state="translated">\（s_i \）、クラスターの各ポイントと平均距離、\（i \）とそのクラスターの重心&amp;ndash;クラスター直径とも呼ばれます。</target>
        </trans-unit>
        <trans-unit id="2904d711734ca668dfddae3cff9c273e4d482636" translate="yes" xml:space="preserve">
          <source>\(t_k=\sum_{i}^{K} C_{ik}\) the number of times class \(k\) truly occurred,</source>
          <target state="translated">\（t_k = \ sum_ {i} ^ {K} C_ {ik} \）クラス\（k \）が実際に発生した回数、</target>
        </trans-unit>
        <trans-unit id="0a59d79c97bec565e1c47b5aab7109c37d7376fa" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\)</source>
          <target state="translated">\（v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \）</target>
        </trans-unit>
        <trans-unit id="ef3a9e22b14c74ec22385c615853f9e45898420d" translate="yes" xml:space="preserve">
          <source>\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\).</source>
          <target state="translated">\（v_ {norm} = \ frac {v} {|| v || _2} = \ frac {v} {\ sqrt {v {_1} ^ 2 + v {_2} ^ 2 + \ dots + v {_n } ^ 2}} \）。</target>
        </trans-unit>
        <trans-unit id="e9fe36499695707a4fa25e6312e0decc4b5ce11a" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\).</source>
          <target state="translated">\（x_1 \ leq x_1 '\はF（x_1、x_2）\ geq F（x_1'、x_2）\）を意味します。</target>
        </trans-unit>
        <trans-unit id="12ab6bd6cdfcad92f2c8d9cd45d8531fb50b8225" translate="yes" xml:space="preserve">
          <source>\(x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2)\), where \(F\) is the predictor with two features.</source>
          <target state="translated">\（x_1 \ leq x_1 '\ implies F（x_1、x_2）\ leq F（x_1'、x_2）\）、ここで\（F \）は2つの特徴を持つ予測子です。</target>
        </trans-unit>
        <trans-unit id="d224f9dd671e9669fa16b0ba657459625c42e63b" translate="yes" xml:space="preserve">
          <source>\(y \in (-\infty, \infty)\)</source>
          <target state="translated">\(y \in (-\infty, \infty)\)</target>
        </trans-unit>
        <trans-unit id="7fb9264ce64cd7d5e1a33f2fcf663917cc9226ab" translate="yes" xml:space="preserve">
          <source>\(y \in (0, \infty)\)</source>
          <target state="translated">\(y \in (0, \infty)\)</target>
        </trans-unit>
        <trans-unit id="6ffefe23f049210303238c3770c5a3a8cbf9ad47" translate="yes" xml:space="preserve">
          <source>\(y \in [0, \infty)\)</source>
          <target state="translated">\(y \in [0, \infty)\)</target>
        </trans-unit>
        <trans-unit id="2f32f66d76e16029cdb54470231bf86f45c56290" translate="yes" xml:space="preserve">
          <source>\(y\) the set of &lt;em&gt;predicted&lt;/em&gt;\((sample, label)\) pairs</source>
          <target state="translated">\（y \）&lt;em&gt;予測された&lt;/em&gt; \（（sample、label）\）ペアのセット</target>
        </trans-unit>
        <trans-unit id="84dbf0f25232d7453b4b36e6d3fffb9c5594408b" translate="yes" xml:space="preserve">
          <source>\(y\): target variable</source>
          <target state="translated">\（y \）：ターゲット変数</target>
        </trans-unit>
        <trans-unit id="29655c66149656107eee3658832dbefda0f10f88" translate="yes" xml:space="preserve">
          <source>\(y_l\) the subset of \(y\) with label \(l\)</source>
          <target state="translated">\（y_l \）\（y \）のサブセット、ラベル\（l \）</target>
        </trans-unit>
        <trans-unit id="2e082165475a8fcee912e7d794c4b87072c02854" translate="yes" xml:space="preserve">
          <source>\(y_s\) the subset of \(y\) with sample \(s\), i.e. \(y_s := \left\{(s', l) \in y | s' = s\right\}\)</source>
          <target state="translated">\（y_s \）\（y \）のサブセットとサンプル\（s \）、つまり\（y_s：= \ left \ {（s '、l）\ in y | s' = s \ right \} \ ）</target>
        </trans-unit>
        <trans-unit id="83a2c7fcc781f513174d7284ba894e2de571456a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}P(y \mid x_1, \dots, x_n) \propto P(y) \prod_{i=1}^{n} P(x_i \mid y)\\\Downarrow\\\hat{y} = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i \mid y),\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} P（y \ mid x_1、\ dots、x_n）\ propto P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y）\\ \ Downarrow \\\ hat {y} = \ arg \ max_y P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y）、\ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="c500aca02db178fd925a59974dd45ddee8face02" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}Q_{left}(\theta) = {(x, y) | x_j &amp;lt;= t_m}\\Q_{right}(\theta) = Q \setminus Q_{left}(\theta)\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} Q_ {left}（\ theta）= {（x、y）| x_j &amp;lt;= t_m} \\ Q_ {right}（\ theta）= Q \ setminus Q_ {left}（\ theta）\ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6d63d132be650c44cbd8191fea374d6099c68415" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} (y_i - \bar{y}_m)^2\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H（X_m）= \ frac {1} {N_m } \ sum_ {i \ in N_m}（y_i-\ bar {y} _m）^ 2 \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="09657abb97474afe531f716bc21393139a923381" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\bar{y}_m = \frac{1}{N_m} \sum_{i \in N_m} y_i\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - \bar{y}_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ bar {y} _m = \ frac {1} {N_m} \ sum_ {i \ in N_m} y_i \\ H（X_m）= \ frac {1} {N_m } \ sum_ {i \ in N_m} | y_i-\ bar {y} _m | \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="a6a013161b26d9345009bc657a0fa52bacc545a7" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\hat{\theta}_{ci} = \frac{\alpha_i + \sum_{j:y_j \neq c} d_{ij}} {\alpha + \sum_{j:y_j \neq c} \sum_{k} d_{kj}}\\w_{ci} = \log \hat{\theta}_{ci}\\w_{ci} = \frac{w_{ci}}{\sum_{j} |w_{cj}|}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ hat {\ theta} _ {ci} = \ frac {\ alpha_i + \ sum_ {j：y_j \ neq c} d_ {ij}} {\ alpha + \ sum_ {j：y_j \ neq c} \ sum_ {k} d_ {kj}} \\ w_ {ci} = \ log \ hat {\ theta} _ {ci} \\ w_ {ci} = \ frac {w_ {ci }} {\ sum_ {j} | w_ {cj} |} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="3d5da4b9043141ddac28de63232838abbbe5a18b" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\log\left(\frac{P(y=k|X)}{P(y=l|X)}\right)= \log\left(\frac{P(X|y=k)P(y=k)}{P(X|y=l)P(y=l)}\right)=0 \Leftrightarrow\\(\mu_k-\mu_l)^t\Sigma^{-1} X = \frac{1}{2} (\mu_k^t \Sigma^{-1} \mu_k - \mu_l^t \Sigma^{-1} \mu_l) - \log\frac{P(y=k)}{P(y=l)}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ log \ left（\ frac {P（y = k | X）} {P（y = l | X）} \ right）= \ log \ left（\ frac {P（X | y = k）P（y = k）} {P（X | y = l）P（y = l）} \ right）= 0 \ Leftrightarrow \\（\ mu_k- \ mu_l）^ t \ Sigma ^ {-1} X = \ frac {1} {2}（\ mu_k ^ t \ Sigma ^ {-1} \ mu_k-\ mu_l ^ t \ Sigma ^ {-1} \ mu_l）-\ log \ frac {P（y = k）} {P（y = l）} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="970228f13e58c5000f67243636530c2e6768a476" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta, \zeta^*} \frac{1}{2} w^T w + C \sum_{i=1}^{n} (\zeta_i + \zeta_i^*)\\\begin{split}\textrm {subject to } &amp;amp; y_i - w^T \phi (x_i) - b \leq \varepsilon + \zeta_i,\\ &amp;amp; w^T \phi (x_i) + b - y_i \leq \varepsilon + \zeta_i^*,\\ &amp;amp; \zeta_i, \zeta_i^* \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min_ {w、b、\ zeta、\ zeta ^ *} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ { n}（\ zeta_i + \ zeta_i ^ *）\\\ begin {split} \ textrm {subject}＆y_i-w ^ T \ phi（x_i）-b \ leq \ varepsilon + \ zeta_i、\\＆w ^ T \ phi（x_i）+ b-y_i \ leq \ varepsilon + \ zeta_i ^ *、\\＆\ zeta_i、\ zeta_i ^ * \ geq 0、i = 1、...、n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="e7cf54257feefa3a1cdfa65288e5d1230916a9ce" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i\\\begin{split}\textrm {subject to } &amp;amp; y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\ &amp;amp; \zeta_i \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min_ {w、b、\ zeta} \ frac {1} {2} w ^ T w + C \ sum_ {i = 1} ^ {n} \ zeta_i \ \\ begin {split} \ textrm {subject}＆y_i（w ^ T \ phi（x_i）+ b）\ geq 1-\ zeta_i、\\＆\ zeta_i \ geq 0、i = 1、...、 n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="80291068f9bc632282f639938cf37593076f7e40" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha, \alpha^*} \frac{1}{2} (\alpha - \alpha^*)^T Q (\alpha - \alpha^*) + \varepsilon e^T (\alpha + \alpha^*) - y^T (\alpha - \alpha^*)\\\begin{split} \textrm {subject to } &amp;amp; e^T (\alpha - \alpha^*) = 0\\ &amp;amp; 0 \leq \alpha_i, \alpha_i^* \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min _ {\ alpha、\ alpha ^ *} \ frac {1} {2}（\ alpha-\ alpha ^ *）^ TQ（\ alpha-\ alpha ^ * ）+ \ varepsilon e ^ T（\ alpha + \ alpha ^ *）-y ^ T（\ alpha-\ alpha ^ *）\\\ begin {split} \ textrm {subject to}＆e ^ T（\ alpha- \ alpha ^ *）= 0 \\＆0 \ leq \ alpha_i、\ alpha_i ^ * \ leq C、i = 1、...、n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="6c7b70ef69da1a978d3d70eb6e72d1cfe185904a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}\min_{\alpha} \frac{1}{2} \alpha^T Q \alpha - e^T \alpha\\\begin{split} \textrm {subject to } &amp;amp; y^T \alpha = 0\\ &amp;amp; 0 \leq \alpha_i \leq C, i=1, ..., n\end{split}\end{aligned}\end{align} \]</source>
          <target state="translated">\ [\ begin {align} \ begin {aligned} \ min _ {\ alpha} \ frac {1} {2} \ alpha ^ TQ \ alpha-e ^ T \ alpha \\\ begin {split} \ textrm {対象}＆y ^ T \ alpha = 0 \\＆0 \ leq \ alpha_i \ leq C、i = 1、...、n \ end {split} \ end {aligned} \ end {align} \]</target>
        </trans-unit>
        <trans-unit id="b61ecb24510d037b2f103f5394b305a25a58f23a" translate="yes" xml:space="preserve">
          <source>\[ \begin{align}\begin{aligned}median(y)_m = \underset{i \in N_m}{\mathrm{median}}(y_i)\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - median(y)_m|\end{aligned}\end{align} \]</source>
          <target state="translated">\[ \begin{align}\begin{aligned}median(y)_m = \underset{i \in N_m}{\mathrm{median}}(y_i)\\H(X_m) = \frac{1}{N_m} \sum_{i \in N_m} |y_i - median(y)_m|\end{aligned}\end{align} \]</target>
        </trans-unit>
        <trans-unit id="d6188a7c021d3288e439ea7246a74358b63a884c" translate="yes" xml:space="preserve">
          <source>\[(1 - eps) \|u - v\|^2 &amp;lt; \|p(u) - p(v)\|^2 &amp;lt; (1 + eps) \|u - v\|^2\]</source>
          <target state="translated">\ [（1-eps）\ | u-v \ | ^ 2 &amp;lt;\ | p（u）-p（v）\ | ^ 2 &amp;lt;（1 + eps）\ | u-v \ | ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c4407dbb151e2710b04032ff6939f68ed3c7179c" translate="yes" xml:space="preserve">
          <source>\[A_n = R^{-1/2} A C^{-1/2}\]</source>
          <target state="translated">\ [A_n = R ^ {-1/2} AC ^ {-1/2} \]</target>
        </trans-unit>
        <trans-unit id="f6b0d9bcf51ca0db910abd2831694b2e6df3d3e4" translate="yes" xml:space="preserve">
          <source>\[BS = \frac{1}{N} \sum_{t=1}^{N}(f_t - o_t)^2\]</source>
          <target state="translated">\ [BS = \ frac {1} {N} \ sum_ {t = 1} ^ {N}（f_t-o_t）^ 2 \]</target>
        </trans-unit>
        <trans-unit id="c92a9c50030567e1c914fdb60f6f36c624d7857a" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_q n_q (c_q - c) (c_q - c)^T\]</source>
          <target state="translated">\ [B_k = \ sum_q n_q（c_q-c）（c_q-c）^ T \]</target>
        </trans-unit>
        <trans-unit id="ba2a7d3bd989e0c77672451c8ebf6d95f02e79e3" translate="yes" xml:space="preserve">
          <source>\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</source>
          <target state="translated">\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</target>
        </trans-unit>
        <trans-unit id="f7004892a8adf03dbfdffcdcf3787b7ebb419e77" translate="yes" xml:space="preserve">
          <source>\[C \sum_{i=1, n} \mathcal{L} (f(x_i), y_i) + \Omega (w)\]</source>
          <target state="translated">\ [C \ sum_ {i = 1、n} \ mathcal {L}（f（x_i）、y_i）+ \ Omega（w）\]</target>
        </trans-unit>
        <trans-unit id="cdd0300688de915acfc1a115df5a69adf7a6197d" translate="yes" xml:space="preserve">
          <source>\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</source>
          <target state="translated">\[D(x, y) = 2\arcsin[\sqrt{\sin^2((x1 - y1) / 2) + \cos(x1)\cos(y1)\sin^2((x2 - y2) / 2)}]\]</target>
        </trans-unit>
        <trans-unit id="24e7ca264d5b1b5ecf81452a44a55176b2008b8c" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</target>
        </trans-unit>
        <trans-unit id="69d401f524d7e967afe2dcb64dc99487200dfcd8" translate="yes" xml:space="preserve">
          <source>\[DB = \frac{1}{k} \sum{i=1}^k \max_{i \neq j} R_{ij}\]</source>
          <target state="translated">\ [DB = \ frac {1} {k} \ sum {i = 1} ^ k \ max_ {i \ neq j} R_ {ij} \]</target>
        </trans-unit>
        <trans-unit id="0e40c0ff9b9201b3e6cc8ee7f729672fe6ce4c93" translate="yes" xml:space="preserve">
          <source>\[E(\mathbf{v}, \mathbf{h}) = -\sum_i \sum_j w_{ij}v_ih_j - \sum_i b_iv_i - \sum_j c_jh_j\]</source>
          <target state="translated">\ [E（\ mathbf {v}、\ mathbf {h}）=-\ sum_i \ sum_j w_ {ij} v_ih_j-\ sum_i b_iv_i-\ sum_j c_jh_j \]</target>
        </trans-unit>
        <trans-unit id="783de3e797180d6f4ba6c3e9379606ecef2ead2a" translate="yes" xml:space="preserve">
          <source>\[E(w,b) = \frac{1}{n}\sum_{i=1}^{n} L(y_i, f(x_i)) + \alpha R(w)\]</source>
          <target state="translated">\ [E（w、b）= \ frac {1} {n} \ sum_ {i = 1} ^ {n} L（y_i、f（x_i））+ \ alpha R（w）\]</target>
        </trans-unit>
        <trans-unit id="365f54944565346973bba6038073efb7e313ed11" translate="yes" xml:space="preserve">
          <source>\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+ }^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right) \frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})! (N-a_i-b_j+n_{ij})!}\]</source>
          <target state="translated">\ [E [\ text {MI}（U、V）] = \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ sum_ {n_ {ij} = （a_i + b_j-N）^ +} ^ {\ min（a_i、b_j）} \ frac {n_ {ij}} {N} \ log \ left（\ frac {N.n_ {ij}} {a_i b_j} \ right）\ frac {a_i！b_j！（N-a_i）！（N-b_j）！} {N！n_ {ij}！（a_i-n_ {ij}）！（b_j-n_ {ij}）！（N-a_i-b_j + n_ {ij}）！} \]</target>
        </trans-unit>
        <trans-unit id="fa1ff8faa81d9e66252f62a095f5cf70ca1078c1" translate="yes" xml:space="preserve">
          <source>\[F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F（x）= \ sum_ {m = 1} ^ {M} \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="8b0368e365c0b4ab2c5226a46b2b8384821b7abd" translate="yes" xml:space="preserve">
          <source>\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}.\]</source>
          <target state="translated">\ [F_ \ beta =（1 + \ beta ^ 2）\ frac {\ text {precision} \ times \ text {recall}} {\ beta ^ 2 \ text {precision} + \ text {recall}}。\]</target>
        </trans-unit>
        <trans-unit id="c9eeb87b260c2954980548a507a8b1393c039854" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \arg\min_{h} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + h(x))\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ arg \ min_ {h} \ sum_ {i = 1} ^ {n} L（y_i、F_ {m-1}（x_i）+ h （バツ））\]</target>
        </trans-unit>
        <trans-unit id="c3b959c536d9b51ce676e93f30895d0c6d681eae" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="9b119698c7b1cbf47db5678415973bc69f053f0c" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu \gamma_m h_m(x)\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）+ \ nu \ gamma_m h_m（x）\]</target>
        </trans-unit>
        <trans-unit id="f67ac5f779f99408bbddee5aabe3119d85a325aa" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</source>
          <target state="translated">\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</target>
        </trans-unit>
        <trans-unit id="53cc4ef6b492c65482e59fea0173cd005acf6ca7" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) + h_m(x),\]</source>
          <target state="translated">\[F_m(x) = F_{m-1}(x) + h_m(x),\]</target>
        </trans-unit>
        <trans-unit id="79620d3f64f3ecc0a5f216eb6a57691d801c15cd" translate="yes" xml:space="preserve">
          <source>\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^{n} \nabla_F L(y_i, F_{m-1}(x_i))\]</source>
          <target state="translated">\ [F_m（x）= F_ {m-1}（x）-\ gamma_m \ sum_ {i = 1} ^ {n} \ nabla_F L（y_i、F_ {m-1}（x_i））\]</target>
        </trans-unit>
        <trans-unit id="90cafad385d21b4d4db9860dff7480af31e6cc3a" translate="yes" xml:space="preserve">
          <source>\[G(Q, \theta) = \frac{n_{left}}{N_m} H(Q_{left}(\theta)) + \frac{n_{right}}{N_m} H(Q_{right}(\theta))\]</source>
          <target state="translated">\ [G（Q、\ theta）= \ frac {n_ {left}} {N_m} H（Q_ {left}（\ theta））+ \ frac {n_ {right}} {N_m} H（Q_ {right} （\ theta））\]</target>
        </trans-unit>
        <trans-unit id="a3b30c3461532826adfe7425f51daed9aaf98e97" translate="yes" xml:space="preserve">
          <source>\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</source>
          <target state="translated">\ [H（C）=-\ sum_ {c = 1} ^ {| C |} \ frac {n_c} {n} \ cdot \ log \ left（\ frac {n_c} {n} \ right）\]</target>
        </trans-unit>
        <trans-unit id="672f9873cccc012ff842c8c7fce069ac5cd92675" translate="yes" xml:space="preserve">
          <source>\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n} \cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</source>
          <target state="translated">\ [H（C | K）=-\ sum_ {c = 1} ^ {| C |} \ sum_ {k = 1} ^ {| K |} \ frac {n_ {c、k}} {n} \ cdot \ log \ left（\ frac {n_ {c、k}} {n_k} \ right）\]</target>
        </trans-unit>
        <trans-unit id="9dcc776906a998f47112457373d3636e82b5c382" translate="yes" xml:space="preserve">
          <source>\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</source>
          <target state="translated">\ [H（U）=-\ sum_ {i = 1} ^ {| U |} P（i）\ log（P（i））\]</target>
        </trans-unit>
        <trans-unit id="bf873d01bafa66fa00d4a9abe244e71c3ad5c483" translate="yes" xml:space="preserve">
          <source>\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</source>
          <target state="translated">\ [H（V）=-\ sum_ {j = 1} ^ {| V |} P '（j）\ log（P'（j））\]</target>
        </trans-unit>
        <trans-unit id="825bd8051092a0ff4da11fbb8a018da499318440" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = - \sum_k p_{mk} \log(p_{mk})\]</source>
          <target state="translated">\ [H（X_m）=-\ sum_k p_ {mk} \ log（p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="86fb9fbe52343d6db8c412062ca26e8b3a61d7f8" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = 1 - \max(p_{mk})\]</source>
          <target state="translated">\ [H（X_m）= 1-\ max（p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="471e679a9a1baa18ae5b83f786849ce5561bcf62" translate="yes" xml:space="preserve">
          <source>\[H(X_m) = \sum_k p_{mk} (1 - p_{mk})\]</source>
          <target state="translated">\ [H（X_m）= \ sum_k p_ {mk}（1-p_ {mk}）\]</target>
        </trans-unit>
        <trans-unit id="d07612141f923e53a5d822ae265800fc511ebfa2" translate="yes" xml:space="preserve">
          <source>\[J(A, B) = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}\]</source>
          <target state="translated">\ [J（A、B）= \ frac {| A \ cap B |} {| A | + | B | -| A \キャップB |} \]</target>
        </trans-unit>
        <trans-unit id="b38d8ccb5f6105408ebebb5c4de384f0bcc0244c" translate="yes" xml:space="preserve">
          <source>\[J(y_i, \hat{y}_i) = \frac{|y_i \cap \hat{y}_i|}{|y_i \cup \hat{y}_i|}.\]</source>
          <target state="translated">\ [J（y_i、\ hat {y} _i）= \ frac {| y_i \ cap \ hat {y} _i |} {| y_i \ cup \ hat {y} _i |}。\]</target>
        </trans-unit>
        <trans-unit id="d318f9ea1800cd74dd7a27a0e7aa26e39a217efa" translate="yes" xml:space="preserve">
          <source>\[K_{ij} = L_{ij} - \overline{L_{i \cdot}} - \overline{L_{\cdot j}} + \overline{L_{\cdot \cdot}}\]</source>
          <target state="translated">\ [K_ {ij} = L_ {ij}-\ overline {L_ {i \ cdot}}-\ overline {L _ {\ cdot j}} + \ overline {L _ {\ cdot \ cdot}} \]</target>
        </trans-unit>
        <trans-unit id="4f142a1b3f1a25b7844f5bd577802840d9086424" translate="yes" xml:space="preserve">
          <source>\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0} \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</source>
          <target state="translated">\ [LRAP（y、\ hat {f}）= \ frac {1} {n _ {\ text {samples}}} \ sum_ {i = 0} ^ {n _ {\ text {samples}}-1} \ frac {1} {|| y_i || _0} \ sum_ {j：y_ {ij} = 1} \ frac {| \ mathcal {L} _ {ij} |} {\ text {rank} _ {ij}} \ ]</target>
        </trans-unit>
        <trans-unit id="ce318e5aa62c88285e6dbc3450ddc43884867d96" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y, w) = \max\left\{1 - wy, 0\right\} = \left|1 - wy\right|_+\]</source>
          <target state="translated">\ [L_ \ text {Hinge}（y、w）= \ max \ left \ {1-wy、0 \ right \} = \ left | 1-wy \ right | _ + \]</target>
        </trans-unit>
        <trans-unit id="ba42e2e6c73e49cc69262971d98739da8f3de127" translate="yes" xml:space="preserve">
          <source>\[L_\text{Hinge}(y_w, y_t) = \max\left\{1 + y_t - y_w, 0\right\}\]</source>
          <target state="translated">\ [L_ \ text {ヒンジ}（y_w、y_t）= \ max \ left \ {1 + y_t-y_w、0 \ right \} \]</target>
        </trans-unit>
        <trans-unit id="7d42c3e71601b07673f2ff67be6498a9b9b5b660" translate="yes" xml:space="preserve">
          <source>\[L_{0-1}(y_i, \hat{y}_i) = 1(\hat{y}_i \not= y_i)\]</source>
          <target state="translated">\ [L_ {0-1}（y_i、\ hat {y} _i）= 1（\ hat {y} _i \ not = y_i）\]</target>
        </trans-unit>
        <trans-unit id="2d55be0d74f5ef605272bd6c32e6867b2bf3e8e6" translate="yes" xml:space="preserve">
          <source>\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{labels}} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_j \not= y_j)\]</source>
          <target state="translated">\ [L_ {Hamming}（y、\ hat {y}）= \ frac {1} {n_ \ text {labels}} \ sum_ {j = 0} ^ {n_ \ text {labels}-1} 1（\帽子{y} _j \ not = y_j）\]</target>
        </trans-unit>
        <trans-unit id="b3092c91dac051243dcdc2b0e51b2cc71f3f1851" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</source>
          <target state="translated">\ [L _ {\ log}（Y、P）=-\ log \ operatorname {Pr}（Y | P）=-\ frac {1} {N} \ sum_ {i = 0} ^ {N-1} \ sum_ {k = 0} ^ {K-1} y_ {i、k} \ log p_ {i、k} \]</target>
        </trans-unit>
        <trans-unit id="253a9ad7d14147f9b4d52f808d7adc29f4f1d369" translate="yes" xml:space="preserve">
          <source>\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</source>
          <target state="translated">\ [L _ {\ log}（y、p）=-\ log \ operatorname {Pr}（y | p）=-（y \ log（p）+（1-y）\ log（1-p））\ ]</target>
        </trans-unit>
        <trans-unit id="2efbeda9bdd157cc2d7a3c7780634a18e9cf252c" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = -y \ln {\hat{y}} - (1-y) \ln{(1-\hat{y})} + \alpha ||W||_2^2\]</source>
          <target state="translated">\ [Loss（\ hat {y}、y、W）= -y \ ln {\ hat {y}}-（1-y）\ ln {（1- \ hat {y}）} + \ alpha || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ad216be468be053e061c385b7f1c21d710fe84a9" translate="yes" xml:space="preserve">
          <source>\[Loss(\hat{y},y,W) = \frac{1}{2}||\hat{y} - y ||_2^2 + \frac{\alpha}{2} ||W||_2^2\]</source>
          <target state="translated">\ [Loss（\ hat {y}、y、W）= \ frac {1} {2} || \ hat {y}-y || _2 ^ 2 + \ frac {\ alpha} {2} || W || _2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="3d4d43e0aa8af2572cd4c7afaa27772d600c52ba" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{ c \times s - \sum_{k}^{K} p_k \times t_k }{\sqrt{ (s^2 - \sum_{k}^{K} p_k^2) \times (s^2 - \sum_{k}^{K} t_k^2) }}\]</source>
          <target state="translated">\ [MCC = \ frac {c \ times s-\ sum_ {k} ^ {K} p_k \ times t_k} {\ sqrt {（s ^ 2-\ sum_ {k} ^ {K} p_k ^ 2）\ times （s ^ 2-\ sum_ {k} ^ {K} t_k ^ 2）}} \]</target>
        </trans-unit>
        <trans-unit id="f5497e39840904c9cb7d2472c1ab3621a66cd485" translate="yes" xml:space="preserve">
          <source>\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</source>
          <target state="translated">\ [MCC = \ frac {tp \ times tn-fp \ times fn} {\ sqrt {（tp + fp）（tp + fn）（tn + fp）（tn + fn）}}。\]</target>
        </trans-unit>
        <trans-unit id="a3da3c85336ea30ff991df5f7886c792d671d3d1" translate="yes" xml:space="preserve">
          <source>\[MI(U,V)=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i\cap V_j|}{N} \log\frac{N|U_i \cap V_j|}{|U_i||V_j|}\]</source>
          <target state="translated">\ [MI（U、V）= \ sum_ {i = 1} ^ {| U |} \ sum_ {j = 1} ^ {| V |} \ frac {| U_i \ cap V_j |} {N} \ log \ frac {N | U_i \ cap V_j |} {| U_i || V_j |} \]</target>
        </trans-unit>
        <trans-unit id="c94cfec038c55c60afa9fef476e0a1aad2563170" translate="yes" xml:space="preserve">
          <source>\[P(X | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (X-\mu_k)^t \Sigma_k^{-1} (X-\mu_k)\right)\]</source>
          <target state="translated">\ [P（X | y = k）= \ frac {1} {（2 \ pi）^ {d / 2} | \ Sigma_k | ^ {1/2}} \ exp \ left（-\ frac {1} {2}（X- \ mu_k）^ t \ Sigma_k ^ {-1}（X- \ mu_k）\ right）\]</target>
        </trans-unit>
        <trans-unit id="cd893dbc741157abd91341aed411a740724f85fa" translate="yes" xml:space="preserve">
          <source>\[P(\mathbf{v}, \mathbf{h}) = \frac{e^{-E(\mathbf{v}, \mathbf{h})}}{Z}\]</source>
          <target state="translated">\ [P（\ mathbf {v}、\ mathbf {h}）= \ frac {e ^ {-E（\ mathbf {v}、\ mathbf {h}）}} {Z} \]</target>
        </trans-unit>
        <trans-unit id="7e8396a93e6bd3272f4718e7de218023882d7d31" translate="yes" xml:space="preserve">
          <source>\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</source>
          <target state="translated">\[P(x | y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}}\exp\left(-\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k)\right)\]</target>
        </trans-unit>
        <trans-unit id="f84acbf7827b429f5edf701fe90ef79259a19956" translate="yes" xml:space="preserve">
          <source>\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</source>
          <target state="translated">\[P(x_i = t \mid y = c \: ;\, \alpha) = \frac{ N_{tic} + \alpha}{N_{c} + \alpha n_i},\]</target>
        </trans-unit>
        <trans-unit id="0a8ab66c6ea03a89651facccbd08d5f0c9be8c6d" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = P(i \mid y) x_i + (1 - P(i \mid y)) (1 - x_i)\]</source>
          <target state="translated">\ [P（x_i \ mid y）= P（i \ mid y）x_i +（1-P（i \ mid y））（1-x_i）\]</target>
        </trans-unit>
        <trans-unit id="33b093ce0e5d6e386417ef609cc2f6a855343cc3" translate="yes" xml:space="preserve">
          <source>\[P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)\]</source>
          <target state="translated">\ [P（x_i \ mid y）= \ frac {1} {\ sqrt {2 \ pi \ sigma ^ 2_y}} \ exp \ left（-\ frac {（x_i-\ mu_y）^ 2} {2 \ sigma ^ 2_y} \右）\]</target>
        </trans-unit>
        <trans-unit id="1f013d2ae1dd46efa06019f68c7849dc72ce7f4e" translate="yes" xml:space="preserve">
          <source>\[P(x_i | y, x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n) = P(x_i | y),\]</source>
          <target state="translated">\ [P（x_i | y、x_1、\ dots、x_ {i-1}、x_ {i + 1}、\ dots、x_n）= P（x_i | y）、\]</target>
        </trans-unit>
        <trans-unit id="c732ad1752bec3f2371482df4bfec3ce784d1ec4" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P（y \ mid x_1、\ dots、x_n）= \ frac {P（y）P（x_1、\ dots x_n \ mid y）} {P（x_1、\ dots、x_n）} \]</target>
        </trans-unit>
        <trans-unit id="facd455c5147b9177420e6f465438d2ec052942b" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\[P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n \mid y)} {P(x_1, \dots, x_n)}\]</target>
        </trans-unit>
        <trans-unit id="84c8d40000ffaabc15011af6c72fc5efaa03e40c" translate="yes" xml:space="preserve">
          <source>\[P(y \mid x_1, \dots, x_n) = \frac{P(y) \prod_{i=1}^{n} P(x_i \mid y)} {P(x_1, \dots, x_n)}\]</source>
          <target state="translated">\ [P（y \ mid x_1、\ dots、x_n）= \ frac {P（y）\ prod_ {i = 1} ^ {n} P（x_i \ mid y）} {P（x_1、\ dots、x_n ）} \]</target>
        </trans-unit>
        <trans-unit id="edcd72a09735a7f6adceea22c0b30c20fbfbd80a" translate="yes" xml:space="preserve">
          <source>\[P(y=k | X) = \frac{P(X | y=k) P(y=k)}{P(X)} = \frac{P(X | y=k) P(y = k)}{ \sum_{l} P(X | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\ [P（y = k | X）= \ frac {P（X | y = k）P（y = k）} {P（X）} = \ frac {P（X | y = k）P（y = k）} {\ sum_ {l} P（X | y = l）\ cdot P（y = l）} \]</target>
        </trans-unit>
        <trans-unit id="d0d051ebe8e5f14c78017b6beb24cfde6b45cc0c" translate="yes" xml:space="preserve">
          <source>\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</source>
          <target state="translated">\[P(y=k | x) = \frac{P(x | y=k) P(y=k)}{P(x)} = \frac{P(x | y=k) P(y = k)}{ \sum_{l} P(x | y=l) \cdot P(y=l)}\]</target>
        </trans-unit>
        <trans-unit id="b5a07827e49a88167851d8970eaa9edda3b99d65" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{\text{samples}} - 1} (y_i - \hat{y}_i)^2}{\sum_{i=0}^{n_\text{samples} - 1} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\ [R ^ 2（y、\ hat {y}）= 1-\ frac {\ sum_ {i = 0} ^ {n _ {\ text {samples}}-1}（y_i-\ hat {y} _i） ^ 2} {\ sum_ {i = 0} ^ {n_ \ text {samples}-1}（y_i-\ bar {y}）^ 2} \]</target>
        </trans-unit>
        <trans-unit id="75a581e81c894ca3d5a39bbe361df977932542f2" translate="yes" xml:space="preserve">
          <source>\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</source>
          <target state="translated">\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</target>
        </trans-unit>
        <trans-unit id="e9b98e0db2ea75d1dfbeda81f631985feb91e53a" translate="yes" xml:space="preserve">
          <source>\[R_\alpha(T) = R(T) + \alpha|T|\]</source>
          <target state="translated">\[R_\alpha(T) = R(T) + \alpha|T|\]</target>
        </trans-unit>
        <trans-unit id="c4a8061b9eb9628b02ec75d4e5fc5a21d09cd880" translate="yes" xml:space="preserve">
          <source>\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</source>
          <target state="translated">\ [R_ {ij} = \ frac {s_i + s_j} {d_ {ij}} \]</target>
        </trans-unit>
        <trans-unit id="a0fa8b8fb90971dc259d470e1011abda5608da98" translate="yes" xml:space="preserve">
          <source>\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</source>
          <target state="translated">\[T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1} \sum_{j \in \mathcal{N}_{i}^{k}} \max(0, (r(i, j) - k))\]</target>
        </trans-unit>
        <trans-unit id="7faa52dada966b566ea53656a8bd94425e2b50a6" translate="yes" xml:space="preserve">
          <source>\[W^{i+1} = W^i - \epsilon \nabla {Loss}_{W}^{i}\]</source>
          <target state="translated">\ [W ^ {i + 1} = W ^ i-\ epsilon \ nabla {Loss} _ {W} ^ {i} \]</target>
        </trans-unit>
        <trans-unit id="e598814b9bd2e3db200ccff196ebf646bf738ec7" translate="yes" xml:space="preserve">
          <source>\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</source>
          <target state="translated">\ [W_k = \ sum_ {q = 1} ^ k \ sum_ {x \ in C_q}（x-c_q）（x-c_q）^ T \]</target>
        </trans-unit>
        <trans-unit id="7eb30be4ba7f05878cf003c46dfa54b35d57c946" translate="yes" xml:space="preserve">
          <source>\[X \approx X_k = U_k \Sigma_k V_k^\top\]</source>
          <target state="translated">\ [X \約X_k = U_k \ Sigma_k V_k ^ \ top \]</target>
        </trans-unit>
        <trans-unit id="c7c03179d6deebc1c581ff68076935c59051f655" translate="yes" xml:space="preserve">
          <source>\[X' = X V_k\]</source>
          <target state="translated">\ [X '= X V_k \]</target>
        </trans-unit>
        <trans-unit id="1b12fce875e4a7610479762a7e27b3b69634b6af" translate="yes" xml:space="preserve">
          <source>\[X^* = D^{-1/2}U^t X\text{ with }\Sigma = UDU^t\]</source>
          <target state="translated">\ [X ^ * = D ^ {-1/2} U ^ t X \ text {with} \ Sigma = UDU ^ t \]</target>
        </trans-unit>
        <trans-unit id="15463a9b27ce80c407246ad66ee390a5bc003068" translate="yes" xml:space="preserve">
          <source>\[\alpha \rho ||W||_1 + \alpha \rho ||H||_1 + \frac{\alpha(1-\rho)}{2} ||W||_{\mathrm{Fro}} ^ 2 + \frac{\alpha(1-\rho)}{2} ||H||_{\mathrm{Fro}} ^ 2\]</source>
          <target state="translated">\ [\ alpha \ rho || W || _1 + \ alpha \ rho || H || _1 + \ frac {\ alpha（1- \ rho）} {2} || W || _ {\ mathrm {Fro }} ^ 2 + \ frac {\ alpha（1- \ rho）} {2} || H || _ {\ mathrm {Fro}} ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="ecb4b9fe8fc24f73a20eeac8e7781ad331ab3cc6" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||U||_1 \\ \text{subject to } &amp;amp; ||V_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{\mathrm{atoms}}\end{split}\]</source>
          <target state="translated">\ [\ begin {split}（U ^ *、V ^ *）= \ underset {U、V} {\ operatorname {arg \、min \、}}＆\ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || U || _1 \\ \ text {subject to}＆|| V_k || _2 = 1 \ text {for all} 0 \ leq k &amp;lt;n _ {\ mathrm {atoms}} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="113192b0908b5ad7f78568d56440ab2d30ef92e9" translate="yes" xml:space="preserve">
          <source>\[\begin{split}(U^*, V^*) = \underset{U, V}{\operatorname{arg\,min\,}} &amp;amp; \frac{1}{2} ||X-UV||_2^2+\alpha||V||_1 \\ \text{subject to } &amp;amp; ||U_k||_2 = 1 \text{ for all } 0 \leq k &amp;lt; n_{components}\end{split}\]</source>
          <target state="translated">\ [\ begin {split}（U ^ *、V ^ *）= \ underset {U、V} {\ operatorname {arg \、min \、}}＆\ frac {1} {2} || X-UV || _2 ^ 2 + \ alpha || V || _1 \\ \ text {subject to}＆|| U_k || _2 = 1 \ text {for all} 0 \ leq k &amp;lt;n_ {components} \ end {split } \]</target>
        </trans-unit>
        <trans-unit id="3136579a6b2a85a0be46315eb9cbc3ba1e261551" translate="yes" xml:space="preserve">
          <source>\[\begin{split}H_{\epsilon}(z) = \begin{cases} z^2, &amp;amp; \text {if } |z| &amp;lt; \epsilon, \\ 2\epsilon|z| - \epsilon^2, &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} H _ {\ epsilon}（z）= \ begin {cases} z ^ 2、＆\ text {if} | z | &amp;lt;\ epsilon、\\ 2 \ epsilon | z | -\ epsilon ^ 2、＆\ text {otherwise} \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="b46cf81ba2e913dc611a985b07c8255c093eef0a" translate="yes" xml:space="preserve">
          <source>\[\begin{split}P(v_i=1|\mathbf{h}) = \sigma(\sum_j w_{ij}h_j + b_i) \\ P(h_i=1|\mathbf{v}) = \sigma(\sum_i w_{ij}v_i + c_j)\end{split}\]</source>
          <target state="translated">\ [\ begin {split} P（v_i = 1 | \ mathbf {h}）= \ sigma（\ sum_j w_ {ij} h_j + b_i）\\ P（h_i = 1 | \ mathbf {v}）= \ sigma （\ sum_i w_ {ij} v_i + c_j）\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="2a61de83e06a531ec76671fed3f61a04aabc9bf7" translate="yes" xml:space="preserve">
          <source>\[\begin{split}Z = \begin{bmatrix} R^{-1/2} U \\\\ C^{-1/2} V \end{bmatrix}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} Z = \ begin {bmatrix} R ^ {-1/2} U \\\\ C ^ {-1/2} V \ end {bmatrix} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="8fd5d1a7323dcc269879eaa3da3604856f3eb3a0" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\left\{ \begin{array}{c c l} -\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ 0 &amp;amp;\text{with probability} &amp;amp; 1 - 1 / s \\ +\sqrt{\frac{s}{n_{\text{components}}}} &amp;amp; &amp;amp; 1 / 2s\\ \end{array} \right.\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ left \ {\ begin {array} {ccl}-\ sqrt {\ frac {s} {n _ {\ text {components}}}}＆＆1 / 2s \\ 0＆\ text {確率あり}＆1-1 / s \\ + \ sqrt {\ frac {s} {n _ {\ text {components}}}}＆＆1 / 2s \\ \ end {array} \ right。\ end {スプリット}\]</target>
        </trans-unit>
        <trans-unit id="240e6564ced61b1bc331dcf97a462834371b6641" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\log P(y=k | x) &amp;amp;= \log P(x | y=k) + \log P(y = k) + Cst \\ &amp;amp;= -\frac{1}{2} \log |\Sigma_k| -\frac{1}{2} (x-\mu_k)^t \Sigma_k^{-1} (x-\mu_k) + \log P(y = k) + Cst,\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ log P（y = k | x）＆= \ log P（x | y = k）+ \ log P（y = k）+ Cst \\＆=-\ frac {1} {2} \ log | \ Sigma_k | -\ frac {1} {2}（x- \ mu_k）^ t \ Sigma_k ^ {-1}（x- \ mu_k）+ \ log P（y = k）+ Cst、\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="cce5812b4c3daf727144c68d463e8caf50c7bfbb" translate="yes" xml:space="preserve">
          <source>\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} \begin{cases} (y_i-\hat{y}_i)^2, &amp;amp; \text{for }p=0\text{ (Normal)}\\ 2(y_i \log(y/\hat{y}_i) + \hat{y}_i - y_i), &amp;amp; \text{for}p=1\text{ (Poisson)}\\ 2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1), &amp;amp; \text{for}p=2\text{ (Gamma)}\\ 2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}- \frac{y\,\hat{y}^{1-p}_i}{1-p}+\frac{\hat{y}^{2-p}_i}{2-p}\right), &amp;amp; \text{otherwise} \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} \ text {D}（y、\ hat {y}）= \ frac {1} {n_ \ text {samples}} \ sum_ {i = 0} ^ {n_ \ text {samples} -1} \ begin {cases}（y_i- \ hat {y} _i）^ 2、＆\ text {for} p = 0 \ text {（Normal）} \\ 2（y_i \ log（y / \ hat { y} _i）+ \ hat {y} _i --y_i）、＆\ text {for} p = 1 \ text {（Poisson）} \\ 2（\ log（\ hat {y} _i / y_i）+ y_i / \ hat {y} _i-1）、＆\ text {for} p = 2 \ text {（ガンマ）} \\ 2 \ left（\ frac {\ max（y_i、0）^ {2-p}} { （1-p）（2-p）}-\ frac {y \、\ hat {y} ^ {1-p} _i} {1-p} + \ frac {\ hat {y} ^ {2-p } _i} {2-p} \ right）、＆\ text {otherwise} \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="64d0ec223c44ca16fb23a31d32e7c757a5e38ba8" translate="yes" xml:space="preserve">
          <source>\[\begin{split}h_i \bot h_j | \mathbf{v} \\ v_i \bot v_j | \mathbf{h}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} h_i \ bot h_j | \ mathbf {v} \\ v_i \ bot v_j | \ mathbf {h} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3a84b3b0085920a5dafc19e08421419f997fff14" translate="yes" xml:space="preserve">
          <source>\[\begin{split}pd_{X_S}(x_S) &amp;amp;\overset{def}{=} \mathbb{E}_{X_C}\left[ f(x_S, X_C) \right]\\ &amp;amp;= \int f(x_S, x_C) p(x_C) dx_C,\end{split}\]</source>
          <target state="translated">\ [\ begin {split} pd_ {X_S}（x_S）＆\ overset {def} {=} \ mathbb {E} _ {X_C} \ left [f（x_S、X_C）\ right] \\＆= \ int f（x_S、x_C）p（x_C）dx_C、\ end {split} \]</target>
        </trans-unit>
        <trans-unit id="6675ac3debfec98638ba1f9b136883988a6a0c0b" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i + 1)} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases} [（x_i + 1）^ \ lambda --1] / \ lambda＆\ text {if} \ lambda \ neq 0、x_i \ geq 0、\\ [8pt] \ ln {（x_i + 1）}＆\ text {if} \ lambda = 0、x_i \ geq 0 \\ [8pt]-[（-x_i + 1）^ {2- \ lambda} -1] /（2- \ lambda）＆\ text {if} \ lambda \ neq 2、x_i &amp;lt;0、\\ [8pt]-\ ln（-x_i + 1）＆\ text {if} \ lambda = 2、x_i &amp;lt;0 \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="3198bb38407bb1554dc0d1959561349fcfcad349" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} [(x_i + 1)^\lambda - 1] / \lambda &amp;amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt] \ln{(x_i) + 1} &amp;amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt] -[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp;amp; \text{if } \lambda \neq 2, x_i &amp;lt; 0, \\[8pt] - \ln (- x_i + 1) &amp;amp; \text{if } \lambda = 2, x_i &amp;lt; 0 \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases} [（x_i + 1）^ \ lambda-1] / \ lambda＆\ text {if} \ lambda \ neq 0、x_i \ geq 0、\\ [8pt] \ ln {（x_i）+ 1}＆\ text {if} \ lambda = 0、x_i \ geq 0 \\ [8pt]-[（-x_i + 1）^ {2-\ lambda}-1] /（2-\ lambda）＆\ text {if} \ lambda \ neq 2、x_i &amp;lt;0、\\ [8pt]-\ ln（-x_i + 1）＆\ text {if} \ lambda = 2、x_i &amp;lt;0 \ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="dc87ecfd4801e13673bdd8bb567f720368f1d00c" translate="yes" xml:space="preserve">
          <source>\[\begin{split}x_i^{(\lambda)} = \begin{cases} \dfrac{x_i^\lambda - 1}{\lambda} &amp;amp; \text{if } \lambda \neq 0, \\[8pt] \ln{(x_i)} &amp;amp; \text{if } \lambda = 0, \end{cases}\end{split}\]</source>
          <target state="translated">\ [\ begin {split} x_i ^ {（\ lambda）} = \ begin {cases} \ dfrac {x_i ^ \ lambda-1} {\ lambda}＆\ text {if} \ lambda \ neq 0、\\ [ 8pt] \ ln {（x_i）}＆\ text {if} \ lambda = 0、\ end {cases} \ end {split} \]</target>
        </trans-unit>
        <trans-unit id="4537e01f403cf1db6a1704e87011ad05c2900083" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</source>
          <target state="translated">\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</target>
        </trans-unit>
        <trans-unit id="a73d653ad8356da32b64d5107d59910b4574da8f" translate="yes" xml:space="preserve">
          <source>\[\binom{n_{samples}}{n_{subsamples}}\]</source>
          <target state="translated">\[\binom{n_{samples}}{n_{subsamples}}\]</target>
        </trans-unit>
        <trans-unit id="ac1ff82d2bb9be7a891279ff19e58ef9606ac1e2" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac {1}{\alpha (t_0 + t)}\]</source>
          <target state="translated">\ [\ eta ^ {（t）} = \ frac {1} {\ alpha（t_0 + t）} \]</target>
        </trans-unit>
        <trans-unit id="94fa32af9a54520431e5e0db6110f5f4be3adb89" translate="yes" xml:space="preserve">
          <source>\[\eta^{(t)} = \frac{eta_0}{t^{power\_t}}\]</source>
          <target state="translated">\ [\ eta ^ {（t）} = \ frac {eta_0} {t ^ {power \ _t}} \]</target>
        </trans-unit>
        <trans-unit id="5914d3325cfa1135b23fa0bc1a30756771d61bd1" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="translated">\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c (\text{AUC}(j | k) + \text{AUC}(k | j))\]</target>
        </trans-unit>
        <trans-unit id="23f7d8421e9f7d86dc62315499303963443744dd" translate="yes" xml:space="preserve">
          <source>\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</source>
          <target state="translated">\[\frac{2}{c(c-1)}\sum_{j=1}^{c}\sum_{k &amp;gt; j}^c p(j \cup k)( \text{AUC}(j | k) + \text{AUC}(k | j))\]</target>
        </trans-unit>
        <trans-unit id="0ab74fa9a47831af7bc26708f2eb4bb36eb7c478" translate="yes" xml:space="preserve">
          <source>\[\gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) - \gamma \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)})\]</source>
          <target state="translated">\ [\ gamma_m = \ arg \ min _ {\ gamma} \ sum_ {i = 1} ^ {n} L（y_i、F_ {m-1}（x_i）-\ gamma \ frac {\ partial L（y_i、F_ {m-1}（x_i））} {\ partial F_ {m-1}（x_i）}）\]</target>
        </trans-unit>
        <trans-unit id="03488d7aa371e338e3a792b1ee0314e7750d1c23" translate="yes" xml:space="preserve">
          <source>\[\hat{K} = \mathrm{argmin}_K \big( \mathrm{tr} S K - \mathrm{log} \mathrm{det} K + \alpha \|K\|_1 \big)\]</source>
          <target state="translated">\ [\ hat {K} = \ mathrm {argmin} _K \ big（\ mathrm {tr} SK-\ mathrm {log} \ mathrm {det} K + \ alpha \ | K \ | _1 \ big）\]</target>
        </trans-unit>
        <trans-unit id="9d564db2d54a230e005c20037b5a37d139fd79dd" translate="yes" xml:space="preserve">
          <source>\[\hat{\theta}_{yi} = \frac{ N_{yi} + \alpha}{N_y + \alpha n}\]</source>
          <target state="translated">\ [\ hat {\ theta} _ {yi} = \ frac {N_ {yi} + \ alpha} {N_y + \ alpha n} \]</target>
        </trans-unit>
        <trans-unit id="c11c6e06d183bd2451c8cb2b3112bec0b1bc1ee8" translate="yes" xml:space="preserve">
          <source>\[\hat{c} = \arg\min_c \sum_{i} t_i w_{ci}\]</source>
          <target state="translated">\ [\ hat {c} = \ arg \ min_c \ sum_ {i} t_i w_ {ci} \]</target>
        </trans-unit>
        <trans-unit id="0d0878697ede61cc2d8e8a17d350fedc4b3570ca" translate="yes" xml:space="preserve">
          <source>\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</source>
          <target state="translated">\ [\ hat {w} _i = \ frac {w_i} {\ sum_j {1（y_j = y_i）w_j}} \]</target>
        </trans-unit>
        <trans-unit id="2a9f64bd46b89b26f87a73f822e103df8215fc20" translate="yes" xml:space="preserve">
          <source>\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</source>
          <target state="translated">\[\hat{y_i} = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</target>
        </trans-unit>
        <trans-unit id="c4cf751319dcee1f0c7d13ac626ea9ed7a5bb6a9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, X) = h(Xw).\]</source>
          <target state="translated">\[\hat{y}(w, X) = h(Xw).\]</target>
        </trans-unit>
        <trans-unit id="463125ace329bbcbe2634beaad2a87856ea8f696" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\]</source>
          <target state="translated">\ [\ hat {y}（w、x）= w_0 + w_1 x_1 + ... + w_p x_p \]</target>
        </trans-unit>
        <trans-unit id="d7104cc52e967d53cc9bb7db2f89101bc8dd84a8" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\]</source>
          <target state="translated">\ [\ hat {y}（w、x）= w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1 ^ 2 + w_5 x_2 ^ 2 \]</target>
        </trans-unit>
        <trans-unit id="658832cb765efda37a6b6c541d565e8e7abeaf9e" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2\]</source>
          <target state="translated">\ [\ hat {y}（w、x）= w_0 + w_1 x_1 + w_2 x_2 \]</target>
        </trans-unit>
        <trans-unit id="e16dea6416d3f9e94f0e5c1b50c7914fc96699e9" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, x) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\ [\ hat {y}（w、x）= w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5 \]</target>
        </trans-unit>
        <trans-unit id="1ef6664dd57ac85f53b0ac082bd4ac87b3d1bc48" translate="yes" xml:space="preserve">
          <source>\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</source>
          <target state="translated">\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</target>
        </trans-unit>
        <trans-unit id="7ee9d5e754305261d56bc754281eac2d4bc47e43" translate="yes" xml:space="preserve">
          <source>\[\kappa = (p_o - p_e) / (1 - p_e)\]</source>
          <target state="translated">\ [\ kappa =（p_o-p_e）/（1-p_e）\]</target>
        </trans-unit>
        <trans-unit id="167a98e04ab5b59774a90feac289ea3a97af6579" translate="yes" xml:space="preserve">
          <source>\[\log P(v) = \log \sum_h e^{-E(v, h)} - \log \sum_{x, y} e^{-E(x, y)}\]</source>
          <target state="translated">\ [\ log P（v）= \ log \ sum_h e ^ {-E（v、h）}-\ log \ sum_ {x、y} e ^ {-E（x、y）} \]</target>
        </trans-unit>
        <trans-unit id="3615a8591ff789e7148f8d4eaedd232d6f832187" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</source>
          <target state="translated">\[\log P(y=k | x) = -\frac{1}{2} (x-\mu_k)^t \Sigma^{-1} (x-\mu_k) + \log P(y = k) + Cst.\]</target>
        </trans-unit>
        <trans-unit id="a818beecd93bff11790e50acc933a2d8090bf837" translate="yes" xml:space="preserve">
          <source>\[\log P(y=k | x) = \omega_k^t x + \omega_{k0} + Cst.\]</source>
          <target state="translated">\[\log P(y=k | x) = \omega_k^t x + \omega_{k0} + Cst.\]</target>
        </trans-unit>
        <trans-unit id="ad74f3245329845209a6a11327e3e01ab638c922" translate="yes" xml:space="preserve">
          <source>\[\log\: P(w | \alpha, \eta) \geq L(w,\phi,\gamma,\lambda) \overset{\triangle}{=} E_{q}[\log\:p(w,z,\theta,\beta|\alpha,\eta)] - E_{q}[\log\:q(z, \theta, \beta)]\]</source>
          <target state="translated">\ [\ log \：P（w | \ alpha、\ eta）\ geq L（w、\ phi、\ gamma、\ lambda）\ overset {\ triangle} {=} E_ {q} [\ log \：p （w、z、\ theta、\ beta | \ alpha、\ eta）]-E_ {q} [\ log \：q（z、\ theta、\ beta）] \]</target>
        </trans-unit>
        <trans-unit id="acd2ba041ece952cccd5e4312456e983a53c6177" translate="yes" xml:space="preserve">
          <source>\[\mathbf{X} = W \mathbf{H} + \mathbf{M} + \mathbf{E}\]</source>
          <target state="translated">\ [\ mathbf {X} = W \ mathbf {H} + \ mathbf {M} + \ mathbf {E} \]</target>
        </trans-unit>
        <trans-unit id="3fc441ca9a3b802fffa9f5232b4a01983592e3f6" translate="yes" xml:space="preserve">
          <source>\[\mathrm{Var}[X] = p(1 - p)\]</source>
          <target state="translated">\ [\ mathrm {Var} [X] = p（1-p）\]</target>
        </trans-unit>
        <trans-unit id="115415b8df2e0037567cec45ba374bf6acae476a" translate="yes" xml:space="preserve">
          <source>\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, y_i (w^T \phi(x_i) + b)),\]</source>
          <target state="translated">\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, y_i (w^T \phi(x_i) + b)),\]</target>
        </trans-unit>
        <trans-unit id="ff67bbd323e7ac7f1f2a65cc0812c3d22a62f042" translate="yes" xml:space="preserve">
          <source>\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, |y_i - (w^T \phi(x_i) + b)| - \varepsilon),\]</source>
          <target state="translated">\[\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, |y_i - (w^T \phi(x_i) + b)| - \varepsilon),\]</target>
        </trans-unit>
        <trans-unit id="1fa465ae3dc6f6cd2a645126f7fc3c5985939961" translate="yes" xml:space="preserve">
          <source>\[\min_{W} { \frac{1}{2n_{\text{samples}}} ||X W - Y||_{\text{Fro}}^2 + \alpha \rho ||W||_{2 1} + \frac{\alpha(1-\rho)}{2} ||W||_{\text{Fro}}^2}\]</source>
          <target state="translated">\[\min_{W} { \frac{1}{2n_{\text{samples}}} ||X W - Y||_{\text{Fro}}^2 + \alpha \rho ||W||_{2 1} + \frac{\alpha(1-\rho)}{2} ||W||_{\text{Fro}}^2}\]</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
