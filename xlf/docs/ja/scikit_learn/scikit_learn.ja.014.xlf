<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="d1e3e38243b5c0275e9fe55822527a766daf84e5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.cross_val_score&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.cross_val_score&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="cd66ce686ba75391d858a270576652221e9366cb" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.cross_validate&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.cross_validate&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="64bdbb73303147fbfb7b4c72e2c5b9f862e6846a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.learning_curve&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.learning_curve&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="058189237019f568402a807ff0f37d6659f730bd" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.permutation_test_score&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.permutation_test_score&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="a35d588868114f2ff75fd130567f7e47c8648990" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.train_test_split&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.train_test_split&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="c436bb41de4b1b0cbaf9f2a30c84739212eaf00c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.model_selection.validation_curve&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.model_selection.validation_curve&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="8c90ea159f2ef33465cc5505a41ebcb13d8fa556" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="3b803ea3410b546ac8080c64d5a283e65161ec36" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multioutput.ClassifierChain&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.multioutput.ClassifierChain&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="175a335aedce67fab5414504b5b10913957177f2" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.multioutput.MultiOutputRegressor&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.multioutput.MultiOutputRegressor&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="7e5276c814e14e2874f1abc67268ecba0a9384b5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.BernoulliNB&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.naive_bayes.BernoulliNB&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="07d68dd4fe4a915ea6b5e32e2eca6d299d857bb7" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.ComplementNB&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.naive_bayes.ComplementNB&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="af3404bd8b46bee3672ba86cfbae1ef5ccc5adfa" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.GaussianNB&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.naive_bayes.GaussianNB&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="141d21773d99f3975d70ea9e9ce62f28b143b5ad" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="5d999f3df66c782268c5cd0602cb79c507903292" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsClassifier&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.KNeighborsClassifier&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="f26682456d970fbdab48470c970d2b2cf9d0be01" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.KNeighborsRegressor&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="da4ee64191a33554442daf81f4b75c328c16de8c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KNeighborsTransformer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.KNeighborsTransformer&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="2b0ca2d2cfcae04b6e8f648035a263800eba906a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="135f507596f50f4128ab7f674fa719851e06ba93" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.LocalOutlierFactor&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.LocalOutlierFactor&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="2d07ff0ebbbb5614d7d55c03e06e43f1f3f6d8b5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.NearestCentroid&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.NearestCentroid&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="0749621ad934aca64b6d4bb597f488ca85f63f5a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.NeighborhoodComponentsAnalysis&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.NeighborhoodComponentsAnalysis&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="9e409523b85d3bf8b35de4b9a79e58e19412df01" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neighbors.kneighbors_graph&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neighbors.kneighbors_graph&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="92b259d24e226f9725b7a2251b317d28f69ae1de" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.BernoulliRBM&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neural_network.BernoulliRBM&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="bc26545aa247592ad5cae0c82982049aecb04005" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.MLPClassifier&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neural_network.MLPClassifier&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="439d6a7e65183ef0435c18b6b323c74a5c51b635" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.neural_network.MLPRegressor&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.neural_network.MLPRegressor&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="aa6ee186b720b58c48c82ddfe44e7546cce24778" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.FeatureUnion&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.pipeline.FeatureUnion&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="998ec3583b26e3fb4a4ed0aff8fa32c106d8d3fd" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="ce16abd7de545850afcb200375d7496f51a99f86" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.make_pipeline&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.pipeline.make_pipeline&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="22b8f1c3009cd0b959254500e33f171fb13ddc5e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.pipeline.make_union&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.pipeline.make_union&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="2542a7119b1badd4a5e17e03f5405355cc7a6b4e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.FunctionTransformer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.FunctionTransformer&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="c5ebd1b718c2b56f55f671f8d4b702c99b6f3049" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.KBinsDiscretizer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.KBinsDiscretizer&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="c4381d9fd377759510c6b6b975b0aef8ecf5740c" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.MaxAbsScaler&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.MaxAbsScaler&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="6c598f0cbf4e71a390fc3aa76e817310e670b681" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.MinMaxScaler&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="c1bc49d9937f0e2a5f4b0d4692671125b0d008b2" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.Normalizer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.Normalizer&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="149136e5bc700b2e0a7747b2cd498f47536f44b4" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="11c249d2a654ff2f1c2cc110185680b161c2af36" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.OrdinalEncoder&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.OrdinalEncoder&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="56c4939b9d0afea5d1cebbe13cfe733258c34c00" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.PolynomialFeatures&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.PolynomialFeatures&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="3a155bf7a30ca61ce1f29447001d55507068d346" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.PowerTransformer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.PowerTransformer&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="deb84a64d1425831a8777aa592bd6255271f75f8" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.QuantileTransformer&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.QuantileTransformer&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="6a98bd8bd28f139beba8d2222e8707ab286c5640" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.RobustScaler&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.RobustScaler&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="cc6025242e9ac27ec2143cf98f98385064f91436" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.StandardScaler&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="be97d0bdf7a32b2c8b6fa3970798bb89bf783b34" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.label_binarize&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.label_binarize&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="36fa08e3b378f54ed6dffaaf0e419793c6ba101a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.minmax_scale&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.minmax_scale&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="69e893f40e9fcd420f194c86a5ec119b1f003520" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.quantile_transform&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.quantile_transform&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="f1b108e5d448ff373a393340cccb912e8ffb72af" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.preprocessing.scale&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.preprocessing.scale&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="955e7e901699a2db4e4172aa9ab76068eea1b92f" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="4c4748cf4849c5fc863bc575791af8141a34cef5" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.random_projection.johnson_lindenstrauss_min_dim&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="88c1a4bb06d05e08ee20fd615bb4b53da175dc3d" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.semi_supervised.LabelSpreading&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.semi_supervised.LabelSpreading&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="737ca8cb1ccf3eeb065178263662a6be9c3d9649" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.set_config&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.set_config&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="7cd962b7c530c80e05b210277444c2bad820ca1e" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="edbf5922b6f27be5c5403e10197b447705e6f9cb" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.NuSVC&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.NuSVC&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="12c9b218e18b941578bc9aca3c23747e42f54c1b" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="dea2aede79f19fb95e5148ee5c11b3c7f223323a" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="6bc3b4bf10642b79be6b77851a23e142b0ca36cf" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.SVC&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.SVC&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="c4dcb2fd7042cd90b5cd989b10ea50e9efa48d50" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.SVR&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.SVR&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="2a2669f574a679afac893b53b03bdb1bd3060d05" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.svm.l1_min_c&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="15e7f4eb0d23fc3ecea22ca0e3a3ebdefcef3322" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.DecisionTreeClassifier&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.tree.DecisionTreeClassifier&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="65c5a0a1817f47dc4a24c72d932486e31f108484" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.DecisionTreeRegressor&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.tree.DecisionTreeRegressor&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="607ad6107d22cda5b789ada19b3e439fe3038b27" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.tree.plot_tree&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.tree.plot_tree&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="5b4d8799f6ce5100bf207b65e66619307f668cac" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.Bunch&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.Bunch&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="668a018e39621dfc09781d5e1a018ed078089b72" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.Memory&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.Memory&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="7213df901109f2c1652eb65fa0f35fe0ff18cd9d" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.check_random_state&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.check_random_state&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="e9dab354869145a323333bb1a6f4abfc5f1cb7b1" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.estimator_checks.parametrize_with_checks&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.estimator_checks.parametrize_with_checks&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="2865372d64705a746f4e393e76c01c0a1fae3b37" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.extmath.density&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.extmath.density&lt;/code&gt; の使用例</target>
        </trans-unit>
        <trans-unit id="da99fb3fb0ad21b853976b89d77d08cdf2ec4f84" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.gen_even_slices&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.gen_even_slices&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="851edad00347cd3937bd7ea24424c348d471aca4" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.metaestimators.if_delegate_has_method&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.metaestimators.if_delegate_has_method&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="08628ee68b552a536a7e40670b9091a9987d81dc" translate="yes" xml:space="preserve">
          <source>Examples using &lt;code&gt;sklearn.utils.shuffle&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;sklearn.utils.shuffle&lt;/code&gt; を使用した例</target>
        </trans-unit>
        <trans-unit id="fb3447b632f6a431215776dcf254a01001a40c4f" translate="yes" xml:space="preserve">
          <source>Examples:</source>
          <target state="translated">Examples:</target>
        </trans-unit>
        <trans-unit id="2c25bc9aea0135b8a44078eaa686262d861b8d2c" translate="yes" xml:space="preserve">
          <source>Exception class to raise if estimator is used before fitting.</source>
          <target state="translated">フィッティングの前に estimator が使用されている場合に発生する例外クラス。</target>
        </trans-unit>
        <trans-unit id="7233f2cfa7da608e08349effe3a0829359d064c0" translate="yes" xml:space="preserve">
          <source>Exception.with_traceback(tb) &amp;ndash; set self.__traceback__ to tb and return self.</source>
          <target state="translated">Exception.with_traceback（tb）&amp;ndash; self .__ traceback__をtbに設定してselfを返します。</target>
        </trans-unit>
        <trans-unit id="adb63819e55094a1c321051667ef69bc97910b3c" translate="yes" xml:space="preserve">
          <source>Exercise 1: Language identification</source>
          <target state="translated">演習1:言語の識別</target>
        </trans-unit>
        <trans-unit id="f2d31e2f590f63884cdac3b6e0353c56e95636fd" translate="yes" xml:space="preserve">
          <source>Exercise 2: Sentiment Analysis on movie reviews</source>
          <target state="translated">演習2:映画レビューのセンチメント分析</target>
        </trans-unit>
        <trans-unit id="f076754d245dfa0bb055ce293bbe18bfa8d62689" translate="yes" xml:space="preserve">
          <source>Exercise 3: CLI text classification utility</source>
          <target state="translated">演習3:CLIテキスト分類ユーティリティ</target>
        </trans-unit>
        <trans-unit id="4dc503dafcf231e8065504c4cd9f19a0dcdfc147" translate="yes" xml:space="preserve">
          <source>Exercises</source>
          <target state="translated">Exercises</target>
        </trans-unit>
        <trans-unit id="9b4e2cce8211934c05426343255dbbe40e6fc29d" translate="yes" xml:space="preserve">
          <source>Exercises for the tutorials</source>
          <target state="translated">チュートリアルの演習</target>
        </trans-unit>
        <trans-unit id="e172501d8e170f5e501dbb7e10f621b359347edb" translate="yes" xml:space="preserve">
          <source>Exhaustive search over specified parameter values for an estimator.</source>
          <target state="translated">推定器の指定されたパラメータ値を網羅的に探索する。</target>
        </trans-unit>
        <trans-unit id="827e74ef83aecac9c6f9fc861a3a010bc5589266" translate="yes" xml:space="preserve">
          <source>Exp-Sine-Squared kernel (aka periodic kernel).</source>
          <target state="translated">Exp-Sine-Squaredカーネル(別名周期カーネル)。</target>
        </trans-unit>
        <trans-unit id="a9607bbaaa4524856cf2140445f92e407ff55546" translate="yes" xml:space="preserve">
          <source>Exp-Sine-Squared kernel.</source>
          <target state="translated">Exp-Sine-Squaredカーネル。</target>
        </trans-unit>
        <trans-unit id="3b0c107b231b7c7d2dd1b666566c6604385763d3" translate="yes" xml:space="preserve">
          <source>Expected results for the top 5 most represented people in the dataset:</source>
          <target state="translated">データセットの中で最も代表的な人の上位5人について期待される結果。</target>
        </trans-unit>
        <trans-unit id="98312dc3857136b93e4f949a4e72a6712170156c" translate="yes" xml:space="preserve">
          <source>Explained variance regression score function</source>
          <target state="translated">説明付き分散回帰スコア関数</target>
        </trans-unit>
        <trans-unit id="31162dbfd1baf8644ae388945633979e4d4b742f" translate="yes" xml:space="preserve">
          <source>Explicit feature map approximation for RBF kernels</source>
          <target state="translated">RBFカーネルのための明示的な特徴マップ近似</target>
        </trans-unit>
        <trans-unit id="2139158fefd69dd7900f572f929357923b2e9c08" translate="yes" xml:space="preserve">
          <source>Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">adamの最初のモーメントベクトルの推定の指数関数的減衰率は、[0、1）である必要があります。solver = 'adam'の場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="3b517f2d5130d355e5abbd42b6b2d0de0b8022fe" translate="yes" xml:space="preserve">
          <source>Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver=&amp;rsquo;adam&amp;rsquo;</source>
          <target state="translated">adamの2次モーメントベクトルの推定の指数関数的減衰率は、[0、1）である必要があります。solver = 'adam'の場合にのみ使用されます</target>
        </trans-unit>
        <trans-unit id="5be074c21803e5b45a92c260ef448b3876757aad" translate="yes" xml:space="preserve">
          <source>Exponential kernel (&lt;code&gt;kernel = 'exponential'&lt;/code&gt;)</source>
          <target state="translated">指数カーネル（ &lt;code&gt;kernel = 'exponential'&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="4e6d09cb3f7c099f340e3cd011063b05dd20e736" translate="yes" xml:space="preserve">
          <source>Exponential loss (&lt;code&gt;'exponential'&lt;/code&gt;): The same loss function as &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt;&lt;code&gt;AdaBoostClassifier&lt;/code&gt;&lt;/a&gt;. Less robust to mislabeled examples than &lt;code&gt;'deviance'&lt;/code&gt;; can only be used for binary classification.</source>
          <target state="translated">指数損失（ &lt;code&gt;'exponential'&lt;/code&gt; ）：&lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt; &lt;code&gt;AdaBoostClassifier&lt;/code&gt; &lt;/a&gt;と同じ損失関数。 &lt;code&gt;'deviance'&lt;/code&gt; よりも、誤ってラベル付けされた例への耐性が低い。バイナリ分類にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="82a5349d4a42ae4b58ce233c1fe754cf20695efd" translate="yes" xml:space="preserve">
          <source>Exponentiate kernel by given exponent.</source>
          <target state="translated">与えられた指数でカーネルを指数化します。</target>
        </trans-unit>
        <trans-unit id="6a1fb392b4816003f7cab8689b69b73b81fd13d1" translate="yes" xml:space="preserve">
          <source>Export a decision tree in DOT format.</source>
          <target state="translated">決定木をDOT形式でエクスポートします。</target>
        </trans-unit>
        <trans-unit id="862ee3b17a826818107e616215cf3c3a954115aa" translate="yes" xml:space="preserve">
          <source>Exposure</source>
          <target state="translated">Exposure</target>
        </trans-unit>
        <trans-unit id="9eb0650b6756b55d46beda1492ea11acfe7e3431" translate="yes" xml:space="preserve">
          <source>Expresses to what extent the local structure is retained.</source>
          <target state="translated">ローカル構造がどの程度保持されているかを表現します。</target>
        </trans-unit>
        <trans-unit id="03b256629a71913d7df02c71e2c067b3de2f6cf2" translate="yes" xml:space="preserve">
          <source>External Resources, Videos and Talks</source>
          <target state="translated">外部リソース、ビデオ、トーク</target>
        </trans-unit>
        <trans-unit id="6a53253fde7542b58764813563b294277a2499e0" translate="yes" xml:space="preserve">
          <source>External Tutorials</source>
          <target state="translated">外部チュートリアル</target>
        </trans-unit>
        <trans-unit id="d29859b915eecd05832dcd65405884b6cc0d4c40" translate="yes" xml:space="preserve">
          <source>Extra keyword arguments will be passed to matplotlib&amp;rsquo;s &lt;code&gt;plot&lt;/code&gt;.</source>
          <target state="translated">追加のキーワード引数がmatplotlibの &lt;code&gt;plot&lt;/code&gt; 渡されます。</target>
        </trans-unit>
        <trans-unit id="8d6114c0a06ffd4fdec489d603f3c2293f085d8e" translate="yes" xml:space="preserve">
          <source>Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the &lt;code&gt;max_features&lt;/code&gt; randomly selected features and the best split among those is chosen. When &lt;code&gt;max_features&lt;/code&gt; is set 1, this amounts to building a totally random decision tree.</source>
          <target state="translated">エクストラツリーは、構築方法が従来の決定木とは異なります。ノードのサンプルを2つのグループに分離するための最良の分割を探すとき、ランダムに選択された各 &lt;code&gt;max_features&lt;/code&gt; に対してランダムな分割が描画され、それらの中から最適な分割が選択されます。 &lt;code&gt;max_features&lt;/code&gt; が1に設定されている場合、これは完全にランダムな決定木を構築することになります。</target>
        </trans-unit>
        <trans-unit id="9955e456c4c0c464fbdd3775651693383fea52c1" translate="yes" xml:space="preserve">
          <source>Extract an ordered array of unique labels</source>
          <target state="translated">ユニークなラベルの順序付き配列を抽出</target>
        </trans-unit>
        <trans-unit id="73640fcc3fc33a24884d5d906a4df64cbbe3523c" translate="yes" xml:space="preserve">
          <source>Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor.</source>
          <target state="translated">生のテ キ ス ト 文書か ら 、 fit に合わせたボキャブラリー、 ま たはコンストラクタに与えられたボキャブラリーを用いて、 トークン カウントを抽出します。</target>
        </trans-unit>
        <trans-unit id="752e876b40a502b1de5591e926917e4bc7914d7e" translate="yes" xml:space="preserve">
          <source>Extracting features from text files</source>
          <target state="translated">テキストファイルから特徴を抽出する</target>
        </trans-unit>
        <trans-unit id="d28d7a25a071634693f533b81722275ae4a2006b" translate="yes" xml:space="preserve">
          <source>Extracting the clusters runs in linear time. Note that this results in &lt;code&gt;labels_&lt;/code&gt; which are close to a &lt;a href=&quot;sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; with similar settings and &lt;code&gt;eps&lt;/code&gt;, only if &lt;code&gt;eps&lt;/code&gt; is close to &lt;code&gt;max_eps&lt;/code&gt;.</source>
          <target state="translated">クラスターの抽出は線形時間で実行されます。これにより、 &lt;code&gt;eps&lt;/code&gt; が &lt;code&gt;max_eps&lt;/code&gt; に近い場合にのみ、同様の設定と &lt;code&gt;eps&lt;/code&gt; を持つ&lt;a href=&quot;sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; に&lt;/a&gt;近い &lt;code&gt;labels_&lt;/code&gt; が生成されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="f1c8b18c9f903ec74b12bbc8b3c4f7151c923f8b" translate="yes" xml:space="preserve">
          <source>Extracts an ordered list of points and reachability distances, and performs initial clustering using &lt;code&gt;max_eps&lt;/code&gt; distance specified at OPTICS object instantiation.</source>
          <target state="translated">ポイントと到達可能距離の順序付きリストを抽出し、OPTICSオブジェクトのインスタンス化で指定された &lt;code&gt;max_eps&lt;/code&gt; 距離を使用して初期クラスタリングを実行します。</target>
        </trans-unit>
        <trans-unit id="4d1d5b7b89c16041c19e08ba2433ff6ccea2c09b" translate="yes" xml:space="preserve">
          <source>Extracts patches from a collection of images</source>
          <target state="translated">画像のコレクションからパッチを抽出</target>
        </trans-unit>
        <trans-unit id="20b1f470ded66ddce46bb1f3957f49e776657ce0" translate="yes" xml:space="preserve">
          <source>F values of features.</source>
          <target state="translated">特徴のF値。</target>
        </trans-unit>
        <trans-unit id="94361d25a9823c7799f46133208e1994c901281f" translate="yes" xml:space="preserve">
          <source>F-beta score of the positive class in binary classification or weighted average of the F-beta score of each class for the multiclass task.</source>
          <target state="translated">2値分類における正のクラスのF-βスコア、またはマルチクラスタスクにおける各クラスのF-βスコアの加重平均。</target>
        </trans-unit>
        <trans-unit id="b88bc0b15f26e6bb0b6f496fb42c5c9bb95eea78" translate="yes" xml:space="preserve">
          <source>F-value between label/feature for regression tasks.</source>
          <target state="translated">回帰タスクのラベル/特徴量間のF値。</target>
        </trans-unit>
        <trans-unit id="3ca92f821d80e2b3e5b34951989fdd6926d62950" translate="yes" xml:space="preserve">
          <source>F1 score of the positive class in binary classification or weighted average of the F1 scores of each class for the multiclass task.</source>
          <target state="translated">2値分類における正のクラスのF1スコア、またはマルチクラスタスクにおける各クラスのF1スコアの加重平均。</target>
        </trans-unit>
        <trans-unit id="03688ba6aa340b87549088aa5739944cb6b1dc73" translate="yes" xml:space="preserve">
          <source>FAQ</source>
          <target state="translated">FAQ</target>
        </trans-unit>
        <trans-unit id="761451a93e0c15b8090688d5167bdaf6518e982d" translate="yes" xml:space="preserve">
          <source>FPR test stands for False Positive Rate test. It controls the total amount of false detections.</source>
          <target state="translated">FPRテストとは、False Positive Rateテストの略です。誤検出の総量をコントロールします。</target>
        </trans-unit>
        <trans-unit id="385b798ea2337dc2cc46e2c01984384fa2b4a883" translate="yes" xml:space="preserve">
          <source>F_beta</source>
          <target state="translated">F_beta</target>
        </trans-unit>
        <trans-unit id="272ad30c6a89ef4d06060249f8d92df03b3df406" translate="yes" xml:space="preserve">
          <source>Face completion with a multi-output estimators</source>
          <target state="translated">多出力推定器を用いた面子補完</target>
        </trans-unit>
        <trans-unit id="0507c7e4982962e832b85d06191a2b4d2bebd20a" translate="yes" xml:space="preserve">
          <source>Face recognition with eigenfaces</source>
          <target state="translated">固有面を用いた顔認識</target>
        </trans-unit>
        <trans-unit id="2a0151d21d57d7f913fb01048c891608a6dbd1dd" translate="yes" xml:space="preserve">
          <source>Face, a 1024 x 768 size image of a raccoon face, is used here to illustrate how &lt;code&gt;k&lt;/code&gt;-means is used for vector quantization.</source>
          <target state="translated">ここでは、アライグマの顔の1024 x 768サイズの画像である顔を使用して、 &lt;code&gt;k&lt;/code&gt; の平均がベクトル量子化にどのように使用されるかを示します。</target>
        </trans-unit>
        <trans-unit id="e470f0e1bd32044d0ac0cbb19036da58e0de1f71" translate="yes" xml:space="preserve">
          <source>Faces dataset decompositions</source>
          <target state="translated">顔のデータセット分解</target>
        </trans-unit>
        <trans-unit id="05a6c8a2b029e9776dffd4a4e031ba78fd52aae9" translate="yes" xml:space="preserve">
          <source>Faces recognition example using eigenfaces and SVMs</source>
          <target state="translated">固有曲面とSVMを用いた顔認識例</target>
        </trans-unit>
        <trans-unit id="1395bbf4ff3a0e8184103b7a1548ed436935fe5c" translate="yes" xml:space="preserve">
          <source>Factor Analysis (FA)</source>
          <target state="translated">因子分析(FA</target>
        </trans-unit>
        <trans-unit id="ef94831c8deb9ad37fe90ab4fff5e44828bcfdae" translate="yes" xml:space="preserve">
          <source>Factor analysis &lt;em&gt;can&lt;/em&gt; produce similar components (the columns of its loading matrix) to &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;. However, one can not make any general statements about these components (e.g. whether they are orthogonal):</source>
          <target state="translated">因子分析&lt;em&gt;は&lt;/em&gt;、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;と同様のコンポーネント（ローディングマトリックスの列）を生成&lt;em&gt;でき&lt;/em&gt;ます。ただし、これらのコンポーネントについての一般的な説明はできません（たとえば、それらが直交しているかどうか）。</target>
        </trans-unit>
        <trans-unit id="d48954e3f19174382e76ae0104e93e844b15de73" translate="yes" xml:space="preserve">
          <source>FactorAnalysis performs a maximum likelihood estimate of the so-called &lt;code&gt;loading&lt;/code&gt; matrix, the transformation of the latent variables to the observed ones, using SVD based approach.</source>
          <target state="translated">FactorAnalysisは、SVDベースのアプローチを使用して、いわゆる &lt;code&gt;loading&lt;/code&gt; 行列の最尤推定、潜在変数から観測変数への変換を実行します。</target>
        </trans-unit>
        <trans-unit id="6452044c700752d1602ef512b59b643cc8ae2400" translate="yes" xml:space="preserve">
          <source>FactorAnalysis performs a maximum likelihood estimate of the so-called &lt;code&gt;loading&lt;/code&gt; matrix, the transformation of the latent variables to the observed ones, using expectation-maximization (EM).</source>
          <target state="translated">FactorAnalysisは、期待値最大化（EM）を使用して、いわゆる &lt;code&gt;loading&lt;/code&gt; マトリックスの最尤推定、潜在変数から観測された変数への変換を実行します。</target>
        </trans-unit>
        <trans-unit id="cf3867c5acb3e93b6681ae294efcb69608ed1285" translate="yes" xml:space="preserve">
          <source>Factorization matrix, sometimes called &amp;lsquo;dictionary&amp;rsquo;.</source>
          <target state="translated">時々「辞書」と呼ばれる因数分解行列。</target>
        </trans-unit>
        <trans-unit id="c37fb3c7cf083e46f6a90c90a7e2709ff0a25468" translate="yes" xml:space="preserve">
          <source>False : never precompute distances</source>
          <target state="translated">False:距離を事前に計算しない</target>
        </trans-unit>
        <trans-unit id="4031377a355ac026bbc01c0a8c66abf927d5347f" translate="yes" xml:space="preserve">
          <source>False : never precompute distances.</source>
          <target state="translated">False:距離を事前に計算しない。</target>
        </trans-unit>
        <trans-unit id="9f59f0377a675667ec374342cc81b9550d388560" translate="yes" xml:space="preserve">
          <source>False positive rate.</source>
          <target state="translated">偽陽性率。</target>
        </trans-unit>
        <trans-unit id="25cefd866e6e705dad47ce327a0915fc7b301c18" translate="yes" xml:space="preserve">
          <source>False when &lt;code&gt;y&lt;/code&gt;&amp;rsquo;s shape is (n_samples, ) or (n_samples, 1) during fit otherwise True.</source>
          <target state="translated">フィット中に &lt;code&gt;y&lt;/code&gt; の形状が（n_samples、）または（n_samples、1）の場合はFalse、それ以外の場合はTrue。</target>
        </trans-unit>
        <trans-unit id="3b5c093eaf163ad057d3c3eb085ce8a982ff3356" translate="yes" xml:space="preserve">
          <source>False: accept both np.inf and np.nan in X.</source>
          <target state="translated">誤り:Xではnp.infとnp.nanの両方を受け入れます。</target>
        </trans-unit>
        <trans-unit id="e8392e19182108180157ea67d85038a25937bf1d" translate="yes" xml:space="preserve">
          <source>False: accepts np.inf, np.nan, pd.NA in X.</source>
          <target state="translated">False:Xでnp.inf,np.nan,pd.NAを受け付ける。</target>
        </trans-unit>
        <trans-unit id="ed9971d141108d2bfea275398777be51a58308ae" translate="yes" xml:space="preserve">
          <source>False: accepts np.inf, np.nan, pd.NA in array.</source>
          <target state="translated">False:np.inf,np.nan,pd.NAを配列で受け付けます。</target>
        </trans-unit>
        <trans-unit id="804378d4f4edbfd6d3a924fd7282c07b3c8233b0" translate="yes" xml:space="preserve">
          <source>False: the results is casted to a signed int</source>
          <target state="translated">False:結果は符号付き整数にキャストされます。</target>
        </trans-unit>
        <trans-unit id="b73e8a734794b535117e86ab6a6ba9f9a65b9a31" translate="yes" xml:space="preserve">
          <source>Fan, Rong-En, et al., &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf&quot;&gt;&amp;ldquo;LIBLINEAR: A library for large linear classification.&amp;rdquo;&lt;/a&gt;, Journal of machine learning research 9.Aug (2008): 1871-1874.</source>
          <target state="translated">Fan, Rong-En, et al., &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf&quot;&gt;&amp;ldquo;LIBLINEAR: A library for large linear classification.&amp;rdquo;&lt;/a&gt;, Journal of machine learning research 9.Aug (2008): 1871-1874.</target>
        </trans-unit>
        <trans-unit id="c87c316f44a57817f64366d0bec154e1f9523fd3" translate="yes" xml:space="preserve">
          <source>Fancy token-level analysis such as stemming, lemmatizing, compound splitting, filtering based on part-of-speech, etc. are not included in the scikit-learn codebase, but can be added by customizing either the tokenizer or the analyzer. Here&amp;rsquo;s a &lt;code&gt;CountVectorizer&lt;/code&gt; with a tokenizer and lemmatizer using &lt;a href=&quot;http://www.nltk.org&quot;&gt;NLTK&lt;/a&gt;:</source>
          <target state="translated">ステミング、見出し語化、複合分割、品詞に基づくフィルタリングなどの豪華なトークンレベルの分析は、scikit-learnコードベースには含まれていませんが、トークナイザーまたはアナライザーをカスタマイズすることで追加できます。ここだ &lt;code&gt;CountVectorizer&lt;/code&gt; 使用トークナイザとlemmatizerと&lt;a href=&quot;http://www.nltk.org&quot;&gt;NLTKは&lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="47db1ac61ed9cca1bf16f757f65fe37b19da02d2" translate="yes" xml:space="preserve">
          <source>Fancy token-level analysis such as stemming, lemmatizing, compound splitting, filtering based on part-of-speech, etc. are not included in the scikit-learn codebase, but can be added by customizing either the tokenizer or the analyzer. Here&amp;rsquo;s a &lt;code&gt;CountVectorizer&lt;/code&gt; with a tokenizer and lemmatizer using &lt;a href=&quot;https://www.nltk.org/&quot;&gt;NLTK&lt;/a&gt;:</source>
          <target state="translated">ステミング、字句解析、複合分割、品詞に基づくフィルタリングなどの高度なトークンレベルの分析は、scikit-learnコードベースには含まれていませんが、トークナイザーまたはアナライザーをカスタマイズすることで追加できます。ここだ &lt;code&gt;CountVectorizer&lt;/code&gt; 使用トークナイザとlemmatizerと&lt;a href=&quot;https://www.nltk.org/&quot;&gt;NLTKは&lt;/a&gt;：</target>
        </trans-unit>
        <trans-unit id="000599c940f606b6105f7d1916791a94094aca12" translate="yes" xml:space="preserve">
          <source>Fast computation of nearest neighbors is an active area of research in machine learning. The most naive neighbor search implementation involves the brute-force computation of distances between all pairs of points in the dataset: for \(N\) samples in \(D\) dimensions, this approach scales as \(O[D N^2]\). Efficient brute-force neighbors searches can be very competitive for small data samples. However, as the number of samples \(N\) grows, the brute-force approach quickly becomes infeasible. In the classes within &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt;, brute-force neighbors searches are specified using the keyword &lt;code&gt;algorithm = 'brute'&lt;/code&gt;, and are computed using the routines available in &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">最近傍の高速計算は、機械学習の研究の活発な分野です。最も単純な近傍検索の実装には、データセット内のすべてのポイントペア間の距離の総当たり計算が含まれます。\（D \）次元の\（N \）サンプルの場合、このアプローチは\（O [DN ^ 2]としてスケーリングされます。 \）。効率的なブルートフォースネイバー検索は、小さなデータサンプルに対して非常に競争力があります。ただし、サンプル数\（N \）が増えると、ブルートフォースアプローチはすぐに実行不可能になります。&lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt;内のクラスでは、ブルートフォースネイバー検索はキーワード &lt;code&gt;algorithm = 'brute'&lt;/code&gt; を使用して指定され、&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; で&lt;/a&gt;使用可能なルーチンを使用して計算されます。</target>
        </trans-unit>
        <trans-unit id="2e91ff193b9320036698a113daf46d8118a44e7d" translate="yes" xml:space="preserve">
          <source>FastICA on 2D point clouds</source>
          <target state="translated">2次元点群上のFastICA</target>
        </trans-unit>
        <trans-unit id="6921319b009c74978f9e5104f25e9063c7cf2c6b" translate="yes" xml:space="preserve">
          <source>FastICA: a fast algorithm for Independent Component Analysis.</source>
          <target state="translated">FastICA:独立成分分析のための高速アルゴリズム。</target>
        </trans-unit>
        <trans-unit id="c2070bedc34b06cdbf740c2fed5e122d3efb93a7" translate="yes" xml:space="preserve">
          <source>Faster for large datasets</source>
          <target state="translated">大規模データセットの高速化</target>
        </trans-unit>
        <trans-unit id="6fa15d231f996464c9e743e456c3d6855ab0d8f6" translate="yes" xml:space="preserve">
          <source>Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition Letters, 2006, 27(8):861-874.</source>
          <target state="translated">Fawcett T.ROC分析入門[日].パターン認識レターズ,2006,27(8):861-874.</target>
        </trans-unit>
        <trans-unit id="0724b7da2e7893e2aa61b560332f137d5b0c3174" translate="yes" xml:space="preserve">
          <source>Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874.</source>
          <target state="translated">Fawcett,T.(2006).ROC分析の入門編。パターン認識レターズ,27(8),861-874.</target>
        </trans-unit>
        <trans-unit id="e6d44f9610f58495afc33ead5474258ef3212417" translate="yes" xml:space="preserve">
          <source>Fawcett, T., 2001. &lt;a href=&quot;http://ieeexplore.ieee.org/document/989510/&quot;&gt;Using rule sets to maximize ROC performance&lt;/a&gt; In Data Mining, 2001. Proceedings IEEE International Conference, pp. 131-138.</source>
          <target state="translated">Fawcett、T.、2001。&lt;a href=&quot;http://ieeexplore.ieee.org/document/989510/&quot;&gt;ルールセットを使用してROCパフォーマンスを最大化する&lt;/a&gt;In Data Mining、2001。Proceedings IEEE International Conference、pp.131-138。</target>
        </trans-unit>
        <trans-unit id="777dc3527e71dea0036f160bc11c11f47afad8e4" translate="yes" xml:space="preserve">
          <source>Fawcett, T., 2006. &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S016786550500303X&quot;&gt;An introduction to ROC analysis.&lt;/a&gt; Pattern Recognition Letters, 27(8), pp. 861-874.</source>
          <target state="translated">Fawcett、T.、2006年&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S016786550500303X&quot;&gt;。ROC分析の概要。&lt;/a&gt;パターン認識レター、27（8）、861-874ページ。</target>
        </trans-unit>
        <trans-unit id="77834b29664ccb5e5cc9173718797e7ec674b1ed" translate="yes" xml:space="preserve">
          <source>Feature 0 (median income in a block) and feature 5 (number of households) of the &lt;a href=&quot;http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;California housing dataset&lt;/a&gt; have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.</source>
          <target state="translated">&lt;a href=&quot;http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;カリフォルニアの住宅データセットの&lt;/a&gt;特徴0（ブロック内の収入の中央値）と特徴5（世帯数）のスケールは非常に異なり、非常に大きな外れ値が含まれています。これら2つの特性は、データの視覚化を困難にし、さらに重要なことに、多くの機械学習アルゴリズムの予測パフォーマンスを低下させる可能性があります。スケーリングされていないデータは、多くの勾配ベースの推定量の収束を遅くしたり、阻止したりすることもできます。</target>
        </trans-unit>
        <trans-unit id="d43b2b4b53fe06f630d6e6fea5ae39ec97ef2464" translate="yes" xml:space="preserve">
          <source>Feature 0 (median income in a block) and feature 5 (number of households) of the &lt;a href=&quot;https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;California housing dataset&lt;/a&gt; have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.</source>
          <target state="translated">&lt;a href=&quot;https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html&quot;&gt;カリフォルニアの住宅データセットの&lt;/a&gt;特徴0（ブロック内の収入の中央値）と特徴5（世帯数）は、スケールが大きく異なり、非常に大きな外れ値が含まれています。これらの2つの特性は、データの視覚化を困難にし、さらに重要なことに、多くの機械学習アルゴリズムの予測パフォーマンスを低下させる可能性があります。スケーリングされていないデータは、多くの勾配ベースの推定量の収束を遅くしたり、妨げたりする可能性もあります。</target>
        </trans-unit>
        <trans-unit id="1e2bfc0d574ebb3c0866208d70d9a4defc9229e8" translate="yes" xml:space="preserve">
          <source>Feature Selection</source>
          <target state="translated">機能選択</target>
        </trans-unit>
        <trans-unit id="3290cbe981e79caf9ab6f89a8812507aa114a727" translate="yes" xml:space="preserve">
          <source>Feature agglomeration</source>
          <target state="translated">特徴的な凝集</target>
        </trans-unit>
        <trans-unit id="81f8ec148b187c97182bf2c56b5ce15909bcbae4" translate="yes" xml:space="preserve">
          <source>Feature agglomeration vs. univariate selection</source>
          <target state="translated">特徴の凝集 vs 一変量選択</target>
        </trans-unit>
        <trans-unit id="49e1dcf68a4912e92e5e7f68710255b3ca05471e" translate="yes" xml:space="preserve">
          <source>Feature discretization</source>
          <target state="translated">特徴の離散化</target>
        </trans-unit>
        <trans-unit id="3c43171269f5f432d869bba89f82c3b54ca0debf" translate="yes" xml:space="preserve">
          <source>Feature extraction</source>
          <target state="translated">特徴抽出</target>
        </trans-unit>
        <trans-unit id="df5954aef1e3ea02a4e2fe61d1e0e10b9f726b5a" translate="yes" xml:space="preserve">
          <source>Feature extraction and normalization.</source>
          <target state="translated">特徴抽出と正規化</target>
        </trans-unit>
        <trans-unit id="aedfee8f7e4b62695a0b89930709eed1e654b00f" translate="yes" xml:space="preserve">
          <source>Feature extraction is very different from &lt;a href=&quot;feature_selection#feature-selection&quot;&gt;Feature selection&lt;/a&gt;: the former consists in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. The latter is a machine learning technique applied on these features.</source>
          <target state="translated">特徴抽出は、&lt;a href=&quot;feature_selection#feature-selection&quot;&gt;特徴選択&lt;/a&gt;とは大きく異なります。前者は、テキストや画像などの任意のデータを機械学習に使用できる数値特徴に変換することです。後者は、これらの機能に適用される機械学習手法です。</target>
        </trans-unit>
        <trans-unit id="4c3a870a4e311a31f848b5314c8f3949d8e31e78" translate="yes" xml:space="preserve">
          <source>Feature hashing can be employed in document classification, but unlike &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;text.CountVectorizer&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt;&lt;code&gt;FeatureHasher&lt;/code&gt;&lt;/a&gt; does not do word splitting or any other preprocessing except Unicode-to-UTF-8 encoding; see &lt;a href=&quot;#hashing-vectorizer&quot;&gt;Vectorizing a large text corpus with the hashing trick&lt;/a&gt;, below, for a combined tokenizer/hasher.</source>
          <target state="translated">機能ハッシュはドキュメント分類で使用できますが、&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;text.CountVectorizer&lt;/code&gt; &lt;/a&gt;とは異なり、&lt;a href=&quot;generated/sklearn.feature_extraction.featurehasher#sklearn.feature_extraction.FeatureHasher&quot;&gt; &lt;code&gt;FeatureHasher&lt;/code&gt; &lt;/a&gt;は単語分割や、UnicodeからUTF-8へのエンコード以外の前処理を行いません。トークナイザーとハッシャーの組み合わせについては、以下&lt;a href=&quot;#hashing-vectorizer&quot;&gt;のハッシュトリックを使用した大きなテキストコーパスのベクトル化を&lt;/a&gt;ご覧ください。</target>
        </trans-unit>
        <trans-unit id="7bb8776f4e73559816ad10cf154be669f7df47cf" translate="yes" xml:space="preserve">
          <source>Feature importances with forests of trees</source>
          <target state="translated">木の森のある輸入品特集</target>
        </trans-unit>
        <trans-unit id="561e2555a0c1659bb31a6148c1abe250489ca708" translate="yes" xml:space="preserve">
          <source>Feature mappings for the samples in X.</source>
          <target state="translated">Xのサンプルのフィーチャーマッピング。</target>
        </trans-unit>
        <trans-unit id="b96ff43d78f2a1f5a4e1d891c2cc36e4c380c32b" translate="yes" xml:space="preserve">
          <source>Feature matrix, for use with estimators or further transformers.</source>
          <target state="translated">特徴行列,推定器または更なる変換器で使用するためのもの.</target>
        </trans-unit>
        <trans-unit id="66d052b121f901629f4ce88124bd7cb2635fe497" translate="yes" xml:space="preserve">
          <source>Feature matrix.</source>
          <target state="translated">特徴的な行列。</target>
        </trans-unit>
        <trans-unit id="c4587a739696f602e34f3bba74d9106ccf3fff49" translate="yes" xml:space="preserve">
          <source>Feature names corresponding to the indices in &lt;code&gt;features&lt;/code&gt;.</source>
          <target state="translated">内のインデックスに対応する機能名 &lt;code&gt;features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="975d25794ea94f600d607356398714d33388d870" translate="yes" xml:space="preserve">
          <source>Feature names of type byte string are used as-is. Unicode strings are converted to UTF-8 first, but no Unicode normalization is done. Feature values must be (finite) numbers.</source>
          <target state="translated">バイト文字列型のフィーチャ名はそのまま使用します。Unicode文字列はまずUTF-8に変換されますが、Unicode正規化は行われません。フィーチャーの値は(有限の)数値でなければなりません。</target>
        </trans-unit>
        <trans-unit id="9509bbe5f8817e2ca0562d6baac6f0ad1787e1d6" translate="yes" xml:space="preserve">
          <source>Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.</source>
          <target state="translated">再帰的特徴除去とクロスバリデートによる最適な特徴数の選択による特徴ランキング。</target>
        </trans-unit>
        <trans-unit id="f706081a8ad25e74e9a88b9e19a48d5a46a52012" translate="yes" xml:space="preserve">
          <source>Feature ranking with recursive feature elimination.</source>
          <target state="translated">再帰的特徴除去を用いた特徴ランキング</target>
        </trans-unit>
        <trans-unit id="7f17a87c5de04e39e04129e9c0737edfeafaee92" translate="yes" xml:space="preserve">
          <source>Feature scaling through standardization (or Z-score normalization) can be an important preprocessing step for many machine learning algorithms. Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.</source>
          <target state="translated">標準化(またはZスコア正規化)による特徴のスケーリングは、多くの機械学習アルゴリズムにとって重要な前処理ステップとなります。標準化は,平均が0で標準偏差が1の標準正規分布の特性を持つように,特徴を再スケーリングすることを含む.</target>
        </trans-unit>
        <trans-unit id="3ac99400fe4169f40a977ea7007419c98db61771" translate="yes" xml:space="preserve">
          <source>Feature scores between 0 and 1 for all values of the regularization parameter. The reference article suggests &lt;code&gt;scores_&lt;/code&gt; is the max of &lt;code&gt;all_scores_&lt;/code&gt;.</source>
          <target state="translated">正則化パラメーターのすべての値の0と1の間の機能スコア。参考記事は、 &lt;code&gt;scores_&lt;/code&gt; がall_scores_の最大値であることを &lt;code&gt;all_scores_&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="aa75d746547685bebfdc2a7e366361e478fa27f0" translate="yes" xml:space="preserve">
          <source>Feature scores between 0 and 1.</source>
          <target state="translated">フィーチャースコアは0~1の間。</target>
        </trans-unit>
        <trans-unit id="afb880f1a910829f871ab84d5509ba79bf00b111" translate="yes" xml:space="preserve">
          <source>Feature selection is usually used as a pre-processing step before doing the actual learning. The recommended way to do this in scikit-learn is to use a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">特徴選択は通常、実際の学習を行う前の前処理ステップとして使用されます。scikit-learnでこれを行うための推奨される方法は、&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;を使用することです。</target>
        </trans-unit>
        <trans-unit id="5a515063a6bfb2324e04a5cb7dd1fe0bf9c9b6c2" translate="yes" xml:space="preserve">
          <source>Feature selection mode.</source>
          <target state="translated">フィーチャー選択モード。</target>
        </trans-unit>
        <trans-unit id="c9b5854c848ad0aec62ba5b490b140e3c7a1bb7d" translate="yes" xml:space="preserve">
          <source>Feature selection using SelectFromModel and LassoCV</source>
          <target state="translated">SelectFromModelとLassoCVによる特徴選択</target>
        </trans-unit>
        <trans-unit id="d13bfd588897e09202c5ea9fa5c11da3f65c72ad" translate="yes" xml:space="preserve">
          <source>Feature selection with sparse data</source>
          <target state="translated">疎なデータを用いた特徴選択</target>
        </trans-unit>
        <trans-unit id="8a9e4457b64c8313be96ab86a00a0aa32201d58b" translate="yes" xml:space="preserve">
          <source>Feature selector that removes all low-variance features.</source>
          <target state="translated">すべての低分散フィーチャを削除するフィーチャセレクタ。</target>
        </trans-unit>
        <trans-unit id="e1b0ac4f2f2d7f5b2a31bb18d47b68f8979e7db4" translate="yes" xml:space="preserve">
          <source>Feature transformations with ensembles of trees</source>
          <target state="translated">木のアンサンブルを用いた特徴変換</target>
        </trans-unit>
        <trans-unit id="9a6ded29908e935164e678c6c6abd840802b0c72" translate="yes" xml:space="preserve">
          <source>Feature values below or equal to this are replaced by 0, above it by 1. Threshold may not be less than 0 for operations on sparse matrices.</source>
          <target state="translated">これ以下の特徴量は 0 に,それ以上の特徴量は 1 に置き換えられます.疎な行列に対する演算では,しきい値は 0 以下にしてはいけません.</target>
        </trans-unit>
        <trans-unit id="0bf4742e81f7f65623aaef302013934b401b3eb5" translate="yes" xml:space="preserve">
          <source>Feature values in training data (also required for prediction)</source>
          <target state="translated">学習データの特徴量(予測にも必要</target>
        </trans-unit>
        <trans-unit id="3252ec9f22752fab5d0e2a9197cc3c5847a58e00" translate="yes" xml:space="preserve">
          <source>Feature vectors or other representations of training data (also required for prediction).</source>
          <target state="translated">特徴ベクトルまたは訓練データの他の表現(予測にも必要)。</target>
        </trans-unit>
        <trans-unit id="1ed37149ccf99f3ffe537e50f5c181c973cd258e" translate="yes" xml:space="preserve">
          <source>Feature vectors or other representations of training data.</source>
          <target state="translated">学習データの特徴ベクトルまたは他の表現。</target>
        </trans-unit>
        <trans-unit id="b7599b9ef6a2c582b4507f1b87929e181ce07276" translate="yes" xml:space="preserve">
          <source>Feature vectors; always 2-d.</source>
          <target state="translated">特徴ベクトル;常に2次元.</target>
        </trans-unit>
        <trans-unit id="8425332e36244b1448079ae72c3edeebff1ff3df" translate="yes" xml:space="preserve">
          <source>Feature-wise means</source>
          <target state="translated">フィーチャーワイズとは</target>
        </trans-unit>
        <trans-unit id="4dfce3abcd43918524b8cd8b96300d3efd01d1fb" translate="yes" xml:space="preserve">
          <source>Feature-wise transformation of the data.</source>
          <target state="translated">データの特徴に応じた変換</target>
        </trans-unit>
        <trans-unit id="5ce13d491431cc736ca395a68aa77c25024d518b" translate="yes" xml:space="preserve">
          <source>Feature-wise variances</source>
          <target state="translated">特徴による差異</target>
        </trans-unit>
        <trans-unit id="8c7ad0b456fa9bf3ae09e270340fb831f15c3f18" translate="yes" xml:space="preserve">
          <source>FeatureHasher and DictVectorizer Comparison</source>
          <target state="translated">FeatureHasherとDictVectorizerの比較</target>
        </trans-unit>
        <trans-unit id="fc338f87a058158eb824b53705961801516a9460" translate="yes" xml:space="preserve">
          <source>Features</source>
          <target state="translated">Features</target>
        </trans-unit>
        <trans-unit id="7b144c2dee4c701c6fc61ec2c427f38a9b6c6529" translate="yes" xml:space="preserve">
          <source>Features 1 and 2 of the diabetes-dataset are fitted and plotted below. It illustrates that although feature 2 has a strong coefficient on the full model, it does not give us much regarding &lt;code&gt;y&lt;/code&gt; when compared to just feature 1</source>
          <target state="translated">糖尿病データセットの特徴1と2は、下にフィッティングされてプロットされています。これは、特徴2が完全なモデルで強い係数を持っているが、特徴1だけと比較した場合、 &lt;code&gt;y&lt;/code&gt; に関して多くを与えないことを示しています。</target>
        </trans-unit>
        <trans-unit id="27bf161ea6af475b73d710eebe7f66e368f22dbd" translate="yes" xml:space="preserve">
          <source>Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.</source>
          <target state="translated">特徴は、乳房腫瘤の細針吸引(FNA)のデジタル化された画像から計算されます。それらは、画像に存在する細胞核の特徴を記述します。</target>
        </trans-unit>
        <trans-unit id="7dc73780307913b147af45ec74f5c7491dc77d15" translate="yes" xml:space="preserve">
          <source>Features got by optimizing the Huber loss.</source>
          <target state="translated">フーバーの損失を最適化することで得られた機能。</target>
        </trans-unit>
        <trans-unit id="0a06ba45f44f1716120206612e20d59fa0c2d9b4" translate="yes" xml:space="preserve">
          <source>Features that are deemed of &lt;strong&gt;low importance for a bad model&lt;/strong&gt; (low cross-validation score) could be &lt;strong&gt;very important for a good model&lt;/strong&gt;. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but &lt;strong&gt;how important this feature is for a particular model&lt;/strong&gt;.</source>
          <target state="translated">&lt;strong&gt;悪いモデルでは重要性&lt;/strong&gt;が&lt;strong&gt;低い&lt;/strong&gt;（相互検証スコアが&lt;strong&gt;低い）&lt;/strong&gt;と見なされる機能&lt;strong&gt;は、良いモデルでは非常に重要である&lt;/strong&gt;可能性があります。したがって、重要度を計算する前に、保持されたセットを使用して（または、交差検定を使用するとより適切に）モデルの予測力を評価することが常に重要です。順列の重要性は、機能自体の固有の予測値には反映されませんが、&lt;strong&gt;この機能が特定のモデルにとってどれほど重要であるかを&lt;/strong&gt;反映します。</target>
        </trans-unit>
        <trans-unit id="285c7b098890786c959265d1fe4e4933df08392b" translate="yes" xml:space="preserve">
          <source>Features that do not occur in a sample (mapping) will have a zero value in the resulting array/matrix.</source>
          <target state="translated">サンプル(マッピング)に存在しないフィーチャは,結果として得られる配列/行列の値が0になります.</target>
        </trans-unit>
        <trans-unit id="e9ec5e9ca7278a6df71a586ca47e81c93d4d7336" translate="yes" xml:space="preserve">
          <source>Features which contain all missing values at &lt;code&gt;fit&lt;/code&gt; are discarded upon &lt;code&gt;transform&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; 時にすべての欠落値を含むフィーチャは、 &lt;code&gt;transform&lt;/code&gt; 時に破棄されます。</target>
        </trans-unit>
        <trans-unit id="71724a67f7aa53e34d06b737e24512de12116bad" translate="yes" xml:space="preserve">
          <source>Features with a training-set variance lower than this threshold will be removed. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples.</source>
          <target state="translated">このしきい値よりも低いトレーニングセットの分散を持つ特徴量は削除されます。デフォルトでは,分散が0ではないすべての特徴量を保持します.</target>
        </trans-unit>
        <trans-unit id="c6023b69815535fce0c52cfebfa0b836b623efcf" translate="yes" xml:space="preserve">
          <source>Ferri, C&amp;egrave;sar &amp;amp; Hernandez-Orallo, Jose &amp;amp; Modroiu, R. (2009). &lt;a href=&quot;https://www.math.ucdavis.edu/~saito/data/roc/ferri-class-perf-metrics.pdf&quot;&gt;An Experimental Comparison of Performance Measures for Classification.&lt;/a&gt; Pattern Recognition Letters. 30. 27-38.</source>
          <target state="translated">Ferri、C&amp;egrave;sar＆Hernandez-Orallo、Jose＆Modroiu、R。（2009）&lt;a href=&quot;https://www.math.ucdavis.edu/~saito/data/roc/ferri-class-perf-metrics.pdf&quot;&gt;分類のためのパフォーマンス測定の実験的比較。&lt;/a&gt;パターン認識レター。30.27-38。</target>
        </trans-unit>
        <trans-unit id="7609c48291c2fa7cc57f1dc4a85a3683c0749b4f" translate="yes" xml:space="preserve">
          <source>Fetch an mldata.org data set</source>
          <target state="translated">mldata.org データセットの取得</target>
        </trans-unit>
        <trans-unit id="2b29d907c2ea7e85ef894ade96f5a9788aa198c9" translate="yes" xml:space="preserve">
          <source>Fetch dataset from openml by name or dataset id.</source>
          <target state="translated">openmlから名前またはデータセットIDでデータセットを取得します。</target>
        </trans-unit>
        <trans-unit id="76c8d1e0086c4e650fc514d650a93664c1ba4aa6" translate="yes" xml:space="preserve">
          <source>Fevotte, C., &amp;amp; Idier, J. (2011). Algorithms for nonnegative matrix factorization with the beta-divergence. Neural Computation, 23(9).</source>
          <target state="translated">Fevotte、C.＆Idier、J.（2011）。ベータダイバージェンスを使用した非負の行列因数分解のアルゴリズム。神経計算、23（9）。</target>
        </trans-unit>
        <trans-unit id="07da69c9120fa48d1a8831ddfdb2e22d5f38a14c" translate="yes" xml:space="preserve">
          <source>Few clusters, even cluster size, non-flat geometry</source>
          <target state="translated">クラスター数が少ない、クラスターサイズでもフラットではない形状</target>
        </trans-unit>
        <trans-unit id="ba82bf0fe9bdb74f2de9056ff08a208a0201f2e5" translate="yes" xml:space="preserve">
          <source>Field &lt;code&gt;support_vectors_&lt;/code&gt; is now empty, only indices of support vectors are stored in &lt;code&gt;support_&lt;/code&gt;</source>
          <target state="translated">フィールド &lt;code&gt;support_vectors_&lt;/code&gt; は空になり、サポートベクトルのインデックスのみが &lt;code&gt;support_&lt;/code&gt; に格納されます</target>
        </trans-unit>
        <trans-unit id="e6b7eea98ef60c86409d4e4dd54b3796ed56341b" translate="yes" xml:space="preserve">
          <source>Figure containing partial dependence plots.</source>
          <target state="translated">部分依存性プロットを含む図。</target>
        </trans-unit>
        <trans-unit id="bf29ad109219929951ed38da3e672e781ba3fade" translate="yes" xml:space="preserve">
          <source>Figure containing the confusion matrix.</source>
          <target state="translated">混乱マトリックスを含む図。</target>
        </trans-unit>
        <trans-unit id="65bafae58e0d2ce7524ef55e10fcc5ed53a13aa4" translate="yes" xml:space="preserve">
          <source>Figure containing the curve.</source>
          <target state="translated">曲線を含む図。</target>
        </trans-unit>
        <trans-unit id="63c41242bc3de30c7fa64bf90cc3aa34e5d08243" translate="yes" xml:space="preserve">
          <source>Filter: Select the p-values corresponding to Family-wise error rate</source>
          <target state="translated">フィルタを選択します。家族単位の誤差率に対応するp値を選択します。</target>
        </trans-unit>
        <trans-unit id="d601967c960c718fae8a27ae10382e904525e519" translate="yes" xml:space="preserve">
          <source>Filter: Select the p-values for an estimated false discovery rate</source>
          <target state="translated">フィルタ。推定誤発見率のp値を選択する</target>
        </trans-unit>
        <trans-unit id="f9d7c51c4e21ffa778934e88c4ada6f78e753e59" translate="yes" xml:space="preserve">
          <source>Filter: Select the pvalues below alpha based on a FPR test.</source>
          <target state="translated">フィルタです。FPRテストに基づいてアルファ以下のp値を選択します。</target>
        </trans-unit>
        <trans-unit id="fa74263b1f44e0e368feef4eccc429e274602a1d" translate="yes" xml:space="preserve">
          <source>Final perplexity score on training set.</source>
          <target state="translated">訓練セットの最終的な錯乱度スコア。</target>
        </trans-unit>
        <trans-unit id="e832a73dedeb0259ac793f9ac425f8e8ee172602" translate="yes" xml:space="preserve">
          <source>Finally it is possible to discover the main topics of a corpus by relaxing the hard assignment constraint of clustering, for instance by using &lt;a href=&quot;decomposition#nmf&quot;&gt;Non-negative matrix factorization (NMF or NNMF)&lt;/a&gt;:</source>
          <target state="translated">最後に、たとえば&lt;a href=&quot;decomposition#nmf&quot;&gt;非負行列因数分解（NMFまたはNNMF）&lt;/a&gt;を使用して、クラスタリングのハード割り当て制約を緩和することにより、コーパスの主要なトピックを発見することが可能です。</target>
        </trans-unit>
        <trans-unit id="3879f3b348e8db024fb12750b7a6d38d6bbf41c3" translate="yes" xml:space="preserve">
          <source>Finally one can also observe that for some intermediate values of &lt;code&gt;gamma&lt;/code&gt; we get equally performing models when &lt;code&gt;C&lt;/code&gt; becomes very large: it is not necessary to regularize by enforcing a larger margin. The radius of the RBF kernel alone acts as a good structural regularizer. In practice though it might still be interesting to simplify the decision function with a lower value of &lt;code&gt;C&lt;/code&gt; so as to favor models that use less memory and that are faster to predict.</source>
          <target state="translated">最後に、 &lt;code&gt;C&lt;/code&gt; が非常に大きくなったときに、 &lt;code&gt;gamma&lt;/code&gt; いくつかの中間値についても同等に機能するモデルが得られることを確認できます。より大きなマージンを適用して正則化する必要はありません。RBFカーネルの半径だけでも、優れた構造的正則化機能として機能します。実際には、より少ないメモリを使用し、予測が高速なモデルを優先するために、より低い &lt;code&gt;C&lt;/code&gt; の値で決定関数を簡略化することは依然として興味深いかもしれません。</target>
        </trans-unit>
        <trans-unit id="023b5a681b65ffd6304d113bea1d054693e2974b" translate="yes" xml:space="preserve">
          <source>Finally one should highlight that the Compound Poisson Gamma model that is directly fit on the pure premium is operationally simpler to develop and maintain as it consists in a single scikit-learn estimator instead of a pair of models, each with its own set of hyperparameters.</source>
          <target state="translated">最後に、純粋なプレミアムに直接フィットする複合ポアソンガンマモデルは、それぞれが独自のハイパーパラメタのセットを持つ一対のモデルではなく、単一のscikit-learn推定器で構成されているため、開発と維持が操作的に単純であることを強調しておきます。</target>
        </trans-unit>
        <trans-unit id="132cf9317ef371444593d6b5ea568f7dd88cd93f" translate="yes" xml:space="preserve">
          <source>Finally we are going to visualize the score:</source>
          <target state="translated">最後にスコアを可視化していきます。</target>
        </trans-unit>
        <trans-unit id="7c7dc3c27466a01b4ea9d811b8dcf76d3f27d658" translate="yes" xml:space="preserve">
          <source>Finally we will plot the selected two features from the data.</source>
          <target state="translated">最後に、データから選択した2つの特徴をプロットします。</target>
        </trans-unit>
        <trans-unit id="968616cc558da3fce60b0fa70563b382cf880868" translate="yes" xml:space="preserve">
          <source>Finally, &lt;a href=&quot;#dummy-estimators&quot;&gt;Dummy estimators&lt;/a&gt; are useful to get a baseline value of those metrics for random predictions.</source>
          <target state="translated">最後に、&lt;a href=&quot;#dummy-estimators&quot;&gt;ダミー推定器&lt;/a&gt;は、ランダムな予測のためにこれらのメトリックのベースライン値を取得するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="f6d5bddccec3511395edb0437e03e1a9559b2146" translate="yes" xml:space="preserve">
          <source>Finally, as we will see next, computing partial dependence plots tree-based models is also orders of magnitude faster making it cheap to compute partial dependence plots for pairs of interacting features:</source>
          <target state="translated">最後に、次に述べるように、木ベースのモデルの部分依存プロットの計算も桁違いに速く、相互作用する特徴のペアの部分依存プロットを安価に計算することができます。</target>
        </trans-unit>
        <trans-unit id="bac8fe99c0a1d10b0495b7da851a20ddd76d68ac" translate="yes" xml:space="preserve">
          <source>Finally, for 3. we have a number of options inside scikit-learn. Although not all algorithms can learn incrementally (i.e. without seeing all the instances at once), all estimators implementing the &lt;code&gt;partial_fit&lt;/code&gt; API are candidates. Actually, the ability to learn incrementally from a mini-batch of instances (sometimes called &amp;ldquo;online learning&amp;rdquo;) is key to out-of-core learning as it guarantees that at any given time there will be only a small amount of instances in the main memory. Choosing a good size for the mini-batch that balances relevancy and memory footprint could involve some tuning &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">最後に、3。については、scikit-learn内にいくつかのオプションがあります。すべてのアルゴリズムが段階的に学習できるわけではありませんが（つまり、すべてのインスタンスを一度に表示しなくても）、 &lt;code&gt;partial_fit&lt;/code&gt; APIを実装するすべての推定器が候補になります。実際、インスタンスのミニバッチから段階的に学習する機能（「オンライン学習」と呼ばれることもあります）は、常に少量のインスタンスしか存在しないことを保証するため、アウトオブコア学習の鍵となります。メインメモリ。関連性とメモリフットプリントのバランスが取れたミニバッチに適したサイズを選択するには、調整が必要になる場合があります&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8f153367033a26a7113472eddd66aa5516b2f784" translate="yes" xml:space="preserve">
          <source>Finally, for 3. we have a number of options inside scikit-learn. Although not all algorithms can learn incrementally (i.e. without seeing all the instances at once), all estimators implementing the &lt;code&gt;partial_fit&lt;/code&gt; API are candidates. Actually, the ability to learn incrementally from a mini-batch of instances (sometimes called &amp;ldquo;online learning&amp;rdquo;) is key to out-of-core learning as it guarantees that at any given time there will be only a small amount of instances in the main memory. Choosing a good size for the mini-batch that balances relevancy and memory footprint could involve some tuning &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">最後に、3。にはscikit-learn内にいくつかのオプションがあります。すべてのアルゴリズムが段階的に学習できるわけではありませんが（つまり、一度にすべてのインスタンスを見ることなく）、 &lt;code&gt;partial_fit&lt;/code&gt; APIを実装するすべての推定量が候補です。実際には、インスタンスのミニバッチから段階的に学習する機能（「オンライン学習」と呼ばれることもあります）は、いつでも少量のインスタンスしか存在しないことが保証されるため、コア外学習の鍵となります。メインメモリ。関連性とメモリフットプリントのバランスをとるミニバッチの適切なサイズを選択するには、調整が必要になる場合があります&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2ea772d9a2706e63fd635b713dfc5a265ad9f7ca" translate="yes" xml:space="preserve">
          <source>Finally, for the last data set, it is hard to say that one sample is more abnormal than another sample as they are uniformly distributed in a hypercube. Except for the &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; which overfits a little, all estimators present decent solutions for this situation. In such a case, it would be wise to look more closely at the scores of abnormality of the samples as a good estimator should assign similar scores to all the samples.</source>
          <target state="translated">最後に、最後のデータセットでは、あるサンプルがハイパーキューブに均一に分布しているため、あるサンプルが別のサンプルよりも異常であるとは言い難いです。少し&lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;するsklearn.svm.OneClassSVMを除いて、すべての推定量はこの状況に対して適切なソリューションを提示します。このような場合、優れた推定量はすべてのサンプルに同様のスコアを割り当てる必要があるため、サンプルの異常のスコアをより詳しく調べることが賢明です。</target>
        </trans-unit>
        <trans-unit id="02251ecbb666e2a1b9f431635bb03c5b54eb0a09" translate="yes" xml:space="preserve">
          <source>Finally, for the last data set, it is hard to say that one sample is more abnormal than another sample as they are uniformly distributed in a hypercube. Except for the &lt;code&gt;svm.OneClassSVM&lt;/code&gt; which overfits a little, all estimators present decent solutions for this situation. In such a case, it would be wise to look more closely at the scores of abnormality of the samples as a good estimator should assign similar scores to all the samples.</source>
          <target state="translated">最後に、最後のデータセットについては、ハイパーキューブに均一に分布しているため、あるサンプルが別のサンプルよりも異常であるとは言いがたいです。少し &lt;code&gt;svm.OneClassSVM&lt;/code&gt; するsvm.OneClassSVMを除いて、すべての推定量はこの状況に対して適切なソリューションを提供します。そのような場合、優れた推定者がすべてのサンプルに同様のスコアを割り当てる必要があるため、サンプルの異常のスコアをより詳しく調べるのが賢明です。</target>
        </trans-unit>
        <trans-unit id="ced44a1e1c24bc2a905bacd41c580fdb8b398c7b" translate="yes" xml:space="preserve">
          <source>Finally, if the centered data is expected to be small enough, explicitly converting the input to an array using the &lt;code&gt;toarray&lt;/code&gt; method of sparse matrices is another option.</source>
          <target state="translated">最後に、中央 &lt;code&gt;toarray&lt;/code&gt; されたデータが十分に小さいと予想される場合は、スパース行列のtoarrayメソッドを使用して入力を明示的に配列に変換することもできます。</target>
        </trans-unit>
        <trans-unit id="3e454243da6a98ce545408a4ef381fa38d1b1d45" translate="yes" xml:space="preserve">
          <source>Finally, many parts of the implementation of &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; are parallelized.</source>
          <target state="translated">最後に、&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; の&lt;/a&gt;実装の多くの部分が並列化されています。</target>
        </trans-unit>
        <trans-unit id="9b957bcce911d726f82907b30c1a02070fcadf91" translate="yes" xml:space="preserve">
          <source>Finally, note that parameters of the models have been here handpicked but that in practice they need to be adjusted. In the absence of labelled data, the problem is completely unsupervised so model selection can be a challenge.</source>
          <target state="translated">最後に、モデルのパラメータはここでは手で選んでいますが、実際には調整が必要であることに注意してください。ラベル付けされたデータがない場合、この問題は完全に教師なしであるため、モデルの選択が困難な場合があります。</target>
        </trans-unit>
        <trans-unit id="657149d8f47b73d795165e7f97ca51bcb04565c9" translate="yes" xml:space="preserve">
          <source>Finally, the precomputation can be performed by custom estimators to use different implementations, such as approximate nearest neighbors methods, or implementation with special data types. The precomputed neighbors &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;sparse graph&lt;/a&gt; needs to be formatted as in &lt;a href=&quot;generated/sklearn.neighbors.radius_neighbors_graph#sklearn.neighbors.radius_neighbors_graph&quot;&gt;&lt;code&gt;radius_neighbors_graph&lt;/code&gt;&lt;/a&gt; output:</source>
          <target state="translated">最後に、事前計算は、カスタム推定器によって実行され、近似最近傍法などのさまざまな実装、または特別なデータ型を使用した実装を使用できます。事前に計算されたネイバー&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-sparse-graph&quot;&gt;スパースグラフ&lt;/a&gt;は、&lt;a href=&quot;generated/sklearn.neighbors.radius_neighbors_graph#sklearn.neighbors.radius_neighbors_graph&quot;&gt; &lt;code&gt;radius_neighbors_graph&lt;/code&gt; &lt;/a&gt;出力のようにフォーマットする必要があります。</target>
        </trans-unit>
        <trans-unit id="5d0d4410d99fc712aa6cde836179153d36f8849c" translate="yes" xml:space="preserve">
          <source>Finally, the preprocessing pipeline is integrated in a full prediction pipeline using &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;, together with a simple classification model.</source>
          <target state="translated">最後に、前処理パイプラインは、単純な分類モデルとともに&lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;を使用して完全な予測パイプラインに統合されます。</target>
        </trans-unit>
        <trans-unit id="88dd3e3888504f660d94f91abf7147882c40ab2a" translate="yes" xml:space="preserve">
          <source>Finally, this module also features the parallel construction of the trees and the parallel computation of the predictions through the &lt;code&gt;n_jobs&lt;/code&gt; parameter. If &lt;code&gt;n_jobs=k&lt;/code&gt; then computations are partitioned into &lt;code&gt;k&lt;/code&gt; jobs, and run on &lt;code&gt;k&lt;/code&gt; cores of the machine. If &lt;code&gt;n_jobs=-1&lt;/code&gt; then all cores available on the machine are used. Note that because of inter-process communication overhead, the speedup might not be linear (i.e., using &lt;code&gt;k&lt;/code&gt; jobs will unfortunately not be &lt;code&gt;k&lt;/code&gt; times as fast). Significant speedup can still be achieved though when building a large number of trees, or when building a single tree requires a fair amount of time (e.g., on large datasets).</source>
          <target state="translated">最後に、このモジュールは、ツリーの並列構築と &lt;code&gt;n_jobs&lt;/code&gt; パラメータによる予測の並列計算も特徴としています。 &lt;code&gt;n_jobs=k&lt;/code&gt; の場合、計算は &lt;code&gt;k&lt;/code&gt; 個のジョブに分割され、マシンの &lt;code&gt;k&lt;/code&gt; 個のコアで実行されます。 &lt;code&gt;n_jobs=-1&lt;/code&gt; の場合、マシンで使用可能なすべてのコアが使用されます。プロセス間通信のオーバーヘッドのため、速度の向上は直線的ではない可能性があることに注意してください（つまり、 &lt;code&gt;k&lt;/code&gt; 個のジョブを使用しても、残念ながら &lt;code&gt;k&lt;/code&gt; 倍の速さではありません）。大量のツリーを構築する場合、または単一のツリーを構築するのにかなりの時間が必要な場合（大きなデータセットなど）でも、大幅なスピードアップを実現できます。</target>
        </trans-unit>
        <trans-unit id="ac4279287fdb399e92fa8f401fc1a571b7df3622" translate="yes" xml:space="preserve">
          <source>Finally, we can compare the two models using a plot of cumulated claims: for each model, the policyholders are ranked from safest to riskiest and the fraction of observed total cumulated claims is plotted on the y axis. This plot is often called the ordered Lorenz curve of the model.</source>
          <target state="translated">最後に、累積クレームのプロットを使って2つのモデルを比較することができます:各モデルについて、保険契約者を安全なものからリスクの高いものまでランク付けし、観測された累積クレームの割合をy軸にプロットします。このプロットは、しばしばモデルの順序付きローレンツ曲線と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="abb5440e13032f9c21233aa604593a79c839b358" translate="yes" xml:space="preserve">
          <source>Finally, we fit our pipeline on the training data and use it to predict topics for &lt;code&gt;X_test&lt;/code&gt;. Performance metrics of our pipeline are then printed.</source>
          <target state="translated">最後に、パイプラインをトレーニングデータに適合させ、それを使用して &lt;code&gt;X_test&lt;/code&gt; のトピックを予測します。次に、パイプラインのパフォーマンスメトリックが出力されます。</target>
        </trans-unit>
        <trans-unit id="f50b898f991b3ec8dadce88abad6749cb3fd8140" translate="yes" xml:space="preserve">
          <source>Finally, we have a full-fledged example of &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;. It is aimed at providing a starting point for people wanting to build out-of-core learning systems and demonstrates most of the notions discussed above.</source>
          <target state="translated">最後に、&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;テキストドキュメントのコア外分類の&lt;/a&gt;本格的な例を示します。これは、コア外の学習システムを構築したい人々に出発点を提供することを目的とし、上で説明した概念のほとんどを示します。</target>
        </trans-unit>
        <trans-unit id="67b1b42b3e66107ae3b505ef41aac41ee3327ff3" translate="yes" xml:space="preserve">
          <source>Finally, we will consider a non-linear model, namely Gradient Boosting Regression Trees. Tree-based models do not require the categorical data to be one-hot encoded: instead, we can encode each category label with an arbitrary integer using &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt;. With this encoding, the trees will treat the categorical features as ordered features, which might not be always a desired behavior. However this effect is limited for deep enough trees which are able to recover the categorical nature of the features. The main advantage of the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt;&lt;code&gt;OrdinalEncoder&lt;/code&gt;&lt;/a&gt; over the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;OneHotEncoder&lt;/code&gt;&lt;/a&gt; is that it will make training faster.</source>
          <target state="translated">最後に、非線形モデル、つまり勾配ブースティング回帰ツリーについて検討します。ツリーベースのモデルでは、カテゴリデータをワンホットエンコードする必要はありません。代わりに、&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt;を使用して各カテゴリラベルを任意の整数でエンコードできます。このエンコーディングでは、ツリーはカテゴリ機能を順序付けられた機能として扱いますが、これは必ずしも望ましい動作とは限りません。ただし、この効果は、フィーチャのカテゴリの性質を回復できる十分に深いツリーでは制限されます。主な利点&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.ordinalencoder#sklearn.preprocessing.OrdinalEncoder&quot;&gt; &lt;code&gt;OrdinalEncoder&lt;/code&gt; &lt;/a&gt;オーバー&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;OneHotEncoder&lt;/code&gt; は&lt;/a&gt;、それはトレーニングより速くなることです。</target>
        </trans-unit>
        <trans-unit id="15e943be721eab8a2c2612f45c392677826a2d6c" translate="yes" xml:space="preserve">
          <source>Finally, we will plot the predictions made by all models for comparison.</source>
          <target state="translated">最後に、比較のためにすべてのモデルで行われた予測をプロットします。</target>
        </trans-unit>
        <trans-unit id="e9d6cf373d4d749e0936e6f64e1c533e8fd8ee41" translate="yes" xml:space="preserve">
          <source>Finally, we will visualize the 20 predictions. The red stars show the average prediction made by &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingregressor#sklearn.ensemble.VotingRegressor&quot;&gt;&lt;code&gt;VotingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">最後に、20の予測を視覚化します。赤い星は、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingregressor#sklearn.ensemble.VotingRegressor&quot;&gt; &lt;code&gt;VotingRegressor&lt;/code&gt; &lt;/a&gt;によって行われた平均予測を示しています。</target>
        </trans-unit>
        <trans-unit id="9f642cdc0abe545be7ddd1dd012ea6198c659512" translate="yes" xml:space="preserve">
          <source>Finally, we will visualize the results. To do that we will first compute the test set deviance and then plot it against boosting iterations.</source>
          <target state="translated">最後に、結果を可視化します。そのためには、まずテストセットのデビアンスを計算し、それをブースト反復に対してプロットします。</target>
        </trans-unit>
        <trans-unit id="a40631d3e46670650e2553ca58294d12cd46b8ee" translate="yes" xml:space="preserve">
          <source>Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches &lt;a href=&quot;#lg2012&quot; id=&quot;id4&quot;&gt;[LG2012]&lt;/a&gt;.</source>
          <target state="translated">最後に、ベースエスティメータがサンプルと機能の両方のサブセットに基づいて構築される場合、この方法はランダムパッチ&lt;a href=&quot;#lg2012&quot; id=&quot;id4&quot;&gt;[LG2012]&lt;/a&gt;と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="7185a548932a7d63b1a08d591559f9d8821b9404" translate="yes" xml:space="preserve">
          <source>Find a &amp;lsquo;safe&amp;rsquo; number of components to randomly project to</source>
          <target state="translated">ランダムに投影する「安全な」数のコンポーネントを見つける</target>
        </trans-unit>
        <trans-unit id="e40e118fb652d4dd06f307746b620728b2345e85" translate="yes" xml:space="preserve">
          <source>Find a good set of parameters using grid search.</source>
          <target state="translated">グリッド検索を使用して、良いパラメータのセットを検索します。</target>
        </trans-unit>
        <trans-unit id="022a840c39dad4bac6c36ba2a156531a2e97ca25" translate="yes" xml:space="preserve">
          <source>Find importance of the features</source>
          <target state="translated">特徴の重要性を見つける</target>
        </trans-unit>
        <trans-unit id="2ff57da6a2f73ea1d0dfc969be6516b83c61b137" translate="yes" xml:space="preserve">
          <source>Find out what the actual encoding of the text is. The file might come with a header or README that tells you the encoding, or there might be some standard encoding you can assume based on where the text comes from.</source>
          <target state="translated">テキストの実際のエンコーディングを調べてください。ファイルには、エンコーディングを教えてくれるヘッダや README が付属しているかもしれませんし、テキストがどこから来たのかに基づいて標準的なエンコーディングがあるかもしれません。</target>
        </trans-unit>
        <trans-unit id="c317277c718283dc0dcc7baf2d812226e24cc453" translate="yes" xml:space="preserve">
          <source>Find the minimum value of an array over positive values</source>
          <target state="translated">正の値以上の配列の最小値を求める</target>
        </trans-unit>
        <trans-unit id="d95b4144f33d10b131b37a33f2e7ad7cc55860b7" translate="yes" xml:space="preserve">
          <source>Find the optimal separating hyperplane using an SVC for classes that are unbalanced.</source>
          <target state="translated">不均衡なクラスに対してSVCを用いて最適な分離双平面を求める.</target>
        </trans-unit>
        <trans-unit id="1c17584736b51c43c88ae3dfa46ea2817cd1a339" translate="yes" xml:space="preserve">
          <source>Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.</source>
          <target state="translated">積が非負行列Xに近似する2つの非負行列(W,H)を求めよ.この因数分解は,例えば,次元削減,ソース分離,トピック抽出などに利用できる.</target>
        </trans-unit>
        <trans-unit id="4daca12ed4dca9ca21325e05dde77793902b89f7" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization parameter \(\alpha\) is best done using &lt;code&gt;GridSearchCV&lt;/code&gt;, usually in the range &lt;code&gt;10.0 ** -np.arange(1, 7)&lt;/code&gt;.</source>
          <target state="translated">妥当な正則化パラメーター\（\ alpha \）を &lt;code&gt;GridSearchCV&lt;/code&gt; には、通常 &lt;code&gt;10.0 ** -np.arange(1, 7)&lt;/code&gt; 範囲のGridSearchCVを使用するのが最適です。</target>
        </trans-unit>
        <trans-unit id="d0410c73baea9b092d4edb9802ae4c10c09f4696" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization term \(\alpha\) is best done using &lt;code&gt;GridSearchCV&lt;/code&gt;, usually in the range &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt;.</source>
          <target state="translated">妥当な正則 &lt;code&gt;GridSearchCV&lt;/code&gt; \（\ alpha \）を見つけるには、通常 &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt; 範囲のGridSearchCVを使用するのが最適です。</target>
        </trans-unit>
        <trans-unit id="37e657d78a9dafeda1b142a17aaad5659fab59b7" translate="yes" xml:space="preserve">
          <source>Finding a reasonable regularization term \(\alpha\) is best done using automatic hyper-parameter search, e.g. &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt;, usually in the range &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt;.</source>
          <target state="translated">妥当な正則&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;\（\ alpha \）を見つけるには、通常 &lt;code&gt;10.0**-np.arange(1,7)&lt;/code&gt; 範囲の自動ハイパーパラメーター検索（GridSearchCVや&lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt;など）を使用するのが最適です。</target>
        </trans-unit>
        <trans-unit id="3c5a640c918941c9e6a6ecbfe984c3f4bfbed0d7" translate="yes" xml:space="preserve">
          <source>Finding help</source>
          <target state="translated">ヘルプを探す</target>
        </trans-unit>
        <trans-unit id="71cc727880d53ab3c238ec955595a0ded28610b7" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) http://arxiv.org/pdf/0909.4061</source>
          <target state="translated">ランダム性を利用した構造の探索 近似行列分解を構築するための確率的アルゴリズム Halko,et al.,2009 (arXiv:909)http://arxiv.org/pdf/0909.4061</target>
        </trans-unit>
        <trans-unit id="de5cdfe8ddd63c8c4fb1f7f388d421a16cbbf828" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</source>
          <target state="translated">ランダム性を利用した構造の探索 近似行列分解を構築するための確率的アルゴリズム Halko,et al.,2009 (arXiv:909)https://arxiv.org/pdf/0909.4061.pdf</target>
        </trans-unit>
        <trans-unit id="50ccb6d4c8a3bfa0951293912c0c5132106a8c89" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 &lt;a href=&quot;http://arxiv.org/abs/arXiv:0909.4061&quot;&gt;http://arxiv.org/abs/arXiv:0909.4061&lt;/a&gt;</source>
          <target state="translated">ランダム性のある構造を見つける：近似行列分解を構築するための確率的アルゴリズムHalko、et al。、2009 &lt;a href=&quot;http://arxiv.org/abs/arXiv:0909.4061&quot;&gt;http://arxiv.org/abs/arXiv:0909.4061&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="09110546ddb637f3471f1e7efbbe318b3963484e" translate="yes" xml:space="preserve">
          <source>Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 &lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;https://arxiv.org/abs/0909.4061&lt;/a&gt;</source>
          <target state="translated">ランダム性のある構造の検索：近似行列分解を構築するための確率的アルゴリズムHalko、et al。、2009 &lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;https://arxiv.org/abs/0909.4061&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="26becafaa69af10fe9097be8fd6bf298839f5095" translate="yes" xml:space="preserve">
          <source>Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.</source>
          <target state="translated">疎なコードを使用してデータを表現するのに最適な辞書(原子の集合)を見つけます。</target>
        </trans-unit>
        <trans-unit id="bdd5a22a4b66cac66c670f6f1297e40cb6d2aae2" translate="yes" xml:space="preserve">
          <source>Finds a sparse representation of data against a fixed, precomputed dictionary.</source>
          <target state="translated">固定された事前計算された辞書に対して、データの疎な表現を見つけます。</target>
        </trans-unit>
        <trans-unit id="a5dbd88babc750758342dfe447e24f6c260c3097" translate="yes" xml:space="preserve">
          <source>Finds core samples of high density and expands clusters from them.</source>
          <target state="translated">高密度のコアサンプルを見つけ、そこからクラスターを展開します。</target>
        </trans-unit>
        <trans-unit id="e0fb0de42fddb601e63b5dedf2b446e9b6fdd66e" translate="yes" xml:space="preserve">
          <source>Finds core samples of high density and expands clusters from them. This example uses data that is generated so that the clusters have different densities. The &lt;a href=&quot;../../modules/generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt;&lt;code&gt;sklearn.cluster.OPTICS&lt;/code&gt;&lt;/a&gt; is first used with its Xi cluster detection method, and then setting specific thresholds on the reachability, which corresponds to &lt;a href=&quot;../../modules/generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;sklearn.cluster.DBSCAN&lt;/code&gt;&lt;/a&gt;. We can see that the different clusters of OPTICS&amp;rsquo;s Xi method can be recovered with different choices of thresholds in DBSCAN.</source>
          <target state="translated">高密度のコアサンプルを見つけ、それらからクラスターを拡張します。この例では、クラスターの密度が異なるように生成されたデータを使用します。&lt;a href=&quot;../../modules/generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt; &lt;code&gt;sklearn.cluster.OPTICS&lt;/code&gt; は、&lt;/a&gt;最初にXiのクラスタ検出方法に使用され、その後に対応する到達可能性、に特定のしきい値を設定して&lt;a href=&quot;../../modules/generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;sklearn.cluster.DBSCAN&lt;/code&gt; &lt;/a&gt;。DBSCANでしきい値をさまざまに選択することで、OPTICSのXiメソッドのさまざまなクラスターを回復できることがわかります。</target>
        </trans-unit>
        <trans-unit id="a0ac333cc4bd6a4e85a5691bb991f9cd4f114c12" translate="yes" xml:space="preserve">
          <source>Finds the K-neighbors of a point.</source>
          <target state="translated">点のK-neighborsを見つけます。</target>
        </trans-unit>
        <trans-unit id="e7def6740e556221f1aa42003fab4e2365f3483e" translate="yes" xml:space="preserve">
          <source>Finds the K-neighbors of a point. Returns indices of and distances to the neighbors of each point.</source>
          <target state="translated">点のK-近傍を求めます。各点のインデックスと隣人までの距離を返します。</target>
        </trans-unit>
        <trans-unit id="011362db8e96e3edcb95f8fcdf5f1e0d92d5e3e2" translate="yes" xml:space="preserve">
          <source>Finds the best dictionary and the corresponding sparse code for approximating the data matrix X by solving:</source>
          <target state="translated">データ行列Xを解くことで近似するための最適な辞書と対応するスパースコードを求めます.</target>
        </trans-unit>
        <trans-unit id="b6f70d43205a979d509f018cfbe88e93d812b3ec" translate="yes" xml:space="preserve">
          <source>Finds the neighbors within a given radius of a point or points.</source>
          <target state="translated">点または点の指定された半径内の隣人を見つけます。</target>
        </trans-unit>
        <trans-unit id="dd8ddfd214a6d88017dd4006d52b1774d72e0be7" translate="yes" xml:space="preserve">
          <source>Finds the set of sparse components that can optimally reconstruct the data. The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.</source>
          <target state="translated">データを最適に再構成できる疎な成分の集合を求めます.スパースネスの量は,パラメータ alpha で与えられる L1 ペナルティの係数によって制御可能です.</target>
        </trans-unit>
        <trans-unit id="9ce397e0f2c9f33bd1911b665e99384e26321100" translate="yes" xml:space="preserve">
          <source>Finite Gaussian mixture fit with EM.</source>
          <target state="translated">EMを用いた有限ガウス混合フィット。</target>
        </trans-unit>
        <trans-unit id="fd9ae1ff1bfcac14b05b92d277d3f6074f078a31" translate="yes" xml:space="preserve">
          <source>First 10 columns are numeric predictive values</source>
          <target state="translated">最初の10列は数値予測値</target>
        </trans-unit>
        <trans-unit id="30250bc7520fcdac140dbcf0c3820bc484ca88d7" translate="yes" xml:space="preserve">
          <source>First example</source>
          <target state="translated">第一例</target>
        </trans-unit>
        <trans-unit id="7874170ffefbed5d0d1c4372827ea2aeb194c3ba" translate="yes" xml:space="preserve">
          <source>First fit an ensemble of trees (totally random trees, a random forest, or gradient boosted trees) on the training set. Then each leaf of each tree in the ensemble is assigned a fixed arbitrary feature index in a new feature space. These leaf indices are then encoded in a one-hot fashion.</source>
          <target state="translated">最初に,木のアンサンブル(完全ランダム木,ランダムフォレスト,勾配ブーストされた木)を訓練セットに適合させる.次に、アンサンブル内の各木の各リーフには、新しい特徴空間内の固定された任意の特徴インデックスが割り当てられます。そして、これらのリーフインデックスは、ワンホット方式で符号化されます。</target>
        </trans-unit>
        <trans-unit id="c9c47ba90ccfdfceca4eb5b8199939d35b815802" translate="yes" xml:space="preserve">
          <source>First note that the K means \(\mu_k\) are vectors in \(\mathcal{R}^d\), and they lie in an affine subspace \(H\) of dimension at least \(K - 1\) (2 points lie on a line, 3 points lie on a plane, etc).</source>
          <target state="translated">まず、Kは、\mathcal{R}^d)の中のベクトルであることに注意してください。そして、少なくとも次元のある部分空間にあることに注意してください。</target>
        </trans-unit>
        <trans-unit id="5b7d36dc535373f63b2b8c97af1496035ebdccf8" translate="yes" xml:space="preserve">
          <source>First of all, we can take a look to the values of the coefficients of the regressor we have fitted.</source>
          <target state="translated">まずは、フィットさせた回帰器の係数の値を見てみましょう。</target>
        </trans-unit>
        <trans-unit id="af1667b67f8a74831d9cbccc10fec01c4bb8c75d" translate="yes" xml:space="preserve">
          <source>First we check which value of \(\alpha\) has been selected.</source>
          <target state="translated">まず、\(\alpha\)のどの値が選ばれているかを確認します。</target>
        </trans-unit>
        <trans-unit id="31c524afbf18465a1ae6f80767e0e696d536b875" translate="yes" xml:space="preserve">
          <source>First we create a data set of 9 samples from 3 classes, and plot the points in the original space. For this example, we focus on the classification of point no. 3. The thickness of a link between point no. 3 and another point is proportional to their distance.</source>
          <target state="translated">まず、3つのクラスから9つのサンプルのデータセットを作成し、元の空間に点をプロットします。この例では、点No.3の分類に注目します。点No.3と他の点との間のリンクの太さは、その距離に比例します。</target>
        </trans-unit>
        <trans-unit id="66d3e97d3998fff9804546e983728130f9a1d48d" translate="yes" xml:space="preserve">
          <source>First we download the two datasets. Diabetes dataset is shipped with scikit-learn. It has 442 entries, each with 10 features. California Housing dataset is much larger with 20640 entries and 8 features. It needs to be downloaded. We will only use the first 400 entries for the sake of speeding up the calculations but feel free to use the whole dataset.</source>
          <target state="translated">まず、2つのデータセットをダウンロードします。糖尿病データセットは、scikit-learnと一緒に出荷されます。データセットには442個のエントリがあり、それぞれ10個の特徴量があります。California Housing datasetは、20640個のエントリと8個の特徴量を持つ、もっと大きなデータセットです。ダウンロードする必要があります。ここでは計算を高速化するために最初の400エントリのみを使用しますが、データセット全体を自由に使用してください。</target>
        </trans-unit>
        <trans-unit id="c2e4b6f9c83c90558d9df87e3572e1d8ff690d21" translate="yes" xml:space="preserve">
          <source>First we need to load the data.</source>
          <target state="translated">まずはデータをロードします。</target>
        </trans-unit>
        <trans-unit id="8d180e35a78f80e45c6959bdc2213230723a6ec9" translate="yes" xml:space="preserve">
          <source>First we verify which value of \(\alpha\) has been selected.</source>
          <target state="translated">まず、どの値が選ばれているかを確認します。</target>
        </trans-unit>
        <trans-unit id="da6f0be97a3f9bc23cb9968f6dd764558635185b" translate="yes" xml:space="preserve">
          <source>First, let&amp;rsquo;s get some insights by looking at the variable distributions and at the pairwise relationships between them. Only numerical variables will be used. In the following plot, each dot represents a sample.</source>
          <target state="translated">まず、変数の分布とそれらの間のペアワイズ関係を見て、いくつかの洞察を得ましょう。数値変数のみが使用されます。次のプロットでは、各ドットはサンプルを表しています。</target>
        </trans-unit>
        <trans-unit id="1c794cffa5e7e2eb61589bb3349c992e76e5c222" translate="yes" xml:space="preserve">
          <source>First, let&amp;rsquo;s load the diabetes dataset which is available from within sklearn. Then, we will look what features are collected for the diabates patients:</source>
          <target state="translated">まず、sklearn内から利用できる糖尿病データセットをロードしましょう。次に、糖尿病患者のために収集された機能を確認します。</target>
        </trans-unit>
        <trans-unit id="cac3b241d42030e20b4b1109edf6cf6d51db7345" translate="yes" xml:space="preserve">
          <source>First, the precomputed graph can be re-used multiple times, for instance while varying a parameter of the estimator. This can be done manually by the user, or using the caching properties of the scikit-learn pipeline:</source>
          <target state="translated">まず、事前計算されたグラフは、例えば、推定器のパラメータを変化させながら、複数回再利用することができます。これはユーザが手動で行うことも、scikit-learnパイプラインのキャッシング機能を使って行うこともできます。</target>
        </trans-unit>
        <trans-unit id="97be8aa0250f0cdac7301eb79bf3b2a478185ccc" translate="yes" xml:space="preserve">
          <source>First, three examplary classifiers are initialized (&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;GaussianNB&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt;) and used to initialize a soft-voting &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; with weights &lt;code&gt;[1, 1, 5]&lt;/code&gt;, which means that the predicted probabilities of the &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; count 5 times as much as the weights of the other classifiers when the averaged probability is calculated.</source>
          <target state="translated">第三examplary分類は、（初期化され&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;../../modules/generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;GaussianNB&lt;/code&gt; &lt;/a&gt;、及び&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt;）とソフト投票初期化するために使用&lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt; &lt;code&gt;VotingClassifier&lt;/code&gt; &lt;/a&gt;量を有する &lt;code&gt;[1, 1, 5]&lt;/code&gt; の予測確率ことを意味する、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; は&lt;/a&gt;限り5回カウントを平均確率が計算されるときの他の分類器の重み。</target>
        </trans-unit>
        <trans-unit id="16a8cd51addf2278ba02a88d4c3026fabfe281d9" translate="yes" xml:space="preserve">
          <source>First, three examplary classifiers are initialized (&lt;code&gt;LogisticRegression&lt;/code&gt;, &lt;code&gt;GaussianNB&lt;/code&gt;, and &lt;code&gt;RandomForestClassifier&lt;/code&gt;) and used to initialize a soft-voting &lt;code&gt;VotingClassifier&lt;/code&gt; with weights &lt;code&gt;[1, 1, 5]&lt;/code&gt;, which means that the predicted probabilities of the &lt;code&gt;RandomForestClassifier&lt;/code&gt; count 5 times as much as the weights of the other classifiers when the averaged probability is calculated.</source>
          <target state="translated">第三examplary分類は、（初期化され &lt;code&gt;LogisticRegression&lt;/code&gt; 、 &lt;code&gt;GaussianNB&lt;/code&gt; 、及び &lt;code&gt;RandomForestClassifier&lt;/code&gt; ）とソフト投票初期化するために使用 &lt;code&gt;VotingClassifier&lt;/code&gt; 量を有する &lt;code&gt;[1, 1, 5]&lt;/code&gt; の予測確率ことを意味する、 &lt;code&gt;RandomForestClassifier&lt;/code&gt; は限り5回カウントを平均確率が計算されるときの他の分類子の重み。</target>
        </trans-unit>
        <trans-unit id="f50c60bee958db3de20cd6c08f2c3fe9b2fb6e88" translate="yes" xml:space="preserve">
          <source>First, three exemplary classifiers are initialized (&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;) and used to initialize a soft-voting &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; with weights &lt;code&gt;[2,
1, 2]&lt;/code&gt;, which means that the predicted probabilities of the &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; each count 2 times as much as the weights of the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt;&lt;code&gt;KNeighborsClassifier&lt;/code&gt;&lt;/a&gt; classifier when the averaged probability is calculated.</source>
          <target state="translated">最初に、3つの例示的な分類器（&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt; &lt;code&gt;KNeighborsClassifier&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;）が初期化され、重み &lt;code&gt;[2, 1, 2]&lt;/code&gt; &lt;a href=&quot;../../modules/generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt; &lt;code&gt;VotingClassifier&lt;/code&gt; &lt;/a&gt;でソフト投票VotingClassifierを初期化するために使用されます。これは、&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; の&lt;/a&gt;予測確率がそれぞれ2回カウントされることを意味します。平均確率が計算されるときの&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier&quot;&gt; &lt;code&gt;KNeighborsClassifier&lt;/code&gt; &lt;/a&gt;分類器の重みと同じです。</target>
        </trans-unit>
        <trans-unit id="1ea180eeb1f820255090eaa2e746ff697919b622" translate="yes" xml:space="preserve">
          <source>First, three exemplary classifiers are initialized (&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;, &lt;code&gt;KNeighborsClassifier&lt;/code&gt;, and &lt;code&gt;SVC&lt;/code&gt;) and used to initialize a soft-voting &lt;code&gt;VotingClassifier&lt;/code&gt; with weights &lt;code&gt;[2, 1, 2]&lt;/code&gt;, which means that the predicted probabilities of the &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; and &lt;code&gt;SVC&lt;/code&gt; count 5 times as much as the weights of the &lt;code&gt;KNeighborsClassifier&lt;/code&gt; classifier when the averaged probability is calculated.</source>
          <target state="translated">最初に、3つの例示的な分類子が初期化され（ &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; 、 &lt;code&gt;KNeighborsClassifier&lt;/code&gt; 、および &lt;code&gt;SVC&lt;/code&gt; ）、重み &lt;code&gt;[2, 1, 2]&lt;/code&gt; &lt;code&gt;VotingClassifier&lt;/code&gt; でソフト投票VotingClassifierを初期化するために使用されます。つまり、 &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; および &lt;code&gt;SVC&lt;/code&gt; の予測確率は5倍カウントされます。平均確率が計算されるときの &lt;code&gt;KNeighborsClassifier&lt;/code&gt; 分類器の重みとして。</target>
        </trans-unit>
        <trans-unit id="5fdc5502e4f55e2ed52afffb452568aea16c1218" translate="yes" xml:space="preserve">
          <source>First, we fit the model.</source>
          <target state="translated">まず、モデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="ef9c4b59f96926f6f0e5f166376f8408083d95db" translate="yes" xml:space="preserve">
          <source>First, we load the wine dataset and convert it to a binary classification problem. Then, we train a support vector classifier on a training dataset.</source>
          <target state="translated">まず、ワインのデータセットをロードし、2値分類問題に変換する。次に、学習データセット上でサポートベクター分類器を訓練する。</target>
        </trans-unit>
        <trans-unit id="9d07cc681f72e7314cfb570248652c85d831875b" translate="yes" xml:space="preserve">
          <source>First, we must understand the structure of our data. It has 100 randomly generated input datapoints, 3 classes split unevenly across datapoints, and 10 &amp;ldquo;groups&amp;rdquo; split evenly across datapoints.</source>
          <target state="translated">まず、データの構造を理解する必要があります。100個のランダムに生成された入力データポイント、3つのクラスがデータポイント間で不均等に分割され、10の「グループ」がデータポイント間で均等に分割されます。</target>
        </trans-unit>
        <trans-unit id="cc0ba427a614a821f465ac72c31717d2cbd7abed" translate="yes" xml:space="preserve">
          <source>First, we train a decision tree and a multi-layer perceptron on the diabetes dataset.</source>
          <target state="translated">まず、糖尿病のデータセットに対して、決定木と多層パーセプトロンを学習する。</target>
        </trans-unit>
        <trans-unit id="f123dfa67a1788d2150ed770bdb351ff3e4fb8cc" translate="yes" xml:space="preserve">
          <source>First, we train a random forest on the breast cancer dataset and evaluate its accuracy on a test set:</source>
          <target state="translated">まず、乳がんのデータセットに対してランダムフォレストを訓練し、テストセットに対してその精度を評価する。</target>
        </trans-unit>
        <trans-unit id="2b8f70566f670b04c1ac522dc7b0f129462badb9" translate="yes" xml:space="preserve">
          <source>First, we want to estimate the score on the original data:</source>
          <target state="translated">まず、元データのスコアを推定したい。</target>
        </trans-unit>
        <trans-unit id="fab091b4d5d2bc522f0ed86af86bd56d5c7a2d19" translate="yes" xml:space="preserve">
          <source>First, we will load the diabetes dataset and initiate a gradient boosting regressor, a random forest regressor and a linear regression. Next, we will use the 3 regressors to build the voting regressor:</source>
          <target state="translated">まず、糖尿病データセットをロードして、勾配ブースト・レグレッサー、ランダム・フォレスト・レグレッサー、線形回帰を開始します。次に、この3つのレグレッサーを用いて、投票レグレッサーを構築します。</target>
        </trans-unit>
        <trans-unit id="5918b4ffaa61bc5b2d97e424d8740b3562535f07" translate="yes" xml:space="preserve">
          <source>First, we would like a transformer that extracts the subject and body of each post. Since this is a stateless transformation (does not require state information from training data), we can define a function that performs the data transformation then use &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt; to create a scikit-learn transformer.</source>
          <target state="translated">まず、各投稿の件名と本文を抽出するトランスフォーマーが必要です。これはステートレス変換であるため（トレーニングデータからの状態情報を必要としません）、データ変換を実行する関数を定義してから、&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt;を使用してscikit-learnトランスフォーマーを作成できます。</target>
        </trans-unit>
        <trans-unit id="b01058ecfb06b2978590da1239a0a81618b1465b" translate="yes" xml:space="preserve">
          <source>Fisher transformation. Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Fisher_transformation&quot;&gt;https://en.wikipedia.org/wiki/Fisher_transformation&lt;/a&gt;</source>
          <target state="translated">フィッシャー変身。ウィキペディア。&lt;a href=&quot;https://en.wikipedia.org/wiki/Fisher_transformation&quot;&gt;https://en.wikipedia.org/wiki/Fisher_transformation&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="75ec02df98bcfaf21ee3dd0abe872b47c664ba1c" translate="yes" xml:space="preserve">
          <source>Fisher, R.A. &amp;ldquo;The use of multiple measurements in taxonomic problems&amp;rdquo; Annual Eugenics, 7, Part II, 179-188 (1936); also in &amp;ldquo;Contributions to Mathematical Statistics&amp;rdquo; (John Wiley, NY, 1950).</source>
          <target state="translated">フィッシャー、RA「分類学的問題における複数の測定の使用」年次優生学、7、パートII、179-188（1936）; また、「数学的統計への貢献」（John Wiley、NY、1950）にも掲載されています。</target>
        </trans-unit>
        <trans-unit id="4d49737491d2fdff73fcfce78bfa3496db9aead4" translate="yes" xml:space="preserve">
          <source>Fit Gaussian Naive Bayes according to X, y</source>
          <target state="translated">X,yに応じたガウス型ナイーブベイズのフィット</target>
        </trans-unit>
        <trans-unit id="5697d81dd45cef7c7ddb8bf2ab425085bcc0125d" translate="yes" xml:space="preserve">
          <source>Fit Gaussian process classification model</source>
          <target state="translated">ガウスプロセス分類モデルのフィット</target>
        </trans-unit>
        <trans-unit id="87cac59f89b2fa13ce5de11220e3eeec4bd8c5cf" translate="yes" xml:space="preserve">
          <source>Fit Gaussian process regression model.</source>
          <target state="translated">ガウスプロセス回帰モデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="8eb1d823143ba03b3eb9b823b5dab8b0cf44511a" translate="yes" xml:space="preserve">
          <source>Fit Kernel Ridge regression model</source>
          <target state="translated">フィットカーネルリッジ回帰モデル</target>
        </trans-unit>
        <trans-unit id="62df27bb0a01d202786ab5c8f2652f91558551a4" translate="yes" xml:space="preserve">
          <source>Fit KernelCenterer</source>
          <target state="translated">フィットカーネルセンター</target>
        </trans-unit>
        <trans-unit id="f97a5239f74bba940e2a0890df2d8120afcfa03c" translate="yes" xml:space="preserve">
          <source>Fit LSI model on training data X.</source>
          <target state="translated">学習データXにLSIモデルをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="c2f5d79cd7108f6536b92a8ab72454a376b81e9e" translate="yes" xml:space="preserve">
          <source>Fit LSI model to X and perform dimensionality reduction on X.</source>
          <target state="translated">LSIモデルをXにフィットさせ、Xの次元削減を行う。</target>
        </trans-unit>
        <trans-unit id="f79f31a7bd81775029053b8e229553093e280715" translate="yes" xml:space="preserve">
          <source>Fit LinearDiscriminantAnalysis model according to the given</source>
          <target state="translated">与えられた</target>
        </trans-unit>
        <trans-unit id="5a914df7976c81fad1a03ac324a4632a19d9e602" translate="yes" xml:space="preserve">
          <source>Fit LinearDiscriminantAnalysis model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従って、LinearDiscriminantAnalysisモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="cb91a62a58b24a52b6e32fdd160e489a55cfbac1" translate="yes" xml:space="preserve">
          <source>Fit MultiTaskElasticNet model with coordinate descent</source>
          <target state="translated">MultiTaskElasticNetモデルを座標降下でフィットさせる</target>
        </trans-unit>
        <trans-unit id="07e793af99a651a8f0a47822a080e4cf194bac9b" translate="yes" xml:space="preserve">
          <source>Fit Naive Bayes classifier according to X, y</source>
          <target state="translated">X,yに応じたナイーブベイズ分類器のフィット</target>
        </trans-unit>
        <trans-unit id="afc10844f54e485a835b4e52b36e0ebefe70c8de" translate="yes" xml:space="preserve">
          <source>Fit OneHotEncoder to X, then transform X.</source>
          <target state="translated">OneHotEncoder を X にフィットし、X を変換します。</target>
        </trans-unit>
        <trans-unit id="6cbc8c577214883d5f9bdf864d2a7d76e95b5a74" translate="yes" xml:space="preserve">
          <source>Fit OneHotEncoder to X.</source>
          <target state="translated">OneHotEncoderをXにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="7a3e15c6e4bf063bec4aa435d4748fb868286ed7" translate="yes" xml:space="preserve">
          <source>Fit Ridge and HuberRegressor on a dataset with outliers.</source>
          <target state="translated">外れ値を持つデータセットにRidgeとHuberRegressorをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="9157b13407894777185a7ac8935a66fc19422ca1" translate="yes" xml:space="preserve">
          <source>Fit Ridge classifier model.</source>
          <target state="translated">リッジ分類器モデルをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="e744f084cdfc69f98e0c6bdc1ef85d9a5fdf52b4" translate="yes" xml:space="preserve">
          <source>Fit Ridge classifier with cv.</source>
          <target state="translated">フィットリッジ分級機(CV付)。</target>
        </trans-unit>
        <trans-unit id="8f8e3b0b4710ae51d90dcd69d91e33d123946d3a" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model</source>
          <target state="translated">フィットリッジ回帰モデル</target>
        </trans-unit>
        <trans-unit id="47da48f063cc42a3f008d1e6c416d90a29ea0591" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model with cv.</source>
          <target state="translated">cv を持つ Fit Ridge 回帰モデル.</target>
        </trans-unit>
        <trans-unit id="2e3e7ebdde04653523f01d0d804ccc0c533f3460" translate="yes" xml:space="preserve">
          <source>Fit Ridge regression model.</source>
          <target state="translated">リッジ回帰モデルをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="74fbf563cb041ef637760be7f01def498fc1300e" translate="yes" xml:space="preserve">
          <source>Fit X into an embedded space and return that transformed output.</source>
          <target state="translated">Xを埋め込み空間にフィットして,その変換された出力を返します.</target>
        </trans-unit>
        <trans-unit id="97ca0bc1677dbeaefd600411062ca557eacc6754" translate="yes" xml:space="preserve">
          <source>Fit X into an embedded space.</source>
          <target state="translated">埋め込まれた空間にXをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="9b21c283121f9ec299302b1b3016dbcdb3391466" translate="yes" xml:space="preserve">
          <source>Fit a Bayesian ridge model and optimize the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</source>
          <target state="translated">ベイジアンリッジモデルをフィットし、正則化パラメータλ(重みの精度)とα(ノイズの精度)を最適化します。</target>
        </trans-unit>
        <trans-unit id="dd6f625705b26516fc692deb07fa9f7046f6035b" translate="yes" xml:space="preserve">
          <source>Fit a Bayesian ridge model. See the Notes section for details on this implementation and the optimization of the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</source>
          <target state="translated">ベイジアンリッジモデルをフィットします。この実装の詳細および正則化パラメータlambda(重みの精度)とα(ノイズの精度)の最適化については,注意事項のセクションを参照してください.</target>
        </trans-unit>
        <trans-unit id="dac39fc69b5b06ff2bcc2ce8d7b8984bce5d49fc" translate="yes" xml:space="preserve">
          <source>Fit a Generalized Linear Model.</source>
          <target state="translated">一般化線形モデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="8bec80135f416f6c22f260fc3b1ac04b4cff59ba" translate="yes" xml:space="preserve">
          <source>Fit a model to the random subset (&lt;code&gt;base_estimator.fit&lt;/code&gt;) and check whether the estimated model is valid (see &lt;code&gt;is_model_valid&lt;/code&gt;).</source>
          <target state="translated">モデルをランダムサブセット（ &lt;code&gt;base_estimator.fit&lt;/code&gt; ）に適合させ、推定モデルが有効かどうかを確認します（ &lt;code&gt;is_model_valid&lt;/code&gt; を参照）。</target>
        </trans-unit>
        <trans-unit id="ebd8c04ad061ef008e394e38c512b2d8b58287fa" translate="yes" xml:space="preserve">
          <source>Fit a semi-supervised label propagation model based</source>
          <target state="translated">に基づく半教師付きラベル伝搬モデルのフィット</target>
        </trans-unit>
        <trans-unit id="deba03b3f9d00ab1e647b43aa626a17c324cec03" translate="yes" xml:space="preserve">
          <source>Fit all the transforms one after the other and transform the data, then fit the transformed data using the final estimator.</source>
          <target state="translated">すべての変換を次々にフィットしてデータを変換し、最終的な推定器を使って変換されたデータをフィットします。</target>
        </trans-unit>
        <trans-unit id="114f8ea42731308cb5abe991bcd972d570944b6a" translate="yes" xml:space="preserve">
          <source>Fit all transformers using X.</source>
          <target state="translated">Xを使用してすべての変圧器をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="246e8826a6bd7a4f56f132c591c766db9ce2d6b0" translate="yes" xml:space="preserve">
          <source>Fit all transformers, transform the data and concatenate results.</source>
          <target state="translated">すべての変換器をフィットさせ、データを変換し、結果を連結します。</target>
        </trans-unit>
        <trans-unit id="922528f3171c2d46b470779ae89446b3062cf8a4" translate="yes" xml:space="preserve">
          <source>Fit estimator and transform dataset.</source>
          <target state="translated">推定器のフィットとデータセットの変換を行う。</target>
        </trans-unit>
        <trans-unit id="54af94e49eb61f7670851d6ef57ae7193fdff2da" translate="yes" xml:space="preserve">
          <source>Fit estimator to data.</source>
          <target state="translated">推定子をデータにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="85fa5fe8b9795ca2b319f392f4a4756a8b584c81" translate="yes" xml:space="preserve">
          <source>Fit estimator using RANSAC algorithm.</source>
          <target state="translated">RANSACアルゴリズムを用いたフィット推定器</target>
        </trans-unit>
        <trans-unit id="820a840249b34711a41e746dbc8ea00e0bef6043" translate="yes" xml:space="preserve">
          <source>Fit estimator.</source>
          <target state="translated">フィット推定器。</target>
        </trans-unit>
        <trans-unit id="c7654cec30bb319e2781e513c9f9ca93708de9b2" translate="yes" xml:space="preserve">
          <source>Fit is on grid of alphas and best alpha estimated by cross-validation.</source>
          <target state="translated">フィットはアルファのグリッド上にあり、クロスバリデーションによって推定された最良のアルファである。</target>
        </trans-unit>
        <trans-unit id="b8cbf7d1420444207c14a8b65b5fcf478860f130" translate="yes" xml:space="preserve">
          <source>Fit label binarizer</source>
          <target state="translated">フィットラベルバイナライザー</target>
        </trans-unit>
        <trans-unit id="e7ecedc7848a8ef424a3d78854bd272e8154c780" translate="yes" xml:space="preserve">
          <source>Fit label binarizer and transform multi-class labels to binary labels.</source>
          <target state="translated">ラベル二値化器をフィットさせ、マルチクラスラベルをバイナリラベルに変換します。</target>
        </trans-unit>
        <trans-unit id="c75cef45e92464b24b2d996a50f9aed44b9ef31e" translate="yes" xml:space="preserve">
          <source>Fit label encoder</source>
          <target state="translated">ラベルエンコーダの適合</target>
        </trans-unit>
        <trans-unit id="5de88deba19907fdf6f6eb3678730f7aacb3c312" translate="yes" xml:space="preserve">
          <source>Fit label encoder and return encoded labels</source>
          <target state="translated">ラベルエンコーダを装着し、エンコードされたラベルを返送</target>
        </trans-unit>
        <trans-unit id="cf615a74e4f9177f1a29f39484c75ecef454ecbe" translate="yes" xml:space="preserve">
          <source>Fit linear model with Passive Aggressive algorithm.</source>
          <target state="translated">パッシブアグレッシブアルゴリズムによる線形モデルのフィット</target>
        </trans-unit>
        <trans-unit id="def5054532c40485109a181ee65c06aba2df1b53" translate="yes" xml:space="preserve">
          <source>Fit linear model with Stochastic Gradient Descent.</source>
          <target state="translated">確率的勾配降下法を用いて線形モデルをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="80dff5f041e36b3407c4f4e7528431510ae562cc" translate="yes" xml:space="preserve">
          <source>Fit linear model with coordinate descent</source>
          <target state="translated">座標降下を用いた線形モデルのフィット</target>
        </trans-unit>
        <trans-unit id="4a42bd8bc00e1e2eb46153b9c0e14ea2a3d30f42" translate="yes" xml:space="preserve">
          <source>Fit linear model.</source>
          <target state="translated">線形モデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="596c5db56f9a987de5f7691971fcf687d77673ec" translate="yes" xml:space="preserve">
          <source>Fit model to data.</source>
          <target state="translated">モデルをデータにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="7bad9b91d21434b63dea0481c80eaf84a7cbcb25" translate="yes" xml:space="preserve">
          <source>Fit model with coordinate descent.</source>
          <target state="translated">座標降下でモデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="8c69e1745d795a8f39d4e8e6661ab7afc8b0bcff" translate="yes" xml:space="preserve">
          <source>Fit regression model</source>
          <target state="translated">フィット回帰モデル</target>
        </trans-unit>
        <trans-unit id="dddcb769b9b69c71c174f417fcd2a333b19f55fd" translate="yes" xml:space="preserve">
          <source>Fit regression model with Bayesian Ridge Regression.</source>
          <target state="translated">ベイズ式リッジ回帰で回帰モデルをフィットさせる。</target>
        </trans-unit>
        <trans-unit id="dda67be7d4db5d3187deb44446a3404222c185a6" translate="yes" xml:space="preserve">
          <source>Fit the ARDRegression model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従ってARDRegressionモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="b5a680830417593aa73dd7de7fcef69c6ed24e1b" translate="yes" xml:space="preserve">
          <source>Fit the EllipticEnvelope model.</source>
          <target state="translated">EllipticEnvelopeモデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="b52ba2a596ae6c033bcc7f3cf20ecd5c58d00c2f" translate="yes" xml:space="preserve">
          <source>Fit the FactorAnalysis model to X using EM</source>
          <target state="translated">EM を使用して X に FactorAnalysis モデルを適合させる</target>
        </trans-unit>
        <trans-unit id="d35f22f8e1c64965b364c3173e1ec356759343b4" translate="yes" xml:space="preserve">
          <source>Fit the FactorAnalysis model to X using SVD based approach</source>
          <target state="translated">SVDベースのアプローチを使用したXへの因子分析モデルのフィット</target>
        </trans-unit>
        <trans-unit id="6613ce48c67ddab345a10c60b764cb90b5d43667" translate="yes" xml:space="preserve">
          <source>Fit the Kernel Density model on the data.</source>
          <target state="translated">データにカーネル密度モデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="18de2bdae7f6b4aabf66891dec1f775662960310" translate="yes" xml:space="preserve">
          <source>Fit the LSH forest on the data.</source>
          <target state="translated">データにLSHフォレストをフィットします。</target>
        </trans-unit>
        <trans-unit id="12a1c0d798db89b07ae159bda7700f6de8a414b1" translate="yes" xml:space="preserve">
          <source>Fit the Ledoit-Wolf shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従って、Ledoit-Wolf縮退共分散モデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="7e835684e570bb3989f14c8abec4c77362174b02" translate="yes" xml:space="preserve">
          <source>Fit the NearestCentroid model according to the given training data.</source>
          <target state="translated">与えられた学習データに基づいてNearestCentroidモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="faef2120c4a0d719909dbc882126884ed71710cf" translate="yes" xml:space="preserve">
          <source>Fit the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた訓練データとパラメータに従って、オラクル近似収縮共分散モデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="f68da32a4110559ba3f4b03666c6374bbe1b67bc" translate="yes" xml:space="preserve">
          <source>Fit the OrdinalEncoder to X.</source>
          <target state="translated">OrdinalEncoderをXにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="9efb3f60cfc062ba641dafe57455afe5be189469" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and automatically tune the number of selected</source>
          <target state="translated">RFEモデルにフィットし、自動的に選択された数を調整します。</target>
        </trans-unit>
        <trans-unit id="a1f31e1eab4986ee8b13885092428f58b3a203e9" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and automatically tune the number of selected features.</source>
          <target state="translated">RFEモデルにフィットし、選択された機能の数を自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="9813edcd03393c0187279f71f7b7e90f266a7ca4" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and then the underlying estimator on the selected</source>
          <target state="translated">RFEモデルをフィットし,選択された</target>
        </trans-unit>
        <trans-unit id="2e888db086bdb6861e2b6c27ddb4959896a661ee" translate="yes" xml:space="preserve">
          <source>Fit the RFE model and then the underlying estimator on the selected features.</source>
          <target state="translated">RFEモデルをフィットしてから,選択した特徴量の基礎となる推定器をフィットします.</target>
        </trans-unit>
        <trans-unit id="3e8e54a78ebc1bc30d8f6371731aa34e571e1cb7" translate="yes" xml:space="preserve">
          <source>Fit the SVM model according to the given training data.</source>
          <target state="translated">与えられた学習データに応じてSVMモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="e094bb2f16b3f77c4f0ded4998dd5acef469f424" translate="yes" xml:space="preserve">
          <source>Fit the SelectFromModel meta-transformer only once.</source>
          <target state="translated">SelectFromModelメタ変換器を一度だけフィットさせます。</target>
        </trans-unit>
        <trans-unit id="4f2b5174d874ffda16493a72eb6b7d9e49692dfa" translate="yes" xml:space="preserve">
          <source>Fit the SelectFromModel meta-transformer.</source>
          <target state="translated">SelectFromModelメタ変換器をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="48df38063d696d0aeb8b0988a010338565cac757" translate="yes" xml:space="preserve">
          <source>Fit the calibrated model</source>
          <target state="translated">校正済みモデルの適合</target>
        </trans-unit>
        <trans-unit id="c57e47c49821e6802e2a740c9051d8c66c744ebb" translate="yes" xml:space="preserve">
          <source>Fit the clustering from features or affinity matrix, and return cluster labels.</source>
          <target state="translated">特徴量またはアフィニティ行列からクラスタリングをフィットし、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="d9687ab7d6ecd0d65550bf660d242c20bd8d898b" translate="yes" xml:space="preserve">
          <source>Fit the clustering from features, or affinity matrix.</source>
          <target state="translated">特徴量からのクラスタリング、またはアフィニティマトリクスをフィットします。</target>
        </trans-unit>
        <trans-unit id="548ac10033a88a7f2f90c29b16d9b1eac7c9baf8" translate="yes" xml:space="preserve">
          <source>Fit the data from X, and returns the embedded coordinates</source>
          <target state="translated">Xからデータをフィットし、埋め込まれた座標を返します。</target>
        </trans-unit>
        <trans-unit id="08758549856b6a0e509ce1e713cae02d47e4bedc" translate="yes" xml:space="preserve">
          <source>Fit the estimator.</source>
          <target state="translated">推定器をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="855887273459477b0845aa915278722b2bfdc95e" translate="yes" xml:space="preserve">
          <source>Fit the estimators.</source>
          <target state="translated">推定値をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="78a5f0fa7f9e8e8876e6f8fdd879d2a72169691e" translate="yes" xml:space="preserve">
          <source>Fit the gradient boosting model.</source>
          <target state="translated">勾配昇圧モデルをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="59e531372ee14a17e072823da12da9c216d03637" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering from features or distance matrix, and return cluster labels.</source>
          <target state="translated">特徴量や距離行列から階層的なクラスタリングをフィットし、クラスタラベルを返します。</target>
        </trans-unit>
        <trans-unit id="5f5e34ffa1bdd98c15becac765f254aeb2f0a093" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering from features, or distance matrix.</source>
          <target state="translated">特徴量、または距離行列から階層的なクラスタリングをフィットします。</target>
        </trans-unit>
        <trans-unit id="6951b3b9c1e77870a95debb989a3776ac4c5d6a1" translate="yes" xml:space="preserve">
          <source>Fit the hierarchical clustering on the data</source>
          <target state="translated">データに階層的クラスタリングを適合させる</target>
        </trans-unit>
        <trans-unit id="5b5563854bcbf3fe8e972427b6550f84e6f5e44a" translate="yes" xml:space="preserve">
          <source>Fit the imputer on X.</source>
          <target state="translated">Xにインパを装着。</target>
        </trans-unit>
        <trans-unit id="f79ad350ada74918a25b6a18b9c98a44219aea81" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer and transform the given label sets</source>
          <target state="translated">ラベルセットの二値化器をフィットし,与えられたラベルセットを変換します.</target>
        </trans-unit>
        <trans-unit id="93ac61c2b8893a8a8dc44af4d06cf2252851b7b2" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer, storing &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-classes&quot;&gt;classes_&lt;/a&gt;</source>
          <target state="translated">ラベルセットを2値化して、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-classes&quot;&gt;classes_を&lt;/a&gt;格納します。</target>
        </trans-unit>
        <trans-unit id="aff4cb7658d810f05c33be44cd22feded7d4bab1" translate="yes" xml:space="preserve">
          <source>Fit the label sets binarizer, storing &lt;code&gt;classes_&lt;/code&gt;</source>
          <target state="translated">ラベルセットを二値化し、 &lt;code&gt;classes_&lt;/code&gt; 保存します_</target>
        </trans-unit>
        <trans-unit id="8fe48671e323549fd93560341a4a3c7b625e4c7d" translate="yes" xml:space="preserve">
          <source>Fit the model</source>
          <target state="translated">モデルをフィットさせる</target>
        </trans-unit>
        <trans-unit id="4a0fb954f184570eb54f89782d45ff6b62de8f93" translate="yes" xml:space="preserve">
          <source>Fit the model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従ってモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="226810036d48f43519ac6362c835a5ebb75ac273" translate="yes" xml:space="preserve">
          <source>Fit the model according to the given training data.</source>
          <target state="translated">与えられた学習データに基づいてモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="12dc3b0f35bd8c187f3d6ad72da28e55416ad4ec" translate="yes" xml:space="preserve">
          <source>Fit the model and recover the sources from X.</source>
          <target state="translated">モデルをフィットさせ、Xからソースを回収します。</target>
        </trans-unit>
        <trans-unit id="71e9ee1734e2bbf9ac4fe07ac1b6c03c04237b08" translate="yes" xml:space="preserve">
          <source>Fit the model and transform with the final estimator</source>
          <target state="translated">モデルを適合させ,最終推定器で変換する</target>
        </trans-unit>
        <trans-unit id="6b8aa0f161bb8a77dc4775ed1ee1fcfc2c406c82" translate="yes" xml:space="preserve">
          <source>Fit the model from data in X and transform X.</source>
          <target state="translated">Xのデータからモデルをフィットし、Xを変換します。</target>
        </trans-unit>
        <trans-unit id="0aa179622924cc08ee70a31764d01ab49bbf6bcd" translate="yes" xml:space="preserve">
          <source>Fit the model from data in X.</source>
          <target state="translated">Xのデータからモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="09a244ac4f08853db4f27fa0f56ca2d8ae157c91" translate="yes" xml:space="preserve">
          <source>Fit the model to X.</source>
          <target state="translated">モデルをXにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="d8fc33348e2baabb167cc4df9e594abe384c1eb2" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and target y.</source>
          <target state="translated">データ行列Xとターゲットyにモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="a08fe1d5397b99194d7ea288b13912038b863a22" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and target(s) y.</source>
          <target state="translated">モデルをデータ行列Xとターゲット(複数可)yにフィットします。</target>
        </trans-unit>
        <trans-unit id="5260da8ec9e88ebba64d6137961aeb8e84b7f391" translate="yes" xml:space="preserve">
          <source>Fit the model to data matrix X and targets Y.</source>
          <target state="translated">モデルをデータ行列XとターゲットYにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="45ba17915e2e3031d1582da2d277da7f4931a4e1" translate="yes" xml:space="preserve">
          <source>Fit the model to data.</source>
          <target state="translated">モデルをデータにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="afd434d49f80c8d01132ca406d4c79b805654e96" translate="yes" xml:space="preserve">
          <source>Fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">モデルをデータにフィットする.各出力変数に個別のモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="cfdc299b35aa8a48c0af501e27ae7cce65e8f528" translate="yes" xml:space="preserve">
          <source>Fit the model to the data X which should contain a partial segment of the data.</source>
          <target state="translated">データの部分的なセグメントを含むデータXにモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="b93160749fdae6a7fa042ecb31b3787d54faa056" translate="yes" xml:space="preserve">
          <source>Fit the model to the data X.</source>
          <target state="translated">モデルをデータXにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="22b95bc22aacaf67cf593094b402a5ffdf9c9f1a" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data</source>
          <target state="translated">Xを学習データとして使用してモデルをフィット</target>
        </trans-unit>
        <trans-unit id="c8f2bc6ec471b46a95d660913e3db5351ccdd413" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data and y as target values</source>
          <target state="translated">Xを学習データ、yを目標値としてモデルを適合させる</target>
        </trans-unit>
        <trans-unit id="67d84010e7f659892bf337ed29c5877ed8354203" translate="yes" xml:space="preserve">
          <source>Fit the model using X as training data.</source>
          <target state="translated">Xを学習データとして使用してモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="3b6c346e2454cc9e9a61a017fe7c431d552c8c5b" translate="yes" xml:space="preserve">
          <source>Fit the model using X, y as training data.</source>
          <target state="translated">X,yを学習データとして使用してモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="5c7f073bf35ac36015511e86a701acdf9d1f18c6" translate="yes" xml:space="preserve">
          <source>Fit the model with X and apply the dimensionality reduction on X.</source>
          <target state="translated">モデルをXでフィットし、Xに次元削減を適用します。</target>
        </trans-unit>
        <trans-unit id="ea7ce544f3a486e6f2a49538bf4fe64bf5a8afde" translate="yes" xml:space="preserve">
          <source>Fit the model with X, using minibatches of size batch_size.</source>
          <target state="translated">サイズbatch_sizeのミニバッチを使用して、Xでモデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="e7967bf329b3c1f757d75d92e374951929321ba7" translate="yes" xml:space="preserve">
          <source>Fit the model with X.</source>
          <target state="translated">モデルをXでフィットさせます。</target>
        </trans-unit>
        <trans-unit id="a5abbc09518b549e779e08db2e6e49f0ba32533d" translate="yes" xml:space="preserve">
          <source>Fit the random classifier.</source>
          <target state="translated">ランダム分類器を適合させます.</target>
        </trans-unit>
        <trans-unit id="30f7575e3bac8aaa2852370b548ad3f04b290586" translate="yes" xml:space="preserve">
          <source>Fit the random regressor.</source>
          <target state="translated">ランダム回帰器をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="4fae2d49ee8a5e8d8ea52343db3e2b05ff45988e" translate="yes" xml:space="preserve">
          <source>Fit the ridge classifier.</source>
          <target state="translated">リッジ分類器をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="1e4446f620ec40ca22b46eba2b6f8ce6be3c57e2" translate="yes" xml:space="preserve">
          <source>Fit the shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従って,縮退共分散モデルをフィットする.</target>
        </trans-unit>
        <trans-unit id="2b96765d688b574c756064537ec2686c8ac36571" translate="yes" xml:space="preserve">
          <source>Fit the transformer on X.</source>
          <target state="translated">トランスをXに装着します。</target>
        </trans-unit>
        <trans-unit id="acd485cd941415835a11d2180278c2146ce5888c" translate="yes" xml:space="preserve">
          <source>Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Also estimate the parameters lambda (precisions of the distributions of the weights) and alpha (precision of the distribution of the noise). The estimation is done by an iterative procedures (Evidence Maximization)</source>
          <target state="translated">ARD事前分布を用いて,回帰モデルの重みを適合させる.回帰モデルの重みは,ガウス分布にあると仮定する.また,パラメータ λ (重みの分布の精度)と alpha (ノイズの分布の精度)を推定する.推定は,繰り返し処理(Evidence Maximization)によって行われる.</target>
        </trans-unit>
        <trans-unit id="ea18404b90123396c3f41537d11afad54c507780" translate="yes" xml:space="preserve">
          <source>Fit to data, then transform it.</source>
          <target state="translated">データにフィットし、変換します。</target>
        </trans-unit>
        <trans-unit id="c2cf341635a3875675d46dd618b9a1757d9a6c7c" translate="yes" xml:space="preserve">
          <source>Fit transformer by checking X.</source>
          <target state="translated">Xを確認してトランスをフィットさせます。</target>
        </trans-unit>
        <trans-unit id="eb75d7eb91b3dadf245e1b3bf8f4c37a27824085" translate="yes" xml:space="preserve">
          <source>Fit underlying estimators.</source>
          <target state="translated">基礎となる推定子をフィットさせます。</target>
        </trans-unit>
        <trans-unit id="c093c0cee7f3b9fa93ffb32acb026baea322889f" translate="yes" xml:space="preserve">
          <source>Fits a Minimum Covariance Determinant with the FastMCD algorithm.</source>
          <target state="translated">FastMCDアルゴリズムを用いて最小共分散決定量にフィットします。</target>
        </trans-unit>
        <trans-unit id="f30506afc59d08eae550fdeb02ae856731ea996b" translate="yes" xml:space="preserve">
          <source>Fits all the transforms one after the other and transforms the data, then uses fit_transform on transformed data with the final estimator.</source>
          <target state="translated">すべての変換を次々にはめ込み、データを変換してから、変換されたデータ上で fit_transform を使用して最終的な推定量を指定します。</target>
        </trans-unit>
        <trans-unit id="c5c1cc9c0352ec3e2d5fcc0df63b71ce152f382f" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso covariance model to X.</source>
          <target state="translated">GraphicalLassoの共分散モデルをXにフィットします.</target>
        </trans-unit>
        <trans-unit id="268ae9ae0a9043d80b2e575c7e344f83f78e662d" translate="yes" xml:space="preserve">
          <source>Fits the GraphicalLasso model to X.</source>
          <target state="translated">GraphicalLassoモデルをXにフィットさせます。</target>
        </trans-unit>
        <trans-unit id="643e04850030e1e1aeeaf619a88e7dab7e6a06be" translate="yes" xml:space="preserve">
          <source>Fits the Ledoit-Wolf shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従って,Ledoit-Wolf縮退共分散モデルを適合させます.</target>
        </trans-unit>
        <trans-unit id="60a2c06b8221e361c36d5fdce8ee644d8456bfce" translate="yes" xml:space="preserve">
          <source>Fits the Maximum Likelihood Estimator covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた訓練データとパラメータに従って最尤推定器の共分散モデルを適合させます.</target>
        </trans-unit>
        <trans-unit id="9b00c787fd8f13356df0bf86c478f2b7848ac4d7" translate="yes" xml:space="preserve">
          <source>Fits the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた訓練データとパラメータに従って、Oracle近似収縮共分散モデルをフィットします。</target>
        </trans-unit>
        <trans-unit id="2fb3d8548147a6429a7eeed9e3fbe0456049bc8c" translate="yes" xml:space="preserve">
          <source>Fits the estimator.</source>
          <target state="translated">見積もりにフィットします。</target>
        </trans-unit>
        <trans-unit id="3cea2475743e34d34ded723467b2a735e1203cfc" translate="yes" xml:space="preserve">
          <source>Fits the imputer on X and return self.</source>
          <target state="translated">Xにインパにフィットして自己を返す。</target>
        </trans-unit>
        <trans-unit id="6bb471485459c492057aae581eaa0cf9c4592a1d" translate="yes" xml:space="preserve">
          <source>Fits the imputer on X and return the transformed X.</source>
          <target state="translated">X上のインピュータにフィットし、変換されたXを返します。</target>
        </trans-unit>
        <trans-unit id="c13921c2e1a959ce7d05648d804f502aded299cf" translate="yes" xml:space="preserve">
          <source>Fits the model to the training set X and returns the labels.</source>
          <target state="translated">モデルを学習集合Xに適合させ,ラベルを返します.</target>
        </trans-unit>
        <trans-unit id="98f6beb1ac87a74b86b8c1fedd5ae0ed0ac89461" translate="yes" xml:space="preserve">
          <source>Fits the shrunk covariance model according to the given training data and parameters.</source>
          <target state="translated">与えられた学習データとパラメータに従って,縮退共分散モデルを適合させます.</target>
        </trans-unit>
        <trans-unit id="f072640da94e1ad56e67373f3632aeaebdd8b854" translate="yes" xml:space="preserve">
          <source>Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.</source>
          <target state="translated">変換器を X と y に、 オプシ ョ ンの引数 fit_params ではめ込み、 変換後の X を返します。</target>
        </trans-unit>
        <trans-unit id="06f59e2a32c90e6aa8aff9dfb100b6f03f2af9ff" translate="yes" xml:space="preserve">
          <source>Fitted classifier or a fitted &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; in which the last estimator is a classifier.</source>
          <target state="translated">適合分類器または最後の推定量が分類器である適合&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e0dea44d64bdac3b47bf2c46576cad767f74d843" translate="yes" xml:space="preserve">
          <source>Fitted estimator.</source>
          <target state="translated">フィットした見積もり。</target>
        </trans-unit>
        <trans-unit id="fd568de48dadd27cd4e3ca2395da082642e8f8ec" translate="yes" xml:space="preserve">
          <source>Fitted regressor.</source>
          <target state="translated">フィットしたレグレッサー。</target>
        </trans-unit>
        <trans-unit id="f162f6bcf340dc521df64a1aae70440e61c389db" translate="yes" xml:space="preserve">
          <source>Fitted scaler.</source>
          <target state="translated">フィットしたスケーラー。</target>
        </trans-unit>
        <trans-unit id="bccb0ee0062e477c480530940a0aca37551f6020" translate="yes" xml:space="preserve">
          <source>Fitted vectorizer.</source>
          <target state="translated">フィットしたベクタライザ。</target>
        </trans-unit>
        <trans-unit id="14c6da7cd39661e1b0c6468a3c6a5907d4f99a9c" translate="yes" xml:space="preserve">
          <source>Fitting transformers may be computationally expensive. With its &lt;code&gt;memory&lt;/code&gt; parameter set, &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; will cache each transformer after calling &lt;code&gt;fit&lt;/code&gt;. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical. A typical example is the case of a grid search in which the transformers can be fitted only once and reused for each configuration.</source>
          <target state="translated">フィッティングトランスフォーマーは、計算コストがかかる場合があります。そのでは &lt;code&gt;memory&lt;/code&gt; パラメータセット、&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;呼び出した後、各トランスをキャッシュします &lt;code&gt;fit&lt;/code&gt; 。この機能は、パラメーターと入力データが同一の場合に、パイプライン内のフィットトランスフォーマーの計算を回避するために使用されます。典型的な例は、変圧器を1回だけ取り付けて、構成ごとに再利用できるグリッド検索の場合です。</target>
        </trans-unit>
        <trans-unit id="01fe05c223cb56d84d085e38ca62de1932a87e50" translate="yes" xml:space="preserve">
          <source>Flag indicating if the cross-validation values corresponding to each alpha should be stored in the &lt;code&gt;cv_values_&lt;/code&gt; attribute (see below). This flag is only compatible with &lt;code&gt;cv=None&lt;/code&gt; (i.e. using Generalized Cross-Validation).</source>
          <target state="translated">各アルファに対応する相互検証値を &lt;code&gt;cv_values_&lt;/code&gt; 属性に格納する必要があるかどうかを示すフラグ（以下を参照）。このフラグは、 &lt;code&gt;cv=None&lt;/code&gt; とのみ互換性があります（つまり、一般化交差検証を使用）。</target>
        </trans-unit>
        <trans-unit id="1f498759924682e2363e94f7b83282b97429fcf5" translate="yes" xml:space="preserve">
          <source>Flag indicating which strategy to use when performing Generalized Cross-Validation. Options are:</source>
          <target state="translated">一般化クロスバリデーションを実行する際に使用するストラテジーを示すフラグ。オプションは以下の通りです。</target>
        </trans-unit>
        <trans-unit id="3407c4421a1f6ede0cab565dc5123546e65ddde6" translate="yes" xml:space="preserve">
          <source>Flat geometry, good for density estimation</source>
          <target state="translated">フラットな形状、密度推定に適しています。</target>
        </trans-unit>
        <trans-unit id="748a38982c93bb25fbfeb18b34277c35439ac98c" translate="yes" xml:space="preserve">
          <source>Flavanoids</source>
          <target state="translated">Flavanoids</target>
        </trans-unit>
        <trans-unit id="f55beb472c3b08362b7861294963760ddd037d08" translate="yes" xml:space="preserve">
          <source>Flavanoids:</source>
          <target state="translated">Flavanoids:</target>
        </trans-unit>
        <trans-unit id="1bf94453d6aa9e9092828eefafa6394692100339" translate="yes" xml:space="preserve">
          <source>Flexible pickling control for the communication to and from the worker processes.</source>
          <target state="translated">作業者工程とのやり取りに柔軟な酸洗制御が可能です。</target>
        </trans-unit>
        <trans-unit id="2d83a2dbf42ef510856c4fe5eb69b3efa4599763" translate="yes" xml:space="preserve">
          <source>Flow Chart</source>
          <target state="translated">フローチャート</target>
        </trans-unit>
        <trans-unit id="87698cca8f914c77b735bad53fe489d2af135e70" translate="yes" xml:space="preserve">
          <source>Folder to be used by the pool for memmapping large arrays for sharing memory with worker processes. If None, this will try in order:</source>
          <target state="translated">ワーカープロセスとメモリを共有するための大規模な配列をメモマップするためにプールが使用するフォルダ。Noneの場合は、順番に試行します。</target>
        </trans-unit>
        <trans-unit id="c09a9bf27e9aabfc7b35dc309da81eb816c5e989" translate="yes" xml:space="preserve">
          <source>Following special cases exist,</source>
          <target state="translated">以下のような特殊なケースがあります。</target>
        </trans-unit>
        <trans-unit id="313fc38f449c398563f152e4416c92af47202923" translate="yes" xml:space="preserve">
          <source>Follows Algorithm 4.3 of Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) http://arxiv.org/pdf/0909.4061</source>
          <target state="translated">ランダム性のある構造を見つけるのアルゴリズム4.3に従う。近似行列分解を構築するための確率的アルゴリズム Halko,et al.,2009 (arXiv:909)http://arxiv.org/pdf/0909.4061</target>
        </trans-unit>
        <trans-unit id="061a7a165d75c1efa21f2a2a8a850415a95a5911" translate="yes" xml:space="preserve">
          <source>Follows Algorithm 4.3 of Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions Halko, et al., 2009 (arXiv:909) https://arxiv.org/pdf/0909.4061.pdf</source>
          <target state="translated">ランダム性のある構造を見つけるのアルゴリズム4.3に従う。近似行列分解を構築するための確率的アルゴリズム Halko,et al.,2009 (arXiv:909)https://arxiv.org/pdf/0909.4061.pdf</target>
        </trans-unit>
        <trans-unit id="ec0c3b76630fd745381cc215a284820af75a683a" translate="yes" xml:space="preserve">
          <source>Footnotes</source>
          <target state="translated">Footnotes</target>
        </trans-unit>
        <trans-unit id="871453ce5a358112246d8fa103eff55b515e95a2" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;one-vs-rest&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;(n_classes, n_features)&lt;/code&gt; and &lt;code&gt;(n_classes,)&lt;/code&gt; respectively. Each row of the coefficients corresponds to one of the &lt;code&gt;n_classes&lt;/code&gt; &amp;ldquo;one-vs-rest&amp;rdquo; classifiers and similar for the intercepts, in the order of the &amp;ldquo;one&amp;rdquo; class.</source>
          <target state="translated">「one-vs-rest」&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; の場合&lt;/a&gt;、属性 &lt;code&gt;coef_&lt;/code&gt; と &lt;code&gt;intercept_&lt;/code&gt; はそれぞれ &lt;code&gt;(n_classes, n_features)&lt;/code&gt; と &lt;code&gt;(n_classes,)&lt;/code&gt; ます。係数の各行は、 &lt;code&gt;n_classes&lt;/code&gt; の「one-vs-rest」分類子の1つに対応し、「one」クラスの順序で切片に類似しています。</target>
        </trans-unit>
        <trans-unit id="41e2c901c13d4daacf7c9adad4d559c077a8e51e" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;one-vs-rest&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class, n_features]&lt;/code&gt; and &lt;code&gt;[n_class]&lt;/code&gt; respectively. Each row of the coefficients corresponds to one of the &lt;code&gt;n_class&lt;/code&gt; many &amp;ldquo;one-vs-rest&amp;rdquo; classifiers and similar for the intercepts, in the order of the &amp;ldquo;one&amp;rdquo; class.</source>
          <target state="translated">「one-vs-rest」の&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; の場合&lt;/a&gt;、属性 &lt;code&gt;coef_&lt;/code&gt; および &lt;code&gt;intercept_&lt;/code&gt; の形状はそれぞれ &lt;code&gt;[n_class, n_features]&lt;/code&gt; および &lt;code&gt;[n_class]&lt;/code&gt; です。係数の各行は、「1」クラスの順序で、切片の &lt;code&gt;n_class&lt;/code&gt; 多くの「1対rest」分類子の 1つに対応し、類似しています。</target>
        </trans-unit>
        <trans-unit id="c6cc35fe8de003f58f84a7c02bbc9d4b652dc227" translate="yes" xml:space="preserve">
          <source>For &amp;ldquo;pairwise&amp;rdquo; metrics, between &lt;em&gt;samples&lt;/em&gt; and not estimators or predictions, see the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section.</source>
          <target state="translated">推定器や予測ではなく&lt;em&gt;サンプル&lt;/em&gt;間の「ペアワイズ」メトリックについては、&lt;a href=&quot;metrics#metrics&quot;&gt;ペアワイズメトリック、アフィニティとカーネルの&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="935f9d2961eec1b64a8d3f62208c3a16e0e7ef63" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; of trees (e.g. RandomForest, GBT, ExtraTrees etc) the number of trees and their depth play the most important role. Latency and throughput should scale linearly with the number of trees. In this case we used directly the &lt;code&gt;n_estimators&lt;/code&gt; parameter of &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;（例えばランダムフォレスト、GBT、ExtraTreesなど）の木の木の数とその深さが最も重要な役割を果たしています。レイテンシとスループットは、ツリーの数に比例してスケーリングする必要があります。このケースでは、直接使用 &lt;code&gt;n_estimators&lt;/code&gt; のパラメータ &lt;code&gt;sklearn.ensemble.gradient_boosting.GradientBoostingRegressor&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="c2e53d45d0579b4b39658069206cb04a03ac3808" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; (e.g. Lasso, ElasticNet, SGDClassifier/Regressor, Ridge &amp;amp; RidgeClassifier, PassiveAggressiveClassifier/Regressor, LinearSVC, LogisticRegression&amp;hellip;) the decision function that is applied at prediction time is the same (a dot product) , so latency should be equivalent.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; &lt;/a&gt;（例えば投げ縄、ElasticNet、SGDClassifier /回帰、リッジ＆RidgeClassifier、PassiveAggressiveClassifier /回帰、LinearSVC、ロジスティック回帰...）予測時に適用される決定関数はそれほどの待ち時間と同等である必要があり、（内積）と同じです。</target>
        </trans-unit>
        <trans-unit id="b1a84d28126765870388f5c6f8149674d42fd858" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt;, note that the output of the &lt;code&gt;estimators&lt;/code&gt; is controlled by the parameter &lt;code&gt;stack_method&lt;/code&gt; and it is called by each estimator. This parameter is either a string, being estimator method names, or &lt;code&gt;'auto'&lt;/code&gt; which will automatically identify an available method depending on the availability, tested in the order of preference: &lt;code&gt;predict_proba&lt;/code&gt;, &lt;code&gt;decision_function&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt;.</source>
          <target state="translated">ため&lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt; &lt;code&gt;StackingClassifier&lt;/code&gt; &lt;/a&gt;の出力なお、 &lt;code&gt;estimators&lt;/code&gt; 、パラメータによって制御され &lt;code&gt;stack_method&lt;/code&gt; 、それは各推定器によって呼び出されます。このパラメータは、推定メソッド名、または対象の文字列のいずれかである &lt;code&gt;'auto'&lt;/code&gt; ：自動的に優先順に試験可用性に応じて利用できる方法、同定する &lt;code&gt;predict_proba&lt;/code&gt; 、 &lt;code&gt;decision_function&lt;/code&gt; しそして &lt;code&gt;predict&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="d5bf64c1d60fc523cf9cf35c71f5018653089c51" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt;, when using &lt;code&gt;stack_method_='predict_proba'&lt;/code&gt;, the first column is dropped when the problem is a binary classification problem. Indeed, both probability columns predicted by each estimator are perfectly collinear.</source>
          <target state="translated">ため&lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt; &lt;code&gt;StackingClassifier&lt;/code&gt; &lt;/a&gt;使用する場合、 &lt;code&gt;stack_method_='predict_proba'&lt;/code&gt; 問題は、バイナリ分類問題である場合、最初の列はドロップされます。実際、各推定量によって予測された両方の確率列は完全に同一線上にあります。</target>
        </trans-unit>
        <trans-unit id="6d0c4acadc1a3e244ad80f139e9b2149c5787665" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;) any input passed as a numpy array will be copied and converted to the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input, we suggest to use the &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; class instead. The objective function can be configured to be almost the same as the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; model.</source>
          <target state="translated">ため&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;（及び&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;）numpyの配列をコピーしてに変換されるように渡される入力&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;内部疎データ表現（倍精度浮動小数点数と非ゼロ成分のINT32インデックス）。密集した&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt;連続倍精度配列を入力としてコピーせずに大規模な線形分類器を適合させたい場合は、代わりにSGDClassifierクラスを使用することをお勧めします。目的関数は、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;モデルとほぼ同じになるように構成できます。</target>
        </trans-unit>
        <trans-unit id="8582a7ae6ed830b76bb2d9fd21363d4d3995f59c" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; (and &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;) any input passed as a numpy array will be copied and converted to the liblinear internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input we suggest to use the &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; class instead. The objective function can be configured to be almost the same as the &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; model.</source>
          <target state="translated">ため&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;（及び&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;）numpyの配列をコピーしてliblinear内部疎データ表現（倍精度浮動小数点数と非ゼロ成分のINT32インデックス）に変換されるように渡される入力。入力として密集した巨大なC隣接の倍精度配列をコピーせずに大規模な線形分類子を適合させたい場合は、代わりに&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt;クラスを使用することをお勧めします。目的関数は、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;モデルとほぼ同じになるように構成できます。</target>
        </trans-unit>
        <trans-unit id="2643eb1343d14a8cde9753d0546e2bd56743d7c1" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, the &amp;lsquo;recursion&amp;rsquo; method (used by default) will not account for the &lt;code&gt;init&lt;/code&gt; predictor of the boosting process. In practice, this will produce the same values as &amp;lsquo;brute&amp;rsquo; up to a constant offset in the target response, provided that &lt;code&gt;init&lt;/code&gt; is a constant estimator (which is the default). However, if &lt;code&gt;init&lt;/code&gt; is not a constant estimator, the partial dependence values are incorrect for &amp;lsquo;recursion&amp;rsquo; because the offset will be sample-dependent. It is preferable to use the &amp;lsquo;brute&amp;rsquo; method. Note that this only applies to &lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, not to &lt;a href=&quot;sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;、（デフォルトで使用）「再帰」メソッドが占めるません &lt;code&gt;init&lt;/code&gt; 高めるプロセスの予測因子。実際には、 &lt;code&gt;init&lt;/code&gt; が一定の推定量（デフォルト）である場合、これはターゲット応答の一定のオフセットまで「brute」と同じ値を生成します。ただし、 &lt;code&gt;init&lt;/code&gt; が定数推定量でない場合、オフセットはサンプルに依存するため、「再帰」の部分依存値は正しくありません。 'brute'メソッドを使用することをお勧めします。これは&lt;a href=&quot;sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; に&lt;/a&gt;のみ適用され、&lt;a href=&quot;sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f9c95b352fd6ddba1a98d2caa12d747735ff41c3" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;0 &amp;lt; power &amp;lt; 1&lt;/code&gt;, no distribution exists.</source>
          <target state="translated">以下のために &lt;code&gt;0 &amp;lt; power &amp;lt; 1&lt;/code&gt; 、全く分布は存在しません。</target>
        </trans-unit>
        <trans-unit id="e56c72d645a0047396221ed2eb5407914a9b6bf6" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;make_classification&lt;/code&gt;, three binary and two multi-class classification datasets are generated, with different numbers of informative features and clusters per class.</source>
          <target state="translated">&lt;code&gt;make_classification&lt;/code&gt; 、3進と2つのマルチクラス分類データセットは、有益な機能やクラスごとのクラスタの数が異なると、生成されます。</target>
        </trans-unit>
        <trans-unit id="dda7c631740b122861937f9ebbfdde73fd44b016" translate="yes" xml:space="preserve">
          <source>For Gaussian distributed data, the distance of an observation \(x_i\) to the mode of the distribution can be computed using its Mahalanobis distance: \(d_{(\mu,\Sigma)}(x_i)^2 = (x_i - \mu)'\Sigma^{-1}(x_i - \mu)\) where \(\mu\) and \(\Sigma\) are the location and the covariance of the underlying Gaussian distribution.</source>
          <target state="translated">Gaussian分布データの場合、分布のモードへの観測の距離は、そのマハラノビス距離を使って計算することができます。\(d_{(\mu,\Sigma)}(x_i)^2=(x_i-\mu)'\Sigma^{-1}(x_i-ﾞ\mu))ここで、\(\(i)と\(i)Sigmaは、位置と分布の共分散である。</target>
        </trans-unit>
        <trans-unit id="3fb903a20f5aad7e20f9123d2edfa2a0638dc6bc" translate="yes" xml:space="preserve">
          <source>For \(k\) clusters, the Calinski-Harabaz score \(s\) is given as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:</source>
          <target state="translated">クラスタの場合、Calinski-Harabazのスコアは、クラスタ間分散の平均とクラスタ内分散の比として与えられます。</target>
        </trans-unit>
        <trans-unit id="d27bcc7c91650762beefd01dc3089ec6978d5c87" translate="yes" xml:space="preserve">
          <source>For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.</source>
          <target state="translated">分類モデルでは,X の各標本の予測されたクラスが返されます.回帰モデルでは,Xに基づく予測値が返されます.</target>
        </trans-unit>
        <trans-unit id="e6fd66f776dfd09a091bc857e8c9d10d50ac3ba8" translate="yes" xml:space="preserve">
          <source>For a comparison of the different scalers, transformers, and normalizers, see &lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;examples/preprocessing/plot_all_scaling.py&lt;/a&gt;.</source>
          <target state="translated">さまざまなスケーラー、トランスフォーマー、ノーマライザの比較については、&lt;a href=&quot;../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;examples / preprocessing / plot_all_scaling.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="33f57a2a03940da66a0808ac0a9d7e45bc98afe2" translate="yes" xml:space="preserve">
          <source>For a complete probabilistic model we also need a prior distribution for the latent variable \(h\). The most straightforward assumption (based on the nice properties of the Gaussian distribution) is \(h \sim \mathcal{N}(0, \mathbf{I})\). This yields a Gaussian as the marginal distribution of \(x\):</source>
          <target state="translated">完全な確率モデルのためには、潜在変数のための事前分布も必要です。最も簡単な仮定は(ガウス分布の良い性質に基づいて)、 これは、ガウス分布の限界分布となります。</target>
        </trans-unit>
        <trans-unit id="7e3b25cfbbacb17bf9ce066c3983b6610e3fab10" translate="yes" xml:space="preserve">
          <source>For a constant learning rate use &lt;code&gt;learning_rate='constant'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the learning rate.</source>
          <target state="translated">一定の学習率の場合、 &lt;code&gt;learning_rate='constant'&lt;/code&gt; を使用し、 &lt;code&gt;eta0&lt;/code&gt; を使用して学習率を指定します。</target>
        </trans-unit>
        <trans-unit id="76a9227cf28fa05c9bb19673e15a2774476a035c" translate="yes" xml:space="preserve">
          <source>For a description of the implementation and details of the algorithms used, please refer to</source>
          <target state="translated">実装の説明と使用されているアルゴリズムの詳細については、以下を参照してください。</target>
        </trans-unit>
        <trans-unit id="ccaff5036b34bf3986d666eb2f98e4ef943f3dfd" translate="yes" xml:space="preserve">
          <source>For a discussion and comparison of these algorithms, see the &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;manifold module page&lt;/a&gt;</source>
          <target state="translated">これらのアルゴリズムの説明と比較については、&lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;多様体モジュールのページを参照してください&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7b7d7f03d534f8340da15e8579a79cb680de77bd" translate="yes" xml:space="preserve">
          <source>For a document generated from multiple topics, all topics are weighted equally in generating its bag of words.</source>
          <target state="translated">複数のトピックから生成されたドキュメントの場合、すべてのトピックは、その単語袋を生成する際に等しく重み付けされます。</target>
        </trans-unit>
        <trans-unit id="b87483db50bfd800e7f61326ccd19592abcc3547" translate="yes" xml:space="preserve">
          <source>For a few of the best biclusters, its most common document categories and its ten most important words get printed. The best biclusters are determined by their normalized cut. The best words are determined by comparing their sums inside and outside the bicluster.</source>
          <target state="translated">最高のバイクラスターのいくつかについては、その最も一般的な文書カテゴリとその10の最も重要な単語が印刷されます。最良のバイクラスターは、その正規化されたカットによって決定されます。最良の単語は、双クラスタの内側と外側の合計を比較することで決定されます。</target>
        </trans-unit>
        <trans-unit id="859f5c51d38da3ad244e41ebf28b507a4a99bc62" translate="yes" xml:space="preserve">
          <source>For a full code example that demonstrates using a &lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt;&lt;code&gt;FunctionTransformer&lt;/code&gt;&lt;/a&gt; to do custom feature selection, see &lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;Using FunctionTransformer to select columns&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.preprocessing.functiontransformer#sklearn.preprocessing.FunctionTransformer&quot;&gt; &lt;code&gt;FunctionTransformer&lt;/code&gt; &lt;/a&gt;を使用してカスタム機能選択を行う方法を示す完全なコード例については、FunctionTransformerを&lt;a href=&quot;../auto_examples/preprocessing/plot_function_transformer#sphx-glr-auto-examples-preprocessing-plot-function-transformer-py&quot;&gt;使用した列の&lt;/a&gt;選択を参照してください。</target>
        </trans-unit>
        <trans-unit id="a29c02b5f33160de772eacbd74337a53f6625181" translate="yes" xml:space="preserve">
          <source>For a full-fledged example of out-of-core scaling in a text classification task see &lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core classification of text documents&lt;/a&gt;.</source>
          <target state="translated">テキスト分類タスクでのコア外スケーリングの完全な例については&lt;a href=&quot;../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;、テキストドキュメントのコア外&lt;/a&gt;分類を参照してください。</target>
        </trans-unit>
        <trans-unit id="d78aafa74d01fdbbdb67982f22aabb8fb92e6131" translate="yes" xml:space="preserve">
          <source>For a given value of &lt;code&gt;n_components&lt;/code&gt;&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is often less accurate as &lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt;&lt;code&gt;Nystroem&lt;/code&gt;&lt;/a&gt;. &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; is cheaper to compute, though, making use of larger feature spaces more efficient.</source>
          <target state="translated">与えられた値については &lt;code&gt;n_components&lt;/code&gt; &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; &lt;/a&gt;しばしば以下のように正確である&lt;a href=&quot;generated/sklearn.kernel_approximation.nystroem#sklearn.kernel_approximation.Nystroem&quot;&gt; &lt;code&gt;Nystroem&lt;/code&gt; &lt;/a&gt;。ただし、&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; の&lt;/a&gt;方が計算コストが安く、より大きな特徴空間をより効率的に利用できます。</target>
        </trans-unit>
        <trans-unit id="46cec00c813e8ea8e2f5bd58264262a28ac481cf" translate="yes" xml:space="preserve">
          <source>For a good choice of alpha, the &lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt; can fully recover the exact set of non-zero variables using only few observations, provided certain specific conditions are met. In particular, the number of samples should be &amp;ldquo;sufficiently large&amp;rdquo;, or L1 models will perform at random, where &amp;ldquo;sufficiently large&amp;rdquo; depends on the number of non-zero coefficients, the logarithm of the number of features, the amount of noise, the smallest absolute value of non-zero coefficients, and the structure of the design matrix X. In addition, the design matrix must display certain specific properties, such as not being too correlated.</source>
          <target state="translated">アルファを適切に選択するために、特定の特定の条件が満たされていれば、&lt;a href=&quot;linear_model#lasso&quot;&gt;Lasso&lt;/a&gt;は少数の観測のみを使用してゼロ以外の変数の正確なセットを完全に回復できます。特に、サンプル数は「十分に大きい」必要があります。そうでない場合、L1モデルはランダムに実行されます。「十分に大きい」は、非ゼロ係数の数、特徴の数の対数、ノイズの量、非ゼロ係数の最小絶対値、および計画行列Xの構造。さらに、計画行列は、過度に相関していないなど、特定の特定のプロパティを表示する必要があります。</target>
        </trans-unit>
        <trans-unit id="283fe9d87c4a4faac62d4b9cee8a3089a1cb638f" translate="yes" xml:space="preserve">
          <source>For a multi-label classification problem with N classes, N binary classifiers are assigned an integer between 0 and N-1. These integers define the order of models in the chain. Each classifier is then fit on the available training data plus the true labels of the classes whose models were assigned a lower number.</source>
          <target state="translated">N個のクラスを持つマルチラベル分類問題では、N個のバイナリ分類器に0からN-1の間の整数が割り当てられます。これらの整数は,連鎖のモデルの順序を定義します.各分類器は,利用可能な学習データに加えて,モデルがより低い数値を割り当てられたクラスの真のラベルを加えて適合させます.</target>
        </trans-unit>
        <trans-unit id="73e6ca6403df9166903acb4326e48adf2d2e8f55" translate="yes" xml:space="preserve">
          <source>For a multi_class problem, if multi_class is set to be &amp;ldquo;multinomial&amp;rdquo; the softmax function is used to find the predicted probability of each class. Else use a one-vs-rest approach, i.e calculate the probability of each class assuming it to be positive using the logistic function. and normalize these values across all the classes.</source>
          <target state="translated">multi_class問題の場合、multi_classが「多項式」に設定されている場合、softmax関数を使用して、各クラスの予測確率が検索されます。それ以外の場合は、1対残りのアプローチを使用します。つまり、ロジスティック関数を使用して、各クラスが正であると仮定して確率を計算します。そして、すべてのクラスにわたってこれらの値を正規化します。</target>
        </trans-unit>
        <trans-unit id="642c44d27e63bf2bd3e040832cd67d4f4b97be3d" translate="yes" xml:space="preserve">
          <source>For a multiclass problem, the hyperparameters for each class are computed using the best scores got by doing a one-vs-rest in parallel across all folds and classes. Hence this is not the true multinomial loss.</source>
          <target state="translated">マルチクラス問題では,各クラスのハイパーパラメタは,すべてのひだとクラスを平行して1対残りを行って得られた最高のスコアを用いて計算されます.したがって,これは真の多項損失ではありません.</target>
        </trans-unit>
        <trans-unit id="3c102da8b9e1a48c3e9639790d9170902789d884" translate="yes" xml:space="preserve">
          <source>For a new point entering the root, it is merged with the subcluster closest to it and the linear sum, squared sum and the number of samples of that subcluster are updated. This is done recursively till the properties of the leaf node are updated.</source>
          <target state="translated">ルートに入る新しい点については,それに最も近いサブクラスタとマージされ,そのサブクラスタの線形和,二乗和,サンプル数が更新されます.これは、リーフノードのプロパティが更新されるまで再帰的に行われます。</target>
        </trans-unit>
        <trans-unit id="14657655d860195eca6994d15ac16d17936616a4" translate="yes" xml:space="preserve">
          <source>For a one-class model, +1 or -1 is returned.</source>
          <target state="translated">1クラスモデルの場合、+1または-1が返されます。</target>
        </trans-unit>
        <trans-unit id="49c44661048e1cd2101f0d885d98fc8331d85aee" translate="yes" xml:space="preserve">
          <source>For a set of data \(E\) of size \(n_E\) which has been clustered into \(k\) clusters, the Calinski-Harabasz score \(s\) is defined as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:</source>
          <target state="translated">For set of data œœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœœﾞ</target>
        </trans-unit>
        <trans-unit id="d36945b7ba93218440d9a3fb3620ffe9bc7ebec1" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to a sphere dataset, see &lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;Manifold Learning methods on a severed sphere&lt;/a&gt;</source>
          <target state="translated">メソッドが球のデータセットに適用される同様の例については&lt;a href=&quot;plot_manifold_sphere#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py&quot;&gt;、切断された球での多様体学習メソッドを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="945c76e7faeb6fe6d013381d6851dfb972b0f8ae" translate="yes" xml:space="preserve">
          <source>For a similar example, where the methods are applied to the S-curve dataset, see &lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt;</source>
          <target state="translated">メソッドがSカーブデータセットに適用される同様の例については&lt;a href=&quot;plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;、多様体学習メソッドの比較を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5693da1a0a426bf5e6f357791de67cea3dcb709e" translate="yes" xml:space="preserve">
          <source>For an adaptively decreasing learning rate, use &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; and use &lt;code&gt;eta0&lt;/code&gt; to specify the starting learning rate. When the stopping criterion is reached, the learning rate is divided by 5, and the algorithm does not stop. The algorithm stops when the learning rate goes below 1e-6.</source>
          <target state="translated">適応的に減少する学習率の場合、 &lt;code&gt;learning_rate='adaptive'&lt;/code&gt; を使用し、 &lt;code&gt;eta0&lt;/code&gt; を使用して開始学習率を指定します。停止基準に達すると、学習率は5で除算され、アルゴリズムは停止しません。アルゴリズムは、学習率が1e-6を下回ると停止します。</target>
        </trans-unit>
        <trans-unit id="289eda38dfb97e5735805aabc918de776eb35066" translate="yes" xml:space="preserve">
          <source>For an estimator to be effective, you need the distance between neighboring points to be less than some value \(d\), which depends on the problem. In one dimension, this requires on average \(n \sim 1/d\) points. In the context of the above \(k\)-NN example, if the data is described by just one feature with values ranging from 0 to 1 and with \(n\) training observations, then new data will be no further away than \(1/n\). Therefore, the nearest neighbor decision rule will be efficient as soon as \(1/n\) is small compared to the scale of between-class feature variations.</source>
          <target state="translated">推定器を有効にするためには、隣り合う点間の距離が、問題に依存するいくつかの値よりも小さくなる必要がある。In one dimension,this requires on average.上記の「\(k)-\(k)-NN」の例では,データが0から1までの値を持つ1つの特徴量で記述され,かつ,訓練観測がある場合には,新しいデータは「\(1/n)」よりも遠くには存在しないことになる.したがって,クラス間の特徴変動の規模に比べて,\(1/n\)が小さくなれば,最近傍決定則は効率的になる.</target>
        </trans-unit>
        <trans-unit id="cc92ccd33be99f33389b25ab23e30ca5c4b36d12" translate="yes" xml:space="preserve">
          <source>For an example of using this dataset with scikit-learn, see &lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples/applications/plot_species_distribution_modeling.py&lt;/a&gt;.</source>
          <target state="translated">このデータセットをscikit-learnで使用する例については、&lt;a href=&quot;../../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;examples / applications / plot_species_distribution_modeling.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="84cc57ff6bd3680e44c549367baf76fa37633107" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;examples/cluster/plot_affinity_propagation.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/cluster/plot_affinity_propagation#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py&quot;&gt;examples / cluster / plot_affinity_propagation.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="550540d863fd72ef27788284d554fe3cf91d4d31" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;examples/cluster/plot_dbscan.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/cluster/plot_dbscan#sphx-glr-auto-examples-cluster-plot-dbscan-py&quot;&gt;examples / cluster / plot_dbscan.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5a609c98d64d09ee64c2c225998c2e63797d885b" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;examples/cluster/plot_mean_shift.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/cluster/plot_mean_shift#sphx-glr-auto-examples-cluster-plot-mean-shift-py&quot;&gt;examples / cluster / plot_mean_shift.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0c7aeec7cbc3121a908ff21339ef38d8e3682ea4" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;examples/linear_model/plot_ard.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/linear_model/plot_ard#sphx-glr-auto-examples-linear-model-plot-ard-py&quot;&gt;examples / linear_model / plot_ard.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="8606b3a4ce46a8dc7d8f3fc386175108176c1a2f" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;examples/linear_model/plot_bayesian_ridge.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/linear_model/plot_bayesian_ridge#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py&quot;&gt;examples / linear_model / plot_bayesian_ridge.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="1a253fcf6bd3baedce8e1812aafc9e481fd05853" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;examples/linear_model/plot_lasso_coordinate_descent_path.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_coordinate_descent_path#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py&quot;&gt;examples / linear_model / plot_lasso_coordinate_descent_path.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="dd893fae3c875581ed42afc5493c8a73ae57ea3a" translate="yes" xml:space="preserve">
          <source>For an example, see &lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;examples/linear_model/plot_lasso_model_selection.py&lt;/a&gt;.</source>
          <target state="translated">例については、&lt;a href=&quot;../../auto_examples/linear_model/plot_lasso_model_selection#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py&quot;&gt;examples / linear_model / plot_lasso_model_selection.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="7185c2666c1903f0809fab3c9082ec1324c6a9c7" translate="yes" xml:space="preserve">
          <source>For an introduction to Unicode and character encodings in general, see Joel Spolsky&amp;rsquo;s &lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Absolute Minimum Every Software Developer Must Know About Unicode&lt;/a&gt;.</source>
          <target state="translated">一般的なUnicodeと文字エンコーディングの&lt;a href=&quot;http://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;概要について&lt;/a&gt;は、Joel Spolskyの絶対的な最小要件を参照してください。</target>
        </trans-unit>
        <trans-unit id="28d13aab6e72bcde5f37b4278086b064720820de" translate="yes" xml:space="preserve">
          <source>For an introduction to Unicode and character encodings in general, see Joel Spolsky&amp;rsquo;s &lt;a href=&quot;https://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;Absolute Minimum Every Software Developer Must Know About Unicode&lt;/a&gt;.</source>
          <target state="translated">Unicodeと文字エンコーディングの&lt;a href=&quot;https://www.joelonsoftware.com/articles/Unicode.html&quot;&gt;概要については&lt;/a&gt;、JoelSpolskyの「すべてのソフトウェア開発者がUnicodeについて知っておく必要のある絶対最小値」を参照してください。</target>
        </trans-unit>
        <trans-unit id="3a88e794655306a2809e5d03a41b7ab87506c6aa" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 (inlier) or -1 (outlier) is returned.</source>
          <target state="translated">1クラスモデルの場合は,+1(正規分布)または-1(外れ値)が返されます.</target>
        </trans-unit>
        <trans-unit id="6b041f627b95dafb713c53f369d3fb59c9505ee0" translate="yes" xml:space="preserve">
          <source>For an one-class model, +1 or -1 is returned.</source>
          <target state="translated">1クラスモデルの場合、+1または-1が返されます。</target>
        </trans-unit>
        <trans-unit id="90c9667034ee59a28024b8500c3a1c0772f75e0b" translate="yes" xml:space="preserve">
          <source>For an overview of available strategies in scikit-learn, see also the &lt;a href=&quot;computing#scaling-strategies&quot;&gt;out-of-core learning&lt;/a&gt; documentation.</source>
          <target state="translated">scikit-learnで使用可能な戦略の概要については、&lt;a href=&quot;computing#scaling-strategies&quot;&gt;コア外学習の&lt;/a&gt;ドキュメントもご覧ください。</target>
        </trans-unit>
        <trans-unit id="bd83f9999f935e2f6fce3641b48e5b3393b97a71" translate="yes" xml:space="preserve">
          <source>For binary classification with a true label \(y \in \{0,1\}\) and a probability estimate \(p = \operatorname{Pr}(y = 1)\), the log loss per sample is the negative log-likelihood of the classifier given the true label:</source>
          <target state="translated">真のラベル \(y \in \{0,1\})と確率推定値 \(p=\operatoratorname{Pr}(y=1)1)を持つ2値分類の場合,log loss per sampleは,真のラベルが与えられた分類器の負の対数尤度である.</target>
        </trans-unit>
        <trans-unit id="23a4f6b8b8e57d58b02ac23ef6f32b82b6049d45" translate="yes" xml:space="preserve">
          <source>For binary classification, \(f(x)\) passes through the logistic function \(g(z)=1/(1+e^{-z})\) to obtain output values between zero and one. A threshold, set to 0.5, would assign samples of outputs larger or equal 0.5 to the positive class, and the rest to the negative class.</source>
          <target state="translated">2値分類では、0から1の間の出力値を得るために、ロジスティック関数\(g(z)=1/(1+e^{-z})を通過します。0.5に設定されたしきい値は、0.5より大きいか等しい出力のサンプルを正のクラスに割り当て、残りのサンプルを負のクラスに割り当てます。</target>
        </trans-unit>
        <trans-unit id="883efcc2dc17e184b74392564fb44d2a6f9c0bf6" translate="yes" xml:space="preserve">
          <source>For binary problems, we can get counts of true negatives, false positives, false negatives and true positives as follows:</source>
          <target state="translated">二進法の問題では、以下のようにして、真の陰性、偽の陽性、偽の陰性、真の陽性のカウントを得ることができます。</target>
        </trans-unit>
        <trans-unit id="7f954d6786e07c3ef37ff8e0245acb91efbb4b2a" translate="yes" xml:space="preserve">
          <source>For classification with &lt;code&gt;loss='deviance'&lt;/code&gt; the target response is logit(p).</source>
          <target state="translated">&lt;code&gt;loss='deviance'&lt;/code&gt; の分類の場合、ターゲット応答はlogit（p）です。</target>
        </trans-unit>
        <trans-unit id="4118e1de638d62fd337275c2f8d28f38f1e40db3" translate="yes" xml:space="preserve">
          <source>For classification with a logistic loss, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">ロジスティック損失のある分類の場合、平均戦略を備えたSGDの別のバリアントは、&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; の&lt;/a&gt;ソルバーとして利用可能な確率的平均勾配（SAG）アルゴリズムで利用できます。</target>
        </trans-unit>
        <trans-unit id="7a750c34f262db1f2c0c844eb9774104416e6f5c" translate="yes" xml:space="preserve">
          <source>For classification you can think of it as the regression score before the link function.</source>
          <target state="translated">分類の場合は、リンク機能の前の回帰スコアと考えることができます。</target>
        </trans-unit>
        <trans-unit id="6a3d9b2c887776af95639587c4c76f62b0d1c8f1" translate="yes" xml:space="preserve">
          <source>For classification, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt;&lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='hinge'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_hinge'&lt;/code&gt; (PA-II). For regression, &lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt;&lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt;&lt;/a&gt; can be used with &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; (PA-I) or &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; (PA-II).</source>
          <target state="translated">分類の場合、&lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveclassifier#sklearn.linear_model.PassiveAggressiveClassifier&quot;&gt; &lt;code&gt;PassiveAggressiveClassifier&lt;/code&gt; &lt;/a&gt;は &lt;code&gt;loss='hinge'&lt;/code&gt; （PA-I）または &lt;code&gt;loss='squared_hinge'&lt;/code&gt; （PA-II）で使用できます。回帰の場合、&lt;a href=&quot;generated/sklearn.linear_model.passiveaggressiveregressor#sklearn.linear_model.PassiveAggressiveRegressor&quot;&gt; &lt;code&gt;PassiveAggressiveRegressor&lt;/code&gt; &lt;/a&gt;は &lt;code&gt;loss='epsilon_insensitive'&lt;/code&gt; （PA-I）または &lt;code&gt;loss='squared_epsilon_insensitive'&lt;/code&gt; （PA-II）で使用できます。</target>
        </trans-unit>
        <trans-unit id="27898fb8346ff80dce087f616900965fd4196842" translate="yes" xml:space="preserve">
          <source>For classification, a somewhat important thing to note is that although a stateless feature extraction routine may be able to cope with new/unseen attributes, the incremental learner itself may be unable to cope with new/unseen targets classes. In this case you have to pass all the possible classes to the first &lt;code&gt;partial_fit&lt;/code&gt; call using the &lt;code&gt;classes=&lt;/code&gt; parameter.</source>
          <target state="translated">分類に関して注意すべき重要なことは、ステートレスな特徴抽出ルーチンは新しい/目に見えない属性に対処できるかもしれないが、インクリメンタルラーナー自体は新しい/目に見えないターゲットクラスに対処できないかもしれないということです。この場合、 &lt;code&gt;classes=&lt;/code&gt; パラメーターを使用して、可能なすべてのクラスを最初の &lt;code&gt;partial_fit&lt;/code&gt; 呼び出しに渡す必要があります。</target>
        </trans-unit>
        <trans-unit id="fda4c776ec3f2170d3e99301b50afa3144298d48" translate="yes" xml:space="preserve">
          <source>For classification, as in the labeling &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; task, linear regression is not the right approach as it will give too much weight to data far from the decision frontier. A linear approach is to fit a sigmoid function or &lt;strong&gt;logistic&lt;/strong&gt; function:</source>
          <target state="translated">分類では、&lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;アイリス&lt;/a&gt;のラベリングタスクと同様に、線形回帰は意思決定の境界から離れたデータに大きな重みを与えるため、適切なアプローチではありません。線形アプローチは、シグモイド関数または&lt;strong&gt;ロジスティック&lt;/strong&gt;関数を近似することです。</target>
        </trans-unit>
        <trans-unit id="cda870024c615048609a38e867ca66fe1aaab764" translate="yes" xml:space="preserve">
          <source>For classification, the target response may be the probability of a class (the positive class for binary classification), or the decision function.</source>
          <target state="translated">分類の場合、対象となる応答は、クラスの確率(2値分類の場合は正のクラス)であってもよいし、決定関数であってもよい。</target>
        </trans-unit>
        <trans-unit id="049512f622ab4a1900a694aa9ec5fcf56244d47a" translate="yes" xml:space="preserve">
          <source>For classification: &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt;&lt;code&gt;f_classif&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">分類の場合：&lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.feature_selection.f_classif#sklearn.feature_selection.f_classif&quot;&gt; &lt;code&gt;f_classif&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2b5c234d472222c920c562abfd3ef4ec80e6cfee" translate="yes" xml:space="preserve">
          <source>For comparison, a quantized image using a random codebook (colors picked up randomly) is also shown.</source>
          <target state="translated">比較のために、ランダムなコードブック(色をランダムに拾ったもの)を使って量子化した画像も示しています。</target>
        </trans-unit>
        <trans-unit id="3be5878f7d3ebd4495804d5a6a55058ed71eceb1" translate="yes" xml:space="preserve">
          <source>For comparison, the documents are also clustered using MiniBatchKMeans. The document clusters derived from the biclusters achieve a better V-measure than clusters found by MiniBatchKMeans.</source>
          <target state="translated">比較のために、文書もMiniBatchKMeansを用いてクラスタ化しています。バイクラスターから得られた文書クラスタは、MiniBatchKMeansで得られたクラスタよりも優れたV値を達成しています。</target>
        </trans-unit>
        <trans-unit id="9da7ddf96abc62edc6f61720c2e84583fe9d6b7c" translate="yes" xml:space="preserve">
          <source>For comparison, we also add the output from &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt;&lt;code&gt;QuantileTransformer&lt;/code&gt;&lt;/a&gt;. It can force any arbitrary distribution into a gaussian, provided that there are enough training samples (thousands). Because it is a non-parametric method, it is harder to interpret than the parametric ones (Box-Cox and Yeo-Johnson).</source>
          <target state="translated">比較のために、&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.quantiletransformer#sklearn.preprocessing.QuantileTransformer&quot;&gt; &lt;code&gt;QuantileTransformer&lt;/code&gt; &lt;/a&gt;からの出力も追加します。十分なトレーニングサンプル（数千）があれば、任意の分布をガウス分布に強制することができます。ノンパラメトリック手法であるため、パラメトリック手法（Box-CoxおよびYeo-Johnson）よりも解釈が困難です。</target>
        </trans-unit>
        <trans-unit id="6d421941474530194b10c6be8d7b89e2eb530191" translate="yes" xml:space="preserve">
          <source>For comparison, we also add the output from &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt;. It can force any arbitrary distribution into a gaussian, provided that there are enough training samples (thousands). Because it is a non-parametric method, it is harder to interpret than the parametric ones (Box-Cox and Yeo-Johnson).</source>
          <target state="translated">比較のために、 &lt;code&gt;preprocessing.QuantileTransformer&lt;/code&gt; からの出力も追加します。十分なトレーニングサンプル（数千）がある場合は、任意の分布を強制的にガウス分布にすることができます。これはノンパラメトリック手法であるため、パラメトリック手法（Box-CoxおよびYeo-Johnson）よりも解釈が困難です。</target>
        </trans-unit>
        <trans-unit id="3fedc899dde91ba75e541f7b8d87d7a3665ca193" translate="yes" xml:space="preserve">
          <source>For compatibility, user code relying on this method should wrap its calls in &lt;code&gt;np.asarray&lt;/code&gt; to avoid type issues.</source>
          <target state="translated">互換性のために、このメソッドに依存するユーザーコードは、その呼び出しを &lt;code&gt;np.asarray&lt;/code&gt; にラップして、型の問題を回避する必要があります。</target>
        </trans-unit>
        <trans-unit id="6f31aee2196032d492cf3c67f7f43ab3f6981996" translate="yes" xml:space="preserve">
          <source>For continuous parameters, such as &lt;code&gt;C&lt;/code&gt; above, it is important to specify a continuous distribution to take full advantage of the randomization. This way, increasing &lt;code&gt;n_iter&lt;/code&gt; will always lead to a finer search.</source>
          <target state="translated">上記の &lt;code&gt;C&lt;/code&gt; などの連続パラメーターの場合、ランダム化を最大限に活用するには連続分布を指定することが重要です。このように、 &lt;code&gt;n_iter&lt;/code&gt; を増やすと、常により詳細な検索が行われます。</target>
        </trans-unit>
        <trans-unit id="4288bdf523218f188616117af5e7ab510c1e81a7" translate="yes" xml:space="preserve">
          <source>For cross-validation, we use 20-fold with 2 algorithms to compute the Lasso path: coordinate descent, as implemented by the LassoCV class, and Lars (least angle regression) as implemented by the LassoLarsCV class. Both algorithms give roughly the same results. They differ with regards to their execution speed and sources of numerical errors.</source>
          <target state="translated">交差検証のために、Lassoパスを計算するために2つのアルゴリズムを20倍に使用します:LassoCVクラスで実装されている座標降下とLassoLarsCVクラスで実装されているLars(最小角度回帰)です。どちらのアルゴリズムもほぼ同じ結果が得られます。両者は,実行速度と数値誤差の発生源が異なります.</target>
        </trans-unit>
        <trans-unit id="c8cbf2457961ac615bed8ee5d0896fee418cd0e6" translate="yes" xml:space="preserve">
          <source>For custom messages if &amp;ldquo;%(name)s&amp;rdquo; is present in the message string, it is substituted for the estimator name.</source>
          <target state="translated">カスタムメッセージの場合、メッセージ文字列に「％（name）s」が含まれていると、推定器名の代わりに使用されます。</target>
        </trans-unit>
        <trans-unit id="67e0a596cb4bf62edc844af1488251663768a571" translate="yes" xml:space="preserve">
          <source>For details on the precise mathematical formulation of the provided kernel functions and how &lt;code&gt;gamma&lt;/code&gt;, &lt;code&gt;coef0&lt;/code&gt; and &lt;code&gt;degree&lt;/code&gt; affect each other, see the corresponding section in the narrative documentation: &lt;a href=&quot;../svm#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt;.</source>
          <target state="translated">提供されるカーネル関数の正確な数学的定式化の詳細、および &lt;code&gt;gamma&lt;/code&gt; 、 &lt;code&gt;coef0&lt;/code&gt; 、および &lt;code&gt;degree&lt;/code&gt; が互いにどのように影響するかについては、ナラティブドキュメントの対応するセクション「&lt;a href=&quot;../svm#svm-kernels&quot;&gt;カーネル関数&lt;/a&gt;」を参照してください。</target>
        </trans-unit>
        <trans-unit id="885e0e96d0439bc0a3432bfe3535963e5dbd93a5" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape (n_features, n_k), where &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; It is the rotation of the Gaussian distribution, i.e. its principal axis. It corresponds to &lt;code&gt;V&lt;/code&gt;, the matrix of eigenvectors coming from the SVD of &lt;code&gt;Xk = U S Vt&lt;/code&gt; where &lt;code&gt;Xk&lt;/code&gt; is the centered matrix of samples from class k.</source>
          <target state="translated">各クラスkについて、形状の配列（n_features、n_k）、ここで &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; ガウス分布の回転、つまりその主軸です。これは、 &lt;code&gt;Xk = U S Vt&lt;/code&gt; SVDから得られる固有ベクトルの行列である &lt;code&gt;V&lt;/code&gt; に対応します。ここで、 &lt;code&gt;Xk&lt;/code&gt; はクラスkのサンプルの中心行列です。</target>
        </trans-unit>
        <trans-unit id="e4ed0f1e2f8642affc7014ca7518ae7bfac1b31c" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_features, n_k], with &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; It is the rotation of the Gaussian distribution, i.e. its principal axis.</source>
          <target state="translated">各クラスkについて、形状の配列[n_features、n_k]、 &lt;code&gt;n_k = min(n_features, number of elements in class k)&lt;/code&gt; これはガウス分布の回転、つまりその主軸です。</target>
        </trans-unit>
        <trans-unit id="a5ae820e12dddee4457f060f6b705b304ca3a1e3" translate="yes" xml:space="preserve">
          <source>For each class k an array of shape [n_k]. It contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system.</source>
          <target state="translated">各クラス k に対して形状 [n_k]の配列。これは,その主軸に沿ったガウス分布のスケーリング,すなわち回転座標系における分散を含みます.</target>
        </trans-unit>
        <trans-unit id="bb1ef71f090300eb5b67a4f2bd338bada7005d30" translate="yes" xml:space="preserve">
          <source>For each class of models we make the model complexity vary through the choice of relevant model parameters and measure the influence on both computational performance (latency) and predictive power (MSE or Hamming Loss).</source>
          <target state="translated">モデルのクラスごとに、関連するモデルパラメータの選択によってモデルの複雑さを変化させ、計算性能(レイテンシー)と予測力(MSEまたはハミング損失)の両方への影響を測定します。</target>
        </trans-unit>
        <trans-unit id="21f3c14e6817e5773b09bd85149800940dffa132" translate="yes" xml:space="preserve">
          <source>For each class, contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system. It corresponds to &lt;code&gt;S^2 /
(n_samples - 1)&lt;/code&gt;, where &lt;code&gt;S&lt;/code&gt; is the diagonal matrix of singular values from the SVD of &lt;code&gt;Xk&lt;/code&gt;, where &lt;code&gt;Xk&lt;/code&gt; is the centered matrix of samples from class k.</source>
          <target state="translated">各クラスについて、主軸に沿ったガウス分布のスケーリング、つまり回転座標系の分散が含まれます。これは &lt;code&gt;S^2 / (n_samples - 1)&lt;/code&gt; に対応します。ここで、 &lt;code&gt;S&lt;/code&gt; は &lt;code&gt;Xk&lt;/code&gt; のSVDからの特異値の対角行列です。ここで、 &lt;code&gt;Xk&lt;/code&gt; はクラスkからのサンプルの中心行列です。</target>
        </trans-unit>
        <trans-unit id="93f968263bf15ebdfa5ca6b61b7631f18bb2dedd" translate="yes" xml:space="preserve">
          <source>For each class, gives the covariance matrix estimated using the samples of that class. The estimations are unbiased. Only present if &lt;code&gt;store_covariance&lt;/code&gt; is True.</source>
          <target state="translated">各クラスについて、そのクラスのサンプルを使用して推定された共分散行列を示します。推定は偏りがありません。 &lt;code&gt;store_covariance&lt;/code&gt; がTrueの場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="51af5a1cbe5b213e1b6f97e9040e40d195d22222" translate="yes" xml:space="preserve">
          <source>For each component k, find the weights u, v that maximizes max corr(Xk u, Yk v), such that &lt;code&gt;|u| = |v| = 1&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;|u| = |v| = 1&lt;/code&gt; ように、各コンポーネントkについて、最大corr（Xk u、Yk v）を最大化する重みu、vを見つけます。= | v | = 1</target>
        </trans-unit>
        <trans-unit id="0acc93a412fe0bc296f4de29ad2df21b9415e5fb" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimize:</source>
          <target state="translated">各成分 k について,最適化された重み u,v を求めます.</target>
        </trans-unit>
        <trans-unit id="34ffb7458447c8e84aeb0c0dcae78f73f1c9783e" translate="yes" xml:space="preserve">
          <source>For each component k, find weights u, v that optimizes: &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt;, such that &lt;code&gt;|u| = 1&lt;/code&gt;</source>
          <target state="translated">各コンポーネントkについて、次を最適化する重みu、vを見つけます： &lt;code&gt;max corr(Xk u, Yk v) * std(Xk u) std(Yk u)&lt;/code&gt; 、 &lt;code&gt;|u| = 1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f9db939b51ba3d78630796e1c0444915001bc251" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator.</source>
          <target state="translated">Xの各データポイントx、およびアンサンブル内の各木について、各推定器で終了する葉xのインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="4571d700205de7840eb7f685393b9c35a449521a" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator. In the case of binary classification n_classes is 1.</source>
          <target state="translated">Xの各データポイントxとアンサンブル内の各木について、各推定器で終わる葉xのインデックスを返します。2値分類の場合、n_classesは1である。</target>
        </trans-unit>
        <trans-unit id="44ac20da24a40ac490697d0897d69873261c6900" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.</source>
          <target state="translated">X の各データポイント x と森の各木について、x が終点とする葉のインデックスを返します。</target>
        </trans-unit>
        <trans-unit id="d82941d49be2d46b8acb0305feded896c81f7a70" translate="yes" xml:space="preserve">
          <source>For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt;, possibly with gaps in the numbering.</source>
          <target state="translated">Xの各データポイントxについて、最終的にxの葉である葉のインデックスを返します。葉は &lt;code&gt;[0; self.tree_.node_count)&lt;/code&gt; 、おそらく番号付けにギャップがあります。</target>
        </trans-unit>
        <trans-unit id="7b85d3d77de0d2c34f470b25ce92cd73fbf8293c" translate="yes" xml:space="preserve">
          <source>For each dataset, 15% of samples are generated as random uniform noise. This proportion is the value given to the nu parameter of the OneClassSVM and the contamination parameter of the other outlier detection algorithms. Decision boundaries between inliers and outliers are displayed in black except for Local Outlier Factor (LOF) as it has no predict method to be applied on new data when it is used for outlier detection.</source>
          <target state="translated">各データセットでは,サンプルの15%がランダムな一様ノイズとして生成されます.この割合は、OneClassSVMのnuパラメータと他の外れ値検出アルゴリズムのコンタミネーションパラメータに与えられた値です。インライアとアウトライアの間の決定境界は、アウトライア検出のために使用されるときに新しいデータに適用される予測方法を持たないので、ローカル・アウトライア・ファクター(LOF)を除いて黒で表示されます。</target>
        </trans-unit>
        <trans-unit id="894d665cd020f2e7e68923ae49f3798173d1a959" translate="yes" xml:space="preserve">
          <source>For each document &lt;code&gt;#i&lt;/code&gt;, count the number of occurrences of each word &lt;code&gt;w&lt;/code&gt; and store it in &lt;code&gt;X[i, j]&lt;/code&gt; as the value of feature &lt;code&gt;#j&lt;/code&gt; where &lt;code&gt;j&lt;/code&gt; is the index of word &lt;code&gt;w&lt;/code&gt; in the dictionary.</source>
          <target state="translated">各文書のため &lt;code&gt;#i&lt;/code&gt; 、各単語の出現回数カウント &lt;code&gt;w&lt;/code&gt; し、それを格納 &lt;code&gt;X[i, j]&lt;/code&gt; 特徴の値として &lt;code&gt;#j&lt;/code&gt; の &lt;code&gt;j&lt;/code&gt; はワードのインデックスであり、 &lt;code&gt;w&lt;/code&gt; は辞書です。</target>
        </trans-unit>
        <trans-unit id="086df8ffb1b70734dd37b88cb050e6a142a873b8" translate="yes" xml:space="preserve">
          <source>For each document \(d \in D\), draw the topic proportions \(\theta_d \sim \mathrm{Dirichlet}(\alpha)\). \(\alpha\) corresponds to &lt;code&gt;doc_topic_prior&lt;/code&gt;.</source>
          <target state="translated">ドキュメント\（d \ in D \）ごとに、トピックの比率\（\ theta_d \ sim \ mathrm {Dirichlet}（\ alpha）\）を描画します。\（\ alpha \）は &lt;code&gt;doc_topic_prior&lt;/code&gt; に対応します。</target>
        </trans-unit>
        <trans-unit id="f8df1081a030b15d2d8afea6cd05ff167080d1cd" translate="yes" xml:space="preserve">
          <source>For each document \(d\), draw \(\theta_d \sim \mathrm{Dirichlet}(\alpha), \: d=1...D\)</source>
          <target state="translated">For each document ¶(d),draw \(D\)theta_d \sim \mathrm{Dirichlet}(\alpha),I'm sorry:d=1...D\)</target>
        </trans-unit>
        <trans-unit id="6eb16a2ee99fe65f3a14878a1546f940e1e0bd2a" translate="yes" xml:space="preserve">
          <source>For each feature \(i\) in the training set \(X\), &lt;a href=&quot;generated/sklearn.naive_bayes.categoricalnb#sklearn.naive_bayes.CategoricalNB&quot;&gt;&lt;code&gt;CategoricalNB&lt;/code&gt;&lt;/a&gt; estimates a categorical distribution for each feature i of X conditioned on the class y. The index set of the samples is defined as \(J = \{ 1, \dots, m \}\), with \(m\) as the number of samples.</source>
          <target state="translated">トレーニングセット\（X \）内の各特徴\（i \）について、&lt;a href=&quot;generated/sklearn.naive_bayes.categoricalnb#sklearn.naive_bayes.CategoricalNB&quot;&gt; &lt;code&gt;CategoricalNB&lt;/code&gt; &lt;/a&gt;は、クラスyを条件とするXの各特徴iのカテゴリ分布を推定します。サンプルのインデックスセットは、\（J = \ {1、\ dots、m \} \）として定義され、\（m \）はサンプルの数です。</target>
        </trans-unit>
        <trans-unit id="9366e353cbe2cfb64854c09c8a8adb8df13a11b1" translate="yes" xml:space="preserve">
          <source>For each feature \(j\) (column of \(D\)):</source>
          <target state="translated">For each feature \(j)(column of \(D\)</target>
        </trans-unit>
        <trans-unit id="d88ce97fd881b7b3225357f99ece9e603e7378b5" translate="yes" xml:space="preserve">
          <source>For each observation, tells whether or not (+1 or -1) it should be considered as an inlier according to the fitted model.</source>
          <target state="translated">各オブザベーションについて、フィットしたモデルに従って、それをインライアとみなすべきかどうか(+1または-1)を指示する。</target>
        </trans-unit>
        <trans-unit id="ceeb3b0129a3e252c3947f10f0ffdea6343158bd" translate="yes" xml:space="preserve">
          <source>For each pair of iris features, the decision tree learns decision boundaries made of combinations of simple thresholding rules inferred from the training samples.</source>
          <target state="translated">虹彩の特徴の各ペアについて、決定木は、訓練サンプルから推測される単純な閾値ルールの組み合わせからなる決定境界を学習する。</target>
        </trans-unit>
        <trans-unit id="63ed3328d4a6b49da02c095fda15b05ff5f99ccf" translate="yes" xml:space="preserve">
          <source>For each repetition \(k\) in \({1, ..., K}\):</source>
          <target state="translated">For each repetition ″\(k)in ″\(k)in ″\(1,...,K″).</target>
        </trans-unit>
        <trans-unit id="ebc579ef4368e5d7216210ea27aaa16d7216a1cd" translate="yes" xml:space="preserve">
          <source>For each sample, the generative process is:</source>
          <target state="translated">各サンプルについて、生成プロセスは</target>
        </trans-unit>
        <trans-unit id="d05dbfe66f302738b6b31b31becd47c7eec37764" translate="yes" xml:space="preserve">
          <source>For each topic \(k \in K\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta)\). This provides a distribution over the words, i.e. the probability of a word appearing in topic \(k\). \(\eta\) corresponds to &lt;code&gt;topic_word_prior&lt;/code&gt;.</source>
          <target state="translated">トピック\（k \ in K \）ごとに、\（\ beta_k \ sim \ mathrm {Dirichlet}（\ eta）\）を描画します。これにより、単語全体に分布が提供されます。つまり、トピック\（k \）に単語が出現する確率がわかります。\（\ eta \）は &lt;code&gt;topic_word_prior&lt;/code&gt; に対応します。</target>
        </trans-unit>
        <trans-unit id="884540e9625ad90cb4316f6468437987a56adbd4" translate="yes" xml:space="preserve">
          <source>For each topic \(k\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta),\: k =1...K\)</source>
          <target state="translated">For each topic ¶(k),draw \(k \beta_k ━━━━━━━━!!!!</target>
        </trans-unit>
        <trans-unit id="ebc60a8584824b9b236f9d24a5aa9b01b10427f0" translate="yes" xml:space="preserve">
          <source>For each value of &lt;code&gt;n_components&lt;/code&gt;, we plot:</source>
          <target state="translated">&lt;code&gt;n_components&lt;/code&gt; の各値について、以下をプロットします。</target>
        </trans-unit>
        <trans-unit id="6ad9736839514923dd21aa4c5541f4da9ec0e497" translate="yes" xml:space="preserve">
          <source>For each value of the &amp;lsquo;target&amp;rsquo; features in the &lt;code&gt;grid&lt;/code&gt; the partial dependence function need to marginalize the predictions of a tree over all possible values of the &amp;lsquo;complement&amp;rsquo; features. In decision trees this function can be evaluated efficiently without reference to the training data. For each grid point a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed, otherwise both branches are followed, each branch is weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all visited leaves. For tree ensembles the results of each individual tree are again averaged.</source>
          <target state="translated">&lt;code&gt;grid&lt;/code&gt; 内の「ターゲット」フィーチャの各値について、部分依存関数は、「補数」フィーチャのすべての可能な値に対してツリーの予測を周辺化する必要があります。決定木では、この関数はトレーニングデータを参照せずに効率的に評価できます。各グリッドポイントについて、重み付きツリートラバーサルが実行されます。分割ノードに「ターゲット」機能が含まれる場合、対応する左または右のブランチが追跡されます。それ以外の場合は、両方のブランチが追跡され、各ブランチは、入力されたトレーニングサンプルの割合によって重み付けされます。ブランチ。最後に、部分的な依存関係は、すべての訪問した葉の加重平均によって与えられます。ツリーアンサンブルの場合、個々のツリーの結果が再び平均化されます。</target>
        </trans-unit>
        <trans-unit id="719d4a30c8dd97a24789edd5bdd1f3a14cdc8a6c" translate="yes" xml:space="preserve">
          <source>For each word \(i\) in document \(d\):</source>
          <target state="translated">For each word \(i)in document ♦♦.</target>
        </trans-unit>
        <trans-unit id="d13eb916a8aa10457ca38f56195d8da451f22b82" translate="yes" xml:space="preserve">
          <source>For efficiency reasons, the euclidean distance between a pair of row vector x and y is computed as:</source>
          <target state="translated">効率的な理由から、行ベクトル x と y のペア間のユークリッド距離は次のように計算されます。</target>
        </trans-unit>
        <trans-unit id="9aa1f675d2607b44cb2ebebaba9400cb8fdf4c6d" translate="yes" xml:space="preserve">
          <source>For evaluating multiple metrics, either give a list of (unique) strings or a dict with names as keys and callables as values.</source>
          <target state="translated">複数のメトリクスを評価するためには、(一意の)文字列のリストを与えるか、名前をキーとし、呼び出し可能な値を持つ dict を与えます。</target>
        </trans-unit>
        <trans-unit id="091a4026feae279bd855844156c1035b747b54da" translate="yes" xml:space="preserve">
          <source>For example &lt;code&gt;average_precision&lt;/code&gt; or the area under the roc curve can not be computed using discrete predictions alone.</source>
          <target state="translated">たとえば、 &lt;code&gt;average_precision&lt;/code&gt; またはroc曲線の下の面積は、離散予測のみを使用して計算することはできません。</target>
        </trans-unit>
        <trans-unit id="d73a71b2256308d0d5e12341f8e7d64f3e849f98" translate="yes" xml:space="preserve">
          <source>For example try instead of the &lt;code&gt;SVC&lt;/code&gt;:</source>
          <target state="translated">たとえば、 &lt;code&gt;SVC&lt;/code&gt; の代わりに試してください。</target>
        </trans-unit>
        <trans-unit id="541edf61321b8728dd0c7cafa11d713cadb8fb1e" translate="yes" xml:space="preserve">
          <source>For example, a less computationally intensive alternative to &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; would be &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt;.</source>
          <target state="translated">たとえば、 &lt;code&gt;LeavePGroupsOut(p=10)&lt;/code&gt; の代わりに計算量が少ない代替手段は &lt;code&gt;GroupShuffleSplit(test_size=10, n_splits=100)&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="65cec63d764ed66c423ae4b0636bcfb02973f7ba" translate="yes" xml:space="preserve">
          <source>For example, a simple linear regression can be extended by constructing &lt;strong&gt;polynomial features&lt;/strong&gt; from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:</source>
          <target state="translated">たとえば、係数から&lt;strong&gt;多項式の特徴&lt;/strong&gt;を作成することにより、単純な線形回帰を拡張できます。標準の線形回帰の場合、2次元データに対して次のようなモデルがある可能性があります。</target>
        </trans-unit>
        <trans-unit id="8a4469c2cb53cff6560ff1210e7df829ee4e673a" translate="yes" xml:space="preserve">
          <source>For example, classification of the properties &amp;ldquo;type of fruit&amp;rdquo; and &amp;ldquo;colour&amp;rdquo; for a set of images of fruit. The property &amp;ldquo;type of fruit&amp;rdquo; has the possible classes: &amp;ldquo;apple&amp;rdquo;, &amp;ldquo;pear&amp;rdquo; and &amp;ldquo;orange&amp;rdquo;. The property &amp;ldquo;colour&amp;rdquo; has the possible classes: &amp;ldquo;green&amp;rdquo;, &amp;ldquo;red&amp;rdquo;, &amp;ldquo;yellow&amp;rdquo; and &amp;ldquo;orange&amp;rdquo;. Each sample is an image of a fruit, a label is output for both properties and each label is one of the possible classes of the corresponding property.</source>
          <target state="translated">たとえば、果物の一連の画像のプロパティ「果物の種類」と「色」の分類。プロパティ「果物の種類」には、「リンゴ」、「梨」、「オレンジ」のクラスがあります。プロパティ「colour」には、「green」、「red」、「yellow」、「orange」のクラスがあります。各サンプルは果物の画像であり、両方のプロパティのラベルが出力され、各ラベルは対応するプロパティの可能なクラスの1つです。</target>
        </trans-unit>
        <trans-unit id="794a77a9ad99cd614e0490463df18e6667fa3c9c" translate="yes" xml:space="preserve">
          <source>For example, classification using features extracted from a set of images of fruit, where each image may either be of an orange, an apple, or a pear. Each image is one sample and is labelled as one of the 3 possible classes. Multiclass classification makes the assumption that each sample is assigned to one and only one label - one sample cannot, for example, be both a pear and an apple.</source>
          <target state="translated">例えば、果物の画像のセットから抽出された特徴量を使用して分類します。各画像は1つのサンプルであり、3つの可能なクラスの1つとしてラベル付けされています。マルチクラス分類では,各サンプルが1つのラベルにのみ割り当てられることを前提としています.</target>
        </trans-unit>
        <trans-unit id="f87725ef6020293ce39f30b54128c30f50570f0e" translate="yes" xml:space="preserve">
          <source>For example, if each point is just a single number (8 bytes), then an effective \(k\)-NN estimator in a paltry \(p \sim 20\) dimensions would require more training data than the current estimated size of the entire internet (&amp;plusmn;1000 Exabytes or so).</source>
          <target state="translated">たとえば、各ポイントが単一の数値（8バイト）の場合、わずかな\（p \ sim 20 \）次元の効果的な\（k \）-NN推定量は、現在の推定サイズよりも多くのトレーニングデータを必要とします。インターネット全体（&amp;plusmn;1000エクサバイト程度）。</target>
        </trans-unit>
        <trans-unit id="5e44134c443036a12804aff41c3842c8f74c39ce" translate="yes" xml:space="preserve">
          <source>For example, in random projection, this warning is raised when the number of components, which quantifies the dimensionality of the target projection space, is higher than the number of features, which quantifies the dimensionality of the original source space, to imply that the dimensionality of the problem will not be reduced.</source>
          <target state="translated">例えば、ランダム投影では、対象投影空間の次元性を定量化する成分の数が、元の元空間の次元性を定量化する特徴量の数よりも多い場合に、問題の次元性が低減されないことを暗示するために、この警告を発する。</target>
        </trans-unit>
        <trans-unit id="4bb7f297d1cf6895bcaff7553e1e2a2edd1164e9" translate="yes" xml:space="preserve">
          <source>For example, in the cases of multiple experiments, &lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt;&lt;code&gt;LeaveOneGroupOut&lt;/code&gt;&lt;/a&gt; can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one:</source>
          <target state="translated">たとえば、複数の実験の場合、&lt;a href=&quot;generated/sklearn.model_selection.leaveonegroupout#sklearn.model_selection.LeaveOneGroupOut&quot;&gt; &lt;code&gt;LeaveOneGroupOut&lt;/code&gt; &lt;/a&gt;を使用して、さまざまな実験に基づく交差検定を作成できます。1つを除くすべての実験のサンプルを使用してトレーニングセットを作成します。</target>
        </trans-unit>
        <trans-unit id="9dc98c27045ddaa13bc1efc30f0c70951a11ebf1" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s look at the results of a multinomial Naive Bayes classifier, which is fast to train and achieves a decent F-score:</source>
          <target state="translated">たとえば、多項式の単純ベイズ分類器の結果を見てみましょう。これは、トレーニングが高速で、適切なFスコアを実現します。</target>
        </trans-unit>
        <trans-unit id="85d6aa34dc31a086da5a0b5a46fa6367e968ccaf" translate="yes" xml:space="preserve">
          <source>For example, let&amp;rsquo;s say we&amp;rsquo;re dealing with a corpus of two documents: &lt;code&gt;['words', 'wprds']&lt;/code&gt;. The second document contains a misspelling of the word &amp;lsquo;words&amp;rsquo;. A simple bag of words representation would consider these two as very distinct documents, differing in both of the two possible features. A character 2-gram representation, however, would find the documents matching in 4 out of 8 features, which may help the preferred classifier decide better:</source>
          <target state="translated">たとえば、2つのドキュメントのコーパス &lt;code&gt;['words', 'wprds']&lt;/code&gt; を扱っているとしましょう。2番目のドキュメントには、単語「words」のスペルミスが含まれています。単純な単語のバッグ表現では、これら2つは非常に異なるドキュメントと見なされ、2つの可能な機能の両方が異なります。ただし、文字の2グラム表現は、8つの機能のうち4つで一致するドキュメントを検出します。これは、優先分類器がより適切に判断するのに役立ちます。</target>
        </trans-unit>
        <trans-unit id="a387381a97998b7238fd2bc704165170ce740115" translate="yes" xml:space="preserve">
          <source>For example, prediction of both wind speed and wind direction, in degrees, using data obtained at a certain location. Each sample would be data obtained at one location and both wind speed and direction would be output for each sample.</source>
          <target state="translated">例えば、ある場所で得られたデータを用いて、風速と風向を度数で予測する。各サンプルは、ある場所で得られたデータであり、サンプルごとに風速と風向の両方を出力します。</target>
        </trans-unit>
        <trans-unit id="0256c851cb28fec27d5dcefe2d74c45aece1b249" translate="yes" xml:space="preserve">
          <source>For example, prediction of the topics relevant to a text document or video. The document or video may be about one of &amp;lsquo;religion&amp;rsquo;, &amp;lsquo;politics&amp;rsquo;, &amp;lsquo;finance&amp;rsquo; or &amp;lsquo;education&amp;rsquo;, several of the topic classes or all of the topic classes.</source>
          <target state="translated">たとえば、テキストドキュメントまたはビデオに関連するトピックの予測。ドキュメントまたはビデオは、「宗教」、「政治」、「金融」、「教育」のいずれか、いくつかのトピッククラス、またはすべてのトピッククラスに関するものである可能性があります。</target>
        </trans-unit>
        <trans-unit id="a34fc3c98b3c662bed7829df5d3e68b291f14f22" translate="yes" xml:space="preserve">
          <source>For example, suppose that we have a first algorithm that extracts Part of Speech (PoS) tags that we want to use as complementary tags for training a sequence classifier (e.g. a chunker). The following dict could be such a window of features extracted around the word &amp;lsquo;sat&amp;rsquo; in the sentence &amp;lsquo;The cat sat on the mat.&amp;rsquo;:</source>
          <target state="translated">たとえば、シーケンス分類器（チャンカーなど）をトレーニングするための補足タグとして使用したい品詞（PoS）タグを抽出する最初のアルゴリズムがあるとします。次の口述は、「猫がマットの上に座った」という文の「sat」という単語の周りに抽出された特徴のウィンドウのようなものです。</target>
        </trans-unit>
        <trans-unit id="5b46799167b8bb61c43e949f07a2335c6f7cd1fa" translate="yes" xml:space="preserve">
          <source>For example, the distance between &lt;code&gt;[3, na, na, 6]&lt;/code&gt; and &lt;code&gt;[1, na, 4, 5]&lt;/code&gt; is:</source>
          <target state="translated">たとえば、 &lt;code&gt;[3, na, na, 6]&lt;/code&gt; と &lt;code&gt;[1, na, 4, 5]&lt;/code&gt; ]の間の距離は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="875d6b4f0ebd92b4525ff9ff007e35a4ef09b992" translate="yes" xml:space="preserve">
          <source>For example, the following snippet uses &lt;code&gt;chardet&lt;/code&gt; (not shipped with scikit-learn, must be installed separately) to figure out the encoding of three texts. It then vectorizes the texts and prints the learned vocabulary. The output is not shown here.</source>
          <target state="translated">たとえば、次のスニペットは、 &lt;code&gt;chardet&lt;/code&gt; （scikit-learnに同梱されていないため、個別にインストールする必要があります）を使用して、3つのテキストのエンコーディングを把握します。次に、テキストをベクトル化し、学習した語彙を出力します。出力はここには表示されません。</target>
        </trans-unit>
        <trans-unit id="a5b55b26c17fcbb577abf03053fdea355f9d1a85" translate="yes" xml:space="preserve">
          <source>For example, this warning may occur when the user</source>
          <target state="translated">例えば、この警告は、ユーザーが</target>
        </trans-unit>
        <trans-unit id="fa61683485e98ae724ab66c0cc502f9a28b6f341" translate="yes" xml:space="preserve">
          <source>For example, to download a dataset of gene expressions in mice brains:</source>
          <target state="translated">例えば、マウス脳内の遺伝子発現のデータセットをダウンロードするには、以下のようにします。</target>
        </trans-unit>
        <trans-unit id="0fb165a7680e316154f88ea288da16adb651003b" translate="yes" xml:space="preserve">
          <source>For example, to use &lt;code&gt;n_jobs&lt;/code&gt; greater than 1 in the example below, &lt;code&gt;custom_scoring_function&lt;/code&gt; function is saved in a user-created module (&lt;code&gt;custom_scorer_module.py&lt;/code&gt;) and imported:</source>
          <target state="translated">たとえば、以下の例で1より大きい &lt;code&gt;n_jobs&lt;/code&gt; を使用するには、 &lt;code&gt;custom_scoring_function&lt;/code&gt; 関数をユーザーが作成したモジュール（ &lt;code&gt;custom_scorer_module.py&lt;/code&gt; ）に保存し、次のようにインポートします。</target>
        </trans-unit>
        <trans-unit id="bea8752fb35944e93422e8c1c3a159c63e531901" translate="yes" xml:space="preserve">
          <source>For example, we can compute the tf-idf of the first term in the first document in the &lt;code&gt;counts&lt;/code&gt; array as follows:</source>
          <target state="translated">たとえば、次のように &lt;code&gt;counts&lt;/code&gt; 配列の最初のドキュメントの最初の用語のtf-idfを計算できます。</target>
        </trans-unit>
        <trans-unit id="8e5e851ba9e40a81086c0f41a19109e3eeaaee54" translate="yes" xml:space="preserve">
          <source>For example, when dealing with boolean features, \(x_i^n = x_i\) for all \(n\) and is therefore useless; but \(x_i x_j\) represents the conjunction of two booleans. This way, we can solve the XOR problem with a linear classifier:</source>
          <target state="translated">例えば、ブーリアン特徴を扱う場合、\(x_i^n=x_i\)for all \(n\)and is therefore useless;but \(x_i x_j)は、2つのブーリアンの結合を表します。このようにして、線形分類器でXOR問題を解くことができます。</target>
        </trans-unit>
        <trans-unit id="dfe2d757676022996b9aa748350ec295d5357a7e" translate="yes" xml:space="preserve">
          <source>For example, when using a validation set, set the &lt;code&gt;test_fold&lt;/code&gt; to 0 for all samples that are part of the validation set, and to -1 for all other samples.</source>
          <target state="translated">たとえば、検証セットを使用する場合、検証セットの一部であるすべてのサンプルについては &lt;code&gt;test_fold&lt;/code&gt; を0に設定し、他のすべてのサンプルについては-1に設定します。</target>
        </trans-unit>
        <trans-unit id="98a47ab600b3d6adb5169d4d316e6fcca6b662b8" translate="yes" xml:space="preserve">
          <source>For examples on how it is to be used refer to the sections below.</source>
          <target state="translated">使用例については、以下のセクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="717701439dd44ea572c3fc98c89180aa00806795" translate="yes" xml:space="preserve">
          <source>For further details on bias-variance decomposition, see section 7.3 of &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">偏りと分散の分解の詳細については、&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1の&lt;/a&gt;セクション7.3を参照してください。</target>
        </trans-unit>
        <trans-unit id="1fd7dfc113fdc87e0b1f446fd7d77e9da35e9457" translate="yes" xml:space="preserve">
          <source>For further details on bias-variance decomposition, see section 7.3 of &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">バイアス分散分解の詳細については、&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]の&lt;/a&gt;セクション7.3を参照してください。</target>
        </trans-unit>
        <trans-unit id="2f1f137cd461ac2e31c6cc087610e0dfea901ed1" translate="yes" xml:space="preserve">
          <source>For further details, &amp;ldquo;How to Use t-SNE Effectively&amp;rdquo; &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt; provides a good discussion of the effects of various parameters, as well as interactive plots to explore those effects.</source>
          <target state="translated">詳細については、「t-SNEを効果的に使用する方法」&lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;http://distill.pub/2016/misread-tsne/&lt;/a&gt;は、さまざまなパラメーターの効果についての適切な説明と、それらの効果を調査するためのインタラクティブなプロットを提供します。</target>
        </trans-unit>
        <trans-unit id="0482a5c448a6c0f244b48ce337c6748a1bc4ca45" translate="yes" xml:space="preserve">
          <source>For further details, &amp;ldquo;How to Use t-SNE Effectively&amp;rdquo; &lt;a href=&quot;https://distill.pub/2016/misread-tsne/&quot;&gt;https://distill.pub/2016/misread-tsne/&lt;/a&gt; provides a good discussion of the effects of various parameters, as well as interactive plots to explore those effects.</source>
          <target state="translated">詳細については、「t-SNEを効果的に使用する方法」&lt;a href=&quot;https://distill.pub/2016/misread-tsne/&quot;&gt;https://distill.pub/2016/misread-tsne/&lt;/a&gt;で、さまざまなパラメーターの効果についての優れた説明と、それらの効果を調査するためのインタラクティブなプロットを提供しています。</target>
        </trans-unit>
        <trans-unit id="0f1bbe6e8000be72ab1e63dd45896ee0e4b6eb7a" translate="yes" xml:space="preserve">
          <source>For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (&lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;) can perform effective non-linear feature extraction.</source>
          <target state="translated">手書きの数字認識のように、ピクセル値を白い背景の黒さの度合いとして解釈できるグレースケール画像データの場合、ベルヌーイ制限付きボルツマンマシンモデル（&lt;a href=&quot;../../modules/generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt;）は、効果的な非線形特徴抽出を実行できます。</target>
        </trans-unit>
        <trans-unit id="0f8240ee0365c34e0de439585e58b6dfcdcc2ed3" translate="yes" xml:space="preserve">
          <source>For high-dimensional datasets with many collinear features, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt; is most often preferable. However, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt;&lt;code&gt;LassoLarsCV&lt;/code&gt;&lt;/a&gt; has the advantage of exploring more relevant values of &lt;code&gt;alpha&lt;/code&gt; parameter, and if the number of samples is very small compared to the number of features, it is often faster than &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">多くの同一線上の特徴を持つ高次元データセットの場合、&lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt;が最も適しています。ただし、&lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt; &lt;code&gt;LassoLarsCV&lt;/code&gt; に&lt;/a&gt;は、 &lt;code&gt;alpha&lt;/code&gt; パラメータのより関連性の高い値を探索するという利点があり、サンプルの数が特徴の数と比較して非常に少ない場合、&lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt;よりも高速であることがよくあります。</target>
        </trans-unit>
        <trans-unit id="866314f9db098f25a642d6cb6f4a133adac68ce1" translate="yes" xml:space="preserve">
          <source>For high-dimensional datasets with many collinear regressors, &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt; is most often preferable. However, &lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt;&lt;code&gt;LassoLarsCV&lt;/code&gt;&lt;/a&gt; has the advantage of exploring more relevant values of &lt;code&gt;alpha&lt;/code&gt; parameter, and if the number of samples is very small compared to the number of features, it is often faster than &lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt;&lt;code&gt;LassoCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">多くの共線回帰子を持つ高次元のデータセットの場合、&lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt;が最もよく使用されます。ただし、&lt;a href=&quot;generated/sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV&quot;&gt; &lt;code&gt;LassoLarsCV&lt;/code&gt; に&lt;/a&gt;は &lt;code&gt;alpha&lt;/code&gt; パラメータのより関連性の高い値を探索できるという利点があり、サンプルの数が特徴の数と比較して非常に少ない場合は、多くの場合&lt;a href=&quot;generated/sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV&quot;&gt; &lt;code&gt;LassoCV&lt;/code&gt; &lt;/a&gt;よりも高速です。</target>
        </trans-unit>
        <trans-unit id="aff7e1aca1f3054316321a609c5b24bbfe0a02a6" translate="yes" xml:space="preserve">
          <source>For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.</source>
          <target state="translated">NIST の前処理ルーチンについては、M.D.Garris,J.L.Blue,G.T.Candela,D.L.Dimmick,J.Geist,P.J.Grother,S.A.Janet,and C.L.Wilson,NIST Form-Based Handprint Recognition System,NISTIR 5469,1994 を参照してください。</target>
        </trans-unit>
        <trans-unit id="ee57e485cfe4c61d12541e3ea6e169aab79014e8" translate="yes" xml:space="preserve">
          <source>For instance a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.</source>
          <target state="translated">例えば、10,000個の短いテキスト文書(電子メールなど)のコレクションは、それぞれの文書が個別に100〜1000個のユニークな単語を使用している間に、合計で10万個のユニークな単語の順序でサイズの語彙を使用しています。</target>
        </trans-unit>
        <trans-unit id="4e9f2f3fee78ca296cddfe5ea5b4e060f79a0a4e" translate="yes" xml:space="preserve">
          <source>For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">例えば、学習アルゴリズムの目的関数で使用される多くの要素(サポートベクターマシンのRBFカーネルや線形モデルのL1およびL2正則化器など)は、すべての特徴が0を中心とし、同じ順序で分散を持つことを前提としています。ある特徴が他の特徴よりも桁違いに大きい分散を持っている場合、それが目的関数を支配し、推定器が他の特徴から期待通りに正しく学習できなくなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="9c54ff6618aa4505fc044efee7a1b7aa2d457afd" translate="yes" xml:space="preserve">
          <source>For instance the below given table</source>
          <target state="translated">例えば、以下の表のようになります。</target>
        </trans-unit>
        <trans-unit id="61fc71afaf6946d5d1cad0702c1f4030326fcb83" translate="yes" xml:space="preserve">
          <source>For instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.</source>
          <target state="translated">例えば、グループはサンプルの収集年とすることができ、それによって時間ベースの分割に対する交差検証を可能にします。</target>
        </trans-unit>
        <trans-unit id="c007161505dacd37b43b63ce0c84bfbd3ce25160" translate="yes" xml:space="preserve">
          <source>For instance, assuming that the inlier data are Gaussian distributed, it will estimate the inlier location and covariance in a robust way (i.e. without being influenced by outliers). The Mahalanobis distances obtained from this estimate is used to derive a measure of outlyingness. This strategy is illustrated below.</source>
          <target state="translated">例えば、インライアのデータがガウス分布であると仮定すると、インライアの位置と共分散をロバストな方法で(つまり、外れ値の影響を受けずに)推定します。この推定値から得られるマハラノビス距離は、アウトライネスの尺度を導出するために使用されます。この戦略は以下に図示されている。</target>
        </trans-unit>
        <trans-unit id="7519828cefe279ed0b1f593fd20db7243c914832" translate="yes" xml:space="preserve">
          <source>For instance, given a matrix of shape &lt;code&gt;(10, 10)&lt;/code&gt;, one possible bicluster with three rows and two columns induces a submatrix of shape &lt;code&gt;(3, 2)&lt;/code&gt;:</source>
          <target state="translated">たとえば、形状 &lt;code&gt;(10, 10)&lt;/code&gt; 行列が与えられた場合、3つの行と2つの列を持つ1つの可能なバイクラスターは、形状の部分行列 &lt;code&gt;(3, 2)&lt;/code&gt; 3、2 ）を誘導します。</target>
        </trans-unit>
        <trans-unit id="66b8e52235d720becae09b00e19696b279a13527" translate="yes" xml:space="preserve">
          <source>For instance, if \(p\) singular vectors were calculated, the \(q\) best are found as described, where \(q&amp;lt;p\). Let \(U\) be the matrix with columns the \(q\) best left singular vectors, and similarly \(V\) for the right. To partition the rows, the rows of \(A\) are projected to a \(q\) dimensional space: \(A * V\). Treating the \(m\) rows of this \(m \times q\) matrix as samples and clustering using k-means yields the row labels. Similarly, projecting the columns to \(A^{\top} * U\) and clustering this \(n \times q\) matrix yields the column labels.</source>
          <target state="translated">たとえば、\（p \）特異ベクトルが計算された場合、説明どおりに\（q \）が見つかります。ここで、\（q &amp;lt;p \）です。\（U \）を、\（q \）の最適な左特異ベクトルと同様に右の\（V \）の列を持つ行列とします。行を分割するには、\（A \）の行を\（q \）次元空間に投影します：\（A * V \）。この\（m \ times q \）行列の\（m \）行をサンプルとして扱い、k平均を使用してクラスタリングすると、行ラベルが生成されます。同様に、列を\（A ^ {\ top} * U \）に射影し、この\（n \ times q \）行列をクラスター化すると、列ラベルが生成されます。</target>
        </trans-unit>
        <trans-unit id="040e034a022032a75dc3b85f4ce9de7cff88a6fc" translate="yes" xml:space="preserve">
          <source>For instance, if we work with 64x64 pixel gray-level pictures for face recognition, the dimensionality of the data is 4096 and it is slow to train an RBF support vector machine on such wide data. Furthermore we know that the intrinsic dimensionality of the data is much lower than 4096 since all pictures of human faces look somewhat alike. The samples lie on a manifold of much lower dimension (say around 200 for instance). The PCA algorithm can be used to linearly transform the data while both reducing the dimensionality and preserve most of the explained variance at the same time.</source>
          <target state="translated">例えば,顔認識のために64x64ピクセルのグレーレベル画像を扱う場合,データの次元数は4096であり,このような広いデータでRBFサポートベクターマシンを訓練するのは遅い.さらに,人間の顔の写真はすべて似ているので,データの本質的な次元は4096よりもはるかに低いことがわかっています.サンプルは,はるかに低い次元の多様体上に存在します(例えば,200程度).PCAアルゴリズムは、データを線形変換するために使用できますが、同時に次元数を減らし、同時に説明された分散の大部分を保存します。</target>
        </trans-unit>
        <trans-unit id="f676ab37a8d5ec2f850de1fcd3ee779d6ce55a52" translate="yes" xml:space="preserve">
          <source>For instance, in the case of the digits dataset, &lt;code&gt;digits.data&lt;/code&gt; gives access to the features that can be used to classify the digits samples:</source>
          <target state="translated">たとえば、数字データセットの場合、 &lt;code&gt;digits.data&lt;/code&gt; は、数字サンプルの分類に使用できる機能へのアクセスを提供します。</target>
        </trans-unit>
        <trans-unit id="0b72faa109feccaf14265d5a54672e188bc4b73a" translate="yes" xml:space="preserve">
          <source>For instance, in the example below, decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.</source>
          <target state="translated">例えば、以下の例では、決定木はデータから学習し、一連のif-then-else決定ルールでサインカーブを近似します。木が深ければ深いほど、決定ルールは複雑になり、モデルはよりフィットします。</target>
        </trans-unit>
        <trans-unit id="a42ba327206d2f6a371d1c7b16518c8946340f21" translate="yes" xml:space="preserve">
          <source>For instance, let&amp;rsquo;s compare the two predictions 1.0 and 100 that are both 50% of their corresponding true value.</source>
          <target state="translated">たとえば、対応する真の値の50％である2つの予測1.0と100を比較してみましょう。</target>
        </trans-unit>
        <trans-unit id="bb4b6181584be99d136bb8fd3d82dd09da37eec0" translate="yes" xml:space="preserve">
          <source>For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.</source>
          <target state="translated">例えば、学習アルゴリズムの目的関数で使用される多くの要素(サポートベクターマシンのRBFカーネルや線形モデルのl1およびl2正則化器など)は、すべての特徴がゼロを中心とし、同じ順序で分散を持つことを前提としています。ある特徴が他の特徴よりも桁違いに大きい分散を持っている場合、それが目的関数を支配し、推定器が他の特徴から期待通りに正しく学習できなくなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="2500a85d8a54066d44afc291418c2bdbdb2d8331" translate="yes" xml:space="preserve">
          <source>For instance, the following shows 16 sample portraits (centered around 0.0) from the Olivetti dataset. On the right hand side are the first 16 singular vectors reshaped as portraits. Since we only require the top 16 singular vectors of a dataset with size \(n_{samples} = 400\) and \(n_{features} = 64 \times 64 = 4096\), the computation time is less than 1s:</source>
          <target state="translated">例えば、以下はオリベッティデータセットの16個のサンプルポートレート(0.0を中心とした)を示しています。右側は,最初の16個の特異点ベクトルをポートレートにリシェイプしたものである.サイズが\(n_{samples}=400)と\(n_{features}=64 \times 64=4096)のデータセットの先頭16個の特異ベクトルだけを求めればよいので,計算時間は1秒以下である.</target>
        </trans-unit>
        <trans-unit id="8f189274df939cb66095eb188cc3a399c86cb294" translate="yes" xml:space="preserve">
          <source>For instance, we can perform a \(\chi^2\) test to the samples to retrieve only the two best features as follows:</source>
          <target state="translated">例えば、以下のように、2つの最良の特徴だけを取り出すために、サンプルに対して「\chi^2」テストを実行することができます。</target>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="translated">例えば</target>
        </trans-unit>
        <trans-unit id="c017c696c4eba476debcc2637355a4ef09f7c0a3" translate="yes" xml:space="preserve">
          <source>For int/None inputs, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">int / None入力の場合、 &lt;code&gt;KFold&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="560fc78b966a9c766c4d5505bc2466cc24122eb7" translate="yes" xml:space="preserve">
          <source>For int/None inputs, if the estimator is a classifier and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">int / None入力の場合、推定量が分類子であり、 &lt;code&gt;y&lt;/code&gt; がバイナリまたはマルチクラスの場合、&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;が使用されます。それ以外の場合はすべて、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;が使用されます。</target>
        </trans-unit>
        <trans-unit id="21205df9d4ba13a75af14823666b84f64bd04084" translate="yes" xml:space="preserve">
          <source>For integer/None inputs &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">整数/なしの入力の場合、 &lt;code&gt;KFold&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="f4cdf9352c6e062816193041b97f5514c42b421e" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">整数/なし入力の場合、 &lt;code&gt;KFold&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="f206c091dc56a7e693c1c1efe6b0899c57cec04a" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used, else, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">場合整数/なし入力の場合、 &lt;code&gt;y&lt;/code&gt; はバイナリまたは多クラス、ある&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; が&lt;/a&gt;使用され、そうでなければ、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; が&lt;/a&gt;使用されます。</target>
        </trans-unit>
        <trans-unit id="84373ac49af10a751441a8470e060e3de62490b1" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">整数/なしの入力の場合、 &lt;code&gt;y&lt;/code&gt; がバイナリまたはマルチクラスの場合、&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt;が使用されます。 &lt;code&gt;y&lt;/code&gt; がバイナリでもマルチクラスでもない場合、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt;が使用されます。</target>
        </trans-unit>
        <trans-unit id="8d4fea32021fed22e35126e0e01d0c620369dc78" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if &lt;code&gt;y&lt;/code&gt; is binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. If the estimator is a classifier or if &lt;code&gt;y&lt;/code&gt; is neither binary nor multiclass, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">整数/なしの入力の場合、 &lt;code&gt;y&lt;/code&gt; がバイナリまたはマルチクラスの場合、&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;sklearn.model_selection.StratifiedKFold&lt;/code&gt; &lt;/a&gt;が使用されます。推定器が分類子である場合、または &lt;code&gt;y&lt;/code&gt; がバイナリでもマルチクラスでもない場合、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;sklearn.model_selection.KFold&lt;/code&gt; &lt;/a&gt;が使用されます。</target>
        </trans-unit>
        <trans-unit id="68ad85210cd514ab63c161f2689020aa738ee186" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if classifier is True and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">整数/なしの入力の場合、分類子がTrueで &lt;code&gt;y&lt;/code&gt; がバイナリまたはマルチクラスの場合、&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;が使用されます。他のすべてのケースでは、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;が使用されます。</target>
        </trans-unit>
        <trans-unit id="821cadb32f750528bd31875526972b81201437b9" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if the estimator is a classifier and &lt;code&gt;y&lt;/code&gt; is either binary or multiclass, &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; is used. In all other cases, &lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is used.</source>
          <target state="translated">整数/なしの入力の場合、推定器が分類子であり、 &lt;code&gt;y&lt;/code&gt; がバイナリまたはマルチクラスの場合、&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;が使用されます。他のすべてのケースでは、&lt;a href=&quot;sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;が使用されます。</target>
        </trans-unit>
        <trans-unit id="ec46cd7e35a119deeb6479ced2aa91071495e898" translate="yes" xml:space="preserve">
          <source>For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, &lt;code&gt;StratifiedKFold&lt;/code&gt; is used. In all other cases, &lt;code&gt;KFold&lt;/code&gt; is used.</source>
          <target state="translated">整数/なし入力の場合、推定量が分類子であり、yがバイナリまたはマルチクラスの場合、 &lt;code&gt;StratifiedKFold&lt;/code&gt; が使用されます。それ以外の場合はすべて、 &lt;code&gt;KFold&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="cfc9bcb00c8530f8c99a68584e1330a4da8fc56a" translate="yes" xml:space="preserve">
          <source>For intermediate values, we can see on the second plot that good models can be found on a diagonal of &lt;code&gt;C&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt;. Smooth models (lower &lt;code&gt;gamma&lt;/code&gt; values) can be made more complex by increasing the importance of classifying each point correctly (larger &lt;code&gt;C&lt;/code&gt; values) hence the diagonal of good performing models.</source>
          <target state="translated">中間値については、2番目のプロットで、 &lt;code&gt;C&lt;/code&gt; と &lt;code&gt;gamma&lt;/code&gt; の対角線上に適切なモデルがあることがわかります。滑らかなモデル（ &lt;code&gt;gamma&lt;/code&gt; 値が低い）は、各ポイントを正しく分類する（ &lt;code&gt;C&lt;/code&gt; 値が大きい）ことの重要性を高めることにより、より複雑にすることができます。</target>
        </trans-unit>
        <trans-unit id="eb96f16ecd15a6be088f1dc93fa28ca4ca7ecca5" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is (n_samples_test, n_samples_train).</source>
          <target state="translated">kernel =&amp;rdquo; precomputed&amp;rdquo;の場合、Xの予想される形状は（n_samples_test、n_samples_train）です。</target>
        </trans-unit>
        <trans-unit id="93c16e02e4641d6fe7bdb8a83439c237817b53cd" translate="yes" xml:space="preserve">
          <source>For kernel=&amp;rdquo;precomputed&amp;rdquo;, the expected shape of X is [n_samples_test, n_samples_train]</source>
          <target state="translated">kernel =&amp;rdquo; precomputed&amp;rdquo;の場合、Xの予想される形状は[n_samples_test、n_samples_train]です</target>
        </trans-unit>
        <trans-unit id="9cb299cfc771ccbc3a241c16ffeed37fabbcff7c" translate="yes" xml:space="preserve">
          <source>For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss.</source>
          <target state="translated">大規模なデータセットの場合、&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt;を「ログ」の損失とともに使用することも検討できます。</target>
        </trans-unit>
        <trans-unit id="3b24421d17b9758d0c0e99f847aff320121bf350" translate="yes" xml:space="preserve">
          <source>For large datasets, similar (but not identical) results can be obtained via &lt;a href=&quot;https://hdbscan.readthedocs.io&quot;&gt;HDBSCAN&lt;/a&gt;. The HDBSCAN implementation is multithreaded, and has better algorithmic runtime complexity than OPTICS, at the cost of worse memory scaling. For extremely large datasets that exhaust system memory using HDBSCAN, OPTICS will maintain &lt;em&gt;n&lt;/em&gt; (as opposed to &lt;em&gt;n^2&lt;/em&gt;) memory scaling; however, tuning of the &lt;code&gt;max_eps&lt;/code&gt; parameter will likely need to be used to give a solution in a reasonable amount of wall time.</source>
          <target state="translated">大規模なデータセットの場合、&lt;a href=&quot;https://hdbscan.readthedocs.io&quot;&gt;HDBSCAN&lt;/a&gt;を介して同様の（ただし同一ではない）結果を取得できます。HDBSCAN実装はマルチスレッドであり、メモリスケーリングが悪化するという犠牲を払って、OPTICSよりもアルゴリズムの実行時の複雑さが向上します。非常に大きなデータセットのための排気システムメモリがHDBSCANを使用することを、光学系は維持する&lt;em&gt;N&lt;/em&gt;（とは対照的に&lt;em&gt;、N ^ 2&lt;/em&gt;メモリスケーリング）。ただし、 &lt;code&gt;max_eps&lt;/code&gt; パラメータの調整を使用して、妥当な時間の壁時間で解を与える必要があります。</target>
        </trans-unit>
        <trans-unit id="98187e1f181515ca77d41de7fa27ac44b69c7c11" translate="yes" xml:space="preserve">
          <source>For many estimators, including the SVMs, having datasets with unit standard deviation for each feature is important to get good prediction.</source>
          <target state="translated">SVMをはじめとする多くの推定器では、各特徴に対して単位標準偏差を持つデータセットを持つことが、良好な予測を得るために重要である。</target>
        </trans-unit>
        <trans-unit id="f1359c1e0656157adbc7e3ee11ae253cb961bb70" translate="yes" xml:space="preserve">
          <source>For mono-output tasks it is:</source>
          <target state="translated">単出力タスクの場合はそうです。</target>
        </trans-unit>
        <trans-unit id="c24592da8118b35d1dd067bf2a75576669aef344" translate="yes" xml:space="preserve">
          <source>For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression,&amp;rdquo; Annals of Statistics (with discussion), 407-499. (&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;)</source>
          <target state="translated">詳細については、Bradley Efron、Trevor Hastie、Iain Johnstone、およびRobert Tibshirani（2004）「Least Angle Regression」、Annals of Statistics（discussion）、407-499を参照してください。（&lt;a href=&quot;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="d5e463f9f0eea6808a42462cec939570f71a16a6" translate="yes" xml:space="preserve">
          <source>For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &amp;ldquo;Least Angle Regression,&amp;rdquo; Annals of Statistics (with discussion), 407-499. (&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;)</source>
          <target state="translated">詳細については、Bradley Efron、Trevor Hastie、Iain Johnstone、Robert Tibshirani（2004）「LeastAngle Regression」、Annals of Statistics（ディスカッション付き）、407-499を参照してください。（&lt;a href=&quot;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&quot;&gt;https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="a4bc4c3f735998ec8c1614ec6127a37e3e7a02d8" translate="yes" xml:space="preserve">
          <source>For more information, see &lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;.</source>
          <target state="translated">詳細については、「&lt;a href=&quot;../../modules/clustering#hierarchical-clustering&quot;&gt;階層的クラスタリング&lt;/a&gt;」を参照してください。</target>
        </trans-unit>
        <trans-unit id="b089e1ecd97ba592f22037a3c3fabf2924387c39" translate="yes" xml:space="preserve">
          <source>For more on usage see the &lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">使用方法の詳細については、&lt;a href=&quot;../feature_selection#univariate-feature-selection&quot;&gt;ユーザーガイドを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="2e682df49d58d058f1f4b4c26ca6fb15a2f979d8" translate="yes" xml:space="preserve">
          <source>For multi-class classification, &lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt;&lt;code&gt;AdaBoostClassifier&lt;/code&gt;&lt;/a&gt; implements AdaBoost-SAMME and AdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]&lt;/a&gt;.</source>
          <target state="translated">マルチクラス分類の場合、&lt;a href=&quot;generated/sklearn.ensemble.adaboostclassifier#sklearn.ensemble.AdaBoostClassifier&quot;&gt; &lt;code&gt;AdaBoostClassifier&lt;/code&gt; &lt;/a&gt;はAdaBoost-SAMMEおよびAdaBoost-SAMME.R &lt;a href=&quot;#zzrh2009&quot; id=&quot;id11&quot;&gt;[ZZRH2009]を実装します&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="416ab9ed1829c79f2f091ddf9b13cfb5bb7486ce" translate="yes" xml:space="preserve">
          <source>For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.</source>
          <target state="translated">マルチクラス分類では、n_class分類器を1対1のアプローチで学習します。具体的には、Ridgeの多変数応答サポートを利用して実装しています。</target>
        </trans-unit>
        <trans-unit id="f04898b2d6925a5dec9ef02339647623f6f19f8d" translate="yes" xml:space="preserve">
          <source>For multi-class classification, you need to set the class label for which the PDPs should be created via the &lt;code&gt;target&lt;/code&gt; argument:</source>
          <target state="translated">マルチクラス分類の場合、 &lt;code&gt;target&lt;/code&gt; 引数を介してPDPを作成するクラスラベルを設定する必要があります。</target>
        </trans-unit>
        <trans-unit id="65042013a5d26811a6a7088f4c47e70c6ddb0074" translate="yes" xml:space="preserve">
          <source>For multi-class models, you need to set the class label for which the PDPs should be created via the &lt;code&gt;label&lt;/code&gt; argument:</source>
          <target state="translated">マルチクラスモデルの場合、 &lt;code&gt;label&lt;/code&gt; 引数を使用して、PDPを作成するクラスラベルを設定する必要があります。</target>
        </trans-unit>
        <trans-unit id="ccc2264ef7a998ec0c6ed9c92245080e0f0807c7" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, the scores for all the scorers are available in the &lt;code&gt;cv_results_&lt;/code&gt; dict at the keys ending with that scorer&amp;rsquo;s name (&lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt;) instead of &lt;code&gt;'_score'&lt;/code&gt; shown above. (&amp;lsquo;split0_test_precision&amp;rsquo;, &amp;lsquo;mean_train_precision&amp;rsquo; etc.)</source>
          <target state="translated">マルチメトリック評価の場合、すべてのスコアラーのスコアは、上記の &lt;code&gt;'_score'&lt;/code&gt; 代わりに、スコアラーの名前（ &lt;code&gt;'_&amp;lt;scorer_name&amp;gt;'&lt;/code&gt; ）で終わるキーの &lt;code&gt;cv_results_&lt;/code&gt; dictで利用できます。（ 'split0_test_precision'、 'mean_train_precision'など）</target>
        </trans-unit>
        <trans-unit id="6cd27769ef18013ec211b9a824f9bced7dd1ce74" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute holds the validated &lt;code&gt;scoring&lt;/code&gt; dict which maps the scorer key to the scorer callable.</source>
          <target state="translated">マルチメトリック評価の場合、この属性は、スコアラーキーをスコアラー呼び出し可能オブジェクトにマップする検証済みの &lt;code&gt;scoring&lt;/code&gt; ディクテーションを保持します。</target>
        </trans-unit>
        <trans-unit id="39c0f65b87a914c1f3244978c44bbc4d0d1190be" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this attribute is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">マルチメトリック評価の場合、この属性は &lt;code&gt;refit&lt;/code&gt; が指定されている場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="dd788cb84c37fa5cbd110321907573fb764ddce9" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is not available if &lt;code&gt;refit&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;. See &lt;code&gt;refit&lt;/code&gt; parameter for more information.</source>
          <target state="translated">マルチメトリック評価では、 &lt;code&gt;refit&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; の場合、これは使用できません。詳細については、 &lt;code&gt;refit&lt;/code&gt; パラメータを参照してください。</target>
        </trans-unit>
        <trans-unit id="4367b150d838b05eaff7170a1426f1dc4e6edc76" translate="yes" xml:space="preserve">
          <source>For multi-metric evaluation, this is present only if &lt;code&gt;refit&lt;/code&gt; is specified.</source>
          <target state="translated">マルチメトリック評価の場合、これは &lt;code&gt;refit&lt;/code&gt; が指定されている場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="d328aa31182c6b57c5d921c1da1c7333c03486fe" translate="yes" xml:space="preserve">
          <source>For multi-output tasks it is:</source>
          <target state="translated">複数出力のタスクの場合はそれになります。</target>
        </trans-unit>
        <trans-unit id="22c12fa701004eab18f67dae2fb9f6cb3b68f428" translate="yes" xml:space="preserve">
          <source>For multi-output, the weights of each column of y will be multiplied.</source>
          <target state="translated">多出力の場合は、yの各列の重みが乗算されます。</target>
        </trans-unit>
        <trans-unit id="77f8b599f18368a52e2142c2cada7c61eef9fbca" translate="yes" xml:space="preserve">
          <source>For multiclass classification with a &amp;ldquo;negative class&amp;rdquo;, it is possible to exclude some labels:</source>
          <target state="translated">「ネガティブクラス」のマルチクラス分類の場合、一部のラベルを除外することができます。</target>
        </trans-unit>
        <trans-unit id="dedd3af803ae0305b6a99c040827201493989ff1" translate="yes" xml:space="preserve">
          <source>For multiclass classification, K trees (for K classes) are built at each of the \(M\) iterations. The probability that \(x_i\) belongs to class k is modeled as a softmax of the \(F_{M,k}(x_i)\) values.</source>
          <target state="translated">多クラス分類の場合は、各回ごとに、K本の木(Kクラス)を作成する。\(x_i)がクラスkに属する確率は、ソフトマックスの値としてモデル化される。</target>
        </trans-unit>
        <trans-unit id="393c73f8bfb73747a6a85987ccf51d73c8d3636f" translate="yes" xml:space="preserve">
          <source>For multiclass problems, only &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; handle multinomial loss; &amp;lsquo;liblinear&amp;rsquo; is limited to one-versus-rest schemes.</source>
          <target state="translated">マルチクラス問題の場合、多項式損失を処理するのは 'newton-cg'、 'sag'、 'saga'および 'lbfgs'のみです。'liblinear'は、1対残りのスキームに制限されています。</target>
        </trans-unit>
        <trans-unit id="de227a68bb98af9d7f682ac4556427f028c04d66" translate="yes" xml:space="preserve">
          <source>For multiple labels per instance, use &lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">インスタンスごとに複数のラベルを使用するには、&lt;a href=&quot;generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; を&lt;/a&gt;使用します。</target>
        </trans-unit>
        <trans-unit id="36264d57db60ea0d287310ae67879ef2207922af" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a &lt;code&gt;str&lt;/code&gt; denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">複数のメトリック評価の場合、これは、最後に推定量を再調整するための最適なパラメーターを見つけるために使用されるスコアラーを示す &lt;code&gt;str&lt;/code&gt; である必要があります。</target>
        </trans-unit>
        <trans-unit id="088c3cd08ec3b30c1e8d705dc9f773b25266ffd1" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer is used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">多重メトリック評価の場合、これはスコアラーを示す文字列である必要があり、最後に推定器のリフィッティングに最適なパラメータを見つけるために使用されます。</target>
        </trans-unit>
        <trans-unit id="ab406c3bb6ddaeec6408e58ba4985d8a5097ee33" translate="yes" xml:space="preserve">
          <source>For multiple metric evaluation, this needs to be a string denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.</source>
          <target state="translated">複数のメトリック評価の場合、これは最後に推定器のリフィッティングに最適なパラメータを見つけるために使用されるスコアラーを示す文字列である必要があります。</target>
        </trans-unit>
        <trans-unit id="f895ac59b8264ca94c275f903e2d6c6c438b4c9c" translate="yes" xml:space="preserve">
          <source>For multiplicative-update (&amp;lsquo;mu&amp;rsquo;) solver, the Frobenius norm (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss, by changing the beta_loss parameter.</source>
          <target state="translated">乗法更新（ 'mu'）ソルバーの場合、Frobeniusノルム（0.5 * || X-WH || _Fro ^ 2）は、beta_lossパラメーターを変更することにより、別のベータ発散損失に変更できます。</target>
        </trans-unit>
        <trans-unit id="4d0bed9bc5aa3b36bb0ba6ad6bc592a5bb3e78af" translate="yes" xml:space="preserve">
          <source>For n_components == &amp;lsquo;mle&amp;rsquo;, this class uses the method of &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt;</source>
          <target state="translated">n_components == 'mle'の場合、このクラスは &lt;code&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/code&gt; メソッドを使用します。NIPSでは、pp。598-604</target>
        </trans-unit>
        <trans-unit id="bd307d11754e6296ef567a0e60c357948ac810da" translate="yes" xml:space="preserve">
          <source>For n_components == &amp;lsquo;mle&amp;rsquo;, this class uses the method of &lt;em&gt;Minka, T. P. &amp;ldquo;Automatic choice of dimensionality for PCA&amp;rdquo;. In NIPS, pp. 598-604&lt;/em&gt;</source>
          <target state="translated">n_components == 'mle'の場合、このクラスは&lt;em&gt;Minka、TP「PCAの次元の自動選択」の&lt;/em&gt;メソッドを使用し&lt;em&gt;ます。NIPSでは、598〜604ページ&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="9f27cc961ae174b8e96b15764c2907159174c2c2" translate="yes" xml:space="preserve">
          <source>For non-sparse models, i.e. when there are not many zeros in &lt;code&gt;coef_&lt;/code&gt;, this may actually &lt;em&gt;increase&lt;/em&gt; memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt;, must be more than 50% for this to provide significant benefits.</source>
          <target state="translated">非スパースモデルの場合、つまり &lt;code&gt;coef_&lt;/code&gt; にゼロが多くない場合、これは実際にメモリ使用量を&lt;em&gt;増やす&lt;/em&gt;可能性があるため、このメソッドは注意して使用してください。経験則では、 &lt;code&gt;(coef_ == 0).sum()&lt;/code&gt; で計算できるゼロ要素の数は、これが大きな利点を提供するために50％を超える必要があります。</target>
        </trans-unit>
        <trans-unit id="ffa9a81349b558a734852a9e93a9e01e72e14f97" translate="yes" xml:space="preserve">
          <source>For normalized mutual information and adjusted mutual information, the normalizing value is typically some &lt;em&gt;generalized&lt;/em&gt; mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides &amp;ldquo;qualitatively similar behaviours&amp;rdquo; &lt;a href=&quot;#yat2016&quot; id=&quot;id14&quot;&gt;[YAT2016]&lt;/a&gt;. In our implementation, this is controlled by the &lt;code&gt;average_method&lt;/code&gt; parameter.</source>
          <target state="translated">正規化された相互情報量と調整された相互情報量の場合、正規化値は通常、各クラスタリングのエントロピーの&lt;em&gt;一般化&lt;/em&gt;平均です。さまざまな一般化された手段が存在し、一方を他方よりも優先するための確固たる規則は存在しません。決定は主にフィールドごとに行われます。たとえば、コミュニティ検出では、算術平均が最も一般的です。それぞれの正規化方法は、「質的に類似した動作」を提供します&lt;a href=&quot;#yat2016&quot; id=&quot;id14&quot;&gt;[YAT2016]&lt;/a&gt;。私たちの実装では、これは &lt;code&gt;average_method&lt;/code&gt; パラメーターによって制御されます。</target>
        </trans-unit>
        <trans-unit id="e62cf2ed735d43186d3b55660d3dd2856258814f" translate="yes" xml:space="preserve">
          <source>For normalized mutual information and adjusted mutual information, the normalizing value is typically some &lt;em&gt;generalized&lt;/em&gt; mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides &amp;ldquo;qualitatively similar behaviours&amp;rdquo; [YAT2016]. In our implementation, this is controlled by the &lt;code&gt;average_method&lt;/code&gt; parameter.</source>
          <target state="translated">正規化された相互情報および調整された相互情報の場合、通常、正規化値は各クラスタリングのエントロピーのいくつかの&lt;em&gt;一般化された&lt;/em&gt;平均です。さまざまな一般化された手段が存在し、他の手段よりも1つを優先するための明確なルールはありません。決定は主にフィールドごとの基準です。たとえば、コミュニティ検出では、算術平均が最も一般的です。各正規化方法は、「質的に類似した動作」[YAT2016]を提供します。私たちの実装では、これは &lt;code&gt;average_method&lt;/code&gt; パラメータによって制御されます。</target>
        </trans-unit>
        <trans-unit id="8d22dd702102471017e490a2b7bc8b22b9add5e5" translate="yes" xml:space="preserve">
          <source>For now &amp;ldquo;auto&amp;rdquo; (kept for backward compatibiliy) chooses &amp;ldquo;elkan&amp;rdquo; but it might change in the future for a better heuristic.</source>
          <target state="translated">今のところ、「auto」（後方互換性のために保持）は「elkan」を選択しますが、より良いヒューリスティックのために将来変更される可能性があります。</target>
        </trans-unit>
        <trans-unit id="5573de0c3d8eae2871980794db1007675aa56eed" translate="yes" xml:space="preserve">
          <source>For now, we will consider the estimator as a black box:</source>
          <target state="translated">とりあえず、推定値をブラックボックスとして考えてみます。</target>
        </trans-unit>
        <trans-unit id="436dc589cc421427188d0cca81de34e1e73f3c7d" translate="yes" xml:space="preserve">
          <source>For one sample, given the vector of continuous ground-truth values for each target \(y \in \mathbb{R}^{M}\), where \(M\) is the number of outputs, and the prediction \(\hat{y}\), which induces the ranking function \(f\), the DCG score is</source>
          <target state="translated">あるサンプルでは、各ターゲットの連続的な基底真実値のベクトルが与えられている。</target>
        </trans-unit>
        <trans-unit id="09d6f289aa89a27e5d33a2c2e001f7d32a001ce5" translate="yes" xml:space="preserve">
          <source>For our dataset, again the model is not very predictive.</source>
          <target state="translated">私たちのデータセットでは、このモデルはあまり予測ができません。</target>
        </trans-unit>
        <trans-unit id="a7f8c21b68cc173c251c1992bff906fb9b13f276" translate="yes" xml:space="preserve">
          <source>For parameter estimation, the posterior distribution is:</source>
          <target state="translated">パラメータ推定の場合、事後分布は</target>
        </trans-unit>
        <trans-unit id="acaedbca04fb48c0d8436452cabe74f03629d275" translate="yes" xml:space="preserve">
          <source>For regression the default learning rate schedule is inverse scaling (&lt;code&gt;learning_rate='invscaling'&lt;/code&gt;), given by</source>
          <target state="translated">回帰の場合、デフォルトの学習率スケジュールは、次の式で与えられる逆スケーリング（ &lt;code&gt;learning_rate='invscaling'&lt;/code&gt; ）です。</target>
        </trans-unit>
        <trans-unit id="17d6bf85a6ee02e9c1e3f5f799f4a791f96ca437" translate="yes" xml:space="preserve">
          <source>For regression with a squared loss and a l2 penalty, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">二乗損失とl2ペナルティのある回帰の場合、平均化戦略を備えたSGDの別のバリアントは、&lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; の&lt;/a&gt;ソルバーとして利用可能な確率平均勾配（SAG）アルゴリズムで利用できます。</target>
        </trans-unit>
        <trans-unit id="82e8631b28597b123d5803439222a08ee2e59047" translate="yes" xml:space="preserve">
          <source>For regression, &lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt;&lt;code&gt;AdaBoostRegressor&lt;/code&gt;&lt;/a&gt; implements AdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]&lt;/a&gt;.</source>
          <target state="translated">回帰の場合、&lt;a href=&quot;generated/sklearn.ensemble.adaboostregressor#sklearn.ensemble.AdaBoostRegressor&quot;&gt; &lt;code&gt;AdaBoostRegressor&lt;/code&gt; &lt;/a&gt;はAdaBoost.R2 &lt;a href=&quot;#d1997&quot; id=&quot;id12&quot;&gt;[D1997]を&lt;/a&gt;実装します。</target>
        </trans-unit>
        <trans-unit id="faab950ebeb88e87f11e22c6efcd943439e07aea" translate="yes" xml:space="preserve">
          <source>For regression, MLP uses the Square Error loss function; written as,</source>
          <target state="translated">回帰では、MLPは二乗誤差損失関数を使用します;次のように書かれています。</target>
        </trans-unit>
        <trans-unit id="a8c842b7da02e24dac30b073413aa7112e52aecd" translate="yes" xml:space="preserve">
          <source>For regression: &lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt;&lt;code&gt;f_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">回帰の場合：&lt;a href=&quot;generated/sklearn.feature_selection.f_regression#sklearn.feature_selection.f_regression&quot;&gt; &lt;code&gt;f_regression&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e8aa16ccbf6b94ae32b7c5b78e608f800f0eb6cd" translate="yes" xml:space="preserve">
          <source>For scikit-learn versions 0.14.1 and prior, return_as=np.ndarray was handled by returning a dense np.matrix instance. Going forward, np.ndarray returns an np.ndarray, as expected.</source>
          <target state="translated">scikit-learnのバージョン0.14.1以前では、return_as=np.ndarrayは密なnp.matrixインスタンスを返すことで処理されていました。今後、np.ndarrayは期待通りnp.ndarrayを返すようになります。</target>
        </trans-unit>
        <trans-unit id="2410f1ccaa1a03065aaeec2b709967381feb9cea" translate="yes" xml:space="preserve">
          <source>For simple transformations, instead of a Transformer object, a pair of functions can be passed, defining the transformation and its inverse mapping:</source>
          <target state="translated">単純な変換の場合は、Transformerオブジェクトの代わりに、変換とその逆マッピングを定義する関数のペアを渡すことができます。</target>
        </trans-unit>
        <trans-unit id="2f72f7e3c1f68f97fc714ad1c06f3f5738fb15a6" translate="yes" xml:space="preserve">
          <source>For simplicity the equation above is written for a single training example. The gradient with respect to the weights is formed of two terms corresponding to the ones above. They are usually known as the positive gradient and the negative gradient, because of their respective signs. In this implementation, the gradients are estimated over mini-batches of samples.</source>
          <target state="translated">簡単にするために、上の式は単一の学習例について書かれています。重みに対する勾配は、上の式に対応する2つの項から成り立っています。これらは、それぞれの符号の関係から、通常、正の勾配と負の勾配として知られています。この実施形態では、勾配はサンプルのミニバッチにわたって推定される。</target>
        </trans-unit>
        <trans-unit id="27c46746207f2a31ae25da1632ef3ccf3ef87e4d" translate="yes" xml:space="preserve">
          <source>For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</source>
          <target state="translated">単一メトリック評価の場合、スコアリングパラメーターが文字列、呼び出し可能、またはなしの場合、キーは- &lt;code&gt;['test_score', 'fit_time', 'score_time']&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a0a8bb77034843b440cd9ae1f7c55bd3aa47ece1" translate="yes" xml:space="preserve">
          <source>For small data sets (\(N\) less than 30 or so), \(\log(N)\) is comparable to \(N\), and brute force algorithms can be more efficient than a tree-based approach. Both &lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; address this through providing a &lt;em&gt;leaf size&lt;/em&gt; parameter: this controls the number of samples at which a query switches to brute-force. This allows both algorithms to approach the efficiency of a brute-force computation for small \(N\).</source>
          <target state="translated">小さいデータセット（\（N \）が30未満）の場合、\（\ log（N）\）は\（N \）に相当し、ブルートフォースアルゴリズムはツリーベースのアプローチよりも効率的です。&lt;a href=&quot;generated/sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; は&lt;/a&gt;どちらも、&lt;em&gt;リーフサイズ&lt;/em&gt;パラメータを提供することでこれに対処しています。これは、クエリがブルートフォースに切り替わるサンプルの数を制御します。これにより、両方のアルゴリズムで、小さい\（N \）のブルートフォース計算の効率に近づくことができます。</target>
        </trans-unit>
        <trans-unit id="4638d963661692a289a12b8cac2d92a9d2c758fa" translate="yes" xml:space="preserve">
          <source>For small datasets, &amp;lsquo;liblinear&amp;rsquo; is a good choice, whereas &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;saga&amp;rsquo; are faster for large ones.</source>
          <target state="translated">小さなデータセットの場合、「liblinear」が適切な選択ですが、「sag」と「saga」は大きなデータセットの方が高速です。</target>
        </trans-unit>
        <trans-unit id="dffce5e2239efe7c22f00e78e9cfce148c8ba698" translate="yes" xml:space="preserve">
          <source>For some applications the amount of examples, features (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. In these cases scikit-learn has a number of options you can consider to make your system scale.</source>
          <target state="translated">アプリケーションによっては、例題の量、特徴(またはその両方)、および/または処理速度が従来のアプローチでは困難な場合があります。このような場合、scikit-learnはシステムを拡張するためのオプションをいくつか用意しています。</target>
        </trans-unit>
        <trans-unit id="d0fa030cdd6e029de147eaddac9b22a69b1ced78" translate="yes" xml:space="preserve">
          <source>For some applications the performance (mainly latency and throughput at prediction time) of estimators is crucial. It may also be of interest to consider the training throughput but this is often less important in a production setup (where it often takes place offline).</source>
          <target state="translated">いくつかのアプリケーションでは、推定者の性能(主に予測時のレイテンシとスループット)が非常に重要である。トレーニングのスループットを考慮することも興味があるかもしれませんが、これは本番環境(オフラインで行われることが多い)ではあまり重要ではないことが多いです。</target>
        </trans-unit>
        <trans-unit id="7c42c316b39e1433fd7efc7ca18424a81519f374" translate="yes" xml:space="preserve">
          <source>For some business applications, we are interested in the ability of the model to rank the riskiest from the safest policyholders, irrespective of the absolute value of the prediction. In this case, the model evaluation would cast the problem as a ranking problem rather than a regression problem.</source>
          <target state="translated">いくつかのビジネス・アプリケーションでは、予測の絶対値に関係なく、最も安全な契約者の中から最もリスクの高い契約者をランク付けするモデルの能力に興味があります。この場合、モデルの評価は、回帰問題ではなく順位付け問題として問題を投げかけることになります。</target>
        </trans-unit>
        <trans-unit id="7400fa7073eb75f62370e5aadbb0f2aef8d5fc81" translate="yes" xml:space="preserve">
          <source>For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using &lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt;&lt;code&gt;PredefinedSplit&lt;/code&gt;&lt;/a&gt; it is possible to use these folds e.g. when searching for hyperparameters.</source>
          <target state="translated">一部のデータセットでは、トレーニングと検証の分割、またはいくつかの相互検証の分割へのデータの事前定義された分割がすでに存在しています。使用&lt;a href=&quot;generated/sklearn.model_selection.predefinedsplit#sklearn.model_selection.PredefinedSplit&quot;&gt; &lt;code&gt;PredefinedSplit&lt;/code&gt; を&lt;/a&gt;ハイパーを検索するときに、これらの折り目などを使用することが可能です。</target>
        </trans-unit>
        <trans-unit id="694369dc091b24e34e3df33be9eef2601d0ef6d1" translate="yes" xml:space="preserve">
          <source>For some losses, e.g. the least absolute deviation (LAD) where the gradients are \(\pm 1\), the values predicted by a fitted \(h_m\) are not accurate enough: the tree can only output integer values. As a result, the leaves values of the tree \(h_m\) are modified once the tree is fitted, such that the leaves values minimize the loss \(L_m\). The update is loss-dependent: for the LAD loss, the value of a leaf is updated to the median of the samples in that leaf.</source>
          <target state="translated">損失の場合、例えば、最小絶対偏差(LAD)の場合、勾配が\(\(m)1\(m)1)では、木が整数値しか出力できないので、木をはめた時の予測値は、十分に正確ではありません。その結果、損失が最小になるように、木の葉の値を修正する。更新は損失に依存します:LAD の損失に対して、リーフの値は、そのリーフのサンプルの中央値に更新されます。</target>
        </trans-unit>
        <trans-unit id="c50bf24a893de08f1d0809fe397202f1a031fb85" translate="yes" xml:space="preserve">
          <source>For some miscellaneous data such as images, videos, and audio, you may wish to refer to:</source>
          <target state="translated">画像や動画、音声などの雑多なデータについては、参考にしてみてはいかがでしょうか。</target>
        </trans-unit>
        <trans-unit id="303cfe0bd7811405e77868ed843c4904556ebde5" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;) before being fed to efficient Cython routines. To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">スパース入力の場合、データは効率的なCythonルーチンに送られる前&lt;strong&gt;に、圧縮スパース行表現&lt;/strong&gt;（ &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; を参照）に&lt;strong&gt;変換され&lt;/strong&gt;ます。不要なメモリコピーを回避するために、上流のCSR表現を選択することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="44ae99861a7942ab4350b3f16d27ddb33207e51f" translate="yes" xml:space="preserve">
          <source>For sparse input the data is &lt;strong&gt;converted to the Compressed Sparse Rows representation&lt;/strong&gt; (see &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt;). To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.</source>
          <target state="translated">スパース入力の場合、データは&lt;strong&gt;圧縮スパース行表現に変換され&lt;/strong&gt;ます（ &lt;code&gt;scipy.sparse.csr_matrix&lt;/code&gt; を参照）。不要なメモリコピーを回避するために、上流のCSR表現を選択することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="a6ddfb481ebd700db5464677bebe705030e704c9" translate="yes" xml:space="preserve">
          <source>For speed and space efficiency reasons &lt;code&gt;scikit-learn&lt;/code&gt; loads the target attribute as an array of integers that corresponds to the index of the category name in the &lt;code&gt;target_names&lt;/code&gt; list. The category integer id of each sample is stored in the &lt;code&gt;target&lt;/code&gt; attribute:</source>
          <target state="translated">速度とスペース効率の理由から、 &lt;code&gt;scikit-learn&lt;/code&gt; は &lt;code&gt;target_names&lt;/code&gt; リスト内のカテゴリ名のインデックスに対応する整数の配列としてターゲット属性をロードします。各サンプルのカテゴリー整数IDは、 &lt;code&gt;target&lt;/code&gt; 属性に保管されます。</target>
        </trans-unit>
        <trans-unit id="7ace947ef3298ab26b0edee5253deecf977a3b02" translate="yes" xml:space="preserve">
          <source>For speed, all real work is done at the C level in function copy_predict (libsvm_helper.c).</source>
          <target state="translated">スピードを上げるために、実際の作業はすべて関数 copy_predict (libsvm_helper.c)の C レベルで行われます。</target>
        </trans-unit>
        <trans-unit id="1c3a0f29bcc1c543ffc020478b77d5b706223ce4" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit domain-specific stratification of the dataset.</source>
          <target state="translated">データセットの明示的なドメイン固有の層別化に従ってデータを分割するためのもの。</target>
        </trans-unit>
        <trans-unit id="0adf7a63adc917db1adffd6d4cf61e05de34a6e7" translate="yes" xml:space="preserve">
          <source>For splitting the data according to explicit, domain-specific stratification of the dataset.</source>
          <target state="translated">データセットの明示的なドメイン固有の層別化に従ってデータを分割するためのもの。</target>
        </trans-unit>
        <trans-unit id="ab4a742934d8510715858d09854f728742beaaec" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;arpack&amp;rsquo;, refer to &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;.</source>
          <target state="translated">svd_solver == 'arpack'については、 &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; を参照してください。</target>
        </trans-unit>
        <trans-unit id="25caaa7ea914cf58c60f262a55964ee17d21e090" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;randomized&amp;rsquo;, see: &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; and also &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</source>
          <target state="translated">svd_solver == 'randomized'については、Halko &lt;code&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/code&gt; また、 &lt;code&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c853f7e3d4c36b0f8076402fc9583125688d75a1" translate="yes" xml:space="preserve">
          <source>For svd_solver == &amp;lsquo;randomized&amp;rsquo;, see: &lt;em&gt;Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). &amp;ldquo;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions&amp;rdquo;. SIAM review, 53(2), 217-288.&lt;/em&gt; and also &lt;em&gt;Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). &amp;ldquo;A randomized algorithm for the decomposition of matrices&amp;rdquo;. Applied and Computational Harmonic Analysis, 30(1), 47-68.&lt;/em&gt;</source>
          <target state="translated">svd_solver == 'randomized'については、Halko &lt;em&gt;、N.、Martinsson、PG、およびTropp、JA（2011）を参照してください。 「ランダム性のある構造の発見：近似行列分解を構築するための確率的アルゴリズム」。 SIAMレビュー、53（2）、217-288。&lt;/em&gt;また、&lt;em&gt;Martinsson、PG、Rokhlin、V。、およびTygert、M。（2011）。 「行列の分解のためのランダム化されたアルゴリズム」。応用および計算調和分析、30（1）、47-68。&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="e7341be727234aad9fa4e331ba9d61b6fce122ff" translate="yes" xml:space="preserve">
          <source>For the &amp;lsquo;liblinear&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">'liblinear'、 'sag'、および 'lbfgs'ソルバーは、冗長性のためにverboseを任意の正の数に設定します。</target>
        </trans-unit>
        <trans-unit id="e0f6f55d7894824895d15fbf0dd2debb3188c403" translate="yes" xml:space="preserve">
          <source>For the &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; family of algorithms with a non-linear kernel, the latency is tied to the number of support vectors (the fewer the faster). Latency and throughput should (asymptotically) grow linearly with the number of support vectors in a SVC or SVR model. The kernel will also influence the latency as it is used to compute the projection of the input vector once per support vector. In the following graph the &lt;code&gt;nu&lt;/code&gt; parameter of &lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt;&lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt;&lt;/a&gt; was used to influence the number of support vectors.</source>
          <target state="translated">非線形カーネルを使用する&lt;a href=&quot;classes#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt;アルゴリズムファミリーの場合、レイテンシーはサポートベクターの数に関係します（少ないほど高速です）。レイテンシーとスループットは、SVCまたはSVRモデルのサポートベクターの数に比例して（漸近的に）増加するはずです。カーネルは、サポートベクターごとに1回入力ベクトルの射影を計算するために使用されるため、レイテンシーにも影響を与えます。次のグラフでは、&lt;a href=&quot;generated/sklearn.svm.nusvr#sklearn.svm.NuSVR&quot;&gt; &lt;code&gt;sklearn.svm.NuSVR&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;nu&lt;/code&gt; パラメーターを使用して、サポートベクターの数に影響を与えています。</target>
        </trans-unit>
        <trans-unit id="a081b6c50a07cf5457333031806f4c48e54ea42e" translate="yes" xml:space="preserve">
          <source>For the &lt;a href=&quot;classes#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; family of algorithms with a non-linear kernel, the latency is tied to the number of support vectors (the fewer the faster). Latency and throughput should (asymptotically) grow linearly with the number of support vectors in a SVC or SVR model. The kernel will also influence the latency as it is used to compute the projection of the input vector once per support vector. In the following graph the &lt;code&gt;nu&lt;/code&gt; parameter of &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; was used to influence the number of support vectors.</source>
          <target state="translated">非線形カーネルを備えたアルゴリズムの&lt;a href=&quot;classes#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; &lt;/a&gt;ファミリーの場合、レイテンシはサポートベクターの数（少ないほど高速）に関連付けられます。レイテンシとスループットは、SVCまたはSVRモデルのサポートベクトルの数に応じて（漸近的に）直線的に増加するはずです。カーネルは、サポートベクトルごとに入力ベクトルの投影を計算するために使用されるため、レイテンシにも影響します。次のグラフでは、 &lt;code&gt;sklearn.svm.classes.NuSVR&lt;/code&gt; の &lt;code&gt;nu&lt;/code&gt; パラメーターを使用して、サポートベクターの数に影響を与えています。</target>
        </trans-unit>
        <trans-unit id="49dfac47eea992144c43ccc29f61713fabd0e5ae" translate="yes" xml:space="preserve">
          <source>For the &lt;code&gt;l2&lt;/code&gt; penalty case, the best result comes from the case where &lt;code&gt;C&lt;/code&gt; is not scaled.</source>
          <target state="translated">以下のために &lt;code&gt;l2&lt;/code&gt; ペナルティ場合、最良の結果がケースから来ている &lt;code&gt;C&lt;/code&gt; はスケーリングされません。</target>
        </trans-unit>
        <trans-unit id="b64515e541acdc2619277e9fede8598b267eca89" translate="yes" xml:space="preserve">
          <source>For the coefficient analysis, scaling is not needed this time.</source>
          <target state="translated">係数分析については、今回はスケーリングは不要です。</target>
        </trans-unit>
        <trans-unit id="73523e969cb224887344b79725c4bd74783daf1f" translate="yes" xml:space="preserve">
          <source>For the grid of &lt;code&gt;Cs&lt;/code&gt; values and &lt;code&gt;l1_ratios&lt;/code&gt; values, the best hyperparameter is selected by the cross-validator &lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt;, but it can be changed using the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; parameter. The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;lbfgs&amp;rsquo; solvers can warm-start the coefficients (see &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;Glossary&lt;/a&gt;).</source>
          <target state="translated">&lt;code&gt;Cs&lt;/code&gt; 値と &lt;code&gt;l1_ratios&lt;/code&gt; 値のグリッドの場合、最適なハイパーパラメーターはクロスバリデーター&lt;a href=&quot;sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;によって選択されますが、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt;パラメーターを使用して変更できます。'newton-cg'、 'sag'、 'saga'、および 'lbfgs'ソルバーは、係数をウォームスタートできます（&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="d9f81a56586341e43516abb99b238b1b5d6587c8" translate="yes" xml:space="preserve">
          <source>For the grid of Cs values (that are set by default to be ten values in a logarithmic scale between 1e-4 and 1e4), the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter. In the case of newton-cg and lbfgs solvers, we warm start along the path i.e guess the initial coefficients of the present fit to be the coefficients got after convergence in the previous fit, so it is supposed to be faster for high-dimensional dense data.</source>
          <target state="translated">Cs値のグリッド(デフォルトでは1e-4から1e-4の間の対数スケールで10の値に設定されています)では、クロスバリデータStratifiedKFoldによって最適なハイパーパラメータが選択されますが、cvパラメータを使用して変更することができます。newton-cgソルバーやlbfgsソルバーの場合は、パスに沿ってウォームスタートし、現在のフィットの初期係数を前回のフィットで収束した後の係数と推測します。</target>
        </trans-unit>
        <trans-unit id="a2e465567e94e51f5ccdac035f7ba7d95a9eeb84" translate="yes" xml:space="preserve">
          <source>For the lbfgs solver set verbose to any positive number for verbosity.</source>
          <target state="translated">lbfgsのソルバーでは、冗長性を表すためにverboseを正の数に設定します。</target>
        </trans-unit>
        <trans-unit id="93f0b6841feed67e5fc00af0443562656921cce7" translate="yes" xml:space="preserve">
          <source>For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.</source>
          <target state="translated">liblinearソルバーとlbfgsソルバーでは、冗長性のためにverboseを任意の正の数に設定します。</target>
        </trans-unit>
        <trans-unit id="181a8f355e9076e45b2bb33dd2324e0459310c3b" translate="yes" xml:space="preserve">
          <source>For the linear case, the algorithm used in &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; by the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt; implementation is much more efficient than its &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; counterpart and can scale almost linearly to millions of samples and/or features.</source>
          <target state="translated">線形の場合、&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/liblinear/&quot;&gt;liblinear&lt;/a&gt;実装によって&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; で&lt;/a&gt;使用されるアルゴリズムは、&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;ベースの&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; の&lt;/a&gt;対応するアルゴリズムよりもはるかに効率的であり、数百万のサンプルや機能にほぼ線形にスケーリングできます。</target>
        </trans-unit>
        <trans-unit id="4c4a7d0fb25ecd0231acfef000eb4ebb4024b077" translate="yes" xml:space="preserve">
          <source>For the most common use cases, you can designate a scorer object with the &lt;code&gt;scoring&lt;/code&gt; parameter; the table below shows all possible values. All scorer objects follow the convention that &lt;strong&gt;higher return values are better than lower return values&lt;/strong&gt;. Thus metrics which measure the distance between the model and the data, like &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;metrics.mean_squared_error&lt;/code&gt;&lt;/a&gt;, are available as neg_mean_squared_error which return the negated value of the metric.</source>
          <target state="translated">最も一般的な使用例では、 &lt;code&gt;scoring&lt;/code&gt; オブジェクトでスコアラーオブジェクトを指定できます。以下の表は、可能なすべての値を示しています。すべてのスコアラーオブジェクトは、&lt;strong&gt;高い戻り値が低い戻り値よりも優れ&lt;/strong&gt;ているという規則に従い&lt;strong&gt;ます&lt;/strong&gt;。したがって、&lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;metrics.mean_squared_error&lt;/code&gt; の&lt;/a&gt;ように、モデルとデータの間の距離を測定するメトリックは、メトリックの否定された値を返すneg_mean_squared_errorとして使用できます。</target>
        </trans-unit>
        <trans-unit id="d789fec5338f15a1f2a15098b90094ce0875aa16" translate="yes" xml:space="preserve">
          <source>For the naive Bayes, both the validation score and the training score converge to a value that is quite low with increasing size of the training set. Thus, we will probably not benefit much from more training data.</source>
          <target state="translated">ナイーブベイズでは、検証スコアと訓練スコアの両方が、訓練セットのサイズが大きくなるにつれてかなり低い値に収束します。したがって、訓練データが多くなっても、おそらくあまり恩恵を受けないでしょう。</target>
        </trans-unit>
        <trans-unit id="5c5d7d9872e083b1cf44dccc9ef51ebf6d1fc473" translate="yes" xml:space="preserve">
          <source>For the rationale behind the names &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt;, i.e. naive Bayes as a linear classifier, see J. Rennie et al. (2003), Tackling the poor assumptions of naive Bayes text classifiers, ICML.</source>
          <target state="translated">&lt;code&gt;coef_&lt;/code&gt; と &lt;code&gt;intercept_&lt;/code&gt; という名前の根拠、つまり線形分類器としての単純ベイズについては、J。Rennie et al。を参照してください。（2003）、ナイーブベイズテキスト分類器の不十分な仮定に取り組む、ICML。</target>
        </trans-unit>
        <trans-unit id="1a1a7cda3c63aae62fc5939e46e880b718f959b0" translate="yes" xml:space="preserve">
          <source>For the remainder of this example, we remove the last element in &lt;code&gt;clfs&lt;/code&gt; and &lt;code&gt;ccp_alphas&lt;/code&gt;, because it is the trivial tree with only one node. Here we show that the number of nodes and tree depth decreases as alpha increases.</source>
          <target state="translated">この例の残りの部分では、 &lt;code&gt;clfs&lt;/code&gt; と &lt;code&gt;ccp_alphas&lt;/code&gt; の最後の要素を削除します。これは、ノードが1つしかない自明なツリーだからです。ここでは、アルファが増加するにつれてノードの数とツリーの深さが減少することを示します。</target>
        </trans-unit>
        <trans-unit id="08233f540a36ed45603c5cb01e2e4f593cd79c27" translate="yes" xml:space="preserve">
          <source>For the simple task of finding the nearest neighbors between two sets of data, the unsupervised algorithms within &lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; can be used:</source>
          <target state="translated">2つのデータセット間の最近傍を見つける簡単なタスクでは、&lt;a href=&quot;classes#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; &lt;/a&gt;内の教師なしアルゴリズムを使用できます。</target>
        </trans-unit>
        <trans-unit id="a0a1bdaba8df32e218fd25f1e35b96e97a68bb33" translate="yes" xml:space="preserve">
          <source>For this data, we might want to encode the &lt;code&gt;'city'&lt;/code&gt; column as a categorical variable using &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; but apply a &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;'title'&lt;/code&gt; column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say &lt;code&gt;'city_category'&lt;/code&gt; and &lt;code&gt;'title_bow'&lt;/code&gt;. By default, the remaining rating columns are ignored (&lt;code&gt;remainder='drop'&lt;/code&gt;):</source>
          <target state="translated">このデータの場合、&lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt;を使用して &lt;code&gt;'city'&lt;/code&gt; 列をカテゴリ変数としてエンコードしますが、 &lt;code&gt;'title'&lt;/code&gt; 列に&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;を適用します。同じ列で複数の特徴抽出方法を使用する可能性があるため、各トランスフォーマーに &lt;code&gt;'city_category'&lt;/code&gt; や &lt;code&gt;'title_bow'&lt;/code&gt; などの一意の名前を付けます。デフォルトでは、残りの評価列は無視されます（ &lt;code&gt;remainder='drop'&lt;/code&gt; ）：</target>
        </trans-unit>
        <trans-unit id="daed0c58d42835f25cc91f4ef37c8c2918d442fd" translate="yes" xml:space="preserve">
          <source>For this data, we might want to encode the &lt;code&gt;'city'&lt;/code&gt; column as a categorical variable, but apply a &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt;&lt;/a&gt; to the &lt;code&gt;'title'&lt;/code&gt; column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say &lt;code&gt;'city_category'&lt;/code&gt; and &lt;code&gt;'title_bow'&lt;/code&gt;. By default, the remaining rating columns are ignored (&lt;code&gt;remainder='drop'&lt;/code&gt;):</source>
          <target state="translated">このデータの場合、 &lt;code&gt;'city'&lt;/code&gt; 列をカテゴリー変数としてエンコードし、&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;feature_extraction.text.CountVectorizer&lt;/code&gt; &lt;/a&gt;を &lt;code&gt;'title'&lt;/code&gt; 列に適用できます。同じ列で複数の特徴抽出メソッドを使用する可能性があるため、各トランスフォーマーに &lt;code&gt;'city_category'&lt;/code&gt; や &lt;code&gt;'title_bow'&lt;/code&gt; などの一意の名前を付けます。デフォルトでは、残りの評価列は無視されます（ &lt;code&gt;remainder='drop'&lt;/code&gt; ）：</target>
        </trans-unit>
        <trans-unit id="2e47bbc09921a29cf4a007e2d92242f5a8a9f3d8" translate="yes" xml:space="preserve">
          <source>For this example we will use the &lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;yeast&lt;/a&gt; dataset which contains 2417 datapoints each with 103 features and 14 possible labels. Each data point has at least one label. As a baseline we first train a logistic regression classifier for each of the 14 labels. To evaluate the performance of these classifiers we predict on a held-out test set and calculate the &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;jaccard similarity score&lt;/a&gt;.</source>
          <target state="translated">この例では、それぞれ1023個の特徴と14個の可能なラベルを持つ2417個のデータポイントを含む&lt;a href=&quot;http://mldata.org/repository/data/viewslug/yeast&quot;&gt;酵母&lt;/a&gt;データセットを使用します。各データポイントには少なくとも1つのラベルがあります。ベースラインとして、最初に14の各ラベルのロジスティック回帰分類器をトレーニングします。これらの分類子のパフォーマンスを評価するために、保留されたテストセットを予測し、&lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;ジャカード類似性スコア&lt;/a&gt;を計算します。</target>
        </trans-unit>
        <trans-unit id="ccd3bf49df3c855961b0d8c881b499df98dfa5eb" translate="yes" xml:space="preserve">
          <source>For this example we will use the &lt;a href=&quot;https://www.openml.org/d/40597&quot;&gt;yeast&lt;/a&gt; dataset which contains 2417 datapoints each with 103 features and 14 possible labels. Each data point has at least one label. As a baseline we first train a logistic regression classifier for each of the 14 labels. To evaluate the performance of these classifiers we predict on a held-out test set and calculate the &lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;jaccard score&lt;/a&gt; for each sample.</source>
          <target state="translated">この例では、それぞれ103個の特徴と14個の可能なラベルを持つ2417個のデータポイントを含む&lt;a href=&quot;https://www.openml.org/d/40597&quot;&gt;酵母&lt;/a&gt;データセットを使用します。各データポイントには、少なくとも1つのラベルがあります。ベースラインとして、最初に14個のラベルのそれぞれについてロジスティック回帰分類器をトレーニングします。これらの分類器のパフォーマンスを評価するために、&lt;a href=&quot;../../modules/model_evaluation#jaccard-similarity-score&quot;&gt;差し出さ&lt;/a&gt;れたテストセットで予測し、各サンプルのジャッカードスコアを計算します。</target>
        </trans-unit>
        <trans-unit id="50c8fe3ea12a1b37824eecf96be6564acb86b697" translate="yes" xml:space="preserve">
          <source>For this example, the impurity-based and permutation methods identify the same 2 strongly predictive features but not in the same order. The third most predictive feature, &amp;ldquo;bp&amp;rdquo;, is also the same for the 2 methods. The remaining features are less predictive and the error bars of the permutation plot show that they overlap with 0.</source>
          <target state="translated">この例では、不純物ベースの方法と順列法は、同じ2つの強力な予測機能を識別しますが、同じ順序ではありません。3番目に予測的な機能である「bp」も2つの方法で同じです。残りの特徴は予測性が低く、順列プロットのエラーバーはそれらが0と重なっていることを示しています。</target>
        </trans-unit>
        <trans-unit id="a29265ef3f92733677c4dbea10c38e7e64e8fed9" translate="yes" xml:space="preserve">
          <source>For this example, we load a blood transfusion service center data set from &lt;code&gt;OpenML &amp;lt;https://www.openml.org/d/1464&amp;gt;&lt;/code&gt;. This is a binary classification problem where the target is whether an individual donated blood. Then the data is split into a train and test dataset and a logistic regression is fitted wtih the train dataset.</source>
          <target state="translated">この例では、 &lt;code&gt;OpenML &amp;lt;https://www.openml.org/d/1464&amp;gt;&lt;/code&gt; から輸血サービスセンターのデータセットを読み込みます。これは、個人が献血したかどうかをターゲットとするバイナリ分類問題です。次に、データは列車とテストのデータセットに分割され、ロジスティック回帰が列車のデータセットに適合されます。</target>
        </trans-unit>
        <trans-unit id="6ab77ac3ad8536d0d4bc113a409f055607cd6e01" translate="yes" xml:space="preserve">
          <source>For this method, M may be a dense matrix, sparse matrix, or general linear operator. Warning: ARPACK can be unstable for some problems. It is best to try several random seeds in order to check results.</source>
          <target state="translated">この方法では、M は密行列、疎行列、一般線形演算子のいずれかである。警告.ARPACKは、問題によっては不安定な場合があります。結果を確認するために、いくつかのランダムな種を試してみるのがよいでしょう。</target>
        </trans-unit>
        <trans-unit id="08c8de94919880222510697f43131d88196a6fc1" translate="yes" xml:space="preserve">
          <source>For this particular pattern of missing values we see that &lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.linear_model.bayesianridge#sklearn.linear_model.BayesianRidge&quot;&gt;&lt;code&gt;sklearn.linear_model.BayesianRidge&lt;/code&gt;&lt;/a&gt; give the best results.</source>
          <target state="translated">欠落値のこの特定のパターンでは、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;sklearn.ensemble.ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;../../modules/generated/sklearn.linear_model.bayesianridge#sklearn.linear_model.BayesianRidge&quot;&gt; &lt;code&gt;sklearn.linear_model.BayesianRidge&lt;/code&gt; &lt;/a&gt;が最良の結果をもたらすことがわかります。</target>
        </trans-unit>
        <trans-unit id="201d282b655d8d026b78eb9f9255553e50678277" translate="yes" xml:space="preserve">
          <source>For this purpose, the estimators use a &amp;lsquo;connectivity&amp;rsquo; matrix, giving which samples are connected.</source>
          <target state="translated">この目的のために、推定器は「接続性」行列を使用して、接続されているサンプルを示します。</target>
        </trans-unit>
        <trans-unit id="764ea2ccb7951b3db73f825ee916559c0e4bce1d" translate="yes" xml:space="preserve">
          <source>For this reason, the functions that load 20 Newsgroups data provide a parameter called &lt;strong&gt;remove&lt;/strong&gt;, telling it what kinds of information to strip out of each file. &lt;strong&gt;remove&lt;/strong&gt; should be a tuple containing any subset of &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt;, telling it to remove headers, signature blocks, and quotation blocks respectively.</source>
          <target state="translated">このため、20個のニュースグループデータをロードする関数は、&lt;strong&gt;remove&lt;/strong&gt;というパラメーターを提供し、各ファイルから削除する情報の種類を伝えます。&lt;strong&gt;remove&lt;/strong&gt;は、 &lt;code&gt;('headers', 'footers', 'quotes')&lt;/code&gt; サブセットを含むタプルで、ヘッダー、署名ブロック、引用ブロックをそれぞれ削除するように指示する必要があります。</target>
        </trans-unit>
        <trans-unit id="60d82b78a5294ae2dc0ada0318b904b11e85c403" translate="yes" xml:space="preserve">
          <source>For two clusters, SpectralClustering solves a convex relaxation of the &lt;a href=&quot;https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;normalised cuts&lt;/a&gt; problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images, where graph vertices are pixels, and weights of the edges of the similarity graph are computed using a function of a gradient of the image.</source>
          <target state="translated">2つのクラスターの場合、SpectralClusteringは、類似性グラフの&lt;a href=&quot;https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;正規化されたカット&lt;/a&gt;問題の凸緩和を解決します。つまり、各クラスター内のエッジの重みと比較して、カットされるエッジの重みが小さくなるようにグラフを2つにカットします。この基準は、グラフの頂点がピクセルであり、類似性グラフのエッジの重みが画像の勾配の関数を使用して計算される画像で作業する場合に特に興味深いものです。</target>
        </trans-unit>
        <trans-unit id="f2d2e6058597b408c702846b2d537e901630ce3a" translate="yes" xml:space="preserve">
          <source>For two clusters, it solves a convex relaxation of the &lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;normalised cuts&lt;/a&gt; problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images: graph vertices are pixels, and edges of the similarity graph are a function of the gradient of the image.</source>
          <target state="translated">2つのクラスターの場合、類似性グラフの&lt;a href=&quot;http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf&quot;&gt;正規化されたカット&lt;/a&gt;問題の凸緩和を解決します。グラフを2つにカットして、カットされたエッジの重みが各クラスター内のエッジの重みに比べて小さくなるようにします。この基準は、画像で作業する場合に特に興味深いものです。グラフの頂点はピクセルであり、類似度グラフのエッジは画像の勾配の関数です。</target>
        </trans-unit>
        <trans-unit id="4092abbbb6ead577ab2b40e6704455f3cb4d3df5" translate="yes" xml:space="preserve">
          <source>For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt; entry on imputation.</source>
          <target state="translated">さまざまな理由により、多くの現実世界のデータセットには欠損値が含まれており、多くの場合、空白、NaN、またはその他のプレースホルダーとしてエンコードされています。ただし、そのようなデータセットは、配列内のすべての値が数値であり、すべてが意味を持ち保持していると想定するscikit-learn推定器と互換性がありません。不完全なデータセットを使用する基本的な戦略は、欠損値を含む行や列全体を破棄することです。ただし、これはデータが失われるという代償を伴います（データは不完全ですが）。より良い戦略は、欠損値を補完すること、つまり、データの既知の部分からそれらを推測することです。帰属&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#glossary&quot;&gt;の一般用語とAPI要素&lt;/a&gt;の用語解説を参照してください。</target>
        </trans-unit>
        <trans-unit id="e2303c3ef75d0f928a4dd5ec4517d95f82d7d02b" translate="yes" xml:space="preserve">
          <source>For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;Glossary of Common Terms and API Elements&lt;/a&gt; entry on imputation.</source>
          <target state="translated">さまざまな理由から、多くの実際のデータセットには欠落値が含まれており、多くの場合、空白、NaN、またはその他のプレースホルダーとしてエンコードされます。ただし、このようなデータセットは、配列内のすべての値が数値であり、すべてが意味を持ち、保持していると想定するscikit-learn推定量とは互換性がありません。不完全なデータセットを使用する基本的な戦略は、欠落した値を含む行や列全体を破棄することです。ただし、これには、（不完全であっても）価値のあるデータが失われるという代償が伴います。より良い戦略は、欠落している値を代入することです。つまり、データの既知の部分からそれらを推測することです。代入については&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#glossary&quot;&gt;、一般用語集とAPI要素の&lt;/a&gt;エントリを参照してください。</target>
        </trans-unit>
        <trans-unit id="7f12e7919ffa1c3009c9eefff46504b7c0642e13" translate="yes" xml:space="preserve">
          <source>For visualization purpose (which is the main use case of t-SNE), using the Barnes-Hut method is strongly recommended. The exact t-SNE method is useful for checking the theoretically properties of the embedding possibly in higher dimensional space but limit to small datasets due to computational constraints.</source>
          <target state="translated">t-SNEの主な用途である可視化のためには、Barnes-Hut法を用いることを強く推奨します。厳密t-SNE法は、高次元空間での埋め込みの理論的性質を確認するのに便利ですが、計算上の制約から小さなデータセットに限られています。</target>
        </trans-unit>
        <trans-unit id="e7a5b4b1244321faa67509dff73df9a23d7da1b3" translate="yes" xml:space="preserve">
          <source>For visualization purposes, given a bicluster, the rows and columns of the data matrix may be rearranged to make the bicluster contiguous.</source>
          <target state="translated">可視化の目的のために、2 つのクラスターが与えられた場合、データマトリクスの行と列を並べ替えて、2 つのクラスターが連続するようにすることができます。</target>
        </trans-unit>
        <trans-unit id="d62d3122e2e4eef979e7c46fd629936aec0233be" translate="yes" xml:space="preserve">
          <source>For visualization purposes, we need to lay out the different symbols on a 2D canvas. For this we use &lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;Manifold learning&lt;/a&gt; techniques to retrieve 2D embedding.</source>
          <target state="translated">視覚化のために、2Dキャンバス上にさまざまなシンボルを配置する必要があります。このために、2D埋め込みを取得するために&lt;a href=&quot;../../modules/manifold#manifold&quot;&gt;多様体学習&lt;/a&gt;手法を使用します。</target>
        </trans-unit>
        <trans-unit id="c502fd7960fae5affa9295a7a329adeddad6ab37" translate="yes" xml:space="preserve">
          <source>Force row-by-row generation by reducing &lt;code&gt;working_memory&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;working_memory&lt;/code&gt; を減らして、行ごとに強制的に生成します。</target>
        </trans-unit>
        <trans-unit id="4bb98e5d778957b0dd66fa6aed87be22d170768c" translate="yes" xml:space="preserve">
          <source>Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.</source>
          <target state="translated">Forina,M.et al,PARVUS-An Extendible Package for Data Exploration,Classification and Correlation.Institute of Pharmaceutical and Food Analysis and Technologies,Via Brigata Salerno,16147 Genoa,Italy.</target>
        </trans-unit>
        <trans-unit id="35705e005c1f18ed14dab92df9e1435742858283" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the average precision is defined as</source>
          <target state="translated">Formally,given a binary indicator matrix of the ground truth labels ♦(y \in ﾞleft ﾞleft\\{0,1\right}^{n_\text{samples}ﾞ\times n_\text{labels}})and the score associated with each label ♦(\hat{f}ﾞ\in ﾞmathbb{R}^{n_\text{samples}ﾞ\times n_\text{labels}})の2値指標行列が与えられると、平均精度は次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="4f395914b8fb9e643646835cc07cbc38c9742edc" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the coverage is defined as</source>
          <target state="translated">Formally,given a binary indicator matrix of the ground truth labels \(y \in ﾞleft ﾞleft\\{0,1\right}^{n_\text{samples}ﾞ\times n_\text{labels}})and the score associated with each label ﾞ\(\hat{f}ﾞ\in ﾞmathbb{R}^{n_\text{samples}ﾞ\times n_\text{labels}}),the coverage defined with the coverage as</target>
        </trans-unit>
        <trans-unit id="c175d46f254d733413b5b0ee831c9d600136a7b6" translate="yes" xml:space="preserve">
          <source>Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the ranking loss is defined as</source>
          <target state="translated">Formally,given a binary indicator matrix of the ground truth labels \(y \in ﾞleft ﾞleft\\{0,1\right}^{n_\text{samples}ﾞ\times n_\text{labels}})and the score associated with each label ﾞ\(\hat{f}ﾞ\in ﾞmathbb{R}^{n_\text{samples}ﾞ\times n_\text{labels}}),ranking loss is defined as as</target>
        </trans-unit>
        <trans-unit id="c45b835372dc3641934de6a0e36f8d5df72bc091" translate="yes" xml:space="preserve">
          <source>Format specification for values in confusion matrix. If &lt;code&gt;None&lt;/code&gt;, the format specification is &amp;lsquo;d&amp;rsquo; or &amp;lsquo;.2g&amp;rsquo; whichever is shorter.</source>
          <target state="translated">混同行列の値の形式仕様。場合 &lt;code&gt;None&lt;/code&gt; 、形式仕様は「D」またはいずれか短い「0.2グラム」です。</target>
        </trans-unit>
        <trans-unit id="47fb5045fef615598469a37da8a59110352753ff" translate="yes" xml:space="preserve">
          <source>Forms an affinity matrix given by the specified function and applies spectral decomposition to the corresponding graph laplacian. The resulting transformation is given by the value of the eigenvectors for each data point.</source>
          <target state="translated">指定された関数で与えられた親和行列を形成し、対応するグラフラプラシアンにスペクトル分解を適用します。結果として得られる変換は,各データポイントの固有ベクトルの値によって与えられます.</target>
        </trans-unit>
        <trans-unit id="638babaaa209a18fe959f40f19725a01af068351" translate="yes" xml:space="preserve">
          <source>Fortunately, &lt;strong&gt;most values in X will be zeros&lt;/strong&gt; since for a given document less than a few thousand distinct words will be used. For this reason we say that bags of words are typically &lt;strong&gt;high-dimensional sparse datasets&lt;/strong&gt;. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory.</source>
          <target state="translated">幸い、&lt;strong&gt;Xのほとんどの値はゼロになります。&lt;/strong&gt;これは、特定のドキュメントでは数千未満の異なる単語が使用されるためです。このため、通常、単語のバッグは&lt;strong&gt;高次元のスパースデータセットである&lt;/strong&gt;と言います。特徴ベクトルのゼロ以外の部分のみをメモリに格納することで、多くのメモリを節約できます。</target>
        </trans-unit>
        <trans-unit id="e399cc71dd11205217c77d4c7f1a914e719b462c" translate="yes" xml:space="preserve">
          <source>Frequency model &amp;ndash; Poisson distribution</source>
          <target state="translated">頻度モデル&amp;ndash;ポアソン分布</target>
        </trans-unit>
        <trans-unit id="659b18cdaec75234c8e955e09af5dc004ab6498a" translate="yes" xml:space="preserve">
          <source>Frequently asked questions about the project and contributing.</source>
          <target state="translated">プロジェクトや貢献に関するよくある質問</target>
        </trans-unit>
        <trans-unit id="c378e5372fbcc6968de3f23916b1cc385b9617be" translate="yes" xml:space="preserve">
          <source>Friedman et al, &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Sparse inverse covariance estimation with the graphical lasso&amp;rdquo;&lt;/a&gt;, Biostatistics 9, pp 432, 2008</source>
          <target state="translated">フリードマン他、&lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;「グラフィカルな投げ縄によるスパース逆共分散推定」&lt;/a&gt;、Biostatistics 9、pp 432、2008</target>
        </trans-unit>
        <trans-unit id="563c92aa7d72e63e351914d407eb4e8a1bed4188" translate="yes" xml:space="preserve">
          <source>Friedman et al, &lt;a href=&quot;https://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;&amp;ldquo;Sparse inverse covariance estimation with the graphical lasso&amp;rdquo;&lt;/a&gt;, Biostatistics 9, pp 432, 2008</source>
          <target state="translated">フリードマン他、&lt;a href=&quot;https://biostatistics.oxfordjournals.org/content/9/3/432.short&quot;&gt;「グラフィカルラッソを使用したスパース逆共分散推定」&lt;/a&gt;、Biostatistics 9、pp 432、2008</target>
        </trans-unit>
        <trans-unit id="8438e27109208985a133518d65493568dedc6924" translate="yes" xml:space="preserve">
          <source>Friedman, &amp;ldquo;Stochastic Gradient Boosting&amp;rdquo;, 1999</source>
          <target state="translated">フリードマン、「確率的勾配ブースティング」、1999</target>
        </trans-unit>
        <trans-unit id="9fcad16d5a3614a8ac9a3dd3615a46004936d92d" translate="yes" xml:space="preserve">
          <source>Friedman, Stochastic Gradient Boosting, 1999</source>
          <target state="translated">フリードマン、確率的勾配ブースティング、1999年</target>
        </trans-unit>
        <trans-unit id="910211d4464f03643fe19d7b724011f366eafec5" translate="yes" xml:space="preserve">
          <source>Friedmann, Jerome H., 2007, &lt;a href=&quot;https://statweb.stanford.edu/~jhf/ftp/stobst.pdf&quot;&gt;&amp;ldquo;Stochastic Gradient Boosting&amp;rdquo;&lt;/a&gt;</source>
          <target state="translated">フリードマン、ジェロームH.、2007年、&lt;a href=&quot;https://statweb.stanford.edu/~jhf/ftp/stobst.pdf&quot;&gt;「確率的勾配ブースティング」&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d93c5ad51427861e9927c0f93ba75f21fa7b3769" translate="yes" xml:space="preserve">
          <source>Frobenius norm of the matrix difference, or beta-divergence, between the training data &lt;code&gt;X&lt;/code&gt; and the reconstructed data &lt;code&gt;WH&lt;/code&gt; from the fitted model.</source>
          <target state="translated">トレーニングデータ &lt;code&gt;X&lt;/code&gt; と近似モデルから再構築されたデータ &lt;code&gt;WH&lt;/code&gt; との間のマトリックス差、つまりベータダイバージェンスのフロベニウスノルム。</target>
        </trans-unit>
        <trans-unit id="c51f06e97e3098b2be5170a19f440afe2d031cf5" translate="yes" xml:space="preserve">
          <source>From features with fewest missing values to most.</source>
          <target state="translated">欠損値が最も少ない特徴から最も多い特徴へ。</target>
        </trans-unit>
        <trans-unit id="42591b8a9cd574128a8414edcfb65dcf2e26248d" translate="yes" xml:space="preserve">
          <source>From features with most missing values to fewest.</source>
          <target state="translated">欠損値が最も多い特徴量から最も少ない特徴量まで。</target>
        </trans-unit>
        <trans-unit id="2a2bd03e6f160e636919837a5a755bde731a1eeb" translate="yes" xml:space="preserve">
          <source>From images</source>
          <target state="translated">画像から</target>
        </trans-unit>
        <trans-unit id="5ff0ffd1e24dbd90ba4e307313dc3fed8b0cd6c4" translate="yes" xml:space="preserve">
          <source>From occurrences to frequencies</source>
          <target state="translated">発生から頻度まで</target>
        </trans-unit>
        <trans-unit id="4a6ea847ae49dd26abc66504268644d690f3206b" translate="yes" xml:space="preserve">
          <source>From scikit-learn: [&amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;, &amp;lsquo;euclidean&amp;rsquo;, &amp;lsquo;l1&amp;rsquo;, &amp;lsquo;l2&amp;rsquo;, &amp;lsquo;manhattan&amp;rsquo;]. These metrics support sparse matrix inputs.</source>
          <target state="translated">scikit-learnから：['cityblock'、 'cosine'、 'euclidean'、 'l1'、 'l2'、 'manhattan']。これらのメトリックは、スパースマトリックス入力をサポートします。</target>
        </trans-unit>
        <trans-unit id="e036581a0079e3a00bbe6bddf83817f4c4f30e31" translate="yes" xml:space="preserve">
          <source>From scikit-learn: [&amp;lsquo;cityblock&amp;rsquo;, &amp;lsquo;cosine&amp;rsquo;, &amp;lsquo;euclidean&amp;rsquo;, &amp;lsquo;l1&amp;rsquo;, &amp;lsquo;l2&amp;rsquo;, &amp;lsquo;manhattan&amp;rsquo;]. These metrics support sparse matrix inputs. [&amp;lsquo;nan_euclidean&amp;rsquo;] but it does not yet support sparse matrices.</source>
          <target state="translated">scikit-learnから：['cityblock'、 'cosine'、 'euclidean'、 'l1'、 'l2'、 'manhattan']。これらのメトリックは、スパース行列入力をサポートします。['nan_euclidean']ですが、スパース行列はまだサポートされていません。</target>
        </trans-unit>
        <trans-unit id="6d8d962b98fbbe50de709ee2f1e71db53d579c2e" translate="yes" xml:space="preserve">
          <source>From scipy.spatial.distance: [&amp;lsquo;braycurtis&amp;rsquo;, &amp;lsquo;canberra&amp;rsquo;, &amp;lsquo;chebyshev&amp;rsquo;, &amp;lsquo;correlation&amp;rsquo;, &amp;lsquo;dice&amp;rsquo;, &amp;lsquo;hamming&amp;rsquo;, &amp;lsquo;jaccard&amp;rsquo;, &amp;lsquo;kulsinski&amp;rsquo;, &amp;lsquo;mahalanobis&amp;rsquo;, &amp;lsquo;minkowski&amp;rsquo;, &amp;lsquo;rogerstanimoto&amp;rsquo;, &amp;lsquo;russellrao&amp;rsquo;, &amp;lsquo;seuclidean&amp;rsquo;, &amp;lsquo;sokalmichener&amp;rsquo;, &amp;lsquo;sokalsneath&amp;rsquo;, &amp;lsquo;sqeuclidean&amp;rsquo;, &amp;lsquo;yule&amp;rsquo;] See the documentation for scipy.spatial.distance for details on these metrics. These metrics do not support sparse matrix inputs.</source>
          <target state="translated">scipy.spatial.distanceから：['braycurtis'、 'canberra'、 'chebyshev'、 'correlation'、 'dice'、 'hamming'、 'jaccard'、 'kulsinski'、 'mahalanobis'、 'minkowski'、 'rogerstanimoto '、' russellrao '、' seuclidean '、' sokalmichener '、' sokalsneath '、' sqeuclidean '、' yule ']これらのメトリックの詳細については、scipy.spatial.distanceのドキュメントをご覧ください。これらのメトリックは、スパース行列入力をサポートしていません。</target>
        </trans-unit>
        <trans-unit id="d3990f36d057d6745fedc272447b2563e02193f7" translate="yes" xml:space="preserve">
          <source>From text</source>
          <target state="translated">本文より</target>
        </trans-unit>
        <trans-unit id="b8b69c633940e44df1e4f7cf5b91c3ed0ce89b65" translate="yes" xml:space="preserve">
          <source>From the Wikipedia page for Discounted Cumulative Gain:</source>
          <target state="translated">ウィキペディアの「Discounted Cumulative Gain」のページより。</target>
        </trans-unit>
        <trans-unit id="eea6e746f349894e725f780b7f19777ab0b59905" translate="yes" xml:space="preserve">
          <source>From the above formula, it is clear that LDA has a linear decision surface. In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id5&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt; for more details.</source>
          <target state="translated">上記の式から、LDAが線形決定面を持っていることは明らかです。QDAの場合、ガウス分布の共分散行列\（\ Sigma_k \）に仮定がないため、2次決定面になります。詳細については、&lt;a href=&quot;#id5&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="13bce2493b501286a428cebcb4e0bc57e6083c63" translate="yes" xml:space="preserve">
          <source>From the implementation point of view, this is just plain Ordinary Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.</source>
          <target state="translated">実装の観点から見ると、これは単なるOrdinary Least Squares (scipy.linalg.lstsq)を予測オブジェクトとしてラップしただけのものです。</target>
        </trans-unit>
        <trans-unit id="704f1c6d00ec317ee90c0b6672883e3dd205ae68" translate="yes" xml:space="preserve">
          <source>From the programming standpoint, it is interesting because it shows how to use the online API of the scikit-learn to process a very large dataset by chunks. The way we proceed is that we load an image at a time and extract randomly 50 patches from this image. Once we have accumulated 500 of these patches (using 10 images), we run the &lt;a href=&quot;../../modules/generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans.partial_fit&quot;&gt;&lt;code&gt;partial_fit&lt;/code&gt;&lt;/a&gt; method of the online KMeans object, MiniBatchKMeans.</source>
          <target state="translated">プログラミングの観点からは、scikit-learnのオンラインAPIを使用して非常に大きなデータセットをチャンクで処理する方法を示しているので興味深いです。続行する方法は、一度に画像をロードし、この画像からランダムに50個のパッチを抽出することです。これらのパッチを500個（10個の画像を使用して）蓄積したら、オンラインKMeansオブジェクトMiniBatchKMeansの&lt;a href=&quot;../../modules/generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans.partial_fit&quot;&gt; &lt;code&gt;partial_fit&lt;/code&gt; &lt;/a&gt;メソッドを実行します。</target>
        </trans-unit>
        <trans-unit id="ae8e3bdf9c1967ed71af43f356a6c2d5d1712708" translate="yes" xml:space="preserve">
          <source>From the programming standpoint, it is interesting because it shows how to use the online API of the scikit-learn to process a very large dataset by chunks. The way we proceed is that we load an image at a time and extract randomly 50 patches from this image. Once we have accumulated 500 of these patches (using 10 images), we run the &lt;code&gt;partial_fit&lt;/code&gt; method of the online KMeans object, MiniBatchKMeans.</source>
          <target state="translated">プログラミングの観点からは、scikit-learnのオンラインAPIを使用して非常に大きなデータセットをチャンクで処理する方法を示しているので興味深いです。次に進む方法は、一度にイメージをロードし、このイメージからランダムに50個のパッチを抽出することです。これらのパッチを500個（10個の画像を使用して）累積したら、オンラインKMeansオブジェクトであるMiniBatchKMeansの &lt;code&gt;partial_fit&lt;/code&gt; メソッドを実行します。</target>
        </trans-unit>
        <trans-unit id="f1e410ad1472b42cb42cc98962428637290b6706" translate="yes" xml:space="preserve">
          <source>Function</source>
          <target state="translated">Function</target>
        </trans-unit>
        <trans-unit id="9f410a9e5384dfe1720c4cd228fe7bb63965656b" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">2つの配列Xおよびyを取り、配列のペア（スコア、p値）またはスコアのある単一の配列を返す関数。デフォルトはf_classifです（以下の「関連項目」も参照）。デフォルトの機能は分類タスクでのみ機能します。</target>
        </trans-unit>
        <trans-unit id="a8696032e0adf35ffec7c9da28cd036adeb91c99" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below &amp;ldquo;See also&amp;rdquo;). The default function only works with classification tasks.</source>
          <target state="translated">2つの配列Xとyを取り、配列のペア（スコア、p値）を返す関数。デフォルトはf_classifです（以下の「関連項目」も参照）。デフォルトの機能は分類タスクでのみ機能します。</target>
        </trans-unit>
        <trans-unit id="acf1f055cd0885a9fc7d245efda7d1c727fca691" translate="yes" xml:space="preserve">
          <source>Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). For modes &amp;lsquo;percentile&amp;rsquo; or &amp;lsquo;kbest&amp;rsquo; it can return a single array scores.</source>
          <target state="translated">2つの配列Xとyを取り、配列のペア（スコア、p値）を返す関数。'percentile'または 'kbest'モードの場合、単一の配列スコアを返すことができます。</target>
        </trans-unit>
        <trans-unit id="0c64f21c81859fb42c302c0d2cd301e40332c2c7" translate="yes" xml:space="preserve">
          <source>Function to apply to &lt;code&gt;y&lt;/code&gt; before passing to &lt;code&gt;fit&lt;/code&gt;. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt;. The function needs to return a 2-dimensional array. If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;, the function used will be the identity function.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; に渡す前に &lt;code&gt;y&lt;/code&gt; に適用する関数。 &lt;code&gt;transformer&lt;/code&gt; と同時に設定できません。関数は2次元配列を返す必要があります。場合 &lt;code&gt;func&lt;/code&gt; はありません &lt;code&gt;None&lt;/code&gt; 、使用する関数は恒等関数になります。</target>
        </trans-unit>
        <trans-unit id="f712e33ad68950dd5132b77ad3129994bf2cbbce" translate="yes" xml:space="preserve">
          <source>Function to apply to the prediction of the regressor. Cannot be set at the same time as &lt;code&gt;transformer&lt;/code&gt; as well. The function needs to return a 2-dimensional array. The inverse function is used to return predictions to the same space of the original training labels.</source>
          <target state="translated">リグレッサの予測に適用する関数。 &lt;code&gt;transformer&lt;/code&gt; と同時に設定することはできません。関数は2次元配列を返す必要があります。逆関数は、元のトレーニングラベルと同じ空間に予測を返すために使用されます。</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="c216053588b385d3de175b467017426b8b421912" translate="yes" xml:space="preserve">
          <source>Further discussion on the importance of centering and scaling data is available on this FAQ: &lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;Should I normalize/standardize/rescale the data?&lt;/a&gt;</source>
          <target state="translated">データのセンタリングとスケーリングの重要性に関するさらなる議論は、このFAQで利用できます。データ&lt;a href=&quot;http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html&quot;&gt;を正規化/標準化/再スケーリングする必要がありますか？&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="606b0f774f1d5e4151969dbb768df62ebca8a20e" translate="yes" xml:space="preserve">
          <source>Further removes the linear correlation across features with &amp;lsquo;whiten=True&amp;rsquo;.</source>
          <target state="translated">さらに、「whiten = True」の機能間の線形相関を削除します。</target>
        </trans-unit>
        <trans-unit id="ec9ba56eabfa3f70786eb84612f0623df80dfc4d" translate="yes" xml:space="preserve">
          <source>Further, the model supports &lt;a href=&quot;multiclass#multiclass&quot;&gt;multi-label classification&lt;/a&gt; in which a sample can belong to more than one class. For each class, the raw output passes through the logistic function. Values larger or equal to &lt;code&gt;0.5&lt;/code&gt; are rounded to &lt;code&gt;1&lt;/code&gt;, otherwise to &lt;code&gt;0&lt;/code&gt;. For a predicted output of a sample, the indices where the value is &lt;code&gt;1&lt;/code&gt; represents the assigned classes of that sample:</source>
          <target state="translated">さらに、モデルは、サンプルが複数のクラスに属することができる&lt;a href=&quot;multiclass#multiclass&quot;&gt;マルチラベル分類を&lt;/a&gt;サポートします。クラスごとに、生の出力はロジスティック関数を通過します。 &lt;code&gt;0.5&lt;/code&gt; 以上の値は &lt;code&gt;1&lt;/code&gt; に丸められ、それ以外の場合は &lt;code&gt;0&lt;/code&gt; に丸められます。サンプルの予測出力の場合、値が &lt;code&gt;1&lt;/code&gt; のインデックスは、そのサンプルの割り当てられたクラスを表します。</target>
        </trans-unit>
        <trans-unit id="cc118108875cca01a2724ce6e20debf4e124a846" translate="yes" xml:space="preserve">
          <source>Furthermore, &lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt;&lt;code&gt;adjusted_rand_score&lt;/code&gt;&lt;/a&gt; is &lt;strong&gt;symmetric&lt;/strong&gt;: swapping the argument does not change the score. It can thus be used as a &lt;strong&gt;consensus measure&lt;/strong&gt;:</source>
          <target state="translated">さらに、&lt;a href=&quot;generated/sklearn.metrics.adjusted_rand_score#sklearn.metrics.adjusted_rand_score&quot;&gt; &lt;code&gt;adjusted_rand_score&lt;/code&gt; &lt;/a&gt;は&lt;strong&gt;対称的&lt;/strong&gt;です。引数を入れ替えてもスコアは変わりません。したがって、&lt;strong&gt;コンセンサス指標&lt;/strong&gt;として使用できます。</target>
        </trans-unit>
        <trans-unit id="f148ccef557451e9c13ec83bfface59d01588547" translate="yes" xml:space="preserve">
          <source>Furthermore, impurity-based feature importance for trees are &lt;strong&gt;strongly biased&lt;/strong&gt; and &lt;strong&gt;favor high cardinality features&lt;/strong&gt; (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories.</source>
          <target state="translated">さらに、ツリーの不純物ベースの特徴の重要性は&lt;strong&gt;強く偏って&lt;/strong&gt;おり、バイナリ特徴や可能なカテゴリの数が少ないカテゴリ変数などの低カーディナリティ特徴よりも&lt;strong&gt;高カーディナリティ特徴&lt;/strong&gt;（通常は数値特徴）を&lt;strong&gt;優先し&lt;/strong&gt;ます。</target>
        </trans-unit>
        <trans-unit id="7218de362b7befd5a71b1a5a01365e3552aa1087" translate="yes" xml:space="preserve">
          <source>Furthermore, it also shows the evolution of the performance of different algorithms with the number of processed examples.</source>
          <target state="translated">さらに、処理された例の数に応じて、異なるアルゴリズムの性能が変化することも示しています。</target>
        </trans-unit>
        <trans-unit id="17753e7322d4f150d032ddf1f2dbdf4fe6d38592" translate="yes" xml:space="preserve">
          <source>Furthermore, the default parameter &lt;code&gt;smooth_idf=True&lt;/code&gt; adds &amp;ldquo;1&amp;rdquo; to the numerator and denominator as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions:</source>
          <target state="translated">さらに、デフォルトのパラメーター &lt;code&gt;smooth_idf=True&lt;/code&gt; は、コレクション内のすべての用語を1回だけ含む追加のドキュメントが見られたかのように分子と分母に「1」を追加し、ゼロ除算を防止します。</target>
        </trans-unit>
        <trans-unit id="2e93583dd7fd8dcf1f0371a9818f0db1fd3c80a7" translate="yes" xml:space="preserve">
          <source>Furthermore, the formulas used to compute tf and idf depend on parameter settings that correspond to the SMART notation used in IR as follows:</source>
          <target state="translated">さらに、tf、idfの計算式は、以下のようにIRで使用されるSMART記法に対応するパラメータの設定に依存する。</target>
        </trans-unit>
        <trans-unit id="f576c03970023ff0ede275b819158dc78e4bd414" translate="yes" xml:space="preserve">
          <source>Furthermore, the impurity-based feature importance of random forests suffers from being computed on statistics derived from the training dataset: the importances can be high even for features that are not predictive of the target variable, as long as the model has the capacity to use them to overfit.</source>
          <target state="translated">さらに、ランダムフォレストの不純物に基づく特徴の重要度は、学習データセットから得られた統計量に基づいて計算されるため、問題があります:モデルがオーバーフィットするためにそれらを使用する能力を持っている限り、目標変数を予測しない特徴でも重要度は高くなります。</target>
        </trans-unit>
        <trans-unit id="a28e3ed3e4426c3b74ba7f5c5c797d3018edc64c" translate="yes" xml:space="preserve">
          <source>Furthermore, when splitting each node during the construction of a tree, the best split is found either from all input features or a random subset of size &lt;code&gt;max_features&lt;/code&gt;. (See the &lt;a href=&quot;#random-forest-parameters&quot;&gt;parameter tuning guidelines&lt;/a&gt; for more details).</source>
          <target state="translated">さらに、ツリーの構築中に各ノードを分割する場合、すべての入力フィーチャまたはサイズ &lt;code&gt;max_features&lt;/code&gt; のランダムなサブセットから最適な分割が見つかります。（詳細については、&lt;a href=&quot;#random-forest-parameters&quot;&gt;パラメーター調整ガイドライン&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="2b6ca190d547b1e777d8fa3e93274ce6ad7c42b4" translate="yes" xml:space="preserve">
          <source>G. Brier, &lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;Verification of forecasts expressed in terms of probability&lt;/a&gt;, Monthly weather review 78.1 (1950)</source>
          <target state="translated">G.ブライアー、&lt;a href=&quot;ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf&quot;&gt;確率&lt;/a&gt;で表された予測の検証、月間天気調査78.1（1950）</target>
        </trans-unit>
        <trans-unit id="8ccf25498da17f5ff69133909511a6d98d2976f3" translate="yes" xml:space="preserve">
          <source>G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert, &amp;ldquo;Regularization in regression: comparing Bayesian and frequentist methods in a poorly informative situation&amp;rdquo;, 2009.</source>
          <target state="translated">G.セルー、M。エルアンバリ、J.-M。マリン、CPロバート、「回帰の正規化：情報量の少ない状況でのベイズ法と頻度主義法の比較」、2009年。</target>
        </trans-unit>
        <trans-unit id="623c67fa2cbbcf37d713401c722eceec0b680645" translate="yes" xml:space="preserve">
          <source>G. Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5, Section 5.4.4, pp. 252-253.</source>
          <target state="translated">G.Golub、C.Van Loan.行列計算、第3版、第5章、5.4.4節、252-253頁。</target>
        </trans-unit>
        <trans-unit id="755f0c9208b383f3b380dd0d2b1a156d6d5865c4" translate="yes" xml:space="preserve">
          <source>G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer 2013.</source>
          <target state="translated">G.ジェームス、D。ウィッテン、T。ハスティ、Rティブシラニ、&lt;a href=&quot;http://www-bcf.usc.edu/~gareth/ISL&quot;&gt;『統計学習入門』&lt;/a&gt;、Springer 2013。</target>
        </trans-unit>
        <trans-unit id="3cb2eea23f004b3e761d528ddc6b2e3e79458d85" translate="yes" xml:space="preserve">
          <source>G. James, D. Witten, T. Hastie, R Tibshirani, &lt;a href=&quot;https://www-bcf.usc.edu/~gareth/ISL/&quot;&gt;An Introduction to Statistical Learning&lt;/a&gt;, Springer 2013.</source>
          <target state="translated">G. James、D。Witten、T。Hastie、R Tibshirani、&lt;a href=&quot;https://www-bcf.usc.edu/~gareth/ISL/&quot;&gt;統計学習入門&lt;/a&gt;、Springer2013。</target>
        </trans-unit>
        <trans-unit id="28ef1689ee2219c624cfde5d7c88afdcae0138ec" translate="yes" xml:space="preserve">
          <source>G. Louppe and P. Geurts, &amp;ldquo;Ensembles on Random Patches&amp;rdquo;, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</source>
          <target state="translated">G. LouppeとP. Geurts、「ランダムパッチのアンサンブル」、機械学習とデータベースでの知識の発見、346-361、2012年。</target>
        </trans-unit>
        <trans-unit id="c722e87d5d9d7dbc54dd2b811a759cc621efb047" translate="yes" xml:space="preserve">
          <source>G. Louppe, &amp;ldquo;Understanding Random Forests: From Theory to Practice&amp;rdquo;, PhD Thesis, U. of Liege, 2014.</source>
          <target state="translated">G.ルーペ、「ランダムフォレストの理解：理論から実践まで」、博士論文、U。of Liege、2014年。</target>
        </trans-unit>
        <trans-unit id="80030b72580197a6197c00418acf9f08511c2c49" translate="yes" xml:space="preserve">
          <source>G. Ridgeway, &amp;ldquo;Generalized Boosted Models: A guide to the gbm package&amp;rdquo;, 2007</source>
          <target state="translated">G. Ridgeway、「一般化されたブーストモデル：gbmパッケージのガイド」、2007年</target>
        </trans-unit>
        <trans-unit id="a8ed6bad205ec1f52f0b48e7f8377435663ec074" translate="yes" xml:space="preserve">
          <source>G.E.P. Box and D.R. Cox, &amp;ldquo;An Analysis of Transformations&amp;rdquo;, Journal of the Royal Statistical Society B, 26, 211-252 (1964).</source>
          <target state="translated">GEP BoxおよびDR Cox、「An Analysis of Transformations」、Journal of the Royal Statistical Society B、26、211〜252（1964）。</target>
        </trans-unit>
        <trans-unit id="83c6052410f7be2971558c8f2b162b661b4a734b" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion. Regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.</source>
          <target state="translated">GB は、段階的な方法で加法モデルを構築します。回帰木は、二項または多項のデビアンス損失関数の負の勾配に適合します。二項分類は、単一の回帰木のみが誘導される特殊なケースです。</target>
        </trans-unit>
        <trans-unit id="b8cb867b444fe174ab482df0a111ed147a9ceddf" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage &lt;code&gt;n_classes_&lt;/code&gt; regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.</source>
          <target state="translated">GBは、前向きの方法で追加モデルを構築します。任意の微分可能な損失関数の最適化を可能にします。各段階で、 &lt;code&gt;n_classes_&lt;/code&gt; 回帰木は、二項または多項の逸脱損失関数の負の勾配に適合します。バイナリ分類は、単一の回帰木のみが誘導される特殊なケースです。</target>
        </trans-unit>
        <trans-unit id="80f39c4fc4a6461ea00d5d7be636d9c6f77055de" translate="yes" xml:space="preserve">
          <source>GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.</source>
          <target state="translated">GBは、段階的に加法モデルを構築し、任意の微分可能な損失関数の最適化を可能にします。各段階では、与えられた損失関数の負の勾配に回帰木が適合します。</target>
        </trans-unit>
        <trans-unit id="2c1af0078ebec6d87c6fe14b52a6ca7ecb93e0e6" translate="yes" xml:space="preserve">
          <source>GBRT considers additive models of the following form:</source>
          <target state="translated">GBRTでは、以下のような形式の加法モデルを考えています。</target>
        </trans-unit>
        <trans-unit id="af90cc1188550654bd22990a09c9155ebaa04680" translate="yes" xml:space="preserve">
          <source>GBRT regressors are additive models whose prediction \(y_i\) for a given input \(x_i\) is of the following form:</source>
          <target state="translated">GBRT regressorsは、Additive modelで、入力の予測が次のような形になるモデルです。</target>
        </trans-unit>
        <trans-unit id="348ddf733ebe39c89fe60cc4aea0def489f0df0c" translate="yes" xml:space="preserve">
          <source>GMM covariances</source>
          <target state="translated">GMM 共分散</target>
        </trans-unit>
        <trans-unit id="89a541e422be32f4e38c95b70a35778f6b3b29a5" translate="yes" xml:space="preserve">
          <source>G[i,j] gives the shortest distance from point i to point j along the graph.</source>
          <target state="translated">G[i,j]はグラフに沿って点iから点jまでの最短距離を与えます。</target>
        </trans-unit>
        <trans-unit id="dc7da4ca9757d9015c0ba1d2228560006792966e" translate="yes" xml:space="preserve">
          <source>Gallery generated by Sphinx-Gallery</source>
          <target state="translated">Sphinx-Galleryによって生成されたギャラリー</target>
        </trans-unit>
        <trans-unit id="cba508b12182b68f501d6af46c4f03f8fc5d2473" translate="yes" xml:space="preserve">
          <source>Gamma</source>
          <target state="translated">Gamma</target>
        </trans-unit>
        <trans-unit id="927ef8e7f274c04e9c8836a36352812cc37bb26c" translate="yes" xml:space="preserve">
          <source>Gamma deviance is equivalent to the Tweedie deviance with the power parameter &lt;code&gt;power=2&lt;/code&gt;. It is invariant to scaling of the target variable, and measures relative errors.</source>
          <target state="translated">ガンマ逸脱度は​​、パワーパラメータ &lt;code&gt;power=2&lt;/code&gt; のTweedie逸脱度と同等です。これは、ターゲット変数のスケーリングに対して不変であり、相対エラーを測定します。</target>
        </trans-unit>
        <trans-unit id="24f0f86d8b8da4a3eb66c5315b49fb7db14a0fa6" translate="yes" xml:space="preserve">
          <source>Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.</source>
          <target state="translated">RBF,laplacian,polynomial,exponential chi2,sigmoid カーネルのガンマパラメータ.デフォルト値の解釈はカーネルに委ねられています;sklearn.metrics.pairwiseのドキュメントを参照してください。他のカーネルでは無視されます。</target>
        </trans-unit>
        <trans-unit id="8abb933fe9bd6d8a92eb104bdc2fd613c351d44f" translate="yes" xml:space="preserve">
          <source>Gamma parameter in rbf, poly and sigmoid kernels. Ignored by other kernels. 0.1 by default.</source>
          <target state="translated">rbf,poly,sigmoid カーネルのガンマパラメータ.他のカーネルでは無視されます。デフォルトでは0.1。</target>
        </trans-unit>
        <trans-unit id="86050f4573c138fca290821e4b579d6d320e40d1" translate="yes" xml:space="preserve">
          <source>Gates, G.W. (1972) &amp;ldquo;The Reduced Nearest Neighbor Rule&amp;rdquo;. IEEE Transactions on Information Theory, May 1972, 431-433.</source>
          <target state="translated">ゲイツ、GW（1972）「削減された最近隣ルール」。情報理論に関するIEEEトランザクション、1972年5月、431-433。</target>
        </trans-unit>
        <trans-unit id="46a57bcdd34ea523f3417e94b431a41097b638e9" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Ellipsoids</source>
          <target state="translated">ガウス混合モデル楕円体</target>
        </trans-unit>
        <trans-unit id="2f22bd1dad8340bd3d8973db40a56083b791482c" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Selection</source>
          <target state="translated">ガウス混合モデルの選択</target>
        </trans-unit>
        <trans-unit id="7ada59d703243073c5122ce20c200108df4cf582" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Model Sine Curve</source>
          <target state="translated">ガウス混合モデル 正弦曲線</target>
        </trans-unit>
        <trans-unit id="b8fb995e81cb89650fea0baec9d6ae8f98a9538f" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture Models</source>
          <target state="translated">ガウス混合モデル</target>
        </trans-unit>
        <trans-unit id="662a25df4ddd527b4e6e6b4415fd19857fcb55fc" translate="yes" xml:space="preserve">
          <source>Gaussian Mixture.</source>
          <target state="translated">ガウス混合物。</target>
        </trans-unit>
        <trans-unit id="52d32c3ce740bd6bf6fa9b8c9a00c471e2b8ab61" translate="yes" xml:space="preserve">
          <source>Gaussian Naive Bayes (GaussianNB)</source>
          <target state="translated">ガウシアンナイーブベイズ</target>
        </trans-unit>
        <trans-unit id="d854cefb413c2902ad18940be1c741ae3117e7e6" translate="yes" xml:space="preserve">
          <source>Gaussian Process for Machine Learning</source>
          <target state="translated">機械学習のためのガウス過程</target>
        </trans-unit>
        <trans-unit id="3e71cc209c706f89187660af28df9dbd656b7dfb" translate="yes" xml:space="preserve">
          <source>Gaussian Processes regression: basic introductory example</source>
          <target state="translated">ガウス過程回帰:基本的な入門例</target>
        </trans-unit>
        <trans-unit id="7c9060d2e2a8ab44211d4b8690374c1230f1b7f2" translate="yes" xml:space="preserve">
          <source>Gaussian kernel (&lt;code&gt;kernel = 'gaussian'&lt;/code&gt;)</source>
          <target state="translated">ガウスカーネル（ &lt;code&gt;kernel = 'gaussian'&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="16bd9bbb5a5342036acd14278f2e03ad41c57f6a" translate="yes" xml:space="preserve">
          <source>Gaussian mixture model fit with a variational inference.</source>
          <target state="translated">変分推論を用いたガウス混合モデルのフィット。</target>
        </trans-unit>
        <trans-unit id="c4278ff51902cddfc2c28028add69085822b616d" translate="yes" xml:space="preserve">
          <source>Gaussian mixture models, useful for clustering, are described in &lt;a href=&quot;mixture#mixture&quot;&gt;another chapter of the documentation&lt;/a&gt; dedicated to mixture models. KMeans can be seen as a special case of Gaussian mixture model with equal covariance per component.</source>
          <target state="translated">クラスタリングに役立つガウス混合モデルは、混合モデル専用&lt;a href=&quot;mixture#mixture&quot;&gt;のドキュメントの別の章で&lt;/a&gt;説明されています。KMeansは、コンポーネントごとに等しい共分散をもつ混合ガウスモデルの特殊なケースと見なすことができます。</target>
        </trans-unit>
        <trans-unit id="52102b8851b98924c7d8b1f347902fc1a6a2f6c4" translate="yes" xml:space="preserve">
          <source>Gaussian mixtures</source>
          <target state="translated">ガウス混合</target>
        </trans-unit>
        <trans-unit id="fb2ed046d4b5b73ab490df316744dbd7803b27c6" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) based on Laplace approximation.</source>
          <target state="translated">ラプラス近似に基づくガウスプロセス分類(GPC)。</target>
        </trans-unit>
        <trans-unit id="6022eb0f0e245ca9c1dcd7d4b4311ff01e4db354" translate="yes" xml:space="preserve">
          <source>Gaussian process classification (GPC) on iris dataset</source>
          <target state="translated">虹彩データセットにおけるガウスプロセス分類(GPC</target>
        </trans-unit>
        <trans-unit id="21a63bbdb2d774ad21ffa6c87b635dc00ddbdcbd" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) on Mauna Loa CO2 data.</source>
          <target state="translated">マウナロアCO2データのガウス過程回帰(GPR)。</target>
        </trans-unit>
        <trans-unit id="0c7b8e025d47923893c509b893c584646dec60f9" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR) with noise-level estimation</source>
          <target state="translated">ノイズレベル推定を用いたガウス過程回帰(GPR)</target>
        </trans-unit>
        <trans-unit id="e020234a1ce464bccd79fd7ca6cd9571320c3263" translate="yes" xml:space="preserve">
          <source>Gaussian process regression (GPR).</source>
          <target state="translated">ガウス過程回帰(GPR)。</target>
        </trans-unit>
        <trans-unit id="81d5ab12411c6f249a3ae9ff3884b17e3d00399b" translate="yes" xml:space="preserve">
          <source>Gaussian processes on discrete data structures</source>
          <target state="translated">離散データ構造上のガウス過程</target>
        </trans-unit>
        <trans-unit id="3eef2758f8f04922436ba69e73f365c3b677d080" translate="yes" xml:space="preserve">
          <source>GaussianNaiveBayes tends to push probabilities to 0 or 1 (note the counts in the histograms). This is mainly because it makes the assumption that features are conditionally independent given the class, which is not the case in this dataset which contains 2 redundant features.</source>
          <target state="translated">GaussianNaiveBayesは,確率を0または1に押し上げる傾向がある(ヒストグラムのカウントに注意).これは主に,特徴がクラスを与えられた条件付きで独立しているという仮定をしているためですが,2つの冗長な特徴を含むこのデータセットではそうではありません.</target>
        </trans-unit>
        <trans-unit id="9ee50bfb8852bcfbfa07c7c7a246c842043563a2" translate="yes" xml:space="preserve">
          <source>General KDD structure :</source>
          <target state="translated">一般的なKDD構造 .</target>
        </trans-unit>
        <trans-unit id="082e84b7a80940ab38b8fafffced3896fbf61a5f" translate="yes" xml:space="preserve">
          <source>General examples about classification algorithms.</source>
          <target state="translated">分類アルゴリズムに関する一般的な例</target>
        </trans-unit>
        <trans-unit id="340183f53d5a585fe2f90b1573169f80622dc9bd" translate="yes" xml:space="preserve">
          <source>General-purpose, even cluster size, flat geometry, not too many clusters</source>
          <target state="translated">汎用、均一なクラスタサイズ、フラットジオメトリ、クラスタ数が多すぎない</target>
        </trans-unit>
        <trans-unit id="5a99200d3c187d0fcefb7b4df6803366dc2748df" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Gamma distribution.</source>
          <target state="translated">ガンマ分布を持つ一般化線形モデル。</target>
        </trans-unit>
        <trans-unit id="0ed4c66ad535ba7380d74741129413d4f8c145bc" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Poisson distribution.</source>
          <target state="translated">ポアソン分布を持つ一般化線形モデル.</target>
        </trans-unit>
        <trans-unit id="d682c681b1fa1783371317722a00ec63b80aa77c" translate="yes" xml:space="preserve">
          <source>Generalized Linear Model with a Tweedie distribution.</source>
          <target state="translated">ツイーディー分布を持つ一般化線形モデル。</target>
        </trans-unit>
        <trans-unit id="b17d9222a12b9513aac695dd37d7bdc64c218d77" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models</source>
          <target state="translated">一般化線形モデル</target>
        </trans-unit>
        <trans-unit id="bcbd479b250088e4214e337494acb2a2758516bc" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models (GLM) extend linear models in two ways &lt;a href=&quot;#id33&quot; id=&quot;id31&quot;&gt;10&lt;/a&gt;. First, the predicted values \(\hat{y}\) are linked to a linear combination of the input variables \(X\) via an inverse link function \(h\) as</source>
          <target state="translated">一般化線形モデル（GLM）は、線形モデルを2つの方法で拡張します&lt;a href=&quot;#id33&quot; id=&quot;id31&quot;&gt;10&lt;/a&gt;。まず、予測値\（\ hat {y} \）は、逆リンク関数\（h \）を介して入力変数\（X \）の線形結合にリンクされます。</target>
        </trans-unit>
        <trans-unit id="050c76b497e038e0c5a06ed24dce47a6958dfb02" translate="yes" xml:space="preserve">
          <source>Generalized Linear Models, and Poisson loss for gradient boosting</source>
          <target state="translated">一般化線形モデル、勾配ブーストのためのポアソン損失</target>
        </trans-unit>
        <trans-unit id="194ee7e5ec30d094070f5f72a72c8597376dc276" translate="yes" xml:space="preserve">
          <source>Generalized linear models (GLM) for regression</source>
          <target state="translated">回帰のための一般化線形モデル(GLM)</target>
        </trans-unit>
        <trans-unit id="a807e718c7c2444084ecd599b5293f02618f18b0" translate="yes" xml:space="preserve">
          <source>Generally speaking, when model complexity increases, predictive power and latency are supposed to increase. Increasing predictive power is usually interesting, but for many applications we would better not increase prediction latency too much. We will now review this idea for different families of supervised models.</source>
          <target state="translated">一般的に、モデルの複雑さが増すと、予測能力とレイテンシは増加すると考えられています。予測力の増加は通常興味深いものですが、多くのアプリケーションでは、予測待ち時間をあまり増加させない方がよいでしょう。ここでは、教師付きモデルのさまざまなファミリについて、この考え方をレビューします。</target>
        </trans-unit>
        <trans-unit id="af9887d0c879889fc0d4b97d28831fef1da0e335" translate="yes" xml:space="preserve">
          <source>Generate a distance matrix chunk by chunk with optional reduction</source>
          <target state="translated">オプションのリダクションを用いて,距離行列をチャンクごとに生成します.</target>
        </trans-unit>
        <trans-unit id="06c2a79c89c40ddc99e314455bfeabb348baaefc" translate="yes" xml:space="preserve">
          <source>Generate a mostly low rank matrix with bell-shaped singular values</source>
          <target state="translated">ベル型の特異値を持つほぼ低ランクの行列を生成する</target>
        </trans-unit>
        <trans-unit id="c1825817fcf44112a4d64fe6f2acf131fceae396" translate="yes" xml:space="preserve">
          <source>Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].</source>
          <target state="translated">指定された次数以下の次数を持つ特徴のすべての多項式の組み合わせからなる新しい特徴行列を生成します.例えば,入力サンプルが2次元で[a,b]の形式の場合,次数2の多項式特徴量は[1,a,b,a^2,ab,b^2]となり,次数2の多項式特徴量は[1,a,b,a^2,ab,b^2]となります.</target>
        </trans-unit>
        <trans-unit id="138afdc51f7a90d9b74b5dc5c84735ab7ad5ab97" translate="yes" xml:space="preserve">
          <source>Generate a random multilabel classification problem.</source>
          <target state="translated">ランダムなマルチラベル分類問題を生成する。</target>
        </trans-unit>
        <trans-unit id="6e53d56707f7eb93fc64a285e9e5b0c1571546a7" translate="yes" xml:space="preserve">
          <source>Generate a random n-class classification problem.</source>
          <target state="translated">ランダムなnクラスの分類問題を生成する。</target>
        </trans-unit>
        <trans-unit id="45b70aa4bfe7b5254dd4845949fd163391dae828" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem with sparse uncorrelated design</source>
          <target state="translated">疎な無相関設計によるランダム回帰問題の生成</target>
        </trans-unit>
        <trans-unit id="097811da2f026de1c67525043ab17d6d057450a6" translate="yes" xml:space="preserve">
          <source>Generate a random regression problem.</source>
          <target state="translated">ランダム回帰問題を生成します。</target>
        </trans-unit>
        <trans-unit id="90aba5bbbbad8863550c06ced91ee520b1c0caff" translate="yes" xml:space="preserve">
          <source>Generate a random symmetric, positive-definite matrix.</source>
          <target state="translated">ランダムな対称正定値行列を生成します。</target>
        </trans-unit>
        <trans-unit id="b303920886f4c442ac72ea67b8bd3cb1b7460430" translate="yes" xml:space="preserve">
          <source>Generate a signal as a sparse combination of dictionary elements.</source>
          <target state="translated">辞書要素の疎な組み合わせとして信号を生成します。</target>
        </trans-unit>
        <trans-unit id="035b22a208f9d34d7467f70a3f8e5a4c27edb9b2" translate="yes" xml:space="preserve">
          <source>Generate a sparse random projection matrix</source>
          <target state="translated">疎なランダム射影行列を生成する</target>
        </trans-unit>
        <trans-unit id="4dc557ac054fd2b6925cea078345560226a5469c" translate="yes" xml:space="preserve">
          <source>Generate a sparse symmetric definite positive matrix.</source>
          <target state="translated">疎な対称正定値行列を生成します。</target>
        </trans-unit>
        <trans-unit id="2b6ed08a20bd86f602cf70906530ae751a13aa6a" translate="yes" xml:space="preserve">
          <source>Generate a swiss roll dataset.</source>
          <target state="translated">スイスロールデータセットを生成します。</target>
        </trans-unit>
        <trans-unit id="2f7e815b3b193bc1cd3e7e4a28307316625909c7" translate="yes" xml:space="preserve">
          <source>Generate an S curve dataset.</source>
          <target state="translated">S曲線データセットを生成します。</target>
        </trans-unit>
        <trans-unit id="a97cf86ca659bda28267893fc11990f8622b62e7" translate="yes" xml:space="preserve">
          <source>Generate an array with block checkerboard structure for biclustering.</source>
          <target state="translated">バイクラスタリングのためのブロックチェッカーボード構造の配列を生成します。</target>
        </trans-unit>
        <trans-unit id="a9f13a8783d09446e6122b3e3234e1d6fcb95591" translate="yes" xml:space="preserve">
          <source>Generate an array with constant block diagonal structure for biclustering.</source>
          <target state="translated">バイクラスタリングのための一定のブロック対角構造を持つ配列を生成します.</target>
        </trans-unit>
        <trans-unit id="afeaee3f091598162e7eb33b08779a77e0e748f4" translate="yes" xml:space="preserve">
          <source>Generate cross-validated estimates for each input data point</source>
          <target state="translated">各入力データポイントについて交差検証された推定値を生成する</target>
        </trans-unit>
        <trans-unit id="99b9ba538a40d50737f63d924a3c7ce27d75993f" translate="yes" xml:space="preserve">
          <source>Generate datasets. We choose the size big enough to see the scalability of the algorithms, but not too big to avoid too long running times</source>
          <target state="translated">データセットを生成します。アルゴリズムのスケーラビリティを確認するのに十分な大きさを選びますが、実行時間が長くなりすぎないように大きすぎないようにします。</target>
        </trans-unit>
        <trans-unit id="c00dd920cc2725de42546dcb337634c4ac897029" translate="yes" xml:space="preserve">
          <source>Generate indices to split data into training and test set.</source>
          <target state="translated">データをトレーニングセットとテストセットに分割するためのインデックスを生成します。</target>
        </trans-unit>
        <trans-unit id="5107cc8a6ff57cac684ccce1f62420eaa4260507" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian and label samples by quantile</source>
          <target state="translated">等方性ガウシアンを生成し、分級値でサンプルをラベル付けする</target>
        </trans-unit>
        <trans-unit id="8e89de3bc63d92fa78eda36337c27db80aab71fe" translate="yes" xml:space="preserve">
          <source>Generate isotropic Gaussian blobs for clustering.</source>
          <target state="translated">クラスタリングのための等方性ガウスブロブを生成します。</target>
        </trans-unit>
        <trans-unit id="37d03dbfefb10390fe483e5ed2d7b03c5a459fa1" translate="yes" xml:space="preserve">
          <source>Generate missing values indicator for X.</source>
          <target state="translated">Xの欠損値指標を生成します。</target>
        </trans-unit>
        <trans-unit id="462cab2784077aa54955d18bb40a9de12e6edf3c" translate="yes" xml:space="preserve">
          <source>Generate polynomial and interaction features.</source>
          <target state="translated">多項式と相互作用の特徴を生成します。</target>
        </trans-unit>
        <trans-unit id="d1bba874447d3710a4261bda204e3775c6148149" translate="yes" xml:space="preserve">
          <source>Generate random samples from the fitted Gaussian distribution.</source>
          <target state="translated">フィットしたガウス分布からランダムサンプルを生成します。</target>
        </trans-unit>
        <trans-unit id="ce67c2d91c83a1d56ab9a9ee35d822063af6506a" translate="yes" xml:space="preserve">
          <source>Generate random samples from the model.</source>
          <target state="translated">モデルからランダムサンプルを生成します。</target>
        </trans-unit>
        <trans-unit id="077b466863e9f097ef6d30c373ea7fea91f90736" translate="yes" xml:space="preserve">
          <source>Generate test sets such that all contain the same distribution of classes, or as close as possible.</source>
          <target state="translated">すべてのクラスが同じ分布を含むような、あるいはできるだけ近い分布を持つようなテストセットを生成します。</target>
        </trans-unit>
        <trans-unit id="7afab3e6555db4edb28194e580e8ac980040a53c" translate="yes" xml:space="preserve">
          <source>Generate test sets where the smallest and largest differ by at most one sample.</source>
          <target state="translated">最小値と最大値が最大1つのサンプルで異なるテストセットを生成します。</target>
        </trans-unit>
        <trans-unit id="f4defed702b6f02ff908f1cd9f8b411c35ee40dd" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #1&amp;rdquo; regression problem</source>
          <target state="translated">「フリードマン＃1」の回帰問題を生成する</target>
        </trans-unit>
        <trans-unit id="75088d435099809ee2a5f0ec830b6e2b26fb0500" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #2&amp;rdquo; regression problem</source>
          <target state="translated">「フリードマン＃2」回帰問題を生成する</target>
        </trans-unit>
        <trans-unit id="18ca02f4b303dec3c31289cd6db22246b19d8adb" translate="yes" xml:space="preserve">
          <source>Generate the &amp;ldquo;Friedman #3&amp;rdquo; regression problem</source>
          <target state="translated">「フリードマン＃3」回帰問題を生成する</target>
        </trans-unit>
        <trans-unit id="1526c84b2e9b495f9ed3216009ebf8b31d461518" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al.</source>
          <target state="translated">Hastie et al.で使用されているバイナリ分類用のデータを生成します。</target>
        </trans-unit>
        <trans-unit id="c2cb269fed6a06711794c0a014b9a89e92300ddb" translate="yes" xml:space="preserve">
          <source>Generates data for binary classification used in Hastie et al. 2009, Example 10.2.</source>
          <target state="translated">Hastie et al.2009,例10.2で使用されている二値分類用のデータを生成します。</target>
        </trans-unit>
        <trans-unit id="fbfd61fc35f16aea2f376426724b313bf45b644a" translate="yes" xml:space="preserve">
          <source>Generates indices to split data into training and test set.</source>
          <target state="translated">データをトレーニングセットとテストセットに分割するためのインデックスを生成します。</target>
        </trans-unit>
        <trans-unit id="9a963ad633fdf36ff4f1d429308e1f3d90a2ceea" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on predefined splits.</source>
          <target state="translated">事前に定義されたスプリットに基づいて訓練/テスト指標を生成します。</target>
        </trans-unit>
        <trans-unit id="4678269441c5cad2dec162c29e80b19e70944794" translate="yes" xml:space="preserve">
          <source>Generates train/test indices based on random permutation.</source>
          <target state="translated">ランダムな並べ替えに基づいて訓練/テスト指標を生成します。</target>
        </trans-unit>
        <trans-unit id="025efadf6f18cb5d61732c8188dd311431f2fe8b" translate="yes" xml:space="preserve">
          <source>Generator on parameters sampled from given distributions.</source>
          <target state="translated">与えられた分布からサンプリングされたパラメータを生成します。</target>
        </trans-unit>
        <trans-unit id="6d76c76581c79bfcc7307e6698c50d3852025179" translate="yes" xml:space="preserve">
          <source>Generator that yields (estimator, check) tuples. Returned when &lt;code&gt;generate_only=True&lt;/code&gt;.</source>
          <target state="translated">（推定量、チェック）タプルを生成するジェネレーター。 &lt;code&gt;generate_only=True&lt;/code&gt; の場合に返されます。</target>
        </trans-unit>
        <trans-unit id="9008c79b50b6e856f48dd8a1acb75bd481c83565" translate="yes" xml:space="preserve">
          <source>Generator to create n_packs slices going up to n.</source>
          <target state="translated">n までの n_packs スライスを作成するジェネレータ。</target>
        </trans-unit>
        <trans-unit id="6a34af9aa1c17133e53bdde13fa952c7bcbcf3f6" translate="yes" xml:space="preserve">
          <source>Geometry (metric used)</source>
          <target state="translated">幾何学(メートル法を使用</target>
        </trans-unit>
        <trans-unit id="e5f048789e3e59e8993091df470af502112331aa" translate="yes" xml:space="preserve">
          <source>George W Bush</source>
          <target state="translated">ジョージ・W・ブッシュ</target>
        </trans-unit>
        <trans-unit id="b583db923d23716d80d92ca8bb6a609aa1f738a2" translate="yes" xml:space="preserve">
          <source>Gerhard Schroeder</source>
          <target state="translated">ゲルハルト・シュローダー</target>
        </trans-unit>
        <trans-unit id="33868dad5f60b783d41cfb7c4e686fd5af82ea02" translate="yes" xml:space="preserve">
          <source>Get a list of all estimators from sklearn.</source>
          <target state="translated">sklearnのすべての見積もり担当者のリストを取得します。</target>
        </trans-unit>
        <trans-unit id="c89b4f911ae16fa0b7caa09ce0c140306df6a7bd" translate="yes" xml:space="preserve">
          <source>Get a mask, or integer index, of the features selected</source>
          <target state="translated">選択された特徴のマスク、または整数値のインデックスを取得します。</target>
        </trans-unit>
        <trans-unit id="72908cf84377de645c7534a22afeddeeaba91d9d" translate="yes" xml:space="preserve">
          <source>Get a scorer from string</source>
          <target state="translated">文字列からスコアラーを取得</target>
        </trans-unit>
        <trans-unit id="892dda63b5e110479cdb36e62f1ec2fd9807071b" translate="yes" xml:space="preserve">
          <source>Get a scorer from string.</source>
          <target state="translated">文字列からスコアラーを取得します。</target>
        </trans-unit>
        <trans-unit id="9077d712fdd7764174aa9d64af32e58e63a20fd2" translate="yes" xml:space="preserve">
          <source>Get data and node arrays.</source>
          <target state="translated">データとノード配列を取得します。</target>
        </trans-unit>
        <trans-unit id="45a250b2600ca82b0e59f392e6c981ee3cc2728d" translate="yes" xml:space="preserve">
          <source>Get feature names from all transformers.</source>
          <target state="translated">すべてのトランスフォーマーから機能名を取得します。</target>
        </trans-unit>
        <trans-unit id="29212f8ab4fb514c62f70555a85d5fbb976ec617" translate="yes" xml:space="preserve">
          <source>Get number of calls.</source>
          <target state="translated">電話番号を取得します。</target>
        </trans-unit>
        <trans-unit id="4be0c520942fc8926cfd53e42cd4ae1d1cc70df9" translate="yes" xml:space="preserve">
          <source>Get parameters for this estimator.</source>
          <target state="translated">この推定子のパラメータを取得します。</target>
        </trans-unit>
        <trans-unit id="fe15f50ace10fe1b8c70139542f4a1796682abb3" translate="yes" xml:space="preserve">
          <source>Get parameters of this kernel.</source>
          <target state="translated">このカーネルのパラメータを取得します。</target>
        </trans-unit>
        <trans-unit id="1314abe875bac1db97b1a7155d7b4a8c13c230ee" translate="yes" xml:space="preserve">
          <source>Get predictions from each split of cross-validation for diagnostic purposes.</source>
          <target state="translated">診断のためのクロスバリデーションの各スプリットから予測値を取得します。</target>
        </trans-unit>
        <trans-unit id="dd0a065fc935a1fd709e1a1d7d55ca6c3433dca5" translate="yes" xml:space="preserve">
          <source>Get the given distance metric from the string identifier.</source>
          <target state="translated">文字列識別子から与えられた距離メトリックを取得します。</target>
        </trans-unit>
        <trans-unit id="d1f7f6e0092ef00a29852a7f857762682fb899cd" translate="yes" xml:space="preserve">
          <source>Get the parameters of an estimator from the ensemble.</source>
          <target state="translated">アンサンブルから推定器のパラメータを取得します。</target>
        </trans-unit>
        <trans-unit id="df2089c702273c8bc78b6842775813fe9702ad55" translate="yes" xml:space="preserve">
          <source>Get the parameters of the VotingClassifier</source>
          <target state="translated">VotingClassifier のパラメータを取得します。</target>
        </trans-unit>
        <trans-unit id="44fa9d84cdb2287aa5766955eab26611c0998b04" translate="yes" xml:space="preserve">
          <source>Get tree status.</source>
          <target state="translated">ツリーの状態を取得します。</target>
        </trans-unit>
        <trans-unit id="1f6030226293d5ed7b4d4b045e215d6de20db61c" translate="yes" xml:space="preserve">
          <source>Getter for the precision matrix.</source>
          <target state="translated">精密行列のゲッターです。</target>
        </trans-unit>
        <trans-unit id="24670d1cd19283e4b5f2e1096ab423493375ec8f" translate="yes" xml:space="preserve">
          <source>Gibbs sampling from visible and hidden layers.</source>
          <target state="translated">可視層と隠蔽層からのギブスサンプリング</target>
        </trans-unit>
        <trans-unit id="53379a8bafa1cbd8bc5da14050f14d3817f01039" translate="yes" xml:space="preserve">
          <source>Given 2 multivariate covarying two-dimensional datasets, X, and Y, PLS extracts the &amp;lsquo;directions of covariance&amp;rsquo;, i.e. the components of each datasets that explain the most shared variance between both datasets. This is apparent on the &lt;strong&gt;scatterplot matrix&lt;/strong&gt; display: components 1 in dataset X and dataset Y are maximally correlated (points lie around the first diagonal). This is also true for components 2 in both dataset, however, the correlation across datasets for different components is weak: the point cloud is very spherical.</source>
          <target state="translated">2つの多変量共変2次元データセット、X、およびYが与えられると、PLSは「共分散の方向」、つまり両方のデータセット間で最も共有される分散を説明する各データセットのコンポーネントを抽出します。これは、&lt;strong&gt;散布図のマトリックス&lt;/strong&gt;表示で明らかです。データセットXとデータセットYのコンポーネント1は最大に相関しています（ポイントは最初の対角線の周りにあります）。これは両方のデータセットのコンポーネント2にも当てはまりますが、異なるコンポーネントのデータセット間の相関は弱く、点群は非常に球形です。</target>
        </trans-unit>
        <trans-unit id="16179644ab5a4c2a1f730ff634ab3d4d3a869791" translate="yes" xml:space="preserve">
          <source>Given a candidate centroid \(x_i\) for iteration \(t\), the candidate is updated according to the following equation:</source>
          <target state="translated">候補のセントロイドがあると、次の式で更新されます。</target>
        </trans-unit>
        <trans-unit id="4368fa47ed8eb35b757e7b3d5aaf6d7ee1cd4ff6" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to a binary one-hot encoding.</source>
          <target state="translated">2つの特徴を持つデータセットが与えられた場合、エンコーダに特徴ごとにユニークな値を見つけさせ、データをバイナリのワンショットエンコーディングに変換させます。</target>
        </trans-unit>
        <trans-unit id="a65060cb3a96ad97e8800308b9076a9a49180060" translate="yes" xml:space="preserve">
          <source>Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to an ordinal encoding.</source>
          <target state="translated">2つの特徴量を持つデータセットが与えられた場合,エンコーダーに特徴量ごとのユニークな値を見つけさせ,データを順序エンコーディングに変換させます.</target>
        </trans-unit>
        <trans-unit id="6cc0cdb4252ae3fe585bd759a612161dfe7c6d85" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^n\) and \(y_i \in \{0, 1\}\), a one hidden layer one hidden neuron MLP learns the function \(f(x) = W_2 g(W_1^T x + b_1) + b_2\) where \(W_1 \in \mathbf{R}^m\) and \(W_2, b_1, b_2 \in \mathbf{R}\) are model parameters. \(W_1, W_2\) represent the weights of the input layer and hidden layer, respectively; and \(b_1, b_2\) represent the bias added to the hidden layer and the output layer, respectively. \(g(\cdot) : R \rightarrow R\) is the activation function, set by default as the hyperbolic tan. It is given as,</source>
          <target state="translated">隠れ層1ニューロンMLPは,関数 \(f(x)=W_2 g(W_1^T x+b_1)+b_2\)を学習する.ここで,W\(W_1 in \mathbf{R}^m)と\(W_2,b_1,b_2 \mathbf{R})はモデルパラメータである.\W\(W_1,W_2)は,入力層と隠蔽層の重みを,\(b_1,b_2\)は,隠蔽層と出力層のバイアスをそれぞれ表している.\は、活性化関数であり、双曲線のtanがデフォルトで設定されている。次のように与えられます。</target>
        </trans-unit>
        <trans-unit id="c774496cc27fa29850b7be4385a4e837807fe19c" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \mathcal{R}\) (\(y_i \in {-1, 1}\) for classification), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions for binary classification, we simply look at the sign of \(f(x)\). To find the model parameters, we minimize the regularized training error given by</source>
          <target state="translated">our goal is to learn a linear scoring function \(f(x)=w^T x+b\)with model parameters w\(w \in \mathbf{R}^m),and intercept b\(b \in \mathbf{R}).2値分類の予測をするためには、「\(f(x)\)」の符号を見るだけでよい。モデルのパラメータを求めるには、以下の式で与えられる正則化学習誤差を最小化する。</target>
        </trans-unit>
        <trans-unit id="99b85508f1069fad6e9945b3624fea4140b5fbae" translate="yes" xml:space="preserve">
          <source>Given a set of training examples \((x_1, y_1), \ldots, (x_n, y_n)\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \{-1,1\}\), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions, we simply look at the sign of \(f(x)\). A common choice to find the model parameters is by minimizing the regularized training error given by</source>
          <target state="translated">our goal is to learn a linear scoring function &quot;\(f(x)=w^T x+b\)&quot; with model parameters &quot;w (w \in \mathbf{R}^m)&quot; and intercept &quot;b (b \in \mathbf{R})&quot; with model parameters &quot;w \(w \in \mathbf{R}^m)予測をするためには、「\(f(x)x)\」の符号を見るだけでよい。モデル・パラメータを見つけるための一般的な選択は、次式で与えられる正則化された訓練誤差を最小化することである。</target>
        </trans-unit>
        <trans-unit id="f05ffd1dc56829aeb2ce3b1aa47183d5a5a71272" translate="yes" xml:space="preserve">
          <source>Given an exception, a callable to raise the exception, and a message string, tests that the correct exception is raised and that the message is a substring of the error thrown. Used to test that the specific message thrown during an exception is correct.</source>
          <target state="translated">例外と、例外を発生させるための callable、そしてメッセージ文字列が与えられると、 正しい例外が発生し、そのメッセージがスローされたエラーの部分文字列であるかどうかをテストします。例外が発生した際にスローされた特定のメッセージが正しいかどうかをテストするために使用されます。</target>
        </trans-unit>
        <trans-unit id="d5588778e54082615cf481fafbc7dcf0b337d76d" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (&lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt;&lt;code&gt;RFE&lt;/code&gt;&lt;/a&gt;) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">フィーチャ（たとえば、線形モデルの係数）に重みを割り当てる外部推定量が与えられると、再帰的フィーチャ除去（&lt;a href=&quot;generated/sklearn.feature_selection.rfe#sklearn.feature_selection.RFE&quot;&gt; &lt;code&gt;RFE&lt;/code&gt; &lt;/a&gt;）は、フィーチャのより小さなセットを再帰的に考慮してフィーチャを選択することです。最初に、推定器は最初の特徴セットでトレーニングされ、各特徴の重要度は &lt;code&gt;coef_&lt;/code&gt; 属性または &lt;code&gt;feature_importances_&lt;/code&gt; 属性のいずれかによって取得されます。次に、最も重要でない機能が現在の機能のセットからプルーニングされます。この手順は、最終的に選択する機能の数が最終的に到達するまで、プルーニングされたセットに対して再帰的に繰り返されます。</target>
        </trans-unit>
        <trans-unit id="0a3e62329db7e0582a525546102e4bc5a3e414ee" translate="yes" xml:space="preserve">
          <source>Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a &lt;code&gt;coef_&lt;/code&gt; attribute or through a &lt;code&gt;feature_importances_&lt;/code&gt; attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</source>
          <target state="translated">フィーチャ（たとえば、線形モデルの係数）に重みを割り当てる外部推定量が与えられた場合、再帰的フィーチャ除去（RFE）の目的は、フィーチャのより小さなセットを再帰的に考慮してフィーチャを選択することです。最初に、推定器は最初の特徴セットでトレーニングされ、各特徴の重要度は &lt;code&gt;coef_&lt;/code&gt; 属性または &lt;code&gt;feature_importances_&lt;/code&gt; 属性のいずれかによって取得されます。次に、最も重要でない機能が現在の機能セットから削除されます。その手順は、最終的に選択する機能の数が最終的に到達するまで、剪定されたセットで再帰的に繰り返されます。</target>
        </trans-unit>
        <trans-unit id="2e4a90e9413cabdb8d0d79c137af8efe3fbd16ef" translate="yes" xml:space="preserve">
          <source>Given enough time, K-means will always converge, however this may be to a local minimum. This is highly dependent on the initialization of the centroids. As a result, the computation is often done several times, with different initializations of the centroids. One method to help address this issue is the k-means++ initialization scheme, which has been implemented in scikit-learn (use the &lt;code&gt;init='k-means++'&lt;/code&gt; parameter). This initializes the centroids to be (generally) distant from each other, leading to provably better results than random initialization, as shown in the reference.</source>
          <target state="translated">十分な時間が与えられれば、K平均法は常に収束しますが、これは局所的な最小値になる場合があります。これは重心の初期化に大きく依存します。その結果、重心の異なる初期化を使用して、計算がしばしば数回行われます。この問題に対処するための1つの方法は、k-means ++初期化スキームで、scikit-learnに実装されています（ &lt;code&gt;init='k-means++'&lt;/code&gt; パラメーターを使用）。これにより、図に示されているように、重心が互いに（一般的に）離れた位置に初期化され、ランダムな初期化よりも結果が良くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="74d4aecb20e2cdcd5c8865136aad914eecac7d61" translate="yes" xml:space="preserve">
          <source>Given the iris dataset, if we knew that there were 3 types of iris, but did not have access to a taxonomist to label them: we could try a &lt;strong&gt;clustering task&lt;/strong&gt;: split the observations into well-separated group called &lt;em&gt;clusters&lt;/em&gt;.</source>
          <target state="translated">私たちはアイリスの3種類があったことを知っていたが、それらにラベルを付けるために分類学者へのアクセス権を持っていなかった場合は、アイリスデータセットを考える：私たちは試みることができる&lt;strong&gt;クラスタリングタスクを&lt;/strong&gt;：十分に分離グループと呼ばれるに観測を分割し&lt;em&gt;たクラスタ&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="7ffdaa4cdda4b54b62086a7f5ac68bd7ea3b5908" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;Mutual Information&lt;/strong&gt; is a function that measures the &lt;strong&gt;agreement&lt;/strong&gt; of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, &lt;strong&gt;Normalized Mutual Information (NMI)&lt;/strong&gt; and &lt;strong&gt;Adjusted Mutual Information (AMI)&lt;/strong&gt;. NMI is often used in the literature, while AMI was proposed more recently and is &lt;strong&gt;normalized against chance&lt;/strong&gt;:</source>
          <target state="translated">グラウンドトゥルースクラスの割り当て &lt;code&gt;labels_true&lt;/code&gt; と、同じサンプル &lt;code&gt;labels_pred&lt;/code&gt; のクラスタリングアルゴリズムの割り当てに関する知識がある場合、&lt;strong&gt;相互情報&lt;/strong&gt;は、順列を無視して2つの割り当ての&lt;strong&gt;一致&lt;/strong&gt;を測定する関数です。このメジャーの2つの異なる正規化バージョン、&lt;strong&gt;Normalized Mutual Information（NMI）&lt;/strong&gt;と&lt;strong&gt;Adjusted Mutual Information（AMI）を使用でき&lt;/strong&gt;ます。 NMIは文献でよく使用されますが、AMIは最近提案され&lt;strong&gt;、偶然に対して正規化&lt;/strong&gt;されています。</target>
        </trans-unit>
        <trans-unit id="943836cb04e0640667940c68f56d5deeb3e35898" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments &lt;code&gt;labels_true&lt;/code&gt; and our clustering algorithm assignments of the same samples &lt;code&gt;labels_pred&lt;/code&gt;, the &lt;strong&gt;adjusted Rand index&lt;/strong&gt; is a function that measures the &lt;strong&gt;similarity&lt;/strong&gt; of the two assignments, ignoring permutations and &lt;strong&gt;with chance normalization&lt;/strong&gt;:</source>
          <target state="translated">グラウンドトゥルースクラスの割り当て &lt;code&gt;labels_true&lt;/code&gt; と、同じサンプル &lt;code&gt;labels_pred&lt;/code&gt; のクラスタリングアルゴリズムの割り当てに関する知識がある場合、&lt;strong&gt;調整されたRandインデックス&lt;/strong&gt;は、順列を無視し&lt;strong&gt;、偶然に正規化&lt;/strong&gt;して、2つの割り当ての&lt;strong&gt;類似性&lt;/strong&gt;を測定する関数です。&lt;strong&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="3a989bbd6a98db5dab53799fee5637e2080ce141" translate="yes" xml:space="preserve">
          <source>Given the knowledge of the ground truth class assignments of the samples, it is possible to define some intuitive metric using conditional entropy analysis.</source>
          <target state="translated">サンプルの基底真理クラスの割り当ての知識があれば、条件付きエントロピー分析を用いて直感的なメトリックを定義することができます。</target>
        </trans-unit>
        <trans-unit id="4d7a7b1af5c7c7276434270fce7100038c705add" translate="yes" xml:space="preserve">
          <source>Given these singular vectors, they are ranked according to which can be best approximated by a piecewise-constant vector. The approximations for each vector are found using one-dimensional k-means and scored using the Euclidean distance. Some subset of the best left and right singular vector are selected. Next, the data is projected to this best subset of singular vectors and clustered.</source>
          <target state="translated">これらの特異なベクトルが与えられると、それらは、断片的に一定のベクトルで最もよく近似できるものに応じてランク付けされる。各ベクトルの近似は,1次元のk-meansを用いて発見され,ユークリッド距離を用いて採点される.最良の左右特異ベクトルのいくつかの部分集合が選択される。次に、データはこの最良の特異ベクトルの部分集合に投影され、クラスタ化される。</target>
        </trans-unit>
        <trans-unit id="21675a464e2ca3b8f99eef191d00e106aa21c0dd" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in R^n\), i=1,&amp;hellip;, l and a label vector \(y \in R^l\), a decision tree recursively partitions the space such that the samples with the same labels are grouped together.</source>
          <target state="translated">トレーニングベクトル\（x_i \ in R ^ n \）、i = 1、&amp;hellip;、lとラベルベクトル\（y \ in R ^ l \）が与えられると、決定木は空間が再帰的に分割され、同じサンプルがラベルはグループ化されます。</target>
        </trans-unit>
        <trans-unit id="02fd4db44c84fce9026584422f7727ba079bc40a" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, and a vector \(y \in \mathbb{R}^n\)\(\varepsilon\)-SVR solves the following primal problem:</source>
          <target state="translated">与えられたトレーニングベクトル\（x_i \ in \ mathbb {R} ^ p \）、i = 1、&amp;hellip;、n、およびベクトル\（y \ in \ mathbb {R} ^ n \）\（\ varepsilon \）- SVRは次の主要な問題を解決します。</target>
        </trans-unit>
        <trans-unit id="70e397398a5003e0a6b00de067e9804bfe571e70" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, in two classes, and a vector \(y \in \{1, -1\}^n\), SVC solves the following primal problem:</source>
          <target state="translated">与えられたトレーニングベクトル\（x_i \ in \ mathbb {R} ^ p \）、i = 1、&amp;hellip;、n、2つのクラス、およびベクトル\（y \ in \ {1、-1 \} ^ n \） 、SVCは次の主要な問題を解決します。</target>
        </trans-unit>
        <trans-unit id="e43c2f871d10fa4875c4f15e109aeb5faf94fb18" translate="yes" xml:space="preserve">
          <source>Given training vectors \(x_i \in \mathbb{R}^p\), i=1,&amp;hellip;, n, in two classes, and a vector \(y \in \{1, -1\}^n\), our goal is to find \(w \in \mathbb{R}^p\) and \(b \in \mathbb{R}\) such that the prediction given by \(\text{sign} (w^T\phi(x) + b)\) is correct for most samples.</source>
          <target state="translated">与えられたトレーニングベクトル\（x_i \ in \ mathbb {R} ^ p \）、i = 1、&amp;hellip;、n、2つのクラス、およびベクトル\（y \ in \ {1、-1 \} ^ n \） 、私たちの目標は、\（\ text {sign}（w ^ T \ phi（x）+ b）\）は、ほとんどのサンプルで正しいです。</target>
        </trans-unit>
        <trans-unit id="e44bf83eca8aa1cc0c5bdaa89da0afa702f51625" translate="yes" xml:space="preserve">
          <source>Gives the number of (complex) sampling points.</source>
          <target state="translated">(複素数の)サンプリングポイントの数を与えます。</target>
        </trans-unit>
        <trans-unit id="ac4e9c94eac5d688eef08c9122f5d38187b8f922" translate="yes" xml:space="preserve">
          <source>Global min and max average predictions, such that all plots will have the same scale and y limits. &lt;code&gt;pdp_lim[1]&lt;/code&gt; is the global min and max for single partial dependence curves. &lt;code&gt;pdp_lim[2]&lt;/code&gt; is the global min and max for two-way partial dependence curves.</source>
          <target state="translated">すべてのプロットが同じスケールとy制限を持つように、グローバルな最小および最大平均予測。 &lt;code&gt;pdp_lim[1]&lt;/code&gt; は、単一の部分的な依存曲線のグローバルな最小値と最大値です。 &lt;code&gt;pdp_lim[2]&lt;/code&gt; は、双方向の部分依存曲線のグローバルな最小値と最大値です。</target>
        </trans-unit>
        <trans-unit id="f36c7685daa8ebc7e1344aa0d6e3a7d679decebf" translate="yes" xml:space="preserve">
          <source>Global structure is not explicitly preserved. This is problem is mitigated by initializing points with PCA (using &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt;).</source>
          <target state="translated">グローバル構造は明示的に保存されません。これは、PCAでポイントを初期化することで問題が軽減されます（ &lt;code&gt;init=&amp;rsquo;pca&amp;rsquo;&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="01649050ef673ff19d8d011219103526d0d7370d" translate="yes" xml:space="preserve">
          <source>Global structure is not explicitly preserved. This problem is mitigated by initializing points with PCA (using &lt;code&gt;init='pca'&lt;/code&gt;).</source>
          <target state="translated">グローバル構造は明示的に保存されません。この問題は、PCAでポイントを初期化することで軽減されます（ &lt;code&gt;init='pca'&lt;/code&gt; を使用）。</target>
        </trans-unit>
        <trans-unit id="178c27bf7200da0534de904ea7e6ca7da842dbb5" translate="yes" xml:space="preserve">
          <source>Glorot, Xavier, and Yoshua Bengio. &amp;ldquo;Understanding the difficulty of</source>
          <target state="translated">Glorot、Xavier、Yoshua Bengio。「の難しさを理解する</target>
        </trans-unit>
        <trans-unit id="7427cf697be16a4ec1d916910128a59d920125e7" translate="yes" xml:space="preserve">
          <source>Glossary</source>
          <target state="translated">Glossary</target>
        </trans-unit>
        <trans-unit id="f7c22aaad44fb28f4ee8f06d6d4f4f14ac9ce899" translate="yes" xml:space="preserve">
          <source>Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5,</source>
          <target state="translated">ゴルブとC.ヴァンローン。行列計算、第三版、第五章。</target>
        </trans-unit>
        <trans-unit id="1de5b736be2f9def46d07ed88549feeeea5a97b0" translate="yes" xml:space="preserve">
          <source>Gorodkin, (2004). Comparing two K-category assignments by a K-category correlation coefficient</source>
          <target state="translated">Gorodkin,(2004).Kカテゴリ相関係数による2つのKカテゴリ割り当ての比較</target>
        </trans-unit>
        <trans-unit id="46268d41f41f8e1954ca3d54fd29ddb1959ea6db" translate="yes" xml:space="preserve">
          <source>Gradient Boosting Out-of-Bag estimates</source>
          <target state="translated">勾配ブーストのアウトオブバグ推定</target>
        </trans-unit>
        <trans-unit id="ff01958eb0f121764b2210794dcbe435f29dcc7a" translate="yes" xml:space="preserve">
          <source>Gradient Boosting Regression Trees for Poisson regression</source>
          <target state="translated">ポアソン回帰のための勾配ブースト回帰木</target>
        </trans-unit>
        <trans-unit id="9396c57fff04d750ce06a05cfd3c756b4f971532" translate="yes" xml:space="preserve">
          <source>Gradient Boosting also gives the possibility to fit the trees with a Poisson loss (with an implicit log-link function) instead of the default least-squares loss. Here we only fit trees with the Poisson loss to keep this example concise.</source>
          <target state="translated">勾配ブーストでは、デフォルトの最小二乗損失の代わりに、ポアソン損失(暗黙のログリンク関数)を用いて木をフィットすることもできます。ここでは、この例を簡潔にするために、ポアソン損失でのみ木をフィットします。</target>
        </trans-unit>
        <trans-unit id="3e3d95a92c5a33953c001956fd3fd6ac3b1082fa" translate="yes" xml:space="preserve">
          <source>Gradient Boosting attempts to solve this minimization problem numerically via steepest descent: The steepest descent direction is the negative gradient of the loss function evaluated at the current model \(F_{m-1}\) which can be calculated for any differentiable loss function:</source>
          <target state="translated">勾配ブースト法は、この最小化問題を急勾配降下を用いて数値的に解決しようとするものである。最急降下の方向は、現在のモデルで評価された損失関数の負の勾配であり、微分可能な損失関数に対して計算することができます。</target>
        </trans-unit>
        <trans-unit id="be45c92854a0f55592d6c3c1c28201cf75d59d94" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for classification.</source>
          <target state="translated">分類のための勾配ブースト</target>
        </trans-unit>
        <trans-unit id="65fd480d2da13d80eb18643fd08c31b9e5239c9a" translate="yes" xml:space="preserve">
          <source>Gradient Boosting for regression.</source>
          <target state="translated">回帰のための勾配ブースト</target>
        </trans-unit>
        <trans-unit id="23dcf8253cdacbdd915f0e5e69e684c3457ad1df" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regression</source>
          <target state="translated">勾配ブースト回帰</target>
        </trans-unit>
        <trans-unit id="33b1659de13c2a7e036f71b3c26eda1d552a4b1c" translate="yes" xml:space="preserve">
          <source>Gradient Boosting regularization</source>
          <target state="translated">勾配ブースト正則化</target>
        </trans-unit>
        <trans-unit id="a558a9ccdbbb397deb97e7223684a95578fb2ba7" translate="yes" xml:space="preserve">
          <source>Gradient boosting for classification is very similar to the regression case. However, the sum of the trees \(F_M(x_i) = \sum_m h_m(x_i)\) is not homogeneous to a prediction: it cannot be a class, since the trees predict continuous values.</source>
          <target state="translated">分類のための勾配ブーストは、回帰の場合と非常に似ています。しかし,木の和は,予測と同質ではなく,連続的な値を予測しているので,クラスにはなりえない.</target>
        </trans-unit>
        <trans-unit id="cf9557c4e6e59de44aebd2e8b07221ff19e46958" translate="yes" xml:space="preserve">
          <source>Gradient boosting is an ensembling technique where several weak learners (regression trees) are combined to yield a powerful single model, in an iterative fashion.</source>
          <target state="translated">勾配ブーストは、いくつかの弱い学習者(回帰木)を組み合わせて、強力な単一モデルを反復的に生成するアンサンブル技術である。</target>
        </trans-unit>
        <trans-unit id="692996b3838fb57cde4b100ea1ec7f66fff47afe" translate="yes" xml:space="preserve">
          <source>Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when &lt;code&gt;eval_gradient&lt;/code&gt; is True.</source>
          <target state="translated">シータ位置でのカーネルハイパーパラメータに関する対数周辺尤度の勾配。 &lt;code&gt;eval_gradient&lt;/code&gt; がTrueの場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="c4611f197e5e7430aa271445ae503720ad1cf3d4" translate="yes" xml:space="preserve">
          <source>Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True.</source>
          <target state="translated">シータの位置におけるカーネルハイパーパラメータに対する対数倍尤度の勾配。eval_gradientがTrueの場合のみ返される。</target>
        </trans-unit>
        <trans-unit id="e64c4914bb8a27678b7a6969455bd717adc62d09" translate="yes" xml:space="preserve">
          <source>GradientBoostingRegressor</source>
          <target state="translated">GradientBoostingRegressor</target>
        </trans-unit>
        <trans-unit id="e2fb5831cb5dd547c1703af3319394a3f8535468" translate="yes" xml:space="preserve">
          <source>Gram = np.dot(X.T * X).</source>
          <target state="translated">グラム=np.dot(X.T*X)。</target>
        </trans-unit>
        <trans-unit id="f77edae6db0cdcd4449adeeb038c653af7406ea3" translate="yes" xml:space="preserve">
          <source>Gram Orthogonal Matching Pursuit (OMP)</source>
          <target state="translated">グラム直交マッチングパシュート(OMP</target>
        </trans-unit>
        <trans-unit id="10ef9123115df39a65f62ffa3d9d0e10899ca7cd" translate="yes" xml:space="preserve">
          <source>Gram matrix of the input data: X.T * X</source>
          <target state="translated">入力データのグラム行列。X.T*X</target>
        </trans-unit>
        <trans-unit id="a83784084519ce853a92535121a74c85019c19b0" translate="yes" xml:space="preserve">
          <source>Graph distance (e.g. nearest-neighbor graph)</source>
          <target state="translated">グラフの距離(例:最も近い隣のグラフ)</target>
        </trans-unit>
        <trans-unit id="8d5c9a04db77341319c1b38643f0d38066fc8710" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel connections</source>
          <target state="translated">画素間接続のグラフ</target>
        </trans-unit>
        <trans-unit id="1b6f746d097f9fe3740f364d944363a7e3d991f9" translate="yes" xml:space="preserve">
          <source>Graph of the pixel-to-pixel gradient connections</source>
          <target state="translated">ピクセル間のグラデーション接続のグラフ</target>
        </trans-unit>
        <trans-unit id="a291a5c559f789dd92fe83af065257b966fe9953" translate="yes" xml:space="preserve">
          <source>Graph where A[i, j] is assigned the weight of edge that connects i to j. The matrix is of CSR format.</source>
          <target state="translated">A[i,j]にはiとjを結ぶ辺の重みが割り当てられているグラフ。</target>
        </trans-unit>
        <trans-unit id="933bf21afdd55a0d2283845fed0e7bbdd1f5db49" translate="yes" xml:space="preserve">
          <source>Green</source>
          <target state="translated">Green</target>
        </trans-unit>
        <trans-unit id="9786dcbe8afbab8ac93bdfcd6653b6cd7aa7993b" translate="yes" xml:space="preserve">
          <source>Grid of Cs used for cross-validation.</source>
          <target state="translated">クロスバリデーションに使用されるCsのグリッド。</target>
        </trans-unit>
        <trans-unit id="5bd85812ea7e2436359885d902fd71d10cd1c2d9" translate="yes" xml:space="preserve">
          <source>Grid of parameters with a discrete number of values for each.</source>
          <target state="translated">それぞれの値が離散的な数のパラメータのグリッド。</target>
        </trans-unit>
        <trans-unit id="4a6f9190abeab5c3ccde3d9c276bc4db019e7d38" translate="yes" xml:space="preserve">
          <source>Grid search can also be performed on the different preprocessing steps defined in the &lt;code&gt;ColumnTransformer&lt;/code&gt; object, together with the classifier&amp;rsquo;s hyperparameters as part of the &lt;code&gt;Pipeline&lt;/code&gt;. We will search for both the imputer strategy of the numeric preprocessing and the regularization parameter of the logistic regression using &lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">グリッド検索は、 &lt;code&gt;Pipeline&lt;/code&gt; の一部としての分類子のハイパー &lt;code&gt;ColumnTransformer&lt;/code&gt; と共に、ColumnTransformerオブジェクトで定義されたさまざまな前処理ステップで実行することもできます。私たちは、数値の前処理のimputer戦略と使用してロジスティック回帰の正則化パラメータの両方を検索します&lt;a href=&quot;../../modules/generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;sklearn.model_selection.GridSearchCV&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="71a1782f5aa6d2b7cc26a083f91eef66c1cf3aff" translate="yes" xml:space="preserve">
          <source>Grid-search</source>
          <target state="translated">Grid-search</target>
        </trans-unit>
        <trans-unit id="ed926e289de9aa5047e6b09f7b537df04bde4bbf" translate="yes" xml:space="preserve">
          <source>Grid-search and cross-validated estimators</source>
          <target state="translated">グリッド検索と交差検証された推定量</target>
        </trans-unit>
        <trans-unit id="64ba146c44fdd8e95f622a314398320f76845aed" translate="yes" xml:space="preserve">
          <source>GridSearchCV implements a &amp;ldquo;fit&amp;rdquo; and a &amp;ldquo;score&amp;rdquo; method. It also implements &amp;ldquo;predict&amp;rdquo;, &amp;ldquo;predict_proba&amp;rdquo;, &amp;ldquo;decision_function&amp;rdquo;, &amp;ldquo;transform&amp;rdquo; and &amp;ldquo;inverse_transform&amp;rdquo; if they are implemented in the estimator used.</source>
          <target state="translated">GridSearchCVは、「フィット」および「スコア」メソッドを実装します。また、使用する推定器に実装されている場合は、「predict」、「predict_proba」、「decision_function」、「transform」、「inverse_transform」も実装します。</target>
        </trans-unit>
        <trans-unit id="2e6f2bdd92d1c5e33352841cf6b10ed864b19fa7" translate="yes" xml:space="preserve">
          <source>Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification: An Overview. International Journal of Data Warehousing &amp;amp; Mining, 3(3), 1-13, July-September 2007.</source>
          <target state="translated">グリゴリオ・ツォマカス、イオアニス・カタキス。マルチラベル分類：概要。International Journal of Data Warehousing＆Mining、3（3）、1-13、July-September 2007。</target>
        </trans-unit>
        <trans-unit id="796325c68f51f69a2afcc84a9fb61fa1d8420435" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels for n_samples samples.</source>
          <target state="translated">n_samplesサンプルの基底真理(正しい)ラベル。</target>
        </trans-unit>
        <trans-unit id="740dd68aa13d511b42941c79135a52aa5a0f5bc4" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) labels.</source>
          <target state="translated">根拠のある真実(正しい)のラベル。</target>
        </trans-unit>
        <trans-unit id="cf154969e860842a471602bf65b740057751e47b" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values.</source>
          <target state="translated">根拠のある真実(正しい)目標値。</target>
        </trans-unit>
        <trans-unit id="b29893e6134ceb0ae63100b750ea64cd6227af16" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values. Requires y_true &amp;gt; 0.</source>
          <target state="translated">グラウンドトゥルース（正しい）ターゲット値。y_true&amp;gt; 0が必要です。</target>
        </trans-unit>
        <trans-unit id="8dcf4476037b86142a6c723cc6d58c74ce6fa30f" translate="yes" xml:space="preserve">
          <source>Ground truth (correct) target values. Requires y_true &amp;gt;= 0.</source>
          <target state="translated">グラウンドトゥルース（正しい）ターゲット値。y_true&amp;gt; = 0が必要です。</target>
        </trans-unit>
        <trans-unit id="691f624e8ff75b4d50175631f407699ccfb7e35d" translate="yes" xml:space="preserve">
          <source>Ground truth class labels to be used as a reference</source>
          <target state="translated">参照として使用する基底真理クラスのラベル</target>
        </trans-unit>
        <trans-unit id="2859baca63ac3255284d20bc28f887a4c54fefb4" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set.</source>
          <target state="translated">データセットを訓練/テストセットに分割する際に使用するサンプルのグループラベル。</target>
        </trans-unit>
        <trans-unit id="da0d044e30ddccc2bad0f6e17da06a788ea2385a" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set. Only used in conjunction with a &amp;ldquo;Group&amp;rdquo; &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; instance (e.g., &lt;a href=&quot;sklearn.model_selection.groupkfold#sklearn.model_selection.GroupKFold&quot;&gt;&lt;code&gt;GroupKFold&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">データセットをトレイン/テストセットに分割するときに使用されるサンプルのラベルをグループ化します。「グループ」&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt;インスタンス（&lt;a href=&quot;sklearn.model_selection.groupkfold#sklearn.model_selection.GroupKFold&quot;&gt; &lt;code&gt;GroupKFold&lt;/code&gt; など&lt;/a&gt;）と組み合わせてのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="f5ee660cf40b3d432d2833cbe2c4255cb71b873d" translate="yes" xml:space="preserve">
          <source>Group labels for the samples used while splitting the dataset into train/test set. This &amp;lsquo;groups&amp;rsquo; parameter must always be specified to calculate the number of splits, though the other parameters can be omitted.</source>
          <target state="translated">データセットをトレーニング/テストセットに分割するときに使用されるサンプルのグループラベル。分割数を計算するには、この「グループ」パラメーターを常に指定する必要がありますが、他のパラメーターは省略できます。</target>
        </trans-unit>
        <trans-unit id="2fe58cc1aca321453c1632eb3218b2ee2034ed27" translate="yes" xml:space="preserve">
          <source>Grow a tree with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">&lt;code&gt;max_leaf_nodes&lt;/code&gt; を使用して、ツリーを最初の方法で成長させます。最良のノードは、不純物の相対的な減少として定義されます。Noneの場合、リーフノードの数に制限はありません。</target>
        </trans-unit>
        <trans-unit id="9f319cd9d13cdc03649579ff252c6b96c720508d" translate="yes" xml:space="preserve">
          <source>Grow trees with &lt;code&gt;max_leaf_nodes&lt;/code&gt; in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</source>
          <target state="translated">&lt;code&gt;max_leaf_nodes&lt;/code&gt; を使用してツリーを最高の方法で成長させます。最良のノードは、不純物の相対的な減少として定義されます。 Noneの場合、リーフノードの数に制限はありません。</target>
        </trans-unit>
        <trans-unit id="bf073fae640ded81eeb7a4cee70faff4a623c16c" translate="yes" xml:space="preserve">
          <source>Guide</source>
          <target state="translated">Guide</target>
        </trans-unit>
        <trans-unit id="1fd932db6b504d046b60a30c3273eb39ba2ac7a5" translate="yes" xml:space="preserve">
          <source>Guyon, I., Weston, J., Barnhill, S., &amp;amp; Vapnik, V., &amp;ldquo;Gene selection for cancer classification using support vector machines&amp;rdquo;, Mach. Learn., 46(1-3), 389&amp;ndash;422, 2002.</source>
          <target state="translated">Guyon、I.、Weston、J.、Barnhill、S。、およびVapnik、V。、「サポートベクターマシンを使用した癌分類のための遺伝子選択」、Mach。Learn。、46（1-3）、389&amp;ndash;422、2002。</target>
        </trans-unit>
        <trans-unit id="dd4d457c816b0cb358c91f5b8813986bac26cb3d" translate="yes" xml:space="preserve">
          <source>H. Zhang (2004). &lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;The optimality of Naive Bayes.&lt;/a&gt; Proc. FLAIRS.</source>
          <target state="translated">H. Zhang（2004）。&lt;a href=&quot;http://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;ナイーブベイズの最適性。&lt;/a&gt;手続き FLAIRS。</target>
        </trans-unit>
        <trans-unit id="ce3bde746d403806636c8d155597ef91ca7e1f03" translate="yes" xml:space="preserve">
          <source>H. Zhang (2004). &lt;a href=&quot;https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;The optimality of Naive Bayes.&lt;/a&gt; Proc. FLAIRS.</source>
          <target state="translated">H.チャン（2004）。&lt;a href=&quot;https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf&quot;&gt;ナイーブベイズの最適性。&lt;/a&gt;手順 フレア。</target>
        </trans-unit>
        <trans-unit id="de489f31c1f185d4a81f0399ead4e066a95b91be" translate="yes" xml:space="preserve">
          <source>HTML representation of &lt;code&gt;Pipeline&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;Pipeline&lt;/code&gt; HTML表現</target>
        </trans-unit>
        <trans-unit id="d930a6037b9120a42017959402d9dc27dd6bf69c" translate="yes" xml:space="preserve">
          <source>HTML representation of estimator.</source>
          <target state="translated">エスティメーターのHTML表現。</target>
        </trans-unit>
        <trans-unit id="f5b6915b0e377ea69d7b62d27d3f027cc63657d7" translate="yes" xml:space="preserve">
          <source>Hagai Attias. (2000). &amp;ldquo;A Variational Bayesian Framework for Graphical Models&amp;rdquo;. In Advances in Neural Information Processing Systems 12.</source>
          <target state="translated">Hagai Attias。（2000）。「グラフィカルモデルの変分ベイズフレームワーク」。ニューラル情報処理システムの進歩12。</target>
        </trans-unit>
        <trans-unit id="8446ed65374f4c03b547ffebe7ab69437207be78" translate="yes" xml:space="preserve">
          <source>Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). &amp;ldquo;On Clustering Validation Techniques&amp;rdquo; Journal of Intelligent Information Systems, 17(2-3), 107-145. &lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;doi:10.1023/A:1012801612483&lt;/a&gt;.</source>
          <target state="translated">ハルキディ、マリア; バチスタキス、ヤニス。Vazirgiannis、Michalis（2001）。「クラスタリング検証手法について」Journal of Intelligent Information Systems、17（2-3）、107-145。&lt;a href=&quot;http://dx.doi.org/10.1023/A:1012801612483&quot;&gt;doi：10.1023 / A：1012801612483&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="959a6f4c185bd74a74d43205ed3cc9281eca4d45" translate="yes" xml:space="preserve">
          <source>Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). &amp;ldquo;On Clustering Validation Techniques&amp;rdquo; Journal of Intelligent Information Systems, 17(2-3), 107-145. &lt;a href=&quot;https://doi.org/10.1023/A:1012801612483&quot;&gt;doi:10.1023/A:1012801612483&lt;/a&gt;.</source>
          <target state="translated">ハルキディ、マリア; バティスタキス、ヤニス; Vazirgiannis、Michalis（2001）。「クラスタリング検証手法について」Journalof Intelligent Information Systems、17（2-3）、107-145。&lt;a href=&quot;https://doi.org/10.1023/A:1012801612483&quot;&gt;doi：10.1023 / A：1012801612483&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="57fe625410e680c160d128700bfb1af1b965809e" translate="yes" xml:space="preserve">
          <source>HammingDistance</source>
          <target state="translated">HammingDistance</target>
        </trans-unit>
        <trans-unit id="9757089e5251a143827d61ff72e389c7fd386869" translate="yes" xml:space="preserve">
          <source>Hand, D.J. and Till, R.J., (2001). &lt;a href=&quot;http://link.springer.com/article/10.1023/A:1010920819831&quot;&gt;A simple generalisation of the area under the ROC curve for multiple class classification problems.&lt;/a&gt; Machine learning, 45(2), pp.171-186.</source>
          <target state="translated">Hand、DJ and Till、RJ、（2001）。&lt;a href=&quot;http://link.springer.com/article/10.1023/A:1010920819831&quot;&gt;複数のクラス分類問題のROC曲線の下の領域の単純な一般化。&lt;/a&gt;機械学習、45（2）、pp.171-186。</target>
        </trans-unit>
        <trans-unit id="88b6ef37ba2f9ba619bbf453c13dce1665119f21" translate="yes" xml:space="preserve">
          <source>Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems. Machine Learning, 45(2), 171-186.</source>
          <target state="translated">複数クラス分類問題に対するROC曲線下面積の単純な一般化.機械学習,45(2),171-186.</target>
        </trans-unit>
        <trans-unit id="dee17735ec3038cb9f5dda5413031eefdf59071a" translate="yes" xml:space="preserve">
          <source>Handle or name of the output file. If &lt;code&gt;None&lt;/code&gt;, the result is returned as a string.</source>
          <target state="translated">出力ファイルのハンドルまたは名前。場合 &lt;code&gt;None&lt;/code&gt; 、結果は文字列として返されます。</target>
        </trans-unit>
        <trans-unit id="528b68d16981ccbe32f7d51bc822d75e077c8b80" translate="yes" xml:space="preserve">
          <source>Handling Multicollinear Features</source>
          <target state="translated">マルチコリニア機能の取り扱い</target>
        </trans-unit>
        <trans-unit id="077bb86f8a4736a0992a0b108c1d4b8e9298e04f" translate="yes" xml:space="preserve">
          <source>Hard constraint to select the backend. If set to &amp;lsquo;sharedmem&amp;rsquo;, the selected backend will be single-host and thread-based even if the user asked for a non-thread based backend with parallel_backend.</source>
          <target state="translated">バックエンドを選択するためのハード制約。'sharedmem'に設定すると、ユーザーがparallel_backendで非スレッドベースのバックエンドを要求した場合でも、選択されたバックエンドは単一ホストでスレッドベースになります。</target>
        </trans-unit>
        <trans-unit id="9b9156693e970a15a3c18a9425374c7bf2903574" translate="yes" xml:space="preserve">
          <source>Hard limit on iterations within solver, or -1 for no limit.</source>
          <target state="translated">ソルバー内での繰り返しのハードリミット、またはリミットがない場合は-1。</target>
        </trans-unit>
        <trans-unit id="73dd008516fbc283773051e5943e3b658488b1b1" translate="yes" xml:space="preserve">
          <source>Harrison, D. and Rubinfeld, D.L.</source>
          <target state="translated">ハリソン、D.とルビンフェルド、D.L.</target>
        </trans-unit>
        <trans-unit id="c23f4e8aad7e2235e0ebdbc3c9d2bf9b602d6e3d" translate="yes" xml:space="preserve">
          <source>Hash function g(p,x) for a tree is an array of 32 randomly generated float arrays with the same dimension as the data set. This array is stored in GaussianRandomProjectionHash object and can be obtained from &lt;code&gt;components_&lt;/code&gt; attribute.</source>
          <target state="translated">ツリーのハッシュ関数g（p、x）は、データセットと同じ次元を持つ32個のランダムに生成されたfloat配列の配列です。この配列はGaussianRandomProjectionHashオブジェクトに格納され、 &lt;code&gt;components_&lt;/code&gt; 属性から取得できます。</target>
        </trans-unit>
        <trans-unit id="8b5d87d4a16c0b826cb8988befd77a0e52c765c1" translate="yes" xml:space="preserve">
          <source>Hashing feature transformation using Totally Random Trees</source>
          <target state="translated">完全ランダム木を用いた特徴量のハッシュ化変換</target>
        </trans-unit>
        <trans-unit id="717a562588a8bf4bd25fb65069c4d3192c7a16dc" translate="yes" xml:space="preserve">
          <source>HashingVectorizer does not provide IDF weighting as this is a stateless model (the fit method does nothing). When IDF weighting is needed it can be added by pipelining its output to a TfidfTransformer instance.</source>
          <target state="translated">HashingVectorizerはステートレスモデルなので、IDF重み付けを提供しません(フィットメソッドは何もしません)。IDF重み付けが必要な場合は、その出力をTfidfTransformerインスタンスにパイプライニングすることで追加することができます。</target>
        </trans-unit>
        <trans-unit id="d06cc92706967f16b8b9c95848cf5aff7ec1c456" translate="yes" xml:space="preserve">
          <source>HashingVectorizer hashes word occurrences to a fixed dimensional space, possibly with collisions. The word count vectors are then normalized to each have l2-norm equal to one (projected to the euclidean unit-ball) which seems to be important for k-means to work in high dimensional space.</source>
          <target state="translated">HashingVectorizerは,単語の出現を固定次元空間にハッシュします.これは,高次元空間でk-meansが動作するために重要であると考えられています.</target>
        </trans-unit>
        <trans-unit id="28041ffc119d6685560d28cedcd34e917cd495e5" translate="yes" xml:space="preserve">
          <source>Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">Hastie、R。TibshiraniおよびJ. Friedman、「Elements of Statistical Learning Ed。2インチ、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="9803f456bd9f04731b6843d220c5ae89fa289aa2" translate="yes" xml:space="preserve">
          <source>Haussler, D. (1999). Convolution kernels on discrete structures (Vol. 646). Technical report, Department of Computer Science, University of California at Santa Cruz.</source>
          <target state="translated">Haussler,D.(1999).離散構造上のコンボリューションカーネル(第646巻).カリフォルニア大学サンタクルス校コンピュータサイエンス学科の技術報告書。</target>
        </trans-unit>
        <trans-unit id="b8dd0d155e19e8a71f19b1bbe40cdccabf151805" translate="yes" xml:space="preserve">
          <source>Have a look at the &lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt; as a memory efficient alternative to &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; に&lt;/a&gt;代わるメモリ効率の良い方法として、&lt;a href=&quot;../../modules/feature_extraction#hashing-vectorizer&quot;&gt;Hashing Vectorizer&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="a899619755f5d06da20b9b2964b88739a1ab106e" translate="yes" xml:space="preserve">
          <source>Have a look at using &lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core Classification&lt;/a&gt; to learn from data that would not fit into the computer main memory.</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/applications/plot_out_of_core_classification#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py&quot;&gt;Out-of-core Classification&lt;/a&gt;を使用して、コンピューターのメインメモリに収まらないデータから学習する方法をご覧ください。</target>
        </trans-unit>
        <trans-unit id="27a688f240efc4c1f8111e73298dc1d5dd7e9964" translate="yes" xml:space="preserve">
          <source>HaversineDistance</source>
          <target state="translated">HaversineDistance</target>
        </trans-unit>
        <trans-unit id="260c7f8bcac0cff0858b268328a3c57270e6d05b" translate="yes" xml:space="preserve">
          <source>He, Kaiming, et al. &amp;ldquo;Delving deep into rectifiers: Surpassing human-level</source>
          <target state="translated">彼、Kaiming、他。「整流器の詳細：人間レベルを超える</target>
        </trans-unit>
        <trans-unit id="2f8a00b4f7c2990e23253c9271642cb45a1f2224" translate="yes" xml:space="preserve">
          <source>Helper class for readable parallel mapping.</source>
          <target state="translated">読み取り可能な並列マッピングのためのヘルパークラスです。</target>
        </trans-unit>
        <trans-unit id="15e3ecfce92d858c5fac5d21e2153dba45c36e72" translate="yes" xml:space="preserve">
          <source>Helper function to test the message raised in an exception.</source>
          <target state="translated">例外で発生したメッセージをテストするためのヘルパー関数です。</target>
        </trans-unit>
        <trans-unit id="e22b8152bb5ec7ad5480951d5d1692b1809abba4" translate="yes" xml:space="preserve">
          <source>Hence using random projections on the digits dataset which only has 64 features in the input space does not make sense: it does not allow for dimensionality reduction in this case.</source>
          <target state="translated">したがって,入力空間に64個の特徴しかない桁のデータセットにランダム投影を使っても意味がありません.</target>
        </trans-unit>
        <trans-unit id="858c4ba42a503184b8af0061cb8145e1add6548c" translate="yes" xml:space="preserve">
          <source>Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:</source>
          <target state="translated">そのため、学習コーパスで見られなかった単語は、今後の変換メソッドの呼び出しでは完全に無視されます。</target>
        </trans-unit>
        <trans-unit id="3fea43b2d3bbf05cef0fdbdec4ca7b01a2de9eb5" translate="yes" xml:space="preserve">
          <source>Hence, the None case results in:</source>
          <target state="translated">したがって、Noneの場合は、結果として</target>
        </trans-unit>
        <trans-unit id="4fffc6a6ec537bad9c19e154df4fbf4c1dee1839" translate="yes" xml:space="preserve">
          <source>Here &lt;code&gt;func&lt;/code&gt; is a function which takes two one-dimensional numpy arrays, and returns a distance. Note that in order to be used within the BallTree, the distance must be a true metric: i.e. it must satisfy the following properties</source>
          <target state="translated">ここで &lt;code&gt;func&lt;/code&gt; は、2つの1次元のnumpy配列を取り、距離を返す関数です。BallTree内で使用するには、距離が真のメトリックでなければならないことに注意してください。つまり、次のプロパティを満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="8918252717f29fe05952e0490941948a7c1afcd2" translate="yes" xml:space="preserve">
          <source>Here a sine function is fit with a polynomial of order 3, for values close to zero.</source>
          <target state="translated">ここでは、ゼロに近い値に対して、次数3の多項式で正弦関数がフィットします。</target>
        </trans-unit>
        <trans-unit id="dd2684d229285b3b1a04454d9cd068cd1e054408" translate="yes" xml:space="preserve">
          <source>Here a small example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a binary class problem:</source>
          <target state="translated">ここでは、バイナリクラスの問題でsvm分類&lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt;使用してHinge_loss関数を使用する方法を示す小さな例を示します。</target>
        </trans-unit>
        <trans-unit id="5113795d86cf9b1916006aecdb0ceee73192da33" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the Gaussian random projection transformer:</source>
          <target state="translated">ここでは、ガウスランダム射影変換器の使い方を説明しています。</target>
        </trans-unit>
        <trans-unit id="d838251a264bfc0a86e50e7c2f5d9ef6f54d10aa" translate="yes" xml:space="preserve">
          <source>Here a small excerpt which illustrates how to use the sparse random projection transformer:</source>
          <target state="translated">ここでは,疎なランダム射影変換器の使い方を説明しています.</target>
        </trans-unit>
        <trans-unit id="32f51b9dd909238771016da8eae995fa183bb752" translate="yes" xml:space="preserve">
          <source>Here are a few suggestions to help further your scikit-learn intuition upon the completion of this tutorial:</source>
          <target state="translated">このチュートリアルが終了したときに、あなたの scikit-learn の直観力をさらに高めるためのいくつかの提案がここにあります。</target>
        </trans-unit>
        <trans-unit id="3dda6ea8d57e795e10f1bb02b3e190ba1eee1ee3" translate="yes" xml:space="preserve">
          <source>Here are some examples demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function to calculate recall (or sensitivity), specificity, fall out and miss rate for each class in a problem with multilabel indicator matrix input.</source>
          <target state="translated">以下は、&lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt; &lt;code&gt;multilabel_confusion_matrix&lt;/code&gt; &lt;/a&gt;関数を使用して、マルチラベルインジケーターマトリックス入力の問題における各クラスの再現率（または感度）、特異度、フォールアウト、およびミス率を計算する方法を示すいくつかの例です。</target>
        </trans-unit>
        <trans-unit id="8d2ed57227d29b030e11d07a6ad14619156d6baa" translate="yes" xml:space="preserve">
          <source>Here are some recommended ways to load standard columnar data into a format usable by scikit-learn:</source>
          <target state="translated">ここでは、標準的な柱状データを scikit-learn で使用可能な形式にロードするための推奨される方法をいくつか紹介します。</target>
        </trans-unit>
        <trans-unit id="6caa2e3f5fa319efda163f3ada59f70b9af4251d" translate="yes" xml:space="preserve">
          <source>Here are some small examples in binary classification:</source>
          <target state="translated">ここでは、二値分類の小さな例を紹介します。</target>
        </trans-unit>
        <trans-unit id="cad58f968788a0c8b830200526f46c2e8380af6d" translate="yes" xml:space="preserve">
          <source>Here is a list of incremental estimators for different tasks:</source>
          <target state="translated">ここでは、さまざまなタスクのインクリメンタル・エスティメー タのリストを示します。</target>
        </trans-unit>
        <trans-unit id="e5cc3ef05cd44a377ff0113c5a0144a6cd05b3f4" translate="yes" xml:space="preserve">
          <source>Here is a sample output of a run on a quad-core machine:</source>
          <target state="translated">クアッドコアマシンで実行した場合の出力サンプルです。</target>
        </trans-unit>
        <trans-unit id="00dac27806e77f637d738445566eb627365e0881" translate="yes" xml:space="preserve">
          <source>Here is a sketch of a system designed to achieve this goal:</source>
          <target state="translated">この目標を達成するために設計されたシステムのスケッチです。</target>
        </trans-unit>
        <trans-unit id="c595619fa24f58ee3930e8429960f874f9b329e7" translate="yes" xml:space="preserve">
          <source>Here is a small example illustrating the usage of the &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">以下は、&lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; &lt;/a&gt;関数の使用法を示す小さな例です。</target>
        </trans-unit>
        <trans-unit id="423aaa3f8753fc630af578bc1fbb46728b5a06e5" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">次に、&lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt;関数の使用例をいくつか示します。</target>
        </trans-unit>
        <trans-unit id="1875c837ecf1df623da5e8546dcb195bb9e83c64" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt; &lt;code&gt;max_error&lt;/code&gt; &lt;/a&gt;関数の使用例を次に示します。</target>
        </trans-unit>
        <trans-unit id="cb41f576a02130e8636700bae5b58c941781076b" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">以下は、&lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt;関数の使用例です。</target>
        </trans-unit>
        <trans-unit id="7c0ba7d72bd4599fa8b6676ec86f846e3705f7da" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">以下は、&lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt;関数の使用例です。</target>
        </trans-unit>
        <trans-unit id="0be0450f469be9534c036908ab2afdbd59b24548" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">以下は、&lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; &lt;/a&gt;関数の使用例です。</target>
        </trans-unit>
        <trans-unit id="f8da86e09b21d704ee9aa6f7fcb4b0cf6258a18d" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">次に、&lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; &lt;/a&gt;関数の使用例をいくつか示します。</target>
        </trans-unit>
        <trans-unit id="e0060b4a19332fa9cdf176d47debc4e3de22af1f" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of the &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">次に、&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt;関数の使用例をいくつか示します。</target>
        </trans-unit>
        <trans-unit id="2121874e07dc9ac1fb205417370f94e728d5e5e6" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function:</source>
          <target state="translated">この関数の使用例を少しだけご紹介します。</target>
        </trans-unit>
        <trans-unit id="f03ea6f9a5b7db0b84376e166dbfe9d87d690fa9" translate="yes" xml:space="preserve">
          <source>Here is a small example of usage of this function::</source>
          <target state="translated">この関数の使用例を以下に示します。</target>
        </trans-unit>
        <trans-unit id="da9291cb119f102218681b72119ede84a1e93115" translate="yes" xml:space="preserve">
          <source>Here is a usage example:</source>
          <target state="translated">使用例をご紹介します。</target>
        </trans-unit>
        <trans-unit id="ec46f6fe41e667dcb81fcf9a89e2aaf0a6763af5" translate="yes" xml:space="preserve">
          <source>Here is a visual representation of such a confusion matrix (this figure comes from the &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; example):</source>
          <target state="translated">以下は、このような混同行列を視覚的に表したものです（この図は、&lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;混同行列の&lt;/a&gt;例からのものです）。</target>
        </trans-unit>
        <trans-unit id="876abdb2188ee5022ae84c77928e2082f05a478c" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior.</source>
          <target state="translated">クロスバリデーションの動作を可視化したものです。</target>
        </trans-unit>
        <trans-unit id="d5a8fd11bd11ae3f4eb764b39ba1acfee92579af" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">これは、相互検証動作の視覚化です。&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;はクラスやグループの影響を受けないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="e10cd61d7e44ad9e6bb0d4cec30745248d4c4e93" translate="yes" xml:space="preserve">
          <source>Here is a visualization of the cross-validation behavior. Note that &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; is not affected by classes or groups.</source>
          <target state="translated">これは、相互検証動作の視覚化です。&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt;はクラスやグループの影響を受けないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="0b166c480658b240c273df0a43ce9ffa8405561c" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function with a svm classifier in a multiclass problem:</source>
          <target state="translated">以下は、マルチクラス問題でのsvm分類器での&lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt;関数の使用を示す例です。</target>
        </trans-unit>
        <trans-unit id="01baca5f1060ff615b57707b27b89349c3831f22" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function with &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;multiclass&lt;/a&gt; input:</source>
          <target state="translated">これは、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multiclass&quot;&gt;マルチクラス&lt;/a&gt;入力での&lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt; &lt;code&gt;multilabel_confusion_matrix&lt;/code&gt; &lt;/a&gt;関数の使用を示す例です。</target>
        </trans-unit>
        <trans-unit id="ac06b69a6bbd9ae081c446d18662dd3517d588fd" translate="yes" xml:space="preserve">
          <source>Here is an example demonstrating the use of the &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function with &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multilabel-indicator-matrix&quot;&gt;multilabel indicator matrix&lt;/a&gt; input:</source>
          <target state="translated">これは、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-multilabel-indicator-matrix&quot;&gt;マルチラベルインジケーターマトリックス&lt;/a&gt;入力での&lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt; &lt;code&gt;multilabel_confusion_matrix&lt;/code&gt; &lt;/a&gt;関数の使用を示す例です。</target>
        </trans-unit>
        <trans-unit id="58bc8e3595ba3624485387b6def524d2d31bae65" translate="yes" xml:space="preserve">
          <source>Here is an example of &lt;code&gt;cross_validate&lt;/code&gt; using a single metric:</source>
          <target state="translated">以下は、単一のメトリックを使用した &lt;code&gt;cross_validate&lt;/code&gt; の例です。</target>
        </trans-unit>
        <trans-unit id="f7e50cdf4078c7823c206e72ce0bf5486f1e2a9f" translate="yes" xml:space="preserve">
          <source>Here is an example of applying this idea to one-dimensional data, using polynomial features of varying degrees:</source>
          <target state="translated">次数の異なる多項式特徴量を使用して、このアイデアを一次元データに適用した例を紹介します。</target>
        </trans-unit>
        <trans-unit id="8375acd14d3c16b75f14ad4cf9799bf09154cba1" translate="yes" xml:space="preserve">
          <source>Here is an example of building custom scorers, and of using the &lt;code&gt;greater_is_better&lt;/code&gt; parameter:</source>
          <target state="translated">カスタムスコアラーを作成し、 &lt;code&gt;greater_is_better&lt;/code&gt; パラメーターを使用する例を次に示します。</target>
        </trans-unit>
        <trans-unit id="3be41bccb12847b90804b0be88468f33593d4dc5" translate="yes" xml:space="preserve">
          <source>Here is an example of stratified 3-fold cross-validation on a dataset with 50 samples from two unbalanced classes. We show the number of samples in each class and compare with &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは、2つの不均衡なクラスからの50個のサンプルを含むデータセットでの層化3分割交差検定の例です。各クラスのサンプル数を示し、&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;と比較します。</target>
        </trans-unit>
        <trans-unit id="120ffb4ca9b2da814644df8eb634b8cef584b2a0" translate="yes" xml:space="preserve">
          <source>Here is an example to scale a toy data matrix to the &lt;code&gt;[0, 1]&lt;/code&gt; range:</source>
          <target state="translated">以下は、おもちゃのデータマトリックスを &lt;code&gt;[0, 1]&lt;/code&gt; 範囲にスケーリングする例です。</target>
        </trans-unit>
        <trans-unit id="04b3257d3ad37f9ca0ccbd79a367325c6e1ed5f4" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt; with the &lt;code&gt;elasticnet&lt;/code&gt; penalty. The regularization strength is globally controlled by the &lt;code&gt;alpha&lt;/code&gt; parameter. With a sufficiently high &lt;code&gt;alpha&lt;/code&gt;, one can then increase the &lt;code&gt;l1_ratio&lt;/code&gt; parameter of &lt;code&gt;elasticnet&lt;/code&gt; to enforce various levels of sparsity in the model coefficients. Higher sparsity here is interpreted as less model complexity as we need fewer coefficients to describe it fully. Of course sparsity influences in turn the prediction time as the sparse dot-product takes time roughly proportional to the number of non-zero coefficients.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;elasticnet&lt;/code&gt; ペナルティを伴うsklearn.linear_model.SGDClassifierを使用した例です。正則化の強さは、 &lt;code&gt;alpha&lt;/code&gt; パラメーターによってグローバルに制御されます。 &lt;code&gt;alpha&lt;/code&gt; が十分に高い場合は、 &lt;code&gt;l1_ratio&lt;/code&gt; パラメーターを &lt;code&gt;elasticnet&lt;/code&gt; て、モデル係数にさまざまなレベルのスパース性を適用できます。ここでのスパース性が高いほど、完全に記述するために必要な係数が少ないため、モデルの複雑さが少ないと解釈されます。もちろん、スパースドット積はゼロ以外の係数の数にほぼ比例して時間がかかるため、スパース性は予測時間に影響を与えます。</target>
        </trans-unit>
        <trans-unit id="8f89ae42a83e786b17cd6f1b83024799754e5687" translate="yes" xml:space="preserve">
          <source>Here is an example using &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; with the &lt;code&gt;elasticnet&lt;/code&gt; penalty. The regularization strength is globally controlled by the &lt;code&gt;alpha&lt;/code&gt; parameter. With a sufficiently high &lt;code&gt;alpha&lt;/code&gt;, one can then increase the &lt;code&gt;l1_ratio&lt;/code&gt; parameter of &lt;code&gt;elasticnet&lt;/code&gt; to enforce various levels of sparsity in the model coefficients. Higher sparsity here is interpreted as less model complexity as we need fewer coefficients to describe it fully. Of course sparsity influences in turn the prediction time as the sparse dot-product takes time roughly proportional to the number of non-zero coefficients.</source>
          <target state="translated">以下は、 &lt;code&gt;elasticnet&lt;/code&gt; ペナルティで &lt;code&gt;sklearn.linear_model.stochastic_gradient.SGDClassifier&lt;/code&gt; を使用する例です。正則化の強度は、 &lt;code&gt;alpha&lt;/code&gt; パラメーターによってグローバルに制御されます。 &lt;code&gt;alpha&lt;/code&gt; が十分に高い場合、 &lt;code&gt;l1_ratio&lt;/code&gt; パラメータを &lt;code&gt;elasticnet&lt;/code&gt; て、モデル係数にさまざまなレベルのスパース性を適用できます。ここでスパース性が高いと、モデルを完全に記述するために必要な係数が少なくなるため、モデルの複雑さが少なくなると解釈されます。もちろん、スパースドット積は非ゼロ係数の数にほぼ比例して時間がかかるため、スパース性は予測時間に影響します。</target>
        </trans-unit>
        <trans-unit id="540ee2aaf7182c6dfc449b18e5accb694e3b0894" translate="yes" xml:space="preserve">
          <source>Here is an example:</source>
          <target state="translated">ここでは一例を紹介します。</target>
        </trans-unit>
        <trans-unit id="a1ce1cc95adf7777aaf8483ebc72e46f7e0c5dd5" translate="yes" xml:space="preserve">
          <source>Here is how to use the toy data from the previous example with this scaler:</source>
          <target state="translated">先ほどのおもちゃのデータをこのスケーラーで使う方法をご紹介します。</target>
        </trans-unit>
        <trans-unit id="da00252cb105e8e07c4719d8131543c2597c6b64" translate="yes" xml:space="preserve">
          <source>Here is sample code that illustrates the use of the &lt;code&gt;sparsify()&lt;/code&gt; method:</source>
          <target state="translated">&lt;code&gt;sparsify()&lt;/code&gt; メソッドの使用法を示すサンプルコードを次に示します。</target>
        </trans-unit>
        <trans-unit id="b1b76d97b9ed98e3661e06b53d247e6f552362c3" translate="yes" xml:space="preserve">
          <source>Here is sample code to test the sparsity of your input:</source>
          <target state="translated">ここでは、入力の分散性をテストするためのサンプルコードを示します。</target>
        </trans-unit>
        <trans-unit id="7a4f1fdf399f62578619e41a5fba4a345597683a" translate="yes" xml:space="preserve">
          <source>Here is the list of models benefiting from the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) for automated model selection:</source>
          <target state="translated">ここでは、自動モデル選択のための赤池情報基準(AIC)またはベイズ情報基準(BIC)の恩恵を受けるモデルの一覧です。</target>
        </trans-unit>
        <trans-unit id="24d46233c5b1cf5947d798926d1e317b272fc656" translate="yes" xml:space="preserve">
          <source>Here is the list of such models:</source>
          <target state="translated">そんな機種の一覧です。</target>
        </trans-unit>
        <trans-unit id="757c8807092bec583b3c00400f122f638dd1b02a" translate="yes" xml:space="preserve">
          <source>Here one can observe that the train accuracy is very high (the forest model has enough capacity to completely memorize the training set) but it can still generalize well enough to the test set thanks to the built-in bagging of random forests.</source>
          <target state="translated">ここでは、訓練精度が非常に高いことがわかります(森林モデルは訓練セットを完全に記憶するのに十分な能力を持っています)が、ランダムフォレストの組み込みのバッキングのおかげで、テストセットに対して十分に一般化することができます。</target>
        </trans-unit>
        <trans-unit id="15f3441e24a8e858a11c375d5c2fee3bc8aa09ba" translate="yes" xml:space="preserve">
          <source>Here our goal goal is to predict the expected value, i.e. the mean, of the total claim amount per exposure unit also referred to as the pure premium.</source>
          <target state="translated">ここでは、私たちの目標は、純粋な保険料とも呼ばれる 1 口当たりの総請求額の期待値、すなわち平均値を予測することです。</target>
        </trans-unit>
        <trans-unit id="785dc58756e0e128c51d97262d985997dfc75263" translate="yes" xml:space="preserve">
          <source>Here the &lt;code&gt;transform&lt;/code&gt; operation returns \(LX^T\), therefore its time complexity equals &lt;code&gt;n_components * n_features * n_samples_test&lt;/code&gt;. There is no added space complexity in the operation.</source>
          <target state="translated">ここで、 &lt;code&gt;transform&lt;/code&gt; 操作は\（LX ^ T \）を返すため、その時間計算量は &lt;code&gt;n_components * n_features * n_samples_test&lt;/code&gt; 等しくなります。操作に追加のスペースの複雑さはありません。</target>
        </trans-unit>
        <trans-unit id="8029b08717fd12d596415c9951c99ad442611512" translate="yes" xml:space="preserve">
          <source>Here the computation is achieved thanks to Martinsson&amp;rsquo;s Randomized SVD algorithm implemented in scikit-learn.</source>
          <target state="translated">ここでは、scikit-learnに実装されたMartinssonのランダム化SVDアルゴリズムのおかげで計算が行われます。</target>
        </trans-unit>
        <trans-unit id="baa6fd34087f3f3b80a068e5198c152eb2224084" translate="yes" xml:space="preserve">
          <source>Here the results are not as good as they could be as our choice for the regularization parameter C was not the best. In real life applications this parameter is usually chosen using &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;Tuning the hyper-parameters of an estimator&lt;/a&gt;.</source>
          <target state="translated">ここでは、正則化パラメーターCの選択が最良ではなかったので、結果は良い結果にはなりません。実際のアプリケーションでは、このパラメーターは通常&lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;、推定器のハイパーパラメーターの調整&lt;/a&gt;を使用して選択されます。</target>
        </trans-unit>
        <trans-unit id="e33a1b9fd8981a72cf8c17c638c489933e2535f4" translate="yes" xml:space="preserve">
          <source>Here we choose the SAGA solver because it can efficiently optimize for the Logistic Regression loss with a non-smooth, sparsity inducing l1 penalty.</source>
          <target state="translated">ここでは、SAGAソルバーを選択しました。これは、ロジスティック回帰の損失に対して、非平滑でスパースシティを誘発するl1ペナルティで効率的に最適化できるからです。</target>
        </trans-unit>
        <trans-unit id="15d9d9f74de48f0968b756664a2f90e7435e3e3c" translate="yes" xml:space="preserve">
          <source>Here we choose the liblinear solver because it can efficiently optimize for the Logistic Regression loss with a non-smooth, sparsity inducing l1 penalty.</source>
          <target state="translated">ここでは、非平滑でスパースシティを誘発するl1ペナルティを用いてロジスティック回帰の損失を効率的に最適化できるので、リバイリニアソルバーを選択しました。</target>
        </trans-unit>
        <trans-unit id="d4668460d1dfffc9a12dd3f0ca645c8016c22599" translate="yes" xml:space="preserve">
          <source>Here we compare 3 approaches:</source>
          <target state="translated">ここでは3つのアプローチを比較します。</target>
        </trans-unit>
        <trans-unit id="3aadfee7aa5bef8aeacf179790398b01b017dc93" translate="yes" xml:space="preserve">
          <source>Here we describe variational inference algorithms on Dirichlet process mixture. The Dirichlet process is a prior probability distribution on &lt;em&gt;clusterings with an infinite, unbounded, number of partitions&lt;/em&gt;. Variational techniques let us incorporate this prior structure on Gaussian mixture models at almost no penalty in inference time, comparing with a finite Gaussian mixture model.</source>
          <target state="translated">ここでは、ディリクレプロセス混合の変分推論アルゴリズムについて説明します。ディリクレプロセスは&lt;em&gt;、無限で無限の数のパーティションを持つクラスタリングの&lt;/em&gt;事前確率分布です。変分法を使用すると、有限ガウス混合モデルと比較して、推論時間のペナルティがほとんどなく、ガウス混合モデルにこの以前の構造を組み込むことができます。</target>
        </trans-unit>
        <trans-unit id="19eba1946aa4b2b6c504a0a7a0b9c334a19205ae" translate="yes" xml:space="preserve">
          <source>Here we fit a multinomial logistic regression with L1 penalty on a subset of the MNIST digits classification task. We use the SAGA algorithm for this purpose: this a solver that is fast when the number of samples is significantly larger than the number of features and is able to finely optimize non-smooth objective functions which is the case with the l1-penalty. Test accuracy reaches &amp;gt; 0.8, while weight vectors remains &lt;em&gt;sparse&lt;/em&gt; and therefore more easily &lt;em&gt;interpretable&lt;/em&gt;.</source>
          <target state="translated">ここでは、MNISTディジット分類タスクのサブセットにL1ペナルティを伴う多項ロジスティック回帰を当てはめます。この目的のためにSAGAアルゴリズムを使用します。これは、サンプルの数が特徴の数よりも大幅に多い場合に高速で、l1-penaltyの場合のように滑らかでない目的関数を細かく最適化できるソルバーです。テストの精度は0.8を超えますが、重みベクトルは&lt;em&gt;スパースな&lt;/em&gt;まま&lt;em&gt;な&lt;/em&gt;ので、より簡単に&lt;em&gt;解釈でき&lt;/em&gt;ます。</target>
        </trans-unit>
        <trans-unit id="bc0bdb5bd44175832d7fcee805ba26710508e043" translate="yes" xml:space="preserve">
          <source>Here we have used &lt;code&gt;kernel='gaussian'&lt;/code&gt;, as seen above. Mathematically, a kernel is a positive function \(K(x;h)\) which is controlled by the bandwidth parameter \(h\). Given this kernel form, the density estimate at a point \(y\) within a group of points \(x_i; i=1\cdots N\) is given by:</source>
          <target state="translated">ここでは、上記のように &lt;code&gt;kernel='gaussian'&lt;/code&gt; を使用しています。数学的には、カーネルは帯域幅パラメーター\（h \）によって制御される正の関数\（K（x; h）\）です。このカーネル形式が与えられると、点のグループ\（x_i; i = 1 \ cdots N \）内の点\（y \）での密度推定は、次のように与えられます。</target>
        </trans-unit>
        <trans-unit id="9bc4f467db4b070f940a4ae98fc40a9d9951075c" translate="yes" xml:space="preserve">
          <source>Here we simulate independent sources using a highly non-Gaussian process, 2 student T with a low number of degrees of freedom (top left figure). We mix them to create observations (top right figure). In this raw observation space, directions identified by PCA are represented by orange vectors. We represent the signal in the PCA space, after whitening by the variance corresponding to the PCA vectors (lower left). Running ICA corresponds to finding a rotation in this space to identify the directions of largest non-Gaussianity (lower right).</source>
          <target state="translated">ここでは、高度に非ガウス過程を用いて独立したソースをシミュレーションしています。それらを混合してオブザベーションを作成します(右上図)。この生の観測空間では、PCAで同定された方向がオレンジ色のベクトルで表現されています。PCA空間では、PCAベクトルに対応する分散で白化した後の信号を表現します(左下)。ICAを実行することは、最大の非ガウス性の方向を特定するために、この空間で回転を見つけることに相当します(右下)。</target>
        </trans-unit>
        <trans-unit id="72e463d9d9e7402af61cb976f70a41a655f66554" translate="yes" xml:space="preserve">
          <source>Here we use the caching property of pipelines to cache the nearest neighbors graph between multiple fits of KNeighborsClassifier. The first call is slow since it computes the neighbors graph, while subsequent call are faster as they do not need to recompute the graph. Here the durations are small since the dataset is small, but the gain can be more substantial when the dataset grows larger, or when the grid of parameter to search is large.</source>
          <target state="translated">ここでは,パイプラインのキャッシュ特性を利用して,KNeighborsClassifierの複数回の適合の間に最近傍グラフをキャッシュします.最初の呼び出しは近傍グラフを計算するので遅いですが,その後の呼び出しはグラフを再計算する必要がないので速くなります.ここでは,データセットが小さいので持続時間は小さいですが,データセットが大きくなったり,検索するパラメータのグリッドが大きくなったりすると,より大きな利得を得ることができます.</target>
        </trans-unit>
        <trans-unit id="4efad2f65eb490631f07741acecbb3c6dbc45f0c" translate="yes" xml:space="preserve">
          <source>Here we use the l1 sparsity that trims the weights of not informative features to zero. This is good if the goal is to extract the strongly discriminative vocabulary of each class. If the goal is to get the best predictive accuracy, it is better to use the non sparsity-inducing l2 penalty instead.</source>
          <target state="translated">ここでは、情報的でない特徴の重みをゼロにするl1 sparsityを使用しています。これは,各クラスの識別力の強い語彙を抽出することが目的であれば,良い方法です.最高の予測精度を得ることが目的であれば,代わりに非スパース度を誘発するl2ペナルティを使う方が良いでしょう.</target>
        </trans-unit>
        <trans-unit id="0013bebf729b11b2c5dfc0313efdfb116ab3b0c5" translate="yes" xml:space="preserve">
          <source>Here we want to model the frequency &lt;code&gt;y = ClaimNb / Exposure&lt;/code&gt; conditionally on &lt;code&gt;X&lt;/code&gt; via a (scaled) Poisson distribution, and use &lt;code&gt;Exposure&lt;/code&gt; as &lt;code&gt;sample_weight&lt;/code&gt;.</source>
          <target state="translated">ここでは、（スケーリングされた）ポアソン分布を介して &lt;code&gt;X&lt;/code&gt; で条件付きで頻度 &lt;code&gt;y = ClaimNb / Exposure&lt;/code&gt; をモデル化し、 &lt;code&gt;Exposure&lt;/code&gt; を &lt;code&gt;sample_weight&lt;/code&gt; として使用します。</target>
        </trans-unit>
        <trans-unit id="034b3c08e48de8757b6f1f86830d0869f87a8e39" translate="yes" xml:space="preserve">
          <source>Here, &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; is the parameter name of the nested estimator, in this case &lt;code&gt;base_estimator&lt;/code&gt;. If the meta-estimator is constructed as a collection of estimators as in &lt;code&gt;pipeline.Pipeline&lt;/code&gt;, then &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; refers to the name of the estimator, see &lt;a href=&quot;compose#pipeline-nested-parameters&quot;&gt;Nested parameters&lt;/a&gt;. In practice, there can be several levels of nesting:</source>
          <target state="translated">ここで、 &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; はネストされた推定量のパラメーター名であり、この場合は &lt;code&gt;base_estimator&lt;/code&gt; です。メタ推定がのように推定量の集合体として構成されている場合は &lt;code&gt;pipeline.Pipeline&lt;/code&gt; 、その後、 &lt;code&gt;&amp;lt;estimator&amp;gt;&lt;/code&gt; 推定の名前を参照し、参照の&lt;a href=&quot;compose#pipeline-nested-parameters&quot;&gt;ネストされたパラメータを&lt;/a&gt;。実際には、ネストにはいくつかのレベルがあります。</target>
        </trans-unit>
        <trans-unit id="0260adbe3be54cb933a36e08a92f87d76459f0fc" translate="yes" xml:space="preserve">
          <source>Here, \(\alpha \geq 0\) is a complexity parameter that controls the amount of shrinkage: the larger the value of \(\alpha\), the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.</source>
          <target state="translated">ここでは、縮み量を制御する複雑度パラメータである\(\(Alpha)の値が大きいほど、縮み量が大きくなり、係数がより強固なコリニアリティになる。</target>
        </trans-unit>
        <trans-unit id="9412689bc5806775f9bf0419d0db25d5c39e9741" translate="yes" xml:space="preserve">
          <source>Here, the classifier is &lt;code&gt;fit()&lt;/code&gt; on a 2d binary label representation of &lt;code&gt;y&lt;/code&gt;, using the &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt;&lt;code&gt;LabelBinarizer&lt;/code&gt;&lt;/a&gt;. In this case &lt;code&gt;predict()&lt;/code&gt; returns a 2d array representing the corresponding multilabel predictions.</source>
          <target state="translated">ここでは、分類子は&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer&quot;&gt; &lt;code&gt;LabelBinarizer&lt;/code&gt; &lt;/a&gt;を使用して、 &lt;code&gt;y&lt;/code&gt; の 2Dバイナリラベル表現の &lt;code&gt;fit()&lt;/code&gt; です。この場合、 &lt;code&gt;predict()&lt;/code&gt; は、対応するマルチラベル予測を表す2d配列を返します。</target>
        </trans-unit>
        <trans-unit id="e42ec4b790491f01a91defa6334fdc833c4f6019" translate="yes" xml:space="preserve">
          <source>Here, the default kernel &lt;code&gt;rbf&lt;/code&gt; is first changed to &lt;code&gt;linear&lt;/code&gt; via &lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt;&lt;code&gt;SVC.set_params()&lt;/code&gt;&lt;/a&gt; after the estimator has been constructed, and changed back to &lt;code&gt;rbf&lt;/code&gt; to refit the estimator and to make a second prediction.</source>
          <target state="translated">ここで、デフォルトのカーネル &lt;code&gt;rbf&lt;/code&gt; は、推定器が構築された後、&lt;a href=&quot;../../modules/generated/sklearn.svm.svc#sklearn.svm.SVC.set_params&quot;&gt; &lt;code&gt;SVC.set_params()&lt;/code&gt; &lt;/a&gt;を介して最初に &lt;code&gt;linear&lt;/code&gt; 変更され、推定器を再 &lt;code&gt;rbf&lt;/code&gt; して2番目の予測を行うためにrbfに戻されます。</target>
        </trans-unit>
        <trans-unit id="379b23b33ba6458bba2f568a4c2b136ad7c827a5" translate="yes" xml:space="preserve">
          <source>Here, the first &lt;code&gt;predict()&lt;/code&gt; returns an integer array, since &lt;code&gt;iris.target&lt;/code&gt; (an integer array) was used in &lt;code&gt;fit&lt;/code&gt;. The second &lt;code&gt;predict()&lt;/code&gt; returns a string array, since &lt;code&gt;iris.target_names&lt;/code&gt; was for fitting.</source>
          <target state="translated">ここでは、 &lt;code&gt;iris.target&lt;/code&gt; （整数配列）が &lt;code&gt;fit&lt;/code&gt; で使用されたため、最初のpredict &lt;code&gt;predict()&lt;/code&gt; は整数配列を返します。2番目の &lt;code&gt;iris.target_names&lt;/code&gt; &lt;code&gt;predict()&lt;/code&gt; は、iris.target_namesがフィッティング用であるため、文字列配列を返します。</target>
        </trans-unit>
        <trans-unit id="21a97ae1e0557499a4ed4420c47199de8f6f0cde" translate="yes" xml:space="preserve">
          <source>Here, the number of samples is slightly larger than the number of dimensions, thus the empirical covariance is still invertible. However, as the observations are strongly correlated, the empirical covariance matrix is ill-conditioned and as a result its inverse &amp;ndash;the empirical precision matrix&amp;ndash; is very far from the ground truth.</source>
          <target state="translated">ここで、サンプルの数は次元の数よりもわずかに多いため、経験的共分散は依然として可逆的です。ただし、観測値は強く相関しているため、経験的共分散行列は悪条件であり、その結果、その逆数-経験的精度行列-は真実からはかなり離れています。</target>
        </trans-unit>
        <trans-unit id="2c6a31e993187ebfe932ff15824a46e0c83fd078" translate="yes" xml:space="preserve">
          <source>Here, the predicted class label is 2, since it has the highest average probability.</source>
          <target state="translated">ここで、予測されたクラスラベルは、最も平均的な確率が高いので、2である。</target>
        </trans-unit>
        <trans-unit id="2ac251de8487bd51d665dc484131dc49cb351bf8" translate="yes" xml:space="preserve">
          <source>Here, the scores for the test data call for caution as they are significantly worse than for the training data indicating an overfit despite the strong regularization.</source>
          <target state="translated">ここでは、テストデータのスコアがトレーニングデータよりも有意に悪く、強い正則化にもかかわらずオーバーフィットを示しているので注意が必要です。</target>
        </trans-unit>
        <trans-unit id="e4ef491b953b35546ea7174e484d0bf1fa4f7b9b" translate="yes" xml:space="preserve">
          <source>Here, we are penalizing samples whose prediction is at least \(\varepsilon\) away from their true target. These samples penalize the objective by \(\zeta_i\) or \(\zeta_i^*\), depending on whether their predictions lie above or below the \(\varepsilon\) tube.</source>
          <target state="translated">ここでは、予測値が目標値から少なくとも離れているサンプルにペナルティを課しています。これらのサンプルは、彼らの予測が上か下にあるかどうかに応じて、目的をペナルティを課す。</target>
        </trans-unit>
        <trans-unit id="3799f87043c16356967f90e71e555e0bd9e10d17" translate="yes" xml:space="preserve">
          <source>Here, we combine 3 learners (linear and non-linear) and use a ridge regressor to combine their outputs together.</source>
          <target state="translated">ここでは、3つの学習者(線形と非線形)を組み合わせて、リッジレグレッサーを使って出力をまとめています。</target>
        </trans-unit>
        <trans-unit id="1a1c9125aac07396a0a83a0358b1364478df4bbe" translate="yes" xml:space="preserve">
          <source>Here, we plot the partial dependence curves for a single feature, &amp;ldquo;age&amp;rdquo;, on the same axes. In this case, &lt;code&gt;tree_disp.axes_&lt;/code&gt; is passed into the second plot function.</source>
          <target state="translated">ここでは、同じ軸上に単一の特徴「年齢」の部分依存曲線をプロットします。この場合、 &lt;code&gt;tree_disp.axes_&lt;/code&gt; は2番目のプロット関数に渡されます。</target>
        </trans-unit>
        <trans-unit id="69bdd751bbdbd7bb5746658b628d98b5240af47b" translate="yes" xml:space="preserve">
          <source>Here, we used the default hyperparameters for the gradient boosting model without any preprocessing as tree-based models are naturally robust to monotonic transformations of numerical features.</source>
          <target state="translated">ここでは、木ベースのモデルは数値特徴の単調な変換に自然に頑健であるため、前処理を行わずに勾配ブーストモデルのデフォルトのハイパーパラメータを使用しました。</target>
        </trans-unit>
        <trans-unit id="264995c0dc7ac7309d4709ed0ce1258e4439b015" translate="yes" xml:space="preserve">
          <source>Hessian Eigenmapping (also known as Hessian-based LLE: HLLE) is another method of solving the regularization problem of LLE. It revolves around a hessian-based quadratic form at each neighborhood which is used to recover the locally linear structure. Though other implementations note its poor scaling with data size, &lt;code&gt;sklearn&lt;/code&gt; implements some algorithmic improvements which make its cost comparable to that of other LLE variants for small output dimension. HLLE can be performed with function &lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt;&lt;code&gt;locally_linear_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt;&lt;code&gt;LocallyLinearEmbedding&lt;/code&gt;&lt;/a&gt;, with the keyword &lt;code&gt;method = 'hessian'&lt;/code&gt;. It requires &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt;.</source>
          <target state="translated">Hessian Eigenmapping（別名Hessian-based LLE：HLLE）は、LLEの正則化問題を解決するもう1つの方法です。局所線形構造を回復するために使用される、各近傍でのヘッセ行列に基づく2次形式を中心に展開します。他の実装では、データサイズによるスケーリングが不十分であることに注意していますが、 &lt;code&gt;sklearn&lt;/code&gt; はアルゴリズムの改善を実装しているため、出力コストが小さい他のLLEバリアントのコストに匹敵します。 HLLEは、ローカルで関数&lt;a href=&quot;generated/sklearn.manifold.locally_linear_embedding#sklearn.manifold.locally_linear_embedding&quot;&gt; &lt;code&gt;locally_linear_embedding&lt;/code&gt; &lt;/a&gt;または対応するオブジェクト指向の&lt;a href=&quot;generated/sklearn.manifold.locallylinearembedding#sklearn.manifold.LocallyLinearEmbedding&quot;&gt; &lt;code&gt;LocallyLinearEmbedding&lt;/code&gt; &lt;/a&gt;をキーワード &lt;code&gt;method = 'hessian'&lt;/code&gt; ます。それは必要と &lt;code&gt;n_neighbors &amp;gt; n_components * (n_components + 3) / 2&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4b22ade72c6627b1b562254b0df9c6b4d814d7ac" translate="yes" xml:space="preserve">
          <source>Hidden Activation sampled from the model distribution, where batch_size in the number of examples per minibatch and n_components is the number of hidden units.</source>
          <target state="translated">モデル分布からサンプリングされた隠れ活性化は、ミニバッチあたりの例数のbatch_size、n_componentsは隠れユニットの数です。</target>
        </trans-unit>
        <trans-unit id="afac02e66e409c4004e2cc2adafb5b5e842109eb" translate="yes" xml:space="preserve">
          <source>Hierarchical agglomerative clustering: Ward</source>
          <target state="translated">階層的凝集クラスタリング.ウォード</target>
        </trans-unit>
        <trans-unit id="09f7d65b121068e93f6d1d655d20b242aded6b7b" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering is a general family of clustering algorithms that build nested clusters by merging or splitting them successively. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample. See the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;Wikipedia page&lt;/a&gt; for more details.</source>
          <target state="translated">階層的クラスタリングは、それらを連続的にマージまたは分割することによりネストされたクラスタを構築するクラスタリングアルゴリズムの一般的なファミリです。このクラスターの階層は、ツリー（または樹状図）として表されます。ツリーのルートは、すべてのサンプルを収集する一意のクラスターであり、葉は1つのサンプルのみを持つクラスターです。詳細については、&lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;Wikipediaのページ&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="dbe40063cd6e20f1519715e45afa5ca7ed6442de" translate="yes" xml:space="preserve">
          <source>Hierarchical clustering: structured vs unstructured ward</source>
          <target state="translated">階層的クラスタリング:構造化された区と構造化されていない区の比較</target>
        </trans-unit>
        <trans-unit id="645ba4388b8ba9172558b321f188082e4d2fd9ef" translate="yes" xml:space="preserve">
          <source>High-dimensional datasets can be very difficult to visualize. While data in two or three dimensions can be plotted to show the inherent structure of the data, equivalent high-dimensional plots are much less intuitive. To aid visualization of the structure of a dataset, the dimension must be reduced in some way.</source>
          <target state="translated">高次元のデータセットを可視化するのは非常に困難です。2次元や3次元のデータは,データの固有の構造を示すためにプロットすることができるが,同等の高次元のプロットは直感的ではない.データセットの構造の可視化を助けるためには,次元を何らかの方法で小さくしなければならない.</target>
        </trans-unit>
        <trans-unit id="769f5c4cc60f755dfe8d93fd7b194f0c3a9b7156" translate="yes" xml:space="preserve">
          <source>Hinge (soft-margin): equivalent to Support Vector Classification. \(L(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))\).</source>
          <target state="translated">Hinge (soft-margin):サポートベクター分類に相当する。\(L(y_i,f(x_i))=\max(0,1-y_i f(x_i))</target>
        </trans-unit>
        <trans-unit id="75c18021e736bcb99a099c597122a642054caa8c" translate="yes" xml:space="preserve">
          <source>Hinge: (soft-margin) Support Vector Machines.</source>
          <target state="translated">ヒンジ。(ソフトマージン)サポートベクターマシン。</target>
        </trans-unit>
        <trans-unit id="a319ae13863bb8d6da087a8b6e0305de9278e27f" translate="yes" xml:space="preserve">
          <source>Hinton, Geoffrey E.</source>
          <target state="translated">ヒントン、ジェフリーE.</target>
        </trans-unit>
        <trans-unit id="04790fed22fa2f8c9274791cf963a575a884ed64" translate="yes" xml:space="preserve">
          <source>Hispanic</source>
          <target state="translated">Hispanic</target>
        </trans-unit>
        <trans-unit id="d6215d83f5c22f8bb7c1095fa0298c0dd2d51f9d" translate="yes" xml:space="preserve">
          <source>Histogram-based Gradient Boosting Classification Tree.</source>
          <target state="translated">ヒストグラムベースの勾配ブースト分類木.</target>
        </trans-unit>
        <trans-unit id="772913778b88215dfb5f0c612cecbcae2c4b1a8f" translate="yes" xml:space="preserve">
          <source>Histogram-based Gradient Boosting Regression Tree.</source>
          <target state="translated">ヒストグラムベースの勾配ブースト回帰木。</target>
        </trans-unit>
        <trans-unit id="b8cd925555526484cde7ba65174f600e33250f6b" translate="yes" xml:space="preserve">
          <source>Hochreiter, Bodenhofer, et. al., 2010. &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;FABIA: factor analysis for bicluster acquisition&lt;/a&gt;.</source>
          <target state="translated">Hochreiter、Bodenhoferなど ら、2010年。&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/&quot;&gt;ファビア：bicluster取得のための要因分析&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cbd8a9628e732e150b1ccedb68c9c6ad4fe27c2c" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the empirical log probability of categories given the respective feature and class, &lt;code&gt;P(x_i|y)&lt;/code&gt;.</source>
          <target state="translated">各フィーチャの形状の配列（n_classes、各フィーチャのn_categories）を保持します。各配列は、それぞれの機能とクラス &lt;code&gt;P(x_i|y)&lt;/code&gt; 与えられた場合に、カテゴリの経験的対数確率を提供します。</target>
        </trans-unit>
        <trans-unit id="0265e0dec8e2ff0952abf481f5094201e14a30d8" translate="yes" xml:space="preserve">
          <source>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the number of samples encountered for each class and category of the specific feature.</source>
          <target state="translated">各フィーチャーの形状(各フィーチャーのn_クラス,n_カテゴリ)の配列を保持します.各配列は,特定の特徴の各クラスとカテゴリで遭遇したサンプル数を提供します.</target>
        </trans-unit>
        <trans-unit id="7a5c3ac7ac58dcde82acc59c23c0dce0d31966d1" translate="yes" xml:space="preserve">
          <source>Holds the label for each class.</source>
          <target state="translated">各クラスのラベルを保持します。</target>
        </trans-unit>
        <trans-unit id="4b7dceb5fe5f7e92199815a2b66fef8fdf05dc27" translate="yes" xml:space="preserve">
          <source>Homogeneity and completeness scores are formally given by:</source>
          <target state="translated">均質性と完全性のスコアは正式には次のように与えられます。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
