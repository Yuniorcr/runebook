<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="4057b3cb6bd141b135fafdb32fce3f5d0c92b8db" translate="yes" xml:space="preserve">
          <source>Sample matrix.</source>
          <target state="translated">サンプルマトリックス。</target>
        </trans-unit>
        <trans-unit id="04c4511b91c525e2da2ef7db41615c6ca0a3fd2e" translate="yes" xml:space="preserve">
          <source>Sample output:</source>
          <target state="translated">サンプル出力。</target>
        </trans-unit>
        <trans-unit id="cc8d82180e352f6e4eb38618a9b77ce032b1c63f" translate="yes" xml:space="preserve">
          <source>Sample pipeline for text feature extraction and evaluation</source>
          <target state="translated">テキスト特徴抽出・評価のためのサンプルパイプライン</target>
        </trans-unit>
        <trans-unit id="0982f69f498171fb424746f3b46f588b79249d60" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">ニアレストセントロイド分類の使用例 各クラスの決定境界をプロットします。</target>
        </trans-unit>
        <trans-unit id="f22b9a32693422a5abcec4767410509915bc2f8f" translate="yes" xml:space="preserve">
          <source>Sample usage of Nearest Neighbors classification. It will plot the decision boundaries for each class.</source>
          <target state="translated">ニアレストネイバー分類の使用例 各クラスの決定境界をプロットします。</target>
        </trans-unit>
        <trans-unit id="c4ad00c210ac74869e557ad5117f0c17f5204222" translate="yes" xml:space="preserve">
          <source>Sample usage of Neighborhood Components Analysis for dimensionality reduction.</source>
          <target state="translated">次元削減のための近傍成分分析の使用例。</target>
        </trans-unit>
        <trans-unit id="b6f1c43a568cbfebecbc9c4a468d534512e56696" translate="yes" xml:space="preserve">
          <source>Sample vectors from which to compute variances.</source>
          <target state="translated">分散を計算するための標本ベクトル.</target>
        </trans-unit>
        <trans-unit id="4701e0099b8ff3338dac13ba80a9fd03a1b4e3e5" translate="yes" xml:space="preserve">
          <source>Sample vectors.</source>
          <target state="translated">ベクターのサンプル。</target>
        </trans-unit>
        <trans-unit id="e2a418c622901df3ef07f5cc98282eefd0e90959" translate="yes" xml:space="preserve">
          <source>Sample weight</source>
          <target state="translated">サンプル重量</target>
        </trans-unit>
        <trans-unit id="e69657285f6aad82f9a81418454c1c4adb873fb2" translate="yes" xml:space="preserve">
          <source>Sample weight.</source>
          <target state="translated">サンプル重量。</target>
        </trans-unit>
        <trans-unit id="b0d17c86dbd02471ac25031f76f6b9e62870f2a0" translate="yes" xml:space="preserve">
          <source>Sample weights</source>
          <target state="translated">サンプル重量</target>
        </trans-unit>
        <trans-unit id="03782597aeab2816675e9752810fe748c242aeef" translate="yes" xml:space="preserve">
          <source>Sample weights.</source>
          <target state="translated">サンプルの重さ。</target>
        </trans-unit>
        <trans-unit id="f828cc5ffdb9cf591696bfda2177ba993eb46afe" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, all samples are given the same weight.</source>
          <target state="translated">サンプルの重み。Noneの場合、すべてのサンプルに同じ重みが与えられます。</target>
        </trans-unit>
        <trans-unit id="516c4850672ccbdd1765de8db9d3606a458e566e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to 1 / n_samples.</source>
          <target state="translated">サンプルの重み。Noneの場合、サンプル重みは1/n_samplesに初期化されます。</target>
        </trans-unit>
        <trans-unit id="06e56dd5257a783cd783e2275240a5cef38438c1" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, the sample weights are initialized to &lt;code&gt;1 / n_samples&lt;/code&gt;.</source>
          <target state="translated">サンプルの重み。Noneの場合、サンプルの重みは &lt;code&gt;1 / n_samples&lt;/code&gt; 初期化されます。</target>
        </trans-unit>
        <trans-unit id="b28026c224fc212b3c8db8d7abcf83fe154d5aba" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted.</source>
          <target state="translated">サンプルの重み。Noneの場合、サンプルは等しく重み付けされます。</target>
        </trans-unit>
        <trans-unit id="dd4e4922a0bf331287b6e7fdee69023638c0a9c2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</source>
          <target state="translated">サンプルの重み。Noneの場合、サンプルは等しく重み付けされる。これは、基礎となるすべての推定量がサンプル重みをサポートしている場合にのみサポートされることに注意してください。</target>
        </trans-unit>
        <trans-unit id="72b5ffbf428e4946121de0a0ea4fb4fa9205e66d" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</source>
          <target state="translated">サンプルの重み。None の場合、サンプルは等しく重み付けされる。これは、基本推定量がサンプル重み付けをサポートしている場合にのみサポートされることに注意してください。</target>
        </trans-unit>
        <trans-unit id="44004435db67a9bbea489a279598bbde7cadacd2" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying classifier supports sample weights.</source>
          <target state="translated">サンプルの重み。None の場合,サンプルは等しく重み付けされます.基礎となる分類器がサンプル重みをサポートしている場合のみサポートされます.</target>
        </trans-unit>
        <trans-unit id="e07f10e1efb6d03970a11a668db91780f97be9f4" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.</source>
          <target state="translated">サンプルの重み。None の場合、サンプルは等しく重み付けされます。基礎となる回帰器が標本重みをサポートしている場合のみサポートされる。</target>
        </trans-unit>
        <trans-unit id="d4811960b5c60cf1d2e21f4adf57777acf8cf860" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.</source>
          <target state="translated">サンプルの重み。None の場合、サンプルは等しく重み付けされます。ネットゼロまたは負の重みを持つ子ノードを作成するスプリットは、各ノードのスプリットを検索する際に無視されます。</target>
        </trans-unit>
        <trans-unit id="76ebb3a0858ee52c5cebb457753ce9dfb9f1fd6e" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">サンプルの重み。None の場合、サンプルは等しく重み付けされます。純ゼロまたは負の重みを持つ子ノードを作成するような分割は、各ノードで分割を検索する際に無視されます。分類の場合,分割が,どちらかの子ノードで負の重みを持つ単一のクラスになる場合も無視されます.</target>
        </trans-unit>
        <trans-unit id="317d3738fe42cf9aeb8c2e6052e8dee6f03e55e0" translate="yes" xml:space="preserve">
          <source>Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.</source>
          <target state="translated">サンプルの重み。None の場合、サンプルは等しく重み付けされます。正味ゼロまたは負の重みを持つ子ノードを作成するような分割は、各ノードで分割を検索する際に無視されます。また、分割によって、どちらかの子ノードで負の重みを持つ単一のクラスが生成された場合も無視されます。</target>
        </trans-unit>
        <trans-unit id="a6e78b9afd27497df49aade34a36635be33138ac" translate="yes" xml:space="preserve">
          <source>Sample-weight support for Lasso and ElasticNet</source>
          <target state="translated">LassoとElasticNetのサンプルウェイトサポート</target>
        </trans-unit>
        <trans-unit id="a90c0865394b45b5f31d5c73cc5fa995827fa090" translate="yes" xml:space="preserve">
          <source>Samples a subset of training points, computes kernel on these and computes normalization matrix.</source>
          <target state="translated">学習点のサブセットをサンプリングし,その上でカーネルを計算し,正規化行列を計算します.</target>
        </trans-unit>
        <trans-unit id="489527d2412e4e73b577f6c6fbbfa5b2fc34f813" translate="yes" xml:space="preserve">
          <source>Samples generator</source>
          <target state="translated">サンプルジェネレータ</target>
        </trans-unit>
        <trans-unit id="984aa7241ddfaa0a1125ba76d49684d954091644" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">サンプルにはそれぞれ複数のラベルが付いている場合があります（&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.htmlを参照&lt;/a&gt;）</target>
        </trans-unit>
        <trans-unit id="4d0b8d7411b8018b991a89ec2a4d88914d35dbf8" translate="yes" xml:space="preserve">
          <source>Samples may have several labels each (see &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&lt;/a&gt;)</source>
          <target state="translated">サンプルにはそれぞれ複数のラベルが付いている場合があります（&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html&quot;&gt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.htmlを&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="a729b3c883140152c8be9c9b913932e3054a28dd" translate="yes" xml:space="preserve">
          <source>Samples per class</source>
          <target state="translated">クラスごとのサンプル</target>
        </trans-unit>
        <trans-unit id="72ff32775331fbcdecdd7b50f2f019ca6fd41d2c" translate="yes" xml:space="preserve">
          <source>Samples random projection according to n_features.</source>
          <target state="translated">n_featuresに応じたランダム投影をサンプリングします。</target>
        </trans-unit>
        <trans-unit id="251d1d7b5c7f8793378b7d465a809b22ff0293ea" translate="yes" xml:space="preserve">
          <source>Samples to cluster.</source>
          <target state="translated">クラスター化するサンプル。</target>
        </trans-unit>
        <trans-unit id="1b35c86a656c810d2ffde5bec3bbb5716273c85d" translate="yes" xml:space="preserve">
          <source>Samples total</source>
          <target state="translated">サンプル合計</target>
        </trans-unit>
        <trans-unit id="d94a358c32f7a1a8aa072b320513050f66fbf3bb" translate="yes" xml:space="preserve">
          <source>Samples.</source>
          <target state="translated">Samples.</target>
        </trans-unit>
        <trans-unit id="79b4194bd3e79bf7f3c58fb9c6afe5574c4f3465" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be a text document (either bytes or unicode strings, file name or file object depending on the constructor argument) which will be tokenized and hashed.</source>
          <target state="translated">サンプル。各サンプルは、トークン化およびハッシュ化されるテキスト文書(コンストラクタの引数に応じて、バイトまたはユニコード文字列、ファイル名またはファイルオブジェクトのいずれか)でなければなりません。</target>
        </trans-unit>
        <trans-unit id="4ecf733dec873b2818a96fff2c4d7137b5e9cce2" translate="yes" xml:space="preserve">
          <source>Samples. Each sample must be iterable an (e.g., a list or tuple) containing/generating feature names (and optionally values, see the input_type constructor argument) which will be hashed. raw_X need not support the len function, so it can be the result of a generator; n_samples is determined on the fly.</source>
          <target state="translated">サンプル。各サンプルは、ハッシュ化される特徴名を含む/生成される特徴名(オプションで値もあります。input_type コンストラクタの引数を参照)を含む/生成される反復可能なもの(リストやタプルなど)でなければなりません。</target>
        </trans-unit>
        <trans-unit id="475a3c12e7131d5c7c597d45cbde5d7c042c5697" translate="yes" xml:space="preserve">
          <source>Samples. If kernel == &amp;ldquo;precomputed&amp;rdquo; this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.</source>
          <target state="translated">サンプル。kernel ==&amp;ldquo; precomputed&amp;rdquo;の場合、これは代わりに事前計算されたカーネル行列、shape = [n_samples、n_samples_fitted]です。ここで、n_samples_fittedは、この推定器のフィッティングで使用されるサンプルの数です。</target>
        </trans-unit>
        <trans-unit id="786961f4d535734fe86dc46d23d2c4ae6643e27e" translate="yes" xml:space="preserve">
          <source>Sampling interval. Must be specified when sample_steps not in {1,2,3}.</source>
          <target state="translated">サンプリング間隔。sample_steps が {1,2,3}にない場合に指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="fb8efe38000470eaaa9cdd2c1e100fa22c387ba8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">より多くの次元をサンプリングすると、明らかに分類結果が向上しますが、コストが高くなります。これは、パラメーターn_componentsによって与えられる、実行時と精度の間にトレードオフがあることを意味します。&lt;a href=&quot;../../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;を介して確率的勾配降下法を使用することにより、線形SVMと近似カーネルSVMの解決を大幅に加速できることに注意してください。これは、カーネル化されたSVMの場合には簡単には不可能です。</target>
        </trans-unit>
        <trans-unit id="2b1ee52c21297b409f91752fd0536580b7df89b8" translate="yes" xml:space="preserve">
          <source>Sampling more dimensions clearly leads to better classification results, but comes at a greater cost. This means there is a tradeoff between runtime and accuracy, given by the parameter n_components. Note that solving the Linear SVM and also the approximate kernel SVM could be greatly accelerated by using stochastic gradient descent via &lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt;&lt;/a&gt;. This is not easily possible for the case of the kernelized SVM.</source>
          <target state="translated">より多くの次元をサンプリングすると、分類結果が向上しますが、コストが高くなります。これは、パラメーターn_componentsによって与えられる、実行時間と精度の間にトレードオフがあることを意味します。線形SVMと近似カーネルSVMの解決は、&lt;a href=&quot;../modules/generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;sklearn.linear_model.SGDClassifier&lt;/code&gt; &lt;/a&gt;を介して確率勾配降下法を使用することで大幅に加速できることに注意してください。これは、カーネル化されたSVMの場合、簡単には不可能です。</target>
        </trans-unit>
        <trans-unit id="3e5ac0adafac21480f1a521f8334d2085c97ee0a" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999, &amp;ldquo;An elementary proof of the Johnson-Lindenstrauss Lemma.&amp;rdquo; &lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</source>
          <target state="translated">Sanjoy DasguptaおよびAnupam Gupta、1999年、「Johnson-Lindenstrauss補題の初歩的な証拠」。&lt;a href=&quot;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&quot;&gt;http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.3654&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="72e45a031f2d9ef687b450c7dbe04851bc78b888" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta and Anupam Gupta, 1999. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;An elementary proof of the Johnson-Lindenstrauss Lemma.&lt;/a&gt;</source>
          <target state="translated">Sanjoy DasguptaおよびAnupam Gupta、1999年。Johnson &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.3334&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;-Lindenstrauss補題の初歩的な証明。&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="916673b66f20fa78c64c3896647266270d456625" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;lsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">Sanjoy Dasgupta。2000. &lt;a href=&quot;http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;ランダム投影の実験。&lt;/a&gt;人工知能における不確実性に関する第16回会議の議事録（UAI'00）で、Craig BoutilierとMois&amp;eacute;sGoldszmidt（編）。Morgan Kaufmann Publishers Inc.、米国カリフォルニア州サンフランシスコ、143-151。</target>
        </trans-unit>
        <trans-unit id="2894bd12dff71a351f3ecafd27a1d2a6b0bda89e" translate="yes" xml:space="preserve">
          <source>Sanjoy Dasgupta. 2000. &lt;a href=&quot;https://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;Experiments with random projection.&lt;/a&gt; In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI&amp;rsquo;00), Craig Boutilier and Mois&amp;eacute;s Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.</source>
          <target state="translated">サンジョイダスグプタ。2000.&lt;a href=&quot;https://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf&quot;&gt;ランダム投影の実験。&lt;/a&gt;人工知能の不確実性に関する第16回会議（UAI'00）の議事録で、Craig BoutilierとMois&amp;eacute;sGoldszmidt（編）。Morgan Kaufmann Publishers Inc.、米国カリフォルニア州サンフランシスコ、143-151。</target>
        </trans-unit>
        <trans-unit id="3dc12a8bd942b1cd9b3ab450a012927de384bfa6" translate="yes" xml:space="preserve">
          <source>Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.</source>
          <target state="translated">フィットしたモデルを,誤差サンプルの数が最大の場合に最適なモデルとして保存する.現在の推定モデルが同じ数のインライアを持っている場合,より良いスコアを持っている場合にのみ,それが最良モデルとみなされます.</target>
        </trans-unit>
        <trans-unit id="94b03c70b196c58604c0a7faf7218bf6901b8e0c" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="translated">Scalability</target>
        </trans-unit>
        <trans-unit id="461b60146605d928fa9b9a5fb416ca167c84c880" translate="yes" xml:space="preserve">
          <source>Scalability and stability improvements to KMeans</source>
          <target state="translated">KMeansのスケーラビリティと安定性の向上</target>
        </trans-unit>
        <trans-unit id="199d842d852910d77fdbfb1dc59f0d2885e1b21f" translate="yes" xml:space="preserve">
          <source>Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.</source>
          <target state="translated">スケーラビリティは、例えば get_bin_seeds 関数で min_bin_freq の値を高くするなどして、より少ないシードを使うことで向上させることができます。</target>
        </trans-unit>
        <trans-unit id="29f2c344812c53bdbb5e427694d6be2d492aaf47" translate="yes" xml:space="preserve">
          <source>Scalability, due to the sequential nature of boosting it can hardly be parallelized.</source>
          <target state="translated">スケーラビリティは、ブースティングのシーケンシャルな性質上、ほとんど並列化できません。</target>
        </trans-unit>
        <trans-unit id="f6484bee2609587949da674a2bdf0fe83ede7b2a" translate="yes" xml:space="preserve">
          <source>Scalability:</source>
          <target state="translated">Scalability:</target>
        </trans-unit>
        <trans-unit id="61dc05feb549eab6c07b7a94be612c538f71b094" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</source>
          <target state="translated">liblinearを使用して実装された分類のためのスケーラブルな線形サポートベクターマシン。より多くの比較要素については、LinearSVCのSee alsoセクションをチェックしてください。</target>
        </trans-unit>
        <trans-unit id="eecb89d050bc91f7d55354e38239145e4acf15ef" translate="yes" xml:space="preserve">
          <source>Scalable Linear Support Vector Machine for regression implemented using liblinear.</source>
          <target state="translated">liblinearを用いて実装された回帰のためのスケーラブルな線形サポートベクターマシン。</target>
        </trans-unit>
        <trans-unit id="22b700f6b9ee53c2fb9ac81cf84c12516aa516e1" translate="yes" xml:space="preserve">
          <source>Scalable linear Support Vector Machine for classification using liblinear.</source>
          <target state="translated">リブリニアを用いた分類のためのスケーラブルな線形サポートベクターマシン</target>
        </trans-unit>
        <trans-unit id="bdabc7bc958d2928d9827e9b54f6956c7bb824f2" translate="yes" xml:space="preserve">
          <source>Scale back the data to the original representation</source>
          <target state="translated">データを元の表現にスケールバック</target>
        </trans-unit>
        <trans-unit id="561dee1ec35178a67790d71472d188769f1e1bd6" translate="yes" xml:space="preserve">
          <source>Scale each feature by its maximum absolute value.</source>
          <target state="translated">各特徴量をその最大絶対値で拡大縮小します。</target>
        </trans-unit>
        <trans-unit id="2d3a1b9b18053dd9fb9c5426f583cf0f7d587a14" translate="yes" xml:space="preserve">
          <source>Scale each feature of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">(n_samples,n_features)の形状を想定して,呼び出し元によって与えられた特定のスケールを乗算することで,データ行列の各特徴をスケールさせます.</target>
        </trans-unit>
        <trans-unit id="c6c81268e0182a1a807ca4c628dc76b97a0fa5dc" translate="yes" xml:space="preserve">
          <source>Scale each feature to the [-1, 1] range without breaking the sparsity.</source>
          <target state="translated">各特徴量を,分散性を崩さずに [-1,1]の範囲に拡大縮小します.</target>
        </trans-unit>
        <trans-unit id="5deb9ce023c33b22d107e28507be5494ec70764b" translate="yes" xml:space="preserve">
          <source>Scale each non zero row of X to unit norm</source>
          <target state="translated">Xの各非ゼロ行を単位ノルムにスケールします。</target>
        </trans-unit>
        <trans-unit id="617d6ad46bfccaf27b4ba0f374d21f46a99d594e" translate="yes" xml:space="preserve">
          <source>Scale each row of the data matrix by multiplying with specific scale provided by the caller assuming a (n_samples, n_features) shape.</source>
          <target state="translated">(n_samples,n_features)の形状を想定して,呼び出し元によって与えられた特定のスケールを乗算することで,データ行列の各行のスケールを調整します.</target>
        </trans-unit>
        <trans-unit id="2febfe8f8ec8796f6ba7a4455156e82486b6b9ad" translate="yes" xml:space="preserve">
          <source>Scale factor between inner and outer circle.</source>
          <target state="translated">内側の円と外側の円の間のスケールファクタ。</target>
        </trans-unit>
        <trans-unit id="c9aadd325b03483aa8cbb4258dd4942f088c00d2" translate="yes" xml:space="preserve">
          <source>Scale features of X according to feature_range.</source>
          <target state="translated">X の特徴量を feature_range に応じて拡大縮小します。</target>
        </trans-unit>
        <trans-unit id="651dfd0de4ed652c75c33e720387c590f106c0bd" translate="yes" xml:space="preserve">
          <source>Scale features using statistics that are robust to outliers.</source>
          <target state="translated">外れ値にロバストな統計量を使用したスケール特徴。</target>
        </trans-unit>
        <trans-unit id="ea253b52225bff13ccf219a7ede865331cee2a5e" translate="yes" xml:space="preserve">
          <source>Scale input vectors individually to unit norm (vector length).</source>
          <target state="translated">入力ベクトルを単位ノルム(ベクトル長)に個別にスケールします。</target>
        </trans-unit>
        <trans-unit id="3db146d5ef4350db484651a2947cc4449aa1c920" translate="yes" xml:space="preserve">
          <source>Scale mixture parameter</source>
          <target state="translated">スケール混合パラメータ</target>
        </trans-unit>
        <trans-unit id="214cf07e698e140c0ab386ee80be892f7e60d56f" translate="yes" xml:space="preserve">
          <source>Scale the data</source>
          <target state="translated">データのスケール</target>
        </trans-unit>
        <trans-unit id="a00231cc0fa6cda008f7de726dc3328122b68e67" translate="yes" xml:space="preserve">
          <source>Scaled data has zero mean and unit variance:</source>
          <target state="translated">スケーリングされたデータは、平均と単位分散がゼロです。</target>
        </trans-unit>
        <trans-unit id="28f5624ffdfd0dbb670e710c5400ff826061c8e3" translate="yes" xml:space="preserve">
          <source>Scalers are linear (or more precisely affine) transformers and differ from each other in the way to estimate the parameters used to shift and scale each feature.</source>
          <target state="translated">スケーラは線形(より正確にはアフィン変換器)であり、各特徴量のシフトとスケーリングに使用されるパラメータの推定方法が互いに異なります。</target>
        </trans-unit>
        <trans-unit id="42fb0a5f800741efdeeef6c8d3f6efbb496929e6" translate="yes" xml:space="preserve">
          <source>Scaling a 1D array</source>
          <target state="translated">1次元配列のスケーリング</target>
        </trans-unit>
        <trans-unit id="5e180a611580dedaac6cdcb57565a42487e31efa" translate="yes" xml:space="preserve">
          <source>Scaling features of X according to feature_range.</source>
          <target state="translated">X の特徴量を feature_range に応じてスケーリングします。</target>
        </trans-unit>
        <trans-unit id="faa375cb6d0913845d11a421f85f4fc1917244d4" translate="yes" xml:space="preserve">
          <source>Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.</source>
          <target state="translated">入力を単位ノルムにスケーリングすることは、例えば、テキストの分類やクラスタリングのための一般的な操作です。例えば、2つのl2正規化されたTF-IDFベクトルのドット積は、ベクトルの余弦類似度であり、情報検索コミュニティで一般的に使用されるベクトル空間モデルの基本類似度指標です。</target>
        </trans-unit>
        <trans-unit id="c9df043572b1169b126da4f0a95f811ab4322363" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids.</source>
          <target state="translated">クラスの中心点で囲まれた空間における特徴量のスケーリング.</target>
        </trans-unit>
        <trans-unit id="b5c5a5ab3639fcbfa287bfb00c2baa97d840c68a" translate="yes" xml:space="preserve">
          <source>Scaling of the features in the space spanned by the class centroids. Only available for &amp;lsquo;svd&amp;rsquo; and &amp;lsquo;eigen&amp;rsquo; solvers.</source>
          <target state="translated">クラス重心がまたがる空間内のフィーチャのスケーリング。'svd'および 'eigen'ソルバーでのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="f91f363e9d78c82d08c38c5a1dbde0b091a85898" translate="yes" xml:space="preserve">
          <source>Scaling parameter of the chi2 kernel.</source>
          <target state="translated">chi2 カーネルのスケーリングパラメータ。</target>
        </trans-unit>
        <trans-unit id="611f59db789837a47c8391146e294e88684d2aac" translate="yes" xml:space="preserve">
          <source>Scaling the regularization parameter for SVCs</source>
          <target state="translated">SVCの正則化パラメータのスケーリング</target>
        </trans-unit>
        <trans-unit id="8ca361aee1b505e96263673a562173e09064f7c8" translate="yes" xml:space="preserve">
          <source>Scaling vs Whitening</source>
          <target state="translated">スケーリング vs ホワイトニング</target>
        </trans-unit>
        <trans-unit id="02ba5e6e4d2072a725717b83a0dcd2c4ccfb8e6e" translate="yes" xml:space="preserve">
          <source>Sch&amp;ouml;lkopf et. al &lt;a href=&quot;https://www.stat.purdue.edu/~yuzhu/stat598m3/Papers/NewSVM.pdf&quot;&gt;New Support Vector Algorithms&lt;/a&gt;</source>
          <target state="translated">Sch&amp;ouml;lkopfら al&lt;a href=&quot;https://www.stat.purdue.edu/~yuzhu/stat598m3/Papers/NewSVM.pdf&quot;&gt;新しいサポートベクターアルゴリズム&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f575a7be2bbae52450cf10acab0f42ab527bed47" translate="yes" xml:space="preserve">
          <source>Schubert, E., Sander, J., Ester, M., Kriegel, H. P., &amp;amp; Xu, X. (2017). DBSCAN revisited, revisited: why and how you should (still) use DBSCAN. ACM Transactions on Database Systems (TODS), 42(3), 19.</source>
          <target state="translated">Schubert、E.、Sander、J.、Ester、M.、Kriegel、HP、＆Xu、X。（2017）DBSCANの再検討、再検討：DBSCANを（まだ）使用する理由と方法。データベースシステム（TODS）でのACMトランザクション、42（3）、19。</target>
        </trans-unit>
        <trans-unit id="35b3e8e65e06fb91614a9faf2b4d8410e9e9072a" translate="yes" xml:space="preserve">
          <source>Schubert, Erich, Michael Gertz. &amp;ldquo;Improving the Cluster Structure Extracted from OPTICS Plots.&amp;rdquo; Proc. of the Conference &amp;ldquo;Lernen, Wissen, Daten, Analysen&amp;rdquo; (LWDA) (2018): 318-329.</source>
          <target state="translated">シューベルト、エーリッヒ、マイケル・ガーツ。「OPTICSプロットから抽出されたクラスター構造の改善。」手順 会議の「Lernen、Wissen、Daten、Analysen」（LWDA）（2018）：318-329。</target>
        </trans-unit>
        <trans-unit id="2ac4d036f5e40e9fc63fcd2b4959a2b29e290cfe" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduced two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id24&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn 0.21は、&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;に触発された勾配ブースティングツリーの2つの新しい実験的実装、つまり&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;とHistGradientBoostingRegressorを導入し&lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;ました&lt;/a&gt;（&lt;a href=&quot;#lightgbm&quot; id=&quot;id24&quot;&gt;[LightGBM]を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="fb84d52fa4915e02b24a271ab0aad024c4056d13" translate="yes" xml:space="preserve">
          <source>Scikit-learn 0.21 introduces two new experimental implementations of gradient boosting trees, namely &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;, inspired by &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt; (See &lt;a href=&quot;#lightgbm&quot; id=&quot;id14&quot;&gt;[LightGBM]&lt;/a&gt;).</source>
          <target state="translated">Scikit-learn 0.21は、&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; &lt;/a&gt;に触発された勾配ブースティングツリーの2つの新しい実験的実装、つまり&lt;a href=&quot;generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;とHistGradientBoostingRegressorを導入してい&lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;ます&lt;/a&gt;（&lt;a href=&quot;#lightgbm&quot; id=&quot;id14&quot;&gt;[LightGBM]を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="0b38453e586dafca0c0308eafbfda226dcf7f7c2" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those image can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learnには、作者がクリエイティブ・コモンズライセンスで公開しているJPEG画像のサンプルも埋め込まれています。これらの画像は、2次元データに対するアルゴリズムやパイプラインのテストに役立ちます。</target>
        </trans-unit>
        <trans-unit id="aad0f03512858b9b99ff0fe8b0c0fddc5ad0d78e" translate="yes" xml:space="preserve">
          <source>Scikit-learn also embed a couple of sample JPEG images published under Creative Commons license by their authors. Those images can be useful to test algorithms and pipeline on 2D data.</source>
          <target state="translated">Scikit-learnには、作者がクリエイティブ・コモンズライセンスで公開しているいくつかのサンプルJPEG画像も埋め込まれています。これらの画像は、2次元データのアルゴリズムやパイプラインをテストするのに便利です。</target>
        </trans-unit>
        <trans-unit id="4f09669bc19a45a6af1925c5dd7e5320d97b9858" translate="yes" xml:space="preserve">
          <source>Scikit-learn also permits evaluation of multiple metrics in &lt;code&gt;GridSearchCV&lt;/code&gt;, &lt;code&gt;RandomizedSearchCV&lt;/code&gt; and &lt;code&gt;cross_validate&lt;/code&gt;.</source>
          <target state="translated">Scikit-learnは、 &lt;code&gt;GridSearchCV&lt;/code&gt; 、 &lt;code&gt;RandomizedSearchCV&lt;/code&gt; 、および &lt;code&gt;cross_validate&lt;/code&gt; の複数のメトリックの評価も許可します。</target>
        </trans-unit>
        <trans-unit id="5427512908da9e885639e4f06d90d3fbb899fa1a" translate="yes" xml:space="preserve">
          <source>Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. They can be understood as a list of multi-dimensional observations. We say that the first axis of these arrays is the &lt;strong&gt;samples&lt;/strong&gt; axis, while the second is the &lt;strong&gt;features&lt;/strong&gt; axis.</source>
          <target state="translated">Scikit-learnは、2D配列として表される1つ以上のデータセットからの学習情報を扱います。それらは、多次元観測のリストとして理解できます。これらの配列の最初の軸は&lt;strong&gt;サンプル&lt;/strong&gt;軸であり、2番目は&lt;strong&gt;特徴&lt;/strong&gt;軸であると言い&lt;strong&gt;ます&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="f9977ec0fe68c8f9bbc6588808c28cd22800a19b" translate="yes" xml:space="preserve">
          <source>Scikit-learn defines a simple API for creating visualizations for machine learning. The key features of this API is to allow for quick plotting and visual adjustments without recalculation. In this example, we will demonstrate how to use the visualization API by comparing ROC curves.</source>
          <target state="translated">Scikit-learnは、機械学習のためのビジュアライゼーションを作成するためのシンプルなAPIを定義しています。このAPIの大きな特徴は、再計算なしで素早くプロットしたり、視覚的な調整を行うことができることです。この例では、ROC曲線を比較することで可視化APIの使い方を実演します。</target>
        </trans-unit>
        <trans-unit id="68787e98ea90825b478bf4a016c311205a6818e9" translate="yes" xml:space="preserve">
          <source>Scikit-learn does some validation on data that increases the overhead per call to &lt;code&gt;predict&lt;/code&gt; and similar functions. In particular, checking that features are finite (not NaN or infinite) involves a full pass over the data. If you ensure that your data is acceptable, you may suppress checking for finiteness by setting the environment variable &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; to a non-empty string before importing scikit-learn, or configure it in Python with &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;. For more control than these global settings, a &lt;code&gt;config_context&lt;/code&gt; allows you to set this configuration within a specified context:</source>
          <target state="translated">Scikit-learnは、 &lt;code&gt;predict&lt;/code&gt; および類似の関数に対する呼び出しごとのオーバーヘッドを増加させるデータの検証を行います。特に、特徴が有限（NaNまたは無限ではない）であることを確認するには、データのフルパスが必要です。データが受け入れ可能であることを確認する場合、scikit-learnをインポートする前に環境変数 &lt;code&gt;SKLEARN_ASSUME_FINITE&lt;/code&gt; を空でない文字列に設定するか、&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; を&lt;/a&gt;使用してPythonで構成することにより、有限性のチェックを抑制できます。これらのグローバル設定よりも詳細に制御するには、 &lt;code&gt;config_context&lt;/code&gt; を使用して、指定されたコンテキスト内でこの構成を設定できます。</target>
        </trans-unit>
        <trans-unit id="56e4295ba33d7d0b066dcb5a29b6f828761a1e6b" translate="yes" xml:space="preserve">
          <source>Scikit-learn generally relies on the &lt;code&gt;loky&lt;/code&gt; backend, which is joblib&amp;rsquo;s default backend. Loky is a multi-processing backend. When doing multi-processing, in order to avoid duplicating the memory in each process (which isn&amp;rsquo;t reasonable with big datasets), joblib will create a &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html&quot;&gt;memmap&lt;/a&gt; that all processes can share, when the data is bigger than 1MB.</source>
          <target state="translated">Scikit-learnは通常、joblibのデフォルトのバックエンドである &lt;code&gt;loky&lt;/code&gt; バックエンドに依存しています。Lokyはマルチプロセッシングバックエンドです。マルチプロセッシングを行う場合には、（大きなデータセットと合理的ではないです）、各プロセスでのメモリの重複を避けるために、JOBLIBが作成されます&lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html&quot;&gt;memmap&lt;/a&gt;データが1メガバイトよりも大きいときには、すべてのプロセスが共有できるということを。</target>
        </trans-unit>
        <trans-unit id="562455165c34b7c83008b571c9bd46eceb879b92" translate="yes" xml:space="preserve">
          <source>Scikit-learn has a collection of classes which can be used to generate lists of train/test indices for popular cross-validation strategies.</source>
          <target state="translated">Scikit-learnには、一般的なクロスバリデーション戦略のための訓練/テスト指標のリストを生成するために使用できるクラスのコレクションがあります。</target>
        </trans-unit>
        <trans-unit id="b670925eafc995f1763e66f682772271e15a05e5" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.</source>
          <target state="translated">Scikit-learnはガウス混合モデルを推定するための異なるクラスを実装しています。</target>
        </trans-unit>
        <trans-unit id="e9a530527422759264cd84546f6a0bd4a26252b3" translate="yes" xml:space="preserve">
          <source>Scikit-learn implements efficient kernel density estimation using either a Ball Tree or KD Tree structure, through the &lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt;&lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt;&lt;/a&gt; estimator. The available kernels are shown in the second figure of this example.</source>
          <target state="translated">Scikit-learnは、&lt;a href=&quot;../../modules/generated/sklearn.neighbors.kerneldensity#sklearn.neighbors.KernelDensity&quot;&gt; &lt;code&gt;sklearn.neighbors.KernelDensity&lt;/code&gt; &lt;/a&gt;推定器を介して、ボールツリーまたはKDツリー構造のいずれかを使用して、効率的なカーネル密度推定を実装します。使用可能なカーネルは、この例の2番目の図に示されています。</target>
        </trans-unit>
        <trans-unit id="b29477e8796624fa3eb37a4b942da5b84d872c57" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learnは、科学的なPythonパッケージ（&lt;a href=&quot;http://www.scipy.org&quot;&gt;NumPy&lt;/a&gt;、&lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt;、&lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt;）の緊密に結びついた世界で、従来の機械学習アルゴリズムを統合するPythonモジュールです。</target>
        </trans-unit>
        <trans-unit id="8efe5ffe4058ee23f32fcb7e77b39f35cffa4409" translate="yes" xml:space="preserve">
          <source>Scikit-learn is a Python module integrating classic machine learning algorithms in the tightly-knit world of scientific Python packages (&lt;a href=&quot;https://www.numpy.org/&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;https://scipy.org/&quot;&gt;SciPy&lt;/a&gt;, &lt;a href=&quot;https://matplotlib.org/&quot;&gt;matplotlib&lt;/a&gt;).</source>
          <target state="translated">Scikit-learnは、科学的なPythonパッケージ（&lt;a href=&quot;https://www.numpy.org/&quot;&gt;NumPy&lt;/a&gt;、&lt;a href=&quot;https://scipy.org/&quot;&gt;SciPy&lt;/a&gt;、&lt;a href=&quot;https://matplotlib.org/&quot;&gt;matplotlib&lt;/a&gt;）の緊密に結びついた世界に古典的な機械学習アルゴリズムを統合するPythonモジュールです。</target>
        </trans-unit>
        <trans-unit id="5244e6b9c3228eb8fcf423888d9d9a31c68e2222" translate="yes" xml:space="preserve">
          <source>Scikit-learn offers a more efficient implementation for the construction of decision trees. A naive implementation (as above) would recompute the class label histograms (for classification) or the means (for regression) at for each new split point along a given feature. Presorting the feature over all relevant samples, and retaining a running label count, will reduce the complexity at each node to \(O(n_{features}\log(n_{samples}))\), which results in a total cost of \(O(n_{features}n_{samples}\log(n_{samples}))\). This is an option for all tree based algorithms. By default it is turned on for gradient boosting, where in general it makes training faster, but turned off for all other algorithms as it tends to slow down training when training deep trees.</source>
          <target state="translated">Scikit-learnは決定木を構築するためのより効率的な実装を提供します。ナイーブな実装(上記のように)では、与えられた特徴に沿った新しい分割点ごとに、クラスラベルヒストグラム(分類のための)または平均値(回帰のための)を再計算します。全ての関連するサンプルで特徴をソートし、実行中のラベルカウントを保持すると、各ノードでの複雑さは、\(O(n_{features}n_{samples}\log(n_{samples}))に減少し、結果として、総コストは、\(O(n_{features}n_{samples}\log(n_{samples}))になります。)これは、すべての木ベースのアルゴリズムのオプションです。デフォルトでは、勾配ブーストではオンになっており、一般的には学習が速くなりますが、その他のアルゴリズムでは、深い木を学習する場合に学習が遅くなる傾向があるため、オフになっています。</target>
        </trans-unit>
        <trans-unit id="4affb29f4cf970be26e1f3befb3e52980b3745a3" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</source>
          <target state="translated">Scikit-learnは、3つの堅牢な回帰推定量を提供します：&lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;、&lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt;および&lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="54ef66758fb920f45dd137b20e476f9003566169" translate="yes" xml:space="preserve">
          <source>Scikit-learn provides 3 robust regression estimators: &lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;, &lt;a href=&quot;#theil-sen-regression&quot;&gt;Theil Sen&lt;/a&gt; and &lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressor&lt;/a&gt;.</source>
          <target state="translated">Scikit-学ぶ3つのロバスト回帰推定量を提供：&lt;a href=&quot;#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;、&lt;a href=&quot;#theil-sen-regression&quot;&gt;テイルセン&lt;/a&gt;と&lt;a href=&quot;#huber-regression&quot;&gt;HuberRegressorを&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="cf6e9e896240b0867bdae025d2a37105852d3491" translate="yes" xml:space="preserve">
          <source>Scikit-learn relies heavily on NumPy and SciPy, which internally call multi-threaded linear algebra routines implemented in libraries such as MKL, OpenBLAS or BLIS.</source>
          <target state="translated">Scikit-learn は NumPy や SciPy に大きく依存しており、MKL,OpenBLAS,BLIS などのライブラリで実装されたマルチスレッド線形代数ルーチンを内部的に呼び出します。</target>
        </trans-unit>
        <trans-unit id="760c9dce2728b87b0e773a2a2023bd5ef6b1ebc6" translate="yes" xml:space="preserve">
          <source>Scikit-learn uses the &lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt; library to enable parallel computing inside its estimators. See the joblib documentation for the switches to control parallel computing.</source>
          <target state="translated">Scikit-learnは&lt;a href=&quot;https://joblib.readthedocs.io/en/latest/&quot;&gt;joblib&lt;/a&gt;ライブラリを使用して、推定器内での並列計算を可能にします。並列計算を制御するスイッチについては、joblibのドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="dbdfa5cbcc37d085da70cbad1d49bb4154a25ae3" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipyは、スパースデータを格納するために最適化されたスパースマトリックスデータ構造を提供します。スパースフォーマットの主な機能は、ゼロを格納しないことです。そのため、データがスパースの場合、使用するメモリがはるかに少なくなります。スパース（&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSRまたはCSC&lt;/a&gt;）表現のゼロ以外の値は、平均して1つの32ビット整数位置+ 64ビット浮動小数点値+行列の行または列ごとに追加の32ビットのみを取ります。密（または疎）線形モデルで疎入力を使用すると、非ゼロ値の特徴のみがドット積に影響を与え、モデルの予測に影響を与えるため、予測をかなり高速化できます。したがって、1e6次元空間に100の非ゼロがある場合、1e6の代わりに100の乗算と加算の演算のみが必要です。</target>
        </trans-unit>
        <trans-unit id="41590fea612397630e8b90182fcd88974e84be1f" translate="yes" xml:space="preserve">
          <source>Scipy provides sparse matrix data structures which are optimized for storing sparse data. The main feature of sparse formats is that you don&amp;rsquo;t store zeros so if your data is sparse then you use much less memory. A non-zero value in a sparse (&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSR or CSC&lt;/a&gt;) representation will only take on average one 32bit integer position + the 64 bit floating point value + an additional 32bit per row or column in the matrix. Using sparse input on a dense (or sparse) linear model can speedup prediction by quite a bit as only the non zero valued features impact the dot product and thus the model predictions. Hence if you have 100 non zeros in 1e6 dimensional space, you only need 100 multiply and add operation instead of 1e6.</source>
          <target state="translated">Scipyは、スパースデータを格納するために最適化されたスパース行列データ構造を提供します。スパース形式の主な機能は、ゼロを格納しないことです。そのため、データがスパースの場合、使用するメモリははるかに少なくなります。スパース（&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/sparse.html&quot;&gt;CSRまたはCSC&lt;/a&gt;）表現のゼロ以外の値は、平均して1つの32ビット整数位置+64ビット浮動小数点値+マトリックスの行または列ごとに追加の32ビットのみを取ります。密な（または疎な）線形モデルでスパース入力を使用すると、ゼロ以外の値の特徴のみが内積に影響を与え、モデルの予測に影響を与えるため、予測をかなり高速化できます。したがって、1e6次元空間に100個の非ゼロがある場合、1e6の代わりに100個の乗算と加算の操作のみが必要です。</target>
        </trans-unit>
        <trans-unit id="73ff9df76cca7434e9bdc94c5c539e98a711a167" translate="yes" xml:space="preserve">
          <source>Scipy sparse matrix formats documentation</source>
          <target state="translated">Scipy 疎な行列フォーマットのドキュメント</target>
        </trans-unit>
        <trans-unit id="ec44ac6f635d9837f888fea19337ecd3bc1dc78d" translate="yes" xml:space="preserve">
          <source>Score function (or loss function) with signature &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">シグニチャー &lt;code&gt;score_func(y, y_pred, **kwargs)&lt;/code&gt; スコア関数（または損失関数）。</target>
        </trans-unit>
        <trans-unit id="e8a42d4da772627d057fecc9d05d1c5e0de456df" translate="yes" xml:space="preserve">
          <source>Score of base estimator with best alpha.</source>
          <target state="translated">最高のアルファを持つ基底推定器のスコア</target>
        </trans-unit>
        <trans-unit id="4106362aa56af5a012e22c8aae43583defb47511" translate="yes" xml:space="preserve">
          <source>Score of self.predict(X) wrt. y.</source>
          <target state="translated">self.predict(X)のyに対するスコア。</target>
        </trans-unit>
        <trans-unit id="269ca6f46a2303fa294fd49cbab7d3d725c81bb2" translate="yes" xml:space="preserve">
          <source>Score of the prediction.</source>
          <target state="translated">予測のスコア。</target>
        </trans-unit>
        <trans-unit id="fee68e2ae75f4d785b563d7d07175bca2df697af" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate.</source>
          <target state="translated">袋外推定値を用いて得られた学習データセットのスコア。</target>
        </trans-unit>
        <trans-unit id="d47762b2bcf100a0eee50ed9f7a0b022146b7037" translate="yes" xml:space="preserve">
          <source>Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when &lt;code&gt;oob_score&lt;/code&gt; is True.</source>
          <target state="translated">アウトオブバッグ推定を使用して取得されたトレーニングデータセットのスコア。この属性は、 &lt;code&gt;oob_score&lt;/code&gt; がTrueの場合にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="4a728e01859e5aacfa8054e6c7ac1cbc91bfd77d" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given test split.</source>
          <target state="translated">このパラメータ設定のスコアは、指定されたテストスプリットのスコアです。</target>
        </trans-unit>
        <trans-unit id="fdd43514c35f028b5dfc878c7661a274717e7633" translate="yes" xml:space="preserve">
          <source>Score of this parameter setting on given training / test split.</source>
          <target state="translated">与えられたトレーニング/テストスプリットでのこのパラメータ設定のスコア。</target>
        </trans-unit>
        <trans-unit id="e14703c8615f59873dec25794c9dae3e6fdaa2e4" translate="yes" xml:space="preserve">
          <source>Score, and cross-validated scores</source>
          <target state="translated">スコア、およびクロスバリデートされたスコア</target>
        </trans-unit>
        <trans-unit id="5ac699be69d4f6f03061e9fdf043eeb8d0ba0ed6" translate="yes" xml:space="preserve">
          <source>Scorer function used on the held out data to choose the best parameters for the model.</source>
          <target state="translated">モデルに最適なパラメータを選択するために、ホールドアウトされたデータ上で使用されるスコアラー関数。</target>
        </trans-unit>
        <trans-unit id="2d120255d84deeb73e3a5484f87eef4818f21119" translate="yes" xml:space="preserve">
          <source>Scorer to use. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="translated">使用するスコアラー。単一の文字列（&lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;スコアリングパラメーター：モデル評価ルールの&lt;/a&gt;&lt;a href=&quot;../model_evaluation#scoring&quot;&gt;定義を&lt;/a&gt;参照）または呼び出し可能（メトリック関数からのスコアリング戦略の定義を参照）にすることができます。Noneの場合、推定量のデフォルトのスコアラーが使用されます。</target>
        </trans-unit>
        <trans-unit id="dafe5cdb100f4bad5185f8a89151e9de127407db" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged with uniform weight.</source>
          <target state="translated">すべての出力のスコアは、一様な重みで平均化されます。</target>
        </trans-unit>
        <trans-unit id="a879b57711ff565bb3c57b9cbdbf3f09144796d5" translate="yes" xml:space="preserve">
          <source>Scores of all outputs are averaged, weighted by the variances of each individual output.</source>
          <target state="translated">すべての出力のスコアは平均化され、各個々の出力の分散で重み付けされます。</target>
        </trans-unit>
        <trans-unit id="bad96478d4d42d160afd8f51da6516a096f00968" translate="yes" xml:space="preserve">
          <source>Scores of features.</source>
          <target state="translated">特徴のスコア。</target>
        </trans-unit>
        <trans-unit id="004421c31cff3e85919b0da3d9213b70c070211e" translate="yes" xml:space="preserve">
          <source>Scores on test set.</source>
          <target state="translated">テストセットのスコア。</target>
        </trans-unit>
        <trans-unit id="9cb2f72d484e4d0e25f5504cf3cb781f6831387a" translate="yes" xml:space="preserve">
          <source>Scores on training sets.</source>
          <target state="translated">トレーニングセットでのスコア。</target>
        </trans-unit>
        <trans-unit id="a6e081bd4fc687e97f2a3c1767e01a47d8d0d090" translate="yes" xml:space="preserve">
          <source>Scoring</source>
          <target state="translated">Scoring</target>
        </trans-unit>
        <trans-unit id="1d35080d3b512f65a9672a3ec57c49c5c7d18fa7" translate="yes" xml:space="preserve">
          <source>Scoring parameter to use for early stopping. It can be a single string (see &lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt;) or a callable (see &lt;a href=&quot;../model_evaluation#scoring&quot;&gt;Defining your scoring strategy from metric functions&lt;/a&gt;). If None, the estimator&amp;rsquo;s default scorer is used. If &lt;code&gt;scoring='loss'&lt;/code&gt;, early stopping is checked w.r.t the loss value. Only used if early stopping is performed.</source>
          <target state="translated">早期停止に使用するスコアリングパラメータ。単一の文字列（&lt;a href=&quot;../model_evaluation#scoring-parameter&quot;&gt;スコアリングパラメーター：モデル評価ルールの&lt;/a&gt;&lt;a href=&quot;../model_evaluation#scoring&quot;&gt;定義を&lt;/a&gt;参照）または呼び出し可能（メトリック関数からのスコアリング戦略の定義を参照）にすることができます。Noneの場合、推定量のデフォルトのスコアラーが使用されます。 &lt;code&gt;scoring='loss'&lt;/code&gt; の場合、損失値を使用して早期停止がチェックされます。早期停止が実行された場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="88173ba266bcaafd44bc526091a11bf84a691634" translate="yes" xml:space="preserve">
          <source>Second example</source>
          <target state="translated">第二の例</target>
        </trans-unit>
        <trans-unit id="01969fb763d816468d958ddf55fbcfeb6492bbfe" translate="yes" xml:space="preserve">
          <source>Second, precomputing the graph can give finer control on the nearest neighbors estimation, for instance enabling multiprocessing though the parameter &lt;code&gt;n_jobs&lt;/code&gt;, which might not be available in all estimators.</source>
          <target state="translated">第2に、グラフを事前に計算することで、最近傍推定をより細かく制御できます。たとえば、パラメーター &lt;code&gt;n_jobs&lt;/code&gt; を介したマルチプロセッシングが可能になります。これは、すべての推定で使用できるとは限りません。</target>
        </trans-unit>
        <trans-unit id="e4e2db45443f0fd4ae50799405ca1ddce61eefb7" translate="yes" xml:space="preserve">
          <source>Second, when using a connectivity matrix, single, average and complete linkage are unstable and tend to create a few clusters that grow very quickly. Indeed, average and complete linkage fight this percolation behavior by considering all the distances between two clusters when merging them ( while single linkage exaggerates the behaviour by considering only the shortest distance between clusters). The connectivity graph breaks this mechanism for average and complete linkage, making them resemble the more brittle single linkage. This effect is more pronounced for very sparse graphs (try decreasing the number of neighbors in kneighbors_graph) and with complete linkage. In particular, having a very small number of neighbors in the graph, imposes a geometry that is close to that of single linkage, which is well known to have this percolation instability.</source>
          <target state="translated">第二に、接続性行列を使用する場合、単一リンケージ、平均リンケージ、および完全リンケージは不安定であり、非常に急速に成長する少数のクラスタを生成する傾向があります。実際、平均連結と完全連結は、2つのクラスタを結合する際に、2つのクラスタ間のすべての距離を考慮することで、このパーコレーション挙動に対抗します(一方、単一連結はクラスタ間の最短距離のみを考慮することで挙動を誇張します)。コネクティビティ・グラフは、平均的なリンケージと完全なリンケージのこのメカニズムを壊し、より脆い単一リンケージに似たものにします。この効果は、非常に疎なグラフ(kneeighbors_graphの隣人の数を減らしてみてください)や完全リンケージではより顕著です。特に、グラフ内の隣人の数が非常に少ない場合、このようなパーコレーション不安定性を持つことでよく知られているシングルリンケージに近い幾何学的な形状になります。</target>
        </trans-unit>
        <trans-unit id="d90e68437e39bd56831ac8f750d7707399d6fbb2" translate="yes" xml:space="preserve">
          <source>Secondly, the squared loss function is replaced by the unit deviance \(d\) of a distribution in the exponential family (or more precisely, a reproductive exponential dispersion model (EDM) &lt;a href=&quot;#id34&quot; id=&quot;id32&quot;&gt;11&lt;/a&gt;).</source>
          <target state="translated">次に、損失の2乗関数は、指数型分布族の分布の単位逸脱度\（d \）（より正確には、生殖指数分散モデル（EDM）&lt;a href=&quot;#id34&quot; id=&quot;id32&quot;&gt;11&lt;/a&gt;）に置き換えられます。</target>
        </trans-unit>
        <trans-unit id="53553e63fb4cb7ed1ae88d54b317154b9777e613" translate="yes" xml:space="preserve">
          <source>Seconds used for refitting the best model on the whole dataset.</source>
          <target state="translated">データセット全体の最適なモデルのリフィットに使用される秒数。</target>
        </trans-unit>
        <trans-unit id="a31532b7821dad04a81b3f8844e44fc4c4735bbf" translate="yes" xml:space="preserve">
          <source>Section 3.3 in Christopher M. Bishop: Pattern Recognition and Machine Learning, 2006</source>
          <target state="translated">クリストファー・M・ビショップの3.3節 パターン認識と機械学習,2006</target>
        </trans-unit>
        <trans-unit id="fa04a576bd56d584afacdf30a223dc3f1fde4eb3" translate="yes" xml:space="preserve">
          <source>Section 5.4.4, pp. 252-253.</source>
          <target state="translated">5.4.4節、252~253頁。</target>
        </trans-unit>
        <trans-unit id="d4628726ca2b8e9b183e1257c782a69297176123" translate="yes" xml:space="preserve">
          <source>Section contents</source>
          <target state="translated">セクションの内容</target>
        </trans-unit>
        <trans-unit id="978feab4a35a4b897d5316b48dac562d3091d0c5" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Features for Large-Scale Kernel Machines&amp;rdquo; by A. Rahimi and Benjamin Recht.</source>
          <target state="translated">A. RahimiおよびBenjamin Rechtによる「大規模カーネルマシンのランダム機能」を参照してください。</target>
        </trans-unit>
        <trans-unit id="b31673babc80845a872201a18703583634f75350" translate="yes" xml:space="preserve">
          <source>See &amp;ldquo;Random Fourier Approximations for Skewed Multiplicative Histogram Kernels&amp;rdquo; by Fuxin Li, Catalin Ionescu and Cristian Sminchisescu.</source>
          <target state="translated">Fuxin Li、Catalin IonescuおよびCristian Sminchisescuによる「歪んだ乗法ヒストグラムカーネルのランダムフーリエ近似」を参照してください。</target>
        </trans-unit>
        <trans-unit id="03ac02c3ddabaad90ce0d4962bc965c10cba4eeb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#r95f74c4622c1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;, Chapter 4, Section 4.2, for further details regarding the DotProduct kernel.</source>
          <target state="translated">参照&lt;a href=&quot;#r95f74c4622c1-1&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;ドット積カーネルに関する詳細については、第4章、4.2節、。</target>
        </trans-unit>
        <trans-unit id="0df8f05c9ec568b4cc1c4d54a3085f0ebf794bd9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">参照&lt;a href=&quot;#rw2006&quot; id=&quot;id6&quot;&gt;[RW2006]&lt;/a&gt;、Mat&amp;eacute;rnカーネルの異なる亜種に関する更なる詳細については、pp84を。</target>
        </trans-unit>
        <trans-unit id="dc2d327bd01f6b4c26633dc7230267bf2994fc43" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#rw2006&quot; id=&quot;id7&quot;&gt;[RW2006]&lt;/a&gt;, pp84 for further details regarding the different variants of the Mat&amp;eacute;rn kernel.</source>
          <target state="translated">参照&lt;a href=&quot;#rw2006&quot; id=&quot;id7&quot;&gt;[RW2006]&lt;/a&gt;、Mat&amp;eacute;rnカーネルの異なる亜種に関する更なる詳細については、pp84を。</target>
        </trans-unit>
        <trans-unit id="dd13548eb92de90d6303ee640236c96cda68888f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;Mathematical formulation&lt;/a&gt; for a complete description of the decision function.</source>
          <target state="translated">決定関数の詳細な説明については、&lt;a href=&quot;#svm-mathematical-formulation&quot;&gt;数学的定式化&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="90eaaa0456af60c46de8c81dc16ee15dad424d81" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples/compose/plot_transformed_target.py&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/compose/plot_transformed_target#sphx-glr-auto-examples-compose-plot-transformed-target-py&quot;&gt;examples / compose / plot_transformed_target.pyを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0d70be16f79f29cfb466970ca83989e73f6c00bb" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples/linear_model/plot_polynomial_interpolation.py&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;examples / linear_model / plot_polynomial_interpolation.pyを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="66218b0f5237d32e41f01914713a47022cf20bb9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples/model_selection/plot_learning_curve.py&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/model_selection/plot_learning_curve#sphx-glr-auto-examples-model-selection-plot-learning-curve-py&quot;&gt;examples / model_selection / plot_learning_curve.pyを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="41261fbeb952dd5951bf36801866ce019db00dde" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;Plotting Validation Curves&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/model_selection/plot_validation_curve#sphx-glr-auto-examples-model-selection-plot-validation-curve-py&quot;&gt;検証曲線のプロットを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="6a3b0e6c0d79b7c03e9dbb288652a52d5e7d7fd5" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;Bayesian Ridge Regression&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">&lt;a href=&quot;../../modules/linear_model#bayesian-ridge-regression&quot;&gt;リグレッサの&lt;/a&gt;詳細については、ベイジアンリッジ回帰を参照してください。</target>
        </trans-unit>
        <trans-unit id="824c64b490bd5bd779a22eec474ba042707228d1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;Theil-Sen estimator: generalized-median-based estimator&lt;/a&gt; for more information on the regressor.</source>
          <target state="translated">&lt;a href=&quot;../../modules/linear_model#theil-sen-regression&quot;&gt;リグレッサの&lt;/a&gt;詳細については、Theil-Sen推定量：一般化中央値ベースの推定量を参照してください。</target>
        </trans-unit>
        <trans-unit id="36bf338f19ee54a0199babdefd0eaf5b203f80f4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;Gaussian mixture models&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">推定器の詳細については、&lt;a href=&quot;../../modules/mixture#gmm&quot;&gt;混合ガウスモデル&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="bda58af52a4d947e4c6e336facf5860c69c8478b" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision tree&lt;/a&gt; for more information on the estimator.</source>
          <target state="translated">推定器の詳細については、&lt;a href=&quot;../../modules/tree#tree&quot;&gt;決定木&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="1876d72641fc6bba23917c9ce1b023a0c5308e82" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;Species distribution modeling&lt;/a&gt; for an example of using ROC to model species distribution.</source>
          <target state="translated">ROCを使用して&lt;a href=&quot;../auto_examples/applications/plot_species_distribution_modeling#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py&quot;&gt;種の分布をモデル化&lt;/a&gt;する例については、種の分布のモデリングを参照してください。</target>
        </trans-unit>
        <trans-unit id="3ca47154d5f58b185be5af00ff9392b2598d6abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;Probability calibration of classifiers&lt;/a&gt; for an example of Brier score loss usage to perform probability calibration of classifiers.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/calibration/plot_calibration#sphx-glr-auto-examples-calibration-plot-calibration-py&quot;&gt;分類子の&lt;/a&gt;確率キャリブレーションを実行するためのブライアスコア損失の使用例については、分類子の確率キャリブレーションを参照してください。</target>
        </trans-unit>
        <trans-unit id="282928c19fbfe87fe4167148ff3b6058bc018479" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of classification report usage for hand-written digits.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;手書き数字&lt;/a&gt;の分類レポートの使用例については、手書き数字の認識を参照してください。</target>
        </trans-unit>
        <trans-unit id="72d62eaa2236b9a2dd2c8a6bb04573291c57c36e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;Recognizing hand-written digits&lt;/a&gt; for an example of using a confusion matrix to classify hand-written digits.</source>
          <target state="translated">混同行列を使用して手書き数字を分類する例については、&lt;a href=&quot;../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;手書き数字の認識を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="87880060115f16d38cb34f093520114ae1691683" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt;オブジェクトをデータに適合させる方法の例と、可能性の観点からLedoit-Wolf推定器のパフォーマンスを視覚化する例については、&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;収縮共分散推定：LedoitWolfとOASおよび最大尤度&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="2209166f8c957bd217f6d5f461ba4322d29b02c2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt;オブジェクトをデータに適合させる方法の例については、&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;収縮共分散推定：LedoitWolf対OASおよび最大尤度&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="88a19b944edc191f5f7b057963b65a4e9112c1b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;オブジェクトをデータに適合させる方法の例については、&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;収縮共分散推定：LedoitWolf対OASおよび最大尤度&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="8a3f5dc7dd1289a56afbdf19c9d4415f754d0c74" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood&lt;/a&gt; for an example on how to fit an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; object to data.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt;オブジェクトをデータに適合させる方法の例については、&lt;a href=&quot;../auto_examples/covariance/plot_covariance_estimation#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py&quot;&gt;収縮共分散推定：LedoitWolf対OASおよび最大尤度&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="a2ce4b68a58fc4d4775fc307d3337bfc6ba95951" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledoit-Wolf vs OAS estimation&lt;/a&gt; to visualize the Mean Squared Error difference between a &lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt;&lt;code&gt;LedoitWolf&lt;/code&gt;&lt;/a&gt; and an &lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt;&lt;code&gt;OAS&lt;/code&gt;&lt;/a&gt; estimator of the covariance.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.ledoitwolf#sklearn.covariance.LedoitWolf&quot;&gt; &lt;code&gt;LedoitWolf&lt;/code&gt; &lt;/a&gt;と共分散の&lt;a href=&quot;generated/sklearn.covariance.oas#sklearn.covariance.OAS&quot;&gt; &lt;code&gt;OAS&lt;/code&gt; &lt;/a&gt;推定量との平均二乗誤差の違いを視覚化するには、&lt;a href=&quot;../auto_examples/covariance/plot_lw_vs_oas#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py&quot;&gt;Ledit-WolfとOASの推定&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="8878b5f91edc950d3f968af54f37c8ec353c6370" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; for an illustration of the difference between using a standard (&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt;&lt;/a&gt;) or a robust estimate (&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;covariance.MinCovDet&lt;/code&gt;&lt;/a&gt;) of location and covariance to assess the degree of outlyingness of an observation.</source>
          <target state="translated">観測の範囲外の度合いを評価するために、場所と共分散の標準（&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;covariance.EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;）またはロバスト推定（&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;covariance.MinCovDet&lt;/code&gt; &lt;/a&gt;）を使用する場合の違いについては、&lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;ロバスト共分散推定とマハラノビス距離の関連性&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="030742fc8b624a6be4238fb99cd9f5a0e364d687" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;Robust covariance estimation and Mahalanobis distances relevance&lt;/a&gt; to visualize the difference between &lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt;&lt;code&gt;EmpiricalCovariance&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.empiricalcovariance#sklearn.covariance.EmpiricalCovariance&quot;&gt; &lt;code&gt;EmpiricalCovariance&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; の&lt;/a&gt;共分散推定量の違いをマハラノビス距離の観点から視覚化するには、&lt;a href=&quot;../auto_examples/covariance/plot_mahalanobis_distances#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py&quot;&gt;ロバストな共分散推定とマハラノビス距離の関連性&lt;/a&gt;を参照してください（精度行列のより良い推定値も得られます）。</target>
        </trans-unit>
        <trans-unit id="f9a056a85b47a4a6c1a6d704788263d39761f07a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;Robust vs Empirical covariance estimate&lt;/a&gt; for an example on how to fit a &lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt;&lt;code&gt;MinCovDet&lt;/code&gt;&lt;/a&gt; object to data and see how the estimate remains accurate despite the presence of outliers.</source>
          <target state="translated">参照してください。&lt;a href=&quot;../auto_examples/covariance/plot_robust_vs_empirical_covariance#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py&quot;&gt;経験的共分散推定値対堅牢&lt;/a&gt;フィットする方法については例えば&lt;a href=&quot;generated/sklearn.covariance.mincovdet#sklearn.covariance.MinCovDet&quot;&gt; &lt;code&gt;MinCovDet&lt;/code&gt; の&lt;/a&gt;推定値が外れ値の存在にもかかわらず、正確なままどのようにデータへのオブジェクトをしてご覧ください。</target>
        </trans-unit>
        <trans-unit id="995b452653e2a34828a53fff1225e032a84a1ed7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;Gradient Boosting regression&lt;/a&gt; for an example of mean squared error usage to evaluate gradient boosting regression.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/ensemble/plot_gradient_boosting_regression#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py&quot;&gt;勾配ブースティング回帰&lt;/a&gt;を評価するための平均二乗誤差の使用例については、勾配ブースティング回帰を参照してください。</target>
        </trans-unit>
        <trans-unit id="c70bb54b9f9c6d372a94de7482636d40519b333f" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForest example&lt;/a&gt; for an illustration of the use of IsolationForest.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/ensemble/plot_isolation_forest#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py&quot;&gt;IsolationForestの使用例&lt;/a&gt;については、IsolationForestの例を参照してください。</target>
        </trans-unit>
        <trans-unit id="462e8cdc93001fb7a3648b1195482e1f8b22fe44" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;Test with permutations the significance of a classification score&lt;/a&gt; for an example of accuracy score usage using permutations of the dataset.</source>
          <target state="translated">データセットの順列を使用した精度スコアの使用例については、順列を使用し&lt;a href=&quot;../auto_examples/feature_selection/plot_permutation_test_for_classification#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py&quot;&gt;た分類スコアの有意性のテストを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="39b73a8956b97e37d2a1a56a5487c771ec6755e2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt; for an example of zero one loss usage to perform recursive feature elimination with cross-validation.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/feature_selection/plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;相互検証&lt;/a&gt;を使用して再帰的な機能の削除を実行するためのゼロワンロスの使用例については、相互検証を使用した再帰的な機能の削除を参照してください。</target>
        </trans-unit>
        <trans-unit id="92f30204fbfed37d4520688e6847c0f1dec6d444" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;Lasso and Elastic Net for Sparse Signals&lt;/a&gt; for an example of R&amp;sup2; score usage to evaluate Lasso and Elastic Net on sparse signals.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/linear_model/plot_lasso_and_elasticnet#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py&quot;&gt;スパース信号&lt;/a&gt;でLassoおよびElastic Netを評価するためのR&amp;sup2;スコアの使用例については、スパース信号のLassoおよびElastic Netを参照してください。</target>
        </trans-unit>
        <trans-unit id="01a78f9ef24e4fc8896bfa27a1c142f94096fbf4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;Polynomial interpolation&lt;/a&gt; for Ridge regression using created polynomial features.</source>
          <target state="translated">作成された多項式機能を使用したリッジ回帰の&lt;a href=&quot;../auto_examples/linear_model/plot_polynomial_interpolation#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py&quot;&gt;多項式補間&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="6cc1903f7fccc8472139b491e9c35281e331be73" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;Comparison of Manifold Learning methods&lt;/a&gt; for an example of dimensionality reduction on a toy &amp;ldquo;S-curve&amp;rdquo; dataset.</source>
          <target state="translated">おもちゃの「Sカーブ」データセットの次元削減の例については、&lt;a href=&quot;../auto_examples/manifold/plot_compare_methods#sphx-glr-auto-examples-manifold-plot-compare-methods-py&quot;&gt;多様体学習法の比較を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="c13f7bab27de634fe8533a5ffc3f4d5d442fb940" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;Manifold learning on handwritten digits: Locally Linear Embedding, Isomap&amp;hellip;&lt;/a&gt; for an example of dimensionality reduction on handwritten digits.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/manifold/plot_lle_digits#sphx-glr-auto-examples-manifold-plot-lle-digits-py&quot;&gt;手書き数字&lt;/a&gt;の次元削減の例については、手書き数字の多様体学習：ローカル線形埋め込み、Isomap&amp;hellip;を参照してください。</target>
        </trans-unit>
        <trans-unit id="2a32db7a757930b4f797df7e8d06a3cd21abcff6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参照&lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;玩具データセット上の外れ値を検出するための異常検出アルゴリズムの比較&lt;/a&gt;の比較のため&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;（外れ値検出手法のように動作するように調整）で共分散ベースの外れ値検出&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="43f0e98d020880753d56a5cecd019501b6cb864a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; の&lt;/a&gt;比較については、&lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;おもちゃのデータセットでの異常値検出のための異常検出アルゴリズムの比較を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="add8ccecfab3f9c846b3f2682673366366734b83" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">他の異常検出方法との比較については、&lt;a href=&quot;../auto_examples/miscellaneous/plot_anomaly_comparison#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py&quot;&gt;おもちゃのデータセット&lt;/a&gt;での異常値検出のための異常検出アルゴリズムの比較を参照してください。</target>
        </trans-unit>
        <trans-unit id="6cee09c79ab5ccf2f8ea1b726ccad8beb5f01cbf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">ジョンソン・リンデンシュトラウスの補題の理論的説明とスパースランダム行列を使用した経験的検証については、&lt;a href=&quot;../auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py&quot;&gt;ランダム射影を埋め込むためのジョンソン・リンデンシュトラウスの限界を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="ba387b296d0109ccfdd27d435e72e0bda0b98a94" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture&lt;/a&gt; for an example plotting the confidence ellipsoids for the &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; with different &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; for different values of the parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt;.</source>
          <target state="translated">パラメータ &lt;code&gt;weight_concentration_prior&lt;/code&gt; のさまざまな値に対して、異なる &lt;code&gt;weight_concentration_prior_type&lt;/code&gt; を使用した&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; の&lt;/a&gt;信頼楕円体をプロットする例については、「&lt;a href=&quot;../auto_examples/mixture/plot_concentration_prior#sphx-glr-auto-examples-mixture-plot-concentration-prior-py&quot;&gt;分散ベイジアンガウス混合の濃度事前型分析&lt;/a&gt;」を参照してください。</target>
        </trans-unit>
        <trans-unit id="17317cd9be65f918f2c9598fbac39ad346f5db56" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt; for an example on plotting the confidence ellipsoids for both &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; の&lt;/a&gt;両方の信頼楕円体をプロットする例については、&lt;a href=&quot;../auto_examples/mixture/plot_gmm#sphx-glr-auto-examples-mixture-plot-gmm-py&quot;&gt;Gaussian Mixture Model Ellipsoids&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="a5877cbb374e3dc33496a562d7ff812fdb5db635" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM covariances&lt;/a&gt; for an example of using the Gaussian mixture as clustering on the iris dataset.</source>
          <target state="translated">アイリスデータセットのクラスタリングとして混合ガウスを使用する例については、&lt;a href=&quot;../auto_examples/mixture/plot_gmm_covariances#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py&quot;&gt;GMM共分散&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="235746c777e5faff74a54e9f92e2aa47946dcca8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;Density Estimation for a Gaussian mixture&lt;/a&gt; for an example on plotting the density estimation.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/mixture/plot_gmm_pdf#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py&quot;&gt;密度推定の&lt;/a&gt;プロット例については、ガウス混合の密度推定を参照してください。</target>
        </trans-unit>
        <trans-unit id="1f45342ed85fb843511e05db7aa53da9e05cd4c8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;Gaussian Mixture Model Selection&lt;/a&gt; for an example of model selection performed with classical Gaussian mixture.</source>
          <target state="translated">古典的なガウス混合で実行されるモデル選択の例については、&lt;a href=&quot;../auto_examples/mixture/plot_gmm_selection#sphx-glr-auto-examples-mixture-plot-gmm-selection-py&quot;&gt;ガウス混合モデルの選択&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="2675c64adf13cc79a9b07f8da3e0d3af0522fc69" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a &lt;code&gt;pipeline.Pipeline&lt;/code&gt; instance.</source>
          <target state="translated">分類子を使用したテキストドキュメントの特徴抽出（n-gram count vectorizerおよびTF-IDFトランスフォーマー）からのグリッド検索カップリングパラメーターの例については、&lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;テキスト特徴の抽出と評価の&lt;/a&gt;ためのサンプルパイプラインを参照してください（ここでは、いずれかのエラスティックネットを使用したSGDでトレーニングされた線形SVMまたはL2ペナルティ）、 &lt;code&gt;pipeline.Pipeline&lt;/code&gt; インスタンスを使用します。</target>
        </trans-unit>
        <trans-unit id="da92f3b35d742326e0c71721384ca2aaccbfcbb6" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;Confusion matrix&lt;/a&gt; for an example of using a confusion matrix to evaluate classifier output quality.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/model_selection/plot_confusion_matrix#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py&quot;&gt;混同行列&lt;/a&gt;を使用して分類子の出力品質を評価する例については、混同行列を参照してください。</target>
        </trans-unit>
        <trans-unit id="de7b9e4f40b1dbfe2688a95ace15280b606fa175" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; usage to estimate parameters using grid search with nested cross-validation.</source>
          <target state="translated">入れ子の交差検証を使用したグリッド検索を使用してパラメーターを推定するための&lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt;使用例については、&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;交差検証&lt;/a&gt;を使用したグリッド検索を使用したパラメーター推定を参照してください。</target>
        </trans-unit>
        <trans-unit id="907fb39fc7f1b14d7a7b9cc2b05542f6688793e4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of Grid Search computation on the digits dataset.</source>
          <target state="translated">数字データセットでのグリッド検索計算の例については、&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;交差検証&lt;/a&gt;を伴うグリッド検索を使用したパラメーター推定を参照してください。</target>
        </trans-unit>
        <trans-unit id="400cd83fcd5e25dceebfea56b549d5be061f5ba4" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;Parameter estimation using grid search with cross-validation&lt;/a&gt; for an example of classification report usage for grid search with nested cross-validation.</source>
          <target state="translated">入れ子の交差検証を使用したグリッド検索の分類レポートの使用例については、&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_digits#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py&quot;&gt;交差検証&lt;/a&gt;を使用したグリッド検索を使用したパラメーター推定を参照してください。</target>
        </trans-unit>
        <trans-unit id="588e2a7cc51b06cfa971b7f26bd8bf4053207cf1" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_refit_callable#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py&quot;&gt;Balance model complexity and cross-validated score&lt;/a&gt; for an example of using &lt;code&gt;refit=callable&lt;/code&gt; interface in &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. The example shows how this interface adds certain amount of flexibility in identifying the &amp;ldquo;best&amp;rdquo; estimator. This interface can also be used in multiple metrics evaluation.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; で&lt;/a&gt; &lt;code&gt;refit=callable&lt;/code&gt; インターフェースを使用する例については、&lt;a href=&quot;../auto_examples/model_selection/plot_grid_search_refit_callable#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py&quot;&gt;バランスモデルの複雑さと相互検証されたスコア&lt;/a&gt;を参照してください。この例は、このインターフェースが「最良の」推定量を特定する際にある程度の柔軟性を追加する方法を示しています。このインターフェイスは、複数のメトリック評価でも使用できます。</target>
        </trans-unit>
        <trans-unit id="2735aad85c6c7c554984533b716de0827c908e17" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; being used to evaluate multiple metrics simultaneously.</source>
          <target state="translated">複数のメトリックを同時に評価するために使用される&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; の&lt;/a&gt;例については、&lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;cross_val_scoreおよびGridSearchCVでのマルチメトリック評価のデモを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="c2ffbe0f12938b51592ad9e927a7d22caaeca8af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV&lt;/a&gt; for an example usage.</source>
          <target state="translated">使用例については、&lt;a href=&quot;../auto_examples/model_selection/plot_multi_metric_evaluation#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py&quot;&gt;cross_val_scoreとGridSearchCVのマルチメトリック評価のデモを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="8476e4237a00d9dd8e2ca35734caeb2c23a0697e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;Nested versus non-nested cross-validation&lt;/a&gt; for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.</source>
          <target state="translated">アイリスデータセットの相互検証ループ内のグリッド検索の例については、&lt;a href=&quot;../auto_examples/model_selection/plot_nested_cross_validation_iris#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py&quot;&gt;ネストされた検証&lt;/a&gt;とネストされていない検証を参照してください。これは、グリッド検索を使用したモデルのパフォーマンスを評価するためのベストプラクティスです。</target>
        </trans-unit>
        <trans-unit id="e8dfb2ba828b857661aeb6d59ff74f5c4db05d22" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; usage to evaluate classifier output quality.</source>
          <target state="translated">分類子の出力品質を評価するための&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; の&lt;/a&gt;使用例については、&lt;a href=&quot;../auto_examples/model_selection/plot_precision_recall#sphx-glr-auto-examples-model-selection-plot-precision-recall-py&quot;&gt;Precision-Recall&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="7914d54070b906eba7716c438acf436730af131e" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;Receiver Operating Characteristic (ROC)&lt;/a&gt; for an example of using ROC to evaluate the quality of the output of a classifier.</source>
          <target state="translated">ROCを使用して分類子の出力の品質を評価する例については、&lt;a href=&quot;../auto_examples/model_selection/plot_roc#sphx-glr-auto-examples-model-selection-plot-roc-py&quot;&gt;受信者動作特性（ROC）&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="61240d29f349f145d4e8cf44909bfb9cc2f016b2" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;Receiver Operating Characteristic (ROC) with cross validation&lt;/a&gt; for an example of using ROC to evaluate classifier output quality, using cross-validation.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/model_selection/plot_roc_crossval#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py&quot;&gt;相互検証&lt;/a&gt;を使用してROCを使用して分類子の出力品質を評価する例については、相互検証を伴う受信者操作特性（ROC）を参照してください。</target>
        </trans-unit>
        <trans-unit id="2194fe880eec73b4ed37b8700c0f77c050a462fc" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Outlier detection with Local Outlier Factor (LOF)&lt;/a&gt; for an illustration of the use of &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;の使用例については、&lt;a href=&quot;../auto_examples/neighbors/plot_lof_outlier_detection#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py&quot;&gt;Local Outlier Factor（LOF）&lt;/a&gt;を使用した外れ値の検出を参照してください。</target>
        </trans-unit>
        <trans-unit id="bb13fcb17f205551a70f65831a46478e0af0f276" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; with &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; (tuned to perform like an outlier detection method) and a covariance-based outlier detection with &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">参照&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;玩具データセット上の外れ値を検出するための異常検出アルゴリズムの比較&lt;/a&gt;の比較のため&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;（外れ値検出手法のように動作するように調整）で共分散ベースの外れ値検出&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="64196936345ba93c97149a5b0ef386464e9766b9" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison of the &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt;&lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.covariance.ellipticenvelope#sklearn.covariance.EllipticEnvelope&quot;&gt; &lt;code&gt;covariance.EllipticEnvelope&lt;/code&gt; の&lt;/a&gt;比較については、&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;おもちゃのデータセットの異常値検出のための異常検出アルゴリズムの比較を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="34db9fa5546a4563c9e371d735571ffbe05f0c7c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;Comparing anomaly detection algorithms for outlier detection on toy datasets&lt;/a&gt; for a comparison with other anomaly detection methods.</source>
          <target state="translated">他の異常検出方法との比較については、&lt;a href=&quot;../auto_examples/plot_anomaly_comparison#sphx-glr-auto-examples-plot-anomaly-comparison-py&quot;&gt;おもちゃのデータセット&lt;/a&gt;での異常値検出のための異常検出アルゴリズムの比較を参照してください。</target>
        </trans-unit>
        <trans-unit id="624945e6b02bb2ff2c43f28f85ed4813c5cbe96d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;The Johnson-Lindenstrauss bound for embedding with random projections&lt;/a&gt; for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.</source>
          <target state="translated">Johnson-Lindenstrauss補題の理論的な説明とスパースランダム行列を使用した経験的検証については、&lt;a href=&quot;../auto_examples/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-plot-johnson-lindenstrauss-bound-py&quot;&gt;ランダムな投影を埋め込むためのJohnson-Lindenstrauss境界を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="9ca7b8e34286a27914e5e700a286fbed9102f4af" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;One-class SVM with non-linear kernel (RBF)&lt;/a&gt; for visualizing the frontier learned around some data by a &lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;svm.OneClassSVM&lt;/code&gt; &lt;/a&gt;オブジェクトによって一部のデータについて学習したフロンティアを視覚化する方法については、&lt;a href=&quot;../auto_examples/svm/plot_oneclass#sphx-glr-auto-examples-svm-plot-oneclass-py&quot;&gt;非線形カーネル（RBF）&lt;/a&gt;を備えた1クラスSVMを参照してください。</target>
        </trans-unit>
        <trans-unit id="76c663b6a0471e4c53ba854f9c09becf8ef59fc7" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt; usage to classify text documents.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;テキストドキュメントを&lt;/a&gt;分類するための&lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; の&lt;/a&gt;使用例については、スパース機能を使用したテキストドキュメントの分類を参照してください。</target>
        </trans-unit>
        <trans-unit id="188cc26ffe635b802535768a1802c77d30908617" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of classification report usage for text documents.</source>
          <target state="translated">&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;テキストドキュメント&lt;/a&gt;の分類レポートの使用例については、スパース機能を使用したテキストドキュメントの分類を参照してください。</target>
        </trans-unit>
        <trans-unit id="19118774a723324b6225f3d83bcf9761f94d3619" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;Classification of text documents using sparse features&lt;/a&gt; for an example of using a confusion matrix to classify text documents.</source>
          <target state="translated">混同行列を使用してテキストドキュメントを分類する例については、&lt;a href=&quot;../auto_examples/text/plot_document_classification_20newsgroups#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py&quot;&gt;スパース機能&lt;/a&gt;を使用したテキストドキュメントの分類を参照してください。</target>
        </trans-unit>
        <trans-unit id="81a2b2d1fb5035ca6b501c666e8a41c6286b60de" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;Specifying multiple metrics for evaluation&lt;/a&gt; for an example.</source>
          <target state="translated">例については、&lt;a href=&quot;../grid_search#multimetric-grid-search&quot;&gt;評価の&lt;/a&gt;ための複数のメトリックの指定を参照してください。</target>
        </trans-unit>
        <trans-unit id="479250f0ad90f3ce8d5fd16594b9c17af606dc2c" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt; in the online documentation for a discussion of the choice of &lt;code&gt;algorithm&lt;/code&gt; and &lt;code&gt;leaf_size&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;algorithm&lt;/code&gt; と &lt;code&gt;leaf_size&lt;/code&gt; の選択については、オンラインドキュメントの「&lt;a href=&quot;../neighbors#neighbors&quot;&gt;Nearest Neighbors&lt;/a&gt;」を参照してください。</target>
        </trans-unit>
        <trans-unit id="91bb5f21ad92edefb7cd46dcdff8e31af1c98298" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;../tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on the pruning process.</source>
          <target state="translated">参照してください。&lt;a href=&quot;../tree#minimal-cost-complexity-pruning&quot;&gt;最小限のコスト・複雑剪定を&lt;/a&gt;剪定プロセスの詳細については。</target>
        </trans-unit>
        <trans-unit id="91032a83e07b0024745974d4bc72e492c7c9e85a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;compose#combining-estimators&quot;&gt;Pipelines and composite estimators&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;compose#combining-estimators&quot;&gt;パイプラインと複合推定量を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="516b0abd274bf0e8eb7951cfd8d017257e70560d" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;Loading features from dicts&lt;/a&gt; for categorical features that are represented as a dict, not as scalars.</source>
          <target state="translated">スカラーとしてではなく、dictとして表されるカテゴリカル機能については&lt;a href=&quot;feature_extraction#dict-feature-extraction&quot;&gt;、dictsからの機能の読み込みを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5f5bdda151c122a6b0f331c022a3fe3419eba6e8" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">このデータセットの詳細については、&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;こちら&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="59cc7550d6ebef4a36dc7cbd048f831a5c0d0f3a" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdfを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="58869cd4ecac8051c9d79dfaa9dbb2a543b85dfe" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;&amp;ldquo;Efficient additive kernels via explicit feature maps&amp;rdquo;&lt;/a&gt; A. Vedaldi and A. Zisserman, Pattern Analysis and Machine Intelligence, 2011</source>
          <target state="translated">&lt;a href=&quot;http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi11efficient.pdf&quot;&gt;「明示的な機能マップによる効率的な追加カーネル」を&lt;/a&gt;参照してください。A。VedaldiおよびA. Zisserman、パターン分析およびマシンインテリジェンス、2011年</target>
        </trans-unit>
        <trans-unit id="8ccf3f09b07311e149a69a4c5ed81e792cfab2aa" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;here&lt;/a&gt; for more information about this dataset.</source>
          <target state="translated">このデータセットの詳細については、&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits&quot;&gt;こちら&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="4bdca7573215dd8d9f679d272cb9da9a534f1291" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;here&lt;/a&gt; for more information on this dataset.</source>
          <target state="translated">このデータセットの詳細については、&lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;こちら&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="eb3a5aff676c4d5166ca0015430772938f3b0abf" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt; for details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ee1e742783ffe82079419a7f74e91fb7300f9192" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf&quot;&gt;https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdfを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="7191cbc48e1c8b07d612d6ecdb398fe05677ce16" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.</source>
          <target state="translated">詳細については&lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;、スコアリングパラメーター：モデル評価ルールの定義&lt;/a&gt;を参照してください。Irisデータセットの場合、サンプルはターゲットクラス間でバランスが取れているため、精度とF1スコアはほぼ同じです。</target>
        </trans-unit>
        <trans-unit id="e083d29e5fc318a8e4c7186d224d71159333e317" translate="yes" xml:space="preserve">
          <source>See &lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;Novelty and Outlier Detection&lt;/a&gt; for the description and usage of OneClassSVM.</source>
          <target state="translated">OneClassSVMの説明と使用法については、新規性&lt;a href=&quot;outlier_detection#outlier-detection&quot;&gt;と外れ値の検出&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="2bf27f073ae6fdc435309a3de7aa195bb3e33f73" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;predict_proba&lt;/code&gt; for details.</source>
          <target state="translated">詳細については、 &lt;code&gt;predict_proba&lt;/code&gt; を参照してください。</target>
        </trans-unit>
        <trans-unit id="9a6c19ee072204bfa0caf7b0899caf92ad1a79e0" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;refit&lt;/code&gt; parameter for more information on allowed values.</source>
          <target state="translated">許可される値の詳細については、 &lt;code&gt;refit&lt;/code&gt; パラメーターを参照してください。</target>
        </trans-unit>
        <trans-unit id="fcd84460747232330056c00c1a39fd6ed47410b5" translate="yes" xml:space="preserve">
          <source>See &lt;code&gt;scoring&lt;/code&gt; parameter to know more about multiple metric evaluation.</source>
          <target state="translated">複数のメトリック評価の詳細については、 &lt;code&gt;scoring&lt;/code&gt; パラメーターを参照してください。</target>
        </trans-unit>
        <trans-unit id="61a08f389a25b863d0fca5015a2885ff6fd5c8cd" translate="yes" xml:space="preserve">
          <source>See Also:</source>
          <target state="translated">も参照してください。</target>
        </trans-unit>
        <trans-unit id="dd75486b56d3a12e77b37b7ce59de88eb8618b01" translate="yes" xml:space="preserve">
          <source>See Rasmussen and Williams 2006, pp84 for details regarding the different variants of the Matern kernel.</source>
          <target state="translated">Matern カーネルのさまざまなバリエーションについての詳細は Rasmussen and Williams 2006,pp84 を参照してください。</target>
        </trans-unit>
        <trans-unit id="2d8243a2c0e464492c9d563c4f92c56ae3421bcc" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="translated">参照:</target>
        </trans-unit>
        <trans-unit id="319ca132af6f206834626d4c0565d67f882f0bf4" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;../../modules/tree#minimal-cost-complexity-pruning&quot;&gt;Minimal Cost-Complexity Pruning&lt;/a&gt; for details on pruning.</source>
          <target state="translated">&lt;a href=&quot;../../modules/tree#minimal-cost-complexity-pruning&quot;&gt;プルーニング&lt;/a&gt;の詳細については、Minimal Cost-ComplexityPruningも参照してください。</target>
        </trans-unit>
        <trans-unit id="eddd8dfbe32e6e27a2f2d9692940c76ecde49164" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;neighbors#nca-dim-reduction&quot;&gt;Dimensionality reduction&lt;/a&gt; for dimensionality reduction with Neighborhood Components Analysis.</source>
          <target state="translated">近傍コンポーネント分析による&lt;a href=&quot;neighbors#nca-dim-reduction&quot;&gt;次元削減&lt;/a&gt;については、次元削減も参照してください。</target>
        </trans-unit>
        <trans-unit id="16d6db1c15da7e05f275e12f2b52c16bcc8dc1f7" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_permutation_importance#sphx-glr-auto-examples-inspection-plot-permutation-importance-py&quot;&gt;Permutation Importance vs Random Forest Feature Importance (MDI)&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;plot_permutation_importance#sphx-glr-auto-examples-inspection-plot-permutation-importance-py&quot;&gt;順列の重要性とランダムフォレストの特徴の重要性（MDI）&lt;/a&gt;も参照してください。</target>
        </trans-unit>
        <trans-unit id="00556fb4b47eda5d6ddfa3723da8312c58733ada" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;Recursive feature elimination with cross-validation&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;plot_rfe_with_cross_validation#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py&quot;&gt;相互検証による再帰的な特徴の排除&lt;/a&gt;も参照してください。</target>
        </trans-unit>
        <trans-unit id="9232d9babf570066106c095c7f9e14cb2421acee" translate="yes" xml:space="preserve">
          <source>See also &lt;a href=&quot;plot_roc_curve_visualization_api#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py&quot;&gt;ROC Curve with Visualization API&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;plot_roc_curve_visualization_api#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py&quot;&gt;VisualizationAPIを使用したROC曲線&lt;/a&gt;も参照してください。</target>
        </trans-unit>
        <trans-unit id="371a87eafb4de078ff674d69a5a89c186532eb49" translate="yes" xml:space="preserve">
          <source>See also:</source>
          <target state="translated">も参照してください。</target>
        </trans-unit>
        <trans-unit id="bbbf1c8bb1bb44153dbb121ba5ff682161041559" translate="yes" xml:space="preserve">
          <source>See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&amp;rdquo;s AUTOCLASS II conceptual clustering system finds 3 classes in the data.</source>
          <target state="translated">1988 MLC Proceedings、54-64も参照してください。Cheeseman et alのAUTOCLASS II概念クラスタリングシステムは、データから3つのクラスを見つけます。</target>
        </trans-unit>
        <trans-unit id="96949ffbfe0e5b8e858a6b32bba0567fa5dcf8f9" translate="yes" xml:space="preserve">
          <source>See glossary entry for &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cross-validation-estimator&quot;&gt;cross-validation estimator&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cross-validation-estimator&quot;&gt;交差検定推定量&lt;/a&gt;については、用語集のエントリを参照してください。</target>
        </trans-unit>
        <trans-unit id="4ce8930e7f553fab96c5eb4cdba6059705f0a1b9" translate="yes" xml:space="preserve">
          <source>See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">スケーリングと正規化の詳細については、&lt;a href=&quot;preprocessing#preprocessing&quot;&gt;データの前処理の&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="6b55a2c7dcbc914b3c4abb672c6103792d08facf" translate="yes" xml:space="preserve">
          <source>See sklearn.svm.predict for a complete list of parameters.</source>
          <target state="translated">パラメータの完全なリストはsklearn.svm.predictを参照してください。</target>
        </trans-unit>
        <trans-unit id="8c30624bfa9869c6a4a63a1b052f17576abbc1b5" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt; to download &lt;code&gt;svm_gui.py&lt;/code&gt;; add data points of both classes with right and left button, fit the model and change parameters and data.</source>
          <target state="translated">&lt;code&gt;svm_gui.py&lt;/code&gt; をダウンロードするには、&lt;a href=&quot;../../auto_examples/applications/svm_gui#sphx-glr-auto-examples-applications-svm-gui-py&quot;&gt;SVM GUI&lt;/a&gt;を参照してください。左右のボタンで両方のクラスのデータポイントを追加し、モデルを適合させ、パラメーターとデータを変更します。</target>
        </trans-unit>
        <trans-unit id="3a7904b44fb635dd1b8e25248a204eaa4fae3a1b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの「&lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;バイクラスタリング評価」&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="68bd165827c5ef6d955b9032ff7e059af8a91538" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;クラスタリングパフォーマンス評価の&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="32e5d32ee9a61e6d932c5ca6a73a2f56a975703b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;https://scikit-learn.org/0.23/visualizations.html#visualizations&quot;&gt;Visualizations&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの「&lt;a href=&quot;https://scikit-learn.org/0.23/visualizations.html#visualizations&quot;&gt;視覚化」&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="8dd9c0a0a464abab54cd5ae3d828ecf303587e8d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;metrics#metrics&quot;&gt;ペアワイズメトリック、アフィニティ、カーネルの&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="a5b49cc34cb79ec02e159e95ecb887eb0b2cb87b" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;Classification metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;model_evaluation#classification-metrics&quot;&gt;分類指標の&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="a370028df0ac77d50f24c414c79435536844962d" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Metrics and scoring: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、「&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;メトリクスとスコアリング：予測の品質の定量化」&lt;/a&gt;セクションおよびユーザーガイドの「&lt;a href=&quot;metrics#metrics&quot;&gt;ペアワイズメトリクス、アフィニティ、カーネル」&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="9391e01adcbcd6eab5489ba5c5bbde2b34c1c767" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;Model evaluation: quantifying the quality of predictions&lt;/a&gt; section and the &lt;a href=&quot;metrics#metrics&quot;&gt;Pairwise metrics, Affinities and Kernels&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、&lt;a href=&quot;model_evaluation#model-evaluation&quot;&gt;モデル評価：予測の質の定量化&lt;/a&gt;セクションと、ユーザーガイドの&lt;a href=&quot;metrics#metrics&quot;&gt;ペアワイズメトリック、アフィニティとカーネル&lt;/a&gt;セクションを参照してください。</target>
        </trans-unit>
        <trans-unit id="794b0f5d5def59a318bd787a4fccdd542a21003c" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;Multilabel ranking metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;model_evaluation#multilabel-ranking-metrics&quot;&gt;マルチラベルランキング指標&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="2e87795fde7a0f4562bca5bb85f3c7f5918727b2" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;Regression metrics&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;model_evaluation#regression-metrics&quot;&gt;回帰メトリックスの&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="e8449bc2e3e9fd1500a092c7a467f1094a642fdf" translate="yes" xml:space="preserve">
          <source>See the &lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;The scoring parameter: defining model evaluation rules&lt;/a&gt; section of the user guide for further details.</source>
          <target state="translated">詳細については、ユーザーガイドの&lt;a href=&quot;model_evaluation#scoring-parameter&quot;&gt;「スコアリングパラメーター：モデル評価ルールの定義」&lt;/a&gt;セクションをご覧ください。</target>
        </trans-unit>
        <trans-unit id="bc10a00d51f81094bb499f5ba451c68f15309214" translate="yes" xml:space="preserve">
          <source>See the console&amp;rsquo;s output for further details about each model.</source>
          <target state="translated">各モデルの詳細については、コンソールの出力を参照してください。</target>
        </trans-unit>
        <trans-unit id="cd81e4d9092f6289f9eb153c5b671f6c9ec59b00" translate="yes" xml:space="preserve">
          <source>See the docstring of DistanceMetric for a list of available metrics.</source>
          <target state="translated">利用可能なメトリクスのリストは DistanceMetric の docstring を参照してください。</target>
        </trans-unit>
        <trans-unit id="bf132d2b0dc3be6b88274385f87b0ee3f849742c" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics.</source>
          <target state="translated">これらのメトリクスの詳細については、scipy.spatial.distanceのドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="7af63b893a630b06c001dfe05c36e8144bafc593" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">これらのメトリックの詳細については、scipy.spatial.distanceのドキュメントを参照してください：&lt;a href=&quot;http://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;http&lt;/a&gt; : //docs.scipy.org/doc/scipy/reference/spatial.distance.html</target>
        </trans-unit>
        <trans-unit id="26decb2493981e4fa0291aaddd53d2d9f9052651" translate="yes" xml:space="preserve">
          <source>See the documentation for scipy.spatial.distance for details on these metrics: &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&lt;/a&gt;</source>
          <target state="translated">これらの指標の詳細については、scipy.spatial.distanceのドキュメントを参照してください：&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;https&lt;/a&gt;：//docs.scipy.org/doc/scipy/reference/spatial.distance.html</target>
        </trans-unit>
        <trans-unit id="c235949c8aa0b531ecb9dfa56db515940237097e" translate="yes" xml:space="preserve">
          <source>See the examples below and the doc string of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">詳細については、以下の例と&lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt;のドキュメント文字列を参照してください。</target>
        </trans-unit>
        <trans-unit id="21e6c58453c3a42f9380294c0c23f1e8e3252a3a" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;NeighborhoodComponentsAnalysis.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">詳細については、以下の例と&lt;a href=&quot;generated/sklearn.neighbors.neighborhoodcomponentsanalysis#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt; &lt;code&gt;NeighborhoodComponentsAnalysis.fit&lt;/code&gt; &lt;/a&gt;のdocstringを参照してください。</target>
        </trans-unit>
        <trans-unit id="e3733f36a35b17995708cf55601d9baf4bb2149b" translate="yes" xml:space="preserve">
          <source>See the examples below and the docstring of &lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt;&lt;code&gt;MLPClassifier.fit&lt;/code&gt;&lt;/a&gt; for further information.</source>
          <target state="translated">詳細については、以下の例と&lt;a href=&quot;generated/sklearn.neural_network.mlpclassifier#sklearn.neural_network.MLPClassifier.fit&quot;&gt; &lt;code&gt;MLPClassifier.fit&lt;/code&gt; &lt;/a&gt;のdocstringを参照してください。</target>
        </trans-unit>
        <trans-unit id="0f593defdf84cd9d54340a0b9eb8bdbba2164c5f" translate="yes" xml:space="preserve">
          <source>See the examples below for further information.</source>
          <target state="translated">詳しくは下記の例をご覧ください。</target>
        </trans-unit>
        <trans-unit id="43e09506578d0fedfc6592860be1e23c1f8ef43b" translate="yes" xml:space="preserve">
          <source>See the examples for such an application.</source>
          <target state="translated">そのような応用例をご覧ください。</target>
        </trans-unit>
        <trans-unit id="e8c17521507d95b1954b9918e527f968af48b835" translate="yes" xml:space="preserve">
          <source>See. &amp;ldquo;Pattern Recognition and Machine Learning&amp;rdquo; by C. Bishop, 12.2.1 p. 574 or &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">見る。C.ビショップによる「パターン認識と機械学習」、12.2.1ページ。574または&lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e4871111c8505b7690af20e518e753ae1b90a5ad" translate="yes" xml:space="preserve">
          <source>Seed for the random number generator used for probability estimates. 0 by default.</source>
          <target state="translated">確率推定に使用される乱数発生器のシード。デフォルトでは0。</target>
        </trans-unit>
        <trans-unit id="72c84d205a7667dfdb05c6ebaaf98f08a838df92" translate="yes" xml:space="preserve">
          <source>Seeding is performed using a binning technique for scalability.</source>
          <target state="translated">種付けは、スケーラビリティのためのビニング技術を用いて行われます。</target>
        </trans-unit>
        <trans-unit id="f1f3844996349c701e3db8be5a62a8ace310a543" translate="yes" xml:space="preserve">
          <source>Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.</source>
          <target state="translated">カーネルの初期化に使用されるシード。設定されていない場合は、グリッドサイズに帯域幅を、その他のパラメータにはデフォルト値を指定して、clustering.get_bin_seedsによってシードが計算されます。</target>
        </trans-unit>
        <trans-unit id="1a053c7e782c53a91d6d509bf6a99224f4b893d2" translate="yes" xml:space="preserve">
          <source>Segmenting the picture of greek coins in regions</source>
          <target state="translated">ギリシャコインの地域別画像のセグメンテーション</target>
        </trans-unit>
        <trans-unit id="05c2c519388dfeab1d2da32ad0c3a55d08148aed" translate="yes" xml:space="preserve">
          <source>Select &lt;code&gt;min_samples&lt;/code&gt; random samples from the original data and check whether the set of data is valid (see &lt;code&gt;is_data_valid&lt;/code&gt;).</source>
          <target state="translated">元のデータから &lt;code&gt;min_samples&lt;/code&gt; ランダムサンプルを選択し、データのセットが有効かどうかを確認します（ &lt;code&gt;is_data_valid&lt;/code&gt; を参照）。</target>
        </trans-unit>
        <trans-unit id="4c8220c40092a5223a7519a4053e419620df4d58" translate="yes" xml:space="preserve">
          <source>Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver.</source>
          <target state="translated">使用する固有ソルバーを選択します。n_componentsが学習サンプル数よりもはるかに少ない場合,arpackは密な固有値ソルバーよりも効率的かもしれません.</target>
        </trans-unit>
        <trans-unit id="a8b26e8dd8c57424e2a0ff5f2b02e8bbc7be69eb" translate="yes" xml:space="preserve">
          <source>Select features according to a percentile of the highest scores.</source>
          <target state="translated">最高得点のパーセンタイルに応じて機能を選択します。</target>
        </trans-unit>
        <trans-unit id="d20a85a468318484f73da066702f203468ec7eb5" translate="yes" xml:space="preserve">
          <source>Select features according to the k highest scores.</source>
          <target state="translated">kの最高得点に応じて機能を選択します。</target>
        </trans-unit>
        <trans-unit id="c3952e3b9f6e5571ab9a9f69665172397cc254d2" translate="yes" xml:space="preserve">
          <source>Select features based on a false positive rate test.</source>
          <target state="translated">偽陽性率テストに基づいて特徴を選択します。</target>
        </trans-unit>
        <trans-unit id="32515d7cef117ccce44afc2f4f0b98f43d0db807" translate="yes" xml:space="preserve">
          <source>Select features based on an estimated false discovery rate.</source>
          <target state="translated">推定された偽発見率に基づいて特徴量を選択します。</target>
        </trans-unit>
        <trans-unit id="6d7a0df88fc316c1f019dac960b65ab544487a37" translate="yes" xml:space="preserve">
          <source>Select features based on family-wise error rate.</source>
          <target state="translated">家族単位のエラー率で機能を選択します。</target>
        </trans-unit>
        <trans-unit id="ba417981f6009fc06cd3596ff9c6cb4c2bd25319" translate="yes" xml:space="preserve">
          <source>Select features based on percentile of the highest scores.</source>
          <target state="translated">最高得点のパーセンタイルに基づいて特徴を選択します。</target>
        </trans-unit>
        <trans-unit id="3532493330a0445601f2381a89fe492b8458f964" translate="yes" xml:space="preserve">
          <source>Select features based on the k highest scores.</source>
          <target state="translated">k個の最高スコアに基づいて特徴を選択します。</target>
        </trans-unit>
        <trans-unit id="d3166439a7b0a709dd15d8647b0a1e23526bb82a" translate="yes" xml:space="preserve">
          <source>Select from the model features with the higest score</source>
          <target state="translated">スコアが最も高いモデルの特徴から選ぶ</target>
        </trans-unit>
        <trans-unit id="fc6cce4211d0c67d4111ac2f86243aa83948ed07" translate="yes" xml:space="preserve">
          <source>Select n_samples integers from the set [0, n_population) without replacement.</source>
          <target state="translated">集合[0,n_population]からn_samplesの整数を置換せずに選択します。</target>
        </trans-unit>
        <trans-unit id="e693da3619bc133d154aaf34e091d4f9f76e8468" translate="yes" xml:space="preserve">
          <source>Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples &amp;gt; n_features.</source>
          <target state="translated">アルゴリズムを選択して、双対最適化問題または主最適化問題を解決します。n_samples&amp;gt; n_featuresの場合はdual = Falseを優先します。</target>
        </trans-unit>
        <trans-unit id="e09f39accd13c28376a1ebc78d546869197bec0f" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the development training set, &amp;lsquo;test&amp;rsquo; for the development test set, and &amp;lsquo;10_folds&amp;rsquo; for the official evaluation set that is meant to be used with a 10-folds cross validation.</source>
          <target state="translated">ロードするデータセットを選択します。「train」は開発トレーニングセット、「test」は開発テストセット、「10_folds」は10分割交差検証で使用するための公式評価セットです。</target>
        </trans-unit>
        <trans-unit id="da5a2fc4086f03333558c16d8aba6a6ba8f98164" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set (23149 samples), &amp;lsquo;test&amp;rsquo; for the test set (781265 samples), &amp;lsquo;all&amp;rsquo; for both, with the training samples first if shuffle is False. This follows the official LYRL2004 chronological split.</source>
          <target state="translated">ロードするデータセットを選択します。トレーニングセット（23149サンプル）の場合は「train」、テストセット（781265サンプル）の場合は「test」、両方の場合は「all」、シャッフルがFalseの場合はトレーニングサンプルを最初に選択します。これは、公式のLYRL2004年表の分割に従っています。</target>
        </trans-unit>
        <trans-unit id="a373737a4d85a4134f237dcaa76f506d35776152" translate="yes" xml:space="preserve">
          <source>Select the dataset to load: &amp;lsquo;train&amp;rsquo; for the training set, &amp;lsquo;test&amp;rsquo; for the test set, &amp;lsquo;all&amp;rsquo; for both, with shuffled ordering.</source>
          <target state="translated">ロードするデータセットを選択します。トレーニングセットには「train」、テストセットには「test」、両方に「all」を、順序を入れ替えて選択します。</target>
        </trans-unit>
        <trans-unit id="c5f861c6085a651c0ed9619f5012b02bb9a2d195" translate="yes" xml:space="preserve">
          <source>Select the parameters that minimises the impurity</source>
          <target state="translated">不純物を最小化するパラメータを選択</target>
        </trans-unit>
        <trans-unit id="776d7f86c8363c5c583ee4e086a4256b8464f6f6" translate="yes" xml:space="preserve">
          <source>Select the portion to load: &amp;lsquo;train&amp;rsquo;, &amp;lsquo;test&amp;rsquo; or &amp;lsquo;raw&amp;rsquo;</source>
          <target state="translated">ロードする部分を選択してください： 'train'、 'test'または 'raw'</target>
        </trans-unit>
        <trans-unit id="b97f498920dc9d14793f9ec22705c51c7828c05e" translate="yes" xml:space="preserve">
          <source>Select whether the regularization affects the components (H), the transformation (W), both or none of them.</source>
          <target state="translated">正則化が成分(H)に影響を与えるか、変換(W)に影響を与えるか、両方に影響を与えるか、あるいは影響を与えないかを選択します。</target>
        </trans-unit>
        <trans-unit id="09caeaab6645f9fa60776419a39bd350760c6b9f" translate="yes" xml:space="preserve">
          <source>Selecting &lt;code&gt;average=None&lt;/code&gt; will return an array with the score for each class.</source>
          <target state="translated">&lt;code&gt;average=None&lt;/code&gt; を選択すると、各クラスのスコアを含む配列が返されます。</target>
        </trans-unit>
        <trans-unit id="09987abb5cb6e00639cc8ad149fcfc0ee4e216e7" translate="yes" xml:space="preserve">
          <source>Selecting dimensionality reduction with Pipeline and GridSearchCV</source>
          <target state="translated">PipelineとGridSearchCVによる次元削減の選択</target>
        </trans-unit>
        <trans-unit id="b619a7e9444390b8df9ed15ee53211d47286dc3c" translate="yes" xml:space="preserve">
          <source>Selecting the number of clusters with silhouette analysis on KMeans clustering</source>
          <target state="translated">KMeansクラスタリング上でのシルエット解析によるクラスタ数の選択</target>
        </trans-unit>
        <trans-unit id="1e3a867140ee60f287b6c8b807e610aee224839f" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, use &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, use &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt;&lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;&lt;/a&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">特異ベクトルを見つけるためのアルゴリズムを選択します。「ランダム化」または「arpack」の場合があります。「ランダム化」されている場合は、&lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; を&lt;/a&gt;使用します。これは、大きな行列に対してはより高速になる場合があります。「arpack」の場合、&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html#scipy.sparse.linalg.svds&quot;&gt; &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; を&lt;/a&gt;使用します。これはより正確ですが、場合によっては遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="fc3d3604d35f10ba0398acd746e6c18250ce369b" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt;&lt;code&gt;randomized_svd&lt;/code&gt;&lt;/a&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">特異ベクトルを見つけるためのアルゴリズムを選択します。「ランダム化」または「arpack」の場合があります。'randomized'の場合、&lt;a href=&quot;sklearn.utils.extmath.randomized_svd#sklearn.utils.extmath.randomized_svd&quot;&gt; &lt;code&gt;randomized_svd&lt;/code&gt; を&lt;/a&gt;使用します。これは、大きな行列の場合は高速になる可能性があります。'arpack'の場合、 &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; を使用します。これはより正確ですが、場合によっては遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="ba0796ade5894bc55073846864af8524b40634d7" translate="yes" xml:space="preserve">
          <source>Selects the algorithm for finding singular vectors. May be &amp;lsquo;randomized&amp;rsquo; or &amp;lsquo;arpack&amp;rsquo;. If &amp;lsquo;randomized&amp;rsquo;, uses &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt;, which may be faster for large matrices. If &amp;lsquo;arpack&amp;rsquo;, uses &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt;, which is more accurate, but possibly slower in some cases.</source>
          <target state="translated">特異ベクトルを見つけるためのアルゴリズムを選択します。「ランダム化」または「arpack」の場合があります。'randomized'の場合、 &lt;code&gt;sklearn.utils.extmath.randomized_svd&lt;/code&gt; を使用します。これは、大きな行列に対してはより高速になる場合があります。'arpack'の場合、 &lt;code&gt;scipy.sparse.linalg.svds&lt;/code&gt; を使用します。これはより正確ですが、場合によっては遅くなる可能性があります。</target>
        </trans-unit>
        <trans-unit id="90a62864642c982296e3e801c0e34e5e7f5e23e4" translate="yes" xml:space="preserve">
          <source>Semi Supervised Classification</source>
          <target state="translated">半教師付き分類</target>
        </trans-unit>
        <trans-unit id="0c634aac4fba33953abfb672747b23d137a6eb94" translate="yes" xml:space="preserve">
          <source>Sepal length</source>
          <target state="translated">セパルの長さ</target>
        </trans-unit>
        <trans-unit id="fb329e5a4491aa43414f15d76bffc8963ea0de09" translate="yes" xml:space="preserve">
          <source>Sepal width</source>
          <target state="translated">セパル幅</target>
        </trans-unit>
        <trans-unit id="e5dddf892a3efc8978d095e912cc4306a1e49804" translate="yes" xml:space="preserve">
          <source>Separating inliers from outliers using a Mahalanobis distance</source>
          <target state="translated">マハラノビス距離を使用した外れ値からの内包物の分離</target>
        </trans-unit>
        <trans-unit id="aece656a00e1c7a3f193615a59fc1f63e6e58693" translate="yes" xml:space="preserve">
          <source>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &amp;ldquo;Decision Tree Construction Via Linear Programming.&amp;rdquo; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</source>
          <target state="translated">上記の分離平面は、多面法ツリー（MSM-T）[KPベネット、「線形計画法による決定木構築」を使用して得られました。第4回中西部人工知能および認知科学学会の議事録、pp。97-101、1992]、線形計画法を使用して決定木を構築する分類方法。1〜4個のフィーチャと1〜3個の分離平面のスペースで徹底的な検索を使用して、関連するフィーチャを選択しました。</target>
        </trans-unit>
        <trans-unit id="749810666e6448d7103b8c1ba2bbfef3e451d983" translate="yes" xml:space="preserve">
          <source>Separator string used when constructing new features for one-hot coding.</source>
          <target state="translated">ワンホットコーディングの新機能を構築する際に使用する区切り文字列。</target>
        </trans-unit>
        <trans-unit id="70aafd2a89678b32332fcfe0ff93efd39c5a3c06" translate="yes" xml:space="preserve">
          <source>Sequence of integer labels or multilabel data to encode.</source>
          <target state="translated">エンコードする整数ラベルまたはマルチラベルデータのシーケンス。</target>
        </trans-unit>
        <trans-unit id="63145e1c892f5c29b2a500cdc3f15222c0784b14" translate="yes" xml:space="preserve">
          <source>Sequence of resampled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">コレクションのリサンプルされたコピーのシーケンス。元の配列は影響を受けません。</target>
        </trans-unit>
        <trans-unit id="22f488ee4fca141470b8e2b188abe2e7275b3dc0" translate="yes" xml:space="preserve">
          <source>Sequence of shuffled copies of the collections. The original arrays are not impacted.</source>
          <target state="translated">コレクションのシャッフルされたコピーのシーケンス。元の配列は影響を受けません。</target>
        </trans-unit>
        <trans-unit id="05f31ec9564cc0e3d1b047a8eba0a9e234d2f0b3" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted class labels (&lt;code&gt;hard&lt;/code&gt; voting) or class probabilities before averaging (&lt;code&gt;soft&lt;/code&gt; voting). Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">重み付けのシーケンス（ &lt;code&gt;float&lt;/code&gt; または &lt;code&gt;int&lt;/code&gt; ）は、平均化する前に予測クラスラベル（ &lt;code&gt;hard&lt;/code&gt; 投票）またはクラス確率の出現に重み付けします（ &lt;code&gt;soft&lt;/code&gt; 投票）。 &lt;code&gt;None&lt;/code&gt; の場合、均一の重みを使用します。</target>
        </trans-unit>
        <trans-unit id="1b2a96243ee03211fb7854a57171cf92c85f5687" translate="yes" xml:space="preserve">
          <source>Sequence of weights (&lt;code&gt;float&lt;/code&gt; or &lt;code&gt;int&lt;/code&gt;) to weight the occurrences of predicted values before averaging. Uses uniform weights if &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">平均化する前に予測値の発生に重みを付けるための重みのシーケンス（ &lt;code&gt;float&lt;/code&gt; または &lt;code&gt;int&lt;/code&gt; ）。 &lt;code&gt;None&lt;/code&gt; の場合、均一な重みを使用します。</target>
        </trans-unit>
        <trans-unit id="0ea6d0fbbfa7ff1125b3f0dc0d1f0f204d3b725f" translate="yes" xml:space="preserve">
          <source>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be &amp;lsquo;transforms&amp;rsquo;, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using &lt;code&gt;memory&lt;/code&gt; argument.</source>
          <target state="translated">変換のリストと最終的な推定量を順次適用します。パイプラインの中間ステップは「変換」である必要があります。つまり、フィットおよび変換メソッドを実装する必要があります。最終的な推定量は、適合を実装する必要があるだけです。パイプラインのトランスフォーマーは、 &lt;code&gt;memory&lt;/code&gt; 引数を使用してキャッシュできます。</target>
        </trans-unit>
        <trans-unit id="5d912fff074ca31c7c82b5fde02f4d9656aba0e0" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;kernel='precomputed'&lt;/code&gt; and pass the Gram matrix instead of X in the fit method. At the moment, the kernel values between &lt;em&gt;all&lt;/em&gt; training vectors and the test vectors must be provided.</source>
          <target state="translated">&lt;code&gt;kernel='precomputed'&lt;/code&gt; を設定し、fitメソッドでXの代わりにグラム行列を渡します。現時点では、&lt;em&gt;すべての&lt;/em&gt;トレーニングベクトルとテストベクトルの間のカーネル値を指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="82c89924e3ff5aee8a7d762157ebec36e4bfb77e" translate="yes" xml:space="preserve">
          <source>Set &lt;code&gt;n_clusters&lt;/code&gt; to a required value using &lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;brc.set_params(n_clusters=n_clusters)&lt;/code&gt; を使用して、 &lt;code&gt;n_clusters&lt;/code&gt; を必要な値に設定します。</target>
        </trans-unit>
        <trans-unit id="baf739c6d3f3081a673c9a62345f43337d9146af" translate="yes" xml:space="preserve">
          <source>Set an initial start configuration, randomly or not.</source>
          <target state="translated">初期起動時の設定をランダムにするかしないかを設定します。</target>
        </trans-unit>
        <trans-unit id="acdb8317b38cc1be24a0a9627d99a9301a5b666a" translate="yes" xml:space="preserve">
          <source>Set and validate the parameters of estimator.</source>
          <target state="translated">エスティメーターのパラメータを設定し、検証します。</target>
        </trans-unit>
        <trans-unit id="7115214e952526d911c94e2c07be9533a4c1bc42" translate="yes" xml:space="preserve">
          <source>Set global scikit-learn configuration</source>
          <target state="translated">グローバルなscikit-learnの設定</target>
        </trans-unit>
        <trans-unit id="d973ce66011b9fa67c29ae92b31d59e39ce28a97" translate="yes" xml:space="preserve">
          <source>Set of samples, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">n_samplesはサンプル数、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="859e800d4c0c95faf85e59d644290b4f9223483a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVCの場合、クラスiのパラメーターCを &lt;code&gt;class_weight[i]*C&lt;/code&gt; に設定します。指定されていない場合、すべてのクラスの重みは1になるはずです。「バランス」モードでは、yの値を使用して、 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として、入力データのクラス頻度に反比例する重みを自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="291ade590fbb6a8638dd1afb8f1376626f33f6ea" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to &lt;code&gt;class_weight[i]*C&lt;/code&gt; for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">SVCの場合、クラスiのパラメータCを &lt;code&gt;class_weight[i]*C&lt;/code&gt; に設定します。指定しない場合、すべてのクラスの重みが1になるはずです。「平衡」モードでは、yの値を使用して、入力データのクラス頻度に反比例する重みを &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="68197d507e5463b3337bc09b3b9761d9525e528a" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVCの場合、クラスiのパラメーターCをclass_weight [i] * Cに設定します。指定されていない場合、すべてのクラスの重みは1になるはずです。「バランス」モードでは、yの値を使用して、クラスの頻度に反比例する重みを &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="7ee0e3c771d52a3f4b21637b50de4b2fa144cadb" translate="yes" xml:space="preserve">
          <source>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">SVCの場合、クラスiのパラメーターCをclass_weight [i] * Cに設定します。指定されていない場合、すべてのクラスの重みは1になるはずです。「バランス」モードでは、yの値を使用して、 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として、入力データのクラス頻度に反比例する重みを自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="02c4dadc552ae2f0292cf77b2c6f20b9175838e2" translate="yes" xml:space="preserve">
          <source>Set the parameters</source>
          <target state="translated">パラメータの設定</target>
        </trans-unit>
        <trans-unit id="3f30532fe6a7a61216e1f94a622dfc009651d7c9" translate="yes" xml:space="preserve">
          <source>Set the parameters of an estimator from the ensemble.</source>
          <target state="translated">アンサンブルから推定器のパラメータを設定します。</target>
        </trans-unit>
        <trans-unit id="72f87d2d27b1f0c322a530ad0dc9b59597d7be5b" translate="yes" xml:space="preserve">
          <source>Set the parameters of this estimator.</source>
          <target state="translated">この推定器のパラメータを設定します。</target>
        </trans-unit>
        <trans-unit id="57d60e82b45349e99163b5cb25f5c26dc09997fb" translate="yes" xml:space="preserve">
          <source>Set the parameters of this kernel.</source>
          <target state="translated">このカーネルのパラメータを設定します。</target>
        </trans-unit>
        <trans-unit id="e51dac5748f92b9a4d95a295db13667c4d900b8f" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation during transformation.</source>
          <target state="translated">Falseに設定すると、変換中にインプレース計算を実行します。</target>
        </trans-unit>
        <trans-unit id="c9e442dcb8465293c9e9b1ca26f1df573cbc8a5b" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace computation.</source>
          <target state="translated">Falseに設定すると、インプレース計算が実行されます。</target>
        </trans-unit>
        <trans-unit id="66ebe619c3b8004252e57f6a28ff4945f1da8024" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Falseに設定すると,インプレース行の正規化を行い,コピーを回避します(入力が既にnumpy配列である場合).</target>
        </trans-unit>
        <trans-unit id="00972eb158db00f5dae23773f938b4091d65b472" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Falseに設定すると,インプレーススケーリングを行い,コピーを避けることができます(入力が既にnumpy配列の場合).</target>
        </trans-unit>
        <trans-unit id="08f65c010729649e9d6102eb99a0ed3b76fe0859" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array).</source>
          <target state="translated">Falseに設定すると,インプレース変換を行い,コピーを避けることができます(入力が既にnumpy配列である場合).</target>
        </trans-unit>
        <trans-unit id="bbfbd49ae916b95e446b3c89c15541e5023cd4ad" translate="yes" xml:space="preserve">
          <source>Set to False to perform inplace transformation and avoid a copy (if the input is already a numpy array). If True, a copy of &lt;code&gt;X&lt;/code&gt; is transformed, leaving the original &lt;code&gt;X&lt;/code&gt; unchanged</source>
          <target state="translated">Falseに設定すると、インプレース変換が実行され、コピーが回避されます（入力がすでにnumpy配列の場合）。Trueの場合、 &lt;code&gt;X&lt;/code&gt; のコピーが変換され、元の &lt;code&gt;X&lt;/code&gt; は変更されません。</target>
        </trans-unit>
        <trans-unit id="70773d7b4f76452047259ed8e2e9af7169f13fc0" translate="yes" xml:space="preserve">
          <source>Set to True to apply zero-mean, unit-variance normalization to the transformed output.</source>
          <target state="translated">True に設定すると、変換された出力にゼロ平均、単位分散正規化が適用されます。</target>
        </trans-unit>
        <trans-unit id="31263c2a03fef7d2c1e558ffe5e1f7ce22d5913e" translate="yes" xml:space="preserve">
          <source>Set to True, both W and H will be estimated from initial guesses. Set to False, only W will be estimated.</source>
          <target state="translated">Trueに設定すると、WとHの両方が最初の推測から推定されます。Falseに設定すると、Wのみが推定されます。</target>
        </trans-unit>
        <trans-unit id="a7d505eb35ec97e19208554a83f21f5336e3915d" translate="yes" xml:space="preserve">
          <source>Set to true if output binary array is desired in CSR sparse format</source>
          <target state="translated">CSR 疎なフォーマットでのバイナリ配列の出力を希望する場合に true を設定します。</target>
        </trans-unit>
        <trans-unit id="e9779b7ab3cf4b478b4bfa7669bfc4f6492ae2ea" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;assume_finite&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">デフォルト値を設定します &lt;code&gt;assume_finite&lt;/code&gt; の引数&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="2047224d21bf76be06bd841e22b2f6efe81f5987" translate="yes" xml:space="preserve">
          <source>Sets the default value for the &lt;code&gt;working_memory&lt;/code&gt; argument of &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;working_memory&lt;/code&gt; 引数のデフォルト値を設定します。</target>
        </trans-unit>
        <trans-unit id="8fc661c1feefb08f484398590a9cfaa0d200700d" translate="yes" xml:space="preserve">
          <source>Sets the seed of the global random generator when running the tests, for reproducibility.</source>
          <target state="translated">再現性のために、テストを実行する際のグローバルランダムジェネレータのシードを設定します。</target>
        </trans-unit>
        <trans-unit id="75bad9ccfc79ab0c0bbe60c8449ed7b0c754d17f" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division, i.e. when all predictions and labels are negative. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="translated">除算がゼロの場合、つまりすべての予測とラベルが負の場合に返される値を設定します。「警告」に設定すると、これは0として機能しますが、警告も発生します。</target>
        </trans-unit>
        <trans-unit id="5785bcff96fce8eedf96c87581cbc35bae5756d5" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division. If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="translated">ゼロ除算がある場合に返す値を設定します。「警告」に設定すると、これは0として機能しますが、警告も発生します。</target>
        </trans-unit>
        <trans-unit id="e057cbf5e19c7dcf916bf2fe2aa47295c10430c1" translate="yes" xml:space="preserve">
          <source>Sets the value to return when there is a zero division:</source>
          <target state="translated">ゼロ除算があったときに返す値を設定します。</target>
        </trans-unit>
        <trans-unit id="ceca261ca4bfaf0dac2e7a5f6879bae3049e05bd" translate="yes" xml:space="preserve">
          <source>Sets the verbosity amount</source>
          <target state="translated">冗長度の量を設定します。</target>
        </trans-unit>
        <trans-unit id="0f757b166230d0f61e44fc2003ab4f4a4d10043d" translate="yes" xml:space="preserve">
          <source>Setting &lt;code&gt;generate_only=True&lt;/code&gt; returns a generator that yields (estimator, check) tuples where the check can be called independently from each other, i.e. &lt;code&gt;check(estimator)&lt;/code&gt;. This allows all checks to be run independently and report the checks that are failing.</source>
          <target state="translated">&lt;code&gt;generate_only=True&lt;/code&gt; を設定すると、チェックが互いに独立して呼び出すことができる（estimator、check）タプルを生成するジェネレーター、つまり &lt;code&gt;check(estimator)&lt;/code&gt; が返されます。これにより、すべてのチェックを個別に実行し、失敗したチェックを報告できます。</target>
        </trans-unit>
        <trans-unit id="41f97bb142955ba403db62394a8510aa45205b7b" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well</source>
          <target state="translated">これをTrueに設定すると、様々な分類器と分類器のパラメータを取得します。</target>
        </trans-unit>
        <trans-unit id="924da9eef84794e1bcb0c0c5d50e7650f0dfc881" translate="yes" xml:space="preserve">
          <source>Setting it to True gets the various classifiers and the parameters of the classifiers as well.</source>
          <target state="translated">これをTrueに設定すると、様々な分類子と分類子のパラメータも取得します。</target>
        </trans-unit>
        <trans-unit id="0e750c0ef44cf143b57f79a94939ea31cd10193d" translate="yes" xml:space="preserve">
          <source>Setting print_changed_only to True will alternate the representation of estimators to only show the parameters that have been set to non-default values. This can be used to have more compact representations.</source>
          <target state="translated">print_changed_onlyをTrueに設定すると、デフォルト値以外に設定されているパラメータのみが表示されるように、推定量の表現が交互に変わります。これを使用すると、よりコンパクトな表現にすることができます。</target>
        </trans-unit>
        <trans-unit id="2623b7b1ad6f2c3b5492832d70831c56aba6aac8" translate="yes" xml:space="preserve">
          <source>Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters.</source>
          <target state="translated">潜在的な収縮パラメータのグリッドに従って三つ折りの尤度を交差検証してパラメータを設定します。</target>
        </trans-unit>
        <trans-unit id="edca67601d1a75cccde1deb24fddb7bb63088fcb" translate="yes" xml:space="preserve">
          <source>Setting the parameters for the voting classifier</source>
          <target state="translated">投票分類器のパラメータ設定</target>
        </trans-unit>
        <trans-unit id="cb6261b9db86d6920a006098fc7538ed80a40df3" translate="yes" xml:space="preserve">
          <source>Several estimators in the scikit-learn can use connectivity information between features or samples. For instance Ward clustering (&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;Hierarchical clustering&lt;/a&gt;) can cluster together only neighboring pixels of an image, thus forming contiguous patches:</source>
          <target state="translated">scikit-learnのいくつかの推定器は、機能またはサンプル間の接続情報を使用できます。たとえば、ウォードクラスタリング（&lt;a href=&quot;clustering#hierarchical-clustering&quot;&gt;階層的クラスタリング&lt;/a&gt;）は、画像の隣接するピクセルのみをクラスター化して、隣接するパッチを形成できます。</target>
        </trans-unit>
        <trans-unit id="b2ad224369c25dffec31e32504aa18be16f8d837" translate="yes" xml:space="preserve">
          <source>Several functions allow you to analyze the precision, recall and F-measures score:</source>
          <target state="translated">いくつかの機能を使用すると、精度、リコール、F対策のスコアを分析することができます。</target>
        </trans-unit>
        <trans-unit id="beccb29e29ebc99080f8c36d4203650a9f29b872" translate="yes" xml:space="preserve">
          <source>Several methods have been developed to compare two sets of biclusters. For now, only &lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt;&lt;code&gt;consensus_score&lt;/code&gt;&lt;/a&gt; (Hochreiter et. al., 2010) is available:</source>
          <target state="translated">2セットのバイクラスターを比較するために、いくつかの方法が開発されています。現時点では、&lt;a href=&quot;generated/sklearn.metrics.consensus_score#sklearn.metrics.consensus_score&quot;&gt; &lt;code&gt;consensus_score&lt;/code&gt; &lt;/a&gt;（Hochreiter et。al。、2010）のみが使用可能です。</target>
        </trans-unit>
        <trans-unit id="bf696ed0c48f638295bdb050d71aac6a4287ef6f" translate="yes" xml:space="preserve">
          <source>Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.</source>
          <target state="translated">scikit-learnでは、いくつかの回帰およびバイナリ分類アルゴリズムが利用可能です。これらのアルゴリズムをマルチクラス分類の場合に拡張する簡単な方法は、いわゆるonevsallスキームを使用することです。</target>
        </trans-unit>
        <trans-unit id="0ac410486b823defe3030785e8a86edcf2b2b7e4" translate="yes" xml:space="preserve">
          <source>Severity Model - Gamma distribution</source>
          <target state="translated">重大度モデル-ガンマ分布</target>
        </trans-unit>
        <trans-unit id="e301dd6062f7e9a79975fe8e2d0ba91694c4dbc3" translate="yes" xml:space="preserve">
          <source>Sex</source>
          <target state="translated">Sex</target>
        </trans-unit>
        <trans-unit id="94351e57e5ad4d9a685a9e5e4a3a8ed2b422ed01" translate="yes" xml:space="preserve">
          <source>Shape of the data arrays</source>
          <target state="translated">データ配列の形状</target>
        </trans-unit>
        <trans-unit id="6ce851a20ced87e3a45210428f1caa987910f68a" translate="yes" xml:space="preserve">
          <source>Shape of the i&amp;rsquo;th bicluster.</source>
          <target state="translated">i番目のバイクラスターの形状。</target>
        </trans-unit>
        <trans-unit id="e14b35d505512b3adb2f8997ae35ca2be24040d8" translate="yes" xml:space="preserve">
          <source>Shape will be [n_samples, 1] for binary problems.</source>
          <target state="translated">形状は2値問題の場合は[n_samples,1]になります。</target>
        </trans-unit>
        <trans-unit id="f4aa10e40109dde70a9d57a4c3969b16b2895540" translate="yes" xml:space="preserve">
          <source>Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep].</source>
          <target state="translated">指定された値で特徴量をシフトします。Noneの場合は、[-class_sep,class_sep]で描画されたランダムな値で特徴量をシフトします。</target>
        </trans-unit>
        <trans-unit id="89ec1dbbc8f85faf0ad282b8a6481e07a4785260" translate="yes" xml:space="preserve">
          <source>Shifted opposite of the Local Outlier Factor of X.</source>
          <target state="translated">Xの局所外れ要因の反対側にシフト。</target>
        </trans-unit>
        <trans-unit id="5433cd73ac014316d0b32695693eab5029601309" translate="yes" xml:space="preserve">
          <source>Shorthand</source>
          <target state="translated">Shorthand</target>
        </trans-unit>
        <trans-unit id="a8178c51c2cc3204c708328447fd16ef389ce9b6" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</source>
          <target state="translated">すべてのデータを学習するためにメモリが非効率な場合に使用されるべきである。データの塊は数回の反復で渡すことができ、最初の呼び出しはすべてのターゲット変数の配列を持つ必要があります。</target>
        </trans-unit>
        <trans-unit id="12700416ee0fef7fdd5157d1c27acbb9da13d5c9" translate="yes" xml:space="preserve">
          <source>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration.</source>
          <target state="translated">すべてのデータを学習するためにメモリが効率的でない場合に使用されるべきである。データの塊は数回の反復で渡すことができる。</target>
        </trans-unit>
        <trans-unit id="ec934ba88e117c3577f933302800f3ab4b85705a" translate="yes" xml:space="preserve">
          <source>Show below is a logistic-regression classifiers decision boundaries on the first two dimensions (sepal length and width) of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;iris&lt;/a&gt; dataset. The datapoints are colored according to their labels.</source>
          <target state="translated">以下に示すのは、&lt;a href=&quot;https://en.wikipedia.org/wiki/Iris_flower_data_set&quot;&gt;虹彩&lt;/a&gt;データセットの最初の2つの次元（がく片の長さと幅）におけるロジスティック回帰分類子の決定境界です。データポイントは、ラベルに従って色分けされています。</target>
        </trans-unit>
        <trans-unit id="c74e263b32d3703a876a54ba7cc367e3fb1c6bbb" translate="yes" xml:space="preserve">
          <source>Shown in the plot is how the logistic regression would, in this synthetic dataset, classify values as either 0 or 1, i.e. class one or two, using the logistic curve.</source>
          <target state="translated">プロットに示されているのは、ロジスティック回帰が、この合成データセットにおいて、ロジスティック曲線を用いて、値を0または1、すなわちクラス1または2に分類する方法です。</target>
        </trans-unit>
        <trans-unit id="ca5bc8cbcc9592e82a2ca132c00133d4ad37408e" translate="yes" xml:space="preserve">
          <source>Shows how shrinkage improves classification.</source>
          <target state="translated">収縮がどのように分類を改善するかを示しています。</target>
        </trans-unit>
        <trans-unit id="5dc7ad8809a977f328219d536276f520094e2981" translate="yes" xml:space="preserve">
          <source>Shows how to use a function transformer in a pipeline. If you know your dataset&amp;rsquo;s first principle component is irrelevant for a classification task, you can use the FunctionTransformer to select all but the first column of the PCA transformed data.</source>
          <target state="translated">パイプラインで関数トランスフォーマーを使用する方法を示します。データセットの最初の主成分が分類タスクに無関係であることがわかっている場合は、FunctionTransformerを使用して、PCA変換データの最初の列を除くすべてを選択できます。</target>
        </trans-unit>
        <trans-unit id="f535d0d4250bfadc5c1c6932476e7cb22e7db70e" translate="yes" xml:space="preserve">
          <source>Shows the effect of collinearity in the coefficients of an estimator.</source>
          <target state="translated">推定量の係数における共線性の効果を示す。</target>
        </trans-unit>
        <trans-unit id="1a78e7f7618436a20d69e64d9d5ffb3bc060c908" translate="yes" xml:space="preserve">
          <source>Shrinkage</source>
          <target state="translated">Shrinkage</target>
        </trans-unit>
        <trans-unit id="29ad8c0361eee52379ab28eb86f7303c232b073b" translate="yes" xml:space="preserve">
          <source>Shrinkage and sparsity with logistic regression</source>
          <target state="translated">ロジスティック回帰を用いた収縮とスパーシティ</target>
        </trans-unit>
        <trans-unit id="92e7e7782831a32d85f1f4adb6e6848b9931e9f2" translate="yes" xml:space="preserve">
          <source>Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</source>
          <target state="translated">縮み共分散推定。LedoitWolf と OAS と最尤の比較</target>
        </trans-unit>
        <trans-unit id="2e2068ed5693c53cc14ed41dc7c2ee819779a1f5" translate="yes" xml:space="preserve">
          <source>Shrinkage is a form of regularization used to improve the estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator, and shrinkage helps improving the generalization performance of the classifier. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id6&quot; id=&quot;id4&quot;&gt;2&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">収縮は、特徴の数と比較してトレーニングサンプルの数が少ない状況で、共分散行列の推定を改善するために使用される正則化の形式です。このシナリオでは、経験的なサンプル共分散は不十分な推定量であり、収縮は分類器の一般化パフォーマンスの向上に役立ちます。収縮LDAは、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;クラスの &lt;code&gt;shrinkage&lt;/code&gt; パラメーターを「auto」に設定することで使用できます。これにより、LedoitとWolf &lt;a href=&quot;#id6&quot; id=&quot;id4&quot;&gt;2&lt;/a&gt;によって導入された補題に従って、分析的な方法で最適な収縮パラメータが自動的に決定されます。現在、収縮は、 &lt;code&gt;solver&lt;/code&gt; パラメータを「lsqr」または「eigen」に設定した場合にのみ機能することに注意してください。</target>
        </trans-unit>
        <trans-unit id="bc56f7d6f334df6e1bf7e25fb6694a2b96d3283e" translate="yes" xml:space="preserve">
          <source>Shrinkage is a tool to improve estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator. Shrinkage LDA can be used by setting the &lt;code&gt;shrinkage&lt;/code&gt; parameter of the &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt; class to &amp;lsquo;auto&amp;rsquo;. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf &lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;. Note that currently shrinkage only works when setting the &lt;code&gt;solver&lt;/code&gt; parameter to &amp;lsquo;lsqr&amp;rsquo; or &amp;lsquo;eigen&amp;rsquo;.</source>
          <target state="translated">収縮は、特徴の数と比較してトレーニングサンプルの数が少ない状況で、共分散行列の推定を改善するツールです。このシナリオでは、経験的サンプルの共分散は貧弱な推定量です。収縮LDA は、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;クラスの &lt;code&gt;shrinkage&lt;/code&gt; パラメーターを「auto」に設定することで使用できます。これにより、レドイトとウルフによって導入された補題に従って分析的な方法で最適な収縮パラメータが自動的に決定されます&lt;a href=&quot;#id5&quot; id=&quot;id3&quot;&gt;[4]&lt;/a&gt;。現在、収縮は &lt;code&gt;solver&lt;/code&gt; パラメーターを 'lsqr'または 'eigen' に設定した場合にのみ機能することに注意してください。</target>
        </trans-unit>
        <trans-unit id="7e8136e1a5918ee41b1666fa514179c5cb22402c" translate="yes" xml:space="preserve">
          <source>Shrinkage parameter, possible values:</source>
          <target state="translated">収縮率パラメータ、設定可能な値。</target>
        </trans-unit>
        <trans-unit id="b2a27e6ba825492dec9776790877b64e516e75e0" translate="yes" xml:space="preserve">
          <source>Shrunk covariance.</source>
          <target state="translated">共分散を縮小した</target>
        </trans-unit>
        <trans-unit id="4dcdf0ff13bd4f7b65e07eadf0216796b5d56197" translate="yes" xml:space="preserve">
          <source>Shuffle arrays or sparse matrices in a consistent way</source>
          <target state="translated">配列や疎な行列を一貫してシャッフルする</target>
        </trans-unit>
        <trans-unit id="c0ccd0261920fa2fccaab512e3420b322d650304" translate="yes" xml:space="preserve">
          <source>Shuffle the samples and the features.</source>
          <target state="translated">サンプルとフィーチャをシャッフルします。</target>
        </trans-unit>
        <trans-unit id="372aba820bed6f2900292d1b119c1b7c02346b33" translate="yes" xml:space="preserve">
          <source>Shuffle the samples.</source>
          <target state="translated">サンプルをシャッフルします。</target>
        </trans-unit>
        <trans-unit id="bb741d2d7cb4e292767bcf7b4c4d2a7dcedf441d" translate="yes" xml:space="preserve">
          <source>Shuffle-Group(s)-Out cross-validation iterator</source>
          <target state="translated">シャッフルグループ(s)-アウトクロスバリデーションイテレータ</target>
        </trans-unit>
        <trans-unit id="04a76dd0a6286b28de9940305c73988458741a00" translate="yes" xml:space="preserve">
          <source>Signed distance is positive for an inlier and negative for an outlier.</source>
          <target state="translated">符号付きの距離は、内在値が正の場合は正、外在値が負の場合は負の値である。</target>
        </trans-unit>
        <trans-unit id="175a8f49ca538859a1536806ea283ecf7546e18e" translate="yes" xml:space="preserve">
          <source>Signed distance to the separating hyperplane.</source>
          <target state="translated">分離双平面までの符号付き距離.</target>
        </trans-unit>
        <trans-unit id="bdea7e4b3b56af1c4dc44f101507e6d5fde4c3c5" translate="yes" xml:space="preserve">
          <source>Silhouette Coefficient for each samples.</source>
          <target state="translated">各サンプルのシルエット係数</target>
        </trans-unit>
        <trans-unit id="cef2e4d37f21e366fe4348cb5c8e3de442e95913" translate="yes" xml:space="preserve">
          <source>Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].</source>
          <target state="translated">シルエット分析は、結果として得られるクラスター間の分離距離を調べるために使用することができます。シルエットプロットは、1つのクラスタ内の各点が隣接するクラスタ内の点にどれだけ近いかの尺度を表示し、クラスタの数などのパラメータを視覚的に評価する方法を提供します。この尺度の範囲は、[-1,1]です。</target>
        </trans-unit>
        <trans-unit id="f28647d65c56d46a3ca67f993f108ac366d59691" translate="yes" xml:space="preserve">
          <source>Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.</source>
          <target state="translated">シルエット係数(これらの値はこれらの値と呼ばれています)が+1に近い場合は、サンプルが隣接するクラスタから遠く離れていることを示します。値が0の場合、サンプルが2つの隣接クラスタ間の決定境界上にあるか、または非常に近くにあることを示し、負の値は、それらのサンプルが間違ったクラスタに割り当てられている可能性があることを示します。</target>
        </trans-unit>
        <trans-unit id="88d328be635604c256d2743bcb180fd1daab0b36" translate="yes" xml:space="preserve">
          <source>Similar feature extractors should be built for other kind of unstructured data input such as images, audio, video, &amp;hellip;</source>
          <target state="translated">同様の特徴抽出器は、画像、オーディオ、ビデオなどの他の種類の非構造化データ入力用に構築する必要があります。</target>
        </trans-unit>
        <trans-unit id="9be20d5d3cad647d5b5693ebaedd1ee1a23948cc" translate="yes" xml:space="preserve">
          <source>Similar to &lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; but only a single metric is permitted.</source>
          <target state="translated">&lt;a href=&quot;sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; に&lt;/a&gt;似ていますが、許可されるメトリックは1つだけです。</target>
        </trans-unit>
        <trans-unit id="319655ff7753a6199642b7bf6692dc2bf99bfe55" translate="yes" xml:space="preserve">
          <source>Similar to AgglomerativeClustering, but recursively merges features instead of samples.</source>
          <target state="translated">AgglomerativeClusteringに似ていますが、サンプルの代わりに再帰的に特徴をマージします。</target>
        </trans-unit>
        <trans-unit id="133d603767b5dc043e4bab49b5255c4ddd0f05fe" translate="yes" xml:space="preserve">
          <source>Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.</source>
          <target state="translated">NuSVCと同様に、回帰のために、支持ベクトルの数を制御するためにパラメータnuを使用します。しかし、nuがCを置き換えるNuSVCとは異なり、ここではnuはepsilon-SVRのパラメータepsilonを置き換えます。</target>
        </trans-unit>
        <trans-unit id="d1a2b055f0753742d67fc90d1d4811e0a5d9ab30" translate="yes" xml:space="preserve">
          <source>Similar to SVC but uses a parameter to control the number of support vectors.</source>
          <target state="translated">SVC に似ていますが、サポートベクタの数を制御するためにパラメータを使用します。</target>
        </trans-unit>
        <trans-unit id="367343dd50d61c27ddbb7a06df2fb9885bdf8a5f" translate="yes" xml:space="preserve">
          <source>Similar to SVC with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">パラメータがkernel = 'linear'のSVCに似ていますが、libsvmではなくliblinearの観点から実装されているため、ペナルティと損失関数の選択に柔軟性があり、多数のサンプルに適切にスケーリングできます。</target>
        </trans-unit>
        <trans-unit id="3ec63304462f4cbac1c3a261d38d9188bcded830" translate="yes" xml:space="preserve">
          <source>Similar to SVR with parameter kernel=&amp;rsquo;linear&amp;rsquo;, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.</source>
          <target state="translated">パラメータkernel = 'linear'のSVRに似ていますが、libsvmではなくliblinearの観点から実装されているため、ペナルティと損失関数の選択に柔軟性があり、多数のサンプルに適切にスケーリングできます。</target>
        </trans-unit>
        <trans-unit id="997a429b680aeb0ca7576cadadd68b1d30fd4132" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms GBRT builds the additive model in a forward stagewise fashion:</source>
          <target state="translated">他のブーストアルゴリズムと同様に、GBRTでは、加法モデルを順送りで構築します。</target>
        </trans-unit>
        <trans-unit id="76a1a1878f09aac58b35d999b125160a70440000" translate="yes" xml:space="preserve">
          <source>Similar to other boosting algorithms, a GBRT is built in a greedy fashion:</source>
          <target state="translated">他のブーストアルゴリズムと同様に、GBRTは貪欲な方法で構築されています。</target>
        </trans-unit>
        <trans-unit id="9dba587c665016505432ed3d83545171f96e0b75" translate="yes" xml:space="preserve">
          <source>Similarity between individual biclusters is computed. Then the best matching between sets is found using the Hungarian algorithm. The final score is the sum of similarities divided by the size of the larger set.</source>
          <target state="translated">個々のバイクラスター間の類似度が計算される.その後、ハンガリー語アルゴリズムを使用して、セット間の最適なマッチングが発見されます。最終的なスコアは、類似度の合計をより大きな集合のサイズで割ったものです。</target>
        </trans-unit>
        <trans-unit id="a365c849553e02aafca0dfedfc5010bc90d3ae71" translate="yes" xml:space="preserve">
          <source>Similarity score between -1.0 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.</source>
          <target state="translated">類似度スコアは-1.0と1.0の間。ランダムラベリングはARIが0.0に近い。1.0 は完全一致を意味します。</target>
        </trans-unit>
        <trans-unit id="186186d91781f080c251077ac03fc20cf1639d0c" translate="yes" xml:space="preserve">
          <source>Similarly, &lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt;&lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt;&lt;/a&gt; repeats Stratified K-Fold n times with different randomization in each repetition.</source>
          <target state="translated">同様に、&lt;a href=&quot;generated/sklearn.model_selection.repeatedstratifiedkfold#sklearn.model_selection.RepeatedStratifiedKFold&quot;&gt; &lt;code&gt;RepeatedStratifiedKFold&lt;/code&gt; &lt;/a&gt;は、層化されたK折りをn回繰り返し、各繰り返しで異なるランダム化を行います。</target>
        </trans-unit>
        <trans-unit id="01f578d801e5d1ea722f26bf3985038251d17ab9" translate="yes" xml:space="preserve">
          <source>Similarly, L1 regularized logistic regression solves the following optimization problem</source>
          <target state="translated">同様に、L1正則化ロジスティック回帰は、以下の最適化問題を解く。</target>
        </trans-unit>
        <trans-unit id="904046bd05dcb9fe24c66e7942e9a89936649854" translate="yes" xml:space="preserve">
          <source>Similarly, \(\ell_1\) regularized logistic regression solves the following optimization problem:</source>
          <target state="translated">同様に,正則化ロジスティック回帰は,次の最適化問題を解く.</target>
        </trans-unit>
        <trans-unit id="c8ee1f0c1cff57e37c89253984120399103de69b" translate="yes" xml:space="preserve">
          <source>Similarly, a negative monotonic constraint is of the form:</source>
          <target state="translated">同様に、負の単調な制約は、形をしています。</target>
        </trans-unit>
        <trans-unit id="33d5515f485c474434afb456d44ce55ecb3a831d" translate="yes" xml:space="preserve">
          <source>Similarly, labels not present in the data sample may be accounted for in macro-averaging.</source>
          <target state="translated">同様に、データサンプルに存在しないラベルは、マクロ平均化で考慮されることがあります。</target>
        </trans-unit>
        <trans-unit id="de3a0306d5f9d4f628a86437bd31f501c79f2495" translate="yes" xml:space="preserve">
          <source>Similarly, the precision recall curve can be plotted using &lt;code&gt;y_score&lt;/code&gt; from the prevision sections.</source>
          <target state="translated">同様に、適合率再現率曲線は、 &lt;code&gt;y_score&lt;/code&gt; セクションのy_scoreを使用してプロットできます。</target>
        </trans-unit>
        <trans-unit id="0c868e091c0bbbbc855227dfcc9797f545ef094e" translate="yes" xml:space="preserve">
          <source>Simple 1D Kernel Density Estimation</source>
          <target state="translated">単純な1次元カーネル密度推定</target>
        </trans-unit>
        <trans-unit id="f5468d7aca1a86ccbbf784d0772796020bb33f7b" translate="yes" xml:space="preserve">
          <source>Simple to understand and to interpret. Trees can be visualised.</source>
          <target state="translated">わかりやすく、解釈しやすい。樹木を可視化できる。</target>
        </trans-unit>
        <trans-unit id="954c17f332cbfd66dfa98282859837f21d64fd6a" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a C-SVM of the selected features.</source>
          <target state="translated">一変量特徴選択をアノバで連続的に実行し、選択された特徴のC-SVMを実行するPipelineの簡単な使い方。</target>
        </trans-unit>
        <trans-unit id="e7766eb7ad8cfdfa67609d5277fb9ac991ed77ce" translate="yes" xml:space="preserve">
          <source>Simple usage of Pipeline that runs successively a univariate feature selection with anova and then a SVM of the selected features.</source>
          <target state="translated">アノバで一変量の特徴を選択し、選択した特徴のSVMを連続して実行するPipelineの簡単な使い方。</target>
        </trans-unit>
        <trans-unit id="50f8d26df97413619de7bb6966a9aa041cc32e16" translate="yes" xml:space="preserve">
          <source>Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors.</source>
          <target state="translated">サンプルを分類するためのサポートベクターマシンの簡単な使用法。決定面とサポートベクトルをプロットします。</target>
        </trans-unit>
        <trans-unit id="5b50d9c69163fc1e922706c7d40ea5de7c4c3507" translate="yes" xml:space="preserve">
          <source>Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with multivariate response, a.k.a. PLS2 - PLSRegression, with univariate response, a.k.a. PLS1 - CCA</source>
          <target state="translated">PLSCanonical-多変量応答を持つPLSRegression,別名PLS2-単変量応答を持つPLSRegression,別名PLS1-CCA</target>
        </trans-unit>
        <trans-unit id="da21ac2a81c42a0cc34c3a8c8243f3f710d2f668" translate="yes" xml:space="preserve">
          <source>SimpleImputer</source>
          <target state="translated">SimpleImputer</target>
        </trans-unit>
        <trans-unit id="0cd5c8d669edd41f72cf141b1f653ffc3a8f7d8a" translate="yes" xml:space="preserve">
          <source>Simply perform a svd on the crosscovariance matrix: X&amp;rsquo;Y There are no iterative deflation here.</source>
          <target state="translated">相互共分散行列に対してsvdを実行するだけです：X'Yここには反復デフレはありません。</target>
        </trans-unit>
        <trans-unit id="f72f0eda605215d24ff9d1908550395272883fb4" translate="yes" xml:space="preserve">
          <source>Simulations</source>
          <target state="translated">Simulations</target>
        </trans-unit>
        <trans-unit id="2e04b6f26b355099b78d114e001527cec11f01b3" translate="yes" xml:space="preserve">
          <source>Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="4ed5170dfb2a4a5fe27dc284ef1f79230346d84b" translate="yes" xml:space="preserve">
          <source>Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.</source>
          <target state="translated">モデルの内部表現は2つの異なるアーキテクチャで異なる場合があるため、あるアーキテクチャでモデルをダンプして別のアーキテクチャでロードすることはサポートされていません。</target>
        </trans-unit>
        <trans-unit id="2e7dca0922f252e8bcb5dd7de62f190d029edf35" translate="yes" xml:space="preserve">
          <source>Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the &lt;code&gt;n_features&lt;/code&gt; parameter; otherwise the features will not be mapped evenly to the columns.</source>
          <target state="translated">単純なモジュロを使用してハッシュ関数を列インデックスに変換するため、 &lt;code&gt;n_features&lt;/code&gt; パラメーターとして2の累乗を使用することをお勧めします。それ以外の場合、機能は列に均等にマッピングされません。</target>
        </trans-unit>
        <trans-unit id="e94526c23963e4af6db5a385aa61965ac4ba9d0e" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times.</source>
          <target state="translated">&lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 分類器に適合させる必要があるため、このメソッドはO（n_classes ^ 2）の複雑さのため、通常、1対残りよりも遅くなります。ただし、この方法は、 &lt;code&gt;n_samples&lt;/code&gt; でうまくスケーリングしないカーネルアルゴリズムなどのアルゴリズムには有利な場合があります。これは、個々の学習問題に含まれるのはデータの小さなサブセットのみであるのに対し、残りと1対1では、完全なデータセットが &lt;code&gt;n_classes&lt;/code&gt; 回使用されるためです。</target>
        </trans-unit>
        <trans-unit id="d70a1912c85de6341311b3ee0902966d17cafa41" translate="yes" xml:space="preserve">
          <source>Since it requires to fit &lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don&amp;rsquo;t scale well with &lt;code&gt;n_samples&lt;/code&gt;. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used &lt;code&gt;n_classes&lt;/code&gt; times. The decision function is the result of a monotonic transformation of the one-versus-one classification.</source>
          <target state="translated">&lt;code&gt;n_classes * (n_classes - 1) / 2&lt;/code&gt; 分類子を適合させる必要があるため、このメソッドは、O（n_classes ^ 2）の複雑さのために、通常、残りの1つよりも低速です。ただし、この方法は、 &lt;code&gt;n_samples&lt;/code&gt; で適切にスケーリングされないカーネルアルゴリズムなどのアルゴリズムに有利な場合があります。これは、個々の学習問題にはデータの小さなサブセットしか含まれていないのに対し、残りの1 &lt;code&gt;n_classes&lt;/code&gt; 、完全なデータセットがn_classes回使用されるためです。決定関数は、1対1の分類の単調変換の結果です。</target>
        </trans-unit>
        <trans-unit id="885cdc36b68d6b1fe527d22b8af012efa7ee88fc" translate="yes" xml:space="preserve">
          <source>Since our loss function is dependent on the amount of samples, the latter will influence the selected value of &lt;code&gt;C&lt;/code&gt;. The question that arises is &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</source>
          <target state="translated">私たちの損失関数はサンプルの量に依存しているため、後者は &lt;code&gt;C&lt;/code&gt; の選択値に影響を与えます。発生する問題は &lt;code&gt;How do we optimally adjust C to account for the different amount of training samples?&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8414cbee67356c2ab2c8ba5220ad5c2247b09cc6" translate="yes" xml:space="preserve">
          <source>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.</source>
          <target state="translated">再帰的分割は木構造で表すことができるので、サンプルを分離するのに必要な分割数は、ルートノードから終端ノードまでのパスの長さに相当します。</target>
        </trans-unit>
        <trans-unit id="e0effd5f72f2afc7c618332a9b819d624a406e57" translate="yes" xml:space="preserve">
          <source>Since the L1 norm promotes sparsity of features we might be interested in selecting only a subset of the most interesting features from the dataset. This example shows how to select two the most interesting features from the diabetes dataset.</source>
          <target state="translated">L1ノルムは特徴量の分散を促進するので,データセットから最も興味深い特徴量のサブセットだけを選択することに興味があるかもしれない.この例は,糖尿病のデータセットから最も興味深い特徴量を2つ選択する方法を示している.</target>
        </trans-unit>
        <trans-unit id="53564a374f656b4eebc264b9099b9cd10a25ad1a" translate="yes" xml:space="preserve">
          <source>Since the Poisson regressor internally models the log of the expected target value instead of the expected value directly (log vs identity link function), the relationship between X and y is not exactly linear anymore. Therefore the Poisson regressor is called a Generalized Linear Model (GLM) rather than a vanilla linear model as is the case for Ridge regression.</source>
          <target state="translated">ポアソン回帰器は、期待値を直接モデル化するのではなく、期待された目標値の対数を内部的にモデル化するので(対数対同一性リンク関数)、Xとyの間の関係は、もはや厳密には線形ではありません。したがって、ポアソン回帰は、リッジ回帰の場合のようなバニラ線形モデルではなく、一般化線形モデル(GLM)と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="41606a5be005625c4678c2fc6968d98c5bcdacbb" translate="yes" xml:space="preserve">
          <source>Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature&amp;rsquo;s value is zero. This mechanism is enabled by default with &lt;code&gt;alternate_sign=True&lt;/code&gt; and is particularly useful for small hash table sizes (&lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt;). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like &lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt;&lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt;&lt;/a&gt; feature selectors that expect non-negative inputs.</source>
          <target state="translated">ハッシュ関数は（無関係な）フィーチャ間の衝突を引き起こす可能性があるため、署名付きハッシュ関数が使用され、ハッシュ値の符号によって、フィーチャの出力行列に格納される値の符号が決まります。このようにして、衝突はエラーを累積するのではなくキャンセルする可能性が高く、出力フィーチャの値の期待される平均はゼロです。このメカニズムはデフォルトで &lt;code&gt;alternate_sign=True&lt;/code&gt; で有効になっており、ハッシュテーブルのサイズが小さい場合（ &lt;code&gt;n_features &amp;lt; 10000&lt;/code&gt; ）に特に役立ちます。ハッシュテーブルサイズが大きい場合は、無効にして、負でない入力を期待する&lt;a href=&quot;generated/sklearn.naive_bayes.multinomialnb#sklearn.naive_bayes.MultinomialNB&quot;&gt; &lt;code&gt;sklearn.naive_bayes.MultinomialNB&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;sklearn.feature_selection.chi2&lt;/code&gt; &lt;/a&gt;機能セレクターなどの推定器に出力を渡すことができます。</target>
        </trans-unit>
        <trans-unit id="91020f655b0d3976000fc58a456fa0d94621c5a6" translate="yes" xml:space="preserve">
          <source>Since the kernel that is to be approximated is additive, the components of the input vectors can be treated separately. Each entry in the original space is transformed into 2*sample_steps+1 features, where sample_steps is a parameter of the method. Typical values of sample_steps include 1, 2 and 3.</source>
          <target state="translated">近似されるカーネルは加法的であるため,入力ベクトルの成分は別々に扱うことができます.元の空間の各エントリは,2*sample_steps+1特徴量に変換されます.sample_steps の典型的な値は 1,2,3 です.</target>
        </trans-unit>
        <trans-unit id="eab55792648442f25c33ef137afa5ea98f14550a" translate="yes" xml:space="preserve">
          <source>Since the linear predictor \(Xw\) can be negative and Poisson, Gamma and Inverse Gaussian distributions don&amp;rsquo;t support negative values, it is necessary to apply an inverse link function that guarantees the non-negativeness. For example with &lt;code&gt;link='log'&lt;/code&gt;, the inverse link function becomes \(h(Xw)=\exp(Xw)\).</source>
          <target state="translated">線形予測子\（Xw \）は負になる可能性があり、ポアソン、ガンマ、および逆ガウス分布は負の値をサポートしないため、非負性を保証する逆リンク関数を適用する必要があります。たとえば、 &lt;code&gt;link='log'&lt;/code&gt; の場合、逆リンク関数は\（h（Xw）= \ exp（Xw）\）になります。</target>
        </trans-unit>
        <trans-unit id="dac98c213a89fd4774cf1c1f95b63e10c23ed6ab" translate="yes" xml:space="preserve">
          <source>Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):</source>
          <target state="translated">後処理が難しいので、変分ベイズ法では、単純な分布を使って近似し、変分パラメータを最適化して、Evidence Lower Bound (ELBO)を最大化します。</target>
        </trans-unit>
        <trans-unit id="ce93b96a689b29304c626bbff15b3c9ae5662f8f" translate="yes" xml:space="preserve">
          <source>Since the thresholds are sorted from low to high values, they are reversed upon returning them to ensure they correspond to both &lt;code&gt;fpr&lt;/code&gt; and &lt;code&gt;tpr&lt;/code&gt;, which are sorted in reversed order during their calculation.</source>
          <target state="translated">しきい値は低い値から高い値に並べ替えられるため、返されるときに逆になり、計算時に逆の順序で並べ替えられる &lt;code&gt;fpr&lt;/code&gt; と &lt;code&gt;tpr&lt;/code&gt; の両方に対応するようになります。</target>
        </trans-unit>
        <trans-unit id="7f69d32984c3b4f143cfa37bb4e60432050ed0eb" translate="yes" xml:space="preserve">
          <source>Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.</source>
          <target state="translated">近似エンベッディングを用いた経験的な研究はあまり行われていないので、可能であれば厳密なカーネル法と結果を比較することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="181ed345f14e5249ac33bd9934643c4f9dd72c8f" translate="yes" xml:space="preserve">
          <source>Since v0.21, if &lt;code&gt;input&lt;/code&gt; is &lt;code&gt;filename&lt;/code&gt; or &lt;code&gt;file&lt;/code&gt;, the data is first read from the file and then passed to the given callable analyzer.</source>
          <target state="translated">v0.21以降、 &lt;code&gt;input&lt;/code&gt; が &lt;code&gt;filename&lt;/code&gt; または &lt;code&gt;file&lt;/code&gt; 場合、データは最初にファイルから読み取られ、次に指定された呼び出し可能アナライザーに渡されます。</target>
        </trans-unit>
        <trans-unit id="fa984969d0a90a5820c4fc022c64bfc47ca5a084" translate="yes" xml:space="preserve">
          <source>Single estimator versus bagging: bias-variance decomposition</source>
          <target state="translated">単一推定器対バギング:バイアス-分散分解</target>
        </trans-unit>
        <trans-unit id="c2fe1a00c3aef2fdadf0dd5e7ea7933f55e2ab1b" translate="yes" xml:space="preserve">
          <source>Single metric evaluation using &lt;code&gt;cross_validate&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;cross_validate&lt;/code&gt; を使用した単一メトリック評価</target>
        </trans-unit>
        <trans-unit id="78a22764fe4a9b48a649589e690300655f65c80d" translate="yes" xml:space="preserve">
          <source>Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (&lt;em&gt;l2&lt;/em&gt;), Manhattan distance (or Cityblock, or &lt;em&gt;l1&lt;/em&gt;), cosine distance, or any precomputed affinity matrix.</source>
          <target state="translated">単一の平均的で完全なリンケージは、さまざまな距離（またはアフィニティ）、特にユークリッド距離（&lt;em&gt;l2&lt;/em&gt;）、マンハッタン距離（またはCityblockまたは&lt;em&gt;l1&lt;/em&gt;）、コサイン距離、または任意の事前計算されたアフィニティマトリックスで使用できます。</target>
        </trans-unit>
        <trans-unit id="b1a526a4c2ab5cc879cbcf97bbdfc6e58be65f64" translate="yes" xml:space="preserve">
          <source>Singular values of &lt;code&gt;X&lt;/code&gt;. Only available when &lt;code&gt;X&lt;/code&gt; is dense.</source>
          <target state="translated">&lt;code&gt;X&lt;/code&gt; の特異値。 &lt;code&gt;X&lt;/code&gt; が密集している場合にのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="409f99dea48046b433f18bebd495f19a0bb51787" translate="yes" xml:space="preserve">
          <source>Singularities</source>
          <target state="translated">Singularities</target>
        </trans-unit>
        <trans-unit id="857a843ae0f540aecaddebae91ddc74b518d5cf4" translate="yes" xml:space="preserve">
          <source>Singularities:</source>
          <target state="translated">Singularities:</target>
        </trans-unit>
        <trans-unit id="2df59d349ec07bd33a82cdc2b0c4c3d4152244c6" translate="yes" xml:space="preserve">
          <source>Size of minibatches for stochastic optimizers. If the solver is &amp;lsquo;lbfgs&amp;rsquo;, the classifier will not use minibatch. When set to &amp;ldquo;auto&amp;rdquo;, &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</source>
          <target state="translated">確率的オプティマイザのミニバッチのサイズ。ソルバーが 'lbfgs'の場合​​、分類器はミニバッチを使用しません。「auto」に設定すると、 &lt;code&gt;batch_size=min(200, n_samples)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7241ed1ae94944f10d565b9b8502a2569d69bebc" translate="yes" xml:space="preserve">
          <source>Size of text font. If None, determined automatically to fit figure.</source>
          <target state="translated">テキストのフォントサイズを指定します。なしの場合は、図形に合わせて自動的に決定されます。</target>
        </trans-unit>
        <trans-unit id="fa65aa30a853af1cf81f53119b6649c5aa5e2817" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">Ledoit-Wolf 推定時に共分散行列が分割されるブロックのサイズ.これは純粋にメモリの最適化であり,結果には影響しません.</target>
        </trans-unit>
        <trans-unit id="3bdf2049b3b05b0720764317c09e88bc19700eec" translate="yes" xml:space="preserve">
          <source>Size of the blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.</source>
          <target state="translated">共分散行列を分割するブロックのサイズ.これは純粋にメモリの最適化であり,結果には影響しません.</target>
        </trans-unit>
        <trans-unit id="612eb8e8a229547855d2a4c02d66bbe2afb0395a" translate="yes" xml:space="preserve">
          <source>Size of the mini batches.</source>
          <target state="translated">ミニバッチのサイズ。</target>
        </trans-unit>
        <trans-unit id="aa636a80a54912b13ca3fa6029e0a40e02f80415" translate="yes" xml:space="preserve">
          <source>Size of the return array</source>
          <target state="translated">戻り値の配列のサイズ</target>
        </trans-unit>
        <trans-unit id="08f603d3fe1f30df7982a9a08f592731c9eab73e" translate="yes" xml:space="preserve">
          <source>Size of the test sets.</source>
          <target state="translated">テストセットのサイズ。</target>
        </trans-unit>
        <trans-unit id="3ede3a7d9dde54c062e45da23a9dc65bbb39cbbf" translate="yes" xml:space="preserve">
          <source>Size of the test sets. Must be strictly less than the number of samples.</source>
          <target state="translated">テストセットのサイズ。厳密にはサンプル数以下でなければならない。</target>
        </trans-unit>
        <trans-unit id="1d7d650781fdf69336502b899ccd5c9f80ba4848" translate="yes" xml:space="preserve">
          <source>Skip input validation checks, including the Gram matrix when provided assuming there are handled by the caller when check_input=False.</source>
          <target state="translated">check_input=Falseの場合、呼び出し元によって処理されると仮定して、提供された場合には、グラム行列を含む入力の検証チェックをスキップします。</target>
        </trans-unit>
        <trans-unit id="119077d89fb1cbe89db9591404feee43530ef290" translate="yes" xml:space="preserve">
          <source>Slides explaining PLS</source>
          <target state="translated">PLSを説明するスライド</target>
        </trans-unit>
        <trans-unit id="c3d721c0cfe644c7ca720484ae796856345cb087" translate="yes" xml:space="preserve">
          <source>Small outliers</source>
          <target state="translated">小さな外れ値</target>
        </trans-unit>
        <trans-unit id="6cf8c0d1548c80d5c7b8e80adf89b56b8a30e60f" translate="yes" xml:space="preserve">
          <source>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to &lt;code&gt;(2*C)^-1&lt;/code&gt; in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</source>
          <target state="translated">alphaの小さな正の値は、問題の条件付けを改善し、推定値の分散を減らします。Alphaは、LogisticRegressionやLinearSVCなどの他の線形モデルの &lt;code&gt;(2*C)^-1&lt;/code&gt; に対応します。配列が渡された場合、ペナルティはターゲットに固有であると見なされます。したがって、それらは数で対応する必要があります。</target>
        </trans-unit>
        <trans-unit id="8e135bd52bd2eb3356a694f0d8575402c5375bb6" translate="yes" xml:space="preserve">
          <source>Smaller values lead to better embedding and higher number of dimensions (n_components) in the target projection space.</source>
          <target state="translated">値が小さいほど、ターゲット投影空間への埋め込みが良くなり、より多くの次元数(n_components)が得られます。</target>
        </trans-unit>
        <trans-unit id="178a5fd9e6a787566f82c9ecbd118e48b0edcccd" translate="yes" xml:space="preserve">
          <source>Smallest value of alpha / alpha_max considered</source>
          <target state="translated">alpha/alpha_max の最小値を考慮</target>
        </trans-unit>
        <trans-unit id="9ec75e4c898141f811f9d6fe4e66f6da7a97bb9c" translate="yes" xml:space="preserve">
          <source>Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</source>
          <target state="translated">文書度数に1を加えることで、まるでコレクション内のすべての用語を含む余分な文書が正確に一度だけ見られたかのように、idfの重みを滑らかにします。ゼロ分割を防ぎます。</target>
        </trans-unit>
        <trans-unit id="8ec8b1649217676578a05802f05dc4dfdec72ebc" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class.</source>
          <target state="translated">各クラスの経験的対数確率を平滑化したもの。</target>
        </trans-unit>
        <trans-unit id="d5d952f65cbc310a8284a0aa676904d4b84a635c" translate="yes" xml:space="preserve">
          <source>Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.</source>
          <target state="translated">各クラスの経験的対数確率を平滑化したもの.学習集合に1つのクラスがある場合のエッジケースでのみ使用される.</target>
        </trans-unit>
        <trans-unit id="fb1739757cbc4d2da964b132a46ededacd98a2aa" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier for unfitted estimators.</source>
          <target state="translated">ソフト投票/多数決分類器を用いた非適合推定器のための分類器。</target>
        </trans-unit>
        <trans-unit id="3c16977f20db1a9e128b2062c246165103dd7921" translate="yes" xml:space="preserve">
          <source>Soft Voting/Majority Rule classifier.</source>
          <target state="translated">ソフト投票/マジョリティルールの分類器。</target>
        </trans-unit>
        <trans-unit id="a33a62c21ea4043dbf31a4f6ee598307b73aa466" translate="yes" xml:space="preserve">
          <source>Soft hint to choose the default backend if no specific backend was selected with the parallel_backend context manager. The default process-based backend is &amp;lsquo;loky&amp;rsquo; and the default thread-based backend is &amp;lsquo;threading&amp;rsquo;.</source>
          <target state="translated">parallel_backendコンテキストマネージャーで特定のバックエンドが選択されていない場合にデフォルトのバックエンドを選択するためのソフトヒント。デフォルトのプロセスベースのバックエンドは「loky」であり、デフォルトのスレッドベースのバックエンドは「threading」です。</target>
        </trans-unit>
        <trans-unit id="9653b7a05f5df3e5d87561ce96e265c541ad8c31" translate="yes" xml:space="preserve">
          <source>SokalMichenerDistance</source>
          <target state="translated">SokalMichenerDistance</target>
        </trans-unit>
        <trans-unit id="01ed2fbc860294634b46d80d008798b47284ef75" translate="yes" xml:space="preserve">
          <source>SokalSneathDistance</source>
          <target state="translated">SokalSneathDistance</target>
        </trans-unit>
        <trans-unit id="7472593b6d35821b7f5c4104f85f3418ec74c28e" translate="yes" xml:space="preserve">
          <source>Solution to the non-negative least squares problem.</source>
          <target state="translated">非負の最小二乗問題の解法。</target>
        </trans-unit>
        <trans-unit id="0b76645291a4941abead277af175738d7e9485f1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解決策：&lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt; / exercises / plot_digits_classification_exercise.py</target>
        </trans-unit>
        <trans-unit id="97a1e21d1798b81e7cea434e741d7087aa2f4a99" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解決策：&lt;a href=&quot;http://scikit-learn.org/stable/_downloads/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt; / exercises / plot_iris_exercise.py</target>
        </trans-unit>
        <trans-unit id="8dc243287f9af0458afdd79c7e208cb930e6e9d1" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/91f0cd01beb5b964a5e1ece5bdd15499/plot_iris_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解決策：&lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/91f0cd01beb5b964a5e1ece5bdd15499/plot_iris_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_iris_exercise.py&lt;/code&gt; &lt;/a&gt; / exercises / plot_iris_exercise.py</target>
        </trans-unit>
        <trans-unit id="e5a155c549be47525e0ef469c6ede18a502d5bc6" translate="yes" xml:space="preserve">
          <source>Solution: &lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/bfcebce45024b267e8546d6914acfedc/plot_digits_classification_exercise.py&quot;&gt;&lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">解決策：&lt;a href=&quot;https://scikit-learn.org/0.23/_downloads/bfcebce45024b267e8546d6914acfedc/plot_digits_classification_exercise.py&quot;&gt; &lt;code&gt;../../auto_examples/exercises/plot_digits_classification_exercise.py&lt;/code&gt; &lt;/a&gt; / exercises / plot_digits_classification_exercise.py</target>
        </trans-unit>
        <trans-unit id="908bab59b18307a14acc0f3d3e00d2c36c09b88e" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model.</source>
          <target state="translated">等張回帰モデルを解きなさい。</target>
        </trans-unit>
        <trans-unit id="d31ac38ecaa97cd7ca9cf4223578d60df63f89a9" translate="yes" xml:space="preserve">
          <source>Solve the isotonic regression model:</source>
          <target state="translated">等張回帰モデルを解きなさい。</target>
        </trans-unit>
        <trans-unit id="48c6334f59edac84435c4184f66b59babd6924b9" translate="yes" xml:space="preserve">
          <source>Solve the ridge equation by the method of normal equations.</source>
          <target state="translated">法線方程式の方法で稜線方程式を解く。</target>
        </trans-unit>
        <trans-unit id="b5fa00edfa7fc06c7e99359e114af78ec006b205" translate="yes" xml:space="preserve">
          <source>Solver to use in the computational routines:</source>
          <target state="translated">計算ルーチンで使用するソルバー。</target>
        </trans-unit>
        <trans-unit id="5c136e6e68fedeebc5e62ea492bdc13f5c51a357" translate="yes" xml:space="preserve">
          <source>Solver to use, possible values:</source>
          <target state="translated">使用するソルバー、可能な値。</target>
        </trans-unit>
        <trans-unit id="577db6a48ff5a1db9c02bebc0320d90f752c60ef" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem online.</source>
          <target state="translated">辞書学習の行列因数分解問題をオンラインで解く。</target>
        </trans-unit>
        <trans-unit id="8820b686f5bac3c2f3bf8f93441f10523c0fe031" translate="yes" xml:space="preserve">
          <source>Solves a dictionary learning matrix factorization problem.</source>
          <target state="translated">辞書学習行列因数分解問題を解く。</target>
        </trans-unit>
        <trans-unit id="b22d518aabf32cc9c9347bf653295056dc359f7f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.</source>
          <target state="translated">グラム行列X.T*Xと積X.T*yのみを用いて、n_targets直交一致追求問題を解く。</target>
        </trans-unit>
        <trans-unit id="80547cf29da9d4cc131f68d1680f3500976f9f6f" translate="yes" xml:space="preserve">
          <source>Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:</source>
          <target state="translated">n_targets 直交一致追求問題を解く。問題のインスタンスは,次のような形式を持つ.</target>
        </trans-unit>
        <trans-unit id="8d4fd8866d93aa1260a7a3d03ef9a9a9f9a2fc7d" translate="yes" xml:space="preserve">
          <source>Solves the optimization problem:</source>
          <target state="translated">最適化問題を解決します。</target>
        </trans-unit>
        <trans-unit id="e29fb180670f8bd6283a93ce616785d39e9b899f" translate="yes" xml:space="preserve">
          <source>Some advantages of decision trees are:</source>
          <target state="translated">決定木の利点はいくつかあります。</target>
        </trans-unit>
        <trans-unit id="2b6f2b5ee645a40c14b49c77184129b10ec1567a" translate="yes" xml:space="preserve">
          <source>Some also work in the multilabel case:</source>
          <target state="translated">マルチラベルの場合も動作するものがあります。</target>
        </trans-unit>
        <trans-unit id="8762622dcc16bf1560cb81f69bbd48256b77f9a4" translate="yes" xml:space="preserve">
          <source>Some calculations when implemented using standard numpy vectorized operations involve using a large amount of temporary memory. This may potentially exhaust system memory. Where computations can be performed in fixed-memory chunks, we attempt to do so, and allow the user to hint at the maximum size of this working memory (defaulting to 1GB) using &lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt;&lt;code&gt;sklearn.set_config&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;config_context&lt;/code&gt;. The following suggests to limit temporary working memory to 128 MiB:</source>
          <target state="translated">標準のnumpyベクトル化された演算を使用して実装された場合の計算には、大量の一時メモリの使用が含まれます。これにより、システムメモリが使い果たされる可能性があります。固定メモリチャンクで計算を実行できる場合は、そのようにして、ユーザーが&lt;a href=&quot;generated/sklearn.set_config#sklearn.set_config&quot;&gt; &lt;code&gt;sklearn.set_config&lt;/code&gt; &lt;/a&gt;または &lt;code&gt;config_context&lt;/code&gt; を使用して、この作業メモリの最大サイズ（デフォルトは1GB）をヒントにできるようにします。以下は、一時的な作業メモリを128 MiBに制限することを提案しています。</target>
        </trans-unit>
        <trans-unit id="f425af2b7289a6eb3b0699842a415a72e1141c04" translate="yes" xml:space="preserve">
          <source>Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in &lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt;&lt;code&gt;StratifiedKFold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt;&lt;code&gt;StratifiedShuffleSplit&lt;/code&gt;&lt;/a&gt; to ensure that relative class frequencies is approximately preserved in each train and validation fold.</source>
          <target state="translated">一部の分類問題は、ターゲットクラスの分布に大きな不均衡を示す可能性があります。たとえば、陽性サンプルの数倍の陰性サンプルが存在する可能性があります。このような場合、&lt;a href=&quot;generated/sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold&quot;&gt; &lt;code&gt;StratifiedKFold&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.model_selection.stratifiedshufflesplit#sklearn.model_selection.StratifiedShuffleSplit&quot;&gt; &lt;code&gt;StratifiedShuffleSplit&lt;/code&gt; で&lt;/a&gt;実装されている層別サンプリングを使用して、相対クラス頻度が各トレインと検証フォールドでほぼ保持されるようにすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="2ea2f829ceb432ffa0e3b3d420b4273e01e30d41" translate="yes" xml:space="preserve">
          <source>Some cross validation iterators, such as &lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt;&lt;code&gt;KFold&lt;/code&gt;&lt;/a&gt;, have an inbuilt option to shuffle the data indices before splitting them. Note that:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.kfold#sklearn.model_selection.KFold&quot;&gt; &lt;code&gt;KFold&lt;/code&gt; &lt;/a&gt;などの一部の相互検証反復子には、データインデックスを分割する前にシャッフルする組み込みオプションがあります。ご了承ください：</target>
        </trans-unit>
        <trans-unit id="1b7524a4e391762865d52d4ee865a5a389b3ed4f" translate="yes" xml:space="preserve">
          <source>Some estimators expose a &lt;code&gt;transform&lt;/code&gt; method, for instance to reduce the dimensionality of the dataset.</source>
          <target state="translated">一部の推定器は、たとえばデータセットの次元数を減らすために &lt;code&gt;transform&lt;/code&gt; メソッドを公開します。</target>
        </trans-unit>
        <trans-unit id="abe93a33221be53771cefc563a6b553fa747a230" translate="yes" xml:space="preserve">
          <source>Some literature promotes alternative definitions of balanced accuracy. Our definition is equivalent to &lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; with class-balanced sample weights, and shares desirable properties with the binary case. See the &lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">一部の文献では、バランスのとれた精度の代替定義を推奨しています。私たちの定義は、クラスのバランスがとれたサンプルの重みを使用した&lt;a href=&quot;sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; &lt;/a&gt;と同等であり、バイナリの場合と望ましい特性を共有しています。&lt;a href=&quot;../model_evaluation#balanced-accuracy-score&quot;&gt;ユーザーガイドを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="65e1dc1251c858f270c665ff61463afe65f478d7" translate="yes" xml:space="preserve">
          <source>Some metrics are essentially defined for binary classification tasks (e.g. &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt;). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled &lt;code&gt;1&lt;/code&gt; (though this may be configurable through the &lt;code&gt;pos_label&lt;/code&gt; parameter).</source>
          <target state="translated">一部のメトリックは基本的にバイナリ分類タスク用に定義されています（例：&lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt;）。これらのケースでは、デフォルトでのみ正のラベルは、正のクラスが標識されていることをデフォルトと仮定して、評価される &lt;code&gt;1&lt;/code&gt; （これを介して設定可能であってもよいけれども &lt;code&gt;pos_label&lt;/code&gt; のパラメータ）。</target>
        </trans-unit>
        <trans-unit id="d5ba6b95ba600216ff9982f7a3dbaf94b6802f73" translate="yes" xml:space="preserve">
          <source>Some models allow for specialized, efficient parameter search strategies, &lt;a href=&quot;#alternative-cv&quot;&gt;outlined below&lt;/a&gt;. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; exhaustively considers all parameter combinations, while &lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt;&lt;code&gt;RandomizedSearchCV&lt;/code&gt;&lt;/a&gt; can sample a given number of candidates from a parameter space with a specified distribution. After describing these tools we detail &lt;a href=&quot;#grid-search-tips&quot;&gt;best practice&lt;/a&gt; applicable to both approaches.</source>
          <target state="translated">一部のモデルで&lt;a href=&quot;#alternative-cv&quot;&gt;は、以下&lt;/a&gt;に概説する、特殊化された効率的なパラメーター検索戦略が可能です。scikit-learnには、検索候補をサンプリングする2つの一般的なアプローチが用意されています。指定された値に対して、&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;はすべてのパラメーターの組み合わせを徹底的に検討しますが、&lt;a href=&quot;generated/sklearn.model_selection.randomizedsearchcv#sklearn.model_selection.RandomizedSearchCV&quot;&gt; &lt;code&gt;RandomizedSearchCV&lt;/code&gt; &lt;/a&gt;は、指定された分布のパラメーター空間から指定された数の候補をサンプリングできます。これらのツールについて説明した後、両方のアプローチに適用できる&lt;a href=&quot;#grid-search-tips&quot;&gt;ベストプラクティス&lt;/a&gt;について詳しく説明します。</target>
        </trans-unit>
        <trans-unit id="95196f8314df139319d7b42ff6d7520f5ecc9f1d" translate="yes" xml:space="preserve">
          <source>Some models also have &lt;code&gt;row_labels_&lt;/code&gt; and &lt;code&gt;column_labels_&lt;/code&gt; attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.</source>
          <target state="translated">一部のモデルには、 &lt;code&gt;row_labels_&lt;/code&gt; および &lt;code&gt;column_labels_&lt;/code&gt; 属性もあります。これらのモデルは、ブロックの対角線やチェッカーボードのバイクラスター構造などで、行と列を分割します。</target>
        </trans-unit>
        <trans-unit id="89f290ef487f7e4f63f1b82009e209966dcbe74f" translate="yes" xml:space="preserve">
          <source>Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.</source>
          <target state="translated">いくつかのモデルは、パラメータの単一の値に対する推定器のフィッティングとほぼ同じくらい効率的に、いくつかのパラメータの値の範囲のデータをフィッティングすることができます。この機能を利用して、このパラメータのモデル選択に使用されるより効率的なクロスバリデーションを実行することができます。</target>
        </trans-unit>
        <trans-unit id="d786744290bacd9a4dfc207be555be0e40c3853e" translate="yes" xml:space="preserve">
          <source>Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).</source>
          <target state="translated">いくつかのモデルは、単一の正則化パスを計算することによって、正則化パラメータの最適推定値の情報理論的な閉形式を提供することができる(クロスバリデーションを使用する場合は、複数の正則化パスを計算する代わりに)。</target>
        </trans-unit>
        <trans-unit id="ad14a182695bef0a4c2fe22edd0961e8db73147c" translate="yes" xml:space="preserve">
          <source>Some of the clusters learned without connectivity constraints do not respect the structure of the swiss roll and extend across different folds of the manifolds. On the opposite, when opposing connectivity constraints, the clusters form a nice parcellation of the swiss roll.</source>
          <target state="translated">接続性制約なしに学習されたクラスタのいくつかは、スイスロールの構造を尊重せず、多様体の異なるひだにまたがって広がっています。反対に、接続性制約に反対すると、クラスタはスイスロールの素敵なパーセル化を形成します。</target>
        </trans-unit>
        <trans-unit id="877cbb42097301f5a68339d0d9f55e4ca85ad3c3" translate="yes" xml:space="preserve">
          <source>Some of these are restricted to the binary classification case:</source>
          <target state="translated">これらの中には、2値分類の場合に限定したものもある。</target>
        </trans-unit>
        <trans-unit id="bc828cde0b0d5dbd5e8ad77797297d4f6416ab76" translate="yes" xml:space="preserve">
          <source>Some other classifiers cope better with this harder version of the task. Try running &lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;Sample pipeline for text feature extraction and evaluation&lt;/a&gt; with and without the &lt;code&gt;--filter&lt;/code&gt; option to compare the results.</source>
          <target state="translated">他の一部の分類子は、このより難しいバージョンのタスクにうまく対応しています。結果を比較するために、 &lt;code&gt;--filter&lt;/code&gt; オプションを使用した場合と使用しない&lt;a href=&quot;../auto_examples/model_selection/grid_search_text_feature_extraction#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py&quot;&gt;場合のテキストフィーチャー抽出と評価のサンプルパイプラインを&lt;/a&gt;実行してみてください。</target>
        </trans-unit>
        <trans-unit id="1d754add1306692cb962c5467414be940979d0ab" translate="yes" xml:space="preserve">
          <source>Some parameter settings may result in a failure to &lt;code&gt;fit&lt;/code&gt; one or more folds of the data. By default, this will cause the entire search to fail, even if some parameter settings could be fully evaluated. Setting &lt;code&gt;error_score=0&lt;/code&gt; (or &lt;code&gt;=np.NaN&lt;/code&gt;) will make the procedure robust to such failure, issuing a warning and setting the score for that fold to 0 (or &lt;code&gt;NaN&lt;/code&gt;), but completing the search.</source>
          <target state="translated">一部のパラメーター設定は、データの1つ以上のフォールドに &lt;code&gt;fit&lt;/code&gt; できない場合があります。デフォルトでは、一部のパラメーター設定を完全に評価できたとしても、検索全体が失敗します。設定 &lt;code&gt;error_score=0&lt;/code&gt; （または &lt;code&gt;=np.NaN&lt;/code&gt; ）警告を発行し、0（またはにその倍のスコアを設定し、このような障害への手順は堅牢になります &lt;code&gt;NaN&lt;/code&gt; の）が、検索を完了しました。</target>
        </trans-unit>
        <trans-unit id="2f1168d7fab23533f7c212613fc87fe5fb99b1b4" translate="yes" xml:space="preserve">
          <source>Some scikit-learn estimators and utilities can parallelize costly operations using multiple CPU cores, thanks to the following components:</source>
          <target state="translated">いくつかのscikit-learnの見積もりツールやユーティリティは、以下のコンポーネントのおかげで、複数のCPUコアを使用してコストのかかる処理を並列化することができます。</target>
        </trans-unit>
        <trans-unit id="f29c3cd2b5860fb787d236e9a466d0e36eb10659" translate="yes" xml:space="preserve">
          <source>Some tips and tricks:</source>
          <target state="translated">いくつかのコツをご紹介します。</target>
        </trans-unit>
        <trans-unit id="63fe20eae64c7864fd32162af52c1f81421bc7d2" translate="yes" xml:space="preserve">
          <source>Sometimes it may be useful to convert the data back into the original feature space. The &lt;code&gt;inverse_transform&lt;/code&gt; function converts the binned data into the original feature space. Each value will be equal to the mean of the two bin edges.</source>
          <target state="translated">データを元の特徴空間に戻すと便利な場合があります。 &lt;code&gt;inverse_transform&lt;/code&gt; の機能は、元の特徴空間にビン化データを変換します。各値は、2つのビンエッジの平均に等しくなります。</target>
        </trans-unit>
        <trans-unit id="315bc72af841ed152a9aae1c3ac0990cdcb834ed" translate="yes" xml:space="preserve">
          <source>Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high.</source>
          <target state="translated">ニューラルネットワークの学習された係数を見ると、学習動作についての洞察が得られることがあります。例えば、重みが構造化されていないように見える場合、一部が全く使用されていなかったり、非常に大きな係数が存在する場合、正則化が低すぎたり、学習率が高すぎたりすることがあります。</target>
        </trans-unit>
        <trans-unit id="fbff2a8532eac744fd3e459bcddf3fd34f40adee" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">ソースURL：&lt;a href=&quot;http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;http&lt;/a&gt; : //www4.stat.ncsu.edu/~boos/var.select/diabetes.html</target>
        </trans-unit>
        <trans-unit id="8173b56b5b02e6dc31d6c2059fb643537f89144d" translate="yes" xml:space="preserve">
          <source>Source URL: &lt;a href=&quot;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&lt;/a&gt;</source>
          <target state="translated">ソースURL：&lt;a href=&quot;https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html&quot;&gt;https&lt;/a&gt;：//www4.stat.ncsu.edu/~boos/var.select/diabetes.html</target>
        </trans-unit>
        <trans-unit id="bdef929636b0e2d76c9bcc79abe376f450451dd0" translate="yes" xml:space="preserve">
          <source>Sources, where n_samples is the number of samples and n_components is the number of components.</source>
          <target state="translated">ソースは、n_samplesはサンプル数、n_componentsはコンポーネント数です。</target>
        </trans-unit>
        <trans-unit id="3af0ce95ad1f86c8c1749c4ae38a0dba87aebcff" translate="yes" xml:space="preserve">
          <source>Sparse Principal Component Analysis.</source>
          <target state="translated">疎な主成分分析。</target>
        </trans-unit>
        <trans-unit id="dcbe3516134bdf9c59a33ffb1c2e3120ebfb3eac" translate="yes" xml:space="preserve">
          <source>Sparse Principal Components Analysis (SparsePCA)</source>
          <target state="translated">疎な主成分分析 (SparsePCA)</target>
        </trans-unit>
        <trans-unit id="e06472c25d26cda25191de9da3a114b1e469b208" translate="yes" xml:space="preserve">
          <source>Sparse coding</source>
          <target state="translated">疎なコーディング</target>
        </trans-unit>
        <trans-unit id="32c8d921f9e1520199d1db9fe64aa6fb0f91121f" translate="yes" xml:space="preserve">
          <source>Sparse coding with a precomputed dictionary</source>
          <target state="translated">事前に計算された辞書を用いた疎な符号化</target>
        </trans-unit>
        <trans-unit id="83cd17de4011d58af20829baa72e8c3c15415081" translate="yes" xml:space="preserve">
          <source>Sparse components extracted from the data.</source>
          <target state="translated">データから抽出された疎な成分</target>
        </trans-unit>
        <trans-unit id="4aefb6aa7d814b8be3e6d2cb6f2931a1dadb31bc" translate="yes" xml:space="preserve">
          <source>Sparse input</source>
          <target state="translated">疎な入力</target>
        </trans-unit>
        <trans-unit id="935bf4a32a6f741a33bb9ac8e725575de63e795c" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation</source>
          <target state="translated">疎な逆共分散推定</target>
        </trans-unit>
        <trans-unit id="409d5a415f20eafd9b9f09c6ba22d21458394422" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance estimation with an l1-penalized estimator.</source>
          <target state="translated">l1ペナルティ付き推定器を用いた疎な逆共分散推定。</target>
        </trans-unit>
        <trans-unit id="2ee089f1e56c91604e7cab7d40e8b9f34677bb75" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</source>
          <target state="translated">疎な逆共分散と交差検証されたl1ペナルティの選択</target>
        </trans-unit>
        <trans-unit id="0113e7df66bdaa38179e1b6944e6cd1aa2f5ffce" translate="yes" xml:space="preserve">
          <source>Sparse inverse covariance w/ cross-validated choice of the l1 penalty.</source>
          <target state="translated">疎な逆共分散と交差検証されたl1ペナルティの選択.</target>
        </trans-unit>
        <trans-unit id="92e371bb810dfdf353c195f32e5335e997df721c" translate="yes" xml:space="preserve">
          <source>Sparse principal components yields a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.</source>
          <target state="translated">疎な主成分は,より解析的で解釈可能な表現をもたらし,元の特徴のうちどの部分がサンプル間の違いに寄与しているかを明確に強調します.</target>
        </trans-unit>
        <trans-unit id="19dbec98d9db7f8dccbc05e595e6dcc554502b17" translate="yes" xml:space="preserve">
          <source>Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">疎なランダム行列は,密なガウスランダム射影行列に代わるもので,メモリ効率が高く,射影データの高速な計算を可能にする一方で,同様の埋め込み品質を保証します.</target>
        </trans-unit>
        <trans-unit id="5ad88cbdaa9d7d5c176762a66b957d3aa9661770" translate="yes" xml:space="preserve">
          <source>Sparse random matrix is an alternative to dense random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.</source>
          <target state="translated">疎ランダム行列は,密なランダム射影行列に代わるものであり,メモリ効率が高く,射影データの高速な計算を可能にする一方で,同様の埋め込み品質を保証します.</target>
        </trans-unit>
        <trans-unit id="a7a844fc75c56ce03e1afce70cb2355152140d0b" translate="yes" xml:space="preserve">
          <source>Sparsity</source>
          <target state="translated">Sparsity</target>
        </trans-unit>
        <trans-unit id="814e5a7e79ded720eafc96bc0232cca516d50079" translate="yes" xml:space="preserve">
          <source>Sparsity Example: Fitting only features 1 and 2</source>
          <target state="translated">スパーシティの例。フィーチャー1と2のみにフィット</target>
        </trans-unit>
        <trans-unit id="43cddceab3d136418b0e03e98d360e468cf1b8e5" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter.</source>
          <target state="translated">スパーシティ制御パラメータ。</target>
        </trans-unit>
        <trans-unit id="647e2a8c2a361b51e5b69ed284ca76c83752d0f6" translate="yes" xml:space="preserve">
          <source>Sparsity controlling parameter. Higher values lead to sparser components.</source>
          <target state="translated">スパース度を制御するパラメータ。値が大きいほど成分が疎になります。</target>
        </trans-unit>
        <trans-unit id="49f74e244eb107a1663f4aabb4f4ff9cbf7f050c" translate="yes" xml:space="preserve">
          <source>Spatial indexing trees are used to avoid calculating the full distance matrix, and allow for efficient memory usage on large sets of samples. Different distance metrics can be supplied via the &lt;code&gt;metric&lt;/code&gt; keyword.</source>
          <target state="translated">空間インデックスツリーは、完全な距離行列の計算を回避し、サンプルの大規模なセットで効率的なメモリ使用を可能にするために使用されます。さまざまな距離メトリックは、 &lt;code&gt;metric&lt;/code&gt; キーワードを介して提供できます。</target>
        </trans-unit>
        <trans-unit id="1a82be20d822213cd6b317bb5903a0613a76bafa" translate="yes" xml:space="preserve">
          <source>Species distribution modeling</source>
          <target state="translated">種の分布モデリング</target>
        </trans-unit>
        <trans-unit id="57d730dfe1585d0d57e966c58e133370714f1563" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. &lt;code&gt;set_params(parameter_name=new_value)&lt;/code&gt;. In addition, to setting the parameters of the stacking estimator, the individual estimator of the stacking estimators can also be set, or can be removed by setting them to &amp;lsquo;drop&amp;rsquo;.</source>
          <target state="translated">たとえば、 &lt;code&gt;set_params(parameter_name=new_value)&lt;/code&gt; を使用した特定のパラメーター。さらに、スタッキング推定器のパラメーターを設定するために、スタッキング推定器の個々の推定器を設定することも、「ドロップ」に設定することで削除することもできます。</target>
        </trans-unit>
        <trans-unit id="37195f9a92f1ed14e524a0ed92aab116b735c4ea" translate="yes" xml:space="preserve">
          <source>Specific parameters using e.g. set_params(parameter_name=new_value) In addition, to setting the parameters of the &lt;code&gt;VotingClassifier&lt;/code&gt;, the individual classifiers of the &lt;code&gt;VotingClassifier&lt;/code&gt; can also be set or replaced by setting them to None.</source>
          <target state="translated">パラメータを設定すること、また、例えばset_params（PARAMETER_NAME = NEW_VALUE）を使用して特定のパラメータ &lt;code&gt;VotingClassifier&lt;/code&gt; は、個々の分類器 &lt;code&gt;VotingClassifier&lt;/code&gt; にも設定又はなしにそれらを設定することによって置き換えることができます。</target>
        </trans-unit>
        <trans-unit id="94e374689a4595b916bcf5e66713548e054c55c6" translate="yes" xml:space="preserve">
          <source>Specific weights can be assigned to each classifier via the &lt;code&gt;weights&lt;/code&gt; parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.</source>
          <target state="translated">特定の重みは、 &lt;code&gt;weights&lt;/code&gt; パラメータを介して各分類子に割り当てることができます。重みが提供されると、各分類子の予測クラス確率が収集され、分類子の重みが乗算されて平均されます。次に、最終的なクラスラベルが、平均確率が最も高いクラスラベルから派生します。</target>
        </trans-unit>
        <trans-unit id="68354cd532978d44f7b8a2998caa562af7db6244" translate="yes" xml:space="preserve">
          <source>Specifically, here the input variables are some gene sequences stored as variable-length strings consisting of letters &amp;lsquo;A&amp;rsquo;, &amp;lsquo;T&amp;rsquo;, &amp;lsquo;C&amp;rsquo;, and &amp;lsquo;G&amp;rsquo;, while the output variables are floating point numbers and True/False labels in the regression and classification tasks, respectively.</source>
          <target state="translated">具体的には、ここでの入力変数は、文字「A」、「T」、「C」、および「G」で構成される可変長文字列として格納されたいくつかの遺伝子配列であり、出力変数は、浮動小数点数およびTrue / Falseラベルです。それぞれ、回帰タスクと分類タスク。</target>
        </trans-unit>
        <trans-unit id="40c186465110b1329791125cf6cae8eb6f471442" translate="yes" xml:space="preserve">
          <source>Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into a neural network or an unregularized regression.</source>
          <target state="translated">特徴ごとにカテゴリの1つを削除するために使用する方法を指定します。これは,ニューラルネットワークや非正規化回帰に結果のデータを投入する場合など,完全に直線的な特徴が問題となる場合に便利です.</target>
        </trans-unit>
        <trans-unit id="8fbbf3fe05797ad1e4c717c36a5a204246056853" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;ldquo;one_vs_rest&amp;rdquo; and &amp;ldquo;one_vs_one&amp;rdquo;. In &amp;ldquo;one_vs_rest&amp;rdquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;ldquo;one_vs_one&amp;rdquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates.</source>
          <target state="translated">マルチクラス分類問題の処理方法を指定します。サポートされているのは、「one_vs_rest」と「one_vs_one」です。 「one_vs_rest」では、クラスごとに1つのバイナリガウスプロセス分類器が適合され、このクラスを残りのクラスから分離するようにトレーニングされています。 「one_vs_one」では、これらの2つのクラスを分離するようにトレーニングされたクラスのペアごとに1つのバイナリガウスプロセス分類器が適合されます。これらのバイナリ予測子の予測は、マルチクラス予測に結合されます。 「one_vs_one」は確率推定の予測をサポートしていないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="e7bd9f102fbfd80a2ad8d309cf0a9504bc2caee0" translate="yes" xml:space="preserve">
          <source>Specifies how multi-class classification problems are handled. Supported are &amp;lsquo;one_vs_rest&amp;rsquo; and &amp;lsquo;one_vs_one&amp;rsquo;. In &amp;lsquo;one_vs_rest&amp;rsquo;, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In &amp;lsquo;one_vs_one&amp;rsquo;, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that &amp;lsquo;one_vs_one&amp;rsquo; does not support predicting probability estimates.</source>
          <target state="translated">マルチクラス分類問題の処理方法を指定します。サポートされているのは「one_vs_rest」と「one_vs_one」です。'one_vs_rest'では、クラスごとに1つのバイナリガウス過程分類器が適合され、このクラスを他のクラスから分離するようにトレーニングされています。'one_vs_one'では、クラスのペアごとに1つのバイナリガウス過程分類器が適合され、これら2つのクラスを分離するようにトレーニングされています。これらのバイナリ予測子の予測は、マルチクラス予測に結合されます。'one_vs_one'は確率推定の予測をサポートしていないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="9bddb5670bf596fd4f95945fb300823355f1c46f" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.</source>
          <target state="translated">定数(バイアスまたは切片)を決定関数に追加するかどうかを指定します。</target>
        </trans-unit>
        <trans-unit id="9cc5cb93f212cfc9a20617982597c3fd3b14a01a" translate="yes" xml:space="preserve">
          <source>Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor (X @ coef + intercept).</source>
          <target state="translated">定数(バイアスまたは切片)を線形予測変数(X @ coef+切片)に追加するかどうかを指定します。</target>
        </trans-unit>
        <trans-unit id="032e8ae2185962af612ef54804c68499bb10a9e0" translate="yes" xml:space="preserve">
          <source>Specifies if the estimated precision is stored.</source>
          <target state="translated">推定精度を格納するかどうかを指定します。</target>
        </trans-unit>
        <trans-unit id="d38faf7dee61c2f434029c24d24417f5a7a63648" translate="yes" xml:space="preserve">
          <source>Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.</source>
          <target state="translated">切片をモデルにはめ込むかどうかを指定します。fit()メソッドのパラメータと一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="21164bb750beb75acb9ae9d1f3fb116169b84f4e" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape &lt;code&gt;(n_samples, n_samples)&lt;/code&gt;.</source>
          <target state="translated">アルゴリズムで使用するカーネルタイプを指定します。「linear」、「poly」、「rbf」、「sigmoid」、「precomputed」、または呼び出し可能のいずれかでなければなりません。何も指定されていない場合は、「rbf」が使用されます。callableが与えられた場合、それはデータ行列からカーネル行列を事前計算するために使用されます。その行列は形状 &lt;code&gt;(n_samples, n_samples)&lt;/code&gt; 配列でなければなりません。</target>
        </trans-unit>
        <trans-unit id="7717364640e0a660ec81dfa33f675030f243fdf0" translate="yes" xml:space="preserve">
          <source>Specifies the kernel type to be used in the algorithm. It must be one of &amp;lsquo;linear&amp;rsquo;, &amp;lsquo;poly&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo;, &amp;lsquo;sigmoid&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo; or a callable. If none is given, &amp;lsquo;rbf&amp;rsquo; will be used. If a callable is given it is used to precompute the kernel matrix.</source>
          <target state="translated">アルゴリズムで使用するカーネルタイプを指定します。「linear」、「poly」、「rbf」、「sigmoid」、「precomputed」、または呼び出し可能のいずれかでなければなりません。何も指定されていない場合は、「rbf」が使用されます。callableが与えられた場合、それはカーネル行列を事前計算するために使用されます。</target>
        </trans-unit>
        <trans-unit id="b9435d1c3c2633287cc32557661450b6f00ca78e" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. &amp;lsquo;hinge&amp;rsquo; is the standard SVM loss (used e.g. by the SVC class) while &amp;lsquo;squared_hinge&amp;rsquo; is the square of the hinge loss.</source>
          <target state="translated">損失関数を指定します。'hinge'は標準のSVM損失（SVCクラスなどで使用）で、 'squared_hinge'はヒンジ損失の2乗です。</target>
        </trans-unit>
        <trans-unit id="68150facd38948e362a68f70eea508701955b6e7" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (&amp;lsquo;squared_epsilon_insensitive&amp;rsquo;) is the L2 loss.</source>
          <target state="translated">損失関数を指定します。イプシロン非依存損失（標準SVR）はL1損失であり、2乗イプシロン非依存損失（ 'squared_epsilon_insensitive'）はL2損失です。</target>
        </trans-unit>
        <trans-unit id="1b5fabde85275fd0a5eb3f705ddd6c262b6e1ace" translate="yes" xml:space="preserve">
          <source>Specifies the loss function. With &amp;lsquo;squared_hinge&amp;rsquo; it is the squared hinge loss (a.k.a. L2 loss). With &amp;lsquo;log&amp;rsquo; it is the loss of logistic regression models.</source>
          <target state="translated">損失関数を指定します。「squared_hinge」では、2乗ヒンジ損失（別名L2損失）です。「ログ」を使用すると、ロジスティック回帰モデルが失われます。</target>
        </trans-unit>
        <trans-unit id="82fe667ff963f19359a5dba7024bcea48fa12322" translate="yes" xml:space="preserve">
          <source>Specifies the norm used in the penalization. The &amp;lsquo;l2&amp;rsquo; penalty is the standard used in SVC. The &amp;lsquo;l1&amp;rsquo; leads to &lt;code&gt;coef_&lt;/code&gt; vectors that are sparse.</source>
          <target state="translated">ペナルティで使用される基準を指定します。「l2」ペナルティはSVCで使用される標準です。「l1」はスパースな &lt;code&gt;coef_&lt;/code&gt; ベクトルにつながります。</target>
        </trans-unit>
        <trans-unit id="5a337b6de37f25f0ac3016f29ff1f6486795a255" translate="yes" xml:space="preserve">
          <source>Specifies the returned model. Select &lt;code&gt;'lar'&lt;/code&gt; for Least Angle Regression, &lt;code&gt;'lasso'&lt;/code&gt; for the Lasso.</source>
          <target state="translated">返されるモデルを指定します。最小角度回帰には &lt;code&gt;'lar'&lt;/code&gt; を選択し、なげなわには &lt;code&gt;'lasso'&lt;/code&gt; を選択します。</target>
        </trans-unit>
        <trans-unit id="ef557ab8128f60634f92721dd7b48ce0309e1238" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. For regressors this parameter is ignored and the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. By default, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and we revert to &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; if it doesn&amp;rsquo;t exist. If &lt;code&gt;method&lt;/code&gt; is &amp;lsquo;recursion&amp;rsquo;, the response is always the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="translated">ターゲット応答として&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;または&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_functionの&lt;/a&gt;どちらを使用するかを指定します。説明変数の場合、このパラメータは無視され、応答は常にの出力である&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;予測します&lt;/a&gt;。デフォルトでは、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;が最初に試行され、存在しない場合は&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;に戻ります。場合 &lt;code&gt;method&lt;/code&gt; 「再帰」で、応答は常にの出力である&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4eb03b762d72883fa3052fd37abd9dd63a6ceb00" translate="yes" xml:space="preserve">
          <source>Specifies whether to use &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; or &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; as the target response. If set to &amp;lsquo;auto&amp;rsquo;, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; is tried first and if it does not exist &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt; is tried next.</source>
          <target state="translated">ターゲット応答として&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;または&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_functionの&lt;/a&gt;どちらを使用するかを指定します。'auto'に設定されている場合、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt;が最初に試行され、存在しない場合は、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;が次に試行されます。</target>
        </trans-unit>
        <trans-unit id="32ab0cdbec2fd77050a55d02bdf5982ebc80779f" translate="yes" xml:space="preserve">
          <source>Specify a download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">データセットのダウンロードおよびキャッシュフォルダーを指定します。Noneの場合、すべてのscikit-learnデータは「〜/ scikit_learn_data」サブフォルダーに保存されます。</target>
        </trans-unit>
        <trans-unit id="5a7f883c69415d4b4614ca7ec1c25ea069f17592" translate="yes" xml:space="preserve">
          <source>Specify an download and cache folder for the datasets. If None, all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">データセットのダウンロードおよびキャッシュフォルダーを指定します。Noneの場合、すべてのscikit-learnデータは「〜/ scikit_learn_data」サブフォルダーに保存されます。</target>
        </trans-unit>
        <trans-unit id="bef377c44b3d810cadc5cf65c208d01924bfa02c" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the data sets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">データセット用に別のダウンロードおよびキャッシュフォルダーを指定します。デフォルトでは、すべてのscikit-learnデータは「〜/ scikit_learn_data」サブフォルダーに保存されます。</target>
        </trans-unit>
        <trans-unit id="db707a2b2d7445205a990e044438fdad3fa08a72" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders.</source>
          <target state="translated">データセット用に別のダウンロードおよびキャッシュフォルダーを指定します。デフォルトでは、すべてのscikit-learnデータは「〜/ scikit_learn_data」サブフォルダーに保存されます。</target>
        </trans-unit>
        <trans-unit id="e0a4c5302feb0239f945ee7ba84757ae55a6d243" translate="yes" xml:space="preserve">
          <source>Specify another download and cache folder for the datasets. By default all scikit-learn data is stored in &amp;lsquo;~/scikit_learn_data&amp;rsquo; subfolders. .. versionadded:: 0.19</source>
          <target state="translated">データセット用に別のダウンロードおよびキャッシュフォルダーを指定します。デフォルトでは、すべてのscikit-learnデータは「〜/ scikit_learn_data」サブフォルダーに保存されます。.. versionadded :: 0.19</target>
        </trans-unit>
        <trans-unit id="3a104a4391c92d3464c7b1efaf07c449c778bcc9" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored</source>
          <target state="translated">推定精度が保存されているかどうかを指定する</target>
        </trans-unit>
        <trans-unit id="68d4702fc734cffadd8a1ccf005f0aff7fa648f2" translate="yes" xml:space="preserve">
          <source>Specify if the estimated precision is stored.</source>
          <target state="translated">推定精度が保存されているかどうかを指定します。</target>
        </trans-unit>
        <trans-unit id="4984f447cb8f4f521871d2431cae9f4220dfb519" translate="yes" xml:space="preserve">
          <source>Specify the column name in the data to use as target. If &amp;lsquo;default-target&amp;rsquo;, the standard target column a stored on the server is used. If &lt;code&gt;None&lt;/code&gt;, all columns are returned as data and the target is &lt;code&gt;None&lt;/code&gt;. If list (of strings), all columns with these names are returned as multi-target (Note: not all scikit-learn classifiers can handle all types of multi-output combinations)</source>
          <target state="translated">ターゲットとして使用するデータの列名を指定します。'default-target'の場合、サーバーに格納されている標準ターゲット列aが使用されます。 &lt;code&gt;None&lt;/code&gt; の場合、すべての列がデータとして返され、ターゲットは &lt;code&gt;None&lt;/code&gt; です。（文字列の）リストの場合、これらの名前を持つすべての列がマルチターゲットとして返されます（注：すべてのscikit-learn分類器がすべてのタイプのマルチ出力の組み合わせを処理できるわけではありません）</target>
        </trans-unit>
        <trans-unit id="86eb3ad2a989c13695b9d85dcb05b7c45343a61d" translate="yes" xml:space="preserve">
          <source>Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; The default is zero (i.e. machine precision) for both.</source>
          <target state="translated">結果の希望する相対および絶対許容誤差を指定します。真の結果がK_trueの場合、返される結果K_retは &lt;code&gt;abs(K_true - K_ret) &amp;lt; atol + rtol * K_ret&lt;/code&gt; ます。デフォルトは両方ともゼロ（つまり、マシン精度）です。</target>
        </trans-unit>
        <trans-unit id="0742682745f85d107eacd49ea30a7e49015c565b" translate="yes" xml:space="preserve">
          <source>Specify the leaf size of the underlying tree. See &lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt;&lt;code&gt;BallTree&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt;&lt;code&gt;KDTree&lt;/code&gt;&lt;/a&gt; for details. Default is 40.</source>
          <target state="translated">基になるツリーの葉のサイズを指定します。詳細については、&lt;a href=&quot;sklearn.neighbors.balltree#sklearn.neighbors.BallTree&quot;&gt; &lt;code&gt;BallTree&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;sklearn.neighbors.kdtree#sklearn.neighbors.KDTree&quot;&gt; &lt;code&gt;KDTree&lt;/code&gt; &lt;/a&gt;を参照してください。デフォルトは40です。</target>
        </trans-unit>
        <trans-unit id="a3eb34c47a1823aab704036791431543ed289a4a" translate="yes" xml:space="preserve">
          <source>Specify the parallelization backend implementation. Supported backends are:</source>
          <target state="translated">並列化バックエンドの実装を指定します。サポートされているバックエンドは以下の通りです。</target>
        </trans-unit>
        <trans-unit id="9ef7e5427d37487b864821803fe9613488fa8ce1" translate="yes" xml:space="preserve">
          <source>Specify the size of the kernel cache (in MB).</source>
          <target state="translated">カーネルキャッシュのサイズを指定します(MB単位)。</target>
        </trans-unit>
        <trans-unit id="4329e4ac0b424da2818ac12cc4d13ce3581c4d3d" translate="yes" xml:space="preserve">
          <source>Specify what features are treated as categorical.</source>
          <target state="translated">どのような機能をカテゴリとして扱うかを指定します。</target>
        </trans-unit>
        <trans-unit id="7d724db10f986282e8a5446f219cdacdbcddece6" translate="yes" xml:space="preserve">
          <source>Specify whether all or any of the given attributes must exist.</source>
          <target state="translated">与えられた属性のすべてまたはいずれかが存在しなければならないかどうかを指定します。</target>
        </trans-unit>
        <trans-unit id="d079850de1341ae0792b165a2e4c64406a6bf6cd" translate="yes" xml:space="preserve">
          <source>Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the &lt;code&gt;n_iter&lt;/code&gt; parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:</source>
          <target state="translated">パラメータのサンプリング方法の指定は、ディクショナリを使用して行われます。これは、&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; の&lt;/a&gt;パラメータの指定と非常に似ています。さらに、 &lt;code&gt;n_iter&lt;/code&gt; パラメーターを使用して、サンプリングされた候補またはサンプリングの反復数である計算量を指定します。パラメータごとに、可能な値の分布または離散的な選択肢のリスト（均一にサンプリングされます）を指定できます。</target>
        </trans-unit>
        <trans-unit id="848f2bc6fd9feea5a4bd159161ff60b7b7f1ad05" translate="yes" xml:space="preserve">
          <source>Specifying the dataset by the name &amp;ldquo;iris&amp;rdquo; yields the lowest version, version 1, with the &lt;code&gt;data_id&lt;/code&gt; 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset &lt;code&gt;data_id&lt;/code&gt;. The other dataset, with &lt;code&gt;data_id&lt;/code&gt; 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data:</source>
          <target state="translated">「iris」という名前でデータセットを指定すると、 &lt;code&gt;data_id&lt;/code&gt; 61 の最も低いバージョン、バージョン1が生成されます。この正確なデータセットを常に取得するには、データセット &lt;code&gt;data_id&lt;/code&gt; で指定するのが最も安全です。 &lt;code&gt;data_id&lt;/code&gt; 969を持つもう1つのデータセットはバージョン3（バージョン2は非アクティブになっています）であり、データの2値化バージョンが含まれています。</target>
        </trans-unit>
        <trans-unit id="a7781532fac864d69f63a26a8d414fddcb049d3b" translate="yes" xml:space="preserve">
          <source>Specifying the value of the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt; attribute will trigger the use of cross-validation with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt;, for example &lt;code&gt;cv=10&lt;/code&gt; for 10-fold cross-validation, rather than Generalized Cross-Validation.</source>
          <target state="translated">&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-cv&quot;&gt;cv&lt;/a&gt;属性の値を指定すると、&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;との相互検証の使用がトリガーされます。たとえば、一般化された相互検証ではなく、10回の相互検証の場合は &lt;code&gt;cv=10&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="3df7d54bd992cb63f5a75a6f7de49938e89cdde2" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to cluster graphs by their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt;:</source>
          <target state="translated">スペクトルクラスタリングは、スペクトルの埋め込みによってグラフをクラスタリングするためにも使用できます。この場合、親和性マトリックスはグラフの隣接行列であり、SpectralClusteringは &lt;code&gt;affinity=&amp;rsquo;precomputed&amp;rsquo;&lt;/code&gt; 初期化されます。</target>
        </trans-unit>
        <trans-unit id="e698832cd5821ea0f1db5828f5b72aad63c46c00" translate="yes" xml:space="preserve">
          <source>Spectral Clustering can also be used to partition graphs via their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with &lt;code&gt;affinity='precomputed'&lt;/code&gt;:</source>
          <target state="translated">スペクトルクラスタリングを使用して、スペクトル埋め込みを介してグラフを分割することもできます。この場合、アフィニティ行列はグラフの隣接行列であり、SpectralClusteringは &lt;code&gt;affinity='precomputed'&lt;/code&gt; で初期化されます。</target>
        </trans-unit>
        <trans-unit id="943c880ba7aef37194c447e5760436985518b340" translate="yes" xml:space="preserve">
          <source>Spectral Co-Clustering algorithm (Dhillon, 2001).</source>
          <target state="translated">スペクトルコクラスタリングアルゴリズム(Dhillon,2001)。</target>
        </trans-unit>
        <trans-unit id="5c8a907562e6db42ff15e9df5a0d9b0b21be7b5f" translate="yes" xml:space="preserve">
          <source>Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.</source>
          <target state="translated">スペクトル埋め込み(ラプラシアン固有マップ)は、グラフが1つの連結成分を持つ場合に最も有用です。グラフに多くの成分がある場合、最初の数個の固有ベクトルはグラフの連結成分を明らかにするだけです。</target>
        </trans-unit>
        <trans-unit id="7ff62a97384e4faf388cb99bbcc076cbdae4a5ec" translate="yes" xml:space="preserve">
          <source>Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function &lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt;&lt;code&gt;spectral_embedding&lt;/code&gt;&lt;/a&gt; or its object-oriented counterpart &lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt;&lt;code&gt;SpectralEmbedding&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">スペクトル埋め込みは、非線形埋め込みを計算するアプローチです。 Scikit-learnはラプラシアン固有マップを実装します。これは、グラフラプラシアンのスペクトル分解を使用してデータの低次元表現を見つけます。生成されたグラフは、高次元空間における低次元多様体の離散近似と見なすことができます。グラフに基づくコスト関数の最小化により、マニホールド上の互いに近い点が低次元空間で互いに近くにマッピングされ、ローカル距離が維持されます。スペクトルの埋め込みは、関数&lt;a href=&quot;generated/sklearn.manifold.spectral_embedding#sklearn.manifold.spectral_embedding&quot;&gt; &lt;code&gt;spectral_embedding&lt;/code&gt; &lt;/a&gt;またはそのオブジェクト指向の対応物&lt;a href=&quot;generated/sklearn.manifold.spectralembedding#sklearn.manifold.SpectralEmbedding&quot;&gt; &lt;code&gt;SpectralEmbedding&lt;/code&gt; を使用&lt;/a&gt;して実行できます。</target>
        </trans-unit>
        <trans-unit id="3266962963ccf3ff289e43e7853a5feea31fa6fe" translate="yes" xml:space="preserve">
          <source>Spectral biclustering (Kluger, 2003).</source>
          <target state="translated">スペクトルバイクラスタリング(Kluger,2003)。</target>
        </trans-unit>
        <trans-unit id="83334448105603952db5b041593dddc0f02ac19b" translate="yes" xml:space="preserve">
          <source>Spectral biclustering algorithms.</source>
          <target state="translated">スペクトルバイクラスタリングアルゴリズム。</target>
        </trans-unit>
        <trans-unit id="3fddf3521d69d12bc13710d54a4adc12aa85f512" translate="yes" xml:space="preserve">
          <source>Spectral clustering</source>
          <target state="translated">スペクトルクラスタリング</target>
        </trans-unit>
        <trans-unit id="453e3a7c69660270eecfb13dabf16149c8b4512b" translate="yes" xml:space="preserve">
          <source>Spectral clustering for image segmentation</source>
          <target state="translated">画像セグメンテーションのためのスペクトルクラスタリング</target>
        </trans-unit>
        <trans-unit id="f9409615dd1103c73760717b8600df9e2157d615" translate="yes" xml:space="preserve">
          <source>Spectral embedding for non-linear dimensionality reduction.</source>
          <target state="translated">非線形次元削減のためのスペクトル埋め込み。</target>
        </trans-unit>
        <trans-unit id="8a0801a4fb2ecc40bcf6f04aa745ad2e1056e690" translate="yes" xml:space="preserve">
          <source>Spectral embedding of the training matrix.</source>
          <target state="translated">訓練行列のスペクトル埋め込み.</target>
        </trans-unit>
        <trans-unit id="2d2cb022bc3d26bd1407c4aa787d5e46e1ad4c3b" translate="yes" xml:space="preserve">
          <source>Speed</source>
          <target state="translated">Speed</target>
        </trans-unit>
        <trans-unit id="063a83567f47ad5f5679accf564d96c923566ee9" translate="yes" xml:space="preserve">
          <source>Speed:</source>
          <target state="translated">Speed:</target>
        </trans-unit>
        <trans-unit id="7d07f6cca3dbed6cdb804f0e2864e093c6647564" translate="yes" xml:space="preserve">
          <source>Split arrays or matrices into random train and test subsets</source>
          <target state="translated">配列や行列をランダムな訓練サブセットとテストサブセットに分割する</target>
        </trans-unit>
        <trans-unit id="5e854ececac820d9fb56cdde854f788365393cf5" translate="yes" xml:space="preserve">
          <source>Splits it into K folds, trains on K-1 and then tests on the left-out.</source>
          <target state="translated">Kフォールドにスプリットし、K-1でトレーニングし、レフトアウトでテスト。</target>
        </trans-unit>
        <trans-unit id="c2518ac986a45f6943dccb55ec28e7fc9787e8f9" translate="yes" xml:space="preserve">
          <source>Splitter Classes</source>
          <target state="translated">スプリッタクラス</target>
        </trans-unit>
        <trans-unit id="474933f1a999ce205b180d93539f6dbb5b05050e" translate="yes" xml:space="preserve">
          <source>Splitter Functions</source>
          <target state="translated">スプリッタ機能</target>
        </trans-unit>
        <trans-unit id="01474e72e0404f40fd189e5ac7233925222e580d" translate="yes" xml:space="preserve">
          <source>Squared L2 norms of the lines of y. Required if tol is not None.</source>
          <target state="translated">tolがNoneでない場合は必須です。</target>
        </trans-unit>
        <trans-unit id="89cdcd77a950e009dab4164bc976d2f6ebb6b9e7" translate="yes" xml:space="preserve">
          <source>Squared Mahalanobis distances of the observations.</source>
          <target state="translated">オブザベーションのマハラノビス距離の2乗。</target>
        </trans-unit>
        <trans-unit id="a0b13f625123904866bd60e38bc7611ba95c992c" translate="yes" xml:space="preserve">
          <source>Squared Sum - Sum of the squared L2 norm of all samples.</source>
          <target state="translated">Squared Sum-すべての標本のL2ノルムの2乗の和.</target>
        </trans-unit>
        <trans-unit id="1c1f19010d2ef30728a1e3cec08abc7bd4b0d974" translate="yes" xml:space="preserve">
          <source>Squared norm of the centroids.</source>
          <target state="translated">セントロイドのノルムの2乗。</target>
        </trans-unit>
        <trans-unit id="ff4530f7332d92145f70c600e76bef65d08e2445" translate="yes" xml:space="preserve">
          <source>Stability path based on randomized Lasso estimates</source>
          <target state="translated">ランダム化されたラッソ推定値に基づく安定性パス</target>
        </trans-unit>
        <trans-unit id="9a5fecba5d8d30ecb602724233c6166d767b3036" translate="yes" xml:space="preserve">
          <source>Stability selection Nicolai Meinshausen, Peter Buhlmann Journal of the Royal Statistical Society: Series B Volume 72, Issue 4, pages 417-473, September 2010 DOI: 10.1111/j.1467-9868.2010.00740.x</source>
          <target state="translated">安定性選択 Nicolai Meinshausen,Peter Buhlmann 英国統計学会誌。シリーズ B 第 72 巻第 4 号、417-473 ページ、2010 年 9 月 DOI:10.1111/j.1467-9868.2010.00740.x</target>
        </trans-unit>
        <trans-unit id="24ab98f7d3b4687c560036182f11b4e7733b1d68" translate="yes" xml:space="preserve">
          <source>Stack Exchange</source>
          <target state="translated">スタック交換</target>
        </trans-unit>
        <trans-unit id="71b2c903e12bff4f98c474e759faf1146ab6ad92" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final classifier.</source>
          <target state="translated">最終的な分類器を持つ推定器のスタック。</target>
        </trans-unit>
        <trans-unit id="8433d8b247979d86acd74f4143c89bb21831f7b9" translate="yes" xml:space="preserve">
          <source>Stack of estimators with a final regressor.</source>
          <target state="translated">最終的な回帰子を持つ推定子のスタック。</target>
        </trans-unit>
        <trans-unit id="a568e00cb92ef139342d099c3bf8234421058e98" translate="yes" xml:space="preserve">
          <source>Stack of predictors on a single data set</source>
          <target state="translated">1つのデータセット上の予測変数のスタック</target>
        </trans-unit>
        <trans-unit id="8781e517c304621291a3255c93ced28430f5c0bd" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="translated">スタッキング汎化は、個々の推定器の出力を積み重ね、分類器を用いて最終的な予測値を計算することで構成される。スタッキングすることで、各推定量の出力を最終推定量の入力として用いることで、各推定量の強さを利用することができる。</target>
        </trans-unit>
        <trans-unit id="0f5f44a8c7d7cd4102991a0e07afa77f83e823da" translate="yes" xml:space="preserve">
          <source>Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</source>
          <target state="translated">スタック一般化は、個々の推定量の出力をスタックし、レグレッサーを使用して最終予測を計算することで構成される。スタッキングすることで、各推定量の出力を最終推定量の入力として使用することで、各推定量の強さを利用することができる。</target>
        </trans-unit>
        <trans-unit id="8d83774fb1981a771cc887192522bcd1ee8713fc" translate="yes" xml:space="preserve">
          <source>Stacked generalization is a method for combining estimators to reduce their biases &lt;a href=&quot;#w1992&quot; id=&quot;id32&quot;&gt;[W1992]&lt;/a&gt;&lt;a href=&quot;#htf&quot; id=&quot;id33&quot;&gt;[HTF]&lt;/a&gt;. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.</source>
          <target state="translated">スタック一般化は、推定量を組み合わせてバイアスを減らす方法です&lt;a href=&quot;#w1992&quot; id=&quot;id32&quot;&gt;[W1992] &lt;/a&gt;&lt;a href=&quot;#htf&quot; id=&quot;id33&quot;&gt;[HTF]&lt;/a&gt;。より正確には、個々の推定量の予測は一緒に積み重ねられ、予測を計算するための最終的な推定量への入力として使用されます。この最終的な推定量は、交差検定を通じてトレーニングされます。</target>
        </trans-unit>
        <trans-unit id="93dcc7ee10b4f7f50030c1b93ea7e60ca7979cd4" translate="yes" xml:space="preserve">
          <source>Stacking Classifier and Regressor</source>
          <target state="translated">スタッキングクラシファイアとリグレッサ</target>
        </trans-unit>
        <trans-unit id="a37a65ea2247a4c331699e362c23755d1370e615" translate="yes" xml:space="preserve">
          <source>Stacking refers to a method to blend estimators. In this strategy, some estimators are individually fitted on some training data while a final estimator is trained using the stacked predictions of these base estimators.</source>
          <target state="translated">スタッキングとは、推定量をブレンドする方法のことである。この手法では、いくつかの推定量がいくつかの訓練データに個別に適合し、最終推定量はこれらのベース推定量のスタックされた予測値を使用して訓練される。</target>
        </trans-unit>
        <trans-unit id="891f1b1c9f204fa14cf72f5b45193c02a0d262be" translate="yes" xml:space="preserve">
          <source>Standard deviation of Gaussian noise added to the data.</source>
          <target state="translated">データに加えたガウスノイズの標準偏差。</target>
        </trans-unit>
        <trans-unit id="a17025349c0cc77d7292705f3e0aace21538f53e" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when &lt;code&gt;return_std&lt;/code&gt; is True.</source>
          <target state="translated">クエリポイントでの予測分布の標準偏差。 &lt;code&gt;return_std&lt;/code&gt; がTrueの場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="f806d5207c92015615b11e0738f918dc0548c864" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution at query points. Only returned when return_std is True.</source>
          <target state="translated">クエリ点における予測分布の標準偏差。return_stdがTrueの場合のみ返されます。</target>
        </trans-unit>
        <trans-unit id="6edd185d8d7cdfc859bd82ca69e1fcc7af90edcd" translate="yes" xml:space="preserve">
          <source>Standard deviation of predictive distribution of query points.</source>
          <target state="translated">クエリ点の予測分布の標準偏差。</target>
        </trans-unit>
        <trans-unit id="c37a2551fc59b4216e7ebb6941b4c543d13c64ce" translate="yes" xml:space="preserve">
          <source>Standard deviation over &lt;code&gt;n_repeats&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;n_repeats&lt;/code&gt; の標準偏差。</target>
        </trans-unit>
        <trans-unit id="ea11cb9dbd7c4fc006fb08938b76124b12688d69" translate="yes" xml:space="preserve">
          <source>StandardScaler</source>
          <target state="translated">StandardScaler</target>
        </trans-unit>
        <trans-unit id="9f96721b99a0217af973cbedbcbf7d1fa7440aeb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results.</source>
          <target state="translated">データセットの標準化は、多くの機械学習推定器にとって共通の要件である。通常、これは平均を除去し、単位分散にスケーリングすることで行われます。しかし、外れ値はしばしばサンプルの平均/分散に負の影響を与えることがある。このような場合、中央値や分位間範囲の方がより良い結果が得られることが多い。</target>
        </trans-unit>
        <trans-unit id="3845481860a037ebc5c39c64e8de0e95fe45e3fb" translate="yes" xml:space="preserve">
          <source>Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).</source>
          <target state="translated">データセットの標準化は、多くの機械学習推定量の共通要件である:個々の特徴が多かれ少なかれ標準的な正規分布データのように見えない場合(例えば、平均値が0で単位分散が0のガウス分布)、これらの推定量の動作が悪くなる可能性がある。</target>
        </trans-unit>
        <trans-unit id="781aef30981524e4bc3b3ab4682d7e1b6f686dcb" translate="yes" xml:space="preserve">
          <source>Standardize a dataset along any axis</source>
          <target state="translated">任意の軸に沿ってデータセットを標準化</target>
        </trans-unit>
        <trans-unit id="8089cb9b9abb90199844c7f8d2ad6ef5ad6b9827" translate="yes" xml:space="preserve">
          <source>Standardize features by removing the mean and scaling to unit variance</source>
          <target state="translated">平均値を除去し、単位分散にスケーリングすることで特徴を標準化する</target>
        </trans-unit>
        <trans-unit id="070fc0ca4dc6d3cb17aee36f0432a76e85e66a77" translate="yes" xml:space="preserve">
          <source>Start pointer to all the leaves.</source>
          <target state="translated">すべての葉へのポインタを開始します。</target>
        </trans-unit>
        <trans-unit id="08a6668f9a564bddd6d8fa9fd4934eeea4b017c7" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">SMACOFアルゴリズムを初期化するためのエンベッディングの開始設定。デフォルトでは、アルゴリズムはランダムに選択された配列で初期化されます。</target>
        </trans-unit>
        <trans-unit id="7252947fdd6406b9475a3bf1b686e53848838289" translate="yes" xml:space="preserve">
          <source>Starting configuration of the embedding to initialize the algorithm. By default, the algorithm is initialized with a randomly chosen array.</source>
          <target state="translated">アルゴリズムを初期化するためのエンベッディングの開始設定。デフォルトでは、アルゴリズムはランダムに選ばれた配列で初期化されます。</target>
        </trans-unit>
        <trans-unit id="08977c4568e04a737e6b3a87f7b6021573de1b1c" translate="yes" xml:space="preserve">
          <source>Starting from &lt;code&gt;joblib &amp;gt;= 0.14&lt;/code&gt;, when the &lt;code&gt;loky&lt;/code&gt; backend is used (which is the default), joblib will tell its child &lt;strong&gt;processes&lt;/strong&gt; to limit the number of threads they can use, so as to avoid oversubscription. In practice the heuristic that joblib uses is to tell the processes to use &lt;code&gt;max_threads
= n_cpus // n_jobs&lt;/code&gt;, via their corresponding environment variable. Back to our example from above, since the joblib backend of &lt;code&gt;GridSearchCV&lt;/code&gt; is &lt;code&gt;loky&lt;/code&gt;, each process will only be able to use 1 thread instead of 8, thus mitigating the oversubscription issue.</source>
          <target state="translated">&lt;code&gt;joblib &amp;gt;= 0.14&lt;/code&gt; から開始して、 &lt;code&gt;loky&lt;/code&gt; バックエンドが使用されると（これがデフォルトです）、joblibは子&lt;strong&gt;プロセス&lt;/strong&gt;に、オーバーサブスクリプションを回避するために使用できるスレッドの数を制限するように指示します。実際には、joblibが使用するヒューリスティックは、対応する環境変数を介して、 &lt;code&gt;max_threads = n_cpus // n_jobs&lt;/code&gt; を使用するようにプロセスに指示することです。上記の例に戻ると、GridSearchCVのjoblibバックエンドは &lt;code&gt;GridSearchCV&lt;/code&gt; ある &lt;code&gt;loky&lt;/code&gt; 、各プロセスは8ではなく1つのスレッドしか使用できず、オーバーサブスクリプションの問題が軽減されます。</target>
        </trans-unit>
        <trans-unit id="91cd41feb47c4fc7679dfd69c834b11820027a8b" translate="yes" xml:space="preserve">
          <source>Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.</source>
          <target state="translated">多層パーセプトロン(MLP)は初期のランダムな重みから始まり、これらの重みを繰り返し更新することで損失関数を最小化します。損失を計算した後、出力層から前の層へと損失を伝搬し、各重みパラメータに損失を減少させるための更新値を与えます。</target>
        </trans-unit>
        <trans-unit id="fcf350fa97b4ef940922ec2e36ae5accc928bb98" translate="yes" xml:space="preserve">
          <source>Starting node for path</source>
          <target state="translated">パスの開始ノード</target>
        </trans-unit>
        <trans-unit id="bed5865b6136905da0496b8ae96a4873f78bef72" translate="yes" xml:space="preserve">
          <source>Stat Ass, 79:871, 1984.</source>
          <target state="translated">Stat Ass,79:871,1984.</target>
        </trans-unit>
        <trans-unit id="6493ce2cca639b99501821839727266114fab06b" translate="yes" xml:space="preserve">
          <source>Statistical learning</source>
          <target state="translated">統計的学習</target>
        </trans-unit>
        <trans-unit id="ff430697ec62291221833385a34a445a9ee9ecdf" translate="yes" xml:space="preserve">
          <source>Statistical learning: the setting and the estimator object in scikit-learn</source>
          <target state="translated">統計的学習:scikit-learnにおける設定と推定オブジェクト</target>
        </trans-unit>
        <trans-unit id="904a41f7fbe4f76d9e16b8a6416dab74831246a2" translate="yes" xml:space="preserve">
          <source>Stef van Buuren, Karin Groothuis-Oudshoorn (2011). &amp;ldquo;mice: Multivariate Imputation by Chained Equations in R&amp;rdquo;. Journal of Statistical Software 45: 1-67.</source>
          <target state="translated">Stef van Buuren、Karin Groothuis-Oudshoorn（2011）。「マウス：Rの連鎖方程式による多変量代入」。Journal of Statistics Software 45：1-67。</target>
        </trans-unit>
        <trans-unit id="a673f9d4e8314126b08e8f81bb3a33f3d78b1e09" translate="yes" xml:space="preserve">
          <source>Still effective in cases where number of dimensions is greater than the number of samples.</source>
          <target state="translated">寸法数がサンプル数より多い場合でも有効です。</target>
        </trans-unit>
        <trans-unit id="2473d40abe8e9fb2e7f524b8bad4d74240273fa9" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent</source>
          <target state="translated">確率勾配降下</target>
        </trans-unit>
        <trans-unit id="195b32448a080f6c15b39de98057b7fe1bc4693b" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is an optimization technique which minimizes a loss function in a stochastic fashion, performing a gradient descent step sample by sample. In particular, it is a very efficient method to fit linear models.</source>
          <target state="translated">確率的勾配降下法は、サンプルごとに勾配降下を行い、確率的に損失関数を最小化する最適化手法です。特に、線形モデルを適合させるのに非常に効率的な手法です。</target>
        </trans-unit>
        <trans-unit id="e3aa3ce34d4d1d755f86485089b5a4b4f435a8e2" translate="yes" xml:space="preserve">
          <source>Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be easily done using &lt;code&gt;StandardScaler&lt;/code&gt;:</source>
          <target state="translated">確率的勾配降下法は特徴のスケーリングの影響を受けやすいため、データをスケーリングすることを強くお勧めします。たとえば、入力ベクトルXの各属性を[0,1]または[-1、+ 1]にスケーリングするか、平均0と分散1になるように標準化します。テストベクトルに&lt;em&gt;同じ&lt;/em&gt;スケーリングを適用して、意味のある結果を得る。これは、 &lt;code&gt;StandardScaler&lt;/code&gt; を使用して簡単に実行できます。</target>
        </trans-unit>
        <trans-unit id="ee01e77469d8f50feb7b1b4735d433d85aa0d812" translate="yes" xml:space="preserve">
          <source>Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute &lt;code&gt;oob_improvement_&lt;/code&gt;. &lt;code&gt;oob_improvement_[i]&lt;/code&gt; holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.</source>
          <target state="translated">確率的勾配ブースティングでは、ブートストラップサンプルに含まれていない例（つまり、out-of-bagの例）の逸脱の改善を計算することにより、テストの逸脱のout-of-bag推定を計算できます。改善は &lt;code&gt;oob_improvement_&lt;/code&gt; 属性に格納されます。 &lt;code&gt;oob_improvement_[i]&lt;/code&gt; は、現在の予測にi番目のステージを追加した場合のOOBサンプルの損失に関する改善を保持します。 Out-of-bagの推定値は、モデルの選択に使用できます。たとえば、最適な反復回数を決定できます。 OOBの見積もりは通常非常に悲観的であるため、代わりに相互検証を使用し、相互検証に時間がかかりすぎる場合にのみOOBを使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="5823a3f0a9a6ed167c583e77307156305a3e83ac" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The &lt;code&gt;partial_fit&lt;/code&gt; method allows online/out-of-core learning.</source>
          <target state="translated">確率的勾配降下法は、線形モデルに適合させるためのシンプルでありながら非常に効率的なアプローチです。これは、サンプルの数（および特徴の数）が非常に多い場合に特に役立ちます。 &lt;code&gt;partial_fit&lt;/code&gt; の方法は、オンライン/アウトオブコア学習することができます。</target>
        </trans-unit>
        <trans-unit id="88c2b7432b4c70aedd301d6441f9f686fac99afd" translate="yes" xml:space="preserve">
          <source>Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.</source>
          <target state="translated">確率的勾配降下法は、制約のない最適化問題のための最適化手法である。(バッチ)勾配降下法とは対照的に、SGD は、一度に一つの訓練例を考慮することで、真の勾配を近似します。</target>
        </trans-unit>
        <trans-unit id="3bc9b5e942f6c3298a3799e63fea9d4e51700363" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">n_clustersで木の構築を早期に停止します。これは,特徴量の数に比べてクラスタの数が少なくない場合に,計算時間を短縮するのに役立ちます.このオプションは,接続性行列を指定する場合にのみ有用です.また,クラスタ数を変化させたり,キャッシングを利用したりする場合には,完全な木を計算する方が有利な場合があることに注意してください.</target>
        </trans-unit>
        <trans-unit id="27fa813a99ee0ee872f0a0fdd316cf176619503c" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">n_clustersでツリーの構築を早期に停止します。これは、クラスターの数が特徴の数と比較して少なくない場合に、計算時間を短縮するのに役立ちます。このオプションは、接続マトリックスを指定する場合にのみ役立ちます。また、クラスターの数を変更してキャッシュを使用する場合は、ツリー全体を計算すると有利な場合があることにも注意してください。 &lt;code&gt;distance_threshold&lt;/code&gt; が &lt;code&gt;None&lt;/code&gt; でない場合は、 &lt;code&gt;True&lt;/code&gt; である必要があります。デフォルトでは、 &lt;code&gt;compute_full_tree&lt;/code&gt; は「auto」です。これは、 &lt;code&gt;distance_threshold&lt;/code&gt; が &lt;code&gt;None&lt;/code&gt; でない場合、または &lt;code&gt;n_clusters&lt;/code&gt; が &lt;code&gt;0.02 * n_samples&lt;/code&gt; 最大値よりも小さい場合に &lt;code&gt;True&lt;/code&gt; と同等です。。それ以外の場合、「auto」は &lt;code&gt;False&lt;/code&gt; と同等です。</target>
        </trans-unit>
        <trans-unit id="3dc26590d142d1e5e73aaec1d67524322b86dfd8" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. In this case, the complete tree is not computed, thus the &amp;lsquo;children&amp;rsquo; output is of limited use, and the &amp;lsquo;parents&amp;rsquo; output should rather be used. This option is valid only when specifying a connectivity matrix.</source>
          <target state="translated">n_clustersでツリーの構築を早期に停止します。これは、サンプル数と比較してクラスター数が少なくない場合に、計算時間を短縮するのに役立ちます。この場合、完全なツリーは計算されないため、「children」出力の使用は制限されており、「parents」出力を使用する必要があります。このオプションは、接続マトリックスを指定する場合にのみ有効です。</target>
        </trans-unit>
        <trans-unit id="44e9e4435e20e453549059a3ee4002b032ad438a" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree.</source>
          <target state="translated">n_clustersで木の構築を早期に停止します。これは,クラスタ数がサンプル数に比べて少なくない場合に,計算時間を短縮するのに役立ちます.このオプションは,接続性行列を指定する場合にのみ有用です.また,クラスタ数を変化させたり,キャッシングを利用したりする場合には,完全な木を計算した方が有利な場合があることに注意してください.</target>
        </trans-unit>
        <trans-unit id="cec77383bf3b11f332bd0e653f87f2dc409b1dee" translate="yes" xml:space="preserve">
          <source>Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt;. By default &lt;code&gt;compute_full_tree&lt;/code&gt; is &amp;ldquo;auto&amp;rdquo;, which is equivalent to &lt;code&gt;True&lt;/code&gt; when &lt;code&gt;distance_threshold&lt;/code&gt; is not &lt;code&gt;None&lt;/code&gt; or that &lt;code&gt;n_clusters&lt;/code&gt; is inferior to the maximum between 100 or &lt;code&gt;0.02 * n_samples&lt;/code&gt;. Otherwise, &amp;ldquo;auto&amp;rdquo; is equivalent to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">n_clustersでツリーの構築を早期に停止します。これは、クラスターの数がサンプルの数と比較して少なくない場合に、計算時間を短縮するのに役立ちます。このオプションは、接続マトリックスを指定する場合にのみ役立ちます。また、クラスターの数を変更してキャッシュを使用する場合は、ツリー全体を計算すると有利な場合があることにも注意してください。 &lt;code&gt;distance_threshold&lt;/code&gt; が &lt;code&gt;None&lt;/code&gt; でない場合は、 &lt;code&gt;True&lt;/code&gt; である必要があります。デフォルトでは、 &lt;code&gt;compute_full_tree&lt;/code&gt; は「auto」です。これは、 &lt;code&gt;distance_threshold&lt;/code&gt; が &lt;code&gt;None&lt;/code&gt; でない場合、または &lt;code&gt;n_clusters&lt;/code&gt; が &lt;code&gt;0.02 * n_samples&lt;/code&gt; 最大値よりも小さい場合に &lt;code&gt;True&lt;/code&gt; と同等です。。それ以外の場合、「auto」は &lt;code&gt;False&lt;/code&gt; と同等です。</target>
        </trans-unit>
        <trans-unit id="84a6e50b1119dc5648f3c425a6b5dee68899e309" translate="yes" xml:space="preserve">
          <source>Stop iteration if at least this number of inliers are found.</source>
          <target state="translated">少なくともこれだけの数のインライアが見つかった場合は、反復処理を停止します。</target>
        </trans-unit>
        <trans-unit id="538193aed5fb2f898d909880cd3e81469e15df67" translate="yes" xml:space="preserve">
          <source>Stop iteration if score is greater equal than this threshold.</source>
          <target state="translated">スコアがこのしきい値より大きい場合は、反復処理を停止します。</target>
        </trans-unit>
        <trans-unit id="12517d0c8ade549d252ae4e535d57433e9861479" translate="yes" xml:space="preserve">
          <source>Stop solver after this many iterations regardless of accuracy (XXX Currently there is no API to know whether this kicked in.) -1 by default.</source>
          <target state="translated">精度に関係なく、これだけの繰り返しを行った後にソルバーを停止する (XXX 現在、この処理が行われたかどうかを知るためのAPIは存在しない)デフォルトでは-1。</target>
        </trans-unit>
        <trans-unit id="356700453d0a0d54f3f7d4b7b513913c4b6ecef8" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged.</source>
          <target state="translated">wが収束した場合は、アルゴリズムを停止します。</target>
        </trans-unit>
        <trans-unit id="df6a1587df9722b5b493e30cfc313089ab29220d" translate="yes" xml:space="preserve">
          <source>Stop the algorithm if w has converged. Default is 1.e-3.</source>
          <target state="translated">w が収束した場合にアルゴリズムを停止します。デフォルトは1.e-3です。</target>
        </trans-unit>
        <trans-unit id="7cf46a1e9b2d853c73253eb4c96cbe1ea1bb5aa6" translate="yes" xml:space="preserve">
          <source>Stop words are words like &amp;ldquo;and&amp;rdquo;, &amp;ldquo;the&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as signal for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.</source>
          <target state="translated">ストップワードとは、「and」、「the」、「him」のような単語であり、テキストの内容を表すのに情報がないと推定され、予測のためのシグナルとして解釈されないように削除される場合があります。ただし、似たような単語は、書き方や性格の分類など、予測に役立つことがあります。</target>
        </trans-unit>
        <trans-unit id="7eb24af52d1aa9e6b8d6715fd2fd646422f9b535" translate="yes" xml:space="preserve">
          <source>Stopping criteria.</source>
          <target state="translated">停止基準。</target>
        </trans-unit>
        <trans-unit id="2eda661dab2cf19600424ed9df7c9d0563861dff" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when &lt;code&gt;eigen_solver='arpack'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;eigen_solver='arpack'&lt;/code&gt; の場合の、ラプラシアン行列の固有分解の停止基準。</target>
        </trans-unit>
        <trans-unit id="51b3a0bb0b4d84ebe8a65cc9b8c0c2b3279fba93" translate="yes" xml:space="preserve">
          <source>Stopping criterion for eigendecomposition of the Laplacian matrix when using arpack eigen_solver.</source>
          <target state="translated">arpack eigen_solverを使用した場合のラプラシアン行列の eigendecompositionの停止基準.</target>
        </trans-unit>
        <trans-unit id="a798cb65fb942fe2386149a92d6481d384d3e392" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the lbfgs solver, the iteration will stop when &lt;code&gt;max{|g_j|, j = 1, ..., d} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_j&lt;/code&gt; is the j-th component of the gradient (derivative) of the objective function.</source>
          <target state="translated">停止基準。lbfgsソルバーの場合、 &lt;code&gt;max{|g_j|, j = 1, ..., d} &amp;lt;= tol&lt;/code&gt; ときに反復が停止します。ここで、 &lt;code&gt;g_j&lt;/code&gt; は目的関数の勾配（導関数）のj番目の成分です。</target>
        </trans-unit>
        <trans-unit id="68414daf9a6e27622678aff82460baea3a51326c" translate="yes" xml:space="preserve">
          <source>Stopping criterion. For the newton-cg and lbfgs solvers, the iteration will stop when &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; where &lt;code&gt;g_i&lt;/code&gt; is the i-th component of the gradient.</source>
          <target state="translated">停止基準。newton-cgおよびlbfgsソルバーの場合、反復は &lt;code&gt;max{|g_i | i = 1, ..., n} &amp;lt;= tol&lt;/code&gt; ここで、 &lt;code&gt;g_i&lt;/code&gt; は勾配のi番目の成分です。</target>
        </trans-unit>
        <trans-unit id="fe10af6492740b92517388e940d4c53ee7e65f2c" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for EM algorithm.</source>
          <target state="translated">EMアルゴリズムの停止公差</target>
        </trans-unit>
        <trans-unit id="54709da56f5bb7c428a618dd7d85fb0e4421bcb5" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for log-likelihood increase.</source>
          <target state="translated">対数尤度上昇の停止公差。</target>
        </trans-unit>
        <trans-unit id="3afb8412732c53a6b3ed5f0cf3d5d66e9526d993" translate="yes" xml:space="preserve">
          <source>Stopping tolerance for updating document topic distribution in E-step.</source>
          <target state="translated">Eステップでの文書トピック分布更新の停止許容範囲</target>
        </trans-unit>
        <trans-unit id="5745be1c1a529a40ad5578990283b7d9ed5dfe16" translate="yes" xml:space="preserve">
          <source>Store n output values in leaves, instead of 1;</source>
          <target state="translated">1ではなく、n個の出力値をリーフに格納します。</target>
        </trans-unit>
        <trans-unit id="0fac441919e9594e005f5d0571a0bfbc255133fa" translate="yes" xml:space="preserve">
          <source>Stored sampling interval. Specified as a parameter if sample_steps not in {1,2,3}.</source>
          <target state="translated">サンプリング間隔を指定します。sample_stepsが{1,2,3}にない場合はパラメータとして指定されます。</target>
        </trans-unit>
        <trans-unit id="8a6ab3415c7252ce3e941fe62193814f0365a625" translate="yes" xml:space="preserve">
          <source>Stores nearest neighbors instance, including BallTree or KDtree if applicable.</source>
          <target state="translated">該当する場合はBallTreeまたはKDtreeを含む、最も近い隣人のインスタンスを格納します。</target>
        </trans-unit>
        <trans-unit id="f9d028499b97399f71598e9bb920fa52d5ec8313" translate="yes" xml:space="preserve">
          <source>Stores the affinity matrix used in &lt;code&gt;fit&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; で使用されるアフィニティマトリックスを格納します。</target>
        </trans-unit>
        <trans-unit id="781b70a9f7d2aabdccb43059620f25863827cacd" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors</source>
          <target state="translated">埋め込みベクトルを格納します。</target>
        </trans-unit>
        <trans-unit id="9fe548f57e57cace725aa47be0bac94930f35de7" translate="yes" xml:space="preserve">
          <source>Stores the embedding vectors.</source>
          <target state="translated">埋め込みベクトルを格納します。</target>
        </trans-unit>
        <trans-unit id="e7019b0e2126237169f8ccc84f1dacd8599b7b63" translate="yes" xml:space="preserve">
          <source>Stores the geodesic distance matrix of training data.</source>
          <target state="translated">学習データの測地線距離行列を格納します。</target>
        </trans-unit>
        <trans-unit id="7bfa0d6921b4ff07d4718354c3a4168af9b3a946" translate="yes" xml:space="preserve">
          <source>Stores the position of the dataset in the embedding space.</source>
          <target state="translated">埋め込み空間におけるデータセットの位置を格納します.</target>
        </trans-unit>
        <trans-unit id="8197f80c6163117652499db82ad63b22aa5b87b2" translate="yes" xml:space="preserve">
          <source>Stores the training data.</source>
          <target state="translated">トレーニングデータを格納します。</target>
        </trans-unit>
        <trans-unit id="6485fe8179de6b50a8b0db7cf302477ffee4cf50" translate="yes" xml:space="preserve">
          <source>Strategy to use to generate predictions.</source>
          <target state="translated">予測を出すために使う戦略。</target>
        </trans-unit>
        <trans-unit id="9ba291b4721c49cd83c83d224ae746db45b32e1d" translate="yes" xml:space="preserve">
          <source>Strategy used to define the widths of the bins.</source>
          <target state="translated">ビンの幅を定義するために使用される戦略。</target>
        </trans-unit>
        <trans-unit id="890ad0feded21dbb4c68bfca3e2d7cdbb498d411" translate="yes" xml:space="preserve">
          <source>Stratified K-Folds cross-validator</source>
          <target state="translated">層化K-Foldsクロスバリデータ</target>
        </trans-unit>
        <trans-unit id="078f2e04c72cf2c2cef672d9cd530d809895796a" translate="yes" xml:space="preserve">
          <source>Stratified ShuffleSplit cross-validator</source>
          <target state="translated">層化シャッフルスプリットクロスバリデーター</target>
        </trans-unit>
        <trans-unit id="10ef227c2ccc54bd522a7229f1c708e11ce5e295" translate="yes" xml:space="preserve">
          <source>Strehl, Alexander, and Joydeep Ghosh (2002). &amp;ldquo;Cluster ensembles &amp;ndash; a knowledge reuse framework for combining multiple partitions&amp;rdquo;. Journal of Machine Learning Research 3: 583&amp;ndash;617. &lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi:10.1162/153244303321897735&lt;/a&gt;.</source>
          <target state="translated">Strehl、Alexander、およびJoydeep Ghosh（2002）。「クラスターアンサンブル&amp;ndash;複数のパーティションを組み合わせるための知識再利用フレームワーク」。Journal of Machine Learning Research 3：583&amp;ndash;617。&lt;a href=&quot;http://strehl.com/download/strehl-jmlr02.pdf&quot;&gt;doi：10.1162 / 153244303321897735&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="738d614dd3bdb5fdb2eecf8a98b676a349ac24fe" translate="yes" xml:space="preserve">
          <source>Strictly speaking, SGD is merely an optimization technique and does not correspond to a specific family of machine learning models. It is only a &lt;em&gt;way&lt;/em&gt; to train a model. Often, an instance of &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; will have an equivalent estimator in the scikit-learn API, potentially using a different optimization technique. For example, using &lt;code&gt;SGDClassifier(loss='log')&lt;/code&gt; results in logistic regression, i.e. a model equivalent to &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; which is fitted via SGD instead of being fitted by one of the other solvers in &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt;. Similarly, &lt;code&gt;SGDRegressor(loss='squared_loss', penalty='l2')&lt;/code&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; solve the same optimization problem, via different means.</source>
          <target state="translated">厳密に言えば、SGDは単なる最適化手法であり、特定の機械学習モデルのファミリーに対応していません。これはモデルをトレーニングする&lt;em&gt;方法&lt;/em&gt;にすぎません。多くの場合、&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt; &lt;code&gt;SGDRegressor&lt;/code&gt; の&lt;/a&gt;インスタンスは、scikit-learn APIに同等の推定量を持ち、異なる最適化手法を使用する可能性があります。例えば、使用 &lt;code&gt;SGDClassifier(loss='log')&lt;/code&gt; 、すなわちに対するモデルと等価ロジスティック回帰をもたらす、&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;代わりに他のソルバの一つでフィッティングされるのSGDを介して嵌合されている&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;。同様に、 &lt;code&gt;SGDRegressor(loss='squared_loss', penalty='l2')&lt;/code&gt; および&lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt; 異なる方法で同じ最適化問題を解きます。</target>
        </trans-unit>
        <trans-unit id="8f823045d1b6e6e3e2566fad8b86b9a7f7274035" translate="yes" xml:space="preserve">
          <source>String describing the type of covariance parameters to use. Must be one of:</source>
          <target state="translated">使用する共分散パラメータの種類を記述する文字列.以下のいずれかである必要があります。</target>
        </trans-unit>
        <trans-unit id="24715b349c9d19241a871e75b2e65bf44d424eee" translate="yes" xml:space="preserve">
          <source>String describing the type of the weight concentration prior. Must be one of:</source>
          <target state="translated">事前の重量集中の種類を記述する文字列。のいずれかでなければならない。</target>
        </trans-unit>
        <trans-unit id="8c721819e7f297061a3852981915f8763538ca5d" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape (n_samples, n_features), and return a (n_samples, n_samples) shaped weight matrix.</source>
          <target state="translated">使用するカーネル関数またはカーネル関数自体の文字列識別子。'rbf'および 'knn'文字列のみが有効な入力です。渡される関数は、それぞれ形状（n_samples、n_features）の2つの入力を受け取り、（n_samples、n_samples）形状の重み行列を返す必要があります。</target>
        </trans-unit>
        <trans-unit id="428566ee279a0d9edb0dac9070b52a231b258cad" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix</source>
          <target state="translated">使用するカーネル関数またはカーネル関数自体の文字列識別子。'rbf'および 'knn'文字列のみが有効な入力です。渡される関数は、形状[n_samples、n_features]の2つの入力を受け取り、[n_samples、n_samples]形状の重み行列を返す必要があります</target>
        </trans-unit>
        <trans-unit id="af724a0a2167e8652dc92f95eace643e40894f38" translate="yes" xml:space="preserve">
          <source>String identifier for kernel function to use or the kernel function itself. Only &amp;lsquo;rbf&amp;rsquo; and &amp;lsquo;knn&amp;rsquo; strings are valid inputs. The function passed should take two inputs, each of shape [n_samples, n_features], and return a [n_samples, n_samples] shaped weight matrix.</source>
          <target state="translated">使用するカーネル関数またはカーネル関数自体の文字列識別子。'rbf'および 'knn'文字列のみが有効な入力です。渡される関数は、形状[n_samples、n_features]の2つの入力を受け取り、[n_samples、n_samples]形状の重み行列を返します。</target>
        </trans-unit>
        <trans-unit id="62948e7b4671e9ca0f3cde3750c969c3432c4224" translate="yes" xml:space="preserve">
          <source>String identifier of the dataset. Note that OpenML can have multiple datasets with the same name.</source>
          <target state="translated">データセットの文字列識別子。OpenMLでは、同じ名前のデータセットを複数持つことができることに注意してください。</target>
        </trans-unit>
        <trans-unit id="df0679bd93bc3d3699b427e726c60dd8e54a8049" translate="yes" xml:space="preserve">
          <source>String inputs, &amp;ldquo;absolute_loss&amp;rdquo; and &amp;ldquo;squared_loss&amp;rdquo; are supported which find the absolute loss and squared loss per sample respectively.</source>
          <target state="translated">文字列入力「absolute_loss」と「squared_loss」がサポートされ、サンプルごとの絶対損失と二乗損失をそれぞれ検出します。</target>
        </trans-unit>
        <trans-unit id="0e35f8f4354526879dda20784b410a6fffd10219" translate="yes" xml:space="preserve">
          <source>String must be in {&amp;lsquo;frobenius&amp;rsquo;, &amp;lsquo;kullback-leibler&amp;rsquo;, &amp;lsquo;itakura-saito&amp;rsquo;}. Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from &amp;lsquo;frobenius&amp;rsquo; (or 2) and &amp;lsquo;kullback-leibler&amp;rsquo; (or 1) lead to significantly slower fits. Note that for beta_loss &amp;lt;= 0 (or &amp;lsquo;itakura-saito&amp;rsquo;), the input matrix X cannot contain zeros. Used only in &amp;lsquo;mu&amp;rsquo; solver.</source>
          <target state="translated">文字列は{'frobenius'、 'kullback-leibler'、 'itakura-saito'}である必要があります。Xと内積WHの間の距離を測定して、ベータダイバージェンスを最小化します。'frobenius'（または2）および 'kullback-leibler'（または1）とは異なる値を使用すると、近似が大幅に遅くなることに注意してください。beta_loss &amp;lt;= 0（または 'itakura-saito'）の場合、入力行列Xにゼロを含めることはできません。'mu'ソルバーでのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="9f2d9e288ea5ff4eb7ea1abaab0c518bb3979797" translate="yes" xml:space="preserve">
          <source>String names for input features if available. By default, &amp;ldquo;x0&amp;rdquo;, &amp;ldquo;x1&amp;rdquo;, &amp;hellip; &amp;ldquo;xn_features&amp;rdquo; is used.</source>
          <target state="translated">利用可能な場合、入力フィーチャの文字列名。デフォルトでは、「x0」、「x1」、&amp;hellip;「xn_features」が使用されます。</target>
        </trans-unit>
        <trans-unit id="6eb302a1a8353d21c585781076747cec5064ac6a" translate="yes" xml:space="preserve">
          <source>String representation of the input tree in GraphViz dot format. Only returned if &lt;code&gt;out_file&lt;/code&gt; is None.</source>
          <target state="translated">GraphVizドット形式の入力ツリーの文字列表現。 &lt;code&gt;out_file&lt;/code&gt; がNoneの場合にのみ返されます。</target>
        </trans-unit>
        <trans-unit id="a25a8a192fb86c92debb43e92001c859f89e3fcf" translate="yes" xml:space="preserve">
          <source>String[s] representing allowed sparse matrix formats, such as &amp;lsquo;csc&amp;rsquo;, &amp;lsquo;csr&amp;rsquo;, etc. If the input is sparse but not in the allowed format, it will be converted to the first listed format. True allows the input to be any format. False means that a sparse matrix input will raise an error.</source>
          <target state="translated">「csc」、「csr」などの許可された疎行列形式を表す文字列[s]。入力がスパースであるが許可された形式ではない場合、最初にリストされた形式に変換されます。 Trueを指定すると、入力を任意の形式にすることができます。 Falseは、スパース行列の入力でエラーが発生することを意味します。</target>
        </trans-unit>
        <trans-unit id="5110c05a58c323fc1a90d8e9c2d4e3215bf368fd" translate="yes" xml:space="preserve">
          <source>Strings can reference columns if the input is a DataFrame, integers are always interpreted as the positional columns.</source>
          <target state="translated">入力がDataFrameの場合、文字列は列を参照することができ、整数は常に位置の列として解釈されます。</target>
        </trans-unit>
        <trans-unit id="b91b90e5e49a63cce92ec827bcf2ae012d9565f3" translate="yes" xml:space="preserve">
          <source>Subsequently, the object is created as:</source>
          <target state="translated">その後、オブジェクトは次のように作成されます。</target>
        </trans-unit>
        <trans-unit id="858f5a05f03a44bd2c0d7ffef4c39076939797fb" translate="yes" xml:space="preserve">
          <source>Subset of X on axis 0 or 1.</source>
          <target state="translated">軸0または軸1上のXのサブセット。</target>
        </trans-unit>
        <trans-unit id="d8cf7e7f541f13164e6f0420a446eeb6e92a09d1" translate="yes" xml:space="preserve">
          <source>Subset of X on first axis</source>
          <target state="translated">第1軸のXのサブセット</target>
        </trans-unit>
        <trans-unit id="6ae596021e773a90882ea646d69c3ae9bc66f60f" translate="yes" xml:space="preserve">
          <source>Subset of target values</source>
          <target state="translated">目標値のサブセット</target>
        </trans-unit>
        <trans-unit id="71578b0f6daa48f798b6ba24f599e04480076227" translate="yes" xml:space="preserve">
          <source>Subset of the target values</source>
          <target state="translated">目標値のサブセット</target>
        </trans-unit>
        <trans-unit id="b6f57836197cd859fcd7456747a897dac9249a7c" translate="yes" xml:space="preserve">
          <source>Subset of the target values.</source>
          <target state="translated">目標値のサブセット。</target>
        </trans-unit>
        <trans-unit id="223f88ba981735506f55650c24adc2c0be541ac7" translate="yes" xml:space="preserve">
          <source>Subset of the training data</source>
          <target state="translated">学習データのサブセット</target>
        </trans-unit>
        <trans-unit id="a36f00d869bab77d370e6340b596e76174606ee7" translate="yes" xml:space="preserve">
          <source>Subset of the training data.</source>
          <target state="translated">学習データのサブセット。</target>
        </trans-unit>
        <trans-unit id="6bc315a85db741490d46c866dcdf3685f245d4e2" translate="yes" xml:space="preserve">
          <source>Subset of training data</source>
          <target state="translated">トレーニングデータのサブセット</target>
        </trans-unit>
        <trans-unit id="19abeb39c58b2714170ce5a2488e41705eacf825" translate="yes" xml:space="preserve">
          <source>Subset of training points used to construct the feature map.</source>
          <target state="translated">特徴マップを構築するために使用される学習点のサブセット.</target>
        </trans-unit>
        <trans-unit id="af82dc274666b6dae18b2b0a4a918322786e1ec9" translate="yes" xml:space="preserve">
          <source>Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.</source>
          <target state="translated">このようなデータのグループ化は、ドメイン固有のものである。例としては、複数の患者から収集された医療データがあり、それぞれの患者から採取された複数のサンプルがある場合が考えられる。そして、そのようなデータは、個々のグループに依存している可能性が高い。この例では、各サンプルの患者IDがそのグループ識別子となる。</target>
        </trans-unit>
        <trans-unit id="116040368f9a04b617abdb5e80205920c1827d88" translate="yes" xml:space="preserve">
          <source>Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).</source>
          <target state="translated">しかし、このような整数表現は、すべてのscikit-learnの推定器で直接使用することはできません。なぜなら、これらの推定器は連続的な入力を期待しているため、カテゴリが順序付けられていると解釈してしまうからです。</target>
        </trans-unit>
        <trans-unit id="db90c3a55b9a44b531c3ac8e926f4bff46ae5000" translate="yes" xml:space="preserve">
          <source>Sum of squared distances of samples to their closest cluster center.</source>
          <target state="translated">最も近いクラスター中心までのサンプルの2乗距離の和。</target>
        </trans-unit>
        <trans-unit id="854e30e5027349dd68053e9c07e26612b753dfb3" translate="yes" xml:space="preserve">
          <source>Sum of the impurities of the subtree leaves for the corresponding alpha value in &lt;code&gt;ccp_alphas&lt;/code&gt;.</source>
          <target state="translated">サブツリーの葉の不純物の合計は、 &lt;code&gt;ccp_alphas&lt;/code&gt; の対応するアルファ値に対応します。</target>
        </trans-unit>
        <trans-unit id="4d0794742200525b0f1825276d5e113f8014eaee" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount.</source>
          <target state="translated">対数的な割引を適用した後、予測されたスコアによって誘導された順にランク付けされた真のスコアを合計します。</target>
        </trans-unit>
        <trans-unit id="8c895953cca3a7be3ad68f35cb10044d9d62303c" translate="yes" xml:space="preserve">
          <source>Sum the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount. Then divide by the best possible score (Ideal DCG, obtained for a perfect ranking) to obtain a score between 0 and 1.</source>
          <target state="translated">対数割引を適用した後、予測されたスコアによって誘導された順にランク付けされた真のスコアを合計します。そして、0から1の間のスコアを得るために、可能な限り最高のスコア(完璧なランキングのために得られた理想的なDCG)で割る。</target>
        </trans-unit>
        <trans-unit id="51853ebee0d0437a819288d394e52f2825e89e10" translate="yes" xml:space="preserve">
          <source>Sum-kernel k1 + k2 of two kernels k1 and k2.</source>
          <target state="translated">2つのカーネルk1、k2の和カーネルk1+k2。</target>
        </trans-unit>
        <trans-unit id="bb594232250fde950a53bc755dc305c05d6d4d31" translate="yes" xml:space="preserve">
          <source>Summary Statistics</source>
          <target state="translated">サマリー統計</target>
        </trans-unit>
        <trans-unit id="70ee3e3bff0af30ecffa237a657d140e21c08452" translate="yes" xml:space="preserve">
          <source>Summary Statistics:</source>
          <target state="translated">サマリー統計。</target>
        </trans-unit>
        <trans-unit id="fd64088007de4ee1ec90faddb61b9fabe7591dbe" translate="yes" xml:space="preserve">
          <source>Supervised learning algorithms will require a category label for each document in the training set. In this case the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents.</source>
          <target state="translated">教師付き学習アルゴリズムでは、学習セット内の各ドキュメントに対してカテゴリラベルが必要になります。この場合、カテゴリはニュースグループの名前であり、個々のドキュメントを保持しているフォルダの名前でもあります。</target>
        </trans-unit>
        <trans-unit id="a76d63a44e8696360e974f3be74fa9ede463ccb8" translate="yes" xml:space="preserve">
          <source>Supervised learning: predicting an output variable from high-dimensional observations</source>
          <target state="translated">教師付き学習:高次元観測から出力変数を予測する</target>
        </trans-unit>
        <trans-unit id="a3f901fb4e96c309b27de60d3fa05a2f6c90ddfd" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">サポートベクトル分類（SVC）は、RandomForestClassifierとしてさらに多くのシグモイド曲線を示します。これは、決定境界に近いハードサンプル（サポートベクトル）に焦点を当てる最大マージンメソッド（Niculescu-MizilとCaruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1を&lt;/a&gt;比較）で一般的です。）。</target>
        </trans-unit>
        <trans-unit id="6eafe7087c2917502cf9a105460eb618a5158ac5" translate="yes" xml:space="preserve">
          <source>Support Vector Classification (SVC) shows an even more sigmoid curve as the RandomForestClassifier, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;), which focus on hard samples that are close to the decision boundary (the support vectors).</source>
          <target state="translated">サポートベクター分類（SVC）はRandomForestClassifierとしてさらに多くのシグモイド曲線を示します。これは最大マージンメソッド（Niculescu-MizilとCaruanaを比較&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;）の典型であり、決定境界に近いハードサンプル（サポートベクター）。</target>
        </trans-unit>
        <trans-unit id="ed5eaa4e09c1fde40caa79c99d658b1a804b4ecf" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. See section &lt;a href=&quot;preprocessing#preprocessing&quot;&gt;Preprocessing data&lt;/a&gt; for more details on scaling and normalization.</source>
          <target state="translated">サポートベクターマシンアルゴリズムはスケール不変ではないため&lt;strong&gt;、データをスケールすることを強くお勧めします&lt;/strong&gt;。たとえば、入力ベクトルXの各属性を[0,1]または[-1、+ 1]にスケーリングするか、平均0と分散1になるように標準化します。テストベクトルに&lt;em&gt;同じ&lt;/em&gt;スケーリングを適用して、意味のある結果を得る。スケーリングと正規化の詳細については、「&lt;a href=&quot;preprocessing#preprocessing&quot;&gt;データの前処理&lt;/a&gt;」を参照してください。</target>
        </trans-unit>
        <trans-unit id="6759d5fe5cd02546f72e19999514f8d8dd0c2afc" translate="yes" xml:space="preserve">
          <source>Support Vector Machine algorithms are not scale invariant, so &lt;strong&gt;it is highly recommended to scale your data&lt;/strong&gt;. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the &lt;em&gt;same&lt;/em&gt; scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">サポートベクターマシンアルゴリズムはスケール不変ではないため&lt;strong&gt;、データをスケーリングすることを強くお勧めします&lt;/strong&gt;。たとえば、入力ベクトルXの各属性を[0,1]または[-1、+ 1]にスケーリングするか、平均0と分散1を持つように標準化します。&lt;em&gt;同じ&lt;/em&gt;スケーリングをテストベクトルに適用する必要があることに注意してください。意味のある結果を得る。これは、&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;を使用して簡単に実行できます。</target>
        </trans-unit>
        <trans-unit id="7db4fe2bb2b495808d702cc828d549eda5ecd6dd" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for Regression implemented using libsvm.</source>
          <target state="translated">回帰のためのサポートベクターマシンはlibsvmを使って実装されています。</target>
        </trans-unit>
        <trans-unit id="f893d85d40edb954e6730df0c490772b3e2a0229" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.</source>
          <target state="translated">分類のためのサポートベクターマシンは、サポートベクターの数を制御するためのパラメータを持つlibsvmで実装されています。</target>
        </trans-unit>
        <trans-unit id="5051cb5a7ebb600b6c87a0405fb53ae2a929b69a" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for classification using libsvm.</source>
          <target state="translated">libsvmを使った分類のためのサポートベクターマシン。</target>
        </trans-unit>
        <trans-unit id="c9c0030d3280fdd6faa0de4e8ec40fd895c7cc05" translate="yes" xml:space="preserve">
          <source>Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.</source>
          <target state="translated">libsvmを使って実装された回帰用のサポートベクターマシンは、サポートベクターの数を制御するためのパラメータを使っています。</target>
        </trans-unit>
        <trans-unit id="0e9e942139034d62a386d593445cc7ca0b8119c8" translate="yes" xml:space="preserve">
          <source>Support Vector Machines</source>
          <target state="translated">サポートベクターマシン</target>
        </trans-unit>
        <trans-unit id="09b4534def5c091569acb02092fe6cf8bbcb767a" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">サポートベクターマシンは強力なツールですが、トレーニングベクターの数に応じて計算とストレージの要件が急速に増加します。 SVMのコアは、サポートベクターを残りのトレーニングデータから分離する二次計画問題（QP）です。&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;ベースの実装で使用されるQPソルバーは、\（O（n_ {features} \ times n_ {samples} ^ 2）\）と\（O（n_ {features} \ times n_ {samples} ^ 3）\の間でスケーリングします。 ）&lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;キャッシュが実際にどれだけ効率的に使用されているかに依存します（データセットに依存します）。データが非常にまばらな場合は、\（n_ {features} \）をサンプルベクトル内のゼロ以外の特徴の平均数に置き換える必要があります。</target>
        </trans-unit>
        <trans-unit id="56158ab7bc33e3424017c0101c6f6a1afb88a3a9" translate="yes" xml:space="preserve">
          <source>Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by this &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt; cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.</source>
          <target state="translated">サポートベクターマシンは強力なツールですが、それらのコンピューティングとストレージの要件は、トレーニングベクターの数とともに急速に増加します。SVMの中核は、2次計画問題（QP）であり、サポートベクトルを残りのトレーニングデータから分離します。この&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;ベースの実装で使用されるQPソルバーは、\（O（n_ {features} \ times n_ {samples} ^ 2）\）と\（O（n_ {features} \ times n_ {samples} ^ 3）\の間でスケーリングします）&lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;キャッシュが実際にどの程度効率的に使用されているかに応じて（データセットに依存）。データが非常に少ない場合は、\（n_ {features} \）をサンプルベクトル内のゼロ以外の特徴の平均数に置き換える必要があります。</target>
        </trans-unit>
        <trans-unit id="5aeba1d5d3764ce4f342c9f3c5c4d98c95831ef3" translate="yes" xml:space="preserve">
          <source>Support Vector Regression (SVR) using linear and non-linear kernels</source>
          <target state="translated">線形および非線形カーネルを用いた支持ベクトル回帰(SVR)</target>
        </trans-unit>
        <trans-unit id="c38caf86bc0ea77939ed0d559b2d4f17cae05de8" translate="yes" xml:space="preserve">
          <source>Support Vector Regression implemented using libsvm.</source>
          <target state="translated">サポートベクトル回帰はlibsvmを使って実装されています。</target>
        </trans-unit>
        <trans-unit id="9f57f9c660b4dd2f0deaa4ba97e0c878c516d5af" translate="yes" xml:space="preserve">
          <source>Support vector machines (SVMs)</source>
          <target state="translated">サポートベクターマシン(SVM)</target>
        </trans-unit>
        <trans-unit id="bbbf41eb38c0c6ebc14c9776b74f3b7c7223e260" translate="yes" xml:space="preserve">
          <source>Support vectors.</source>
          <target state="translated">支持ベクトル。</target>
        </trans-unit>
        <trans-unit id="a54e8408d47bb6e31202d1c04b19dcb2a41dd085" translate="yes" xml:space="preserve">
          <source>Supports sparse matrices, as long as they are nonnegative.</source>
          <target state="translated">負でない限り,疎な行列をサポートします.</target>
        </trans-unit>
        <trans-unit id="3d69897cfb127444947f0af512011088c32f7842" translate="yes" xml:space="preserve">
          <source>Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(n\cdot m \cdot h^k \cdot o \cdot i)\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.</source>
          <target state="translated">仮に、訓練サンプルがあるとすると、訓練サンプルの中には、&quot;Training samples&quot;,&quot;It'm Features&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone&quot;,&quot;I'llone &quot;がある。バックプロパゲーションの時間的な複雑さは、\(O(n\cdot m \cdot h^k \cdot o \cdot i)\),ここで、Iは反復回数。バックプロパゲーションは時間的に複雑なので、学習のための隠れニューロンの数を少なくして、隠れ層の数を少なくすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="cd4ffcedd7e0903b657852f1e48effcf51cd6dba" translate="yes" xml:space="preserve">
          <source>Suppose you have a machine with 8 CPUs. Consider a case where you&amp;rsquo;re running a &lt;code&gt;GridSearchCV&lt;/code&gt; (parallelized with joblib) with &lt;code&gt;n_jobs=8&lt;/code&gt; over a &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; (parallelized with OpenMP). Each instance of &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; will spawn 8 threads (since you have 8 CPUs). That&amp;rsquo;s a total of &lt;code&gt;8 * 8 = 64&lt;/code&gt; threads, which leads to oversubscription of physical CPU resources and to scheduling overhead.</source>
          <target state="translated">8個のCPUを搭載したマシンがあるとします。あなたが実行している場合を検討 &lt;code&gt;GridSearchCV&lt;/code&gt; と（JOBLIBと並列化） &lt;code&gt;n_jobs=8&lt;/code&gt; 以上 &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; （のOpenMPで並列化を）。 &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; の各インスタンスは8つのスレッドを生成します（8つのCPUがあるため）。これは合計 &lt;code&gt;8 * 8 = 64&lt;/code&gt; スレッドであり、物理CPUリソースのオーバーサブスクリプションとスケジューリングのオーバーヘッドにつながります。</target>
        </trans-unit>
        <trans-unit id="717b26aef2df5c03a35ae859cfcbb420ec45f953" translate="yes" xml:space="preserve">
          <source>Swaps two columns of a CSC/CSR matrix in-place.</source>
          <target state="translated">CSC/CSRマトリックスの2つの列をその場で入れ替えます。</target>
        </trans-unit>
        <trans-unit id="1069fce64f91499526a54ca2a920222a7a6a7b20" translate="yes" xml:space="preserve">
          <source>Swaps two rows of a CSC/CSR matrix in-place.</source>
          <target state="translated">CSC/CSRマトリックスの2つの行を入れ替えます。</target>
        </trans-unit>
        <trans-unit id="fe072010fa51f4d65d4b1c57510d1adce13a6e7b" translate="yes" xml:space="preserve">
          <source>Swiss Roll reduction with LLE</source>
          <target state="translated">LLEによるスイスロール還元</target>
        </trans-unit>
        <trans-unit id="2230299d58c6b8fd7778e9806246c78a89ba5d37" translate="yes" xml:space="preserve">
          <source>Symmetrized version of the input array, i.e. the average of array and array.transpose(). If sparse, then duplicate entries are first summed and zeros are eliminated.</source>
          <target state="translated">入力配列の対称化されたバージョン,すなわち,array と array.transpose()の平均.疎な場合は,重複するエントリが最初に合計され,ゼロが除去されます.</target>
        </trans-unit>
        <trans-unit id="5617e20da29f8f9d1be80cd4e8da4f2cca7d87a9" translate="yes" xml:space="preserve">
          <source>Symmetry: d(x, y) = d(y, x)</source>
          <target state="translated">対称性:d(x,y)=d(y,x)</target>
        </trans-unit>
        <trans-unit id="5c4b58b32e84506455d7badad68c3391e5ed62f8" translate="yes" xml:space="preserve">
          <source>Synthetic example</source>
          <target state="translated">合成例</target>
        </trans-unit>
        <trans-unit id="a2f05b63d3eed62a3d034f7470902282f6f3879f" translate="yes" xml:space="preserve">
          <source>T. Calinski and J. Harabasz, 1974. &amp;ldquo;A dendrite method for cluster analysis&amp;rdquo;. Communications in Statistics</source>
          <target state="translated">T. CalinskiおよびJ. Harabasz、1974。「クラスター分析のための樹状突起法」。統計におけるコミュニケーション</target>
        </trans-unit>
        <trans-unit id="cfd0a0e6ed4317c498cad6dff52fb64a880cf1fc" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T.ハスティ、R。ティブシラニ、J。フリードマン、「Elements of Statistical Learning Ed。2インチ、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="7f7943ebfea41ffafd05b1021989488d98e43338" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning Ed. 2&amp;rdquo;, p592-593, Springer, 2009.</source>
          <target state="translated">T.ハスティ、R。ティブシラニ、J。フリードマン、「Elements of Statistical Learning Ed。2インチ、p592-593、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="70c29954ab4c3cb7794dae94a173c1937d4eb172" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T.ハスティ、R。ティブシラニ、J。フリードマン、「統計学習の要素」、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="1a36ad5ec8c80f7993b9fd82eb2686d2da21883a" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn//&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Second Edition, Section 10.13.2, Springer, 2009.</source>
          <target state="translated">T. Hastie、R。Tibshirani、J。Friedman、&lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn//&quot;&gt;The Elements of Statistics Learning&lt;/a&gt;、第2版、セクション10.13.2、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="83fcdb4c642340f440ec3c76643b0ff4a3e4d907" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. &amp;ldquo;Elements of Statistical Learning&amp;rdquo;, Springer, 2009.</source>
          <target state="translated">T.ハスティー、R。ティブシラニ、J。フリードマン。「統計学習の要素」、Springer、2009年。</target>
        </trans-unit>
        <trans-unit id="cb7835aaacc19565f84e186774c00699f37d4811" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.</source>
          <target state="translated">T.遺伝学的学習の要素は、統計学的学習の要素である。統計的学習の要素 第2版,シュプリンガー,2009.</target>
        </trans-unit>
        <trans-unit id="d4c99bc2ba4c28ec35fea9e0c8535d7da602917b" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.</source>
          <target state="translated">T.確率論的学習の要素,シュプリンガー,2009.統計的学習の要素,シュプリンガー,2009.</target>
        </trans-unit>
        <trans-unit id="080b47cb3536b08b8d64a0132c354c0e69235639" translate="yes" xml:space="preserve">
          <source>T. Hastie, R. Tibshirani, J. Friedman, &lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of Statistical Learning&lt;/a&gt;, Springer 2009</source>
          <target state="translated">T.ハスティ、R。ティブシラニ、J。フリードマン、&lt;a href=&quot;https://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;統計的学習の要素&lt;/a&gt;、Springer 2009</target>
        </trans-unit>
        <trans-unit id="caa676716fee5a5c020ff878a7d0616f2b82e015" translate="yes" xml:space="preserve">
          <source>T. Ho, &amp;ldquo;The random subspace method for constructing decision forests&amp;rdquo;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</source>
          <target state="translated">T. Ho、「意思決定フォレストを構築するためのランダム部分空間法」、Pattern Analysis and Machine Intelligence、20（8）、832-844、1998。</target>
        </trans-unit>
        <trans-unit id="12a252b4085c50c08e5600b6a2ace31faa3ef960" translate="yes" xml:space="preserve">
          <source>T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou &amp;ldquo;Nystroem Method vs Random Fourier Features: A Theoretical and Empirical Comparison&amp;rdquo;, Advances in Neural Information Processing Systems 2012</source>
          <target state="translated">T.ヤン、Y。リー、M。マダビ、R。ジン、Z。ジョウ「Nystroemメソッドとランダムフーリエの特徴：理論的および経験的比較」、神経情報処理システムの進歩2012</target>
        </trans-unit>
        <trans-unit id="01f0642e8e9ab9a87342728e5ceb8bbd9d2f4ab3" translate="yes" xml:space="preserve">
          <source>TAX full-value property-tax rate per $10,000</source>
          <target state="translated">10,000ドルあたりの全価額固定資産税の税率</target>
        </trans-unit>
        <trans-unit id="dd1b5c68340d106d37b309522fe8b393cb21ad39" translate="yes" xml:space="preserve">
          <source>TF-IDF vectors of text documents crawled from the web</source>
          <target state="translated">ウェブからクロールされたテキスト文書のTF-IDFベクトル</target>
        </trans-unit>
        <trans-unit id="45e8bc91482fcb8372ecf82971819bb3adf7f455" translate="yes" xml:space="preserve">
          <source>TODO: implement zip dataset loading too</source>
          <target state="translated">TODO:zipデータセットの読み込みも実装する</target>
        </trans-unit>
        <trans-unit id="8ab0e32d1d047cd892b558c9b2f078b6857615c4" translate="yes" xml:space="preserve">
          <source>Takes a group array to group observations.</source>
          <target state="translated">グループの配列をグループのオブザベーションに利用します。</target>
        </trans-unit>
        <trans-unit id="3fd5fa24212eb9a6093f6fb3922373c2e928c57e" translate="yes" xml:space="preserve">
          <source>Takes group information into account to avoid building folds with imbalanced class distributions (for binary or multiclass classification tasks).</source>
          <target state="translated">グループ情報を考慮に入れて,不均衡なクラス分布を持つ折り目を作らないようにします(バイナリまたはマルチクラス分類タスクの場合).</target>
        </trans-unit>
        <trans-unit id="d9f2745c15759b2e07e7b8ac9dcbd8d3eb7f1df5" translate="yes" xml:space="preserve">
          <source>Talks given, slide-sets and other information relevant to scikit-learn.</source>
          <target state="translated">講演、スライドセット、その他scikit-learnに関連する情報を提供します。</target>
        </trans-unit>
        <trans-unit id="61ad50a9b9189cc3cf1874568e35e7901ff4c982" translate="yes" xml:space="preserve">
          <source>Target</source>
          <target state="translated">Target</target>
        </trans-unit>
        <trans-unit id="27a0909e2e214e16b84c188da9b6e36fbb24a75c" translate="yes" xml:space="preserve">
          <source>Target Domain</source>
          <target state="translated">対象領域</target>
        </trans-unit>
        <trans-unit id="c0810f8f564f353b71a4c98cca217fcf1b526a4f" translate="yes" xml:space="preserve">
          <source>Target cardinality</source>
          <target state="translated">ターゲットのカーディナリティ</target>
        </trans-unit>
        <trans-unit id="a92a80f8cb5657b9d712fa7c0bc7d1998153a6b8" translate="yes" xml:space="preserve">
          <source>Target names used for plotting. By default, &lt;code&gt;labels&lt;/code&gt; will be used if it is defined, otherwise the unique labels of &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; will be used.</source>
          <target state="translated">プロットに使用されるターゲット名。デフォルトでは、 &lt;code&gt;labels&lt;/code&gt; 、それが定義されていればそれ以外のユニークなラベル、使用され &lt;code&gt;y_true&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="3566560919d090e98a5bc58e40d68ba478487e60" translate="yes" xml:space="preserve">
          <source>Target number of non-zero coefficients. Use &lt;code&gt;np.inf&lt;/code&gt; for no limit.</source>
          <target state="translated">非ゼロ係数のターゲット数。 &lt;code&gt;np.inf&lt;/code&gt; を使用してください。</target>
        </trans-unit>
        <trans-unit id="de81f661c0a5f66b2eb62d654cf5ee97c42a462f" translate="yes" xml:space="preserve">
          <source>Target relative to X for classification or regression; None for unsupervised learning.</source>
          <target state="translated">分類や回帰の場合はXに対する相対的な目標;教師なし学習の場合はなし.</target>
        </trans-unit>
        <trans-unit id="d9d3de45f60123470c229b29def5cf613978229f" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">ターゲットスコアは、ポジティブクラスの確率推定値、信頼値、またはしきい値のない決定尺度（一部の分類子の「decision_function」によって返される）のいずれかです。</target>
        </trans-unit>
        <trans-unit id="2da36130db1b72e7220423e41225d3cfbecbf96b" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</source>
          <target state="translated">ターゲットスコアは、ポジティブクラスの確率推定値、信頼値、またはしきい値のない決定尺度（一部の分類子の「decision_function」によって返される）のいずれかです。バイナリy_trueの場合、y_scoreはより大きなラベルを持つクラスのスコアであると想定されています。</target>
        </trans-unit>
        <trans-unit id="e311afc7eeab469d8890dd7eea87d765736badbd" translate="yes" xml:space="preserve">
          <source>Target scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions (as returned by &amp;ldquo;decision_function&amp;rdquo; on some classifiers).</source>
          <target state="translated">ターゲットスコアは、確率推定、信頼値、または決定の非しきい値測定値（一部の分類子の「decision_function」によって返される）のいずれかです。</target>
        </trans-unit>
        <trans-unit id="8b0d9d264d1c088751e6e40c1e8e25db9f44f02f" translate="yes" xml:space="preserve">
          <source>Target scores. In the binary and multilabel cases, these can be either probability estimates or non-thresholded decision values (as returned by &lt;code&gt;decision_function&lt;/code&gt; on some classifiers). In the multiclass case, these must be probability estimates which sum to 1. The binary case expects a shape (n_samples,), and the scores must be the scores of the class with the greater label. The multiclass and multilabel cases expect a shape (n_samples, n_classes). In the multiclass case, the order of the class scores must correspond to the order of &lt;code&gt;labels&lt;/code&gt;, if provided, or else to the numerical or lexicographical order of the labels in &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">目標スコア。バイナリおよびマルチラベルの場合、これらは確率推定値または非しきい値決定値（一部の分類子の &lt;code&gt;decision_function&lt;/code&gt; によって返される）のいずれかになります。マルチクラスの場合、これらは合計が1になる確率推定値である必要があります。バイナリの場合は形状（n_samples、）が必要であり、スコアはラベルが大きいクラスのスコアである必要があります。マルチクラスおよびマルチラベルの場合は、形状（n_samples、n_classes）が必要です。マルチクラスの場合、クラススコアの順序は、提供されている場合は &lt;code&gt;labels&lt;/code&gt; の順序に対応する必要があります。そうでない場合は、 &lt;code&gt;y_true&lt;/code&gt; のラベルの数値または辞書式順序に対応する必要があります。</target>
        </trans-unit>
        <trans-unit id="1c1467eb9fce38ab3f431a143b7b4099a3d2d978" translate="yes" xml:space="preserve">
          <source>Target values</source>
          <target state="translated">目標値</target>
        </trans-unit>
        <trans-unit id="1eb29851ae3516c30efee3683f12f4c58d29d5ce" translate="yes" xml:space="preserve">
          <source>Target values (class labels in classification, real numbers in regression)</source>
          <target state="translated">目標値(分類ではクラスラベル、回帰では実数</target>
        </trans-unit>
        <trans-unit id="9236c7bb185e41917cc98485dd0c1b72938dc4f1" translate="yes" xml:space="preserve">
          <source>Target values (integers for classification, real numbers for regression).</source>
          <target state="translated">目標値(分類用の整数、回帰用の実数)。</target>
        </trans-unit>
        <trans-unit id="abfa5417a6d6ee53dab20f6c0ef952512e0950c9" translate="yes" xml:space="preserve">
          <source>Target values (integers)</source>
          <target state="translated">目標値(整数</target>
        </trans-unit>
        <trans-unit id="030d74b88e6ada2cc611aa05819c6875ad926cb6" translate="yes" xml:space="preserve">
          <source>Target values (integers). Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目標値（整数）。必要に応じてXのdtypeにキャストされます</target>
        </trans-unit>
        <trans-unit id="489913dd1ba6e89f6fe19c6ab73a6d0ba1572bbc" translate="yes" xml:space="preserve">
          <source>Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.</source>
          <target state="translated">目標値(分類では文字列または整数、回帰では実数)分類では、ラベルはクラスに対応していなければなりません。</target>
        </trans-unit>
        <trans-unit id="20f1907edd6deff55545e2c6878457953ca23f05" translate="yes" xml:space="preserve">
          <source>Target values in training data (also required for prediction)</source>
          <target state="translated">学習データの目標値(予測にも必要</target>
        </trans-unit>
        <trans-unit id="5698f85443295556a3231f89aa327fa20aab0ad9" translate="yes" xml:space="preserve">
          <source>Target values of shape = [n_samples] or [n_samples, n_outputs]</source>
          <target state="translated">形状の目標値=[n_samples]または[n_samples,n_outputs]の値</target>
        </trans-unit>
        <trans-unit id="da9e802f308bd36e270eb5bda433836f08ce2390" translate="yes" xml:space="preserve">
          <source>Target values, array of float values, shape = [n_samples]</source>
          <target state="translated">目標値、float 値の配列、形状=[n_samples]</target>
        </trans-unit>
        <trans-unit id="9d4acf064ddb5b23ed0c4bdf7cb1ed1c86e0cce4" translate="yes" xml:space="preserve">
          <source>Target values, must be binary</source>
          <target state="translated">目標値は、バイナリでなければなりません。</target>
        </trans-unit>
        <trans-unit id="3784ae1e62853f0d4899c1eb47f9d650c50e4292" translate="yes" xml:space="preserve">
          <source>Target values.</source>
          <target state="translated">目標値。</target>
        </trans-unit>
        <trans-unit id="7a264b43381dcd3fa803548587f56b48ebe73a21" translate="yes" xml:space="preserve">
          <source>Target values. All sparse matrices are converted to CSR before inverse transformation.</source>
          <target state="translated">目標値。すべての疎行列は、逆変換の前にCSRに変換されます。</target>
        </trans-unit>
        <trans-unit id="338b0342f37ab2a3243f471f75fbb6b8060759e1" translate="yes" xml:space="preserve">
          <source>Target values. Class labels must be an integer or float, or array-like objects of integer or float for multilabel classifications.</source>
          <target state="translated">対象となる値。クラスラベルは整数か浮動小数点数でなければならず、マルチラベルのクラス分類の場合は整数か浮動小数点数の配列状のオブジェクトでなければなりません。</target>
        </trans-unit>
        <trans-unit id="d95ddd0372c185ada4f873880d8cf72b3e972b79" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.</source>
          <target state="translated">目標値。2-dマトリックスは0と1のみを含むべきであり、マルチラベル分類を表す。</target>
        </trans-unit>
        <trans-unit id="7d68da7045b7713975074def112516b22e3d548e" translate="yes" xml:space="preserve">
          <source>Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.</source>
          <target state="translated">目標値。2-d マトリックスは 0 と 1 のみを含み、マルチラベル分類を表す。疎な行列は、CSR、CSC、COO、DOK、またはLILとすることができます。</target>
        </trans-unit>
        <trans-unit id="5ca333a3206ea1ae310cc995419dd5b579b0311c" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目標値。必要に応じてXのdtypeにキャストされます</target>
        </trans-unit>
        <trans-unit id="26a7504c7e3fd5624ea9f7504b20b691f54baa64" translate="yes" xml:space="preserve">
          <source>Target values. Will be cast to X&amp;rsquo;s dtype if necessary.</source>
          <target state="translated">目標値。必要に応じてXのdtypeにキャストされます。</target>
        </trans-unit>
        <trans-unit id="a73f8fffa45e4edde85ae5cfe9a7df8f5b0ddf64" translate="yes" xml:space="preserve">
          <source>Target vector (class labels).</source>
          <target state="translated">対象となるベクトル(クラスラベル).</target>
        </trans-unit>
        <trans-unit id="fbbf7212be6c75614582f7683105e9b145317ffe" translate="yes" xml:space="preserve">
          <source>Target vector relative to X</source>
          <target state="translated">X からの相対的な目標ベクトル</target>
        </trans-unit>
        <trans-unit id="9b9ad2408038efc60fe0697bee9336f5ceee389a" translate="yes" xml:space="preserve">
          <source>Target vector relative to X.</source>
          <target state="translated">Xからの相対的な目標ベクトル.</target>
        </trans-unit>
        <trans-unit id="cb81b6b3ab32530c4b31b59fded732e0bc1457db" translate="yes" xml:space="preserve">
          <source>Target vector.</source>
          <target state="translated">目標のベクトル。</target>
        </trans-unit>
        <trans-unit id="86747748812222a9af434d10160edcea63797259" translate="yes" xml:space="preserve">
          <source>Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.</source>
          <target state="translated">ターゲットベクターは、n_samplesはサンプル数、n_targetsは応答変数の数である。</target>
        </trans-unit>
        <trans-unit id="bb444a37f78059e3557a89e3cec7d30ee2a0e255" translate="yes" xml:space="preserve">
          <source>Target. Will be cast to X&amp;rsquo;s dtype if necessary</source>
          <target state="translated">目標。必要に応じてXのdtypeにキャストされます</target>
        </trans-unit>
        <trans-unit id="652ac2cbbafccc62d55637f20bfa949ef565ffbd" translate="yes" xml:space="preserve">
          <source>Target:</source>
          <target state="translated">Target:</target>
        </trans-unit>
        <trans-unit id="d35260a00f655f27edcc35a7eb16da44a4f671a6" translate="yes" xml:space="preserve">
          <source>Targets</source>
          <target state="translated">Targets</target>
        </trans-unit>
        <trans-unit id="bae347ef05fa5719d83860ee11ad8e50b4550a95" translate="yes" xml:space="preserve">
          <source>Targets for input data.</source>
          <target state="translated">入力データのターゲット。</target>
        </trans-unit>
        <trans-unit id="25e14b664fd8a2e3008eacd528868e3512f875a8" translate="yes" xml:space="preserve">
          <source>Targets for supervised learning.</source>
          <target state="translated">教師付き学習の目標。</target>
        </trans-unit>
        <trans-unit id="135d4c14ef59d437ba9b3977ff9548aa96a57252" translate="yes" xml:space="preserve">
          <source>Targets for supervised or &lt;code&gt;None&lt;/code&gt; for unsupervised.</source>
          <target state="translated">監視ありのターゲットまたは監視 &lt;code&gt;None&lt;/code&gt; ターゲット。</target>
        </trans-unit>
        <trans-unit id="e907b7e300146da06f6bd372dfec64398cc10d60" translate="yes" xml:space="preserve">
          <source>Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.</source>
          <target state="translated">スコアリングに使用されるターゲット。パイプラインの全ステップのラベル要件を満たす必要があります。</target>
        </trans-unit>
        <trans-unit id="12f7c88d38da9108a78eb595ada57372e18cdd00" translate="yes" xml:space="preserve">
          <source>Technically the Lasso model is optimizing the same objective function as the Elastic Net with &lt;code&gt;l1_ratio=1.0&lt;/code&gt; (no L2 penalty).</source>
          <target state="translated">技術的には、Lassoモデルは、 &lt;code&gt;l1_ratio=1.0&lt;/code&gt; （L2ペナルティなし）でElastic Netと同じ目的関数を最適化しています。</target>
        </trans-unit>
        <trans-unit id="7c21757d6dba7765c9b420762d607df44985a57d" translate="yes" xml:space="preserve">
          <source>Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.</source>
          <target state="translated">n=442人の糖尿病患者それぞれについて,10のベースライン変数,年齢,性別,体格指数,平均血圧,6つの血中血清測定値,およびベースラインから1年後の疾患進行の定量的な指標である反応を得た.</target>
        </trans-unit>
        <trans-unit id="faacbc438202f94eb51c4c27efecd77f5a804a90" translate="yes" xml:space="preserve">
          <source>Tenenbaum, J.B.; De Silva, V.; &amp;amp; Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)</source>
          <target state="translated">Tenenbaum、JB; デシルバ、V。＆Langford、JC非線形次元削減のためのグローバルな幾何学的フレームワーク。サイエンス290（5500）</target>
        </trans-unit>
        <trans-unit id="2a1358959d0f2f819085e4aa4680265c467cbf33" translate="yes" xml:space="preserve">
          <source>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">テネンハウス、M.(1998).PLS回帰:理論と実践。パリ:Editions Technic.</target>
        </trans-unit>
        <trans-unit id="0a268d2f62458299ec67330e170374c2cecaa669" translate="yes" xml:space="preserve">
          <source>Terms that were ignored because they either:</source>
          <target state="translated">どちらかの理由で無視されていた用語</target>
        </trans-unit>
        <trans-unit id="9f2d4d3a12b50c0b296af732b3fa3674c7292a32" translate="yes" xml:space="preserve">
          <source>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</source>
          <target state="translated">n_samples は標本数,n_features は特徴量の数.X_test は,フィットに使用されたデータと同じ分布(センタリングを含む)から引き出されたものと仮定されます.</target>
        </trans-unit>
        <trans-unit id="ed7e95a0302971bec5a032415d69927921186679" translate="yes" xml:space="preserve">
          <source>Test data to be transformed, must have the same number of features as the data used to train the model.</source>
          <target state="translated">変換されるテストデータは、モデルを訓練するために使用されるデータと同じ数の特徴量を持つ必要があります。</target>
        </trans-unit>
        <trans-unit id="65eaa1a409cbf0736a7b1da17a35a153fc9af91f" translate="yes" xml:space="preserve">
          <source>Test samples</source>
          <target state="translated">テストサンプル</target>
        </trans-unit>
        <trans-unit id="29446ed524d3e237184352cbcf6e1c5aaeb464e4" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator. Passing None as test samples gives the same result as passing real test samples, since DummyRegressor operates independently of the sampled observations.</source>
          <target state="translated">shape=(n_samples,n_features)または None でのテストサンプル。推定量によっては、これを代わりに事前計算されたカーネル行列とすることもできます。ダミーレグレッサーはサンプリングされたオブザベーションから独立して動作するので、テストサンプルとして None を渡すと、実際のテストサンプルを渡すのと同じ結果が得られます。</target>
        </trans-unit>
        <trans-unit id="12cad09d9d4837878fb37fd506e5f7fb71a801c9" translate="yes" xml:space="preserve">
          <source>Test samples with shape = (n_samples, n_features) or None. Passing None as test samples gives the same result as passing real test samples, since DummyClassifier operates independently of the sampled observations.</source>
          <target state="translated">shape=(n_samples,n_features)または None を持つテスト・サンプル。None をテスト・サンプルとして渡すと,DummyClassifier がサンプリングされたオブザベーションから独立して動作するので,実際のテスト・サンプルを渡すのと同じ結果が得られます.</target>
        </trans-unit>
        <trans-unit id="0c1d5bbb82f5cfc66b7e35e84179b02f4b13f8b1" translate="yes" xml:space="preserve">
          <source>Test samples.</source>
          <target state="translated">サンプルをテストします。</target>
        </trans-unit>
        <trans-unit id="bdec5057d32ebe97bd4c525fff2435009f4be0a0" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="translated">テストサンプル。推定量によっては、これが代わりに事前計算されたカーネル行列となる場合があります。</target>
        </trans-unit>
        <trans-unit id="a3c0fad25d001ac0a0589946fd03f6f0be795bec" translate="yes" xml:space="preserve">
          <source>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead, shape = (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.</source>
          <target state="translated">テストサンプル。shape=(n_samples,n_samples_fitted)ここで、n_samples_fitted は推定器のフィッティングで使用されるサンプル数です。</target>
        </trans-unit>
        <trans-unit id="7f9baccc70399290d29568f9812594e6335c4ae0" translate="yes" xml:space="preserve">
          <source>Test with permutations the significance of a classification score</source>
          <target state="translated">分類スコアの有意性を順列で検定する</target>
        </trans-unit>
        <trans-unit id="c67f73aee0c3dc1034cba236cfe8c8526d7a9123" translate="yes" xml:space="preserve">
          <source>Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.</source>
          <target state="translated">テキスト解析は機械学習アルゴリズムの主要な応用分野である。しかし、生データである記号の列は、アルゴリズムの多くが可変長の生のテキスト文書ではなく、固定サイズの数値特徴ベクトルを期待しているため、直接アルゴリズムに与えることはできません。</target>
        </trans-unit>
        <trans-unit id="990226708ed5e3f7319c13e5c3e22d22fd438346" translate="yes" xml:space="preserve">
          <source>Text is made of characters, but files are made of bytes. These bytes represent characters according to some &lt;em&gt;encoding&lt;/em&gt;. To work with text files in Python, their bytes must be &lt;em&gt;decoded&lt;/em&gt; to a character set called Unicode. Common encodings are ASCII, Latin-1 (Western Europe), KOI8-R (Russian) and the universal encodings UTF-8 and UTF-16. Many others exist.</source>
          <target state="translated">テキストは文字で構成されていますが、ファイルはバイトで構成されています。これらのバイトは、いくつかの&lt;em&gt;エンコーディング&lt;/em&gt;に従って文字を表します。Pythonでテキストファイルを操作するには、そのバイトをUnicodeと呼ばれる文字セットに&lt;em&gt;デコード&lt;/em&gt;する必要があります。一般的なエンコードは、ASCII、Latin-1（西ヨーロッパ）、KOI8-R（ロシア語）、およびユニバーサルエンコードUTF-8およびUTF-16です。他にもたくさんあります。</target>
        </trans-unit>
        <trans-unit id="2a2f9f7e298485c4a85bf6b791046a1b63087cf9" translate="yes" xml:space="preserve">
          <source>Text preprocessing, tokenizing and filtering of stopwords are all included in &lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt;, which builds a dictionary of features and transforms documents to feature vectors:</source>
          <target state="translated">ストップワードのテキストの前処理、トークン化、およびフィルタリングはすべて、&lt;a href=&quot;../../modules/generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;に含まれています。これは、特徴の辞書を構築し、ドキュメントを特徴ベクトルに変換します。</target>
        </trans-unit>
        <trans-unit id="81ed5011593c32dbca614ea281c1292f374dff62" translate="yes" xml:space="preserve">
          <source>Text summary of all the rules in the decision tree.</source>
          <target state="translated">デシジョンツリー内のすべてのルールのテキストサマリー。</target>
        </trans-unit>
        <trans-unit id="79142cb36f8945e4d341c82cf5dc060dc02c8f0f" translate="yes" xml:space="preserve">
          <source>Text summary of the precision, recall, F1 score for each class. Dictionary returned if output_dict is True. Dictionary has the following structure:</source>
          <target state="translated">各クラスの精度、リコール、F1スコアのテキストサマリー。output_dictがTrueの場合に返される辞書。辞書の構造は以下の通り。</target>
        </trans-unit>
        <trans-unit id="f042ff208f7aff2fdebc20ebdcfe3611681222ed" translate="yes" xml:space="preserve">
          <source>Tf is &amp;ldquo;n&amp;rdquo; (natural) by default, &amp;ldquo;l&amp;rdquo; (logarithmic) when &lt;code&gt;sublinear_tf=True&lt;/code&gt;. Idf is &amp;ldquo;t&amp;rdquo; when use_idf is given, &amp;ldquo;n&amp;rdquo; (none) otherwise. Normalization is &amp;ldquo;c&amp;rdquo; (cosine) when &lt;code&gt;norm='l2'&lt;/code&gt;, &amp;ldquo;n&amp;rdquo; (none) when &lt;code&gt;norm=None&lt;/code&gt;.</source>
          <target state="translated">Tfはデフォルトで「n」（自然）、 &lt;code&gt;sublinear_tf=True&lt;/code&gt; の場合は「l」（対数）です。Idfは、use_idfが指定されている場合は「t」、指定されていない場合は「n」（なし）です。正規化は、 &lt;code&gt;norm='l2'&lt;/code&gt; の場合は「c」（コサイン）、 &lt;code&gt;norm=None&lt;/code&gt; の場合は「n」（なし）です。</target>
        </trans-unit>
        <trans-unit id="97730bbab5383bbe19dd65de91be719c29295304" translate="yes" xml:space="preserve">
          <source>Tf means &lt;strong&gt;term-frequency&lt;/strong&gt; while tf&amp;ndash;idf means term-frequency times &lt;strong&gt;inverse document-frequency&lt;/strong&gt;: \(\text{tf-idf(t,d)}=\text{tf(t,d)} \times \text{idf(t)}\).</source>
          <target state="translated">Tfは&lt;strong&gt;用語の頻度&lt;/strong&gt;を意味し、tf&amp;ndash;idfは用語の頻度と&lt;strong&gt;ドキュメントの頻度の逆数を&lt;/strong&gt;意味し&lt;strong&gt;ます&lt;/strong&gt;：\（\ text {tf-idf（t、d）} = \ text {tf（t、d）} \ times \ text {idf （t）} \）。</target>
        </trans-unit>
        <trans-unit id="f1cc0d39fa695e88ce231644990ae2b503602ddb" translate="yes" xml:space="preserve">
          <source>Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.</source>
          <target state="translated">Tfは用語頻度を意味し、tf-idfは用語頻度×逆文書頻度を意味する。これは、情報検索における一般的な用語の重み付け方式であり、文書の分類にもよく使われています。</target>
        </trans-unit>
        <trans-unit id="771178a448f62a1d367a9045d97d08b26eb6869c" translate="yes" xml:space="preserve">
          <source>Tf-idf-weighted document-term matrix.</source>
          <target state="translated">Tf-idf加重文書項行列。</target>
        </trans-unit>
        <trans-unit id="daaa1c74bc4f107e3ab2cba2520cc29b4809af00" translate="yes" xml:space="preserve">
          <source>TfidfVectorizer uses a in-memory vocabulary (a python dict) to map the most frequent words to features indices and hence compute a word occurrence frequency (sparse) matrix. The word frequencies are then reweighted using the Inverse Document Frequency (IDF) vector collected feature-wise over the corpus.</source>
          <target state="translated">TfidfVectorizerは、最も頻繁に使われる単語を特徴指標にマッピングするために、メモリ内の語彙(python dict)を使用して、単語出現頻度(スパース)行列を計算します。単語出現頻度は、コーパス上で特徴的に収集された逆文書頻度(IDF)ベクトルを用いて再重み付けされます。</target>
        </trans-unit>
        <trans-unit id="2c1e749a66bcce49e10daf1b4a981af3bebb9284" translate="yes" xml:space="preserve">
          <source>That this function takes time at least quadratic in n_samples. For large datasets, it&amp;rsquo;s wise to set that parameter to a small value.</source>
          <target state="translated">この関数がn_samplesで少なくとも2次の時間を要すること。大きなデータセットの場合は、そのパラメーターを小さな値に設定するのが賢明です。</target>
        </trans-unit>
        <trans-unit id="fb20b5f965f5eb1a2ab7f1c1219e1e8adbfdfc00" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; heuristic is inspired by Logistic Regression in Rare Events Data, King, Zen, 2001.</source>
          <target state="translated">「バランスのとれた」ヒューリスティックは、レアイベントデータ、キング、禅、2001年のロジスティック回帰に触発されました。</target>
        </trans-unit>
        <trans-unit id="f4d692dace6b9f963c8a80ff6fb54e77b0936bf5" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;</source>
          <target state="translated">「バランス」モードでは、yの値を使用して、 &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として、入力データのクラス頻度に反比例する重みを自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="ef34b0ee7fbdfc2770447dcdf0759da38193f229" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">「バランス」モードでは、yの値を使用して、入力データのクラス頻度に反比例する重みを &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; として自動的に調整します。</target>
        </trans-unit>
        <trans-unit id="66610aa2288acbb0ecf69897c27cb9799d361b2f" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced&amp;rdquo; mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data: &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;.</source>
          <target state="translated">「バランス」モードでは、yの値を使用して、入力データのクラス頻度に反比例する重みを自動的に調整します： &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ef1bbf84c17d648e39cb34085672c6faaeb47082" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;balanced_subsample&amp;rdquo; mode is the same as &amp;ldquo;balanced&amp;rdquo; except that weights are computed based on the bootstrap sample for every tree grown.</source>
          <target state="translated">「balanced_subsample」モードは、重みがすべての成長したツリーのブートストラップサンプルに基づいて計算されることを除いて、「balanced」と同じです。</target>
        </trans-unit>
        <trans-unit id="ed963145b52986c215cb0664e22ee6755071701e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; is an optimization algorithm that approximates the Broyden&amp;ndash;Fletcher&amp;ndash;Goldfarb&amp;ndash;Shanno algorithm &lt;a href=&quot;#id28&quot; id=&quot;id23&quot;&gt;8&lt;/a&gt;, which belongs to quasi-Newton methods. The &amp;ldquo;lbfgs&amp;rdquo; solver is recommended for use for small data-sets but for larger datasets its performance suffers. &lt;a href=&quot;#id29&quot; id=&quot;id24&quot;&gt;9&lt;/a&gt;</source>
          <target state="translated">「lbfgs」は、準ニュートン法に属するBroyden&amp;ndash;Fletcher&amp;ndash;Goldfarb&amp;ndash;Shannoアルゴリズム&lt;a href=&quot;#id28&quot; id=&quot;id23&quot;&gt;8&lt;/a&gt;を近似する最適化アルゴリズムです。「lbfgs」ソルバーは、小さなデータセットに使用することをお勧めしますが、大きなデータセットにはパフォーマンスが低下します。&lt;a href=&quot;#id29&quot; id=&quot;id24&quot;&gt;9&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fd9d2df3102671da4d90b6a16223e62bcf13a40d" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo; solver is used by default for its robustness. For large datasets the &amp;ldquo;saga&amp;rdquo; solver is usually faster. For large dataset, you may also consider using &lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt;&lt;code&gt;SGDClassifier&lt;/code&gt;&lt;/a&gt; with &amp;lsquo;log&amp;rsquo; loss, which might be even faster but requires more tuning.</source>
          <target state="translated">「lbfgs」ソルバーは、その堅牢性のためにデフォルトで使用されます。大規模なデータセットの場合、通常、「佐賀」ソルバーの方が高速です。大規模なデータセットの場合は、「ログ」損失のある&lt;a href=&quot;generated/sklearn.linear_model.sgdclassifier#sklearn.linear_model.SGDClassifier&quot;&gt; &lt;code&gt;SGDClassifier&lt;/code&gt; の&lt;/a&gt;使用を検討することもできます。これはさらに高速になる可能性がありますが、より多くの調整が必要です。</target>
        </trans-unit>
        <trans-unit id="9570d1ba54b75e486c6a8fe70ab0af402d1567cc" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support L2 penalization and are found to converge faster for some high dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="translated">「lbfgs」、「sag」、および「newton-cg」ソルバーはL2ペナルティのみをサポートし、一部の高次元データではより速く収束することがわかっています。これらのソルバーを使用して &lt;code&gt;multi_class&lt;/code&gt; を「multinomial」に設定すると、真の多項ロジスティック回帰モデル&lt;a href=&quot;#id26&quot; id=&quot;id23&quot;&gt;[5]が&lt;/a&gt;学習されます。つまり、その確率推定値は、デフォルトの「one-vs-rest」設定よりも適切に調整されます。</target>
        </trans-unit>
        <trans-unit id="5921538cf9d0b305a04fb55e5723f201454da417" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;lbfgs&amp;rdquo;, &amp;ldquo;sag&amp;rdquo; and &amp;ldquo;newton-cg&amp;rdquo; solvers only support \(\ell_2\) regularization or no regularization, and are found to converge faster for some high-dimensional data. Setting &lt;code&gt;multi_class&lt;/code&gt; to &amp;ldquo;multinomial&amp;rdquo; with these solvers learns a true multinomial logistic regression model &lt;a href=&quot;#id25&quot; id=&quot;id20&quot;&gt;5&lt;/a&gt;, which means that its probability estimates should be better calibrated than the default &amp;ldquo;one-vs-rest&amp;rdquo; setting.</source>
          <target state="translated">「lbfgs」、「sag」、および「newton-cg」ソルバーは、\（\ ell_2 \）正則化のみをサポートするか、正則化をサポートせず、一部の高次元データではより速く収束することがわかります。これらのソルバーで &lt;code&gt;multi_class&lt;/code&gt; を「multinomial」に設定すると、真の多項ロジスティック回帰モデル&lt;a href=&quot;#id25&quot; id=&quot;id20&quot;&gt;5が&lt;/a&gt;学習されます。つまり、その確率推定値は、デフォルトの「one-vs-rest」設定よりも適切に調整する必要があります。</target>
        </trans-unit>
        <trans-unit id="c76cf618fdea0e603c8990092e5d960628df7c0c" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;new&amp;rdquo; data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model.</source>
          <target state="translated">「新しい」データは、入力データの線形結合で構成され、KDEモデルが与えられると確率的に重みが描画されます。</target>
        </trans-unit>
        <trans-unit id="6e028a15cea05a7ec04768381b1c3e0f7d725291" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses Stochastic Average Gradient descent &lt;a href=&quot;#id26&quot; id=&quot;id21&quot;&gt;6&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="translated">「サグ」ソルバーは、確率的平均勾配降下法&lt;a href=&quot;#id26&quot; id=&quot;id21&quot;&gt;6を使用し&lt;/a&gt;ます。サンプル数と特徴数の両方が多い場合、大規模なデータセットに対して他のソルバーよりも高速です。</target>
        </trans-unit>
        <trans-unit id="420229f24d72cfc948f72b9aaf53e46dfcb25b62" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;sag&amp;rdquo; solver uses a Stochastic Average Gradient descent &lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt;. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.</source>
          <target state="translated">「サグ」ソルバーは、確率的平均勾配降下法を使用します&lt;a href=&quot;#id27&quot; id=&quot;id24&quot;&gt;[6]&lt;/a&gt;。サンプル数とフィーチャ数の両方が大きい場合、大規模なデータセットの他のソルバーよりも高速です。</target>
        </trans-unit>
        <trans-unit id="2dbe4d8b05b25b3ecc8447f4c7fa6494b583e905" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id27&quot; id=&quot;id22&quot;&gt;7&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt;. This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports &lt;code&gt;penalty=&quot;elasticnet&quot;&lt;/code&gt;.</source>
          <target state="translated">「saga」ソルバー&lt;a href=&quot;#id27&quot; id=&quot;id22&quot;&gt;7&lt;/a&gt;は、「sag」の変形であり、滑らかでない &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; もサポートします。したがって、これはスパース多項ロジスティック回帰に最適なソルバーです。また、 &lt;code&gt;penalty=&quot;elasticnet&quot;&lt;/code&gt; をサポートする唯一のソルバーです。</target>
        </trans-unit>
        <trans-unit id="cf55bf4220bbf6e5ad8c38b76c827b53a1e3f193" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver &lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt; is a variant of &amp;ldquo;sag&amp;rdquo; that also supports the non-smooth &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; option. This is therefore the solver of choice for sparse multinomial logistic regression.</source>
          <target state="translated">「saga」ソルバー&lt;a href=&quot;#id28&quot; id=&quot;id25&quot;&gt;[7]&lt;/a&gt;は、「sag」の変形で、スムーズでない &lt;code&gt;penalty=&amp;rdquo;l1&amp;rdquo;&lt;/code&gt; オプションもサポートしています。したがって、これはスパース多項ロジスティック回帰に最適なソルバーです。</target>
        </trans-unit>
        <trans-unit id="77bf2f7306c562160b3a78c9199a57470ad6395e" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;saga&amp;rdquo; solver is often the best choice. The &amp;ldquo;liblinear&amp;rdquo; solver is used by default for historical reasons.</source>
          <target state="translated">「サガ」ソルバーは、多くの場合、最良の選択です。「liblinear」ソルバーは、歴史的な理由からデフォルトで使用されます。</target>
        </trans-unit>
        <trans-unit id="068bc43bd479e1422a1e2139866c2ca587dbb3ad" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;steepness&amp;rdquo; of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.</source>
          <target state="translated">偽陽性率を最小限にしながら真陽性率を最大化することが理想的であるため、ROC曲線の「急峻さ」も重要です。</target>
        </trans-unit>
        <trans-unit id="0eb5d5532023d8acbeeebff557bc347056c3c6a7" translate="yes" xml:space="preserve">
          <source>The &amp;ldquo;target&amp;rdquo; for this database is an integer from 0 to 39 indicating the identity of the person pictured; however, with only 10 examples per class, this relatively small dataset is more interesting from an unsupervised or semi-supervised perspective.</source>
          <target state="translated">このデータベースの「ターゲット」は、0から39までの整数で、写真に写っている人物のアイデンティティを示します。ただし、クラスあたりの例が10個しかないため、この比較的小さなデータセットは、監視なしまたは半監視の観点から見るとより興味深いものになります。</target>
        </trans-unit>
        <trans-unit id="457f2fe1e264c1b033671c931911858da10508e3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending on the shape of the training data.</source>
          <target state="translated">「自動」モードがデフォルトであり、トレーニングデータの形状に応じて2つのより安価なオプションを選択することを目的としています。</target>
        </trans-unit>
        <trans-unit id="6893a2ecba3f5b3ceba43b94c7037a23940a0678" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;auto&amp;rsquo; mode is the default and is intended to pick the cheaper option of the two depending upon the shape and format of the training data.</source>
          <target state="translated">「自動」モードがデフォルトであり、トレーニングデータの形状と形式に応じて、2つのオプションのうち安価なオプションを選択することを目的としています。</target>
        </trans-unit>
        <trans-unit id="c686d2e453ba3e5377730ccb9178f9e3372548ba" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;brute&amp;rsquo; method is a generic method that works with any estimator. It approximates the above integral by computing an average over the data &lt;code&gt;X&lt;/code&gt;:</source>
          <target state="translated">'brute'メソッドは、任意の推定量で機能する一般的なメソッドです。データ &lt;code&gt;X&lt;/code&gt; の平均を計算することにより、上記の積分を近似します。</target>
        </trans-unit>
        <trans-unit id="0f80449b3a36a9645d51b541d6ac4415080a7df2" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;cd&amp;rsquo; solver can only optimize the Frobenius norm. Due to the underlying non-convexity of NMF, the different solvers may converge to different minima, even when optimizing the same distance function.</source>
          <target state="translated">'cd'ソルバーは、フロベニウスノルムのみを最適化できます。同じ距離関数を最適化する場合でも、NMFの根底にある非凸性のため、異なるソルバーは異なる最小値に収束する可能性があります。</target>
        </trans-unit>
        <trans-unit id="370b11b6ae177f24cc2d42a049dda5c0d7e30775" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;eigen&amp;rsquo; solver is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classification and transform, and it supports shrinkage. However, the &amp;lsquo;eigen&amp;rsquo; solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.</source>
          <target state="translated">「固有値」ソルバーは、クラス散布間のクラス散布比への最適化に基づいています。分類と変換の両方に使用でき、収縮をサポートします。ただし、「固有値」ソルバーは共分散行列を計算する必要があるため、特徴の数が多い状況には適さない可能性があります。</target>
        </trans-unit>
        <trans-unit id="969c56b312ffc26d2c3d7a44ecbd20546b358e11" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see &lt;a href=&quot;sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; for a description.</source>
          <target state="translated">'log'損失は、確率的分類子であるロジスティック回帰を提供します。'modified_huber'は、外れ値と確率推定値に許容度をもたらすもう1つのスムーズな損失です。'squared_hinge'はヒンジに似ていますが、二乗的にペナルティが課せられます。「パーセプトロン」は、パーセプトロンアルゴリズムで使用される線形損失です。他の損失は回帰用に設計されていますが、分類にも役立ちます。説明については、&lt;a href=&quot;sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt; &lt;code&gt;SGDRegressor&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ccda076fda793672987d7568e3ca12c3047fb684" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;log&amp;rsquo; loss gives logistic regression, a probabilistic classifier. &amp;lsquo;modified_huber&amp;rsquo; is another smooth loss that brings tolerance to outliers as well as probability estimates. &amp;lsquo;squared_hinge&amp;rsquo; is like hinge but is quadratically penalized. &amp;lsquo;perceptron&amp;rsquo; is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see SGDRegressor for a description.</source>
          <target state="translated">「ログ」損失は、ロジスティック回帰、確率的分類子を提供します。'modified_huber'は、外れ値と確率推定に許容誤差をもたらすもう1つの滑らかな損失です。'squared_hinge'はヒンジに似ていますが、二次ペナルティが課されます。'perceptron'は、パーセプトロンアルゴリズムで使用される線形損失です。他の損失は回帰用に設計されていますが、分類にも役立ちます。説明については、SGDRegressorを参照してください。</target>
        </trans-unit>
        <trans-unit id="960f213c3988b3643a9995192d8dbe5d183a7506" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It needs to explicitly compute the covariance matrix \(\Sigma\), and supports shrinkage. This solver computes the coefficients \(\omega_k = \Sigma^{-1}\mu_k\) by solving for \(\Sigma \omega = \mu_k\), thus avoiding the explicit computation of the inverse \(\Sigma^{-1}\).</source>
          <target state="translated">'lsqr'ソルバーは、分類に対してのみ機能する効率的なアルゴリズムです。共分散行列\（\ Sigma \）を明示的に計算する必要があり、収縮をサポートします。このソルバーは、\（\ Sigma \ omega = \ mu_k \）を解くことにより、係数\（\ omega_k = \ Sigma ^ {-1} \ mu_k \）を計算します。これにより、逆\（\ Sigma ^ { -1} \）。</target>
        </trans-unit>
        <trans-unit id="5302138e8a256151a982f3c737747f8db1fec2f7" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;lsqr&amp;rsquo; solver is an efficient algorithm that only works for classification. It supports shrinkage.</source>
          <target state="translated">'lsqr'ソルバーは、分類に対してのみ機能する効率的なアルゴリズムです。縮みに対応しています。</target>
        </trans-unit>
        <trans-unit id="920a5500dd530a18d71ed258f87f05c8340a0987" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation, or no regularization. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the &amp;lsquo;saga&amp;rsquo; solver.</source>
          <target state="translated">'newton-cg'、 'sag'、および 'lbfgs'ソルバーは、主定式化によるL2正則化のみをサポートするか、正則化をサポートしません。'liblinear'ソルバーは、L1とL2の両方の正則化をサポートし、L2ペナルティのみの二重定式化を行います。Elastic-Net正則化は、「saga」ソルバーでのみサポートされます。</target>
        </trans-unit>
        <trans-unit id="e2a91334301a1b93c477cd479a707ce044fefdf3" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;newton-cg&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, and &amp;lsquo;lbfgs&amp;rsquo; solvers support only L2 regularization with primal formulation. The &amp;lsquo;liblinear&amp;rsquo; solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.</source>
          <target state="translated">'newton-cg'、 'sag'、および 'lbfgs'ソルバーは、主定式化によるL2正則化のみをサポートします。'liblinear'ソルバーはL1とL2の両方の正則化をサポートし、L2ペナルティのみのデュアル定式化を行います。</target>
        </trans-unit>
        <trans-unit id="f2d81bdc600d48b918368b0b02059bc57b808de5" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;recursion&amp;rsquo; method is faster than the &amp;lsquo;brute&amp;rsquo; method, but it is only supported by some tree-based estimators. It is computed as follows. For a given point \(x_S\), a weighted tree traversal is performed: if a split node involves a &amp;lsquo;target&amp;rsquo; feature, the corresponding left or right branch is followed; otherwise both branches are followed, each branch being weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all the visited leaves values.</source>
          <target state="translated">'recursion'メソッドは 'brute'メソッドよりも高速ですが、一部のツリーベースの推定量でのみサポートされています。次のように計算されます。指定されたポイント\（x_S \）に対して、重み付きツリー走査が実行されます。分割ノードに「ターゲット」機能が含まれる場合、対応する左または右の分岐が続きます。それ以外の場合は、両方のブランチが続き、各ブランチは、そのブランチに入ったトレーニングサンプルの割合によって重み付けされます。最後に、部分的な依存関係は、訪問したすべての葉の値の加重平均によって与えられます。</target>
        </trans-unit>
        <trans-unit id="ade2e6c6872bcfb8e63408411f739881d7395764" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;squared_loss&amp;rsquo; refers to the ordinary least squares fit. &amp;lsquo;huber&amp;rsquo; modifies &amp;lsquo;squared_loss&amp;rsquo; to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. &amp;lsquo;epsilon_insensitive&amp;rsquo; ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. &amp;lsquo;squared_epsilon_insensitive&amp;rsquo; is the same but becomes squared loss past a tolerance of epsilon.</source>
          <target state="translated">「squared_loss」は、通常の最小二乗法を指します。'huber'は、 'squared_loss'を変更して、イプシロンの距離を過ぎると二乗損失から線形損失に切り替えることで、外れ値の修正に重点を置きません。'epsilon_insensitive'は、イプシロンより小さいエラーを無視し、それを超えて線形になります。これはSVRで使用される損失関数です。'squared_epsilon_insensitive'は同じですが、イプシロンの許容誤差を超えると二乗損失になります。</target>
        </trans-unit>
        <trans-unit id="d846a2b9506766851ba4d72a28fde6b068825be1" translate="yes" xml:space="preserve">
          <source>The &amp;lsquo;svd&amp;rsquo; solver is the default solver used for &lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;, and it is the only available solver for &lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;. It can perform both classification and transform (for LDA). As it does not rely on the calculation of the covariance matrix, the &amp;lsquo;svd&amp;rsquo; solver may be preferable in situations where the number of features is large. The &amp;lsquo;svd&amp;rsquo; solver cannot be used with shrinkage. For QDA, the use of the SVD solver relies on the fact that the covariance matrix \(\Sigma_k\) is, by definition, equal to \(\frac{1}{n - 1} X_k^tX_k = V S^2 V^t\) where \(V\) comes from the SVD of the (centered) matrix: \(X_k = U S V^t\). It turns out that we can compute the log-posterior above without having to explictly compute \(\Sigma\): computing \(S\) and \(V\) via the SVD of \(X\) is enough. For LDA, two SVDs are computed: the SVD of the centered input matrix \(X\) and the SVD of the class-wise mean vectors.</source>
          <target state="translated">'svd'ソルバーは、&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;に使用されるデフォルトのソルバーであり、&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;QuadraticDiscriminantAnalysis&lt;/code&gt; で&lt;/a&gt;使用できる唯一のソルバーです。。分類と変換（LDAの場合）の両方を実行できます。共分散行列の計算に依存しないため、特徴の数が多い状況では「svd」ソルバーが適している場合があります。 'svd'ソルバーは収縮とともに使用できません。 QDAの場合、SVDソルバーの使用は、共分散行列\（\ Sigma_k \）が定義上\（\ frac {1} {n-1} X_k ^ tX_k = VS ^ 2Vに等しいという事実に依存しています。 ^ t \）ここで、\（V \）は（中央の）行列のSVDから取得されます：\（X_k = USV ^ t \）。 \（\ Sigma \）を明示的に計算しなくても、上記の対数事後確率を計算できることがわかります。\（X \）のSVDを介して\（S \）と\（V \）を計算するだけで十分です。 LDAの場合、2つのSVDが計算されます。中央の入力行列\（X \）のSVDとクラスごとの平均ベクトルのSVDです。</target>
        </trans-unit>
        <trans-unit id="388443bd992c152f7c80a788085a15982e280e0a" translate="yes" xml:space="preserve">
          <source>The (scaled) interquartile range for each feature in the training set.</source>
          <target state="translated">訓練セットの各特徴の(スケーリングされた)クォリティ間の範囲。</target>
        </trans-unit>
        <trans-unit id="1db16517be9cf545f06172e2c55188fa78cfa7fa" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new set of features</source>
          <target state="translated">（時には驚くべき）観察は、これが&lt;em&gt;まだ線形モデルであるということ&lt;/em&gt;です：これを見るには、新しい特徴のセットを作成することを想像してください</target>
        </trans-unit>
        <trans-unit id="b3533a4edec1fdb05f12a2a421dc320606ca77c6" translate="yes" xml:space="preserve">
          <source>The (sometimes surprising) observation is that this is &lt;em&gt;still a linear model&lt;/em&gt;: to see this, imagine creating a new variable</source>
          <target state="translated">（時には意外な）観察は、これが&lt;em&gt;まだ線形モデルである&lt;/em&gt;ということです。これを確認するには、新しい変数を作成することを想像してください。</target>
        </trans-unit>
        <trans-unit id="ae37fbc1863417aba870f086fd7dcb7d12932667" translate="yes" xml:space="preserve">
          <source>The (x,y) position of the lower-left corner, in degrees</source>
          <target state="translated">左下隅の (x,y)位置を度単位で指定します。</target>
        </trans-unit>
        <trans-unit id="bcd6ca42c3472afbe27069a62710b5c531496d9b" translate="yes" xml:space="preserve">
          <source>The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper &amp;ldquo;Newsweeder: Learning to filter netnews,&amp;rdquo; though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.</source>
          <target state="translated">20ニュースグループのデータセットは、約20,000のニュースグループドキュメントのコレクションであり、20の異なるニュースグループ間で（ほぼ）均等に分割されます。私たちの知る限りでは、このコレクションは元々ケンラングによって収集されました。おそらく彼の論文「Newsweeder：Learning to filter netnews」のために、彼はこのコレクションについて明示的に言及していません。20のニュースグループコレクションは、テキスト分類やテキストクラスタリングなどの機械学習技術のテキストアプリケーションでの実験用の人気のあるデータセットになっています。</target>
        </trans-unit>
        <trans-unit id="4b2a042059fffe007deb9ebabf02d8062c1e6bda" translate="yes" xml:space="preserve">
          <source>The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.</source>
          <target state="translated">20 のニュースグループデータセットは、20 のトピックに関する約 18,000 件のニュースグループの投稿から構成されており、2 つのサブセットに分割されています:1 つはトレーニング(または開発)用、もう 1 つはテスト(またはパフォーマンス評価)用です。トレーニングセットとテストセットの分割は、特定の日付の前後に投稿されたメッセージに基づいています。</target>
        </trans-unit>
        <trans-unit id="6f66371b5ad2b199bde3ecde676da8dfe31ce717" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#ht2001&quot; id=&quot;id25&quot;&gt;[HT2001]&lt;/a&gt; multiclass AUC metric can be extended to be weighted by the prevalence:</source>
          <target state="translated">&lt;a href=&quot;#ht2001&quot; id=&quot;id25&quot;&gt;【HT2001】&lt;/a&gt;多クラスAUCメトリックは、有病率で重み付けするように拡張することができます。</target>
        </trans-unit>
        <trans-unit id="c380ecdb017c04631da3ca1753b6ddf07ce8267f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.cluster&quot;&gt;&lt;code&gt;sklearn.cluster&lt;/code&gt;&lt;/a&gt; module gathers popular unsupervised clustering algorithms.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.cluster&quot;&gt; &lt;code&gt;sklearn.cluster&lt;/code&gt; の&lt;/a&gt;モジュールは、人気の教師なしクラスタリングアルゴリズムを収集します。</target>
        </trans-unit>
        <trans-unit id="6a798b177e574d6ff4ac12be7b93e3b8f8d74b71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.covariance&quot;&gt;&lt;code&gt;sklearn.covariance&lt;/code&gt;&lt;/a&gt; module includes methods and algorithms to robustly estimate the covariance of features given a set of points. The precision matrix defined as the inverse of the covariance is also estimated. Covariance estimation is closely related to the theory of Gaussian Graphical Models.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.covariance&quot;&gt; &lt;code&gt;sklearn.covariance&lt;/code&gt; の&lt;/a&gt;モジュールは、ロバスト点の集合が与えられた特徴の共分散を推定する方法およびアルゴリズムを含んでいます。共分散の逆数として定義された精度行列も推定されます。共分散推定は、ガウスグラフィカルモデルの理論と密接に関連しています。</target>
        </trans-unit>
        <trans-unit id="d1230decfda989b60168bc88df7b70ef79122b2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.datasets&quot;&gt;&lt;code&gt;sklearn.datasets&lt;/code&gt;&lt;/a&gt; module includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.datasets&quot;&gt; &lt;code&gt;sklearn.datasets&lt;/code&gt; の&lt;/a&gt;モジュールをロードし、人気のある参照データセットをフェッチする方法を含む負荷データセットにユーティリティを含みます。また、いくつかの人工データジェネレーターも備えています。</target>
        </trans-unit>
        <trans-unit id="94bdb0abc615359801b0dde8f5ed432fa774aae6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.decomposition&quot;&gt;&lt;code&gt;sklearn.decomposition&lt;/code&gt;&lt;/a&gt; module includes matrix decomposition algorithms, including among others PCA, NMF or ICA. Most of the algorithms of this module can be regarded as dimensionality reduction techniques.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.decomposition&quot;&gt; &lt;code&gt;sklearn.decomposition&lt;/code&gt; の&lt;/a&gt;モジュールは、行列分解アルゴリズムを含む他のPCA、NMFまたはICAの間を含みます。このモジュールのアルゴリズムのほとんどは、次元削減手法と見なすことができます。</target>
        </trans-unit>
        <trans-unit id="cce83af2900332bbe995457713d2e3977e6cea91" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes ensemble-based methods for classification, regression and anomaly detection.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;モジュールは、分類、回帰および異常検出のためのアンサンブルに基づく方法を含みます。</target>
        </trans-unit>
        <trans-unit id="a3b34965d608c8571221686c4eaa7dd2128cda34" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.exceptions&quot;&gt;&lt;code&gt;sklearn.exceptions&lt;/code&gt;&lt;/a&gt; module includes all custom warnings and error classes used across scikit-learn.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.exceptions&quot;&gt; &lt;code&gt;sklearn.exceptions&lt;/code&gt; の&lt;/a&gt;モジュールは、学ぶscikit全体で使用されるすべてのカスタム警告とエラークラスが含まれています。</target>
        </trans-unit>
        <trans-unit id="88149e0dc35a9af4a24d012611fba0cc883c2d66" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.experimental&quot;&gt;&lt;code&gt;sklearn.experimental&lt;/code&gt;&lt;/a&gt; module provides importable modules that enable the use of experimental features or estimators.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.experimental&quot;&gt; &lt;code&gt;sklearn.experimental&lt;/code&gt; &lt;/a&gt;モジュールは、実験的な特徴または推定器の使用を可能にインポート可能なモジュールを提供します。</target>
        </trans-unit>
        <trans-unit id="953e85b8304fe86126d3f8d4d49e2c347def818a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module deals with feature extraction from raw data. It currently includes methods to extract features from text and images.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; の&lt;/a&gt;モジュールは、生データからの特徴抽出を扱います。現在、テキストと画像から特徴を抽出するメソッドが含まれています。</target>
        </trans-unit>
        <trans-unit id="2ff97b1fa019f5f400e3468860cd96aea04f63dc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt;&lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to extract features from images.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.feature_extraction.image&quot;&gt; &lt;code&gt;sklearn.feature_extraction.image&lt;/code&gt; の&lt;/a&gt;サブモジュールのギャザーユーティリティは、画像から特徴を抽出します。</target>
        </trans-unit>
        <trans-unit id="5fb7f21374928a29d973d39c8eed205507941559" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt; submodule gathers utilities to build feature vectors from text documents.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.feature_extraction.text&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; &lt;/a&gt;テキスト文書から特徴ベクトルを構築するためのサブモジュールが収集ユーティリティ。</target>
        </trans-unit>
        <trans-unit id="f8894b12541a4b0b591ccbf9c1c5e42bf4d0c13b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt;&lt;code&gt;sklearn.feature_selection&lt;/code&gt;&lt;/a&gt; module implements feature selection algorithms. It currently includes univariate filter selection methods and the recursive feature elimination algorithm.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.feature_selection&quot;&gt; &lt;code&gt;sklearn.feature_selection&lt;/code&gt; の&lt;/a&gt;モジュールの実装は、選択アルゴリズムを備えています。現在、一変量フィルターの選択方法と再帰的特徴除去アルゴリズムが含まれています。</target>
        </trans-unit>
        <trans-unit id="af392a06a08e896e0c1f9a845ceba81c0151ed14" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt;&lt;code&gt;sklearn.gaussian_process&lt;/code&gt;&lt;/a&gt; module implements Gaussian Process based regression and classification.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.gaussian_process&quot;&gt; &lt;code&gt;sklearn.gaussian_process&lt;/code&gt; &lt;/a&gt;回帰および分類をベースモジュールが実装ガウスプロセス。</target>
        </trans-unit>
        <trans-unit id="385213737ec5d4067fe933c56afb4e9039eb2d7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module includes tools for model inspection.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.inspection&quot;&gt; &lt;code&gt;sklearn.inspection&lt;/code&gt; の&lt;/a&gt;モジュールは、モデル検査のためのツールが含まれています。</target>
        </trans-unit>
        <trans-unit id="e25959a779b184ae02a906c2808f68686c73aab5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt;&lt;code&gt;sklearn.kernel_approximation&lt;/code&gt;&lt;/a&gt; module implements several approximate kernel feature maps base on Fourier transforms.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.kernel_approximation&quot;&gt; &lt;code&gt;sklearn.kernel_approximation&lt;/code&gt; の&lt;/a&gt;モジュールが実装いくつかのおおよそのカーネル機能では、フーリエ変換のベースをマッピングします。</target>
        </trans-unit>
        <trans-unit id="311a58f7516f87097f4b239ae388620a5fb8155d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements a variety of linear models.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; の&lt;/a&gt;モジュールは、線形モデルの多様性を実装しています。</target>
        </trans-unit>
        <trans-unit id="cf3dc31fd9ef458aef6de4af32bf51a7e61106a1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.linear_model&quot;&gt;&lt;code&gt;sklearn.linear_model&lt;/code&gt;&lt;/a&gt; module implements generalized linear models. It includes Ridge regression, Bayesian Regression, Lasso and Elastic Net estimators computed with Least Angle Regression and coordinate descent. It also implements Stochastic Gradient Descent related algorithms.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.linear_model&quot;&gt; &lt;code&gt;sklearn.linear_model&lt;/code&gt; の&lt;/a&gt;モデル線形一般化モジュールが実装。これには、リッジ回帰、ベイジアン回帰、なげなわ、および最小角回帰と座標降下で計算されたElastic Net推定量が含まれます。また、確率的勾配降下法に関連するアルゴリズムも実装しています。</target>
        </trans-unit>
        <trans-unit id="75e43c84de91a4a1d643ca88db0beef9e86494b8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.manifold&quot;&gt;&lt;code&gt;sklearn.manifold&lt;/code&gt;&lt;/a&gt; module implements data embedding techniques.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.manifold&quot;&gt; &lt;code&gt;sklearn.manifold&lt;/code&gt; &lt;/a&gt;モジュールの実装データが技術を埋め込みます。</target>
        </trans-unit>
        <trans-unit id="f55aa3d6c230d41fe62ec5929fa59e00645b5d62" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module includes score functions, performance metrics and pairwise metrics and distance computations.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; の&lt;/a&gt;モジュールは、スコア機能、パフォーマンス・メトリックとペアワイズ・メトリックおよび距離の計算を含みます。</target>
        </trans-unit>
        <trans-unit id="90553131dabe004a613ea2c87be35b6b6db9a1ae" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt;&lt;code&gt;sklearn.metrics.cluster&lt;/code&gt;&lt;/a&gt; submodule contains evaluation metrics for cluster analysis results. There are two forms of evaluation:</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.metrics.cluster&quot;&gt; &lt;code&gt;sklearn.metrics.cluster&lt;/code&gt; の&lt;/a&gt;サブモジュールは、クラスタ解析結果の評価指標が含まれています。評価には2つの形式があります。</target>
        </trans-unit>
        <trans-unit id="537333336506a029d4e76c0c5320f3e14636c908" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.mixture&quot;&gt;&lt;code&gt;sklearn.mixture&lt;/code&gt;&lt;/a&gt; module implements mixture modeling algorithms.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.mixture&quot;&gt; &lt;code&gt;sklearn.mixture&lt;/code&gt; &lt;/a&gt;アルゴリズムをモデル化モジュールが実装混合物。</target>
        </trans-unit>
        <trans-unit id="1b9bcfe9136ee1328197e574e66457c49aa39ded" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt;&lt;code&gt;sklearn.naive_bayes&lt;/code&gt;&lt;/a&gt; module implements Naive Bayes algorithms. These are supervised learning methods based on applying Bayes&amp;rsquo; theorem with strong (naive) feature independence assumptions.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.naive_bayes&quot;&gt; &lt;code&gt;sklearn.naive_bayes&lt;/code&gt; は&lt;/a&gt;実装ナイーブベイズアルゴリズムをモジュール。これらは、ベイズの定理を強力な（素朴な）特徴の独立性の仮定に適用することに基づいた教師あり学習方法です。</target>
        </trans-unit>
        <trans-unit id="31da4b6c2407f749b7e6e441bc1101265b243a97" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neighbors&quot;&gt;&lt;code&gt;sklearn.neighbors&lt;/code&gt;&lt;/a&gt; module implements the k-nearest neighbors algorithm.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.neighbors&quot;&gt; &lt;code&gt;sklearn.neighbors&lt;/code&gt; は&lt;/a&gt;実装にk近傍法をモジュール。</target>
        </trans-unit>
        <trans-unit id="637db5b82af4c4775ad8c11b2cc086c407ac4adc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.neural_network&quot;&gt;&lt;code&gt;sklearn.neural_network&lt;/code&gt;&lt;/a&gt; module includes models based on neural networks.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.neural_network&quot;&gt; &lt;code&gt;sklearn.neural_network&lt;/code&gt; の&lt;/a&gt;モジュールは、ニューラルネットワークに基づくモデルが含まれています。</target>
        </trans-unit>
        <trans-unit id="97c84f48ddcbce9eff5bb423de61ca9bed7742a5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline&lt;/code&gt;&lt;/a&gt; module implements utilities to build a composite estimator, as a chain of transforms and estimators.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline&lt;/code&gt; &lt;/a&gt;モジュール実装ユーティリティは、変換及び推定のチェーンとして、複合推定を構築します。</target>
        </trans-unit>
        <trans-unit id="3e4a3abf94a63259dfe9d5546d6b613a02821c2d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization and imputation methods.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt; &lt;code&gt;sklearn.preprocessing&lt;/code&gt; &lt;/a&gt;モジュールは、スケーリング、センタリング、正規化、二値化と代入方法を含みます。</target>
        </trans-unit>
        <trans-unit id="f8f509d37a71bbf7a86f10aff8bf2d2fdd437066" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt;&lt;code&gt;sklearn.preprocessing&lt;/code&gt;&lt;/a&gt; module includes scaling, centering, normalization, binarization methods.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.preprocessing&quot;&gt; &lt;code&gt;sklearn.preprocessing&lt;/code&gt; &lt;/a&gt;モジュールは、スケーリング、センタリング、正規化、二値化方法を含みます。</target>
        </trans-unit>
        <trans-unit id="5fd91efb13a21a364a66a195be3f60dbc3429cc3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt;&lt;code&gt;sklearn.semi_supervised&lt;/code&gt;&lt;/a&gt; module implements semi-supervised learning algorithms. These algorithms utilized small amounts of labeled data and large amounts of unlabeled data for classification tasks. This module includes Label Propagation.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.semi_supervised&quot;&gt; &lt;code&gt;sklearn.semi_supervised&lt;/code&gt; &lt;/a&gt;モジュールの実装は、半教師学習アルゴリズム。これらのアルゴリズムは、分類タスクに少量のラベル付きデータと大量のラベルなしデータを利用しました。このモジュールには、ラベル伝播が含まれています。</target>
        </trans-unit>
        <trans-unit id="6b1e5de562db4c7ae4499c2a4fcb3f75a3027318" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.svm&quot;&gt;&lt;code&gt;sklearn.svm&lt;/code&gt;&lt;/a&gt; module includes Support Vector Machine algorithms.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.svm&quot;&gt; &lt;code&gt;sklearn.svm&lt;/code&gt; の&lt;/a&gt;モジュールは、サポートベクトルマシンアルゴリズムを含んでいます。</target>
        </trans-unit>
        <trans-unit id="ef3c16856f883650f7c10c3b8b62a045804fc7da" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.tree&quot;&gt;&lt;code&gt;sklearn.tree&lt;/code&gt;&lt;/a&gt; module includes decision tree-based models for classification and regression.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.tree&quot;&gt; &lt;code&gt;sklearn.tree&lt;/code&gt; &lt;/a&gt;モジュールは、分類および回帰の決定ツリーベースのモデルを含んでいます。</target>
        </trans-unit>
        <trans-unit id="fd392963cb16a5b60813f22af8246fa4065eb565" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;#module-sklearn.utils&quot;&gt;&lt;code&gt;sklearn.utils&lt;/code&gt;&lt;/a&gt; module includes various utilities.</source>
          <target state="translated">&lt;a href=&quot;#module-sklearn.utils&quot;&gt; &lt;code&gt;sklearn.utils&lt;/code&gt; の&lt;/a&gt;モジュールは、様々なユーティリティを含みます。</target>
        </trans-unit>
        <trans-unit id="9c614be243d558a71ca4ede548ecf4767e4adc7c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;simple example on this dataset&lt;/a&gt; illustrates how starting from the original problem one can shape the data for consumption in scikit-learn.</source>
          <target state="translated">&lt;a href=&quot;../../auto_examples/classification/plot_digits_classification#sphx-glr-auto-examples-classification-plot-digits-classification-py&quot;&gt;このデータセット&lt;/a&gt;の簡単な例は、元の問題から始めて、scikit-learnで使用するデータをどのように形成できるかを示しています。</target>
        </trans-unit>
        <trans-unit id="1173339ea4209f3d2d9f369da23b0882a1bab947" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; estimator was entirely re-worked, and it is now significantly faster and more stable. In addition, the Elkan algorithm is now compatible with sparse matrices. The estimator uses OpenMP based parallelism instead of relying on joblib, so the &lt;code&gt;n_jobs&lt;/code&gt; parameter has no effect anymore. For more details on how to control the number of threads, please refer to our &lt;a href=&quot;../../modules/computing#parallelism&quot;&gt;Parallelism&lt;/a&gt; notes.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt;推定再働い完全であり、それは今非常に高速で、より安定しました。さらに、Elkanアルゴリズムはスパース行列と互換性があります。Estimatorはjoblibに依存する代わりにOpenMPベースの並列処理を使用するため、 &lt;code&gt;n_jobs&lt;/code&gt; パラメーターは機能しなくなります。スレッド数を制御する方法の詳細については、&lt;a href=&quot;../../modules/computing#parallelism&quot;&gt;並列処理&lt;/a&gt;に関する注意事項を参照してください。</target>
        </trans-unit>
        <trans-unit id="30870f8f1c3b8d652d87325d159164cb4897186f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt;&lt;code&gt;ensemble.HistGradientBoostingRegressor&lt;/code&gt;&lt;/a&gt; now have native support for missing values (NaNs). This means that there is no need for imputing data when training or predicting.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingclassifier#sklearn.ensemble.HistGradientBoostingClassifier&quot;&gt; &lt;code&gt;ensemble.HistGradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;../../modules/generated/sklearn.ensemble.histgradientboostingregressor#sklearn.ensemble.HistGradientBoostingRegressor&quot;&gt; &lt;code&gt;ensemble.HistGradientBoostingRegressor&lt;/code&gt; は&lt;/a&gt;今、欠損値（NaNを）のネイティブサポートを持っています。これは、トレーニングや予測の際にデータを代入する必要がないことを意味します。</target>
        </trans-unit>
        <trans-unit id="d52c41feb33f6dcb3543db8b050b747b486d3d88" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt; class is very flexible - it can be used with a variety of estimators to do round-robin regression, treating every variable as an output in turn.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt; の&lt;/a&gt;クラスは非常に柔軟である-順番に出力としてすべての変数を処理し、ラウンドロビン回帰を行うために推定の様々な使用することができます。</target>
        </trans-unit>
        <trans-unit id="20080456681e7e51efd596990b6fe9c5442d5451" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;inspection.permutation_importance&lt;/code&gt;&lt;/a&gt; can be used to get an estimate of the importance of each feature, for any fitted estimator:</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;inspection.permutation_importance&lt;/code&gt; は、&lt;/a&gt;任意のフィット推定のために、各機能の重要性の推定値を取得するために使用することができます。</target>
        </trans-unit>
        <trans-unit id="32ce39f7d5e0bf9b7a13f0705f1c0e1a4677070b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; function returns a &lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay&quot;&gt;&lt;code&gt;PartialDependenceDisplay&lt;/code&gt;&lt;/a&gt; object that can be used for plotting without needing to recalculate the partial dependence. In this example, we show how to plot partial dependence plots and how to quickly customize the plot with the visualization API.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt; &lt;code&gt;plot_partial_dependence&lt;/code&gt; の&lt;/a&gt;関数は返す&lt;a href=&quot;../../modules/generated/sklearn.inspection.partialdependencedisplay#sklearn.inspection.PartialDependenceDisplay&quot;&gt; &lt;code&gt;PartialDependenceDisplay&lt;/code&gt; の&lt;/a&gt;部分的依存性を再計算する必要なしにプロットするために使用することができるオブジェクト。この例では、部分的な依存関係のプロットをプロットする方法と、視覚化APIを使用してプロットをすばやくカスタマイズする方法を示します。</target>
        </trans-unit>
        <trans-unit id="fa56488b2914a0f1ce166cbc607c029c9e711d0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;sklearn.metrics.mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; depends on a &lt;code&gt;power&lt;/code&gt; parameter. As we do not know the true value of the &lt;code&gt;power&lt;/code&gt; parameter, we here compute the mean deviances for a grid of possible values, and compare the models side by side, i.e. we compare them at identical values of &lt;code&gt;power&lt;/code&gt;. Ideally, we hope that one model will be consistently better than the other, regardless of &lt;code&gt;power&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt; &lt;code&gt;sklearn.metrics.mean_tweedie_deviance&lt;/code&gt; は&lt;/a&gt;に依存し &lt;code&gt;power&lt;/code&gt; パラメータ。 &lt;code&gt;power&lt;/code&gt; パラメータの真の値がわからないため、ここでは、可能な値のグリッドの平均逸脱度を計算し、モデルを並べて比較します。つまり、同じ &lt;code&gt;power&lt;/code&gt; 値でモデルを比較します。理想的には、 &lt;code&gt;power&lt;/code&gt; に関係なく、一方のモデルがもう一方のモデルよりも一貫して優れていることを願っています。</target>
        </trans-unit>
        <trans-unit id="14b4e05e10f859ded14445d95cdfc3e13fffcfe1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;sklearn.metrics.roc_auc_score&lt;/code&gt;&lt;/a&gt; function can be used for multi-class classification. The multi-class One-vs-One scheme compares every unique pairwise combination of classes. In this section, we calculate the AUC using the OvR and OvO schemes. We report a macro average, and a prevalence-weighted average.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;sklearn.metrics.roc_auc_score&lt;/code&gt; の&lt;/a&gt;機能は、マルチクラス分類のために使用することができます。マルチクラスのOne-vs-Oneスキームは、クラスの一意のペアごとの組み合わせをすべて比較します。このセクションでは、OvRおよびOvOスキームを使用してAUCを計算します。マクロ平均と有病率加重平均を報告します。</target>
        </trans-unit>
        <trans-unit id="4f876970ad7209ceedd7d12cc65c7506766be528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt;&lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt;&lt;/a&gt; is known to be sensitive to outliers and thus does not perform very well for outlier detection. This estimator is best suited for novelty detection when the training set is not contaminated by outliers. That said, outlier detection in high-dimension, or without any assumptions on the distribution of the inlying data is very challenging, and a One-class SVM might give useful results in these situations depending on the value of its hyperparameters.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.svm.oneclasssvm#sklearn.svm.OneClassSVM&quot;&gt; &lt;code&gt;sklearn.svm.OneClassSVM&lt;/code&gt; は&lt;/a&gt;外れ値に敏感であることが知られているので、外れ値検出のために非常によく実行されません。この推定量は、トレーニングセットが外れ値で汚染されていない場合の新規性の検出に最適です。とは言うものの、高次元での、または内在するデータの分布に関する仮定なしでの外れ値の検出は非常に困難であり、ワンクラスSVMは、ハイパーパラメーターの値に応じて、これらの状況で有用な結果をもたらす可能性があります。</target>
        </trans-unit>
        <trans-unit id="6a4f7d548c6a3daf45cbc9aca2408b6479c48a9f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt; provides parameters such as &lt;code&gt;min_samples_leaf&lt;/code&gt; and &lt;code&gt;max_depth&lt;/code&gt; to prevent a tree from overfiting. Cost complexity pruning provides another option to control the size of a tree. In &lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt;&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;&lt;/a&gt;, this pruning technique is parameterized by the cost complexity parameter, &lt;code&gt;ccp_alpha&lt;/code&gt;. Greater values of &lt;code&gt;ccp_alpha&lt;/code&gt; increase the number of nodes pruned. Here we only show the effect of &lt;code&gt;ccp_alpha&lt;/code&gt; on regularizing the trees and how to choose a &lt;code&gt;ccp_alpha&lt;/code&gt; based on validation scores.</source>
          <target state="translated">&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; は、&lt;/a&gt;のようなパラメータ提供 &lt;code&gt;min_samples_leaf&lt;/code&gt; と &lt;code&gt;max_depth&lt;/code&gt; overfitingからツリーを防ぐために。コストの複雑さのプルーニングは、ツリーのサイズを制御するための別のオプションを提供します。で&lt;a href=&quot;../../modules/generated/sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier&quot;&gt; &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; &lt;/a&gt;、この剪定技術は、コストの複雑さのパラメータによってパラメータ化さ &lt;code&gt;ccp_alpha&lt;/code&gt; 。 &lt;code&gt;ccp_alpha&lt;/code&gt; の値を大きくすると、プルーニングされるノードの数が増えます。ここでは、ツリーの正則化に対する &lt;code&gt;ccp_alpha&lt;/code&gt; の効果と、検証スコアに基づいて &lt;code&gt;ccp_alpha&lt;/code&gt; を選択する方法のみを示します。</target>
        </trans-unit>
        <trans-unit id="424aa7402b9869b036306a671e3630b4177e36b0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to fit a sine curve with addition noisy observation. As a result, it learns local linear regressions approximating the sine curve.</source>
          <target state="translated">&lt;a href=&quot;../../modules/tree#tree&quot;&gt;決定木は、&lt;/a&gt;さらにノイズの多い観測の正弦曲線を適合させるために使用されます。その結果、正弦曲線に近似する局所線形回帰を学習します。</target>
        </trans-unit>
        <trans-unit id="eb2cbae46431d84a4889d55d659950b594e78664" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../../modules/tree#tree&quot;&gt;decision trees&lt;/a&gt; is used to predict simultaneously the noisy x and y observations of a circle given a single underlying feature. As a result, it learns local linear regressions approximating the circle.</source>
          <target state="translated">&lt;a href=&quot;../../modules/tree#tree&quot;&gt;決定木は、&lt;/a&gt;同時に騒々しいX及び単一下層の機能を与えられた円のY観察を予測するために使用されます。その結果、円を近似する局所線形回帰を学習します。</target>
        </trans-unit>
        <trans-unit id="4ea0ad8f51ec5bec92f088b272fa90a6ac2d5b55" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt;&lt;/a&gt; function is a data fetching / caching functions that downloads the data archive from the original &lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;20 newsgroups website&lt;/a&gt;, extracts the archive contents in the &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; folder and calls the &lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; on either the training or testing set folder, or both of them:</source>
          <target state="translated">&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_20newsgroups&lt;/code&gt; の&lt;/a&gt;機能は、元からのデータのアーカイブをダウンロードする機能をキャッシュするデータフェッチ/ある&lt;a href=&quot;http://people.csail.mit.edu/jrennie/20Newsgroups/&quot;&gt;20のニュースグループのウェブサイトを&lt;/a&gt;、でアーカイブの内容を抽出し、 &lt;code&gt;~/scikit_learn_data/20news_home&lt;/code&gt; フォルダと呼び出す&lt;a href=&quot;../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; の&lt;/a&gt;訓練のいずれかにまたはテストセットフォルダー、またはその両方：</target>
        </trans-unit>
        <trans-unit id="26c038b3ea935758dab579b3237ee5588d78f251" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt;&lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt;&lt;/a&gt; datasets is subdivided into 3 subsets: the development &lt;code&gt;train&lt;/code&gt; set, the development &lt;code&gt;test&lt;/code&gt; set and an evaluation &lt;code&gt;10_folds&lt;/code&gt; set meant to compute performance metrics using a 10-folds cross validation scheme.</source>
          <target state="translated">&lt;a href=&quot;../modules/generated/sklearn.datasets.fetch_lfw_pairs#sklearn.datasets.fetch_lfw_pairs&quot;&gt; &lt;code&gt;sklearn.datasets.fetch_lfw_pairs&lt;/code&gt; の&lt;/a&gt;データセットは、3つのサブセットに細分される：現像 &lt;code&gt;train&lt;/code&gt; セット、開発 &lt;code&gt;test&lt;/code&gt; セットと評価 &lt;code&gt;10_folds&lt;/code&gt; が 10フォールドクロスバリデーション方式を使用して計算パフォーマンス・メトリックを意味セット。</target>
        </trans-unit>
        <trans-unit id="d14958ad2582740fd909337c2882b7ba18717e2a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt;&lt;code&gt;sklearn.ensemble&lt;/code&gt;&lt;/a&gt; module includes two averaging algorithms based on randomized &lt;a href=&quot;tree#tree&quot;&gt;decision trees&lt;/a&gt;: the RandomForest algorithm and the Extra-Trees method. Both algorithms are perturb-and-combine techniques &lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998]&lt;/a&gt; specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.ensemble&quot;&gt; &lt;code&gt;sklearn.ensemble&lt;/code&gt; &lt;/a&gt;モジュールには、ランダム化された&lt;a href=&quot;tree#tree&quot;&gt;決定木に&lt;/a&gt;基づく2つの平均化アルゴリズム、RandomForestアルゴリズムとExtra-Treesメソッドが含まれています。どちらのアルゴリズムも、特に木のために設計された摂動と結合の手法&lt;a href=&quot;#b1998&quot; id=&quot;id5&quot;&gt;[B1998]&lt;/a&gt;です。これは、分類器の構築にランダム性を導入することにより、分類器の多様なセットが作成されることを意味します。アンサンブルの予測は、個々の分類子の平均予測として与えられます。</target>
        </trans-unit>
        <trans-unit id="fbeef59e0313a7e281a500dd36152abed677fa2e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt;&lt;code&gt;sklearn.feature_extraction&lt;/code&gt;&lt;/a&gt; module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.feature_extraction&quot;&gt; &lt;code&gt;sklearn.feature_extraction&lt;/code&gt; の&lt;/a&gt;モジュールは、テキストや画像などの形式からなるデータセットからの機械学習アルゴリズムによってサポートされている形式で抽出機能を使用することができます。</target>
        </trans-unit>
        <trans-unit id="ff270d1b4e640c5be645e763d862de5cbdc56019" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.inspection&quot;&gt;&lt;code&gt;sklearn.inspection&lt;/code&gt;&lt;/a&gt; module provides a convenience function &lt;a href=&quot;generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt;&lt;code&gt;plot_partial_dependence&lt;/code&gt;&lt;/a&gt; to create one-way and two-way partial dependence plots. In the below example we show how to create a grid of partial dependence plots: two one-way PDPs for the features &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; and a two-way PDP between the two features:</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.inspection&quot;&gt; &lt;code&gt;sklearn.inspection&lt;/code&gt; の&lt;/a&gt;モジュールは、便利な機能を提供し&lt;a href=&quot;generated/sklearn.inspection.plot_partial_dependence#sklearn.inspection.plot_partial_dependence&quot;&gt; &lt;code&gt;plot_partial_dependence&lt;/code&gt; &lt;/a&gt;一方向および双方向の部分依存性のプロットを作成するために。以下の例では、部分的な依存関係プロットのグリッドを作成する方法を示します &lt;code&gt;0&lt;/code&gt; 機能0と &lt;code&gt;1&lt;/code&gt; の2つの一方向PDPと、2つの機能間の双方向PDPです。</target>
        </trans-unit>
        <trans-unit id="565412031e53246181e593ab56b9ab7f3accb362" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure classification performance. Some metrics might require probability estimates of the positive class, confidence values, or binary decisions values. Most implementations allow each sample to provide a weighted contribution to the overall score, through the &lt;code&gt;sample_weight&lt;/code&gt; parameter.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; は、&lt;/a&gt;分類性能を測定するための道具を何損失、スコア、およびユーティリティ機能をモジュール。一部のメトリックでは、陽性クラスの確率推定、信頼値、またはバイナリ決定値が必要になる場合があります。ほとんどの実装では、 &lt;code&gt;sample_weight&lt;/code&gt; パラメーターを介して、各サンプルが全体的なスコアに加重寄与を提供できます。</target>
        </trans-unit>
        <trans-unit id="6986be647f522d4ad92a86deccdacfb4588f163b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions to measure regression performance. Some of those have been enhanced to handle the multioutput case: &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; は&lt;/a&gt;、回帰のパフォーマンスを測定するための道具を何損失、スコア、およびユーティリティ機能をモジュール。それらのいくつかは多出力のケースを処理するために強化されました：&lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; を&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e3af9dc32993fb04e5c47da4dea690da48a6baa4" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt;&lt;code&gt;sklearn.metrics&lt;/code&gt;&lt;/a&gt; module implements several loss, score, and utility functions. For more information see the &lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;Clustering performance evaluation&lt;/a&gt; section for instance clustering, and &lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;Biclustering evaluation&lt;/a&gt; for biclustering.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.metrics&quot;&gt; &lt;code&gt;sklearn.metrics&lt;/code&gt; は&lt;/a&gt;道具を何損失、スコア、およびユーティリティ機能をモジュール。詳細については、インスタンスクラスタリングの&lt;a href=&quot;clustering#clustering-evaluation&quot;&gt;クラスタリングパフォーマンス評価&lt;/a&gt;セクション、および&lt;a href=&quot;biclustering#biclustering-evaluation&quot;&gt;バイ&lt;/a&gt;クラスタリングのバイクラスタリング評価を参照してください。</target>
        </trans-unit>
        <trans-unit id="095cb4e1ad7cf586616a563cdbf95404fbb2310e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt;&lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt;&lt;/a&gt; submodule implements utilities to evaluate pairwise distances or affinity of sets of samples.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.metrics.pairwise&quot;&gt; &lt;code&gt;sklearn.metrics.pairwise&lt;/code&gt; の&lt;/a&gt;サンプルのセットの対距離または親和性を評価するためのサブモジュールが実装ユーティリティ。</target>
        </trans-unit>
        <trans-unit id="8e4a825968b52124826a5f75996abc15ec7f1a2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. &lt;code&gt;multioutput&lt;/code&gt; regression is also supported.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; &lt;/a&gt;モジュール実装&lt;em&gt;メタ推定量&lt;/em&gt;解決する &lt;code&gt;multiclass&lt;/code&gt; と &lt;code&gt;multilabel&lt;/code&gt; バイナリ分類問題にこのような問題を分解することにより、分類の問題を。 &lt;code&gt;multioutput&lt;/code&gt; 回帰もサポートされています。</target>
        </trans-unit>
        <trans-unit id="60f0063776d96ccddba5880841f7defdb7f0d5d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt;&lt;code&gt;sklearn.multiclass&lt;/code&gt;&lt;/a&gt; module implements &lt;em&gt;meta-estimators&lt;/em&gt; to solve &lt;code&gt;multiclass&lt;/code&gt; and &lt;code&gt;multilabel&lt;/code&gt; classification problems by decomposing such problems into binary classification problems. Multitarget regression is also supported.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.multiclass&quot;&gt; &lt;code&gt;sklearn.multiclass&lt;/code&gt; &lt;/a&gt;モジュール実装&lt;em&gt;メタ推定量&lt;/em&gt;解決する &lt;code&gt;multiclass&lt;/code&gt; と &lt;code&gt;multilabel&lt;/code&gt; バイナリ分類問題にこのような問題を分解することにより、分類の問題を。マルチターゲット回帰もサポートされています。</target>
        </trans-unit>
        <trans-unit id="8db5d205727541fd60809b9d143967244bf8e79b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt;&lt;code&gt;sklearn.random_projection&lt;/code&gt;&lt;/a&gt; module implements a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes. This module implements two types of unstructured random matrix: &lt;a href=&quot;#gaussian-random-matrix&quot;&gt;Gaussian random matrix&lt;/a&gt; and &lt;a href=&quot;#sparse-random-matrix&quot;&gt;sparse random matrix&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;classes#module-sklearn.random_projection&quot;&gt; &lt;code&gt;sklearn.random_projection&lt;/code&gt; の&lt;/a&gt;モジュールが実装単純で計算上効率的な方法は、より高速な処理時間およびより小さなモデルサイズの（追加の分散など）の精度の制御された量を取引することにより、データの次元を低減します。このモジュールは、&lt;a href=&quot;#gaussian-random-matrix&quot;&gt;ガウスランダムマトリックス&lt;/a&gt;と&lt;a href=&quot;#sparse-random-matrix&quot;&gt;スパースランダムマトリックスの&lt;/a&gt; 2種類の非構造化ランダムマトリックスを実装します。</target>
        </trans-unit>
        <trans-unit id="a34e8e8e9bf3ccf9c2fa51aff7ed58e5e45bbffa" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt;&lt;code&gt;CalibratedClassifierCV&lt;/code&gt;&lt;/a&gt; class is used to calibrate a classifier.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.calibration.calibratedclassifiercv#sklearn.calibration.CalibratedClassifierCV&quot;&gt; &lt;code&gt;CalibratedClassifierCV&lt;/code&gt; の&lt;/a&gt;クラスは、分類器を校正するために使用されます。</target>
        </trans-unit>
        <trans-unit id="aaa03339275413a44471cce8ed9110742f7e29fb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt;&lt;code&gt;AgglomerativeClustering&lt;/code&gt;&lt;/a&gt; object performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. The linkage criteria determines the metric used for the merge strategy:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.agglomerativeclustering#sklearn.cluster.AgglomerativeClustering&quot;&gt; &lt;code&gt;AgglomerativeClustering&lt;/code&gt; の&lt;/a&gt;オブジェクトが実行ボトムアップアプローチを用いて階層的クラスタリング：独自のクラスタ内の各観測を開始し、クラスタを順次一緒にマージされます。リンケージ基準は、マージ戦略に使用されるメトリックを決定します。</target>
        </trans-unit>
        <trans-unit id="913b5a9805377fabb258d2653b5b70e8adeffb2c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt;&lt;code&gt;SpectralBiclustering&lt;/code&gt;&lt;/a&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralbiclustering#sklearn.cluster.bicluster.SpectralBiclustering&quot;&gt; &lt;code&gt;SpectralBiclustering&lt;/code&gt; &lt;/a&gt;アルゴリズムは、入力データ行列は、隠されたチェッカーボード構造を有していることを前提としています。この構造を持つ行列の行と列は、行クラスターと列クラスターのデカルト積の任意のバイクラスターのエントリがほぼ一定になるように分割できます。たとえば、2つの行パーティションと3つの列パーティションがある場合、各行は3つのバイクラスターに属し、各列は2つのバイクラスターに属します。</target>
        </trans-unit>
        <trans-unit id="96812a842015efa920168397038c120e6e957561" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt;&lt;code&gt;SpectralCoclustering&lt;/code&gt;&lt;/a&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.bicluster.spectralcoclustering#sklearn.cluster.bicluster.SpectralCoclustering&quot;&gt; &lt;code&gt;SpectralCoclustering&lt;/code&gt; &lt;/a&gt;アルゴリズムは、対応する他の行に比べて高い値と列とbiclustersを見出します。各行と各列は1つのバイクラスターに属しているため、行と列を並べ替えてパーティションを隣接させると、対角線に沿ってこれらの高い値がわかります。</target>
        </trans-unit>
        <trans-unit id="9debcd56df8be7e32ea091b79dc8e313d63ea1d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Characteristic Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Characteristic Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Characteristic Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt; &lt;code&gt;Birch&lt;/code&gt; &lt;/a&gt;与えられたデータに特徴的な性質ツリー（CFT）と呼ばれるツリーを構築します。データは本質的に、不可逆圧縮されて一連のCharacteristic Featureノード（CFノード）に圧縮されます。 CFノードにはCharacteristic Featureサブクラスター（CFサブクラスター）と呼ばれるいくつかのサブクラスターがあり、非ターミナルCFノードにあるこれらのCFサブクラスターは、子としてCFノードを持つことができます。</target>
        </trans-unit>
        <trans-unit id="5792059d2ce9d3e99380df43abdafaacd52cf188" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt;&lt;code&gt;Birch&lt;/code&gt;&lt;/a&gt; builds a tree called the Clustering Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Clustering Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Clustering Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.birch#sklearn.cluster.Birch&quot;&gt; &lt;code&gt;Birch&lt;/code&gt; &lt;/a&gt;与えられたデータのためのクラスタリング機能ツリー（CFT）と呼ばれるツリーを構築します。データは本質的に不可逆圧縮されて、クラスタリング機能ノード（CFノード）のセットになります。 CFノードには、クラスタリング機能サブクラスター（CFサブクラスター）と呼ばれるいくつかのサブクラスターがあり、非終端CFノードにあるこれらのCFサブクラスターは、CFノードを子として持つことができます。</target>
        </trans-unit>
        <trans-unit id="e8b115edebda7f7bf86445503d0ce08900b4f8de" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm views clusters as areas of high density separated by areas of low density. Due to this rather generic view, clusters found by DBSCAN can be any shape, as opposed to k-means which assumes that clusters are convex shaped. The central component to the DBSCAN is the concept of &lt;em&gt;core samples&lt;/em&gt;, which are samples that are in areas of high density. A cluster is therefore a set of core samples, each close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples). There are two parameters to the algorithm, &lt;code&gt;min_samples&lt;/code&gt; and &lt;code&gt;eps&lt;/code&gt;, which define formally what we mean when we say &lt;em&gt;dense&lt;/em&gt;. Higher &lt;code&gt;min_samples&lt;/code&gt; or lower &lt;code&gt;eps&lt;/code&gt; indicate higher density necessary to form a cluster.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt;低密度の領域によって分離された高濃度の領域としてアルゴリズムビューのクラスター。このかなり一般的なビューのため、DBSCANによって検出されたクラスターは、クラスターが凸型であると想定するk平均法とは異なり、任意の形状にすることができます。 DBSCANの中心的なコンポーネントは、&lt;em&gt;コアサンプル&lt;/em&gt;の概念です。これは、高密度の領域にあるサンプルです。したがって、クラスターは、それぞれが互いに近い（ある距離測定によって測定された）コアサンプルのセットと、コアサンプルに近い（ただし、それ自体はコアサンプルではない）非コアサンプルのセットです。アルゴリズム、には2つのパラメータがあり &lt;code&gt;min_samples&lt;/code&gt; と &lt;code&gt;eps&lt;/code&gt; 我々が言うとき、私たちが何を意味するか正式に定義し、&lt;em&gt;密に&lt;/em&gt;。より高い &lt;code&gt;min_samples&lt;/code&gt; またはより低い &lt;code&gt;eps&lt;/code&gt; は、クラスターを形成するために必要なより高い密度を示します。</target>
        </trans-unit>
        <trans-unit id="844222980d29de5ed47698200091f13bdd09a284" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt;&lt;code&gt;FeatureAgglomeration&lt;/code&gt;&lt;/a&gt; uses agglomerative clustering to group together features that look very similar, thus decreasing the number of features. It is a dimensionality reduction tool, see &lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;Unsupervised dimensionality reduction&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration&quot;&gt; &lt;code&gt;FeatureAgglomeration&lt;/code&gt; は&lt;/a&gt;一緒にグループに凝集クラスタリングを使用してこのような機能の数を減少させる、非常に類似している外観を備えています。これは、次元削減ツールです。&lt;a href=&quot;unsupervised_reduction#data-reduction&quot;&gt;教師なし次元削減を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="3ccd68ae912b5d8e7b609345a756782aaea1f1b3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;a href=&quot;inertia&quot;&gt;inertia&lt;/a&gt; or within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt;として知られている基準最小化、等分散のN個のグループに別々の試料を試みることによってクラスタデータを、アルゴリズム&lt;a href=&quot;inertia&quot;&gt;慣性&lt;/a&gt;または内クラスタ和の二乗です。このアルゴリズムでは、クラスターの数を指定する必要があります。多数のサンプルに対応し、さまざまな分野の広範なアプリケーション領域で使用されています。</target>
        </trans-unit>
        <trans-unit id="1ffab773fe637da04ea4c04490bc4a37e92e75f6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the &lt;em&gt;inertia&lt;/em&gt; or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt;として知られている基準最小化、等分散のN個のグループに別々の試料を試みることによってクラスタデータを、アルゴリズム&lt;em&gt;慣性&lt;/em&gt;または内クラスタ和の二乗を（下記参照します）。このアルゴリズムでは、クラスターの数を指定する必要があります。多数のサンプルに対応し、さまざまな分野の幅広いアプリケーション分野で使用されています。</target>
        </trans-unit>
        <trans-unit id="f8f9ba49e304c2e7e84cbf4122c9838a65e0d463" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt;&lt;code&gt;MiniBatchKMeans&lt;/code&gt;&lt;/a&gt; is a variant of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;KMeans&lt;/code&gt;&lt;/a&gt; algorithm which uses mini-batches to reduce the computation time, while still attempting to optimise the same objective function. Mini-batches are subsets of the input data, randomly sampled in each training iteration. These mini-batches drastically reduce the amount of computation required to converge to a local solution. In contrast to other algorithms that reduce the convergence time of k-means, mini-batch k-means produces results that are generally only slightly worse than the standard algorithm.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.minibatchkmeans#sklearn.cluster.MiniBatchKMeans&quot;&gt; &lt;code&gt;MiniBatchKMeans&lt;/code&gt; で&lt;/a&gt;の変異体である&lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;KMeans&lt;/code&gt; &lt;/a&gt;依然として同じ目的関数を最適化しようとしたとき、計算時間を短縮するために、ミニバッチを使用するアルゴリズム。ミニバッチは入力データのサブセットであり、トレーニングの反復ごとにランダムにサンプリングされます。これらのミニバッチは、ローカルソリューションに収束するために必要な計算量を大幅に削減します。 k-meansの収束時間を短縮する他のアルゴリズムとは対照的に、ミニバッチk-meansは、一般的に標準アルゴリズムよりもわずかに悪い結果しか生成しません。</target>
        </trans-unit>
        <trans-unit id="13f492ae552c222beb8a78a6fea9613c4b7f22e2" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt;&lt;code&gt;OPTICS&lt;/code&gt;&lt;/a&gt; algorithm shares many similarities with the &lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt;&lt;code&gt;DBSCAN&lt;/code&gt;&lt;/a&gt; algorithm, and can be considered a generalization of DBSCAN that relaxes the &lt;code&gt;eps&lt;/code&gt; requirement from a single value to a value range. The key difference between DBSCAN and OPTICS is that the OPTICS algorithm builds a &lt;em&gt;reachability&lt;/em&gt; graph, which assigns each sample both a &lt;code&gt;reachability_&lt;/code&gt; distance, and a spot within the cluster &lt;code&gt;ordering_&lt;/code&gt; attribute; these two attributes are assigned when the model is fitted, and are used to determine cluster membership. If OPTICS is run with the default value of &lt;em&gt;inf&lt;/em&gt; set for &lt;code&gt;max_eps&lt;/code&gt;, then DBSCAN style cluster extraction can be performed repeatedly in linear time for any given &lt;code&gt;eps&lt;/code&gt; value using the &lt;code&gt;cluster_optics_dbscan&lt;/code&gt; method. Setting &lt;code&gt;max_eps&lt;/code&gt; to a lower value will result in shorter run times, and can be thought of as the maximum neighborhood radius from each point to find other potential reachable points.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.cluster.optics#sklearn.cluster.OPTICS&quot;&gt; &lt;code&gt;OPTICS&lt;/code&gt; の&lt;/a&gt;アルゴリズムを共有すると多くの類似&lt;a href=&quot;generated/sklearn.cluster.dbscan#sklearn.cluster.DBSCAN&quot;&gt; &lt;code&gt;DBSCAN&lt;/code&gt; &lt;/a&gt;アルゴリズム、及び緩和DBSCANの一般化とみなすことができる &lt;code&gt;eps&lt;/code&gt; 値の範囲に単一の値から要件を。 DBSCANとOPTICSの主な違いは、OPTICSアルゴリズムが&lt;em&gt;到達可能性&lt;/em&gt;グラフを作成し、各サンプルに &lt;code&gt;reachability_&lt;/code&gt; 距離とクラスター &lt;code&gt;ordering_&lt;/code&gt; 属性内のスポットの両方を割り当てることです。これらの2つの属性は、モデルが適合されるときに割り当てられ、クラスターメンバーシップを決定するために使用されます。 &lt;code&gt;max_eps&lt;/code&gt; に設定された&lt;em&gt;inf&lt;/em&gt;のデフォルト値でOPTICSを実行する場合、次に、 &lt;code&gt;cluster_optics_dbscan&lt;/code&gt; メソッドを使用して、任意の &lt;code&gt;eps&lt;/code&gt; 値に対してDBSCANスタイルのクラスター抽出を線形時間で繰り返し実行できます。 &lt;code&gt;max_eps&lt;/code&gt; を低い値に設定すると、実行時間が短くなり、他の潜在的な到達可能なポイントを見つけるための各ポイントからの最大近隣半径と考えることができます。</target>
        </trans-unit>
        <trans-unit id="381def8c4d001638003d40e7acf9264b0a49ea0f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; は&lt;/a&gt;内、データの異なる列に異なる変換を実行することができます&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;データ漏洩やそのパラメータ化することができますから、安全であること。&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; は&lt;/a&gt;配列、スパース行列、そして上で動作&lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/&quot;&gt;パンダのデータフレーム&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="d5b3cf1eea0426995e81b4c182953586d3dd6af5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; helps performing different transformations for different columns of the data, within a &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; that is safe from data leakage and that can be parametrized. &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; works on arrays, sparse matrices, and &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/&quot;&gt;pandas DataFrames&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; は&lt;/a&gt;内、データの異なる列に異なる変換を実行することができます&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;データ漏洩やそのパラメータ化することができますから、安全であること。&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; &lt;/a&gt;は、配列、スパース行列、および&lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/&quot;&gt;パンダDataFramesで機能し&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="37d727244bb97826f98eb0365b95bf6cd4afb239" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;compose.ColumnTransformer&lt;/code&gt;&lt;/a&gt; class is experimental and the API is subject to change.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;compose.ColumnTransformer&lt;/code&gt; の&lt;/a&gt;クラスでは、実験的であるとAPIは変更されることがあります。</target>
        </trans-unit>
        <trans-unit id="36f50b6d2de06293da3e162b3eb7e342568ccd05" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.compose.make_column_transformer#sklearn.compose.make_column_transformer&quot;&gt;&lt;code&gt;make_column_transformer&lt;/code&gt;&lt;/a&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.compose.make_column_transformer#sklearn.compose.make_column_transformer&quot;&gt; &lt;code&gt;make_column_transformer&lt;/code&gt; の&lt;/a&gt;機能をより簡単に作成することが可能です&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; の&lt;/a&gt;オブジェクトを。具体的には、名前は自動的に付けられます。上記の例に相当するものは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="83e5137b54932bec66ccc36542bace6834598b69" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt;&lt;code&gt;GraphicalLasso&lt;/code&gt;&lt;/a&gt; estimator uses an l1 penalty to enforce sparsity on the precision matrix: the higher its &lt;code&gt;alpha&lt;/code&gt; parameter, the more sparse the precision matrix. The corresponding &lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt;&lt;code&gt;GraphicalLassoCV&lt;/code&gt;&lt;/a&gt; object uses cross-validation to automatically set the &lt;code&gt;alpha&lt;/code&gt; parameter.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.covariance.graphicallasso#sklearn.covariance.GraphicalLasso&quot;&gt; &lt;code&gt;GraphicalLasso&lt;/code&gt; &lt;/a&gt;高いその：推定精度行列にスパースを強制するL1ペナルティを使用して &lt;code&gt;alpha&lt;/code&gt; より疎なパラメーター、精密マトリックス。対応する&lt;a href=&quot;generated/sklearn.covariance.graphicallassocv#sklearn.covariance.GraphicalLassoCV&quot;&gt; &lt;code&gt;GraphicalLassoCV&lt;/code&gt; &lt;/a&gt;オブジェクトは、交差検証を使用して、 &lt;code&gt;alpha&lt;/code&gt; パラメーターを自動的に設定します。</target>
        </trans-unit>
        <trans-unit id="4d547fe6e0c2b8c31056c1efceecbd9d17b8cbf1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-score&quot;&gt;score&lt;/a&gt; method that can be used in cross-validation:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; の&lt;/a&gt;オブジェクトは、それが説明分散の量に基づいてデータの可能性を与えることができPCAの確率的解釈を提供します。そのため、相互検証で使用できる&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-score&quot;&gt;スコア&lt;/a&gt;メソッドを実装します。</target>
        </trans-unit>
        <trans-unit id="9447390bf3cfd368da76e6282f132428b32dfff8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a &lt;code&gt;score&lt;/code&gt; method that can be used in cross-validation:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; の&lt;/a&gt;オブジェクトは、それが説明分散の量に基づいてデータの可能性を与えることができPCAの確率的解釈を提供します。そのため、相互検証で使用できる &lt;code&gt;score&lt;/code&gt; メソッドを実装しています。</target>
        </trans-unit>
        <trans-unit id="de1125bcd2177e15b5b35e281621b5bbf18681e1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; object is very useful, but has certain limitations for large datasets. The biggest limitation is that &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; only supports batch processing, which means all of the data to be processed must fit in main memory. The &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; object uses a different form of processing and allows for partial computations which almost exactly match the results of &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; while processing the data in a minibatch fashion. &lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt;&lt;code&gt;IncrementalPCA&lt;/code&gt;&lt;/a&gt; makes it possible to implement out-of-core Principal Component Analysis either by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; の&lt;/a&gt;オブジェクトは、非常に便利ですが、大規模なデータセットのために一定の制限があります。最大の制限は、&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;がバッチ処理のみをサポートすることです。つまり、処理されるすべてのデータがメインメモリに収まる必要があります。&lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; の&lt;/a&gt;オブジェクトは、処理の異なる形態を使用し、ほぼ正確の結果と一致する部分の計算を可能に&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; を&lt;/a&gt; minibatch方式でデータを処理している間。&lt;a href=&quot;generated/sklearn.decomposition.incrementalpca#sklearn.decomposition.IncrementalPCA&quot;&gt; &lt;code&gt;IncrementalPCA&lt;/code&gt; を使用&lt;/a&gt;すると、次のいずれかの方法でコア外主成分分析を実装できます。</target>
        </trans-unit>
        <trans-unit id="ecd6b33d3bd2199aadcf263cff0e5246cde4bd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt;&lt;code&gt;SparseCoder&lt;/code&gt;&lt;/a&gt; object is an estimator that can be used to transform signals into sparse linear combination of atoms from a fixed, precomputed dictionary such as a discrete wavelet basis. This object therefore does not implement a &lt;code&gt;fit&lt;/code&gt; method. The transformation amounts to a sparse coding problem: finding a representation of the data as a linear combination of as few dictionary atoms as possible. All variations of dictionary learning implement the following transform methods, controllable via the &lt;code&gt;transform_method&lt;/code&gt; initialization parameter:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder&quot;&gt; &lt;code&gt;SparseCoder&lt;/code&gt; の&lt;/a&gt;オブジェクトが固定からの原子のスパース線形結合に信号を変換するために使用することができる推定され、このような離散ウェーブレット基盤として辞書予め計算。したがって、このオブジェクトは &lt;code&gt;fit&lt;/code&gt; メソッドを実装していません。変換はまばらなコーディングの問題に相当します。データの表現を、できるだけ少ない辞書アトムの線形結合として見つけることです。辞書学習のすべてのバリエーションは、 &lt;code&gt;transform_method&lt;/code&gt; 初期化パラメーターを介して制御可能な次の変換メソッドを実装します。</target>
        </trans-unit>
        <trans-unit id="e3da78a60195e1f6e094f14916e2b477c6f8356b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt;&lt;code&gt;ensemble.IsolationForest&lt;/code&gt;&lt;/a&gt; supports &lt;code&gt;warm_start=True&lt;/code&gt; which allows you to add more trees to an already fitted model:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.ensemble.isolationforest#sklearn.ensemble.IsolationForest&quot;&gt; &lt;code&gt;ensemble.IsolationForest&lt;/code&gt; &lt;/a&gt;サポート &lt;code&gt;warm_start=True&lt;/code&gt; すでにフィットモデルに多くの樹木を追加することができます：</target>
        </trans-unit>
        <trans-unit id="541c2e4d790ae9e327bfbba2dc5bd507a6c1e503" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt; provide such strategies which can be applied to classification and regression problems.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt; &lt;code&gt;StackingClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt; &lt;code&gt;StackingRegressor&lt;/code&gt; は、&lt;/a&gt;分類と回帰の問題に適用することができ、このような戦略を提供しています。</target>
        </trans-unit>
        <trans-unit id="b8482134b0c48ad8bcdfc22624a585a7b569b1ee" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; can also be used together with &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt; &lt;code&gt;VotingClassifier&lt;/code&gt; は&lt;/a&gt;また、一緒に使用することができる&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; &lt;/a&gt;個々推定のハイパー調整するために：</target>
        </trans-unit>
        <trans-unit id="51b760d25143490b212d3dce7b63a475beffe57d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt; function extracts patches from an image stored as a two-dimensional array, or three-dimensional with color information along the third axis. For rebuilding an image from all its patches, use &lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt;&lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt;&lt;/a&gt;. For example let use generate a 4x4 pixel picture with 3 color channels (e.g. in RGB format):</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt;画像から機能抽出パッチは、二次元配列として格納され、又は第3の軸に沿って色情報を有する三次元。すべてのパッチからイメージを&lt;a href=&quot;generated/sklearn.feature_extraction.image.reconstruct_from_patches_2d#sklearn.feature_extraction.image.reconstruct_from_patches_2d&quot;&gt; &lt;code&gt;reconstruct_from_patches_2d&lt;/code&gt; &lt;/a&gt;するには、reconstruct_from_patches_2dを使用します。たとえば、3つのカラーチャネルを持つ4x4ピクセルの画像（RGB形式など）を生成してみましょう。</target>
        </trans-unit>
        <trans-unit id="13de12da96c62cdbe967814b1ded04e8c85eef13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt;&lt;code&gt;PatchExtractor&lt;/code&gt;&lt;/a&gt; class works in the same way as &lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt;&lt;code&gt;extract_patches_2d&lt;/code&gt;&lt;/a&gt;, only it supports multiple images as input. It is implemented as an estimator, so it can be used in pipelines. See:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.feature_extraction.image.patchextractor#sklearn.feature_extraction.image.PatchExtractor&quot;&gt; &lt;code&gt;PatchExtractor&lt;/code&gt; の&lt;/a&gt;クラスと同じように動作します&lt;a href=&quot;generated/sklearn.feature_extraction.image.extract_patches_2d#sklearn.feature_extraction.image.extract_patches_2d&quot;&gt; &lt;code&gt;extract_patches_2d&lt;/code&gt; &lt;/a&gt;、それだけでは、入力として複数の画像をサポートしています。推定器として実装されているため、パイプラインで使用できます。見る：</target>
        </trans-unit>
        <trans-unit id="5f1d9b11617dc21530d4a8e947334af50d14c144" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt;&lt;code&gt;HashingVectorizer&lt;/code&gt;&lt;/a&gt; also comes with the following limitations:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.feature_extraction.text.hashingvectorizer#sklearn.feature_extraction.text.HashingVectorizer&quot;&gt; &lt;code&gt;HashingVectorizer&lt;/code&gt; は&lt;/a&gt;また、以下の制限が付属しています：</target>
        </trans-unit>
        <trans-unit id="dec1e79879a530cf5d8d2ea5bf189d8118bb1961" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for classification purposes, more specifically for probabilistic classification, where test predictions take the form of class probabilities. GaussianProcessClassifier places a GP prior on a latent function \(f\), which is then squashed through a link function to obtain the probabilistic classification. The latent function \(f\) is a so-called nuisance function, whose values are not observed and are not relevant by themselves. Its purpose is to allow a convenient formulation of the model, and \(f\) is removed (integrated out) during prediction. GaussianProcessClassifier implements the logistic link function, for which the integral cannot be computed analytically but is easily approximated in the binary case.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; は、&lt;/a&gt;試験の予測は、クラス確率の形をとる確率的分類のために、より具体的には、分類の目的のために、ガウス過程（GP）を実装します。 GaussianProcessClassifierはGPを潜在関数\（f \）の前に配置します。これは、リンク関数を介して押しつぶされ、確率的分類が取得されます。潜在関数\（f \）はいわゆる迷惑関数であり、その値は観測されず、それ自体では関係ありません。その目的は、モデルの便利な定式化を可能にすることであり、\（f \）は予測中に削除（統合）されます。 GaussianProcessClassifierはロジスティックリンク関数を実装します。この関数では、積分を解析的に計算することはできませんが、バイナリの場合は簡単に近似できます。</target>
        </trans-unit>
        <trans-unit id="2a70b80f4163a2c6bfd08f3c8b84b458a9627cc7" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by a passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt; &lt;code&gt;GaussianProcessRegressor&lt;/code&gt; は&lt;/a&gt;、回帰の目的のためにガウス過程（GP）を実装しています。このためには、GPの事前を指定する必要があります。以前の平均は、定数でゼロ（ &lt;code&gt;normalize_y=False&lt;/code&gt; の場合）またはトレーニングデータの平均（ &lt;code&gt;normalize_y=True&lt;/code&gt; の場合）であると見なされます。事前分布の共分散は、&lt;a href=&quot;#gp-kernels&quot;&gt;カーネル&lt;/a&gt;オブジェクトを渡すことによって指定されます。カーネルのハイパーパラメーターは、GaussianProcessRegressorのフィッティング中に、渡さ &lt;code&gt;optimizer&lt;/code&gt; 基づいてlog-marginal-likelihood（LML）を最大化することにより最適化されます。 LMLには複数のローカルオプティマがある可能性があるため、 &lt;code&gt;n_restarts_optimizer&lt;/code&gt; を指定することでオプティマイザーを繰り返し起動できます。。最初の実行は常に、カーネルの初期ハイパーパラメーター値から開始されます。後続の実行は、許容値の範囲からランダムに選択されたハイパーパラメーター値から行われます。初期ハイパーパラメータを固定したままにする必要がある場合は、オプティマイザとして &lt;code&gt;None&lt;/code&gt; を渡すことができます。</target>
        </trans-unit>
        <trans-unit id="cef90bbcd0a36066d60f0a9fa46fd7add704859a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt;&lt;code&gt;GaussianProcessRegressor&lt;/code&gt;&lt;/a&gt; implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. The prior mean is assumed to be constant and zero (for &lt;code&gt;normalize_y=False&lt;/code&gt;) or the training data&amp;rsquo;s mean (for &lt;code&gt;normalize_y=True&lt;/code&gt;). The prior&amp;rsquo;s covariance is specified by passing a &lt;a href=&quot;#gp-kernels&quot;&gt;kernel&lt;/a&gt; object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed &lt;code&gt;optimizer&lt;/code&gt;. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying &lt;code&gt;n_restarts_optimizer&lt;/code&gt;. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, &lt;code&gt;None&lt;/code&gt; can be passed as optimizer.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor&quot;&gt; &lt;code&gt;GaussianProcessRegressor&lt;/code&gt; は&lt;/a&gt;、回帰の目的のためにガウス過程（GP）を実装しています。このためには、GPの事前指定が必要です。以前の平均は一定でゼロ（ &lt;code&gt;normalize_y=False&lt;/code&gt; の場合）またはトレーニングデータの平均（ &lt;code&gt;normalize_y=True&lt;/code&gt; の場合）であると想定されます。事前の共分散は、&lt;a href=&quot;#gp-kernels&quot;&gt;カーネル&lt;/a&gt;オブジェクトを渡すことによって指定されます。カーネルのハイパーパラメータは、渡さ &lt;code&gt;optimizer&lt;/code&gt; 基づいて対数周辺尤度（LML）を最大化することにより、GaussianProcessRegressorのフィッティング中に最適化されます。 LMLには複数のローカルオプティマがある場合があるため、 &lt;code&gt;n_restarts_optimizer&lt;/code&gt; を指定することでオプティマイザを繰り返し開始できます。最初の実行は、常にカーネルの初期ハイパーパラメータ値から開始して実行されます。後続の実行は、許可された値の範囲からランダムに選択されたハイパーパラメータ値から実行されます。初期ハイパーパラメータを固定しておく必要がある場合は、オプティマイザとして &lt;code&gt;None&lt;/code&gt; を渡すことができます。</target>
        </trans-unit>
        <trans-unit id="a013933edad2184a36ef1d15fcbf21a794c0c7f5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt;&lt;code&gt;ConstantKernel&lt;/code&gt;&lt;/a&gt; kernel can be used as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt;&lt;code&gt;Product&lt;/code&gt;&lt;/a&gt; kernel where it scales the magnitude of the other factor (kernel) or as part of a &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt;&lt;code&gt;Sum&lt;/code&gt;&lt;/a&gt; kernel, where it modifies the mean of the Gaussian process. It depends on a parameter \(constant\_value\). It is defined as:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.constantkernel#sklearn.gaussian_process.kernels.ConstantKernel&quot;&gt; &lt;code&gt;ConstantKernel&lt;/code&gt; の&lt;/a&gt;カーネルの一部として使用することができる&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.product#sklearn.gaussian_process.kernels.Product&quot;&gt; &lt;code&gt;Product&lt;/code&gt; &lt;/a&gt;は、他の因子（カーネル）の大きさやの一部としてスケーリングカーネル&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.sum#sklearn.gaussian_process.kernels.Sum&quot;&gt; &lt;code&gt;Sum&lt;/code&gt; &lt;/a&gt;がガウス過程の平均修正カーネルを、。パラメータ\（constant \ _value \）によって異なります。次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="a1a78e3b1d5985ce1973c8989ff0075d7d078b79" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is commonly combined with exponentiation. An example with exponent 2 is shown in the following figure:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;カーネルは、一般的に、べき乗と組み合わされます。指数2の例を次の図に示します。</target>
        </trans-unit>
        <trans-unit id="299194d50f816028e01666a91e5aaf031d88d5c0" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt;&lt;code&gt;DotProduct&lt;/code&gt;&lt;/a&gt; kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter \(\sigma_0^2\). For \(\sigma_0^2 = 0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;カーネルは非定常であり、\ \（x_d（D = 1、。。。、D）\）の係数に（N（0、1）\）事前確率を置くことによって、線形回帰から得られ、前ことができますバイアスの\（N（0、\ sigma_0 ^ 2）\）の。&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.dotproduct#sklearn.gaussian_process.kernels.DotProduct&quot;&gt; &lt;code&gt;DotProduct&lt;/code&gt; &lt;/a&gt;カーネルは、起源については、座標ではなく、翻訳の回転に対して不変です。パラメータ\（\ sigma_0 ^ 2 \）によってパラメータ化されます。\（\ sigma_0 ^ 2 = 0 \）の場合、カーネルは同種線形カーネルと呼ばれ、それ以外の場合は不均一です。カーネルは</target>
        </trans-unit>
        <trans-unit id="9b254fd92e2584b8ca8c7f30ca756b0bac24ec2b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt;&lt;code&gt;ExpSineSquared&lt;/code&gt;&lt;/a&gt; kernel allows modeling periodic functions. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a periodicity parameter \(p&amp;gt;0\). Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.expsinesquared#sklearn.gaussian_process.kernels.ExpSineSquared&quot;&gt; &lt;code&gt;ExpSineSquared&lt;/code&gt; の&lt;/a&gt;カーネルは定期的な機能をモデル化できます。これは、長さスケールのパラメーター\（l&amp;gt; 0 \）および周期性パラメーター\（p&amp;gt; 0 \）によってパラメーター化されます。現時点では、\（l \）がスカラーである等方性バリアントのみがサポートされています。カーネルは以下によって与えられます：</target>
        </trans-unit>
        <trans-unit id="4fa9c3925ee31fe17ddb7d4f95d9aa563f446e7b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt;&lt;code&gt;Matern&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel and a generalization of the &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel. It has an additional parameter \(\nu\) which controls the smoothness of the resulting function. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.matern#sklearn.gaussian_process.kernels.Matern&quot;&gt; &lt;code&gt;Matern&lt;/code&gt; &lt;/a&gt;カーネルは、固定カーネルとの一般化である&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; の&lt;/a&gt;カーネル。結果の関数の滑らかさを制御する追加のパラメーター\（\ nu \）があります。これは、長さスケールパラメーター\（l&amp;gt; 0 \）によってパラメーター化されます。これは、スカラー（カーネルの等方性バリアント）または入力と同じ次元数のベクトル\（x \）（異方性バリアント）のいずれかです。カーネルの）。カーネルは以下によって与えられます：</target>
        </trans-unit>
        <trans-unit id="9cc391d0a3f24c35e3e834b704611ffc08dfc23c" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt;&lt;code&gt;RationalQuadratic&lt;/code&gt;&lt;/a&gt; kernel can be seen as a scale mixture (an infinite sum) of &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernels with different characteristic length-scales. It is parameterized by a length-scale parameter \(l&amp;gt;0\) and a scale mixture parameter \(\alpha&amp;gt;0\) Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rationalquadratic#sklearn.gaussian_process.kernels.RationalQuadratic&quot;&gt; &lt;code&gt;RationalQuadratic&lt;/code&gt; &lt;/a&gt;カーネルのスケール混合物（無限和）として見ることができる&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; の&lt;/a&gt;異なる特性長さスケールを有するカーネル。これは、長さスケールパラメーター\（l&amp;gt; 0 \）およびスケール混合パラメーター\（\ alpha&amp;gt; 0 \）によってパラメーター化されます。現時点では、\（l \）がスカラーである等方性バリアントのみがサポートされています。カーネルは以下によって与えられます：</target>
        </trans-unit>
        <trans-unit id="a0d4e8e5df8534d7f797dec945fa5951797b46d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt;&lt;code&gt;RBF&lt;/code&gt;&lt;/a&gt; kernel is a stationary kernel. It is also known as the &amp;ldquo;squared exponential&amp;rdquo; kernel. It is parameterized by a length-scale parameter \(l&amp;gt;0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.gaussian_process.kernels.rbf#sklearn.gaussian_process.kernels.RBF&quot;&gt; &lt;code&gt;RBF&lt;/code&gt; の&lt;/a&gt;カーネルは、静止したカーネルです。「二乗指数」カーネルとしても知られています。これは、長さスケールパラメーター\（l&amp;gt; 0 \）によってパラメーター化されます。これは、スカラー（カーネルの等方性バリアント）または入力と同じ次元数のベクトル\（x \）（異方性バリアント）のいずれかです。カーネルの）。カーネルは以下によって与えられます：</target>
        </trans-unit>
        <trans-unit id="82f3fd9dd57bf0bc3cf4c6bc458ae2db6dc1ab71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.knnimputer#sklearn.impute.KNNImputer&quot;&gt;&lt;code&gt;KNNImputer&lt;/code&gt;&lt;/a&gt; class provides imputation for filling in missing values using the k-Nearest Neighbors approach. By default, a euclidean distance metric that supports missing values, &lt;code&gt;nan_euclidean_distances&lt;/code&gt;, is used to find the nearest neighbors. Each missing feature is imputed using values from &lt;code&gt;n_neighbors&lt;/code&gt; nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. If a sample has more than one feature missing, then the neighbors for that sample can be different depending on the particular feature being imputed. When the number of available neighbors is less than &lt;code&gt;n_neighbors&lt;/code&gt; and there are no defined distances to the training set, the training set average for that feature is used during imputation. If there is at least one neighbor with a defined distance, the weighted or unweighted average of the remaining neighbors will be used during imputation. If a feature is always missing in training, it is removed during &lt;code&gt;transform&lt;/code&gt;. For more information on the methodology, see ref. &lt;a href=&quot;#ol2001&quot; id=&quot;id5&quot;&gt;[OL2001]&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.knnimputer#sklearn.impute.KNNImputer&quot;&gt; &lt;code&gt;KNNImputer&lt;/code&gt; の&lt;/a&gt;クラスは、k最近傍法を用いて欠損値を埋めるための代入を提供します。デフォルトでは、欠落値をサポートするユークリッド距離メトリック &lt;code&gt;nan_euclidean_distances&lt;/code&gt; が、最近傍を見つけるために使用されます。欠落している各機能は、その機能の値を持つ &lt;code&gt;n_neighbors&lt;/code&gt; 最近傍からの値を使用して代入されます。ネイバーの特徴は、均一に平均化されるか、各ネイバーまでの距離によって重み付けされます。サンプルに複数の特徴が欠落している場合、そのサンプルの近傍は、代入される特定の特徴に応じて異なる可能性があります。使用可能なネイバーの数が &lt;code&gt;n_neighbors&lt;/code&gt; 未満の場合トレーニングセットまでの距離が定義されていない場合、そのフィーチャのトレーニングセットの平均が代入中に使用されます。定義された距離を持つネイバーが少なくとも1つある場合、残りのネイバーの加重平均または非加重平均が代入中に使用されます。トレーニングで機能が常に欠落している場合、その機能は &lt;code&gt;transform&lt;/code&gt; 中に削除されます。方法論の詳細については、参考文献を参照してください。&lt;a href=&quot;#ol2001&quot; id=&quot;id5&quot;&gt;[OL2001]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8f4b1aa7c1e397df865fdc8d1fd65546b5eaaf2f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; の&lt;/a&gt;変圧器は、データセット内の欠損値の存在を示すバイナリ行列を対応にデータセットを変換するのに有用です。この変換は補完と組み合わせて使用​​すると便利です。補完を使用する場合、どの値が欠落していたかについての情報を保持することは有益です。</target>
        </trans-unit>
        <trans-unit id="a7157e982e0dbd339518050ff3330356266a7d9d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative. Note that both the &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;IterativeImputer&lt;/code&gt;&lt;/a&gt; have the boolean parameter &lt;code&gt;add_indicator&lt;/code&gt; (&lt;code&gt;False&lt;/code&gt; by default) which when set to &lt;code&gt;True&lt;/code&gt; provides a convenient way of stacking the output of the &lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transformer with the output of the imputer.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; の&lt;/a&gt;変圧器は、データセット内の欠損値の存在を示すバイナリ行列を対応にデータセットを変換するのに有用です。この変換は、代入と組み合わせて使用​​すると便利です。代入を使用する場合、欠落していた値に関する情報を保持することは有益な場合があります。&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;IterativeImputer&lt;/code&gt; の&lt;/a&gt;両方にブールパラメーター &lt;code&gt;add_indicator&lt;/code&gt; （デフォルトでは &lt;code&gt;False&lt;/code&gt; ）があり、 &lt;code&gt;True&lt;/code&gt; に設定すると、&lt;a href=&quot;generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;トランスフォーマーの出力を代入器の出力とスタックする便利な方法を提供することに注意してください。</target>
        </trans-unit>
        <trans-unit id="c0c9736c8ad276e3deabee46eb181026e0204e8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports categorical data represented as string values or pandas categoricals when using the &lt;code&gt;'most_frequent'&lt;/code&gt; or &lt;code&gt;'constant'&lt;/code&gt; strategy:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; の&lt;/a&gt;クラスには、使用している場合、文字列値またはパンダcategoricalsとして表さカテゴリーデータサポート &lt;code&gt;'most_frequent'&lt;/code&gt; または &lt;code&gt;'constant'&lt;/code&gt; の戦略を：</target>
        </trans-unit>
        <trans-unit id="4d17103c250c5ab6ac126fd9a857f81de53fed6f" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class also supports sparse matrices:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; の&lt;/a&gt;クラスには、スパース行列をサポートしています。</target>
        </trans-unit>
        <trans-unit id="618df5d6360d655fcf582933900e1cb3bcf02379" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt;&lt;code&gt;SimpleImputer&lt;/code&gt;&lt;/a&gt; class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. This class also allows for different missing values encodings.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.impute.simpleimputer#sklearn.impute.SimpleImputer&quot;&gt; &lt;code&gt;SimpleImputer&lt;/code&gt; の&lt;/a&gt;クラスでは、欠損値を帰するための基本的な戦略を提供します。欠落値は、提供された定数値を使用して、または欠落値が配置されている各列の統計（平均、中央値、または最も頻度の高い）を使用して補完できます。このクラスでは、さまざまな欠損値エンコーディングも可能です。</target>
        </trans-unit>
        <trans-unit id="68b4ceed0ca0d6a56ff0860f4ead39fbe0f8312e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt; function calculates the feature importance of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;estimators&lt;/a&gt; for a given dataset. The &lt;code&gt;n_repeats&lt;/code&gt; parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;permutation_importance&lt;/code&gt; の&lt;/a&gt;機能はの機能の重要性を算出し、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimators&quot;&gt;推定&lt;/a&gt;与えられたデータセットのを。 &lt;code&gt;n_repeats&lt;/code&gt; 機能がランダムにシャッフルされた回数を設定し、特徴重要度のサンプルを返すパラメータ。</target>
        </trans-unit>
        <trans-unit id="6f59968771d1dbbd03a744853045d3c0b7aa414b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt;&lt;code&gt;RBFSampler&lt;/code&gt;&lt;/a&gt; constructs an approximate mapping for the radial basis function kernel, also known as &lt;em&gt;Random Kitchen Sinks&lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007]&lt;/a&gt;. This transformation can be used to explicitly model a kernel map, prior to applying a linear algorithm, for example a linear SVM:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.kernel_approximation.rbfsampler#sklearn.kernel_approximation.RBFSampler&quot;&gt; &lt;code&gt;RBFSampler&lt;/code&gt; は、&lt;/a&gt;としても知られているラジアル基底関数カーネルの近似マッピング、構築&lt;em&gt;ランダムキッチンシンク&lt;/em&gt;&lt;a href=&quot;#rr2007&quot; id=&quot;id2&quot;&gt;[RR2007を]&lt;/a&gt;。この変換は、線形SVMなどの線形アルゴリズムを適用する前に、カーネルマップを明示的にモデル化するために使用できます。</target>
        </trans-unit>
        <trans-unit id="44948166b7a6695399209dd8e1e1f1af0b0058e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; differs from using &lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt;&lt;code&gt;SGDRegressor&lt;/code&gt;&lt;/a&gt; with loss set to &lt;code&gt;huber&lt;/code&gt; in the following ways.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; の&lt;/a&gt;使用と異なっ&lt;a href=&quot;generated/sklearn.linear_model.sgdregressor#sklearn.linear_model.SGDRegressor&quot;&gt; &lt;code&gt;SGDRegressor&lt;/code&gt; を&lt;/a&gt;する損失セットで &lt;code&gt;huber&lt;/code&gt; 、次の方法インチ</target>
        </trans-unit>
        <trans-unit id="7ab9e90f2b3f808e98761c90cab46994be6820bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt;&lt;code&gt;HuberRegressor&lt;/code&gt;&lt;/a&gt; is different to &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; because it applies a linear loss to samples that are classified as outliers. A sample is classified as an inlier if the absolute error of that sample is lesser than a certain threshold. It differs from &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt;&lt;code&gt;RANSACRegressor&lt;/code&gt;&lt;/a&gt; because it does not ignore the effect of the outliers but gives a lesser weight to them.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.huberregressor#sklearn.linear_model.HuberRegressor&quot;&gt; &lt;code&gt;HuberRegressor&lt;/code&gt; は&lt;/a&gt;と異なる&lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt;それは外れ値として分類されているサンプルに直線的損失を適用するため。サンプルの絶対誤差が特定のしきい値よりも小さい場合、サンプルはインライアとして分類されます。外れ値の影響を無視せず、外れ値の重みを小さくするため、&lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.linear_model.ransacregressor#sklearn.linear_model.RANSACRegressor&quot;&gt; &lt;code&gt;RANSACRegressor&lt;/code&gt; &lt;/a&gt;とは異なります。</target>
        </trans-unit>
        <trans-unit id="6c9667130f9758bb96a7c943daf0a6616eced1f9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt; &lt;code&gt;Lasso&lt;/code&gt; &lt;/a&gt;スパース係数を推定線形モデルです。ゼロ以外の係数が少ない解を好む傾向があるため、状況によっては便利です。これにより、特定の解が依存する特徴の数が効果的に削減されます。このため、ラッソとそのバリアントは、圧縮センシングの分野の基本です。特定の条件下では、ゼロ以外の係数の正確なセットを回復できます（&lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;圧縮センシング：L1事前（Lasso）を使用した断層撮影の再構成を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="70ef4a25a40856b26fd987533d68c36540345c20" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt;&lt;code&gt;Lasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent. For this reason, the Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero weights (see &lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;Compressive sensing: tomography reconstruction with L1 prior (Lasso)&lt;/a&gt;).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.lasso#sklearn.linear_model.Lasso&quot;&gt; &lt;code&gt;Lasso&lt;/code&gt; &lt;/a&gt;スパース係数を推定線形モデルです。これは、パラメーター値の少ないソリューションを優先する傾向があるため、状況によっては有用であり、所定のソリューションが依存する変数の数を効果的に削減します。このため、投げ縄とその変形は、圧縮センシングの分野の基本です。特定の条件下では、ゼロ以外の重みの正確なセットを復元できます（「&lt;a href=&quot;../auto_examples/applications/plot_tomography_l1_reconstruction#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py&quot;&gt;圧縮センシング：L1以前のトモグラフィー再構成（投げ縄）」を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="eec44edb57da642e68d30eaaa1191346c0a6b209" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt; &lt;code&gt;MultiTaskElasticNet&lt;/code&gt; は&lt;/a&gt;共同重回帰問題の疎係数を推定する弾性ネットモデルである： &lt;code&gt;Y&lt;/code&gt; は、形状の2次元アレイである &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; 。制約は、選択された機能が、タスクとも呼ばれるすべての回帰問題で同じであるということです。</target>
        </trans-unit>
        <trans-unit id="8c1095adf7bd87312f73373efdee9c54e778b1be" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt;&lt;code&gt;MultiTaskElasticNet&lt;/code&gt;&lt;/a&gt; is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;Y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.multitaskelasticnet#sklearn.linear_model.MultiTaskElasticNet&quot;&gt; &lt;code&gt;MultiTaskElasticNet&lt;/code&gt; は&lt;/a&gt;：共同重回帰問題の疎係数を推定する弾性ネットモデルである &lt;code&gt;Y&lt;/code&gt; は、形状の2次元アレイである &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; 。制約は、選択された機能が、タスクとも呼ばれるすべての回帰問題で同じであることです。</target>
        </trans-unit>
        <trans-unit id="0855f24dbbabd45aa8775e800911f6fb3f3411c3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt;&lt;code&gt;MultiTaskLasso&lt;/code&gt;&lt;/a&gt; is a linear model that estimates sparse coefficients for multiple regression problems jointly: &lt;code&gt;y&lt;/code&gt; is a 2D array, of shape &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt;. The constraint is that the selected features are the same for all the regression problems, also called tasks.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.multitasklasso#sklearn.linear_model.MultiTaskLasso&quot;&gt; &lt;code&gt;MultiTaskLasso&lt;/code&gt; は&lt;/a&gt;共同重回帰問題の疎係数を推定する線形モデルである： &lt;code&gt;y&lt;/code&gt; は形状の2次元アレイである &lt;code&gt;(n_samples, n_tasks)&lt;/code&gt; 。制約は、選択された機能が、タスクとも呼ばれるすべての回帰問題で同じであることです。</target>
        </trans-unit>
        <trans-unit id="d927ce91bac1b6df649580c487bdf34ce5f21e13" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt;&lt;code&gt;Perceptron&lt;/code&gt;&lt;/a&gt; is another simple classification algorithm suitable for large scale learning. By default:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.perceptron#sklearn.linear_model.Perceptron&quot;&gt; &lt;code&gt;Perceptron&lt;/code&gt; &lt;/a&gt;大規模な学習に適した別の単純な分類アルゴリズムです。デフォルトでは：</target>
        </trans-unit>
        <trans-unit id="114bd6c0908df3918d68db503a6c5b185beb59c6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt;&lt;code&gt;Ridge&lt;/code&gt;&lt;/a&gt; regressor has a classifier variant: &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt;. This classifier first converts binary targets to &lt;code&gt;{-1, 1}&lt;/code&gt; and then treats the problem as a regression task, optimizing the same objective as above. The predicted class corresponds to the sign of the regressor&amp;rsquo;s prediction. For multiclass classification, the problem is treated as multi-output regression, and the predicted class corresponds to the output with the highest value.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.ridge#sklearn.linear_model.Ridge&quot;&gt; &lt;code&gt;Ridge&lt;/code&gt; &lt;/a&gt;回帰は、分類器のバリアントを持っています&lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt; &lt;code&gt;RidgeClassifier&lt;/code&gt; &lt;/a&gt;。この分類器は、最初にバイナリターゲットを &lt;code&gt;{-1, 1}&lt;/code&gt; 変換し、次に問題を回帰タスクとして扱い、上記と同じ目的を最適化します。予測されたクラスは、リグレッサーの予測の符号に対応します。マルチクラス分類の場合、問題はマルチ出力回帰として扱われ、予測されたクラスは最も高い値の出力に対応します。</target>
        </trans-unit>
        <trans-unit id="97c2977337c286541956e3848f1e0d89e23d036d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt;&lt;code&gt;RidgeClassifier&lt;/code&gt;&lt;/a&gt; can be significantly faster than e.g. &lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; with a high number of classes, because it is able to compute the projection matrix \((X^T X)^{-1} X^T\) only once.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.ridgeclassifier#sklearn.linear_model.RidgeClassifier&quot;&gt; &lt;code&gt;RidgeClassifier&lt;/code&gt; は、&lt;/a&gt;例えば、より大幅に速くすることができる&lt;a href=&quot;generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;回のみ- （{1} X ^ T \（X ^ TX）^）は、射影行列を\計算することができるので、クラスの数が多いです。</target>
        </trans-unit>
        <trans-unit id="dc6941408ce5829c04ee30dacb5eec313120d42e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It looses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; の&lt;/a&gt;推定は、複数の次元での中央値の一般化を使用します。したがって、多変量外れ値に対してロバストです。ただし、推定量のロバスト性は問題の次元数とともに急速に低下することに注意してください。それはその堅牢性特性を失い、高次元で通常の最小二乗と同等になります。</target>
        </trans-unit>
        <trans-unit id="6c80a0d39e7d7595f1867b8a38b3ed5fa33131bb" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt;&lt;code&gt;TheilSenRegressor&lt;/code&gt;&lt;/a&gt; estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It loses its robustness properties and becomes no better than an ordinary least squares in high dimension.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.linear_model.theilsenregressor#sklearn.linear_model.TheilSenRegressor&quot;&gt; &lt;code&gt;TheilSenRegressor&lt;/code&gt; の&lt;/a&gt;推定は、複数の次元での中央値の一般化を使用します。したがって、多変量外れ値に対してロバストです。ただし、推定量のロバスト性は、問題の次元によって急速に低下することに注意してください。堅牢性が失われ、高次元の通常の最小二乗法に勝るものはありません。</target>
        </trans-unit>
        <trans-unit id="497dd0db8e84137ac4b140cff3317a3423c09e22" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt;&lt;code&gt;accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;accuracy&lt;/a&gt;, either the fraction (default) or the count (normalize=False) of correct predictions.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.accuracy_score#sklearn.metrics.accuracy_score&quot;&gt; &lt;code&gt;accuracy_score&lt;/code&gt; の&lt;/a&gt;関数は計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;精度を&lt;/a&gt;正しい予測のいずれかの画分（デフォルト）またはカウント（正規=偽）。</target>
        </trans-unit>
        <trans-unit id="734b9a83298cb0e5bb404a0eb951bb89a38c30c1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数が計算&lt;a href=&quot;http://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;平均精度&lt;/a&gt;予測スコアから（AP）を。値は0から1の間で、より高い方が良いです。APは次のよ​​うに定義されます</target>
        </trans-unit>
        <trans-unit id="e82eb3ff042c4b3a5e1b920dfccc7718db2306b1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;average precision&lt;/a&gt; (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数が計算&lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;amp;oldid=793358396#Average_precision&quot;&gt;平均精度&lt;/a&gt;予測スコアから（AP）を。値は0から1の間で、高いほど良いです。APは次のよ​​うに定義されます</target>
        </trans-unit>
        <trans-unit id="4c1e547613cb8b25282a0a1d2e2d0fa8b86fab4a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt;&lt;code&gt;balanced_accuracy_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;balanced accuracy&lt;/a&gt;, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.balanced_accuracy_score#sklearn.metrics.balanced_accuracy_score&quot;&gt; &lt;code&gt;balanced_accuracy_score&lt;/code&gt; の&lt;/a&gt;関数は、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Accuracy_and_precision&quot;&gt;バランス精度&lt;/a&gt;不均衡データセットに膨張性能見積もりを回避します。これは、クラスごとの再現スコアのマクロ平均です。つまり、各サンプルがその真のクラスの逆有病率に従って重み付けされている生の精度です。したがって、バランスのとれたデータセットの場合、スコアは正確さに等しくなります。</target>
        </trans-unit>
        <trans-unit id="6c29a08df4ccee7316d3d3b84f8a1be99122d005" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;brier_score_loss&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;Brier score&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt; &lt;code&gt;brier_score_loss&lt;/code&gt; &lt;/a&gt;関数は、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Brier_score&quot;&gt;ブライヤースコア&lt;/a&gt;バイナリクラスのために。ウィキペディアの引用：</target>
        </trans-unit>
        <trans-unit id="446d2ff4c24d7bf4bbe8a92416191f1e2b3de72b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt;&lt;code&gt;sklearn.metrics.brier_score_loss&lt;/code&gt;&lt;/a&gt; may be used to evaluate how well a classifier is calibrated.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.brier_score_loss#sklearn.metrics.brier_score_loss&quot;&gt; &lt;code&gt;sklearn.metrics.brier_score_loss&lt;/code&gt; は、&lt;/a&gt;分類器が校正されてどれだけ評価するために使用することができます。</target>
        </trans-unit>
        <trans-unit id="80ef899573ebb3be6112621f7df5aadf4a0d99d9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt;&lt;code&gt;classification_report&lt;/code&gt;&lt;/a&gt; function builds a text report showing the main classification metrics. Here is a small example with custom &lt;code&gt;target_names&lt;/code&gt; and inferred labels:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.classification_report#sklearn.metrics.classification_report&quot;&gt; &lt;code&gt;classification_report&lt;/code&gt; の&lt;/a&gt;機能は、メインの分類指標を示すテキスト形式のレポートを作成します。カスタム &lt;code&gt;target_names&lt;/code&gt; と推定ラベルを使用した小さな例を次に示します。</target>
        </trans-unit>
        <trans-unit id="297cbd08a7b9d6cdee2db0fac772b51c60ecb158" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion matrix&lt;/a&gt; with each row corresponding to the true class (Wikipedia and other references may use different convention for axes).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; の&lt;/a&gt;関数は、計算することによって分類精度を評価する&lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;混同行列を&lt;/a&gt;（ウィキペディアおよび他の参考文献は、軸の異なる規則を使用してもよい）各行が真のクラスに対応します。</target>
        </trans-unit>
        <trans-unit id="646495d784f725b3203da7b1895753c47a46c957" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt; function evaluates classification accuracy by computing the confusion matrix with each row corresponding to the true class &amp;lt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt;&amp;gt;`_. (Wikipedia and other references may use different convention for axes.)</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; の&lt;/a&gt;機能は、真のクラスに対応する各行との混同行列を計算することによって分類精度を評価する&amp;lt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt; &amp;gt; `_。（ウィキペディアや他のリファレンスでは、軸に異なる規則を使用している場合があります。）</target>
        </trans-unit>
        <trans-unit id="627c762ce2611d603b6cf9dd93706bacfe9a64ab" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt;&lt;code&gt;coverage_error&lt;/code&gt;&lt;/a&gt; function computes the average number of labels that have to be included in the final prediction such that all true labels are predicted. This is useful if you want to know how many top-scored-labels you have to predict in average without missing any true one. The best value of this metrics is thus the average number of true labels.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.coverage_error#sklearn.metrics.coverage_error&quot;&gt; &lt;code&gt;coverage_error&lt;/code&gt; の&lt;/a&gt;機能は、全ての真のラベルが予測されるように、最終的な予測に含まれなければならないラベルの平均数を計算します。これは、真のラベルを見落とすことなく、平均して予測する必要のあるトップスコアラベルの数を知りたい場合に役立ちます。したがって、このメトリックの最良の値は、真のラベルの平均数です。</target>
        </trans-unit>
        <trans-unit id="365c5eb64f0dc2e33be205a551210f568e81546d" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;explained variance regression score&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; は&lt;/a&gt;計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Explained_variation&quot;&gt;説明された分散回帰スコアを&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="16accfb21d784810c328541c85b1894b818cde8e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt;&lt;code&gt;hamming_loss&lt;/code&gt;&lt;/a&gt; computes the average Hamming loss or &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;Hamming distance&lt;/a&gt; between two sets of samples.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.hamming_loss#sklearn.metrics.hamming_loss&quot;&gt; &lt;code&gt;hamming_loss&lt;/code&gt; は&lt;/a&gt;平均ハミング損失又は計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Hamming_distance&quot;&gt;ハミング距離&lt;/a&gt;サンプルの2つのセット間を。</target>
        </trans-unit>
        <trans-unit id="6d1238c9791f472ba1850e50c0898d87bebfa2d3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; function computes the average distance between the model and the data using &lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;hinge loss&lt;/a&gt;, a one-sided metric that considers only prediction errors. (Hinge loss is used in maximal margin classifiers such as support vector machines.)</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt;関数は、モデルと使用してデータ間の平均距離計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Hinge_loss&quot;&gt;ヒンジ損失を&lt;/a&gt;、唯一の予測誤差を考慮し、その1つのメトリックは、両面。（ヒンジ損失は、サポートベクターマシンなどの最大マージン分類器で使用されます。）</target>
        </trans-unit>
        <trans-unit id="8897c326f42ba94a97047f2763d3dfdfd57b8bb8" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_score#sklearn.metrics.jaccard_score&quot;&gt;&lt;code&gt;jaccard_score&lt;/code&gt;&lt;/a&gt; function computes the average of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.jaccard_score#sklearn.metrics.jaccard_score&quot;&gt; &lt;code&gt;jaccard_score&lt;/code&gt; の&lt;/a&gt;関数は、平均計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;ジャカード類似性係数&lt;/a&gt;ラベルセットの対の間にもジャカードインデックスと呼ばれるが、、。</target>
        </trans-unit>
        <trans-unit id="29930da8eb2c0b1ff7129cc1cbfbb0416883031e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt;&lt;code&gt;jaccard_similarity_score&lt;/code&gt;&lt;/a&gt; function computes the average (default) or sum of &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard similarity coefficients&lt;/a&gt;, also called the Jaccard index, between pairs of label sets.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.jaccard_similarity_score#sklearn.metrics.jaccard_similarity_score&quot;&gt; &lt;code&gt;jaccard_similarity_score&lt;/code&gt; の&lt;/a&gt;関数の平均（デフォルト）または和演算&lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;ジャカード類似性係数&lt;/a&gt;ラベルセットの対の間にもジャカードインデックスと呼ばれるが、、。</target>
        </trans-unit>
        <trans-unit id="cbf6f35f94b93c090ec2e48a35d245f91dcfca65" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt;&lt;code&gt;label_ranking_average_precision_score&lt;/code&gt;&lt;/a&gt; function implements label ranking average precision (LRAP). This metric is linked to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; function, but is based on the notion of label ranking instead of precision and recall.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.label_ranking_average_precision_score#sklearn.metrics.label_ranking_average_precision_score&quot;&gt; &lt;code&gt;label_ranking_average_precision_score&lt;/code&gt; の&lt;/a&gt;機能の実装は、ランキングの平均精度（LRAP）を標識します。このメトリックは&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;関数にリンクされていますが、精度と再現率ではなく、ラベルランキングの概念に基づいています。</target>
        </trans-unit>
        <trans-unit id="79620a85c10a9be19922ad33cc7395bed79c9e4e" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt;&lt;code&gt;label_ranking_loss&lt;/code&gt;&lt;/a&gt; function computes the ranking loss which averages over the samples the number of label pairs that are incorrectly ordered, i.e. true labels have a lower score than false labels, weighted by the inverse of the number of ordered pairs of false and true labels. The lowest achievable ranking loss is zero.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.label_ranking_loss#sklearn.metrics.label_ranking_loss&quot;&gt; &lt;code&gt;label_ranking_loss&lt;/code&gt; &lt;/a&gt;機能は、真のラベルが偽と真のラベルの順序対の数の逆数で重み付けし、偽のラベルよりも低いスコアを持っていたサンプルを超える平均値が誤って注文しているラベルのペアの数、すなわち、ランキングの損失を計算します。達成可能な最低のランキング損失はゼロです。</target>
        </trans-unit>
        <trans-unit id="4b0810d3cef1ca02b990e21053d774c24a0e430b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt;&lt;code&gt;log_loss&lt;/code&gt;&lt;/a&gt; function computes log loss given a list of ground-truth labels and a probability matrix, as returned by an estimator&amp;rsquo;s &lt;code&gt;predict_proba&lt;/code&gt; method.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.log_loss#sklearn.metrics.log_loss&quot;&gt; &lt;code&gt;log_loss&lt;/code&gt; の&lt;/a&gt;関数計算するには、推定ので返される損失は、グラウンドトゥルースラベルと確率行列のリストを与えられたログ &lt;code&gt;predict_proba&lt;/code&gt; の方法。</target>
        </trans-unit>
        <trans-unit id="3661b0b19cd7cbd747b2bf1ce7b4a383102a7abe" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt;&lt;code&gt;matthews_corrcoef&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;Matthew&amp;rsquo;s correlation coefficient (MCC)&lt;/a&gt; for binary classes. Quoting Wikipedia:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.matthews_corrcoef#sklearn.metrics.matthews_corrcoef&quot;&gt; &lt;code&gt;matthews_corrcoef&lt;/code&gt; の&lt;/a&gt;関数は、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Matthews_correlation_coefficient&quot;&gt;マシューの相関係数（MCC）を&lt;/a&gt;バイナリクラスの。ウィキペディアの引用：</target>
        </trans-unit>
        <trans-unit id="61afc8dcca66cd062b78b06b9f6f1f6a381f8368" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt; &lt;code&gt;max_error&lt;/code&gt; は、&lt;/a&gt;多出力をサポートしていません。</target>
        </trans-unit>
        <trans-unit id="6d67557cc032f22cb8c3e56bc9812e04ade8f8ad" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt;&lt;code&gt;max_error&lt;/code&gt;&lt;/a&gt; function computes the maximum &lt;a href=&quot;https://en.wikipedia.org/wiki/Errors_and_residuals&quot;&gt;residual error&lt;/a&gt; , a metric that captures the worst case error between the predicted value and the true value. In a perfectly fitted single output regression model, &lt;code&gt;max_error&lt;/code&gt; would be &lt;code&gt;0&lt;/code&gt; on the training set and though this would be highly unlikely in the real world, this metric shows the extent of error that the model had when it was fitted.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.max_error#sklearn.metrics.max_error&quot;&gt; &lt;code&gt;max_error&lt;/code&gt; の&lt;/a&gt;機能は、最大計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Errors_and_residuals&quot;&gt;残差&lt;/a&gt;予測値と真値との間の最悪の場合のエラーを捕捉する、メトリック。完全に適合した単一出力回帰モデルでは、トレーニングセットで &lt;code&gt;max_error&lt;/code&gt; は &lt;code&gt;0&lt;/code&gt; になります。これは現実の世界ではほとんどあり得ませんが、このメトリックは、モデルが適合したときに発生したエラーの程度を示します。</target>
        </trans-unit>
        <trans-unit id="8af6e2db7d7843522a3d6755e0b8d1e9cbd1e8f1" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt;&lt;code&gt;mean_absolute_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;mean absolute error&lt;/a&gt;, a risk metric corresponding to the expected value of the absolute error loss or \(l1\)-norm loss.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.mean_absolute_error#sklearn.metrics.mean_absolute_error&quot;&gt; &lt;code&gt;mean_absolute_error&lt;/code&gt; の&lt;/a&gt;関数は、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_absolute_error&quot;&gt;、平均絶対誤差&lt;/a&gt;ノルム喪失- 、絶対誤差の損失や\（L1 \）の期待値に対応するメトリックリスク。</target>
        </trans-unit>
        <trans-unit id="798074cb4600d0906a9ad4975942309f6067f034" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt;&lt;code&gt;mean_squared_error&lt;/code&gt;&lt;/a&gt; function computes &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;mean square error&lt;/a&gt;, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.mean_squared_error#sklearn.metrics.mean_squared_error&quot;&gt; &lt;code&gt;mean_squared_error&lt;/code&gt; の&lt;/a&gt;関数は、計算し&lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_squared_error&quot;&gt;た平均二乗誤差&lt;/a&gt;、二乗（二次）エラー又は損失の期待値に対応するメトリックリスク。</target>
        </trans-unit>
        <trans-unit id="e4bbccf6d12a691e935e91e2611be809f1bb4329" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt;&lt;code&gt;mean_squared_log_error&lt;/code&gt;&lt;/a&gt; function computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.mean_squared_log_error#sklearn.metrics.mean_squared_log_error&quot;&gt; &lt;code&gt;mean_squared_log_error&lt;/code&gt; の&lt;/a&gt;関数は、二乗対数（二次）エラー又は損失の期待値に対応するメトリックリスクを計算します。</target>
        </trans-unit>
        <trans-unit id="9206d6989b69732d0750b8f7b0f0cca35f16a502" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt;&lt;code&gt;mean_tweedie_deviance&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance&quot;&gt;mean Tweedie deviance error&lt;/a&gt; with a &lt;code&gt;power&lt;/code&gt; parameter (\(p\)). This is a metric that elicits predicted expectation values of regression targets.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.mean_tweedie_deviance#sklearn.metrics.mean_tweedie_deviance&quot;&gt; &lt;code&gt;mean_tweedie_deviance&lt;/code&gt; の&lt;/a&gt;関数は、計算し&lt;a href=&quot;https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance&quot;&gt;た平均トゥイーディーのずれ誤差を&lt;/a&gt;用いて &lt;code&gt;power&lt;/code&gt; パラメータ（\（P \））。これは、回帰ターゲットの予測された期待値を引き出すメトリックです。</target>
        </trans-unit>
        <trans-unit id="39f48c0bbd67ae6ad01f06368c176486b0da9e3b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; does not support multioutput.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; は、&lt;/a&gt;多出力をサポートしていません。</target>
        </trans-unit>
        <trans-unit id="4c03eab2aa446025510f65f3a7e796a70c97a820" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt;&lt;code&gt;median_absolute_error&lt;/code&gt;&lt;/a&gt; is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.median_absolute_error#sklearn.metrics.median_absolute_error&quot;&gt; &lt;code&gt;median_absolute_error&lt;/code&gt; は&lt;/a&gt;、それが外れ値に対してロバストであるため、特に興味深いものです。損失は​​、ターゲットと予測の間のすべての絶対差の中央値を取ることによって計算されます。</target>
        </trans-unit>
        <trans-unit id="9e08c2b58ff3ad56580920cccb403426006e1ddc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt;&lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;&lt;/a&gt; function computes class-wise (default) or sample-wise (samplewise=True) multilabel confusion matrix to evaluate the accuracy of a classification. multilabel_confusion_matrix also treats multiclass data as if it were multilabel, as this is a transformation commonly applied to evaluate multiclass problems with binary classification metrics (such as precision, recall, etc.).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.multilabel_confusion_matrix#sklearn.metrics.multilabel_confusion_matrix&quot;&gt; &lt;code&gt;multilabel_confusion_matrix&lt;/code&gt; の&lt;/a&gt;機能は、クラスごと（デフォルト）または分類の精度を評価するためにsamplewise（samplewise =真）マルチラベル混同行列を計算します。multilabel_confusion_matrixは、マルチラベルデータをマルチラベルであるかのように扱います。これは、バイナリ分類メトリック（適合率、再現率など）でマルチクラス問題を評価するために一般的に適用される変換であるためです。</target>
        </trans-unit>
        <trans-unit id="9f5631acff2238ea5bcb79376fef6d2e143756a6" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt;&lt;code&gt;precision_recall_curve&lt;/code&gt;&lt;/a&gt; computes a precision-recall curve from the ground truth label and a score given by the classifier by varying a decision threshold.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.precision_recall_curve#sklearn.metrics.precision_recall_curve&quot;&gt; &lt;code&gt;precision_recall_curve&lt;/code&gt; は&lt;/a&gt;グランドトゥルースラベルから精密リコール曲線と判定閾値を変化させることにより、分類器によって与えられたスコアを計算します。</target>
        </trans-unit>
        <trans-unit id="d16f1c84f45a895677960253a6c6c45cf8b671e5" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt;&lt;code&gt;explained_variance_score&lt;/code&gt;&lt;/a&gt; accept an additional value &lt;code&gt;'variance_weighted'&lt;/code&gt; for the &lt;code&gt;multioutput&lt;/code&gt; parameter. This option leads to a weighting of each individual score by the variance of the corresponding target variable. This setting quantifies the globally captured unscaled variance. If the target variables are of different scale, then this score puts more importance on well explaining the higher variance variables. &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; is the default value for &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; for backward compatibility. This will be changed to &lt;code&gt;uniform_average&lt;/code&gt; in the future.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.metrics.explained_variance_score#sklearn.metrics.explained_variance_score&quot;&gt; &lt;code&gt;explained_variance_score&lt;/code&gt; は&lt;/a&gt;付加価値受け入れる &lt;code&gt;'variance_weighted'&lt;/code&gt; のための &lt;code&gt;multioutput&lt;/code&gt; パラメータを。このオプションは、対応するターゲット変数の分散による各個々のスコアの重み付けにつながります。この設定は、グローバルにキャプチャされたスケーリングされていない分散を定量化します。ターゲット変数のスケールが異なる場合、このスコアは、より高い分散変数をうまく説明することをより重視します。 &lt;code&gt;multioutput='variance_weighted'&lt;/code&gt; は、下位互換性のための&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; &lt;/a&gt;のデフォルト値です。これは将来的に &lt;code&gt;uniform_average&lt;/code&gt; に変更されます。</target>
        </trans-unit>
        <trans-unit id="093b69e0a2a3ccbb33c0abc5ad459d307bcf6553" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes R&amp;sup2;, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;. It provides a measure of how well future samples are likely to be predicted by the model. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; の&lt;/a&gt;機能は、R2、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;決意の係数&lt;/a&gt;。これは、将来のサンプルがモデルによってどれほど予測される可能性が高いかを示す尺度を提供します。最良のスコアは1.0であり、負の値になる可能性があります（モデルが恣意的に悪化する可能性があるため）。入力フィーチャを無視して、yの期待値を常に予測する定数モデルの場合、R ^ 2スコアは0.0になります。</target>
        </trans-unit>
        <trans-unit id="38084709322f1f775abaac153e1595951318cede" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt;&lt;code&gt;r2_score&lt;/code&gt;&lt;/a&gt; function computes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;coefficient of determination&lt;/a&gt;, usually denoted as R&amp;sup2;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.r2_score#sklearn.metrics.r2_score&quot;&gt; &lt;code&gt;r2_score&lt;/code&gt; の&lt;/a&gt;関数は、計算&lt;a href=&quot;https://en.wikipedia.org/wiki/Coefficient_of_determination&quot;&gt;決意係数&lt;/a&gt;通常R&amp;sup2;と表記し、。</target>
        </trans-unit>
        <trans-unit id="4fdc4c3e65c0a2a9ffbf753fef92ef0300417867" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function can also be used in multi-class classification. Two averaging strategies are currently supported: the one-vs-one algorithm computes the average of the pairwise ROC AUC scores, and the one-vs-rest algorithm computes the average of the ROC AUC scores for each class against all other classes. In both cases, the predicted labels are provided in an array with values from 0 to &lt;code&gt;n_classes&lt;/code&gt;, and the scores correspond to the probability estimates that a sample belongs to a particular class. The OvO and OvR algorithms support weighting uniformly (&lt;code&gt;average='macro'&lt;/code&gt;) and by prevalence (&lt;code&gt;average='weighted'&lt;/code&gt;).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; の&lt;/a&gt;機能は、マルチクラス分類に使用することができます。現在、2つの平均化戦略がサポートされています。1対1アルゴリズムは、ペアワイズROC AUCスコアの平均を計算し、1対レストアルゴリズムは、他のすべてのクラスに対する各クラスのROCAUCスコアの平均を計算します。どちらの場合も、予測されたラベルは0から &lt;code&gt;n_classes&lt;/code&gt; までの値を持つ配列で提供され、スコアはサンプルが特定のクラスに属する確率推定に対応します。 OvOおよびOvRアルゴリズムは、均一な重み付け（ &lt;code&gt;average='macro'&lt;/code&gt; ）および普及率による &lt;code&gt;average='weighted'&lt;/code&gt; （average = 'weighted'）をサポートします。</target>
        </trans-unit>
        <trans-unit id="6cdf15299db25ef1f3b3628cdbe3b0de1b0d0ab3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function computes the area under the receiver operating characteristic (ROC) curve, which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number. For more information see the &lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;Wikipedia article on AUC&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; の&lt;/a&gt;機能はまた、AUC又はAUROCで示される受信者動作特性（ROC）曲線下面積を計算します。roc曲線の下の面積を計算することにより、曲線情報が1つの数値に要約されます。詳細については、&lt;a href=&quot;https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot;&gt;AUCに関するWikipediaの記事を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="fbc2259a8dc85fa7ed24780d0f0e2ac678fbcad9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; function computes the sum or the average of the 0-1 classification loss (\(L_{0-1}\)) over \(n_{\text{samples}}\). By default, the function normalizes over the sample. To get the sum of the \(L_{0-1}\), set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; &lt;/a&gt;関数は和または0-1分類損失（\（L_ {0-1} \））上\（N _ {\テキスト{サンプル}} \）の平均値を算出します。デフォルトでは、関数はサンプルを正規化します。\（L_ {0-1} \）の合計を取得するには、 &lt;code&gt;normalize&lt;/code&gt; を &lt;code&gt;False&lt;/code&gt; に設定します。</target>
        </trans-unit>
        <trans-unit id="0ce78ef531a28f4df4b9620cf7454901e00bf965" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt;&lt;code&gt;BayesianGaussianMixture&lt;/code&gt;&lt;/a&gt; object implements a variant of the Gaussian mixture model with variational inference algorithms. The API is similar as the one defined by &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.bayesiangaussianmixture#sklearn.mixture.BayesianGaussianMixture&quot;&gt; &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; の&lt;/a&gt;オブジェクトは、変分推論アルゴリズムを有するガウス混合モデルの変形を実現します。APIは&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; で&lt;/a&gt;定義されているものと似ています。</target>
        </trans-unit>
        <trans-unit id="7755b185d3bd9567bc77a31c3d84e8be2c332f90" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; comes with different options to constrain the covariance of the difference classes estimated: spherical, diagonal, tied or full covariance.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; は&lt;/a&gt;、球状の対角線、縛られたり、完全な共分散：推定差異クラスの共分散を拘束するためにさまざまなオプションが付属しています。</target>
        </trans-unit>
        <trans-unit id="9cb1ef419e28ff804b54eef9fc18747641996ac9" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt;&lt;code&gt;GaussianMixture&lt;/code&gt;&lt;/a&gt; object implements the &lt;a href=&quot;#expectation-maximization&quot;&gt;expectation-maximization&lt;/a&gt; (EM) algorithm for fitting mixture-of-Gaussian models. It can also draw confidence ellipsoids for multivariate models, and compute the Bayesian Information Criterion to assess the number of clusters in the data. A &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt;&lt;code&gt;GaussianMixture.fit&lt;/code&gt;&lt;/a&gt; method is provided that learns a Gaussian Mixture Model from train data. Given test data, it can assign to each sample the Gaussian it mostly probably belong to using the &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt;&lt;code&gt;GaussianMixture.predict&lt;/code&gt;&lt;/a&gt; method.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture&quot;&gt; &lt;code&gt;GaussianMixture&lt;/code&gt; の&lt;/a&gt;オブジェクトの実装は、&lt;a href=&quot;#expectation-maximization&quot;&gt;期待値最大化&lt;/a&gt;混合-のガウスモデルをフィッティングするための（EM）アルゴリズム。また、多変量モデルの信頼楕円体を描画し、ベイズ情報量基準を計算して、データ内のクラスター数を評価することもできます。A &lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.fit&quot;&gt; &lt;code&gt;GaussianMixture.fit&lt;/code&gt; の&lt;/a&gt;方法は、列車のデータから学習ガウス混合モデルが提供されます。テストデータが与えられると、&lt;a href=&quot;generated/sklearn.mixture.gaussianmixture#sklearn.mixture.GaussianMixture.predict&quot;&gt; &lt;code&gt;GaussianMixture.predict&lt;/code&gt; &lt;/a&gt;メソッドを使用して、各サンプルにほとんどが属するガウスを割り当てることができます。</target>
        </trans-unit>
        <trans-unit id="0716de4b023c33cd11d454f2784cb63c7a79bbcc" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt;&lt;code&gt;cross_validate&lt;/code&gt;&lt;/a&gt; function differs from &lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt;&lt;code&gt;cross_val_score&lt;/code&gt;&lt;/a&gt; in two ways:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.cross_validate#sklearn.model_selection.cross_validate&quot;&gt; &lt;code&gt;cross_validate&lt;/code&gt; &lt;/a&gt;機能が異なり&lt;a href=&quot;generated/sklearn.model_selection.cross_val_score#sklearn.model_selection.cross_val_score&quot;&gt; &lt;code&gt;cross_val_score&lt;/code&gt; &lt;/a&gt;二つの方法で：</target>
        </trans-unit>
        <trans-unit id="0de55d1a8cabbad74e59064d298db364a4949211" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt;&lt;code&gt;GridSearchCV&lt;/code&gt;&lt;/a&gt; instance implements the usual estimator API: when &amp;ldquo;fitting&amp;rdquo; it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.gridsearchcv#sklearn.model_selection.GridSearchCV&quot;&gt; &lt;code&gt;GridSearchCV&lt;/code&gt; の&lt;/a&gt;インスタンスを実装通常の推定API：データセットの上に「フィッティング」すべてのパラメータ値の可能な組み合わせが評価され、最良の組み合わせが保持されます。</target>
        </trans-unit>
        <trans-unit id="45a8a9b77f54ed1a1a49e1eebdf058e73c1ad33a" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt;&lt;code&gt;GroupShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator behaves as a combination of &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt;&lt;code&gt;LeavePGroupsOut&lt;/code&gt;&lt;/a&gt;, and generates a sequence of randomized partitions in which a subset of groups are held out for each split.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.groupshufflesplit#sklearn.model_selection.GroupShuffleSplit&quot;&gt; &lt;code&gt;GroupShuffleSplit&lt;/code&gt; &lt;/a&gt;イテレータの組み合わせとして動作&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.model_selection.leavepgroupsout#sklearn.model_selection.LeavePGroupsOut&quot;&gt; &lt;code&gt;LeavePGroupsOut&lt;/code&gt; &lt;/a&gt;、およびグループのサブセットが各分割のために保持されたランダム化パーティションのシーケンスを生成します。</target>
        </trans-unit>
        <trans-unit id="ec15ef26f9a075815cd5139e68468c23802a4936" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt;&lt;code&gt;ShuffleSplit&lt;/code&gt;&lt;/a&gt; iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.model_selection.shufflesplit#sklearn.model_selection.ShuffleSplit&quot;&gt; &lt;code&gt;ShuffleSplit&lt;/code&gt; は、&lt;/a&gt;反復子は、独立した列車/テストデータセット分割のユーザ定義された数を生成します。サンプルは最初にシャッフルされ、次にトレーニングとテストセットのペアに分割されます。</target>
        </trans-unit>
        <trans-unit id="9d19931407bdaf26c2091f0ff552c9705b61d84b" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; (LOF) algorithm computes a score (called local outlier factor) reflecting the degree of abnormality of the observations. It measures the local density deviation of a given data point with respect to its neighbors. The idea is to detect the samples that have a substantially lower density than their neighbors.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;（LOF）アルゴリズムは、観測値の異常の程度を反映する（局所的外れ値の因子と呼ばれる）スコアを計算します。これは、特定のデータポイントの近傍に対する局所的な密度偏差を測定します。アイデアは、隣接するサンプルよりも密度が大幅に低いサンプルを検出することです。</target>
        </trans-unit>
        <trans-unit id="7ee66eef276fb6deecd16d4b6508f3c8417f58ed" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier has a &lt;code&gt;shrink_threshold&lt;/code&gt; parameter, which implements the nearest shrunken centroid classifier. In effect, the value of each feature for each centroid is divided by the within-class variance of that feature. The feature values are then reduced by &lt;code&gt;shrink_threshold&lt;/code&gt;. Most notably, if a particular feature value crosses zero, it is set to zero. In effect, this removes the feature from affecting the classification. This is useful, for example, for removing noisy features.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt;分類器は持ってい &lt;code&gt;shrink_threshold&lt;/code&gt; 最短収縮重心分類器を実装したパラメータを、。実際には、各重心の各特徴の値は、その特徴のクラス内分散で除算されます。次に、機能値は &lt;code&gt;shrink_threshold&lt;/code&gt; によって削減されます。特に、特定の機能値がゼロと交差する場合は、ゼロに設定されます。事実上、これにより分類に影響を与える機能が削除されます。これは、ノイズの多い機能を削除する場合などに便利です。</target>
        </trans-unit>
        <trans-unit id="80f0d0589fbf3ca83c23f0b6ee7bc1939986e528" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt;&lt;code&gt;sklearn.cluster.KMeans&lt;/code&gt;&lt;/a&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt;分類器は、そのメンバーの重心により、各クラスを表す単純なアルゴリズムです。事実上、これは&lt;a href=&quot;generated/sklearn.cluster.kmeans#sklearn.cluster.KMeans&quot;&gt; &lt;code&gt;sklearn.cluster.KMeans&lt;/code&gt; &lt;/a&gt;アルゴリズムのラベル更新フェーズに似ています。また、選択するパラメーターがないため、優れたベースライン分類子になります。ただし、すべての次元で等しい分散が想定されているため、非凸クラス、およびクラスの分散が大幅に異なる場合には問題が発生します。この仮定を行わないより複雑な方法については、線形判別分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）および二次判別分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）を参照してください。デフォルトの使用法&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt;はシンプルです：</target>
        </trans-unit>
        <trans-unit id="43771e48f74cd166aa989881024956f81686fd39" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the &lt;code&gt;sklearn.KMeans&lt;/code&gt; algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) and Quadratic Discriminant Analysis (&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt;&lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt;&lt;/a&gt;) for more complex methods that do not make this assumption. Usage of the default &lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt;&lt;code&gt;NearestCentroid&lt;/code&gt;&lt;/a&gt; is simple:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; &lt;/a&gt;分類器は、そのメンバーの重心により、各クラスを表す単純なアルゴリズムです。実際には、これは &lt;code&gt;sklearn.KMeans&lt;/code&gt; アルゴリズムのラベル更新フェーズと同様になります。また、選択するパラメーターがないため、ベースライン分類器として適しています。ただし、すべての次元で等しい分散が想定されているため、クラスが大幅に異なる分散を持っている場合と同様に、非凸クラスでも影響を受けます。この仮定を行わないより複雑な方法については、線形判別分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.lineardiscriminantanalysis#sklearn.discriminant_analysis.LinearDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）および2次判別分析（&lt;a href=&quot;generated/sklearn.discriminant_analysis.quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&quot;&gt; &lt;code&gt;sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis&lt;/code&gt; &lt;/a&gt;）を参照してください。デフォルトの&lt;a href=&quot;generated/sklearn.neighbors.nearestcentroid#sklearn.neighbors.NearestCentroid&quot;&gt; &lt;code&gt;NearestCentroid&lt;/code&gt; の&lt;/a&gt;使用 簡単です：</target>
        </trans-unit>
        <trans-unit id="39bfe25102ea45948a285842eddb73a441e962a3" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; is built using a list of &lt;code&gt;(key, value)&lt;/code&gt; pairs, where the &lt;code&gt;key&lt;/code&gt; is a string containing the name you want to give this step and &lt;code&gt;value&lt;/code&gt; is an estimator object:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;リスト使用して構築された &lt;code&gt;(key, value)&lt;/code&gt; のペア、 &lt;code&gt;key&lt;/code&gt; あなたがこのステップと付ける名前を含む文字列である &lt;code&gt;value&lt;/code&gt; 推定オブジェクトです：</target>
        </trans-unit>
        <trans-unit id="c923ad3a865326ec6c72af48e5305bcc89674896" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space on a randomly generated matrix where components are drawn from the following distribution \(N(0, \frac{1}{n_{components}})\).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.random_projection.gaussianrandomprojection#sklearn.random_projection.GaussianRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.GaussianRandomProjection&lt;/code&gt; は、&lt;/a&gt;成分は以下の分布から引き出されるランダムに生成された行列\（N（0、\ FRAC {1} {N_ {成分}）\）で元の入力空間を投影することによって次元を減少させます。</target>
        </trans-unit>
        <trans-unit id="bf402b0deb2f6872588357c0d1a4ee6663793993" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt;&lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt;&lt;/a&gt; reduces the dimensionality by projecting the original input space using a sparse random matrix.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.random_projection.sparserandomprojection#sklearn.random_projection.SparseRandomProjection&quot;&gt; &lt;code&gt;sklearn.random_projection.SparseRandomProjection&lt;/code&gt; は&lt;/a&gt;スパースランダム行列を使用して、元の入力空間を投影することによって次元を減少させます。</target>
        </trans-unit>
        <trans-unit id="bfc6d74a43acae56b2f26724a2d5ae8338eaf262" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt;&lt;code&gt;export_graphviz&lt;/code&gt;&lt;/a&gt; exporter also supports a variety of aesthetic options, including coloring nodes by their class (or value for regression) and using explicit variable and class names if desired. Jupyter notebooks also render these plots inline automatically:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.tree.export_graphviz#sklearn.tree.export_graphviz&quot;&gt; &lt;code&gt;export_graphviz&lt;/code&gt; の&lt;/a&gt;輸出はまた、所望であれば、それらのクラス（または回帰の値）ノードを着色し、明示的な変数及びクラス名を使用することを含む美的オプション、様々なサポート。Jupyterノートブックは、これらのプロットを自動的にインラインでレンダリングします。</target>
        </trans-unit>
        <trans-unit id="7c175b2e5f3e3958b57eb43bc3177612df200e71" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/%20Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/%20Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;ジョンソン・Lindenstrauss補題は、&lt;/a&gt;ペアワイズ距離の歪みを制御しながら、任意の高次元のデータセットがランダムに低次元のユークリッド空間に投影することができると述べています。</target>
        </trans-unit>
        <trans-unit id="4a15d0b16a3ea1ca7d8280fbccb678c643c12770" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F-measure&lt;/a&gt; (\(F_\beta\) and \(F_1\) measures) can be interpreted as a weighted harmonic mean of the precision and recall. A \(F_\beta\) measure reaches its best value at 1 and its worst score at 0. With \(\beta = 1\), \(F_\beta\) and \(F_1\) are equivalent, and the recall and the precision are equally important.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F値&lt;/a&gt;（\（F_ \ベータ版\）と\（F_1 \）措置は）精度と再現率の加重調和平均と解釈することができます。\（F_ \ beta \）メジャーは、1で最高値に達し、0でその最悪スコアに達します。\（\ beta = 1 \）では、\（F_ \ beta \）と\（F_1 \）は同等であり、リコールと精度も同様に重要です。</target>
        </trans-unit>
        <trans-unit id="88cf2fa597f50207550c56a5d725499fc42ad462" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;Johnson-Lindenstrauss lemma&lt;/a&gt; states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances.</source>
          <target state="translated">&lt;a href=&quot;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&quot;&gt;ジョンソン・Lindenstrauss補題は、&lt;/a&gt;ペアワイズ距離の歪みを制御しながら、任意の高次元のデータセットがランダムに低次元のユークリッド空間に投影することができると述べています。</target>
        </trans-unit>
        <trans-unit id="6b941988cfc8d08eb5daa76d4a5974b4197ff783" translate="yes" xml:space="preserve">
          <source>The &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;estimator&lt;/a&gt; is required to be a fitted estimator. &lt;code&gt;X&lt;/code&gt; can be the data set used to train the estimator or a hold-out set. The permutation importance of a feature is calculated as follows. First, a baseline metric, defined by &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scoring&quot;&gt;scoring&lt;/a&gt;, is evaluated on a (potentially different) dataset defined by the &lt;code&gt;X&lt;/code&gt;. Next, a feature column from the validation set is permuted and the metric is evaluated again. The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column.</source>
          <target state="translated">&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-estimator&quot;&gt;推定量&lt;/a&gt;は、近似推定量である必要があります。 &lt;code&gt;X&lt;/code&gt; は、推定量のトレーニングに使用されるデータセットまたはホールドアウトセットにすることができます。特徴の順列の重要性は次のように計算されます。最初に、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-scoring&quot;&gt;スコアリング&lt;/a&gt;によって定義されたベースラインメトリックが、 &lt;code&gt;X&lt;/code&gt; によって定義された（潜在的に異なる）データセットで評価されます。次に、検証セットの特徴列が並べ替えられ、メトリックが再度評価されます。順列の重要度は、ベースラインメトリックとフィーチャ列の順列からのメトリックの差として定義されます。</target>
        </trans-unit>
        <trans-unit id="96678c00449216bcbe65a0961a8b25b8baf7a396" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;BayesianGaussianMixture&lt;/code&gt; class can adapt its number of mixture components automatically. The parameter &lt;code&gt;weight_concentration_prior&lt;/code&gt; has a direct link with the resulting number of components with non-zero weights. Specifying a low value for the concentration prior will make the model put most of the weight on few components set the remaining components weights very close to zero. High values of the concentration prior will allow a larger number of components to be active in the mixture.</source>
          <target state="translated">&lt;code&gt;BayesianGaussianMixture&lt;/code&gt; のクラスが自動的に混合成分のその数を適応させることができます。パラメータ &lt;code&gt;weight_concentration_prior&lt;/code&gt; は、重みがゼロでないコンポーネントの結果の数と直接リンクしています。前の濃度に低い値を指定すると、モデルはほとんどの重量を少数のコンポーネントに配置し、残りのコンポーネントの重量を非常にゼロに設定します。前の濃度の値が高いと、混合物中でより多くの成分を活性化できます。</target>
        </trans-unit>
        <trans-unit id="c17c439e95320993d0276d174b035cd14b7ce3b3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter controls the amount of regularization in the &lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt;&lt;code&gt;LogisticRegression&lt;/code&gt;&lt;/a&gt; object: a large value for &lt;code&gt;C&lt;/code&gt; results in less regularization. &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; gives &lt;a href=&quot;#shrinkage&quot;&gt;Shrinkage&lt;/a&gt; (i.e. non-sparse coefficients), while &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; gives &lt;a href=&quot;#sparsity&quot;&gt;Sparsity&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;C&lt;/code&gt; のパラメータ制御における正則化の量&lt;a href=&quot;../../modules/generated/sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression&quot;&gt; &lt;code&gt;LogisticRegression&lt;/code&gt; &lt;/a&gt;目的のための：大きな値 &lt;code&gt;C&lt;/code&gt; を以下正則化をもたらします。 &lt;code&gt;penalty=&quot;l2&quot;&lt;/code&gt; 得られる&lt;a href=&quot;#shrinkage&quot;&gt;収縮&lt;/a&gt;しながら、（すなわち、非スパース係数） &lt;code&gt;penalty=&quot;l1&quot;&lt;/code&gt; 得られる&lt;a href=&quot;#sparsity&quot;&gt;スパースを&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="9164d9a9144eaecf5fe284f2e40277e82f0b8068" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;C&lt;/code&gt; parameter trades off correct classification of training examples against maximization of the decision function&amp;rsquo;s margin. For larger values of &lt;code&gt;C&lt;/code&gt;, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower &lt;code&gt;C&lt;/code&gt; will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words``C`` behaves as a regularization parameter in the SVM.</source>
          <target state="translated">&lt;code&gt;C&lt;/code&gt; の決定関数のマージンの最大化に対する訓練例の正しい分類オフパラメータ取引。 &lt;code&gt;C&lt;/code&gt; の値が大きい場合、すべてのトレーニングポイントを正しく分類するための決定関数の方が優れていれば、マージンは小さくなります。 &lt;code&gt;C&lt;/code&gt; が低いと、マージンが大きくなるため、決定関数が単純になりますが、トレーニングの精度は犠牲になります。言い換えると、「C」はSVMの正則化パラメーターとして動作します。</target>
        </trans-unit>
        <trans-unit id="9aa2de3f6ced8022ed53d959fe2e18d24e70ecf1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;DESCR&lt;/code&gt; contains a free-text description of the data, while &lt;code&gt;details&lt;/code&gt; contains a dictionary of meta-data stored by openml, like the dataset id. For more details, see the &lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;OpenML documentation&lt;/a&gt; The &lt;code&gt;data_id&lt;/code&gt; of the mice protein dataset is 40966, and you can use this (or the name) to get more information on the dataset on the openml website:</source>
          <target state="translated">&lt;code&gt;DESCR&lt;/code&gt; は一方で、データのフリーテキスト記述が含まれています &lt;code&gt;details&lt;/code&gt; データセットIDのように、openmlによって保存されたメタデータの辞書が含まれています。詳細については、&lt;a href=&quot;https://docs.openml.org/#data&quot;&gt;OpenMLのドキュメントを&lt;/a&gt; &lt;code&gt;data_id&lt;/code&gt; マウスタンパク質データセットのが40966である、とあなたがopenmlウェブサイト上のデータセットに関する詳細な情報を取得するには、この（または名前）を使用することができます。</target>
        </trans-unit>
        <trans-unit id="388bd8e84c98bb0ce4ff6564cc35fb4e0e8f41db" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; estimator has the most flexibility and is able to predict higher expected values.</source>
          <target state="translated">&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt; の推定は、最も柔軟性があり、高い期待値を予測することができます。</target>
        </trans-unit>
        <trans-unit id="81a0037eca65e4ed69e2a49ca4871b0ce138bc10" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Normalizer&lt;/code&gt; rescales the vector for each sample to have unit norm, independently of the distribution of the samples. It can be seen on both figures below where all samples are mapped onto the unit circle. In our example the two selected features have only positive values; therefore the transformed data only lie in the positive quadrant. This would not be the case if some original features had a mix of positive and negative values.</source>
          <target state="translated">&lt;code&gt;Normalizer&lt;/code&gt; 独立して、サンプルの分布の、単位ノルムを有するように各サンプルのベクトルを再スケール。これは、すべてのサンプルが単位円にマッピングされている以下の両方の図で確認できます。この例では、選択された2つの特徴は正の値のみを持っています。したがって、変換されたデータは正の象限にのみ存在します。一部の元の機能に正と負の値が混在している場合、これは当てはまりません。</target>
        </trans-unit>
        <trans-unit id="c108938c180fba7834742cb26f12054acc7a2184" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;PCA&lt;/code&gt; fitting is only computed at the evaluation of the first configuration of the &lt;code&gt;C&lt;/code&gt; parameter of the &lt;code&gt;LinearSVC&lt;/code&gt; classifier. The other configurations of &lt;code&gt;C&lt;/code&gt; will trigger the loading of the cached &lt;code&gt;PCA&lt;/code&gt; estimator data, leading to save processing time. Therefore, the use of caching the pipeline using &lt;code&gt;memory&lt;/code&gt; is highly beneficial when fitting a transformer is costly.</source>
          <target state="translated">&lt;code&gt;PCA&lt;/code&gt; のフィッティングのみの第一の構成の評価で計算された &lt;code&gt;C&lt;/code&gt; 用のパラメータ &lt;code&gt;LinearSVC&lt;/code&gt; のクラシファイア。 &lt;code&gt;C&lt;/code&gt; の他の構成は、キャッシュされた &lt;code&gt;PCA&lt;/code&gt; 見積もりデータのロードをトリガーし、処理時間を節約します。したがって、 &lt;code&gt;memory&lt;/code&gt; を使用してパイプラインをキャッシュすることは、トランスフォーマーの取り付けにコストがかかる場合に非常に有益です。</target>
        </trans-unit>
        <trans-unit id="c287f0a262d74ac1807987cdaae52227ef4012e1" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Product&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="translated">&lt;code&gt;Product&lt;/code&gt; カーネルは、経由して、それらを（K_1 \）\ 2つのカーネルを取り、\（K_2 \）、コンバイン</target>
        </trans-unit>
        <trans-unit id="6a3cb6faf35a31966ca4f91d6d7c341a997f291b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;RandomForestClassifier&lt;/code&gt; を使用して訓練された&lt;em&gt;ブートストラップ集約&lt;/em&gt;それぞれの新しいツリーがトレーニング観測\（z_i =（X_I、Y_I）\）のブートストラップサンプルからのフィット感です。&lt;em&gt;アウトオブバッグ&lt;/em&gt;（OOB）エラーは、各\（z_i \）には、それぞれのブートストラップサンプル中（z_i \）\含まれていない木からの予測を使用して計算のための平均誤差です。これにより、トレーニング中に &lt;code&gt;RandomForestClassifier&lt;/code&gt; を適合させて検証することができます&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="17baab07595bc9a1b9010bf52fc5ebb7c1555943" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;RandomForestClassifier&lt;/code&gt; is trained using &lt;em&gt;bootstrap aggregation&lt;/em&gt;, where each new tree is fit from a bootstrap sample of the training observations \(z_i = (x_i, y_i)\). The &lt;em&gt;out-of-bag&lt;/em&gt; (OOB) error is the average error for each \(z_i\) calculated using predictions from the trees that do not contain \(z_i\) in their respective bootstrap sample. This allows the &lt;code&gt;RandomForestClassifier&lt;/code&gt; to be fit and validated whilst being trained &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;RandomForestClassifier&lt;/code&gt; を使用して訓練された&lt;em&gt;ブートストラップ集約&lt;/em&gt;それぞれの新しいツリーがトレーニング観測\（z_i =（X_I、Y_I）\）のブートストラップサンプルからのフィット感です。&lt;em&gt;アウトオブバッグ&lt;/em&gt;（OOB）エラーは、各\（z_i \）には、それぞれのブートストラップサンプル中（z_i \）\含まれていない木からの予測を使用して計算のための平均誤差です。これにより、トレーニング中に &lt;code&gt;RandomForestClassifier&lt;/code&gt; を適合および検証することができます&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="b88cefdaf9f96b3cdafb06bfae8af6e9f9c7d591" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Ridge&lt;/code&gt; regression model can predict very low expected frequencies that do not match the data. It can therefore severly under-estimate the risk for some policyholders.</source>
          <target state="translated">&lt;code&gt;Ridge&lt;/code&gt; 回帰モデルは、データと一致していない非常に低いと予想周波数を予測することができます。したがって、一部の保険契約者のリスクを大幅に過小評価する可能性があります。</target>
        </trans-unit>
        <trans-unit id="2fcb1f40315317ee430343ccf6429ac412e1cf20" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralBiclustering&lt;/code&gt; algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.</source>
          <target state="translated">&lt;code&gt;SpectralBiclustering&lt;/code&gt; アルゴリズムは、入力データ行列は、隠されたチェッカーボード構造を有していることを前提としています。この構造を持つ行列の行と列は、行クラスターと列クラスターのデカルト積の任意のバイクラスターのエントリがほぼ一定になるように分割できます。たとえば、2つの行パーティションと3つの列パーティションがある場合、各行は3つのバイクラスターに属し、各列は2つのバイクラスターに属します。</target>
        </trans-unit>
        <trans-unit id="68d62b9583d10d4cdba8ebe8ca76f4a0cc3bafcf" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;SpectralCoclustering&lt;/code&gt; algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:</source>
          <target state="translated">&lt;code&gt;SpectralCoclustering&lt;/code&gt; アルゴリズムは、対応する他の行に比べて高い値と列とbiclustersを見出します。各行と各列は正確に1つのバイクラスターに属しているため、行と列を再配置してパーティションを隣接させると、対角線に沿ってこれらの高い値が明らかになります。</target>
        </trans-unit>
        <trans-unit id="d2977d18fbb46e84c7bb310b8e5bfcc96a3f259f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;Sum&lt;/code&gt; kernel takes two kernels \(k_1\) and \(k_2\) and combines them via</source>
          <target state="translated">&lt;code&gt;Sum&lt;/code&gt; カーネルは経由して、それらを（K_1 \）\ 2つのカーネルを取り、\（K_2 \）、コンバイン</target>
        </trans-unit>
        <trans-unit id="093b9af7ff877738a1c191bf8fe58f666ce1b93c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;VotingClassifier&lt;/code&gt; can also be used together with &lt;code&gt;GridSearch&lt;/code&gt; in order to tune the hyperparameters of the individual estimators:</source>
          <target state="translated">&lt;code&gt;VotingClassifier&lt;/code&gt; はまた、一緒に使用することができる &lt;code&gt;GridSearch&lt;/code&gt; 個々推定のハイパー調整するために：</target>
        </trans-unit>
        <trans-unit id="a92f24d7703ca3728952e82f17755a0b7604fe2c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the coefficients estimated.</source>
          <target state="translated">&lt;code&gt;alpha&lt;/code&gt; パラメータは、推定された係数のスパース性の程度を制御します。</target>
        </trans-unit>
        <trans-unit id="315ca80415fed5e99f9417365418d048de6cb5f9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;alpha&lt;/code&gt; parameter controls the degree of sparsity of the estimated coefficients.</source>
          <target state="translated">&lt;code&gt;alpha&lt;/code&gt; パラメータは、推定された係数のスパース性の程度を制御します。</target>
        </trans-unit>
        <trans-unit id="d22b7c9a5ce685adf8551f77a733c13cab8fe2d4" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;best_estimator_&lt;/code&gt;, &lt;code&gt;best_index_&lt;/code&gt;, &lt;code&gt;best_score_&lt;/code&gt; and &lt;code&gt;best_params_&lt;/code&gt; correspond to the scorer (key) that is set to the &lt;code&gt;refit&lt;/code&gt; attribute.</source>
          <target state="translated">&lt;code&gt;best_estimator_&lt;/code&gt; 、 &lt;code&gt;best_index_&lt;/code&gt; 、 &lt;code&gt;best_score_&lt;/code&gt; と &lt;code&gt;best_params_&lt;/code&gt; に設定されている得点（キー）に対応する &lt;code&gt;refit&lt;/code&gt; 属性。</target>
        </trans-unit>
        <trans-unit id="ea04fcbf02a8de4070a990d8e4f932cdf0278b0d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of precision in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; only recall).</source>
          <target state="translated">&lt;code&gt;beta&lt;/code&gt; パラメータは、複合スコアの精度の重量を決定します。 &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; は精度を重視し、 &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; は再現を優先します（ &lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; は精度のみを考慮し、 &lt;code&gt;beta -&amp;gt; inf&lt;/code&gt; は再現のみを考慮します）。</target>
        </trans-unit>
        <trans-unit id="baaa5bd4c537184b8165bf82e50573a6954bd1a3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;beta&lt;/code&gt; parameter determines the weight of recall in the combined score. &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; lends more weight to precision, while &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; favors recall (&lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; considers only precision, &lt;code&gt;beta -&amp;gt; +inf&lt;/code&gt; only recall).</source>
          <target state="translated">&lt;code&gt;beta&lt;/code&gt; パラメータは、複合スコアのリコールの重みを決定します。 &lt;code&gt;beta &amp;lt; 1&lt;/code&gt; は精度を重視し、 &lt;code&gt;beta &amp;gt; 1&lt;/code&gt; はリコールを優先します（ &lt;code&gt;beta -&amp;gt; 0&lt;/code&gt; は精度のみを考慮し、 &lt;code&gt;beta -&amp;gt; +inf&lt;/code&gt; のみリコールを考慮します）。</target>
        </trans-unit>
        <trans-unit id="1cbc8f71751f51b8523a564fa7c56816a950df46" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;clf&lt;/code&gt; (for classifier) estimator instance is first fitted to the model; that is, it must &lt;em&gt;learn&lt;/em&gt; from the model. This is done by passing our training set to the &lt;code&gt;fit&lt;/code&gt; method. For the training set, we&amp;rsquo;ll use all the images from our dataset, except for the last image, which we&amp;rsquo;ll reserve for our predicting. We select the training set with the &lt;code&gt;[:-1]&lt;/code&gt; Python syntax, which produces a new array that contains all but the last item from &lt;code&gt;digits.data&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;clf&lt;/code&gt; 推定インスタンス（分類器のための）は、最初のモデルに装着されています。つまり、モデルから&lt;em&gt;学習&lt;/em&gt;する必要があり&lt;em&gt;ます&lt;/em&gt;。これは、トレーニングセットを &lt;code&gt;fit&lt;/code&gt; メソッドに渡すことで行われます。トレーニングセットでは、予測のために予約する最後の画像を除いて、データセットのすべての画像を使用します。 &lt;code&gt;[:-1]&lt;/code&gt; Python構文を使用してトレーニングセットを選択します。これにより、 &lt;code&gt;digits.data&lt;/code&gt; の最後の項目を除くすべてを含む新しい配列が生成されます。</target>
        </trans-unit>
        <trans-unit id="0655de3e2b717fc73c590188fdaa9881c37414a7" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cross_validate&lt;/code&gt; function differs from &lt;code&gt;cross_val_score&lt;/code&gt; in two ways -</source>
          <target state="translated">&lt;code&gt;cross_validate&lt;/code&gt; 機能が異なり &lt;code&gt;cross_val_score&lt;/code&gt; 二つの方法で-</target>
        </trans-unit>
        <trans-unit id="f3aad90428722c87b3422d97c1856aa8204966ed" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;cv_results_&lt;/code&gt; parameter can be easily imported into pandas as a &lt;code&gt;DataFrame&lt;/code&gt; for further inspection.</source>
          <target state="translated">&lt;code&gt;cv_results_&lt;/code&gt; のパラメータを簡単としてパンダにインポートすることができ &lt;code&gt;DataFrame&lt;/code&gt; 詳細な検査をするために。</target>
        </trans-unit>
        <trans-unit id="6d0144f231c5dfa868fda545c176e4a6eca95147" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;data_id&lt;/code&gt; also uniquely identifies a dataset from OpenML:</source>
          <target state="translated">&lt;code&gt;data_id&lt;/code&gt; また、一意OpenMLからデータセットを識別する。</target>
        </trans-unit>
        <trans-unit id="7bfd5d978dedbc7159d3a401f357dd25ad25428a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers:</source>
          <target state="translated">また、 &lt;code&gt;decision_function&lt;/code&gt; メソッドは、負の値が外れ値で非負の値が外れ値になるように、スコアリング関数から定義されます。</target>
        </trans-unit>
        <trans-unit id="bc22b4069c85e3e1ecbf3c942877625aea87d185" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling &lt;a href=&quot;#id11&quot; id=&quot;id2&quot;&gt;9&lt;/a&gt;: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per &lt;a href=&quot;#id12&quot; id=&quot;id3&quot;&gt;10&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;decision_function&lt;/code&gt; メソッドは、各サンプルのクラスごとのスコア（または、バイナリの場合はサンプルごとの単一のスコア）を提供します。コンストラクターオプションの &lt;code&gt;probability&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合、クラスメンバーシップの確率の推定値（メソッド &lt;code&gt;predict_proba&lt;/code&gt; および &lt;code&gt;predict_log_proba&lt;/code&gt; から）が有効になります。バイナリの場合、確率はPlattスケーリング&lt;a href=&quot;#id11&quot; id=&quot;id2&quot;&gt;9&lt;/a&gt;を使用して調整されます。SVMのスコアのロジスティック回帰は、トレーニングデータの追加の相互検証によって適合されます。マルチクラスの場合、これは&lt;a href=&quot;#id12&quot; id=&quot;id3&quot;&gt;10&lt;/a&gt;に従って拡張されます。</target>
        </trans-unit>
        <trans-unit id="62eacbcbc4132ef1f5317a0a939d640165e31df3" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;decision_function&lt;/code&gt; method of &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt; gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option &lt;code&gt;probability&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, class membership probability estimates (from the methods &lt;code&gt;predict_proba&lt;/code&gt; and &lt;code&gt;predict_log_proba&lt;/code&gt;) are enabled. In the binary case, the probabilities are calibrated using Platt scaling: logistic regression on the SVM&amp;rsquo;s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per Wu et al. (2004).</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;decision_function&lt;/code&gt; メソッドは、各サンプルのクラスごとのスコア（またはバイナリの場合はサンプルごとに単一のスコア）を提供します。コンストラクタオプションの &lt;code&gt;probability&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; に設定されている場合、クラスメンバーシップの確率の推定（メソッド &lt;code&gt;predict_proba&lt;/code&gt; および &lt;code&gt;predict_log_proba&lt;/code&gt; から）が有効になります。バイナリの場合、確率は、プラットスケーリングを使用して調整されます。SVMのスコアに対するロジスティック回帰は、トレーニングデータの追加の交差検証によって適合されます。マルチクラスの場合、これはWuらのように拡張されます。 （2004）。</target>
        </trans-unit>
        <trans-unit id="cacd73f2ee1bdb21ccf547bfa27f031af8d1c84f" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;estimators&lt;/code&gt; parameter corresponds to the list of the estimators which are stacked together in parallel on the input data. It should be given as a list of names and estimators:</source>
          <target state="translated">&lt;code&gt;estimators&lt;/code&gt; 入力データを並列に一緒に積層された推定のリストに対応するパラメータ。名前と推定量のリストとして指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="912eed5f20931cd928be8a8b3c3891f77622f73b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to return all features whether or not they contain missing values:</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; パラメータがに設定することができます &lt;code&gt;'all'&lt;/code&gt; 彼らは欠損値が含まれているかどうかに関係なく、すべての機能を返すために：</target>
        </trans-unit>
        <trans-unit id="ac9899847d23144b2277382b5ec5bf6360733941" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter can be set to &lt;code&gt;'all'&lt;/code&gt; to returned all features whether or not they contain missing values:</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; パラメータがに設定することができます &lt;code&gt;'all'&lt;/code&gt; ：彼らは欠損値が含まれているかどうかに関係なく、すべての機能を返却します</target>
        </trans-unit>
        <trans-unit id="0e29ac108f496200ac17f2eb1912fca379623586" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;features&lt;/code&gt; parameter is used to choose the features for which the mask is constructed. By default, it is &lt;code&gt;'missing-only'&lt;/code&gt; which returns the imputer mask of the features containing missing values at &lt;code&gt;fit&lt;/code&gt; time:</source>
          <target state="translated">&lt;code&gt;features&lt;/code&gt; マスクが構築されている機能を選択するために使用されるパラメータ。デフォルトでは、それは &lt;code&gt;'missing-only'&lt;/code&gt; であり、 &lt;code&gt;fit&lt;/code&gt; 時に欠損値を含む特徴の入力マスクを返します。</target>
        </trans-unit>
        <trans-unit id="9c67ef88019a1b7e1168b9363c0a3a8856eb06c6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;final_estimator&lt;/code&gt; will use the predictions of the &lt;code&gt;estimators&lt;/code&gt; as input. It needs to be a classifier or a regressor when using &lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt;&lt;code&gt;StackingClassifier&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt;&lt;code&gt;StackingRegressor&lt;/code&gt;&lt;/a&gt;, respectively:</source>
          <target state="translated">&lt;code&gt;final_estimator&lt;/code&gt; はの予測に使用する &lt;code&gt;estimators&lt;/code&gt; 入力として。&lt;a href=&quot;generated/sklearn.ensemble.stackingclassifier#sklearn.ensemble.StackingClassifier&quot;&gt; &lt;code&gt;StackingClassifier&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/sklearn.ensemble.stackingregressor#sklearn.ensemble.StackingRegressor&quot;&gt; &lt;code&gt;StackingRegressor&lt;/code&gt; &lt;/a&gt;を使用する場合は、それぞれ分類子またはリグレッサーである必要があります。</target>
        </trans-unit>
        <trans-unit id="9b06298ca8347e48ebdf3df08a4c5d05e9d2dcbb" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;fit&lt;/code&gt; function takes two arguments: &lt;code&gt;n_components&lt;/code&gt;, which is the target dimensionality of the feature transform, and &lt;code&gt;gamma&lt;/code&gt;, the parameter of the RBF-kernel. A higher &lt;code&gt;n_components&lt;/code&gt; will result in a better approximation of the kernel and will yield results more similar to those produced by a kernel SVM. Note that &amp;ldquo;fitting&amp;rdquo; the feature function does not actually depend on the data given to the &lt;code&gt;fit&lt;/code&gt; function. Only the dimensionality of the data is used. Details on the method can be found in &lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;fit&lt;/code&gt; ：関数は2つの引数取り &lt;code&gt;n_components&lt;/code&gt; 機能のターゲット次元変換であると、 &lt;code&gt;gamma&lt;/code&gt; 、RBFカーネルのパラメータを。 &lt;code&gt;n_components&lt;/code&gt; が高いほど、カーネルの近似が向上し、カーネルSVMによって生成される結果により近い結果が得られます。特徴関数の「適合」は、実際には &lt;code&gt;fit&lt;/code&gt; 関数に与えられたデータに依存しないことに注意してください。データの次元のみが使用されます。この方法の詳細は&lt;a href=&quot;#rr2007&quot; id=&quot;id3&quot;&gt;[RR2007]にあり&lt;/a&gt;ます。</target>
        </trans-unit>
        <trans-unit id="24f4fe27df1296a0eb0115a0bb0e2832f2225923" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;id&lt;/code&gt; of each check is set to be a pprint version of the estimator and the name of the check with its keyword arguments. This allows to use &lt;code&gt;pytest -k&lt;/code&gt; to specify which tests to run:</source>
          <target state="translated">各小切手の &lt;code&gt;id&lt;/code&gt; は、推定量のpprintバージョンと、キーワード引数を持つ小切手の名前に設定されます。これにより、 &lt;code&gt;pytest -k&lt;/code&gt; を使用して、実行するテストを指定できます。</target>
        </trans-unit>
        <trans-unit id="c8f8ea902ec10f43c9cca575477617a393bf1406" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;increasing&lt;/code&gt; parameter changes the constraint to \(\hat{y}_i \ge \hat{y}_j\) whenever \(X_i \le X_j\). Setting it to &amp;lsquo;auto&amp;rsquo; will automatically choose the constraint based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&quot;&gt;Spearman&amp;rsquo;s rank correlation coefficient&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;increasing&lt;/code&gt; パラメータはいつでも\（X_I \ルX - jが\）\（\ハット{Y} _i \ GE \帽子{Y} _j \）に制約を変更します。'auto'に設定すると、&lt;a href=&quot;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&quot;&gt;スピアマンの順位相関係数に&lt;/a&gt;基づいて制約が自動的に選択されます。</target>
        </trans-unit>
        <trans-unit id="f460a2e1f3d0337b4c58660913081d08e87c0f52" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;4&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="translated">&lt;code&gt;init&lt;/code&gt; 属性は、メソッドのパフォーマンスに大きな影響を与える適用初期化方法を決定します。&lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt;は、メソッドNonnegative Double Singular ValueDecompositionを実装します。 NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;4&lt;/a&gt;は、2つのSVDプロセスに基づいており、1つはデータ行列を近似し、もう1つは単位ランク行列の代数的特性を利用して結果の部分SVD因子の正のセクションを近似します。基本的なNNDSVDアルゴリズムは、スパース因数分解に適しています。そのバリアントNNDSVDa（すべてのゼロがデータのすべての要素の平均に等しく設定される）およびNNDSVDar（ゼロがデータの平均を100で割った値よりも小さいランダムな摂動に設定される）が密集した場所で推奨されます場合。</target>
        </trans-unit>
        <trans-unit id="759d68cbc1b0e0c960b6f5234a5fe3b985174684" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;init&lt;/code&gt; attribute determines the initialization method applied, which has a great impact on the performance of the method. &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt; implements the method Nonnegative Double Singular Value Decomposition. NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt; is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.</source>
          <target state="translated">&lt;code&gt;init&lt;/code&gt; 属性は、メソッドのパフォーマンスに大きな影響を与える適用初期化方法を決定します。&lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt;は、メソッドNonnegative Double Singular Value Decompositionを実装しています。 NNDSVD &lt;a href=&quot;#id13&quot; id=&quot;id7&quot;&gt;[4]&lt;/a&gt;は2つのSVDプロセスに基づいており、1つはデータマトリックスを近似し、もう1つは単位ランクマトリックスの代数プロパティを利用して、結果の部分SVD因子の正のセクションを近似します。基本的なNNDSVDアルゴリズムは、スパース分解に適しています。そのバリアントNNDSVDa（すべてのゼロがデータのすべての要素の平均に等しく設定される）、およびNNDSVDar（ゼロがデータの平均を100で割った値よりも小さいランダムな摂動に設定される）は、密に推奨されます場合。</target>
        </trans-unit>
        <trans-unit id="dae4c344a8a96bf6754b4ff3002f4e9350562dbc" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; attribute holds the intercept (aka offset or bias):</source>
          <target state="translated">&lt;code&gt;intercept_&lt;/code&gt; 属性は（別名オフセットまたはバイアス）インターセプトを保持しています：</target>
        </trans-unit>
        <trans-unit id="5aaf2ff68858d9c24eece58235794e4a322e1ce9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;intercept_&lt;/code&gt; member is not converted.</source>
          <target state="translated">&lt;code&gt;intercept_&lt;/code&gt; メンバーは変換されません。</target>
        </trans-unit>
        <trans-unit id="0e6b2b935d052640da205c359a0d82666ebb9942" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; functions allow to identify and reject degenerate combinations of random sub-samples. If the estimated model is not needed for identifying degenerate cases, &lt;code&gt;is_data_valid&lt;/code&gt; should be used as it is called prior to fitting the model and thus leading to better computational performance.</source>
          <target state="translated">&lt;code&gt;is_data_valid&lt;/code&gt; と &lt;code&gt;is_model_valid&lt;/code&gt; 機能はランダムサブサンプルの縮退の組み合わせを識別し、拒否することを可能にします。推定モデルが縮退したケースの識別に必要でない場合は、モデルの近似前に呼び出される &lt;code&gt;is_data_valid&lt;/code&gt; を使用して、計算パフォーマンスを向上させる必要があります。</target>
        </trans-unit>
        <trans-unit id="dee80932cbc9425c512fa33535be444f8c4ddfa6" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;l2_regularization&lt;/code&gt; parameter is a regularizer on the loss function and corresponds to \(\lambda\) in equation (2) of &lt;a href=&quot;#xgboost&quot; id=&quot;id26&quot;&gt;[XGBoost]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;l2_regularization&lt;/code&gt; のパラメータは、損失関数と対応上の正則であると\（\ラムダ\）に式（2）の&lt;a href=&quot;#xgboost&quot; id=&quot;id26&quot;&gt;[XGBoost] &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="a1aa8bc8d7f393abce9beb6161257c50a1665624" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots.</source>
          <target state="translated">&lt;code&gt;len(features)&lt;/code&gt; プロットして格子状に配置され &lt;code&gt;n_cols&lt;/code&gt; の列。双方向の部分依存プロットは、等高線図としてプロットされます。</target>
        </trans-unit>
        <trans-unit id="da451cbcbf87abb0e9a3cde3e39db4fedec8991d" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;len(features)&lt;/code&gt; plots are arranged in a grid with &lt;code&gt;n_cols&lt;/code&gt; columns. Two-way partial dependence plots are plotted as contour plots. The deciles of the feature values will be shown with tick marks on the x-axes for one-way plots, and on both axes for two-way plots.</source>
          <target state="translated">&lt;code&gt;len(features)&lt;/code&gt; プロットして格子状に配置され &lt;code&gt;n_cols&lt;/code&gt; の列。双方向の部分依存プロットは、等高線プロットとしてプロットされます。特徴値の十分位数は、一方向プロットの場合はx軸に、双方向プロットの場合は両方の軸に目盛りで表示されます。</target>
        </trans-unit>
        <trans-unit id="4d39915194cee376ca662b61de9924274942d60a" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;make_columntransformer&lt;/code&gt; function is available to more easily create a &lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt;&lt;code&gt;ColumnTransformer&lt;/code&gt;&lt;/a&gt; object. Specifically, the names will be given automatically. The equivalent for the above example would be:</source>
          <target state="translated">&lt;code&gt;make_columntransformer&lt;/code&gt; の機能をより簡単に作成することが可能です&lt;a href=&quot;generated/sklearn.compose.columntransformer#sklearn.compose.ColumnTransformer&quot;&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt; の&lt;/a&gt;オブジェクトを。具体的には、名前は自動的に付けられます。上記の例と同等のものは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="e3ab7886f45f0e5bcfcb494c5dda13f6aee54058" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;mean_fit_time&lt;/code&gt;, &lt;code&gt;std_fit_time&lt;/code&gt;, &lt;code&gt;mean_score_time&lt;/code&gt; and &lt;code&gt;std_score_time&lt;/code&gt; are all in seconds.</source>
          <target state="translated">&lt;code&gt;mean_fit_time&lt;/code&gt; 、 &lt;code&gt;std_fit_time&lt;/code&gt; 、 &lt;code&gt;mean_score_time&lt;/code&gt; と &lt;code&gt;std_score_time&lt;/code&gt; は数秒ですべてです。</target>
        </trans-unit>
        <trans-unit id="5067a7dbb7441ffa442bc35298e784d3bbb5d81c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;out_of_bounds&lt;/code&gt; parameter handles how &lt;code&gt;X&lt;/code&gt; values outside of the training domain are handled. When set to &amp;ldquo;nan&amp;rdquo;, predictions will be NaN. When set to &amp;ldquo;clip&amp;rdquo;, predictions will be set to the value corresponding to the nearest train interval endpoint. When set to &amp;ldquo;raise&amp;rdquo; a &lt;code&gt;ValueError&lt;/code&gt; is raised.</source>
          <target state="translated">&lt;code&gt;out_of_bounds&lt;/code&gt; どのようにハンドルパラメータ &lt;code&gt;X&lt;/code&gt; がトレーニングドメイン外の値が処理されます。「nan」に設定すると、予測はNaNになります。「クリップ」に設定すると、予測は最も近い列車間隔の終点に対応する値に設定されます。「raise」に設定すると、 &lt;code&gt;ValueError&lt;/code&gt; が発生します。</target>
        </trans-unit>
        <trans-unit id="4dc710fdb008b124893854b1db0d772123e2f23c" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;out_of_bounds&lt;/code&gt; parameter handles how x-values outside of the training domain are handled. When set to &amp;ldquo;nan&amp;rdquo;, predicted y-values will be NaN. When set to &amp;ldquo;clip&amp;rdquo;, predicted y-values will be set to the value corresponding to the nearest train interval endpoint. When set to &amp;ldquo;raise&amp;rdquo;, allow &lt;code&gt;interp1d&lt;/code&gt; to throw ValueError.</source>
          <target state="translated">&lt;code&gt;out_of_bounds&lt;/code&gt; ハンドルパラメータがどのようにx値外の研修ドメインの処理されます。「nan」に設定すると、予測されるy値はNaNになります。「clip」に設定すると、予測されるy値は、最も近い列車間隔のエンドポイントに対応する値に設定されます。「raise」に設定すると、 &lt;code&gt;interp1d&lt;/code&gt; がValueErrorをスローできるようになります。</target>
        </trans-unit>
        <trans-unit id="3c0e73047db48d9d2c7fabbdd5b52d96e2b806a9" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;partial_fit&lt;/code&gt; method call of naive Bayes models introduces some computational overhead. It is recommended to use data chunk sizes that are as large as possible, that is as the available RAM allows.</source>
          <target state="translated">単純ベイズモデルの &lt;code&gt;partial_fit&lt;/code&gt; メソッド呼び出しは、いくつかの計算オーバーヘッドをもたらします。使用可能なRAMが許す限り、可能な限り大きいデータチャンクサイズを使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="12fb3214c445789e7d1fb007eb13c0f9c87b3271" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;penalty&lt;/code&gt; parameter determines the regularization to be used (see description above in the classification section).</source>
          <target state="translated">&lt;code&gt;penalty&lt;/code&gt; パラメータは（分類セクションの上記の説明を参照）を使用する正則化を決定します。</target>
        </trans-unit>
        <trans-unit id="c075895944959b3ce70972d2605db496c74ee36b" translate="yes" xml:space="preserve">
          <source>The &lt;code&gt;preprocessing&lt;/code&gt; module further provides a utility class &lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt;&lt;code&gt;Normalizer&lt;/code&gt;&lt;/a&gt; that implements the same operation using the &lt;code&gt;Transformer&lt;/code&gt; API (even though the &lt;code&gt;fit&lt;/code&gt; method is useless in this case: the class is stateless as this operation treats samples independently).</source>
          <target state="translated">&lt;code&gt;preprocessing&lt;/code&gt; モジュールはさらに、ユーティリティクラス提供&lt;a href=&quot;generated/sklearn.preprocessing.normalizer#sklearn.preprocessing.Normalizer&quot;&gt; &lt;code&gt;Normalizer&lt;/code&gt; &lt;/a&gt;実装同じ操作を使用してその &lt;code&gt;Transformer&lt;/code&gt; （にもかかわらずAPIを &lt;code&gt;fit&lt;/code&gt; ：クラスは、独立して、この操作扱いサンプルとしてステートレスである方法は、この場合には無用です）。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
