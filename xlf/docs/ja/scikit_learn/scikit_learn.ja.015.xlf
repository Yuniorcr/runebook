<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="scikit_learn">
    <body>
      <group id="scikit_learn">
        <trans-unit id="7c13e77bc830b382c041eec0e3fcc1723f375e05" translate="yes" xml:space="preserve">
          <source>Homogeneity metric of a cluster labeling given a ground truth.</source>
          <target state="translated">基底真理を与えられたクラスタラベリングの同質性メトリック。</target>
        </trans-unit>
        <trans-unit id="3afc9b67230d985e8782525c7b58b615e013e8f9" translate="yes" xml:space="preserve">
          <source>Homogeneity, completeness and V-measure can be computed at once using &lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt;&lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt;&lt;/a&gt; as follows:</source>
          <target state="translated">均質性、完全性、Vメジャーは、次のように&lt;a href=&quot;generated/sklearn.metrics.homogeneity_completeness_v_measure#sklearn.metrics.homogeneity_completeness_v_measure&quot;&gt; &lt;code&gt;homogeneity_completeness_v_measure&lt;/code&gt; &lt;/a&gt;を使用して一度に計算できます。</target>
        </trans-unit>
        <trans-unit id="0878824f511837fc1a1c8d27240af19053ebdbd4" translate="yes" xml:space="preserve">
          <source>HouseAge median house age in block</source>
          <target state="translated">HouseAge ブロック内の住宅築年数の中央値</target>
        </trans-unit>
        <trans-unit id="95f00bca96463f976c07bb46f71ce6b37ead0db0" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="translated">困惑を評価する頻度。 &lt;code&gt;fit&lt;/code&gt; 法でのみ使用されます。トレーニングの混乱をまったく評価しないようにするには、0または負の数に設定します。困惑を評価すると、トレーニングプロセスの収束を確認するのに役立ちますが、合計トレーニング時間も長くなります。すべての反復で困惑を評価すると、トレーニング時間が最大2倍になる可能性があります。</target>
        </trans-unit>
        <trans-unit id="be45c283b4c54643c38f84bc65a4bfc525d6d30a" translate="yes" xml:space="preserve">
          <source>How often to evaluate perplexity. Only used in &lt;code&gt;fit&lt;/code&gt; method. set it to 0 or negative number to not evalute perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.</source>
          <target state="translated">混乱を評価する頻度。 &lt;code&gt;fit&lt;/code&gt; 法でのみ使用されます。それを0または負の数に設定すると、トレーニングの混乱をまったく評価しません。混乱を評価することは、トレーニングプロセスの収束をチェックするのに役立ちますが、トレーニングの合計時間も増加します。すべての反復で混乱を評価すると、トレーニング時間が最大2倍になる可能性があります。</target>
        </trans-unit>
        <trans-unit id="82dc6d28bb69b15075cb833b4ea7ee856b1fb8a5" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;.</source>
          <target state="translated">分母のノーマライザーを計算する方法。可能なオプションは、「min」、「geometric」、「arithmetic」、および「max」です。</target>
        </trans-unit>
        <trans-unit id="060faa287065b4ad6ba6c00f598635b42adc21de" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">分母でノーマライザを計算する方法。可能なオプションは、「min」、「geometric」、「arithmetic」、および「max」です。「警告」の場合、「ジオメトリック」が使用されます。バージョン0.22では、デフォルトが「算術」に変更されます。</target>
        </trans-unit>
        <trans-unit id="b8efa217d0db9ce56ac60653645beebe151304f9" translate="yes" xml:space="preserve">
          <source>How to compute the normalizer in the denominator. Possible options are &amp;lsquo;min&amp;rsquo;, &amp;lsquo;geometric&amp;rsquo;, &amp;lsquo;arithmetic&amp;rsquo;, and &amp;lsquo;max&amp;rsquo;. If &amp;lsquo;warn&amp;rsquo;, &amp;lsquo;max&amp;rsquo; will be used. The default will change to &amp;lsquo;arithmetic&amp;rsquo; in version 0.22.</source>
          <target state="translated">分母でノーマライザを計算する方法。可能なオプションは、「min」、「geometric」、「arithmetic」、および「max」です。「警告」の場合、「最大」が使用されます。バージョン0.22では、デフォルトが「算術」に変更されます。</target>
        </trans-unit>
        <trans-unit id="cf894bb3f8fceedab10cdd5da9a5edd37e00865d" translate="yes" xml:space="preserve">
          <source>How to construct the affinity matrix.</source>
          <target state="translated">アフィニティーマトリックスの構築方法</target>
        </trans-unit>
        <trans-unit id="d34268ba2716d71aaaeee2c35e527ca55a46dd2f" translate="yes" xml:space="preserve">
          <source>However ARI can also be useful in a purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection (TODO).</source>
          <target state="translated">しかし、ARI は純粋に教師なしの設定では、クラスタリングモデルの選択に使用できるコンセンサス指数の構成要素としても有用である(TODO)。</target>
        </trans-unit>
        <trans-unit id="0121c2b22395d1a9db3fd77f24d0a9f0e41170e3" translate="yes" xml:space="preserve">
          <source>However MI-based measures can also be useful in purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection.</source>
          <target state="translated">しかし,MI に基づく測定値は,クラスタリングモデルの選択に用いることができるコンセンサス指数の構成要素として,純粋に教師なしの設定でも有用である.</target>
        </trans-unit>
        <trans-unit id="117b6230e0e8ab3fcdc1b277507becef8a05f759" translate="yes" xml:space="preserve">
          <source>However care must taken to always make the affinity matrix symmetric so that the eigenvector decomposition works as expected.</source>
          <target state="translated">しかし、固有ベクトル分解が期待通りに動作するように、親和行列を常に対称にするように注意しなければなりません。</target>
        </trans-unit>
        <trans-unit id="92447df8a934c98a63d3aa91a9c263efa88d6300" translate="yes" xml:space="preserve">
          <source>However let&amp;rsquo;s keep our high capacity random forest model for now so as to illustrate some pitfalls with feature importance on variables with many unique values.</source>
          <target state="translated">ただし、多くの一意の値を持つ変数の特徴が重要ないくつかの落とし穴を説明するために、今のところ大容量のランダムフォレストモデルを維持しましょう。</target>
        </trans-unit>
        <trans-unit id="925f5b77eb2888a89c04118c35bff0f0ace7255e" translate="yes" xml:space="preserve">
          <source>However the RI score does not guarantee that random label assignments will get a value close to zero (esp. if the number of clusters is in the same order of magnitude as the number of samples).</source>
          <target state="translated">しかし、RIスコアは、ラベルのランダムな割り当てがゼロに近い値を得ることを保証するものではありません(特に、クラスターの数がサンプル数と同じ桁数である場合)。</target>
        </trans-unit>
        <trans-unit id="11d179b15971b8eaae6270be9fce57c0bd0d2416" translate="yes" xml:space="preserve">
          <source>However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.</source>
          <target state="translated">しかし、利用可能なデータを3つのセットに分割することで、モデルの学習に使用できるサンプルの数を大幅に減らし、結果は(訓練、検証)セットのペアのための特定のランダムな選択に依存することができます。</target>
        </trans-unit>
        <trans-unit id="56c680421b5fb07e56baa9a65f13a80fce385b54" translate="yes" xml:space="preserve">
          <source>However, coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix \(X\) have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance. This situation of &lt;em&gt;multicollinearity&lt;/em&gt; can arise, for example, when data are collected without an experimental design.</source>
          <target state="translated">ただし、通常最小二乗法の係数推定は、モデル項の独立性に依存しています。項が相関していて、計画行列\（X \）の列に近似線形依存がある場合、計画行列は特異に近くなり、その結果、最小二乗推定は観測された応答のランダム誤差に非常に敏感になります。大きな分散を生成します。この&lt;em&gt;多重共線性の&lt;/em&gt;状況は、たとえば、実験計画なしでデータが収集された場合に発生する可能&lt;em&gt;性&lt;/em&gt;があります。</target>
        </trans-unit>
        <trans-unit id="aca3ba038ade9dc36b01dc839f8a0cfb1c392a3d" translate="yes" xml:space="preserve">
          <source>However, dropping one category breaks the symmetry of the original representation and can therefore induce a bias in downstream models, for instance for penalized linear classification or regression models.</source>
          <target state="translated">しかし、1つのカテゴリを削除すると、元の表現の対称性が崩れ、そのため、例えば、罰則付き線形分類や回帰モデルのように、下流のモデルに偏りが生じる可能性があります。</target>
        </trans-unit>
        <trans-unit id="bf734282463bfc3a9cb343729f546342ec401691" translate="yes" xml:space="preserve">
          <source>However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error.</source>
          <target state="translated">しかし、問題の訓練サイズに対して学習曲線が急峻な場合、5倍または10倍のクロスバリデーションは一般化誤差を過大評価する可能性があります。</target>
        </trans-unit>
        <trans-unit id="fc162d85afa0b20b4064f40b16eb0e55ca89c629" translate="yes" xml:space="preserve">
          <source>However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values.</source>
          <target state="translated">しかし、あるハイパーパラメータ値について、推定器がオーバーフィットしているか、あるいはアンダーフィットしているかを調べるために、1つのハイパーパラメータのトレーニングスコアとバリデーションスコアへの影響をプロットすると便利な場合があります。</target>
        </trans-unit>
        <trans-unit id="5c8b24673bb3f660f66f90035a856044be6d6f9e" translate="yes" xml:space="preserve">
          <source>However, note that this transformer will only do a binary one-hot encoding when feature values are of type string. If categorical features are represented as numeric values such as int, the DictVectorizer can be followed by &lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; to complete binary one-hot encoding.</source>
          <target state="translated">ただし、このトランスフォーマーは、機能値が文字列型である場合にのみ、バイナリワンホットエンコーディングを実行することに注意してください。カテゴリー特徴がintなどの数値として表されている場合、DictVectorizerの後に&lt;a href=&quot;sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;sklearn.preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt;を続けて、バイナリワンホットエンコーディングを完了することができます。</target>
        </trans-unit>
        <trans-unit id="8b25d9ad009118aef0894664f601ac10786f8b49" translate="yes" xml:space="preserve">
          <source>However, this is not the most precise way of doing this computation, and the distance matrix returned by this function may not be exactly symmetric as required by, e.g., &lt;code&gt;scipy.spatial.distance&lt;/code&gt; functions.</source>
          <target state="translated">ただし、これはこの計算を行う最も正確な方法ではなく、この関数によって返される距離行列は、たとえば &lt;code&gt;scipy.spatial.distance&lt;/code&gt; 関数で必要とされるように正確に対称的ではない場合があります。</target>
        </trans-unit>
        <trans-unit id="379cfb166aa26713fe1131478e9b37a4224780ad" translate="yes" xml:space="preserve">
          <source>Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent</source>
          <target state="translated">Hsiang-Fu Yu,Fang-Lan Huang,Chih-Jen Lin (2011).二重座標降下</target>
        </trans-unit>
        <trans-unit id="15d1d4b26d2ba06629e368bf6c8a860d8762ef89" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="translated">Huber（ &lt;code&gt;'huber'&lt;/code&gt; ）：最小二乗と最小絶対偏差を組み合わせた別のロバスト損失関数。外れ値に関する感度を制御するには、 &lt;code&gt;alpha&lt;/code&gt; を使用します（詳細については、&lt;a href=&quot;#f2001&quot; id=&quot;id15&quot;&gt;[F2001]&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="31a935f21354ade96cddb9bceb15816934445a99" translate="yes" xml:space="preserve">
          <source>Huber (&lt;code&gt;'huber'&lt;/code&gt;): Another robust loss function that combines least squares and least absolute deviation; use &lt;code&gt;alpha&lt;/code&gt; to control the sensitivity with regards to outliers (see &lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id18&quot;&gt;[F2001]&lt;/a&gt; for more details).</source>
          <target state="translated">Huber（ &lt;code&gt;'huber'&lt;/code&gt; ）：最小二乗法と最小絶対偏差を組み合わせたもう1つの堅牢な損失関数。 &lt;code&gt;alpha&lt;/code&gt; を使用して、外れ値に関する感度を制御します（詳細については、&lt;a href=&quot;model_evaluation#f2001&quot; id=&quot;id18&quot;&gt;[F2001]&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="9ac7569be3812003aa580f2d415abbe085c935f8" translate="yes" xml:space="preserve">
          <source>Huber: less sensitive to outliers than least-squares. It is equivalent to least squares when \(|y_i - f(x_i)| \leq \varepsilon\), and \(L(y_i, f(x_i)) = \varepsilon |y_i - f(x_i)| - \frac{1}{2} \varepsilon^2\) otherwise.</source>
          <target state="translated">Huber:最小二乗よりも外れ値の影響を受けにくい。It is equivalent to least squares when \(|y_i-f(x_i)| \(L(y_i,f(x_i)))and \(L(y_i,f(x_i))=\varepsilon |y_i-f(x_i)|-\frac{1}{2}\そうでなければ</target>
        </trans-unit>
        <trans-unit id="3d12d436101cbc3212af50bf81000f6d78d4cf01" translate="yes" xml:space="preserve">
          <source>HuberRegressor vs Ridge on dataset with strong outliers</source>
          <target state="translated">強い外れ値を持つデータセットにおけるHuberRegressorとRidgeの比較</target>
        </trans-unit>
        <trans-unit id="7e58a6e8d89e8504ad31e135de9b485ad40f05f6" translate="yes" xml:space="preserve">
          <source>Hue</source>
          <target state="translated">Hue</target>
        </trans-unit>
        <trans-unit id="c7a8b2b20a9c45f674f17cd8ef7ece305e1c36eb" translate="yes" xml:space="preserve">
          <source>Hue:</source>
          <target state="translated">Hue:</target>
        </trans-unit>
        <trans-unit id="4e99bcdee413a9c98d317e0e8e4199a2bf582f90" translate="yes" xml:space="preserve">
          <source>Hugo Chavez</source>
          <target state="translated">ヒューゴ・チャベス</target>
        </trans-unit>
        <trans-unit id="27d175ec2bd32b6e89237e92741eaada2632ca6b" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter.</source>
          <target state="translated">Hyper-parameter:αパラメータよりも前のガンマ分布の逆スケールパラメータ(レートパラメータ)。</target>
        </trans-unit>
        <trans-unit id="135e7e12c7ab5ea7496649e72ee134478ecf558e" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hyper-parameter:アルファパラメータよりも前のガンマ分布の逆スケールパラメータ(レートパラメータ).デフォルトは 1.e-6.</target>
        </trans-unit>
        <trans-unit id="b2f7b3253a19f527d0298206233b561d7b41b5a7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter.</source>
          <target state="translated">Hyper-parameter:ラムダパラメータ上のガンマ分布の事前分布の逆スケールパラメータ(レートパラメータ).</target>
        </trans-unit>
        <trans-unit id="761054fe5bafcad49a16f057764235860452b8da" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6</source>
          <target state="translated">Hyper-parameter:ラムダパラメータよりも前のガンマ分布の逆スケールパラメータ(レートパラメータ).デフォルトは 1.e-6</target>
        </trans-unit>
        <trans-unit id="6001ea6392d3003569381e7107254e88f75fd600" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hyper-parameter:ラムダパラメータよりも前のガンマ分布の逆スケールパラメータ(レートパラメータ).デフォルトは1.e-6です。</target>
        </trans-unit>
        <trans-unit id="dc7fba2810913663c629f4f037b88df90cdd9978" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter.</source>
          <target state="translated">Hyper-parameter:アルファパラメータ上のガンマ分布の事前分布の形状パラメータ.</target>
        </trans-unit>
        <trans-unit id="81e171654bf22a490946ec147c219e96694497ff" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6</source>
          <target state="translated">Hyper-parameter:アルファパラメータに対するガンマ分布の事前分布の形状パラメータ.デフォルトは 1.e-6 です.</target>
        </trans-unit>
        <trans-unit id="b07af48fd68aeaacb4df041ef30bae006150c237" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</source>
          <target state="translated">Hyper-parameter:アルファパラメータよりもガンマ分布の優先順位を表す形状パラメータ.デフォルトは 1.e-6.</target>
        </trans-unit>
        <trans-unit id="532d93a63b09b5d558170a615d6e76799550e7c3" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter.</source>
          <target state="translated">Hyper-parameter:ラムダパラメータに対するガンマ分布の事前分布の形状パラメータ.</target>
        </trans-unit>
        <trans-unit id="1398aea0b1e181e76b6d9d73db4040ccf06ee2f7" translate="yes" xml:space="preserve">
          <source>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</source>
          <target state="translated">Hyper-parameter:ラムダパラメータに対するガンマ分布優先度の形状パラメータ.デフォルトは 1.e-6.</target>
        </trans-unit>
        <trans-unit id="7a5b8a439bb2492412d2944256add4dcdf337928" translate="yes" xml:space="preserve">
          <source>Hyper-parameter optimizers</source>
          <target state="translated">ハイパーパラメータオプティマイザ</target>
        </trans-unit>
        <trans-unit id="223bf115da53d3d9cdf837b624135b565596fd92" translate="yes" xml:space="preserve">
          <source>Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;kernel&lt;/code&gt; and &lt;code&gt;gamma&lt;/code&gt; for Support Vector Classifier, &lt;code&gt;alpha&lt;/code&gt; for Lasso, etc.</source>
          <target state="translated">ハイパーパラメーターは、推定器内で直接学習されないパラメーターです。scikit-learnでは、それらは引数として推定クラスのコンストラクターに渡されます。典型的な例には、 &lt;code&gt;C&lt;/code&gt; 、 &lt;code&gt;kernel&lt;/code&gt; 、サポートベクトル分類子の &lt;code&gt;gamma&lt;/code&gt; 、投げ縄の &lt;code&gt;alpha&lt;/code&gt; などがあります。</target>
        </trans-unit>
        <trans-unit id="568b05951392672a52de0358537dd29fcafbe544" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="translated">推定器のハイパーパラメータは、&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-set-params&quot;&gt;set_params（）&lt;/a&gt;メソッドを介して構築された後で更新できます。 &lt;code&gt;fit()&lt;/code&gt; を複数回呼び出すと、以前の &lt;code&gt;fit()&lt;/code&gt; で学習した内容が上書きされます。</target>
        </trans-unit>
        <trans-unit id="3320fca926b13c61acfba24014e8ac870169bd3f" translate="yes" xml:space="preserve">
          <source>Hyper-parameters of an estimator can be updated after it has been constructed via the &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-set-params&quot;&gt;set_params()&lt;/a&gt; method. Calling &lt;code&gt;fit()&lt;/code&gt; more than once will overwrite what was learned by any previous &lt;code&gt;fit()&lt;/code&gt;:</source>
          <target state="translated">推定器のハイパーパラメータは、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-set-params&quot;&gt;set_params（）&lt;/a&gt;メソッドを介して構築された後に更新できます。 &lt;code&gt;fit()&lt;/code&gt; を複数回呼び出すと、以前の &lt;code&gt;fit()&lt;/code&gt; で学習した内容が上書きされます。</target>
        </trans-unit>
        <trans-unit id="1db8c072507305b4aa23189287be39423349b8f4" translate="yes" xml:space="preserve">
          <source>Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True).</source>
          <target state="translated">逆変換を学習する尾根回帰のハイパーパラ メ タ (fit_inverse_transform=True の場合)。</target>
        </trans-unit>
        <trans-unit id="a15138d06876fc00149292405bf57e4204d00bbe" translate="yes" xml:space="preserve">
          <source>Hyperparameters</source>
          <target state="translated">Hyperparameters</target>
        </trans-unit>
        <trans-unit id="181eca8daf7aaeed93f61701c7eddb643dc6b36a" translate="yes" xml:space="preserve">
          <source>Hyperparameters:</source>
          <target state="translated">Hyperparameters:</target>
        </trans-unit>
        <trans-unit id="8bb86931be2a9d0449c3eec151da751cb88591f1" translate="yes" xml:space="preserve">
          <source>I. Guyon, &amp;ldquo;Design of experiments for the NIPS 2003 variable selection benchmark&amp;rdquo;, 2003.</source>
          <target state="translated">I. Guyon、「NIPS 2003変数選択ベンチマークの実験計画」、2003年。</target>
        </trans-unit>
        <trans-unit id="074b587a2df67fa7bdaebb29bf4f1381e49051c3" translate="yes" xml:space="preserve">
          <source>I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Maci&amp;agrave;, B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, &lt;a href=&quot;https://ieeexplore.ieee.org/document/7280767&quot;&gt;Design of the 2015 ChaLearn AutoML Challenge&lt;/a&gt;, IJCNN 2015.</source>
          <target state="translated">I. Guyon、K。Bennett、G。Cawley、HJ Escalante、S。Escalera、TK Ho、N.Maci&amp;agrave;、B。Ray、M。Saeed、AR Statnikov、E。Viegas、&lt;a href=&quot;https://ieeexplore.ieee.org/document/7280767&quot;&gt;2015 ChaLearn AutoMLチャレンジのデザイン&lt;/a&gt;、IJCNN 2015年。</target>
        </trans-unit>
        <trans-unit id="483f14c4d9fef04833d7508282eb9a08a8019931" translate="yes" xml:space="preserve">
          <source>I.K. Yeo and R.A. Johnson, &amp;ldquo;A new family of power transformations to improve normality or symmetry.&amp;rdquo; Biometrika, 87(4), pp.954-959, (2000).</source>
          <target state="translated">IKYeoとRAJohnson、「正規性または対称性を改善するための電力変換の新しいファミリ」。Biometrika、87（4）、pp.954-959、（2000）。</target>
        </trans-unit>
        <trans-unit id="a238a89365b9d0ce7f5fb26e189eb03cdc08fbe5" translate="yes" xml:space="preserve">
          <source>ICA can also be used as yet another non linear decomposition that finds components with some sparsity:</source>
          <target state="translated">ICAは、ある程度の疎さを持つ成分を見つける別の非線形分解としても使用することができます。</target>
        </trans-unit>
        <trans-unit id="57933c6e2d57c3e3911db47768687ccc98d16924" translate="yes" xml:space="preserve">
          <source>IDpol</source>
          <target state="translated">IDpol</target>
        </trans-unit>
        <trans-unit id="fcc34dd193c826ae2f0c8b804c532252b4a25480" translate="yes" xml:space="preserve">
          <source>INDUS proportion of non-retail business acres per town</source>
          <target state="translated">INDUS 1町あたりの非小売業の面積の割合</target>
        </trans-unit>
        <trans-unit id="44a4d7b7db7815be999da6a406f4dadd2c4327c5" translate="yes" xml:space="preserve">
          <source>Identification number of each sample, as ordered in dataset.data.</source>
          <target state="translated">dataset.data.dataで順番に並べられた各サンプルの識別番号。</target>
        </trans-unit>
        <trans-unit id="4b5c601d48e24d2806952d270f88677fcd7cfb39" translate="yes" xml:space="preserve">
          <source>Identifying which category an object belongs to.</source>
          <target state="translated">オブジェクトがどのカテゴリに属するかを識別する</target>
        </trans-unit>
        <trans-unit id="02d51b4f13558cbcfc807b53522b1ffb156ad7e7" translate="yes" xml:space="preserve">
          <source>Identity: d(x, y) = 0 if and only if x == y</source>
          <target state="translated">同一性:d(x,y)=0 (ただし、x ==y の場合のみ)</target>
        </trans-unit>
        <trans-unit id="35bd2069c37f2c6a308bc5401948b247d5bcfc02" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;all&amp;rdquo;, the imputer mask will represent all features.</source>
          <target state="translated">「すべて」の場合、入力マスクはすべての機能を表します。</target>
        </trans-unit>
        <trans-unit id="84934b5d658c0a370c458ee55fa3255bb65884a6" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo; (default), the imputer mask will be of same type as input.</source>
          <target state="translated">「auto」（デフォルト）の場合、入力マスクは入力と同じタイプになります。</target>
        </trans-unit>
        <trans-unit id="7cdc1bc49e801caf1ff212e1000d88bb13d7e93e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">「auto」の場合、 &lt;code&gt;max_features=n_features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="164a2722286c1b34bc2df80a90c75397afce3e6b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">「auto」の場合、 &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="911a50d98b398312fa01572b5d7b864da542117b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;auto&amp;rdquo;, then &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt;.</source>
          <target state="translated">「auto」の場合、 &lt;code&gt;max_samples=min(256, n_samples)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="dca169b413a6ec050ae0928eb38f43b00b9c08e0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;constant&amp;rdquo;, then replace missing values with fill_value. Can be used with strings or numeric data.</source>
          <target state="translated">「定数」の場合、欠損値をfill_valueに置き換えます。文字列または数値データで使用できます。</target>
        </trans-unit>
        <trans-unit id="fed653e1ff76c14b62a8cb9c0f4474c620b2641e" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;log2&amp;rdquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="translated">「log2」の場合、 &lt;code&gt;max_features=log2(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e799052bdd1932be1b28378fc91f87421f6d1065" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along each column. Can only be used with numeric data.</source>
          <target state="translated">「平均」の場合、各列の平均を使用して欠損値を置き換えます。数値データでのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="8c28cbae695709f5ae6daaba6d2035fa26d4e040" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;mean&amp;rdquo;, then replace missing values using the mean along the axis.</source>
          <target state="translated">「平均」の場合、軸に沿った平均を使用して欠損値を置き換えます。</target>
        </trans-unit>
        <trans-unit id="d5353b7f39f25231d62cbbc36fcd604e05d2faa0" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along each column. Can only be used with numeric data.</source>
          <target state="translated">「中央値」の場合、各列の中央値を使用して欠損値を置き換えます。数値データでのみ使用できます。</target>
        </trans-unit>
        <trans-unit id="2c7bf0a70af62c9d1ff80c38810d3732da415b46" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;median&amp;rdquo;, then replace missing values using the median along the axis.</source>
          <target state="translated">「中央値」の場合、軸に沿った中央値を使用して欠損値を置き換えます。</target>
        </trans-unit>
        <trans-unit id="b9dfb246debbef95e2bc6e78da2b0aca54b8e768" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;missing-only&amp;rdquo; (default), the imputer mask will only represent features containing missing values during fit time.</source>
          <target state="translated">「missing-only」（デフォルト）の場合、インプターマスクは、適合時間中に欠損値を含む特徴のみを表します。</target>
        </trans-unit>
        <trans-unit id="fb9cd590a090a11e857ebbc7c5d49f19787d4a57" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along each column. Can be used with strings or numeric data.</source>
          <target state="translated">「most_frequency」の場合、各列に沿って最も頻度の高い値を使用して、missingを置き換えます。文字列または数値データで使用できます。</target>
        </trans-unit>
        <trans-unit id="a90ab2bff0e7c4a2db0c7d70bcb17fa44e1b8cb3" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;most_frequent&amp;rdquo;, then replace missing using the most frequent value along the axis.</source>
          <target state="translated">「most_frequency」の場合、軸に沿って最も頻度の高い値を使用して、missingを置き換えます。</target>
        </trans-unit>
        <trans-unit id="8007580c79fb9470823eec0b7f7391f7011a44a8" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that &lt;code&gt;base_estimator&lt;/code&gt; has been fitted already and all data is used for calibration.</source>
          <target state="translated">「prefit」が渡された場合、 &lt;code&gt;base_estimator&lt;/code&gt; はすでに適合されていると見なされ、すべてのデータがキャリブレーションに使用されます。</target>
        </trans-unit>
        <trans-unit id="d25972b438acba3aa495003bff5b880c3dc78f95" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;prefit&amp;rdquo; is passed, it is assumed that base_estimator has been fitted already and all data is used for calibration.</source>
          <target state="translated">「prefit」が渡された場合、base_estimatorはすでに適合していると見なされ、すべてのデータがキャリブレーションに使用されます。</target>
        </trans-unit>
        <trans-unit id="ddc01f2adfc0b5da49bb0bea104c04055f37082b" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (same as &amp;ldquo;auto&amp;rdquo;).</source>
          <target state="translated">「sqrt」の場合、 &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; （「auto」と同じ）。</target>
        </trans-unit>
        <trans-unit id="050de520f25e08567f8dcb7bcdaa6887bd8ca53c" translate="yes" xml:space="preserve">
          <source>If &amp;ldquo;sqrt&amp;rdquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">「sqrt」の場合、 &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="274dd12ab1d70a7a9d00df8bbe2aa7f35f2ca3c4" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;SAMME.R&amp;rsquo; then use the SAMME.R real boosting algorithm. &lt;code&gt;base_estimator&lt;/code&gt; must support calculation of class probabilities. If &amp;lsquo;SAMME&amp;rsquo; then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations.</source>
          <target state="translated">「SAMME.R」の場合、SAMME.Rリアルブースティングアルゴリズムを使用します。 &lt;code&gt;base_estimator&lt;/code&gt; は、クラス確率の計算をサポートする必要があります。「SAMME」の場合、SAMME離散ブースティングアルゴリズムを使用します。SAMME.Rアルゴリズムは通常、SAMMEよりも速く収束し、ブースティングの反復回数を減らしてテストエラーを低減します。</target>
        </trans-unit>
        <trans-unit id="51b26722f92fe40c28c6f4d36bb516d8181566a9" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, early stopping is enabled if the sample size is larger than 10000. If True, early stopping is enabled, otherwise early stopping is disabled.</source>
          <target state="translated">'auto'の場合、サンプルサイズが10000より大きい場合、早期停止が有効になります。Trueの場合、早期停止が有効になります。それ以外の場合、早期停止は無効になります。</target>
        </trans-unit>
        <trans-unit id="7ae3261c7ce3a365ccb1e46d21ef269f4ad371b0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, the threshold is determined as in the original paper.</source>
          <target state="translated">'auto'の場合、しきい値は元の論文と同様に決定されます。</target>
        </trans-unit>
        <trans-unit id="34bbe83eef64f8685433d192f4dd39b726225179" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;auto&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">'auto'の場合、 &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7bac8214432dad215f7331c0af16dfd3868b9e19" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;balanced&amp;rsquo;, class weights will be given by &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt;. If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.</source>
          <target state="translated">「バランス」の場合、クラスの重みは &lt;code&gt;n_samples / (n_classes * np.bincount(y))&lt;/code&gt; によって与えられます。辞書が指定されている場合、キーはクラスであり、値は対応するクラスの重みです。Noneを指定すると、クラスの重みは均一になります。</target>
        </trans-unit>
        <trans-unit id="2ed37f73bd5305414a6ee47c4802aa22bc780ac0" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;diagram&amp;rsquo;, estimators will be displayed as a diagram in a Jupyter lab or notebook context. If &amp;lsquo;text&amp;rsquo;, estimators will be displayed as text. Default is &amp;lsquo;text&amp;rsquo;.</source>
          <target state="translated">'diagram'の場合、推定値はJupyterラボまたはノートブックのコンテキストで図として表示されます。'text'の場合、推定値はテキストとして表示されます。デフォルトは「テキスト」です。</target>
        </trans-unit>
        <trans-unit id="456401c87cfc2a15cdd408f2dd8be315dc3e833e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;english&amp;rsquo;, a built-in stop word list for English is used. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">「english」の場合、英語の組み込みストップワードリストが使用されます。「英語」にはいくつかの既知の問題があり、別の方法を検討する必要があります（&lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;ストップワードの使用を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="f2019bdbdfa8956b7b54e8a5677954f4996f6374" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;file&amp;rsquo;, the sequence items must have a &amp;lsquo;read&amp;rsquo; method (file-like object) that is called to fetch the bytes in memory.</source>
          <target state="translated">'file'の場合、シーケンスアイテムには、メモリ内のバイトをフェッチするために呼び出される 'read'メソッド（ファイルのようなオブジェクト）が必要です。</target>
        </trans-unit>
        <trans-unit id="3dd1f3ca74314afe1ddf15184f6ab04977d1a20b" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;filename&amp;rsquo;, the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.</source>
          <target state="translated">'filename'の場合、引数としてfitに渡されるシーケンスは、分析するために生のコンテンツをフェッチするために読み取る必要があるファイル名のリストであることが期待されます。</target>
        </trans-unit>
        <trans-unit id="6381402e5f026c95872c614d3f284a846d432d3e" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;hard&amp;rsquo;, uses predicted class labels for majority rule voting. Else if &amp;lsquo;soft&amp;rsquo;, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.</source>
          <target state="translated">「ハード」の場合、多数決ルールの投票に予測クラスラベルを使用します。そうでない場合、「ソフト」の場合、予測された確率の合計のargmaxに基づいてクラスラベルを予測します。これは、十分に調整された分類器のアンサンブルに推奨されます。</target>
        </trans-unit>
        <trans-unit id="4a61aad0a278d4a0b23f699c1bb6bc9a25b8f483" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;log2&amp;rsquo;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.</source>
          <target state="translated">'log2'の場合、 &lt;code&gt;max_features=log2(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="034a602ff18129b75a77961464f62c916fb178cb" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;precomputed&amp;rsquo;, the training input X is expected to be a distance matrix.</source>
          <target state="translated">「事前計算済み」の場合、トレーニング入力Xは距離行列であると予想されます。</target>
        </trans-unit>
        <trans-unit id="d286c5a17d9d64b09f62a6cd1cf2dc973056dbb7" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;sqrt&amp;rsquo;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.</source>
          <target state="translated">'sqrt'の場合、 &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="efe2693abb0ad6fb0bb32fc7410403c6f8a6131c" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">「warm_start」がTrueの場合、最後のフィッティングの解が次のfit（）呼び出しの初期化として使用されます。これにより、類似の問題でfitが複数回呼び出されたときに、収束を高速化できます。その場合、「n_init」は無視され、最初の呼び出しで1回の初期化のみが行われます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="65bcde64719b83bdeb345ca5fab269155ae4a753" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, &amp;lsquo;n_init&amp;rsquo; is ignored and only a single initialization occurs upon the first call. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">'warm_start'がTrueの場合、最後のフィッティングの解が、fit（）の次の呼び出しの初期化として使用されます。これにより、同様の問題でfitが数回呼び出されたときに、収束を高速化できます。その場合、「n_init」は無視され、最初の呼び出しで1回の初期化のみが発生します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="245f671779646599b33075b7dcf37bf735b34555" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">「warm_start」がTrueの場合、最後のフィッティングの解が次のfit（）呼び出しの初期化として使用されます。これにより、類似の問題でfitが複数回呼び出されたときに、収束を高速化できます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="775000d0783a0c4a0cc36e649a7e52e403237e23" translate="yes" xml:space="preserve">
          <source>If &amp;lsquo;warm_start&amp;rsquo; is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">'warm_start'がTrueの場合、最後のフィッティングの解が、fit（）の次の呼び出しの初期化として使用されます。これにより、同様の問題でfitが数回呼び出されたときに、収束を高速化できます。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="5bb29953be4032aa8bb2090970ba2fb09c57dc65" translate="yes" xml:space="preserve">
          <source>If 0, no progress messages will be printed. If 1, progress messages will be printed to stdout. If &amp;gt; 1, progress messages will be printed and the &lt;code&gt;disp&lt;/code&gt; parameter of &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize&quot;&gt;&lt;code&gt;scipy.optimize.minimize&lt;/code&gt;&lt;/a&gt; will be set to &lt;code&gt;verbose - 2&lt;/code&gt;.</source>
          <target state="translated">0の場合、進行状況メッセージは出力されません。1の場合、進行状況メッセージがstdoutに出力されます。&amp;gt; 1の場合、進行状況メッセージが出力され、&lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize&quot;&gt; &lt;code&gt;scipy.optimize.minimize&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;disp&lt;/code&gt; パラメーターが &lt;code&gt;verbose - 2&lt;/code&gt; 設定されます。</target>
        </trans-unit>
        <trans-unit id="6a2ad0e9541d6795a0339e5a9c03b37f24ea5bc7" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has not been called before.</source>
          <target state="translated">以前に&lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt;が呼び出されたことがない場合。</target>
        </trans-unit>
        <trans-unit id="e311856e2dbc16a358c30263eb21c62e3f976c09" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt;&lt;code&gt;MinMaxScaler&lt;/code&gt;&lt;/a&gt; is given an explicit &lt;code&gt;feature_range=(min, max)&lt;/code&gt; the full formula is:</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.preprocessing.minmaxscaler#sklearn.preprocessing.MinMaxScaler&quot;&gt; &lt;code&gt;MinMaxScaler&lt;/code&gt; に&lt;/a&gt;明示的な &lt;code&gt;feature_range=(min, max)&lt;/code&gt; が指定されている場合、完全な式は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="6f352ac5787c6e0994736f1793f840aefef2eb74" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</source>
          <target state="translated">もし &lt;code&gt;0 &amp;lt; n_components &amp;lt; 1&lt;/code&gt; と &lt;code&gt;svd_solver == 'full'&lt;/code&gt; 、ニーズが説明されること分散量がn_componentsによって指定されたパーセンテージよりも大きくなるように構成要素の数を選択します。</target>
        </trans-unit>
        <trans-unit id="6154e481a1bfebf053da4021c41ed6b15075ac75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;Gram&lt;/code&gt; is overwritten.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、 &lt;code&gt;Gram&lt;/code&gt; は上書きされます。</target>
        </trans-unit>
        <trans-unit id="c8ea59a59509714d84c6c3be2a8959e87ca2c339" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; is overwritten.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、 &lt;code&gt;X&lt;/code&gt; は上書きされます。</target>
        </trans-unit>
        <trans-unit id="ecd953eee019b7cf39fa95c1745e9486ce5fb903" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、正しく分類されたサンプルの数を返します。それ以外の場合は、正しく分類されたサンプルの割合を返します。</target>
        </trans-unit>
        <trans-unit id="8dd52da2b8b6d856acbbc6b969b86fd0a4246941" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the number of misclassifications. Otherwise, return the fraction of misclassifications.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、誤分類の数を返します。それ以外の場合は、誤分類の割合を返します。</target>
        </trans-unit>
        <trans-unit id="85fcfc531652a8814592a07e791b2030fbc9598e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, return the sum of the Jaccard similarity coefficient over the sample set. Otherwise, return the average of Jaccard similarity coefficient.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、サンプルセットのJaccard類似係数の合計を返します。それ以外の場合は、Jaccard類似度係数の平均を返します。</target>
        </trans-unit>
        <trans-unit id="c21045a17e85201e2f77134fc96d9edd698a8ef9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores.</source>
          <target state="translated">場合 &lt;code&gt;False&lt;/code&gt; 、 &lt;code&gt;cv_results_&lt;/code&gt; の属性は、トレーニングのスコアは含まれません。</target>
        </trans-unit>
        <trans-unit id="363d7b7bc89b4fe7d745ba13b3bf107700064544" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;False&lt;/code&gt;, the &lt;code&gt;cv_results_&lt;/code&gt; attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.</source>
          <target state="translated">場合 &lt;code&gt;False&lt;/code&gt; 、 &lt;code&gt;cv_results_&lt;/code&gt; の属性は、トレーニングのスコアは含まれません。トレーニングスコアの計算は、さまざまなパラメーター設定が過剰適合/過適合のトレードオフにどのように影響するかについての洞察を得るために使用されます。ただし、トレーニングセットでスコアを計算すると、計算コストが高くなる可能性があり、最高の一般化パフォーマンスを実現するパラメーターを選択する必要はありません。</target>
        </trans-unit>
        <trans-unit id="4f7a2b9af6d7b5ad533a302e51ca948f564886c6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s default scorer is used.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、推定器のデフォルトのスコアラーが使用されます。</target>
        </trans-unit>
        <trans-unit id="ab9a136f2eebf764f09dd9b08d3d9d7a3daec6b9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt; the estimator&amp;rsquo;s score method is used.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、推定量のスコア法が使用されます。</target>
        </trans-unit>
        <trans-unit id="a8dec298ccc565c5c7f632ae827694845b31aa21" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;estimator&lt;/code&gt; is considered fitted if there exist an attribute that ends with a underscore and does not start with double underscore.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、アンダースコアで終わり、ダブルアンダースコアで始まらない属性が存在する場合、 &lt;code&gt;estimator&lt;/code&gt; は適合していると見なされます。</target>
        </trans-unit>
        <trans-unit id="89a2c07a59e8a597581d7c4accbf8ade7624601a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, &lt;code&gt;init_size= 3 * batch_size&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、 &lt;code&gt;init_size= 3 * batch_size&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0206caad9c301767e28c1eb37b72a3a7f7598e94" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、各クラスのスコアが返されます。それ以外の場合、これはデータに対して実行される平均化のタイプを決定します。</target>
        </trans-unit>
        <trans-unit id="de8d1676c9bb98aea236fe73b6992134925cbda9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;None&lt;/code&gt;, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data: Note: multiclass ROC AUC currently only handles the &amp;lsquo;macro&amp;rsquo; and &amp;lsquo;weighted&amp;rsquo; averages.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; の場合、各クラスのスコアが返されます。それ以外の場合、これにより、データに対して実行される平均化のタイプが決まります。注：マルチクラスROC AUCは現在、「マクロ」および「加重」平均のみを処理します。</target>
        </trans-unit>
        <trans-unit id="f1170dbf5a5618e80add067200212cb5804a58cd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、フルパスは &lt;code&gt;coef_path_&lt;/code&gt; 属性に格納されます。大きな問題または多くのターゲットのソリューションを計算する場合、 &lt;code&gt;fit_path&lt;/code&gt; を &lt;code&gt;False&lt;/code&gt; に設定すると、特に小さなアルファでスピードアップにつながります。</target>
        </trans-unit>
        <trans-unit id="97edef35821191bb6c4443dade8924b80d003e19" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt; then features with missing values during &lt;code&gt;transform&lt;/code&gt; which did not have any missing values during &lt;code&gt;fit&lt;/code&gt; will be imputed with the initial imputation method only. Set to &lt;code&gt;True&lt;/code&gt; if you have many features with no missing values at both &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; time to save compute.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、 &lt;code&gt;transform&lt;/code&gt; 中 &lt;code&gt;fit&lt;/code&gt; 欠測値があり、近似中に欠測値がなかったフィーチャは、最初の代入方法でのみ代入されます。計算を節約するために、 &lt;code&gt;fit&lt;/code&gt; 時間と &lt;code&gt;transform&lt;/code&gt; 時間の両方で欠測値のない多くのフィーチャがある場合は、 &lt;code&gt;True&lt;/code&gt; に設定します。</target>
        </trans-unit>
        <trans-unit id="e703de20e5680ee264e2b1b950a8b1ca587cd24f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、Xがコピーされます。そうしないと、上書きされる可能性があります。</target>
        </trans-unit>
        <trans-unit id="8e26b0bb501133486ba99496e311f44a49ce472b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, perform metric MDS; otherwise, perform nonmetric MDS.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、メトリックMDSを実行します。それ以外の場合は、非メトリックMDSを実行します。</target>
        </trans-unit>
        <trans-unit id="a2b129bca8e38a348fd53d1896c7796acded2f57" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return a sparse feature matrix</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、スパース特徴行列を返します</target>
        </trans-unit>
        <trans-unit id="887d26ef7077238a636d223d3985225a211c8d82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, return the prior class probability and conditional probabilities of features given classes, from which the data was drawn.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、データが抽出された、指定されたクラスの特徴の以前のクラス確率と条件付き確率を返します。</target>
        </trans-unit>
        <trans-unit id="0b7bef40bad08d9d2c4e67da6c9b56ea79751005" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;True&lt;/code&gt;, some instances might not belong to any class.</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; の場合、一部のインスタンスはどのクラスにも属していない可能性があります。</target>
        </trans-unit>
        <trans-unit id="e223ba26a8622e808f0df02e86007844177282d6" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; or &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="translated">もし &lt;code&gt;algorithm=&amp;rsquo;lasso_lars&amp;rsquo;&lt;/code&gt; または &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; 、 &lt;code&gt;alpha&lt;/code&gt; ペナルティがL1ノルムに適用されます。もし &lt;code&gt;algorithm=&amp;rsquo;threshold&amp;rsquo;&lt;/code&gt; 、 &lt;code&gt;alpha&lt;/code&gt; 係数がゼロに押しつぶさされるの下閾値の絶対値です。 &lt;code&gt;algorithm=&amp;rsquo;omp&amp;rsquo;&lt;/code&gt; 場合、 &lt;code&gt;alpha&lt;/code&gt; は許容誤差パラメーター、つまり対象となる再構成エラーの値です。この場合、 &lt;code&gt;n_nonzero_coefs&lt;/code&gt; をオーバーライドします。</target>
        </trans-unit>
        <trans-unit id="c8adb20b3b91095a2c077330ab11f60b186c2818" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;algorithm='lasso_lars'&lt;/code&gt; or &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the penalty applied to the L1 norm. If &lt;code&gt;algorithm='threshold'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the absolute value of the threshold below which coefficients will be squashed to zero. If &lt;code&gt;algorithm='omp'&lt;/code&gt;, &lt;code&gt;alpha&lt;/code&gt; is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides &lt;code&gt;n_nonzero_coefs&lt;/code&gt;.</source>
          <target state="translated">もし &lt;code&gt;algorithm='lasso_lars'&lt;/code&gt; または &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt; 、 &lt;code&gt;alpha&lt;/code&gt; ペナルティがL1ノルムに適用されます。もし &lt;code&gt;algorithm='threshold'&lt;/code&gt; 、 &lt;code&gt;alpha&lt;/code&gt; 係数がゼロに押しつぶさされるの下閾値の絶対値です。 &lt;code&gt;algorithm='omp'&lt;/code&gt; 場合、 &lt;code&gt;alpha&lt;/code&gt; は許容範囲パラメーターです。対象となる再構成エラーの値です。この場合、 &lt;code&gt;n_nonzero_coefs&lt;/code&gt; をオーバーライドします。</target>
        </trans-unit>
        <trans-unit id="1ef12938b73ad4fc11883a02f290e9f35cac58e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;axes_[i, j]&lt;/code&gt; is the axes on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;axes_[i]&lt;/code&gt; is the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes in that position.</source>
          <target state="translated">場合 &lt;code&gt;ax&lt;/code&gt; 軸又はなしで、 &lt;code&gt;axes_[i, j]&lt;/code&gt; 第i行の軸とj番目の列です。 &lt;code&gt;ax&lt;/code&gt; が軸のリストである場合、 &lt;code&gt;axes_[i]&lt;/code&gt; は &lt;code&gt;ax&lt;/code&gt; のi番目の項目です。Noneの要素は、その位置に存在しない軸に対応します。</target>
        </trans-unit>
        <trans-unit id="fd2bdf4031503663b9e9168a5bd9a1faa112780b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;contours_[i, j]&lt;/code&gt; is the partial dependence plot on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;contours_[i]&lt;/code&gt; is the partial dependence plot corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a contour plot.</source>
          <target state="translated">場合 &lt;code&gt;ax&lt;/code&gt; 軸又はなしで、 &lt;code&gt;contours_[i, j]&lt;/code&gt; 第i行の部分依存プロットとj番目の列です。 &lt;code&gt;ax&lt;/code&gt; が軸のリストである場合、 &lt;code&gt;contours_[i]&lt;/code&gt; は、 &lt;code&gt;ax&lt;/code&gt; のi番目の項目に対応する部分的な依存関係のプロットです。Noneの要素は、存在しない軸または等高線図を含まない軸に対応します。</target>
        </trans-unit>
        <trans-unit id="16daa78b71c8fbb0a04353048c9be677f4bd1a67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;lines_[i, j]&lt;/code&gt; is the partial dependence curve on the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;lines_[i]&lt;/code&gt; is the partial dependence curve corresponding to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a line plot.</source>
          <target state="translated">場合 &lt;code&gt;ax&lt;/code&gt; 軸又はなしで、 &lt;code&gt;lines_[i, j]&lt;/code&gt; 第i行の部分依存曲線とj番目の列です。 &lt;code&gt;ax&lt;/code&gt; が軸のリストである場合、 &lt;code&gt;lines_[i]&lt;/code&gt; は &lt;code&gt;ax&lt;/code&gt; のi番目の項目に対応する部分的な依存曲線です。 Noneの要素は、存在しない軸または折れ線グラフを含まない軸に対応します。</target>
        </trans-unit>
        <trans-unit id="7b7c522014bc873fbd61bfb64d47b7833096d1b1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the x axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a PDP plot. .. versionadded:: 0.23</source>
          <target state="translated">場合 &lt;code&gt;ax&lt;/code&gt; 軸又はなしで、 &lt;code&gt;vlines_[i, j]&lt;/code&gt; X軸十分位数i行のj列を示す線コレクションです。 &lt;code&gt;ax&lt;/code&gt; が軸のリストである場合、 &lt;code&gt;vlines_[i]&lt;/code&gt; は &lt;code&gt;ax&lt;/code&gt; のi番目の項目に対応します。 Noneの要素は、存在しない軸またはPDPプロットを含まない軸に対応します。 .. versionadded :: 0.23</target>
        </trans-unit>
        <trans-unit id="03e758847856246528ffcca83ba803cf5d3e9c24" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, &lt;code&gt;vlines_[i, j]&lt;/code&gt; is the line collection representing the y axis deciles of the i-th row and j-th column. If &lt;code&gt;ax&lt;/code&gt; is a list of axes, &lt;code&gt;vlines_[i]&lt;/code&gt; corresponds to the i-th item in &lt;code&gt;ax&lt;/code&gt;. Elements that are None correspond to a nonexisting axes or an axes that does not include a 2-way plot. .. versionadded:: 0.23</source>
          <target state="translated">場合 &lt;code&gt;ax&lt;/code&gt; 軸又はなしで、 &lt;code&gt;vlines_[i, j]&lt;/code&gt; 第i行のY軸十分位数とj番目の列を表す線の集合です。 &lt;code&gt;ax&lt;/code&gt; が軸のリストである場合、 &lt;code&gt;vlines_[i]&lt;/code&gt; は &lt;code&gt;ax&lt;/code&gt; のi番目の項目に対応します。Noneの要素は、存在しない軸または2方向プロットを含まない軸に対応します。.. versionadded :: 0.23</target>
        </trans-unit>
        <trans-unit id="1e5d3c60fbe26a21b3685b7cd50d8157796cb85c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;ax&lt;/code&gt; is an axes or None, the &lt;code&gt;bounding_ax_&lt;/code&gt; is the axes where the grid of partial dependence plots are drawn. If &lt;code&gt;ax&lt;/code&gt; is a list of axes or a numpy array of axes, &lt;code&gt;bounding_ax_&lt;/code&gt; is None.</source>
          <target state="translated">場合は &lt;code&gt;ax&lt;/code&gt; 軸またはなしで、 &lt;code&gt;bounding_ax_&lt;/code&gt; は部分的依存性プロットのグリッドが描かれている軸です。場合は &lt;code&gt;ax&lt;/code&gt; 軸のリストや軸のnumpyの配列である、 &lt;code&gt;bounding_ax_&lt;/code&gt; はNoneです。</target>
        </trans-unit>
        <trans-unit id="a88caf8f6b6232395c9c1524315c6ed672bcf763" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt; and X is encoded as a CSR matrix;</source>
          <target state="translated">もし &lt;code&gt;axis=0&lt;/code&gt; かつXがCSRマトリックスとして符号化されます。</target>
        </trans-unit>
        <trans-unit id="160d044408c23f7840586e9cc7d8cab0e43ba9b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, boolean and integer array-like, integer slice, and scalar integer are supported.</source>
          <target state="translated">&lt;code&gt;axis=0&lt;/code&gt; の場合、ブールおよび整数配列のような、整数スライス、およびスカラー整数がサポートされます。</target>
        </trans-unit>
        <trans-unit id="b74f02ef0c3e3aceaf2040e39764c8bf5d153fee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=0&lt;/code&gt;, then impute along columns.</source>
          <target state="translated">&lt;code&gt;axis=0&lt;/code&gt; の場合、列に沿って代入します。</target>
        </trans-unit>
        <trans-unit id="231cba4e2ed9eee1fca5c3a6b02c0c6f66c47550" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt; and X is encoded as a CSC matrix.</source>
          <target state="translated">もし &lt;code&gt;axis=1&lt;/code&gt; 及びXは、CSCマトリックスとして符号化されます。</target>
        </trans-unit>
        <trans-unit id="4405a4c1e894889993d89bb6694cef1a6a8f7db3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;, then impute along rows.</source>
          <target state="translated">&lt;code&gt;axis=1&lt;/code&gt; の場合、行に沿って代入します。</target>
        </trans-unit>
        <trans-unit id="afe718681bc04a6b175f3e0dbacf56b2e22d3277" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;axis=1&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;axis=1&lt;/code&gt; の場合：</target>
        </trans-unit>
        <trans-unit id="bf71a4a70c1ff1b9076f02c43d89e78c4b0ffc27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;backend&lt;/code&gt; is a string it must match a previously registered implementation using the &lt;code&gt;register_parallel_backend&lt;/code&gt; function.</source>
          <target state="translated">&lt;code&gt;backend&lt;/code&gt; が文字列の場合は、 &lt;code&gt;register_parallel_backend&lt;/code&gt; 関数を使用して以前に登録された実装と一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="6456a4494f2ba1f052aff4cf6d35ef66e787bc14" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;base_estimator&lt;/code&gt; is None, then &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; is used for target values of dtype float.</source>
          <target state="translated">&lt;code&gt;base_estimator&lt;/code&gt; がNoneの場合、dtype floatのターゲット値にbase_estimator &lt;code&gt;base_estimator=sklearn.linear_model.LinearRegression()&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="898731158b64382ef9aad2307b39d22b5cd2a315" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dense&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the dense binary indicator format. If &lt;code&gt;'sparse'&lt;/code&gt; return &lt;code&gt;Y&lt;/code&gt; in the sparse binary indicator format. &lt;code&gt;False&lt;/code&gt; returns a list of lists of labels.</source>
          <target state="translated">&lt;code&gt;dense&lt;/code&gt; 場合、高密度のバイナリインジケータ形式で &lt;code&gt;Y&lt;/code&gt; を返します。 &lt;code&gt;'sparse'&lt;/code&gt; 場合、スパースバイナリインジケーター形式で &lt;code&gt;Y&lt;/code&gt; を返します。 &lt;code&gt;False&lt;/code&gt; はラベルのリストのリストを返します。</target>
        </trans-unit>
        <trans-unit id="b1213caecc623f2a5139e82ba5db339edb5f6265" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="translated">&lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合、切片はゼロに設定されます。与えられた問題がバイナリの場合、 &lt;code&gt;intercept_&lt;/code&gt; の形状は（1）です。特に、 &lt;code&gt;multi_class=&amp;rsquo;multinomial&amp;rsquo;&lt;/code&gt; 場合、 &lt;code&gt;intercept_&lt;/code&gt; は結果1（True）に対応し、 &lt;code&gt;-intercept_&lt;/code&gt; は結果0（False）に対応します。</target>
        </trans-unit>
        <trans-unit id="5adb2b902dec2303b1749b6ba9f10123fe5ab03c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape (1,) when the given problem is binary. In particular, when &lt;code&gt;multi_class='multinomial'&lt;/code&gt;, &lt;code&gt;intercept_&lt;/code&gt; corresponds to outcome 1 (True) and &lt;code&gt;-intercept_&lt;/code&gt; corresponds to outcome 0 (False).</source>
          <target state="translated">&lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合、切片はゼロに設定されます。与えられた問題がバイナリの場合、 &lt;code&gt;intercept_&lt;/code&gt; は形状（1、）です。特に、 &lt;code&gt;multi_class='multinomial'&lt;/code&gt; の場合、 &lt;code&gt;intercept_&lt;/code&gt; は結果1（True）に対応し、 &lt;code&gt;-intercept_&lt;/code&gt; は結果0（False）に対応します。</target>
        </trans-unit>
        <trans-unit id="4504cae87026fef1f6989cfa20e2e5bc171d37e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;fit_intercept&lt;/code&gt; is set to False, the intercept is set to zero. &lt;code&gt;intercept_&lt;/code&gt; is of shape(1,) when the problem is binary.</source>
          <target state="translated">&lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合、切片はゼロに設定されます。問題がバイナリの場合、 &lt;code&gt;intercept_&lt;/code&gt; はshape（1、）です。</target>
        </trans-unit>
        <trans-unit id="646836188c841e4fea39e4e4200d1f27e6191986" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;loss&lt;/code&gt; is a callable, then it should be a function that takes two arrays as inputs, the true and predicted value and returns a 1-D array with the i-th value of the array corresponding to the loss on &lt;code&gt;X[i]&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;loss&lt;/code&gt; が呼び出し可能である場合、それは2つの配列を入力として受け取り、真の値と予測された値を取り、 &lt;code&gt;X[i]&lt;/code&gt; 損失に対応する配列のi番目の値を含む1次元配列を返す関数である必要があります。</target>
        </trans-unit>
        <trans-unit id="c42d62680a26d66fc0f439c634f24ee01c670c77" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;memory&lt;/code&gt; is not joblib.Memory-like.</source>
          <target state="translated">&lt;code&gt;memory&lt;/code&gt; がjoblib.Memory-likeでない場合。</target>
        </trans-unit>
        <trans-unit id="e14dd7c153267d74f6b2214ce66bcf041482d792" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_bins&lt;/code&gt; is an array, and there is an ignored feature at index &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;n_bins[i]&lt;/code&gt; will be ignored.</source>
          <target state="translated">&lt;code&gt;n_bins&lt;/code&gt; が配列で、インデックス &lt;code&gt;i&lt;/code&gt; に無視される機能がある場合、 &lt;code&gt;n_bins[i]&lt;/code&gt; は無視されます。</target>
        </trans-unit>
        <trans-unit id="20ab457ec31da79f104a0f7a337ba6bfe94b5438" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_clusters&lt;/code&gt; is set to None, the data is reduced from 100,000 samples to a set of 158 clusters. This can be viewed as a preprocessing step before the final (global) clustering step that further reduces these 158 clusters to 100 clusters.</source>
          <target state="translated">&lt;code&gt;n_clusters&lt;/code&gt; がNoneに設定されている場合、データは100,000サンプルから158クラスターのセットに削減されます。これは、これらの158クラスターをさらに100クラスターに削減する最終（グローバル）クラスター化ステップの前の前処理ステップと見なすことができます。</target>
        </trans-unit>
        <trans-unit id="1769c2fe615105013ff722090827f85ac960dff9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components == 'mle'&lt;/code&gt; and &lt;code&gt;svd_solver == 'full'&lt;/code&gt;, Minka&amp;rsquo;s MLE is used to guess the dimension. Use of &lt;code&gt;n_components == 'mle'&lt;/code&gt; will interpret &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; as &lt;code&gt;svd_solver == 'full'&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;n_components == 'mle'&lt;/code&gt; と &lt;code&gt;svd_solver == 'full'&lt;/code&gt; 、民家のMLEは、ディメンションを推測するために使用されます。 &lt;code&gt;n_components == 'mle'&lt;/code&gt; を使用すると、svd_solver == ' &lt;code&gt;svd_solver == 'auto'&lt;/code&gt; は &lt;code&gt;svd_solver == 'full'&lt;/code&gt; と解釈されます。</target>
        </trans-unit>
        <trans-unit id="959758e689ea656dd0e72e3bda18b0a45bbef2e0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is not set then all components are stored and the sum of the ratios is equal to 1.0.</source>
          <target state="translated">&lt;code&gt;n_components&lt;/code&gt; が設定されていない場合、すべてのコンポーネントが格納され、比率の合計は1.0になります。</target>
        </trans-unit>
        <trans-unit id="712e62a0190856257c5f6877b0d11f259bd408b5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_components&lt;/code&gt; is strictly smaller than the dimensionality of the inputs passed to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt;, the identity matrix will be truncated to the first &lt;code&gt;n_components&lt;/code&gt; rows.</source>
          <target state="translated">場合 &lt;code&gt;n_components&lt;/code&gt; がに渡された入力の次元よりも厳密に小さい&lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt;、単位行列は最初に切り捨てられます &lt;code&gt;n_components&lt;/code&gt; の行。</target>
        </trans-unit>
        <trans-unit id="4aaa2df3fa37c88b24d06638ef7188d7e8ebe112" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each parameter setting(and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;n_jobs&lt;/code&gt; のものよりも高い値に設定し、データは、各パラメータの設定のためにコピーされ（そしてれない &lt;code&gt;n_jobs&lt;/code&gt; 回）。これは、個々のジョブにほとんど時間がかからない場合の効率上の理由で行われますが、データセットが大きく、十分なメモリが利用できない場合は、エラーが発生する可能性があります。この場合の回避策は、 &lt;code&gt;pre_dispatch&lt;/code&gt; を設定することです。その後、メモリは &lt;code&gt;pre_dispatch&lt;/code&gt; のみ何度もコピーされます。 &lt;code&gt;pre_dispatch&lt;/code&gt; の適切な値は &lt;code&gt;2 * n_jobs&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="53682a81a25d0884d79ca09b064b0fc6e7cabd67" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_jobs&lt;/code&gt; was set to a value higher than one, the data is copied for each point in the grid (and not &lt;code&gt;n_jobs&lt;/code&gt; times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set &lt;code&gt;pre_dispatch&lt;/code&gt;. Then, the memory is copied only &lt;code&gt;pre_dispatch&lt;/code&gt; many times. A reasonable value for &lt;code&gt;pre_dispatch&lt;/code&gt; is &lt;code&gt;2 * n_jobs&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;n_jobs&lt;/code&gt; のものよりも高い値に設定し、データは、グリッドの各点のためにコピーされ（そしてれない &lt;code&gt;n_jobs&lt;/code&gt; 回）。これは、個々のジョブにほとんど時間がかからない場合の効率上の理由で行われますが、データセットが大きく、十分なメモリが利用できない場合は、エラーが発生する可能性があります。この場合の回避策は、 &lt;code&gt;pre_dispatch&lt;/code&gt; を設定することです。その後、メモリは &lt;code&gt;pre_dispatch&lt;/code&gt; のみ何度もコピーされます。 &lt;code&gt;pre_dispatch&lt;/code&gt; の適切な値は &lt;code&gt;2 * n_jobs&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="c1cc035dd2ff12188f95601d6fe5c4679ad6bb78" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n_samples == 10000&lt;/code&gt;, storing &lt;code&gt;X&lt;/code&gt; as a NumPy array of type float32 would require 10000 x 100000 x 4 bytes = &lt;strong&gt;4GB in RAM&lt;/strong&gt; which is barely manageable on today&amp;rsquo;s computers.</source>
          <target state="translated">&lt;code&gt;n_samples == 10000&lt;/code&gt; 場合、float32型のNumPy配列として &lt;code&gt;X&lt;/code&gt; を格納するには、10000 x 100000 x 4バイト= &lt;strong&gt;4GBのRAMが必要&lt;/strong&gt;であり、今日のコンピューターではほとんど管理できません。</target>
        </trans-unit>
        <trans-unit id="dd40778e7a383f2053d98b9a07e6219944c6316f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;needs_proba=False&lt;/code&gt; and &lt;code&gt;needs_threshold=False&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt;. If &lt;code&gt;needs_proba=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_proba&lt;/a&gt; (For binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept probability of the positive class). If &lt;code&gt;needs_threshold=True&lt;/code&gt;, the score function is supposed to accept the output of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;.</source>
          <target state="translated">場合 &lt;code&gt;needs_proba=False&lt;/code&gt; のと &lt;code&gt;needs_threshold=False&lt;/code&gt; を、スコア関数は、出力受け入れるようになっている&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;予測を&lt;/a&gt;。場合 &lt;code&gt;needs_proba=True&lt;/code&gt; 、スコア関数は、の出力受け入れるようになっている&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict-proba&quot;&gt;predict_probaを&lt;/a&gt;（バイナリため &lt;code&gt;y_true&lt;/code&gt; 、スコア関数は、正のクラスの確率を受け入れるようになっています）。場合 &lt;code&gt;needs_threshold=True&lt;/code&gt; 、スコア関数は、出力受け入れるようになっている&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_functionを&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="8e65ba558868cb56b0c8a76632ea67901b254afe" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the average Jaccard similarity coefficient, else it returns the sum of the Jaccard similarity coefficient over the sample set.</source>
          <target state="translated">&lt;code&gt;normalize == True&lt;/code&gt; 場合、平均Jaccard類似係数を返します。それ以外の場合は、サンプルセットのJaccard類似係数の合計を返します。</target>
        </trans-unit>
        <trans-unit id="c606413521700e073d3e669024415faa2300a113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).</source>
          <target state="translated">&lt;code&gt;normalize == True&lt;/code&gt; 場合、正しく分類されたサンプルの割合（float）を返します。それ以外の場合、正しく分類されたサンプルの数（int）を返します。</target>
        </trans-unit>
        <trans-unit id="cd9dc36a4d7167817c2823908b4ce633913b9765" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalize == True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int).</source>
          <target state="translated">&lt;code&gt;normalize == True&lt;/code&gt; 場合、誤分類の割合（float）を返します。それ以外の場合は、誤分類の数（int）を返します。</target>
        </trans-unit>
        <trans-unit id="4260d2abf4eeb10994306d99a6424e7eb5ca19c8" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;order='random'&lt;/code&gt;, determines random number generation for the chain order. In addition, it controls the random seed given at each &lt;code&gt;base_estimator&lt;/code&gt; at each chaining iteration. Thus, it is only used when &lt;code&gt;base_estimator&lt;/code&gt; exposes a &lt;code&gt;random_state&lt;/code&gt;. Pass an int for reproducible output across multiple function calls. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;Glossary&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;order='random'&lt;/code&gt; の場合、チェーン順序の乱数生成を決定します。さらに、各連鎖反復で各 &lt;code&gt;base_estimator&lt;/code&gt; に与えられるランダムシードを制御します。ときしたがって、のみ使用され &lt;code&gt;base_estimator&lt;/code&gt; が公開さ &lt;code&gt;random_state&lt;/code&gt; を。複数の関数呼び出しにわたって再現可能な出力のためにintを渡します。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-random-state&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="d0b860961bc5b4a4c45189c0fd4de5c2d61f1ab4" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;out=None&lt;/code&gt;, returns a new array containing the mean values, otherwise a reference to the output array is returned.</source>
          <target state="translated">&lt;code&gt;out=None&lt;/code&gt; の場合は、平均値を含む新しい配列を返します。それ以外の場合は、出力配列への参照を返します。</target>
        </trans-unit>
        <trans-unit id="a1e72f87e91fc5bb6f8882ece59a46bf9ee089e2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;pos_label is None&lt;/code&gt; and in binary classification, this function returns the average precision, recall and F-measure if &lt;code&gt;average&lt;/code&gt; is one of &lt;code&gt;'micro'&lt;/code&gt;, &lt;code&gt;'macro'&lt;/code&gt;, &lt;code&gt;'weighted'&lt;/code&gt; or &lt;code&gt;'samples'&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;pos_label is None&lt;/code&gt; バイナリ分類であれば、この関数は、平均精度、再現率とF値を返す &lt;code&gt;average&lt;/code&gt; の一つである &lt;code&gt;'micro'&lt;/code&gt; 、 &lt;code&gt;'macro'&lt;/code&gt; 、 &lt;code&gt;'weighted'&lt;/code&gt; または &lt;code&gt;'samples'&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="933b8be58a37dcefc6ca9fd3f4735aba59bace4c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r20c70293ef72-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r20c70293ef72-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;probability=True&lt;/code&gt; 場合、決定値から確率推定値を生成するためにPlattスケーリングで学習されたパラメーターに対応します。 &lt;code&gt;probability=False&lt;/code&gt; 場合、それは空の配列です。プラットスケーリングは、ロジスティック関数 &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; ここで、 &lt;code&gt;probA_&lt;/code&gt; と &lt;code&gt;probB_&lt;/code&gt; はデータセットから学習されます&lt;a href=&quot;#r20c70293ef72-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;。マルチクラスのケースとトレーニング手順の詳細については、&lt;a href=&quot;#r20c70293ef72-1&quot; id=&quot;id2&quot;&gt;[1]の&lt;/a&gt;セクション8を参照してください。</target>
        </trans-unit>
        <trans-unit id="afcc3cf20f075d3a281dbe1f0f610f65f9ef38a7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;probability=True&lt;/code&gt;, it corresponds to the parameters learned in Platt scaling to produce probability estimates from decision values. If &lt;code&gt;probability=False&lt;/code&gt;, it&amp;rsquo;s an empty array. Platt scaling uses the logistic function &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; where &lt;code&gt;probA_&lt;/code&gt; and &lt;code&gt;probB_&lt;/code&gt; are learned from the dataset &lt;a href=&quot;#r9709ce4a60d3-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;. For more information on the multiclass case and training procedure see section 8 of &lt;a href=&quot;#r9709ce4a60d3-1&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">&lt;code&gt;probability=True&lt;/code&gt; 場合、決定値から確率推定値を生成するためにPlattスケーリングで学習されたパラメーターに対応します。 &lt;code&gt;probability=False&lt;/code&gt; 場合、それは空の配列です。プラットスケーリングは、ロジスティック関数 &lt;code&gt;1 / (1 + exp(decision_value * probA_ + probB_))&lt;/code&gt; ここで、 &lt;code&gt;probA_&lt;/code&gt; と &lt;code&gt;probB_&lt;/code&gt; はデータセットから学習されます&lt;a href=&quot;#r9709ce4a60d3-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt;。マルチクラスのケースとトレーニング手順の詳細については、&lt;a href=&quot;#r9709ce4a60d3-1&quot; id=&quot;id2&quot;&gt;[1]の&lt;/a&gt;セクション8を参照してください。</target>
        </trans-unit>
        <trans-unit id="7bb4c6eca31ede3ca3e8fe5a9b41ecd9a55b266b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_path==True&lt;/code&gt; returns the entire path, else returns only the last point of the path.</source>
          <target state="translated">&lt;code&gt;return_path==True&lt;/code&gt; がパス全体を返す場合は、パスの最後のポイントのみを返します。</target>
        </trans-unit>
        <trans-unit id="9e477bb8072307702a812f869b8166fe31bf9ca0" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.</source>
          <target state="translated">場合 &lt;code&gt;smooth_idf=True&lt;/code&gt; の IDF（D、T：（デフォルト）、余分なドキュメントがゼロ分裂を防ぎ、正確に一度、コレクション内のすべての用語を含む見られたかのように、定数「1」IDFの分子と分母に加算されます）= log [（1 + n）/（1 + df（d、t））] + 1。</target>
        </trans-unit>
        <trans-unit id="7e7ad1036fa8cee418b26fc730608087f9208f2c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;smooth_idf=True&lt;/code&gt; (the default), the constant &amp;ldquo;1&amp;rdquo; is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1.</source>
          <target state="translated">場合 &lt;code&gt;smooth_idf=True&lt;/code&gt; のIDF（T）=（デフォルト）、余分なドキュメントは、ゼロ除算を防止する、正確に一度、コレクション内のすべての用語を含む見られたかのように、定数「1」IDFの分子と分母に加算されますlog [（1 + n）/（1 + df（t））] +1。</target>
        </trans-unit>
        <trans-unit id="3f772487671a5560a2a2bb3464b54cf0bad5b348" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;svd_solver == 'arpack'&lt;/code&gt;, the number of components must be strictly less than the minimum of n_features and n_samples.</source>
          <target state="translated">&lt;code&gt;svd_solver == 'arpack'&lt;/code&gt; 場合、コンポーネントの数はn_featuresとn_samplesの最小値より厳密に少なくなければなりません。</target>
        </trans-unit>
        <trans-unit id="abdb8ed2b871d03510343cf9ee77736674d298ab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;validate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt; will be checked.</source>
          <target state="translated">&lt;code&gt;validate&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、 &lt;code&gt;X&lt;/code&gt; がチェックされます。</target>
        </trans-unit>
        <trans-unit id="5cfb594032bd50fcef2738a25df520e95867f411" translate="yes" xml:space="preserve">
          <source>If C is a ground truth class assignment and K the clustering, let us define \(a\) and \(b\) as:</source>
          <target state="translated">C が基底真理クラスの代入であり、K がクラスタリングであるとすると、\(a\)と \(b\)を次のように定義します。</target>
        </trans-unit>
        <trans-unit id="40e72ab25b1921db07187a1c526cc9080a10eaea" translate="yes" xml:space="preserve">
          <source>If False, X will be overwritten. &lt;code&gt;copy=False&lt;/code&gt; can be used to save memory but is unsafe for general use.</source>
          <target state="translated">Falseの場合、Xは上書きされます。 &lt;code&gt;copy=False&lt;/code&gt; はメモリを節約するために使用できますが、一般的な使用には安全ではありません。</target>
        </trans-unit>
        <trans-unit id="b5379fd8e8700833a560e6ab84ea58c40e10b6a8" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.</source>
          <target state="translated">False にする と 、 はめ込みに渡されたデータは上書きされ、 fit(X).transform(X)を実行しても期待した結果が得られませんので、 代わりに fit_transform(X)を使います。</target>
        </trans-unit>
        <trans-unit id="3d545281a4ef31d03ffb244079b728a3c5cc8b18" translate="yes" xml:space="preserve">
          <source>If False, data passed to fit are overwritten. Defaults to True.</source>
          <target state="translated">False にする と 、 はめ込みに渡されたデータは上書きされます。デフォルトは True です。</target>
        </trans-unit>
        <trans-unit id="4bf616e8d9d604d2525c59d889782525e410270c" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned</source>
          <target state="translated">Falseの場合、距離は返されません。</target>
        </trans-unit>
        <trans-unit id="b4145c6e6cc098818614b51aca0cae30eca8ed94" translate="yes" xml:space="preserve">
          <source>If False, distances will not be returned.</source>
          <target state="translated">Falseの場合、距離は返されません。</target>
        </trans-unit>
        <trans-unit id="d8cdf8e9cb326e6212f67c80aca3a4f04326fc4c" translate="yes" xml:space="preserve">
          <source>If False, raise a IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">False の場合、ソースサイトからデータをダウンロードしようとするのではなく、データがローカルで利用できない場合に IOError を発生させます。</target>
        </trans-unit>
        <trans-unit id="707f36c34b2f81eacbaf143a8e62cb9371b1332e" translate="yes" xml:space="preserve">
          <source>If False, raise an IOError if the data is not locally available instead of trying to download the data from the source site.</source>
          <target state="translated">False の場合、ソースサイトからデータをダウンロードしようとするのではなく、データがローカルで利用できない場合に IOError を発生させます。</target>
        </trans-unit>
        <trans-unit id="d32001af2bcb0806daa431ab8cf432f700c0bb79" translate="yes" xml:space="preserve">
          <source>If False, the imputer mask will be a numpy array.</source>
          <target state="translated">False の場合、インピュターマスクは numpy 配列になります。</target>
        </trans-unit>
        <trans-unit id="2823ebb07c9bdb5cae0bfca227f5db48d585ba5a" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and dictionary will not be checked.</source>
          <target state="translated">Falseの場合、入力配列Xと辞書はチェックされません。</target>
        </trans-unit>
        <trans-unit id="bd8e933f9aa74b9b27da566d4ffb96f4e62218cf" translate="yes" xml:space="preserve">
          <source>If False, the input arrays X and y will not be checked.</source>
          <target state="translated">Falseの場合、入力配列Xとyはチェックされません。</target>
        </trans-unit>
        <trans-unit id="85aa52dd8c7d5d29b6bebfd616a7ca3fe91cde14" translate="yes" xml:space="preserve">
          <source>If False, the projected data uses a sparse representation if the input is sparse.</source>
          <target state="translated">Falseの場合、入力が疎な場合、投影データは疎な表現を使用します。</target>
        </trans-unit>
        <trans-unit id="7bfec8f3204bdf713e2d3557ec53ea6f3960ad24" translate="yes" xml:space="preserve">
          <source>If False, there is no input validation.</source>
          <target state="translated">Falseの場合、入力の検証は行われません。</target>
        </trans-unit>
        <trans-unit id="a67320198a0b746d35fcc941198f1221ee73c87b" translate="yes" xml:space="preserve">
          <source>If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.</source>
          <target state="translated">Falseの場合、コピーを回避し、代わりにインプレーススケーリングを行います。これは常にインプレースで動作することを保証するものではありません;例えば、データが NumPy 配列や scipy.sparse CSR 行列でない場合、コピーが返される可能性があります。</target>
        </trans-unit>
        <trans-unit id="fcd08eda0bca1685e28de89ae046095006b92653" translate="yes" xml:space="preserve">
          <source>If None (default), load all the categories. If not None, list of category names to load (other categories ignored).</source>
          <target state="translated">None(デフォルト)の場合、すべてのカテゴリを読み込みます。Noneでない場合は、読み込むカテゴリ名のリスト(他のカテゴリは無視されます)。</target>
        </trans-unit>
        <trans-unit id="7c0ab0b638c1cad0f1492e60796eecd4f321a731" translate="yes" xml:space="preserve">
          <source>If None (default), then draw &lt;code&gt;X.shape[0]&lt;/code&gt; samples.</source>
          <target state="translated">None（デフォルト）の場合、 &lt;code&gt;X.shape[0]&lt;/code&gt; サンプルを描画します。</target>
        </trans-unit>
        <trans-unit id="a7cbd99fe721a3cd173045eddaf688b83e7620c1" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s default scorer, if available, is used.</source>
          <target state="translated">Noneの場合、推定器のデフォルトのスコアラー（使用可能な場合）が使用されます。</target>
        </trans-unit>
        <trans-unit id="8c0f950a52950ceff35d04e0ab42f83a05b3adb9" translate="yes" xml:space="preserve">
          <source>If None the estimator&amp;rsquo;s score method is used.</source>
          <target state="translated">Noneの場合、推定量のスコア法が使用されます。</target>
        </trans-unit>
        <trans-unit id="96ad58db5ee1b903109c173fcab72b0955bb0408" translate="yes" xml:space="preserve">
          <source>If None, defaults to 1.0 / n_features</source>
          <target state="translated">None の場合、デフォルトは 1.0/n_features</target>
        </trans-unit>
        <trans-unit id="e5ce9a9046a52014390758ba790166ae01779c1f" translate="yes" xml:space="preserve">
          <source>If None, do not try to decode the content of the files (e.g. for images or other non-text content). If not None, encoding to use to decode text files to Unicode if load_content is True.</source>
          <target state="translated">None の場合は、ファイルの内容をデコードしようとしません (画像やその他のテキスト以外の内容の場合など)。None でない場合は、load_content が True の場合にテキストファイルを Unicode にデコードするために使用するエンコーディング。</target>
        </trans-unit>
        <trans-unit id="3e5e8d666168a7a15a80edb16364256ae0a379e4" translate="yes" xml:space="preserve">
          <source>If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.</source>
          <target state="translated">max_df は [0.7,1.0]の範囲の値を設定することで、コーパス内の文書の用語の頻度に基づいて停止語を自動的に検出し、フィルタリングすることができます。</target>
        </trans-unit>
        <trans-unit id="02542a43a2f09f5328657402d69f49ce442cb6c2" translate="yes" xml:space="preserve">
          <source>If None, pairwise_distances_chunked returns a generator of vertical chunks of the distance matrix.</source>
          <target state="translated">Noneの場合、pairwise_distances_chunkedは、距離行列の垂直チャンクの生成器を返します。</target>
        </trans-unit>
        <trans-unit id="eb5d73cb83520641b0e2c815c109159135d569cc" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s default scorer (if available) is used.</source>
          <target state="translated">Noneの場合、推定器のデフォルトのスコアラー（使用可能な場合）が使用されます。</target>
        </trans-unit>
        <trans-unit id="43ea051b06405f0316e7696e80296e11d93edbf6" translate="yes" xml:space="preserve">
          <source>If None, the estimator&amp;rsquo;s score method is used.</source>
          <target state="translated">Noneの場合、推定量のスコア法が使用されます。</target>
        </trans-unit>
        <trans-unit id="651c3653c15c90a6722a00465ba57c19c30adb9b" translate="yes" xml:space="preserve">
          <source>If None, the threshold is assumed to be half way between neg_label and pos_label.</source>
          <target state="translated">Noneの場合、閾値はneg_labelとpos_labelの中間にあると仮定します。</target>
        </trans-unit>
        <trans-unit id="ac652d29bc285e4e46f5aaf2fe5415c63aee1f09" translate="yes" xml:space="preserve">
          <source>If None, then &lt;code&gt;max_features=n_features&lt;/code&gt;.</source>
          <target state="translated">Noneの場合、 &lt;code&gt;max_features=n_features&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2f9e5ee96434f57529c2481b71d631d9dd0cb5e7" translate="yes" xml:space="preserve">
          <source>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</source>
          <target state="translated">True(デフォルト)の場合,誤差2乗法線をn_featuresで分割します.Falseの場合,誤差2乗法線は再スケーリングされません.</target>
        </trans-unit>
        <trans-unit id="da82574bb396bf8045c493d20398be74e4e9ef51" translate="yes" xml:space="preserve">
          <source>If True (default), then include a bias column, the feature in which all polynomial powers are zero (i.e. a column of ones - acts as an intercept term in a linear model).</source>
          <target state="translated">True(デフォルト)の場合、バイアス列を含みます。これは、すべての多項式の累乗が0である特徴(すなわち、1の列-線形モデルの切片項として機能します)を含みます。</target>
        </trans-unit>
        <trans-unit id="d150b2a4c21e929dfd726f6463d03ca9f005e91a" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="translated">True（デフォルト）の場合、変換に欠損値があり、フィットに欠損値がない特徴がある場合、transformはエラーを発生させます。これは &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt; の場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="9da3cf1a0e0153fc6c646a1aa71f68e34d8d27f5" translate="yes" xml:space="preserve">
          <source>If True (default), transform will raise an error when there are features with missing values in transform that have no missing values in fit. This is applicable only when &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt;.</source>
          <target state="translated">True（デフォルト）の場合、変換に欠落値があり、フィットに欠落値がないフィーチャがある場合、変換はエラーを発生させます。これは、 &lt;code&gt;features=&quot;missing-only&quot;&lt;/code&gt; の場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="a4fe165b3f600e13152308080cc2a736269c867b" translate="yes" xml:space="preserve">
          <source>If True and &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; has been called before, the solution of the previous call to &lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/a&gt; is used as the initial linear transformation (&lt;code&gt;n_components&lt;/code&gt; and &lt;code&gt;init&lt;/code&gt; will be ignored).</source>
          <target state="translated">真とした場合&lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt;以前に呼び出されている、前回の呼び出しの解決&lt;a href=&quot;#sklearn.neighbors.NeighborhoodComponentsAnalysis.fit&quot;&gt; &lt;code&gt;fit&lt;/code&gt; &lt;/a&gt;初期線形変換として使用されている（ &lt;code&gt;n_components&lt;/code&gt; と &lt;code&gt;init&lt;/code&gt; 無視されます）。</target>
        </trans-unit>
        <trans-unit id="d91ad850130f94be79fb668041bf3eecd01a29b0" translate="yes" xml:space="preserve">
          <source>If True and if X is sparse, the method also returns the intercept, and the solver is automatically changed to &amp;lsquo;sag&amp;rsquo;. This is only a temporary fix for fitting the intercept with sparse data. For dense data, use sklearn.linear_model._preprocess_data before your regression.</source>
          <target state="translated">TrueでXがスパースの場合、メソッドは切片も返し、ソルバーは自動的に「サグ」に変更されます。これは、切片をスパースデータに合わせるための一時的な修正にすぎません。密なデータの場合、回帰の前にsklearn.linear_model._preprocess_dataを使用します。</target>
        </trans-unit>
        <trans-unit id="d1eef608e634bc22aa5f2e22e802ae927e355666" translate="yes" xml:space="preserve">
          <source>If True returns MSE value, if False returns RMSE value.</source>
          <target state="translated">True の場合は MSE 値を返し、False の場合は RMSE 値を返します。</target>
        </trans-unit>
        <trans-unit id="a68108e0ea5bf983075f127e077ee80517d6dfdd" translate="yes" xml:space="preserve">
          <source>If True the covariance matrices are computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="translated">Trueの場合、共分散行列が計算され、 &lt;code&gt;self.covariance_&lt;/code&gt; 属性に格納されます。</target>
        </trans-unit>
        <trans-unit id="5c5d5facc126a265032a533a4664c8926339ade0" translate="yes" xml:space="preserve">
          <source>If True the full path is stored in the &lt;code&gt;coef_path_&lt;/code&gt; attribute. If you compute the solution for a large problem or many targets, setting &lt;code&gt;fit_path&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; will lead to a speedup, especially with a small alpha.</source>
          <target state="translated">Trueの場合、フルパスは &lt;code&gt;coef_path_&lt;/code&gt; 属性に格納されます。大きな問題または多くのターゲットのソリューションを計算する場合、 &lt;code&gt;fit_path&lt;/code&gt; を &lt;code&gt;False&lt;/code&gt; に設定すると、特に小さなアルファでスピードアップにつながります。</target>
        </trans-unit>
        <trans-unit id="53e960778922c6ba257a9c66f18d0e260655f043" translate="yes" xml:space="preserve">
          <source>If True the function returns the pairwise distance matrix else it returns the componentwise L1 pairwise-distances. Not supported for sparse matrix inputs.</source>
          <target state="translated">True の場合,この関数はペアワイズ距離行列を返し,そうでない場合はコンポーネントワイズ L1 のペアワイズ距離を返します.疎な行列の入力ではサポートされません。</target>
        </trans-unit>
        <trans-unit id="2546c89362b151bbba35dab463b810d1f7c0a359" translate="yes" xml:space="preserve">
          <source>If True the order of the dataset is shuffled to avoid having images of the same person grouped.</source>
          <target state="translated">Trueの場合、同じ人物の画像がグループ化されないように、データセットの順序がシャッフルされます。</target>
        </trans-unit>
        <trans-unit id="618a67ac95fc4ccc3385ae319143bf344e1ffb63" translate="yes" xml:space="preserve">
          <source>If True then raise a warning if conversion is required.</source>
          <target state="translated">Trueの場合は、変換が必要な場合に警告を表示します。</target>
        </trans-unit>
        <trans-unit id="19362eed638b2dc6d204e12092075aedd87e6e93" translate="yes" xml:space="preserve">
          <source>If True then raise an exception if array is not symmetric.</source>
          <target state="translated">真の場合、配列が対称でない場合は例外を発生させます。</target>
        </trans-unit>
        <trans-unit id="baf82faf959595f525e5d5a94c6b8526ad942779" translate="yes" xml:space="preserve">
          <source>If True, X will be copied; else, it may be overwritten.</source>
          <target state="translated">True の場合は X がコピーされ、そうでない場合は上書きされる可能性があります。</target>
        </trans-unit>
        <trans-unit id="e25c58f63a5736150718d46a3a4c05d31a44c0e6" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="translated">Trueの場合、&lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;変換は、代入子の変換の出力にスタックされます。これにより、予測推定量は、代入にもかかわらず欠落を説明できます。フィット/トレーニング時にフィーチャに欠損値がない場合、変換/テスト時に欠損値があったとしても、そのフィーチャは欠損インジケーターに表示されません。</target>
        </trans-unit>
        <trans-unit id="df1778fbc0c3701b8b17966bdd64201d1f2550fe" translate="yes" xml:space="preserve">
          <source>If True, a &lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;MissingIndicator&lt;/code&gt;&lt;/a&gt; transform will stack onto the output of the imputer&amp;rsquo;s transform. This allows a predictive estimator to account for missingness despite imputation. If a feature has no missing values at fit/train time, the feature won&amp;rsquo;t appear on the missing indicator even if there are missing values at transform/test time.</source>
          <target state="translated">Trueの場合、&lt;a href=&quot;sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;MissingIndicator&lt;/code&gt; &lt;/a&gt;変換は、代入子の変換の出力にスタックされます。これにより、予測推定量は、代入にもかかわらず欠落を説明できます。フィット/トレーニング時にフィーチャに欠損値がない場合、変換/テスト時に欠損値があったとしても、そのフィーチャは欠損インジケーターに表示されません。</target>
        </trans-unit>
        <trans-unit id="aa91f074d713faca021e35ddd5331805b9848f9e" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, a copy may still be returned if X&amp;rsquo;s dtype is not a floating point type.</source>
          <target state="translated">Trueの場合、Xのコピーが作成されます。Falseの場合、Xのdtypeが浮動小数点型でない場合でもコピーが返される可能性があります。</target>
        </trans-unit>
        <trans-unit id="45f6e4d313f4bf3abc200106ce518a942e07ab23" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible.</source>
          <target state="translated">True の場合、X のコピーが作成されます。Falseの場合、可能な限りその場でインputationが行われます。</target>
        </trans-unit>
        <trans-unit id="054b374d036034be5d7258a6a975038eb8fec935" translate="yes" xml:space="preserve">
          <source>If True, a copy of X will be created. If False, imputation will be done in-place whenever possible. Note that, in the following cases, a new copy will always be made, even if &lt;code&gt;copy=False&lt;/code&gt;:</source>
          <target state="translated">Trueの場合、Xのコピーが作成されます。Falseの場合、代入は可能な限りインプレースで行われます。次の場合、 &lt;code&gt;copy=False&lt;/code&gt; であっても、常に新しいコピーが作成されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="f237ade75e04520befb53fc36267d58be41dc5ae" translate="yes" xml:space="preserve">
          <source>If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.</source>
          <target state="translated">Trueの場合、学習データの永続的なコピーがオブジェクトに格納されます。そうでない場合は、学習データへの参照のみが格納され、データが外部から変更された場合に予測値が変更される可能性があります。</target>
        </trans-unit>
        <trans-unit id="5b4ca3bdeb594ab34289df8cfc7fa70c9919ad95" translate="yes" xml:space="preserve">
          <source>If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.</source>
          <target state="translated">これは、整数カウントではなくバイナリイベントをモデル化する離散確率モデルに有用です。</target>
        </trans-unit>
        <trans-unit id="95f1a98443a6aa5501cfb81c289c266bb7baf4d6" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs).</source>
          <target state="translated">これは出力が0/1の値しか持たないという意味ではなく、tf-idfのtf項がバイナリであることを意味します。(0/1の出力を得るためにidfと正規化をFalseに設定します)。</target>
        </trans-unit>
        <trans-unit id="0beec2b2d6b910456e155063f83ec1e59c6c0df1" translate="yes" xml:space="preserve">
          <source>If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs.)</source>
          <target state="translated">これは出力が0/1の値しか持たないという意味ではなく、tf-idfのtf項がバイナリであることを意味します。(0/1の出力を得るためにidfと正規化をFalseに設定します)。</target>
        </trans-unit>
        <trans-unit id="b69242de00e60526a79082b37846a2a724d7b3dd" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling.</source>
          <target state="translated">True の場合、スケーリングの前にデータを中央に配置します。</target>
        </trans-unit>
        <trans-unit id="6c9a4d2da449884c97015be12ce056a53dc04757" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">True の場合、スケーリングの前にデータをセンタリングします。これは、疎な行列で試した場合には動作しません(例外が発生します)。なぜなら、中央揃えを行うと、一般的な使用例ではメモリに収まりきらないほど大きな行列を作成しなければならないからです。</target>
        </trans-unit>
        <trans-unit id="9d7135e468914be214009091b1fc11f6721afd0a" translate="yes" xml:space="preserve">
          <source>If True, center the data before scaling. This will cause &lt;code&gt;transform&lt;/code&gt; to raise an exception when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.</source>
          <target state="translated">Trueの場合、スケーリングの前にデータを中央揃えにします。これにより、スパースマトリックスでの試行時に &lt;code&gt;transform&lt;/code&gt; 例外が発生します。これは、スパースマトリックスを中央に配置すると、通常のユースケースではメモリに収まりきらないほど密集したマトリックスを構築する必要があるためです。</target>
        </trans-unit>
        <trans-unit id="694a00b6963c573c0a68b328feb15483853b44c0" translate="yes" xml:space="preserve">
          <source>If True, compute the log marginal likelihood at each iteration of the optimization.</source>
          <target state="translated">真の場合、最適化の各反復での対数限界尤度を計算します。</target>
        </trans-unit>
        <trans-unit id="c24f1c3d35266b322135ac3270540ea5ef40a09d" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model.</source>
          <target state="translated">真の場合、モデルの各ステップで目的関数を計算します。</target>
        </trans-unit>
        <trans-unit id="20839df17b3bca6b55533337f17b7c17f0881d1a" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False</source>
          <target state="translated">Trueの場合、モデルの各ステップで目的関数を計算します。デフォルトはFalseです。</target>
        </trans-unit>
        <trans-unit id="afb80999f635ad0619301e31bb4cd6b353188af0" translate="yes" xml:space="preserve">
          <source>If True, compute the objective function at each step of the model. Default is False.</source>
          <target state="translated">Trueの場合、モデルの各ステップで目的関数を計算します。デフォルトはFalseです。</target>
        </trans-unit>
        <trans-unit id="9df36ef1b24eb49a93a9d932c395b3324554689c" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Trueの場合、データは計算前に中央揃えされません。平均値が有意にゼロに等しいが、正確にはゼロではないデータを扱うのに便利です。Falseの場合、データは計算前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="cdd266c276f30f1ed8fec5e418bed1790d829f9f" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.</source>
          <target state="translated">Trueの場合、データは計算前に中央揃えされません。平均値がほぼゼロではなく、正確にはゼロではないデータを扱う場合に便利です。False(デフォルト)の場合、データは計算の前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="b4e1adfc1374b7a62eee31a2ac4be08eea958149" translate="yes" xml:space="preserve">
          <source>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</source>
          <target state="translated">Trueの場合、データは計算前に中央揃えされません。平均値がほぼゼロではなく、正確にはゼロではないデータを扱う場合に便利です。Falseの場合、データは計算の前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="4b7584f328528f9b2a426f648be6c8534ecc99c4" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data will be centered before computation.</source>
          <target state="translated">Trueの場合、計算の前にデータは中央揃えされません。平均値が有意にゼロに等しいが、正確にはゼロではないデータを扱うのに便利です。Falseの場合、データは計算前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="899541250010cf3e75fa34e54556cce0c0296945" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data will be centered before computation.</source>
          <target state="translated">Trueの場合、計算の前にデータは中央揃えされません。平均値がほぼゼロではなく、正確にはゼロではないデータを扱う場合に便利です。False(デフォルト)の場合、データは計算前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="d925d680717ba978e6037a9fa61e005a509ad73c" translate="yes" xml:space="preserve">
          <source>If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data will be centered before computation.</source>
          <target state="translated">Trueの場合、計算の前にデータは中央揃えされません。平均値がほぼゼロではなく、正確にはゼロではないデータを扱う場合に便利です。Falseの場合、データは計算前に中央揃えされます。</target>
        </trans-unit>
        <trans-unit id="a2902b07926590508dee697d1e97c541f35cd531" translate="yes" xml:space="preserve">
          <source>If True, ensure that the output of the random projection is a dense numpy array even if the input and random projection matrix are both sparse. In practice, if the number of components is small the number of zero components in the projected data will be very small and it will be more CPU and memory efficient to use a dense representation.</source>
          <target state="translated">Trueの場合、入力行列とランダム投影行列が共にスパースであっても、ランダム投影の出力が密なnumpy配列であることを保証します。実際には,成分の数が少ない場合,投影データ中のゼロ成分の数は非常に少なくなり,密な表現を用いた方が CPU やメモリの効率が良くなります.</target>
        </trans-unit>
        <trans-unit id="41679ec27e720c4445a3d18e34d01eeadf44de13" translate="yes" xml:space="preserve">
          <source>If True, explicitely compute the weighted within-class covariance matrix when solver is &amp;lsquo;svd&amp;rsquo;. The matrix is always computed and stored for the other solvers.</source>
          <target state="translated">Trueの場合、ソルバーが「svd」のときに、重み付きクラス内共分散行列を明示的に計算します。行列は常に計算され、他のソルバー用に保存されます。</target>
        </trans-unit>
        <trans-unit id="a5a6d396b2b3b1ae647f1eed557078cef4ea31ec" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class or the decision function, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="translated">Trueの場合、バイナリ &lt;code&gt;y_true&lt;/code&gt; の場合、スコア関数は1D &lt;code&gt;y_pred&lt;/code&gt; （つまり、正のクラスまたは決定関数の確率、形状 &lt;code&gt;(n_samples,)&lt;/code&gt; ）を受け入れることになっています。</target>
        </trans-unit>
        <trans-unit id="92550063b64465fcb2c6a46cd5346c9970dc1bb3" translate="yes" xml:space="preserve">
          <source>If True, for binary &lt;code&gt;y_true&lt;/code&gt;, the score function is supposed to accept a 1D &lt;code&gt;y_pred&lt;/code&gt; (i.e., probability of the positive class, shape &lt;code&gt;(n_samples,)&lt;/code&gt;).</source>
          <target state="translated">Trueの場合、バイナリ &lt;code&gt;y_true&lt;/code&gt; の場合、スコア関数は1D &lt;code&gt;y_pred&lt;/code&gt; （つまり、正のクラスの確率、形状 &lt;code&gt;(n_samples,)&lt;/code&gt; ）を受け入れることになっています。</target>
        </trans-unit>
        <trans-unit id="a3946c2202800dbed0f15da39a81b563f2054e41" translate="yes" xml:space="preserve">
          <source>If True, individual trees are fit on random subsets of the training data sampled with replacement. If False, sampling without replacement is performed.</source>
          <target state="translated">True の場合、個々の木は、置換を行ってサンプリングされた訓練データのランダムな部分集合にフィットします。Falseの場合、置換なしのサンプリングが実行されます。</target>
        </trans-unit>
        <trans-unit id="47a8f3ebe1bf3e97122b0404e375e9c09f1cef3f" translate="yes" xml:space="preserve">
          <source>If True, input X is copied and stored by the model in the &lt;code&gt;X_fit_&lt;/code&gt; attribute. If no further changes will be done to X, setting &lt;code&gt;copy_X=False&lt;/code&gt; saves memory by storing a reference.</source>
          <target state="translated">Trueの場合、入力Xがコピーされ、モデルによって &lt;code&gt;X_fit_&lt;/code&gt; 属性に格納されます。Xにそれ以上の変更が行われない場合、 &lt;code&gt;copy_X=False&lt;/code&gt; を設定すると、参照が保存されてメモリが節約されます。</target>
        </trans-unit>
        <trans-unit id="396eb3a1b9a656b43a14e28fce4ff1f92f4bae42" translate="yes" xml:space="preserve">
          <source>If True, normalizes each document&amp;rsquo;s feature vector to unit norm using &lt;a href=&quot;sklearn.preprocessing.normalize#sklearn.preprocessing.normalize&quot;&gt;&lt;code&gt;sklearn.preprocessing.normalize&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Trueの場合、&lt;a href=&quot;sklearn.preprocessing.normalize#sklearn.preprocessing.normalize&quot;&gt; &lt;code&gt;sklearn.preprocessing.normalize&lt;/code&gt; &lt;/a&gt;を使用して、各ドキュメントの特徴ベクトルを単位ノルムに正規化します。</target>
        </trans-unit>
        <trans-unit id="5f3a3bba5e0b6c545bdd5d5451a2769f0ab6a17d" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo; while the default behaviour would be to print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters.</source>
          <target state="translated">Trueの場合、推定器を印刷するときに、デフォルト以外の値に設定されたパラメーターのみが印刷されます。たとえば、 &lt;code&gt;print(SVC())&lt;/code&gt; while Trueは「SVC（）」のみを出力しますが、デフォルトの動作では、変更されていないすべてのパラメーターを使用して「SVC（C = 1.0、cache_size = 200、&amp;hellip;）」を出力します。</target>
        </trans-unit>
        <trans-unit id="1e2f5f725dbeca38c6f078963224eb5885ad4abb" translate="yes" xml:space="preserve">
          <source>If True, only the parameters that were set to non-default values will be printed when printing an estimator. For example, &lt;code&gt;print(SVC())&lt;/code&gt; while True will only print &amp;lsquo;SVC()&amp;rsquo;, but would print &amp;lsquo;SVC(C=1.0, cache_size=200, &amp;hellip;)&amp;rsquo; with all the non-changed parameters when False. Default is True.</source>
          <target state="translated">Trueの場合、推定器を印刷するときに、デフォルト以外の値に設定されたパラメーターのみが印刷されます。たとえば、 &lt;code&gt;print(SVC())&lt;/code&gt; while Trueは、「SVC（）」のみを出力しますが、Falseの場合、変更されていないすべてのパラメーターを使用して「SVC（C = 1.0、cache_size = 200、&amp;hellip;）」を出力します。デフォルトはTrueです。</target>
        </trans-unit>
        <trans-unit id="10ab7d9c4ef9751f0861c3cfbcd363da08ee1196" translate="yes" xml:space="preserve">
          <source>If True, return a sparse CSR continency matrix. If &lt;code&gt;eps is not None&lt;/code&gt;, and &lt;code&gt;sparse is True&lt;/code&gt;, will throw ValueError.</source>
          <target state="translated">Trueの場合、まばらなCSR大陸性行列を返します。場合は &lt;code&gt;eps is not None&lt;/code&gt; 、と &lt;code&gt;sparse is True&lt;/code&gt; 、とValueErrorを送出します。</target>
        </trans-unit>
        <trans-unit id="bbadcb21277fb2fd7500e5e018984adc0515f847" translate="yes" xml:space="preserve">
          <source>If True, return output as dict</source>
          <target state="translated">True の場合、出力を dict として返します。</target>
        </trans-unit>
        <trans-unit id="5d0bfe964a0a56bae92b114342901e57452f609f" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds.</source>
          <target state="translated">True の場合、各テスト・セットのサンプル数で重み付けされたヒダ全体の平均スコアを返します。この場合、データはひだ全体で同じように分布していると仮定され、最小化される損失は、サンプルごとの損失の合計であり、ひだ全体の平均損失ではありません。</target>
        </trans-unit>
        <trans-unit id="4c0f661b8fac7f22363a5a1e55327c6967bb56d8" translate="yes" xml:space="preserve">
          <source>If True, return the average score across folds, weighted by the number of samples in each test set. In this case, the data is assumed to be identically distributed across the folds, and the loss minimized is the total loss per sample, and not the mean loss across the folds. If False, return the average score across folds. Default is True, but will change to False in version 0.21, to correspond to the standard definition of cross-validation.</source>
          <target state="translated">True の場合、各テスト・セットのサンプル数で重み付けされたヒダ全体の平均スコアを返します。この場合、データはひだ全体で同じように分布していると仮定され、最小化される損失はサンプルごとの総損失であり、ひだ全体の平均損失ではありません。Falseの場合、ひだ全体の平均スコアを返します。デフォルトはTrueですが、バージョン0.21ではFalseに変更され、クロスバリデーションの標準的な定義に対応します。</target>
        </trans-unit>
        <trans-unit id="cd7031ac688b02e25258c5831c7d3ea164486db6" translate="yes" xml:space="preserve">
          <source>If True, return the distance between the clusters.</source>
          <target state="translated">真の場合、クラスタ間の距離を返します。</target>
        </trans-unit>
        <trans-unit id="a6e36ec8e19c4760ce9d4d884ef8627513b82b97" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a &lt;code&gt;Bunch&lt;/code&gt; object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="translated">Trueの場合、 &lt;code&gt;Bunch&lt;/code&gt; オブジェクトの代わりに &lt;code&gt;(data, target)&lt;/code&gt; 返します。 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; オブジェクトの詳細については、以下を参照してください。</target>
        </trans-unit>
        <trans-unit id="48eeb388f7c432fd1b00c136703cc691939b77aa" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; object.</source>
          <target state="translated">Trueの場合、Bunchオブジェクトの代わりに &lt;code&gt;(data, target)&lt;/code&gt; 返します。 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; オブジェクトの詳細については、以下を参照してください。</target>
        </trans-unit>
        <trans-unit id="b8ef976b3bf0a8c5fe0d328bf69ca77595314915" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data, target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;target&lt;/code&gt; objects.</source>
          <target state="translated">Trueの場合、Bunchオブジェクトの代わりに &lt;code&gt;(data, target)&lt;/code&gt; 返します。 &lt;code&gt;data&lt;/code&gt; と &lt;code&gt;target&lt;/code&gt; オブジェクトの詳細については、以下を参照してください。</target>
        </trans-unit>
        <trans-unit id="d467c22a2bd71ab649cbad26364f06a31ce58ac1" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(data.data, data.target)&lt;/code&gt; instead of a Bunch object.</source>
          <target state="translated">Trueの場合、Bunchオブジェクトの代わりに &lt;code&gt;(data.data, data.target)&lt;/code&gt; 返します。</target>
        </trans-unit>
        <trans-unit id="248b6d0d481e47f352d5f3203242e6800072c658" translate="yes" xml:space="preserve">
          <source>If True, returns &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; instead of a Bunch object. See below for more information about the &lt;code&gt;dataset.data&lt;/code&gt; and &lt;code&gt;dataset.target&lt;/code&gt; object.</source>
          <target state="translated">Trueの場合、Bunchオブジェクトの代わりに &lt;code&gt;(dataset.data, dataset.target)&lt;/code&gt; 返します。 &lt;code&gt;dataset.data&lt;/code&gt; および &lt;code&gt;dataset.target&lt;/code&gt; オブジェクトの詳細については、以下を参照してください。</target>
        </trans-unit>
        <trans-unit id="c220af25fde2fda1e9985d78b63166a331905d63" translate="yes" xml:space="preserve">
          <source>If True, scale the data to interquartile range.</source>
          <target state="translated">Trueの場合は、データを四分位間の範囲にスケールします。</target>
        </trans-unit>
        <trans-unit id="0f395f8257fe0bdfb8a823c88f3be9843583f8a6" translate="yes" xml:space="preserve">
          <source>If True, scale the data to unit variance (or equivalently, unit standard deviation).</source>
          <target state="translated">真の場合、データを単位分散(または同等に、単位標準偏差)にスケールします。</target>
        </trans-unit>
        <trans-unit id="df95a4486aac1e164d23cfb2a72a9a3a02411ccb" translate="yes" xml:space="preserve">
          <source>If True, the class covariance matrices are explicitely computed and stored in the &lt;code&gt;self.covariance_&lt;/code&gt; attribute.</source>
          <target state="translated">Trueの場合、クラス共分散行列は明示的に計算され、 &lt;code&gt;self.covariance_&lt;/code&gt; 属性に格納されます。</target>
        </trans-unit>
        <trans-unit id="a491ca8d8797fa01293c195b8787d725c30e073a" translate="yes" xml:space="preserve">
          <source>If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope.</source>
          <target state="translated">真の場合、クラスタは超立方体の頂点に置かれます。Falseの場合、クラスタはランダムな多面体の頂点に置かれます。</target>
        </trans-unit>
        <trans-unit id="dc426ca785aa82bc3726faf833e38673875ff1ab" translate="yes" xml:space="preserve">
          <source>If True, the coefficients of the underlying linear model are returned.</source>
          <target state="translated">Trueの場合、基礎となる線形モデルの係数が返されます。</target>
        </trans-unit>
        <trans-unit id="5724be8fac97575b0a1ba6783afc1c2fbe0fcac8" translate="yes" xml:space="preserve">
          <source>If True, the covariance of the joint predictive distribution at the query points is returned along with the mean</source>
          <target state="translated">Trueの場合,問い合わせ点における共同予測分布の共分散が,平均</target>
        </trans-unit>
        <trans-unit id="dbcfae5acdcda56eec77c1115971fac37cdadcbc" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="translated">Trueの場合、データは適切なdtype（数値）の列を含むパンダのDataFrameです。ターゲットは、ターゲット列の数に応じて、パンダのDataFrameまたはSeriesです。場合 &lt;code&gt;return_X_y&lt;/code&gt; がTrueの場合、（ &lt;code&gt;data&lt;/code&gt; 、 &lt;code&gt;target&lt;/code&gt; 後述のように）パンダのデータフレームまたはシリーズになります。</target>
        </trans-unit>
        <trans-unit id="7e36608088c739a911a649d964516a72573ccb05" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target columns. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then (&lt;code&gt;data&lt;/code&gt;, &lt;code&gt;target&lt;/code&gt;) will be pandas DataFrames or Series as described below.</source>
          <target state="translated">Trueの場合、データは適切なdtype（数値、文字列、またはカテゴリ）を持つ列を含むパンダのDataFrameです。ターゲットは、ターゲット列の数に応じて、パンダのDataFrameまたはSeriesです。場合 &lt;code&gt;return_X_y&lt;/code&gt; がTrueの場合、（ &lt;code&gt;data&lt;/code&gt; 、 &lt;code&gt;target&lt;/code&gt; 後述のように）パンダのデータフレームまたはシリーズになります。</target>
        </trans-unit>
        <trans-unit id="b39e4230ac891358bd0af7c3eedd9e07bde06b43" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns.</source>
          <target state="translated">True の場合、データは、適切な dtypes(数値、文字列、またはカテゴリ)を持つ列を含む pandas DataFrame です。ターゲットは、target_columnsの数に応じて、pandas DataFrameまたはSeriesです。</target>
        </trans-unit>
        <trans-unit id="132ae12ba4f9038c17051f7e128fd887c18e17fe" translate="yes" xml:space="preserve">
          <source>If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric, string or categorical). The target is a pandas DataFrame or Series depending on the number of target_columns. The Bunch will contain a &lt;code&gt;frame&lt;/code&gt; attribute with the target and the data. If &lt;code&gt;return_X_y&lt;/code&gt; is True, then &lt;code&gt;(data, target)&lt;/code&gt; will be pandas DataFrames or Series as describe above.</source>
          <target state="translated">Trueの場合、データは適切なdtype（数値、文字列、またはカテゴリ）を持つ列を含むパンダのDataFrameです。ターゲットは、target_columnsの数に応じて、pandasDataFrameまたはSeriesです。バンチには、ターゲットとデータを含む &lt;code&gt;frame&lt;/code&gt; 属性が含まれます。場合 &lt;code&gt;return_X_y&lt;/code&gt; がTrueの場合、 &lt;code&gt;(data, target)&lt;/code&gt; 上記のようにパンダのデータフレームまたはシリーズになります。</target>
        </trans-unit>
        <trans-unit id="ab63854b4cbc92de5ee21a5ee4815065271902d4" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.</source>
          <target state="translated">True の場合、距離とインデックスはソートされてから返されます。Falseの場合、結果はソートされません。return_distance ==Falseの場合、sort_results=Trueとするとエラーになります。</target>
        </trans-unit>
        <trans-unit id="91db79e9bb9248c604fdbf115bede6d2bc2e0f43" translate="yes" xml:space="preserve">
          <source>If True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. Only used with mode=&amp;rsquo;distance&amp;rsquo;.</source>
          <target state="translated">Trueの場合、距離とインデックスは返される前に並べ替えられます。Falseの場合、結果はソートされません。mode = 'distance'でのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="d28765388f526f443e8440713d9f120592d23759" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None.</source>
          <target state="translated">真の場合、θの位置におけるカーネル・ハイパーパラメータに対する対数最尤度の勾配が追加で返されます。真の場合、θはNoneであってはなりません。</target>
        </trans-unit>
        <trans-unit id="2ecaf6f4ca3e741011335b25b38b91313c972ea3" translate="yes" xml:space="preserve">
          <source>If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If True, theta must not be None.</source>
          <target state="translated">真の場合、位置θでのカーネル・ハイパーパラメータに対する対数最尤度の勾配が追加で返されます。勾配の計算は、非二値分類ではサポートされていないことに注意してください。真の場合、θはNoneであってはなりません。</target>
        </trans-unit>
        <trans-unit id="65ddb79c8d6a76beebeeb976d10455d7eb1fb46d" translate="yes" xml:space="preserve">
          <source>If True, the imputer mask will be a sparse matrix.</source>
          <target state="translated">Trueの場合、インピュータマスクはスパース行列になります。</target>
        </trans-unit>
        <trans-unit id="eb2cac4cae6a6c8ef92320b8c850d0341c9b187b" translate="yes" xml:space="preserve">
          <source>If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement.</source>
          <target state="translated">True の場合、カーネル属性がコピーされます。False の場合、カーネル属性は変更されますが、パフォーマンスが向上する可能性があります。</target>
        </trans-unit>
        <trans-unit id="a134a28236267fd097c12ab6f4f7b85d957aa9ca" translate="yes" xml:space="preserve">
          <source>If True, the method also returns &lt;code&gt;n_iter&lt;/code&gt;, the actual number of iteration performed by the solver.</source>
          <target state="translated">Trueの場合、メソッドは、ソルバーによって実行された実際の反復回数である &lt;code&gt;n_iter&lt;/code&gt; も返します。</target>
        </trans-unit>
        <trans-unit id="af50e40087f45610f2fbcc323b88ccd93dcf9324" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learned more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Trueの場合、リグレッサXは回帰前に正規化されます。このパラメーターは、 &lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合は無視されます。リグレッサが正規化されている場合、これによりハイパーパラメータがより堅牢になり、サンプル数にほとんど依存しないことに注意してください。同じプロパティは、標準化されたデータには無効です。あなたが標準化したい場合は、ご使用ください &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; を呼び出す前に、 &lt;code&gt;fit&lt;/code&gt; 持つ推定量に &lt;code&gt;normalize=False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="016e8fefc2c3108a2b7a4351de86dada7ecbd68e" translate="yes" xml:space="preserve">
          <source>If True, the regressors X will be normalized before regression. This parameter is ignored when &lt;code&gt;fit_intercept&lt;/code&gt; is set to False. When the regressors are normalized, note that this makes the hyperparameters learnt more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; before calling &lt;code&gt;fit&lt;/code&gt; on an estimator with &lt;code&gt;normalize=False&lt;/code&gt;.</source>
          <target state="translated">Trueの場合、リグレッサXは回帰前に正規化されます。このパラメーターは、 &lt;code&gt;fit_intercept&lt;/code&gt; がFalseに設定されている場合は無視されます。リグレッサが正規化されている場合、これによりハイパーパラメータがより堅牢になり、サンプル数にほとんど依存しないことに注意してください。同じプロパティは、標準化されたデータには無効です。あなたが標準化したい場合は、ご使用ください &lt;code&gt;preprocessing.StandardScaler&lt;/code&gt; を呼び出す前に、 &lt;code&gt;fit&lt;/code&gt; 持つ推定量に &lt;code&gt;normalize=False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c3fdb7e36f654834d666d698b8cb7219451a4481" translate="yes" xml:space="preserve">
          <source>If True, the return value will be an array of integers, rather than a boolean mask.</source>
          <target state="translated">True の場合、戻り値はブール値のマスクではなく、整数の配列になります。</target>
        </trans-unit>
        <trans-unit id="d17d4bbcdf2df4ef33c01a7114516c2e4e90d7d8" translate="yes" xml:space="preserve">
          <source>If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean.</source>
          <target state="translated">Trueの場合,問い合わせ点における予測分布の標準偏差が平均とともに返されます.</target>
        </trans-unit>
        <trans-unit id="3f294130716f356d91654999eee9757bd2ba6c1c" translate="yes" xml:space="preserve">
          <source>If True, the support of robust location and covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Trueの場合、ロバストな位置推定値と共分散推定値のサポートが計算され、データをセンタリングせずに共分散推定値が再計算されます。平均が有意にゼロに等しいが、正確にはゼロではないデータを扱うのに便利です。Falseの場合,ロバストな位置と共分散は,追加の処理をせずにFastMCDアルゴリズムを用いて直接計算されます.</target>
        </trans-unit>
        <trans-unit id="667a36b1a1b94aa0d760aa610f277fcd1918ae0a" translate="yes" xml:space="preserve">
          <source>If True, the support of the robust location and the covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.</source>
          <target state="translated">Trueの場合、ロバスト位置と共分散推定値のサポートが計算され、データをセンタリングせずに、そこから共分散推定値が再計算されます。平均が有意にゼロに等しいが、正確にはゼロではないデータを扱うのに便利です。Falseの場合,ロバストな位置と共分散は,追加の処理をせずにFastMCDアルゴリズムを用いて直接計算されます.</target>
        </trans-unit>
        <trans-unit id="77487b230b7ba030d96d8037319b1c202fdf89dc" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each step will be printed as it is completed.</source>
          <target state="translated">True の場合、各ステップのフィッティング中に経過した時間が、フィッティングが完了した時点で印刷されます。</target>
        </trans-unit>
        <trans-unit id="9c5c205f98c6f7e0686c6b1dad61d3840345a50a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting each transformer will be printed as it is completed.</source>
          <target state="translated">True の場合は、各変圧器の取り付け中の経過時間が完了した時点で表示されます。</target>
        </trans-unit>
        <trans-unit id="af3eeb64eec0b2d56ce55e625f484e757480a63a" translate="yes" xml:space="preserve">
          <source>If True, the time elapsed while fitting will be printed as it is completed.</source>
          <target state="translated">True の場合、フィッティング中の経過時間は、フィッティングが完了した時点で印刷されます。</target>
        </trans-unit>
        <trans-unit id="28346b69fb6f1a64d688b2ef42aabb524b6563d8" translate="yes" xml:space="preserve">
          <source>If True, then X will be converted to a 2-dimensional NumPy array or sparse matrix. If the conversion is not possible an exception is raised.</source>
          <target state="translated">Trueの場合,Xは2次元のNumPy配列または疎な行列に変換されます.変換できない場合は例外が発生します。</target>
        </trans-unit>
        <trans-unit id="5c0fef9c1e6748fc4d3cb84e62459147a039a4fd" translate="yes" xml:space="preserve">
          <source>If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be &amp;lt; n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless.</source>
          <target state="translated">Trueの場合、固有値がゼロのすべてのコンポーネントが削除されるため、出力のコンポーネントの数は&amp;lt;n_components（数値の不安定性のためにゼロになる場合もあります）になる場合があります。n_componentsがNoneの場合、このパラメーターは無視され、固有値がゼロのコンポーネントは関係なく削除されます。</target>
        </trans-unit>
        <trans-unit id="42874c4e7adb064c98a0fb44835161462f985220" translate="yes" xml:space="preserve">
          <source>If True, then compute normalized Laplacian.</source>
          <target state="translated">真であれば、正規化されたラプラシアンを計算します。</target>
        </trans-unit>
        <trans-unit id="ba532aca0424d37b34ea4248f58728a030b07d2d" translate="yes" xml:space="preserve">
          <source>If True, then return the centers of each cluster</source>
          <target state="translated">真であれば、各クラスタの中心を返します。</target>
        </trans-unit>
        <trans-unit id="7818bd11ce52f2496690f2a19701e1fdc3bace9d" translate="yes" xml:space="preserve">
          <source>If True, transpose the downloaded data array.</source>
          <target state="translated">True の場合、ダウンロードしたデータ配列を転置します。</target>
        </trans-unit>
        <trans-unit id="9b28aadc7e361758f4f56436eeab711f856e9105" translate="yes" xml:space="preserve">
          <source>If True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.</source>
          <target state="translated">True の場合、幅優先検索を使用します。False(デフォルト)の場合は、深さ優先検索を使用します。一般的に、コンパクトなカーネルや高許容差の場合は、ブレッドファースト検索の方が高速です。</target>
        </trans-unit>
        <trans-unit id="06e972e2019f64a904722b2934f5b7cf1e54e236" translate="yes" xml:space="preserve">
          <source>If True, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="translated">真の場合は、二重木アルゴリズムを使用します。そうでなければ、シングルツリー・アルゴリズムを使用します。デュアルツリーアルゴリズムは、大きなNに対してより良いスケーリングが可能です。</target>
        </trans-unit>
        <trans-unit id="09f8cdcb36703e0413a45867eb062d48bc42e4a4" translate="yes" xml:space="preserve">
          <source>If True, validation for finiteness will be skipped, saving time, but leading to potential crashes. If False, validation for finiteness will be performed, avoiding error. Global default: False.</source>
          <target state="translated">True の場合、有限性の検証はスキップされ、時間は節約されますが、クラッシュの可能性があります。False の場合、有限性の検証が実行され、エラーを回避します。グローバルなデフォルト。False。</target>
        </trans-unit>
        <trans-unit id="f770d204acb3934762188e63b6bd0977cfe619aa" translate="yes" xml:space="preserve">
          <source>If True, will return the parameters for this estimator and contained subobjects that are estimators.</source>
          <target state="translated">Trueの場合、この推定子のパラメータと、その推定子である含まれているサブオブジェクトを返します。</target>
        </trans-unit>
        <trans-unit id="edc518974aa9f8ea115d0f36469bc2b1e2cd15a2" translate="yes" xml:space="preserve">
          <source>If True, will return the query_id array for each file.</source>
          <target state="translated">True の場合、各ファイルの query_id 配列を返します。</target>
        </trans-unit>
        <trans-unit id="80fdba1026cc980884a84dfa72ad1747c034afc6" translate="yes" xml:space="preserve">
          <source>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</source>
          <target state="translated">X と y が np.float64 の C 次数で連続した配列ではなく,X が scipy.sparse.csr_matrix でない場合,X と y はコピーされます.</target>
        </trans-unit>
        <trans-unit id="a601440183ce5a872479c357e441563196aab652" translate="yes" xml:space="preserve">
          <source>If X is a dense array, then the other methods will not support sparse matrices as input.</source>
          <target state="translated">X が密な配列である場合,他のメソッドは入力として疎な行列をサポートしません.</target>
        </trans-unit>
        <trans-unit id="efab9063b47a2afb85758f067069188b21b34f3e" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix.</source>
          <target state="translated">XがCSR行列として符号化されている場合。</target>
        </trans-unit>
        <trans-unit id="f4e2537cdb42d2bfe76e858b065192a8758650ef" translate="yes" xml:space="preserve">
          <source>If X is encoded as a CSR matrix;</source>
          <target state="translated">XがCSR行列として符号化されている場合。</target>
        </trans-unit>
        <trans-unit id="da96e9fabf18fc39905756390120e4a7a1e09f97" translate="yes" xml:space="preserve">
          <source>If X is not a C-ordered contiguous array it is copied.</source>
          <target state="translated">X が C 次の連続配列でない場合はコピーされます.</target>
        </trans-unit>
        <trans-unit id="9cc8f34afbd30e04cc65d91f1b233abc1c382996" translate="yes" xml:space="preserve">
          <source>If X is not an array of floating values;</source>
          <target state="translated">Xが浮動小数点数の配列でない場合。</target>
        </trans-unit>
        <trans-unit id="e7ca7ce1d419c3d60265041304210343f2e8b91d" translate="yes" xml:space="preserve">
          <source>If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that &lt;em&gt;X = L C&lt;/em&gt;. Different criteria exist to choose the components</source>
          <target state="translated">Xが多変量データである場合、解決しようとしている問題は、別の観測に基づいてデータを書き換えることです。つまり、負荷Lと、&lt;em&gt;X = LCである&lt;/em&gt;ようなコンポーネントのセットCを学習したいとします。コンポーネントを選択するためのさまざまな基準があります</target>
        </trans-unit>
        <trans-unit id="4691b6eeb6f44a63af5f24ac30dc066ab023aa61" translate="yes" xml:space="preserve">
          <source>If X is sparse and &lt;code&gt;missing_values=0&lt;/code&gt;;</source>
          <target state="translated">Xがスパースで、 &lt;code&gt;missing_values=0&lt;/code&gt; の場合 ;</target>
        </trans-unit>
        <trans-unit id="5bf131136f9283115170d3f032466f07678834a5" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise distance between the arrays from both X and Y.</source>
          <target state="translated">Y が与えられた場合(デフォルトは None),返される行列は,X と Y の両方からの配列間のペアワイズ距離です.</target>
        </trans-unit>
        <trans-unit id="a6e7fe3e345be28d5e67984fa49ad01aeaa444dd" translate="yes" xml:space="preserve">
          <source>If Y is given (default is None), then the returned matrix is the pairwise kernel between the arrays from both X and Y.</source>
          <target state="translated">Y が与えられた場合(デフォルトは None),返される行列は,X と Y の両方の配列間のペアワイズカーネルとなります.</target>
        </trans-unit>
        <trans-unit id="15e0fd61e3b85d8ebad2fc2135f6d5822723ce41" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}\) is the estimated target output, \(y\) the corresponding (correct) target output, and \(Var\) is &lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;Variance&lt;/a&gt;, the square of the standard deviation, then the explained variance is estimated as follow:</source>
          <target state="translated">\（\ hat {y} \）が推定ターゲット出力であり、\（y \）が対応する（正しい）ターゲット出力であり、\（Var \）が&lt;a href=&quot;https://en.wikipedia.org/wiki/Variance&quot;&gt;Variance&lt;/a&gt;（標準偏差の2乗）である場合、説明される分散は次のように推定されます：</target>
        </trans-unit>
        <trans-unit id="1d8ad99bdd9bde4f8f4c5eb30616979db9d7983c" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value for total \(n\) samples, the estimated R&amp;sup2; is defined as:</source>
          <target state="translated">\（\ hat {y} _i \）が\（i \）番目のサンプルの予測値であり、\（y_i \）が合計\（n \）サンプルの対応する真の値である場合、推定R&amp;sup2;が定義されます。なので：</target>
        </trans-unit>
        <trans-unit id="c8fb389b8a60a2b57fc22c9161412c484a73dd18" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the 0-1 loss \(L_{0-1}\) is defined as:</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるならば、0-1の損失は、0-1の損失と定義される。</target>
        </trans-unit>
        <trans-unit id="01fda7f04ce93ad5d6b5843c80c53ee91e04866d" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるとすると、正しい予測値の割合は、次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="af46aeec0a0c654990b43c84ec26ca8a3817bbd3" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the median absolute error (MedAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるならば、\(y_i\)th サンプル上で推定された中央絶対誤差(MedAE)は、次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="27ab05c62dcfc0b1ca98228a2c106c2bd25d72f6" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the score R&amp;sup2; estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">\（\ hat {y} _i \）が\（i \）番目のサンプルの予測値であり、\（y_i \）が対応する真の値である場合、\（n _ {\ text {サンプル}} \）は次のように定義されます</target>
        </trans-unit>
        <trans-unit id="2057e5fd21ea6e3999b964ff2858a1023496793a" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the max error is defined as</source>
          <target state="translated">If \(i\)th サンプルの予測値であり、対応する真の値であるならば、最大誤差は次のように定義される。</target>
        </trans-unit>
        <trans-unit id="0b2139578cc75e1715d428f9c389fc66abbdc391" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean Tweedie deviance error (D) for power \(p\), estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">If \(\(i\)th サンプルの予測値と、対応する真の値であれば、power \(p\)の平均Tweedie deviance error (D)は、次のように定義される。</target>
        </trans-unit>
        <trans-unit id="e9be139031431f33624d9549cf24272bbec27cad" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean absolute error (MAE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるとすると、平均絶対誤差(MAE)は、次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="b7836e2114e345225a74c22cbe0d3b5d52c8f253" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared error (MSE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるとすると、平均二乗誤差(MSE)は、次のように定義される。</target>
        </trans-unit>
        <trans-unit id="1cf47fc0a0aaaffd1c0a818b8704218b8ae722c1" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over \(n_{\text{samples}}\) is defined as</source>
          <target state="translated">\(i\)th サンプルの予測値であり、対応する真の値であるとすると、平均二乗対数誤差(MSLE)は、次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="f295fa8851d145ac326bc63b92809e2fbf3d1f72" translate="yes" xml:space="preserve">
          <source>If \(\hat{y}_j\) is the predicted value for the \(j\)-th label of a given sample, \(y_j\) is the corresponding true value, and \(n_\text{labels}\) is the number of classes or labels, then the Hamming loss \(L_{Hamming}\) between two samples is defined as:</source>
          <target state="translated">\(\(j)番目のラベルの予測値、\(y_\_j)が対応する真の値、\(n_\text{labels})がクラス数である場合、2つのサンプル間のハミング損失は、次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="7fa4bf510f83c73a55e8dec038abaacf960351ca" translate="yes" xml:space="preserve">
          <source>If \(c_0 = 0\) the kernel is said to be homogeneous.</source>
          <target state="translated">If \(c_0=0)は、カーネルが均質であることを示している。</target>
        </trans-unit>
        <trans-unit id="c7d07701826b4f4c8efa455b46a49990993930f2" translate="yes" xml:space="preserve">
          <source>If \(h_i\) is given, the above equation automatically implies the following probabilistic interpretation:</source>
          <target state="translated">\(h_i)が与えられると、上の式は自動的に次のような確率的解釈をする。</target>
        </trans-unit>
        <trans-unit id="9d9af8bc9b90a6fbf0d539b126efbd694bdaddf6" translate="yes" xml:space="preserve">
          <source>If \(y_i\) is the true value of the \(i\)-th sample, and \(w_i\) is the corresponding sample weight, then we adjust the sample weight to:</source>
          <target state="translated">\(y_i\)th サンプルの真の値と、対応するサンプルの重さを 合わせて、重さを調整します。</target>
        </trans-unit>
        <trans-unit id="4c76ddad0ef7a743f202685a0861880cbc2062e2" translate="yes" xml:space="preserve">
          <source>If \(y_w\) is the predicted decision for true label and \(y_t\) is the maximum of the predicted decisions for all other labels, where predicted decisions are output by decision function, then multiclass hinge loss is defined by:</source>
          <target state="translated">\(y_w\)が真のラベルの予測決定であり、\(y_t\)が他のラベルの予測決定の最大値である場合、予測決定が決定関数で出力されるので、マルチクラスヒンジ損失は次のように定義される。</target>
        </trans-unit>
        <trans-unit id="b8371056060d53aef38082b274a12c6e92dd981b" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">CSR,CSC,COO,BSR の疎な行列が供給され、 accept_sparse によって受け入れられた場合、 accept_large_sparse は、そのインデックスが 32 ビットの dtype で格納されている場合にのみ、その行列を受け入れます。</target>
        </trans-unit>
        <trans-unit id="ca2f554a4272574081b19f205bd8db66223aa9f8" translate="yes" xml:space="preserve">
          <source>If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by accept_sparse, accept_large_sparse=False will cause it to be accepted only if its indices are stored with a 32-bit dtype.</source>
          <target state="translated">CSR,CSC,COO,BSR の疎な行列が与えられて accept_sparse で受け入れられる場合、 accept_large_sparse=False を指定すると、そのインデックスが 32 ビットの dtype で格納されている場合にのみ受け入れられるようになります。</target>
        </trans-unit>
        <trans-unit id="b0090a224443cfea422c2167734e98ec705e71a5" translate="yes" xml:space="preserve">
          <source>If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.</source>
          <target state="translated">callableが渡されると,未処理の生の入力から特徴のシーケンスを抽出するために利用されます.</target>
        </trans-unit>
        <trans-unit id="dcd8eacb988e0fa27afa1a7692943530b07747f6" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, k and and a random state and return an initialization.</source>
          <target state="translated">callable が渡された場合、引数 X,k とランダムな状態を取り、初期化を返します。</target>
        </trans-unit>
        <trans-unit id="cf28b181c12fdc4001f26b46f656bc18426882b0" translate="yes" xml:space="preserve">
          <source>If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.</source>
          <target state="translated">callableが渡された場合、引数X、n_clusters、ランダムな状態を取り、初期化を返します。</target>
        </trans-unit>
        <trans-unit id="15b5ddf5d35e7b6d7436896e31247316b726ba30" translate="yes" xml:space="preserve">
          <source>If a float, that value is added to all values in the contingency matrix. This helps to stop NaN propagation. If &lt;code&gt;None&lt;/code&gt;, nothing is adjusted.</source>
          <target state="translated">浮動小数点数の場合、その値は偶発行列のすべての値に追加されます。これは、NaNの伝播を停止するのに役立ちます。 &lt;code&gt;None&lt;/code&gt; の場合、何も調整されません。</target>
        </trans-unit>
        <trans-unit id="aec58020de2b924f9656034ee47c95a7ace302db" translate="yes" xml:space="preserve">
          <source>If a list is passed it&amp;rsquo;s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the &lt;code&gt;fit_path&lt;/code&gt; parameter is &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">リストが渡される場合、リストはn_targetsなどの配列の1つであることが期待されます。パスに沿った係数の変動値。 &lt;code&gt;fit_path&lt;/code&gt; パラメータが &lt;code&gt;False&lt;/code&gt; の場合は存在しません。</target>
        </trans-unit>
        <trans-unit id="8e3b6cd9422926a607fefd39c3e9bd3020c06d14" translate="yes" xml:space="preserve">
          <source>If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if &lt;code&gt;analyzer == 'word'&lt;/code&gt;.</source>
          <target state="translated">リストの場合、そのリストにはストップワードが含まれていると見なされ、そのすべてが結果のトークンから削除されます。 &lt;code&gt;analyzer == 'word'&lt;/code&gt; 場合にのみ適用されます。</target>
        </trans-unit>
        <trans-unit id="3a891d1ec4d966c2171dc7ddf73d952ce675676b" translate="yes" xml:space="preserve">
          <source>If a single axis is passed in, it is treated as a bounding axes</source>
          <target state="translated">1つの軸が渡された場合、それはバウンディング軸として扱われます。</target>
        </trans-unit>
        <trans-unit id="58d1b02436a7aa9160e580f582400827e1ad046d" translate="yes" xml:space="preserve">
          <source>If a string, it is passed to _check_stop_list and the appropriate stop list is returned. &amp;lsquo;english&amp;rsquo; is currently the only supported string value. There are several known issues with &amp;lsquo;english&amp;rsquo; and you should consider an alternative (see &lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;Using stop words&lt;/a&gt;).</source>
          <target state="translated">文字列の場合、_check_stop_listに渡され、適切なストップリストが返されます。「english」は現在サポートされている唯一の文字列値です。「英語」にはいくつかの既知の問題があり、別の方法を検討する必要があります（&lt;a href=&quot;../feature_extraction#stop-words&quot;&gt;ストップワードの使用を&lt;/a&gt;参照）。</target>
        </trans-unit>
        <trans-unit id="564b43bc82acf22a1de3b85bb28ac591ff97b4bf" translate="yes" xml:space="preserve">
          <source>If a string, this may be one of &amp;lsquo;nearest_neighbors&amp;rsquo;, &amp;lsquo;precomputed&amp;rsquo;, &amp;lsquo;rbf&amp;rsquo; or one of the kernels supported by &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt;.</source>
          <target state="translated">文字列の場合、これは「nearest_neighbors」、「precomputed」、「rbf」のいずれか、または &lt;code&gt;sklearn.metrics.pairwise_kernels&lt;/code&gt; でサポートされているカーネルのいずれかです。</target>
        </trans-unit>
        <trans-unit id="675cbfc234c52633edd36cba3388cd72c1b8e2d3" translate="yes" xml:space="preserve">
          <source>If a target is a classification outcome taking on values 0,1,&amp;hellip;,K-1, for node \(m\), representing a region \(R_m\) with \(N_m\) observations, let</source>
          <target state="translated">ターゲットが、ノード\（m \）の値0、1、&amp;hellip;、K-1をとる分類結果であり、\（N_m \）の観測を持つ領域\（R_m \）を表す場合、</target>
        </trans-unit>
        <trans-unit id="b39b95bbd18e310b00daaab2152e27da5d834f6a" translate="yes" xml:space="preserve">
          <source>If add_indicator=True.</source>
          <target state="translated">add_indicator=True の場合。</target>
        </trans-unit>
        <trans-unit id="373500a68bbbd934744d157d24ba37240f790a20" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : array-like, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="translated">アフィニティが「事前計算された」Xの場合：配列のような形状（n_samples、n_samples）、Xをサンプルから計算された事前計算された隣接グラフとして解釈します。</target>
        </trans-unit>
        <trans-unit id="86d4d97c781f9d1a441e0d9197ea013d3820b489" translate="yes" xml:space="preserve">
          <source>If affinity is &amp;ldquo;precomputed&amp;rdquo; X : {array-like, sparse matrix}, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.</source>
          <target state="translated">親和性が「事前計算された」Xの場合：{配列のようなスパース行列}、形状（n_samples、n_samples）、サンプルから計算された事前計算された隣接グラフとしてXを解釈します。</target>
        </trans-unit>
        <trans-unit id="c306493486d7abaed871db69a1b0f3a0d3e230f4" translate="yes" xml:space="preserve">
          <source>If affinity is the adjacency matrix of a graph, this method can be used to find normalized graph cuts.</source>
          <target state="translated">親和性がグラフの隣接行列である場合、この方法は正規化されたグラフの切り口を見つけるために使用することができます。</target>
        </trans-unit>
        <trans-unit id="fef3ba1186af33eef8e244a6a4bb530d43ffdf84" translate="yes" xml:space="preserve">
          <source>If all examples are from the same class, it uses a one-class SVM.</source>
          <target state="translated">すべての例が同じクラスのものであれば、1クラスのSVMを使用します。</target>
        </trans-unit>
        <trans-unit id="b53805960d76925767243aca9c19243fc1b08d06" translate="yes" xml:space="preserve">
          <source>If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.</source>
          <target state="translated">すべてのパラメータがリストとして提示された場合、置換なしのサンプリングが実行されます。少なくとも1つのパラメータが分布として与えられている場合,置換によるサンプリングが使用される.連続パラメータには連続分布を使用することが強く推奨されます。</target>
        </trans-unit>
        <trans-unit id="44ee4928f6faf842a93c2259e4d1b6db16c4073a" translate="yes" xml:space="preserve">
          <source>If all the coordinates are missing or if there are no common present coordinates then NaN is returned for that pair.</source>
          <target state="translated">すべての座標が欠落している場合、または共通の現在の座標がない場合は、そのペアに対してNaNが返されます。</target>
        </trans-unit>
        <trans-unit id="4f219d1953670922fbbfe88159427df7222c9397" translate="yes" xml:space="preserve">
          <source>If an algorithm, such as a linear support vector machine or PCA, relies only on the scalar product of data points \(x_i\), one may use the value of \(k(x_i, x_j)\), which corresponds to applying the algorithm to the mapped data points \(\phi(x_i)\). The advantage of using \(k\) is that the mapping \(\phi\) never has to be calculated explicitly, allowing for arbitrary large features (even infinite).</source>
          <target state="translated">線形支持ベクトルマシンやPCAなどのアルゴリズムが、データ点のスカラー積にしか依存しない場合は、\(k(x_i,x_j)の値を使うことができます。この方法の利点は、マッピングを明示的に計算する必要がなく、任意の大きな特徴量(無限大)にも対応できることです。</target>
        </trans-unit>
        <trans-unit id="22b4c02685073d2c5c3e900f3a57456658da8b22" translate="yes" xml:space="preserve">
          <source>If an array-like of axes are passed in, the partial dependence</source>
          <target state="translated">軸の配列的なものが渡されると、部分的な依存性</target>
        </trans-unit>
        <trans-unit id="9fea95f95d0577b3d2b8dde1c99a4f5f11240b1d" translate="yes" xml:space="preserve">
          <source>If an exception is triggered, use &lt;code&gt;%debug&lt;/code&gt; to fire-up a post mortem ipdb session.</source>
          <target state="translated">例外がトリガーされた場合は、 &lt;code&gt;%debug&lt;/code&gt; を使用して事後分析のipdbセッションを起動します。</target>
        </trans-unit>
        <trans-unit id="5c4a826b768bf0ea44b0de0cf9a279c59410da1d" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details.</source>
          <target state="translated">整数が与えられた場合、使用する alpha のグリッド上の点の数を固定します。リストが与えられた場合は、使用するグリッドを指定します。詳細はクラスdocstringのノートを参照してください。</target>
        </trans-unit>
        <trans-unit id="9e0d496b83e5a4c02138b5662acc0d0357377648" translate="yes" xml:space="preserve">
          <source>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details. Range is (0, inf] when floats given.</source>
          <target state="translated">整数が与えられた場合、使用する alpha のグリッド上の点の数を固定します。リストが与えられた場合は、使用するグリッドを指定します。詳細はクラスdocstringのノートを参照してください。フロートが与えられた場合、範囲は(0,inf)です。</target>
        </trans-unit>
        <trans-unit id="3f54c86c80b29ba93fdb4405121f2a742f42412e" translate="yes" xml:space="preserve">
          <source>If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.</source>
          <target state="translated">ndarrayが渡された場合、それは形状(n_clusters,n_features)であり、初期中心を与えなければなりません。</target>
        </trans-unit>
        <trans-unit id="ce1d1dc15735f50591b21078e51cada592338767" translate="yes" xml:space="preserve">
          <source>If arpack :</source>
          <target state="translated">もし arpack が .</target>
        </trans-unit>
        <trans-unit id="57a89ce6b3eb175b37e97fdc8660396b5ef203e5" translate="yes" xml:space="preserve">
          <source>If auto :</source>
          <target state="translated">自動の場合。</target>
        </trans-unit>
        <trans-unit id="7bf20b6ab9e24e0313be1f29e5bd87350c62fc72" translate="yes" xml:space="preserve">
          <source>If bandwidth is not given, it is determined using a heuristic based on the median of all pairwise distances. This will take quadratic time in the number of samples. The sklearn.cluster.estimate_bandwidth function can be used to do this more efficiently.</source>
          <target state="translated">帯域幅が与えられていない場合は、すべてのペアワイズ距離の中央値に基づくヒューリスティックを使用して決定されます。これにはサンプル数の2次的な時間がかかります.sklearn.cluster.estimate_bandwidth関数を使うとより効率的に行うことができます。</target>
        </trans-unit>
        <trans-unit id="307d133eac653119e68c3f800803dcc4776573b9" translate="yes" xml:space="preserve">
          <source>If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If &amp;lsquo;auto&amp;rsquo;, it is assigned to False for dense &lt;code&gt;X&lt;/code&gt; and to True for sparse &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">boolの場合、すべてのフィーチャを離散的または連続的と見なすかどうかを決定します。配列の場合、形状（n_features）のブールマスクか、離散フィーチャのインデックスを持つ配列のいずれかである必要があります。'auto'の場合、密 &lt;code&gt;X&lt;/code&gt; の場合はFalse 、疎 &lt;code&gt;X&lt;/code&gt; の場合は Trueに割り当てられます。</target>
        </trans-unit>
        <trans-unit id="14d26c2cb6ccf4f84a440b5eee94360749d30490" translate="yes" xml:space="preserve">
          <source>If boolean, whether or not to fit the isotonic regression with y increasing or decreasing.</source>
          <target state="translated">ブール値の場合,y を増加させるか減少させるかで等張回帰を適合させるかどうかを指定します.</target>
        </trans-unit>
        <trans-unit id="34ddc69f78e9ae21f32c4048eb992eb5ea37253a" translate="yes" xml:space="preserve">
          <source>If bootstrap is True, the number of samples to draw from X to train each base estimator.</source>
          <target state="translated">ブートストラップがTrueの場合、各基底推定量を訓練するためにXから描画するサンプル数。</target>
        </trans-unit>
        <trans-unit id="c7380002883f78b7443a4cf144369e2cdf9c7dd5" translate="yes" xml:space="preserve">
          <source>If bytes or files are given to analyze, this encoding is used to decode.</source>
          <target state="translated">解析にバイトやファイルが与えられた場合、このエンコーディングがデコードに使用されます。</target>
        </trans-unit>
        <trans-unit id="b1cd46fc8b5b18d3d8ec258c92a5832fe49ecb69" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the AMI is null:</source>
          <target state="translated">クラスのメンバが異なるクラスタに完全に分割されている場合、割り当ては完全に完全ではないので AMI は NULL になります。</target>
        </trans-unit>
        <trans-unit id="e6f2dbc2c288fdff952bc5d6d0612fad044f50c2" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally in-complete, hence the NMI is null:</source>
          <target state="translated">クラスのメンバーが異なるクラスタに完全に分割されている場合、割り当ては完全に完全ではないので、NMIはnullです。</target>
        </trans-unit>
        <trans-unit id="60b93fba5d2befe30dad173ef2989a32caf2707d" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the ARI is very low:</source>
          <target state="translated">クラスのメンバーが異なるクラスタに完全に分割されている場合、割り当てが完全に不完全であるため、ARIは非常に低くなります。</target>
        </trans-unit>
        <trans-unit id="e02bb35b2a969fdf2ff25b865a0b3ba938fb92a9" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally incomplete, hence the V-Measure is null:</source>
          <target state="translated">クラス メンバが異なるクラスタ間で完全に分割されている場合、割り当ては完全に不完全であるため、V-Measure は NULL になります。</target>
        </trans-unit>
        <trans-unit id="d0974a75f074fb11fd0a08f495fdb803227dd0c6" translate="yes" xml:space="preserve">
          <source>If classes members are completely split across different clusters, the assignment is totally random, hence the FMI is null:</source>
          <target state="translated">クラスのメンバーが異なるクラスタに完全に分割されている場合、割り当ては完全にランダムであり、したがって FMI はヌルです。</target>
        </trans-unit>
        <trans-unit id="3a4c44f6cadbe5141305e79bc3f8068062652c4d" translate="yes" xml:space="preserve">
          <source>If classes members are split across different clusters, the assignment cannot be complete:</source>
          <target state="translated">クラスのメンバーが異なるクラスタに分割されている場合、割り当てを完了することはできません。</target>
        </trans-unit>
        <trans-unit id="a2787535a9b0772f98dac284faca0d2184e54d74" translate="yes" xml:space="preserve">
          <source>If coefficients vary significantly when changing the input dataset their robustness is not guaranteed, and they should probably be interpreted with caution.</source>
          <target state="translated">入力データセットを変更したときに係数が有意に変化する場合、そのロバスト性は保証されていません。</target>
        </trans-unit>
        <trans-unit id="52c8ac55b5c80763168c6804bd2b4b595db63ef9" translate="yes" xml:space="preserve">
          <source>If computed_score is True, value of the log marginal likelihood (to be maximized) at each iteration of the optimization. The array starts with the value of the log marginal likelihood obtained for the initial values of alpha and lambda and ends with the value obtained for the estimated alpha and lambda.</source>
          <target state="translated">computed_score が True の場合、最適化の各反復における(最大化される)対数限界尤度の値を指定します。この配列は、アルファとラムダの初期値で得られた対数限界尤度の値で始まり、アルファとラムダの推定値で終わります。</target>
        </trans-unit>
        <trans-unit id="baf96abe9df5cd386826eafcd47454c9dcc36819" translate="yes" xml:space="preserve">
          <source>If copy is False, the affinity matrix is modified inplace by the algorithm, for memory efficiency</source>
          <target state="translated">copy が False の場合,メモリ効率を考慮して,アフィニティ行列はアルゴリズムによって代用されます.</target>
        </trans-unit>
        <trans-unit id="0070f2c19699b732c372ba0e363293b507463ed1" translate="yes" xml:space="preserve">
          <source>If decision_function_shape=&amp;rsquo;ovo&amp;rsquo;, the function values are proportional to the distance of the samples X to the separating hyperplane. If the exact distances are required, divide the function values by the norm of the weight vector (&lt;code&gt;coef_&lt;/code&gt;). See also &lt;a href=&quot;https://stats.stackexchange.com/questions/14876/interpreting-distance-from-hyperplane-in-svm&quot;&gt;this question&lt;/a&gt; for further details. If decision_function_shape=&amp;rsquo;ovr&amp;rsquo;, the decision function is a monotonic transformation of ovo decision function.</source>
          <target state="translated">Decision_function_shape = 'ovo'の場合、関数値は分離超平面までのサンプルXの距離に比例します。正確な距離が必要な場合は、関数値を重みベクトル（ &lt;code&gt;coef_&lt;/code&gt; ）のノルムで除算します。詳細については、&lt;a href=&quot;https://stats.stackexchange.com/questions/14876/interpreting-distance-from-hyperplane-in-svm&quot;&gt;この質問&lt;/a&gt;も参照してください。Decision_function_shape = 'ovr'の場合、決定関数はovo決定関数の単調変換です。</target>
        </trans-unit>
        <trans-unit id="671e4e16873255449d2ba54f06975c272f73c34d" translate="yes" xml:space="preserve">
          <source>If density = &amp;lsquo;auto&amp;rsquo;, the value is set to the minimum density as recommended by Ping Li et al.: 1 / sqrt(n_features).</source>
          <target state="translated">Density = 'auto'の場合、値はPing Li et al。が推奨する最小密度に設定されます：1 / sqrt（n_features）。</target>
        </trans-unit>
        <trans-unit id="391517cb3cfce3ac9c6c32b7ceac049807282afc" translate="yes" xml:space="preserve">
          <source>If documents are pre-tokenized by an external package, then store them in files (or strings) with the tokens separated by whitespace and pass &lt;code&gt;analyzer=str.split&lt;/code&gt;</source>
          <target state="translated">ドキュメントが外部パッケージによって事前にトークン化されている場合は、空白で区切られたトークンを使用してファイル（または文字列）に保存し、 &lt;code&gt;analyzer=str.split&lt;/code&gt; を渡します。</target>
        </trans-unit>
        <trans-unit id="80416b24b5f24b22b80d50d90aa942e77a2dadfc" translate="yes" xml:space="preserve">
          <source>If each row and each column belongs to exactly one bicluster, then rearranging the rows and columns of the data matrix reveals the biclusters on the diagonal. Here is an example of this structure where biclusters have higher average values than the other rows and columns:</source>
          <target state="translated">各行と各列が正確に 1 つのビクラスタに属している場合、データ行列の行と列を並べ替えると、対角線上のビクラスタがわかります。ビックラスターの平均値が他の行と列よりも高い場合のこの構造の例を以下に示します。</target>
        </trans-unit>
        <trans-unit id="78ba0badd104b3ed95bd2061747613a1b6f84ce9" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of groups to include in the test split (rounded up). If int, represents the absolute number of test groups. If None, the value is set to the complement of the train size. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">floatの場合、0.0〜1.0であり、テスト分割に含めるグループの比率を表します（切り上げ）。intの場合、テストグループの絶対数を表します。Noneの場合、値はトレインサイズの補数に設定されます。デフォルトはバージョン0.21で変更されます。 &lt;code&gt;train_size&lt;/code&gt; が指定されていない場合にのみ、0.2のままになります。それ以外の場合は、指定された &lt;code&gt;train_size&lt;/code&gt; を補完します。</target>
        </trans-unit>
        <trans-unit id="1db9c10662b6d49b6b84ca8b7b7ce2a9580afa10" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default (the parameter is unspecified), the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">浮動小数点数の場合、0.0と1.0の間で、テスト分割に含めるデータセットの比率を表す必要があります。 intの場合、テストサンプルの絶対数を表します。 Noneの場合、値はトレインサイズの補数に設定されます。デフォルトでは（パラメーターは指定されていません）、値は0.1に設定されています。デフォルトはバージョン0.21で変更されます。 &lt;code&gt;train_size&lt;/code&gt; が指定されていない場合にのみ0.1のまま &lt;code&gt;train_size&lt;/code&gt; 。それ以外の場合は、指定されたtrain_sizeを補完します。</target>
        </trans-unit>
        <trans-unit id="73ce93bb920d84bef49715afdf02f771938f8206" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.1. The default will change in version 0.21. It will remain 0.1 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">浮動小数点数の場合、0.0と1.0の間で、テスト分割に含めるデータセットの比率を表す必要があります。 intの場合、テストサンプルの絶対数を表します。 Noneの場合、値はトレインサイズの補数に設定されます。デフォルトでは、値は0.1に設定されています。デフォルトはバージョン0.21で変更されます。 &lt;code&gt;train_size&lt;/code&gt; が指定されていない場合にのみ0.1のまま &lt;code&gt;train_size&lt;/code&gt; 。それ以外の場合は、指定されたtrain_sizeを補完します。</target>
        </trans-unit>
        <trans-unit id="aa74ab3ce21513c4e7c83e9b91dad63582c835b8" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.2. The default will change in version 0.21. It will remain 0.2 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">浮動小数点数の場合、0.0と1.0の間で、テスト分割に含めるデータセットの比率を表す必要があります。 intの場合、テストサンプルの絶対数を表します。 Noneの場合、値はトレインサイズの補数に設定されます。デフォルトでは、値は0.2に設定されています。デフォルトはバージョン0.21で変更されます。 &lt;code&gt;train_size&lt;/code&gt; が指定されていない場合にのみ0.2のままになります。それ以外の場合は、指定された &lt;code&gt;train_size&lt;/code&gt; を補完します。</target>
        </trans-unit>
        <trans-unit id="dfe0bc4ba0825c6b9e54b3177711e714d6e28a2b" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if &lt;code&gt;train_size&lt;/code&gt; is unspecified, otherwise it will complement the specified &lt;code&gt;train_size&lt;/code&gt;.</source>
          <target state="translated">浮動小数点数の場合、0.0と1.0の間で、テスト分割に含めるデータセットの比率を表す必要があります。intの場合、テストサンプルの絶対数を表します。Noneの場合、値はトレインサイズの補数に設定されます。デフォルトでは、値は0.25に設定されています。デフォルトはバージョン0.21で変更されます。 &lt;code&gt;train_size&lt;/code&gt; が指定されていない場合のみ、0.25のまま &lt;code&gt;train_size&lt;/code&gt; 。それ以外の場合は、指定されたtrain_sizeを補完します。</target>
        </trans-unit>
        <trans-unit id="09a40f5654bce0b9dd81c58e4db01bd35e373391" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.1.</source>
          <target state="translated">floatの場合、0.0〜1.0であり、テスト分割に含めるデータセットの比率を表す必要があります。intの場合、テストサンプルの絶対数を表します。Noneの場合、値はトレインサイズの補数に設定されます。 &lt;code&gt;train_size&lt;/code&gt; もNoneの場合、0.1に設定されます。</target>
        </trans-unit>
        <trans-unit id="2c86f8c8782626d870a975f8a368ba48b84e1e80" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If &lt;code&gt;train_size&lt;/code&gt; is also None, it will be set to 0.25.</source>
          <target state="translated">floatの場合、0.0〜1.0であり、テスト分割に含めるデータセットの比率を表す必要があります。intの場合、テストサンプルの絶対数を表します。Noneの場合、値はトレインサイズの補数に設定されます。 &lt;code&gt;train_size&lt;/code&gt; もNoneの場合、0.25に設定されます。</target>
        </trans-unit>
        <trans-unit id="a3b7da8f21403a8e0fce55a369b8d82b4da5bfd1" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">float の場合は,0.0 から 1.0 の間の値で,訓練分割に含めるデータセットの割合を表します.int の場合は,訓練サンプルの絶対数を表します.None の場合,値は自動的にテストサイズの補数に設定されます.</target>
        </trans-unit>
        <trans-unit id="62b47f7a89d7c976d2813299381cdc4f4f5b3cad" translate="yes" xml:space="preserve">
          <source>If float, should be between 0.0 and 1.0 and represent the proportion of the groups to include in the train split. If int, represents the absolute number of train groups. If None, the value is automatically set to the complement of the test size.</source>
          <target state="translated">float の場合は 0.0 から 1.0 の間で、列車分割に含めるグループの割合を表します。int の場合、列車分割に含めるグループの絶対数を表します。Noneの場合は,自動的にテストサイズの補数に設定されます.</target>
        </trans-unit>
        <trans-unit id="561d4c125db4b741d015190537a6b19d8f8e55c1" translate="yes" xml:space="preserve">
          <source>If float, the contamination should be in the range [0, 0.5].</source>
          <target state="translated">フロートの場合、コンタミネーションは[0,0.5]の範囲内でなければなりません。</target>
        </trans-unit>
        <trans-unit id="b0ffbda1c59db43809cf9245f33efa45a65a5c05" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;max_features&lt;/code&gt; is a fraction and &lt;code&gt;int(max_features * n_features)&lt;/code&gt; features are considered at each split.</source>
          <target state="translated">floatの場合、 &lt;code&gt;max_features&lt;/code&gt; は分数であり、 &lt;code&gt;int(max_features * n_features)&lt;/code&gt; フィーチャーは各分割で考慮されます。</target>
        </trans-unit>
        <trans-unit id="47d0c1ebc9dc44a7018a0ce88d0d45201068f385" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; are the minimum number of samples for each node.</source>
          <target state="translated">floatの場合、 &lt;code&gt;min_samples_leaf&lt;/code&gt; は分数で、 &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; は各ノードの最小サンプル数です。</target>
        </trans-unit>
        <trans-unit id="c217707834c84f95b745c6fd735e46ef1d5cb29d" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_leaf&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; is the minimum number of samples for each node.</source>
          <target state="translated">floatの場合、 &lt;code&gt;min_samples_leaf&lt;/code&gt; は分数で、 &lt;code&gt;ceil(min_samples_leaf * n_samples)&lt;/code&gt; は各ノードのサンプルの最小数です。</target>
        </trans-unit>
        <trans-unit id="f5813e9c1656f619ed6234eb86815e1c76ec9071" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; are the minimum number of samples for each split.</source>
          <target state="translated">floatの場合、 &lt;code&gt;min_samples_split&lt;/code&gt; は分数で、 &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; は各分割のサンプルの最小数です。</target>
        </trans-unit>
        <trans-unit id="c32957ea85344bbb6b41aa874b4a5e7763ff6b76" translate="yes" xml:space="preserve">
          <source>If float, then &lt;code&gt;min_samples_split&lt;/code&gt; is a fraction and &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; is the minimum number of samples for each split.</source>
          <target state="translated">floatの場合、 &lt;code&gt;min_samples_split&lt;/code&gt; は分数で、 &lt;code&gt;ceil(min_samples_split * n_samples)&lt;/code&gt; は各分割のサンプルの最小数です。</target>
        </trans-unit>
        <trans-unit id="81fe24c94c96599e85080c0cc195542bdb1ce722" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; features.</source>
          <target state="translated">floatの場合、 &lt;code&gt;max_features * X.shape[1]&lt;/code&gt; フィーチャーを描画します。</target>
        </trans-unit>
        <trans-unit id="a2b1676fcae8577852e20614ce418906e2f79102" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples.</source>
          <target state="translated">floatの場合、 &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; サンプルを描画します。</target>
        </trans-unit>
        <trans-unit id="271d97216c612b23c04f108b3da94d4db7dcfcec" translate="yes" xml:space="preserve">
          <source>If float, then draw &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; samples. Thus, &lt;code&gt;max_samples&lt;/code&gt; should be in the interval &lt;code&gt;(0, 1)&lt;/code&gt;.</source>
          <target state="translated">floatの場合は、 &lt;code&gt;max_samples * X.shape[0]&lt;/code&gt; サンプルを描画します。したがって、 &lt;code&gt;max_samples&lt;/code&gt; は間隔 &lt;code&gt;(0, 1)&lt;/code&gt; 必要があります。</target>
        </trans-unit>
        <trans-unit id="2cf469ccb5c1129883a42e4f4a3183401e643c51" translate="yes" xml:space="preserve">
          <source>If full :</source>
          <target state="translated">完全な場合。</target>
        </trans-unit>
        <trans-unit id="f234188a9694365b66e83538b40de1fa4059a074" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration.</source>
          <target state="translated">1以上の場合、 &lt;code&gt;step&lt;/code&gt; は各反復で削除する特徴の（整数の）数に対応します。（0.0、1.0）以内の場合、 &lt;code&gt;step&lt;/code&gt; は各反復で削除するフィーチャのパーセンテージ（切り捨て）に対応します。</target>
        </trans-unit>
        <trans-unit id="d3aeb6a39c457b69bdde12a943780461d08c388d" translate="yes" xml:space="preserve">
          <source>If greater than or equal to 1, then &lt;code&gt;step&lt;/code&gt; corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then &lt;code&gt;step&lt;/code&gt; corresponds to the percentage (rounded down) of features to remove at each iteration. Note that the last iteration may remove fewer than &lt;code&gt;step&lt;/code&gt; features in order to reach &lt;code&gt;min_features_to_select&lt;/code&gt;.</source>
          <target state="translated">1以上の場合、 &lt;code&gt;step&lt;/code&gt; は各反復で削除する特徴の（整数の）数に対応します。（0.0、1.0）以内の場合、 &lt;code&gt;step&lt;/code&gt; は各反復で削除するフィーチャのパーセンテージ（切り捨て）に対応します。最後の反復では、 &lt;code&gt;min_features_to_select&lt;/code&gt; に到達するために、 &lt;code&gt;step&lt;/code&gt; フィーチャよりも少ない数が削除される場合があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="1351e34960b08f78869e356e9d9129a529a17168" translate="yes" xml:space="preserve">
          <source>If in the QDA model one assumes that the covariance matrices are diagonal, then the inputs are assumed to be conditionally independent in each class, and the resulting classifier is equivalent to the Gaussian Naive Bayes classifier &lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt;&lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">QDAモデルで、共分散行列が対角であると仮定する場合、入力は各クラスで条件付きで独立していると想定され、結果の分類器はガウスナイーブベイズ分類器&lt;a href=&quot;generated/sklearn.naive_bayes.gaussiannb#sklearn.naive_bayes.GaussianNB&quot;&gt; &lt;code&gt;naive_bayes.GaussianNB&lt;/code&gt; と同等&lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="47884bf7f490577d7025ceb970813cb997acfc82" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution.</source>
          <target state="translated">init = 'custom'の場合、ソリューションの初期推定として使用されます。</target>
        </trans-unit>
        <trans-unit id="25a1f9fc4e56498f0b6e355b29cc8aeb5e3daeb3" translate="yes" xml:space="preserve">
          <source>If init=&amp;rsquo;custom&amp;rsquo;, it is used as initial guess for the solution. If update_H=False, it is used as a constant, to solve for W only.</source>
          <target state="translated">init = 'custom'の場合、ソリューションの初期推定として使用されます。update_H = Falseの場合、Wのみを解くために、定数として使用されます。</target>
        </trans-unit>
        <trans-unit id="5b9c788e52ff7adb618d2b8cf3dd396e088800c8" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points equally divided among clusters. If array-like, each element of the sequence indicates the number of samples per cluster.</source>
          <target state="translated">int の場合は,クラスタ間で等分されたポイントの総数を表します.配列のような場合、シーケンスの各要素はクラスタごとのサンプル数を示します。</target>
        </trans-unit>
        <trans-unit id="424c096f1eaf5892378c66d2235ced4e356f327c" translate="yes" xml:space="preserve">
          <source>If int, it is the total number of points generated. For odd numbers, the inner circle will have one point more than the outer circle. If two-element tuple, number of points in outer circle and inner circle.</source>
          <target state="translated">intの場合は、生成されたポイントの総数です。奇数の場合、内側の円は外側の円よりも1点多く発生します。2要素タプルの場合は、外円と内円の点の数。</target>
        </trans-unit>
        <trans-unit id="2403d0bd3d2ac8c8a9756c4cde9cd9202cbe9926" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレーターです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。</target>
        </trans-unit>
        <trans-unit id="676c2454734bf9216c5797d643595f0b850b4e7a" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Note that different initializations might result in different local minima of the cost function.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。初期化が異なると、コスト関数の極小値が異なる可能性があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="a1933900181bd8e24f0237ebecc7a06b2ef8b486" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Only used when &lt;code&gt;svd_method&lt;/code&gt; equals &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;svd_method&lt;/code&gt; が 'randomized'に等しい場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="4914440c8828885c0b1efea7679daefd5f1e4eaf" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;eigen_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;eigen_solver&lt;/code&gt; == 'arpack'の場合に使用されます。</target>
        </trans-unit>
        <trans-unit id="90657492e3c46d11fb3a1c799a4569e4854211ed" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; == True.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;shuffle&lt;/code&gt; == Trueの場合に使用されます。</target>
        </trans-unit>
        <trans-unit id="7e39c8ed74a38762200c178da772671eaa6b3f52" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;shuffle&lt;/code&gt; is True.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;shuffle&lt;/code&gt; がTrueの場合に使用されます。</target>
        </trans-unit>
        <trans-unit id="636d95a8f3edcd08bb7a122de05f8944c1a330ee" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo;.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;solver&lt;/code&gt; == 'arpack'の場合に使用されます。</target>
        </trans-unit>
        <trans-unit id="d8bb54edf7a318cb4f3734b3f7721b6c840db8b1" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by &lt;code&gt;np.random&lt;/code&gt;. Used when &lt;code&gt;svd_solver&lt;/code&gt; == &amp;lsquo;arpack&amp;rsquo; or &amp;lsquo;randomized&amp;rsquo;.</source>
          <target state="translated">intの場合、random_stateは乱数ジェネレータによって使用されるシードです。RandomStateインスタンスの場合、random_stateは乱数ジェネレータです。Noneの場合、乱数ジェネレータはnp.randomによって使用される &lt;code&gt;np.random&lt;/code&gt; インスタンスです。 &lt;code&gt;svd_solver&lt;/code&gt; == 'arpack'または 'randomized'の場合に使用されます。</target>
        </trans-unit>
        <trans-unit id="49fc99a0f8ec79ab5cf6633c8b91ad397447b0ae" translate="yes" xml:space="preserve">
          <source>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. Note that this is used by subsampling and smoothing noise.</source>
          <target state="translated">intの場合、random_stateは乱数生成器が使用するシードです。 RandomStateインスタンスの場合、random_stateは乱数生成器です。これは、サブサンプリングやノイズの平滑化などで使用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="20ecb73824a9c787c46458c94b754eb343f23997" translate="yes" xml:space="preserve">
          <source>If int, the total number of points generated. If two-element tuple, number of points in each of two moons.</source>
          <target state="translated">int の場合は、生成されたポイントの総数。2要素タプルの場合、2つの月のそれぞれの点の数。</target>
        </trans-unit>
        <trans-unit id="c8faba5e55a8f0e899120109354364cac8c2354b" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;max_features&lt;/code&gt; features at each split.</source>
          <target state="translated">intの場合、分割ごとに &lt;code&gt;max_features&lt;/code&gt; 機能を検討します。</target>
        </trans-unit>
        <trans-unit id="79438cfe8b8de1684467307814da6af61cdfe6ba" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_leaf&lt;/code&gt; as the minimum number.</source>
          <target state="translated">intの場合、 &lt;code&gt;min_samples_leaf&lt;/code&gt; を最小数と見なします。</target>
        </trans-unit>
        <trans-unit id="69e04ca78560d3ef445be4d724f5c0cc8198187a" translate="yes" xml:space="preserve">
          <source>If int, then consider &lt;code&gt;min_samples_split&lt;/code&gt; as the minimum number.</source>
          <target state="translated">intの場合、 &lt;code&gt;min_samples_split&lt;/code&gt; を最小数と見なします。</target>
        </trans-unit>
        <trans-unit id="a8d276c242fbe315ce14903af35e7ebf9a0c3619" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_features&lt;/code&gt; features.</source>
          <target state="translated">intの場合、 &lt;code&gt;max_features&lt;/code&gt; フィーチャーを描画します。</target>
        </trans-unit>
        <trans-unit id="0771ca4ef29dd427aac0ffda56943aa541e3af54" translate="yes" xml:space="preserve">
          <source>If int, then draw &lt;code&gt;max_samples&lt;/code&gt; samples.</source>
          <target state="translated">intの場合、 &lt;code&gt;max_samples&lt;/code&gt; サンプルを描画します。</target>
        </trans-unit>
        <trans-unit id="4430c154e22158c0d6435f75a2d640312ee73ab2" translate="yes" xml:space="preserve">
          <source>If log normalization was used, all the singular vectors are meaningful. However, if independent normalization or bistochastization were used, the first singular vectors, \(u_1\) and \(v_1\). are discarded. From now on, the &amp;ldquo;first&amp;rdquo; singular vectors refers to \(u_2 \dots u_{p+1}\) and \(v_2 \dots v_{p+1}\) except in the case of log normalization.</source>
          <target state="translated">対数正規化が使用された場合、すべての特異ベクトルは意味があります。ただし、独立した正規化または双安定化が使用された場合、最初の特異ベクトル、\（u_1 \）および\（v_1 \）。破棄されます。これ以降、「最初の」特異ベクトルは、ログ正規化の場合を除いて、\（u_2 \ dots u_ {p + 1} \）および\（v_2 \ dots v_ {p + 1} \）を指します。</target>
        </trans-unit>
        <trans-unit id="f38434d38fce86523bd80aac7625c65019a5f868" translate="yes" xml:space="preserve">
          <source>If max_samples is larger than the number of samples provided, all samples will be used for all trees (no sampling).</source>
          <target state="translated">max_samplesが提供されたサンプル数よりも大きい場合、すべてのツリーにすべてのサンプルが使用されます(サンプリングなし)。</target>
        </trans-unit>
        <trans-unit id="0512919782ceb898f5e82137605d37f1918f7fe8" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;auto&amp;rdquo;, the ratio of n_samples / n_population is used to determine which algorithm to use: If ratio is between 0 and 0.01, tracking selection is used. If ratio is between 0.01 and 0.99, numpy.random.permutation is used. If ratio is greater than 0.99, reservoir sampling is used. The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">method ==&amp;ldquo; auto&amp;rdquo;の場合、n_samples / n_populationの比率を使用して、使用するアルゴリズムを決定します。比率が0〜0.01の場合、追跡選択が使用されます。比率が0.01から0.99の場合、numpy.random.permutationが使用されます。比率が0.99より大きい場合、貯水池サンプリングが使用されます。選択した整数の順序は定義されていません。ランダムな順序が必要な場合は、選択したサブセットをシャッフルする必要があります。</target>
        </trans-unit>
        <trans-unit id="aa3ae5990e2e00fef99c00cc07049cdbc9d8e931" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;pool&amp;rdquo;, a pool based algorithm is particularly fast, even faster than the tracking selection method. Hovewer, a vector containing the entire population has to be initialized. If n_samples ~ n_population, the reservoir sampling method is faster.</source>
          <target state="translated">method ==&amp;ldquo; pool&amp;rdquo;の場合、プールベースのアルゴリズムは特に高速で、追跡選択メソッドよりもさらに高速です。Hovewer、母集団全体を含むベクトルを初期化する必要があります。n_samples〜n_populationの場合、リザーバーサンプリング方式の方が高速です。</target>
        </trans-unit>
        <trans-unit id="6916dcd6d6c8f00e1ac0ef865ab4c75ff38ebedf" translate="yes" xml:space="preserve">
          <source>If method == &amp;ldquo;reservoir_sampling&amp;rdquo;, a reservoir sampling algorithm is used which is suitable for high memory constraint or when O(&lt;code&gt;n_samples&lt;/code&gt;) ~ O(&lt;code&gt;n_population&lt;/code&gt;). The order of the selected integers is undefined. If a random order is desired, the selected subset should be shuffled.</source>
          <target state="translated">もし方法==「reservoir_sampling」Aリザーバサンプリングアルゴリズム高いメモリ制約場合やO（適しているが使用される &lt;code&gt;n_samples&lt;/code&gt; ）〜O（ &lt;code&gt;n_population&lt;/code&gt; ）。選択した整数の順序は定義されていません。ランダムな順序が必要な場合は、選択したサブセットをシャッフルする必要があります。</target>
        </trans-unit>
        <trans-unit id="0dea8a6c91cef90e0430014d895bb3954c8fb19c" translate="yes" xml:space="preserve">
          <source>If method ==&amp;rdquo;tracking_selection&amp;rdquo;, a set based implementation is used which is suitable for &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt;.</source>
          <target state="translated">method ==&amp;rdquo; tracking_selection&amp;rdquo;の場合、 &lt;code&gt;n_samples&lt;/code&gt; &amp;lt;&amp;lt;&amp;lt; &lt;code&gt;n_population&lt;/code&gt; に適したセットベースの実装が使用されます。</target>
        </trans-unit>
        <trans-unit id="b83a3c2dac1d5c17a6e580230ebdf136c940fa15" translate="yes" xml:space="preserve">
          <source>If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square. X may be a sparse matrix, in which case only &amp;ldquo;nonzero&amp;rdquo; elements may be considered neighbors.</source>
          <target state="translated">メトリックが「事前計算」されている場合、Xは距離行列であると見なされ、正方形である必要があります。Xはスパース行列である可能性があり、その場合、「非ゼロ」要素のみが近傍と見なされます。</target>
        </trans-unit>
        <trans-unit id="79ae0bba548597b9902c41c70fbd6bf9602e8534" translate="yes" xml:space="preserve">
          <source>If metric is &amp;lsquo;precomputed&amp;rsquo;, Y is ignored and X is returned.</source>
          <target state="translated">メトリックが「事前計算」されている場合、Yは無視され、Xが返されます。</target>
        </trans-unit>
        <trans-unit id="ca8cb47e72e166fd730a116349e050254e6876d5" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string.</source>
          <target state="translated">メトリックが呼び出し可能な関数の場合、インスタンス（行）の各ペアで呼び出され、結果の値が記録されます。呼び出し可能オブジェクトは、2つの配列を入力として取り、それらの間の距離を示す1つの値を返す必要があります。これはScipyのメトリックスでは機能しますが、メトリックス名を文字列として渡すよりも効率的ではありません。</target>
        </trans-unit>
        <trans-unit id="574d42008b369aefc553aab20dba12b6d233789b" translate="yes" xml:space="preserve">
          <source>If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy&amp;rsquo;s metrics, but is less efficient than passing the metric name as a string. If metric is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be a distance matrix and must be square.</source>
          <target state="translated">メトリックが呼び出し可能な関数である場合、インスタンス（行）の各ペアで呼び出され、結果の値が記録されます。呼び出し可能オブジェクトは、入力として2つの配列を受け取り、それらの間の距離を示す1つの値を返す必要があります。これはScipyのメトリックに対して機能しますが、メトリック名を文字列として渡すよりも効率的ではありません。メトリックが「事前計算」されている場合、Xは距離行列であると見なされ、正方形である必要があります。</target>
        </trans-unit>
        <trans-unit id="27305db22802f1bb3d3e2d60db076f6f0d275369" translate="yes" xml:space="preserve">
          <source>If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.</source>
          <target state="translated">ミニバッチ k-means が使用される場合、最良の初期化が選択され、アルゴリズムは一度だけ実行される。そうでない場合は、アルゴリズムは各初期化ごとに実行され、最良の解が選択されます。</target>
        </trans-unit>
        <trans-unit id="16e6684b95c26e373af21b6c0d2ea50b705c0505" translate="yes" xml:space="preserve">
          <source>If multioutput is &amp;lsquo;raw_values&amp;rsquo;, then mean absolute error is returned for each output separately. If multioutput is &amp;lsquo;uniform_average&amp;rsquo; or an ndarray of weights, then the weighted average of all output errors is returned.</source>
          <target state="translated">multioutputが 'raw_values'の場合​​、平均絶対誤差が各出力に対して個別に返されます。multioutputが 'uniform_average'または重みのndarrayの場合、すべての出力エラーの加重平均が返されます。</target>
        </trans-unit>
        <trans-unit id="5304821b08fca43ab85cd7593997416e8f601261" translate="yes" xml:space="preserve">
          <source>If neighbors_algorithm=&amp;rsquo;precomputed&amp;rsquo;, X is assumed to be a distance matrix or a sparse graph of shape (n_queries, n_samples_fit).</source>
          <target state="translated">neighbors_algorithm = 'precomputed'の場合、Xは距離行列または形状のまばらなグラフ（n_queries、n_samples_fit）であると見なされます。</target>
        </trans-unit>
        <trans-unit id="62bc17472717b60146346d5aed7f5c0278bbe8ae" translate="yes" xml:space="preserve">
          <source>If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.</source>
          <target state="translated">学習中に与えられた特徴に対して欠損値が見つからなかった場合、欠損値を持つサンプルは、最も多くのサンプルを持つ子にマッピングされます。</target>
        </trans-unit>
        <trans-unit id="caf3d42023b133b9efdfbb493fc66df503092e71" translate="yes" xml:space="preserve">
          <source>If no scoring is specified and the estimator has no score function, we can either return None or raise an exception.</source>
          <target state="translated">スコアリングが指定されておらず、推定子にスコア関数がない場合は、Noneを返すか、例外を発生させることができます。</target>
        </trans-unit>
        <trans-unit id="5519c1c6825bf59bfd06c08f68bb64b64ee1a0ae" translate="yes" xml:space="preserve">
          <source>If no valid consensus set could be found. This occurs if &lt;code&gt;is_data_valid&lt;/code&gt; and &lt;code&gt;is_model_valid&lt;/code&gt; return False for all &lt;code&gt;max_trials&lt;/code&gt; randomly chosen sub-samples.</source>
          <target state="translated">有効なコンセンサスセットが見つからなかった場合。これは、ランダムに選択されたすべての &lt;code&gt;max_trials&lt;/code&gt; サブサンプルに対して &lt;code&gt;is_data_valid&lt;/code&gt; および &lt;code&gt;is_model_valid&lt;/code&gt; がFalseを返した場合に発生します。</target>
        </trans-unit>
        <trans-unit id="e48a960f323664c14eed43108cfafa1159796090" translate="yes" xml:space="preserve">
          <source>If normalize is &lt;code&gt;True&lt;/code&gt;, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.</source>
          <target state="translated">正規化が &lt;code&gt;True&lt;/code&gt; の場合、誤分類の割合（float）を返します。それ以外の場合は、誤分類の数（int）を返します。最高のパフォーマンスは0です。</target>
        </trans-unit>
        <trans-unit id="66ebd47239b72bc82239183dacc1b3e58bfa41bb" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-2&quot; id=&quot;id1&quot;&gt;[2]&lt;/a&gt; over the range [0, max_fpr] is returned. For the multiclass case, &lt;code&gt;max_fpr&lt;/code&gt;, should be either equal to &lt;code&gt;None&lt;/code&gt; or &lt;code&gt;1.0&lt;/code&gt; as AUC ROC partial computation currently is not supported for multiclass.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; でない場合、[0、max_fpr]の範囲にわたる標準化された部分AUC &lt;a href=&quot;#r4bb7c4558997-2&quot; id=&quot;id1&quot;&gt;[2&lt;/a&gt; ]が返されます。マルチクラスの場合、現在AUC ROCの部分計算はマルチクラスでサポートされていないため、 &lt;code&gt;max_fpr&lt;/code&gt; は &lt;code&gt;None&lt;/code&gt; または &lt;code&gt;1.0&lt;/code&gt; のいずれかに等しくする必要があります。</target>
        </trans-unit>
        <trans-unit id="d93355ca0c397a92c0eb63483bbae0b531d00cf1" translate="yes" xml:space="preserve">
          <source>If not &lt;code&gt;None&lt;/code&gt;, the standardized partial AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; over the range [0, max_fpr] is returned.</source>
          <target state="translated">&lt;code&gt;None&lt;/code&gt; でない場合、[0、max_fpr]の範囲の標準化された部分AUC &lt;a href=&quot;#r4bb7c4558997-3&quot; id=&quot;id1&quot;&gt;[3&lt;/a&gt; ]が返されます。</target>
        </trans-unit>
        <trans-unit id="954d968337062d6fae676f5915fb0dc48db9ccef" translate="yes" xml:space="preserve">
          <source>If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.</source>
          <target state="translated">Noneでない場合は、コーパス全体で用語の頻度が高い順に並べられた上位のmax_featuresのみを考慮した語彙を構築します。</target>
        </trans-unit>
        <trans-unit id="6b6dff5f6d294c2bdbfe5ee6b0ee56319193880c" translate="yes" xml:space="preserve">
          <source>If not None, data is split in a stratified fashion, using this as the class labels.</source>
          <target state="translated">None でない場合は、これをクラス・ラベルとして使用して、データを階層化して分割します。</target>
        </trans-unit>
        <trans-unit id="d9fe4271c08ca870db7143f08e0938aa49f2d1d0" translate="yes" xml:space="preserve">
          <source>If not None, set the highest value of the fit to y_max.</source>
          <target state="translated">None でない と きは、 はめ込みの最高値を y_max に設定します。</target>
        </trans-unit>
        <trans-unit id="3c138b5d1ed12eddb3226ed7535814059b7a615c" translate="yes" xml:space="preserve">
          <source>If not None, set the lowest value of the fit to y_min.</source>
          <target state="translated">None でない と きは、 はめ込みの最小値を y_min に設定します。</target>
        </trans-unit>
        <trans-unit id="ebcf44116da09ed76a723aed5cadbe6d4ed2530d" translate="yes" xml:space="preserve">
          <source>If not None, this argument is passed as &lt;code&gt;sample_weight&lt;/code&gt; keyword argument to the &lt;code&gt;score&lt;/code&gt; method of the final estimator.</source>
          <target state="translated">Noneでない場合、この引数は &lt;code&gt;sample_weight&lt;/code&gt; キーワード引数として最終推定器の &lt;code&gt;score&lt;/code&gt; メソッドに渡されます。</target>
        </trans-unit>
        <trans-unit id="3798f9f768af1129609b1d811ed41c3721cfae7d" translate="yes" xml:space="preserve">
          <source>If not None, this function is called after every iteration of the optimizer, taking as arguments the current solution (flattened transformation matrix) and the number of iterations. This might be useful in case one wants to examine or store the transformation found after each iteration.</source>
          <target state="translated">Noneでない場合、この関数はオプティマイザの反復処理のたびに呼び出され、現在の解(平坦化された変換行列)と反復処理の回数を引数にとります。これは、各反復の後に見つかった変換を調べたり保存したりしたい場合に便利です。</target>
        </trans-unit>
        <trans-unit id="f0f7d0b7263b16cf926e8314af8096b9ae6c9066" translate="yes" xml:space="preserve">
          <source>If not given, the bandwidth is estimated using sklearn.cluster.estimate_bandwidth; see the documentation for that function for hints on scalability (see also the Notes, below).</source>
          <target state="translated">もし指定されていなければ、帯域幅はsklearn.cluster.estimate_bandwidthを使って推定されます;スケーラビリティのヒントについては、その関数のドキュメントを参照してください (下記の注意事項も参照してください)。</target>
        </trans-unit>
        <trans-unit id="e77fe01e6cae9364473d1714c8219315178ecad2" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;.</source>
          <target state="translated">指定しない場合、ラベルはy_trueから推測されます。場合 &lt;code&gt;labels&lt;/code&gt; ありません &lt;code&gt;None&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; 形状（n_samplesは、）を有するラベルがバイナリであると想定されるから推測される &lt;code&gt;y_true&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="3fc57ade66d3b29b2e5dacfcee394aac7f4ec951" translate="yes" xml:space="preserve">
          <source>If not provided, labels will be inferred from y_true. If &lt;code&gt;labels&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; has shape (n_samples,) the labels are assumed to be binary and are inferred from &lt;code&gt;y_true&lt;/code&gt;. .. versionadded:: 0.18</source>
          <target state="translated">指定しない場合、ラベルはy_trueから推定されます。場合 &lt;code&gt;labels&lt;/code&gt; ありません &lt;code&gt;None&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; 形状（n_samplesは、）を有するラベルがバイナリであると想定されるから推測される &lt;code&gt;y_true&lt;/code&gt; 。.. versionadded :: 0.18</target>
        </trans-unit>
        <trans-unit id="d3a1f4e96f04c6f8dfd4835d50de53587903b2e7" translate="yes" xml:space="preserve">
          <source>If one-of-K coding is applied to categorical features, this will include the constructed feature names but not the original ones.</source>
          <target state="translated">カテゴリ特徴に1-of-K符号化が適用されている場合、これは構築された特徴名を含みますが、元の特徴名は含みません。</target>
        </trans-unit>
        <trans-unit id="c3b8faf61102e14148418b48bf3dbb3389d54ef3" translate="yes" xml:space="preserve">
          <source>If only the diagonal of the auto-covariance is being used, the method &lt;code&gt;diag()&lt;/code&gt; of a kernel can be called, which is more computationally efficient than the equivalent call to &lt;code&gt;__call__&lt;/code&gt;: &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</source>
          <target state="translated">自己共分散の唯一の対角が使用されている場合、方法 &lt;code&gt;diag()&lt;/code&gt; カーネルのは、より計算効率と同等の呼び出しよりなる、と呼ばれることができる &lt;code&gt;__call__&lt;/code&gt; ： &lt;code&gt;np.diag(k(X, X)) == k.diag(X)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="db7f35e5fc1dd73c10c86bdccb4a2449d5a89ec7" translate="yes" xml:space="preserve">
          <source>If order is &amp;lsquo;random&amp;rsquo; a random ordering will be used.</source>
          <target state="translated">順序が「ランダム」の場合、ランダムな順序が使用されます。</target>
        </trans-unit>
        <trans-unit id="f42275492b00fc14b5861ea85e0f4944992d0324" translate="yes" xml:space="preserve">
          <source>If passed, include the name of the estimator in warning messages.</source>
          <target state="translated">渡された場合は、警告メッセージにエスティメー タの名前を含める。</target>
        </trans-unit>
        <trans-unit id="908cd551a5eab6201799122746b2ad3d99f4a3d2" translate="yes" xml:space="preserve">
          <source>If positive, restrict regression coefficients to be positive</source>
          <target state="translated">正の場合、回帰係数を正に制限する</target>
        </trans-unit>
        <trans-unit id="66637d66644751acb1ce04342cdfce0be0ef5495" translate="yes" xml:space="preserve">
          <source>If provided, this parameter will override the choice of copy_X made at instance creation. If &lt;code&gt;True&lt;/code&gt;, X will be copied; else, it may be overwritten.</source>
          <target state="translated">指定した場合、このパラメーターは、インスタンスの作成時に行われたcopy_Xの選択をオーバーライドします。 &lt;code&gt;True&lt;/code&gt; の場合、Xがコピーされます。そうしないと、上書きされる可能性があります。</target>
        </trans-unit>
        <trans-unit id="71021bee801a334b18f6587cd74d122911551ceb" translate="yes" xml:space="preserve">
          <source>If query_id is set to True, this will return instead [X1, y1, q1,</source>
          <target state="translated">query_idがTrueに設定されている場合、代わりに[X1,y1,q1]が返されます。</target>
        </trans-unit>
        <trans-unit id="54d5c9aca2dfc54fbbbdb98327375a6f374bdf8f" translate="yes" xml:space="preserve">
          <source>If randomized :</source>
          <target state="translated">無作為化された場合。</target>
        </trans-unit>
        <trans-unit id="c5484f943f94af044829e2453a87ea1beff675d6" translate="yes" xml:space="preserve">
          <source>If return_costs is True, the objective function and dual gap at each iteration are returned.</source>
          <target state="translated">return_costsがTrueの場合、各反復時の対物関数とデュアルギャップが返されます。</target>
        </trans-unit>
        <trans-unit id="3a07f641c209d2556442bcd652915ffb4ab857db" translate="yes" xml:space="preserve">
          <source>If safe is false, clone will fall back to a deep copy on objects that are not estimators.</source>
          <target state="translated">safeがfalseの場合、cloneは推定値ではないオブジェクトのディープコピーにフォールバックします。</target>
        </trans-unit>
        <trans-unit id="179d83839b7c246b21dd4fad6260ec3c338cc783" translate="yes" xml:space="preserve">
          <source>If seed is None, return the RandomState singleton used by np.random. If seed is an int, return a new RandomState instance seeded with seed. If seed is already a RandomState instance, return it. Otherwise raise ValueError.</source>
          <target state="translated">seedがNoneの場合、np.randomによって使用されるRandomStateのシングルトンを返します。seed が int の場合は、seed でシードされた新しい RandomState インスタンスを返します。seed が既に RandomState インスタンスである場合は、それを返します。それ以外の場合は ValueError を発生させます。</target>
        </trans-unit>
        <trans-unit id="7108bbb3c9ecad70c2ad038e49ece7ce906a1c8f" translate="yes" xml:space="preserve">
          <source>If seq[i] is an int or a tuple with one int value, a one-way PDP is created; if seq[i] is a tuple of two ints, a two-way PDP is created. If feature_names is specified and seq[i] is an int, seq[i] must be &amp;lt; len(feature_names). If seq[i] is a string, feature_names must be specified, and seq[i] must be in feature_names.</source>
          <target state="translated">seq [i]がintまたは1つのint値を持つタプルの場合、一方向PDPが作成されます。seq [i]が2つの整数のタプルである場合、双方向PDPが作成されます。feature_namesが指定され、seq [i]がintの場合、seq [i]は&amp;lt;len（feature_names）でなければなりません。seq [i]が文字列の場合、feature_namesを指定する必要があり、seq [i]はfeature_namesに含める必要があります。</target>
        </trans-unit>
        <trans-unit id="4c1ce6df0b81e7680bbf5092a9535a5fa0cb37a8" translate="yes" xml:space="preserve">
          <source>If set to &amp;ldquo;warn&amp;rdquo;, this acts as 0, but warnings are also raised.</source>
          <target state="translated">「警告」に設定すると、これは0として機能しますが、警告も発生します。</target>
        </trans-unit>
        <trans-unit id="b01ea458e6ed79ec076f21dd79564eecc3f7a882" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4</source>
          <target state="translated">「ランダム」に設定されている場合、ランダム係数は、デフォルトでフィーチャを順次ループするのではなく、反復ごとに更新されます。これ（「ランダム」に設定）は、特にtolが1e-4より大きい場合に、収束が大幅に速くなることがよくあります。</target>
        </trans-unit>
        <trans-unit id="7a4374896942a67a58d05d59133607fc7483d7a2" translate="yes" xml:space="preserve">
          <source>If set to &amp;lsquo;random&amp;rsquo;, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to &amp;lsquo;random&amp;rsquo;) often leads to significantly faster convergence especially when tol is higher than 1e-4.</source>
          <target state="translated">「ランダム」に設定されている場合、ランダム係数は、デフォルトでフィーチャを順次ループするのではなく、反復ごとに更新されます。これ（「ランダム」に設定）は、特にtolが1e-4より大きい場合に、収束が大幅に速くなることがよくあります。</target>
        </trans-unit>
        <trans-unit id="b3732982402454957d1d44e2700684220ba9b532" translate="yes" xml:space="preserve">
          <source>If set to &lt;code&gt;True&lt;/code&gt;, reuse the solution of the previous call to &lt;code&gt;fit&lt;/code&gt; as initialization for &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; .</source>
          <target state="translated">&lt;code&gt;True&lt;/code&gt; に設定されている場合は、前の呼び出しのソリューションを再利用して、 &lt;code&gt;coef_&lt;/code&gt; および &lt;code&gt;intercept_&lt;/code&gt; の初期化として &lt;code&gt;fit&lt;/code&gt; させます。</target>
        </trans-unit>
        <trans-unit id="d15f7a009cd3b6e81a757534913f0edc7a2b7947" translate="yes" xml:space="preserve">
          <source>If set to True, forces coefficients to be positive. (Only allowed when &lt;code&gt;y.ndim == 1&lt;/code&gt;).</source>
          <target state="translated">Trueに設定すると、係数が正になります。（ &lt;code&gt;y.ndim == 1&lt;/code&gt; 場合にのみ許可されます）。</target>
        </trans-unit>
        <trans-unit id="6bd31584b0a279bb6a357ab195ba9534cb5cad4e" translate="yes" xml:space="preserve">
          <source>If set to True, the scores are averaged across all folds, and the coefs and the C that corresponds to the best score is taken, and a final refit is done using these parameters. Otherwise the coefs, intercepts and C that correspond to the best scores across folds are averaged.</source>
          <target state="translated">Trueに設定されている場合、スコアはすべてのフォールドで平均化され、最良のスコアに対応するcoefsとCが取られ、これらのパラメータを使用して最終的な再フィットが行われます。そうでない場合は、ひだ全体で最高のスコアに対応するcoefs、切片、Cが平均化されます。</target>
        </trans-unit>
        <trans-unit id="f3d43f9f7c9e3af1ca6eddc0268b8ee91bb07ee3" translate="yes" xml:space="preserve">
          <source>If set, scikit-learn will attempt to limit the size of temporary arrays to this number of MiB (per job when parallelised), often saving both computation time and memory on expensive operations that can be performed in chunks. Global default: 1024.</source>
          <target state="translated">設定されている場合、scikit-learnは一時的な配列のサイズを(並列化されている場合はジョブごとに)この数のMiBに制限しようとします。グローバルデフォルトは1024です。</target>
        </trans-unit>
        <trans-unit id="cd9d66e1ab8be1fe689482ddb0cbca43b44a3950" translate="yes" xml:space="preserve">
          <source>If strictly positive, stop reading any new line of data once the position in the file has reached the (offset + length) bytes threshold.</source>
          <target state="translated">厳密に正の場合、ファイル内の位置が(オフセット+長さ)バイトのしきい値に達した時点で、データの新しい行の読み込みを停止します。</target>
        </trans-unit>
        <trans-unit id="af99c20b0f1015ebcecc8bfb6a50ca848ab08d15" translate="yes" xml:space="preserve">
          <source>If string, specifies the path that will contain the data. If file-like, data will be written to f. f should be opened in binary mode.</source>
          <target state="translated">文字列の場合は、データを格納するパスを指定します。ファイルライクな場合、データはfに書き込まれます。</target>
        </trans-unit>
        <trans-unit id="d25cbbfb18995acebbdc8e788e3994e16b21b8ae" translate="yes" xml:space="preserve">
          <source>If sum_over_features is False shape is (n_samples_X * n_samples_Y, n_features) and D contains the componentwise L1 pairwise-distances (ie. absolute difference), else shape is (n_samples_X, n_samples_Y) and D contains the pairwise L1 distances.</source>
          <target state="translated">sum_over_featuresがFalseの場合、形状は(n_samples_X*n_samples_Y,n_features)であり、Dは成分単位のL1のペアウィズ距離(すなわち絶対差)を含み、そうでない場合、形状は(n_samples_X,n_samples_Y)であり、DはペアウィズL1の距離を含む。</target>
        </trans-unit>
        <trans-unit id="1979731cc29c616c5ac5593ab888192599b2d46b" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;loss&lt;/code&gt; does not support probabilities.</source>
          <target state="translated">&lt;code&gt;loss&lt;/code&gt; が確率をサポートしていない場合。</target>
        </trans-unit>
        <trans-unit id="41f96f9118cd39448d94e68aca8aa6d327b368ef" translate="yes" xml:space="preserve">
          <source>If the algorithm is &amp;ldquo;deflation&amp;rdquo;, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge.</source>
          <target state="translated">アルゴリズムが「デフレ」の場合、n_iterはすべてのコンポーネントで実行される反復の最大数です。そうでなければ、それらは収束するために取られた反復の数です。</target>
        </trans-unit>
        <trans-unit id="b72ab6a8a780a6da86f798b7381c54dc2236b80c" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; of &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;means_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;means_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="translated">アルゴリズムが完全に収束する前に停止した場合（ &lt;code&gt;max_iter&lt;/code&gt; の &lt;code&gt;tol&lt;/code&gt; のため）、 &lt;code&gt;labels_&lt;/code&gt; と &lt;code&gt;means_&lt;/code&gt; は一致しません。つまり、 &lt;code&gt;means_&lt;/code&gt; は各クラスターのポイントの平均ではありません。また、推定器は、再割り当てされます &lt;code&gt;labels_&lt;/code&gt; を作るために、最後の反復後 &lt;code&gt;labels_&lt;/code&gt; はと一致 &lt;code&gt;predict&lt;/code&gt; トレーニングセットに。</target>
        </trans-unit>
        <trans-unit id="12008b7aa6dad452411115d8236f3a855fd0fea9" translate="yes" xml:space="preserve">
          <source>If the algorithm stops before fully converging (because of &lt;code&gt;tol&lt;/code&gt; or &lt;code&gt;max_iter&lt;/code&gt;), &lt;code&gt;labels_&lt;/code&gt; and &lt;code&gt;cluster_centers_&lt;/code&gt; will not be consistent, i.e. the &lt;code&gt;cluster_centers_&lt;/code&gt; will not be the means of the points in each cluster. Also, the estimator will reassign &lt;code&gt;labels_&lt;/code&gt; after the last iteration to make &lt;code&gt;labels_&lt;/code&gt; consistent with &lt;code&gt;predict&lt;/code&gt; on the training set.</source>
          <target state="translated">アルゴリズムが完全に収束する前に停止した場合（ &lt;code&gt;tol&lt;/code&gt; または &lt;code&gt;max_iter&lt;/code&gt; のため）、 &lt;code&gt;labels_&lt;/code&gt; と &lt;code&gt;cluster_centers_&lt;/code&gt; は一貫性がありません。つまり、 &lt;code&gt;cluster_centers_&lt;/code&gt; は各クラスター内のポイントの平均ではありません。また、推定器は、再割り当てされます &lt;code&gt;labels_&lt;/code&gt; を作るために、最後の反復後 &lt;code&gt;labels_&lt;/code&gt; はと一致 &lt;code&gt;predict&lt;/code&gt; トレーニングセットに。</target>
        </trans-unit>
        <trans-unit id="4043c787702cc081c41f25b031d69ea98cf35c42" translate="yes" xml:space="preserve">
          <source>If the array is not symmetric, then a symmetrized version is returned. Optionally, a warning or exception is raised if the matrix is not symmetric.</source>
          <target state="translated">配列が対称でない場合は,対称化されたものが返されます.オプションとして,行列が対称でない場合には警告や例外が発生します.</target>
        </trans-unit>
        <trans-unit id="d4238935d45ce51eea0be6c47146a609e05c26ed" translate="yes" xml:space="preserve">
          <source>If the attributes are not found.</source>
          <target state="translated">属性が見つからない場合</target>
        </trans-unit>
        <trans-unit id="10f86bc0a8ef8d94dd88200305e21d6ac290743f" translate="yes" xml:space="preserve">
          <source>If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).</source>
          <target state="translated">分類器がどちらのクラスでも同じように良好な性能を発揮する場合、この項は従来の精度(すなわち、正しい予測値の数を予測値の総数で割った数)を低下させる。</target>
        </trans-unit>
        <trans-unit id="9d0651dbf433477af9dfe8c9482b03c0b28a7aea" translate="yes" xml:space="preserve">
          <source>If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples.</source>
          <target state="translated">データの順序が任意でない場合(例えば、同じクラスラベルを持つサンプルが連続しているなど)、意味のある交差検証結果を得るためには、最初にデータをシャッフルすることが必要不可欠かもしれません。しかし、サンプルが独立して同じように分布していない場合は、逆のこともあります。例えば、サンプルがニュース記事に対応しており、掲載時期順に並べられている場合、データをシャッフルすると、モデルがオーバーフィットし、検証スコアが高くなる可能性があります:学習サンプルと人為的に似ている(時間的に近い)サンプルでテストされます。</target>
        </trans-unit>
        <trans-unit id="4fdc5debb409dcec7a673c288152f0ef6e4738ef" translate="yes" xml:space="preserve">
          <source>If the default value is passed, then &lt;code&gt;keepdims&lt;/code&gt; will not be passed through to the &lt;code&gt;mean&lt;/code&gt; method of sub-classes of &lt;code&gt;ndarray&lt;/code&gt;, however any non-default value will be. If the sub-class&amp;rsquo; method does not implement &lt;code&gt;keepdims&lt;/code&gt; any exceptions will be raised.</source>
          <target state="translated">デフォルト値が渡された場合、その後、 &lt;code&gt;keepdims&lt;/code&gt; はに渡されることはありません &lt;code&gt;mean&lt;/code&gt; のサブクラスの方法 &lt;code&gt;ndarray&lt;/code&gt; 、しかし、任意のデフォルト以外の値になります。サブクラスのメソッドが &lt;code&gt;keepdims&lt;/code&gt; を実装しない場合、例外が発生します。</target>
        </trans-unit>
        <trans-unit id="322da3aec4cc8f30cb7592a5692203180007e581" translate="yes" xml:space="preserve">
          <source>If the degree is 2 or 3, the method described in &amp;ldquo;Leveraging Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices Using K-Simplex Numbers&amp;rdquo; by Andrew Nystrom and John Hughes is used, which is much faster than the method used on CSC input. For this reason, a CSC input will be converted to CSR, and the output will be converted back to CSC prior to being returned, hence the preference of CSR.</source>
          <target state="translated">次数が2または3の場合、AndrewNystromとJohnHughesによる「K-シンプレックス数を使用したCSR行列の多項式特徴拡張を高速化するためのスパース性の活用」で説明されている方法が使用されます。これはCSC入力で使用される方法よりもはるかに高速です。 。このため、CSC入力はCSRに変換され、出力は返される前にCSCに変換されます。したがって、CSRが優先されます。</target>
        </trans-unit>
        <trans-unit id="ca5777d1057fb92ff835301c12f93dc71bd51069" translate="yes" xml:space="preserve">
          <source>If the difference between the current prediction and the correct label is below this threshold, the model is not updated.</source>
          <target state="translated">現在の予測値と正しいラベルの差がこの閾値を下回る場合、モデルは更新されません。</target>
        </trans-unit>
        <trans-unit id="54f187a0c12dbeb2b22455f8308653334a568512" translate="yes" xml:space="preserve">
          <source>If the estimator supports incremental learning, this will be used to speed up fitting for different training set sizes.</source>
          <target state="translated">エスティメー タが増分学習をサポートしている場合は、これを使用して、異なる訓練セットサイズに対するフィッティングを高速化します。</target>
        </trans-unit>
        <trans-unit id="28446974a089033b0f005a14dd2e5e7cde0d019d" translate="yes" xml:space="preserve">
          <source>If the file does not exist yet, it is downloaded from mldata.org .</source>
          <target state="translated">ファイルがまだ存在しない場合は、mldata.orgからダウンロードします。</target>
        </trans-unit>
        <trans-unit id="3377386ec971b5f97505ad0b0efacd641307a6b2" translate="yes" xml:space="preserve">
          <source>If the folder does not already exist, it is automatically created.</source>
          <target state="translated">フォルダがまだ存在しない場合は、自動的に作成されます。</target>
        </trans-unit>
        <trans-unit id="bcf86cd76452a354a39a384d6cc008f0521fadc0" translate="yes" xml:space="preserve">
          <source>If the gradient norm is below this threshold, the optimization will be stopped.</source>
          <target state="translated">勾配ノルムがこのしきい値以下の場合、最適化を停止します。</target>
        </trans-unit>
        <trans-unit id="aaea0ac91de1101ebb5583d72a39edadc546a9ed" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (&lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt;&lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt;&lt;/a&gt;) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:</source>
          <target state="translated">グラウンドトゥルースラベルが不明な場合は、モデル自体を使用して評価を実行する必要があります。シルエット係数（&lt;a href=&quot;generated/sklearn.metrics.silhouette_score#sklearn.metrics.silhouette_score&quot;&gt; &lt;code&gt;sklearn.metrics.silhouette_score&lt;/code&gt; &lt;/a&gt;）はそのような評価の例であり、より高いシルエット係数スコアは、より適切に定義されたクラスターを持つモデルに関連しています。シルエット係数はサンプルごとに定義され、2つのスコアで構成されます。</target>
        </trans-unit>
        <trans-unit id="f86f2c18ff62eced8e4c69ce5c4a60d3487f70e2" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabasz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabasz_score#sklearn.metrics.calinski_harabasz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabasz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabasz score relates to a model with better defined clusters.</source>
          <target state="translated">グラウンドトゥルースラベルが不明な場合は、Calinski-Harabaszインデックス（&lt;a href=&quot;generated/sklearn.metrics.calinski_harabasz_score#sklearn.metrics.calinski_harabasz_score&quot;&gt; &lt;code&gt;sklearn.metrics.calinski_harabasz_score&lt;/code&gt; &lt;/a&gt;）（分散比基準とも呼ばれます）を使用してモデルを評価できます。Calinski-Harabaszスコアが高いほど、より適切に定義されたクラスター。</target>
        </trans-unit>
        <trans-unit id="bb3f5944370bdcf362ff4bffb46e8bf1ded41ef1" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Calinski-Harabaz index (&lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt;&lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt;&lt;/a&gt;) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.</source>
          <target state="translated">グラウンドトゥルースラベルが不明な場合、Calinski-Harabazインデックス（&lt;a href=&quot;generated/sklearn.metrics.calinski_harabaz_score#sklearn.metrics.calinski_harabaz_score&quot;&gt; &lt;code&gt;sklearn.metrics.calinski_harabaz_score&lt;/code&gt; &lt;/a&gt;）（別名分散比基準）を使用してモデルを評価できます。この場合、Calinski-Harabazスコアが高いモデルは、より適切に定義されたクラスター。</target>
        </trans-unit>
        <trans-unit id="a4a519d35f95c18e319df7e8878b98f013f9bd44" translate="yes" xml:space="preserve">
          <source>If the ground truth labels are not known, the Davies-Bouldin index (&lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt;&lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt;&lt;/a&gt;) can be used to evaluate the model, where a lower Davies-Bouldin index relates to a model with better separation between the clusters.</source>
          <target state="translated">グラウンドトゥルースラベルが不明な場合は、Davies-Bouldinインデックス（&lt;a href=&quot;generated/sklearn.metrics.davies_bouldin_score#sklearn.metrics.davies_bouldin_score&quot;&gt; &lt;code&gt;sklearn.metrics.davies_bouldin_score&lt;/code&gt; &lt;/a&gt;）を使用してモデルを評価できます。Davies -Bouldinインデックスが低いほど、クラスター間の分離が良好なモデルに関連します。</target>
        </trans-unit>
        <trans-unit id="7ce6861d9ec6948a6bc8aef858e97abae7ed0654" translate="yes" xml:space="preserve">
          <source>If the input is a sparse matrix, only the non-zero values are subject to update by the Binarizer class.</source>
          <target state="translated">入力が疎な行列の場合,Binarizer クラスによって更新されるのは,0 ではない値のみです.</target>
        </trans-unit>
        <trans-unit id="c10a8d9d8c40f9f50dafe36b727f5b47e7075f19" translate="yes" xml:space="preserve">
          <source>If the input matrix X is very sparse, it is recommended to convert to sparse &lt;code&gt;csc_matrix&lt;/code&gt; before calling fit and sparse &lt;code&gt;csr_matrix&lt;/code&gt; before calling predict. Training time can be orders of magnitude faster for a sparse matrix input compared to a dense matrix when features have zero values in most of the samples.</source>
          <target state="translated">入力行列Xは非常に希薄である場合には、スパースに変換することが推奨され &lt;code&gt;csc_matrix&lt;/code&gt; フィット感とスパース呼び出す前に &lt;code&gt;csr_matrix&lt;/code&gt; を予測呼び出す前に。ほとんどのサンプルでフィーチャの値がゼロの場合、疎行列入力の方が密行列と比較して、トレーニング時間が数桁速くなります。</target>
        </trans-unit>
        <trans-unit id="661cb29a3f5fe68fda8ea5f8c53273efb7753ce1" translate="yes" xml:space="preserve">
          <source>If the labels are encoded with +1 and -1, \(y\): is the true value, and \(w\) is the predicted decisions as output by &lt;code&gt;decision_function&lt;/code&gt;, then the hinge loss is defined as:</source>
          <target state="translated">ラベルが+1と-1でエンコードされている場合、\（y \）：は真の値であり、\（w \）はDecision_functionの出力として予測される &lt;code&gt;decision_function&lt;/code&gt; である場合、ヒンジ損失は次のように定義されます。</target>
        </trans-unit>
        <trans-unit id="30e7605353fedb22ff0c25c7418abbab28137e70" translate="yes" xml:space="preserve">
          <source>If the loss on a sample is greater than the &lt;code&gt;residual_threshold&lt;/code&gt;, then this sample is classified as an outlier.</source>
          <target state="translated">サンプルの損失が &lt;code&gt;residual_threshold&lt;/code&gt; より大きい場合、このサンプルは外れ値として分類されます。</target>
        </trans-unit>
        <trans-unit id="fd47c1f065810b1b45f0d8d994aa0a4ff29505d4" translate="yes" xml:space="preserve">
          <source>If the metric constructor parameter is &amp;ldquo;precomputed&amp;rdquo;, X is assumed to be the distance matrix between the data to be predicted and &lt;code&gt;self.centroids_&lt;/code&gt;.</source>
          <target state="translated">メトリックコンストラクターパラメーターが「事前計算」されている場合、Xは予測されるデータと &lt;code&gt;self.centroids_&lt;/code&gt; の間の距離行列であると見なされます。</target>
        </trans-unit>
        <trans-unit id="c8476d320358236ab03a9b2e5775d6207658d4f7" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row.</source>
          <target state="translated">メトリックが「事前計算」されている場合、Xは平方距離行列でなければなりません。それ以外の場合は、行ごとのサンプルが含まれます。</target>
        </trans-unit>
        <trans-unit id="ed2846275337b6c05f70ce353bc177c3fd2fc1b0" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;.</source>
          <target state="translated">メトリックが「事前計算」されている場合、Xは平方距離行列でなければなりません。それ以外の場合は、行ごとのサンプルが含まれます。メソッドが 'exact'の場合、Xは 'csr'、 'csc'、または 'coo'タイプのスパース行列になります。</target>
        </trans-unit>
        <trans-unit id="3a27e115b0c223dd4eebc69d8c1ee49334684c4e" translate="yes" xml:space="preserve">
          <source>If the metric is &amp;lsquo;precomputed&amp;rsquo; X must be a square distance matrix. Otherwise it contains a sample per row. If the method is &amp;lsquo;exact&amp;rsquo;, X may be a sparse matrix of type &amp;lsquo;csr&amp;rsquo;, &amp;lsquo;csc&amp;rsquo; or &amp;lsquo;coo&amp;rsquo;. If the method is &amp;lsquo;barnes_hut&amp;rsquo; and the metric is &amp;lsquo;precomputed&amp;rsquo;, X may be a precomputed sparse graph.</source>
          <target state="translated">メトリックが「事前計算」されている場合、Xは二乗距離行列でなければなりません。それ以外の場合は、行ごとのサンプルが含まれます。メソッドが「exact」の場合、Xは「csr」、「csc」、または「coo」タイプのスパース行列である可能性があります。メソッドが「barnes_hut」で、メトリックが「事前計算済み」の場合、Xは事前計算済みのスパースグラフである可能性があります。</target>
        </trans-unit>
        <trans-unit id="be2b4ccc2ee21bcc622b72ad8a09e29905f86d22" translate="yes" xml:space="preserve">
          <source>If the number of features is \(p\), you now require \(n \sim 1/d^p\) points. Let&amp;rsquo;s say that we require 10 points in one dimension: now \(10^p\) points are required in \(p\) dimensions to pave the \([0, 1]\) space. As \(p\) becomes large, the number of training points required for a good estimator grows exponentially.</source>
          <target state="translated">特徴の数が\（p \）の場合、\（n \ sim 1 / d ^ p \）ポイントが必要になります。1次元で10ポイントが必要であるとしましょう。\（[0、1] \）スペースを舗装するには、\（p \）次元で\（10 ^ p \）ポイントが必要です。\（p \）が大きくなると、優れた推定量に必要なトレーニングポイントの数は指数関数的に増加します。</target>
        </trans-unit>
        <trans-unit id="31f6fadae8fdb5e25318685f0dd36c90a3234b90" translate="yes" xml:space="preserve">
          <source>If the number of features is much greater than the number of samples, avoid over-fitting in choosing &lt;a href=&quot;#svm-kernels&quot;&gt;Kernel functions&lt;/a&gt; and regularization term is crucial.</source>
          <target state="translated">特徴の数がサンプルの数よりもはるかに多い場合は、&lt;a href=&quot;#svm-kernels&quot;&gt;カーネル関数&lt;/a&gt;を選択する際の過剰適合を避けてください。正則化の用語は重要です。</target>
        </trans-unit>
        <trans-unit id="421f2017551080d266c05ad587f0ba1ecff6bff8" translate="yes" xml:space="preserve">
          <source>If the number of instances of data needs to be reduced, or if one wants a large number of subclusters either as a preprocessing step or otherwise, Birch is more useful than MiniBatchKMeans.</source>
          <target state="translated">データのインスタンス数を減らす必要がある場合や、前処理のステップとして、あるいはそうでない場合に、多数のサブクラスタを必要とする場合には、MiniBatchKMeansよりもBirchの方が便利です。</target>
        </trans-unit>
        <trans-unit id="0169ea68b458a3b315ac7acca32e943f8bdb1bed" translate="yes" xml:space="preserve">
          <source>If the option chosen is &amp;lsquo;ovr&amp;rsquo;, then a binary problem is fit for each label. For &amp;lsquo;multinomial&amp;rsquo; the loss minimised is the multinomial loss fit across the entire probability distribution, &lt;em&gt;even when the data is binary&lt;/em&gt;. &amp;lsquo;multinomial&amp;rsquo; is unavailable when solver=&amp;rsquo;liblinear&amp;rsquo;. &amp;lsquo;auto&amp;rsquo; selects &amp;lsquo;ovr&amp;rsquo; if the data is binary, or if solver=&amp;rsquo;liblinear&amp;rsquo;, and otherwise selects &amp;lsquo;multinomial&amp;rsquo;.</source>
          <target state="translated">選択したオプションが 'ovr'の場合、バイナリ問題は各ラベルに適合します。「多項式」の場合、最小化される損失は&lt;em&gt;、データがバイナリの場合でも、&lt;/em&gt;確率分布全体に当てはまる多項式損失です。'multinomial'は、solver = 'liblinear'の場合は使用できません。'auto'は、データがバイナリの場合、またはsolver = 'liblinear'の場合は 'ovr'を選択し、それ以外の場合は 'multinomial'を選択します。</target>
        </trans-unit>
        <trans-unit id="e56253ed1e137739144617c8f91af1433e314b57" translate="yes" xml:space="preserve">
          <source>If the output of the different transformers contains sparse matrices, these will be stacked as a sparse matrix if the overall density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all dense data, the stacked result will be dense, and this keyword will be ignored.</source>
          <target state="translated">異なるトランスの出力にスパース行列が含まれている場合、全体の密度がこの値よりも低いと、これらはスパース行列としてスタックされます。常に密を返すには、 &lt;code&gt;sparse_threshold=0&lt;/code&gt; を使用します。変換された出力がすべての密なデータで構成されている場合、スタックされた結果は密になり、このキーワードは無視されます。</target>
        </trans-unit>
        <trans-unit id="1ff404c7c7b751e78382edbf95c1647019d00b38" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s type does not match the desired type.</source>
          <target state="translated">パラメータのタイプが目的のタイプと一致しない場合。</target>
        </trans-unit>
        <trans-unit id="74c8a6dddf7307f96841c8e0079e93341eb05526" translate="yes" xml:space="preserve">
          <source>If the parameter&amp;rsquo;s value violates the given bounds.</source>
          <target state="translated">パラメータの値が指定された範囲に違反している場合。</target>
        </trans-unit>
        <trans-unit id="fb7bde2a134f67333f646adb3cb422fdb3b0a619" translate="yes" xml:space="preserve">
          <source>If the prediction task is to classify the observations in a set of finite labels, in other words to &amp;ldquo;name&amp;rdquo; the objects observed, the task is said to be a &lt;strong&gt;classification&lt;/strong&gt; task. On the other hand, if the goal is to predict a continuous target variable, it is said to be a &lt;strong&gt;regression&lt;/strong&gt; task.</source>
          <target state="translated">予測タスクが観測値を一連の有限ラベルに分類すること、つまり観測されたオブジェクトに「名前を付ける」ことである場合、そのタスクは&lt;strong&gt;分類&lt;/strong&gt;タスクと呼ばれます。一方、目標が連続的なターゲット変数を予測することである場合、これは&lt;strong&gt;回帰&lt;/strong&gt;タスクと呼ばれます。</target>
        </trans-unit>
        <trans-unit id="c305135e1b17987e86652a7910deafacf0f5dc9d" translate="yes" xml:space="preserve">
          <source>If the pyamg package is installed, it is used: this greatly speeds up computation.</source>
          <target state="translated">pyamgパッケージがインストールされている場合は、それを使用します。</target>
        </trans-unit>
        <trans-unit id="04f07265ff7d7b70145be5aec52784e1b24d6f09" translate="yes" xml:space="preserve">
          <source>If the radius of the subcluster obtained by merging the new sample and the nearest subcluster is greater than the square of the threshold and if the number of subclusters is greater than the branching factor, then a space is temporarily allocated to this new sample. The two farthest subclusters are taken and the subclusters are divided into two groups on the basis of the distance between these subclusters.</source>
          <target state="translated">新しいサンプルと最も近いサブクラスターをマージして得られたサブクラスターの半径が閾値の二乗よりも大きく、サブクラスターの数が分岐係数よりも大きい場合には、この新しいサンプルに一時的にスペースが割り当てられる。最も遠い2つのサブクラスターを取り、これらのサブクラスター間の距離に基づいてサブクラスターを2つのグループに分割する。</target>
        </trans-unit>
        <trans-unit id="41eef1b8a501219131b2619b097a82294e78c28a" translate="yes" xml:space="preserve">
          <source>If the samples are weighted, it will be easier to optimize the tree structure using weight-based pre-pruning criterion such as &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt;, which ensure that leaf nodes contain at least a fraction of the overall sum of the sample weights.</source>
          <target state="translated">サンプルに重みが付けられている場合は、 &lt;code&gt;min_weight_fraction_leaf&lt;/code&gt; などの重みベースの事前剪定基準を使用してツリー構造を最適化する方が簡単です。これにより、リーフノードに少なくともサンプルの重みの合計の一部が含まれるようになります。</target>
        </trans-unit>
        <trans-unit id="0c1baaebbfab363e25ace0c6b6ee91539fab116b" translate="yes" xml:space="preserve">
          <source>If the selected solver is &amp;lsquo;L-BFGS&amp;rsquo;, training does not support online nor mini-batch learning.</source>
          <target state="translated">選択したソルバーが「L-BFGS」の場合、トレーニングはオンライン学習もミニバッチ学習もサポートしていません。</target>
        </trans-unit>
        <trans-unit id="6b79b273c5ccf0e85d810ff5a4ad56e9102a13be" translate="yes" xml:space="preserve">
          <source>If the target is a continuous value, then for node \(m\), representing a region \(R_m\) with \(N_m\) observations, common criteria to minimise as for determining locations for future splits are Mean Squared Error, which minimizes the L2 error using mean values at terminal nodes, and Mean Absolute Error, which minimizes the L1 error using median values at terminal nodes.</source>
          <target state="translated">目標が連続値であれば、将来の分割位置を決定するための共通の基準は、端末ノードの平均値を用いてL2の誤差を最小化するMean Squared Errorと、端末ノードの中央値を用いてL1の誤差を最小化するMean Absolute Errorである。</target>
        </trans-unit>
        <trans-unit id="43d2fac91a90af78192c1e9cb5f608e633304262" translate="yes" xml:space="preserve">
          <source>If the target values \(y\) are counts (non-negative integer valued) or relative frequencies (non-negative), you might use a Poisson deviance with log-link.</source>
          <target state="translated">目標値\(y)がカウント(非負の整数値)や相対度数(非負)であれば、対数リンク付きのポアソンデビアンスを使うことができます。</target>
        </trans-unit>
        <trans-unit id="25b233fcf730d262746a1d2c5c4f20ca63e89053" translate="yes" xml:space="preserve">
          <source>If the target values are positive valued and skewed, you might try a Gamma deviance with log-link.</source>
          <target state="translated">目標値が正の値でスキューがある場合は、ログリンクを使ってガンマ・ディビアンスを試してみるといいかもしれません。</target>
        </trans-unit>
        <trans-unit id="73b808b1b5912c4df231c6d6d8790651299cc5e0" translate="yes" xml:space="preserve">
          <source>If the target values seem to be heavier tailed than a Gamma distribution, you might try an Inverse Gaussian deviance (or even higher variance powers of the Tweedie family).</source>
          <target state="translated">目標値がガンマ分布よりも重い尾を引いているようであれば、逆ガウスのディビアンス(またはTweedieファミリーのより高い分散乗)を試してみるとよいでしょう。</target>
        </trans-unit>
        <trans-unit id="bd360b0d17d9758c91116a373249c96c3c493365" translate="yes" xml:space="preserve">
          <source>If the text is in a mish-mash of encodings that is simply too hard to sort out (which is the case for the 20 Newsgroups dataset), you can fall back on a simple single-byte encoding such as &lt;code&gt;latin-1&lt;/code&gt;. Some text may display incorrectly, but at least the same sequence of bytes will always represent the same feature.</source>
          <target state="translated">テキストが単純に整理するのが非常に難しいエンコーディングの寄せ集めに含まれている場合（20ニュースグループデータセットの場合）、 &lt;code&gt;latin-1&lt;/code&gt; などの単純なシングルバイトエンコーディングに頼ることができます。一部のテキストは正しく表示されない場合がありますが、少なくとも同じバイトシーケンスは常に同じ機能を表します。</target>
        </trans-unit>
        <trans-unit id="21286b430a50cd4c4f50df67c996d4b5b475416f" translate="yes" xml:space="preserve">
          <source>If the text you are loading is not actually encoded with UTF-8, however, you will get a &lt;code&gt;UnicodeDecodeError&lt;/code&gt;. The vectorizers can be told to be silent about decoding errors by setting the &lt;code&gt;decode_error&lt;/code&gt; parameter to either &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; or &lt;code&gt;&quot;replace&quot;&lt;/code&gt;. See the documentation for the Python function &lt;code&gt;bytes.decode&lt;/code&gt; for more details (type &lt;code&gt;help(bytes.decode)&lt;/code&gt; at the Python prompt).</source>
          <target state="translated">ロードするテキストが実際にUTF-8でエンコードされていない場合は、 &lt;code&gt;UnicodeDecodeError&lt;/code&gt; が発生します。 &lt;code&gt;decode_error&lt;/code&gt; は、decode_errorパラメーターを &lt;code&gt;&quot;ignore&quot;&lt;/code&gt; または &lt;code&gt;&quot;replace&quot;&lt;/code&gt; のいずれかに設定することにより、デコードエラーについてサイレントにすることができます。詳細については、Python関数 &lt;code&gt;bytes.decode&lt;/code&gt; のドキュメントを参照してください（Pythonプロンプトで &lt;code&gt;help(bytes.decode)&lt;/code&gt; と入力してください）。</target>
        </trans-unit>
        <trans-unit id="13a9f813159d9e6258a164870cb1dc6a301dddd5" translate="yes" xml:space="preserve">
          <source>If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be found in the plot below where we vary the parameter \(\gamma\) of an SVM on the digits dataset.</source>
          <target state="translated">トレーニングスコアとバリデーションスコアの両方が低い場合、推定器はアンダーフィッティングになります。トレーニングスコアが高く、バリデーションスコアが低い場合、推定器はオーバーフィットしており、それ以外の場合は非常にうまく機能しています。トレーニングスコアが低く、バリデーションスコアが高い場合は、通常は不可能です。この3つのケースはすべて、数字データセット上でSVMのパラメータ\(Gamma)を変化させたプロットにあります。</target>
        </trans-unit>
        <trans-unit id="80e789647361ff21671194a00300fe312dc530d2" translate="yes" xml:space="preserve">
          <source>If the transformed output consists of a mix of sparse and dense data, it will be stacked as a sparse matrix if the density is lower than this value. Use &lt;code&gt;sparse_threshold=0&lt;/code&gt; to always return dense. When the transformed output consists of all sparse or all dense data, the stacked result will be sparse or dense, respectively, and this keyword will be ignored.</source>
          <target state="translated">変換された出力が疎データと密データの混合で構成されている場合、密度がこの値よりも低いと、疎行列として積み重ねられます。常に密に戻すには、 &lt;code&gt;sparse_threshold=0&lt;/code&gt; を使用します。変換された出力がすべてスパースデータまたはすべてデンスデータで構成される場合、スタックされた結果はそれぞれスパースまたはデンスとなり、このキーワードは無視されます。</target>
        </trans-unit>
        <trans-unit id="efca83041c066057e65d83989c4190b74b69dba6" translate="yes" xml:space="preserve">
          <source>If the underlying graph has nodes with much more connections than the average node, the algorithm will miss some of these connections.</source>
          <target state="translated">基礎となるグラフに平均ノードよりもはるかに多くの接続を持つノードがある場合、アルゴリズムはこれらの接続の一部を見逃してしまいます。</target>
        </trans-unit>
        <trans-unit id="27f470c8c1d74aa01f92e63860f4d2b9149dd0bb" translate="yes" xml:space="preserve">
          <source>If there are few data points per dimension, noise in the observations induces high variance:</source>
          <target state="translated">次元あたりのデータ点が少ない場合,オブザベーションのノイズが高い分散を引き起こす.</target>
        </trans-unit>
        <trans-unit id="fbaec65eed1139944f6f906201326eaef7bc4d08" translate="yes" xml:space="preserve">
          <source>If there are more than two classes, \(f(x)\) itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as,</source>
          <target state="translated">クラスが2つ以上ある場合は、\(f(x)mm)自体がサイズ(n_classes,)のベクトルになります。ロジスティック関数を通さずに、ソフトマックス関数を通します。</target>
        </trans-unit>
        <trans-unit id="e2c9b002eac60ce02e4a3cafb47196266855c43e" translate="yes" xml:space="preserve">
          <source>If there are more than two labels, &lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt;&lt;code&gt;hinge_loss&lt;/code&gt;&lt;/a&gt; uses a multiclass variant due to Crammer &amp;amp; Singer. &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;Here&lt;/a&gt; is the paper describing it.</source>
          <target state="translated">ラベルが3つ以上ある場合、&lt;a href=&quot;generated/sklearn.metrics.hinge_loss#sklearn.metrics.hinge_loss&quot;&gt; &lt;code&gt;hinge_loss&lt;/code&gt; &lt;/a&gt;＆SingerによるHinge_lossはマルチクラスバリアントを使用します。&lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf&quot;&gt;ここでは&lt;/a&gt;それについての論文があります。</target>
        </trans-unit>
        <trans-unit id="362b6e0ad023f937918b9ce5c294c8243f2c8ea1" translate="yes" xml:space="preserve">
          <source>If there is a possibility that the training data might have missing categorical features, it can often be better to specify &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; instead of setting the &lt;code&gt;categories&lt;/code&gt; manually as above. When &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros (&lt;code&gt;handle_unknown='ignore'&lt;/code&gt; is only supported for one-hot encoding):</source>
          <target state="translated">トレーニングデータにカテゴリ特徴が欠落している可能性がある場合は、上記のように手動で &lt;code&gt;categories&lt;/code&gt; を設定 &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; なく、handle_unknown = 'ignore'を指定した方がよい場合があります。とき &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; に指定され、未知のカテゴリは変換中に発生し、エラーは発生しませんが、この機能の結果としてワンホットエンコードされた列は、（すべてゼロになります &lt;code&gt;handle_unknown='ignore'&lt;/code&gt; 唯一のワンホットエンコーディングのためにサポートされています）：</target>
        </trans-unit>
        <trans-unit id="76c3aee0f8dcd7757eeddd2a91b271bc2108fb17" translate="yes" xml:space="preserve">
          <source>If there is more than one such value, only the first is returned. The bin-count for the modal bins is also returned.</source>
          <target state="translated">このような値が複数ある場合は、最初の値だけが返されます。モーダルビンのビンカウントも返されます。</target>
        </trans-unit>
        <trans-unit id="e4599c6e53b844db2376ed9e56ed7b49e63c6ec3" translate="yes" xml:space="preserve">
          <source>If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before.</source>
          <target state="translated">これがintのタプルである場合、以前のように1つの軸またはすべての軸ではなく、複数の軸に渡って平均が実行されます。</target>
        </trans-unit>
        <trans-unit id="015e500928e7c3f86f2c9b5121c746246fcd7a9f" translate="yes" xml:space="preserve">
          <source>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.</source>
          <target state="translated">これが True に設定されている場合、縮小された軸はサイズ 1 の寸法として結果に残されます。このオプションを指定すると、結果は入力配列に対して正しくブロードキャストされます。</target>
        </trans-unit>
        <trans-unit id="1d47783a4de427039b4db643f305b3dd195e7ba2" translate="yes" xml:space="preserve">
          <source>If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root.</source>
          <target state="translated">この分割ノードに親サブクラスターがあり、新しいサブクラスターを作成する余地がある場合、親サブクラスターを2つに分割します。もし空きがなければ、このノードは再び2つに分割され、処理はルートに到達するまで再帰的に続けられます。</target>
        </trans-unit>
        <trans-unit id="012f5a7e85e6e4a424dae20b5f0c103c4fa516ee" translate="yes" xml:space="preserve">
          <source>If true (default), use a breadth-first approach to the problem. Otherwise use a depth-first approach.</source>
          <target state="translated">true (デフォルト)の場合、問題に対して幅優先のアプローチを使用します。そうでない場合は、深さ優先のアプローチを使用します。</target>
        </trans-unit>
        <trans-unit id="5f57fd46a52f081b17c9c11ebb2ef30582e94549" translate="yes" xml:space="preserve">
          <source>If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.</source>
          <target state="translated">trueの場合、分類重みは各リーフにエクスポートされます。分類重みは、各クラスのサンプル数です。</target>
        </trans-unit>
        <trans-unit id="cec7c6586dbaf8eb8cda6633d2caddbd361cde5b" translate="yes" xml:space="preserve">
          <source>If true, &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt;, and number of classes &amp;gt; 2, &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;predict&lt;/a&gt; will break ties according to the confidence values of &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_function&lt;/a&gt;; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.</source>
          <target state="translated">trueの場合、 &lt;code&gt;decision_function_shape='ovr'&lt;/code&gt; 、およびクラス&amp;gt; 2の数は、&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-predict&quot;&gt;予測&lt;/a&gt;の信頼値に応じ絆壊れる&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-decision-function&quot;&gt;decision_functionを&lt;/a&gt;。それ以外の場合は、タイクラスの最初のクラスが返されます。関係を断ち切るには、単純な予測と比較して比較的高い計算コストがかかることに注意してください。</target>
        </trans-unit>
        <trans-unit id="8002efc50268110232cc0ffbdad97c50440caadd" translate="yes" xml:space="preserve">
          <source>If true, X and y will be centered.</source>
          <target state="translated">真の場合、Xとyは中央に配置されます。</target>
        </trans-unit>
        <trans-unit id="de73b79cb6d725781d21d3fce59be150e3f40a4c" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. Ignored if seeds argument is not None.</source>
          <target state="translated">真の場合、初期カーネルの位置はすべての点の位置ではなく、むしろ離散化された点の位置となります。このオプションをTrueに設定すると、初期化されるシード数が少なくなるため、アルゴリズムが高速化されます。seeds 引数が None でない場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="8e21ac3d3be6bbf299e61e387ddc28e4aa0e4b76" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. The default value is False. Ignored if seeds argument is not None.</source>
          <target state="translated">真の場合、初期カーネルの位置はすべての点の位置ではなく、むしろ離散化された点の位置となります。このオプションをTrueに設定すると、初期化されるシードの数が少なくなるため、アルゴリズムが高速化されます。デフォルト値は False です.seeds 引数が None でない場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="382a329c7d03e3dc0838d8f846116bb309725e41" translate="yes" xml:space="preserve">
          <source>If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. default value: False Ignored if seeds argument is not None.</source>
          <target state="translated">真の場合、初期カーネルの位置はすべての点の位置ではなく、むしろ離散化された点の位置となります。このオプションをTrueに設定すると、初期化されるシード数が少なくなるため、アルゴリズムが高速化されます。False seeds 引数が None でない場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="5f8f1503f4ad4447aabcfddb9ab2a5dcd7bfde79" translate="yes" xml:space="preserve">
          <source>If true, only interaction features are produced: features that are products of at most &lt;code&gt;degree&lt;/code&gt;&lt;em&gt;distinct&lt;/em&gt; input features (so not &lt;code&gt;x[1] ** 2&lt;/code&gt;, &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt;, etc.).</source>
          <target state="translated">trueの場合、唯一の相互作用の特徴が生成される：最大での生成物である特徴 &lt;code&gt;degree&lt;/code&gt; &lt;em&gt;の異なる&lt;/em&gt;入力フィーチャ（そうではない &lt;code&gt;x[1] ** 2&lt;/code&gt; 、 &lt;code&gt;x[0] * x[2] ** 3&lt;/code&gt; 、など）。</target>
        </trans-unit>
        <trans-unit id="2d6ce18ffe19be253728c95b7f8882b85215b418" translate="yes" xml:space="preserve">
          <source>If true, randomize the order of coordinates in the CD solver.</source>
          <target state="translated">true の場合、CD ソルバーの座標の順序をランダムにします。</target>
        </trans-unit>
        <trans-unit id="c9d7c7ecbdd08be425848806cc6f9d68c29d7323" translate="yes" xml:space="preserve">
          <source>If true, return the mean loss per sample. Otherwise, return the sum of the per-sample losses.</source>
          <target state="translated">真の場合、サンプルごとの平均損失を返します。そうでなければ、サンプルごとの損失の合計を返します。</target>
        </trans-unit>
        <trans-unit id="6d32e9cabd3e10e0279ad9dd2b7c71514057bf52" translate="yes" xml:space="preserve">
          <source>If true, then all points are clustered, even those orphans that are not within any kernel. Orphans are assigned to the nearest kernel. If false, then orphans are given cluster label -1.</source>
          <target state="translated">もし真であれば、どのカーネル内にもないオーファンであっても、すべての点がクラスタ化されます。孤児は最も近いカーネルに割り当てられます。falseの場合、オーファンにはクラスタラベル-1が与えられます。</target>
        </trans-unit>
        <trans-unit id="87535a59e28d16a49b32c83a6882f2aefd67503d" translate="yes" xml:space="preserve">
          <source>If true, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.</source>
          <target state="translated">真の場合は、二重木アルゴリズムを使用します。そうでなければ、シングルツリーアルゴリズムを使用します。二重木アルゴリズムは、大きなNに対してより良いスケーリングを持つことができます。</target>
        </trans-unit>
        <trans-unit id="1f1b5d26ff8a3e05067cc01bd3cc7a0f425c7062" translate="yes" xml:space="preserve">
          <source>If two features are almost equally correlated with the target, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="translated">2つの特徴がターゲットとほぼ等しく相関している場合、それらの係数はほぼ同じ速度で増加しなければなりません。このようにして、アルゴリズムは直感が期待するように動作し、より安定しています。</target>
        </trans-unit>
        <trans-unit id="a62f22814f97612f53d5c62d8ea50a484acea3fc" translate="yes" xml:space="preserve">
          <source>If two variables are almost equally correlated with the response, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.</source>
          <target state="translated">2つの変数が応答とほぼ等しく相関している場合、それらの係数はほぼ同じ速度で増加するはずです。このアルゴリズムは、このようにして直感が期待するように動作し、より安定しています。</target>
        </trans-unit>
        <trans-unit id="c6d813716240a58cb1e341ee096ed78ff4d17824" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are plotted at each iteration.</source>
          <target state="translated">verboseがTrueの場合、目的関数とデュアルギャップが各反復でプロットされます。</target>
        </trans-unit>
        <trans-unit id="c845cf733c967b921d034159fbd6e6d551e8f5a1" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and dual gap are printed at each iteration.</source>
          <target state="translated">verboseがTrueの場合、目的関数とデュアルギャップが各イテレーションで印刷されます。</target>
        </trans-unit>
        <trans-unit id="d04bb65f95446e17ac813ad52d517cc52bee8bef" translate="yes" xml:space="preserve">
          <source>If verbose is True, the objective function and duality gap are printed at each iteration.</source>
          <target state="translated">verboseがTrueの場合、目的関数と双対性ギャップが各イテレーションで印刷されます。</target>
        </trans-unit>
        <trans-unit id="c297e2c2dea63aea70529d05594e08d33ba95930" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">ウォームスタートが有効になっている場合、事後モードのラプラス近似の最後のニュートン反復の解は、_posterior_mode（）の次の呼び出しの初期化として使用されます。これにより、ハイパーパラメーター最適化と同様の問題で_posterior_modeが複数回呼び出されたときに、収束を高速化できます。&lt;a href=&quot;http://scikit-learn.org/stable/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="250e3ab5ccbd8ff9f61320148d394ace048df253" translate="yes" xml:space="preserve">
          <source>If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See &lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;the Glossary&lt;/a&gt;.</source>
          <target state="translated">ウォームスタートが有効になっている場合、事後モードのラプラス近似での最後のニュートン反復の解が、次の_posterior_mode（）呼び出しの初期化として使用されます。これにより、ハイパーパラメータの最適化と同様の問題で_posterior_modeが数回呼び出されたときに、収束を高速化できます。&lt;a href=&quot;https://scikit-learn.org/0.23/glossary.html#term-warm-start&quot;&gt;用語集を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="0beda1307d8fba8bf455ad043421d0e1b5743334" translate="yes" xml:space="preserve">
          <source>If we consider the loss function to be the individual error per sample, then the data-fit term, or the sum of the error for each sample, will increase as we add more samples. The penalization term, however, will not increase.</source>
          <target state="translated">損失関数を標本ごとの個々の誤差と考えると、データフィット項(各標本の誤差の合計)は、標本を増やすにつれて増加します。しかし、ペナルティ項は増加しません。</target>
        </trans-unit>
        <trans-unit id="232b0b83965c86185ba5cb4047fca7ca1eb2e5e8" translate="yes" xml:space="preserve">
          <source>If we define &lt;code&gt;s = 1 / density&lt;/code&gt;, the elements of the random matrix are drawn from</source>
          <target state="translated">&lt;code&gt;s = 1 / density&lt;/code&gt; を定義すると、ランダム行列の要素は、</target>
        </trans-unit>
        <trans-unit id="de1968292a81bf57ac7d922cf400e8863c649aea" translate="yes" xml:space="preserve">
          <source>If we increase &lt;code&gt;power&lt;/code&gt; to 1,:</source>
          <target state="translated">&lt;code&gt;power&lt;/code&gt; を1に増やすと、：</target>
        </trans-unit>
        <trans-unit id="1427e0ae27c6ada10257117ddf3e602836e812e6" translate="yes" xml:space="preserve">
          <source>If we note &lt;code&gt;s = 1 / density&lt;/code&gt; the components of the random matrix are drawn from:</source>
          <target state="translated">&lt;code&gt;s = 1 / density&lt;/code&gt; 注意すると、ランダム行列の成分は以下から引き出されます。</target>
        </trans-unit>
        <trans-unit id="f9cbc4d2964857d1865d4f91b696f12d3cce3cff" translate="yes" xml:space="preserve">
          <source>If we note \(n_{\max} = \max(n_{\mathrm{samples}}, n_{\mathrm{features}})\) and \(n_{\min} = \min(n_{\mathrm{samples}}, n_{\mathrm{features}})\), the time complexity of the randomized &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt; is \(O(n_{\max}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\max}^2 \cdot n_{\min})\) for the exact method implemented in &lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt;&lt;code&gt;PCA&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">\（n _ {\ max} = \ max（n _ {\ mathrm {samples}}、n _ {\ mathrm {features}}）\）と\（n _ {\ min} = \ min（n _ {\ mathrm {samples}}、n _ {\ mathrm {features}}）\）、ランダム化された&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; の&lt;/a&gt;時間の複雑さは代わりに\（O（n _ {\ max} ^ 2 \ cdot n _ {\ mathrm {components}}）\）です実装正確な方法\（O（N _ {\最大} ^ 2 \ CDOT N _ {\分}）\）の&lt;a href=&quot;generated/sklearn.decomposition.pca#sklearn.decomposition.PCA&quot;&gt; &lt;code&gt;PCA&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="483854d9b52bcc6a7814b6c99e197398a7767c0e" translate="yes" xml:space="preserve">
          <source>If we use l2 shrinkage, as with the Ledoit-Wolf estimator, as the number of samples is small, we need to shrink a lot. As a result, the Ledoit-Wolf precision is fairly close to the ground truth precision, that is not far from being diagonal, but the off-diagonal structure is lost.</source>
          <target state="translated">Ledoit-Wolf 推定器のように l2 縮小を使うと、サンプル数が少ないので、かなりの縮小が必要になります。その結果、Ledoit-Wolfの精度は、対角線には遠く及ばないが、対角線から外れた構造が失われているという、かなり地真の精度に近いものになります。</target>
        </trans-unit>
        <trans-unit id="c048d2d806d4fc664d0d49e2240da1f9038d7165" translate="yes" xml:space="preserve">
          <source>If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:</source>
          <target state="translated">平面ではなく放物線をデータにフィットさせたい場合は、2次多項式の特徴を組み合わせることで、このようなモデルになります。</target>
        </trans-unit>
        <trans-unit id="9cd2bdd13889db844fd297c5019d226d5f2214ec" translate="yes" xml:space="preserve">
          <source>If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain &lt;code&gt;PPCA&lt;/code&gt;.</source>
          <target state="translated">モデルをさらに制限する場合、ガウスノイズは等方性である（すべての対角要素は同じである）と &lt;code&gt;PPCA&lt;/code&gt; することにより、PPCAを取得します。</target>
        </trans-unit>
        <trans-unit id="722d8ecf13f293f3aeb1f206f30063d8afe3b1aa" translate="yes" xml:space="preserve">
          <source>If whiten is false, the data is already considered to be whitened, and no whitening is performed.</source>
          <target state="translated">美白が偽物であれば、すでに美白が行われていると考えられているデータであり、美白は行われていません。</target>
        </trans-unit>
        <trans-unit id="7d7146f3cf5f6ee3a12daad9561636b3070c19dc" translate="yes" xml:space="preserve">
          <source>If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.</source>
          <target state="translated">ホワイトニングが有効な場合、inverse_transformは、ホワイトニングの反転を含む正確な反転演算を計算します。</target>
        </trans-unit>
        <trans-unit id="d6701cdf426d6a22381b3dd206332eab0defeb4b" translate="yes" xml:space="preserve">
          <source>If you apply SGD to features extracted using PCA we found that it is often wise to scale the feature values by some constant &lt;code&gt;c&lt;/code&gt; such that the average L2 norm of the training data equals one.</source>
          <target state="translated">PCAを使用して抽出した特徴にSGDを適用した場合、特徴値を定数 &lt;code&gt;c&lt;/code&gt; でスケーリングして、トレーニングデータの平均L2ノルムが1になるようにすることが賢​​明であることがわかりました。</target>
        </trans-unit>
        <trans-unit id="88e7b5f8ea1b769958767cd4c4986cb0d84b69d4" translate="yes" xml:space="preserve">
          <source>If you are having trouble decoding text, here are some things to try:</source>
          <target state="translated">テキストの解読にお困りの方は、以下のことを試してみてはいかがでしょうか。</target>
        </trans-unit>
        <trans-unit id="79c8dbf5a9dd8e0bcb21dbc0b3d21d4a002af1f5" translate="yes" xml:space="preserve">
          <source>If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:</source>
          <target state="translated">L1とL2のペナルティを別々にコントロールしたい場合は、それに相当することを覚えておきましょう。</target>
        </trans-unit>
        <trans-unit id="fda5569b1e927ca58d1243554ef8331577e43162" translate="yes" xml:space="preserve">
          <source>If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.</source>
          <target state="translated">a-preriori辞書を提供せず、ある種の特徴選択を行う分析器を使用しない場合、特徴の数はデータを分析して見つかった語彙数と同じになります。</target>
        </trans-unit>
        <trans-unit id="44906a85511569286aafb87826155b3c2905ddf9" translate="yes" xml:space="preserve">
          <source>If you don&amp;rsquo;t have labels, try using &lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;Clustering&lt;/a&gt; on your problem.</source>
          <target state="translated">ラベルがない場合は、問題に対して&lt;a href=&quot;../../auto_examples/text/plot_document_clustering#sphx-glr-auto-examples-text-plot-document-clustering-py&quot;&gt;クラスタリング&lt;/a&gt;を使用してみてください。</target>
        </trans-unit>
        <trans-unit id="951c73020178956033a4088912e01e49fd5d4ad8" translate="yes" xml:space="preserve">
          <source>If you encounter a bug with &lt;code&gt;scikit-learn&lt;/code&gt; or something that needs clarification in the docstring or the online documentation, please feel free to ask on the &lt;a href=&quot;http://scikit-learn.org/stable/support.html&quot;&gt;Mailing List&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;scikit-learn&lt;/code&gt; のバグや、docstringまたはオンラインドキュメントで説明が必要なものに遭遇した場合は、&lt;a href=&quot;http://scikit-learn.org/stable/support.html&quot;&gt;メーリングリストでお&lt;/a&gt;気軽にお問い合わせください</target>
        </trans-unit>
        <trans-unit id="1e3c9a76f4703e92f09f761bb01632ba0994c7fc" translate="yes" xml:space="preserve">
          <source>If you experience hanging subprocesses with &lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; or &lt;code&gt;n_jobs=-1&lt;/code&gt;, make sure you have a single-threaded BLAS library, or set &lt;code&gt;n_jobs=1&lt;/code&gt;, or upgrade to Python 3.4 which has a new version of &lt;code&gt;multiprocessing&lt;/code&gt; that should be immune to this problem.</source>
          <target state="translated">&lt;code&gt;n_jobs&amp;gt;1&lt;/code&gt; または &lt;code&gt;n_jobs=-1&lt;/code&gt; でサブプロセスがハングする場合は、シングルスレッドのBLASライブラリがあることを確認するか、 &lt;code&gt;n_jobs=1&lt;/code&gt; を設定するか、これに影響されない新しいバージョンの &lt;code&gt;multiprocessing&lt;/code&gt; を持つPython 3.4にアップグレードしてください問題。</target>
        </trans-unit>
        <trans-unit id="01bbb2c6066f4ee0c3cd8eec64a157d2ed58c8df" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(\phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(\phi\) followed by removal of the mean in that space.</source>
          <target state="translated">関数\（\ phi \）で定義された特徴空間で内積を計算するカーネル\（K \）のカーネル行列がある場合、&lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt; &lt;code&gt;KernelCenterer&lt;/code&gt; &lt;/a&gt;は、特徴空間に内積を含むようにカーネル行列を変換できます。 \（\ phi \）で定義され、その後にその空間の平均が削除されます。</target>
        </trans-unit>
        <trans-unit id="b4d3f940390acd5b7c567c108aba27222ddceb7d" translate="yes" xml:space="preserve">
          <source>If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space defined by function \(phi\), a &lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt;&lt;code&gt;KernelCenterer&lt;/code&gt;&lt;/a&gt; can transform the kernel matrix so that it contains inner products in the feature space defined by \(phi\) followed by removal of the mean in that space.</source>
          <target state="translated">関数\（phi \）で定義された特徴空間でドット積を計算するカーネル\（K \）のカーネル行列がある場合、&lt;a href=&quot;generated/sklearn.preprocessing.kernelcenterer#sklearn.preprocessing.KernelCenterer&quot;&gt; &lt;code&gt;KernelCenterer&lt;/code&gt; &lt;/a&gt;はカーネル行列を変換して、定義された特徴空間の内積を含むようにすることができます。 \（phi \）に続けて、そのスペースの平均を削除します。</target>
        </trans-unit>
        <trans-unit id="2615ef2dcc8005e7f8f1fe1a8b864f8c5c8b40ba" translate="yes" xml:space="preserve">
          <source>If you have an affinity matrix, such as a distance matrix, for which 0 means identical elements, and high values means very dissimilar elements, it can be transformed in a similarity matrix that is well suited for the algorithm by applying the Gaussian (RBF, heat) kernel:</source>
          <target state="translated">0 は同一の要素を意味し、高い値は非常に非類似な要素を意味する距離行列のような親和性行列を持っている場合は、ガウシアン(RBF,heat)カーネルを適用することで、アルゴリズムに適した類似性行列に変換することができます。</target>
        </trans-unit>
        <trans-unit id="fe35ae96a69c356c4c790a684b706493b567f769" translate="yes" xml:space="preserve">
          <source>If you have multiple labels per document, e.g categories, have a look at the &lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;Multiclass and multilabel section&lt;/a&gt;.</source>
          <target state="translated">ドキュメントごとに複数のラベル（カテゴリなど）がある場合は、&lt;a href=&quot;../../modules/multiclass#multiclass&quot;&gt;マルチクラスとマルチラベルのセクションをご覧ください&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4c5f38a361bcbafd12cc29508483a444dfcf9728" translate="yes" xml:space="preserve">
          <source>If you have several classes to predict, an option often used is to fit one-versus-all classifiers and then use a voting heuristic for the final decision.</source>
          <target state="translated">予測するクラスが複数ある場合,よく使われるオプションは,1対すべての分類器を適合させ,最終的な決定に投票ヒューリスティックを使用することです.</target>
        </trans-unit>
        <trans-unit id="f97615967054f5695c197161c38be5160cb380e9" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots you can use the &lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt;&lt;code&gt;partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">プロットではなく部分依存関数の生の値が必要な場合は、&lt;a href=&quot;generated/sklearn.ensemble.partial_dependence.partial_dependence#sklearn.ensemble.partial_dependence.partial_dependence&quot;&gt; &lt;code&gt;partial_dependence&lt;/code&gt; &lt;/a&gt;関数を使用できます。</target>
        </trans-unit>
        <trans-unit id="89ce73b51d6a3d39879546007326b93ba776d729" translate="yes" xml:space="preserve">
          <source>If you need the raw values of the partial dependence function rather than the plots, you can use the &lt;a href=&quot;generated/sklearn.inspection.partial_dependence#sklearn.inspection.partial_dependence&quot;&gt;&lt;code&gt;sklearn.inspection.partial_dependence&lt;/code&gt;&lt;/a&gt; function:</source>
          <target state="translated">プロットではなく部分依存関数の生の値が必要な場合は、&lt;a href=&quot;generated/sklearn.inspection.partial_dependence#sklearn.inspection.partial_dependence&quot;&gt; &lt;code&gt;sklearn.inspection.partial_dependence&lt;/code&gt; &lt;/a&gt;関数を使用できます。</target>
        </trans-unit>
        <trans-unit id="57ce2ca8cd47ab25ffa05da2880829913ab0ea8d" translate="yes" xml:space="preserve">
          <source>If you really want to use &lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt;&lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt;&lt;/a&gt; for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the &lt;code&gt;novelty&lt;/code&gt; parameter set to &lt;code&gt;True&lt;/code&gt; before fitting the estimator. In this case, &lt;code&gt;fit_predict&lt;/code&gt; is not available.</source>
          <target state="translated">ノベルティ検出のために&lt;a href=&quot;generated/sklearn.neighbors.localoutlierfactor#sklearn.neighbors.LocalOutlierFactor&quot;&gt; &lt;code&gt;neighbors.LocalOutlierFactor&lt;/code&gt; &lt;/a&gt;を本当に使用する場合、つまりラベルを予測するか、新しい未表示データの異常スコアを計算する場合は、 &lt;code&gt;novelty&lt;/code&gt; パラメーターを &lt;code&gt;True&lt;/code&gt; に設定して推定器をインスタンス化してから、推定器をフィッティングします。この場合、 &lt;code&gt;fit_predict&lt;/code&gt; は使用できません。</target>
        </trans-unit>
        <trans-unit id="d5eafa493c5ec5c70bb915830d883a4547e5cefd" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;text&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">load_content = Trueを設定する場合は、「encoding」パラメーターを使用してテキストのエンコードも指定する必要があります。最近の多くのテキストファイルでは、「utf-8」が正しいエンコーディングになります。エンコーディングをNoneのままにすると、コンテンツはUnicodeではなくバイトで作成され、&lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt; &lt;code&gt;text&lt;/code&gt; &lt;/a&gt;ほとんどの関数を使用できなくなります。</target>
        </trans-unit>
        <trans-unit id="9f2c392b35ce2be9956cf3b6740e21a9cb0e7eb8" translate="yes" xml:space="preserve">
          <source>If you set load_content=True, you should also specify the encoding of the text using the &amp;lsquo;encoding&amp;rsquo; parameter. For many modern text files, &amp;lsquo;utf-8&amp;rsquo; will be the correct encoding. If you leave encoding equal to None, then the content will be made of bytes instead of Unicode, and you will not be able to use most functions in &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;.</source>
          <target state="translated">load_content = Trueを設定する場合は、 'encoding'パラメータを使用してテキストのエンコーディングも指定する必要があります。最近の多くのテキストファイルでは、「utf-8」が正しいエンコーディングになります。エンコーディングをNoneのままにすると、コンテンツはUnicodeではなくバイトで作成され、 &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; のほとんどの関数を使用できなくなります。</target>
        </trans-unit>
        <trans-unit id="bc2de8e7176de3a7ec5f2ba66eebe7612bd92fb1" translate="yes" xml:space="preserve">
          <source>If you specify &lt;code&gt;max_depth=h&lt;/code&gt; then complete binary trees of depth &lt;code&gt;h&lt;/code&gt; will be grown. Such trees will have (at most) &lt;code&gt;2**h&lt;/code&gt; leaf nodes and &lt;code&gt;2**h - 1&lt;/code&gt; split nodes.</source>
          <target state="translated">&lt;code&gt;max_depth=h&lt;/code&gt; を指定すると、深さ &lt;code&gt;h&lt;/code&gt; の完全なバイナリツリーが成長します。このようなツリーには、（最大で） &lt;code&gt;2**h&lt;/code&gt; リーフノードと &lt;code&gt;2**h - 1&lt;/code&gt; 分割ノードがあります。</target>
        </trans-unit>
        <trans-unit id="b5e591b33a0bd24a7e9f3db1117e493d465fb600" translate="yes" xml:space="preserve">
          <source>If you use sparse data (i.e. data represented as sparse matrices), &lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt;&lt;code&gt;chi2&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt;&lt;code&gt;mutual_info_regression&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt;&lt;code&gt;mutual_info_classif&lt;/code&gt;&lt;/a&gt; will deal with the data without making it dense.</source>
          <target state="translated">スパースデータ（つまり、スパース行列として表されるデータ）を使用する場合、&lt;a href=&quot;generated/sklearn.feature_selection.chi2#sklearn.feature_selection.chi2&quot;&gt; &lt;code&gt;chi2&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_regression#sklearn.feature_selection.mutual_info_regression&quot;&gt; &lt;code&gt;mutual_info_regression&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.feature_selection.mutual_info_classif#sklearn.feature_selection.mutual_info_classif&quot;&gt; &lt;code&gt;mutual_info_classif&lt;/code&gt; &lt;/a&gt;はデータを密にすることなく処理します。</target>
        </trans-unit>
        <trans-unit id="a1ac2d367786359c2f555cec450b280865094e6b" translate="yes" xml:space="preserve">
          <source>If you want more control over stopping criteria or learning rate in SGD, or want to do additional monitoring, using &lt;code&gt;warm_start=True&lt;/code&gt; and &lt;code&gt;max_iter=1&lt;/code&gt; and iterating yourself can be helpful:</source>
          <target state="translated">SGDの停止基準または学習率をさらに制御したい場合、または追加の監視を実行したい場合は、 &lt;code&gt;warm_start=True&lt;/code&gt; と &lt;code&gt;max_iter=1&lt;/code&gt; を使用して、自分自身を繰り返すと便利です。</target>
        </trans-unit>
        <trans-unit id="5572f4380789e92c52811040d71f90082bdb6315" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="translated">これらの問題の詳細を知り、他の可能なシリアライゼーション方法を検討したい場合は&lt;a href=&quot;http://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;、Alex Gaynorによる&lt;/a&gt;この講演を参照してください。</target>
        </trans-unit>
        <trans-unit id="f3aeb01a6e584fc1ad67fbb7aa6de9be209b24eb" translate="yes" xml:space="preserve">
          <source>If you want to know more about these issues and explore other possible serialization methods, please refer to this &lt;a href=&quot;https://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;talk by Alex Gaynor&lt;/a&gt;.</source>
          <target state="translated">これらの問題について詳しく知り、他の可能なシリアル化方法を調べたい場合は、&lt;a href=&quot;https://pyvideo.org/video/2566/pickles-are-for-delis-not-software&quot;&gt;AlexGaynorによる&lt;/a&gt;この講演を参照してください。</target>
        </trans-unit>
        <trans-unit id="73e4bcb37920038eaa4bbe1483d8a08f411face1" translate="yes" xml:space="preserve">
          <source>If you want to model a relative frequency, i.e. counts per exposure (time, volume, &amp;hellip;) you can do so by using a Poisson distribution and passing \(y=\frac{\mathrm{counts}}{\mathrm{exposure}}\) as target values together with \(\mathrm{exposure}\) as sample weights. For a concrete example see e.g. &lt;a href=&quot;../auto_examples/linear_model/plot_tweedie_regression_insurance_claims#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py&quot;&gt;Tweedie regression on insurance claims&lt;/a&gt;.</source>
          <target state="translated">相対度数、つまり露出ごとのカウント（時間、ボリュームなど）をモデル化する場合は、ポアソン分布を使用して\（y = \ frac {\ mathrm {counts}} {\ mathrm {exposure}を渡すことでモデル化できます。 } \）をターゲット値として、\（\ mathrm {exposure} \）をサンプルの重みとして使用します。具体的な例については、たとえば&lt;a href=&quot;../auto_examples/linear_model/plot_tweedie_regression_insurance_claims#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py&quot;&gt;保険金請求に関するTweedie回帰を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="c9d28c176517636a408517ab464ebf5a8ed78a10" translate="yes" xml:space="preserve">
          <source>If your attributes have an intrinsic scale (e.g. word frequencies or indicator features) scaling is not needed.</source>
          <target state="translated">属性に固有のスケールがある場合(単語の頻度や指標特徴など)は、スケーリングは必要ありません。</target>
        </trans-unit>
        <trans-unit id="1c54fdc8274e03b04e776296dd28d5ff9fd81085" translate="yes" xml:space="preserve">
          <source>If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use &lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt;&lt;code&gt;robust_scale&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt;&lt;code&gt;RobustScaler&lt;/code&gt;&lt;/a&gt; as drop-in replacements instead. They use more robust estimates for the center and range of your data.</source>
          <target state="translated">データに多くの外れ値が含まれている場合、データの平均と分散を使用したスケーリングはあまりうまく機能しない可能性があります。これらの場合、代わりに&lt;a href=&quot;generated/sklearn.preprocessing.robust_scale#sklearn.preprocessing.robust_scale&quot;&gt; &lt;code&gt;robust_scale&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.preprocessing.robustscaler#sklearn.preprocessing.RobustScaler&quot;&gt; &lt;code&gt;RobustScaler&lt;/code&gt; &lt;/a&gt;をドロップイン置換として使用できます。彼らはあなたのデータの中心と範囲のためのよりロバストな推定を使用します。</target>
        </trans-unit>
        <trans-unit id="a10bfba29a759d89e81956a541262290109cf294" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="translated">機能の数が多い場合は、監視ありステップの前に監視なしステップを使用してそれを減らすと便利な場合があります。&lt;a href=&quot;http://scikit-learn.org/stable/unsupervised_learning.html#unsupervised-learning&quot;&gt;教師なし学習&lt;/a&gt;メソッドの多くは、次元数を減らすために使用できる &lt;code&gt;transform&lt;/code&gt; メソッドを実装しています。以下では、頻繁に使用されるこのパターンの2つの特定の例について説明します。</target>
        </trans-unit>
        <trans-unit id="7fd7c263c0ce2fcb7f46b0e79b01f4b5e3878456" translate="yes" xml:space="preserve">
          <source>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the &lt;a href=&quot;https://scikit-learn.org/0.23/unsupervised_learning.html#unsupervised-learning&quot;&gt;Unsupervised learning&lt;/a&gt; methods implement a &lt;code&gt;transform&lt;/code&gt; method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</source>
          <target state="translated">特徴の数が多い場合は、教師ありステップの前に教師なしステップでそれを減らすことが役立つ場合があります。&lt;a href=&quot;https://scikit-learn.org/0.23/unsupervised_learning.html#unsupervised-learning&quot;&gt;教師なし学習&lt;/a&gt;メソッドの多くは、次元を削減するために使用できる &lt;code&gt;transform&lt;/code&gt; メソッドを実装しています。以下では、頻繁に使用されるこのパターンの2つの特定の例について説明します。</target>
        </trans-unit>
        <trans-unit id="933c257247173f2464c3cf8d4de4af2d678e5a7c" translate="yes" xml:space="preserve">
          <source>If your number of observations is not large compared to the number of edges in your underlying graph, you will not recover it.</source>
          <target state="translated">もしオブザベーションの数が、基礎となるグラフのエッジの数に比べて大きくない場合は、それを回復することはできません。</target>
        </trans-unit>
        <trans-unit id="4f34c772816074a373c0d5e918e2e9ac136448b7" translate="yes" xml:space="preserve">
          <source>Ignore the offset first bytes by seeking forward, then discarding the following bytes up until the next new line character.</source>
          <target state="translated">オフセットの最初のバイトを無視してフォワードを求め、次の改行文字までの次のバイトを破棄します。</target>
        </trans-unit>
        <trans-unit id="78fee1435d74666b84850cd5e82c18229351da5d" translate="yes" xml:space="preserve">
          <source>Ignored</source>
          <target state="translated">Ignored</target>
        </trans-unit>
        <trans-unit id="9b02e8c10d5a363337d6fcee177ec3e9cae9f1ce" translate="yes" xml:space="preserve">
          <source>Ignored in binary classification or classical regression settings.</source>
          <target state="translated">二値分類や古典回帰の設定では無視されます。</target>
        </trans-unit>
        <trans-unit id="ce03a847a845250be1b2b174971c463802e32813" translate="yes" xml:space="preserve">
          <source>Ignored variable.</source>
          <target state="translated">無視された変数です。</target>
        </trans-unit>
        <trans-unit id="1e65bb4eca2d3c71529c96890a4b735eb7dafeac" translate="yes" xml:space="preserve">
          <source>Ignored.</source>
          <target state="translated">Ignored.</target>
        </trans-unit>
        <trans-unit id="d0c592be2a6267cc2802c86a5116a8ba2d4b6ff9" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with &lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">無視されます。このパラメーターは、&lt;a href=&quot;sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; &lt;/a&gt;との互換性のためにのみ存在します。</target>
        </trans-unit>
        <trans-unit id="1e417badfc4d52f79664b451110854e41b4a0daf" translate="yes" xml:space="preserve">
          <source>Ignored. This parameter exists only for compatibility with sklearn.pipeline.Pipeline.</source>
          <target state="translated">無視されます。このパラメータはsklearn.pipeline.Pipeline.Pipelineとの互換性のためだけに存在します。</target>
        </trans-unit>
        <trans-unit id="2d34b7c897f7b41a0f0625575a2c9cc21b1078a7" translate="yes" xml:space="preserve">
          <source>Illustration of &lt;code&gt;Pipeline&lt;/code&gt; and &lt;code&gt;GridSearchCV&lt;/code&gt;</source>
          <target state="translated">イラスト &lt;code&gt;Pipeline&lt;/code&gt; と &lt;code&gt;GridSearchCV&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="643998f34944846c305de7d49de1c3e80f814d2d" translate="yes" xml:space="preserve">
          <source>Illustration of Gaussian process classification (GPC) on the XOR dataset</source>
          <target state="translated">XORデータセット上でのガウス過程分類(GPC)の図解</target>
        </trans-unit>
        <trans-unit id="c2cd661f8089fd4df71dfb566ea137083aa22024" translate="yes" xml:space="preserve">
          <source>Illustration of how the performance of an estimator on unseen data (test data) is not the same as the performance on training data. As the regularization increases the performance on train decreases while the performance on test is optimal within a range of values of the regularization parameter. The example with an Elastic-Net regression model and the performance is measured using the explained variance a.k.a. R^2.</source>
          <target state="translated">見えないデータ(テストデータ)に対する推定器の性能が、訓練データに対する性能と同じではないことを示す図。正則化が増加すると訓練時の性能は低下しますが、テスト時の性能は正則化パラメータの値の範囲内で最適です。Elastic-Net回帰モデルを用いた例で、性能は説明済み分散 a.k.a.R^2.を用いて測定されます。</target>
        </trans-unit>
        <trans-unit id="5790a5aaa3a6c4543a820b9b12ce6d261eeb0581" translate="yes" xml:space="preserve">
          <source>Illustration of prior and posterior Gaussian process for different kernels</source>
          <target state="translated">異なるカーネルに対する事前・事後ガウス過程の説明</target>
        </trans-unit>
        <trans-unit id="71618836e7c136eb1b3d1aef884b22f68af959aa" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;.</source>
          <target state="translated">勾配ブースティングのさまざまな正則化戦略の効果の図。例は、Hastieら2009から取られる&lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;1&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="27c062ea4e410688effe23ac51313a8ab9a70f1c" translate="yes" xml:space="preserve">
          <source>Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;.</source>
          <target state="translated">勾配ブースティングのさまざまな正則化戦略の効果の図。この例は、Hastie et al 2009 &lt;a href=&quot;#id2&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;からの引用です。</target>
        </trans-unit>
        <trans-unit id="5beb1d257bbb65ddb7ec568445a1c3acdcb42d37" translate="yes" xml:space="preserve">
          <source>Image denoising using dictionary learning</source>
          <target state="translated">辞書学習を用いた画像デノイジング</target>
        </trans-unit>
        <trans-unit id="5ab7decf36c80b04aff06a11c0e8ef068c85a1b9" translate="yes" xml:space="preserve">
          <source>Image histogram</source>
          <target state="translated">画像ヒストグラム</target>
        </trans-unit>
        <trans-unit id="2c151a57b190c9b9e70046810542a00e0344b5af" translate="yes" xml:space="preserve">
          <source>Image representing the confusion matrix.</source>
          <target state="translated">混同行列を表す画像。</target>
        </trans-unit>
        <trans-unit id="5c328038b14054033bab1147ef5d1ad234b3373d" translate="yes" xml:space="preserve">
          <source>Imagine you have three subjects, each with an associated number from 1 to 3:</source>
          <target state="translated">3つの被験者がいて、それぞれに1から3までの番号が関連付けられていると想像してください。</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="8d522809f4125f5930c1f4f77ec91f8735a003d8" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/code&gt; 基づく実装、独立成分分析：アルゴリズムとアプリケーション、ニューラルネットワーク、13（4-5）、2000、pp.411-430</target>
        </trans-unit>
        <trans-unit id="1f57545a08e425cccaf152a77959fb187cad06cb" translate="yes" xml:space="preserve">
          <source>Implementation based on &lt;em&gt;A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430&lt;/em&gt;</source>
          <target state="translated">&lt;em&gt;A.HyvarinenとE.Ojaに&lt;/em&gt;基づく実装&lt;em&gt;、Independent Component Analysis：Algorithms and Applications、Neural Networks、13（4-5）、2000、pp。411-430&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="c6a1ab1256c83ccf4dbd316f43007b044bc691a2" translate="yes" xml:space="preserve">
          <source>Implementation detail: taking sample weights into account amounts to multiplying the gradients (and the hessians) by the sample weights. Note that the binning stage (specifically the quantiles computation) does not take the weights into account.</source>
          <target state="translated">実装の詳細:サンプル重みを考慮に入れることは,勾配(およびヘシアン)にサンプル重みを乗算することになります.ビニングの段階(具体的には,クオンタイルの計算)では,重みを考慮に入れないことに注意してください.</target>
        </trans-unit>
        <trans-unit id="b6ac8df85fe47d2d00b4a78e1facdef4fbcae73b" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does. Furthermore SVC multi-class mode is implemented using one vs one scheme while LinearSVC uses one vs the rest. It is possible to implement one vs the rest with SVC by using the &lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt;&lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt;&lt;/a&gt; wrapper. Finally SVC can fit dense data without memory copy if the input is C-contiguous. Sparse data will still incur memory copy though.</source>
          <target state="translated">libsvmを使用したサポートベクターマシン分類器の実装：カーネルは非線形にすることができますが、そのSMOアルゴリズムは、LinearSVCのように多数のサンプルにスケーリングしません。さらに、SVCマルチクラスモードは1つと1つのスキームを使用して実装され、LinearSVCは1つと残りのスキームを使用します。&lt;a href=&quot;sklearn.multiclass.onevsrestclassifier#sklearn.multiclass.OneVsRestClassifier&quot;&gt; &lt;code&gt;sklearn.multiclass.OneVsRestClassifier&lt;/code&gt; &lt;/a&gt;ラッパーを使用することで、SVCを使用して残りの1つを実装することが可能です。最後に、入力がC隣接である場合、SVCはメモリコピーなしで密データに適合できます。スパースデータでもメモリコピーは発生します。</target>
        </trans-unit>
        <trans-unit id="78b58091d5da65fb36aa747d9975841d97302dec" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine classifier using the same library as this class (liblinear).</source>
          <target state="translated">本クラスと同じライブラリ(liblinear)を用いたサポートベクターマシン分類器の実装。</target>
        </trans-unit>
        <trans-unit id="0faf8832b17d93a1b230f7a6ca4feb36d15cc4ac" translate="yes" xml:space="preserve">
          <source>Implementation of Support Vector Machine regression using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does.</source>
          <target state="translated">libsvmを用いたサポートベクターマシン回帰の実装:カーネルは非線形にすることができますが、そのSMOアルゴリズムはLinearSVCのように大量のサンプル数にはスケールしません。</target>
        </trans-unit>
        <trans-unit id="adae10003f16f5885f71700e866f2cc76e2c6af9" translate="yes" xml:space="preserve">
          <source>Implements feature hashing, aka the hashing trick.</source>
          <target state="translated">機能ハッシュ、別名ハッシュトリックを実装します。</target>
        </trans-unit>
        <trans-unit id="d98e09b894119d4a2d55bf3e2f04052ec103359a" translate="yes" xml:space="preserve">
          <source>Implements resampling with replacement. If False, this will implement (sliced) random permutations.</source>
          <target state="translated">置換による再サンプリングを実装します。Falseの場合、これは(スライスされた)ランダムな並べ替えを実装します。</target>
        </trans-unit>
        <trans-unit id="9f9d0b6a3b9dbc770ff8e17c3a6979d6ebb5425d" translate="yes" xml:space="preserve">
          <source>Implements the Birch clustering algorithm.</source>
          <target state="translated">Birchクラスタリングアルゴリズムを実装しています.</target>
        </trans-unit>
        <trans-unit id="82028db75262dc1a82a0dc4cf2e6f254032ff9f7" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; See &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="translated">道具から増分PCAモデル： &lt;code&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/code&gt; &lt;a href=&quot;http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;。http：&lt;/a&gt;//www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdfを参照</target>
        </trans-unit>
        <trans-unit id="eddd9fc5411550a8b67e601c8cf138c977f02e42" translate="yes" xml:space="preserve">
          <source>Implements the incremental PCA model from: &lt;em&gt;D. Ross, J. Lim, R. Lin, M. Yang, Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008.&lt;/em&gt; See &lt;a href=&quot;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&lt;/a&gt;</source>
          <target state="translated">&lt;em&gt;D.ロス、J。リム、R。リン、M。ヤン、ロバストビジュアルトラッキングのためのインクリメンタルラーニング、International Journal of Computer Vision、第77巻、第1〜3号、125〜141ページ&lt;/em&gt;のインクリメンタルPCAモデルを実装します&lt;em&gt;。 2008年5月&lt;/em&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf&quot;&gt;。https：&lt;/a&gt;&lt;em&gt;//www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdfを&lt;/em&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="06be3bf25c44efb35fdd12e8816c051b94a6e5d6" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: &lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt;Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#id1&quot;&gt;&lt;span id=&quot;id2&quot;&gt;`&lt;/span&gt;&lt;/a&gt; Tipping、ME、and Bishop、CM（1999）の確率的PCAモデルを実装します。「確率論的主成分分析」。王立統計学会誌：シリーズB（統計手法）、61（3）、611-622。scoreメソッドとscore_samplesメソッドを使用します。&lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdfを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="5153c1832189653f3d836c4da5e485c3d1b56671" translate="yes" xml:space="preserve">
          <source>Implements the probabilistic PCA model from: Tipping, M. E., and Bishop, C. M. (1999). &amp;ldquo;Probabilistic principal component analysis&amp;rdquo;. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods. See &lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdf&lt;/a&gt;</source>
          <target state="translated">Tipping、ME、およびBishop、CM（1999）から確率的PCAモデルを実装します。「確率的主成分分析」。Journal of the Royal Statistics Society：Series B（Statistical Methodology）、61（3）、611-622。scoreおよびscore_samplesメソッドを介して。&lt;a href=&quot;http://www.miketipping.com/papers/met-mppca.pdf&quot;&gt;http://www.miketipping.com/papers/met-mppca.pdfを&lt;/a&gt;参照してください</target>
        </trans-unit>
        <trans-unit id="496d8573358dc0bbf8fad0d466b95c37d153e5fd" translate="yes" xml:space="preserve">
          <source>Importance of Feature Scaling</source>
          <target state="translated">フィーチャースケーリングの重要性</target>
        </trans-unit>
        <trans-unit id="dee0fbd7a096536203f3e083c7a95f20ef772057" translate="yes" xml:space="preserve">
          <source>Important members are fit, predict.</source>
          <target state="translated">重要なメンバーはフィット、予測。</target>
        </trans-unit>
        <trans-unit id="34aace9b4c119f775f92304ec637d19c91f28ab6" translate="yes" xml:space="preserve">
          <source>Importantly, this tabular dataset has very different dynamic ranges for its features. Neural networks tend to be very sensitive to features with varying scales and forgetting to preprocess the numeric feature would lead to a very poor model.</source>
          <target state="translated">重要なことは、この表形式のデータセットは、その特徴の動的範囲が非常に異なっているということです。ニューラルネットワークはスケールの異なる特徴に非常に敏感に反応する傾向があり、数値特徴の前処理を忘れてしまうと、非常に悪いモデルになってしまいます。</target>
        </trans-unit>
        <trans-unit id="a7f6e12fca9c93deac0f3e9ce5406887ec818c03" translate="yes" xml:space="preserve">
          <source>Improvements to the histogram-based Gradient Boosting estimators</source>
          <target state="translated">ヒストグラムベースの勾配ブースト推定器の改良</target>
        </trans-unit>
        <trans-unit id="eed74af8ff28262ccadec0b3ca567aeb04ce5592" translate="yes" xml:space="preserve">
          <source>Imputation for completing missing values using k-Nearest Neighbors.</source>
          <target state="translated">k-最近傍を用いた欠測値の補完のためのインピュテーション。</target>
        </trans-unit>
        <trans-unit id="0004bf233145469d6159f141af0ae0b05f3c5e9a" translate="yes" xml:space="preserve">
          <source>Imputation transformer for completing missing values.</source>
          <target state="translated">欠落している値を補完するためのインピュテーション変換器。</target>
        </trans-unit>
        <trans-unit id="8154b566118976ff2097cfffb2c92470797b0a69" translate="yes" xml:space="preserve">
          <source>Impute all missing values in X.</source>
          <target state="translated">X の欠落している値をすべてインプリートします。</target>
        </trans-unit>
        <trans-unit id="ad8e498cb05e98f21bd0f42774d74dde4c2bb7ea" translate="yes" xml:space="preserve">
          <source>Impute missing values with mean</source>
          <target state="translated">欠損値を平均値でインピュート</target>
        </trans-unit>
        <trans-unit id="a4715d3875af4e3819958eff35e6816030a9c89e" translate="yes" xml:space="preserve">
          <source>Impute the missing data and score</source>
          <target state="translated">欠損データとスコアをインプリメント</target>
        </trans-unit>
        <trans-unit id="689f1aca2f66f40afe86b2a1257542980cceee50" translate="yes" xml:space="preserve">
          <source>Imputer used to initialize the missing values.</source>
          <target state="translated">欠損値の初期化に使用されるインプータ。</target>
        </trans-unit>
        <trans-unit id="74ee388ccf36d172dba88b767c11eeb31f63d971" translate="yes" xml:space="preserve">
          <source>Imputes all missing values in X.</source>
          <target state="translated">Xの欠落しているすべての値をインプリメントします。</target>
        </trans-unit>
        <trans-unit id="510c592fb9a4fd828788fc0bdd902c165ca78889" translate="yes" xml:space="preserve">
          <source>Imputing missing values before building an estimator</source>
          <target state="translated">推定器を構築する前に欠落値を注入する</target>
        </trans-unit>
        <trans-unit id="87c53ba7fd85032a63ff707cca98951b5852e72d" translate="yes" xml:space="preserve">
          <source>Imputing missing values with variants of IterativeImputer</source>
          <target state="translated">IterativeImputerのバリアントを用いた欠落値の注入</target>
        </trans-unit>
        <trans-unit id="e5d148df74ab3f703a9d283fda0c99f4936ff674" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt;&lt;code&gt;NMF&lt;/code&gt;&lt;/a&gt;, L1 and L2 priors can be added to the loss function in order to regularize the model. The L2 prior uses the Frobenius norm, while the L1 prior uses an elementwise L1 norm. As in &lt;code&gt;ElasticNet&lt;/code&gt;, we control the combination of L1 and L2 with the &lt;code&gt;l1_ratio&lt;/code&gt; (\(\rho\)) parameter, and the intensity of the regularization with the &lt;code&gt;alpha&lt;/code&gt; (\(\alpha\)) parameter. Then the priors terms are:</source>
          <target state="translated">で&lt;a href=&quot;generated/sklearn.decomposition.nmf#sklearn.decomposition.NMF&quot;&gt; &lt;code&gt;NMF&lt;/code&gt; &lt;/a&gt;、L1およびL2事前確率モデルを正則化するために、損失関数に追加することができます。L2事前は、フロベニウスノルムを使用し、L1事前は、要素ごとのL1ノルムを使用します。 &lt;code&gt;ElasticNet&lt;/code&gt; と同様に、L1とL2の組み合わせを &lt;code&gt;l1_ratio&lt;/code&gt; （\（\ rho \））パラメーターで制御し、正則化の強度を &lt;code&gt;alpha&lt;/code&gt; （\（\ alpha \））パラメーターで制御します。次に、事前条件は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="eee03375c59654f18a55a7961e4f26a36fbc2cee" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt;&lt;code&gt;OutputCodeClassifier&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;code_size&lt;/code&gt; attribute allows the user to control the number of classifiers which will be used. It is a percentage of the total number of classes.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.multiclass.outputcodeclassifier#sklearn.multiclass.OutputCodeClassifier&quot;&gt; &lt;code&gt;OutputCodeClassifier&lt;/code&gt; &lt;/a&gt;、 &lt;code&gt;code_size&lt;/code&gt; 属性は、ユーザが使用する分類子の数を制御することを可能にします。クラスの総数に対する割合です。</target>
        </trans-unit>
        <trans-unit id="92869ea1268ab85728d32cc145b2fc2a3cf98201" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if data for classification are unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;、場合分類のためのデータがアンバランスである（例えば、多くの肯定的及び少数陰性）、セット &lt;code&gt;class_weight='balanced'&lt;/code&gt; 及び/又は異なるペナルティパラメータ試みる &lt;code&gt;C&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="3c0402c73702f19dd4de5bea870fc6f39e9426a9" translate="yes" xml:space="preserve">
          <source>In &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, if the data is unbalanced (e.g. many positive and few negative), set &lt;code&gt;class_weight='balanced'&lt;/code&gt; and/or try different penalty parameters &lt;code&gt;C&lt;/code&gt;.</source>
          <target state="translated">で&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;、データがアンバランスである場合（例えば、多くの肯定的及び少数陰性）、セット &lt;code&gt;class_weight='balanced'&lt;/code&gt; 及び/又は異なるペナルティパラメータ試みる &lt;code&gt;C&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="d4a2dd93e9c8bc18123ea577d336109c88e8c2c3" translate="yes" xml:space="preserve">
          <source>In &lt;strong&gt;averaging methods&lt;/strong&gt;, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.</source>
          <target state="translated">で&lt;strong&gt;メソッドを平均化&lt;/strong&gt;、駆動原理は平均的な彼らの予測に独立して、いくつかの推定を構築することです。平均すると、結合された推定量は、その分散が減少するため、通常、単一ベースの推定量よりも優れています。</target>
        </trans-unit>
        <trans-unit id="ca51c131377adedf53770a869ad18245bd6bd115" translate="yes" xml:space="preserve">
          <source>In a binary classification context, imposing a monotonic constraint means that the feature is supposed to have a positive / negative effect on the probability to belong to the positive class. Monotonic constraints are not supported for multiclass context.</source>
          <target state="translated">2値分類のコンテキストでは、単調制約を課すことは、特徴が正のクラスに属する確率に正/負の影響を与えることを意味します。単調制約は、マルチクラス・コンテキストではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="baeac0931c0e4b4385579000935f2bb52ceb9f07" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;lsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="translated">バイナリ分類タスクでは、用語「ポジティブ」および「ネガティブ」は分類子の予測を指し、用語「true」および「false」はその予測が外部判断に対応するかどうかを示します（ 「オブザベーション」としても知られています）。これらの定義を前提として、次の表を作成できます。</target>
        </trans-unit>
        <trans-unit id="ccc920586f4d3de666e5e909b4599881349f812c" translate="yes" xml:space="preserve">
          <source>In a binary classification task, the terms &amp;lsquo;&amp;rsquo;positive&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;negative&amp;rsquo;&amp;rsquo; refer to the classifier&amp;rsquo;s prediction, and the terms &amp;lsquo;&amp;rsquo;true&amp;rsquo;&amp;rsquo; and &amp;lsquo;&amp;rsquo;false&amp;rsquo;&amp;rsquo; refer to whether that prediction corresponds to the external judgment (sometimes known as the &amp;lsquo;&amp;rsquo;observation&amp;rsquo;&amp;rsquo;). Given these definitions, we can formulate the following table:</source>
          <target state="translated">二項分類タスクでは、「ポジティブ」および「ネガティブ」という用語は分類器の予測を指し、「真」および「偽」という用語はその予測が外部の判断に対応するかどうかを示します（ 「観察」としても知られています）。これらの定義があれば、次の表を作成できます。</target>
        </trans-unit>
        <trans-unit id="995a1ae8b5be72e5d8cbdf391052b665e77e9964" translate="yes" xml:space="preserve">
          <source>In a first step, the hierarchical clustering is performed without connectivity constraints on the structure and is solely based on distance, whereas in a second step the clustering is restricted to the k-Nearest Neighbors graph: it&amp;rsquo;s a hierarchical clustering with structure prior.</source>
          <target state="translated">最初のステップでは、階層的クラスタリングは構造の接続制約なしで実行され、距離のみに基づいています。一方、2番目のステップでは、クラスタリングはk-Nearest Neighborsグラフに制限されます。これは、事前構造を持つ階層的クラスタリングです。</target>
        </trans-unit>
        <trans-unit id="0336cb4d8e7c9adb72abdea9417802db49cccd1f" translate="yes" xml:space="preserve">
          <source>In a large text corpus, some words will be very present (e.g. &amp;ldquo;the&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, &amp;ldquo;is&amp;rdquo; in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.</source>
          <target state="translated">大きなテキストコーパスでは、一部の単語が非常に存在するため（英語では「the」、「a」、「is」など）、ドキュメントの実際の内容に関する意味のある情報はほとんどありません。直接カウントデータを分類子に直接フィードする場合、これらの非常に頻繁な用語は、より希少でより興味深い用語の頻度を覆い隠します。</target>
        </trans-unit>
        <trans-unit id="0caaa107286ab067ca8115855386dd04703bccc4" translate="yes" xml:space="preserve">
          <source>In a multiclass setting, specifies the class for which the PDPs should be computed. Note that for binary classification, the positive class (index 1) is always used.</source>
          <target state="translated">マルチクラス設定では、PDPを計算するクラスを指定します。2値分類では、常に正のクラス(インデックス1)が使用されることに注意してください。</target>
        </trans-unit>
        <trans-unit id="52eb2197195ece26c6612081f2107f907b3e4099" translate="yes" xml:space="preserve">
          <source>In a multioutput setting, specifies the task for which the PDPs should be computed.</source>
          <target state="translated">マルチ出力設定では、PDPを計算するタスクを指定します。</target>
        </trans-unit>
        <trans-unit id="cd0ed349168abd35a1fce87e6ae9e8ccc5ff58f4" translate="yes" xml:space="preserve">
          <source>In a nutshell, the following table summarizes the solvers characteristics:</source>
          <target state="translated">一言で言えば、ソルバーの特徴をまとめると以下のようになります。</target>
        </trans-unit>
        <trans-unit id="b4ec4bcaff3e86d4d99c938f5623ab4b737e65c7" translate="yes" xml:space="preserve">
          <source>In a real world setting, the &lt;code&gt;n_features&lt;/code&gt; parameter can be left to its default value of &lt;code&gt;2 ** 20&lt;/code&gt; (roughly one million possible features). If memory or downstream models size is an issue selecting a lower value such as &lt;code&gt;2 **
18&lt;/code&gt; might help without introducing too many additional collisions on typical text classification tasks.</source>
          <target state="translated">実際の設定では、 &lt;code&gt;n_features&lt;/code&gt; パラメータをデフォルト値の &lt;code&gt;2 ** 20&lt;/code&gt; （約100万の可能な機能）のままにすることができます。メモリまたはダウンストリームモデルのサイズが問題である場合、 &lt;code&gt;2 ** 18&lt;/code&gt; などの低い値を選択すると、通常のテキスト分類タスクで衝突を追加しすぎずに役立つ場合があります。</target>
        </trans-unit>
        <trans-unit id="c75e295f24e05d06cacc1a2f9bb570a61bdd802e" translate="yes" xml:space="preserve">
          <source>In a similar manner, the boston housing data set is used to show the impact of transforming the targets before learning a model. In this example, the targets to be predicted corresponds to the weighted distances to the five Boston employment centers.</source>
          <target state="translated">同様に、モデルを学習する前にターゲットを変換した場合の影響を示すために、ボストンの住宅データセットを使用しています。この例では、予測されるターゲットは、ボストンの5つの雇用センターまでの加重距離に対応しています。</target>
        </trans-unit>
        <trans-unit id="c210295417ef2f29cc593be46bbc5efed5892a5f" translate="yes" xml:space="preserve">
          <source>In addition of using an imputing method, we can also keep an indication of the missing information using &lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt;&lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt;&lt;/a&gt; which might carry some information.</source>
          <target state="translated">補完メソッドを使用するだけでなく、&lt;a href=&quot;../modules/generated/sklearn.impute.missingindicator#sklearn.impute.MissingIndicator&quot;&gt; &lt;code&gt;sklearn.impute.MissingIndicator&lt;/code&gt; &lt;/a&gt;を使用して欠落している情報を示すこともできます。</target>
        </trans-unit>
        <trans-unit id="67d21513f58775c1e37b37d0e7fc556492bd761a" translate="yes" xml:space="preserve">
          <source>In addition to imputing the missing values, the imputers have an &lt;code&gt;add_indicator&lt;/code&gt; parameter that marks the values that were missing, which might carry some information.</source>
          <target state="translated">欠落している値を入力することに加えて、 &lt;code&gt;add_indicator&lt;/code&gt; 者には、欠落している値をマークするadd_indicatorパラメーターがあり、情報が含まれている可能性があります。</target>
        </trans-unit>
        <trans-unit id="45e3263783ee36dc90c5821ae7ffc8d210750151" translate="yes" xml:space="preserve">
          <source>In addition to its current contents, this module will eventually be home to refurbished versions of Pipeline and FeatureUnion.</source>
          <target state="translated">現在の内容に加えて、このモジュールは最終的にPipelineとFeatureUnionの改修版のホームになる予定です。</target>
        </trans-unit>
        <trans-unit id="3dda0db479e61a3dc2539c918fe85f072a3cc4a4" translate="yes" xml:space="preserve">
          <source>In addition to standard scikit-learn estimator API, GaussianProcessRegressor:</source>
          <target state="translated">標準的なscikit-learnの推定APIに加えて、GaussianProcessRegressorがあります。</target>
        </trans-unit>
        <trans-unit id="6c259b1081efe473add72a6c01ee26dbc96ee486" translate="yes" xml:space="preserve">
          <source>In addition to the mean of the predictive distribution, also its standard deviation can be returned.</source>
          <target state="translated">予測分布の平均に加えて,その標準偏差も返すことができます.</target>
        </trans-unit>
        <trans-unit id="f5f01da0b407208bd57121f71ed7408cbbce3fe6" translate="yes" xml:space="preserve">
          <source>In addition, as there is no useful information in the intensity of the image, or its gradient, we choose to perform the spectral clustering on a graph that is only weakly informed by the gradient. This is close to performing a Voronoi partition of the graph.</source>
          <target state="translated">さらに、画像の強度やグラデーションには有用な情報がないので、グラデーションの情報が弱いグラフ上でスペクトルクラスタリングを実行することを選択します。これはグラフのボロノイ分割の実行に近いものです。</target>
        </trans-unit>
        <trans-unit id="8be2789c3e2f5a1d410c34b62e20c28c8adc9fef" translate="yes" xml:space="preserve">
          <source>In addition, if the &lt;code&gt;dask&lt;/code&gt; and &lt;code&gt;distributed&lt;/code&gt; Python packages are installed, it is possible to use the &amp;lsquo;dask&amp;rsquo; backend for better scheduling of nested parallel calls without over-subscription and potentially distribute parallel calls over a networked cluster of several hosts.</source>
          <target state="translated">さらに、 &lt;code&gt;dask&lt;/code&gt; および &lt;code&gt;distributed&lt;/code&gt; Pythonパッケージがインストールされている場合は、「dask」バックエンドを使用して、オーバーサブスクリプションなしでネストされた並列呼び出しのスケジューリングを改善し、複数のホストのネットワーク化されたクラスターに並列呼び出しを分散することができます。</target>
        </trans-unit>
        <trans-unit id="1068dbee0dd3c16e2fc93e44b0ce455f5b052f8b" translate="yes" xml:space="preserve">
          <source>In addition, scikit-learn includes various random sample generators that can be used to build artificial datasets of controlled size and complexity.</source>
          <target state="translated">さらに、scikit-learnには、サイズと複雑さが制御された人工的なデータセットを構築するために使用できる様々なランダムサンプルジェネレータが含まれています。</target>
        </trans-unit>
        <trans-unit id="fc65b58b68e776527046619280b83dca96b85eef" translate="yes" xml:space="preserve">
          <source>In addition, some of the numpy routines that are used internally by scikit-learn may also be parallelized if numpy is installed with specific numerical libraries such as MKL, OpenBLAS, or BLIS.</source>
          <target state="translated">さらに、scikit-learnで内部的に使用されるいくつかのnumpyルーチンは、numpyがMKL,OpenBLAS,BLISのような特定の数値ライブラリと一緒にインストールされていれば、並列化されているかもしれません。</target>
        </trans-unit>
        <trans-unit id="5a9dc36feb47a20be69368bf3755ac289f3cd578" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellaneous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="translated">さらに、&lt;a href=&quot;#loading-other-datasets&quot;&gt;他のデータセット&lt;/a&gt;のロードのセクションで説明されているように、他の形式のデータセットまたは他の場所からデータセットをロードするためのその他のツールもあります。</target>
        </trans-unit>
        <trans-unit id="67ed28f1d0cd9fef0560dd0bbfe2b568680ea5a6" translate="yes" xml:space="preserve">
          <source>In addition, there are also miscellanous tools to load datasets of other formats or from other locations, described in the &lt;a href=&quot;#loading-other-datasets&quot;&gt;Loading other datasets&lt;/a&gt; section.</source>
          <target state="translated">さらに、&lt;a href=&quot;#loading-other-datasets&quot;&gt;他のデータセット&lt;/a&gt;のロードセクションで説明されている、他の形式のデータセットまたは他の場所からロードするためのその他のツールもあります。</target>
        </trans-unit>
        <trans-unit id="5f2d75a19b27e52127d76b03616ce749746e4308" translate="yes" xml:space="preserve">
          <source>In addition, we show two different ways to dispatch the columns to the particular pre-processor: by column names and by column data types.</source>
          <target state="translated">さらに、カラムを特定のプリプロセッサにディスパッチする方法として、カラム名によるものとカラムデータ型によるものの2つの異なる方法を示します。</target>
        </trans-unit>
        <trans-unit id="846c6c3d11b49bd5243a8b72c066c7aae06dcfe3" translate="yes" xml:space="preserve">
          <source>In addition, we use the mask of the objects to restrict the graph to the outline of the objects. In this example, we are interested in separating the objects one from the other, and not from the background.</source>
          <target state="translated">さらに、オブジェクトのマスクを使用して、グラフをオブジェクトの輪郭に限定しています。この例では、オブジェクトを背景からではなく、1つのオブジェクトから他のオブジェクトに分離したいと考えています。</target>
        </trans-unit>
        <trans-unit id="b490744f01019d4237b3a8568465e031a5ae6e1f" translate="yes" xml:space="preserve">
          <source>In all these strategies, the &lt;code&gt;predict&lt;/code&gt; method completely ignores the input data.</source>
          <target state="translated">これらすべての戦略で、 &lt;code&gt;predict&lt;/code&gt; メソッドは入力データを完全に無視します。</target>
        </trans-unit>
        <trans-unit id="450c8a41f7c5da3bb2b7da9a15306b194b36c681" translate="yes" xml:space="preserve">
          <source>In an &lt;strong&gt;unsupervised setting&lt;/strong&gt; it can be used to group similar documents together by applying clustering algorithms such as &lt;a href=&quot;clustering#k-means&quot;&gt;K-means&lt;/a&gt;:</source>
          <target state="translated">で&lt;strong&gt;教師なしの設定&lt;/strong&gt;、それは、次のようなクラスタリングアルゴリズムを適用することによって、一緒にグループに同様のドキュメントを使用することができる&lt;a href=&quot;clustering#k-means&quot;&gt;K-手段&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e5af8b183011d6bf7238d58f71b94384a5a96f84" translate="yes" xml:space="preserve">
          <source>In any case be warned that decreasing model complexity can hurt accuracy as mentioned above. For instance a non-linearly separable problem can be handled with a speedy linear model but prediction power will very likely suffer in the process.</source>
          <target state="translated">いずれにしても、上記のようにモデルの複雑さを減らすと精度が低下する可能性があることに注意してください。例えば、非線形に分離可能な問題は、高速な線形モデルで処理することができますが、その過程で予測力が低下する可能性が高いです。</target>
        </trans-unit>
        <trans-unit id="8c17ce8abfedb506f7ed46ebde27121f581c8bb7" translate="yes" xml:space="preserve">
          <source>In applications where a high false positive rate is not tolerable the parameter &lt;code&gt;max_fpr&lt;/code&gt; of &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; can be used to summarize the ROC curve up to the given limit.</source>
          <target state="translated">高い偽陽性率は、パラメータの許容されていないアプリケーションでは &lt;code&gt;max_fpr&lt;/code&gt; の&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; を&lt;/a&gt;与えられた限界までROC曲線を要約するために使用することができます。</target>
        </trans-unit>
        <trans-unit id="bbcc07c440f8193b3e7ecf64eaaca0e386adcbad" translate="yes" xml:space="preserve">
          <source>In bin edges for feature &lt;code&gt;i&lt;/code&gt;, the first and last values are used only for &lt;code&gt;inverse_transform&lt;/code&gt;. During transform, bin edges are extended to:</source>
          <target state="translated">特徴 &lt;code&gt;i&lt;/code&gt; の &lt;code&gt;inverse_transform&lt;/code&gt; は、最初と最後の値は、inverse_transformに対してのみ使用されます。変換中、ビンのエッジは次のように拡張されます。</target>
        </trans-unit>
        <trans-unit id="9d083c0b55e1a00133d4b27dd85f5ea26aca3922" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, the Jaccard similarity coefficient score is equal to the classification accuracy.</source>
          <target state="translated">二元分類や多元分類では、ジャカード類似度係数スコアは分類精度に等しい。</target>
        </trans-unit>
        <trans-unit id="834fbb10f3b1dd0752ef9b7f9aa530ac5202b2db" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_score&lt;/code&gt; function.</source>
          <target state="translated">バイナリおよびマルチクラス分類では、この関数は &lt;code&gt;jaccard_score&lt;/code&gt; 関数と同じです。</target>
        </trans-unit>
        <trans-unit id="b0b30958f6975dadd3d7eaf24f5447254d56c629" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equal to the &lt;code&gt;jaccard_similarity_score&lt;/code&gt; function.</source>
          <target state="translated">バイナリおよびマルチクラス分類では、この関数は &lt;code&gt;jaccard_similarity_score&lt;/code&gt; 関数と同じです。</target>
        </trans-unit>
        <trans-unit id="e731c9654f26a8d7255165d2c0d5f78e47c3bd9a" translate="yes" xml:space="preserve">
          <source>In binary and multiclass classification, this function is equivalent to the &lt;code&gt;accuracy_score&lt;/code&gt;. It differs in the multilabel classification problem.</source>
          <target state="translated">バイナリおよびマルチクラス分類では、この関数は &lt;code&gt;accuracy_score&lt;/code&gt; スコアと同等です。マルチラベル分類の問題が異なります。</target>
        </trans-unit>
        <trans-unit id="c4cb57bb3e2c0bb1485829473f6ca6362cee5b90" translate="yes" xml:space="preserve">
          <source>In binary class case, assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; is always negative (since the signs disagree), implying &lt;code&gt;1 - margin&lt;/code&gt; is always greater than 1. The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">バイナリクラスの場合、y_trueのラベルが+1と-1でエンコードされていると仮定すると、予測ミスがあった場合、 &lt;code&gt;margin = y_true * pred_decision&lt;/code&gt; は常に負であり（符号が一致しないため）、 &lt;code&gt;1 - margin&lt;/code&gt; を意味します-marginは常に1より大きいです。したがって、累積されたヒンジ損失は、分類子によって行われた誤りの数の上限です。</target>
        </trans-unit>
        <trans-unit id="f2c8a5d61695d64c32adbdec8051b4ecc7f404cb" translate="yes" xml:space="preserve">
          <source>In binary classification settings</source>
          <target state="translated">二値分類の設定では</target>
        </trans-unit>
        <trans-unit id="0e8524872beef3003e748e1d9b4f90c7ce280313" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with a tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="translated">どちらの場合も、基準はエポックによって1回評価され、基準が行の &lt;code&gt;n_iter_no_change&lt;/code&gt; 時間を改善しない場合、アルゴリズムは停止します。改善は許容誤差 &lt;code&gt;tol&lt;/code&gt; で評価され、アルゴリズムは最大反復回数 &lt;code&gt;max_iter&lt;/code&gt; の後でいずれの場合でも停止します。</target>
        </trans-unit>
        <trans-unit id="e7dad232dab7fc7fe4bb0ec13d7d0a07fef6ce88" translate="yes" xml:space="preserve">
          <source>In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve &lt;code&gt;n_iter_no_change&lt;/code&gt; times in a row. The improvement is evaluated with absolute tolerance &lt;code&gt;tol&lt;/code&gt;, and the algorithm stops in any case after a maximum number of iteration &lt;code&gt;max_iter&lt;/code&gt;.</source>
          <target state="translated">どちらの場合も、基準はエポックによって1回評価され、基準が連続して &lt;code&gt;n_iter_no_change&lt;/code&gt; 時間を改善しない場合にアルゴリズムは停止します。改善は絶対許容誤差 &lt;code&gt;tol&lt;/code&gt; で評価され、アルゴリズムはいずれの場合も最大反復回数 &lt;code&gt;max_iter&lt;/code&gt; の後に停止します。</target>
        </trans-unit>
        <trans-unit id="f03bffae8069d1108a85252dc34a4485434865b8" translate="yes" xml:space="preserve">
          <source>In both cases, the kernel&amp;rsquo;s parameters are estimated using the maximum likelihood principle.</source>
          <target state="translated">どちらの場合も、カーネルのパラメーターは最尤法を使用して推定されます。</target>
        </trans-unit>
        <trans-unit id="dc8004c8d5b437fc6c479e2e5882eb635fa97592" translate="yes" xml:space="preserve">
          <source>In both examples below, the main result is that the empirical covariance estimate, as a non-robust one, is highly influenced by the heterogeneous structure of the observations. Although the robust covariance estimate is able to focus on the main mode of the data distribution, it sticks to the assumption that the data should be Gaussian distributed, yielding some biased estimation of the data structure, but yet accurate to some extent. The One-Class SVM does not assume any parametric form of the data distribution and can therefore model the complex shape of the data much better.</source>
          <target state="translated">以下の両方の事例において、主な結果は、経験的な共分散推定が、非ロバストなものとして、オブザベーションの不均一構造に大きく影響されることです。ロバスト共分散推定は、データ分布の主なモードに焦点を当てることができますが、データがガウス分布であるべきだという仮定に固執し、データ構造の推定に若干の偏りが生じますが、ある程度正確です。ワンクラスSVMはデータ分布のパラメトリックな形態を仮定しないので、データの複雑な形状をより良くモデル化することができます。</target>
        </trans-unit>
        <trans-unit id="7f2b051010be4e679b8556fa182a1724fa1e49b9" translate="yes" xml:space="preserve">
          <source>In case the file contains a pairwise preference constraint (known as &amp;ldquo;qid&amp;rdquo; in the svmlight format) these are ignored unless the query_id parameter is set to True. These pairwise preference constraints can be used to constraint the combination of samples when using pairwise loss functions (as is the case in some learning to rank problems) so that only pairs with the same query_id value are considered.</source>
          <target state="translated">ファイルにペアワイズ設定制約（svmlight形式では「qid」と呼ばれる）が含まれている場合、query_idパラメーターがTrueに設定されていない限り、これらは無視されます。これらのペアワイズ優先制約を使用して、ペアワイズ損失関数を使用するときにサンプルの組み合わせを制約でき（ランク付け問題の学習の場合のように）、同じquery_id値を持つペアのみが考慮されます。</target>
        </trans-unit>
        <trans-unit id="b2d3bbc7ab1d1edcd850a10f6fb01a251c14a28b" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zero&amp;rsquo;s in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="translated">不明なカテゴリが検出された場合（ワンホットエンコーディングではすべてゼロ）、 &lt;code&gt;None&lt;/code&gt; を使用してこのカテゴリを表します。</target>
        </trans-unit>
        <trans-unit id="d452896d1312cac0434176b68ca8ca9a2bb1195e" translate="yes" xml:space="preserve">
          <source>In case unknown categories are encountered (all zeros in the one-hot encoding), &lt;code&gt;None&lt;/code&gt; is used to represent this category.</source>
          <target state="translated">不明なカテゴリが検出された場合（ワンホットエンコーディングではすべてゼロ）、このカテゴリを表すために &lt;code&gt;None&lt;/code&gt; が使用されます。</target>
        </trans-unit>
        <trans-unit id="ca499264726caa99e06bab43fc3d4644ea84df01" translate="yes" xml:space="preserve">
          <source>In cases where not all of a pairwise distance matrix needs to be stored at once, this is used to calculate pairwise distances in &lt;code&gt;working_memory&lt;/code&gt;-sized chunks. If &lt;code&gt;reduce_func&lt;/code&gt; is given, it is run on each chunk and its return values are concatenated into lists, arrays or sparse matrices.</source>
          <target state="translated">すべてのペアワイズ距離マトリックスを一度に格納する必要がない場合、これを使用して、 &lt;code&gt;working_memory&lt;/code&gt; サイズのチャンクのペアワイズ距離を計算します。 &lt;code&gt;reduce_func&lt;/code&gt; が指定されている場合、各チャンクで実行され、その戻り値はリスト、配列、または疎行列に連結されます。</target>
        </trans-unit>
        <trans-unit id="261de18f8066fcaced5cb3f145cb26c170301e09" translate="yes" xml:space="preserve">
          <source>In cases where the data is not uniformly sampled, radius-based neighbors classification in &lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt;&lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt;&lt;/a&gt; can be a better choice. The user specifies a fixed radius \(r\), such that points in sparser neighborhoods use fewer nearest neighbors for the classification. For high-dimensional parameter spaces, this method becomes less effective due to the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;.</source>
          <target state="translated">データが均一にサンプリングされていない場合は、&lt;a href=&quot;generated/sklearn.neighbors.radiusneighborsclassifier#sklearn.neighbors.RadiusNeighborsClassifier&quot;&gt; &lt;code&gt;RadiusNeighborsClassifier&lt;/code&gt; &lt;/a&gt;での半径ベースの近傍分類の方が適しています。ユーザーは固定半径\（r \）を指定します。これにより、まばらな近傍内のポイントは、分類に使用する最近傍点が少なくなります。高次元のパラメーター空間の場合、この方法は、いわゆる「次元の呪い」のために効果が低くなります。</target>
        </trans-unit>
        <trans-unit id="46149a533d1136e96a72fc2595f06ccb02814862" translate="yes" xml:space="preserve">
          <source>In certain cases Theil-Sen performs better than &lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC&lt;/a&gt; which is also a robust method. This is illustrated in the second example below where outliers with respect to the x-axis perturb RANSAC. Tuning the &lt;code&gt;residual_threshold&lt;/code&gt; parameter of RANSAC remedies this but in general a priori knowledge about the data and the nature of the outliers is needed. Due to the computational complexity of Theil-Sen it is recommended to use it only for small problems in terms of number of samples and features. For larger problems the &lt;code&gt;max_subpopulation&lt;/code&gt; parameter restricts the magnitude of all possible combinations of p subsample points to a randomly chosen subset and therefore also limits the runtime. Therefore, Theil-Sen is applicable to larger problems with the drawback of losing some of its mathematical properties since it then works on a random subset.</source>
          <target state="translated">場合によっては、Theil-Senは、堅牢な方法である&lt;a href=&quot;../../modules/linear_model#ransac-regression&quot;&gt;RANSAC&lt;/a&gt;よりもパフォーマンスが優れています。これは、x軸に関する外れ値がRANSACを混乱させる以下の2番目の例に示されています。チューニング &lt;code&gt;residual_threshold&lt;/code&gt; の RANSAC救済のパラメータにこれを一般的には、データや外れ値の性質についての事前知識が必要とされています。 Theil-Senは計算が複雑であるため、サンプルと機能の数の点で小さな問題に対してのみ使用することをお勧めします。より大きな問題の場合、 &lt;code&gt;max_subpopulation&lt;/code&gt; パラメータは、p個のサブサンプルポイントのすべての可能な組み合わせの大きさをランダムに選択されたサブセットに制限するため、実行時間も制限されます。したがって、Theil-Senはより大きな問題に適用でき、ランダムなサブセットで機能するため、その数学的な特性の一部が失われるという欠点があります。</target>
        </trans-unit>
        <trans-unit id="08403787ed9849b402f6d04f68a0bae46063dfaf" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id13&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="translated">&lt;a href=&quot;#id13&quot;&gt;ベイジアンリッジ回帰&lt;/a&gt;とは対照的に、\（w_ {i} \）の各座標には独自の標準偏差\（\ lambda_i \）があります。すべての前の\（\ lambda_i \）は、ハイパーパラメーター\（\ lambda_1 \）および\（\ lambda_2 \）によって与えられる同じガンマ分布になるように選択されます。</target>
        </trans-unit>
        <trans-unit id="f00603c6aeddee02bf1dc7fdebe82c8fea70d634" translate="yes" xml:space="preserve">
          <source>In contrast to &lt;a href=&quot;#id9&quot;&gt;Bayesian Ridge Regression&lt;/a&gt;, each coordinate of \(w_{i}\) has its own standard deviation \(\lambda_i\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by hyperparameters \(\lambda_1\) and \(\lambda_2\).</source>
          <target state="translated">&lt;a href=&quot;#id9&quot;&gt;ベイジアンリッジ回帰&lt;/a&gt;とは対照的に、\（w_ {i} \）の各座標には独自の標準偏差\（\ lambda_i \）があります。すべての\（\ lambda_i \）の優先順位は、ハイパーパラメーター\（\ lambda_1 \）および\（\ lambda_2 \）によって与えられる同じガンマ分布になるように選択されます。</target>
        </trans-unit>
        <trans-unit id="741dc2ca1b0b96b753a4293cdc66da483cb961b9" translate="yes" xml:space="preserve">
          <source>In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.</source>
          <target state="translated">GridSearchCVとは異なり,すべてのパラメータ値を試すのではなく,指定された分布の中から一定数のパラメータ設定をサンプリングします.試されるパラメータ設定数は n_iter で与えられます.</target>
        </trans-unit>
        <trans-unit id="f7007cbebb915951a7329a621ec59e7bfd3c1528" translate="yes" xml:space="preserve">
          <source>In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities.</source>
          <target state="translated">多数決(ハード投票)とは対照的に、ソフト投票は、予測された確率の総和のargmaxとしてクラスラベルを返します。</target>
        </trans-unit>
        <trans-unit id="a5222e41535c7e60d0bed8020d5a39a4cdb9c58d" translate="yes" xml:space="preserve">
          <source>In contrast to the original publication &lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt;, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.</source>
          <target state="translated">元の出版物&lt;a href=&quot;#b2001&quot; id=&quot;id6&quot;&gt;[B2001]&lt;/a&gt;とは異なり、scikit-learnの実装では、各分類子に単一のクラスに投票させるのではなく、確率予測を平均化することで分類子を組み合わせます。</target>
        </trans-unit>
        <trans-unit id="092465bd0b61837459fb29bf14c2dda6ed20e949" translate="yes" xml:space="preserve">
          <source>In contrast to the regression setting, the posterior of the latent function \(f\) is not Gaussian even for a GP prior since a Gaussian likelihood is inappropriate for discrete class labels. Rather, a non-Gaussian likelihood corresponding to the logistic link function (logit) is used. GaussianProcessClassifier approximates the non-Gaussian posterior with a Gaussian based on the Laplace approximation. More details can be found in Chapter 3 of &lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]&lt;/a&gt;.</source>
          <target state="translated">回帰設定とは対照的に、潜在クラス\（f \）の事後はガウス分布ではありません。これは、ガウス確率が離散クラスラベルには不適切であるためです。むしろ、ロジスティックリンク関数（ロジット）に対応する非ガウス尤度が使用されます。 GaussianProcessClassifierは、ラプラス近似に基づいて、ガウス以外の事後をガウスで近似します。詳細については、&lt;a href=&quot;#rw2006&quot; id=&quot;id4&quot;&gt;[RW2006]の&lt;/a&gt;第3章を参照してください。</target>
        </trans-unit>
        <trans-unit id="8da23c4fea95dfb9e1a4723525c1617ef732103e" translate="yes" xml:space="preserve">
          <source>In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization.</source>
          <target state="translated">対照的に、データ量が少ない場合、SVMのトレーニングスコアは検証スコアよりもはるかに大きくなります。より多くのトレーニングサンプルを追加することで、一般化が高まる可能性が高いです。</target>
        </trans-unit>
        <trans-unit id="2d7f12a42ea8277b24625f1aff8d53cb363a14e0" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{\text{n\_classes}}\).</source>
          <target state="translated">これに対して,従来の精度が偶然性を超えているのは,分類器が不均衡なテストセットを利用しているからに過ぎないとすると,均衡した精度は,適宜,\(\frac{1}{\text{n\_classes}})に落ちていくことになる.</target>
        </trans-unit>
        <trans-unit id="8343cdcc0bd2973a4149cb63a31822f5be571a78" translate="yes" xml:space="preserve">
          <source>In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{n\_classes}\).</source>
          <target state="translated">これに対して,分類器が不均衡なテストセットを利用しているために,従来の精度が偶然性を超えているだけであれば,均衡した精度は,適宜,\(\frac{1}{n_\classes})まで低下します.</target>
        </trans-unit>
        <trans-unit id="89611c1358b346353d5469c5670ea64fb02fcdd7" translate="yes" xml:space="preserve">
          <source>In descending order of quality, when trained (outside of this example) on all 4 features using 30 estimators and scored using 10 fold cross validation, we see:</source>
          <target state="translated">品質の高い順に、30 個の推定子を使用して 4 つの特徴すべてについて(この例以外で)学習し、10 倍のクロスバリデーションを使用してスコアリングすると、次のようになります。</target>
        </trans-unit>
        <trans-unit id="0732cca6c2251b860da4c331fa5748d479b14945" translate="yes" xml:space="preserve">
          <source>In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).</source>
          <target state="translated">アンサンブルアルゴリズムでは、バギング法は、元の訓練セットのランダムな部分集合上にブラックボックス推定器の複数のインスタンスを構築し、それらの個々の予測を集約して最終予測を形成するアルゴリズムのクラスを形成する。これらの手法は、基本推定量(例えば、決定木)の構築手順にランダム化を導入し、その中からアンサンブルを作成することで、基本推定量(例えば、決定木)の分散を減らす方法として使用される。多くの場合、バギング手法は、基礎となる基本アルゴリズムを適応させる必要がなく、単一モデルに関して改善する非常にシンプルな方法を構成している。オーバーフィットを減らす方法を提供するので、バギング手法は、強力で複雑なモデル(例えば、完全に開発された決定木)に最適に働き、通常は弱いモデル(例えば、浅い決定木)に最適に働くブースティング手法とは対照的です。</target>
        </trans-unit>
        <trans-unit id="5305d1e9b70806a8391e61e804a0df6abd8f6cc5" translate="yes" xml:space="preserve">
          <source>In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">バイナリメトリックをマルチクラスまたはマルチラベルの問題に拡張する場合、データは、クラスごとに1つずつ、バイナリ問題のコレクションとして扱われます。次に、クラスのセット全体でバイナリメトリック計算を平均化する方法がいくつかあります。それぞれの方法は、いくつかのシナリオで役立ちます。可能な場合は、 &lt;code&gt;average&lt;/code&gt; パラメーターを使用してこれらの中から選択する必要があります。</target>
        </trans-unit>
        <trans-unit id="e87cfc9dff0fe670bd40ebf7e26edaa15ca842ad" translate="yes" xml:space="preserve">
          <source>In extremely randomized trees (see &lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt;&lt;code&gt;ExtraTreesClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt;&lt;code&gt;ExtraTreesRegressor&lt;/code&gt;&lt;/a&gt; classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:</source>
          <target state="translated">極端にランダム化されたツリー（&lt;a href=&quot;generated/sklearn.ensemble.extratreesclassifier#sklearn.ensemble.ExtraTreesClassifier&quot;&gt; &lt;code&gt;ExtraTreesClassifier&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.ensemble.extratreesregressor#sklearn.ensemble.ExtraTreesRegressor&quot;&gt; &lt;code&gt;ExtraTreesRegressor&lt;/code&gt; &lt;/a&gt;クラスを参照）では、ランダム性は、スプリットの計算方法をさらに一歩進めます。ランダムフォレストの場合と同様に、候補フィーチャのランダムサブセットが使用されますが、最も特徴的なしきい値を探す代わりに、各候補フィーチャに対してランダムにしきい値が描画され、ランダムに生成されたこれらのしきい値の最適なものが分割ルールとして選択されます。これにより、通常、モデルの分散をもう少し減らすことができますが、バイアスが少し大きくなります。</target>
        </trans-unit>
        <trans-unit id="5c1305e3ce4cbb99adc8d313e42a43efab81ea5c" translate="yes" xml:space="preserve">
          <source>In fact, this dataset only has one version. The iris dataset on the other hand has multiple versions:</source>
          <target state="translated">実際,このデータセットには1つのバージョンしかない.一方,虹彩データセットには複数のバージョンがある.</target>
        </trans-unit>
        <trans-unit id="63493dde535d33b43819cf48666bb2a9620c2476" translate="yes" xml:space="preserve">
          <source>In french but still a reference: Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.</source>
          <target state="translated">フランス語ですが、まだ参照してください。Tenenhaus,M.(1998).回帰PLS:理論と実践.パリ。エディション・テクニック。</target>
        </trans-unit>
        <trans-unit id="6e95c3ada3b2525ed5f608da19594b4a42ad3dc4" translate="yes" xml:space="preserve">
          <source>In general doing predictions in bulk (many instances at the same time) is more efficient for a number of reasons (branching predictability, CPU cache, linear algebra libraries optimizations etc.). Here we see on a setting with few features that independently of estimator choice the bulk mode is always faster, and for some of them by 1 to 2 orders of magnitude:</source>
          <target state="translated">一般的に、多くの理由(分岐予測可能性、CPUキャッシュ、線形代数ライブラリの最適化など)から、バルク(多数のインスタンスを同時に)で予測を行う方が効率的である。ここでは、いくつかの特徴を持つ設定では、推定器の選択に関係なくバルクモードの方が常に高速であり、1~2桁の差があることを示している。</target>
        </trans-unit>
        <trans-unit id="73d5a0649f1537ceaa4a43b2819de8ab34f4f95d" translate="yes" xml:space="preserve">
          <source>In general, &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; is a technique used for analyzing similarity or dissimilarity data. It attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="translated">一般に、&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;は、類似性または非類似性のデータを分析するために使用される手法です。類似性または非類似性のデータを幾何学的空間の距離としてモデル化しようとします。データは、オブジェクト間の類似性の評価、分子の相互作用頻度、または国間の貿易指数です。</target>
        </trans-unit>
        <trans-unit id="d5f14cdf8cb9c0df1b6ffce69bd866cdeffd9355" translate="yes" xml:space="preserve">
          <source>In general, a learning problem considers a set of n &lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;samples&lt;/a&gt; of data and then tries to predict properties of unknown data. If each sample is more than a single number and, for instance, a multi-dimensional entry (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;multivariate&lt;/a&gt; data), it is said to have several attributes or &lt;strong&gt;features&lt;/strong&gt;.</source>
          <target state="translated">一般に、学習問題はデータのn個の&lt;a href=&quot;https://en.wikipedia.org/wiki/Sample_(statistics)&quot;&gt;サンプル&lt;/a&gt;のセットを考慮し、不明なデータのプロパティを予測しようとします。各サンプルが複数の数値であり、たとえば多次元エントリ（別名&lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariate_random_variable&quot;&gt;多変量&lt;/a&gt;データ）である場合、複数の属性または&lt;strong&gt;特徴&lt;/strong&gt;を持っていると言われ&lt;strong&gt;ます&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="9cf7334c38597a2189c7af702ab9abdbe9f10093" translate="yes" xml:space="preserve">
          <source>In general, is a technique used for analyzing similarity or dissimilarity data. &lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt;&lt;code&gt;MDS&lt;/code&gt;&lt;/a&gt; attempts to model similarity or dissimilarity data as distances in a geometric spaces. The data can be ratings of similarity between objects, interaction frequencies of molecules, or trade indices between countries.</source>
          <target state="translated">一般に、は類似性または非類似性データの分析に使用される手法です。&lt;a href=&quot;generated/sklearn.manifold.mds#sklearn.manifold.MDS&quot;&gt; &lt;code&gt;MDS&lt;/code&gt; &lt;/a&gt;は、類似性または非類似性データを幾何学的空間の距離としてモデル化しようとします。データは、オブジェクト間の類似性の評価、分子の相互作用頻度、または国間の貿易指数です。</target>
        </trans-unit>
        <trans-unit id="71aab6786f00490669e72ac36911ce2d2486dab4" translate="yes" xml:space="preserve">
          <source>In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \(p\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population than the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment.</source>
          <target state="translated">一般的には、初期オブザベーション分布の輪郭を区切る大まかで近いフロンティアを学習しようとしていますが、これは、埋め込み(p\)次元空間にプロットされます。そして、さらなるオブザベーションがフロンティアで区切られた部分空間内にある場合、それらは初期オブザベーションと同じ母集団から来ていると考えられます。そうでなければ、それらがフロンティアの外にある場合、我々の評価で与えられた信頼度でそれらが異常であると言うことができる。</target>
        </trans-unit>
        <trans-unit id="c9bca25ec918e4e036ec8a37ec502896ec56d542" translate="yes" xml:space="preserve">
          <source>In general, learning algorithms benefit from standardization of the data set. If some outliers are present in the set, robust scalers or transformers are more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers is highlighted in &lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;Compare the effect of different scalers on data with outliers&lt;/a&gt;.</source>
          <target state="translated">一般に、学習アルゴリズムはデータセットの標準化から利益を得ます。セットに外れ値が存在する場合は、堅牢なスケーラーまたはトランスフォーマーがより適切です。限界外れ値を含むデータセットでのさまざまなスケーラー、トランスフォーマー、ノーマライザの動作は、「外れ値を持つデータ&lt;a href=&quot;../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py&quot;&gt;に対するさまざまなスケーラーの影響の比較」&lt;/a&gt;で強調表示されています。</target>
        </trans-unit>
        <trans-unit id="baeb2b7a43c2bc0dd04675c021d6ed663a58bf2d" translate="yes" xml:space="preserve">
          <source>In general, the run time cost to construct a balanced binary tree is \(O(n_{samples}n_{features}\log(n_{samples}))\) and query time \(O(\log(n_{samples}))\). Although the tree construction algorithm attempts to generate balanced trees, they will not always be balanced. Assuming that the subtrees remain approximately balanced, the cost at each node consists of searching through \(O(n_{features})\) to find the feature that offers the largest reduction in entropy. This has a cost of \(O(n_{features}n_{samples}\log(n_{samples}))\) at each node, leading to a total cost over the entire trees (by summing the cost at each node) of \(O(n_{features}n_{samples}^{2}\log(n_{samples}))\).</source>
          <target state="translated">一般的に、バランスのとれたバイナリツリーを構築するための実行時間コストは、\(O(n_{samples}n_{features})log(n_{samples}))であり、問い合わせ時間は、\(O(\log(n_{samples})))である。木の構築アルゴリズムは、バランスのとれた木を生成しようとしますが、必ずしもバランスがとれているとは限りません。部分木がほぼ均衡していると仮定すると、各ノードでのコストは、エントロピーの最大の減少をもたらす特徴を見つけるために、\(O(n_{features}))を検索することになる。これにより、各ノードでのコストは\(O(n_{features}n_{samples}\log(n_{samples})))となり、木全体でのコストは(各ノードでのコストを合計して)\(O(n_{features}n_{samples}^{2}\log(n_{samples}))となる。</target>
        </trans-unit>
        <trans-unit id="144a3925f6b19404e9d474c272482fb04a69a6ff" translate="yes" xml:space="preserve">
          <source>In general, when fitting a curve with a polynomial by Bayesian ridge regression, the selection of initial values of the regularization parameters (alpha, lambda) may be important. This is because the regularization parameters are determined by an iterative procedure that depends on initial values.</source>
          <target state="translated">一般に、ベイズ式リッジ回帰による多項式で曲線をフィッティングする場合、正則化パラメータ(α、λ)の初期値の選択が重要になることがあります。これは、正則化パラメータが初期値に依存する反復手順によって決定されるからです。</target>
        </trans-unit>
        <trans-unit id="dba314b8268f3eec306fec03d7cfe13e8e090ace" translate="yes" xml:space="preserve">
          <source>In general, when the problem isn&amp;rsquo;t linearly separable, the support vectors are the samples &lt;em&gt;within&lt;/em&gt; the margin boundaries.</source>
          <target state="translated">一般に、問題が線形分離可能でない場合、サポートベクターはマージン境界&lt;em&gt;内&lt;/em&gt;のサンプルです。</target>
        </trans-unit>
        <trans-unit id="635895acc09f2d99381585bc2d144c9a66a85f3a" translate="yes" xml:space="preserve">
          <source>In gradient descent, the gradient \(\nabla Loss_{W}\) of the loss with respect to the weights is computed and deducted from \(W\). More formally, this is expressed as,</source>
          <target state="translated">勾配降下法では、重みに対する損失の勾配を計算し、\(W\(W)から差し引く。より正式には、これは次のように表されます。</target>
        </trans-unit>
        <trans-unit id="2c51a2af5a19ac0ce7e4fb04fd6d887c03b6fecb" translate="yes" xml:space="preserve">
          <source>In high-dimensional spaces, linear classifiers often achieve excellent accuracy. For sparse binary data, BernoulliNB is particularly well-suited. The bottom row compares the decision boundary obtained by BernoulliNB in the transformed space with an ExtraTreesClassifier forests learned on the original data.</source>
          <target state="translated">高次元空間では、線形分類器はしばしば優れた精度を達成する。疎なバイナリデータでは、BernoulliNBが特に適しています。下の行は、変換された空間でBernoulliNBによって得られた決定境界を、元のデータで学習したExtraTreesClassifierの森と比較したものです。</target>
        </trans-unit>
        <trans-unit id="26c26ee3d75b66c7f22fed706da52f459434240f" translate="yes" xml:space="preserve">
          <source>In linear models, the target value is modeled as a linear combination of the features (see the &lt;a href=&quot;../../modules/linear_model#linear-model&quot;&gt;Linear Models&lt;/a&gt; User Guide section for a description of a set of linear models available in scikit-learn). Coefficients in multiple linear models represent the relationship between the given feature, \(X_i\) and the target, \(y\), assuming that all the other features remain constant (&lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_dependence&quot;&gt;conditional dependence&lt;/a&gt;). This is different from plotting \(X_i\) versus \(y\) and fitting a linear relationship: in that case all possible values of the other features are taken into account in the estimation (marginal dependence).</source>
          <target state="translated">線形モデルでは、ターゲット値は機能の線形結合としてモデル化されます（scikit-learnで使用可能な線形モデルのセットの説明については、&lt;a href=&quot;../../modules/linear_model#linear-model&quot;&gt;線形モデル&lt;/a&gt;ユーザーガイドのセクションを参照してください）。複数の線形モデルの係数は、他のすべての特徴が一定のままであると仮定して、与えられた特徴\（X_i \）とターゲット\（y \）の間の関係を表します（&lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_dependence&quot;&gt;条件依存&lt;/a&gt;）。これは、\（X_i \）と\（y \）をプロットして線形関係をフィッティングすることとは異なります。その場合、他の特徴のすべての可能な値が推定で考慮されます（限界依存性）。</target>
        </trans-unit>
        <trans-unit id="2367cf553e95efae790eac559ef2be19cd28f503" translate="yes" xml:space="preserve">
          <source>In machine-learning practice, Ridge Regression is more often used with non-negligible regularization.</source>
          <target state="translated">機械学習の実践では、無視できない正則化を用いてリッジ回帰を行うことが多い。</target>
        </trans-unit>
        <trans-unit id="7b577c96674cf299faa19ce0d11e2224d3c2c813" translate="yes" xml:space="preserve">
          <source>In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.</source>
          <target state="translated">多数決では,特定のサンプルの予測されたクラス・ラベルは,個々の分類器によって予測されたクラス・ラベルの多数派(モード)を表すクラス・ラベルである.</target>
        </trans-unit>
        <trans-unit id="589394183aec0e7af2afe4b456559f6baedc9992" translate="yes" xml:space="preserve">
          <source>In many cases it is thus recommended to carefully time and profile your feature extraction code as it may be a good place to start optimizing when your overall latency is too slow for your application.</source>
          <target state="translated">多くの場合、アプリケーションの全体的なレイテンシが遅すぎる場合に最適化を開始するのに適した場所である可能性があるため、特徴抽出コードの時間を慎重に設定し、プロファイルを作成することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="aeae04273a5ed1fc88f796de718e3c2190c04f0d" translate="yes" xml:space="preserve">
          <source>In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.</source>
          <target state="translated">多くのモデリングシナリオでは、データセットの特徴の正規性が望まれます。動力変換は,分散を安定させ,歪度を最小化するために,任意の分布から可能な限りガウス分布に近い分布にデータをマッピングすることを目的としたパラメトリックな単調変換の一群である.</target>
        </trans-unit>
        <trans-unit id="c82f65d47c3f4e11ad468a4165bdc787c51720a5" translate="yes" xml:space="preserve">
          <source>In many real-world examples, there are many ways to extract features from a dataset. Often it is beneficial to combine several methods to obtain good performance. This example shows how to use &lt;code&gt;FeatureUnion&lt;/code&gt; to combine features obtained by PCA and univariate selection.</source>
          <target state="translated">多くの実際の例では、データセットから特徴を抽出する多くの方法があります。多くの場合、良いパフォーマンスを得るためにいくつかの方法を組み合わせることが有益です。この例は、 &lt;code&gt;FeatureUnion&lt;/code&gt; を使用して、PCAによって取得された特徴と単変量選択を組み合わせる方法を示しています。</target>
        </trans-unit>
        <trans-unit id="9c0b7f3861d3fe001968b978c49f3447d1233fa3" translate="yes" xml:space="preserve">
          <source>In mathematics, the Johnson-Lindenstrauss lemma is a result concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.</source>
          <target state="translated">数学では、ジョンソン-リンデンストラウス・リーマは、高次元空間から低次元ユークリッド空間への点の低歪み埋め込みに関する結果である。このリーマは、高次元空間の小さな点の集合は、点間の距離がほぼ保存されるような方法で、はるかに低い次元の空間に埋め込むことができることを述べています。埋め込みに用いられる写像は、少なくともリップシッツであり、直交射影であるとみなすこともできます。</target>
        </trans-unit>
        <trans-unit id="35a3805825da50966c5f8cb649b1d2ea852b8f59" translate="yes" xml:space="preserve">
          <source>In maximizing the log-likelihood, the positive gradient makes the model prefer hidden states that are compatible with the observed training data. Because of the bipartite structure of RBMs, it can be computed efficiently. The negative gradient, however, is intractable. Its goal is to lower the energy of joint states that the model prefers, therefore making it stay true to the data. It can be approximated by Markov chain Monte Carlo using block Gibbs sampling by iteratively sampling each of \(v\) and \(h\) given the other, until the chain mixes. Samples generated in this way are sometimes referred as fantasy particles. This is inefficient and it is difficult to determine whether the Markov chain mixes.</source>
          <target state="translated">対数尤度を最大化する場合、正の勾配は、観測された訓練データと互換性のある隠れた状態をモデルが好むようにする。RBMは二部構造であるため、効率的に計算できる。しかし、負の勾配は難解である。負の勾配の目的は、モデルが好む結合状態のエネルギーを下げることで、データに忠実な状態を維持することです。負の勾配は、ブロックギブスサンプリングを用いたマルコフ連鎖モンテカルロ法で近似することができます。このようにして生成されたサンプルを空想粒子と呼ぶことがある。これは非効率的で、マルコフ連鎖が混ざるかどうかを判断するのが難しい。</target>
        </trans-unit>
        <trans-unit id="54db7da5f1b2e2f16e8f4dc3a375dac661b78213" translate="yes" xml:space="preserve">
          <source>In multi-label classification, the &lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt;&lt;code&gt;roc_auc_score&lt;/code&gt;&lt;/a&gt; function is extended by averaging over the labels as &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;.</source>
          <target state="translated">マルチラベル分類では、&lt;a href=&quot;generated/sklearn.metrics.roc_auc_score#sklearn.metrics.roc_auc_score&quot;&gt; &lt;code&gt;roc_auc_score&lt;/code&gt; &lt;/a&gt;関数は&lt;a href=&quot;#average&quot;&gt;上記のように&lt;/a&gt;ラベルを平均することによって拡張されます。</target>
        </trans-unit>
        <trans-unit id="d9be5dcb267dcb84c278d12d7b1a881ada760886" translate="yes" xml:space="preserve">
          <source>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</source>
          <target state="translated">マルチラベル分類では、これはサブセット精度であり、各サンプルに対して各ラベルセットが正しく予測されることが要求されるため、厳しい指標となります。</target>
        </trans-unit>
        <trans-unit id="9ff5420b9cd3095ee44bf9941c38c72dce6d517a" translate="yes" xml:space="preserve">
          <source>In multi-label settings</source>
          <target state="translated">マルチラベル設定では</target>
        </trans-unit>
        <trans-unit id="cf7a69d811fd496380ea6a3966d13bf17ca83f43" translate="yes" xml:space="preserve">
          <source>In multiclass and multilabel classification task, the notions of precision, recall, and F-measures can be applied to each label independently. There are a few ways to combine results across labels, specified by the &lt;code&gt;average&lt;/code&gt; argument to the &lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt;&lt;code&gt;average_precision_score&lt;/code&gt;&lt;/a&gt; (multilabel only), &lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt;&lt;code&gt;f1_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt;&lt;code&gt;fbeta_score&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt;&lt;code&gt;precision_recall_fscore_support&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt;&lt;code&gt;precision_score&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt;&lt;code&gt;recall_score&lt;/code&gt;&lt;/a&gt; functions, as described &lt;a href=&quot;#average&quot;&gt;above&lt;/a&gt;. Note that if all labels are included, &amp;ldquo;micro&amp;rdquo;-averaging in a multiclass setting will produce precision, recall and \(F\) that are all identical to accuracy. Also note that &amp;ldquo;weighted&amp;rdquo; averaging may produce an F-score that is not between precision and recall.</source>
          <target state="translated">マルチクラスおよびマルチラベル分類タスクでは、精度、再現率、およびFメジャーの概念を各ラベルに個別に適用できます。指定されたラベルの両端の結果を結合するいくつかの方法がある &lt;code&gt;average&lt;/code&gt; の引数&lt;a href=&quot;generated/sklearn.metrics.average_precision_score#sklearn.metrics.average_precision_score&quot;&gt; &lt;code&gt;average_precision_score&lt;/code&gt; &lt;/a&gt;（マルチラベルのみ）、&lt;a href=&quot;generated/sklearn.metrics.f1_score#sklearn.metrics.f1_score&quot;&gt; &lt;code&gt;f1_score&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.fbeta_score#sklearn.metrics.fbeta_score&quot;&gt; &lt;code&gt;fbeta_score&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.precision_recall_fscore_support#sklearn.metrics.precision_recall_fscore_support&quot;&gt; &lt;code&gt;precision_recall_fscore_support&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/sklearn.metrics.precision_score#sklearn.metrics.precision_score&quot;&gt; &lt;code&gt;precision_score&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.metrics.recall_score#sklearn.metrics.recall_score&quot;&gt; &lt;code&gt;recall_score&lt;/code&gt; &lt;/a&gt;記載されているような機能は、&lt;a href=&quot;#average&quot;&gt;上に&lt;/a&gt;。すべてのラベルが含まれている場合、マルチクラス設定での「マイクロ」平均は、精度と同じである精度、再現率、および\（F \）を生成することに注意してください。また、「加重」平均では、精度と再現率の間にないFスコアが生成される場合があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="afc91520f5287da47360dcd6fd00b4fb446bcf96" translate="yes" xml:space="preserve">
          <source>In multiclass case, the function expects that either all the labels are included in y_true or an optional labels argument is provided which contains all the labels. The multilabel margin is calculated according to Crammer-Singer&amp;rsquo;s method. As in the binary case, the cumulated hinge loss is an upper bound of the number of mistakes made by the classifier.</source>
          <target state="translated">マルチクラスの場合、関数はすべてのラベルがy_trueに含まれるか、すべてのラベルを含むオプションのラベル引数が提供されることを期待します。マルチラベルマージンは、Crammer-Singerの方法に従って計算されます。バイナリの場合と同様に、累積されたヒンジ損失は、分類器によって行われた誤りの数の上限です。</target>
        </trans-unit>
        <trans-unit id="a7ec36140af641cfb5e4e5e11dec536798cfb2f8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss correspond to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function.</source>
          <target state="translated">マルチクラス分類では、ハミング損失は &lt;code&gt;y_true&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; の間のハミング距離に対応し、サブセット &lt;code&gt;zero_one_loss&lt;/code&gt; 関数に相当します。</target>
        </trans-unit>
        <trans-unit id="a514b0b14d02249930d02d183e261b474a100dbd" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is equivalent to the subset &lt;code&gt;zero_one_loss&lt;/code&gt; function, when &lt;code&gt;normalize&lt;/code&gt; parameter is set to True.</source>
          <target state="translated">マルチクラス分類では、ハミング損失は &lt;code&gt;y_true&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; の間のハミング距離に対応します。これは、 &lt;code&gt;normalize&lt;/code&gt; パラメーターがTrueに設定されている場合、サブセット &lt;code&gt;zero_one_loss&lt;/code&gt; 関数に相当します。</target>
        </trans-unit>
        <trans-unit id="ff1916ae5265c4d87d1472e5cc3e0c2594a22de8" translate="yes" xml:space="preserve">
          <source>In multiclass classification, the Hamming loss corresponds to the Hamming distance between &lt;code&gt;y_true&lt;/code&gt; and &lt;code&gt;y_pred&lt;/code&gt; which is similar to the &lt;a href=&quot;#zero-one-loss&quot;&gt;Zero one loss&lt;/a&gt; function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always between zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss between zero and one, exclusive.</source>
          <target state="translated">マルチクラス分類では、ハミング損失は &lt;code&gt;y_true&lt;/code&gt; と &lt;code&gt;y_pred&lt;/code&gt; の間のハミング距離に対応し、&lt;a href=&quot;#zero-one-loss&quot;&gt;ゼロ1損失&lt;/a&gt;関数に似ています。ただし、ゼロ1損失は真のセットと厳密には一致しない予測セットにペナルティを課しますが、ハミング損失は個々のラベルにペナルティを課します。したがって、ハミング損失は、ゼロ1損失によって上限が定められ、常に0と1の間であり、両端を含みます。真のラベルの適切なサブセットまたはスーパーセットを予測すると、ゼロと1の間のハミング損失が発生します。</target>
        </trans-unit>
        <trans-unit id="cf7ce831a18d046dad4e38dc2cae92648b792778" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the &lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt;&lt;code&gt;zero_one_loss&lt;/code&gt;&lt;/a&gt; scores a subset as one if its labels strictly match the predictions, and as a zero if there are any errors. By default, the function returns the percentage of imperfectly predicted subsets. To get the count of such subsets instead, set &lt;code&gt;normalize&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">マルチラベル分類では、&lt;a href=&quot;generated/sklearn.metrics.zero_one_loss#sklearn.metrics.zero_one_loss&quot;&gt; &lt;code&gt;zero_one_loss&lt;/code&gt; は&lt;/a&gt;、ラベルが予測と完全に一致する場合、サブセットを1としてスコア付けし、エラーがある場合、0としてスコア付けします。デフォルトでは、この関数は不完全に予測されたサブセットの割合を返します。代わりにそのようなサブセットの数を取得するには、 &lt;code&gt;normalize&lt;/code&gt; を &lt;code&gt;False&lt;/code&gt; に設定します</target>
        </trans-unit>
        <trans-unit id="2cdc777c3fd9aacea19e984339f1423c55608098" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes the individual labels.</source>
          <target state="translated">マルチラベル分類では,ハミング損失はサブセット・ゼロワン損失とは異なります.ゼロワン損失は,与えられたサンプルのラベルの集合全体が真のラベルの集合と完全に一致していない場合,ラベルの集合全体が不正確であるとみなします.ハミング損失は,個々のラベルにペナルティを与えるという点で,より寛容です.</target>
        </trans-unit>
        <trans-unit id="602aeb7c2d89b27ea6d03c59146d4b4fecde4c31" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does not entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes only the individual labels.</source>
          <target state="translated">マルチラベル分類では,ハミング損失はサブセット・ゼロワン損失とは異なります.ゼロワン損失は、与えられたサンプルのラベルの集合全体が、ラベルの真の集合と完全に一致しない場合、不正確であるとみなします。ハミング損失は,個々のラベルのみを罰するという点で,より寛容である.</target>
        </trans-unit>
        <trans-unit id="00e9bece59054d08c4ac787e06eeb4fc8070bdab" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.</source>
          <target state="translated">マルチラベル分類では,この関数は部分集合の精度を返します.サンプルの予測ラベルのセット全体が,真のラベルのセットと厳密に一致する場合,サブセット精度は1.0となり,そうでない場合は0.0となります.</target>
        </trans-unit>
        <trans-unit id="7cd1b88a6c55666089bdc7543f7e259d70d5898d" translate="yes" xml:space="preserve">
          <source>In multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.</source>
          <target state="translated">マルチラベル分類では,zero_one_loss関数は,サブセットの0-1損失に対応します:各サンプルについて,ラベルのセット全体が正しく予測されなければならず,そうでなければ,そのサンプルの損失は1に等しくなります.</target>
        </trans-unit>
        <trans-unit id="c56a96e702a01557c0cb1c7c6c5d254cdaebcc8b" translate="yes" xml:space="preserve">
          <source>In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must &lt;em&gt;exactly&lt;/em&gt; match the corresponding set of labels in y_true.</source>
          <target state="translated">マルチラベル分類では、この関数はサブセットの精度を計算します。サンプルに対して予測されたラベルのセットは、y_trueの対応するラベルのセットと&lt;em&gt;正確に&lt;/em&gt;一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="00440d1e0316ae49b10a616cf581f0acff1a935a" translate="yes" xml:space="preserve">
          <source>In multilabel confusion matrix \(MCM\), the count of true negatives is \(MCM_{:,0,0}\), false negatives is \(MCM_{:,1,0}\), true positives is \(MCM_{:,1,1}\) and false positives is \(MCM_{:,0,1}\).</source>
          <target state="translated">多言混同行列の場合、真の否定の数は、(MCM_{:,0,0})、偽の否定は、(MCM_{:,1,0})、真の陽性は、(MCM_{:,1,1})、偽の陽性は、(MCM_{:,0,1})であることを示します。</target>
        </trans-unit>
        <trans-unit id="3fad4287dcc0210ad8169708b233947ca706f077" translate="yes" xml:space="preserve">
          <source>In multilabel learning, each sample can have any number of ground truth labels associated with it. The goal is to give high scores and better rank to the ground truth labels.</source>
          <target state="translated">マルチラベル学習では、各サンプルはそれに関連付けられた任意の数の基底真理ラベルを持つことができます。目標は,基底真理ラベルに高得点とより良いランクを与えることである.</target>
        </trans-unit>
        <trans-unit id="9d6449537c42279d12e406059563c338784d06f3" translate="yes" xml:space="preserve">
          <source>In multilabel learning, the joint set of binary classification tasks is expressed with label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values: the one, i.e. the non zero elements, corresponds to the subset of labels. An array such as &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.</source>
          <target state="translated">マルチラベル学習では、バイナリ分類タスクのジョイントセットはラベルバイナリインジケーター配列で表されます。各サンプルは、バイナリ値を持つ形状の2D配列（n_samples、n_classes）の1行です。1つ、つまり非ゼロ要素は、ラベルのサブセット。 &lt;code&gt;np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])&lt;/code&gt; などの配列は、最初のサンプルのラベル0、2番目のサンプルのラベル1および2を表します、3番目のサンプルにはラベルがありません。</target>
        </trans-unit>
        <trans-unit id="65f6ef4e3d2b7a1359958abf87c802c2de77e1d9" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabasz index is applied to the results of a cluster analysis:</source>
          <target state="translated">通常の使用法では、Calinski-Harabasz指数はクラスタ分析の結果に適用されます。</target>
        </trans-unit>
        <trans-unit id="6c2c0f769c8a98dc6df3f2e7afe566ac80c0f339" translate="yes" xml:space="preserve">
          <source>In normal usage, the Calinski-Harabaz index is applied to the results of a cluster analysis.</source>
          <target state="translated">通常の使用法では、Calinski-Harabaz指数は、クラスタ分析の結果に適用されます。</target>
        </trans-unit>
        <trans-unit id="5f0c7d20ec265094d1673fd625fd38165b384452" translate="yes" xml:space="preserve">
          <source>In normal usage, the Davies-Bouldin index is applied to the results of a cluster analysis as follows:</source>
          <target state="translated">通常の使用法では、Davies-Bouldin指数は、以下のようにクラスタ分析の結果に適用されます。</target>
        </trans-unit>
        <trans-unit id="0488e7351783ef8ef785f4bdea49af8c75724adf" translate="yes" xml:space="preserve">
          <source>In normal usage, the Silhouette Coefficient is applied to the results of a cluster analysis.</source>
          <target state="translated">通常の使用法では、シルエット係数はクラスタ分析の結果に適用されます。</target>
        </trans-unit>
        <trans-unit id="af7916eabb756a4304309b1e18ceea097a7a5071" translate="yes" xml:space="preserve">
          <source>In order to address the wider task of Natural Language Understanding, the local structure of sentences and paragraphs should thus be taken into account. Many such models will thus be casted as &amp;ldquo;Structured output&amp;rdquo; problems which are currently outside of the scope of scikit-learn.</source>
          <target state="translated">自然言語理解のより幅広い課題に取り組むために、文と段落のローカル構造を考慮に入れるべきです。したがって、そのようなモデルの多くは、現在scikit-learnの範囲外である「構造化された出力」の問題としてキャストされます。</target>
        </trans-unit>
        <trans-unit id="819693d214fc959100941f9c2bf3cb570fc069ec" translate="yes" xml:space="preserve">
          <source>In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:</source>
          <target state="translated">これに対応するために、scikit-learnはテキストコンテンツから数値特徴量を抽出する最も一般的な方法である、以下のようなユーティリティを提供しています。</target>
        </trans-unit>
        <trans-unit id="5bdd52099ccc039c40b609f18b326c63aea62fae" translate="yes" xml:space="preserve">
          <source>In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the &lt;code&gt;scipy.sparse&lt;/code&gt; package.</source>
          <target state="translated">そのような行列をメモリに格納できるようにするだけでなく、代数演算行列/ベクトルを高速化するために、実装は通常、 &lt;code&gt;scipy.sparse&lt;/code&gt; パッケージで利用可能な実装などの疎な表現を使用します。</target>
        </trans-unit>
        <trans-unit id="af0531a207de85560d0c6e1dcc4e5a478aa65d8d" translate="yes" xml:space="preserve">
          <source>In order to build histograms, the input data &lt;code&gt;X&lt;/code&gt; needs to be binned into integer-valued bins. This binning procedure does require sorting the feature values, but it only happens once at the very beginning of the boosting process (not at each node, like in &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt;&lt;code&gt;GradientBoostingClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt;&lt;code&gt;GradientBoostingRegressor&lt;/code&gt;&lt;/a&gt;).</source>
          <target state="translated">ヒストグラムを作成するには、入力データ &lt;code&gt;X&lt;/code&gt; を整数値のビンにビニングする必要があります。このビニング手順では、特徴値の並べ替えが必要ですが、ブースティングプロセスの最初に1回だけ発生します（&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingclassifier#sklearn.ensemble.GradientBoostingClassifier&quot;&gt; &lt;code&gt;GradientBoostingClassifier&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;generated/sklearn.ensemble.gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor&quot;&gt; &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; の&lt;/a&gt;ように各ノードでは発生しません）。</target>
        </trans-unit>
        <trans-unit id="b0bf98f40bc311f4824763dea8c552bc0812d861" translate="yes" xml:space="preserve">
          <source>In order to feed predictive or clustering models with the text data, one first need to turn the text into vectors of numerical values suitable for statistical analysis. This can be achieved with the utilities of the &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; as demonstrated in the following example that extract &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt; vectors of unigram tokens from a subset of 20news:</source>
          <target state="translated">予測モデルまたはクラスタリングモデルにテキストデータをフィードするには、まずテキストを統計分析に適した数値のベクトルに変換する必要があります。これは、 &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; のサブセットからユニグラムトークンの&lt;a href=&quot;https://en.wikipedia.org/wiki/Tf-idf&quot;&gt;TF-IDF&lt;/a&gt;ベクトルを抽出する次の例に示すように、sklearn.feature_extraction.textのユーティリティを使用して実現できます。</target>
        </trans-unit>
        <trans-unit id="c3614fb1e15f18200960459d2e1c203458a6eae2" translate="yes" xml:space="preserve">
          <source>In order to fit linear models with those predictors it is therefore necessary to perform standard feature transformations as follows:</source>
          <target state="translated">したがって,それらの予測変数で線形モデルを適合させるためには,以下のように標準的な特徴変換を実行することが必要である.</target>
        </trans-unit>
        <trans-unit id="a439a73e36b65ee0a94b3f1d9d89e3ac154697cf" translate="yes" xml:space="preserve">
          <source>In order to get faster execution times for this first example we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:</source>
          <target state="translated">この最初の例の実行時間を速くするために、データセット内の20のカテゴリのうち4つだけのカテゴリを持つ部分的なデータセットで作業を行います。</target>
        </trans-unit>
        <trans-unit id="da7edac191ef2f2a6bab6d167570c5dc3d626b83" translate="yes" xml:space="preserve">
          <source>In order to learn good latent representations from a small dataset, we artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.</source>
          <target state="translated">少ないデータセットから良い潜在表現を学習するために、訓練データを各方向に1ピクセルの線形シフトで摂動することで、より多くのラベル付きデータを人工的に生成します。</target>
        </trans-unit>
        <trans-unit id="6983d2c6ff1cbf277ea5d9522b128070bfd0a615" translate="yes" xml:space="preserve">
          <source>In order to make the vectorizer =&amp;gt; transformer =&amp;gt; classifier easier to work with, &lt;code&gt;scikit-learn&lt;/code&gt; provides a &lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;Pipeline&lt;/code&gt;&lt;/a&gt; class that behaves like a compound classifier:</source>
          <target state="translated">ベクトライザー=&amp;gt;トランスフォーマー=&amp;gt;分類子を扱いやすくするために、 &lt;code&gt;scikit-learn&lt;/code&gt; は複合分類子のように動作する&lt;a href=&quot;../../modules/generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;Pipeline&lt;/code&gt; &lt;/a&gt;クラスを提供します。</target>
        </trans-unit>
        <trans-unit id="5257e11193f291f6f81d5d2347e3cbb71ec9f310" translate="yes" xml:space="preserve">
          <source>In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.</source>
          <target state="translated">テキスト文書に対して機械学習を行うためには、まず、テキストの内容を数値特徴ベクトルに変換する必要があります。</target>
        </trans-unit>
        <trans-unit id="7b973d24b18f4331d1cc68b945953f9c40c766fe" translate="yes" xml:space="preserve">
          <source>In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support &lt;code&gt;predict_proba&lt;/code&gt; method):</source>
          <target state="translated">予測されたクラス確率に基づいてクラスラベルを予測するには（VottingClassifierのscikit-learn推定器が &lt;code&gt;predict_proba&lt;/code&gt; メソッドをサポートしている必要があります）：</target>
        </trans-unit>
        <trans-unit id="a7ffbb7849ad7a74935991324e062c6b6722378d" translate="yes" xml:space="preserve">
          <source>In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf&amp;ndash;idf transform.</source>
          <target state="translated">カウント機能を分類器による使用に適した浮動小数点値に再重み付けするために、tf-idf変換を使用することは非常に一般的です。</target>
        </trans-unit>
        <trans-unit id="4707665df8a323c1a68b209bc6166b3798e4ea75" translate="yes" xml:space="preserve">
          <source>In order to rebuild a similar model with future versions of scikit-learn, additional metadata should be saved along the pickled model:</source>
          <target state="translated">将来のバージョンのscikit-learnで同様のモデルを再構築するためには、追加のメタデータをピクルスモデルに沿って保存しなければなりません。</target>
        </trans-unit>
        <trans-unit id="168239ecf279021917cbfef805f1d7d711ae1c44" translate="yes" xml:space="preserve">
          <source>In order to test if a classification score is significative a technique in repeating the classification procedure after randomizing, permuting, the labels. The p-value is then given by the percentage of runs for which the score obtained is greater than the classification score obtained in the first place.</source>
          <target state="translated">分類スコアが有意であるかどうかをテストするために、ラベルをランダム化し、入れ替えた後に、分類手順を繰り返す手法です。p値は、得られたスコアが最初に得られた分類スコアよりも大きいランのパーセンテージで与えられます。</target>
        </trans-unit>
        <trans-unit id="fdc8e1656ba1332f0933f9f656403151b15252d2" translate="yes" xml:space="preserve">
          <source>In other words, return an input X_original whose transform would be X.</source>
          <target state="translated">言い換えれば、変換がXになる入力X_originalを返します。</target>
        </trans-unit>
        <trans-unit id="f84fbaf022a2c87e2f72b92c7b8059751d7f8963" translate="yes" xml:space="preserve">
          <source>In other words, we &lt;em&gt;decomposed&lt;/em&gt; matrix \(\mathbf{X}\).</source>
          <target state="translated">つまり、行列\（\ mathbf {X} \）を&lt;em&gt;分解しました&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="573ad5780d66d8749d635925a4f90732aa002652" translate="yes" xml:space="preserve">
          <source>In particular Rosenberg and Hirschberg (2007) define the following two desirable objectives for any cluster assignment:</source>
          <target state="translated">特に、Rosenberg and Hirschberg (2007)は、どのようなクラスター割り当てにおいても、以下の2つの望ましい目的を定義しています。</target>
        </trans-unit>
        <trans-unit id="dafd8fff090495231531a6dce6a0d9bf23cd3c87" translate="yes" xml:space="preserve">
          <source>In particular in a &lt;strong&gt;supervised setting&lt;/strong&gt; it can be successfully combined with fast and scalable linear models to train &lt;strong&gt;document classifiers&lt;/strong&gt;, for instance:</source>
          <target state="translated">特に、&lt;strong&gt;監視対象の設定&lt;/strong&gt;では、高速かつスケーラブルな線形モデルとうまく組み合わせて、次のような&lt;strong&gt;ドキュメント分類子&lt;/strong&gt;をトレーニングできます。</target>
        </trans-unit>
        <trans-unit id="b70db829e86f8b0b87ee4b4ea9165e2800cb135e" translate="yes" xml:space="preserve">
          <source>In particular the interrogative form &amp;ldquo;Is this&amp;rdquo; is only present in the last document:</source>
          <target state="translated">特に、疑問形「Is this」は最後の文書にのみ存在します。</target>
        </trans-unit>
        <trans-unit id="48a72aaef5f57348c3c02ddfbd84f34663c56133" translate="yes" xml:space="preserve">
          <source>In particular we name:</source>
          <target state="translated">特に私たちは名前を挙げます。</target>
        </trans-unit>
        <trans-unit id="32bae48b70c29501503578b88b61dfab45b0637c" translate="yes" xml:space="preserve">
          <source>In particular, \(\nu = 3/2\):</source>
          <target state="translated">とくに、「♪」は、3/2。</target>
        </trans-unit>
        <trans-unit id="204dd46cfb26952328568f02a630bc8ec2809e56" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in &lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt;&lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt;&lt;/a&gt;. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">特に、切り捨てられたSVDは、&lt;a href=&quot;../classes#module-sklearn.feature_extraction.text&quot;&gt; &lt;code&gt;sklearn.feature_extraction.text&lt;/code&gt; のベクトライザー&lt;/a&gt;によって返されるterm count / tf-idf行列で機能します。その文脈では、それは潜在意味解析（LSA）として知られています。</target>
        </trans-unit>
        <trans-unit id="ff34c019cd4067dd0b8a1a6d1536db31ff351b58" translate="yes" xml:space="preserve">
          <source>In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).</source>
          <target state="translated">特に、切り捨てSVDは、sklearn.feature_extraction.textのベクタライザが返す項数/tf-idf-idf行列に対して働きます。この文脈では、これは潜在意味分析(LSA)として知られています。</target>
        </trans-unit>
        <trans-unit id="74d856933005d819af2a4b7d2ce24317b5186453" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plan.</source>
          <target state="translated">実際には、スペクトルクラスタリングは、個々のクラスタの構造が非常に非凸である場合や、より一般的にクラスタの中心や広がりの尺度が完全なクラスタの適切な記述ではない場合に非常に有用です。例えば、クラスターが2次元平面上で入れ子になった円である場合などです。</target>
        </trans-unit>
        <trans-unit id="316ef03a3b1d8845e6fcfccde0af625da5037900" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance when clusters are nested circles on the 2D plane.</source>
          <target state="translated">実際には、スペクトルクラスタリングは、個々のクラスタの構造が非常に非凸である場合や、より一般的にクラスタの中心や広がりの尺度が完全なクラスタの適切な記述ではない場合に非常に有用です。例えば、クラスターが2次元平面上に入れ子になった円である場合などです。</target>
        </trans-unit>
        <trans-unit id="21d1a0735c97d36c546ea3246065facc34b4f5a9" translate="yes" xml:space="preserve">
          <source>In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster. For instance, when clusters are nested circles on the 2D plane.</source>
          <target state="translated">実際には、スペクトルクラスタリングは、個々のクラスタの構造が非常に非凸である場合や、より一般的にクラスタの中心と広がりの尺度が完全なクラスタの適切な記述ではない場合に非常に有用である。例えば、クラスターが2次元平面上に入れ子になった円である場合などです。</target>
        </trans-unit>
        <trans-unit id="5662b7bb73c6d21ae298513382716bd3fe526ba2" translate="yes" xml:space="preserve">
          <source>In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of his k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.</source>
          <target state="translated">実際には、局所密度はk-最も近い隣人から得られます。観測のLOFスコアは、彼のk-最も近い隣人の平均局所密度とそれ自身の局所密度の比に等しい:正常なインスタンスは、その隣人のそれに似た局所密度を持つことが期待され、一方、異常なデータは、はるかに小さい局所密度を持つことが期待されます。</target>
        </trans-unit>
        <trans-unit id="7ab811a62d63edef5c9695fca6cafd8cc266404c" translate="yes" xml:space="preserve">
          <source>In practice those estimates are stored as an attribute named &lt;code&gt;feature_importances_&lt;/code&gt; on the fitted model. This is an array with shape &lt;code&gt;(n_features,)&lt;/code&gt; whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.</source>
          <target state="translated">実際には、これらの推定値は、適合モデルの &lt;code&gt;feature_importances_&lt;/code&gt; という名前の属性として保存されます。これは、値が正で合計が1.0になる形状 &lt;code&gt;(n_features,)&lt;/code&gt; 配列です。値が高いほど、予測機能に対するマッチング機能の寄与が重要になります。</target>
        </trans-unit>
        <trans-unit id="2f91c327e74b19930bc0b8d2d9c2f5d99fe44af7" translate="yes" xml:space="preserve">
          <source>In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.</source>
          <target state="translated">実際には、分布の形状を無視して、各特徴の平均値を除去することでデータを中心に変換し、一定でない特徴をそれらの標準偏差で割ることで尺度化します。</target>
        </trans-unit>
        <trans-unit id="4c632dd9d37d8e850afe2fbbbdbddfedb108d119" translate="yes" xml:space="preserve">
          <source>In practice, \(\mu\) and \(\Sigma\) are replaced by some estimates. The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set and therefor, the corresponding Mahalanobis distances are. One would better have to use a robust estimator of covariance to guarantee that the estimation is resistant to &amp;ldquo;erroneous&amp;rdquo; observations in the data set and that the associated Mahalanobis distances accurately reflect the true organisation of the observations.</source>
          <target state="translated">実際には、\（\ mu \）と\（\ Sigma \）はいくつかの推定値に置き換えられます。通常の共分散最尤推定値は、データセット内の外れ値の存在に非常に敏感であるため、対応するマハラノビス距離はそうです。推定がデータセット内の「誤った」観測に耐性があり、関連するマハラノビス距離が観測の真の構成を正確に反映していることを保証するには、共分散のロバスト推定量を使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="7f19bfe5f66f3783151b8147191d95599d9b587d" translate="yes" xml:space="preserve">
          <source>In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That&amp;rsquo;s why it can be useful to restart it several times.</source>
          <target state="translated">実際には、k-meansアルゴリズムは非常に高速ですが（利用可能な最高速のクラスタリングアルゴリズムの1つ）、極小値に分類されます。そのため、何度か再起動すると便利です。</target>
        </trans-unit>
        <trans-unit id="514529e761d628932a46cfab06e171128c270c12" translate="yes" xml:space="preserve">
          <source>In practice, whether parallelism is helpful at improving runtime depends on many factors. It is usually a good idea to experiment rather than assuming that increasing the number of workers is always a good thing. In some cases it can be highly detrimental to performance to run multiple copies of some estimators or functions in parallel (see oversubscription below).</source>
          <target state="translated">実際には、並列化が実行時間の向上に役立つかどうかは、多くの要因に依存します。通常、作業員の数を増やすことが常に良いことだと仮定するのではなく、実験してみるのが良い考えである。場合によっては、いくつかの推定量や関数の複数のコピーを並列に実行することがパフォーマンスに大きく悪影響を及ぼすことがあります(下記のオーバーサブスクリプションを参照してください)。</target>
        </trans-unit>
        <trans-unit id="f131bcc125dc920f59e2c48cc0ec0622c3531f86" translate="yes" xml:space="preserve">
          <source>In practice, you will have to handle yourself the column data type. If you want some columns to be considered as &lt;code&gt;category&lt;/code&gt;, you will have to convert them into categorical columns. If you are using pandas, you can refer to their documentation regarding &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html&quot;&gt;Categorical data&lt;/a&gt;.</source>
          <target state="translated">実際には、列のデータ型を自分で処理する必要があります。一部の列を &lt;code&gt;category&lt;/code&gt; と見なす場合は、それらをカテゴリ列に変換する必要があります。パンダを使用している場合は、&lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html&quot;&gt;カテゴリデータ&lt;/a&gt;に関するドキュメントを参照できます。</target>
        </trans-unit>
        <trans-unit id="3c017831824360a69856c6ccfffcd3f1b73574d4" translate="yes" xml:space="preserve">
          <source>In practise, a stacking predictor predict as good as the best predictor of the base layer and even sometimes outputperform it by combining the different strength of the these predictors. However, training a stacking predictor is computationally expensive.</source>
          <target state="translated">実際には、スタッキング予測器は、ベース層の最良の予測器と同程度の予測を行い、時にはこれらの予測器の異なる強さを組み合わせて出力することもあります。しかし、スタッキング予測器を訓練するには計算量がかかります。</target>
        </trans-unit>
        <trans-unit id="0aad0cfd8ffb7884222ad0979279d2b7ce81ef15" translate="yes" xml:space="preserve">
          <source>In principle, any function can be passed that provides a &lt;code&gt;rvs&lt;/code&gt; (random variate sample) method to sample a value. A call to the &lt;code&gt;rvs&lt;/code&gt; function should provide independent random samples from possible parameter values on consecutive calls.</source>
          <target state="translated">原則として、値をサンプリングするための &lt;code&gt;rvs&lt;/code&gt; （確率変量サンプル）メソッドを提供する任意の関数を渡すことができます。 &lt;code&gt;rvs&lt;/code&gt; 関数の呼び出しは、連続した呼び出しで可能なパラメーター値から独立したランダムサンプルを提供する必要があります。</target>
        </trans-unit>
        <trans-unit id="a9809378b0338436bd7bbe8f2e2070a6272b570d" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples keywords &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">特定のクラスまたは特定の個別のサンプルをより重要にしたい問題では、キーワード &lt;code&gt;class_weight&lt;/code&gt; および &lt;code&gt;sample_weight&lt;/code&gt; を使用できます。</target>
        </trans-unit>
        <trans-unit id="274191e11959a25ec702f3eb0728b40adf181870" translate="yes" xml:space="preserve">
          <source>In problems where it is desired to give more importance to certain classes or certain individual samples, the parameters &lt;code&gt;class_weight&lt;/code&gt; and &lt;code&gt;sample_weight&lt;/code&gt; can be used.</source>
          <target state="translated">特定のクラスまたは特定の個々のサンプルをより重要視したい問題では、パラメーター &lt;code&gt;class_weight&lt;/code&gt; および &lt;code&gt;sample_weight&lt;/code&gt; を使用できます。</target>
        </trans-unit>
        <trans-unit id="c88cb15e9453fb980c7d19e00322e852632f7bf2" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.</source>
          <target state="translated">ランダム森（参照で&lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt;クラス）、アンサンブル内の各ツリーは、トレーニングセットからの置換（すなわち、ブートストラップサンプル）で描かれたサンプルから構築されています。</target>
        </trans-unit>
        <trans-unit id="cae7f41bfdb577edc832687cbceee9865d3220c5" translate="yes" xml:space="preserve">
          <source>In random forests (see &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt;&lt;code&gt;RandomForestRegressor&lt;/code&gt;&lt;/a&gt; classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.</source>
          <target state="translated">ランダムフォレスト（&lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.ensemble.randomforestregressor#sklearn.ensemble.RandomForestRegressor&quot;&gt; &lt;code&gt;RandomForestRegressor&lt;/code&gt; &lt;/a&gt;クラスを参照）では、アンサンブル内の各ツリーは、トレーニングセットからの置換で描画されたサンプル（つまり、ブートストラップサンプル）から構築されます。さらに、ツリーの構築中にノードを分割する場合、選択された分割は、すべての機能の中で最良の分割ではなくなります。代わりに、選択された分割は、機能のランダムなサブセット間の最適な分割です。このランダム性の結果として、フォレストのバイアスは通常、（単一の非ランダムツリーのバイアスに対して）わずかに増加しますが、平均化により、その分散も減少し、通常、バイアスの増加を補うだけではありません。したがって、全体的に優れたモデルが得られます。</target>
        </trans-unit>
        <trans-unit id="eee63fdeeb00f1867cdf7e3f336a4276e1d12ae2" translate="yes" xml:space="preserve">
          <source>In regression, the expected mean squared error of an estimator can be decomposed in terms of bias, variance and noise. On average over datasets of the regression problem, the bias term measures the average amount by which the predictions of the estimator differ from the predictions of the best possible estimator for the problem (i.e., the Bayes model). The variance term measures the variability of the predictions of the estimator when fit over different instances LS of the problem. Finally, the noise measures the irreducible part of the error which is due the variability in the data.</source>
          <target state="translated">回帰では、推定器の期待平均2乗誤差は、バイアス、分散、およびノイズの観点から分解することができる。回帰問題のデータセットの平均では、バイアス項は、推定量の予測値が、その問題に最適な推定量(すなわち、ベイズモデル)の予測値と異なる平均量を測定する。分散項は、問題の異なるインスタンスLSに当てはめた場合の推定器の予測値の変動性を測定する。最後に、ノイズは、データの変動に起因する誤差の不可逆部分を測定する。</target>
        </trans-unit>
        <trans-unit id="3eae88b0a075df5d4090eee16e911849fedcc7b3" translate="yes" xml:space="preserve">
          <source>In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.</source>
          <target state="translated">回帰では、アウトプットは\(f(x)\)のままなので、アウトプット活性化関数は単なる同一性関数です。</target>
        </trans-unit>
        <trans-unit id="253be6f032627aec5a3b2c4240659e2190b9fba2" translate="yes" xml:space="preserve">
          <source>In scikit-learn a random split into training and test sets can be quickly computed with the &lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt; helper function. Let&amp;rsquo;s load the iris data set to fit a linear support vector machine on it:</source>
          <target state="translated">scikit-learnでは、トレーニングセットとテストセットへのランダムな分割を&lt;a href=&quot;generated/sklearn.model_selection.train_test_split#sklearn.model_selection.train_test_split&quot;&gt; &lt;code&gt;train_test_split&lt;/code&gt; &lt;/a&gt;ヘルパー関数ですばやく計算できます。アイリスデータセットを読み込んで、線形サポートベクターマシンに適合させます。</target>
        </trans-unit>
        <trans-unit id="bdcdb5bf0b220e10633a04e3b3d7b23fb832fcf9" translate="yes" xml:space="preserve">
          <source>In scikit-learn, an estimator for classification is a Python object that implements the methods &lt;code&gt;fit(X, y)&lt;/code&gt; and &lt;code&gt;predict(T)&lt;/code&gt;.</source>
          <target state="translated">scikit-learnでは、分類のための推定量は、メソッド &lt;code&gt;fit(X, y)&lt;/code&gt; および &lt;code&gt;predict(T)&lt;/code&gt; を実装するPythonオブジェクトです。</target>
        </trans-unit>
        <trans-unit id="a15700735758e7e1606b13cd4f276e5fe1e0ef96" translate="yes" xml:space="preserve">
          <source>In scikit-learn, bagging methods are offered as a unified &lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt;&lt;code&gt;BaggingClassifier&lt;/code&gt;&lt;/a&gt; meta-estimator (resp. &lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt;&lt;code&gt;BaggingRegressor&lt;/code&gt;&lt;/a&gt;), taking as input a user-specified base estimator along with parameters specifying the strategy to draw random subsets. In particular, &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;max_features&lt;/code&gt; control the size of the subsets (in terms of samples and features), while &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;bootstrap_features&lt;/code&gt; control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting &lt;code&gt;oob_score=True&lt;/code&gt;. As an example, the snippet below illustrates how to instantiate a bagging ensemble of &lt;code&gt;KNeighborsClassifier&lt;/code&gt; base estimators, each built on random subsets of 50% of the samples and 50% of the features.</source>
          <target state="translated">scikit-learnでは、バギングメソッドは統合された&lt;a href=&quot;generated/sklearn.ensemble.baggingclassifier#sklearn.ensemble.BaggingClassifier&quot;&gt; &lt;code&gt;BaggingClassifier&lt;/code&gt; &lt;/a&gt;メタ推定器（&lt;a href=&quot;generated/sklearn.ensemble.baggingregressor#sklearn.ensemble.BaggingRegressor&quot;&gt; &lt;code&gt;BaggingRegressor&lt;/code&gt; &lt;/a&gt;）として提供され、ランダムなサブセットを描画するための戦略を指定するパラメーターと共にユーザー指定のベースエスティメーターを入力として受け取ります。特に、 &lt;code&gt;max_samples&lt;/code&gt; と &lt;code&gt;max_features&lt;/code&gt; はサブセットのサイズを（サンプルと機能に関して）制御し、 &lt;code&gt;bootstrap&lt;/code&gt; と &lt;code&gt;bootstrap_features&lt;/code&gt; は、サンプルと機能が置換の有無にかかわらず描画されるかどうかを制御します。利用可能なサンプルのサブセットを使用する場合、out-of-bagサンプルで &lt;code&gt;oob_score=True&lt;/code&gt; を設定することにより、汎化精度を推定できます。。例として、以下のスニペットは、サンプルの50％と特徴の50％のランダムなサブセットに基づいて構築された &lt;code&gt;KNeighborsClassifier&lt;/code&gt; 基本推定量のバギングアンサンブルをインスタンス化する方法を示しています。</target>
        </trans-unit>
        <trans-unit id="0848ab34fddbc88dcbfdd395d0519986e8d182eb" translate="yes" xml:space="preserve">
          <source>In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the &lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt;&lt;code&gt;shrunk_covariance&lt;/code&gt;&lt;/a&gt; method. Also, a shrunk estimator of the covariance can be fitted to data with a &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt;&lt;code&gt;ShrunkCovariance&lt;/code&gt;&lt;/a&gt; object and its &lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt;&lt;code&gt;ShrunkCovariance.fit&lt;/code&gt;&lt;/a&gt; method. Again, results depend on whether the data are centered, so one may want to use the &lt;code&gt;assume_centered&lt;/code&gt; parameter accurately.</source>
          <target state="translated">scikit-learnでは、この変換（ユーザー定義の収縮係数を使用）は、&lt;a href=&quot;generated/sklearn.covariance.shrunk_covariance#sklearn.covariance.shrunk_covariance&quot;&gt; &lt;code&gt;shrunk_covariance&lt;/code&gt; &lt;/a&gt;メソッドで事前に計算された共分散に直接適用できます。また、共分散の縮小推定量は、&lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance&quot;&gt; &lt;code&gt;ShrunkCovariance&lt;/code&gt; &lt;/a&gt;オブジェクトとその&lt;a href=&quot;generated/sklearn.covariance.shrunkcovariance#sklearn.covariance.ShrunkCovariance.fit&quot;&gt; &lt;code&gt;ShrunkCovariance.fit&lt;/code&gt; &lt;/a&gt;メソッドを使用してデータに適合させることができます。この場合も、結果はデー​​タが中央に配置されているかどうかに依存するため、 &lt;code&gt;assume_centered&lt;/code&gt; パラメータを正確に使用する必要がある場合があります。</target>
        </trans-unit>
        <trans-unit id="77c9e3634b9d256acc307751b68c900b0b833a29" translate="yes" xml:space="preserve">
          <source>In single precision, &lt;code&gt;mean&lt;/code&gt; can be inaccurate:</source>
          <target state="translated">単精度では、 &lt;code&gt;mean&lt;/code&gt; は不正確になる可能性があります。</target>
        </trans-unit>
        <trans-unit id="640c5c337251b299605fe0c1704cd43d50fcda84" translate="yes" xml:space="preserve">
          <source>In some cases it&amp;rsquo;s not necessary to include higher powers of any single feature, but only the so-called &lt;em&gt;interaction features&lt;/em&gt; that multiply together at most \(d\) distinct features. These can be gotten from &lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt;&lt;code&gt;PolynomialFeatures&lt;/code&gt;&lt;/a&gt; with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;.</source>
          <target state="translated">場合によっては、単一の機能のより高い能力を含める必要はありませんが、最大で\（d \）個の異なる機能を乗算するいわゆる&lt;em&gt;相互作用機能&lt;/em&gt;のみを含める必要があります。これらは、 &lt;code&gt;interaction_only=True&lt;/code&gt; の設定で&lt;a href=&quot;generated/sklearn.preprocessing.polynomialfeatures#sklearn.preprocessing.PolynomialFeatures&quot;&gt; &lt;code&gt;PolynomialFeatures&lt;/code&gt; &lt;/a&gt;から取得できます。</target>
        </trans-unit>
        <trans-unit id="4976a8ab8df4ced9a6ceb9c8368b484dbc953550" translate="yes" xml:space="preserve">
          <source>In some cases, only interaction terms among features are required, and it can be gotten with the setting &lt;code&gt;interaction_only=True&lt;/code&gt;:</source>
          <target state="translated">場合によっては、機能間の相互作用の用語のみが必要であり、 &lt;code&gt;interaction_only=True&lt;/code&gt; の設定で取得できます。</target>
        </trans-unit>
        <trans-unit id="fc4d9d9d36cc2fd0e96fb6fded728410f07d4165" translate="yes" xml:space="preserve">
          <source>In some specific cases (when the code that is run in parallel releases the GIL), scikit-learn will indicate to &lt;code&gt;joblib&lt;/code&gt; that a multi-threading backend is preferable.</source>
          <target state="translated">一部の特定のケース（並列で実行されるコードがGILを解放する場合）では、scikit-learnは、マルチスレッドバックエンドが望ましいことを &lt;code&gt;joblib&lt;/code&gt; に示します。</target>
        </trans-unit>
        <trans-unit id="1b40a5cc0ca592bd5c1306138f251a81fe534579" translate="yes" xml:space="preserve">
          <source>In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)</source>
          <target state="translated">ナイーブベイズ分類器は、一見単純化されすぎた仮定にもかかわらず、多くの実世界の状況で非常によく機能しています。ナイーブベイズ分類器は、必要なパラメータを推定するために少量の学習データを必要とします。(ナイーブベイズがなぜうまく機能するのかの理論的な理由や、どのようなデータタイプのデータを使用するのかについては、以下の参考文献を参照してください)</target>
        </trans-unit>
        <trans-unit id="389828ed3005eb646a2fbe827835555cbdc74437" translate="yes" xml:space="preserve">
          <source>In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.</source>
          <target state="translated">精度の面では、LOO は、テストエラーの推定値として高い分散をもたらすことが多い。直感的には、各モデルの構築には、\(n-1\)サンプルのうちの\(n-1\)サンプルが使用されるので、折り目から構築されたモデルは、お互いに、また、訓練セット全体から構築されたモデルと実質的に同一であることになります。</target>
        </trans-unit>
        <trans-unit id="36132aafc76511f4279f2a1765dcbaeb9d7a44b1" translate="yes" xml:space="preserve">
          <source>In terms of time and space complexity, Theil-Sen scales according to</source>
          <target state="translated">時間と空間の複雑さという点では、Theil-Senは次のようにスケールします。</target>
        </trans-unit>
        <trans-unit id="8cac8320893acecd46013a1cd740f5237cabb213" translate="yes" xml:space="preserve">
          <source>In that case, the model with 2 components and full covariance (which corresponds to the true generative model) is selected.</source>
          <target state="translated">その場合、2成分と完全共分散(真の生成モデルに相当する)を持つモデルが選択される。</target>
        </trans-unit>
        <trans-unit id="56b0989d4ac400367ce631898b8b32a7aa114deb" translate="yes" xml:space="preserve">
          <source>In that way, we emphasize that the greater the variance of a feature, the larger the weight of the corresponding coefficient on the output, all else being equal.</source>
          <target state="translated">このようにして、特徴の分散が大きいほど、出力に対する対応する係数の重みが大きくなることを強調しています。</target>
        </trans-unit>
        <trans-unit id="df23be83a828beae97b01644c9cebfd6ec568f81" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt;&lt;code&gt;TfidfTransformer&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt;&lt;code&gt;TfidfVectorizer&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;smooth_idf=False&lt;/code&gt;, the &amp;ldquo;1&amp;rdquo; count is added to the idf instead of the idf&amp;rsquo;s denominator:</source>
          <target state="translated">で&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidftransformer#sklearn.feature_extraction.text.TfidfTransformer&quot;&gt; &lt;code&gt;TfidfTransformer&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.feature_extraction.text.tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer&quot;&gt; &lt;code&gt;TfidfVectorizer&lt;/code&gt; &lt;/a&gt;と &lt;code&gt;smooth_idf=False&lt;/code&gt; のは、「1」のカウントではなく、IDFの分母のIDFに追加されます。</target>
        </trans-unit>
        <trans-unit id="5bd53e1aa867b99daf4cb138797f33e24d9cfda1" translate="yes" xml:space="preserve">
          <source>In the &lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt;&lt;code&gt;BernoulliRBM&lt;/code&gt;&lt;/a&gt;, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren&amp;rsquo;t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.</source>
          <target state="translated">&lt;a href=&quot;generated/sklearn.neural_network.bernoullirbm#sklearn.neural_network.BernoulliRBM&quot;&gt; &lt;code&gt;BernoulliRBM&lt;/code&gt; &lt;/a&gt;、すべてのユニットは、バイナリ確率論的単位です。これは、入力データがバイナリであるか、0と1の間の実数値である必要があることを意味し、可視単位がオンまたはオフになる確率を示します。これは、文字認識に適したモデルで、アクティブなピクセルとアクティブでないピクセルに関心があります。自然のシーンの画像の場合、背景、深度、および隣接するピクセルが同じ値をとる傾向があるため、適合しなくなります。</target>
        </trans-unit>
        <trans-unit id="729860dcb0b5963ed7d873f5d8718ecbded39d56" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; case, theory says that prediction consistency (i.e. that under given hypothesis, the estimator learned predicts as well as a model knowing the true distribution) is not possible because of the bias of the &lt;code&gt;l1&lt;/code&gt;. It does say, however, that model consistency, in terms of finding the right set of non-zero parameters as well as their signs, can be achieved by scaling &lt;code&gt;C1&lt;/code&gt;.</source>
          <target state="translated">では &lt;code&gt;l1&lt;/code&gt; の場合、理論的には、その予測の一貫性は述べています（つまり、与えられた仮説の下で、学んだ推定器は真の分布を知るモデルとしてだけでなく予測する）ためのバイアスのために不可能である &lt;code&gt;l1&lt;/code&gt; 。ただし、ゼロ以外のパラメーターの適切なセットとそれらの符号を見つけるという点で、モデルの整合性は &lt;code&gt;C1&lt;/code&gt; をスケーリングすることによって達成できると述べています。</target>
        </trans-unit>
        <trans-unit id="3ac113ba1d5ea8579f40e00fa885b5d980c4ba43" translate="yes" xml:space="preserve">
          <source>In the &lt;code&gt;l1&lt;/code&gt; penalty case, the cross-validation-error correlates best with the test-error, when scaling our &lt;code&gt;C&lt;/code&gt; with the number of samples, &lt;code&gt;n&lt;/code&gt;, which can be seen in the first figure.</source>
          <target state="translated">&lt;code&gt;l1&lt;/code&gt; 我々のスケーリング場合ペナルティ場合、クロスバリデーション・エラーは、試験誤差との最良相関 &lt;code&gt;C&lt;/code&gt; のサンプルの数で &lt;code&gt;n&lt;/code&gt; は最初の図に見ることができます。</target>
        </trans-unit>
        <trans-unit id="4495b7082e60ec7cb3a7d3cf1946536697a0e6b3" translate="yes" xml:space="preserve">
          <source>In the above case, the classifier is fit on a 1d array of multiclass labels and the &lt;code&gt;predict()&lt;/code&gt; method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:</source>
          <target state="translated">上記の場合、分類子はマルチクラスラベルの1次元配列に適合し、predict &lt;code&gt;predict()&lt;/code&gt; メソッドは対応するマルチクラス予測を提供します。バイナリラベルインジケーターの2D配列に適合させることもできます。</target>
        </trans-unit>
        <trans-unit id="41d2181ce120b72b14a943b5e6f5608fe64d404d" translate="yes" xml:space="preserve">
          <source>In the above example, &lt;code&gt;char_wb&lt;/code&gt; analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The &lt;code&gt;char&lt;/code&gt; analyzer, alternatively, creates n-grams that span across words:</source>
          <target state="translated">上記の例では、 &lt;code&gt;char_wb&lt;/code&gt; アナライザーが使用され、単語の境界（両側にスペースが埋め込まれている）内の文字からのみn-gramが作成されます。または、 &lt;code&gt;char&lt;/code&gt; アナライザーは、単語をまたがるn-gramを作成します。</target>
        </trans-unit>
        <trans-unit id="02dd6b844a6f6c7bb7b63318a0172b18e25d4984" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'city'&lt;/code&gt;). However, other transformers generally expect 2D data, and in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">上記の例では、&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;は1D配列を入力として想定しているため、列は文字列（ &lt;code&gt;'city'&lt;/code&gt; ）として指定されています。ただし、他のトランスフォーマーは通常2Dデータを想定しているため、その場合は列を文字列のリスト（ &lt;code&gt;['city']&lt;/code&gt; ）として指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="af32f30ac84780c46ec03071f0807a02a06be37e" translate="yes" xml:space="preserve">
          <source>In the above example, the &lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt;&lt;code&gt;CountVectorizer&lt;/code&gt;&lt;/a&gt; expects a 1D array as input and therefore the columns were specified as a string (&lt;code&gt;'title'&lt;/code&gt;). However, &lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt;&lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt;&lt;/a&gt; as most of other transformers expects 2D data, therefore in that case you need to specify the column as a list of strings (&lt;code&gt;['city']&lt;/code&gt;).</source>
          <target state="translated">上記の例では、&lt;a href=&quot;generated/sklearn.feature_extraction.text.countvectorizer#sklearn.feature_extraction.text.CountVectorizer&quot;&gt; &lt;code&gt;CountVectorizer&lt;/code&gt; &lt;/a&gt;は入力として1D配列を想定しているため、列は文字列（ &lt;code&gt;'title'&lt;/code&gt; ）として指定されています。ただし、&lt;a href=&quot;generated/sklearn.preprocessing.onehotencoder#sklearn.preprocessing.OneHotEncoder&quot;&gt; &lt;code&gt;preprocessing.OneHotEncoder&lt;/code&gt; &lt;/a&gt;は、他のほとんどのトランスフォーマーと同様に2Dデータを想定しているため、その場合、列を文字列のリスト（ &lt;code&gt;['city']&lt;/code&gt; ）として指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="8be3ffb93abc4e32a08a3f61b709f6ed3e6124c4" translate="yes" xml:space="preserve">
          <source>In the above example-code, we firstly use the &lt;code&gt;fit(..)&lt;/code&gt; method to fit our estimator to the data and secondly the &lt;code&gt;transform(..)&lt;/code&gt; method to transform our count-matrix to a tf-idf representation. These two steps can be combined to achieve the same end result faster by skipping redundant processing. This is done through using the &lt;code&gt;fit_transform(..)&lt;/code&gt; method as shown below, and as mentioned in the note in the previous section:</source>
          <target state="translated">上記のコード例では、最初に &lt;code&gt;fit(..)&lt;/code&gt; メソッドを使用して推定量をデータに適合させ、次に &lt;code&gt;transform(..)&lt;/code&gt; メソッドを使用してカウントマトリックスをtf-idf表現に変換します。これらの2つのステップを組み合わせて、冗長な処理をスキップすることにより、同じ最終結果をより速く達成できます。これは、以下に示すように、前のセクションの注記で述べたように、 &lt;code&gt;fit_transform(..)&lt;/code&gt; メソッドを使用して行われます。</target>
        </trans-unit>
        <trans-unit id="370df873906104ebc3c5f7c3ad3752f50f2bb258" translate="yes" xml:space="preserve">
          <source>In the above illustrating figure, we consider some points from a randomly generated dataset. We focus on the stochastic KNN classification of point no. 3. The thickness of a link between sample 3 and another point is proportional to their distance, and can be seen as the relative weight (or probability) that a stochastic nearest neighbor prediction rule would assign to this point. In the original space, sample 3 has many stochastic neighbors from various classes, so the right class is not very likely. However, in the projected space learned by NCA, the only stochastic neighbors with non-negligible weight are from the same class as sample 3, guaranteeing that the latter will be well classified. See the &lt;a href=&quot;#nca-mathematical-formulation&quot;&gt;mathematical formulation&lt;/a&gt; for more details.</source>
          <target state="translated">上の図では、ランダムに生成されたデータセットからいくつかのポイントを検討しています。ポイント番号の確率的KNN分類に焦点を当てます。 3.サンプル3と別のポイントの間のリンクの厚さは、それらの距離に比例し、確率的最近傍予測ルールがこのポイントに割り当てる相対的な重み（または確率）と見なすことができます。元の空間では、サンプル3にはさまざまなクラスからの確率的近傍が多数あるため、適切なクラスである可能性はほとんどありません。ただし、NCAによって学習された投影空間では、重みが無視できない確率的近傍のみがサンプル3と同じクラスからのものであり、後者が適切に分類されることが保証されます。詳細については、&lt;a href=&quot;#nca-mathematical-formulation&quot;&gt;数式を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="fc1fc9feffcc3ab7062a5968abf403f994be456d" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is more than 2, and that the document length is never zero. Likewise, we reject classes which have already been chosen. The documents that are assigned to both classes are plotted surrounded by two colored circles.</source>
          <target state="translated">上記の処理では、nが2以上であること、文書の長さが0になることがないことを確認するために、リジェクトサンプリングを行う。同様に、既に選択されているクラスを拒絶する。両方のクラスに割り当てられた文書は、2つの色付きの円で囲まれてプロットされています。</target>
        </trans-unit>
        <trans-unit id="35ac86e1f976c024d854c94dc1a07d9250df373b" translate="yes" xml:space="preserve">
          <source>In the above process, rejection sampling is used to make sure that n is never zero or more than &lt;code&gt;n_classes&lt;/code&gt;, and that the document length is never zero. Likewise, we reject classes which have already been chosen.</source>
          <target state="translated">上記のプロセスでは、拒否サンプリングを使用して、nがゼロまたは &lt;code&gt;n_classes&lt;/code&gt; より大きくならないようにし、ドキュメントの長さがゼロにならないようにします。同様に、すでに選択されているクラスは拒否されます。</target>
        </trans-unit>
        <trans-unit id="35b3eed71c5956697e4e941c9abda7fa7875d908" translate="yes" xml:space="preserve">
          <source>In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as</source>
          <target state="translated">バイナリー(2クラス)の場合、\(tp)、\(tn\)、\(f\)、F\(f\n)は、それぞれ、真の陽性、真の陰性、偽の陽性、偽の陰性の数であり、MCCは、次のように定義される。</target>
        </trans-unit>
        <trans-unit id="8cf754386b9e93bff61012cc7eebd891fe098125" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores.</source>
          <target state="translated">バイナリの場合、バランスの取れた精度は、&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;感度&lt;/a&gt;（真陽性率）と&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;特異度&lt;/a&gt;（真の陰性率）の算術平均、またはスコアではなくバイナリ予測を使用したROC曲線の下の面積に等しくなります。</target>
        </trans-unit>
        <trans-unit id="43cd3b6bd763c03854427d73b603fdca48b2b30e" translate="yes" xml:space="preserve">
          <source>In the binary case, balanced accuracy is equal to the arithmetic mean of &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;sensitivity&lt;/a&gt; (true positive rate) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;specificity&lt;/a&gt; (true negative rate), or the area under the ROC curve with binary predictions rather than scores:</source>
          <target state="translated">バイナリの場合、バランスの取れた精度は、&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;感度&lt;/a&gt;（真の陽性率）と&lt;a href=&quot;https://en.wikipedia.org/wiki/Sensitivity_and_specificity&quot;&gt;特異度&lt;/a&gt;（真の陰性率）の算術平均、またはスコアではなくバイナリ予測を使用したROC曲線の下の領域に等しくなります。</target>
        </trans-unit>
        <trans-unit id="a998ef5238ae7921fe9486295ae64f00deab3566" translate="yes" xml:space="preserve">
          <source>In the binary case, we can extract true positives, etc as follows:</source>
          <target state="translated">バイナリの場合は、以下のようにして真正値などを抽出することができます。</target>
        </trans-unit>
        <trans-unit id="3e94daaa4e8fed019552e1789dc3caf5c267c82f" translate="yes" xml:space="preserve">
          <source>In the binary case:</source>
          <target state="translated">バイナリーの場合。</target>
        </trans-unit>
        <trans-unit id="193e8f9e646cb769a122ba34f156f35dc1f6d79e" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt;&lt;code&gt;NuSVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;(n_classes * (n_classes - 1) / 2, n_features)&lt;/code&gt; and &lt;code&gt;(n_classes *
(n_classes - 1) / 2)&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">「one-vs-one」&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/sklearn.svm.nusvc#sklearn.svm.NuSVC&quot;&gt; &lt;code&gt;NuSVC&lt;/code&gt; の&lt;/a&gt;場合、属性のレイアウトはもう少し複雑です。線形カーネルの場合、属性 &lt;code&gt;coef_&lt;/code&gt; と &lt;code&gt;intercept_&lt;/code&gt; の形状はそれぞれ &lt;code&gt;(n_classes * (n_classes - 1) / 2, n_features)&lt;/code&gt; と &lt;code&gt;(n_classes * (n_classes - 1) / 2)&lt;/code&gt; です。これは、上記の&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;のレイアウトに似ており、各行がバイナリ分類子に対応しています。クラス0からnの順序は、「0 vs 1」、「0 vs 2」、&amp;hellip;「0 vs n」、「1 vs 2」、「1 vs 3」、「1 vs n」、です。 。 。 「n-1対n」。</target>
        </trans-unit>
        <trans-unit id="2482e7f51309cef70ec85538824011f95f0813b1" translate="yes" xml:space="preserve">
          <source>In the case of &amp;ldquo;one-vs-one&amp;rdquo; &lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt;&lt;code&gt;SVC&lt;/code&gt;&lt;/a&gt;, the layout of the attributes is a little more involved. In the case of having a linear kernel, the attributes &lt;code&gt;coef_&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; have the shape &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; and &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; respectively. This is similar to the layout for &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;LinearSVC&lt;/code&gt;&lt;/a&gt; described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is &amp;ldquo;0 vs 1&amp;rdquo;, &amp;ldquo;0 vs 2&amp;rdquo; , &amp;hellip; &amp;ldquo;0 vs n&amp;rdquo;, &amp;ldquo;1 vs 2&amp;rdquo;, &amp;ldquo;1 vs 3&amp;rdquo;, &amp;ldquo;1 vs n&amp;rdquo;, . . . &amp;ldquo;n-1 vs n&amp;rdquo;.</source>
          <target state="translated">「1対1」の&lt;a href=&quot;generated/sklearn.svm.svc#sklearn.svm.SVC&quot;&gt; &lt;code&gt;SVC&lt;/code&gt; の&lt;/a&gt;場合、属性のレイアウトが少し複雑になります。線形カーネルの場合、属性 &lt;code&gt;coef_&lt;/code&gt; および &lt;code&gt;intercept_&lt;/code&gt; の形状はそれぞれ &lt;code&gt;[n_class * (n_class - 1) / 2, n_features]&lt;/code&gt; および &lt;code&gt;[n_class * (n_class - 1) / 2]&lt;/code&gt; です。これは上記の&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;LinearSVC&lt;/code&gt; &lt;/a&gt;のレイアウトに似ており、各行がバイナリ分類子に対応しています。クラス0からnの順序は、「0 vs 1」、「0 vs 2」、&amp;hellip;「0 vs n」、「1 vs 2」、「1 vs 3」、「1 vs n」、&amp;hellip;です。 。 。 「n-1 vs n」。</target>
        </trans-unit>
        <trans-unit id="7befa9fe69dc29e17ce8c14ce1f24dcd596f25dc" translate="yes" xml:space="preserve">
          <source>In the case of Gaussian process classification, &amp;ldquo;one_vs_one&amp;rdquo; might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that &amp;ldquo;one_vs_one&amp;rdquo; does not support predicting probability estimates but only plain predictions. Moreover, note that &lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt;&lt;code&gt;GaussianProcessClassifier&lt;/code&gt;&lt;/a&gt; does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.</source>
          <target state="translated">ガウスプロセス分類の場合、「one_vs_one」は、データセット全体の問題を減らすのではなく、トレーニングセット全体のサブセットのみを含む多くの問題を解決する必要があるため、計算コストが低くなる可能性があります。ガウスプロセス分類はデータセットのサイズに応じて3次的にスケーリングされるため、これはかなり高速になる可能性があります。ただし、「one_vs_one」は確率予測の予測をサポートせず、単純な予測のみをサポートすることに注意してください。さらに、&lt;a href=&quot;generated/sklearn.gaussian_process.gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier&quot;&gt; &lt;code&gt;GaussianProcessClassifier&lt;/code&gt; &lt;/a&gt;は真のマルチクラスラプラス近似を（まだ）内部で実装していないことに注意してください。ただし、前述のように、1対レストまたは1対1を使用して結合された複数のバイナリ分類タスクを内部で解決することに基づいています。</target>
        </trans-unit>
        <trans-unit id="35a5ada3d16c18d2778299b423e5960182d45740" translate="yes" xml:space="preserve">
          <source>In the case of LDA, the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This leads to linear decision surfaces, which can be seen by comparing the log-probability ratios \(\log[P(y=k | X) / P(y=l | X)]\):</source>
          <target state="translated">LDAの場合,各クラスのGaussiansは,同じ共分散行列を共有すると仮定する。\(K\Sigma_k=\Sigma)for all \(k\).これは、対数確率比を比較することにより、線形の決定面が得られることを示している。</target>
        </trans-unit>
        <trans-unit id="9191afe7181654f4c123a5274615786e30f48b2b" translate="yes" xml:space="preserve">
          <source>In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See &lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt; for more details.</source>
          <target state="translated">QDAの場合、ガウス分布の共分散行列\（\ Sigma_k \）には仮定がなく、二次決定曲面になります。詳細については、&lt;a href=&quot;#id4&quot; id=&quot;id1&quot;&gt;[3]&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="be50ffb98df62eb79c354d934aa76c5587bf8cba" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of &lt;code&gt;shape=[n_classes]&lt;/code&gt;. The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">マルチクラス分類の場合、 &lt;code&gt;coef_&lt;/code&gt; は &lt;code&gt;shape=[n_classes, n_features]&lt;/code&gt; 2次元配列で、 &lt;code&gt;intercept_&lt;/code&gt; は &lt;code&gt;shape=[n_classes]&lt;/code&gt; の 1次元配列です。 &lt;code&gt;coef_&lt;/code&gt; のi番目の行は、i番目のクラスのOVA分類器の重みベクトルを保持します。クラスには昇順でインデックスが付けられます（ &lt;code&gt;classes_&lt;/code&gt; 属性を参照）。原則として、確率モデルを作成できるため、 &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; と &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; はone-vs-all分類に適しています。</target>
        </trans-unit>
        <trans-unit id="a5109fe6449c3757593d6d14759e9857d15d95c4" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification &lt;code&gt;coef_&lt;/code&gt; is a two-dimensional array of shape (n_classes, n_features) and &lt;code&gt;intercept_&lt;/code&gt; is a one-dimensional array of shape (n_classes,). The i-th row of &lt;code&gt;coef_&lt;/code&gt; holds the weight vector of the OVA classifier for the i-th class; classes are indexed in ascending order (see attribute &lt;code&gt;classes_&lt;/code&gt;). Note that, in principle, since they allow to create a probability model, &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; and &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; are more suitable for one-vs-all classification.</source>
          <target state="translated">マルチクラス分類の場合、 &lt;code&gt;coef_&lt;/code&gt; は形状の2次元配列（n_classes、n_features）であり、 &lt;code&gt;intercept_&lt;/code&gt; は形状の1次元配列（n_classes、）です。 &lt;code&gt;coef_&lt;/code&gt; のi番目の行は、i番目のクラスのOVA分類器の重みベクトルを保持します。クラスは昇順でインデックス付けされます（属性 &lt;code&gt;classes_&lt;/code&gt; を参照）。原則として、確率モデルを作成できるため、 &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; および &lt;code&gt;loss=&quot;modified_huber&quot;&lt;/code&gt; が1対すべての分類に適していることに注意してください。</target>
        </trans-unit>
        <trans-unit id="e1959581346965192dc91c946ef9926bceb1c51a" translate="yes" xml:space="preserve">
          <source>In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.</source>
          <target state="translated">多階級分類の場合、1対1-resest分類器の対数有義尤度の平均値が返されます。</target>
        </trans-unit>
        <trans-unit id="a45d03e82085c1e194b2b19d0700767439a7ac42" translate="yes" xml:space="preserve">
          <source>In the case of one-hot/one-of-K coding, the constructed feature names and values are returned rather than the original ones.</source>
          <target state="translated">ワンホット/ワンオブKコーディングの場合、元のものではなく、構築された特徴名と値が返されます。</target>
        </trans-unit>
        <trans-unit id="108b9e0576d5a78538771fb415a46ae76d1a6e26" translate="yes" xml:space="preserve">
          <source>In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. &lt;code&gt;BernoulliNB&lt;/code&gt; might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.</source>
          <target state="translated">テキスト分類の場合、この分類子をトレーニングして使用するために、（単語数ベクトルではなく）単語発生ベクトルを使用できます。 &lt;code&gt;BernoulliNB&lt;/code&gt; は、一部のデータセット、特にドキュメントが短いデータセットでパフォーマンスが向上する可能性があります。時間に余裕がある場合は、両方のモデルを評価することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="1ee37ddaa2e2b7fb0103fdddd162d9ad76a8f2dd" translate="yes" xml:space="preserve">
          <source>In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we &lt;em&gt;fit&lt;/em&gt; an &lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;estimator&lt;/a&gt; to be able to &lt;em&gt;predict&lt;/em&gt; the classes to which unseen samples belong.</source>
          <target state="translated">数字データセットの場合、タスクは、画像が与えられれば、それが表す数字を予測することです。私たちはその上10個の可能なクラスのそれぞれのサンプル（数字は9を通じてゼロ）が与えられた&lt;em&gt;フィット&lt;/em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Estimator&quot;&gt;推定を&lt;/a&gt;することができるように&lt;em&gt;予測する&lt;/em&gt;目に見えないサンプルが属するクラスを。</target>
        </trans-unit>
        <trans-unit id="0484e6facaecfeba6a4ff8e0552fa9a5ac1c52dd" translate="yes" xml:space="preserve">
          <source>In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if &lt;code&gt;method&lt;/code&gt; produces columns per class, as in {&amp;lsquo;decision_function&amp;rsquo;, &amp;lsquo;predict_proba&amp;rsquo;, &amp;lsquo;predict_log_proba&amp;rsquo;}. For &lt;code&gt;predict_proba&lt;/code&gt; this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.</source>
          <target state="translated">{'decision_function'、 'predict_proba'、 'predict_log_proba'}のように、 &lt;code&gt;method&lt;/code&gt; がクラスごとに列を生成する場合、トレーニング部分に1つ以上のクラスが存在しない場合、デフォルトのスコアをそのクラスのすべてのインスタンスに割り当てる必要があります。 。ため &lt;code&gt;predict_proba&lt;/code&gt; この値は他の場合にはDTYPEの最小有限の浮動小数点値によって有限の出力、我々近似負の無限大を確保するために0です。</target>
        </trans-unit>
        <trans-unit id="74ff5bfdda6b3e93f59169f7c22fc2d68fa3fcf3" translate="yes" xml:space="preserve">
          <source>In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model&amp;rsquo;s decision_function method directly as the input of inverse_transform.</source>
          <target state="translated">バイナリラベルが小数（確率的）の場合、inverse_transformは最大の値を持つクラスを選択します。通常、これにより、線形モデルのdecision_functionメソッドの出力をinverse_transformの入力として直接使用できます。</target>
        </trans-unit>
        <trans-unit id="e087c17fe61957d86c5cc0e9905f0323cd8dea87" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt;&lt;code&gt;VotingClassifier&lt;/code&gt;&lt;/a&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">同点の場合、&lt;a href=&quot;generated/sklearn.ensemble.votingclassifier#sklearn.ensemble.VotingClassifier&quot;&gt; &lt;code&gt;VotingClassifier&lt;/code&gt; &lt;/a&gt;は昇順のソート順にクラスを選択します。たとえば、次のシナリオでは</target>
        </trans-unit>
        <trans-unit id="2d852af4ac330c07eec96a31a9559a88b3b70655" translate="yes" xml:space="preserve">
          <source>In the cases of a tie, the &lt;code&gt;VotingClassifier&lt;/code&gt; will select the class based on the ascending sort order. E.g., in the following scenario</source>
          <target state="translated">同 &lt;code&gt;VotingClassifier&lt;/code&gt; の場合、VotingClassifierは昇順のソート順に基づいてクラスを選択します。たとえば、次のシナリオでは</target>
        </trans-unit>
        <trans-unit id="84352a0fa93e8d3c09e63ba562819b09bff22e0e" translate="yes" xml:space="preserve">
          <source>In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:</source>
          <target state="translated">市松模様の場合、各行はすべての列クラスタに属し、各列はすべての行クラスタに属します。ここでは、各二重クラスタ内の値の分散が小さい場合のこの構造の例を示します。</target>
        </trans-unit>
        <trans-unit id="6a06bacf0f95acd504bad8493dc228833ae72576" translate="yes" xml:space="preserve">
          <source>In the event that the 95% confidence interval based on Fisher transform spans zero, a warning is raised.</source>
          <target state="translated">Fisher変換に基づく95%信頼区間がゼロに広がっている場合、警告が表示されます。</target>
        </trans-unit>
        <trans-unit id="2da0fe066fd806cee05903c8f41b8c38bb726d66" translate="yes" xml:space="preserve">
          <source>In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.</source>
          <target state="translated">以下の例では、小さなシュリンク閾値を使用することで、モデルの精度が0.81から0.82に向上しています。</target>
        </trans-unit>
        <trans-unit id="ae3527cc8009043f3459062f8b3ac5f4c7cdc080" translate="yes" xml:space="preserve">
          <source>In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.</source>
          <target state="translated">下の図では、色はクラスターのメンバーシップを示し、大きな円はアルゴリズムによって発見されたコア・サンプルを示しています。小さな丸は、クラスタに属しているコアサンプルではないサンプルを示しています。さらに、外れたサンプルは下の黒い点で示されています。</target>
        </trans-unit>
        <trans-unit id="cfa64cd986932f750b1c68de33ab3971d444bf3d" translate="yes" xml:space="preserve">
          <source>In the first column, first row the learning curve of a naive Bayes classifier is shown for the digits dataset. Note that the training score and the cross-validation score are both not very good at the end. However, the shape of the curve can be found in more complex datasets very often: the training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases. In the second column, first row we see the learning curve of an SVM with RBF kernel. We can see clearly that the training score is still around the maximum and the validation score could be increased with more training samples. The plots in the second row show the times required by the models to train with various sizes of training dataset. The plots in the third row show how much time was required to train the models for each training sizes.</source>
          <target state="translated">最初の列、最初の行に、数字のデータセットに対するナイーブベイズ分類器の学習曲線が示されています。学習スコアと交差検証スコアの両方が最後にはあまり良くないことに注意してください。しかし、この曲線の形状は、より複雑なデータセットでは非常によく見られます:訓練スコアは最初に非常に高く、その後減少し、交差検証スコアは最初に非常に低く、その後増加します。2列目の最初の行では、RBFカーネルを用いたSVMの学習曲線を見ることができます。学習スコアがまだ最大値付近にあり、より多くの学習サンプルで検証スコアを増加させることができることがわかります。2行目のプロットは、様々なサイズの学習データセットでの学習に必要な時間を示しています。3列目のプロットは、各トレーニングサイズでモデルのトレーニングにどれだけの時間がかかったかを示しています。</target>
        </trans-unit>
        <trans-unit id="bbb41405aaf08b233f5d5a9cb37143ee4833765d" translate="yes" xml:space="preserve">
          <source>In the first figure, we visualize the value of the kernel, i.e. the similarity of the sequences, using a colormap. Brighter color here indicates higher similarity.</source>
          <target state="translated">最初の図では、カーネルの値、すなわち配列の類似度をカラーマップを用いて可視化しています。ここでは、色が明るいほど類似度が高いことを示しています。</target>
        </trans-unit>
        <trans-unit id="a915ebedbc9fc712ae336eb7409727fc370425dc" translate="yes" xml:space="preserve">
          <source>In the first row, the classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.</source>
          <target state="translated">1列目はセパル幅とセパル長の特徴量のみを用いて分類器を構築し、2列目は花弁長とセパル長の特徴量のみを用いて分類器を構築し、3列目は花弁幅と花弁長の特徴量のみを用いて分類器を構築します。</target>
        </trans-unit>
        <trans-unit id="974efdfc7b27c9e04d6e731c42ba40fb3d593ff5" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">次の例では、データセットを表す配列からNearestNeighborsクラスを作成し、[1,1,1]に最も近いポイントを尋ねます。</target>
        </trans-unit>
        <trans-unit id="bd9366b471cf174a5dc26260b1ee3e4775bd8a95" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1, 1, 1]:</source>
          <target state="translated">次の例では、データセットを表す配列からNeighborsClassifierクラスを作成し、[1、1、1]に最も近い点を誰に尋ねます。</target>
        </trans-unit>
        <trans-unit id="f873541d5e32ccd97b454877a7265b9e862eeb9a" translate="yes" xml:space="preserve">
          <source>In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who&amp;rsquo;s the closest point to [1,1,1]</source>
          <target state="translated">次の例では、データセットを表す配列からNeighborsClassifierクラスを構築し、[1,1,1]に最も近いポイントが誰であるかを尋ねます</target>
        </trans-unit>
        <trans-unit id="65f9f2f58e8b0fd298381aa88835a40b1607c17f" translate="yes" xml:space="preserve">
          <source>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</source>
          <target state="translated">次の図では、二峰分布から100点を抽出し、カーネルの3つの選択肢についてカーネル密度の推定値を示しています。</target>
        </trans-unit>
        <trans-unit id="a08df9eebc31ca3edc4756b37a4fdadef1454fe3" translate="yes" xml:space="preserve">
          <source>In the following plot, the maximum effective alpha value is removed, because it is the trivial tree with only one node.</source>
          <target state="translated">以下のプロットでは、ノードが1つしかない些細な木なので、有効α値の最大値は削除されています。</target>
        </trans-unit>
        <trans-unit id="24263a7351535bc4435386a661d4637b721eb5a0" translate="yes" xml:space="preserve">
          <source>In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).</source>
          <target state="translated">次のプロットでは、関数 \(f(x)=\cos (\frac{3}{2}\pi x))と、その関数からのノイズの多いサンプルが見えます。我々は、次数1,4,15の多項式特徴量を持つ線形回帰の3つの異なる推定量を使用して、関数を適合させる。最初の推定量は、単純すぎて(バイアスが高い)、2番目の推定量はほぼ完璧に近似し、最後の推定量は訓練データを完璧に近似するが、真の関数にはあまりフィットしない、つまり、訓練データの変化に非常に敏感である(分散が高い)ことがわかります。</target>
        </trans-unit>
        <trans-unit id="605a0ccca31d97f6c29fd62c728a36908756654e" translate="yes" xml:space="preserve">
          <source>In the following section, we will interpret the coefficients of the model. While we do so, we should keep in mind that any conclusion we draw is about the model that we build, rather than about the true (real-world) generative process of the data.</source>
          <target state="translated">次のセクションでは、モデルの係数を解釈します。その間、我々が導き出す結論は、データの真の(実世界の)生成プロセスではなく、我々が構築したモデルについてのものであることに留意すべきです。</target>
        </trans-unit>
        <trans-unit id="de54ef0bf525631d31eb0623dcd55f8a9ddc120b" translate="yes" xml:space="preserve">
          <source>In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.</source>
          <target state="translated">以下のサブセクションでは、共通のAPIとメトリックの定義についての注意事項に続いて、それぞれの関数について説明します。</target>
        </trans-unit>
        <trans-unit id="7549668dfe247eb9e0e172cc89f620a63604992b" translate="yes" xml:space="preserve">
          <source>In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the &lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt;&lt;code&gt;sklearn.datasets.load_files&lt;/code&gt;&lt;/a&gt; function by pointing it to the &lt;code&gt;20news-bydate-train&lt;/code&gt; sub-folder of the uncompressed archive folder.</source>
          <target state="translated">以下では、scikit-learnの20のニュースグループに組み込みのデータセットローダーを使用します。または、ウェブサイトから手動でデータセットをダウンロードし、非圧縮アーカイブフォルダーの &lt;code&gt;20news-bydate-train&lt;/code&gt; サブフォルダーを&lt;a href=&quot;../../modules/generated/sklearn.datasets.load_files#sklearn.datasets.load_files&quot;&gt; &lt;code&gt;sklearn.datasets.load_files&lt;/code&gt; &lt;/a&gt;することにより、sklearn.datasets.load_files関数を使用することもできます。</target>
        </trans-unit>
        <trans-unit id="2cb0b9817ecf09ea4893bb9df9d328ce75ef2d1b" translate="yes" xml:space="preserve">
          <source>In the following, &amp;ldquo;city&amp;rdquo; is a categorical attribute while &amp;ldquo;temperature&amp;rdquo; is a traditional numerical feature:</source>
          <target state="translated">以下では、「都市」はカテゴリ属性であり、「気温」は従来の数値的特徴です。</target>
        </trans-unit>
        <trans-unit id="3e019b4cbe3ce7f1554fa08ce08898c560cb8a3b" translate="yes" xml:space="preserve">
          <source>In the following, we start a Python interpreter from our shell and then load the &lt;code&gt;iris&lt;/code&gt; and &lt;code&gt;digits&lt;/code&gt; datasets. Our notational convention is that &lt;code&gt;$&lt;/code&gt; denotes the shell prompt while &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; denotes the Python interpreter prompt:</source>
          <target state="translated">以下では、シェルからPythonインタープリターを起動し、 &lt;code&gt;iris&lt;/code&gt; および &lt;code&gt;digits&lt;/code&gt; データセットをロードします。表記規則では、 &lt;code&gt;$&lt;/code&gt; はシェルプロンプトを示し、 &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; はPythonインタープリタープロンプトを示します。</target>
        </trans-unit>
        <trans-unit id="fe30ab8cfcc104ee94b5fb01793274570a377034" translate="yes" xml:space="preserve">
          <source>In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:</source>
          <target state="translated">上の式において、\(\mathbf{b}\)と\(\mathbf{c}\)は、それぞれ可視層と隠蔽層の切片ベクトルである。モデルの結合確率は,エネルギーで定義される.</target>
        </trans-unit>
        <trans-unit id="e448c91ec6db1584eec64770c66e9fad7266b47b" translate="yes" xml:space="preserve">
          <source>In the graphical model, each node is a random variable and has a role in the generative process. A shaded node indicates an observed variable and an unshaded node indicates a hidden (latent) variable. In this case, words in the corpus are the only data that we observe. The latent variables determine the random mixture of topics in the corpus and the distribution of words in the documents. The goal of LDA is to use the observed words to infer the hidden topic structure.</source>
          <target state="translated">グラフィカル・モデルでは、各ノードはランダム変数であり、生成プロセスでの役割を持っています。網掛けされたノードは観測された変数を示し、網掛けされていないノードは隠れた(潜在的な)変数を示す。この場合、コーパス内の単語は観測される唯一のデータである。潜在変数は、コーパス内のトピックのランダムな混合と文書内の単語の分布を決定する。LDAの目的は、観測された単語を用いて隠れたトピック構造を推論することである。</target>
        </trans-unit>
        <trans-unit id="66070e8da21856ec34fc0b507e5d723e9475a567" translate="yes" xml:space="preserve">
          <source>In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the &lt;code&gt;average&lt;/code&gt; parameter.</source>
          <target state="translated">マルチクラスおよびマルチラベルの場合、これは各パラメーターのF1スコアの平均であり、 &lt;code&gt;average&lt;/code&gt; パラメーターに応じて重み付けされます。</target>
        </trans-unit>
        <trans-unit id="47604d7ff8f733fb868ecbca5a77b859a57fe5aa" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the Matthews correlation coefficient can be &lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;defined&lt;/a&gt; in terms of a &lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt;&lt;code&gt;confusion_matrix&lt;/code&gt;&lt;/a&gt;\(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:</source>
          <target state="translated">マルチクラス場合に、マシューズの相関係数をすることができる&lt;a href=&quot;http://rk.kvl.dk/introduction/index.html&quot;&gt;定義&lt;/a&gt;の点で&lt;a href=&quot;generated/sklearn.metrics.confusion_matrix#sklearn.metrics.confusion_matrix&quot;&gt; &lt;code&gt;confusion_matrix&lt;/code&gt; &lt;/a&gt; \（C \）（K \）クラス\ました。定義を簡略化するために、次の中間変数を検討してください。</target>
        </trans-unit>
        <trans-unit id="b8d01a57cb617acafda7dfb6fdd570d7cb46be7c" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross- entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">マルチクラスの場合、トレーニングアルゴリズムは、 'multi_class'オプションが 'ovr'に設定されている場合はone-vs-rest（OvR）スキームを使用し、 'multi_class'オプションが 'multinomial'に設定されている場合はクロスエントロピー損失を使用します'。（現在、「多項式」オプションは「lbfgs」、「sag」、および「newton-cg」ソルバーでのみサポートされています。）</target>
        </trans-unit>
        <trans-unit id="df1f72c5b54cf7ce11968ba990ade83d8b80475a" translate="yes" xml:space="preserve">
          <source>In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;ovr&amp;rsquo;, and uses the cross-entropy loss if the &amp;lsquo;multi_class&amp;rsquo; option is set to &amp;lsquo;multinomial&amp;rsquo;. (Currently the &amp;lsquo;multinomial&amp;rsquo; option is supported only by the &amp;lsquo;lbfgs&amp;rsquo;, &amp;lsquo;sag&amp;rsquo;, &amp;lsquo;saga&amp;rsquo; and &amp;lsquo;newton-cg&amp;rsquo; solvers.)</source>
          <target state="translated">マルチクラスの場合、トレーニングアルゴリズムは、「multi_class」オプションが「ovr」に設定されている場合はone-vs-rest（OvR）スキームを使用し、「multi_class」オプションが「multinomial」に設定されている場合はクロスエントロピー損失を使用します。 '。（現在、「多項」オプションは、「lbfgs」、「sag」、「saga」、および「newton-cg」ソルバーでのみサポートされています。）</target>
        </trans-unit>
        <trans-unit id="0fc004eb44e3b89b80f2b6796f35d04551e921cc" translate="yes" xml:space="preserve">
          <source>In the multiclass case:</source>
          <target state="translated">マルチクラスの場合。</target>
        </trans-unit>
        <trans-unit id="d77598124fa8bad46b51e89decd127c4c83bc1e3" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators, where the first label set [0,1] has an error:</source>
          <target state="translated">バイナリラベル表示器を持つマルチラベルの場合、最初のラベル集合[0,1]がエラーになる。</target>
        </trans-unit>
        <trans-unit id="4557110f167a92f3d0af48823270c458eb95839b" translate="yes" xml:space="preserve">
          <source>In the multilabel case with binary label indicators:</source>
          <target state="translated">バイナリーラベルインジケーターのマルチラベルの場合。</target>
        </trans-unit>
        <trans-unit id="e898613ef6934f2809451f3fa3e427c4a4bd49ce" translate="yes" xml:space="preserve">
          <source>In the multilabel case, this calculates a confusion matrix per sample</source>
          <target state="translated">マルチラベルの場合、これはサンプルごとの混同行列を計算します。</target>
        </trans-unit>
        <trans-unit id="2b2a464789db8978cf9674eef13e9bc3f4a4cf79" translate="yes" xml:space="preserve">
          <source>In the multilabel case:</source>
          <target state="translated">マルチラベルの場合</target>
        </trans-unit>
        <trans-unit id="3dbb497f0422701e359a6bab16a477019a81aa92" translate="yes" xml:space="preserve">
          <source>In the multilabel learning literature, OvR is also known as the binary relevance method.</source>
          <target state="translated">マルチラベル学習の文献では、OvRは二値関連性法としても知られています。</target>
        </trans-unit>
        <trans-unit id="b098a0ed402e179dee6b5de05c6210f893507735" translate="yes" xml:space="preserve">
          <source>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by &lt;code&gt;transform&lt;/code&gt; will typically be dense.</source>
          <target state="translated">新しい空間では、各次元はクラスターの中心までの距離です。Xがスパースであっても、通常、 &lt;code&gt;transform&lt;/code&gt; によって返される配列は密になります。</target>
        </trans-unit>
        <trans-unit id="a90aa674a36fbb7c4f65ac18f5e6a5a0eb4c7bc3" translate="yes" xml:space="preserve">
          <source>In the official &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt; this task is described as the &amp;ldquo;Restricted&amp;rdquo; task. As I am not sure as to implement the &amp;ldquo;Unrestricted&amp;rdquo; variant correctly, I left it as unsupported for now.</source>
          <target state="translated">公式の&lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/README.txt&quot;&gt;README.txt&lt;/a&gt;では、このタスクは「制限付き」タスクとして説明されています。「Unrestricted」バリアントを正しく実装するかどうか確信が持てないため、現時点ではサポートしないままにしておきます。</target>
        </trans-unit>
        <trans-unit id="5f046ff1a0210873f4b93ca532a15f1f001fc328" translate="yes" xml:space="preserve">
          <source>In the second figure, we show some regression result on a dataset of 6 sequences. Here we use the 1st, 2nd, 4th, and 5th sequences as the training set to make predictions on the 3rd and 6th sequences.</source>
          <target state="translated">2番目の図は、6つの配列のデータセットに対する回帰結果を示しています。ここでは、第1、第2、第4、第5の配列を学習セットとして使用し、第3、第6の配列の予測を行っています。</target>
        </trans-unit>
        <trans-unit id="901c760a214576d30b4ced7bbcce771984b42233" translate="yes" xml:space="preserve">
          <source>In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.</source>
          <target state="translated">例で見たような単純な一次元問題では、推定子がバイアスを受けているのか、分散を受けているのかは簡単にわかります。しかし、高次元空間では、モデルの可視化が非常に困難になることがあります。そのため、以下のツールを使用すると便利なことが多いです。</target>
        </trans-unit>
        <trans-unit id="bada0a0c8458a65354b2c23e7134e865cc4bf85c" translate="yes" xml:space="preserve">
          <source>In the single label multiclass case, the rows of the returned matrix sum to 1.</source>
          <target state="translated">シングルラベルのマルチクラスの場合,返される行列の行の和は1になります.</target>
        </trans-unit>
        <trans-unit id="696912c12d134eed0fdc2e472302634288905dc5" translate="yes" xml:space="preserve">
          <source>In the small-samples situation, in which &lt;code&gt;n_samples&lt;/code&gt; is on the order of &lt;code&gt;n_features&lt;/code&gt; or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.</source>
          <target state="translated">&lt;code&gt;n_samples&lt;/code&gt; が &lt;code&gt;n_features&lt;/code&gt; 以下の小さいサンプルの状況では、スパース逆共分散推定量は、縮小された共分散推定量よりも機能する傾向があります。ただし、反対の状況、または相関性の高いデータでは、数値的に不安定になる可能性があります。さらに、収縮推定量とは異なり、スパース推定量は非対角構造を回復できます。</target>
        </trans-unit>
        <trans-unit id="1c648bbbf8ddd269e7c36de7c1822a2705968fac" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;dump&lt;/code&gt; &amp;amp; &lt;code&gt;load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">scikit-learnの特定のケースでは、joblibのpickle（ &lt;code&gt;dump&lt;/code&gt; ＆ &lt;code&gt;load&lt;/code&gt; ）の代わりに使用する方がよい場合があります。これは、フィットしたscikit-learn推定器の場合によくあるように、内部に大きなnumpy配列を運ぶオブジェクトでより効率的です。ディスクにのみピクルスでき、文字列にはピクルスできません。</target>
        </trans-unit>
        <trans-unit id="d5f33dda5b96ece3c041650e9fa8db02e62bfd46" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be better to use joblib&amp;rsquo;s replacement of pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string:</source>
          <target state="translated">scikit-learnの特定のケースでは、joblibのピクル（ &lt;code&gt;joblib.dump&lt;/code&gt; ＆ &lt;code&gt;joblib.load&lt;/code&gt; ）の代わりを使用する方がよい場合があります。これは、フィットされたscikit-の場合によくあるように、内部で大きなnumpy配列を持つオブジェクトでより効率的です。推定器を学びますが、ディスクにのみピクルでき、文字列にはピクルできません：</target>
        </trans-unit>
        <trans-unit id="4d7c6f4a78fb7d42f5b6b076760e4c0fb27e052c" translate="yes" xml:space="preserve">
          <source>In the specific case of scikit-learn, it may be more interesting to use joblib&amp;rsquo;s replacement for pickle (&lt;code&gt;joblib.dump&lt;/code&gt; &amp;amp; &lt;code&gt;joblib.load&lt;/code&gt;), which is more efficient on big data but it can only pickle to the disk and not to a string:</source>
          <target state="translated">scikit-learnの特定のケースでは、pickleの代わりにjoblibを使用する（ &lt;code&gt;joblib.dump&lt;/code&gt; ＆ &lt;code&gt;joblib.load&lt;/code&gt; ）の方が興味深いかもしれません。これは、ビッグデータではより効率的ですが、文字列ではなくディスクにピクルするだけです。 ：</target>
        </trans-unit>
        <trans-unit id="6bc18b31ba734fa9a1f609c8898b12e640d531fb" translate="yes" xml:space="preserve">
          <source>In the statistics community, it is common practice to perform multiple imputations, generating, for example, &lt;code&gt;m&lt;/code&gt; separate imputations for a single feature matrix. Each of these &lt;code&gt;m&lt;/code&gt; imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The &lt;code&gt;m&lt;/code&gt; final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.</source>
          <target state="translated">統計コミュニティでは、複数の代入を実行して、たとえば、単一の特徴行列に対して &lt;code&gt;m&lt;/code&gt; 個の個別の代入を生成するのが一般的な方法です。次に、これらの &lt;code&gt;m&lt;/code&gt; 個の代入のそれぞれが、後続の分析パイプライン（たとえば、機能エンジニアリング、クラスタリング、回帰、分類）にかけられます。 &lt;code&gt;m&lt;/code&gt; 最終的な分析結果（例えば、保持アウト検証エラー）は、データ科学者は、欠損値に起因する固有の不確実性の結果として異なっていてもよい方法の解析結果の理解得ることを可能にします。上記の方法は、多重代入と呼ばれます。</target>
        </trans-unit>
        <trans-unit id="d3fa57071e687f0bc6b84bf63b957df19fb1d89e" translate="yes" xml:space="preserve">
          <source>In the third figure, we demonstrate a classification model by training on 6 sequences and make predictions on another 5 sequences. The ground truth here is simply whether there is at least one &amp;lsquo;A&amp;rsquo; in the sequence. Here the model makes four correct classifications and fails on one.</source>
          <target state="translated">3番目の図では、6つのシーケンスでトレーニングし、別の5つのシーケンスで予測を行うことにより、分類モデルを示しています。ここでのグラウンドトゥルースは、シーケンスに少なくとも1つの「A」があるかどうかです。ここで、モデルは4つの正しい分類を行い、1つで失敗します。</target>
        </trans-unit>
        <trans-unit id="4e8940d2e745f9a24bd23b0a1547dcf715a870bb" translate="yes" xml:space="preserve">
          <source>In the total set of features, only the 4 first ones are significant. We can see that they have the highest score with univariate feature selection. The SVM assigns a large weight to one of these features, but also Selects many of the non-informative features. Applying univariate feature selection before the SVM increases the SVM weight attributed to the significant features, and will thus improve classification.</source>
          <target state="translated">特徴量の総集合の中で、最初の4つの特徴量だけが有意である。それらが一変量特徴選択で最も高いスコアを持っていることがわかります。SVM はこれらの特徴のうちの 1 つに大きな重みを割り当てますが、非情報的な特徴の多くも選択します。SVMの前に一変量特徴選択を適用すると、有意な特徴に帰属するSVMの重みが増加し、その結果、分類が改善されます。</target>
        </trans-unit>
        <trans-unit id="5cab08ab26978fd8cb0ee3262a21c03baca4d379" translate="yes" xml:space="preserve">
          <source>In the transformed &lt;code&gt;X&lt;/code&gt;, the first column is the encoding of the feature with categories &amp;ldquo;male&amp;rdquo;/&amp;rdquo;female&amp;rdquo;, while the remaining 6 columns is the encoding of the 2 features with respectively 3 categories each.</source>
          <target state="translated">変換された &lt;code&gt;X&lt;/code&gt; では、最初の列はカテゴリ「男性」/「女性」の特徴のエンコーディングであり、残りの6列はそれぞれ3つのカテゴリの2つの特徴のエンコーディングです。</target>
        </trans-unit>
        <trans-unit id="a3dd53135ff49dbe7e421a248bf614a3ea8f0d5e" translate="yes" xml:space="preserve">
          <source>In the vector quantization literature, &lt;code&gt;cluster_centers_&lt;/code&gt; is called the code book and each value returned by &lt;code&gt;predict&lt;/code&gt; is the index of the closest code in the code book.</source>
          <target state="translated">ベクトル量子化の文献では、 &lt;code&gt;cluster_centers_&lt;/code&gt; は、コードブックと呼ばれ、各値は、によって返された &lt;code&gt;predict&lt;/code&gt; コードブック内の最も近いコードのインデックスです。</target>
        </trans-unit>
        <trans-unit id="71ea1d0e6870ae14110d577f25dbcd29b63431c3" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">2004年の論文&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;1で&lt;/a&gt;、O。LedoitとM. Wolfは、推定された共分散行列と実際の共分散行列の間の平均二乗誤差を最小化する最適な収縮係数\（\ alpha \）を計算する式を提案しています。</target>
        </trans-unit>
        <trans-unit id="9a63d5086bf9614df56a7612405271e0122a8145" translate="yes" xml:space="preserve">
          <source>In their 2004 paper &lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.</source>
          <target state="translated">2004年の論文&lt;a href=&quot;#id3&quot; id=&quot;id2&quot;&gt;[1]で&lt;/a&gt;、O。LedoitとM. Wolfは、推定された共分散行列と実際の共分散行列の間の平均二乗誤差を最小化する最適収縮係数\（\ alpha \）を計算する式を提案しています。</target>
        </trans-unit>
        <trans-unit id="ee9767309b3df05ebf7c392a0bb4e8915eee3d46" translate="yes" xml:space="preserve">
          <source>In these settings, the &lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;Spectral clustering&lt;/a&gt; approach solves the problem know as &amp;lsquo;normalized graph cuts&amp;rsquo;: the image is seen as a graph of connected voxels, and the spectral clustering algorithm amounts to choosing graph cuts defining regions while minimizing the ratio of the gradient along the cut, and the volume of the region.</source>
          <target state="translated">これらの設定では、&lt;a href=&quot;../../modules/clustering#spectral-clustering&quot;&gt;スペクトルクラスタリング&lt;/a&gt;アプローチは「正規化されたグラフカット」として知られる問題を解決します。画像は接続されたボクセルのグラフとして表示され、スペクトルクラスタリングアルゴリズムは、領域に沿った勾配の比率を最小化しながら、グラフカットを選択することになります。カット、および領域のボリューム。</target>
        </trans-unit>
        <trans-unit id="e2e4475ec0999dd975ba681e19179d817d6681ae" translate="yes" xml:space="preserve">
          <source>In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.</source>
          <target state="translated">この場合,特定のグループのセットで訓練されたモデルが,見ていないグループにもよく一般化するかどうかを知りたい.これを測定するには、検証フォールドのすべてのサンプルが、ペアの訓練フォールドではまったく表現されていないグループから来ていることを確認する必要があります。</target>
        </trans-unit>
        <trans-unit id="8e6586aaac37d3a887b7276aee6797fdd6471b11" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features:</source>
          <target state="translated">この場合、 &lt;code&gt;X_train&lt;/code&gt; と &lt;code&gt;X_test&lt;/code&gt; は同じ数の機能を持つことが保証されています。同じ結果を得る別の方法は、機能の数を修正することです：</target>
        </trans-unit>
        <trans-unit id="c94c921d6a6a8582b29da8ef5a3a44fe1ea80a89" translate="yes" xml:space="preserve">
          <source>In this case, the classifier is fit upon instances each assigned multiple labels. The &lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt;&lt;code&gt;MultiLabelBinarizer&lt;/code&gt;&lt;/a&gt; is used to binarize the 2d array of multilabels to &lt;code&gt;fit&lt;/code&gt; upon. As a result, &lt;code&gt;predict()&lt;/code&gt; returns a 2d array with multiple predicted labels for each instance.</source>
          <target state="translated">この場合、分類子は、複数のラベルがそれぞれ割り当てられているインスタンスに適合します。&lt;a href=&quot;../../modules/generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer&quot;&gt; &lt;code&gt;MultiLabelBinarizer&lt;/code&gt; は&lt;/a&gt;にmultilabelsの2次元配列を2値化するために使用される &lt;code&gt;fit&lt;/code&gt; 時に。その結果、 &lt;code&gt;predict()&lt;/code&gt; は、インスタンスごとに複数の予測ラベルを持つ2D配列を返します。</target>
        </trans-unit>
        <trans-unit id="4367a423584d0b6ba622189fa17b21bb3e206f2c" translate="yes" xml:space="preserve">
          <source>In this case, the cross-validation retained the same ratio of classes across each CV split. Next we&amp;rsquo;ll visualize this behavior for a number of CV iterators.</source>
          <target state="translated">この場合、交差検証では、CV分割ごとに同じ比率のクラスが保持されました。次に、いくつかのCVイテレータのこの動作を視覚化します。</target>
        </trans-unit>
        <trans-unit id="d121f450bc55250670235f93c8cd2083eb40a561" translate="yes" xml:space="preserve">
          <source>In this context, we can define the notions of precision, recall and F-measure:</source>
          <target state="translated">この文脈では、精度、リコール、Fメジャーの概念を定義することができます。</target>
        </trans-unit>
        <trans-unit id="308ef10a0e6fa4feab74c9fff8eae0756aa171db" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy, i.e. a contract within an insurance company and an individual (policyholder). Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="translated">このデータセットでは,各サンプルは保険契約,すなわち保険会社内の契約と個人(契約者)に対応している.利用可能な特徴としては,運転者の年齢,車の年齢,車のパワーなどがある.</target>
        </trans-unit>
        <trans-unit id="b69830262e95394b14f5a754f7290cc7372dc2b1" translate="yes" xml:space="preserve">
          <source>In this dataset, each sample corresponds to an insurance policy. Available features include driver age, vehicle age, vehicle power, etc.</source>
          <target state="translated">このデータセットでは,各サンプルは保険契約に対応している.利用可能な特徴としては,運転者の年齢,車齢,車のパワーなどがある.</target>
        </trans-unit>
        <trans-unit id="6b7e5d4a758a26d1b659ba54387246d5cebcf12f" translate="yes" xml:space="preserve">
          <source>In this example the dependent variable Y is set as a function of the input features: y = X*w + c. The coefficient vector w is randomly sampled from a normal distribution, whereas the bias term c is set to a constant.</source>
          <target state="translated">この例では、従属変数 Y は入力特徴量の関数として設定されます:y=X*w+c.</target>
        </trans-unit>
        <trans-unit id="5d530c717737ac885c81ddc70c9c4fe51f2f2e42" translate="yes" xml:space="preserve">
          <source>In this example the silhouette analysis is used to choose an optimal value for &lt;code&gt;n_clusters&lt;/code&gt;. The silhouette plot shows that the &lt;code&gt;n_clusters&lt;/code&gt; value of 3, 5 and 6 are a bad pick for the given data due to the presence of clusters with below average silhouette scores and also due to wide fluctuations in the size of the silhouette plots. Silhouette analysis is more ambivalent in deciding between 2 and 4.</source>
          <target state="translated">この例では、シルエット分析を使用して &lt;code&gt;n_clusters&lt;/code&gt; の最適値を選択しています。シルエットプロットは、 &lt;code&gt;n_clusters&lt;/code&gt; 値が、平均シルエットスコアより低いクラスターの存在と、シルエットプロットのサイズの大きな変動のために、特定のデータにとって不適切な選択であることを示しています。シルエット分析は、2と4の間で決定する際によりあいまいです。</target>
        </trans-unit>
        <trans-unit id="0b7aa73d7d4561b0e25989b4fff6f5d53474b724" translate="yes" xml:space="preserve">
          <source>In this example we compare some estimators for the purpose of missing feature imputation with &lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt;&lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">この例では、特徴の代入を欠落させる目的でいくつかの推定量を&lt;a href=&quot;../../modules/generated/sklearn.impute.iterativeimputer#sklearn.impute.IterativeImputer&quot;&gt; &lt;code&gt;sklearn.impute.IterativeImputer&lt;/code&gt; &lt;/a&gt;と比較します。</target>
        </trans-unit>
        <trans-unit id="550c896ceafe31d2e76547c4031642097a79581f" translate="yes" xml:space="preserve">
          <source>In this example we compare the various initialization strategies for K-means in terms of runtime and quality of the results.</source>
          <target state="translated">この例では、実行時間と結果の品質の観点から、K-meansの様々な初期化戦略を比較します。</target>
        </trans-unit>
        <trans-unit id="d9bed364e1f96090d42e72d8ad4e31b8f81dfc1d" translate="yes" xml:space="preserve">
          <source>In this example we prefer the &lt;code&gt;elasticnet&lt;/code&gt; penalty as it is often a good compromise between model compactness and prediction power. One can also further tune the &lt;code&gt;l1_ratio&lt;/code&gt; parameter (in combination with the regularization strength &lt;code&gt;alpha&lt;/code&gt;) to control this tradeoff.</source>
          <target state="translated">この例では、モデルのコンパクトさと予測能力の間の適切な妥協点であることが多いため、 &lt;code&gt;elasticnet&lt;/code&gt; ペナルティを使用します。 &lt;code&gt;l1_ratio&lt;/code&gt; パラメータを（正則化強度 &lt;code&gt;alpha&lt;/code&gt; と組み合わせて）さらに調整して、このトレードオフを制御することもできます。</target>
        </trans-unit>
        <trans-unit id="5f4ca84332e1fc2168e90c43c86e1d784ebd5f8c" translate="yes" xml:space="preserve">
          <source>In this example we see how to robustly fit a linear model to faulty data using the RANSAC algorithm.</source>
          <target state="translated">この例では、RANSACアルゴリズムを使用して、欠陥のあるデータに線形モデルをロバストに適合させる方法を見てみましょう。</target>
        </trans-unit>
        <trans-unit id="8b2f8ba713590c7461bca4df745b9c8578a9ee4a" translate="yes" xml:space="preserve">
          <source>In this example we will illustrate both approaches. We start by defining a few helper functions for loading the data and visualizing results.</source>
          <target state="translated">この例では、両方のアプローチを説明します。まず、データをロードして結果を可視化するためのヘルパー関数をいくつか定義します。</target>
        </trans-unit>
        <trans-unit id="9cb7bd690b6a99c0206d146b05cd9c20c5a47dca" translate="yes" xml:space="preserve">
          <source>In this example we will investigate different imputation techniques:</source>
          <target state="translated">この例では、異なる入力技術を調査します。</target>
        </trans-unit>
        <trans-unit id="38fc37287fc51222e73dd7c83e6c92e563107ff6" translate="yes" xml:space="preserve">
          <source>In this example you might try to:</source>
          <target state="translated">この例では、次のようにしてみてください。</target>
        </trans-unit>
        <trans-unit id="8a61e0fa0737723bbfe9d0174ce3aad285419f4d" translate="yes" xml:space="preserve">
          <source>In this example, &lt;code&gt;X&lt;/code&gt; is &lt;code&gt;float32&lt;/code&gt;, which is cast to &lt;code&gt;float64&lt;/code&gt; by &lt;code&gt;fit_transform(X)&lt;/code&gt;.</source>
          <target state="translated">この例では、 &lt;code&gt;X&lt;/code&gt; は、である &lt;code&gt;float32&lt;/code&gt; にキャストされ、 &lt;code&gt;float64&lt;/code&gt; によって &lt;code&gt;fit_transform(X)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2812da8873763c11175cae962f9ab9000ab381c4" translate="yes" xml:space="preserve">
          <source>In this example, an image with connected circles is generated and spectral clustering is used to separate the circles.</source>
          <target state="translated">この例では、円が連結された画像が生成され、スペクトルクラスタリングが円を分離するために使用されます。</target>
        </trans-unit>
        <trans-unit id="79a59d7ef51f3f34cd5dc94073ebe194acbc66c6" translate="yes" xml:space="preserve">
          <source>In this example, both modeling approaches yield comparable performance metrics. For implementation reasons, the percentage of explained variance \(D^2\) is not available for the product model.</source>
          <target state="translated">この例では、両方のモデリング・アプローチは、同等のパフォーマンス・メトリクスをもたらします。実装上の理由から、説明された分散のパーセンテージは、製品モデルでは利用できません。</target>
        </trans-unit>
        <trans-unit id="69af0b849be70a0524a821dde21a609feb16811a" translate="yes" xml:space="preserve">
          <source>In this example, pixels are represented in a 3D-space and K-means is used to find 64 color clusters. In the image processing literature, the codebook obtained from K-means (the cluster centers) is called the color palette. Using a single byte, up to 256 colors can be addressed, whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.</source>
          <target state="translated">この例では、画素を3次元空間で表現し、K-meansを用いて64個の色クラスタを求める。画像処理の文献では、K-meansから得られるコードブック(クラスタの中心)をカラーパレットと呼んでいます。1バイトを使用して、最大256色をアドレスすることができるのに対し、RGBエンコーディングでは1ピクセルあたり3バイトを必要とする。例えば、GIFファイルフォーマットは、このようなパレットを使用しています。</target>
        </trans-unit>
        <trans-unit id="2f0fb947da0f2bfc5faf32b771a3cb10ff049eda" translate="yes" xml:space="preserve">
          <source>In this example, the numeric data is standard-scaled after mean-imputation, while the categorical data is one-hot encoded after imputing missing values with a new category (&lt;code&gt;'missing'&lt;/code&gt;).</source>
          <target state="translated">この例では、数値データは平均補完後に標準スケーリングされますが、カテゴリデータは欠損値を新しいカテゴリで補完（ &lt;code&gt;'missing'&lt;/code&gt; ）した後にワンホットエンコードされます。</target>
        </trans-unit>
        <trans-unit id="354a556d83cef273107f176ebec9db1b19a5c757" translate="yes" xml:space="preserve">
          <source>In this example, the sinusoid is approximated by a polynomial using different pairs of initial values.</source>
          <target state="translated">この例では、正弦波は、異なる初期値の組を用いて多項式で近似されている。</target>
        </trans-unit>
        <trans-unit id="d88656bc2e040320cf9595554acac12be98f916c" translate="yes" xml:space="preserve">
          <source>In this example, we compare the estimation errors that are made when using various types of location and covariance estimates on contaminated Gaussian distributed data sets:</source>
          <target state="translated">この例では、汚染されたガウス分布データセット上で様々なタイプの位置推定値と共分散推定値を使用した場合に生じる推定誤差を比較する。</target>
        </trans-unit>
        <trans-unit id="26a8e8ae6383655dcfc18bd00f71528218aa360e" translate="yes" xml:space="preserve">
          <source>In this example, we compute the permutation importance on the Wisconsin breast cancer dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; can easily get about 97% accuracy on a test dataset. Because this dataset contains multicollinear features, the permutation importance will show that none of the features are important. One approach to handling multicollinearity is by performing hierarchical clustering on the features&amp;rsquo; Spearman rank-order correlations, picking a threshold, and keeping a single feature from each cluster.</source>
          <target state="translated">この例では、permutation_importanceを使用して、ウィスコンシン州の乳がんデータセットの順列の重要度を計算し&lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;permutation_importance&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; は&lt;/a&gt;簡単にテストデータセットの約97％の精度を得ることができます。このデータセットには多重共線性の特徴が含まれているため、順列の重要性は、どの特徴も重要ではないことを示します。多重共線性を処理するための1つのアプローチは、特徴のスピアマンの順位相関で階層的クラスタリングを実行し、しきい値を選択し、各クラスターから単一の特徴を保持することです。</target>
        </trans-unit>
        <trans-unit id="2b7bcaf87ef3b0730f7083836942b0b038810927" translate="yes" xml:space="preserve">
          <source>In this example, we give an overview of the &lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt;&lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt;&lt;/a&gt;. Two examples illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Boston housing data set.</source>
          <target state="translated">この例では、&lt;a href=&quot;../../modules/generated/sklearn.compose.transformedtargetregressor#sklearn.compose.TransformedTargetRegressor&quot;&gt; &lt;code&gt;sklearn.compose.TransformedTargetRegressor&lt;/code&gt; の&lt;/a&gt;概要を示します。2つの例は、線形回帰モデルを学習する前にターゲットを変換する利点を示しています。最初の例は合成データを使用していますが、2番目の例はボストンの住宅データセットに基づいています。</target>
        </trans-unit>
        <trans-unit id="5f4a1f2d68c8f41cbf437ea7e001b2f1285b3f2f" translate="yes" xml:space="preserve">
          <source>In this example, we illustrate the use case in which different regressors are stacked together and a final linear penalized regressor is used to output the prediction. We compare the performance of each individual regressor with the stacking strategy. Stacking slightly improves the overall performance.</source>
          <target state="translated">この例では、異なるレグレッサーを積み重ねて、最終的な線形ペナルティ付きレグレッサーを使用して予測を出力する場合の使用例を示します。各個別のレグレッサーの性能を、スタッキング・ストラテジーと比較します。スタッキングは、全体的な性能をわずかに向上させる。</target>
        </trans-unit>
        <trans-unit id="fd9410f53a0f1d1aa2f5ff77c7bafaf9751d4c08" translate="yes" xml:space="preserve">
          <source>In this example, we set the value of &lt;code&gt;gamma&lt;/code&gt; manually. To find good values for these parameters, we can use tools such as &lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;grid search&lt;/a&gt; and &lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;cross validation&lt;/a&gt;.</source>
          <target state="translated">この例では、 &lt;code&gt;gamma&lt;/code&gt; の値を手動で設定します。これらのパラメーターの適切な値を見つけるには、&lt;a href=&quot;../../modules/grid_search#grid-search&quot;&gt;グリッド検索&lt;/a&gt;や&lt;a href=&quot;../../modules/cross_validation#cross-validation&quot;&gt;交差検証&lt;/a&gt;などのツールを使用できます。</target>
        </trans-unit>
        <trans-unit id="be5803bd91839824804bc4aadf2784b6ed10723a" translate="yes" xml:space="preserve">
          <source>In this example, we will compare the impurity-based feature importance of &lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;RandomForestClassifier&lt;/code&gt;&lt;/a&gt; with the permutation importance on the titanic dataset using &lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt;&lt;code&gt;permutation_importance&lt;/code&gt;&lt;/a&gt;. We will show that the impurity-based feature importance can inflate the importance of numerical features.</source>
          <target state="translated">この例では、permutation_importanceを使用して、&lt;a href=&quot;../../modules/generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;RandomForestClassifier&lt;/code&gt; の&lt;/a&gt;不純物ベースの特徴の重要度をタイタニックデータセットの順列の重要度と比較し&lt;a href=&quot;../../modules/generated/sklearn.inspection.permutation_importance#sklearn.inspection.permutation_importance&quot;&gt; &lt;code&gt;permutation_importance&lt;/code&gt; &lt;/a&gt;。不純物ベースの特徴の重要性が数値的特徴の重要性を膨らませることができることを示します。</target>
        </trans-unit>
        <trans-unit id="f66533d22104292e30bad75824b906ee4fc1acd9" translate="yes" xml:space="preserve">
          <source>In this example, we will construct display objects, &lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt;&lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay&quot;&gt;&lt;code&gt;RocCurveDisplay&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;../../modules/generated/sklearn.metrics.precisionrecalldisplay#sklearn.metrics.PrecisionRecallDisplay&quot;&gt;&lt;code&gt;PrecisionRecallDisplay&lt;/code&gt;&lt;/a&gt; directly from their respective metrics. This is an alternative to using their corresponding plot functions when a model&amp;rsquo;s predictions are already computed or expensive to compute. Note that this is advanced usage, and in general we recommend using their respective plot functions.</source>
          <target state="translated">この例では、表示オブジェクト、&lt;a href=&quot;../../modules/generated/sklearn.metrics.confusionmatrixdisplay#sklearn.metrics.ConfusionMatrixDisplay&quot;&gt; &lt;code&gt;ConfusionMatrixDisplay&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;../../modules/generated/sklearn.metrics.roccurvedisplay#sklearn.metrics.RocCurveDisplay&quot;&gt; &lt;code&gt;RocCurveDisplay&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;../../modules/generated/sklearn.metrics.precisionrecalldisplay#sklearn.metrics.PrecisionRecallDisplay&quot;&gt; &lt;code&gt;PrecisionRecallDisplay&lt;/code&gt; &lt;/a&gt;をそれぞれのメトリックから直接作成します。これは、モデルの予測がすでに計算されているか、計算に費用がかかる場合に、対応するプロット関数を使用する代わりの方法です。これは高度な使用法であり、一般に、それぞれのプロット関数を使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="9e0782ea6d7859077c07d60aaa0a30b1c4373f50" translate="yes" xml:space="preserve">
          <source>In this plot you can see the training scores and validation scores of an SVM for different values of the kernel parameter gamma. For very low values of gamma, you can see that both the training score and the validation score are low. This is called underfitting. Medium values of gamma will result in high values for both scores, i.e. the classifier is performing fairly well. If gamma is too high, the classifier will overfit, which means that the training score is good but the validation score is poor.</source>
          <target state="translated">このプロットでは、カーネルパラメータγの値を変えた場合のSVMの学習スコアと検証スコアを見ることができます。ガンマの値が非常に低い場合、学習スコアと検証スコアの両方が低いことがわかります。これはアンダーフィッティングと呼ばれます。ガンマ値が中程度の場合、両方のスコアが高い値になります。ガンマ値が高すぎると、分類器はオーバーフィットしてしまい、つまり、学習スコアは良いが検証スコアは悪いということになります。</target>
        </trans-unit>
        <trans-unit id="2c39a03080473177a8509645110953edafebbd76" translate="yes" xml:space="preserve">
          <source>In this scheme, features and samples are defined as follows:</source>
          <target state="translated">この方式では、特徴量とサンプルは以下のように定義される。</target>
        </trans-unit>
        <trans-unit id="5941fbb58c226f551ff80660bcd51a84bcc2bae1" translate="yes" xml:space="preserve">
          <source>In this section we will see how to:</source>
          <target state="translated">このセクションでは、その方法を見ていきます。</target>
        </trans-unit>
        <trans-unit id="6ce5845b6414a0cfccffc603f3efdd4b47c7ce4b" translate="yes" xml:space="preserve">
          <source>In this section, we introduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; vocabulary that we use throughout scikit-learn and give a simple learning example.</source>
          <target state="translated">このセクションでは、scikit-learn全体で使用する&lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;機械学習の&lt;/a&gt;語彙を紹介し、簡単な学習の例を示します。</target>
        </trans-unit>
        <trans-unit id="e7b54ae8e73f20fa370a273bbb52814367b82582" translate="yes" xml:space="preserve">
          <source>In this snippet we make use of a &lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt;&lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt;&lt;/a&gt; coupled with &lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt;&lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt;&lt;/a&gt; to evaluate feature importances and select the most relevant features. Then, a &lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt;&lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt;&lt;/a&gt; is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the &lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt;&lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt;&lt;/a&gt; examples for more details.</source>
          <target state="translated">このスニペットでは、&lt;a href=&quot;generated/sklearn.svm.linearsvc#sklearn.svm.LinearSVC&quot;&gt; &lt;code&gt;sklearn.svm.LinearSVC&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/sklearn.feature_selection.selectfrommodel#sklearn.feature_selection.SelectFromModel&quot;&gt; &lt;code&gt;sklearn.feature_selection.SelectFromModel&lt;/code&gt; &lt;/a&gt;を組み合わせて使用して、機能の重要度を評価し、最も関連性の高い機能を選択します。次に、&lt;a href=&quot;generated/sklearn.ensemble.randomforestclassifier#sklearn.ensemble.RandomForestClassifier&quot;&gt; &lt;code&gt;sklearn.ensemble.RandomForestClassifier&lt;/code&gt; &lt;/a&gt;が変換された出力でトレーニングされます。つまり、関連する機能のみを使用します。他の特徴選択方法や、もちろん特徴の重要性を評価する方法を提供する分類子を使用して、同様の操作を実行できます。詳細については、&lt;a href=&quot;generated/sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline&quot;&gt; &lt;code&gt;sklearn.pipeline.Pipeline&lt;/code&gt; の&lt;/a&gt;例を参照してください。</target>
        </trans-unit>
        <trans-unit id="87aee0924ee2a28e2d573efd8e050c2a5c1632a3" translate="yes" xml:space="preserve">
          <source>In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple &lt;code&gt;continuous latent variable&lt;/code&gt; model for \(X\) is</source>
          <target state="translated">教師なし学習では、データセット\（X = \ {x_1、x_2、\ dots、x_n \} \）しかありません。このデータセットはどのように数学的に記述できますか？\（X \）の非常に単純な &lt;code&gt;continuous latent variable&lt;/code&gt; モデルは次のとおりです。</target>
        </trans-unit>
        <trans-unit id="a1efe7e891f38316d324e0fe7b8b483308bcbebf" translate="yes" xml:space="preserve">
          <source>Includes values in confusion matrix.</source>
          <target state="translated">混乱マトリックスの値を含む。</target>
        </trans-unit>
        <trans-unit id="c89a6ca6f29b888687c7afd577a282b5b95a2be5" translate="yes" xml:space="preserve">
          <source>Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as &lt;em&gt;data leakage&lt;/em&gt;), for example in the case of scalers or imputing missing values.</source>
          <target state="translated">テストデータの統計情報をプリプロセッサに組み込むと、たとえばスケーラーや欠損値を補完する場合などに、交差検証スコアが信頼できなくなります（&lt;em&gt;データ漏洩と&lt;/em&gt;呼ばれ&lt;em&gt;ます&lt;/em&gt;）。</target>
        </trans-unit>
        <trans-unit id="4c33f1e1286c254eaae3fbe03197d5578f08f56a" translate="yes" xml:space="preserve">
          <source>Increasing &lt;code&gt;max_depth&lt;/code&gt; for AdaBoost lowers the standard deviation of the scores (but the average score does not improve).</source>
          <target state="translated">AdaBoostの &lt;code&gt;max_depth&lt;/code&gt; を増やすと、スコアの標準偏差が下がります（ただし、平均スコアは向上しません）。</target>
        </trans-unit>
        <trans-unit id="e79b1358981354168a853701629e2643ba45bf93" translate="yes" xml:space="preserve">
          <source>Increasing false positive rates such that element i is the false positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">要素iがスコア&amp;gt; = thresholds [i]の予測の偽陽性率になるように、偽陽性率を増やします。</target>
        </trans-unit>
        <trans-unit id="3ca08d3a2216068596512fa76cc1f85e2464a3a8" translate="yes" xml:space="preserve">
          <source>Increasing thresholds on the decision function used to compute precision and recall.</source>
          <target state="translated">精度とリコールの計算に使用される決定関数のしきい値を増加させます。</target>
        </trans-unit>
        <trans-unit id="7ae5f53b337e575381bac1d47d2d4a4d2e4839b6" translate="yes" xml:space="preserve">
          <source>Increasing true positive rates such that element i is the true positive rate of predictions with score &amp;gt;= thresholds[i].</source>
          <target state="translated">要素iがスコア&amp;gt; = thresholds [i]の予測の真陽性率になるように真陽性率を増加させます。</target>
        </trans-unit>
        <trans-unit id="54206634ab03f8962d59d7c24e12c85ebd45b5e1" translate="yes" xml:space="preserve">
          <source>Incremental PCA</source>
          <target state="translated">インクリメンタルPCA</target>
        </trans-unit>
        <trans-unit id="0254682de6b7d13bd44669747bb093c1dca18b21" translate="yes" xml:space="preserve">
          <source>Incremental Principal Component Analysis.</source>
          <target state="translated">インクリメンタル主成分分析。</target>
        </trans-unit>
        <trans-unit id="acaf3165fc4e0ddec759b9648ee12eed48089691" translate="yes" xml:space="preserve">
          <source>Incremental fit on a batch of samples.</source>
          <target state="translated">サンプルのバッチにインクリメンタルフィット。</target>
        </trans-unit>
        <trans-unit id="a79a34aec33f8c8b084e4316cf8e243a4d6601e6" translate="yes" xml:space="preserve">
          <source>Incremental fit with X.</source>
          <target state="translated">Xとのインクリメンタルフィット。</target>
        </trans-unit>
        <trans-unit id="87210470540ea5af2ee40f330fdeea4017f1c0aa" translate="yes" xml:space="preserve">
          <source>Incremental fit with X. All of X is processed as a single batch.</source>
          <target state="translated">Xとのインクリメンタルフィット。</target>
        </trans-unit>
        <trans-unit id="5b9d567927b0a80924b0a28fdea6cf19b23d2e57" translate="yes" xml:space="preserve">
          <source>Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.</source>
          <target state="translated">インクリメンタル主成分分析(IPCA)は、分解するデータセットが大きすぎてメモリに収まりきらない場合に、主成分分析(PCA)の代替として一般的に使用されます。IPCAは、入力データのサンプル数に依存しないメモリ量を使用して、入力データの低ランク近似を構築します。これは入力データの特徴に依存しますが、バッチサイズを変更することでメモリ使用量を制御することができます。</target>
        </trans-unit>
        <trans-unit id="66088e706ece2d903ed2071fa2d42be9315774b6" translate="yes" xml:space="preserve">
          <source>Incremental principal components analysis (IPCA).</source>
          <target state="translated">インクリメンタル主成分分析(IPCA)。</target>
        </trans-unit>
        <trans-unit id="ef7722207a6c2343d08e45f401cd00ccd19381c7" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data.</source>
          <target state="translated">モデルをデータに漸増的に適合させます。</target>
        </trans-unit>
        <trans-unit id="505bf67b8aa7cec37d64a9ce9b03d73f70b38b8b" translate="yes" xml:space="preserve">
          <source>Incrementally fit the model to data. Fit a separate model for each output variable.</source>
          <target state="translated">モデルをデータに段階的に適合させる.各出力変数に個別のモデルを適合させる.</target>
        </trans-unit>
        <trans-unit id="e7353e5363cf13ee1c3efdc144e75ff650f6c2d1" translate="yes" xml:space="preserve">
          <source>Incrementally trained logistic regression (when given the parameter &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt;).</source>
          <target state="translated">増分的にトレーニングされたロジスティック回帰（パラメーター &lt;code&gt;loss=&quot;log&quot;&lt;/code&gt; が指定されている場合）。</target>
        </trans-unit>
        <trans-unit id="9e12e704fa3eb16be83d58c2167c9c4f83379a1d" translate="yes" xml:space="preserve">
          <source>Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data.</source>
          <target state="translated">実際、多くの推定量は、各特徴がゼロに近い値を取ること、あるいはより重要なことに、すべての特徴が同等の尺度で変化することを前提に設計されている。特に、メトリックベースおよび勾配ベースの推定量は、多くの場合、ほぼ標準化されたデータ(単位分散を持つ中心の特徴量)を想定している。特筆すべき例外は、データの任意のスケーリングにロバストな決定木ベースの推定量である。</target>
        </trans-unit>
        <trans-unit id="9cde6c3dae7189a85444fb86f682cb4ecd226cef" translate="yes" xml:space="preserve">
          <source>Indeed, from the plot above the most important factor in determining WAGE appears to be the variable UNION, even if our intuition might tell us that variables like EXPERIENCE should have more impact.</source>
          <target state="translated">実際、上のプロットから、WAGEを決定する上で最も重要な要因はUNIONという変数であるように見えますが、たとえ私たちの直感が、EXPERIENCEのような変数の方がインパクトがあるはずだと教えてくれるかもしれません。</target>
        </trans-unit>
        <trans-unit id="7933c6d72de999f40e22d3286d9c782fd636305b" translate="yes" xml:space="preserve">
          <source>Independent Component Analysis: ICA</source>
          <target state="translated">独立成分分析。ICA</target>
        </trans-unit>
        <trans-unit id="d170598045cdc9e2df037718a96d1706ed03e640" translate="yes" xml:space="preserve">
          <source>Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the &lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt;&lt;code&gt;Fast ICA&lt;/code&gt;&lt;/a&gt; algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.</source>
          <target state="translated">独立成分分析は、多変量信号を最大限に独立した付加的な副成分に分離します。&lt;a href=&quot;generated/sklearn.decomposition.fastica#sklearn.decomposition.FastICA&quot;&gt; &lt;code&gt;Fast ICA&lt;/code&gt; &lt;/a&gt;アルゴリズムを使用してscikit-learnに実装されています。通常、ICAは次元を減らすためではなく、重ね合わせた信号を分離するために使用されます。ICAモデルにはノイズ項が含まれていないため、モデルを正しくするには、ホワイトニングを適用する必要があります。これは、whiten引数を使用して内部で行うことも、PCAバリアントの1つを使用して手動で行うこともできます。</target>
        </trans-unit>
        <trans-unit id="420bdf88d0c37e0c49c684e7be83be0c3065749b" translate="yes" xml:space="preserve">
          <source>Independent component analysis, a latent variable model with non-Gaussian latent variables.</source>
          <target state="translated">独立成分分析、非ガウス潜在変数を持つ潜在変数モデル。</target>
        </trans-unit>
        <trans-unit id="e81fd2ba1ed4351b51becec6b3e044be03272d29" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel.</source>
          <target state="translated">ポリ/シグモイドカーネルの独立したパラメータ。</target>
        </trans-unit>
        <trans-unit id="75b2e172573134b992419919380eaa4d379125c8" translate="yes" xml:space="preserve">
          <source>Independent parameter in poly/sigmoid kernel. 0 by default.</source>
          <target state="translated">poly/sigmoidカーネルの独立したパラメータ。デフォルトでは0。</target>
        </trans-unit>
        <trans-unit id="93ccb8f475af3ead0828a4d704d80fd7c1bcca2a" translate="yes" xml:space="preserve">
          <source>Independent term in decision function.</source>
          <target state="translated">意思決定関数の独立項。</target>
        </trans-unit>
        <trans-unit id="d60b4ce63cb13d9b546e71bb468305b122e1ff12" translate="yes" xml:space="preserve">
          <source>Independent term in decision function. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">決定関数の独立した用語。 &lt;code&gt;fit_intercept = False&lt;/code&gt; 場合は0.0に設定します。</target>
        </trans-unit>
        <trans-unit id="62ca36e367478a373b265bf6692ac1dd0b87c736" translate="yes" xml:space="preserve">
          <source>Independent term in kernel function. It is only significant in &amp;lsquo;poly&amp;rsquo; and &amp;lsquo;sigmoid&amp;rsquo;.</source>
          <target state="translated">カーネル関数の独立した用語。これは「ポリ」と「シグモイド」でのみ意味があります。</target>
        </trans-unit>
        <trans-unit id="498514c5789196d4e7f38be6d2ccefad9084f660" translate="yes" xml:space="preserve">
          <source>Independent term in poly and sigmoid kernels. Ignored by other kernels.</source>
          <target state="translated">ポリおよびシグモイドカーネルの独立項。他のカーネルでは無視される。</target>
        </trans-unit>
        <trans-unit id="c818388cffefe0c1449b9099e6b8c434f2466b05" translate="yes" xml:space="preserve">
          <source>Independent term in the decision function.</source>
          <target state="translated">意思決定関数の独立項。</target>
        </trans-unit>
        <trans-unit id="b8069da00c91cf6e966b739b57f9cbe347e859d2" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model.</source>
          <target state="translated">線形モデルの独立項。</target>
        </trans-unit>
        <trans-unit id="191e8d234bde29edd43499e6f75fe115a0a775a9" translate="yes" xml:space="preserve">
          <source>Independent term in the linear model. Set to 0.0 if &lt;code&gt;fit_intercept = False&lt;/code&gt;.</source>
          <target state="translated">線形モデルの独立項。 &lt;code&gt;fit_intercept = False&lt;/code&gt; 場合、0.0に設定します。</target>
        </trans-unit>
        <trans-unit id="5c78017fad7dc4be13e21b61b07a09cb5931df33" translate="yes" xml:space="preserve">
          <source>Index of the cluster each sample belongs to.</source>
          <target state="translated">各サンプルが属するクラスタのインデックス。</target>
        </trans-unit>
        <trans-unit id="79bbc01c7afbd569e88078c06011f6a142dc18ba" translate="yes" xml:space="preserve">
          <source>Index of the column of X to be swapped.</source>
          <target state="translated">入れ替えられるXの列のインデックス。</target>
        </trans-unit>
        <trans-unit id="ed1d58c02de7a13d74564b832a9effc7dd7512f7" translate="yes" xml:space="preserve">
          <source>Index of the row of X to be swapped.</source>
          <target state="translated">スワップされるXの行のインデックス。</target>
        </trans-unit>
        <trans-unit id="ec76f2d92b2be403363a104dc4a87849c9c331a9" translate="yes" xml:space="preserve">
          <source>Indexable data-structures can be arrays, lists, dataframes or scipy sparse matrices with consistent first dimension.</source>
          <target state="translated">インデックス可能なデータ構造体には、配列、リスト、データフレーム、または一貫した1次元の疎な行列があります。</target>
        </trans-unit>
        <trans-unit id="436737ead6b730ec05aa4979d3ab186eb46b0b4a" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above.</source>
          <target state="translated">2番目の軸でデータにインデックスを付けます。整数は定位置列として解釈されますが、文字列は名前でDataFrame列を参照できます。Xが1次元配列のような（ベクトル）であると &lt;code&gt;transformer&lt;/code&gt; 期待する場合は、スカラー文字列または整数を使用する必要があります。そうでない場合は、2次元配列がトランスフォーマーに渡されます。呼び出し可能オブジェクトには入力データ &lt;code&gt;X&lt;/code&gt; が渡され、上記のいずれかを返すことができます。</target>
        </trans-unit>
        <trans-unit id="14c06502f716a74d640158c7430747c2d65e82bc" translate="yes" xml:space="preserve">
          <source>Indexes the data on its second axis. Integers are interpreted as positional columns, while strings can reference DataFrame columns by name. A scalar string or int should be used where &lt;code&gt;transformer&lt;/code&gt; expects X to be a 1d array-like (vector), otherwise a 2d array will be passed to the transformer. A callable is passed the input data &lt;code&gt;X&lt;/code&gt; and can return any of the above. To select multiple columns by name or dtype, you can use &lt;a href=&quot;sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt;&lt;code&gt;make_column_selector&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">2番目の軸でデータにインデックスを付けます。整数は定位置列として解釈されますが、文字列は名前でDataFrame列を参照できます。スカラー文字列またはintは、 &lt;code&gt;transformer&lt;/code&gt; Xが1d配列のような（ベクトル）であると期待する場合に使用する必要があります。そうでない場合、2d配列がトランスフォーマーに渡されます。呼び出し可能オブジェクトには入力データ &lt;code&gt;X&lt;/code&gt; が渡され、上記のいずれかを返すことができます。名前またはdtypeで複数の列を選択するには、&lt;a href=&quot;sklearn.compose.make_column_selector#sklearn.compose.make_column_selector&quot;&gt; &lt;code&gt;make_column_selector&lt;/code&gt; &lt;/a&gt;を使用できます。</target>
        </trans-unit>
        <trans-unit id="33324894ea0a98c1ef1f880dc97967e00c913318" translate="yes" xml:space="preserve">
          <source>Indicate that func accepts a sparse matrix as input. If validate is False, this has no effect. Otherwise, if accept_sparse is false, sparse matrix inputs will cause an exception to be raised.</source>
          <target state="translated">funcが入力として疎な行列を受け入れることを示します。validate が False の場合、これは何の効果もありません。そうでなければ、 accept_sparse が false の場合、疎な行列を入力すると例外が発生します。</target>
        </trans-unit>
        <trans-unit id="eb7cd0d8cb7fae1e80a3e28d3771772ae8884b48" translate="yes" xml:space="preserve">
          <source>Indicate that the input X array should be checked before calling &lt;code&gt;func&lt;/code&gt;. The possibilities are:</source>
          <target state="translated">&lt;code&gt;func&lt;/code&gt; を呼び出す前に入力X配列をチェックする必要があることを示します。可能性は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="ae286e88bfa268243cfd38132ccb40e58428bfed" translate="yes" xml:space="preserve">
          <source>Indicate that transform should forward the y argument to the inner callable.</source>
          <target state="translated">transform が y 引数を内側の callable に転送することを示します。</target>
        </trans-unit>
        <trans-unit id="9d241566a403a6506d3449cf17d407da2b6e2613" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels</source>
          <target state="translated">クラスラベルの順序を示す</target>
        </trans-unit>
        <trans-unit id="5daac4dde04b0b12288306e9a52dc06ec04c0c8f" translate="yes" xml:space="preserve">
          <source>Indicates an ordering for the class labels. All entries should be unique (cannot contain duplicate classes).</source>
          <target state="translated">クラス・ラベルの順序を示します。すべてのエントリは一意でなければなりません(重複したクラスを含むことはできません)。</target>
        </trans-unit>
        <trans-unit id="1159dbae1b402de01888d0798e1ed328834a2b28" translate="yes" xml:space="preserve">
          <source>Indicates the monotonic constraint to enforce on each feature. -1, 1 and 0 respectively correspond to a positive constraint, negative constraint and no constraint. Read more in the &lt;a href=&quot;../ensemble#monotonic-cst-gbdt&quot;&gt;User Guide&lt;/a&gt;.</source>
          <target state="translated">各機能に適用する単調な制約を示します。-1、1、および0は、それぞれ正の制約、負の制約、および制約なしに対応します。詳細については、&lt;a href=&quot;../ensemble#monotonic-cst-gbdt&quot;&gt;ユーザーガイド&lt;/a&gt;をご覧ください。</target>
        </trans-unit>
        <trans-unit id="61bd4246c5310fe8fe14b7816d8991bfb310307e" translate="yes" xml:space="preserve">
          <source>Indicator used to add binary indicators for missing values. &lt;code&gt;None&lt;/code&gt; if add_indicator is False.</source>
          <target state="translated">欠落値のバイナリインジケーターを追加するために使用されるインジケーター。add_indicatorがFalseの場合は &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="9f992c130abda366b807271662ae2ae17c7305e7" translate="yes" xml:space="preserve">
          <source>Indices according to which X will be subsampled.</source>
          <target state="translated">Xがサブサンプル化される指標。</target>
        </trans-unit>
        <trans-unit id="13d9e5d82e7cab8325fb7843fa12831d259a69f1" translate="yes" xml:space="preserve">
          <source>Indices of &lt;code&gt;components_&lt;/code&gt; in the training set.</source>
          <target state="translated">トレーニングセット内の &lt;code&gt;components_&lt;/code&gt; のインデックス。</target>
        </trans-unit>
        <trans-unit id="eeb5984b85169d88759ac10f7fe9d10f5246bc74" translate="yes" xml:space="preserve">
          <source>Indices of active variables at the end of the path.</source>
          <target state="translated">パスの最後にあるアクティブな変数のインデックス。</target>
        </trans-unit>
        <trans-unit id="fff8cc57ffbca371ebcb1bd938597e8d339ff509" translate="yes" xml:space="preserve">
          <source>Indices of cluster centers</source>
          <target state="translated">クラスターセンターの指標</target>
        </trans-unit>
        <trans-unit id="2c68ceeb78b6311d290c266259420efe85138435" translate="yes" xml:space="preserve">
          <source>Indices of columns in the dataset that belong to the bicluster.</source>
          <target state="translated">データセットの中で、二重クラスタに属する列のインデックス。</target>
        </trans-unit>
        <trans-unit id="d4d2ad6637f8190da67b396b7e452baac4f7558f" translate="yes" xml:space="preserve">
          <source>Indices of core samples.</source>
          <target state="translated">コアサンプルの指標。</target>
        </trans-unit>
        <trans-unit id="82cd4a5510ba380bec1e554cdeb5d721222207d6" translate="yes" xml:space="preserve">
          <source>Indices of features for a given plot. A tuple of one integer will plot a partial dependence curve of one feature. A tuple of two integers will plot a two-way partial dependence curve as a contour plot.</source>
          <target state="translated">与えられたプロットの特徴のインデックス。1つの整数のタプルは、1つの特徴の部分依存曲線をプロットします。2つの整数のタプルは、2方向の部分依存曲線を等高線グラフとしてプロットします。</target>
        </trans-unit>
        <trans-unit id="c71c298055da26ecac09942b9115f5fc73f7640d" translate="yes" xml:space="preserve">
          <source>Indices of rows in the dataset that belong to the bicluster.</source>
          <target state="translated">データセットの中で、二重クラスタに属する行のインデックス。</target>
        </trans-unit>
        <trans-unit id="d9c7ee7b4f1a89fde0903f47c0111e0985a4d274" translate="yes" xml:space="preserve">
          <source>Indices of samples used when training the estimators. &lt;code&gt;None&lt;/code&gt; when &lt;code&gt;estimator&lt;/code&gt; does not have &lt;code&gt;_pairwise&lt;/code&gt; attribute.</source>
          <target state="translated">推定量をトレーニングするときに使用されるサンプルのインデックス。 &lt;code&gt;estimator&lt;/code&gt; に &lt;code&gt;_pairwise&lt;/code&gt; 属性がない場合は &lt;code&gt;None&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="a5ecd973c55633f90c97a971f74a80fe11af3310" translate="yes" xml:space="preserve">
          <source>Indices of support vectors.</source>
          <target state="translated">サポートベクトルのインデックス.</target>
        </trans-unit>
        <trans-unit id="9ccd80ce2c5e0529264583d000f7c9651892271d" translate="yes" xml:space="preserve">
          <source>Indices of the approximate nearest points in the population matrix.</source>
          <target state="translated">母集団行列の近似最近接点のインデックス.</target>
        </trans-unit>
        <trans-unit id="94147abfa5127a12fe3c3b0c7153a32b171d401a" translate="yes" xml:space="preserve">
          <source>Indices of the nearest points in the population matrix.</source>
          <target state="translated">母集団行列の中で最も近い点のインデックス.</target>
        </trans-unit>
        <trans-unit id="3db97f5586a1b88a52d6998bdcb68ce6424bd44e" translate="yes" xml:space="preserve">
          <source>Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.</source>
          <target state="translated">個々の決定木は、木の構造を視覚化するだけで簡単に解釈できます。しかし、勾配ブーストモデルは数百本の回帰木で構成されているため、個々の木を目視しただけでは容易に解釈できません。幸いなことに、勾配ブーストモデルを要約して解釈するための手法がいくつか提案されています。</target>
        </trans-unit>
        <trans-unit id="dda28c621b6ebb6a75808a25ba823af15c148423" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">個々の決定木は、適切な分割ポイントを選択することにより、本質的に特徴選択を実行します。この情報は、各機能の重要性を測定するために使用できます。基本的な考え方は、ツリーの分割ポイントで使用される機能が多いほど、その機能が重要になるということです。この重要性の概念は、各ツリーの機能の重要性を単純に平均化することで、決定木の集団に拡張できます（詳細については、&lt;a href=&quot;#random-forest-feature-importance&quot;&gt;機能の重要性の評価&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="a4ca1ad4d7f055ed4989788bfa5efeb8e8f28cc3" translate="yes" xml:space="preserve">
          <source>Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the impurity-based feature importance of each tree (see &lt;a href=&quot;#random-forest-feature-importance&quot;&gt;Feature importance evaluation&lt;/a&gt; for more details).</source>
          <target state="translated">個々の決定木は、適切な分割点を選択することにより、本質的に特徴選択を実行します。この情報は、各機能の重要性を測定するために使用できます。基本的な考え方は、ツリーの分割点で機能が使用される頻度が高いほど、その機能の重要性が高くなるということです。この重要性の概念は、各ツリーの不純物ベースの特徴重要度を単純に平均化することで、決定木アンサンブルに拡張できます（詳細については、&lt;a href=&quot;#random-forest-feature-importance&quot;&gt;特徴重要度の評価&lt;/a&gt;を参照してください）。</target>
        </trans-unit>
        <trans-unit id="e3bee3019e098ad6b65e2ff793a0e712b529b8f1" translate="yes" xml:space="preserve">
          <source>Individual samples are assumed to be files stored a two levels folder structure such as the following:</source>
          <target state="translated">個々のサンプルは、以下のような2階層のフォルダ構造で保存されたファイルを想定しています。</target>
        </trans-unit>
        <trans-unit id="675958cddf4afedd9b3304a64c0ebf41aefd317c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;'passthrough'&lt;/code&gt;:</source>
          <target state="translated">個々のステップをパラメーターとして置き換えることもできます。非最終ステップは、 &lt;code&gt;'passthrough'&lt;/code&gt; 設定することで無視できます。</target>
        </trans-unit>
        <trans-unit id="c0fc01010c6e24d626cecdd62fd33ec75c0c929c" translate="yes" xml:space="preserve">
          <source>Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">個々のステップはパラメータとして置き換えることもでき、非最終ステップは &lt;code&gt;None&lt;/code&gt; に設定することで無視できます。</target>
        </trans-unit>
        <trans-unit id="1005c12f11beba0f3b6f9dd6a7112c31b922588d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample</source>
          <target state="translated">各サンプルの個別の重み</target>
        </trans-unit>
        <trans-unit id="1fda26bba39629c5adc019bfeebf23b6ea1cae92" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample raises error if sample_weight is passed and base_estimator fit method does not support it.</source>
          <target state="translated">各サンプルの個別の重みは、sample_weight が渡され、base_estimator のフィットメソッドがそれをサポートしていない場合にエラーを発生させます。</target>
        </trans-unit>
        <trans-unit id="fa75f1e4d13933a19ded3aa860129fc7cab3ed7d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample, ignored if None is passed.</source>
          <target state="translated">各サンプルの個別の重み,None が渡された場合は無視されます.</target>
        </trans-unit>
        <trans-unit id="00c4a167764cbf2ab25348f070ffdca6c4a1b160" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight.</source>
          <target state="translated">各サンプルの個別の重み。浮動小数点数を与えた場合、すべてのサンプルは同じ重みを持ちます。</target>
        </trans-unit>
        <trans-unit id="f445327eb6fc51f2a25624b484ae69f8950143fb" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If given a float, every sample will have the same weight. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">各サンプルの個々の重み。フロートが与えられた場合、すべてのサンプルの重量は同じになります。sample_weightがNoneでなく、solver = 'auto'の場合、ソルバーは 'cholesky'に設定されます。</target>
        </trans-unit>
        <trans-unit id="718e842694bb04faf5cc021c83e29c576f98c12d" translate="yes" xml:space="preserve">
          <source>Individual weights for each sample. If sample_weight is not None and solver=&amp;rsquo;auto&amp;rsquo;, the solver will be set to &amp;lsquo;cholesky&amp;rsquo;.</source>
          <target state="translated">各サンプルの個別の重量。sample_weightがNoneでなく、solver = 'auto'の場合、ソルバーは「cholesky」に設定されます。</target>
        </trans-unit>
        <trans-unit id="080f186426dd365e06ebdb64bb4da000ce313de8" translate="yes" xml:space="preserve">
          <source>Inductive Clustering</source>
          <target state="translated">帰納的クラスタリング</target>
        </trans-unit>
        <trans-unit id="390c151b41ae038aa81f8d4fccaa7e2c366dd521" translate="yes" xml:space="preserve">
          <source>Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">慣性は、内部的にコヒーレントなクラスタがどれだけあるかの指標として認識することができます。これには様々な欠点があります。</target>
        </trans-unit>
        <trans-unit id="c4facccaf3ac8930794a0b5d15e4cd633a166965" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;decomposition#pca&quot;&gt;Principal component analysis (PCA)&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">慣性は正規化されたメトリックではありません。値が小さいほど優れており、ゼロが最適であることがわかっています。しかし、非常に高次元の空間では、ユークリッド距離が膨らむ傾向があります（これはいわゆる「次元の呪い」の例です）。k-meansクラスタリングの前に&lt;a href=&quot;decomposition#pca&quot;&gt;主成分分析（PCA）&lt;/a&gt;などの次元削減アルゴリズムを実行すると、この問題を軽減し、計算を高速化できます。</target>
        </trans-unit>
        <trans-unit id="f221e5d04a99f60098722e2605a369c8541e6c9c" translate="yes" xml:space="preserve">
          <source>Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called &amp;ldquo;curse of dimensionality&amp;rdquo;). Running a dimensionality reduction algorithm such as &lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt; prior to k-means clustering can alleviate this problem and speed up the computations.</source>
          <target state="translated">慣性は正規化されたメトリックではありません。値が小さいほど優れ、ゼロが最適であることを知っています。しかし、非常に高次元の空間では、ユークリッド距離は膨張する傾向があります（これはいわゆる「次元の呪い」の例です）。k平均クラスタリングの前に&lt;a href=&quot;pca&quot;&gt;PCA&lt;/a&gt;などの次元削減アルゴリズムを実行すると、この問題を緩和し、計算を高速化できます。</target>
        </trans-unit>
        <trans-unit id="e010b0c9058bbaf9975d3f14818f3861029f83a1" translate="yes" xml:space="preserve">
          <source>Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.</source>
          <target state="translated">慣性はクラスターが凸で等方的であることを前提としていますが、必ずしもそうとは限りません。細長いクラスターや不規則な形状の多様体にはあまり反応しません。</target>
        </trans-unit>
        <trans-unit id="2d57b1c4d1f958efe3710f23677dd552a8a1384c" translate="yes" xml:space="preserve">
          <source>Inertia, or the within-cluster sum of squares criterion, can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:</source>
          <target state="translated">慣性(クラスタ内二乗和基準)は、クラスタがどれだけ内部的に凝集しているかの指標として認識されます。これには様々な欠点があります。</target>
        </trans-unit>
        <trans-unit id="1b9b7d4cd56309d7954eee8c5d88a8d58559a22d" translate="yes" xml:space="preserve">
          <source>Inference of the model can be time consuming.</source>
          <target state="translated">モデルの推論には時間がかかります。</target>
        </trans-unit>
        <trans-unit id="52570031388abf13077117eb25231bb2412ec6ba" translate="yes" xml:space="preserve">
          <source>Inferred batch size from &lt;code&gt;batch_size&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;batch_size&lt;/code&gt; から推測されるバッチサイズ。</target>
        </trans-unit>
        <trans-unit id="f3406f3eade82db35711ae0ecbcd4dea59f7e1be" translate="yes" xml:space="preserve">
          <source>Inferred value for &lt;code&gt;increasing&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;increasing&lt;/code&gt; ための推定値。</target>
        </trans-unit>
        <trans-unit id="8f5d2c4b74b9f6de8f1a369f5793fd5ad3db1bd0" translate="yes" xml:space="preserve">
          <source>Influence of outliers on location and covariance estimates</source>
          <target state="translated">位置および共分散推定値に対する外れ値の影響</target>
        </trans-unit>
        <trans-unit id="b8c700f6663aab653644d35fb6aa9a0e53919c01" translate="yes" xml:space="preserve">
          <source>Information on how to contribute. This also contains useful information for advanced users, for example how to build their own estimators.</source>
          <target state="translated">貢献する方法についての情報。また、独自の推定器を構築する方法など、上級者向けの有用な情報も含まれています。</target>
        </trans-unit>
        <trans-unit id="c4fbdb7aab44015fbed39936864f9255a99074c1" translate="yes" xml:space="preserve">
          <source>Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples).</source>
          <target state="translated">情報基準に基づくモデル選択は非常に高速ですが、自由度の適切な推定に依存しており、大きなサンプルに対して導出され(漸近的な結果)、モデルが正しいこと、すなわち、データが実際にこのモデルによって生成されることを前提としています。また、問題の条件が悪い(標本よりも多くの特徴量がある)場合に壊れやすい傾向があります。</target>
        </trans-unit>
        <trans-unit id="132062fafb54cb7d1e8b42d922906ff561bc3d9c" translate="yes" xml:space="preserve">
          <source>Inherits from SGDClassifier. &lt;code&gt;Perceptron()&lt;/code&gt; is equivalent to &lt;code&gt;SGDClassifier(loss=&quot;perceptron&quot;, eta0=1, learning_rate=&quot;constant&quot;, penalty=None)&lt;/code&gt;.</source>
          <target state="translated">SGDClassifierから継承します。 &lt;code&gt;SGDClassifier(loss=&quot;perceptron&quot;, eta0=1, learning_rate=&quot;constant&quot;, penalty=None)&lt;/code&gt; &lt;code&gt;Perceptron()&lt;/code&gt; は、SGDClassifier（loss = &quot;perceptron&quot;、eta0 = 1、learning_rate = &quot;constant&quot;、penalty = None）と同等です。</target>
        </trans-unit>
        <trans-unit id="897de0e7da29095e5d730f2c7102743d023bc056" translate="yes" xml:space="preserve">
          <source>Initial value for alpha (precision of the noise). If not set, alpha_init is 1/Var(y).</source>
          <target state="translated">アルファ(ノイズの精度)の初期値。設定されていない場合、alpha_initは1/Var(y)となります。</target>
        </trans-unit>
        <trans-unit id="5584ccc82484d2c61a85300c7acd35cb5205fef6" translate="yes" xml:space="preserve">
          <source>Initial value for lambda (precision of the weights). If not set, lambda_init is 1.</source>
          <target state="translated">ラムダ(重みの精度)の初期値。設定されていない場合はlambda_initが1になります。</target>
        </trans-unit>
        <trans-unit id="168bf67b39abe0e5515698a4ec915c75e07ca524" translate="yes" xml:space="preserve">
          <source>Initial value for the dictionary for warm restart scenarios.</source>
          <target state="translated">温かい再起動シナリオのための辞書の初期値。</target>
        </trans-unit>
        <trans-unit id="64b2b9f72c239478fc1b9e586ac8147218ca87bd" translate="yes" xml:space="preserve">
          <source>Initial value for the sparse code for warm restart scenarios.</source>
          <target state="translated">温かい再起動シナリオのためのスパースコードの初期値。</target>
        </trans-unit>
        <trans-unit id="1a6282c9a9baf1c9231fe6132d9510c0860835e2" translate="yes" xml:space="preserve">
          <source>Initial values for the components for warm restart scenarios.</source>
          <target state="translated">ウォームリスタートシナリオのコンポーネントの初期値。</target>
        </trans-unit>
        <trans-unit id="ff1f0a80e07dd6cd648bd3a5e935a909ec2cb299" translate="yes" xml:space="preserve">
          <source>Initial values for the loadings for warm restart scenarios.</source>
          <target state="translated">温かい再起動シナリオのための負荷の初期値。</target>
        </trans-unit>
        <trans-unit id="e597ad1e68022a1929058718fd92959e281b3619" translate="yes" xml:space="preserve">
          <source>Initialization of embedding. Possible options are &amp;lsquo;random&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, and a numpy array of shape (n_samples, n_components). PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.</source>
          <target state="translated">埋め込みの初期化。可能なオプションは、「ランダム」、「pca」、および形状の数の多い配列（n_samples、n_components）です。PCAの初期化は、事前に計算された距離では使用できず、通常、ランダムな初期化よりもグローバルに安定しています。</target>
        </trans-unit>
        <trans-unit id="726483459f359a8ededc78286c7835b11430e40a" translate="yes" xml:space="preserve">
          <source>Initialization of the linear transformation. Possible options are &amp;lsquo;auto&amp;rsquo;, &amp;lsquo;pca&amp;rsquo;, &amp;lsquo;lda&amp;rsquo;, &amp;lsquo;identity&amp;rsquo;, &amp;lsquo;random&amp;rsquo;, and a numpy array of shape (n_features_a, n_features_b).</source>
          <target state="translated">線形変換の初期化。可能なオプションは、「auto」、「pca」、「lda」、「identity」、「random」、および形状の多数の配列（n_features_a、n_features_b）です。</target>
        </trans-unit>
        <trans-unit id="e644154875d3e41452e4b87177ec7a98e4e47540" translate="yes" xml:space="preserve">
          <source>Initialization value for coefficients of logistic regression. Useless for liblinear solver.</source>
          <target state="translated">ロジスティック回帰の係数の初期化値。liblinearソルバーには不要。</target>
        </trans-unit>
        <trans-unit id="ed7011971816dd0f1903ad54a411facedaee4ded" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt;.</source>
          <target state="translated">スパースコードの初期化値。 &lt;code&gt;algorithm=&amp;rsquo;lasso_cd&amp;rsquo;&lt;/code&gt; 場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="8989f9ab8650a480a58e2f03b20f1b5428df4549" translate="yes" xml:space="preserve">
          <source>Initialization value of the sparse codes. Only used if &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt;.</source>
          <target state="translated">スパースコードの初期化値。 &lt;code&gt;algorithm='lasso_cd'&lt;/code&gt; 場合にのみ使用されます。</target>
        </trans-unit>
        <trans-unit id="5f66672d1a211feccb2663e524389cc7bbdc9544" translate="yes" xml:space="preserve">
          <source>Initialize self. See help(type(self)) for accurate signature.</source>
          <target state="translated">selfを初期化します。正確な署名は help(type(self))を参照してください。</target>
        </trans-unit>
        <trans-unit id="ccac906d8789727d67e839b8a0f34db2f9002a71" translate="yes" xml:space="preserve">
          <source>Initializing components, sampling from layers during fit.</source>
          <target state="translated">コンポーネントの初期化、はめ込み中のレイヤーからのサンプリング。</target>
        </trans-unit>
        <trans-unit id="f4694fddfebcd07057574f3bedbe073aecef8cbe" translate="yes" xml:space="preserve">
          <source>Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the &lt;code&gt;score_samples&lt;/code&gt; method, while the threshold can be controlled by the &lt;code&gt;contamination&lt;/code&gt; parameter.</source>
          <target state="translated">外れ値のラベルは-1、外れ値のラベルは1です。予測メソッドは、推定器によって計算された生のスコアリング関数のしきい値を利用します。このスコアリング関数は、 &lt;code&gt;score_samples&lt;/code&gt; メソッドを介してアクセスできますが、しきい値は &lt;code&gt;contamination&lt;/code&gt; パラメーターによって制御できます。</target>
        </trans-unit>
        <trans-unit id="2495be2cc170e277a5d9d5dd99a3f779ff0175c9" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid loosing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">アルゴリズムによって保持される内部の十分な統計量。初期化時にそれらを渡すことは,オンライン設定では,進化の履歴を失わないようにするために有用である.A (n_components,n_components)は,辞書共分散行列です.B (n_features,n_components)は,データ近似行列.</target>
        </trans-unit>
        <trans-unit id="06dcf06c32dda54c31aa74eee694be9763d822e4" translate="yes" xml:space="preserve">
          <source>Inner sufficient statistics that are kept by the algorithm. Passing them at initialization is useful in online settings, to avoid losing the history of the evolution. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix</source>
          <target state="translated">アルゴリズムによって保持される内部の十分な統計量。初期化時にそれらを渡すことは,オンライン設定では,進化の履歴を失わないようにするために有用である.A (n_components,n_components)は,辞書共分散行列です.B (n_features,n_components)は,データ近似行列.</target>
        </trans-unit>
        <trans-unit id="4cb705151cf2a5dcfea8029a0e74d39c67469fa5" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSC/CSR matrix.</source>
          <target state="translated">CSC/CSR行列の列スケーリングをインプレースします。</target>
        </trans-unit>
        <trans-unit id="15ad21d3f40808b965488683b0faaff07ad4b5e9" translate="yes" xml:space="preserve">
          <source>Inplace column scaling of a CSR matrix.</source>
          <target state="translated">CSR行列の列のスケーリングを挿入します。</target>
        </trans-unit>
        <trans-unit id="75290bdbc975498c98c7572ec067e43ddceb0c68" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l1 norm</source>
          <target state="translated">l1 normを使用して行を正規化します。</target>
        </trans-unit>
        <trans-unit id="bc0180825da8415aba8c76f27c29d7e471b70c2a" translate="yes" xml:space="preserve">
          <source>Inplace row normalize using the l2 norm</source>
          <target state="translated">l2 normを使用して行を正規化します。</target>
        </trans-unit>
        <trans-unit id="d91ae689358e283ef6d343e24e55244f1fb1cad2" translate="yes" xml:space="preserve">
          <source>Inplace row scaling of a CSR or CSC matrix.</source>
          <target state="translated">CSR または CSC 行列の行スケーリングをインプレースします。</target>
        </trans-unit>
        <trans-unit id="16ca749420dd58126c1f3f4ccf95ce2fc49387c9" translate="yes" xml:space="preserve">
          <source>Input array.</source>
          <target state="translated">入力配列。</target>
        </trans-unit>
        <trans-unit id="f6fcca00499ce6b21e6114d56b450f6d3d43ccb2" translate="yes" xml:space="preserve">
          <source>Input checker utility for building a cross-validator</source>
          <target state="translated">クロスバリデータを構築するための入力チェッカーユーティリティ</target>
        </trans-unit>
        <trans-unit id="3f43a2e4863dbf39da8cfbd5e4e557f3052ec269" translate="yes" xml:space="preserve">
          <source>Input data</source>
          <target state="translated">入力データ</target>
        </trans-unit>
        <trans-unit id="a2e2ac083ce3186e216de5448418ffc50e83a494" translate="yes" xml:space="preserve">
          <source>Input data for prediction.</source>
          <target state="translated">予測のための入力データ。</target>
        </trans-unit>
        <trans-unit id="41aa04ac5754100b497c803419573444b7e1d42b" translate="yes" xml:space="preserve">
          <source>Input data representation and sparsity</source>
          <target state="translated">入力データの表現とスパリティ</target>
        </trans-unit>
        <trans-unit id="66a8a4e34fe15bd5eafb5d984d77b9c0e3866728" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed.</source>
          <target state="translated">変換されるデータを入力します。</target>
        </trans-unit>
        <trans-unit id="fbb05f66a147e8520f226c078931507f60d0caac" translate="yes" xml:space="preserve">
          <source>Input data that will be transformed. It cannot be sparse.</source>
          <target state="translated">変換される入力データ。スパースにすることはできません。</target>
        </trans-unit>
        <trans-unit id="1e3e0a570b83c9cbe639106afeb9bedd23e3fcfd" translate="yes" xml:space="preserve">
          <source>Input data to be transformed.</source>
          <target state="translated">変換する入力データ。</target>
        </trans-unit>
        <trans-unit id="071feefe9143dba47a473de169ba49367bfce443" translate="yes" xml:space="preserve">
          <source>Input data to be transformed. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency. Sparse matrices are also supported, use sparse &lt;code&gt;csr_matrix&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">変換する入力データ。効率を最大にするには、 &lt;code&gt;dtype=np.float32&lt;/code&gt; を使用します。スパース行列もサポートされています。効率を最大にするには、スパース &lt;code&gt;csr_matrix&lt;/code&gt; を使用してください。</target>
        </trans-unit>
        <trans-unit id="688f24dc1e25fac1dc510cf29e6e51a5cdee42ba" translate="yes" xml:space="preserve">
          <source>Input data used to build forests. Use &lt;code&gt;dtype=np.float32&lt;/code&gt; for maximum efficiency.</source>
          <target state="translated">フォレストの構築に使用される入力データ。効率を最大にするには、 &lt;code&gt;dtype=np.float32&lt;/code&gt; を使用します。</target>
        </trans-unit>
        <trans-unit id="ece9df27fcdc2d8935842ef4ed6ac1e8d53f8b6c" translate="yes" xml:space="preserve">
          <source>Input data, of which specified subsets are used to fit the transformers.</source>
          <target state="translated">指定されたサブセットが変換器に適合するために使用される入力データ。</target>
        </trans-unit>
        <trans-unit id="8c020a67c0398f86d112987222d02c36283701ba" translate="yes" xml:space="preserve">
          <source>Input data, target values.</source>
          <target state="translated">入力データ、目標値。</target>
        </trans-unit>
        <trans-unit id="0d15fc28721eb2bcf2d53de59215da674d786463" translate="yes" xml:space="preserve">
          <source>Input data, used to fit transformers.</source>
          <target state="translated">入力データ、変圧器の適合に使用されます。</target>
        </trans-unit>
        <trans-unit id="6db69e17f58030ae15478a3e504e982203a8ead7" translate="yes" xml:space="preserve">
          <source>Input data, where &amp;ldquo;n_samples&amp;rdquo; is the number of samples and &amp;ldquo;n_features&amp;rdquo; is the number of features.</source>
          <target state="translated">入力データ。「n_samples」はサンプルの数、「n_features」は特徴の数です。</target>
        </trans-unit>
        <trans-unit id="aee2f5203193bb3069f6e2f7b08e833e91d53841" translate="yes" xml:space="preserve">
          <source>Input data, where &lt;code&gt;n_samples&lt;/code&gt; is the number of samples and &lt;code&gt;n_features&lt;/code&gt; is the number of features.</source>
          <target state="translated">入力データ。ここで、 &lt;code&gt;n_samples&lt;/code&gt; はサンプルの数、 &lt;code&gt;n_features&lt;/code&gt; は特徴の数です。</target>
        </trans-unit>
        <trans-unit id="8f9c683e36e31c7c38c7e8d6a2daeccf181d4c94" translate="yes" xml:space="preserve">
          <source>Input data, where n_samples is the number of samples and n_features is the number of features.</source>
          <target state="translated">入力データで、n_samplesはサンプル数、n_featuresは特徴量の数です。</target>
        </trans-unit>
        <trans-unit id="260753716624ad2077f13f38ada17a33c0f48cba" translate="yes" xml:space="preserve">
          <source>Input data.</source>
          <target state="translated">データを入力します。</target>
        </trans-unit>
        <trans-unit id="c414149f534c72aa4d2016c93404604f17aa41fd" translate="yes" xml:space="preserve">
          <source>Input data. Columns are assumed to have unit norm.</source>
          <target state="translated">入力データ。列は単位ノルムを持つと仮定しています。</target>
        </trans-unit>
        <trans-unit id="fc921091c020b61d18864b21129c4eb989ef6d69" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;None&lt;/code&gt;, the output will be the pairwise similarities between all samples in &lt;code&gt;X&lt;/code&gt;.</source>
          <target state="translated">入力データ。場合 &lt;code&gt;None&lt;/code&gt; 、出力は内のすべてのサンプル間のペアごとの類似点となります &lt;code&gt;X&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="afaf08d18a1423dc1a78bf3492e5ce0eb50d8638" translate="yes" xml:space="preserve">
          <source>Input data. If &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt;, the input should be the dissimilarity matrix.</source>
          <target state="translated">入力データ。場合は &lt;code&gt;dissimilarity=='precomputed'&lt;/code&gt; 、入力が非類似度行列でなければなりません。</target>
        </trans-unit>
        <trans-unit id="c7e2acaca5145e47486c9c2928ab5532aee98fd4" translate="yes" xml:space="preserve">
          <source>Input data. If X is not provided, only the global clustering step is done.</source>
          <target state="translated">入力データ。Xが与えられない場合は、グローバルクラスタリングステップのみが実行されます。</target>
        </trans-unit>
        <trans-unit id="609eafdfc25268bf81369faed57dc8b7d067fce7" translate="yes" xml:space="preserve">
          <source>Input data. Note that if X is None then the Gram matrix must be specified, i.e., cannot be None or False.</source>
          <target state="translated">入力データ。X が None の場合、グラム行列が指定されなければならないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="d39fe8b9c923e952612de77f70ad5aff60c34542" translate="yes" xml:space="preserve">
          <source>Input object to check / convert.</source>
          <target state="translated">チェック/変換するための入力オブジェクト。</target>
        </trans-unit>
        <trans-unit id="ca7fd27e447d5e335b2e80d1b2bb1406dceac239" translate="yes" xml:space="preserve">
          <source>Input object to check / convert. Must be two-dimensional and square, otherwise a ValueError will be raised.</source>
          <target state="translated">チェック/変換する入力オブジェクト。二次元で正方形でなければならず、そうでない場合は ValueError が発生します。</target>
        </trans-unit>
        <trans-unit id="f24bf584af83fad1f47a5035ff05cdc62fd1daef" translate="yes" xml:space="preserve">
          <source>Input points.</source>
          <target state="translated">入力ポイント。</target>
        </trans-unit>
        <trans-unit id="71b2d21e1f2e71c0dcf88bd09dfe9ef6fd499ea3" translate="yes" xml:space="preserve">
          <source>Input targets</source>
          <target state="translated">入力対象</target>
        </trans-unit>
        <trans-unit id="b58e4bce1b7ebb41f970a06dbe933522f9ad2c46" translate="yes" xml:space="preserve">
          <source>Input targets multiplied by X: X.T * y</source>
          <target state="translated">入力ターゲットにXを乗じたもの:X.T*y</target>
        </trans-unit>
        <trans-unit id="69a0e9f3a009e8ccbba64367545e9fbe88306b19" translate="yes" xml:space="preserve">
          <source>Input targets.</source>
          <target state="translated">ターゲットを入力します。</target>
        </trans-unit>
        <trans-unit id="51c9f9fb1fac83429c51404b5e9b2caee57cc2f2" translate="yes" xml:space="preserve">
          <source>Input validation for standard estimators.</source>
          <target state="translated">標準推定量の入力検証</target>
        </trans-unit>
        <trans-unit id="346da7aa7d7e4eb884706a35a69404b7d3fc9daa" translate="yes" xml:space="preserve">
          <source>Input validation on an array, list, sparse matrix or similar.</source>
          <target state="translated">配列,リスト,疎な行列などの入力検証.</target>
        </trans-unit>
        <trans-unit id="4191049318f63b6c3a85211b91a5c1cecb649bdb" translate="yes" xml:space="preserve">
          <source>Input values.</source>
          <target state="translated">入力値。</target>
        </trans-unit>
        <trans-unit id="8344beaf285df55c120907e8b74a9a1f87253895" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are 4 independent features uniformly distributed on the intervals:</source>
          <target state="translated">入力 &lt;code&gt;X&lt;/code&gt; は、間隔で均一に分布する4つの独立した特徴です。</target>
        </trans-unit>
        <trans-unit id="bcbcb56a88ddeef69ce01bcc9a78a456071e2cf0" translate="yes" xml:space="preserve">
          <source>Inputs &lt;code&gt;X&lt;/code&gt; are independent features uniformly distributed on the interval [0, 1]. The output &lt;code&gt;y&lt;/code&gt; is created according to the formula:</source>
          <target state="translated">入力 &lt;code&gt;X&lt;/code&gt; は、区間[0、1]に均一に分布する独立した特徴です。出力 &lt;code&gt;y&lt;/code&gt; は次の式に従って作成されます。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
