<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="00b13dec03b43a1e31572c6206c49d66e2649772" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; and this copy is between CPU and GPU, the copy may occur asynchronously with respect to the host. For other cases, this argument has no effect.</source>
          <target state="translated">&lt;strong&gt;non_blocking&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt; and this copy is between CPU and GPU, the copy may occur asynchronously with respect to the host. For other cases, this argument has no effect.</target>
        </trans-unit>
        <trans-unit id="23e61115abf60d0f6a77464558c090db5540aa9e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;non_leaf_module_list&lt;/strong&gt; &amp;ndash; list of non-leaf modules we want to add observer</source>
          <target state="translated">&lt;strong&gt;non_leaf_module_list&lt;/strong&gt; &amp;ndash;オブザーバーを追加する非リーフモジュールのリスト</target>
        </trans-unit>
        <trans-unit id="d97e40b345e0eaa999d1b92e40db509bc22da78b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nondet_tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; tolerance for non-determinism. When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance.</source>
          <target state="translated">&lt;strong&gt;nondet_tol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;非決定論に対する許容度。微分を通じて同一の入力を実行する場合、結果は正確に一致するか（デフォルト、0.0）、この許容範囲内にある必要があります。</target>
        </trans-unit>
        <trans-unit id="8f5856c3c6589a1314d66382282476615b5a82fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nondet_tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; tolerance for non-determinism. When running identical inputs through the differentiation, the results must either match exactly (default, 0.0) or be within this tolerance. Note that a small amount of nondeterminism in the gradient will lead to larger inaccuracies in the second derivative.</source>
          <target state="translated">&lt;strong&gt;nondet_tol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;非決定論に対する許容度。微分を通じて同一の入力を実行する場合、結果は正確に一致するか（デフォルト、0.0）、この許容範囲内にある必要があります。勾配に少量の非決定性があると、2次導関数の不正確さが大きくなることに注意してください。</target>
        </trans-unit>
        <trans-unit id="dc977ce4adf32dbf0bccc2e0e481f93caf29accf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; The non-linearity to use. Can be either &lt;code&gt;'tanh'&lt;/code&gt; or &lt;code&gt;'relu'&lt;/code&gt;. Default: &lt;code&gt;'tanh'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; The non-linearity to use. Can be either &lt;code&gt;'tanh'&lt;/code&gt; or &lt;code&gt;'relu'&lt;/code&gt; . Default: &lt;code&gt;'tanh'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3130318f0a7fea9d363cd7ece82482a7951ecf83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function (&lt;code&gt;nn.functional&lt;/code&gt; name)</source>
          <target state="translated">&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function ( &lt;code&gt;nn.functional&lt;/code&gt; name)</target>
        </trans-unit>
        <trans-unit id="4aa37508fa49cde50a4584a0a4a2daca12ff537e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function (&lt;code&gt;nn.functional&lt;/code&gt; name), recommended to use only with &lt;code&gt;'relu'&lt;/code&gt; or &lt;code&gt;'leaky_relu'&lt;/code&gt; (default).</source>
          <target state="translated">&lt;strong&gt;nonlinearity&lt;/strong&gt; &amp;ndash; the non-linear function ( &lt;code&gt;nn.functional&lt;/code&gt; name), recommended to use only with &lt;code&gt;'relu'&lt;/code&gt; or &lt;code&gt;'leaky_relu'&lt;/code&gt; (default).</target>
        </trans-unit>
        <trans-unit id="af1aae5aa50bc026c9cb830597267216d05aa8f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm&lt;/strong&gt; &amp;ndash; the layer normalization component (optional).</source>
          <target state="translated">&lt;strong&gt;norm&lt;/strong&gt; &amp;ndash; the layer normalization component (optional).</target>
        </trans-unit>
        <trans-unit id="042826a4724ce41d943ad1739990aba3a85a4a51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;norm&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="25b7d7d86b234b69e97817612f3d8411fbdc3831" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; type of the used p-norm. Can be &lt;code&gt;'inf'&lt;/code&gt; for infinity norm.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; type of the used p-norm. Can be &lt;code&gt;'inf'&lt;/code&gt; for infinity norm.</target>
        </trans-unit>
        <trans-unit id="5fbeccb6b749ceedad0227342ff93bd8d1b3c38e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="67a00acec5420f77031cf95c030b9e478dabf5ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The &lt;code&gt;p&lt;/code&gt; in the &lt;code&gt;p&lt;/code&gt;-norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The &lt;code&gt;p&lt;/code&gt; in the &lt;code&gt;p&lt;/code&gt; -norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="6c0575ab7282d8575f927d745ef2b2ba33374a8d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The p of the p-norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;norm_type&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The p of the p-norm to compute for the &lt;code&gt;max_norm&lt;/code&gt; option. Default &lt;code&gt;2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f7e673690158062d96a0d2ab65a7cef662314e39" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether the STFT was normalized. (Default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether the STFT was normalized. (Default: &lt;code&gt;False&lt;/code&gt; )</target>
        </trans-unit>
        <trans-unit id="e814d9b9d8871174bb71b430fdad8deb479f898c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return normalized results. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return normalized results. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="55c2c1e33d4fa16ec0ad8d020fa793df29564524" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the normalized STFT results Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;normalized&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the normalized STFT results Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="46fbb1084d5f3c7db6c165371d7dc2e34cf14b9f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;normalized_shape&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;normalized_shape&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="34ddc3ee75c6e422834e70e579e7d1f48d9225b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;nprocs&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of processes to spawn.</source>
          <target state="translated">&lt;strong&gt;nprocs&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;生成するプロセスの数。</target>
        </trans-unit>
        <trans-unit id="0893590e108f46268f24f1a5dcb2dddba9556031" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of channels expected in input</source>
          <target state="translated">&lt;strong&gt;num_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of channels expected in input</target>
        </trans-unit>
        <trans-unit id="5cfb2a3b4581e8308eef2a0a6f8caba338ba2eb1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Total number of classes. If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.</source>
          <target state="translated">&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Total number of classes. If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor.</target>
        </trans-unit>
        <trans-unit id="0cedc9f268bdd45102c976aafc252937bfb35224" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of output classes of the model (including the background)</source>
          <target state="translated">&lt;strong&gt;num_classes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of output classes of the model (including the background)</target>
        </trans-unit>
        <trans-unit id="b89059d982eca861114c424da98eed8e996d7cf1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_decoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (default=6).</source>
          <target state="translated">&lt;strong&gt;num_decoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (default=6).</target>
        </trans-unit>
        <trans-unit id="849f5a2c21cc33c1cacad354c0a79d6a1f17b0c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_embeddings&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of the dictionary of embeddings</source>
          <target state="translated">&lt;strong&gt;num_embeddings&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of the dictionary of embeddings</target>
        </trans-unit>
        <trans-unit id="8181be00d6cb90d97280a1382ec1a1a05ca6c394" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_encoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (default=6).</source>
          <target state="translated">&lt;strong&gt;num_encoder_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (default=6).</target>
        </trans-unit>
        <trans-unit id="fb50075c2dd76286e5338792fc9e620415adf047" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_features&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;num_features&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="b606c4e5166178414dc02bf646ef98468d9aef12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_groups&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of groups to separate the channels into</source>
          <target state="translated">&lt;strong&gt;num_groups&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of groups to separate the channels into</target>
        </trans-unit>
        <trans-unit id="93f81723e37eb2609764e3fe95a3bac369d5a4b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_heads&lt;/strong&gt; &amp;ndash; parallel attention heads.</source>
          <target state="translated">&lt;strong&gt;num_heads&lt;/strong&gt; &amp;ndash; parallel attention heads.</target>
        </trans-unit>
        <trans-unit id="716e2a8f4f7ad74c1067fb5b8a90a00f71da6a83" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two GRUs together to form a &lt;code&gt;stacked GRU&lt;/code&gt;, with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two GRUs together to form a &lt;code&gt;stacked GRU&lt;/code&gt; , with the second GRU taking in outputs of the first GRU and computing the final results. Default: 1</target>
        </trans-unit>
        <trans-unit id="848be87c245b176a092f816c28a51ec302bfbd9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two LSTMs together to form a &lt;code&gt;stacked LSTM&lt;/code&gt;, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two LSTMs together to form a &lt;code&gt;stacked LSTM&lt;/code&gt; , with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1</target>
        </trans-unit>
        <trans-unit id="3f20f56b362366655c5f5d500d3983ccb38896b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two RNNs together to form a &lt;code&gt;stacked RNN&lt;/code&gt;, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; Number of recurrent layers. E.g., setting &lt;code&gt;num_layers=2&lt;/code&gt; would mean stacking two RNNs together to form a &lt;code&gt;stacked RNN&lt;/code&gt; , with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1</target>
        </trans-unit>
        <trans-unit id="80d0325c2a7e14f3b87f5fbe564e95166bea3899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (required).</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-decoder-layers in the decoder (required).</target>
        </trans-unit>
        <trans-unit id="6981d7fa46aee8b590e66abd7ac32bb99332f4b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (required).</source>
          <target state="translated">&lt;strong&gt;num_layers&lt;/strong&gt; &amp;ndash; the number of sub-encoder-layers in the encoder (required).</target>
        </trans-unit>
        <trans-unit id="1c6217d241d0c6e30110c21e501846e588f977b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_parameters&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of</source>
          <target state="translated">&lt;strong&gt;num_parameters&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of</target>
        </trans-unit>
        <trans-unit id="400bd8b77c00061e5eae688001b6628633196c98" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_replicas&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of processes participating in distributed training. By default, &lt;code&gt;rank&lt;/code&gt; is retrieved from the current distributed group.</source>
          <target state="translated">&lt;strong&gt;num_replicas&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;分散トレーニングに参加しているプロセスの数。デフォルトでは、 &lt;code&gt;rank&lt;/code&gt; は現在の分散グループから取得されます。</target>
        </trans-unit>
        <trans-unit id="217f93399a3e49b6a211efe4dfeb93b9b074c795" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_samples&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of samples to draw</source>
          <target state="translated">&lt;strong&gt;num_samples&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of samples to draw</target>
        </trans-unit>
        <trans-unit id="7c74e9e010f947a1d1f639420c7586d124de415e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_samples&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of samples to draw, default=`len(dataset)`. This argument is supposed to be specified only when &lt;code&gt;replacement&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;num_samples&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;描画するサンプルの数、default = `len（dataset）`。この引数は、 &lt;code&gt;replacement&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合にのみ指定されることになっています。</target>
        </trans-unit>
        <trans-unit id="261b75892c45e73ce2bcf393c665d4350903ddd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_send_recv_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;ProcessGroupAgent&lt;/code&gt; (default: 4).</source>
          <target state="translated">&lt;strong&gt;num_send_recv_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;ProcessGroupAgent&lt;/code&gt; (default: 4).</target>
        </trans-unit>
        <trans-unit id="9e30ae31cb163bad5dd2dce2717b84e6e7ebd501" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_thresholds&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of thresholds used to draw the curve.</source>
          <target state="translated">&lt;strong&gt;num_thresholds&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of thresholds used to draw the curve.</target>
        </trans-unit>
        <trans-unit id="b15859c381baa669db57383f7570015c6f11a1eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_worker_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;TensorPipeAgent&lt;/code&gt; to execute requests (default: 16).</source>
          <target state="translated">&lt;strong&gt;num_worker_threads&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The number of threads in the thread-pool used by &lt;code&gt;TensorPipeAgent&lt;/code&gt; to execute requests (default: 16).</target>
        </trans-unit>
        <trans-unit id="8bf5929cbf77d6b6e96064b0308a982665a52cec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;num_workers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; how many subprocesses to use for data loading. &lt;code&gt;0&lt;/code&gt; means that the data will be loaded in the main process. (default: &lt;code&gt;0&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;num_workers&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;データのロードに使用するサブプロセスの数。 &lt;code&gt;0&lt;/code&gt; は、データがメインプロセスでロードされることを意味します。（デフォルト： &lt;code&gt;0&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="f2a5564d5b72bbb54db0dee38713bf01705f62e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; &amp;ndash; saved object</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; &amp;ndash; saved object</target>
        </trans-unit>
        <trans-unit id="339eb04d43f579222956fff0d0593550e205956a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Storage&lt;/em&gt;) &amp;ndash; object allocated on the selected device.</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Storage&lt;/em&gt;）&amp;ndash;選択したデバイスに割り当てられたオブジェクト。</target>
        </trans-unit>
        <trans-unit id="9df8cf76692544b5e3907cc50ab40d5bd8586e94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; (&lt;em&gt;Object&lt;/em&gt;) &amp;ndash; Object to test</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; (&lt;em&gt;Object&lt;/em&gt;) &amp;ndash; Object to test</target>
        </trans-unit>
        <trans-unit id="1efcc773a7594d495f38b29dce91f4e0fcb2d526" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;obj&lt;/strong&gt; (callable, class, or &lt;code&gt;nn.Module&lt;/code&gt;) &amp;ndash; The &lt;code&gt;nn.Module&lt;/code&gt;, function, or class type to compile.</source>
          <target state="translated">&lt;strong&gt;obj&lt;/strong&gt; (callable, class, or &lt;code&gt;nn.Module&lt;/code&gt; ) &amp;ndash; The &lt;code&gt;nn.Module&lt;/code&gt; , function, or class type to compile.</target>
        </trans-unit>
        <trans-unit id="d6c4e0bbeea69d8599a25da4f144962160ea1886" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;observer&lt;/strong&gt; (&lt;em&gt;module&lt;/em&gt;) &amp;ndash; Module for observing statistics on input tensors and calculating scale and zero-point.</source>
          <target state="translated">&lt;strong&gt;オブザーバー&lt;/strong&gt;（&lt;em&gt;モジュール&lt;/em&gt;）&amp;ndash;入力テンソルの統計を観測し、スケールとゼロ点を計算するためのモジュール。</target>
        </trans-unit>
        <trans-unit id="8ba4f41b8381dd854ee440f11080a46465c4c0e9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;observer_kwargs&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Arguments for the observer module</source>
          <target state="translated">&lt;strong&gt;observer_kwargs&lt;/strong&gt;（&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;オブザーバーモジュールの引数</target>
        </trans-unit>
        <trans-unit id="964cfe304a42815568c84ad629c3feba66c4a36b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;observer_non_leaf_module_list&lt;/strong&gt; &amp;ndash; list of non-leaf modules we want to add observer</source>
          <target state="translated">&lt;strong&gt;observer_non_leaf_module_list&lt;/strong&gt; &amp;ndash;オブザーバーを追加する非リーフモジュールのリスト</target>
        </trans-unit>
        <trans-unit id="4d631610135b6d78e1caf59354dfcdfe0e55f151" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the diagonal to consider. Default: 0 (main diagonal).</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the diagonal to consider. Default: 0 (main diagonal).</target>
        </trans-unit>
        <trans-unit id="a23fd1c737ac34111ea6878cbb466517bbf61204" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; which diagonal to consider. Default: 0 (main diagonal).</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; which diagonal to consider. Default: 0 (main diagonal).</target>
        </trans-unit>
        <trans-unit id="b094d10e5ad29ad4b91fe1094a0e0451c35935ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offset&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; diagonal offset from the main diagonal. Default: if not provided, 0.</source>
          <target state="translated">&lt;strong&gt;offset&lt;/strong&gt; ( &lt;code&gt;int&lt;/code&gt; ) &amp;ndash; diagonal offset from the main diagonal. Default: if not provided, 0.</target>
        </trans-unit>
        <trans-unit id="59680b913232bfc3f5ca8eefc5ea0a3e439f606d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;offsets&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Only used when &lt;code&gt;input&lt;/code&gt; is 1D. &lt;code&gt;offsets&lt;/code&gt; determines the starting index position of each bag (sequence) in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;offsets&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Only used when &lt;code&gt;input&lt;/code&gt; is 1D. &lt;code&gt;offsets&lt;/code&gt; determines the starting index position of each bag (sequence) in &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f3eeb1215829aa860254719c6ed490994631af72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether &lt;code&gt;input&lt;/code&gt; was halfed to avoid redundancy, e.g., by &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether &lt;code&gt;input&lt;/code&gt; was halfed to avoid redundancy, e.g., by &lt;a href=&quot;torch.rfft#torch.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;. Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c3828107f07c747332fcb7869a55bac90d7123f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy for real inputs. Default: &lt;code&gt;True&lt;/code&gt; for real &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;window&lt;/code&gt;, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy for real inputs. Default: &lt;code&gt;True&lt;/code&gt; for real &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;window&lt;/code&gt; , &lt;code&gt;False&lt;/code&gt; otherwise.</target>
        </trans-unit>
        <trans-unit id="b8c4c667951698c100009eb45a650b471858d1c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return half of results to avoid redundancy. Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="227c5f582067ca753f45fef8e7cb4cc34373476c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;onesided&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the STFT was onesided. (Default: &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;n_fft != fft_size&lt;/code&gt; in the input size)</source>
          <target state="translated">&lt;strong&gt;onesided&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the STFT was onesided. (Default: &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;n_fft != fft_size&lt;/code&gt; in the input size)</target>
        </trans-unit>
        <trans-unit id="b0dae8ba515d13e7989bf49ea6f91f0aa98dcae4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;op&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; One of the values from &lt;code&gt;torch.distributed.ReduceOp&lt;/code&gt; enum. Specifies an operation used for element-wise reductions.</source>
          <target state="translated">&lt;strong&gt;op&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; One of the values from &lt;code&gt;torch.distributed.ReduceOp&lt;/code&gt; enum. Specifies an operation used for element-wise reductions.</target>
        </trans-unit>
        <trans-unit id="ca9e3fe2123059286c3e6e03e1667d5bcbe86c04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;operands&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The operands to compute the Einstein sum of.</source>
          <target state="translated">&lt;strong&gt;operands&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The operands to compute the Einstein sum of.</target>
        </trans-unit>
        <trans-unit id="64c84dfc01211648b09d190f92dcde0b67c4d354" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;operator_export_type&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default OperatorExportTypes.ONNX&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;operator_export_type&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default OperatorExportTypes.ONNX&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="ae2e7fa69f17a2f7d525734c74794c386a5f53af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;opset_version&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default is 9&lt;/em&gt;) &amp;ndash; by default we export the model to the opset version of the onnx submodule. Since ONNX&amp;rsquo;s latest opset may evolve before next stable release, by default we export to one stable opset version. Right now, supported stable opset version is 9. The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py</source>
          <target state="translated">&lt;strong&gt;opset_version&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default is 9&lt;/em&gt;) &amp;ndash; by default we export the model to the opset version of the onnx submodule. Since ONNX&amp;rsquo;s latest opset may evolve before next stable release, by default we export to one stable opset version. Right now, supported stable opset version is 9. The opset_version must be _onnx_master_opset or in _onnx_stable_opsets which are defined in torch/onnx/symbolic_helper.py</target>
        </trans-unit>
        <trans-unit id="eeac5b5644cfe9f927a8580dad78015f44b4e5df" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimization options.&lt;/strong&gt; (&lt;em&gt;specific&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;最適化オプション。&lt;/strong&gt;（&lt;em&gt;特定&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="341b800a5d451a2739a7cf894c4169dfd8a8ab69" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimization_blocklist&lt;/strong&gt; &amp;ndash; A set with type of MobileOptimizerType. When set is not passed, optimization method will run all the optimizer pass; otherwise, optimizer method will run the optimization pass that is not included inside optimization_blocklist.</source>
          <target state="translated">&lt;strong&gt;optimization_blocklist&lt;/strong&gt; &amp;ndash; A set with type of MobileOptimizerType. When set is not passed, optimization method will run all the optimizer pass; otherwise, optimizer method will run the optimization pass that is not included inside optimization_blocklist.</target>
        </trans-unit>
        <trans-unit id="e384b8bc869084e0aad2704cab3a0c3783273b65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimizer&lt;/strong&gt; (&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;Optimizer&lt;/a&gt;) &amp;ndash; Wrapped optimizer.</source>
          <target state="translated">&lt;strong&gt;オプティマイザー&lt;/strong&gt;（&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;オプティマイザー&lt;/a&gt;）&amp;ndash;ラップされたオプティマイザー。</target>
        </trans-unit>
        <trans-unit id="1207cb8cc2010faa25bd487265a929700cd7ee0c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimizer&lt;/strong&gt; (&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;torch.optim.Optimizer&lt;/a&gt;) &amp;ndash; Optimizer that applies the gradients.</source>
          <target state="translated">&lt;strong&gt;オプティマイザー&lt;/strong&gt;（&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;torch.optim.Optimizer&lt;/a&gt;）&amp;ndash;グラデーションを適用するオプティマイザー。</target>
        </trans-unit>
        <trans-unit id="7c10e05231937bf3ab042ec5af55f70548f71ca1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimizer&lt;/strong&gt; (&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;torch.optim.Optimizer&lt;/a&gt;) &amp;ndash; Optimizer that owns the gradients to be unscaled.</source>
          <target state="translated">&lt;strong&gt;オプティマイザー&lt;/strong&gt;（&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;torch.optim.Optimizer&lt;/a&gt;）&amp;ndash;スケーリングされないグラデーションを所有するオプティマイザー。</target>
        </trans-unit>
        <trans-unit id="3eb51832b6aa0f276cb8df9ff35933a83aafdcb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;optimizer_class&lt;/strong&gt; (&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;optim.Optimizer&lt;/a&gt;) &amp;ndash; the class of optimizer to instantiate on each worker.</source>
          <target state="translated">&lt;strong&gt;optimizer_class&lt;/strong&gt; (&lt;a href=&quot;optim#torch.optim.Optimizer&quot;&gt;optim.Optimizer&lt;/a&gt;) &amp;ndash; the class of optimizer to instantiate on each worker.</target>
        </trans-unit>
        <trans-unit id="d4b6fe40a78147f10f4276a3fff8e0f880f89f66" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ord&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;ord&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="c278df20ef2016b751d8544cf7c0d4206d20cb20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ortho_fparams, ortho_bparams&lt;/strong&gt; (&lt;em&gt;ortho_iparams&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; various parameters to LOBPCG algorithm when using &lt;code&gt;method=&amp;rdquo;ortho&amp;rdquo;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;ortho_fparams, ortho_bparams&lt;/strong&gt; (&lt;em&gt;ortho_iparams&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash; various parameters to LOBPCG algorithm when using &lt;code&gt;method=&amp;rdquo;ortho&amp;rdquo;&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="3de7c1b5054808fbf162ba527fa5af49d0d5b2a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; &amp;ndash; the second input tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; &amp;ndash; the second input tensor</target>
        </trans-unit>
        <trans-unit id="9830ed943f8f4c46a3eaf71558a02ad41461cee1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The result tensor has the same shape as &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;) &amp;ndash; The result tensor has the same shape as &lt;code&gt;other&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="d83937e2055c79b7eeec7c9e6cd7007e8c6ba7b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The result tensor has the same size as &lt;code&gt;other&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;) &amp;ndash; The result tensor has the same size as &lt;code&gt;other&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="575d583c4e3da2e5f40414a1c2ac1f8053858442" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor in the dot product.</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor in the dot product.</target>
        </trans-unit>
        <trans-unit id="9683962d0d021c44b4feb57563050d15e672f921" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor to compare</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; second tensor to compare</target>
        </trans-unit>
        <trans-unit id="1c95b6612a9c23b59a8184a8bc3fac93a55448ec" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the Right-hand-side input tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the Right-hand-side input tensor</target>
        </trans-unit>
        <trans-unit id="03ddfd5bad09382b4da8e30aba277bed53e1d92c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second input tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second input tensor</target>
        </trans-unit>
        <trans-unit id="7a7c2bdc488731ec762bebe69342927cf0cc7a4e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second multiplicand tensor</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;2番目の被乗数テンソル</target>
        </trans-unit>
        <trans-unit id="006601c4fdb977844e03c057c807959c8ed0607e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;乗算される2番目のテンソル</target>
        </trans-unit>
        <trans-unit id="669f8aaad77167734f2e1b5bbdc071b3c8cca4fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute AND with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;ANDを計算するテンソル</target>
        </trans-unit>
        <trans-unit id="812d6aefc371af303841ae4e35623a96b151d7af" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute OR with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;ORを計算するテンソル</target>
        </trans-unit>
        <trans-unit id="cc9311b9409e52a798efcdc865571b70ee24d69a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to compute XOR with</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;XORを計算するテンソル</target>
        </trans-unit>
        <trans-unit id="1dc58021bcaef0b4c84bf5fbd8eac7072cf21ee6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the divisor that may be either a number or a Tensor of the same shape as the dividend</source>
          <target state="translated">&lt;strong&gt;その他&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;フロート&lt;/a&gt;）&amp;ndash;被除数と同じ形状の数値またはテンソルのいずれかである除数</target>
        </trans-unit>
        <trans-unit id="4af20d1a0478746ed342d723899ffae24e31673f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the divisor, which may be either a number or a tensor of the same shape as the dividend</source>
          <target state="translated">&lt;strong&gt;その他&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;フロート&lt;/a&gt;）&amp;ndash;除数。これは、被除数と同じ形状の数値またはテンソルのいずれかです。</target>
        </trans-unit>
        <trans-unit id="5f7bb660268bfc1f1ce99fb1f5d6144452802639" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the tensor or value to compare</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;比較するテンソルまたは値</target>
        </trans-unit>
        <trans-unit id="2083d9580c98436be500de8f122860e994452f50" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the divisor</source>
          <target state="translated">&lt;strong&gt;その他&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;数&lt;/em&gt;）&amp;ndash;除数</target>
        </trans-unit>
        <trans-unit id="24c486bb19e0b203a2a62ea6e87e873812911826" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the tensor or scalar to subtract from &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;その他&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;スカラー&lt;/em&gt;）&amp;ndash; &lt;code&gt;input&lt;/code&gt; から減算するテンソルまたはスカラー</target>
        </trans-unit>
        <trans-unit id="6897c0ab62af0e375bdc00c90649a3563fa23660" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; the tensor or value to compare</source>
          <target state="translated">&lt;strong&gt;その他&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;スカラー&lt;/em&gt;）&amp;ndash;比較するテンソルまたは値</target>
        </trans-unit>
        <trans-unit id="1ca11bab125e2ff340132dc741c4418bbb9be48f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;other&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the number to be multiplied to each element of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;other&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;）&amp;ndash; &lt;code&gt;input&lt;/code&gt; 各要素に乗算される数値</target>
        </trans-unit>
        <trans-unit id="8bbe00078fcdd90156cc48ebd3d452934d098736" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル</target>
        </trans-unit>
        <trans-unit id="4909287a5578c3077500a804d4cacd409ba1cbb4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; If the inputs are &lt;code&gt;torch.float32&lt;/code&gt;, must be &lt;code&gt;torch.complex64&lt;/code&gt;. If the inputs are &lt;code&gt;torch.float64&lt;/code&gt;, must be &lt;code&gt;torch.complex128&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;アウト&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -入力がある場合は &lt;code&gt;torch.float32&lt;/code&gt; 、でなければなりません &lt;code&gt;torch.complex64&lt;/code&gt; 。入力がある場合は &lt;code&gt;torch.float64&lt;/code&gt; 、でなければなりません &lt;code&gt;torch.complex128&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="49191fc918c7fbbf6b67857e145e1c13e69615dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル</target>
        </trans-unit>
        <trans-unit id="865f26f7ba269d26b55b78b56f8c40704e8bdc68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output matrix</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;オプションの出力行列</target>
        </trans-unit>
        <trans-unit id="c4d5ed5877e75a302ce827729fa9cc1a243e1951" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the destination tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;宛先テンソル</target>
        </trans-unit>
        <trans-unit id="c65d5e1626eb8eac6c27cd8f3a19ef6cfca82d2b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output matrix</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力行列</target>
        </trans-unit>
        <trans-unit id="dc670798304fb38fad30b85d22d05a85c1854899" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル</target>
        </trans-unit>
        <trans-unit id="2913addd49fe786d1b73d0259fcdb7a5929ea3da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor for &lt;code&gt;c&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） &lt;code&gt;c&lt;/code&gt; 出力テンソル</target>
        </trans-unit>
        <trans-unit id="14f81c54913f4111d9238607d8ce61fae4bd2cc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor for &lt;code&gt;inv&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） &lt;code&gt;inv&lt;/code&gt; 出力テンソル</target>
        </trans-unit>
        <trans-unit id="485744ee6c684eac51b20a24c837baecaa778471" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor, must be the same size as &lt;code&gt;input&lt;/code&gt; if provided.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソルは、提供されている場合、 &lt;code&gt;input&lt;/code&gt; と同じサイズである必要があります。</target>
        </trans-unit>
        <trans-unit id="3ebd6deba9d17676dd19fc0c1b7635fe63639228" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor, must be the same size as &lt;code&gt;values&lt;/code&gt; if provided.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソルは、提供されている場合、 &lt;code&gt;values&lt;/code&gt; と同じサイズである必要があります。</target>
        </trans-unit>
        <trans-unit id="964eb34dca913baad53314e60e02dd63488de605" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル。</target>
        </trans-unit>
        <trans-unit id="fa34d018743c897888089d8a79ee1afc57d1450c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor. Ignored if &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル。 &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; および &lt;code&gt;out&lt;/code&gt; = &lt;code&gt;None&lt;/code&gt; の場合は無視されます。</target>
        </trans-unit>
        <trans-unit id="606bdb70440f1c778aed44d5a2f91dc6db6f4c37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output tuple. If &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the elements in the tuple are Tensor, IntTensor, and IntTensor. If &lt;code&gt;get_infos&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the elements in the tuple are Tensor, IntTensor. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;オプションの出力タプル。 &lt;code&gt;get_infos&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、タプルの要素はTensor、IntTensor、およびIntTensorです。 &lt;code&gt;get_infos&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; の場合、タプルの要素はTensor、IntTensorです。デフォルト： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b8efb0d2ac488f256c5bbb46000794a0044cbe5c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the optional destination tensor</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;オプションの宛先テンソル</target>
        </trans-unit>
        <trans-unit id="5381b6d62cf34413978a3eab8706a0bde8040c25" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensors</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル</target>
        </trans-unit>
        <trans-unit id="f069527b4f11758b1081d0eb36c8c58ea9e99e0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (&lt;code&gt;Tensor&lt;/code&gt;, &lt;code&gt;LongTensor&lt;/code&gt;) that can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;出力バッファーとして使用するためにオプションで指定できる（ &lt;code&gt;Tensor&lt;/code&gt; 、 &lt;code&gt;LongTensor&lt;/code&gt; ）の出力タプル</target>
        </trans-unit>
        <trans-unit id="e270a7a389c717e8d14893d5b4ccc1bd8f03693e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, LongTensor) can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;（Tensor、LongTensor）の出力タプルをオプションで指定して、出力バッファーとして使用できます。</target>
        </trans-unit>
        <trans-unit id="1ffc56309f4997d2adc30f856fbd91f3447214a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, LongTensor) that can be optionally given to be used as output buffers</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;（Tensor、LongTensor）の出力タプル。オプションで指定して出力バッファーとして使用できます。</target>
        </trans-unit>
        <trans-unit id="489596f4185eee384c4b282ccfc92c2a9977b741" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of (Tensor, Tensor)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;（Tensor、Tensor）の出力タプル</target>
        </trans-unit>
        <trans-unit id="d316ec30ac2f8ba6b2289f13dd8a11cf7021e946" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tuple of tensors</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;テンソルの出力タプル</target>
        </trans-unit>
        <trans-unit id="7708a683bac6a7fafb6df65ba8e0784d087454b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the result tuple of two output tensors (max, max_indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; 2つの出力テンソルの結果タプル（max、max_indices）</target>
        </trans-unit>
        <trans-unit id="6a9bb0824abf9ea55c48cd268133b1146f437fd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the result tuple of two output tensors (values, indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; 2つの出力テンソル（値、インデックス）の結果タプル</target>
        </trans-unit>
        <trans-unit id="c901d01fb46bbe38d29cc46eda894f717e98cbb5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the tuple of two output tensors (min, min_indices)</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; 2つの出力テンソルのタプル（min、min_indices）</target>
        </trans-unit>
        <trans-unit id="197a7a690b00cbe491d5fbf6fc25fcca33fdffa6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; tuple of &lt;code&gt;Q&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; tensors satisfying &lt;code&gt;input = torch.matmul(Q, R)&lt;/code&gt;. The dimensions of &lt;code&gt;Q&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; are</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;input = torch.matmul(Q, R)&lt;/code&gt; を満たす &lt;code&gt;Q&lt;/code&gt; および &lt;code&gt;R&lt;/code&gt; テンソルのタプル。 &lt;code&gt;Q&lt;/code&gt; と &lt;code&gt;R&lt;/code&gt; の寸法は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="b5510b7d23f0333ea37fb16d363c66ea86b78cc1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The output tensor. Ignored if &lt;code&gt;None&lt;/code&gt;. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル。 &lt;code&gt;None&lt;/code&gt; 場合は無視されます。デフォルト： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="11b25d060a0bb91a3a6bd4eb9234921ee682e10d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor. If &lt;code&gt;out&lt;/code&gt; is used, this operation won&amp;rsquo;t be differentiable.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソル。 &lt;code&gt;out&lt;/code&gt; を使用する場合、この操作は微分可能ではありません。</target>
        </trans-unit>
        <trans-unit id="e4b8ca618e12fa653720e70948c720d1330c823f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;keyword-only&lt;/em&gt;) &amp;ndash; the tensor to store gather result. Its sizes must match those of &lt;code&gt;tensors&lt;/code&gt;, except for &lt;code&gt;dim&lt;/code&gt;, where the size must equal &lt;code&gt;sum(tensor.size(dim) for tensor in tensors)&lt;/code&gt;. Can be on CPU or CUDA.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;キーワードのみ&lt;/em&gt;）&amp;ndash;収集結果を格納するテンソル。そのサイズは、サイズが &lt;code&gt;sum(tensor.size(dim) for tensor in tensors)&lt;/code&gt; と等しくなければならない &lt;code&gt;dim&lt;/code&gt; を除いて、 &lt;code&gt;tensors&lt;/code&gt; サイズと一致する必要があります。CPUまたはCUDA上に置くことができます。</target>
        </trans-unit>
        <trans-unit id="d7bbe5a42e951041522cf9dd2a446fdcc33325b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; optional output tuple.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;em&gt;（&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;）&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;オプションの出力タプル。</target>
        </trans-unit>
        <trans-unit id="209dfca5f1c305b375517af898ffea87b3b235b7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the output tensor containing indices</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;em&gt;LongTensor &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;インデックスを含む出力テンソル</target>
        </trans-unit>
        <trans-unit id="32fca21fc6c66cdf66c39e78522f6ed5d3485149" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;Sequence&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;keyword-only&lt;/em&gt;) &amp;ndash; the GPU tensors to store output results.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;em&gt;Sequence &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;キーワードのみ&lt;/em&gt;）&amp;ndash;出力結果を格納するGPUテンソル。</target>
        </trans-unit>
        <trans-unit id="d075f0b19db2420856dfc3cd7bd9e5e606444306" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out&lt;/strong&gt; (&lt;em&gt;Sequence&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;keyword-only&lt;/em&gt;) &amp;ndash; the GPU tensors to store output results. Sizes of these tensors must match that of &lt;code&gt;tensor&lt;/code&gt;, except for &lt;code&gt;dim&lt;/code&gt;, where the total size must sum to &lt;code&gt;tensor.size(dim)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;out&lt;/strong&gt;（&lt;em&gt;Sequence &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;キーワードのみ&lt;/em&gt;）&amp;ndash;出力結果を格納するGPUテンソル。これらのテンソルのサイズは、合計サイズが &lt;code&gt;tensor.size(dim)&lt;/code&gt; になる必要がある &lt;code&gt;dim&lt;/code&gt; を除いて、 &lt;code&gt;tensor&lt;/code&gt; サイズと一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="fbf9c4879b754e5485d4adfd6cf789f5297488df" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_channels&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of channels produced by the convolution</source>
          <target state="translated">&lt;strong&gt;out_channels&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;畳み込みによって生成されたチャネルの数</target>
        </trans-unit>
        <trans-unit id="cb2ef6ac4d28b8ca3c953e0855d6ae16d965ac4f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_features&lt;/strong&gt; &amp;ndash; size of each output sample</source>
          <target state="translated">&lt;strong&gt;out_features&lt;/strong&gt; &amp;ndash;各出力サンプルのサイズ</target>
        </trans-unit>
        <trans-unit id="d7de66fc4b74ea02276b09800cfd2ae532e3bc76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;out_int32&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicate the output data type. torch.int32 if True, torch.int64 otherwise. Default value is False, i.e. default output data type is torch.int64.</source>
          <target state="translated">&lt;strong&gt;out_int32&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力データ型を示します。Trueの場合はtorch.int32、それ以外の場合はtorch.int64。デフォルト値はFalseです。つまり、デフォルトの出力データ型はtorch.int64です。</target>
        </trans-unit>
        <trans-unit id="d4c83d604511fcf859161efc385f906819b96864" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Output tensor.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力テンソル。</target>
        </trans-unit>
        <trans-unit id="54e1f470236ead45903663caa70f84c32cb8d0d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the output list of unique scalar elements.</source>
          <target state="translated">&lt;strong&gt;output&lt;/strong&gt;（&lt;em&gt;Tensor&lt;/em&gt;）：一意のスカラー要素の出力リスト。</target>
        </trans-unit>
        <trans-unit id="8042cc420b9244c9f4146afa6f88da5858ea8729" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; is a Tensor of size &lt;code&gt;N&lt;/code&gt; containing computed target log probabilities for each example</source>
          <target state="translated">&lt;strong&gt;出力&lt;/strong&gt;は、各例の計算されたターゲットログ確率を含むサイズ &lt;code&gt;N&lt;/code&gt; のテンソルです。</target>
        </trans-unit>
        <trans-unit id="ee40fd7a70a6bf8cc86c927f28159d12e52c4fcd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features (&lt;code&gt;h_t&lt;/code&gt;) from the last layer of the RNN, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状の&lt;strong&gt;出力&lt;/strong&gt; &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; ：各 &lt;code&gt;t&lt;/code&gt; について、RNNの最後のレイヤーからの出力特徴（ &lt;code&gt;h_t&lt;/code&gt; ）を含むテンソル。&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; &lt;/a&gt;が入力として指定されている場合、出力もパックされたシーケンスになります。</target>
        </trans-unit>
        <trans-unit id="1dc2c70a675e8e584ab85a82d21f959742d0aaf7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features &lt;code&gt;(h_t)&lt;/code&gt; from the last layer of the LSTM, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状の&lt;strong&gt;出力&lt;/strong&gt; &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; ：各 &lt;code&gt;t&lt;/code&gt; について、LSTMの最後のレイヤーからの出力特徴 &lt;code&gt;(h_t)&lt;/code&gt; を含むテンソル。&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; &lt;/a&gt;が入力として指定されている場合、出力もパックされたシーケンスになります。</target>
        </trans-unit>
        <trans-unit id="44bac24d4e0073747a76bcde5580e1630789e3cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output&lt;/strong&gt; of shape &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt;: tensor containing the output features h_t from the last layer of the GRU, for each &lt;code&gt;t&lt;/code&gt;. If a &lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt;&lt;/a&gt; has been given as the input, the output will also be a packed sequence. For the unpacked case, the directions can be separated using &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt;, with forward and backward being direction &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; respectively.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;形状の&lt;strong&gt;出力&lt;/strong&gt; &lt;code&gt;(seq_len, batch, num_directions * hidden_size)&lt;/code&gt; ：各 &lt;code&gt;t&lt;/code&gt; について、GRUの最後のレイヤーからの出力特徴h_tを含むテンソル。&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;torch.nn.utils.rnn.PackedSequence&lt;/code&gt; &lt;/a&gt;が入力として指定されている場合、出力もパックされたシーケンスになります。解凍された場合、方向は &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt; を使用して分離でき、順方向と逆方向はそれぞれ方向 &lt;code&gt;0&lt;/code&gt; と &lt;code&gt;1&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="255f1d7d987dadd4223a022923279a9324511b84" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; Device location of output for single-device CUDA modules. For multi-device modules and CPU modules, it must be &lt;code&gt;None&lt;/code&gt;, and the module itself dictates the output location. (default: &lt;code&gt;device_ids[0]&lt;/code&gt; for single-device modules)</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;）&amp;ndash;単一デバイスのCUDAモジュールの出力のデバイス位置。マルチデバイスモジュールおよびCPUモジュールの場合、 &lt;code&gt;None&lt;/code&gt; である必要があり、モジュール自体が出力場所を決定します。（デフォルト：単一デバイスモジュールの場合は &lt;code&gt;device_ids[0]&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="8b601fc16628c28a84e5091b7164b5ba737b9327" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; device location of output (default: device_ids[0])</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;）&amp;ndash;出力のデバイスの場所（デフォルト：device_ids [0]）</target>
        </trans-unit>
        <trans-unit id="2e98efe0558eb0f88016b3110b664c00e2dd175e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_device&lt;/strong&gt; (&lt;em&gt;list of python:int&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.device&lt;/a&gt;) &amp;ndash; GPU location of the output Use -1 to indicate the CPU. (default: device_ids[0])</source>
          <target state="translated">&lt;strong&gt;output_device&lt;/strong&gt;（&lt;em&gt;python：int&lt;/em&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;torch.deviceのリスト&lt;/a&gt;）&amp;ndash;出力のGPUの場所-1を使用してCPUを示します。（デフォルト：device_ids [0]）</target>
        </trans-unit>
        <trans-unit id="cd583af9b2638b2ed135367bf25e08abf6423093" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_names&lt;/strong&gt; (&lt;em&gt;list of strings&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default empty list&lt;/em&gt;) &amp;ndash; names to assign to the output nodes of the graph, in order</source>
          <target state="translated">&lt;strong&gt;output_names&lt;/strong&gt;（&lt;em&gt;文字列のリスト&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;デフォルトの空のリスト&lt;/em&gt;）&amp;ndash;グラフの出力ノードに順番に割り当てる名前</target>
        </trans-unit>
        <trans-unit id="f491b241ade48cc378ec5122b4841e99e9754e6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padH, out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash;出力形状の各寸法の片側に追加されたサイズ。単一の数値またはタプル &lt;code&gt;(out_padH, out_padW)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="734ccdbb1e5796890980cb4649cd409e247b53a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padT, out_padH, out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash;出力形状の各寸法の片側に追加されたサイズ。単一の数値またはタプル &lt;code&gt;(out_padT, out_padH, out_padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="658b917621e239d640e2b03f43964b708d2c55ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash; additional size added to one side of each dimension in the output shape. Can be a single number or a tuple &lt;code&gt;(out_padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt; &amp;ndash;出力形状の各寸法の片側に追加されたサイズ。単一の数値またはタプル &lt;code&gt;(out_padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="f16b08ff1eb258821023064b32148058b9079ce3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Additional size added to one side of each dimension in the output shape. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力形状の各次元の片側に追加されたサイズ。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="a4a46c3866c2c1510433f2a4903dbbbe5fde896f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Additional size added to one side of the output shape. Default: 0</source>
          <target state="translated">&lt;strong&gt;output_padding&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力形状の片側に追加のサイズが追加されました。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="2d697a1fa9ed20cfea2be8860a73c26c65201a48" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_ratio&lt;/strong&gt; &amp;ndash; If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</source>
          <target state="translated">&lt;strong&gt;output_ratio&lt;/strong&gt; &amp;ndash;入力サイズの比率として出力サイズを設定したい場合は、このオプションを指定できます。これは、（0、1）の範囲の数値またはタプルである必要があります</target>
        </trans-unit>
        <trans-unit id="d139558d8497f0a45efe69a095d8ca0b00a79bb1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer or double-integer tuple)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash;ターゲット出力サイズ（単一整数または二重整数タプル）</target>
        </trans-unit>
        <trans-unit id="9aef33d381ddbb64a977de5875d434c15130e1b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer or triple-integer tuple)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash;ターゲット出力サイズ（単一整数またはトリプル整数タプル）</target>
        </trans-unit>
        <trans-unit id="d7553c6c16b6821129bbbbffa2b2ab7a88d48c73" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size (single integer)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash;ターゲット出力サイズ（単一整数）</target>
        </trans-unit>
        <trans-unit id="5b92d42ba70c23bb2437e683e87b4a32323b7656" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size H</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash;ターゲット出力サイズH</target>
        </trans-unit>
        <trans-unit id="72273a2ad460dccb1f289d60806321a98b8260ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the form D x H x W. Can be a tuple (D, H, W) or a single number D for a cube D x D x D. D, H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; D x H x W形式のターゲット出力サイズ。タプル（D、H、W）またはキューブD x D x Dの単一の数値Dにすることができます。D、H、およびWは &lt;code&gt;int&lt;/code&gt; のいずれかです。、または &lt;code&gt;None&lt;/code&gt; は、サイズが入力のサイズと同じになることを意味します。</target>
        </trans-unit>
        <trans-unit id="ffbcc66c67e1dc1781d70637ab1a7011a5a86b0c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form &lt;code&gt;oH x oW&lt;/code&gt;. Can be a tuple &lt;code&gt;(oH, oW)&lt;/code&gt; or a single number oH for a square image &lt;code&gt;oH x oH&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; -フォームの画像の目標出力サイズは &lt;code&gt;oH x oW&lt;/code&gt; 。タプル &lt;code&gt;(oH, oW)&lt;/code&gt; または正方形の画像 &lt;code&gt;oH x oH&lt;/code&gt; 単一の数値oHにすることができます</target>
        </trans-unit>
        <trans-unit id="2b13fdfcd89a724ec673724cf570c1569f4c6c2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form D x H x W. Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; D x H x W形式の画像のターゲット出力サイズ。タプル（D、H、W）またはキューブD x D x Dの単一のDにすることができます。D、H、およびWは次のいずれかになります。 &lt;code&gt;int&lt;/code&gt; 、または &lt;code&gt;None&lt;/code&gt; のサイズを入力手段と同じであろう。</target>
        </trans-unit>
        <trans-unit id="3da4b11e13dd7cb4717e94a2c74219954c4fc38b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; &amp;ndash; the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. H and W can be either a &lt;code&gt;int&lt;/code&gt;, or &lt;code&gt;None&lt;/code&gt; which means the size will be the same as that of the input.</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt; - HはW.タプル（H、W）又は正方形の画像Hのための単一のHすることができxはフォームの画像の目標出力サイズはH HとWはいずれであってもよいxは &lt;code&gt;int&lt;/code&gt; 、または &lt;code&gt;None&lt;/code&gt; 手段サイズは入力のサイズと同じになります。</target>
        </trans-unit>
        <trans-unit id="94b03ab4769532cfd586a9f93960f9dbdb397633" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the shape of the spatial dimensions of the output (i.e., &lt;code&gt;output.sizes()[2:]&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;output_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;出力の空間次元の形状（つまり、 &lt;code&gt;output.sizes()[2:]&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="a3faf432bc4aa5f657bed43eb96ddf6068193374" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to be gathered one per rank.</source>
          <target state="translated">&lt;strong&gt;output_tensor_list&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;ランクごとに1つずつ収集されるテンソルのリスト。</target>
        </trans-unit>
        <trans-unit id="859379055368818b2ccae1f2f63e2ee0a75004d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;output_tensor_list&lt;/strong&gt;（&lt;em&gt;リスト&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="0978f0a55922d996ca9a0fd7211f8e99295fc05a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;output_tensor_lists&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;output_tensor_lists&lt;/strong&gt;（&lt;em&gt;リスト&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;リスト&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="088213e8c0ac027cdebbe4c6a7f1f41158f63b10" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;outputs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;iterable of Tensors&lt;/em&gt;) &amp;ndash; Outputs to scale.</source>
          <target state="translated">&lt;strong&gt;出力&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;テンソルの&lt;em&gt;反復可能&lt;/em&gt;）&amp;ndash;&lt;em&gt;縮尺どおりの&lt;/em&gt;出力。</target>
        </trans-unit>
        <trans-unit id="a07f83b85bbf21108c57977c33c5fd41bf4b861e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;outputs&lt;/strong&gt; (&lt;em&gt;sequence of Tensor&lt;/em&gt;) &amp;ndash; outputs of the differentiated function.</source>
          <target state="translated">&lt;strong&gt;出力&lt;/strong&gt;（&lt;em&gt;テンソルのシーケンス&lt;/em&gt;）&amp;ndash;微分関数の出力。</target>
        </trans-unit>
        <trans-unit id="79584f8c8990b1c876dbadf460c2b02b547a0a20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; dropout probability of a channel to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash;チャネルがゼロになる確率。デフォルト：0.5</target>
        </trans-unit>
        <trans-unit id="bd6aaa726614b383781b34c1c9759a061af7eef1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; p value for the p-norm distance to calculate between each vector pair</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash;各ベクトルペア間で計算するpノルム距離のp値</target>
        </trans-unit>
        <trans-unit id="60e05b10c2aa191fd0f512b35139ad3f5166ee85" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; probability of a channel to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash;チャネルがゼロになる確率。デフォルト：0.5</target>
        </trans-unit>
        <trans-unit id="055d3b3dc7e2825662e52c7899ba890592b92a5b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; &amp;ndash; probability of an element to be zeroed. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt; &amp;ndash;要素がゼロになる確率。デフォルト：0.5</target>
        </trans-unit>
        <trans-unit id="ed3ed17d9e98cf2b21b9f8991f3865f41f4dc9da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;Distribution&lt;/a&gt;) &amp;ndash; A &lt;code&gt;Distribution&lt;/code&gt; object.</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;分布&lt;/a&gt;）&amp;ndash; &lt;code&gt;Distribution&lt;/code&gt; オブジェクト。</target>
        </trans-unit>
        <trans-unit id="fc61e4898026558df455ea228711212cc5f6bf2e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; probability of an element to be dropped. Default: 0.5</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;要素がドロップされる確率。デフォルト：0.5</target>
        </trans-unit>
        <trans-unit id="be2c8a91ba679dbe9334ded6489b8da7b91810a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the exponent value in the norm formulation. Default: 2</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;ノルム定式化の指数値。デフォルト：2</target>
        </trans-unit>
        <trans-unit id="8ba0723e1b20dae5871248bdf08777de23e09a35" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the power for the norm computation</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;ノルム計算のパワー</target>
        </trans-unit>
        <trans-unit id="e35faf459e929b30d01b57525c4b3b7ff20ddb4b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; probability of an element to be zero-ed.</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;要素がゼロになる確率。</target>
        </trans-unit>
        <trans-unit id="c610f90195dd6efe31a7edae7cac213bdfe97ff2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; probability of an element to be zeroed.</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;要素がゼロになる確率。</target>
        </trans-unit>
        <trans-unit id="b58fa037642d7f64f2e095fa9889db70e6bb817b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the norm to be computed</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;計算される基準</target>
        </trans-unit>
        <trans-unit id="d02eaf36455552ed32ca3c35a59e5ff0754e7bc2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of dimensions</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;次元の数</target>
        </trans-unit>
        <trans-unit id="94c331619b61acdfddc0975afbf5ab2cd627bfa1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;-inf&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'fro'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;'nuc'&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;inf &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;-inf &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;'fro' &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;'nuc' &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="5885620cdb9d6e6007a7bfaa1257ea3fcbf35862" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Has a default value of</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;デフォルト値は</target>
        </trans-unit>
        <trans-unit id="eca1775966b053a849d07171e8c7fca4bc68e061" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The norm degree for pairwise distance. Default:</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ペアワイズ距離の標準度。デフォルト：</target>
        </trans-unit>
        <trans-unit id="fd42949d40f645424a960ea51a5b0155e9547aae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;p&lt;/strong&gt; (&lt;em&gt;real&lt;/em&gt;) &amp;ndash; the norm degree. Default: 2</source>
          <target state="translated">&lt;strong&gt;p&lt;/strong&gt;（&lt;em&gt;実数&lt;/em&gt;）&amp;ndash;標準度。デフォルト：2</target>
        </trans-unit>
        <trans-unit id="2a7801e112cc1d15948e989881ab27456d36b8d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; m-elements tuple, where</source>
          <target state="translated">&lt;strong&gt;pad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;）&amp;ndash; m要素タプル、ここで</target>
        </trans-unit>
        <trans-unit id="f2e07cdbfd62345d8b7cd60d6940e8a0fbab4ae2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pad_mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the padding method used when &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;. Default: &lt;code&gt;&quot;reflect&quot;&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;pad_mode&lt;/strong&gt;（&lt;em&gt;ストリング&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） -際に使用されるコントロールパディング法 &lt;code&gt;center&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 。デフォルト： &lt;code&gt;&quot;reflect&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="8a9ca37fdb632d5816c23727858cdabb73430e65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; ゼロパディングは、入力の各次元の両側に追加されます。単一の数値またはタプル &lt;code&gt;(padH, padW)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="7562e0bf8b2fbf8f0612a3b04ddb3e0c77c8e2de" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; ゼロパディングは、入力の各次元の両側に追加されます。単一の数値またはタプル &lt;code&gt;(padT, padH, padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="448222bb6d7290e9d682e5dc18b926f4f3f2a062" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; ゼロパディングは、入力の各次元の両側に追加されます。単一の数値またはタプル &lt;code&gt;(padW,)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="c82509396ecabb06e2ab93e27c0d96e3494c85e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; Implicit negative infinity padding to be added on both sides, must be &amp;gt;= 0 and &amp;lt;= kernel_size / 2.</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;両側に追加される暗黙の負の無限大パディング。&amp;gt; = 0かつ&amp;lt;= kernel_size / 2である必要があります。</target>
        </trans-unit>
        <trans-unit id="035775c3f31b9fdf2b9087a4ab72feb97800345a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a one-element tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側の暗黙的な&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値または1つの要素のタプル &lt;code&gt;(padW,)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="eb115b29f2d4e8986dbb7361d1bde22d523aa2fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padD, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側の暗黙的な&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padD, padH, padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="c77720bd3be235f43a31a948921e71d65c1c2909" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側の暗黙的な&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padH, padW)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="3615da94c4b802be1f5c636b261921ec43ca9b61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側の暗黙的な&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padT, padH, padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="0da72c244db3c1c00f8e0e0ec331cec0af62c835" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側の暗黙的な&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padW,)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="d76aaa6cddce6d9de011fab349f55959decabc91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero padding to be added on all three sides</source>
          <target state="translated">&lt;strong&gt;パディング&amp;ndash;3&lt;/strong&gt;つの側面すべてに追加される暗黙のゼロパディング</target>
        </trans-unit>
        <trans-unit id="c6eb557a7d88c437df862c9c9d77547955ec2e9c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero padding to be added on both sides</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;両側に追加される暗黙のゼロパディング</target>
        </trans-unit>
        <trans-unit id="5b5113170b2a3f7e706888c5ccdb6b94ee870598" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padH, padW)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側に暗黙のゼロ&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padH, padW)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="85e6b037c865499fe258c3d24a4079141415f86f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padT, padH, padW)&lt;/code&gt;, Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側に暗黙のゼロ&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padT, padH, padW)&lt;/code&gt; にすることができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="fe955794273a21194f7067e1ae48e4951e5e799b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; &amp;ndash; implicit zero paddings on both sides of the input. Can be a single number or a tuple &lt;code&gt;(padW,)&lt;/code&gt;. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;&amp;ndash;入力の両側に暗黙のゼロ&lt;strong&gt;パディング&lt;/strong&gt;。単一の数値またはタプル &lt;code&gt;(padW,)&lt;/code&gt; することができます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="1772edf760a9f7e7c4c981c7145fff686e883581" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Padding that was added to the input</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;入力に追加されたパディング</target>
        </trans-unit>
        <trans-unit id="9378d98a5c97c1044f08880972e01ac3393dbb72" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of each dimension in the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; ゼロパディングは、入力の各次元の両側に追加されます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="6bab43419d41e24875998f0b0d4b8567ba1bd7b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; zero-padding will be added to both sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;dilation * (kernel_size - 1) - padding&lt;/code&gt; ゼロパディングが入力の両側に追加されます。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="198506b9fb9056c9654540b4487b630e49f578c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Zero-padding added to all three sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;入力の3つの側面すべてにゼロパディングが追加されました。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="71ff1d7f40410d7f42df028ec0f884ae0b40ef54" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Zero-padding added to both sides of the input. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;入力の両側にゼロパディングが追加されました。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="acde30c2a2360aeb1bb9367ebe202c70986d7598" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; implicit zero padding to be added on both sides of input. Default: 0</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;入力の両側に追加される暗黙のゼロパディング。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="661ddd64fdf787533b21bb87f5850bcd7ca62102" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 2-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;パディングのサイズ。が &lt;code&gt;int&lt;/code&gt; の場合、すべての境界で同じパディングを使用します。2 &lt;code&gt;tuple&lt;/code&gt; 場合、（</target>
        </trans-unit>
        <trans-unit id="f8c452117fc928955dd2bd55760ff8548c5d6e4c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 4-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;パディングのサイズ。が &lt;code&gt;int&lt;/code&gt; の場合、すべての境界で同じパディングを使用します。4 &lt;code&gt;tuple&lt;/code&gt; 場合、（</target>
        </trans-unit>
        <trans-unit id="0c871849a3c90385e2d2dfb4fade7f685e558919" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in all boundaries. If a 6-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;パディングのサイズ。が &lt;code&gt;int&lt;/code&gt; の場合、すべての境界で同じパディングを使用します。6 &lt;code&gt;tuple&lt;/code&gt; 場合、（</target>
        </trans-unit>
        <trans-unit id="de0fe1f500b814cb0dab544c02e18d3f627fc075" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the size of the padding. If is &lt;code&gt;int&lt;/code&gt;, uses the same padding in both boundaries. If a 2-&lt;code&gt;tuple&lt;/code&gt;, uses (</source>
          <target state="translated">&lt;strong&gt;パディング&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;パディングのサイズ。が &lt;code&gt;int&lt;/code&gt; の場合、両方の境界で同じパディングを使用します。2 &lt;code&gt;tuple&lt;/code&gt; 場合、（</target>
        </trans-unit>
        <trans-unit id="9401caef7f5afbf352224bad95b3fe76778191fe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_idx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, pads the output with the embedding vector at &lt;code&gt;padding_idx&lt;/code&gt; (initialized to zeros) whenever it encounters the index.</source>
          <target state="translated">&lt;strong&gt;padding_idx&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;指定されている場合、インデックスに遭遇するたびに、出力を &lt;code&gt;padding_idx&lt;/code&gt; （ゼロに初期化）の埋め込みベクトルでパディングします。</target>
        </trans-unit>
        <trans-unit id="9ada542978419d7c3da9e87c076d2586fc884e6e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_idx&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;padding_idx&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;モジュール初期化のドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="3943fa317748711d3f74fb28e963a67dc6ae1023" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; &amp;ndash; the padding mode to use. Only &amp;ldquo;zeros&amp;rdquo; is supported for quantized convolution at the moment. Default: &amp;ldquo;zeros&amp;rdquo;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt; &amp;ndash;使用するパディングモード。現在、量子化された畳み込みでは「ゼロ」のみがサポートされています。デフォルト：「ゼロ」</target>
        </trans-unit>
        <trans-unit id="d48e37505fe88a204a4698afd9bd53c6178eb622" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; padding mode for outside grid values &lt;code&gt;'zeros'&lt;/code&gt; | &lt;code&gt;'border'&lt;/code&gt; | &lt;code&gt;'reflection'&lt;/code&gt;. Default: &lt;code&gt;'zeros'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;外側のグリッド値 &lt;code&gt;'zeros'&lt;/code&gt; パディングモード'ゼロ' | &lt;code&gt;'border'&lt;/code&gt; | &lt;code&gt;'reflection'&lt;/code&gt; 。デフォルト： &lt;code&gt;'zeros'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4afe9a05f840c246091966bf0c12fea8eff4ade1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_mode&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;'zeros'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, &lt;code&gt;'replicate'&lt;/code&gt; or &lt;code&gt;'circular'&lt;/code&gt;. Default: &lt;code&gt;'zeros'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;padding_mode&lt;/strong&gt;（&lt;em&gt;string &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;'zeros'&lt;/code&gt; 、 &lt;code&gt;'reflect'&lt;/code&gt; 、 &lt;code&gt;'replicate'&lt;/code&gt; または &lt;code&gt;'circular'&lt;/code&gt; 。デフォルト： &lt;code&gt;'zeros'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1c8930299bc472b0bf01b43e4876b43bc57b0afd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; value for padded elements. Default: 0.</source>
          <target state="translated">&lt;strong&gt;padding_value&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;パディングされた要素の値。デフォルト：0。</target>
        </trans-unit>
        <trans-unit id="e46a4080234de5b81dc28aa5cf6494e583b2dfc4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;padding_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; values for padded elements.</source>
          <target state="translated">&lt;strong&gt;padding_value&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;パディングされた要素の値。</target>
        </trans-unit>
        <trans-unit id="1e944f55958d7c17e7297fead1ace3158d4a22b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;param&lt;/strong&gt; &amp;ndash; optional parameter for the non-linear function</source>
          <target state="translated">&lt;strong&gt;param&lt;/strong&gt; &amp;ndash;非線形関数のオプションのパラメーター</target>
        </trans-unit>
        <trans-unit id="2a439f504eecae5ec1487c4ee52295b7169b16a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;param&lt;/strong&gt; (&lt;a href=&quot;torch.nn.parameter.parameter#torch.nn.parameter.Parameter&quot;&gt;Parameter&lt;/a&gt;) &amp;ndash; parameter to be added to the module.</source>
          <target state="translated">&lt;strong&gt;param&lt;/strong&gt;（&lt;a href=&quot;torch.nn.parameter.parameter#torch.nn.parameter.Parameter&quot;&gt;パラメーター&lt;/a&gt;）&amp;ndash;モジュールに追加されるパラメーター。</target>
        </trans-unit>
        <trans-unit id="a6e15f4d36c2b934c8b9075fb6dc299572c2c953" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;param_group&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Specifies what Tensors should be optimized along with group</source>
          <target state="translated">&lt;strong&gt;param_group&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;グループとともに最適化するテンソルを指定します</target>
        </trans-unit>
        <trans-unit id="f75a00d4efb185ff63b6a63af312bfa294122453" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameter&lt;/strong&gt; (&lt;em&gt;nn.Parameter&lt;/em&gt;) &amp;ndash; parameter to append</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;nn.Parameter&lt;/em&gt;）&amp;ndash;追加するパラメータ</target>
        </trans-unit>
        <trans-unit id="489497c61c6c4ca41d36025fee2d4513e38423ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable of&lt;/em&gt;&lt;em&gt; (&lt;/em&gt;&lt;em&gt;module&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;name&lt;/em&gt;&lt;em&gt;) &lt;/em&gt;&lt;em&gt;tuples&lt;/em&gt;) &amp;ndash; parameters of the model to prune in a global fashion, i.e. by aggregating all weights prior to deciding which ones to prune. module must be of type &lt;code&gt;nn.Module&lt;/code&gt;, and name must be a string.</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;の反復処理可能&lt;/em&gt;&lt;em&gt;（&lt;/em&gt;&lt;em&gt;モジュール&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;名前&lt;/em&gt;&lt;em&gt;）&lt;/em&gt;&lt;em&gt;のタプル&lt;/em&gt;） -すなわち前プルーンにどれを決定するすべての重みを集約することにより、世界のファッションでプルーンのモデルのパラメータ、。moduleは &lt;code&gt;nn.Module&lt;/code&gt; タイプである必要があり、nameは文字列である必要があります。</target>
        </trans-unit>
        <trans-unit id="d320f6d02ed2f210bc2bb94d849c5a4a0333a948" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; an iterable of Tensors or a single Tensor that will have gradients normalized</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;のIterable &lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -勾配を有することになるテンソルの反復可能な又は単一テンソルは、正規化されました</target>
        </trans-unit>
        <trans-unit id="088332766231b5fb1e917d8a22e9be51803d3339" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; an iterator of Tensors that are the parameters of a model.</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;モデルのパラメーターであるテンソルのイテレーター。</target>
        </trans-unit>
        <trans-unit id="22d3c60c713a7260e180dbfeec107c5a3c8c8e37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; a mapping (dictionary) from string to &lt;code&gt;Parameter&lt;/code&gt;, or an iterable of key-value pairs of type (string, &lt;code&gt;Parameter&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;parameters&lt;/strong&gt;（&lt;em&gt;iterable&lt;/em&gt;）&amp;ndash;文字列から &lt;code&gt;Parameter&lt;/code&gt; へのマッピング（辞書）、またはタイプ（string、 &lt;code&gt;Parameter&lt;/code&gt; ）のキーと値のペアの反復可能</target>
        </trans-unit>
        <trans-unit id="b029593b0723b3ed9d1778d6c527b9cc13f2e3dd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of parameters to append</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;反復可能&lt;/em&gt;）&amp;ndash;追加するパラメータの反復可能</target>
        </trans-unit>
        <trans-unit id="b756d03d964186ac93672f10364095cbcb790305" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a mapping (dictionary) of (string : &lt;code&gt;Parameter&lt;/code&gt;) or an iterable of key-value pairs of type (string, &lt;code&gt;Parameter&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;反復可能&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;（文字列： &lt;code&gt;Parameter&lt;/code&gt; ）のマッピング（辞書）またはタイプ（文字列、 &lt;code&gt;Parameter&lt;/code&gt; ）のキーと値のペアの反復可能</target>
        </trans-unit>
        <trans-unit id="7a1a7adbc39a4daf48449acfbbb118da27774d19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parameters&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of &lt;code&gt;Parameter&lt;/code&gt; to add</source>
          <target state="translated">&lt;strong&gt;パラメータ&lt;/strong&gt;（&lt;em&gt;反復可能&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;追加する &lt;code&gt;Parameter&lt;/code&gt; 反復可能</target>
        </trans-unit>
        <trans-unit id="115933d529771be89fc68336db02fcf00bb79520" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;params&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; an iterable of &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; s or &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/a&gt; s. Specifies what Tensors should be optimized.</source>
          <target state="translated">&lt;strong&gt;params&lt;/strong&gt;（&lt;em&gt;iterable&lt;/em&gt;）&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt; &lt;code&gt;dict&lt;/code&gt; &lt;/a&gt;の反復可能。最適化するテンソルを指定します。</target>
        </trans-unit>
        <trans-unit id="01f57d38e895cf47e995315469bf1de4745eabc0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;params&lt;/strong&gt; (&lt;em&gt;iterable&lt;/em&gt;) &amp;ndash; iterable of parameters to optimize or dicts defining parameter groups</source>
          <target state="translated">&lt;strong&gt;params&lt;/strong&gt;（&lt;em&gt;iterable&lt;/em&gt;）&amp;ndash;パラメータグループの定義を最適化または指示するためのパラメータの反復可能</target>
        </trans-unit>
        <trans-unit id="88c32fc1811dc3014215ab77e8ab52e5f171a72c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;params_rref&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;RRef&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; list of RRefs to local or remote parameters to optimize.</source>
          <target state="translated">&lt;strong&gt;params_rref&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;RRef &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;最適化するローカルまたはリモートパラメータへのRRefのリスト。</target>
        </trans-unit>
        <trans-unit id="aa7a53279c1837507c2fe5c94e103220a1d49e82" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;parts&lt;/strong&gt; (list of &lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt;&lt;code&gt;Transform&lt;/code&gt;&lt;/a&gt;) &amp;ndash; A list of transforms to compose.</source>
          <target state="translated">&lt;strong&gt;部品&lt;/strong&gt;（のリスト&lt;a href=&quot;#torch.distributions.transforms.Transform&quot;&gt; &lt;code&gt;Transform&lt;/code&gt; &lt;/a&gt;） -構成するトランスフォームのリスト。</target>
        </trans-unit>
        <trans-unit id="bed12dc0de75cc0eb2c41cb6816108cf95e6ea9a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;path&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; Path where the trace will be written.</source>
          <target state="translated">&lt;strong&gt;path&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;トレースが書き込まれるパス。</target>
        </trans-unit>
        <trans-unit id="f3bc0f1d455d09bb05991fbe5db3a4cb4d74742b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;path&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; path to nvprof trace</source>
          <target state="translated">&lt;strong&gt;パス&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;nvprofトレースへのパス</target>
        </trans-unit>
        <trans-unit id="05386d14aa6eff4c85da6a56408e676b2a826d6f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;patience&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of epochs with no improvement after which learning rate will be reduced. For example, if &lt;code&gt;patience = 2&lt;/code&gt;, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn&amp;rsquo;t improved then. Default: 10.</source>
          <target state="translated">&lt;strong&gt;忍耐&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;改善が見られず、その後学習率が低下するエポックの数。たとえば、 &lt;code&gt;patience = 2&lt;/code&gt; 場合、最初の2エポックは改善されずに無視され、損失がまだ改善されていない場合は3番目のエポック以降のLRのみが減少します。デフォルト：10。</target>
        </trans-unit>
        <trans-unit id="acf92cc771b32560798f3f952f36649dd693efa9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pct_start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; The percentage of the cycle (in number of steps) spent increasing the learning rate. Default: 0.3</source>
          <target state="translated">&lt;strong&gt;pct_start&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;学習率の増加に費やされたサイクルのパーセンテージ（ステップ数）。デフォルト：0.3</target>
        </trans-unit>
        <trans-unit id="c73980a2dbe97d6cc5f31cd9778490dcbce3fd01" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;per_sample_weights&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a tensor of float / double weights, or None to indicate all weights should be taken to be 1. If specified, &lt;code&gt;per_sample_weights&lt;/code&gt; must have exactly the same shape as input and is treated as having the same &lt;code&gt;offsets&lt;/code&gt;, if those are not None.</source>
          <target state="translated">&lt;strong&gt;per_sample_weights&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; float / double weightsのテンソル、またはすべての重みを1と &lt;code&gt;per_sample_weights&lt;/code&gt; 必要があることを示すNone。指定した場合、per_sample_weightsは入力とまったく同じ形状である必要があり、同じ &lt;code&gt;offsets&lt;/code&gt; を持つものとして扱われます。それらはNoneではありません。</target>
        </trans-unit>
        <trans-unit id="1e8c363177f0382a2ca52911b44cd26dbb02b01b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;periodic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, returns a periodic window suitable for use in spectral analysis. If False, returns a symmetric window suitable for use in filter design.</source>
          <target state="translated">&lt;strong&gt;周期的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; Trueの場合、スペクトル分析での使用に適した周期的ウィンドウを返します。Falseの場合、フィルター設計での使用に適した対称ウィンドウを返します。</target>
        </trans-unit>
        <trans-unit id="9dc935030f617a99daedb64a9e2141255a78596a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;periodic&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If True, returns a window to be used as periodic function. If False, return a symmetric window.</source>
          <target state="translated">&lt;strong&gt;周期的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; Trueの場合、周期関数として使用されるウィンドウを返します。Falseの場合、対称ウィンドウを返します。</target>
        </trans-unit>
        <trans-unit id="10ac8ca2d66e3e1712e04c036b9bf70de5e5b9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;perserved_methods&lt;/strong&gt; &amp;ndash; A list of methods that needed to be preserved when freeze_module pass is invoked</source>
          <target state="translated">&lt;strong&gt;perserved_methods&lt;/strong&gt; &amp;ndash;freeze_moduleパスが呼び出されたときに保持する必要のあるメソッドのリスト</target>
        </trans-unit>
        <trans-unit id="27ea671e2a5ede173ebe44a6fbf6a5dfc8e07a55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;永続的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;バッファがこのモジュールの&lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; の&lt;/a&gt;一部であるかどうか。</target>
        </trans-unit>
        <trans-unit id="00ab29ea4c85832585125194a8d3ce432d70b86b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;永続的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;バッファがこのモジュールの&lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; の&lt;/a&gt;一部であるかどうか。</target>
        </trans-unit>
        <trans-unit id="d9ed1cdbc115cc96411a0714a99ba4f42fb9ffaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;永続的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;バッファがこのモジュールの&lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; の&lt;/a&gt;一部であるかどうか。</target>
        </trans-unit>
        <trans-unit id="730eade83c492cb9c9d61b0d4e948adf920f85d5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether the buffer is part of this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;永続的&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;バッファがこのモジュールの&lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; の&lt;/a&gt;一部であるかどうか。</target>
        </trans-unit>
        <trans-unit id="cb3bb81fbe6b31c4f4a56e96a20f9e5651de1195" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;persistent_workers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the workers &lt;code&gt;Dataset&lt;/code&gt; instances alive. (default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;persistent_workers&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、データセットが一度消費された後、データローダーはワーカープロセスをシャットダウンしません。これにより、ワーカーの &lt;code&gt;Dataset&lt;/code&gt; インスタンスを存続させることができます。（デフォルト： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="6616e16bfa20c63814b50ea16a8dbe20de09b074" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_load_args&lt;/strong&gt; &amp;ndash; (Python 3 only) optional keyword arguments passed over to &lt;code&gt;pickle_module.load()&lt;/code&gt; and &lt;code&gt;pickle_module.Unpickler()&lt;/code&gt;, e.g., &lt;code&gt;errors=...&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pickle_load_args&lt;/strong&gt; &amp;ndash;（Python 3のみ） &lt;code&gt;pickle_module.load()&lt;/code&gt; および &lt;code&gt;pickle_module.Unpickler()&lt;/code&gt; に渡されるオプションのキーワード引数（例： &lt;code&gt;errors=...&lt;/code&gt; )。</target>
        </trans-unit>
        <trans-unit id="80a816c0ab01c996cd7ea1aa403c557f4fa9c91f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; module used for pickling metadata and objects</source>
          <target state="translated">&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash;メタデータとオブジェクトの&lt;strong&gt;pickle化に&lt;/strong&gt;使用されるモジュール</target>
        </trans-unit>
        <trans-unit id="2f4bba92d9ab262c68a9aa63c263e3ecc1546639" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash; module used for unpickling metadata and objects (has to match the &lt;code&gt;pickle_module&lt;/code&gt; used to serialize file)</source>
          <target state="translated">&lt;strong&gt;pickle_module&lt;/strong&gt; &amp;ndash;メタデータとオブジェクトの &lt;code&gt;pickle_module&lt;/code&gt; 使用されるモジュール（ファイルのシリアル化に使用されるpickle_moduleと一致する必要があります）</target>
        </trans-unit>
        <trans-unit id="d45a398e45519ff88900ce547f84f72e8159bc02" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pickle_protocol&lt;/strong&gt; &amp;ndash; can be specified to override the default protocol</source>
          <target state="translated">&lt;strong&gt;pickle_protocol&lt;/strong&gt; &amp;ndash;デフォルトのプロトコルを上書きするように指定できます</target>
        </trans-unit>
        <trans-unit id="93bc0635305d11284034a5a8601f085bc3597090" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pin_memory&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your &lt;code&gt;collate_fn&lt;/code&gt; returns a batch that is a custom type, see the example below.</source>
          <target state="translated">&lt;strong&gt;pin_memory&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、データローダーはTensorをCUDAに固定されたメモリにコピーしてから返します。データ要素がカスタムタイプである場合、または &lt;code&gt;collate_fn&lt;/code&gt; がカスタムタイプであるバッチを返す場合は、以下の例を参照してください。</target>
        </trans-unit>
        <trans-unit id="158a245072a4f4a11829d7283abb48b4e1e9eb19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pin_memory&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pin_memory&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;設定されている場合、返されたテンソルは固定されたメモリに割り当てられます。CPUテンソルでのみ機能します。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="30a109270dbf3f6ec8bac6d1654792ed9100f8cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pivot&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether pivoting is done. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ピボット&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ピボットを実行するかどうかを制御します。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="cd32ee50a83eb126fa1a1c22993913d7830c61d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pivots&lt;/strong&gt; (&lt;em&gt;IntTensor&lt;/em&gt;): the pivots of size</source>
          <target state="translated">&lt;strong&gt;ピボット&lt;/strong&gt;（&lt;em&gt;IntTensor&lt;/em&gt;）：サイズのピボット</target>
        </trans-unit>
        <trans-unit id="f2e2c490dcdc08b15ee53f75826edaf1f53d7fd1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;port&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The port on which the server store should listen for incoming requests.</source>
          <target state="translated">&lt;strong&gt;port&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;サーバーストアが着信要求をリッスンする必要があるポート。</target>
        </trans-unit>
        <trans-unit id="a7e3a169027105e593b1192ecd8a9853f1788650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pos_weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a weight of positive examples. Must be a vector with length equal to the number of classes.</source>
          <target state="translated">&lt;strong&gt;pos_weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;肯定的な例の重み。クラスの数に等しい長さのベクトルである必要があります。</target>
        </trans-unit>
        <trans-unit id="5d9e32c819f28a6d6eb1c4b5e3bf66285ee0131e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pos_weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a weight of positive examples. Must be a vector with length equal to the number of classes.</source>
          <target state="translated">&lt;strong&gt;pos_weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;肯定的な例の重み。クラスの数に等しい長さのベクトルである必要があります。</target>
        </trans-unit>
        <trans-unit id="63a4d9260aa840607a810cbe8d0437c578111576" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;precision&lt;/strong&gt; &amp;ndash; Number of digits of precision for floating point output (default = 4).</source>
          <target state="translated">&lt;strong&gt;精度&lt;/strong&gt;&amp;ndash;浮動小数点出力の精度の桁数（デフォルト= 4）。</target>
        </trans-unit>
        <trans-unit id="b7887c4f9ed7cd09ae84c628834259b5f7580508" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;precision_matrix&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; positive-definite precision matrix</source>
          <target state="translated">&lt;strong&gt;precision_matrix&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;正定精度行列</target>
        </trans-unit>
        <trans-unit id="abaf92d6b3ab9531ecb8cfe273227a30db2aba37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;predictions&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; The probability that an element be classified as true. Value should in [0, 1]</source>
          <target state="translated">&lt;strong&gt;予測&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;numpy.array &lt;/em&gt;&lt;em&gt;、または&lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt;）&amp;ndash;要素がtrueとして分類される確率。値は[0、1]である必要があります</target>
        </trans-unit>
        <trans-unit id="6fb3354ed439843dd8ef32205babe7ce9688e7c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefetch_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;keyword-only arg&lt;/em&gt;) &amp;ndash; Number of sample loaded in advance by each worker. &lt;code&gt;2&lt;/code&gt; means there will be a total of 2 * num_workers samples prefetched across all workers. (default: &lt;code&gt;2&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;prefetch_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;keyword-only arg&lt;/em&gt;）&amp;ndash;各ワーカーによって事前にロードされたサンプルの数。 &lt;code&gt;2&lt;/code&gt; は、すべてのワーカーで合計2 * num_workersサンプルがプリフェッチされることを意味します。（デフォルト： &lt;code&gt;2&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="739bd144f8a0f654bdebf94781331327df2092bf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The prefix string that is prepended to each key before being inserted into the store.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;ストアに挿入される前に各キーの前に付加されるプレフィックス文字列。</target>
        </trans-unit>
        <trans-unit id="fa8d87d0a691a6a353587f6a788059707272207e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; prefix to prepend to all buffer names.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;すべてのバッファ名の前に付けるプレフィックス。</target>
        </trans-unit>
        <trans-unit id="a986463f78b9961525aa208023a9f037690aad13" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prefix&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; prefix to prepend to all parameter names.</source>
          <target state="translated">&lt;strong&gt;prefix&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;すべてのパラメーター名の前に付けるプレフィックス。</target>
        </trans-unit>
        <trans-unit id="9ada4cefd9a3c036b0c581d2f7f607e59a4d3f95" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;prehook&lt;/strong&gt; &amp;ndash; observer we want to add to forward_pre_hook</source>
          <target state="translated">&lt;strong&gt;prehook &amp;ndash;forward_pre_hook&lt;/strong&gt;に追加するオブザーバー</target>
        </trans-unit>
        <trans-unit id="87f996b18f2064a1da55736eae49c39b0a0515d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;preserve_rng_state&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default=True&lt;/em&gt;) &amp;ndash; Omit stashing and restoring the RNG state during each checkpoint.</source>
          <target state="translated">&lt;strong&gt;preserve_rng_state&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;ブール値&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;デフォルト=真&lt;/em&gt;） -省略スタッシュと各チェックポイントの間にRNGの状態を復元します。</target>
        </trans-unit>
        <trans-unit id="7c2241fe546f8b691ed0b5ac683a6b12c7593208" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on COCO train2017</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、COCOtrain2017で事前トレーニングされたモデルを返します</target>
        </trans-unit>
        <trans-unit id="4130c1fbf426acf115174024390b36c99e17bb23" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on COCO train2017 which contains the same classes as Pascal VOC</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、PascalVOCと同じクラスを含むCOCOtrain2017で事前トレーニングされたモデルを返します</target>
        </trans-unit>
        <trans-unit id="3368d37398eeaa3adc0a4b2005b7ee2eb4eae69a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on ImageNet</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、ImageNetで事前トレーニングされたモデルを返します</target>
        </trans-unit>
        <trans-unit id="f82401ac0221d2cb1ccfd88239494a6d6471b218" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model pre-trained on Kinetics-400</source>
          <target state="translated">&lt;strong&gt;pretrained&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、Kinetics-400で事前トレーニングされたモデルを返します。</target>
        </trans-unit>
        <trans-unit id="7c650eeb51be2510d223d56911e3f6d5151fafd9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pretrained_backbone&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, returns a model with backbone pre-trained on Imagenet</source>
          <target state="translated">&lt;strong&gt;pretrained_backbone&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、Imagenetで事前トレーニングされたバックボーンを持つモデルを返します</target>
        </trans-unit>
        <trans-unit id="a012d454021e986a52416ed8bd22349eed031564" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;priority&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; priority of the stream. Can be either -1 (high priority) or 0 (low priority). By default, streams have priority 0.</source>
          <target state="translated">&lt;strong&gt;優先度&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ストリームの優先度。-1（優先度が高い）または0（優先度が低い）のいずれかになります。デフォルトでは、ストリームの優先度は0です。</target>
        </trans-unit>
        <trans-unit id="836a0ae5aaa2a4b5ebe789fe8a6b8eba4a2503f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Event probabilities</source>
          <target state="translated">&lt;strong&gt;ちゃったごめんなさい&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -イベント確率</target>
        </trans-unit>
        <trans-unit id="9a547f3ca966c92d1b1c810aec9fbec6b5bae1da" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Event probabilities of success in the half open interval [0, 1)</source>
          <target state="translated">&lt;strong&gt;probs&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;ハーフオープン間隔での成功のイベント確率[0、1）</target>
        </trans-unit>
        <trans-unit id="57d78570b63b97e29d6e38d0d65aae44fc55c4ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; event probabilities</source>
          <target state="translated">&lt;strong&gt;ちゃったごめんなさい&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -イベント確率</target>
        </trans-unit>
        <trans-unit id="0ac25c99cbf653bc1bdacc6809f8131f7843f062" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; (0,1) valued parameters</source>
          <target state="translated">&lt;strong&gt;probs&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;（0,1）値のパラメーター</target>
        </trans-unit>
        <trans-unit id="c1fdcacad1373d6a9e0e8771ad4a3e2671dab2a3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the probability of sampling &lt;code&gt;1&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ちゃったごめんなさい&lt;/strong&gt;（&lt;em&gt;番号&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -サンプリングの確率は &lt;code&gt;1&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="63137d647ab82091cd7358c87c0ba51703ae7f65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;probs&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the probability of sampling &lt;code&gt;1&lt;/code&gt;. Must be in range (0, 1]</source>
          <target state="translated">&lt;strong&gt;probs&lt;/strong&gt;（&lt;em&gt;Number &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;サンプリングの確率 &lt;code&gt;1&lt;/code&gt; 。範囲（0、1]内にある必要があります</target>
        </trans-unit>
        <trans-unit id="c9bb8392d89004ba45474c8414a4e0ac5c0dec7d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; The process group to be used for distributed data all-reduction. If &lt;code&gt;None&lt;/code&gt;, the default process group, which is created by &lt;a href=&quot;../distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt;&lt;/a&gt;, will be used. (default: &lt;code&gt;None&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash;分散データのすべての削減に使用されるプロセスグループ。 &lt;code&gt;None&lt;/code&gt; の場合、&lt;a href=&quot;../distributed#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;torch.distributed.init_process_group()&lt;/code&gt; &lt;/a&gt;によって作成されたデフォルトのプロセスグループが使用されます。（デフォルト： &lt;code&gt;None&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="ada49fdca36ec13c35249cb76cecbfce751dce94" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash; synchronization of stats happen within each process group individually. Default behavior is synchronization across the whole world</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt; &amp;ndash;統計の同期は各プロセスグループ内で個別に行われます。デフォルトの動作は、全世界での同期です</target>
        </trans-unit>
        <trans-unit id="ab933fbb9c2c9f17574f6d3222ab8887ecfcdd68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;process_group&lt;/strong&gt; (&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; process group to scope synchronization, default is the whole world</source>
          <target state="translated">&lt;strong&gt;process_group&lt;/strong&gt;（&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;プロセスグループからスコープへの同期。デフォルトは全世界です。</target>
        </trans-unit>
        <trans-unit id="63cde1066d72754dbf25cd05b0ce992cd2c0bf1a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;profile&lt;/strong&gt; &amp;ndash; Sane defaults for pretty printing. Can override with any of the above options. (any one of &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;short&lt;/code&gt;, &lt;code&gt;full&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;プロファイル&lt;/strong&gt;&amp;ndash;プリティプリントの正常なデフォルト。上記のオプションのいずれかでオーバーライドできます。（ &lt;code&gt;default&lt;/code&gt; 、 &lt;code&gt;short&lt;/code&gt; 、 &lt;code&gt;full&lt;/code&gt; いずれか）</target>
        </trans-unit>
        <trans-unit id="4cce827d14fdd2e9caa71382821e2ec163703757" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;profile_memory&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether to report memory usage, default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;profile_memory&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;メモリ使用量を報告するかどうか、デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4b15a59aebfcfe93a0fb0b923c3d5e9329cf089d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, displays a progress bar of the download to stderr</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、stderrへのダウンロードの進行状況バーを表示します</target>
        </trans-unit>
        <trans-unit id="fb2a87f24d269533a9f43524829d450e3c20d9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether or not to display a progress bar to stderr Default: True</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; stderrにプログレスバーを表示するかどうかデフォルト：True</target>
        </trans-unit>
        <trans-unit id="1f4a965676c83faefeff0a640a396640b206ce90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;progress&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether or not to display a progress bar to stderr. Default: True</source>
          <target state="translated">&lt;strong&gt;progress&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;プログレスバーをstderrに表示するかどうか。デフォルト：True</target>
        </trans-unit>
        <trans-unit id="904f28013662ab6c545488f5c421363d39caa951" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;pruning_method&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; a valid pruning function from this module, or a custom one implemented by the user that satisfies the implementation guidelines and has &lt;code&gt;PRUNING_TYPE='unstructured'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;pruning_method&lt;/strong&gt;（&lt;em&gt;function&lt;/em&gt;）&amp;ndash;このモジュールからの有効なプルーニング関数、または実装ガイドラインを満たし、 &lt;code&gt;PRUNING_TYPE='unstructured'&lt;/code&gt; を持つユーザーによって実装されたカスタム関数。</target>
        </trans-unit>
        <trans-unit id="e2d5c802a24580a7de621d4fd574838b9fee79a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;purge_step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; When logging crashes at step</source>
          <target state="translated">&lt;strong&gt;purge_step&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ステップでログがクラッシュした場合</target>
        </trans-unit>
        <trans-unit id="2c77c29b32dbddf5df2161d33068a2c919a7f28a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;q&lt;/strong&gt; (&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;Distribution&lt;/a&gt;) &amp;ndash; A &lt;code&gt;Distribution&lt;/code&gt; object.</source>
          <target state="translated">&lt;strong&gt;q&lt;/strong&gt;（&lt;a href=&quot;#torch.distributions.distribution.Distribution&quot;&gt;分布&lt;/a&gt;）&amp;ndash; &lt;code&gt;Distribution&lt;/code&gt; オブジェクト。</target>
        </trans-unit>
        <trans-unit id="d1cf443a5e0dc3febcb5f16e5dcd17ebe5190074" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;q&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a scalar or 1D tensor of quantile values in the range [0, 1]</source>
          <target state="translated">&lt;strong&gt;q&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;範囲[0、1]の分位値のスカラーまたは1Dテンソル</target>
        </trans-unit>
        <trans-unit id="a79e6547c6d8a86b6b38364e5726183256af0cff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;q&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a slightly overestimated rank of</source>
          <target state="translated">&lt;strong&gt;q&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;わずかに過大評価されたランク</target>
        </trans-unit>
        <trans-unit id="19980c41df6565f1cebbe94e3136eaac2d85dd26" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;qconfig&lt;/strong&gt; &amp;ndash; quantization configuration for the tensor, if qconfig is not provided, we will get qconfig from parent modules</source>
          <target state="translated">&lt;strong&gt;qconfig&lt;/strong&gt; &amp;ndash;テンソルの量子化構成。qconfigが提供されていない場合、親モジュールからqconfigを取得します。</target>
        </trans-unit>
        <trans-unit id="2d06744fd3fe91170a1358d5cbdbabaeaa95f37e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;qconfig_dict&lt;/strong&gt; &amp;ndash; dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute)</source>
          <target state="translated">&lt;strong&gt;qconfig_dict&lt;/strong&gt; &amp;ndash;サブモジュールの名前またはタイプから量子化構成にマップする辞書。サブモジュールのqconfigが指定されていない限り、qconfigは特定のモジュールのすべてのサブモジュールに適用されます（サブモジュールにすでにqconfig属性がある場合）。</target>
        </trans-unit>
        <trans-unit id="d8ae7bd422f6a67dd76f0faf46879a1ac2e30be1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;qconfig_spec&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;qconfig_spec&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="513991e27786f7e8f557b7f26358994ddf0d7171" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;qscheme&lt;/strong&gt; &amp;ndash; Quantization scheme to be used</source>
          <target state="translated">&lt;strong&gt;qscheme&lt;/strong&gt; &amp;ndash;使用する量子化スキーム</target>
        </trans-unit>
        <trans-unit id="a0b208a2eac673c5afa2a571d2f7b43dbc1b7802" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;quant_max&lt;/strong&gt; &amp;ndash; Maximum quantization value. If unspecified, it will follow the 8-bit setup.</source>
          <target state="translated">&lt;strong&gt;quant_max&lt;/strong&gt; &amp;ndash;最大量子化値。指定しない場合は、8ビット設定に従います。</target>
        </trans-unit>
        <trans-unit id="13aeba16f14baca22ce7389ada7786093da7b81d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;quant_max&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The maximum allowable quantized value.</source>
          <target state="translated">&lt;strong&gt;quant_max&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最大許容量子化値。</target>
        </trans-unit>
        <trans-unit id="53b5cb54c65a69d34cae88c78e6cf1d327781d3a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;quant_min&lt;/strong&gt; &amp;ndash; Minimum quantization value. If unspecified, it will follow the 8-bit setup.</source>
          <target state="translated">&lt;strong&gt;quant_min&lt;/strong&gt; &amp;ndash;最小量子化値。指定しない場合は、8ビット設定に従います。</target>
        </trans-unit>
        <trans-unit id="4457923d474c9d812a47035e795d3a26ec0aede5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;quant_min&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The minimum allowable quantized value.</source>
          <target state="translated">&lt;strong&gt;quant_min&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最小許容量子化値。</target>
        </trans-unit>
        <trans-unit id="2b03c96abe488a3ad5cb0d36a695b5ff1baba3a5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;r&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; number of elements to combine</source>
          <target state="translated">&lt;strong&gt;r&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;組み合わせる要素の数</target>
        </trans-unit>
        <trans-unit id="8b6f1d94cb019e9c8d76124f3064ce78117f6ad1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;raise_exception&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicating whether to raise an exception if the check fails. The exception gives more information about the exact nature of the failure. This is helpful when debugging gradchecks.</source>
          <target state="translated">&lt;strong&gt;raise_exception&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;チェックが失敗した場合に例外を発生させるかどうかを示します。例外は、障害の正確な性質に関する詳細情報を提供します。これは、gradcheckをデバッグするときに役立ちます。</target>
        </trans-unit>
        <trans-unit id="46b43eec40a9385ec340e004393520434a0a5eff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; a globally unique id/rank of this node.</source>
          <target state="translated">&lt;strong&gt;ランク&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;このノードのグローバルに一意のID /ランク。</target>
        </trans-unit>
        <trans-unit id="1b9f3f2fe3816f64c8a2d72a1f782fb24e29f8c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Rank of the current process within &lt;code&gt;num_replicas&lt;/code&gt;. By default, &lt;code&gt;rank&lt;/code&gt; is retrieved from the current distributed group.</source>
          <target state="translated">&lt;strong&gt;ランク&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） &lt;code&gt;num_replicas&lt;/code&gt; 内の現在のプロセスのランク。デフォルトでは、 &lt;code&gt;rank&lt;/code&gt; は現在の分散グループから取得されます。</target>
        </trans-unit>
        <trans-unit id="213d6776c2e063ecf8780712ac1852b9cd773740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rank&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Rank of the current process. Required if &lt;code&gt;store&lt;/code&gt; is specified.</source>
          <target state="translated">&lt;strong&gt;ランク&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;現在のプロセスのランク。 &lt;code&gt;store&lt;/code&gt; が指定されている場合は必須です。</target>
        </trans-unit>
        <trans-unit id="eded7c6be7a599ab9e04149f80d8815426799286" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;ranks&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of ranks of group members. If &lt;code&gt;None&lt;/code&gt;, will be set to all ranks. Default is &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;ランク&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;グループメンバーのランクのリスト。 &lt;code&gt;None&lt;/code&gt; の場合、すべてのランクに設定されます。デフォルトは &lt;code&gt;None&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="8172a5e10a4de560b57298957c2be9e6c1d992c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; rate = 1 / scale of the distribution</source>
          <target state="translated">&lt;strong&gt;レート&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;フロート&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;レート= 1 /分布のスケール</target>
        </trans-unit>
        <trans-unit id="eb69dd0379b97bdbdf3170bc41f3f933f59297ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; rate = 1 / scale of the distribution (often referred to as beta)</source>
          <target state="translated">&lt;strong&gt;レート&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;レート= 1 /分布のスケール（ベータと呼ばれることが多い）</target>
        </trans-unit>
        <trans-unit id="c13c2129dc5528a3975452686d875d982aa4e939" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rate&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the rate parameter</source>
          <target state="translated">&lt;strong&gt;レート&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;レートパラメータ</target>
        </trans-unit>
        <trans-unit id="75f1a5c80836b92712f937ef8445c423fd9ea3f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rcond&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; A floating point value to determine the cutoff for small singular values. Default: 1e-15</source>
          <target state="translated">&lt;strong&gt;rcond&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;小さな特異値のカットオフを決定するための浮動小数点値。デフォルト：1e-15</target>
        </trans-unit>
        <trans-unit id="af581fa7827e69e59f0e4da3fc56082b354bc569" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;real&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The real part of the complex tensor. Must be float or double.</source>
          <target state="translated">&lt;strong&gt;実数&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;複雑なテンソルの実数部。浮動小数点または倍精度である必要があります。</target>
        </trans-unit>
        <trans-unit id="d062ec2db1e149329c436d3f85532b1325d11a04" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recompute_scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; recompute the scale_factor for use in the interpolation calculation. When &lt;code&gt;scale_factor&lt;/code&gt; is passed as a parameter, it is used to compute the &lt;code&gt;output_size&lt;/code&gt;. If &lt;code&gt;recompute_scale_factor&lt;/code&gt; is &lt;code&gt;`False&lt;/code&gt; or not specified, the passed-in &lt;code&gt;scale_factor&lt;/code&gt; will be used in the interpolation computation. Otherwise, a new &lt;code&gt;scale_factor&lt;/code&gt; will be computed based on the output and input sizes for use in the interpolation computation (i.e. the computation will be identical to if the computed &lt;code&gt;output_size&lt;/code&gt; were passed-in explicitly). Note that when &lt;code&gt;scale_factor&lt;/code&gt; is floating-point, the recomputed scale_factor may differ from the one passed in due to rounding and precision issues.</source>
          <target state="translated">&lt;strong&gt;recompute_scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;補間計算で使用するためにscale_factorを再計算します。とき &lt;code&gt;scale_factor&lt;/code&gt; パラメータとして渡され、それを計算するために使用される &lt;code&gt;output_size&lt;/code&gt; を。場合 &lt;code&gt;recompute_scale_factor&lt;/code&gt; がある &lt;code&gt;`False&lt;/code&gt; を指定したかどうか、渡された &lt;code&gt;scale_factor&lt;/code&gt; 補間演算に使用されます。それ以外の場合、新しい &lt;code&gt;scale_factor&lt;/code&gt; は、補間計算で使用する出力サイズと入力サイズに基づいて計算されます（つまり、計算は、計算された &lt;code&gt;output_size&lt;/code&gt; が明示的に渡された場合と同じになります）。 &lt;code&gt;scale_factor&lt;/code&gt; の場合は注意してください が浮動小数点の場合、丸めと精度の問題により、再計算されたscale_factorが渡されたものと異なる場合があります。</target>
        </trans-unit>
        <trans-unit id="6d147c57163aacc18c731dbb3194a3e546b62f51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;record_shapes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If shapes recording is set, information about input dimensions will be collected. This allows one to see which dimensions have been used under the hood and further group by them using prof.key_averages(group_by_input_shape=True). Please note that shape recording might skew your profiling data. It is recommended to use separate runs with and without shape recording to validate the timing. Most likely the skew will be negligible for bottom most events (in a case of nested function calls). But for higher level functions the total self cpu time might be artificially increased because of the shape collection.</source>
          <target state="translated">&lt;strong&gt;record_shapes&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;形状の記録が設定されている場合、入力ディメンションに関する情報が収集されます。これにより、内部で使用されているディメンションを確認し、prof.key_averages（group_by_input_shape = True）を使用してさらにグループ化することができます。形状の記録により、プロファイリングデータが歪む可能性があることに注意してください。タイミングを検証するために、形状記録がある場合とない場合で別々の実行を使用することをお勧めします。ほとんどの場合、最下位のイベント（ネストされた関数呼び出しの場合）ではスキューは無視できます。ただし、より高いレベルの関数の場合、形状の収集により、合計自己CPU時間が人為的に増加する可能性があります。</target>
        </trans-unit>
        <trans-unit id="b9bb0a7673177fd2fbc7643ab228a01c936fa373" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;record_shapes&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default=False&lt;/em&gt;) &amp;ndash; If &lt;code&gt;record_shapes=True&lt;/code&gt;, the nvtx range wrapping each autograd op will append information about the sizes of Tensor arguments received by that op, in the following format: &lt;code&gt;[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]&lt;/code&gt; Non-tensor arguments will be represented by &lt;code&gt;[]&lt;/code&gt;. Arguments will be listed in the order they are received by the backend op. Please note that this order may not match the order in which those arguments were passed on the Python side. Also note that shape recording may increase the overhead of nvtx range creation.</source>
          <target state="translated">&lt;strong&gt;record_shapes&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;default = False&lt;/em&gt;）&amp;ndash; &lt;code&gt;record_shapes=True&lt;/code&gt; の場合、各autograd opをラップするnvtx範囲は、そのopによって受信されたTensor引数のサイズに関する情報を次の形式で &lt;code&gt;[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]&lt;/code&gt; ます。[[arg0.size（0） 、arg0.size（1）、...]、[arg1.size（0）、arg1.size（1）、...]、...]非テンソル引数は &lt;code&gt;[]&lt;/code&gt; で表されます。引数は、バックエンド操作によって受信された順序でリストされます。この順序は、Python側でこれらの引数が渡された順序と一致しない場合があることに注意してください。また、形状の記録により、nvtx範囲の作成のオーバーヘッドが増加する可能性があることにも注意してください。</target>
        </trans-unit>
        <trans-unit id="66b7e6f37f61ed7bcaf736cc00b93f71e3e9d94f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recurse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.</source>
          <target state="translated">&lt;strong&gt;recurse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、このモジュールとすべてのサブモジュールのバッファーを生成します。それ以外の場合は、このモジュールの直接メンバーであるバッファーのみが生成されます。</target>
        </trans-unit>
        <trans-unit id="644d5b1b0bd86304bca7dd80429d10befe174346" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;recurse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module.</source>
          <target state="translated">&lt;strong&gt;recurse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; Trueの場合、このモジュールとすべてのサブモジュールのパラメーターを生成します。それ以外の場合は、このモジュールの直接メンバーであるパラメーターのみが生成されます。</target>
        </trans-unit>
        <trans-unit id="9d6ed3cdc238c90248d062e02e2aeb40a792fd6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduce&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged or summed over observations for each minibatch depending on &lt;code&gt;size_average&lt;/code&gt;. When &lt;code&gt;reduce&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, returns a loss per batch element instead and ignores &lt;code&gt;size_average&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;reduce&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;非推奨（ &lt;code&gt;reduction&lt;/code&gt; を参照）。デフォルトでは、size_averageに応じて、各ミニバッチの観測値全体で損失が平均化または合計され &lt;code&gt;size_average&lt;/code&gt; 。 &lt;code&gt;reduce&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; の場合、代わりにバッチ要素ごとの損失を返し、 &lt;code&gt;size_average&lt;/code&gt; を無視します。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ec48eb52fa8aaaf96330bc31ea80796de3009600" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduce&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; reduction operation to apply, can be either &amp;lsquo;add&amp;rsquo; or &amp;lsquo;multiply&amp;rsquo;.</source>
          <target state="translated">&lt;strong&gt;reduce&lt;/strong&gt;（&lt;em&gt;string&lt;/em&gt;）&amp;ndash;適用する削減操作。「add」または「multiply」のいずれかです。</target>
        </trans-unit>
        <trans-unit id="df9ff944cb4c0142267f05a92f7850f1e92dc9ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduce_range&lt;/strong&gt; &amp;ndash; Reduces the range of the quantized data type by 1 bit</source>
          <target state="translated">&lt;strong&gt;reduce_range&lt;/strong&gt; &amp;ndash;量子化されたデータ型の範囲を1ビット&lt;strong&gt;縮小し&lt;/strong&gt;ます</target>
        </trans-unit>
        <trans-unit id="999d2f01d581c18979dd9cf3c2b7eed8f5feaf65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the (optional) reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the sum of the output will be divided by the number of elements in the output, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） -指定した出力に適用する（オプション）削減： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：なし減少適用され、 &lt;code&gt;'mean'&lt;/code&gt; ：出力の和は、出力内の要素の数で分割される &lt;code&gt;'sum'&lt;/code&gt; ：出力が加算されます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="be1520205497ebdaeafa4280ed8c7e38f481ddbb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied &lt;code&gt;'batchmean'&lt;/code&gt;: the sum of the output will be divided by the batchsize &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed &lt;code&gt;'mean'&lt;/code&gt;: the output will be divided by the number of elements in the output Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：削減は適用されません &lt;code&gt;'batchmean'&lt;/code&gt; ：出力 &lt;code&gt;'sum'&lt;/code&gt; はbatchsizeで除算されます'sum'：出力は合計されます &lt;code&gt;'mean'&lt;/code&gt; ：出力は出力の要素数で除算されますデフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c4b4f64c1d6c7c3276f90a766a11f80a1ea5e149" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied. &lt;code&gt;'batchmean'&lt;/code&gt;: the sum of the output will be divided by batchsize. &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. &lt;code&gt;'mean'&lt;/code&gt;: the output will be divided by the number of elements in the output. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'batchmean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：削減は適用されません。 &lt;code&gt;'batchmean'&lt;/code&gt; ：出力の合計がbatchsizeで除算されます。 &lt;code&gt;'sum'&lt;/code&gt; ：出力が合計されます。 &lt;code&gt;'mean'&lt;/code&gt; ：出力は出力の要素数で除算されます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="550432cc430b06db5fb2ea76d0d512f8f5fde312" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the output losses will be divided by the target lengths and then the mean over the batch is taken, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：削減は適用されません &lt;code&gt;'mean'&lt;/code&gt; ：出力損失はターゲットの長さで除算され、バッチ &lt;code&gt;'sum'&lt;/code&gt; 平均が取られます。' sum '：出力は合計されます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fab0f58a76f5ab9a119f22747e3687485076ce27" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the output losses will be divided by the target lengths and then the mean over the batch is taken. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：削減は適用されません &lt;code&gt;'mean'&lt;/code&gt; ：出力損失はターゲットの長さで除算され、バッチ全体の平均が取得されます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2038b00821d8c29dc11b468c90bec48a089c2703" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the sum of the output will be divided by the number of elements in the output, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Note: &lt;code&gt;size_average&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are in the process of being deprecated, and in the meantime, specifying either of those two args will override &lt;code&gt;reduction&lt;/code&gt;. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：なし減少適用され、 &lt;code&gt;'mean'&lt;/code&gt; ：出力の和は、出力内の要素の数で分割される &lt;code&gt;'sum'&lt;/code&gt; ：出力が加算されます。注： &lt;code&gt;size_average&lt;/code&gt; と &lt;code&gt;reduce&lt;/code&gt; は非推奨になる過程にあり、その間、これら2つの引数のいずれかを指定すると &lt;code&gt;reduction&lt;/code&gt; がオーバーライドされます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="eeb5334dd27eff929df501296bde2d45292263ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reduction&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Specifies the reduction to apply to the output: &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt;. &lt;code&gt;'none'&lt;/code&gt;: no reduction will be applied, &lt;code&gt;'mean'&lt;/code&gt;: the weighted mean of the output is taken, &lt;code&gt;'sum'&lt;/code&gt;: the output will be summed. Note: &lt;code&gt;size_average&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; are in the process of being deprecated, and in the meantime, specifying either of those two args will override &lt;code&gt;reduction&lt;/code&gt;. Default: &lt;code&gt;'mean'&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;削減&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力に適用する削減を指定します： &lt;code&gt;'none'&lt;/code&gt; | &lt;code&gt;'mean'&lt;/code&gt; | &lt;code&gt;'sum'&lt;/code&gt; 。 &lt;code&gt;'none'&lt;/code&gt; ：何低減は、適用されません &lt;code&gt;'mean'&lt;/code&gt; ：出力の加重平均は、取られない &lt;code&gt;'sum'&lt;/code&gt; ：出力が加算されます。注： &lt;code&gt;size_average&lt;/code&gt; と &lt;code&gt;reduce&lt;/code&gt; は非推奨になる過程にあり、その間、これら2つの引数のいずれかを指定すると &lt;code&gt;reduction&lt;/code&gt; がオーバーライドされます。デフォルト： &lt;code&gt;'mean'&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="26f5663a719cfdd4fa447aac8908e9938b53db2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;reinterpreted_batch_ndims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of batch dims to reinterpret as event dims</source>
          <target state="translated">&lt;strong&gt;reinterpreted_batch_ndims&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;イベントdimとして再解釈するバッチdimの数</target>
        </trans-unit>
        <trans-unit id="6a3f6bd6ab2f6e4081336546b9b09a6627d4bd3b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;repeats&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of repetitions for each element. repeats is broadcasted to fit the shape of the given axis.</source>
          <target state="translated">&lt;strong&gt;繰り返し&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;各要素の繰り返しの数。繰り返しは、指定された軸の形状に合うようにブロードキャストされます。</target>
        </trans-unit>
        <trans-unit id="b1b614c9ba8db64b7bf312b7a13b2a9bb7e47954" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;replacement&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, samples are drawn with replacement. If not, they are drawn without replacement, which means that when a sample index is drawn for a row, it cannot be drawn again for that row.</source>
          <target state="translated">&lt;strong&gt;置換&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、サンプルは置換で抽出されます。そうでない場合、それらは置換なしで描画されます。つまり、サンプルインデックスが行に対して描画されると、その行に対して再度描画することはできません。</target>
        </trans-unit>
        <trans-unit id="c742f71bde47f3a77d49c3447369afe1d00535bb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;replacement&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; samples are drawn on-demand with replacement if &lt;code&gt;True&lt;/code&gt;, default=``False``</source>
          <target state="translated">&lt;strong&gt;置換&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;サンプルはオンデマンドで描画され、 &lt;code&gt;True&lt;/code&gt; の場合は置換されます。defaultNUMFalse``</target>
        </trans-unit>
        <trans-unit id="624d56544251a5adb1f3f92beef5fbb3779fffe6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;replacement&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to draw with replacement or not</source>
          <target state="translated">&lt;strong&gt;置換&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;置換で描画するかどうか</target>
        </trans-unit>
        <trans-unit id="c9636def42aa5ea6379407cbf86e341937067fa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;repo_or_dir&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; repo name (&lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt;), if &lt;code&gt;source = 'github'&lt;/code&gt;; or a path to a local directory, if &lt;code&gt;source = 'local'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;repo_or_dir&lt;/strong&gt;（&lt;em&gt;string&lt;/em&gt;）&amp;ndash; repo name（ &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; ）、if &lt;code&gt;source = 'github'&lt;/code&gt; ; または、 &lt;code&gt;source = 'local'&lt;/code&gt; 場合は、ローカルディレクトリへのパス。</target>
        </trans-unit>
        <trans-unit id="9d8769220135033f3f9eb757c4af510a8fde0c5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If autograd should record operations on this tensor. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;require_grad （&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;autogradがこのテンソルの操作を記録&lt;strong&gt;する必要がある&lt;/strong&gt;場合。デフォルト： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4b55034c998f6c870737977254bec184876385d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether autograd should record operations on parameters in this module. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;&lt;/strong&gt;require_grad （&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;autogradがこのモジュールのパラメーターに対する操作を記録&lt;strong&gt;する必要がある&lt;/strong&gt;かどうか。デフォルト： &lt;code&gt;True&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="7483a3c1ab04560df78ce5fcc47dc422c5b6fb38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If autograd should record operations on the returned tensor. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;requires_grad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;ブール値&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） - autogradが返さテンソルの操作を記録する必要があります。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="4f8da86e61fff9872b332d5a83e86f2da79513dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;requires_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if the parameter requires gradient. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#excluding-subgraphs&quot;&gt;Excluding subgraphs from backward&lt;/a&gt; for more details. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;require_grad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;パラメーターに勾配が必要な場合。詳細については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#excluding-subgraphs&quot;&gt;サブグラフを後方から除外するを&lt;/a&gt;参照してください。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="50f6783d1e07f9c1440a696e4976ac787e5b69d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;result&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#object&quot;&gt;object&lt;/a&gt;) &amp;ndash; the result object of this &lt;code&gt;Future&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;result&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#object&quot;&gt;object&lt;/a&gt;）&amp;ndash;この &lt;code&gt;Future&lt;/code&gt; の結果オブジェクト。</target>
        </trans-unit>
        <trans-unit id="6760018ae15219fda8ff14952fb1cf636108f831" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;retain_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to &lt;code&gt;True&lt;/code&gt; is not needed and often can be worked around in a much more efficient way. Defaults to the value of &lt;code&gt;create_graph&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;hold_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;False&lt;/code&gt; の場合、卒業生の計算に使用されたグラフが解放されます。ほとんどすべての場合、このオプションを &lt;code&gt;True&lt;/code&gt; に設定する必要はなく、はるかに効率的な方法で回避できる場合が多いことに注意してください。デフォルトは &lt;code&gt;create_graph&lt;/code&gt; の値です。</target>
        </trans-unit>
        <trans-unit id="90a602776d12962951cc0385731c01ed3bcab28d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;retain_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, the graph used to compute the grads will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of &lt;code&gt;create_graph&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;hold_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;False&lt;/code&gt; の場合、卒業生の計算に使用されたグラフが解放されます。ほとんどすべての場合、このオプションをTrueに設定する必要はなく、はるかに効率的な方法で回避できる場合が多いことに注意してください。デフォルトは &lt;code&gt;create_graph&lt;/code&gt; の値です。</target>
        </trans-unit>
        <trans-unit id="2cfcdef9f1e81b511c2a831483836e1d2395c58f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;retain_graph&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If False, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Usually, you need to set this to True to run backward multiple times.</source>
          <target state="translated">&lt;strong&gt;hold_graph&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; Falseの場合、卒業生の計算に使用されたグラフが解放されます。ほとんどすべての場合、このオプションをTrueに設定する必要はなく、はるかに効率的な方法で回避できる場合が多いことに注意してください。通常、これをTrueに設定して、複数回逆方向に実行する必要があります。</target>
        </trans-unit>
        <trans-unit id="a53068eb20e1703e6fae54e116c28d41c909b9cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_complex&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return a complex tensor, or a real tensor with an extra last dimension for the real and imaginary components.</source>
          <target state="translated">&lt;strong&gt;return_complex&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;複素テンソルを返すか、実数および虚数成分の最後の次元が追加された実テンソルを返すか。</target>
        </trans-unit>
        <trans-unit id="6e3ba44aedb23f32452a877f1431281949acdfbc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_complex&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Whether the output should be complex, or if the input should be assumed to derive from a real signal and window. Note that this is incompatible with &lt;code&gt;onesided=True&lt;/code&gt;. (Default: &lt;code&gt;False&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;return_complex&lt;/strong&gt;（&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;出力を複雑にするか、入力が実際の信号とウィンドウから派生すると想定するか。これは &lt;code&gt;onesided=True&lt;/code&gt; と互換性がないことに注意してください。（デフォルト： &lt;code&gt;False&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="451a8ec8a7c215fb8c9eb2bcdfe93c4066ee62d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_counts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the counts for each unique element.</source>
          <target state="translated">&lt;strong&gt;return_counts&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;各一意の要素のカウントも返すかどうか。</target>
        </trans-unit>
        <trans-unit id="be0b737a57d022be99ca3806d10ba96bda8a2e6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, will return the argmax along with the max values. Useful for &lt;a href=&quot;torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool1d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、最大値とともにargmaxを返します。後で&lt;a href=&quot;torch.nn.maxunpool1d#torch.nn.MaxUnpool1d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool1d&lt;/code&gt; &lt;/a&gt;に役立ちます</target>
        </trans-unit>
        <trans-unit id="dfccddd5be08bd3e21421b7d578619f610a4ebf2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to &lt;code&gt;nn.MaxUnpool2d()&lt;/code&gt;. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともにインデックスを返します。 &lt;code&gt;nn.MaxUnpool2d()&lt;/code&gt; に渡すのに便利です。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="24f9f4b06fa0e2c9a270a8c0bf40171f36526e9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool1d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともにインデックスを返します。nn.MaxUnpool1dに渡すのに便利です。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3acdc3b1a33b53e4798f96fee93430c34612b83e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool2d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともにインデックスを返します。nn.MaxUnpool2dに渡すのに便利です。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="dc9007ec5c0f693cbc0478e2780a9eeb50ea22b3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the indices along with the outputs. Useful to pass to nn.MaxUnpool3d. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともにインデックスを返します。nn.MaxUnpool3dに渡すのに便利です。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e2e8bb04f084571c1e2d5a7885f2d614f58c1003" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool2d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともに最大インデックスを返します。後で&lt;a href=&quot;torch.nn.maxunpool2d#torch.nn.MaxUnpool2d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool2d&lt;/code&gt; &lt;/a&gt;に役立ちます</target>
        </trans-unit>
        <trans-unit id="cb3879f13bacb4ac2075aca61af136eb87bb632e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, will return the max indices along with the outputs. Useful for &lt;a href=&quot;torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt;&lt;code&gt;torch.nn.MaxUnpool3d&lt;/code&gt;&lt;/a&gt; later</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、出力とともに最大インデックスを返します。後で&lt;a href=&quot;torch.nn.maxunpool3d#torch.nn.MaxUnpool3d&quot;&gt; &lt;code&gt;torch.nn.MaxUnpool3d&lt;/code&gt; &lt;/a&gt;に役立ちます</target>
        </trans-unit>
        <trans-unit id="c2d9bba5ad78165f7e64c1456856426896f737bb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash; whether to return pooling indices. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;return_indices&lt;/strong&gt; &amp;ndash;プーリングインデックスを返すかどうか。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="0ccd823978e457f89c779b1144535100d72c2c1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;return_inverse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to also return the indices for where elements in the original input ended up in the returned unique list.</source>
          <target state="translated">&lt;strong&gt;return_inverse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;元の入力の要素が返された一意のリストのどこにあるかについてのインデックスも返すかどうか。</target>
        </trans-unit>
        <trans-unit id="1e938f9292b067d102f23035466dfb0011287d87" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rho&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; coefficient used for computing a running average of squared gradients (default: 0.9)</source>
          <target state="translated">&lt;strong&gt;rho&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;勾配の二乗の移動平均を計算するために使用される係数（デフォルト：0.9）</target>
        </trans-unit>
        <trans-unit id="dac774a90d09e020fc94b8cf488f1c4dac29e906" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;code&gt;boundaries&lt;/code&gt; (one pass the last index). In other words, if False, gets the lower bound index for each value in &lt;code&gt;input&lt;/code&gt; from &lt;code&gt;boundaries&lt;/code&gt;. If True, gets the upper bound index instead. Default value is False.</source>
          <target state="translated">&lt;strong&gt;right&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; Falseの場合、最初に見つかった適切な場所を返します。 Trueの場合、そのような最後のインデックスを返します。適切なインデックスが見つからない場合は、数値以外の値（nan、infなど）または &lt;code&gt;boundaries&lt;/code&gt; のサイズ（最後のインデックスを1つ渡す）の場合は0を返します。つまり、Falseの場合、 &lt;code&gt;boundaries&lt;/code&gt; からの &lt;code&gt;input&lt;/code&gt; 各値の下限インデックスを取得します。 Trueの場合、代わりに上限インデックスを取得します。デフォルト値はFalseです。</target>
        </trans-unit>
        <trans-unit id="5f99ca7c7e81085a92ca3b1ee3f61f4f25afa5c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;right&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of &lt;em&gt;innermost&lt;/em&gt; dimension within &lt;code&gt;sorted_sequence&lt;/code&gt; (one pass the last index of the &lt;em&gt;innermost&lt;/em&gt; dimension). In other words, if False, gets the lower bound index for each value in &lt;code&gt;values&lt;/code&gt; on the corresponding &lt;em&gt;innermost&lt;/em&gt; dimension of the &lt;code&gt;sorted_sequence&lt;/code&gt;. If True, gets the upper bound index instead. Default value is False.</source>
          <target state="translated">&lt;strong&gt;right&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; Falseの場合、最初に見つかった適切な場所を返します。 Trueの場合、そのような最後のインデックスを返します。適切なインデックスが見つからない場合、（例えば、ナン、INF）又はサイズ非数値0を返す&lt;em&gt;最も内側の&lt;/em&gt;内寸法 &lt;code&gt;sorted_sequence&lt;/code&gt; （一つの最後のインデックス通過&lt;em&gt;最も内側の&lt;/em&gt;寸法）。つまり、Falseの場合、 &lt;code&gt;sorted_sequence&lt;/code&gt; の対応する&lt;em&gt;最も内側の&lt;/em&gt;次元の &lt;code&gt;values&lt;/code&gt; 各値の下限インデックスを取得します。 Trueの場合、代わりに上限インデックスを取得します。デフォルト値はFalseです。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="8af0242748d4ccc71f6d117d72964f9f1a6dfc76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;roots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;) &amp;ndash; Tensors which represent the roots of the autograd computation. All the tensors should be scalars.</source>
          <target state="translated">&lt;strong&gt;roots&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;）&amp;ndash;autograd計算の根を表すテンソル。すべてのテンソルはスカラーでなければなりません。</target>
        </trans-unit>
        <trans-unit id="6e703cfc7b66dc3da520fdcf8d4940424403970a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;row&lt;/strong&gt; (&lt;code&gt;int&lt;/code&gt;) &amp;ndash; number of rows in the 2-D matrix.</source>
          <target state="translated">&lt;strong&gt;row&lt;/strong&gt;（ &lt;code&gt;int&lt;/code&gt; ）&amp;ndash;2次元行列の行数。</target>
        </trans-unit>
        <trans-unit id="df8808dbd32331cc487f9561ab89f6497d98b06d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rpc_backend_options&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;RpcBackendOptions&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The options passed to the RpcAgent constructor. It must be an agent-specific subclass of &lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;&lt;code&gt;RpcBackendOptions&lt;/code&gt;&lt;/a&gt; and contains agent-specific initialization configurations. By default, for all agents, it sets the default timeout to 60 seconds and performs the rendezvous with an underlying process group initialized using &lt;code&gt;init_method = &quot;env://&quot;&lt;/code&gt;, meaning that environment variables &lt;code&gt;MASTER_ADDR&lt;/code&gt; and &lt;code&gt;MASTER_PORT&lt;/code&gt; need to be set properly. See &lt;a href=&quot;#rpc-backends&quot;&gt;Backends&lt;/a&gt; for more information and find which options are available.</source>
          <target state="translated">&lt;strong&gt;rpc_backend_options&lt;/strong&gt;（&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt;RpcBackendOptions &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;RpcAgentコンストラクターに渡されるオプション。これは、&lt;a href=&quot;#torch.distributed.rpc.RpcBackendOptions&quot;&gt; &lt;code&gt;RpcBackendOptions&lt;/code&gt; の&lt;/a&gt;エージェント固有のサブクラスである必要があり、エージェント固有の初期化構成が含まれています。デフォルトでは、すべてのエージェントについて、デフォルトのタイムアウトを60秒に設定し、 &lt;code&gt;init_method = &quot;env://&quot;&lt;/code&gt; を使用して初期化された基になるプロセスグループとのランデブーを実行します。つまり、環境変数 &lt;code&gt;MASTER_ADDR&lt;/code&gt; と &lt;code&gt;MASTER_PORT&lt;/code&gt; を適切に設定する必要があります。詳細については、&lt;a href=&quot;#rpc-backends&quot;&gt;バックエンド&lt;/a&gt;を参照し、使用可能なオプションを見つけてください。</target>
        </trans-unit>
        <trans-unit id="fa0b9defbfa21ac977266023b0b5c46f0b2f3e8a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rpc_timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The default timeout, in seconds, for RPC requests (default: 60 seconds). If the RPC has not completed in this timeframe, an exception indicating so will be raised. Callers can override this timeout for individual RPCs in &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; if necessary.</source>
          <target state="translated">&lt;strong&gt;rpc_timeout&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; RPC要求のデフォルトのタイムアウト（秒単位）（デフォルト：60秒）。この時間枠内にRPCが完了していない場合、そのことを示す例外が発生します。呼び出し元は、必要に応じて、&lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt; &lt;code&gt;rpc_sync()&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;で個々のRPCのこのタイムアウトをオーバーライドできます。</target>
        </trans-unit>
        <trans-unit id="a9b4c9479c732d9f30ea164524b3a33731786f26" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rtol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; relative tolerance</source>
          <target state="translated">&lt;strong&gt;rtol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;相対公差</target>
        </trans-unit>
        <trans-unit id="bacc9f0e60fd24a901f52d44a4638e9e04c80978" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;rtol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; relative tolerance. Default: 1e-05</source>
          <target state="translated">&lt;strong&gt;rtol&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;相対公差。デフォルト：1e-05</target>
        </trans-unit>
        <trans-unit id="68516e2a3f22a5073a1b61d78f57c2742a450d43" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;run_args&lt;/strong&gt; &amp;ndash; positional arguments for &lt;code&gt;run_fn&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;run_args&lt;/strong&gt; -のための位置引数 &lt;code&gt;run_fn&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bd1dab5b3aea5e89f1c99964e19bebd1e28fff57" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;run_fn&lt;/strong&gt; &amp;ndash; a calibration function for calibrating the prepared model</source>
          <target state="translated">&lt;strong&gt;run_fn&lt;/strong&gt; &amp;ndash;準備されたモデルをキャリブレーションするためのキャリブレーション関数</target>
        </trans-unit>
        <trans-unit id="931e0227dde3971f2dd3e3a902f46ff3b3f327d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;run_fn&lt;/strong&gt; &amp;ndash; a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop</source>
          <target state="translated">&lt;strong&gt;run_fn&lt;/strong&gt; &amp;ndash;準備されたモデルを評価するための関数。準備されたモデルまたはトレーニングループを実行するだけの関数にすることができます。</target>
        </trans-unit>
        <trans-unit id="4b07538c76cf919ebc72b7a60c06e46f59f69d90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;run_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; Name of the run, to be included as part of the logdir. If unspecified, will use current timestamp.</source>
          <target state="translated">&lt;strong&gt;run_name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;logdirの一部として含まれる実行の名前。指定しない場合、現在のタイムスタンプを使用します。</target>
        </trans-unit>
        <trans-unit id="d393489b76cacef3a8a7486c7be0cd8c3544afb0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt;（&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;変換された次元の信号サイズ。指定した場合、各次元 &lt;code&gt;dim[i]&lt;/code&gt; は、FFTを計算する前に、ゼロが埋め込まれるか、長さ &lt;code&gt;s[i]&lt;/code&gt; にトリミングされます。長さ &lt;code&gt;-1&lt;/code&gt; が指定されている場合、その次元ではパディングは行われません。デフォルト： &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="383f45f0226b4e5e81f81f93c4ac71001b0283d4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the IFFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt;（&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;変換された次元の信号サイズ。指定された場合、各次元 &lt;code&gt;dim[i]&lt;/code&gt; は、IFFTを計算する前に、ゼロが埋め込まれるか、長さ &lt;code&gt;s[i]&lt;/code&gt; にトリミングされます。長さ &lt;code&gt;-1&lt;/code&gt; が指定されている場合、その次元ではパディングは行われません。デフォルト： &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3025f4149f55dd0264a95f1c44c06d665d4e4023" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Default: &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt;（&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;変換された次元の信号サイズ。指定した場合、実際のFFTを計算する前に、各次元 &lt;code&gt;dim[i]&lt;/code&gt; にゼロが埋め込まれるか、長さ &lt;code&gt;s[i]&lt;/code&gt; にトリミングされます。長さ &lt;code&gt;-1&lt;/code&gt; が指定されている場合、その次元ではパディングは行われません。デフォルト： &lt;code&gt;s = [input.size(d) for d in dim]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7febbe2af643e6ca772e051b519b3c65a06281d0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;s&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Signal size in the transformed dimensions. If given, each dimension &lt;code&gt;dim[i]&lt;/code&gt; will either be zero-padded or trimmed to the length &lt;code&gt;s[i]&lt;/code&gt; before computing the real FFT. If a length &lt;code&gt;-1&lt;/code&gt; is specified, no padding is done in that dimension. Defaults to even output in the last dimension: &lt;code&gt;s[-1] = 2*(input.size(dim[-1]) - 1)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;s&lt;/strong&gt;（&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;変換された次元の信号サイズ。指定した場合、実際のFFTを計算する前に、各次元 &lt;code&gt;dim[i]&lt;/code&gt; にゼロが埋め込まれるか、長さ &lt;code&gt;s[i]&lt;/code&gt; にトリミングされます。長さ &lt;code&gt;-1&lt;/code&gt; が指定されている場合、その次元ではパディングは行われません。デフォルトでは、最後の次元で偶数出力になります： &lt;code&gt;s[-1] = 2*(input.size(dim[-1]) - 1)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e00929ae140d39c48352cf6fa3194ee39c66f5ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sample_rate&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; sample rate in Hz</source>
          <target state="translated">&lt;strong&gt;sample_rate&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;サンプルレート（Hz）</target>
        </trans-unit>
        <trans-unit id="ede0ae581174ad5f881503114e9fd37062ebd9c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sampler&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;Sampler&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Iterable&lt;/em&gt;) &amp;ndash; Base sampler. Can be any iterable object</source>
          <target state="translated">&lt;strong&gt;サンプラー&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;サンプラー&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;反復可能&lt;/em&gt;）&amp;ndash;ベースサンプラー。任意の反復可能なオブジェクトにすることができます</target>
        </trans-unit>
        <trans-unit id="e17b89346bc0115c104f4ad35f54ceb6abdcd713" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sampler&lt;/strong&gt; (&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;Sampler&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; defines the strategy to draw samples from the dataset. Can be any &lt;code&gt;Iterable&lt;/code&gt; with &lt;code&gt;__len__&lt;/code&gt; implemented. If specified, &lt;code&gt;shuffle&lt;/code&gt; must not be specified.</source>
          <target state="translated">&lt;strong&gt;サンプラー&lt;/strong&gt;（&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;サンプラー&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;イテラブル&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;データセットからサンプルを&lt;em&gt;抽出&lt;/em&gt;する戦略を定義します。 &lt;code&gt;__len__&lt;/code&gt; が実装された任意の &lt;code&gt;Iterable&lt;/code&gt; にすることができます。指定する場合、 &lt;code&gt;shuffle&lt;/code&gt; は指定しないでください。</target>
        </trans-unit>
        <trans-unit id="0f88769c8058a6eff5bd8fee7b065e6e5f50592a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scalar_value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Value to save</source>
          <target state="translated">&lt;strong&gt;scalar_value&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;string / blobname&lt;/em&gt;）&amp;ndash;保存する値</target>
        </trans-unit>
        <trans-unit id="70829693ef66298f30df8e08fe38a1e8755c2ac6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale for the output. Default: 1.0</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash;出力の量子化スケール。デフォルト：1.0</target>
        </trans-unit>
        <trans-unit id="8194d48378537f087c73ec0589aa42997e1c5c42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; quantization scale of the output tensor</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash;出力テンソルの量子化スケール</target>
        </trans-unit>
        <trans-unit id="0a965b18684d8dfdbd37cc4f8057ea12da1baa61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash; scale of the output Quantized Tensor</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt; &amp;ndash;出力のスケールQuantized Tensor</target>
        </trans-unit>
        <trans-unit id="d171e9b1743bffba5ac11a6cc0337364c0f09257" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; scale to apply in quantization formula</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;量子化式に適用するスケール</target>
        </trans-unit>
        <trans-unit id="a5475858e5269ec567bda19595cd62989e64c5f2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Scale parameter of distribution (lambda).</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布のスケールパラメーター（ラムダ）。</target>
        </trans-unit>
        <trans-unit id="0b6af0ea65b40800b2fae6da73738fab11b8f539" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Scale parameter of the distribution</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布のスケールパラメーター</target>
        </trans-unit>
        <trans-unit id="5cf6bbf14633821ae6932495b773f589768f9883" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; half width at half maximum.</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;フロート&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;半値全幅。</target>
        </trans-unit>
        <trans-unit id="8e3168db0f835585afe526c7a2207657fd63567b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scale of the distribution</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布のスケール</target>
        </trans-unit>
        <trans-unit id="e80c10e47ee88300a9ec3b9e4150ab361d1b234b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scale of the full Cauchy distribution</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;フロート&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;完全なコーシー分布のスケール</target>
        </trans-unit>
        <trans-unit id="e3e27d0068eebb99b1c5c41e219ae176a56ddfb6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scale of the full Normal distribution</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;完全な正規分布のスケール</target>
        </trans-unit>
        <trans-unit id="17769021d37f4a1162d81775831adc53c9dbb866" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; standard deviation of log of the distribution</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布の対数の標準偏差</target>
        </trans-unit>
        <trans-unit id="0762f9d704810cff600f854a8a17f9eac019fd19" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; standard deviation of the distribution (often referred to as sigma)</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分布の標準偏差（シグマと呼ばれることが多い）</target>
        </trans-unit>
        <trans-unit id="8dcf78ac62be4f4d6912e826c211335f116f32ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Scale parameter.</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;スケールパラメーター。</target>
        </trans-unit>
        <trans-unit id="7bf27f94abfecc48294933aebaa97dc03946f28b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; (&lt;em&gt;double&lt;/em&gt;) &amp;ndash; output scale. If None, derived from the input scale</source>
          <target state="translated">&lt;strong&gt;scale&lt;/strong&gt;（&lt;em&gt;double&lt;/em&gt;）&amp;ndash;出力スケール。なしの場合、入力スケールから導出</target>
        </trans-unit>
        <trans-unit id="2b336660f6fee25a7f04192c1f5d9cf1fa688414" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale&lt;/strong&gt; - quantization scale of the output, type: double.</source>
          <target state="translated">&lt;strong&gt;スケール&lt;/strong&gt;-出力の量子化スケール、タイプ：ダブル。</target>
        </trans-unit>
        <trans-unit id="a683de9da2c79075bf71043aa5f98cf77b5329fb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;空間サイズの乗数。</target>
        </trans-unit>
        <trans-unit id="87bbe589969398126c66e3c05dc45cc47c8a68bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;空間サイズの乗数。タプルの場合、入力サイズと一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="0990d26d84ad85e506c48292c1fe24a540c4e742" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;空間サイズの乗数。整数である必要があります。</target>
        </trans-unit>
        <trans-unit id="c6a7cf25445a5d29d088501a3080baadf196fbe1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size. Has to match input size if it is a tuple.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;空間サイズの乗数。タプルの場合、入力サイズと一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="9aec3e62b7b949348936978b7c1cb99d932c0d1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; multiplier for spatial size. Has to be an integer.</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;空間サイズの乗数。整数である必要があります。</target>
        </trans-unit>
        <trans-unit id="74af9ed5d3017b743baa3848deaf6665c7f9adf4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; multiplier for spatial size</source>
          <target state="translated">&lt;strong&gt;scale_factor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;空間サイズの乗数</target>
        </trans-unit>
        <trans-unit id="4f035dbf64185002cfc63d6f96931c6065065b6e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_fn&lt;/strong&gt; (&lt;em&gt;function&lt;/em&gt;) &amp;ndash; Custom scaling policy defined by a single argument lambda function, where 0 &amp;lt;= scale_fn(x) &amp;lt;= 1 for all x &amp;gt;= 0. If specified, then &amp;lsquo;mode&amp;rsquo; is ignored. Default: None</source>
          <target state="translated">&lt;strong&gt;scale_fn&lt;/strong&gt;（&lt;em&gt;function&lt;/em&gt;）&amp;ndash;単一引数のラムダ関数で定義されたカスタムスケーリングポリシー。0&amp;lt;= scale_fn（x）&amp;lt;= 1 for all x&amp;gt; = 0.指定されている場合、「mode」は無視されます。デフォルト：なし</target>
        </trans-unit>
        <trans-unit id="dc440c6b67388bb8565432e11af1c8daf58557ee" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt;（&lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;指定されている場合、これはミニバッチ内の単語の頻度の逆数でグラデーションをスケーリングします。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="1a079c4c0b1c3e38cde6fc8a641cfa06c56a1010" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt;（&lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;モジュール初期化のドキュメントを参照してください。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="85cf53fa92b9f2533942327656544089d09a9765" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default &lt;code&gt;False&lt;/code&gt;. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;scale_grad_by_freq&lt;/strong&gt;（&lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash;指定されている場合、これはミニバッチ内の単語の頻度の逆数でグラデーションをスケーリングします。デフォルトは &lt;code&gt;False&lt;/code&gt; です。注： &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; の場合、このオプションはサポートされません。</target>
        </trans-unit>
        <trans-unit id="cd7a2b15683af22c973bad97482e50efa4fda201" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; {&amp;lsquo;cycle&amp;rsquo;, &amp;lsquo;iterations&amp;rsquo;}. Defines whether scale_fn is evaluated on cycle number or cycle iterations (training iterations since start of cycle). Default: &amp;lsquo;cycle&amp;rsquo;</source>
          <target state="translated">&lt;strong&gt;scale_mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash; {'cycle'、 'iterations'}。scale_fnをサイクル数で評価するか、サイクル反復（サイクルの開始以降のトレーニング反復）で評価するかを定義します。デフォルト：「サイクル」</target>
        </trans-unit>
        <trans-unit id="bb349689664c276bbe5b79256f79b9d60afa7249" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scale_tril&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; lower-triangular factor of covariance, with positive-valued diagonal</source>
          <target state="translated">&lt;strong&gt;scale_tril&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;正の値の対角を持つ共分散の低三角因子</target>
        </trans-unit>
        <trans-unit id="1979e70804c1eb78b8633c391b664926b49b8921" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scales&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; float 1D tensor of scales to use, size should match &lt;code&gt;input.size(axis)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;scales&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;使用するスケールのfloat 1Dテンソル、サイズは &lt;code&gt;input.size(axis)&lt;/code&gt; と一致する必要があります</target>
        </trans-unit>
        <trans-unit id="97926b134c895c01bbe8f6c26f328a2eb031fb49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scatter_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; List of tensors to scatter (default is None, must be specified on the source rank)</source>
          <target state="translated">&lt;strong&gt;scatter_list&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;スキャッターするテンソルのリスト（デフォルトはNone、ソースランクで指定する必要があります）</target>
        </trans-unit>
        <trans-unit id="95f54acc947d1c59dde2c9179fd3865f972d8dfa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sci_mode&lt;/strong&gt; &amp;ndash; Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by &lt;code&gt;torch._tensor_str._Formatter&lt;/code&gt;. This value is automatically chosen by the framework.</source>
          <target state="translated">&lt;strong&gt;sci_mode&lt;/strong&gt; &amp;ndash;科学的記数法を有効（True）または無効（False）にします。None（デフォルト）が指定されている場合、値は &lt;code&gt;torch._tensor_str._Formatter&lt;/code&gt; によって定義されます。この値は、フレームワークによって自動的に選択されます。</target>
        </trans-unit>
        <trans-unit id="31b95efb697eb9d32d8d0513d989798a369d679f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;scramble&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Setting this to &lt;code&gt;True&lt;/code&gt; will produce scrambled Sobol sequences. Scrambling is capable of producing better Sobol sequences. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;スクランブル&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;これを &lt;code&gt;True&lt;/code&gt; に設定すると、スクランブルされたソボル列が生成されます。スクランブリングは、より優れたソボル列を生成することができます。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="0ace9de306213673d4dcea0e235e9069d516de2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;script_module&lt;/strong&gt; &amp;ndash; An instance of torch script module with type of ScriptModule.</source>
          <target state="translated">&lt;strong&gt;script_module&lt;/strong&gt; &amp;ndash;タイプがScriptModuleのトーチスクリプトモジュールのインスタンス。</target>
        </trans-unit>
        <trans-unit id="6cbb6e6c8f68076ceee85d8b653f1446d37b3d55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The desired seed.</source>
          <target state="translated">&lt;strong&gt;seed&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;希望の種。</target>
        </trans-unit>
        <trans-unit id="9556506326cc7e5aba9d2bab7c9e945c1aa33011" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The desired seed. Value must be within the inclusive range &lt;code&gt;[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]&lt;/code&gt;. Otherwise, a RuntimeError is raised. Negative inputs are remapped to positive values with the formula &lt;code&gt;0xffff_ffff_ffff_ffff + seed&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;seed&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;希望の種。値は、包括的範囲 &lt;code&gt;[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]&lt;/code&gt; 内である必要があります。それ以外の場合は、RuntimeErrorが発生します。負の入力は、式 &lt;code&gt;0xffff_ffff_ffff_ffff + seed&lt;/code&gt; して正の値に再マップされます。</target>
        </trans-unit>
        <trans-unit id="67900e91c8cb909f9e66451d9b54da1a81002763" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; random seed used to shuffle the sampler if &lt;code&gt;shuffle=True&lt;/code&gt;. This number should be identical across all processes in the distributed group. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;seed&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;shuffle=True&lt;/code&gt; の場合にサンプラーをシャッフルするために使用されるランダムシード。この番号は、分散グループ内のすべてのプロセスで同一である必要があります。デフォルト： &lt;code&gt;0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="42e3c476b10a593814d704cb92704cdb7628a925" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;seed&lt;/strong&gt; (&lt;em&gt;Int&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; This is the seed for the scrambling. The seed of the random number generator is set to this, if specified. Otherwise, it uses a random seed. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;シード&lt;/strong&gt;（&lt;em&gt;Int &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;これはスクランブリングのシードです。指定されている場合、乱数ジェネレーターのシードはこれに設定されます。それ以外の場合は、ランダムシードを使用します。デフォルト： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="34b993f82c0bff4c8876e51f86a4d0cd94041cd4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;segments&lt;/strong&gt; &amp;ndash; Number of chunks to create in the model</source>
          <target state="translated">&lt;strong&gt;セグメント&lt;/strong&gt;&amp;ndash;モデルで作成するチャンクの数</target>
        </trans-unit>
        <trans-unit id="b234df8ca1796df94acd4f2582e16d322c4d7b53" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;self&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the scalar base value for the power operation</source>
          <target state="translated">&lt;strong&gt;self&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;パワー演算のスカラー基数値</target>
        </trans-unit>
        <trans-unit id="3db3b9e470815a2d029e3df80be582d9373bb440" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequence&lt;/strong&gt; (&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;PackedSequence&lt;/a&gt;) &amp;ndash; batch to pad</source>
          <target state="translated">&lt;strong&gt;シーケンス&lt;/strong&gt;（&lt;a href=&quot;torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence&quot;&gt;PackedSequence&lt;/a&gt;）&amp;ndash;バッチからパッド</target>
        </trans-unit>
        <trans-unit id="b266c49abe7b1dae13bdcaca6267d611f6a53c0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; A list of sequences of decreasing length.</source>
          <target state="translated">&lt;strong&gt;シーケンス&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;リスト&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;長さが減少するシーケンスのリスト。</target>
        </trans-unit>
        <trans-unit id="d2e643683d77e2e4974f3cca173d349dcef11874" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sequences&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; list of variable length sequences.</source>
          <target state="translated">&lt;strong&gt;シーケンス&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;リスト&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;可変長シーケンスのリスト。</target>
        </trans-unit>
        <trans-unit id="516d3113df1d3fc366757f1c749d6916067ab846" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;set_to_none&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; instead of setting to zero, set the grads to None. See &lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt;&lt;code&gt;torch.optim.Optimizer.zero_grad()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">&lt;strong&gt;set_to_none&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;ゼロに設定する代わりに、gradsをNoneに設定します。詳細については、&lt;a href=&quot;../optim#torch.optim.Optimizer.zero_grad&quot;&gt; &lt;code&gt;torch.optim.Optimizer.zero_grad()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ae5372adcf73544efed6303bb63476d781673d62" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;set_to_none&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; instead of setting to zero, set the grads to None. This is will in general have lower memory footprint, and can modestly improve performance. However, it changes certain behaviors. For example: 1. When the user tries to access a gradient and perform manual ops on it, a None attribute or a Tensor full of 0s will behave differently. 2. If the user requests &lt;code&gt;zero_grad(set_to_none=True)&lt;/code&gt; followed by a backward pass, &lt;code&gt;.grad&lt;/code&gt;s are guaranteed to be None for params that did not receive a gradient. 3. &lt;code&gt;torch.optim&lt;/code&gt; optimizers have a different behavior if the gradient is 0 or None (in one case it does the step with a gradient of 0 and in the other it skips the step altogether).</source>
          <target state="translated">&lt;strong&gt;set_to_none&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;ゼロに設定する代わりに、gradsをNoneに設定します。これにより、一般的にメモリフットプリントが低くなり、パフォーマンスが適度に向上します。ただし、特定の動作が変更されます。次に例を示します。1。ユーザーがグラデーションにアクセスして手動操作を実行しようとすると、None属性または0でいっぱいのTensorの動作が異なります。 2.ユーザーが &lt;code&gt;zero_grad(set_to_none=True)&lt;/code&gt; の後に逆方向のパスを要求した場合、勾配を受け取らなかった &lt;code&gt;.grad&lt;/code&gt; の.gradはNoneであることが保証されます。 3. &lt;code&gt;torch.optim&lt;/code&gt; オプティマイザーは、勾配が0またはなしの場合に異なる動作をします（一方の場合は勾配0でステップを実行し、もう一方の場合はステップを完全にスキップします）。</target>
        </trans-unit>
        <trans-unit id="1192414a9f920287eff5dbc4ec8c50b8a59e87d8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</source>
          <target state="translated">&lt;strong&gt;形状&lt;/strong&gt;（&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;目的のサイズ</target>
        </trans-unit>
        <trans-unit id="dcd529c43883015420ed4381022949480a774183" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the new shape</source>
          <target state="translated">&lt;strong&gt;形状&lt;/strong&gt;（&lt;em&gt;python：intsのタプル&lt;/em&gt;）&amp;ndash;新しい形状</target>
        </trans-unit>
        <trans-unit id="afa1bc3f88d2613db86fb8ef6b22d240a6775e5f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shape&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired shape</source>
          <target state="translated">&lt;strong&gt;形状&lt;/strong&gt;（&lt;em&gt;python：ints&lt;/em&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;intの&lt;/em&gt;&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;...&lt;/em&gt;）&amp;ndash;目的の形状</target>
        </trans-unit>
        <trans-unit id="182b2a09bf2ce9bed6ebdfb84b2291a8e31953a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shared&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to share memory</source>
          <target state="translated">&lt;strong&gt;共有&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;メモリを共有するかどうか</target>
        </trans-unit>
        <trans-unit id="6bb7f0e432956024dc35ef632a85dc75136860f3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shifts&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; The number of places by which the elements of the tensor are shifted. If shifts is a tuple, dims must be a tuple of the same size, and each dimension will be rolled by the corresponding value</source>
          <target state="translated">&lt;strong&gt;shifts&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;python：intsのタプル&lt;/em&gt;）&amp;ndash;テンソルの要素がシフトされる場所の数。shiftsがタプルの場合、dimは同じサイズのタプルである必要があり、各ディメンションは対応する値でロールされます。</target>
        </trans-unit>
        <trans-unit id="a87a9278041bab20a7726487ef393bef15581381" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shuffle&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt; (default), sampler will shuffle the indices.</source>
          <target state="translated">&lt;strong&gt;shuffle&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; （デフォルト）の場合、サンプラーはインデックスをシャッフルします。</target>
        </trans-unit>
        <trans-unit id="b2afec4ec297d37812ebe2a9e2d39534f54d4b8e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;shuffle&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; set to &lt;code&gt;True&lt;/code&gt; to have the data reshuffled at every epoch (default: &lt;code&gt;False&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;shuffle&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; に設定すると、エポックごとにデータが再シャッフルされます（デフォルト： &lt;code&gt;False&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="03ea4cf5be76330e494785ae14e7e331672f9049" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;signal_ndim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the number of dimensions in each signal. &lt;code&gt;signal_ndim&lt;/code&gt; can only be 1, 2 or 3</source>
          <target state="translated">&lt;strong&gt;signal_ndim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;各信号の次元数。 &lt;code&gt;signal_ndim&lt;/code&gt; は、1、2、または3のみにすることができます</target>
        </trans-unit>
        <trans-unit id="3943ffb53f48c82b94eeb325494fc3c504f9b9b5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;signal_sizes&lt;/strong&gt; (list or &lt;code&gt;torch.Size&lt;/code&gt;, optional) &amp;ndash; the size of the original signal (without batch dimension). Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;signal_sizes&lt;/strong&gt;（listまたは &lt;code&gt;torch.Size&lt;/code&gt; 、オプション）&amp;ndash;元の信号のサイズ（バッチ寸法なし）。デフォルト： &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="50e5115f0007f7707ab429cdfe68e39549183aab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; &amp;ndash; amount of neighbouring channels used for normalization</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;&amp;ndash;正規化に使用される隣接チャネルの量</target>
        </trans-unit>
        <trans-unit id="8fa4eb29dfbddf8f29442f7879d71c63e1cbeecf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of elements in the storage</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ストレージ内の要素の数</target>
        </trans-unit>
        <trans-unit id="275c9f306dba8511bb3cfa93aa9598de38ef32ca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of each slice that is unfolded</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;展開される各スライスのサイズ</target>
        </trans-unit>
        <trans-unit id="0b59659707a6fdfb9c664448cffe7da20582f359" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatia size.</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;出力スパティアサイズ。</target>
        </trans-unit>
        <trans-unit id="cdf514b8ff20b8c4739f70c9f9e484a81b944c49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;出力空間サイズ。</target>
        </trans-unit>
        <trans-unit id="149915349ce02ffdf5ceea93fe5bb247fae568e2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;出力空間サイズ。</target>
        </trans-unit>
        <trans-unit id="16964d2ffbdb9acd4dd1156889d58d0dbd349b50" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力空間サイズ</target>
        </trans-unit>
        <trans-unit id="ec88c2bc82655addd9428024abd5b8f71a7f9cae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; output spatial size.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;出力空間サイズ。</target>
        </trans-unit>
        <trans-unit id="efc98ce302823923f910c2ca140408828b2cf385" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; output spatial sizes</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;Tuple &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力空間サイズ</target>
        </trans-unit>
        <trans-unit id="0f7b874897c486cf1ce74a993c5f615d99fa025b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; a tuple defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;出力テンソルの形状を定義するタプル。</target>
        </trans-unit>
        <trans-unit id="03a0a29e015390c8b6d2b6595aefea70b182be7a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;int&lt;/em&gt;）&amp;ndash;出力テンソルの形状</target>
        </trans-unit>
        <trans-unit id="26a6ff6e605560d0327d5d701a4a8866e0a1e65d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt; of integers defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;リスト、タプル、または &lt;code&gt;torch.Size&lt;/code&gt; 。出力テンソルの形状を定義する整数の&lt;strong&gt;サイズ&lt;/strong&gt;。</target>
        </trans-unit>
        <trans-unit id="1a4f563f5d02f780ce83e0cc48b42515c2124c45" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;出力テンソルの形状を定義する整数のシーケンス。</target>
        </trans-unit>
        <trans-unit id="6f9a10015b06b51485833aee1a18eb0d6ca9ec1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;出力テンソルの形状を定義する整数のシーケンス。可変数の引数、またはリストやタプルなどのコレクションにすることができます。</target>
        </trans-unit>
        <trans-unit id="94baf289fa3f083898ae05024e21746311170982" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;) &amp;ndash; the target output image size. (</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（&lt;em&gt;torch.Size&lt;/em&gt;）&amp;ndash;ターゲット出力画像サイズ。（（</target>
        </trans-unit>
        <trans-unit id="f072e677d05eac98b80bb810fa352b0b054f140e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired size. Defaults to the size of the source.</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;em&gt;torch.Size &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;目的のサイズ。デフォルトはソースのサイズです。</target>
        </trans-unit>
        <trans-unit id="3fc5235f279542b6d70b7bd49613ee59572fce51" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the shape of the output tensor</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;em&gt;python：intsのタプル&lt;/em&gt;）&amp;ndash;出力テンソルの形状</target>
        </trans-unit>
        <trans-unit id="bd9344ee97a013a9847fea7b4e8e18307f4e8e61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size&lt;/strong&gt; (list, tuple, or &lt;code&gt;torch.Size&lt;/code&gt;, optional) &amp;ndash; Size of the sparse tensor. If not provided the size will be inferred as the minimum size big enough to hold all non-zero elements.</source>
          <target state="translated">&lt;strong&gt;size&lt;/strong&gt;（list、tuple、または &lt;code&gt;torch.Size&lt;/code&gt; 、オプション）&amp;ndash;スパーステンソルのサイズ。指定しない場合、サイズは、ゼロ以外のすべての要素を保持するのに十分な大きさの最小サイズとして推測されます。</target>
        </trans-unit>
        <trans-unit id="7c9af3450b1512ce0b9ac6b4af383477e20316fa" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;size_average&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;非推奨（ &lt;code&gt;reduction&lt;/code&gt; を参照）。デフォルトでは、損失はバッチ内の各損失要素で平均化されます。一部の損失については、サンプルごとに複数の要素があることに注意してください。フィールド &lt;code&gt;size_average&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; に設定されている場合、損失は代わりにミニバッチごとに合計されます。reduceが &lt;code&gt;False&lt;/code&gt; の場合は無視されます。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="a285cc358e12c5f4409aa06b08afb278f4b8c558" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;size_average&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Deprecated (see &lt;code&gt;reduction&lt;/code&gt;). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field &lt;code&gt;size_average&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, the losses are instead summed for each minibatch. Ignored when reduce is &lt;code&gt;False&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;size_average&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;非推奨（ &lt;code&gt;reduction&lt;/code&gt; を参照）。デフォルトでは、損失はバッチ内の各損失要素で平均化されます。一部の損失については、サンプルごとに複数の要素があることに注意してください。フィールド &lt;code&gt;size_average&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; に設定されている場合、損失は代わりにミニバッチごとに合計されます。reduceが &lt;code&gt;False&lt;/code&gt; の場合は無視されます。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5308eb7679205686160791ca8161c5d58dbfe2c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;] or &lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;em&gt;連合&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;]または&lt;/em&gt;&lt;em&gt;torch.Size &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;STR &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;]&lt;/em&gt;） -平坦化されない大きさの新しい形</target>
        </trans-unit>
        <trans-unit id="e1ebc0e50c25e5537cd83715368f39f3ae4ecbfc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; The number of times to repeat this tensor along each dimension</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;各次元に沿ってこのテンソルを繰り返す回数</target>
        </trans-unit>
        <trans-unit id="0a54d8fbd33de9da7dc0fc42b5e2c08cb4d412fd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sizes&lt;/strong&gt; (&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;int...&lt;/em&gt;) &amp;ndash; the desired size</source>
          <target state="translated">&lt;strong&gt;サイズ&lt;/strong&gt;（&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;int..。&lt;/em&gt;）&amp;ndash;目的のサイズ</target>
        </trans-unit>
        <trans-unit id="3ed38299ca2e29a9d9250d3fd4689c245a1c9056" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;snd_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Sound data</source>
          <target state="translated">&lt;strong&gt;snd_tensor&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;サウンドデータ</target>
        </trans-unit>
        <trans-unit id="04df36410cc80bf7688b9b2775248dad717b281c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;solution&lt;/strong&gt; (&lt;em&gt;Tensor&lt;/em&gt;): the least squares solution</source>
          <target state="translated">&lt;strong&gt;解&lt;/strong&gt;（&lt;em&gt;テンソル&lt;/em&gt;）：最小二乗解</target>
        </trans-unit>
        <trans-unit id="a7ea50e0998478f8190ddf227de9fc8ccad28e5a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Set to &lt;code&gt;True&lt;/code&gt; for reduced QR decomposition and &lt;code&gt;False&lt;/code&gt; for complete QR decomposition.</source>
          <target state="translated">&lt;strong&gt;some&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; QR分解を減らすには &lt;code&gt;True&lt;/code&gt; に設定し、完全なQR分解には &lt;code&gt;False&lt;/code&gt; に設定します。</target>
        </trans-unit>
        <trans-unit id="07a0dcb8d5e99634c38c0e2c2522103284a69856" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;some&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls the shape of returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;some&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;返される &lt;code&gt;U&lt;/code&gt; と &lt;code&gt;V&lt;/code&gt; の形状を制御します</target>
        </trans-unit>
        <trans-unit id="815339fca61a4eec429f6db55252b5c5d2c244f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sort_by&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Attribute used to sort entries. By default they are printed in the same order as they were registered. Valid keys include: &lt;code&gt;cpu_time&lt;/code&gt;, &lt;code&gt;cuda_time&lt;/code&gt;, &lt;code&gt;cpu_time_total&lt;/code&gt;, &lt;code&gt;cuda_time_total&lt;/code&gt;, &lt;code&gt;cpu_memory_usage&lt;/code&gt;, &lt;code&gt;cuda_memory_usage&lt;/code&gt;, &lt;code&gt;self_cpu_memory_usage&lt;/code&gt;, &lt;code&gt;self_cuda_memory_usage&lt;/code&gt;, &lt;code&gt;count&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;sort_by&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;エントリのソートに使用される属性。デフォルトでは、登録されたのと同じ順序で印刷されます。有効なキーは次の &lt;code&gt;cpu_time&lt;/code&gt; です。cpu_time、 &lt;code&gt;cuda_time&lt;/code&gt; 、 &lt;code&gt;cpu_time_total&lt;/code&gt; 、 &lt;code&gt;cuda_time_total&lt;/code&gt; 、 &lt;code&gt;cpu_memory_usage&lt;/code&gt; 、 &lt;code&gt;cuda_memory_usage&lt;/code&gt; 、 &lt;code&gt;self_cpu_memory_usage&lt;/code&gt; 、 &lt;code&gt;self_cuda_memory_usage&lt;/code&gt; 、 &lt;code&gt;count&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="c964615183041f78000d335f6006659de8eaa42a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to sort the unique elements in ascending order before returning as output.</source>
          <target state="translated">&lt;strong&gt;ソート済み&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;出力として返す前に一意の要素を昇順でソートするかどうか。</target>
        </trans-unit>
        <trans-unit id="d9cd0c6e3bf7a9c26be9ab6eb578de1df1d27078" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to return the elements in sorted order</source>
          <target state="translated">&lt;strong&gt;ソート済み&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;要素をソート済みの順序で返すかどうかを制御します</target>
        </trans-unit>
        <trans-unit id="ba3bc3fc862fb1d978c7e8f26f45ac4560b6cbb6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sorted_sequence&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; N-D or 1-D tensor, containing monotonically increasing sequence on the &lt;em&gt;innermost&lt;/em&gt; dimension.</source>
          <target state="translated">&lt;strong&gt;sort_sequence&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&lt;strong&gt;&amp;ndash;ND&lt;/strong&gt;または1-Dテンソル。&lt;em&gt;最も内側の&lt;/em&gt;次元で単調に増加するシーケンスを含みます。</target>
        </trans-unit>
        <trans-unit id="ff092f5a8d7513d4041f8ec05bf6db9a6433a55a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to copy from</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;コピー&lt;strong&gt;元の&lt;/strong&gt;テンソル</target>
        </trans-unit>
        <trans-unit id="d3e050c1ccd84c4a56619568303f30198e45f1ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Storage&lt;/em&gt;) &amp;ndash; the tensor or storage to use</source>
          <target state="translated">&lt;strong&gt;ソース&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;ストレージ&lt;/em&gt;）&amp;ndash;使用するテンソルまたはストレージ</target>
        </trans-unit>
        <trans-unit id="537a3683bbbd7cb37d1a1e68afc20c93f4950810" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; Original positions of the dims to move. These must be unique.</source>
          <target state="translated">&lt;strong&gt;source&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;python：intsのタプル&lt;/em&gt;）&amp;ndash;移動するdimの元の位置。これらは一意である必要があります。</target>
        </trans-unit>
        <trans-unit id="736b5df270b468d2d70fee90f0c6304038935e20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;source&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; &lt;code&gt;'github'&lt;/code&gt; | &lt;code&gt;'local'&lt;/code&gt;. Specifies how &lt;code&gt;repo_or_dir&lt;/code&gt; is to be interpreted. Default is &lt;code&gt;'github'&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;ソース&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;'github'&lt;/code&gt; | &lt;code&gt;'local'&lt;/code&gt; 。 &lt;code&gt;repo_or_dir&lt;/code&gt; の解釈方法を指定します。デフォルトは &lt;code&gt;'github'&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="7e187210f431543be9a1749f439d018aa4b11087" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sources&lt;/strong&gt; &amp;ndash; A list of relative or absolute paths to C++ source files.</source>
          <target state="translated">&lt;strong&gt;ソース&lt;/strong&gt;&amp;ndash; C ++ソースファイルへの相対パスまたは絶対パスのリスト。</target>
        </trans-unit>
        <trans-unit id="16b83bb63832023cd48fcbf7cf2e3c51644ad4e7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、勾配wrt &lt;code&gt;weight&lt;/code&gt; 行列はスパーステンソルになります。スパースグラデーションの詳細については、注を参照してください。</target>
        </trans-unit>
        <trans-unit id="d82071676e26d482c374d70ee42605a5252d8f79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; will be a sparse tensor. See Notes under &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details regarding sparse gradients.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、 &lt;code&gt;weight&lt;/code&gt; 勾配はスパーステンソルになります。スパースグラデーションの詳細については、&lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt; &lt;code&gt;torch.nn.Embedding&lt;/code&gt; の&lt;/a&gt;下の注を参照してください。</target>
        </trans-unit>
        <trans-unit id="490e7f9dc42b376ca2804c6155a64ad37564fb2c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;モジュール初期化のドキュメントを参照してください。</target>
        </trans-unit>
        <trans-unit id="ef9a73bc582ac8360689c39a1c63c78ddde0dd12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; See module initialization documentation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;sparse&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;モジュール初期化のドキュメントを参照してください。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="ac1945361265423208febe431a5add209b0405e6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; matrix will be a sparse tensor. See Notes for more details regarding sparse gradients. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;スパース&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、勾配wrt &lt;code&gt;weight&lt;/code&gt; 行列はスパーステンソルになります。スパースグラデーションの詳細については、注を参照してください。注： &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; の場合、このオプションはサポートされません。</target>
        </trans-unit>
        <trans-unit id="264742d3a555bb6302cc2b99bcbdbaea90e73571" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;weight&lt;/code&gt; will be a sparse tensor. See Notes under &lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt;&lt;code&gt;torch.nn.Embedding&lt;/code&gt;&lt;/a&gt; for more details regarding sparse gradients. Note: this option is not supported when &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;スパース&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、 &lt;code&gt;weight&lt;/code&gt; 勾配はスパーステンソルになります。スパースグラデーションの詳細については、&lt;a href=&quot;generated/torch.nn.embedding#torch.nn.Embedding&quot;&gt; &lt;code&gt;torch.nn.Embedding&lt;/code&gt; の&lt;/a&gt;下の注を参照してください。注： &lt;code&gt;mode=&quot;max&quot;&lt;/code&gt; の場合、このオプションはサポートされません。</target>
        </trans-unit>
        <trans-unit id="94981b1994886031e5de3502e8d05e4753cd4159" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparseDims&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the number of sparse dimensions to include in the new sparse tensor</source>
          <target state="translated">&lt;strong&gt;sparseDims&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;新しいスパーステンソルに含めるスパース次元の数</target>
        </trans-unit>
        <trans-unit id="4b18e538096fb082b8177bc1560caf9a9d7bc9a7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparse_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, gradient w.r.t. &lt;code&gt;input&lt;/code&gt; will be a sparse tensor.</source>
          <target state="translated">&lt;strong&gt;sparse_grad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、勾配wrt &lt;code&gt;input&lt;/code&gt; はスパーステンソルになります。</target>
        </trans-unit>
        <trans-unit id="b37daeb607924ba93a0bda59b58e026064bd654d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;sparsity&lt;/strong&gt; &amp;ndash; The fraction of elements in each column to be set to zero</source>
          <target state="translated">&lt;strong&gt;スパース性&lt;/strong&gt;&amp;ndash;ゼロに設定される各列の要素の割合</target>
        </trans-unit>
        <trans-unit id="e30145ed58f140ce4c89e2f335125ba650c4f507" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;split_size_or_sections&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;) or &lt;/em&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;(&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;)&lt;/em&gt;) &amp;ndash; size of a single chunk or list of sizes for each chunk</source>
          <target state="translated">&lt;strong&gt;split_size_or_sections&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;）または&lt;/em&gt;&lt;em&gt;（&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list &lt;/a&gt;&lt;em&gt;（&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;）&lt;/em&gt;）&amp;ndash;単一のチャンクのサイズまたは各チャンクのサイズのリスト</target>
        </trans-unit>
        <trans-unit id="9b97dbfc339fde5bc389bd8ab93d7f7cb7c44dfc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; the sequence to the encoder (required).</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; &amp;ndash;エンコーダーへのシーケンス（必須）。</target>
        </trans-unit>
        <trans-unit id="78fa5919448d76e6a64f4bd45287924a3a34df33" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; &amp;ndash; the sequence to the encoder layer (required).</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt; &amp;ndash;エンコーダーレイヤーへのシーケンス（必須）。</target>
        </trans-unit>
        <trans-unit id="3cbdd89942669cde945cfe86a26dcfcd5645519c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source element(s) to scatter, incase &lt;code&gt;value&lt;/code&gt; is not specified</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash; &lt;code&gt;value&lt;/code&gt; が指定されていない場合に分散するソース要素</target>
        </trans-unit>
        <trans-unit id="c00ac345411ae3480e897e5cbdd023e0d52ba5ba" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source elements to scatter and add</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分散して追加するソース要素</target>
        </trans-unit>
        <trans-unit id="cca60735cb66c0fd24e9daf6bd9a2d6affdd8b18" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the source tensor to copy from</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;コピー元のソーステンソル</target>
        </trans-unit>
        <trans-unit id="2605c126b88196f5cf7d630fe3b356d67096670b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Source rank (default is 0)</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ソースランク（デフォルトは0）</target>
        </trans-unit>
        <trans-unit id="5422756d7624b629fb6d789ff63552dac7a631ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Source rank.</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ソースランク。</target>
        </trans-unit>
        <trans-unit id="6ecfc113b4210a133571a1ba6eee75db6462f3ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Source rank. Will receive from any process if unspecified.</source>
          <target state="translated">&lt;strong&gt;src&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ソースランク。指定されていない場合、任意のプロセスから受信します。</target>
        </trans-unit>
        <trans-unit id="1bf7cb7495026465a5e025f645be215970d3c3f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for src keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash;バッチごとのsrcキーのByteTensorマスク（オプション）。</target>
        </trans-unit>
        <trans-unit id="20d1aac54a28167b80b444f3e283804c33610581" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the src keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;src_key_padding_mask&lt;/strong&gt; &amp;ndash;バッチごとのsrcキーのマスク（オプション）。</target>
        </trans-unit>
        <trans-unit id="2e4d7f0b7f046f61667e190129080811355c102a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; the additive mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; srcシーケンスの追加マスク（オプション）。</target>
        </trans-unit>
        <trans-unit id="b8ff899002109344c4f233e16bca9c3f67cf5740" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; the mask for the src sequence (optional).</source>
          <target state="translated">&lt;strong&gt;src_mask&lt;/strong&gt; &amp;ndash; srcシーケンスのマスク（オプション）。</target>
        </trans-unit>
        <trans-unit id="480ed9f7356f0f1438f0c3e67548752e2e88b19d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;src_tensor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Source tensor rank within &lt;code&gt;tensor_list&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;src_tensor&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） &lt;code&gt;tensor_list&lt;/code&gt; 内のソーステンソルランク</target>
        </trans-unit>
        <trans-unit id="6c54e581b4a64152f841eae4b7132eca48a8ce38" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the starting value for the set of points</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;一連のポイントの開始値</target>
        </trans-unit>
        <trans-unit id="fd9b8604b8d10a61d30a016be638c8f89e228f17" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the starting value for the set of points. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;ポイントのセットの開始値。デフォルト： &lt;code&gt;0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="61cea1b64e6864ce3fd4c5cdb9ba97526597a0e9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the starting dimension</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;開始ディメンション</target>
        </trans-unit>
        <trans-unit id="017f9db566260fcc32ff561f6f41f549f1ab1b1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the starting value for the set of points. Default: &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;start&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;）&amp;ndash;ポイントのセットの開始値。デフォルト： &lt;code&gt;0&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="db305563060fce9be4b380f28e1127159859b2ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start_dim&lt;/strong&gt; &amp;ndash; first dim to flatten (default = 1).</source>
          <target state="translated">&lt;strong&gt;start_dim&lt;/strong&gt; &amp;ndash;フラット化する最初の&lt;strong&gt;調&lt;/strong&gt;光（デフォルト= 1）。</target>
        </trans-unit>
        <trans-unit id="1aa7a3bfd2813f5dbf3d94b9c4043556308d2159" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the first dim to flatten</source>
          <target state="translated">&lt;strong&gt;start_dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;最初に平坦化するdim</target>
        </trans-unit>
        <trans-unit id="13b544bfd8927b59e44add059240511dff37c576" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;start_method&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; (deprecated) this method will always use &lt;code&gt;spawn&lt;/code&gt; as the start method. To use a different start method use &lt;code&gt;start_processes()&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;start_method&lt;/strong&gt;（&lt;em&gt;string&lt;/em&gt;）&amp;ndash;（非推奨）このメソッドは常に &lt;code&gt;spawn&lt;/code&gt; をstartメソッドとして使用します。別のstartメソッドを使用するには、 &lt;code&gt;start_processes()&lt;/code&gt; を使用します。</target>
        </trans-unit>
        <trans-unit id="e706afdee5bbb0a79b5a2f832271401d69b23519" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; a dict containing parameters and persistent buffers.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;パラメーターと永続バッファーを含むdict。</target>
        </trans-unit>
        <trans-unit id="6d5556d76adbdb45cbe68476db8185b5492374d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; optimizer state. Should be an object returned from a call to &lt;a href=&quot;#torch.optim.Optimizer.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;オプティマイザーの状態。&lt;a href=&quot;#torch.optim.Optimizer.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; の&lt;/a&gt;呼び出しから返されるオブジェクトである必要があります。</target>
        </trans-unit>
        <trans-unit id="5cbbb29e1fe7881fd5844bacc7ca16ca6b9024eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; scaler state. Should be an object returned from a call to &lt;a href=&quot;#torch.cuda.amp.GradScaler.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;スケーラーの状態。&lt;a href=&quot;#torch.cuda.amp.GradScaler.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; の&lt;/a&gt;呼び出しから返されるオブジェクトである必要があります。</target>
        </trans-unit>
        <trans-unit id="66750c76d7c187af01e3a824d960ff4b84685f61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; scheduler state. Should be an object returned from a call to &lt;a href=&quot;#torch.optim.lr_scheduler.LambdaLR.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;スケジューラーの状態。&lt;a href=&quot;#torch.optim.lr_scheduler.LambdaLR.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; の&lt;/a&gt;呼び出しから返されるオブジェクトである必要があります。</target>
        </trans-unit>
        <trans-unit id="b56f7ed2e459a991898c4628d117292ad6733aef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;state_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; scheduler state. Should be an object returned from a call to &lt;a href=&quot;#torch.optim.lr_scheduler.MultiplicativeLR.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;state_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;スケジューラーの状態。&lt;a href=&quot;#torch.optim.lr_scheduler.MultiplicativeLR.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; の&lt;/a&gt;呼び出しから返されるオブジェクトである必要があります。</target>
        </trans-unit>
        <trans-unit id="397f739ec24999cef4aedd3f271bf305d11784f1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; the standard deviation of the normal distribution</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; &amp;ndash;正規分布の標準偏差</target>
        </trans-unit>
        <trans-unit id="19af3df9428cf525a7500c9af96c43b782849a34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; &amp;ndash; the standard deviation of the normal distribution used to generate the non-zero values</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt; &amp;ndash;ゼロ以外の値を生成するために使用される正規分布の標準偏差</target>
        </trans-unit>
        <trans-unit id="8fd58ae2ac219c0c179d6b0c321bc9877f3d5c08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor of per-element standard deviations</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;要素ごとの標準偏差のテンソル</target>
        </trans-unit>
        <trans-unit id="cc539f1fbf4c4bdbab694cd3aa4e1e85f66c6288" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the standard deviation for all distributions</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;すべての分布の標準偏差</target>
        </trans-unit>
        <trans-unit id="5c558f61587c7e53fc6d918f3a17c5e6dd6e0602" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;std&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the standard deviation for all distributions</source>
          <target state="translated">&lt;strong&gt;std&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;すべての分布の標準偏差</target>
        </trans-unit>
        <trans-unit id="baf9f5309ab39bb6c1581c5f3b05b5bdbedb7c06" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the gap between each pair of adjacent points. Default: &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;step&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;隣接するポイントの各ペア間のギャップ。デフォルト： &lt;code&gt;1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1abac8c895387b0b9cd2795f79c2431234a95f31" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the step between each slice</source>
          <target state="translated">&lt;strong&gt;step&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;各スライス間のステップ</target>
        </trans-unit>
        <trans-unit id="55d5b2b9ad99b0efd35850f714bb971bc246e22f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the gap between each pair of adjacent points. Default: &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;ステップ&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;）&amp;ndash;隣接するポイントの各ペア間のギャップ。デフォルト： &lt;code&gt;1&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="f83940981c3f69f7e6548653f4f568bae12ff7dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Period of learning rate decay.</source>
          <target state="translated">&lt;strong&gt;step_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;学習率の低下の期間。</target>
        </trans-unit>
        <trans-unit id="f24616594618270e9b38c9591ee4052979020811" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step_size_down&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of training iterations in the decreasing half of a cycle. If step_size_down is None, it is set to step_size_up. Default: None</source>
          <target state="translated">&lt;strong&gt;step_size_down&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;サイクルの減少する半分でのトレーニングの反復回数。step_size_downがNoneの場合、step_size_upに設定されます。デフォルト：なし</target>
        </trans-unit>
        <trans-unit id="a4590b69559f14282bc9131a5417b5b46f2b757a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step_size_up&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of training iterations in the increasing half of a cycle. Default: 2000</source>
          <target state="translated">&lt;strong&gt;step_size_up&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;サイクルの増加する半分でのトレーニングの反復回数。デフォルト：2000</target>
        </trans-unit>
        <trans-unit id="1c7814a208624eebc76b6a820bea42f2dd649e23" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;step_sizes&lt;/strong&gt; (&lt;em&gt;Tuple&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a pair of minimal and maximal allowed step sizes (default: (1e-6, 50))</source>
          <target state="translated">&lt;strong&gt;step_sizes&lt;/strong&gt;（&lt;em&gt;タプル&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;許可される最小および最大のステップサイズのペア（デフォルト：（1e- &lt;strong&gt;6、50&lt;/strong&gt;））</target>
        </trans-unit>
        <trans-unit id="a166db3ce9222d4bcbe13cb6bde4fbbfc394f117" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;steps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; size of the constructed tensor</source>
          <target state="translated">&lt;strong&gt;ステップ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;構築されたテンソルのサイズ</target>
        </trans-unit>
        <trans-unit id="bb9aa8a045e47f15c5cda85f9343f2cff9c54503" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;steps_per_epoch&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of steps per epoch to train for. This is used along with epochs in order to infer the total number of steps in the cycle if a value for total_steps is not provided. Default: None</source>
          <target state="translated">&lt;strong&gt;Steps_per_epoch&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;トレーニングするエポックあたりのステップ数。total_stepsの値が指定されていない場合、これはサイクル内の合計ステップ数を推測するためにエポックとともに使用されます。デフォルト：なし</target>
        </trans-unit>
        <trans-unit id="2401eb00fd1cd4eb0e88575af75256fc34e93df2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;storage_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the offset in the storage</source>
          <target state="translated">&lt;strong&gt;storage_offset&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ストレージ内のオフセット</target>
        </trans-unit>
        <trans-unit id="a464ae09605bcd29232df8491b551330fa7b201e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;storage_offset&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the offset in the underlying storage of the output tensor</source>
          <target state="translated">&lt;strong&gt;storage_offset&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;出力テンソルの基になるストレージのオフセット</target>
        </trans-unit>
        <trans-unit id="36921320f19d087af835850826666bf4b078eaa7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;store&lt;/strong&gt; (&lt;a href=&quot;#torch.distributed.Store&quot;&gt;Store&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Key/value store accessible to all workers, used to exchange connection/address information. Mutually exclusive with &lt;code&gt;init_method&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;store&lt;/strong&gt;（&lt;a href=&quot;#torch.distributed.Store&quot;&gt;Store &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;接続/アドレス情報を交換するために使用される、すべてのワーカーがアクセスできるキー/値ストア。 &lt;code&gt;init_method&lt;/code&gt; と相互に排他的です。</target>
        </trans-unit>
        <trans-unit id="4dc03df96ec79acaac3452a59e6207bd786c9d6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;store&lt;/strong&gt; (&lt;em&gt;torch.distributed.store&lt;/em&gt;) &amp;ndash; A store object that forms the underlying key-value store.</source>
          <target state="translated">&lt;strong&gt;store&lt;/strong&gt;（&lt;em&gt;torch.distributed.store&lt;/em&gt;）&amp;ndash;基になるKey-Valueストアを形成するストアオブジェクト。</target>
        </trans-unit>
        <trans-unit id="3808a536d61ce3eeaf910236762d7fc972e3843c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stream&lt;/strong&gt; (&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream&lt;/a&gt;) &amp;ndash; a stream to synchronize.</source>
          <target state="translated">&lt;strong&gt;stream&lt;/strong&gt;（&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream&lt;/a&gt;）&amp;ndash;同期するストリーム。</target>
        </trans-unit>
        <trans-unit id="44c2c07b80e8e091417520bc0794619cec3517a3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stream&lt;/strong&gt; (&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream&lt;/a&gt;) &amp;ndash; selected stream. This manager is a no-op if it&amp;rsquo;s &lt;code&gt;None&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;stream&lt;/strong&gt;（&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream&lt;/a&gt;）&amp;ndash;選択されたストリーム。このマネージャーは、 &lt;code&gt;None&lt;/code&gt; の場合は何もしません。</target>
        </trans-unit>
        <trans-unit id="0d198b00164cdb2d75aad580963cb14be1623fbe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;streams&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; an iterable of Streams, among which to execute the scatter. If not specified, the default stream will be utilized.</source>
          <target state="translated">&lt;strong&gt;ストリーム&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;#torch.cuda.Stream&quot;&gt;Stream &lt;/a&gt;&lt;em&gt;] &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;スキャッターを実行するためのStreamsの反復可能。指定しない場合、デフォルトのストリームが使用されます。</target>
        </trans-unit>
        <trans-unit id="15a9a33618c8145e65db0df141897cb687b7f41b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the hessian for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、期待される数学的値である、上記の入力のヘッセ行列としてゼロのテンソルを返します。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="521e1bbc2df156a33be4ed0a762f4b6dc1c8ad68" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the hvp for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、上記の入力のhvpとしてゼロのテンソルを返します。これは予想される数学的値です。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="c862109158a12033724c85557e4c10782bcd3e2a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the jacobian for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、期待される数学的値である、上記の入力のヤコビアンとしてゼロのテンソルを返します。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="d3196a755940ba28a032a950660ced9d1132f5ff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the jvp for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、上記の入力のjvpとしてゼロのテンソルを返します。これは予想される数学的値です。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="0cf1dbbdc41dad0369c4ebb8aa27533a686a95a2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the vhp for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、上記の入力のvhpとしてゼロのテンソルを返します。これは予想される数学的値です。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="ddeb9357a7bf045b78eba2cf1739a79dd06a4609" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, an error will be raised when we detect that there exists an input such that all the outputs are independent of it. If &lt;code&gt;False&lt;/code&gt;, we return a Tensor of zeros as the vjp for said inputs, which is the expected mathematical value. Defaults to &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、すべての出力が独立しているような入力が存在することを検出すると、エラーが発生します。 &lt;code&gt;False&lt;/code&gt; の場合、上記の入力のvjpとしてゼロのテンソルを返します。これは予想される数学的値です。デフォルトは &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="aef94a04df5ea5876b7e12de6f0824f58976f3e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&lt;a href=&quot;#torch.jit.ScriptModule.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;のキーがこのモジュールの&lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt;関数によって返されるキーと一致することを厳密に強制するかどうか。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="33b205deb049448da3c0a8dc2d460e0783955775" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&lt;a href=&quot;#torch.nn.Flatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;のキーがこのモジュールの&lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt;関数によって返されるキーと一致することを厳密に強制するかどうか。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ea9289c76d8286090b8a4f3dd767eca0a4c5e0c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;のキーがこのモジュールの&lt;a href=&quot;#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt;関数によって返されるキーと一致することを厳密に強制するかどうか。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="1544925b842cb8d8b87627d19af858e20b780645" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to strictly enforce that the keys in &lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt;&lt;code&gt;state_dict&lt;/code&gt;&lt;/a&gt; match the keys returned by this module&amp;rsquo;s &lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; function. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&lt;a href=&quot;#torch.nn.Unflatten.state_dict&quot;&gt; &lt;code&gt;state_dict&lt;/code&gt; &lt;/a&gt;のキーがこのモジュールの&lt;a href=&quot;torch.nn.module#torch.nn.Module.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt;関数によって返されるキーと一致することを厳密に強制するかどうか。デフォルト： &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="685790b38e543d30d0b76c6ee8fcd86be2ab18e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strict&lt;/strong&gt; (&lt;code&gt;bool&lt;/code&gt;, optional) &amp;ndash; run the tracer in a strict mode or not (default: &lt;code&gt;True&lt;/code&gt;). Only turn this off when you want the tracer to record your mutable container types (currently &lt;code&gt;list&lt;/code&gt;/&lt;code&gt;dict&lt;/code&gt;) and you are sure that the container you are using in your problem is a &lt;code&gt;constant&lt;/code&gt; structure and does not get used as control flow (if, for) conditions.</source>
          <target state="translated">&lt;strong&gt;strict&lt;/strong&gt;（ &lt;code&gt;bool&lt;/code&gt; 、オプション）&amp;ndash;トレーサーをstrictモードで実行するかどうか（デフォルト： &lt;code&gt;True&lt;/code&gt; ）。トレーサーに可変コンテナータイプ（現在は &lt;code&gt;list&lt;/code&gt; / &lt;code&gt;dict&lt;/code&gt; ）を記録させ、問題で使用しているコンテナーが &lt;code&gt;constant&lt;/code&gt; 構造であり、制御フローとして使用されないことが確実な場合にのみ、これをオフにします（ ）条件。</target>
        </trans-unit>
        <trans-unit id="d42c648d3610293a7cf248220e9664c5134177bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; The stride of the sliding window, must be &amp;gt; 0. Default value is &lt;code&gt;kernel_size&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash;スライディングウィンドウのストライドは0より大きい必要があります。デフォルト値は &lt;code&gt;kernel_size&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="ece50bfaa1c42101ecdb71c0cdd588d8acf212c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; a single int, the stride of the window. Default value is &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;単一の整数、ウィンドウのストライド。デフォルト値は &lt;code&gt;kernel_size&lt;/code&gt; です</target>
        </trans-unit>
        <trans-unit id="3d66128b0d5b6f8a04eda5e5cafb00185fe896d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; stride of the pooling operation. Can be a single number or a tuple &lt;code&gt;(sH, sW)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;プーリング操作のストライド。単一の数値またはタプル &lt;code&gt;(sH, sW)&lt;/code&gt; することができます。デフォルト： &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="214b0bd7f37429dbe8ebc6dded03c3882c664098" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; stride of the pooling operation. Can be a single number or a tuple &lt;code&gt;(sT, sH, sW)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;プーリング操作のストライド。単一の数値またはタプル &lt;code&gt;(sT, sH, sW)&lt;/code&gt; にすることができます。デフォルト： &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c0738f57cba9ff50e90a91a07935ba7bfbd70a60" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a one-element tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;畳み込みカーネルのストライド。単一の数値または1つの要素のタプル &lt;code&gt;(sW,)&lt;/code&gt; にすることができます。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="a8bfc0051811863634e34e362ca2dc7ac04c0a76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sD, sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;畳み込みカーネルのストライド。単一の数値またはタプル &lt;code&gt;(sD, sH, sW)&lt;/code&gt; にすることができます。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="e99fe233d3379e77fe12415abc7f2b4a4414ea6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;畳み込みカーネルのストライド。単一の数値またはタプル &lt;code&gt;(sH, sW)&lt;/code&gt; することができます。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="dc03b1c42fd2881680cf96ca6f9def163d1c788c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sT, sH, sW)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;畳み込みカーネルのストライド。単一の数値またはタプル &lt;code&gt;(sT, sH, sW)&lt;/code&gt; にすることができます。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="1e07709d5ef30fc3327e2bffbfec50c789ae30d7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the convolving kernel. Can be a single number or a tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;畳み込みカーネルのストライド。単一の数値またはタプル &lt;code&gt;(sW,)&lt;/code&gt; することができます。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="6a3d3677bf8aef87647950a0175bf46a290a6881" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the window. Can be a single number or a tuple &lt;code&gt;(sW,)&lt;/code&gt;. Default: &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;ウィンドウのストライド。単一の数値またはタプル &lt;code&gt;(sW,)&lt;/code&gt; することができます。デフォルト： &lt;code&gt;kernel_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4d1ac3de99275d24a51b19deff5f49a4c626918a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; &amp;ndash; the stride of the window. Default value is &lt;code&gt;kernel_size&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;&amp;ndash;ウィンドウのストライド。デフォルト値は &lt;code&gt;kernel_size&lt;/code&gt; です</target>
        </trans-unit>
        <trans-unit id="0e83b71423e0fab8d3fec82e9b62f9e213048e07" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; Stride of the max pooling window. It is set to &lt;code&gt;kernel_size&lt;/code&gt; by default.</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;最大プーリングウィンドウのストライド。デフォルトでは &lt;code&gt;kernel_size&lt;/code&gt; に設定されています。</target>
        </trans-unit>
        <trans-unit id="d642049bdaf0da3e7ac2a9bb747d7157b42b5143" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;) &amp;ndash; the stride of the sliding blocks in the input spatial dimensions. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;）&amp;ndash;入力空間次元でのスライディングブロックのストライド。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="32f6fe46ead4028a3ff5fec9da1140af45a6f195" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Stride of the convolution. Default: 1</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;畳み込みのストライド。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="c28631e28f33721680bff83305d7dc712c049afc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the stride of the sliding blocks in the input spatial dimensions. Default: 1</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;入力空間次元でのスライディングブロックのストライド。デフォルト：1</target>
        </trans-unit>
        <trans-unit id="5286e3c0bfd8223f9b20165f169fcac7223712b4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;ints&lt;/em&gt;) &amp;ndash; the stride of the output tensor</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;int&lt;/em&gt;）&amp;ndash;出力テンソルのストライド</target>
        </trans-unit>
        <trans-unit id="6af3c97a48669b717945a12fdf9a7cc81362788e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;tuple&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the desired stride. Defaults to C-contiguous strides.</source>
          <target state="translated">&lt;strong&gt;ストライド&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#tuple&quot;&gt;タプル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;目的のストライド。デフォルトはC連続ストライドです。</target>
        </trans-unit>
        <trans-unit id="9ed1797b9bf63c6b5db820aab38cf98e6f4f5b0d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;stride&lt;/strong&gt; (&lt;em&gt;tuple of python:ints&lt;/em&gt;) &amp;ndash; the strides of the output tensor</source>
          <target state="translated">&lt;strong&gt;stride&lt;/strong&gt;（&lt;em&gt;python：intsのタプル&lt;/em&gt;）&amp;ndash;出力テンソルのストライド</target>
        </trans-unit>
        <trans-unit id="b449245dfa29c41483eaf98f7744e5e9162391f6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;strip_doc_string&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default True&lt;/em&gt;) &amp;ndash; if True, strips the field &amp;ldquo;doc_string&amp;rdquo; from the exported model, which information about the stack trace.</source>
          <target state="translated">&lt;strong&gt;strip_doc_string&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;デフォルトはTrue&lt;/em&gt;）&amp;ndash; Trueの場合、エクスポートされたモデルからフィールド「doc_string」を削除します。これは、スタックトレースに関する情報です。</target>
        </trans-unit>
        <trans-unit id="19ac5a27007bad74f30226abe0c536a26c0a089d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;swap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; The distance swap is described in detail in the paper &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; by V. Balntas, E. Riba et al. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;スワップ&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;BOOL &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;） -距離スワップが紙に詳細に記載されている &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; V. Balntas、E. Ribaのらによる。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b154c5f2ebad9bb907ebc07611f820bf1efab1c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;swap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether to use the distance swap described in the paper &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; by V. Balntas, E. Riba et al. If True, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;swap&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; V. Balntas、E。Ribaetal。による論文 &lt;code&gt;Learning shallow convolutional feature descriptors with triplet losses&lt;/code&gt; 説明されている距離スワップを使用するかどうか。Trueの場合、および正の例がアンカーよりも負の例に近い場合、損失計算で正の例とアンカーを交換します。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="65dc3057d66834aa80e6916cc4680ab2424ee9dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;symmetric&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; indicates whether &lt;code&gt;input&lt;/code&gt; is symmetric. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;対称&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; &lt;code&gt;input&lt;/code&gt; が対称かどうかを示します。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4fa21981bc63a0d2a7702caf8a85ccba75b7cbe3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t0&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; point at which to start averaging (default: 1e6)</source>
          <target state="translated">&lt;strong&gt;t0&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;平均化を開始するポイント（デフォルト：1e6）</target>
        </trans-unit>
        <trans-unit id="0da7b9236fa7ec34aca8677755a15ff355bf2e5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor representing the parameter to prune</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;剪定するパラメーターを表すテンソル</target>
        </trans-unit>
        <trans-unit id="11deee4e01f144b32149bba99489b147b2b2f8c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor representing the parameter to prune (of same dimensions as &lt;code&gt;default_mask&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;プルーニングするパラメーターを表すテンソル（ &lt;code&gt;default_mask&lt;/code&gt; と同じ次元）。</target>
        </trans-unit>
        <trans-unit id="4a7620705c26f4724dfdfc18ad935e7dca1d4ba2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; tensor to prune (of same dimensions as &lt;code&gt;default_mask&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;プルーニングするテンソル（ &lt;code&gt;default_mask&lt;/code&gt; と同じ次元）。</target>
        </trans-unit>
        <trans-unit id="bad38a299dffdc28afcdbc450487e34252d433d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;t&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;string&lt;/em&gt;) &amp;ndash; the floating point tensor type or its name</source>
          <target state="translated">&lt;strong&gt;t&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;タイプ&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;文字列&lt;/em&gt;）&amp;ndash;浮動小数点テンソルタイプまたはその名前</target>
        </trans-unit>
        <trans-unit id="148b2bfd250a2dd94c21a77dac7daca25f087bca" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tag to match recv with remote send</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;recvをリモート送信と一致させるタグ</target>
        </trans-unit>
        <trans-unit id="f3d72f85bf8966156f98c3d0b833f53240d28797" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tag to match send with remote recv</source>
          <target state="translated">&lt;strong&gt;tag&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;送信とリモート受信を照合するタグ</target>
        </trans-unit>
        <trans-unit id="24131f44dbc1a3c7ca0a89f0809f0ba1b31deb1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Data identifier</source>
          <target state="translated">&lt;strong&gt;タグ&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;）&amp;ndash;データ識別子</target>
        </trans-unit>
        <trans-unit id="1e47865c46d7c3937ed182d2bce842b69d717584" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; Name for the embedding</source>
          <target state="translated">&lt;strong&gt;タグ&lt;/strong&gt;（&lt;em&gt;文字列&lt;/em&gt;）&amp;ndash;埋め込みの名前</target>
        </trans-unit>
        <trans-unit id="6d1b78b5bcbeb528ec42020fb51c475acd78d770" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tag_scalar_dict&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;) &amp;ndash; Key-value pair storing the tag and corresponding values</source>
          <target state="translated">&lt;strong&gt;tag_scalar_dict&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#dict&quot;&gt;dict&lt;/a&gt;）&amp;ndash;タグと対応する値を格納するキーと値のペア</target>
        </trans-unit>
        <trans-unit id="8f30aad2305773e67a4ac76efb57c166bcbc5811" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;ターゲット&lt;/strong&gt;&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="719f030afe3ca4c13961bb8f325f84d710260d20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; Tensor of the same shape as input</source>
          <target state="translated">&lt;strong&gt;ターゲット&lt;/strong&gt;&amp;ndash;入力と同じ形状のテンソル</target>
        </trans-unit>
        <trans-unit id="9206762f88088e88aeb5e77137d3fbb745052050" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; &amp;ndash; random sample</source>
          <target state="translated">&lt;strong&gt;ターゲット&lt;/strong&gt;&amp;ndash;ランダムサンプル</target>
        </trans-unit>
        <trans-unit id="e65a2d46ca874e2e756d7350a646d869ef4c730d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;ターゲット&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="72a23b074b2288d4e0ffc008a1ed4dc002ba4f88" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;target_lengths&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;target_lengths&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="c98a50b7621481810ef1add02c8fb6b879a9c206" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;targets&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;ターゲット&lt;/strong&gt;&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="1e8d2e93abbf10103deb46414323861cf338c14e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tau&lt;/strong&gt; &amp;ndash; non-negative scalar temperature</source>
          <target state="translated">&lt;strong&gt;タウ&lt;/strong&gt;&amp;ndash;非負のスカラー温度</target>
        </trans-unit>
        <trans-unit id="d3e4cee8df27fa35e5fc4ea9723fd730a3218d61" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;temperature&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; relaxation temperature</source>
          <target state="translated">&lt;strong&gt;温度&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;緩和温度</target>
        </trans-unit>
        <trans-unit id="582dba7550e8ec990794ee9bb0c943f9584d6a9a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the numerator tensor</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;分子テンソル</target>
        </trans-unit>
        <trans-unit id="fe51c36bff59a01f2f78ad03d8e073164d1af5b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;乗算されるテンソル</target>
        </trans-unit>
        <trans-unit id="d7c8f48497c84ad5e4208e1eddc9d137b9867057" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; an input tensor or number</source>
          <target state="translated">&lt;strong&gt;tensor1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;数値&lt;/em&gt;）&amp;ndash;入力テンソルまたは数値</target>
        </trans-unit>
        <trans-unit id="0ddefe13e55f57fbd638c942ea4f7390bcbffe28" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the denominator tensor</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;分母テンソル</target>
        </trans-unit>
        <trans-unit id="41bea45291973dd63ddd884b78f07e00d3ab7d86" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor to be multiplied</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;乗算されるテンソル</target>
        </trans-unit>
        <trans-unit id="b7570a5e6d003c7758abda29ee8e97e855d23054" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; an input tensor or number</source>
          <target state="translated">&lt;strong&gt;tensor2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;数値&lt;/em&gt;）&amp;ndash;入力テンソルまたは数値</target>
        </trans-unit>
        <trans-unit id="8f71579bdc06e7c9c71d37a5240b5de48b5701ac" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a 2-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;&amp;ndash;2次元 &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;strong&gt;テンソル&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="1efb28f257d49ada4a2b28823d609173cc47778d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a tensor to be exported</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;&amp;ndash;エクスポートされるテンソル</target>
        </trans-unit>
        <trans-unit id="ebd185db4dcd0096fd7b5c3f6d3e9f89f2fe9c11" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; a {3, 4, 5}-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;&amp;ndash; {3、4、5}次元の &lt;code&gt;torch.Tensor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="38120be427a851f124349ce7081bb1e1d17f8071" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; an n-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;&amp;ndash;n次元の &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;strong&gt;テンソル&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="9324a2a3b49e2c9c5b1f421b1679082153eb02c1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; &amp;ndash; an n-dimensional &lt;code&gt;torch.Tensor&lt;/code&gt;, where</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;&amp;ndash; n次元の &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;strong&gt;テンソル&lt;/strong&gt;、ここで</target>
        </trans-unit>
        <trans-unit id="fd9f9b08ebf1b11c3c6c5c2342c4729faa2bd202" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to add</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;追加する値を含むテンソル</target>
        </trans-unit>
        <trans-unit id="f130d0f3db6962333521550a2aac19265d9b05ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to copy</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;コピーする値を含むテンソル</target>
        </trans-unit>
        <trans-unit id="48b5c5ac8e5e9b826ebcd51ac110f06caead74d9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor containing values to copy from</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;コピー元の値を含むテンソル</target>
        </trans-unit>
        <trans-unit id="db831c557616296e8156131ded5d0c40f87ca1c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the tensor which has the desired type</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;目的のタイプのテンソル</target>
        </trans-unit>
        <trans-unit id="43e7c30902c9179fb0b37459c8ea94f10d65684d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; A quantized Tensor</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;量子化されたテンソル</target>
        </trans-unit>
        <trans-unit id="595262930a1db5ff17082aa694d1b0f8665e76ef" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; buffer to be registered.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;登録するバッファ。</target>
        </trans-unit>
        <trans-unit id="daa8d39d1206451461ce1d0b71e54ecbc3499778" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor to split.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;分割するテンソル。</target>
        </trans-unit>
        <trans-unit id="c5119c9d3c84560f70044a06335745fbc7690c5e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Tensor whose dtype and device are the desired dtype and device for all parameters and buffers in this module</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;）&amp;ndash;dtypeとdeviceがこのモジュールのすべてのパラメーターとバッファーに必要なdtypeとdeviceであるテンソル</target>
        </trans-unit>
        <trans-unit id="4ea925f35e05eeec0ce6c6ede21012597e80ba1d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Data to be sent if &lt;code&gt;src&lt;/code&gt; is the rank of current process, and tensor to be used to save received data otherwise.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Data to be sent if &lt;code&gt;src&lt;/code&gt; is the rank of current process, and tensor to be used to save received data otherwise.</target>
        </trans-unit>
        <trans-unit id="0ea5bf92870a7e63a9dc7b73483e6447ea902554" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input and output of the collective. The function operates in-place.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input and output of the collective. The function operates in-place.</target>
        </trans-unit>
        <trans-unit id="871bd0fcd2a298c26c4d81bf5750fd9c2750ed91" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input tensor.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Input tensor.</target>
        </trans-unit>
        <trans-unit id="4086bda3a1c5df109757d3e351db5cbbd66ea1c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Output tensor.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Output tensor.</target>
        </trans-unit>
        <trans-unit id="d003bad4eb45ea45fc9aa2947e6f3d43bd663f2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to be broadcast from current process.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to be broadcast from current process.</target>
        </trans-unit>
        <trans-unit id="8057a0b7b9e31fa19b74af90d185d7232521ede8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to fill with received data.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to fill with received data.</target>
        </trans-unit>
        <trans-unit id="c5e9e88f62d8e8a8f1bab1c4e5838b8d932d6e95" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to send.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor to send.</target>
        </trans-unit>
        <trans-unit id="c96308f3675384050b175ef61d2607c351010e84" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor to broadcast. Can be on CPU or GPU.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;ブロードキャストするテンソル。CPUまたはGPU上に置くことができます。</target>
        </trans-unit>
        <trans-unit id="a96d9a8bda9ef562edf641df4347b4b73d26cbdb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor to scatter. Can be on CPU or GPU.</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;散乱するテンソル。CPUまたはGPU上に置くことができます。</target>
        </trans-unit>
        <trans-unit id="6ed36b8ea65f06efab795d8ef00bc8f1d04ff81c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; class values of any shape.</source>
          <target state="translated">&lt;strong&gt;tensor&lt;/strong&gt; (&lt;em&gt;LongTensor&lt;/em&gt;) &amp;ndash; class values of any shape.</target>
        </trans-unit>
        <trans-unit id="771c4af8e8d1e14069a64799aa2b6b2856c84f0a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Output list. It should contain correctly-sized tensors to be used for output of the collective.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;list&lt;/a&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Output list. It should contain correctly-sized tensors to be used for output of the collective.</target>
        </trans-unit>
        <trans-unit id="0529bcde8eee4077490565e65382a12d0014ef8d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Input and output GPU tensors of the collective. The function operates in-place. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Input and output GPU tensors of the collective. The function operates in-place. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</target>
        </trans-unit>
        <trans-unit id="fd42e4e4f033181e34931a8527efa00ab289b6ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Tensors that participate in the collective operation. If &lt;code&gt;src&lt;/code&gt; is the rank, then the specified &lt;code&gt;src_tensor&lt;/code&gt; element of &lt;code&gt;tensor_list&lt;/code&gt; (&lt;code&gt;tensor_list[src_tensor]&lt;/code&gt;) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in &lt;code&gt;tensor_list&lt;/code&gt; of other non-src processes. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</source>
          <target state="translated">&lt;strong&gt;tensor_list&lt;/strong&gt; (&lt;em&gt;List&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; Tensors that participate in the collective operation. If &lt;code&gt;src&lt;/code&gt; is the rank, then the specified &lt;code&gt;src_tensor&lt;/code&gt; element of &lt;code&gt;tensor_list&lt;/code&gt; ( &lt;code&gt;tensor_list[src_tensor]&lt;/code&gt; ) will be broadcast to all other tensors (on different GPUs) in the src process and all tensors in &lt;code&gt;tensor_list&lt;/code&gt; of other non-src processes. You also need to make sure that &lt;code&gt;len(tensor_list)&lt;/code&gt; is the same for all the distributed processes calling this function.</target>
        </trans-unit>
        <trans-unit id="11c199d5a721aff7dadaa91e201fd37a621320be" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;Iterable&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; an iterable of tensors to gather. Tensor sizes in all dimensions other than &lt;code&gt;dim&lt;/code&gt; have to match.</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;em&gt;Iterable &lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;収集するテンソルの反復可能。 &lt;code&gt;dim&lt;/code&gt; 以外のすべての次元のテンソルサイズは一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="251ca5120d14a95efd17bbf7ac86f2e8dcd31a74" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensor&lt;/em&gt;) &amp;ndash; Tensors of which the derivative will be computed.</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;strong&gt;テンソルの&lt;/strong&gt;&lt;em&gt;シーケンス&lt;/em&gt;）&amp;ndash;導関数が計算される&lt;em&gt;テンソル&lt;/em&gt;。</target>
        </trans-unit>
        <trans-unit id="6c11521362c09d9790c6e10205b4f5e9d4d0f8d2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; A list of quantized Tensors</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; A list of quantized Tensors</target>
        </trans-unit>
        <trans-unit id="56d11e41f90bcf5265e9b581f446c4e0dd727f96" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</target>
        </trans-unit>
        <trans-unit id="17a8b4a65e76b16fe0001dce91103bc1f0d95788" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; sequence of tensors to concatenate</source>
          <target state="translated">&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence of Tensors&lt;/em&gt;) &amp;ndash; sequence of tensors to concatenate</target>
        </trans-unit>
        <trans-unit id="c9c0ad52006da24004a15eb5f4a77cf9446867a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tensors&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; tensors to broadcast. Must be on the same device, either CPU or GPU.</source>
          <target state="translated">&lt;strong&gt;テンソル&lt;/strong&gt;（&lt;em&gt;シーケンス&lt;/em&gt;）&amp;ndash;ブロードキャストするテンソル。CPUまたはGPUのいずれかの同じデバイス上にある必要があります。</target>
        </trans-unit>
        <trans-unit id="eac06248fef5ff01ab7df814f04387fca91e048c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;text_string&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; String to save</source>
          <target state="translated">&lt;strong&gt;text_string&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; String to save</target>
        </trans-unit>
        <trans-unit id="23bc89e013fe710997ceb4e02308dc814861dd46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder (required).</source>
          <target state="translated">&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder (required).</target>
        </trans-unit>
        <trans-unit id="a97b7e4ae84d91f24d47d3e533654ba0c637aeda" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder layer (required).</source>
          <target state="translated">&lt;strong&gt;tgt&lt;/strong&gt; &amp;ndash; the sequence to the decoder layer (required).</target>
        </trans-unit>
        <trans-unit id="46691f105bd3761d4561a84637a0dc690d56304c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for tgt keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the ByteTensor mask for tgt keys per batch (optional).</target>
        </trans-unit>
        <trans-unit id="c272aa66d6d78c6319db9bd44d86112843bcbd0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt keys per batch (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_key_padding_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt keys per batch (optional).</target>
        </trans-unit>
        <trans-unit id="ed8a93d25be2a772ab9ad79f5fd98f7466a44647" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the additive mask for the tgt sequence (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the additive mask for the tgt sequence (optional).</target>
        </trans-unit>
        <trans-unit id="132d016583670fccbcfcac0d15e9840ebbe1f4a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt sequence (optional).</source>
          <target state="translated">&lt;strong&gt;tgt_mask&lt;/strong&gt; &amp;ndash; the mask for the tgt sequence (optional).</target>
        </trans-unit>
        <trans-unit id="5601a92236ec47fd0c06d7f0fed5b5b6c8fcc29b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;that need to be respected after the new mask is&lt;/strong&gt; (&lt;em&gt;iterations&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;that need to be respected after the new mask is&lt;/strong&gt; (&lt;em&gt;iterations&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="ae41ef1091d9aad2a5c98f17e3318f399d0289bd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;the best candidates for quantization&lt;/strong&gt; (&lt;em&gt;choosing&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;量子化の最良の候補&lt;/strong&gt;（&lt;em&gt;選択&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="6712ad21050e25aa58857f430d28e66ca2b72d67" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;theta&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input batch of affine matrices with shape (</source>
          <target state="translated">&lt;strong&gt;theta&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input batch of affine matrices with shape (</target>
        </trans-unit>
        <trans-unit id="1f97d9939a572f78a3fab174d3aace7d899626d1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; The value to threshold at</source>
          <target state="translated">&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; The value to threshold at</target>
        </trans-unit>
        <trans-unit id="4e72f74774d99b133267f9808f645ba3f90baa42" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; Total number of array elements which trigger summarization rather than full &lt;code&gt;repr&lt;/code&gt; (default = 1000).</source>
          <target state="translated">&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; Total number of array elements which trigger summarization rather than full &lt;code&gt;repr&lt;/code&gt; (default = 1000).</target>
        </trans-unit>
        <trans-unit id="9beeeb50002c6e9c428d419f497bfffeb0df1d1b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; values above this revert to a linear function. Default: 20</source>
          <target state="translated">&lt;strong&gt;threshold&lt;/strong&gt; &amp;ndash; values above this revert to a linear function. Default: 20</target>
        </trans-unit>
        <trans-unit id="6cb0c42969ee401db173a6b40a7eca999d5919d0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.</source>
          <target state="translated">&lt;strong&gt;threshold&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;重要な変更のみに焦点を当てるための新しい最適値を測定するためのしきい値。デフォルト：1e-4。</target>
        </trans-unit>
        <trans-unit id="2d0eb62fc3c7ef60a698a936e990467a02a92a1c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;threshold_mode&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; One of &lt;code&gt;rel&lt;/code&gt;, &lt;code&gt;abs&lt;/code&gt;. In &lt;code&gt;rel&lt;/code&gt; mode, dynamic_threshold = best * ( 1 + threshold ) in &amp;lsquo;max&amp;rsquo; mode or best * ( 1 - threshold ) in &lt;code&gt;min&lt;/code&gt; mode. In &lt;code&gt;abs&lt;/code&gt; mode, dynamic_threshold = best + threshold in &lt;code&gt;max&lt;/code&gt; mode or best - threshold in &lt;code&gt;min&lt;/code&gt; mode. Default: &amp;lsquo;rel&amp;rsquo;.</source>
          <target state="translated">&lt;strong&gt;threshold_mode&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash; &lt;code&gt;rel&lt;/code&gt; 、 &lt;code&gt;abs&lt;/code&gt; のいずれか。で &lt;code&gt;rel&lt;/code&gt; で- （しきい値1）モード、dynamic_threshold =「最大」モードまたは最高*最高*（1つの+しきい値） &lt;code&gt;min&lt;/code&gt; モード。で &lt;code&gt;abs&lt;/code&gt; モード、dynamic_threshold =最高+しきい値 &lt;code&gt;max&lt;/code&gt; モードまたはベスト-における閾値 &lt;code&gt;min&lt;/code&gt; モード。デフォルト： 'rel'。</target>
        </trans-unit>
        <trans-unit id="c6464c5c07bfa189e529ba00b647f718ccc94239" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Wait this long before giving up on waiting.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;待機をあきらめる前に、これだけ長く待機します。</target>
        </trans-unit>
        <trans-unit id="a4158143cd3f539f6f9f4f75136861c57fa1f337" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for &lt;code&gt;to_here&lt;/code&gt;. If the call does not complete within this timeframe, an exception indicating so will be raised. If this argument is not provided, the default RPC timeout (60s) will be used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for &lt;code&gt;to_here&lt;/code&gt; . If the call does not complete within this timeframe, an exception indicating so will be raised. If this argument is not provided, the default RPC timeout (60s) will be used.</target>
        </trans-unit>
        <trans-unit id="e0ca20ba1ac1f4702011bcb3b44292663520556f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds for this remote call. If the creation of this &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; on worker &lt;code&gt;to&lt;/code&gt; is not successfully processed on this worker within this timeout, then the next time there is an attempt to use the RRef (such as &lt;code&gt;to_here()&lt;/code&gt;), a timeout will be raised indicating this failure. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds for this remote call. If the creation of this &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt; on worker &lt;code&gt;to&lt;/code&gt; is not successfully processed on this worker within this timeout, then the next time there is an attempt to use the RRef (such as &lt;code&gt;to_here()&lt;/code&gt; ), a timeout will be raised indicating this failure. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</target>
        </trans-unit>
        <trans-unit id="cb09a1d9765bc72d97aa2aa954e843c0cc306ebd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds to use for this RPC. If the RPC does not complete in this amount of time, an exception indicating it has timed out will be raised. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; timeout in seconds to use for this RPC. If the RPC does not complete in this amount of time, an exception indicating it has timed out will be raised. A value of 0 indicates an infinite timeout, i.e. a timeout error will never be raised. If not provided, the default value set during initialization or with &lt;code&gt;_set_rpc_timeout&lt;/code&gt; is used.</target>
        </trans-unit>
        <trans-unit id="d38206a16efc702de4b546c7ebb66bce20140dc1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;numeric&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: &lt;code&gt;0&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;タイムアウト&lt;/strong&gt;（&lt;em&gt;数値&lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;正の場合、ワーカーからバッチを収集するためのタイムアウト値。常に非負である必要があります。（デフォルト： &lt;code&gt;0&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="9273f5efc9a2168581a1563dc88271535c09449c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Time to wait for the keys to be added before throwing an exception.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Time to wait for the keys to be added before throwing an exception.</target>
        </trans-unit>
        <trans-unit id="52d6695e842a69c4f1f1155be378bf5f945bf62e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Timeout used by the store during initialization and for methods such as &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;wait()&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; Timeout used by the store during initialization and for methods such as &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;wait()&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8232ad0889858559e2f3203547e409d87becb68e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; timeout to be set in the store.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;) &amp;ndash; timeout to be set in the store.</target>
        </trans-unit>
        <trans-unit id="2751f8d0a7ffb7b1eea973ad31d6029c6cf7b2ad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is applicable for the &lt;code&gt;gloo&lt;/code&gt; backend. For &lt;code&gt;nccl&lt;/code&gt;, this is applicable only if the environment variable &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; or &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set to 1. When &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; is set, this is the duration for which the process will block and wait for collectives to complete before throwing an exception. When &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set, this is the duration after which collectives will be aborted asynchronously and the process will crash. &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; will provide errors to the user which can be caught and handled, but due to its blocking nature, it has a performance overhead. On the other hand, &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; has little performance overhead, but crashes the process on errors. This is done since CUDA execution is async and it is no longer safe to continue executing user code since failed async NCCL operations might result in subsequent CUDA operations to run on corrupted data. Only one of these two environment variables should be set.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is applicable for the &lt;code&gt;gloo&lt;/code&gt; backend. For &lt;code&gt;nccl&lt;/code&gt; , this is applicable only if the environment variable &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; or &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set to 1. When &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; is set, this is the duration for which the process will block and wait for collectives to complete before throwing an exception. When &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; is set, this is the duration after which collectives will be aborted asynchronously and the process will crash. &lt;code&gt;NCCL_BLOCKING_WAIT&lt;/code&gt; will provide errors to the user which can be caught and handled, but due to its blocking nature, it has a performance overhead. On the other hand, &lt;code&gt;NCCL_ASYNC_ERROR_HANDLING&lt;/code&gt; has little performance overhead, but crashes the process on errors. This is done since CUDA execution is async and it is no longer safe to continue executing user code since failed async NCCL operations might result in subsequent CUDA operations to run on corrupted data. Only one of these two environment variables should be set.</target>
        </trans-unit>
        <trans-unit id="00a4cf1534a34a3e1bdbf78c948e2ba0bebb6650" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is only applicable for the &lt;code&gt;gloo&lt;/code&gt; backend.</source>
          <target state="translated">&lt;strong&gt;timeout&lt;/strong&gt; (&lt;em&gt;timedelta&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Timeout for operations executed against the process group. Default value equals 30 minutes. This is only applicable for the &lt;code&gt;gloo&lt;/code&gt; backend.</target>
        </trans-unit>
        <trans-unit id="02c882e856aedbce8abb8c0907459899847d1718" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;to&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;WorkerInfo&lt;/a&gt;) &amp;ndash; id or name of the destination worker.</source>
          <target state="translated">&lt;strong&gt;to&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;WorkerInfo&lt;/a&gt;) &amp;ndash; id or name of the destination worker.</target>
        </trans-unit>
        <trans-unit id="ea9f5f30be6e298274025992da4c6c4ec845554e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;to&lt;/strong&gt; (&lt;em&gt;dpython:type&lt;/em&gt;) &amp;ndash; The target &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;strong&gt;to&lt;/strong&gt; (&lt;em&gt;dpython:type&lt;/em&gt;) &amp;ndash; The target &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="e52fdd2bd38561ad6a0c5c61e130e89b4aada3ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; residual tolerance for stopping criterion. Default is &lt;code&gt;feps ** 0.5&lt;/code&gt; where &lt;code&gt;feps&lt;/code&gt; is smallest non-zero floating-point number of the given input tensor &lt;code&gt;A&lt;/code&gt; data type.</source>
          <target state="translated">&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; residual tolerance for stopping criterion. Default is &lt;code&gt;feps ** 0.5&lt;/code&gt; where &lt;code&gt;feps&lt;/code&gt; is smallest non-zero floating-point number of the given input tensor &lt;code&gt;A&lt;/code&gt; data type.</target>
        </trans-unit>
        <trans-unit id="ebb57295704495b7e390dfbf06821990d8f2e8d3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the tolerance value. Default: &lt;code&gt;None&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;tol&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the tolerance value. Default: &lt;code&gt;None&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="bd525427c04eccdee85fc4cee3c55e31a24cb304" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tolerance_change&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; termination tolerance on function value/parameter changes (default: 1e-9).</source>
          <target state="translated">&lt;strong&gt;tolerance_change&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash;関数値/パラメーター変更の終了許容値（デフォルト：1e-9）。</target>
        </trans-unit>
        <trans-unit id="3c197525a443a87cf9f094716c1dcb003057eef0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tolerance_grad&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; termination tolerance on first order optimality (default: 1e-5).</source>
          <target state="translated">&lt;strong&gt;tolerance_grad&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;）&amp;ndash; 1次最適化の終了許容値（デフォルト：1e-5）。</target>
        </trans-unit>
        <trans-unit id="407c445fafb074d2e67a14d4a7333561e68a55d0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;top_level_events_only&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Boolean flag to determine the selection of events to display. If true, the profiler will only display events at top level like top-level invocation of python &lt;code&gt;lstm&lt;/code&gt;, python &lt;code&gt;add&lt;/code&gt; or other functions, nested events like low-level cpu/cuda ops events are omitted for profiler result readability.</source>
          <target state="translated">&lt;strong&gt;top_level_events_only&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;表示するイベントの選択を決定するブールフラグ。trueの場合、プロファイラーはpython &lt;code&gt;lstm&lt;/code&gt; 、python &lt;code&gt;add&lt;/code&gt; 、またはその他の関数のトップレベルの呼び出しなどのトップレベルのイベントのみを表示します。プロファイラーの結果を読みやすくするために、低レベルのcpu / cudaopsイベントなどのネストされたイベントは省略されます。</target>
        </trans-unit>
        <trans-unit id="abe1f21ed4cea1ee1d4b3f7ed2f79c15752c40b1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_count&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; non-negative number of negative Bernoulli trials to stop, although the distribution is still valid for real valued count</source>
          <target state="translated">&lt;strong&gt;total_count&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;停止する負のベルヌーイ試行の非負の数。ただし、分布は実数値のカウントに対して有効です。</target>
        </trans-unit>
        <trans-unit id="d26e0c4265279fa280cd914ce50f04f7c4aa40eb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_count&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of trials</source>
          <target state="translated">&lt;strong&gt;total_count&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;試行回数</target>
        </trans-unit>
        <trans-unit id="077375196e8792ce500b9544f90a99bec0c48113" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_count&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; number of Bernoulli trials</source>
          <target state="translated">&lt;strong&gt;total_count&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;ベルヌーイ試行の数</target>
        </trans-unit>
        <trans-unit id="c6231da05b67c6d40cc466aa082bc7aa1fceb57f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if not &lt;code&gt;None&lt;/code&gt;, the output will be padded to have length &lt;code&gt;total_length&lt;/code&gt;. This method will throw &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#ValueError&quot;&gt;&lt;code&gt;ValueError&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;total_length&lt;/code&gt; is less than the max sequence length in &lt;code&gt;sequence&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;total_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; if not &lt;code&gt;None&lt;/code&gt; , the output will be padded to have length &lt;code&gt;total_length&lt;/code&gt; . This method will throw &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#ValueError&quot;&gt; &lt;code&gt;ValueError&lt;/code&gt; &lt;/a&gt; if &lt;code&gt;total_length&lt;/code&gt; is less than the max sequence length in &lt;code&gt;sequence&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="13b2d7d1150a6055778df0dc94b65e3f358e1ead" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;total_steps&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The total number of steps in the cycle. Note that if a value is not provided here, then it must be inferred by providing a value for epochs and steps_per_epoch. Default: None</source>
          <target state="translated">&lt;strong&gt;total_steps&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;サイクルの合計ステップ数。ここで値が指定されていない場合は、epochsとsteps_per_epochの値を指定して推測する必要があることに注意してください。デフォルト：なし</target>
        </trans-unit>
        <trans-unit id="07c5deb90e808db58c55e72b715383a8fbfd19d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt;, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt; , this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt; , this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3efa70ce9f7603a628298aac133f6c2ebf2aea12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt;, this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt;, this module does not track such statistics, and initializes statistics buffers &lt;code&gt;running_mean&lt;/code&gt; and &lt;code&gt;running_var&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt;. When these buffers are &lt;code&gt;None&lt;/code&gt;, this module always uses batch statistics. in both training and eval modes. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;track_running_stats&lt;/strong&gt; &amp;ndash; a boolean value that when set to &lt;code&gt;True&lt;/code&gt; , this module tracks the running mean and variance, and when set to &lt;code&gt;False&lt;/code&gt; , this module does not track such statistics, and initializes statistics buffers &lt;code&gt;running_mean&lt;/code&gt; and &lt;code&gt;running_var&lt;/code&gt; as &lt;code&gt;None&lt;/code&gt; . When these buffers are &lt;code&gt;None&lt;/code&gt; , this module always uses batch statistics. in both training and eval modes. Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83e1567d195f61030af1691e6408ec395faa36b6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;tracker&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;tracker&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="cae553a329b41a39ac2ef28a1128e47f2aff1a79" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;trainable_backbone_layers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of trainable (not frozen) resnet layers starting from final block. Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.</source>
          <target state="translated">&lt;strong&gt;trainable_backbone_layers&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; number of trainable (not frozen) resnet layers starting from final block. Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.</target>
        </trans-unit>
        <trans-unit id="1918b886e2cf75d47f208888e3bf63f2ca3faa0e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; &amp;ndash; apply dropout if is &lt;code&gt;True&lt;/code&gt;. Default: &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;training&lt;/strong&gt; &amp;ndash; apply dropout if is &lt;code&gt;True&lt;/code&gt; . Default: &lt;code&gt;True&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9b04f39ddad8101f7db51608eea54f5bf896eeb7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Boolean represents whether this module is in training or evaluation mode.</source>
          <target state="translated">&lt;strong&gt;training&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Boolean represents whether this module is in training or evaluation mode.</target>
        </trans-unit>
        <trans-unit id="51af50b75452e3c060a548901f1c86020bc06d08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;training&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default TrainingMode.EVAL&lt;/em&gt;) &amp;ndash; TrainingMode.EVAL: export the model in inference mode. TrainingMode.PRESERVE: export the model in inference mode if model.training is False and to a training friendly mode if model.training is True. TrainingMode.TRAINING: export the model in a training friendly mode.</source>
          <target state="translated">&lt;strong&gt;training&lt;/strong&gt; (&lt;em&gt;enum&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default TrainingMode.EVAL&lt;/em&gt;) &amp;ndash; TrainingMode.EVAL: export the model in inference mode. TrainingMode.PRESERVE: export the model in inference mode if model.training is False and to a training friendly mode if model.training is True. TrainingMode.TRAINING: export the model in a training friendly mode.</target>
        </trans-unit>
        <trans-unit id="6b489d8a5fd1b48c8841b422261d73f6fc9f5019" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;transform_input&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, preprocesses the input according to the method with which it was trained on ImageNet. Default: &lt;em&gt;False&lt;/em&gt;</source>
          <target state="translated">&lt;strong&gt;transform_input&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If True, preprocesses the input according to the method with which it was trained on ImageNet. Default: &lt;em&gt;False&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="0f7f01bd2f696782296281656611b9d7f0e11af1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;transpose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</source>
          <target state="translated">&lt;strong&gt;transpose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</target>
        </trans-unit>
        <trans-unit id="5d7f3ae8d3896d551417a34cad2154f4876e37e8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type1&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;type1&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="db83431c42acbc4313b6844960f9f9b62081f0cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type2&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;type2&lt;/strong&gt; (&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;) &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a0c7d87b9ea55c63dfca094efac9fe724ed34848" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type_p&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;) &amp;ndash; A subclass of &lt;code&gt;Distribution&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;type_p&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;タイプ&lt;/a&gt;） -のサブクラス &lt;code&gt;Distribution&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5169a079777e56a56ce65c29ef02ee71884331c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;type_q&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;type&lt;/a&gt;) &amp;ndash; A subclass of &lt;code&gt;Distribution&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;type_q&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#type&quot;&gt;タイプ&lt;/a&gt;） -のサブクラス &lt;code&gt;Distribution&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2ebcbce8f74baa28dc73e78635230701acf753b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unbiased&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to use the unbiased estimation or not</source>
          <target state="translated">&lt;strong&gt;unbiased&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; whether to use the unbiased estimation or not</target>
        </trans-unit>
        <trans-unit id="2e13564fc77541067b4971002e5a668623c64ae3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unexpected_keys&lt;/strong&gt; is a list of str containing the unexpected keys</source>
          <target state="translated">&lt;strong&gt;unexpected_keys&lt;/strong&gt; is a list of str containing the unexpected keys</target>
        </trans-unit>
        <trans-unit id="40c65479b90b1228aa4509bb18c068347e1a8396" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unflattened_size&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;NamedShape&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</source>
          <target state="translated">&lt;strong&gt;unflattened_size&lt;/strong&gt; (&lt;em&gt;Union&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;torch.Size&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;NamedShape&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; New shape of the unflattened dimension</target>
        </trans-unit>
        <trans-unit id="6577f53f07c6b82453a5e4d8ee1cdce173f1095c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unitriangular&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</source>
          <target state="translated">&lt;strong&gt;unitriangular&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether</target>
        </trans-unit>
        <trans-unit id="f6abb29d9132a1cca0511aeb0026c03c9d5e185c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unpack_data&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the data should be unpacked</source>
          <target state="translated">&lt;strong&gt;unpack_data&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the data should be unpacked</target>
        </trans-unit>
        <trans-unit id="04e96028a5908db9b44aee6aad14f15f640b0004" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;unpack_pivots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the pivots should be unpacked</source>
          <target state="translated">&lt;strong&gt;unpack_pivots&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; flag indicating if the pivots should be unpacked</target>
        </trans-unit>
        <trans-unit id="f545e5ba1e2fb058ee8bbcf81cc46f57b737b0f7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; &amp;ndash; upper bound of the uniform distribution. Default:</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; &amp;ndash; upper bound of the uniform distribution. Default:</target>
        </trans-unit>
        <trans-unit id="078b557c79445664413d140b19483eb01fc4a40b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; flag that indicates whether to return a upper or lower triangular matrix. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; flag that indicates whether to return a upper or lower triangular matrix. Default: &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f6e194e2ffa34563a9da2cd5695fbad2b195aeb3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to consider the Cholesky factor as a lower or upper triangular matrix. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to consider the Cholesky factor as a lower or upper triangular matrix. Default: &lt;code&gt;False&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e4c027c4ea86e34928bea3afd23c0befc2ae84dc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return a lower (default) or upper triangular matrix</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to return a lower (default) or upper triangular matrix</target>
        </trans-unit>
        <trans-unit id="e817dde6e0d6a551d34fc3800e9ab1a2430679a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to solve the upper-triangular system of equations (default) or the lower-triangular system of equations. Default: &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to solve the upper-triangular system of equations (default) or the lower-triangular system of equations. Default: &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f6bd6cb43a30358db4258c20658d93f8d71b69f5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upper&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to consider upper-triangular or lower-triangular region</source>
          <target state="translated">&lt;strong&gt;upper&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; controls whether to consider upper-triangular or lower-triangular region</target>
        </trans-unit>
        <trans-unit id="f5cb009f2bb1f037cbc1a012ac4ce862506a7d43" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upsample_rate&lt;/strong&gt; &amp;ndash; Factor by which the histograms are upsampled, this is used to interpolate histograms with varying ranges across observations</source>
          <target state="translated">&lt;strong&gt;upsample_rate&lt;/strong&gt; &amp;ndash;ヒストグラムがアップサンプリングされる係数。これは、観測全体で範囲が変化するヒストグラムを内挿するために使用されます。</target>
        </trans-unit>
        <trans-unit id="f8ed541c4bbf8acbeeefe806b08d772cdb213ba6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;upscale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; factor to increase spatial resolution by</source>
          <target state="translated">&lt;strong&gt;upscale_factor&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; factor to increase spatial resolution by</target>
        </trans-unit>
        <trans-unit id="dbbba1d51581a2e6efdbd392cc9848e659d8b9c2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;url&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; URL of the object to download</source>
          <target state="translated">&lt;strong&gt;url&lt;/strong&gt; (&lt;em&gt;string&lt;/em&gt;) &amp;ndash; URL of the object to download</target>
        </trans-unit>
        <trans-unit id="0f0afdb93eece512a7ce83a3e5f3b3330df3e43c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;use_cuda&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Enables timing of CUDA events as well using the cudaEvent API. Adds approximately 4us of overhead to each tensor operation. Default: &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;use_cuda&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; cudaEventAPIを使用してCUDAイベントのタイミングも有効にします。各テンソル操作に約4usのオーバーヘッドを追加します。デフォルト： &lt;code&gt;False&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="03fa705d67fc134339599e4e459d34c6a562acc7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;v&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The vector for which the Hessian vector product is computed. Must be the same size as the input of &lt;code&gt;func&lt;/code&gt;. This argument is optional when &lt;code&gt;func&lt;/code&gt;&amp;rsquo;s input contains a single element and (if it is not provided) will be set as a Tensor containing a single &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;v&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;テンソルの&lt;em&gt;タプル&lt;/em&gt;）&amp;ndash;ヘッセベクトル積が計算されるベクトル。 &lt;code&gt;func&lt;/code&gt; の入力と同じサイズである必要があります。 &lt;code&gt;func&lt;/code&gt; の入力に単一の要素が含まれ、（提供されていない場合）単一の &lt;code&gt;1&lt;/code&gt; を含むテンソルとして設定される場合、この引数はオプションです。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="13f694a2701ec74a73a5d0f00ebff38c907669d6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;v&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The vector for which the Jacobian vector product is computed. Must be the same size as the input of &lt;code&gt;func&lt;/code&gt;. This argument is optional when the input to &lt;code&gt;func&lt;/code&gt; contains a single element and (if it is not provided) will be set as a Tensor containing a single &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;v&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;テンソルの&lt;em&gt;タプル&lt;/em&gt;）&amp;ndash;ヤコビアンベクトル積が計算されるベクトル。 &lt;code&gt;func&lt;/code&gt; の入力と同じサイズである必要があります。 &lt;code&gt;func&lt;/code&gt; への入力に単一の要素が含まれ、（提供されていない場合）単一の &lt;code&gt;1&lt;/code&gt; を含むテンソルとして設定される場合、この引数はオプションです。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="11eb112c28f57578089a428d40281d86b3149af8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;v&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The vector for which the vector Hessian product is computed. Must be the same size as the input of &lt;code&gt;func&lt;/code&gt;. This argument is optional when &lt;code&gt;func&lt;/code&gt;&amp;rsquo;s input contains a single element and (if it is not provided) will be set as a Tensor containing a single &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;v&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;テンソルの&lt;em&gt;タプル&lt;/em&gt;）&amp;ndash;ベクトルヘッセ積が計算されるベクトル。 &lt;code&gt;func&lt;/code&gt; の入力と同じサイズである必要があります。 &lt;code&gt;func&lt;/code&gt; の入力に単一の要素が含まれ、（提供されていない場合）単一の &lt;code&gt;1&lt;/code&gt; を含むテンソルとして設定される場合、この引数はオプションです。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="d835c6d1aa6fb4ff923c35566662ff986f45e13f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;v&lt;/strong&gt; (&lt;em&gt;tuple of Tensors&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The vector for which the vector Jacobian product is computed. Must be the same size as the output of &lt;code&gt;func&lt;/code&gt;. This argument is optional when the output of &lt;code&gt;func&lt;/code&gt; contains a single element and (if it is not provided) will be set as a Tensor containing a single &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;v&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;テンソルの&lt;em&gt;タプル&lt;/em&gt;）&amp;ndash;ベクトルヤコビアン積が計算されるベクトル。 &lt;code&gt;func&lt;/code&gt; の出力と同じサイズである必要があります。 &lt;code&gt;func&lt;/code&gt; の出力に単一の要素が含まれ、（提供されていない場合）単一の &lt;code&gt;1&lt;/code&gt; を含むテンソルとして設定される場合、この引数はオプションです。&lt;em&gt;&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="98118f8f62fd734993f566a38ff617a7ee9952b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;val&lt;/strong&gt; &amp;ndash; the value to fill the tensor with</source>
          <target state="translated">&lt;strong&gt;val&lt;/strong&gt; &amp;ndash; the value to fill the tensor with</target>
        </trans-unit>
        <trans-unit id="7e6a7de4d7910c74c696408d838f32027dedb43c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;val&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill with</source>
          <target state="translated">&lt;strong&gt;val&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill with</target>
        </trans-unit>
        <trans-unit id="e1ad2ed4dd7f0bf60e90e62bbcab68ef4dd2b46f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; The value to replace with</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; The value to replace with</target>
        </trans-unit>
        <trans-unit id="5ea89c83b46186a326f0e2a0c5a74bf1b7ed29c3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; fill value for &lt;code&gt;'constant'&lt;/code&gt; padding. Default: &lt;code&gt;0&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; &amp;ndash; fill value for &lt;code&gt;'constant'&lt;/code&gt; padding. Default: &lt;code&gt;0&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="7b65f448578fca2733acf40a459ffeecb2eddae8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor of same dtype as &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; tensor of same dtype as &lt;code&gt;self&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="1d73cf9df184ed1151607fad31d5ce6f0c1674e1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the source element(s) to scatter, incase &lt;code&gt;src&lt;/code&gt; is not specified</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the source element(s) to scatter, incase &lt;code&gt;src&lt;/code&gt; is not specified</target>
        </trans-unit>
        <trans-unit id="2231cde0326d2e7cbe7a063bea9dd6db2ca090b8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill in with</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; the value to fill in with</target>
        </trans-unit>
        <trans-unit id="9b8e6c78f63bfe21f3c21ce8282ea0ac124b1636" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The value associated with &lt;code&gt;key&lt;/code&gt; to be added to the store.</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; The value associated with &lt;code&gt;key&lt;/code&gt; to be added to the store.</target>
        </trans-unit>
        <trans-unit id="58297fdeed23352e6cee0f60735b074f80fc01b0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;値&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="dbe8188f9a9c1f457d68930c71ccb9451d1315c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the number to be added to each element of &lt;code&gt;input&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;) &amp;ndash; the number to be added to each element of &lt;code&gt;input&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="b0865065739e87d295963220665d5169b7839527" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for</source>
          <target state="translated">&lt;strong&gt;value&lt;/strong&gt; (&lt;em&gt;Number&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; multiplier for</target>
        </trans-unit>
        <trans-unit id="83dafd80344b2148557bddd1e22227cc205b7bf0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The values to use where &lt;code&gt;input&lt;/code&gt; is zero.</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The values to use where &lt;code&gt;input&lt;/code&gt; is zero.</target>
        </trans-unit>
        <trans-unit id="a0a6ed69f7bb031d32442c8207e6351c28728f97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; N-D tensor or a Scalar containing the search value(s).</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; N-D tensor or a Scalar containing the search value(s).</target>
        </trans-unit>
        <trans-unit id="068141ee62e0c741721a1ca247da7418337fa905" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Values to build histogram</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;numpy.array&lt;/em&gt;&lt;em&gt;, or &lt;/em&gt;&lt;em&gt;string/blobname&lt;/em&gt;) &amp;ndash; Values to build histogram</target>
        </trans-unit>
        <trans-unit id="81346c9c646d8fdc4c0b129427baa5e0d2452356" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;values&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial values for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt;, scalar, and other types.</source>
          <target state="translated">&lt;strong&gt;values&lt;/strong&gt; (&lt;em&gt;array_like&lt;/em&gt;) &amp;ndash; Initial values for the tensor. Can be a list, tuple, NumPy &lt;code&gt;ndarray&lt;/code&gt; , scalar, and other types.</target>
        </trans-unit>
        <trans-unit id="2514f73a2f02b616f12aa53311fb41936e3843bc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vdim&lt;/strong&gt; &amp;ndash; total number of features in value. Default: None.</source>
          <target state="translated">&lt;strong&gt;vdim&lt;/strong&gt; &amp;ndash; total number of features in value. Default: None.</target>
        </trans-unit>
        <trans-unit id="819b9c6fd109a7c509127d79322ef0512ba65bd2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first vector of the outer product</source>
          <target state="translated">&lt;strong&gt;vec1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the first vector of the outer product</target>
        </trans-unit>
        <trans-unit id="4e73eb0cbf6f2a91979ca7e439e5aa7d715d0300" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input vector</source>
          <target state="translated">&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input vector</target>
        </trans-unit>
        <trans-unit id="131877debbb3166e16ce26108f5a3eed6fc2f019" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second vector of the outer product</source>
          <target state="translated">&lt;strong&gt;vec2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the second vector of the outer product</target>
        </trans-unit>
        <trans-unit id="4d0559907de880bfcd717f1f78869a200f9027f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a single vector represents the parameters of a model.</source>
          <target state="translated">&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; a single vector represents the parameters of a model.</target>
        </trans-unit>
        <trans-unit id="daede4c661612057da3d485c36e667e3f8d4dad0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; vector to be multiplied</source>
          <target state="translated">&lt;strong&gt;vec&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; vector to be multiplied</target>
        </trans-unit>
        <trans-unit id="ff9a7e40dc82a226dc8f29f776ec07c36e2e317b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, turns on verbose logging of load steps.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; &amp;ndash; If &lt;code&gt;True&lt;/code&gt; , turns on verbose logging of load steps.</target>
        </trans-unit>
        <trans-unit id="3c7c98a393594108f301ee2c897c52950fcdeb33" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; If &lt;code&gt;True&lt;/code&gt;, prints a message to stdout for each update. Default: &lt;code&gt;False&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash; &lt;code&gt;True&lt;/code&gt; の場合、更新ごとにstdoutにメッセージを出力します。デフォルト： &lt;code&gt;False&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="2094bc9935f0b3c92d97f3cf874c37a89b5048a1" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to print graph structure in console.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether to print graph structure in console.</target>
        </trans-unit>
        <trans-unit id="c171e7c8da79938ba578ce62f6d80ce02e508b76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; if specified, we will print out a debug description of the trace being exported.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;default False&lt;/em&gt;) &amp;ndash; if specified, we will print out a debug description of the trace being exported.</target>
        </trans-unit>
        <trans-unit id="f3599691f4621301d1623dd0c2e7a30947cc6548" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt;, mute messages about hitting local caches. Note that the message about first download cannot be muted. Does not have any effect if &lt;code&gt;source = 'local'&lt;/code&gt;. Default is &lt;code&gt;True&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;verbose&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If &lt;code&gt;False&lt;/code&gt; , mute messages about hitting local caches. Note that the message about first download cannot be muted. Does not have any effect if &lt;code&gt;source = 'local'&lt;/code&gt; . Default is &lt;code&gt;True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="c849d403c5b92168af96b652290de46caebea368" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vertices&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; List of the 3D coordinates of vertices.</source>
          <target state="translated">&lt;strong&gt;vertices&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; List of the 3D coordinates of vertices.</target>
        </trans-unit>
        <trans-unit id="f13839df85806a7d212ed83a81c31127bf2c2237" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;vid_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Video data</source>
          <target state="translated">&lt;strong&gt;vid_tensor&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;) &amp;ndash; Video data</target>
        </trans-unit>
        <trans-unit id="dc84a7d8a07edfd6dc468d5b20a74d4a8841fdbe" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) seconds after epoch of event</source>
          <target state="translated">&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) seconds after epoch of event</target>
        </trans-unit>
        <trans-unit id="f41030565ca27ea1362cda461c42d37902d0ff5c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) with seconds after epoch of event</source>
          <target state="translated">&lt;strong&gt;walltime&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;) &amp;ndash; Optional override default walltime (time.time()) with seconds after epoch of event</target>
        </trans-unit>
        <trans-unit id="8173b0dc1b32bad0b60a75ecb20d002cd08f4f9e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;we want to quantize&lt;/strong&gt; (&lt;em&gt;that&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;量子化したい&lt;/strong&gt;（&lt;em&gt;それ&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="f9d74e109cb0a14286b98abd2e21c589f1814826" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; filters of shape</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; filters of shape</target>
        </trans-unit>
        <trans-unit id="f9a334f0285a62a48b2313f31b6d8a7b66efc571" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; quantized filters of shape</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; &amp;ndash; quantized filters of shape</target>
        </trans-unit>
        <trans-unit id="ab4ea073acb19584f6540d88c6edee778c2582cc" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="70e8975c00d113cb45edf143611e73c84cc5ce44" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, it has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;. Otherwise, it is treated as if having all ones.</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, it has to be a Tensor of size &lt;code&gt;C&lt;/code&gt; . Otherwise, it is treated as if having all ones.</target>
        </trans-unit>
        <trans-unit id="954e4537a940f3ba78802ce2a539fbef33a42e08" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size &lt;code&gt;nbatch&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size &lt;code&gt;nbatch&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a1f17f82ec381f64b173aaca9f8effdf46eb1689" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; the weight for the interpolation formula</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;tensor&lt;/em&gt;) &amp;ndash; the weight for the interpolation formula</target>
        </trans-unit>
        <trans-unit id="22154f27393e88b905a5d41b51a84b23ab22932b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Quantized weight of type &lt;code&gt;torch.qint8&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Quantized weight of type &lt;code&gt;torch.qint8&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="c4cf9889c18f266792e6d5b0d19e359c339fffa5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size</source>
          <target state="translated">&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size</target>
        </trans-unit>
        <trans-unit id="0b17239462ca378c70577124e3fcde25d087b526" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight given to each class. If given, has to be a Tensor of size &lt;code&gt;C&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;重み&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;各クラスに与えられる手動の再スケーリングの重み。与えられた場合、サイズ &lt;code&gt;C&lt;/code&gt; のテンソルでなければなりません</target>
        </trans-unit>
        <trans-unit id="ceb298880b72c5ea4b42cc8ffeba86de3610e3c0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; a manual rescaling weight if provided it&amp;rsquo;s repeated to match input tensor shape</source>
          <target state="translated">&lt;strong&gt;重み&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;入力テンソルの形状に一致するように繰り返される場合は、手動で再スケーリングする重み</target>
        </trans-unit>
        <trans-unit id="4ae1b6ef1e362f74c30172fdf4ed58e3642a6d88" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight_decay&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; weight decay (L2 penalty) (default: 0)</source>
          <target state="translated">&lt;strong&gt;weight_decay&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;重みの減衰（L2ペナルティ）（デフォルト：0）</target>
        </trans-unit>
        <trans-unit id="0c1b82ff67c5795bc63f72d0dc340e41b6ccd345" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weight_decay&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; weight decay coefficient (default: 1e-2)</source>
          <target state="translated">&lt;strong&gt;weight_decay&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#float&quot;&gt;float &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;重み減衰係数（デフォルト：1e-2）</target>
        </trans-unit>
        <trans-unit id="30220330ec8f9548f71ee65df724e11d72d2b160" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weights&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; optional, weight for each value in the input tensor. Should be of same size as input tensor.</source>
          <target state="translated">&lt;strong&gt;重み&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;オプション、入力テンソルの各値の重み。入力テンソルと同じサイズである必要があります。</target>
        </trans-unit>
        <trans-unit id="98654312450d33fec9fb0161447c6249d66d1d84" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;weights&lt;/strong&gt; (&lt;em&gt;sequence&lt;/em&gt;) &amp;ndash; a sequence of weights, not necessary summing up to one</source>
          <target state="translated">&lt;strong&gt;重み&lt;/strong&gt;（&lt;em&gt;シーケンス&lt;/em&gt;）&amp;ndash;&lt;strong&gt;重みの&lt;/strong&gt;&lt;em&gt;シーケンス。&lt;/em&gt;合計する必要はありません。</target>
        </trans-unit>
        <trans-unit id="1dacae6023a61e8210dc97a03d769ec15092e68e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;win_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the size of window frame and STFT filter. Default: &lt;code&gt;None&lt;/code&gt; (treated as equal to &lt;code&gt;n_fft&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;win_length&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ウィンドウフレームとSTFTフィルターのサイズ。デフォルト： &lt;code&gt;None&lt;/code&gt; （ &lt;code&gt;n_fft&lt;/code&gt; と等しいものとして扱われます）</target>
        </trans-unit>
        <trans-unit id="6b1bf34b632ccb28e0c558a94dd1b77ac54ce12b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;win_length&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The size of window frame and STFT filter. (Default: &lt;code&gt;n_fft&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;win_length&lt;/strong&gt;（&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;ウィンドウフレームとSTFTフィルターのサイズ。（デフォルト： &lt;code&gt;n_fft&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="7d9a9a55c05cd5b2885fb65d4e15a0e9d0340b49" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; the optional window function. Default: &lt;code&gt;None&lt;/code&gt; (treated as window of all</source>
          <target state="translated">&lt;strong&gt;window&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;オプションのウィンドウ関数。デフォルト： &lt;code&gt;None&lt;/code&gt; （すべてのウィンドウとして扱われます</target>
        </trans-unit>
        <trans-unit id="f0f614133f5e416c9d9f06c46de251960734b001" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window&lt;/strong&gt; (&lt;em&gt;Optional&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor&lt;/a&gt;&lt;em&gt;]&lt;/em&gt;) &amp;ndash; The optional window function. (Default: &lt;code&gt;torch.ones(win_length)&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;window&lt;/strong&gt;（&lt;em&gt;オプション&lt;/em&gt;&lt;em&gt;[ &lt;/em&gt;&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;torch.Tensor &lt;/a&gt;&lt;em&gt;]&lt;/em&gt;）&amp;ndash;オプションのウィンドウ関数。（デフォルト： &lt;code&gt;torch.ones(win_length)&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="49b7cd3881023ff5bbecb687d60192ac07560fe8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; length of the window.</source>
          <target state="translated">&lt;strong&gt;window_length&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ウィンドウの長さ。</target>
        </trans-unit>
        <trans-unit id="4e3bec63120999c913a0f66ab321260fd1dfb2c9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;window_length&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; the size of returned window</source>
          <target state="translated">&lt;strong&gt;window_length&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;返されたウィンドウのサイズ</target>
        </trans-unit>
        <trans-unit id="9ccfcc0cdca44901901265e154f3e79d9b261692" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; Determines whether CUDA headers and libraries are added to the build. If set to &lt;code&gt;None&lt;/code&gt; (default), this value is automatically determined based on the existence of &lt;code&gt;.cu&lt;/code&gt; or &lt;code&gt;.cuh&lt;/code&gt; in &lt;code&gt;sources&lt;/code&gt;. Set it to &lt;code&gt;True`&lt;/code&gt; to force CUDA headers and libraries to be included.</source>
          <target state="translated">&lt;strong&gt;with_cuda &amp;ndash;CUDA&lt;/strong&gt;ヘッダーとライブラリをビルドに追加するかどうかを決定します。 &lt;code&gt;None&lt;/code&gt; （デフォルト）に設定すると、この値は &lt;code&gt;sources&lt;/code&gt; 内の &lt;code&gt;.cu&lt;/code&gt; または &lt;code&gt;.cuh&lt;/code&gt; の存在に基づいて自動的に決定されます。 &lt;code&gt;True`&lt;/code&gt; に設定すると、CUDAヘッダーとライブラリが強制的に含まれます。</target>
        </trans-unit>
        <trans-unit id="bd3ed9cacd1f8bdf1897ff6845942937dc2aa6cd" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_cuda&lt;/strong&gt; &amp;ndash; Determines whether CUDA headers and libraries are added to the build. If set to &lt;code&gt;None&lt;/code&gt; (default), this value is automatically determined based on whether &lt;code&gt;cuda_sources&lt;/code&gt; is provided. Set it to &lt;code&gt;True&lt;/code&gt; to force CUDA headers and libraries to be included.</source>
          <target state="translated">&lt;strong&gt;with_cuda &amp;ndash;CUDA&lt;/strong&gt;ヘッダーとライブラリをビルドに追加するかどうかを決定します。 &lt;code&gt;None&lt;/code&gt; （デフォルト）に設定すると、この値は &lt;code&gt;cuda_sources&lt;/code&gt; が提供されているかどうかに基づいて自動的に決定されます。 &lt;code&gt;True&lt;/code&gt; に設定すると、CUDAヘッダーとライブラリが強制的に含まれます。</target>
        </trans-unit>
        <trans-unit id="4815336ed54522c0846013f45d4ba87f409a2251" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_pytorch_error_handling&lt;/strong&gt; &amp;ndash; Determines whether pytorch error and warning macros are handled by pytorch instead of pybind. To do this, each function &lt;code&gt;foo&lt;/code&gt; is called via an intermediary &lt;code&gt;_safe_foo&lt;/code&gt; function. This redirection might cause issues in obscure cases of cpp. This flag should be set to &lt;code&gt;False&lt;/code&gt; when this redirect causes issues.</source>
          <target state="translated">&lt;strong&gt;with_pytorch_error_handling&lt;/strong&gt; &amp;ndash;pytorchエラーおよび警告マクロをpybindではなくpytorchで処理するかどうかを決定します。これを行うために、各関数 &lt;code&gt;foo&lt;/code&gt; は中間の &lt;code&gt;_safe_foo&lt;/code&gt; 関数を介して呼び出されます。このリダイレクトは、cppのあいまいなケースで問題を引き起こす可能性があります。このリダイレクトによって問題が発生する場合は、このフラグを &lt;code&gt;False&lt;/code&gt; に設定する必要があります。</target>
        </trans-unit>
        <trans-unit id="4a19e10a55ff5cbaf67b76afd814820dc5724ee4" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_replacement&lt;/strong&gt; (&lt;em&gt;boolean&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; whether to allow duplication in combination</source>
          <target state="translated">&lt;strong&gt;with_replacement&lt;/strong&gt;（&lt;em&gt;boolean &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;組み合わせて複製を許可するかどうか</target>
        </trans-unit>
        <trans-unit id="5415451ab70a55f73cd0137592447b005d436e95" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;with_stack&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; record source information (file and line number) for the ops</source>
          <target state="translated">&lt;strong&gt;with_stack&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash; opsのソース情報（ファイルと行番号）を記録します</target>
        </trans-unit>
        <trans-unit id="4dc6dc49be43948f81126e0018a7bfcb14810907" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;worker_init_fn&lt;/strong&gt; (&lt;em&gt;callable&lt;/em&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; If not &lt;code&gt;None&lt;/code&gt;, this will be called on each worker subprocess with the worker id (an int in &lt;code&gt;[0, num_workers - 1]&lt;/code&gt;) as input, after seeding and before data loading. (default: &lt;code&gt;None&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;worker_init_fn&lt;/strong&gt;（&lt;em&gt;callable &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;）&amp;ndash; &lt;code&gt;None&lt;/code&gt; でない場合、これは、シード後、データのロード前に、ワーカーID（ &lt;code&gt;[0, num_workers - 1]&lt;/code&gt; int ）を入力として各ワーカーサブプロセスで呼び出されます。（デフォルト： &lt;code&gt;None&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="d520029ad1a21541a6983cd1bbd1d13e71672aaf" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;worker_name&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;) &amp;ndash; the string name of a worker. If &lt;code&gt;None&lt;/code&gt;, return the the id of the current worker. (default &lt;code&gt;None&lt;/code&gt;)</source>
          <target state="translated">&lt;strong&gt;worker_name&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str&quot;&gt;str&lt;/a&gt;）&amp;ndash;ワーカーの文字列名。 &lt;code&gt;None&lt;/code&gt; の場合、現在のワーカーのIDを返します。（デフォルトは &lt;code&gt;None&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="bb05a633103b92865e059e320074b5a31b7d0338" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The number of workers in the group.</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;グループ内のワーカーの数。</target>
        </trans-unit>
        <trans-unit id="8944fd0aa7e0a543d0eb0d57230c998dddc0f01f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The total number of processes using the store</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ストアを使用しているプロセスの総数</target>
        </trans-unit>
        <trans-unit id="4b40d216b7322f8dca0f99cbebec725fe60f6e0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; The total number of store users (number of clients + 1 for the server).</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;ストアユーザーの総数（クライアントの数+サーバーの1）。</target>
        </trans-unit>
        <trans-unit id="d09ea2fd888d7766224d3eb255ea7484752c0c9d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;world_size&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Number of processes participating in the job. Required if &lt;code&gt;store&lt;/code&gt; is specified.</source>
          <target state="translated">&lt;strong&gt;world_size&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;ジョブに参加しているプロセスの数。 &lt;code&gt;store&lt;/code&gt; が指定されている場合は必須です。</target>
        </trans-unit>
        <trans-unit id="e6ab46733a3cf79484335cfec30ffadc77125f0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;wrap&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; the diagonal &amp;lsquo;wrapped&amp;rsquo; after N columns for tall matrices.</source>
          <target state="translated">&lt;strong&gt;wrap&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;）&amp;ndash;背の高い行列のN列の後に対角線の「&lt;strong&gt;折り返し&lt;/strong&gt;」。</target>
        </trans-unit>
        <trans-unit id="039b003cafbdb956a808db4a8f6a45acd6067df8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x1&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor of shape</source>
          <target state="translated">&lt;strong&gt;x1&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;形状の入力テンソル</target>
        </trans-unit>
        <trans-unit id="4e34f43957ff13fc9b613484e5941ff19da8a3ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x1&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; First input.</source>
          <target state="translated">&lt;strong&gt;x1&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;最初の入力。</target>
        </trans-unit>
        <trans-unit id="8c4e3cfe4db7965d9ad32d9b63db999f3ce5916d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x2&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; input tensor of shape</source>
          <target state="translated">&lt;strong&gt;x2&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;形状の入力テンソル</target>
        </trans-unit>
        <trans-unit id="3da2f4cab51d1d5ba9a574263a3bb5682b0875ae" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x2&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Second input (of size matching x1).</source>
          <target state="translated">&lt;strong&gt;x2&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash; 2番目の入力（サイズがx1に一致）。</target>
        </trans-unit>
        <trans-unit id="b14756a562cc7fda7e1454cc0eb57d083473e78a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; 1-D input tensor.</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;1-D入力テンソル。</target>
        </trans-unit>
        <trans-unit id="8604fc9ce7b9564333699bb4a5095a672bbc3ef3" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The points at which the function &lt;code&gt;y&lt;/code&gt; is sampled. If &lt;code&gt;x&lt;/code&gt; is not in ascending order, intervals on which it is decreasing contribute negatively to the estimated integral (i.e., the convention</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;関数 &lt;code&gt;y&lt;/code&gt; がサンプリングされるポイント。 &lt;code&gt;x&lt;/code&gt; が昇順でない場合、xが減少する区間は、推定された積分に負の影響を及ぼします（つまり、規則</target>
        </trans-unit>
        <trans-unit id="e7876837160f02de9f8a91a92f6b6e1b84b26b5d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;x&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; value (if :attr:x is a scalar) or values selected at indices where &lt;code&gt;condition&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;x&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;スカラー&lt;/em&gt;）&amp;ndash;値（：attr：xがスカラーの場合）または &lt;code&gt;condition&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; のインデックスで選択された値</target>
        </trans-unit>
        <trans-unit id="c68f34fbda8cdacd4cc4e099cfcd5fcf6cc52209" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;y&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; The values of the function to integrate</source>
          <target state="translated">&lt;strong&gt;y&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;）&amp;ndash;積分する関数の値</target>
        </trans-unit>
        <trans-unit id="72163565538ba72a52711498c5bfc9bb0d1c872a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;y&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;Scalar&lt;/em&gt;) &amp;ndash; value (if :attr:x is a scalar) or values selected at indices where &lt;code&gt;condition&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;y&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;em&gt;スカラー&lt;/em&gt;）&amp;ndash;値（：attr：xがスカラーの場合）または &lt;code&gt;condition&lt;/code&gt; が &lt;code&gt;False&lt;/code&gt; のインデックスで選択された値</target>
        </trans-unit>
        <trans-unit id="3ba6c96ac6975a47208ccc9a0b52c75bb531c910" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_infinity&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Whether to zero infinite losses and the associated gradients. Default: &lt;code&gt;False&lt;/code&gt; Infinite losses mainly occur when the inputs are too short to be aligned to the targets.</source>
          <target state="translated">&lt;strong&gt;zero_infinity&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;無限の損失と関連する勾配をゼロにするかどうか。デフォルト： &lt;code&gt;False&lt;/code&gt; 無限損失は主に、入力が短すぎてターゲットに位置合わせできない場合に発生します。</target>
        </trans-unit>
        <trans-unit id="8638d6633ab7a4cf4da345720cc4bf2ac60e6815" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point, dtype&lt;/strong&gt; (&lt;em&gt;`scale`&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;) &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;zero_point、dtype&lt;/strong&gt;（&lt;em&gt;`scale` &lt;/em&gt;&lt;em&gt;、&lt;/em&gt;）&amp;ndash;</target>
        </trans-unit>
        <trans-unit id="a1615df751082d4be9fb7cb31b4bb34695adfb0b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; quantization zero point of the output tensor</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash;出力テンソルの量子化ゼロ点</target>
        </trans-unit>
        <trans-unit id="7247c88b2e908aea42f2ec3b7339d9a256569c09" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; quantization zero_point for the output. Default: 0</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash;出力の量子化zero_point。デフォルト：0</target>
        </trans-unit>
        <trans-unit id="c2f7a803cb5fc582e2a288ee7168564bc33aa879" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash; zero_point of output Quantized Tensor</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt; &amp;ndash;出力のzero_point量子化テンソル</target>
        </trans-unit>
        <trans-unit id="223a725fe4e09c854eee949c752211f3d9820057" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; offset in integer value that maps to float zero</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;浮動小数点ゼロにマップされる整数値のオフセット</target>
        </trans-unit>
        <trans-unit id="4989efaac53b9d7d2d13c26d99d3def10531a636" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; (&lt;em&gt;long&lt;/em&gt;) &amp;ndash; output zero point. If None, derived from the input zero_point</source>
          <target state="translated">&lt;strong&gt;zero_point&lt;/strong&gt;（&lt;em&gt;long&lt;/em&gt;）&amp;ndash;ゼロ点を出力します。Noneの場合、入力zero_pointから派生</target>
        </trans-unit>
        <trans-unit id="429279404949d69c49587e68892b656c79b73f46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_point&lt;/strong&gt; - quantization zero point of the output, type: long.</source>
          <target state="translated">&lt;strong&gt;zero_point-&lt;/strong&gt;出力の量子化ゼロ点、タイプ：long。</target>
        </trans-unit>
        <trans-unit id="ffac724f17c0594d2ca1937a69bcfaf236dd1829" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;zero_points&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; integer 1D tensor of offset to use, size should match &lt;code&gt;input.size(axis)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;zero_points&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;）&amp;ndash;使用するオフセットの整数1Dテンソル。サイズは &lt;code&gt;input.size(axis)&lt;/code&gt; と一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="47893dd3bbacac551e16f1ea5a7f8a26eeaf9113" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;{input}&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;{入力}&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="20c4529cd2a28cc535afcdbc8ecd226b45340d70" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;{out}&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;{out}&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="b7c764a4f83bf4672db31e3ba964ce2216c4e083" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Bilinear.bias&lt;/strong&gt; &amp;ndash; the learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Bilinear.bias&lt;/strong&gt; &amp;ndash;形状のモジュールの学習可能なバイアス</target>
        </trans-unit>
        <trans-unit id="f89b33be0a086eb9b0633fea112be0da1cf2bd2d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Bilinear.weight&lt;/strong&gt; &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Bilinear.weight&lt;/strong&gt; &amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="786e19415c7aa959d92f4e6681a37e6161c762ce" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜Conv1d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状モジュール（out_channels）の学習可能なバイアス。場合 &lt;code&gt;bias&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 、これらの重みの値は、以下からサンプリングされます</target>
        </trans-unit>
        <trans-unit id="e06e33e99b955e617b52597dc55cd653ebf70f55" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;〜Conv1d.scale&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力スケールのスカラー</target>
        </trans-unit>
        <trans-unit id="54e6f2689f69e48b8f9ee81ce716072bcf839a90" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Conv1d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="2b1b80d43979766fbec56a2cf03434689febed6b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;〜Conv1d.weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;学習可能な重みパラメーターから導出されたパックテンソル。</target>
        </trans-unit>
        <trans-unit id="7fe271f7c736601cbe58a60730d1ba367c3b713a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv1d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;〜Conv1d.zero_point&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力ゼロ点のスカラー</target>
        </trans-unit>
        <trans-unit id="cab585d0b3b7a1e8311f27f86e9c9020f1f22fd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状モジュール（out_channels）の学習可能なバイアス。場合 &lt;code&gt;bias&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 、これらの重みの値は、以下からサンプリングされます</target>
        </trans-unit>
        <trans-unit id="491e2d85ab2736d7aafefcdd0aaf9951c3be3bd0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.scale&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力スケールのスカラー</target>
        </trans-unit>
        <trans-unit id="1dbb931cba576b031f6690c20c53e86c7d5dd799" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="bbb22808d75f21da185917b5905c1df4c0e208f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;学習可能な重みパラメーターから導出されたパックテンソル。</target>
        </trans-unit>
        <trans-unit id="b3438ce5dca3a7cf14dc3bcf4aa9bbd6b0f92e36" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.weight_fake_quant&lt;/strong&gt; &amp;ndash;ウェイト用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="7b8c7c333216763559ed33e7c4b13fa4f678413a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv2d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;〜Conv2d.zero_point&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力ゼロ点のスカラー</target>
        </trans-unit>
        <trans-unit id="e2b641a6ffee3b2c43dbc8fe09c7d0c721cd8b22" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜Conv3d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状モジュール（out_channels）の学習可能なバイアス。場合 &lt;code&gt;bias&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 、これらの重みの値は、以下からサンプリングされます</target>
        </trans-unit>
        <trans-unit id="aa18d65289a64a7ca20ed8be2d410df1bdc536a6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.scale&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output scale</source>
          <target state="translated">&lt;strong&gt;〜Conv3d.scale&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力スケールのスカラー</target>
        </trans-unit>
        <trans-unit id="a72fbf59ce9ea685622e291418b9e3268a772b76" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Conv3d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="a3ad7c44a3e4e0fbec86bf00ce697cd744bb9a39" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; packed tensor derived from the learnable weight parameter.</source>
          <target state="translated">&lt;strong&gt;〜Conv3d.weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;学習可能な重みパラメーターから導出されたパックテンソル。</target>
        </trans-unit>
        <trans-unit id="99396f2687699c53375347ac0faddcdc798b2e6a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Conv3d.zero_point&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; scalar for the output zero point</source>
          <target state="translated">&lt;strong&gt;〜Conv3d.zero_point&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;出力ゼロ点のスカラー</target>
        </trans-unit>
        <trans-unit id="378d1f43230566f1da52f54e6a88d20a5d7790c7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBn2d.freeze_bn&lt;/strong&gt; &amp;ndash;</source>
          <target state="translated">&lt;strong&gt;〜ConvBn2d.freeze_bn&lt;/strong&gt; &amp;ndash;</target>
        </trans-unit>
        <trans-unit id="d3bca18d068926bc6367e11701b6f03abca19647" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBn2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜ConvBn2d.weight_fake_quant&lt;/strong&gt; &amp;ndash;ウェイト用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="a55571977e6df390a36d65d847d2bb319eff0223" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvBnReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜ConvBnReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash;ウェイト用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="ebcdaceff86165d2388fbceb90c8330fe2a56cad" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜ConvReLU2d.weight_fake_quant&lt;/strong&gt; &amp;ndash;ウェイト用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="e9364c34d7f64012a1bdca3fb740fa3d412f113d" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose1d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels). If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose1d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状モジュール（out_channels）の学習可能なバイアス。場合 &lt;code&gt;bias&lt;/code&gt; ある &lt;code&gt;True&lt;/code&gt; 、これらの重みの値は、以下からサンプリングされます</target>
        </trans-unit>
        <trans-unit id="a79a77bf8698fc3e5d49fe813734ef802e085354" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose1d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose1d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="aa3f13f16be4b75d562347e054c32c5197265a17" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose2d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels) If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose2d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能なバイアス（out_channels） &lt;code&gt;bias&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、これらの重みの値はからサンプリングされます。</target>
        </trans-unit>
        <trans-unit id="53cb49c11f8899c6db6dd4eb8c1f8305369a4456" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose2d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose2d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="114696aaba144dbc47af743af9b2db6c274492f0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose3d.bias&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable bias of the module of shape (out_channels) If &lt;code&gt;bias&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then the values of these weights are sampled from</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose3d.bias&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能なバイアス（out_channels） &lt;code&gt;bias&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、これらの重みの値はからサンプリングされます。</target>
        </trans-unit>
        <trans-unit id="b02b6fb26cf3d035db5c31efc0adbe6ef4663d46" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~ConvTranspose3d.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜ConvTranspose3d.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="97aab65ac8b5ca1756a2ee2ae4334c7bb0f4c4cb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~DataParallel.module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to be parallelized</source>
          <target state="translated">&lt;strong&gt;〜DataParallel.module&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;モジュール&lt;/a&gt;）&amp;ndash;並列化されるモジュール</target>
        </trans-unit>
        <trans-unit id="7badf98694d23be19ae92b4f0b3ca4ed320885bb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~DistributedDataParallel.module&lt;/strong&gt; (&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; the module to be parallelized.</source>
          <target state="translated">&lt;strong&gt;〜DistributedDataParallel.module&lt;/strong&gt;（&lt;a href=&quot;torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;）&amp;ndash;並列化されるモジュール。</target>
        </trans-unit>
        <trans-unit id="4a07a3b857af99d25c9450da6034aa156ec65dd7" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Embedding.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape (num_embeddings, embedding_dim) initialized from</source>
          <target state="translated">&lt;strong&gt;〜Embedding.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -から初期化形状のモジュールの学習可能量（num_embeddings、embedding_dim）</target>
        </trans-unit>
        <trans-unit id="4792bf3140649d4ebb921e27eb721fd115e1989e" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~EmbeddingBag.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of the module of shape &lt;code&gt;(num_embeddings, embedding_dim)&lt;/code&gt; initialized from</source>
          <target state="translated">&lt;strong&gt;〜EmbeddingBag.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -形状のモジュールの学習可能な重み &lt;code&gt;(num_embeddings, embedding_dim)&lt;/code&gt; から初期化</target>
        </trans-unit>
        <trans-unit id="469ff81b0263f1ef2386e2d3a21c2873edb34512" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~FakeQuantize.observer&lt;/strong&gt; (&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;Module&lt;/a&gt;) &amp;ndash; User provided module that collects statistics on the input tensor and provides a method to calculate scale and zero-point.</source>
          <target state="translated">&lt;strong&gt;〜FakeQuantize.observer&lt;/strong&gt;（&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;モジュール&lt;/a&gt;）&amp;ndash;入力テンソルの統計を収集し、スケールとゼロ点を計算する方法を提供するユーザー提供のモジュール。</target>
        </trans-unit>
        <trans-unit id="486db63a3b0eb7b18fc654f2a679c9e1761d4529" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;〜GRU.bias_hh_l [k]&lt;/strong&gt; &amp;ndash;学習可能な隠された隠されたバイアス</target>
        </trans-unit>
        <trans-unit id="568c0d45242b2e051763f666ab66932f82363330" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;〜GRU.bias_ih_l [k]&lt;/strong&gt; &amp;ndash;学習可能な入力-の隠れたバイアス</target>
        </trans-unit>
        <trans-unit id="b93874bd3ab7dfbc56dd2f71474633014b2b0a34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;〜GRU.weight_hh_l [k]&lt;/strong&gt; &amp;ndash;学習可能な隠れた隠れた重み</target>
        </trans-unit>
        <trans-unit id="9a37d1757288e74e92d126a36c7070cd51271da9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRU.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;〜GRU.weight_ih_l [k]&lt;/strong&gt; &amp;ndash;学習可能な入力-の隠された重み</target>
        </trans-unit>
        <trans-unit id="397fce9905ce991267cadb4abd4e3c29554129d2" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(3*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜GRUCell.bias_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な隠れた隠れたバイアス &lt;code&gt;(3*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="98348f5219246cc6f34a9fbbfd7a43291f274e65" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(3*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜GRUCell.bias_ih&lt;/strong&gt; &amp;ndash;学習可能な入力-形状の非表示バイアス &lt;code&gt;(3*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="4b4ebd2844961149a79509e03328089d66209c3c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(3*hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜GRUCell.weight_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な非表示の非表示の重み &lt;code&gt;(3*hidden_size, hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="3cae575d5f85368dddcd51b697fe12eaeafcac2f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~GRUCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(3*hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜GRUCell.weight_ih&lt;/strong&gt; &amp;ndash;形状の学習可能な入力非表示の重み &lt;code&gt;(3*hidden_size, input_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="67b82474914eb62986326c4401fa4d0253bcf5b9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;〜LSTM.bias_hh_l [k]&lt;/strong&gt; &amp;ndash;学習可能な隠れた隠れたバイアス</target>
        </trans-unit>
        <trans-unit id="418dca198dc36225a9737c2df2779e304936c820" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the</source>
          <target state="translated">&lt;strong&gt;〜LSTM.bias_ih_l [k]&lt;/strong&gt; &amp;ndash;学習可能な入力-の隠れたバイアス</target>
        </trans-unit>
        <trans-unit id="761d7bd5940b869c800a8cec2a3765c298134c32" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;〜LSTM.weight_hh_l [k]&lt;/strong&gt; &amp;ndash;学習可能な隠れた隠れた重み</target>
        </trans-unit>
        <trans-unit id="8ba84e472b18b379b7629198d242e16cefb87b3a" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTM.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the</source>
          <target state="translated">&lt;strong&gt;〜LSTM.weight_ih_l [k]&lt;/strong&gt; &amp;ndash;学習可能な入力-の隠された重み</target>
        </trans-unit>
        <trans-unit id="e9139487e553f7287b9b802b6302d1d46e37ac6c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(4*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜LSTMCell.bias_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な隠し隠しバイアス &lt;code&gt;(4*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="896732c137e496c5eb6b474667fdc650df4d1ba0" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(4*hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜LSTMCell.bias_ih&lt;/strong&gt; &amp;ndash;形状の学習可能な入力非表示バイアス &lt;code&gt;(4*hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="83260aa680a5b73dc2123fca87588a53fe5ecabb" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(4*hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜LSTMCell.weight_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な非表示の非表示の重み &lt;code&gt;(4*hidden_size, hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ef0a5b92b7bdcb40d6493138f43418d1354cc221" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LSTMCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(4*hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜LSTMCell.weight_ih&lt;/strong&gt; &amp;ndash;形状の学習可能な入力非表示の重み &lt;code&gt;(4*hidden_size, input_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="d0bff85ad6b7e10c45ded2385264495acab8f4ab" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.bias&lt;/strong&gt; &amp;ndash; the learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.bias&lt;/strong&gt; &amp;ndash;形状のモジュールの学習可能なバイアス</target>
        </trans-unit>
        <trans-unit id="ae7d6b9dea3f23c1bf0ec9b92c65617e42b54758" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.bias&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.bias&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習不可能なバイアス</target>
        </trans-unit>
        <trans-unit id="80ff6fec5931df84e49c65ccc4fcb004cef4385f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.bias&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable floating point bias of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.bias&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習不可能な浮動小数点バイアス</target>
        </trans-unit>
        <trans-unit id="fb2839a507719a2a7e1c7f3c45c3a78738935aff" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.scale&lt;/strong&gt; &amp;ndash; &lt;code&gt;scale&lt;/code&gt; parameter of output Quantized Tensor, type: double</source>
          <target state="translated">&lt;strong&gt;〜Linear.scale&lt;/strong&gt; &amp;ndash;出力量子化テンソルの &lt;code&gt;scale&lt;/code&gt; パラメータ、タイプ：double</target>
        </trans-unit>
        <trans-unit id="aa119f3519a628ea703e857ef172d9d75ef8b21f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜Linear.weight&lt;/strong&gt; &amp;ndash;重量用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="315c79b44e7a362abc428a093029318a5cb6ebc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; &amp;ndash; the learnable weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.weight&lt;/strong&gt; &amp;ndash;形状のモジュールの学習可能な重み</target>
        </trans-unit>
        <trans-unit id="74afca0120ba709897a38dc272bc9981208e2d0f" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable quantized weights of the module of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習不可能な量子化された重み</target>
        </trans-unit>
        <trans-unit id="64fb9620d600935b122442b73d2593dbde83a4d5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.weight&lt;/strong&gt; (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the non-learnable quantized weights of the module which are of shape</source>
          <target state="translated">&lt;strong&gt;〜Linear.weight&lt;/strong&gt;（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;形状のモジュールの学習不可能な量子化された重み</target>
        </trans-unit>
        <trans-unit id="3afcb3e4388b0cbfaa40fe5fcad92e725f9bf434" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Linear.zero_point&lt;/strong&gt; &amp;ndash; &lt;code&gt;zero_point&lt;/code&gt; parameter for output Quantized Tensor, type: long</source>
          <target state="translated">&lt;strong&gt;〜Linear.zero_point&lt;/strong&gt; &amp;ndash;出力量子化テンソルの &lt;code&gt;zero_point&lt;/code&gt; パラメーター、タイプ：long</target>
        </trans-unit>
        <trans-unit id="522c0534c3e108071d6f81950228abd00552637b" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~LinearReLU.weight&lt;/strong&gt; &amp;ndash; fake quant module for weight</source>
          <target state="translated">&lt;strong&gt;〜LinearReLU.weight&lt;/strong&gt; &amp;ndash;重量用の偽のquantモジュール</target>
        </trans-unit>
        <trans-unit id="8895a1b0c2e6107ada5018ca16d43d982c7d6188" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PReLU.weight&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; the learnable weights of shape (&lt;code&gt;num_parameters&lt;/code&gt;).</source>
          <target state="translated">&lt;strong&gt;〜PReLU.weight&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;学習可能な形状の重み（ &lt;code&gt;num_parameters&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="cc864c7bcceabd4bb9ba42bcf609c115c46dde97" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.batch_sizes&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor of integers holding information about the batch size at each sequence step</source>
          <target state="translated">&lt;strong&gt;〜PackedSequence.batch_sizes&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;各シーケンスステップでのバッチサイズに関する情報を保持する整数のテンソル</target>
        </trans-unit>
        <trans-unit id="2e648b81d63ca51e2c59bfb2670172ffa0bdcd12" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.data&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; Tensor containing packed sequence</source>
          <target state="translated">&lt;strong&gt;〜PackedSequence.data&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;）&amp;ndash;パックされたシーケンスを含むテンソル</target>
        </trans-unit>
        <trans-unit id="21b5da5ef8600388a81b311dc469708b1a243874" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.sorted_indices&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tensor of integers holding how this &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt;&lt;code&gt;PackedSequence&lt;/code&gt;&lt;/a&gt; is constructed from sequences.</source>
          <target state="translated">&lt;strong&gt;〜PackedSequence.sorted_indices&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;この&lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence&quot;&gt; &lt;code&gt;PackedSequence&lt;/code&gt; &lt;/a&gt;がシーケンスからどのように構築されるかを保持する整数のテンソル。</target>
        </trans-unit>
        <trans-unit id="2f61547990dd4c37a589c3d1c949f534ce964d34" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~PackedSequence.unsorted_indices&lt;/strong&gt; (&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;em&gt;optional&lt;/em&gt;) &amp;ndash; Tensor of integers holding how this to recover the original sequences with correct order.</source>
          <target state="translated">&lt;strong&gt;〜PackedSequence.unsorted_indices&lt;/strong&gt;（&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;Tensor &lt;/a&gt;&lt;em&gt;、&lt;/em&gt;&lt;em&gt;オプション&lt;/em&gt;）&amp;ndash;これが元のシーケンスを正しい順序で復元する方法を保持する整数のテンソル。</target>
        </trans-unit>
        <trans-unit id="235904bb81615face6c03f7fdd0762f01a44c648" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.bias_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias of the k-th layer, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNN.bias_hh_l [k]&lt;/strong&gt; &amp;ndash;形状 &lt;code&gt;(hidden_size)&lt;/code&gt; k番目の層の学習可能な隠れた隠れたバイアス</target>
        </trans-unit>
        <trans-unit id="e8ba0fa05da47543bfecbc4b3d0f4f691b034e37" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.bias_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias of the k-th layer, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNN.bias_ih_l [k]&lt;/strong&gt; &amp;ndash;学習可能な入力-形状のk番目の層の非表示バイアス &lt;code&gt;(hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="fe5a76d8bdd2bfbda4a600d6f968bab8b67aadc6" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.weight_hh_l[k]&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights of the k-th layer, of shape &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNN.weight_hh_l [k]&lt;/strong&gt; &amp;ndash;形状 &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt; のk番目のレイヤーの学習可能な非表示の非表示の重み</target>
        </trans-unit>
        <trans-unit id="6b55d7debcf00b4a9aace4971974309ba4880f3c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNN.weight_ih_l[k]&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights of the k-th layer, of shape &lt;code&gt;(hidden_size, input_size)&lt;/code&gt; for &lt;code&gt;k = 0&lt;/code&gt;. Otherwise, the shape is &lt;code&gt;(hidden_size, num_directions * hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNN.weight_ih_l [k]&lt;/strong&gt; &amp;ndash; &lt;code&gt;k = 0&lt;/code&gt; 場合の形状 &lt;code&gt;(hidden_size, input_size)&lt;/code&gt; のk番目の層の学習可能な入力非表示の重み。それ以外の場合、形状は &lt;code&gt;(hidden_size, num_directions * hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2d2a5ac7fe67f4afaa29c61a8d22a1372b50c310" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.bias_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden bias, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNNCell.bias_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な隠れた隠れたバイアス &lt;code&gt;(hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="ca09dd35f6974547104a869f45041f8189618781" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.bias_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden bias, of shape &lt;code&gt;(hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNNCell.bias_ih&lt;/strong&gt; &amp;ndash;学習可能な入力-形状の非表示バイアス &lt;code&gt;(hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="5b9525f25b880e8e32703e40cb26509bc4d00f20" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.weight_hh&lt;/strong&gt; &amp;ndash; the learnable hidden-hidden weights, of shape &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNNCell.weight_hh&lt;/strong&gt; &amp;ndash;形状の学習可能な非表示の非表示の重み &lt;code&gt;(hidden_size, hidden_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="6fdb4b833f363ac5882e1551bb76b1d609be001c" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~RNNCell.weight_ih&lt;/strong&gt; &amp;ndash; the learnable input-hidden weights, of shape &lt;code&gt;(hidden_size, input_size)&lt;/code&gt;</source>
          <target state="translated">&lt;strong&gt;〜RNNCell.weight_ih&lt;/strong&gt; &amp;ndash;学習可能な入力-形状の非表示の重み &lt;code&gt;(hidden_size, input_size)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="e82390ad46fb58d4732ab24417e49c04a40e1ca9" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Transform.bijective&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;bool&lt;/a&gt;) &amp;ndash; Whether this transform is bijective. A transform &lt;code&gt;t&lt;/code&gt; is bijective iff &lt;code&gt;t.inv(t(x)) == x&lt;/code&gt; and &lt;code&gt;t(t.inv(y)) == y&lt;/code&gt; for every &lt;code&gt;x&lt;/code&gt; in the domain and &lt;code&gt;y&lt;/code&gt; in the codomain. Transforms that are not bijective should at least maintain the weaker pseudoinverse properties &lt;code&gt;t(t.inv(t(x)) == t(x)&lt;/code&gt; and &lt;code&gt;t.inv(t(t.inv(y))) == t.inv(y)&lt;/code&gt;.</source>
          <target state="translated">&lt;strong&gt;〜Transform.bijective&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;ブール値&lt;/a&gt;） -この変換するかどうかは、全単射です。変換 &lt;code&gt;t&lt;/code&gt; 全単射であるIFF &lt;code&gt;t.inv(t(x)) == x&lt;/code&gt; と &lt;code&gt;t(t.inv(y)) == y&lt;/code&gt; すべてのための &lt;code&gt;x&lt;/code&gt; ドメインとにおける &lt;code&gt;y&lt;/code&gt; 終域です。全単射ではない変換は、少なくとも弱い &lt;code&gt;t(t.inv(t(x)) == t(x)&lt;/code&gt; 逆行列プロパティt（t.inv（t（x））== t（x）および &lt;code&gt;t.inv(t(t.inv(y))) == t.inv(y)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="824ccd97fb865047d77b970e039164f07cd61cc5" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Transform.codomain&lt;/strong&gt; (&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The constraint representing valid outputs to this transform which are inputs to the inverse transform.</source>
          <target state="translated">&lt;strong&gt;〜Transform.codomain&lt;/strong&gt;（&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;）&amp;ndash;逆変換への入力であるこの変換への有効な出力を表す制約。</target>
        </trans-unit>
        <trans-unit id="db2c67871aa1327e4e09c9aa493aef93bdaba1a8" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Transform.domain&lt;/strong&gt; (&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt;&lt;code&gt;Constraint&lt;/code&gt;&lt;/a&gt;) &amp;ndash; The constraint representing valid inputs to this transform.</source>
          <target state="translated">&lt;strong&gt;〜Transform.domain&lt;/strong&gt;（&lt;a href=&quot;#torch.distributions.constraints.Constraint&quot;&gt; &lt;code&gt;Constraint&lt;/code&gt; &lt;/a&gt;）&amp;ndash;この変換への有効な入力を表す制約。</target>
        </trans-unit>
        <trans-unit id="ee9340a9cb2c6500b85b8240b95a54b6ea0ed558" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Transform.event_dim&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;) &amp;ndash; Number of dimensions that are correlated together in the transform &lt;code&gt;event_shape&lt;/code&gt;. This should be 0 for pointwise transforms, 1 for transforms that act jointly on vectors, 2 for transforms that act jointly on matrices, etc.</source>
          <target state="translated">&lt;strong&gt;〜Transform.event_dim&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;INT&lt;/a&gt;） -変換で一緒に相関している次元数 &lt;code&gt;event_shape&lt;/code&gt; 。これは、点ごとの変換の場合は0、ベクトルに共同で作用する変換の場合は1、行列に共同で作用する変換の場合は2などになります。</target>
        </trans-unit>
        <trans-unit id="df7985766a96947f6970e908f5ca42cbfd70b948" translate="yes" xml:space="preserve">
          <source>&lt;strong&gt;~Transform.sign&lt;/strong&gt; (&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int&lt;/a&gt;&lt;em&gt; or &lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt;) &amp;ndash; For bijective univariate transforms, this should be +1 or -1 depending on whether transform is monotone increasing or decreasing.</source>
          <target state="translated">&lt;strong&gt;〜Transform.sign&lt;/strong&gt;（&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;int型&lt;/a&gt;&lt;em&gt;または&lt;/em&gt;&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;） -全単射単変量変換のために、この変換するかどうかが単調増加または減少しているに応じて、1または-1でなければなりません。</target>
        </trans-unit>
        <trans-unit id="4363d72fe0148f9fd5bda59b03b2597b475ecb3d" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;hidden_size&lt;/code&gt; Defaults to zero if not provided.</source>
          <target state="translated">= &lt;code&gt;hidden_size&lt;/code&gt; れていない場合、デフォルトはゼロです。</target>
        </trans-unit>
        <trans-unit id="76c6be0a47b9e469e03f3d72ce03df30479e07c5" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;input_size&lt;/code&gt;</source>
          <target state="translated">= &lt;code&gt;input_size&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="22b30cde9b5535b0a766c1d74e242d402d5dfdfd" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;signal_ndim&lt;/code&gt; is number of dimensions for the signal, and</source>
          <target state="translated">= &lt;code&gt;signal_ndim&lt;/code&gt; は信号の次元数であり、</target>
        </trans-unit>
        <trans-unit id="74a544e408284dc448cde186b7b615c6eac7a62c" translate="yes" xml:space="preserve">
          <source>= &lt;code&gt;signal_ndim&lt;/code&gt;. &lt;code&gt;onesided&lt;/code&gt; flag controls whether to avoid redundancy in the output results. If set to &lt;code&gt;True&lt;/code&gt; (default), the output will not be full complex result of shape</source>
          <target state="translated">= &lt;code&gt;signal_ndim&lt;/code&gt; 。 &lt;code&gt;onesided&lt;/code&gt; フラグは、出力結果の冗長性を回避するかどうかを制御します。 &lt;code&gt;True&lt;/code&gt; （デフォルト）に設定すると、出力は形状の完全に複雑な結果にはなりません</target>
        </trans-unit>
        <trans-unit id="f9c16f2184526910dd910a4f6192e4c698a5444c" translate="yes" xml:space="preserve">
          <source>≠</source>
          <target state="translated">≠</target>
        </trans-unit>
        <trans-unit id="6dcd4ce23d88e2ee9568ba546c007c63d9131c1b" translate="yes" xml:space="preserve">
          <source>A</source>
          <target state="translated">A</target>
        </trans-unit>
        <trans-unit id="0ba2b2257c8b8d78f6250b41bc82133cdb8d0d85" translate="yes" xml:space="preserve">
          <source>A (Tensor): the input tensor of size</source>
          <target state="translated">A(テンソル):サイズの入力テンソル</target>
        </trans-unit>
        <trans-unit id="c771998369e681962e03e40a977496f10f66e4ab" translate="yes" xml:space="preserve">
          <source>A - M</source>
          <target state="translated">A-M</target>
        </trans-unit>
        <trans-unit id="163f6731aec462243f49bce7b3f447cfca092a3d" translate="yes" xml:space="preserve">
          <source>A 1-D tensor of size</source>
          <target state="translated">サイズの1次元テンソル</target>
        </trans-unit>
        <trans-unit id="5ea1abe027131df5fe0f08815006944c348e7434" translate="yes" xml:space="preserve">
          <source>A 2 dimensional tensor with all the input tensors arranged in</source>
          <target state="translated">すべての入力テンソルが配置された2次元テンソル</target>
        </trans-unit>
        <trans-unit id="2da7899e802f2306f976e1aaf402515d02db4967" translate="yes" xml:space="preserve">
          <source>A 2-D tensor with ones on the diagonal and zeros elsewhere</source>
          <target state="translated">対角線上の1とゼロを持つ2次元テンソル</target>
        </trans-unit>
        <trans-unit id="94dae2aa29f01378af45a02523af98deeb730db7" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is a multi-dimensional matrix containing elements of a single data type.</source>
          <target state="translated">A &lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; は、&lt;/a&gt;単一のデータタイプの要素を含む多次元マトリックスです。</target>
        </trans-unit>
        <trans-unit id="30862db2302d182cfad7095752f0185b9568d784" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; can be constructed via a string or via a string and device ordinal</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; は&lt;/a&gt;、文字列を介して、または文字列と装置を介して構築することができる序</target>
        </trans-unit>
        <trans-unit id="24d39a42c40922c085cc28a510764783ea381734" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; is an object representing the device on which a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is or will be allocated.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; は、&lt;/a&gt;その上にデバイスを表すオブジェクトである&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; が&lt;/a&gt;あるか、または割り当てられますが。</target>
        </trans-unit>
        <trans-unit id="194543d5c9873e7986896f48770c7b948114ce57" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; is an object that represents the data type of a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. PyTorch has twelve different data types:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; は、&lt;/a&gt;データ型表すオブジェクトである&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; を&lt;/a&gt;。PyTorchには12の異なるデータ型があります。</target>
        </trans-unit>
        <trans-unit id="38e208177382a27c53d72149eef4e9baaa2dc1d2" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; is an object that represents the numerical properties of a floating point &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, (i.e. &lt;code&gt;torch.float32&lt;/code&gt;, &lt;code&gt;torch.float64&lt;/code&gt;, and &lt;code&gt;torch.float16&lt;/code&gt;). This is similar to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.finfo.html&quot;&gt;numpy.finfo&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; は、&lt;/a&gt;浮動小数点の数値特性表すオブジェクトである&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;（すなわち &lt;code&gt;torch.float32&lt;/code&gt; 、 &lt;code&gt;torch.float64&lt;/code&gt; 、及び &lt;code&gt;torch.float16&lt;/code&gt; を）。これは&lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.finfo.html&quot;&gt;numpy.finfoに&lt;/a&gt;似ています。</target>
        </trans-unit>
        <trans-unit id="e9b5788e7f1ba02d4ce5b044c5845d26ea320e06" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.finfo&quot;&gt;&lt;code&gt;torch.finfo&lt;/code&gt;&lt;/a&gt; provides the following attributes:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.finfo&quot;&gt; &lt;code&gt;torch.finfo&lt;/code&gt; は、&lt;/a&gt;次の属性が用意されています。</target>
        </trans-unit>
        <trans-unit id="dc99c23c305b6eee6243eadd6e2b8739deea9e14" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.iinfo&quot;&gt;&lt;code&gt;torch.iinfo&lt;/code&gt;&lt;/a&gt; is an object that represents the numerical properties of a integer &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; (i.e. &lt;code&gt;torch.uint8&lt;/code&gt;, &lt;code&gt;torch.int8&lt;/code&gt;, &lt;code&gt;torch.int16&lt;/code&gt;, &lt;code&gt;torch.int32&lt;/code&gt;, and &lt;code&gt;torch.int64&lt;/code&gt;). This is similar to &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.iinfo.html&quot;&gt;numpy.iinfo&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.iinfo&quot;&gt; &lt;code&gt;torch.iinfo&lt;/code&gt; は&lt;/a&gt;整数の数値特性表すオブジェクトである&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; を&lt;/a&gt;（すなわち &lt;code&gt;torch.uint8&lt;/code&gt; 、 &lt;code&gt;torch.int8&lt;/code&gt; 、 &lt;code&gt;torch.int16&lt;/code&gt; 、 &lt;code&gt;torch.int32&lt;/code&gt; 、及び &lt;code&gt;torch.int64&lt;/code&gt; ）。これは&lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.iinfo.html&quot;&gt;numpy.iinfoに&lt;/a&gt;似ています。</target>
        </trans-unit>
        <trans-unit id="ea287a33429f2668f3a29b9f646857cd3589f455" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.iinfo&quot;&gt;&lt;code&gt;torch.iinfo&lt;/code&gt;&lt;/a&gt; provides the following attributes:</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.iinfo&quot;&gt; &lt;code&gt;torch.iinfo&lt;/code&gt; は、&lt;/a&gt;次の属性が用意されています。</target>
        </trans-unit>
        <trans-unit id="c2142ddfec581443f517442f35bb15b0be1e58bb" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt; is an object that represents the memory layout of a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. Currently, we support &lt;code&gt;torch.strided&lt;/code&gt; (dense Tensors) and have beta support for &lt;code&gt;torch.sparse_coo&lt;/code&gt; (sparse COO Tensors).</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; は&lt;/a&gt;のメモリレイアウト表すオブジェクトである&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; を&lt;/a&gt;。現在、 &lt;code&gt;torch.strided&lt;/code&gt; （密なテンソル）をサポートしており、 &lt;code&gt;torch.sparse_coo&lt;/code&gt; （疎なCOOテンソル）のベータ版をサポートしています。</target>
        </trans-unit>
        <trans-unit id="de355853c58ee99175ccddd4a1b61f2e88daa33a" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.torch.memory_format&quot;&gt;&lt;code&gt;torch.memory_format&lt;/code&gt;&lt;/a&gt; is an object representing the memory format on which a &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt; is or will be allocated.</source>
          <target state="translated">&lt;a href=&quot;#torch.torch.memory_format&quot;&gt; &lt;code&gt;torch.memory_format&lt;/code&gt; は、&lt;/a&gt;その上にメモリ形式を表すオブジェクトである&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; が&lt;/a&gt;あるか、または割り当てられますが。</target>
        </trans-unit>
        <trans-unit id="c2fda6a0424485527dc39199cf94f24420a7588b" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; uses single-process data loading by default.</source>
          <target state="translated">A&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;、デフォルトでは、単一のプロセスデータの読み込みを使用しています。</target>
        </trans-unit>
        <trans-unit id="10fbed407aac8b67f8332747c3e4586eb1dec2dc" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torchscript-class&quot;&gt;TorchScript Class&lt;/a&gt;</source>
          <target state="translated">A &lt;a href=&quot;#torchscript-class&quot;&gt;TorchScriptクラス&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="87a00529d12368e11ecb0951f6020b25b804bf4c" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;#torchscript-enum&quot;&gt;TorchScript Enum&lt;/a&gt;</source>
          <target state="translated">A &lt;a href=&quot;#torchscript-enum&quot;&gt;TorchScript列挙&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7404dcf6cb59834c3f935967f5f2cff903cab0d1" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; with a single &lt;code&gt;forward&lt;/code&gt; method will have an attribute &lt;code&gt;code&lt;/code&gt;, which you can use to inspect the &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s code. If the &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; has more than one method, you will need to access &lt;code&gt;.code&lt;/code&gt; on the method itself and not the module. We can inspect the code of a method named &lt;code&gt;foo&lt;/code&gt; on a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; by accessing &lt;code&gt;.foo.code&lt;/code&gt;. The example above produces this output:</source>
          <target state="translated">A &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;シングルと &lt;code&gt;forward&lt;/code&gt; 方法は属性があります &lt;code&gt;code&lt;/code&gt; あなたが検査に使用することができ、&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;のコードを。場合&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; が&lt;/a&gt;複数のメソッドを持っている、あなたはアクセスにする必要があります &lt;code&gt;.code&lt;/code&gt; 方法自体ではなく、モジュール上。私たちは、指定されたメソッドのコードを検査することができます &lt;code&gt;foo&lt;/code&gt; の上&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;アクセスして &lt;code&gt;.foo.code&lt;/code&gt; を。上記の例では、次の出力が生成されます。</target>
        </trans-unit>
        <trans-unit id="fe55e59d1093f23c98c38d66836a27b73eecda96" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt;&lt;code&gt;collections.namedtuple&lt;/code&gt;&lt;/a&gt; tuple type</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt; &lt;code&gt;collections.namedtuple&lt;/code&gt; の&lt;/a&gt;タプル型</target>
        </trans-unit>
        <trans-unit id="52f3bfdc6708921215b778992e2b2023ce0cf17c" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls where TensorFloat-32 tensor cores may be used in cuDNN convolutions on Ampere or newer GPUs. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat-32(TF32) on Ampere devices&lt;/a&gt;.</source>
          <target state="translated">TensorFloat-32テンソルコアをAmpere以降のGPUのcuDNN畳み込みで使用できる場所を制御する&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;AmpereデバイスのTensorFloat-32（TF32）を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="ee7cf0dafdb20b0870f4ba1b8b3c1c9c0b0961ae" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls whether TensorFloat-32 tensor cores may be used in matrix multiplications on Ampere or newer GPUs. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;TensorFloat-32(TF32) on Ampere devices&lt;/a&gt;.</source>
          <target state="translated">TensorFloat-32テンソルコアをAmpere以降のGPUでの行列乗算に使用できるかどうかを制御する&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;。&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#tf32-on-ampere&quot;&gt;AmpereデバイスのTensorFloat-32（TF32）を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="132439c11835b26ffb69dbea90cbf5ac7df424e2" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that controls whether cuDNN is enabled.</source>
          <target state="translated">cuDNNを有効にするかどうかを制御する&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="f8f9daed2aeb319caf641cde5cc61730c1047610" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that, if True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest.</source>
          <target state="translated">Trueの場合、cuDNNが複数の畳み込みアルゴリズムをベンチマークし、最速を選択する&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="ad8b39b030a50343fcfc5491aa61a98d87ef927a" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/a&gt; that, if True, causes cuDNN to only use deterministic convolution algorithms. See also &lt;a href=&quot;generated/torch.is_deterministic#torch.is_deterministic&quot;&gt;&lt;code&gt;torch.is_deterministic()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.set_deterministic#torch.set_deterministic&quot;&gt;&lt;code&gt;torch.set_deterministic()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://docs.python.org/3/library/functions.html#bool&quot;&gt; &lt;code&gt;bool&lt;/code&gt; &lt;/a&gt;Trueの場合、唯一の決定論的畳み込みアルゴリズムを使用するようにcuDNNの原因となる、ということ。&lt;a href=&quot;generated/torch.is_deterministic#torch.is_deterministic&quot;&gt; &lt;code&gt;torch.is_deterministic()&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;generated/torch.set_deterministic#torch.set_deterministic&quot;&gt; &lt;code&gt;torch.set_deterministic()&lt;/code&gt; &lt;/a&gt;も参照してください。</target>
        </trans-unit>
        <trans-unit id="363a5bf37cd0bd5599a7ac4f74f15c234a572c9d" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/a&gt; that controls cache capacity of cuFFT plan.</source>
          <target state="translated">cuFFTプランのキャッシュ容量を制御する&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt; &lt;code&gt;int&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="15086d30a742ea962251815a98fb5f43c932d666" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;&amp;rsquo;s device can be accessed via the &lt;a href=&quot;tensors#torch.Tensor.device&quot;&gt;&lt;code&gt;Tensor.device&lt;/code&gt;&lt;/a&gt; property.</source>
          <target state="translated">A &lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;の装置を介してアクセスすることができる&lt;a href=&quot;tensors#torch.Tensor.device&quot;&gt; &lt;code&gt;Tensor.device&lt;/code&gt; の&lt;/a&gt;プロパティ。</target>
        </trans-unit>
        <trans-unit id="669a8dfbb51e49ee0a4e2b45cc3fe7e68a5626a0" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. When &lt;code&gt;func&lt;/code&gt; is a &lt;code&gt;torch.nn.Module&lt;/code&gt;, the returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; will have the same set of sub-modules and parameters as &lt;code&gt;func&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; の&lt;/a&gt;単一持つオブジェクト &lt;code&gt;forward&lt;/code&gt; 追跡コードを含む方法。場合 &lt;code&gt;func&lt;/code&gt; がある &lt;code&gt;torch.nn.Module&lt;/code&gt; 、返さ&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; は&lt;/a&gt;としてサブモジュールとパラメータの同じセットがあります &lt;code&gt;func&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="41acf1053b0302918ca7cea8e31ad650f225d642" translate="yes" xml:space="preserve">
          <source>A &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; の&lt;/a&gt;オブジェクト。</target>
        </trans-unit>
        <trans-unit id="7ba4764527a7c1083db1bd25ed8621fc70d8ebcb" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;dim&lt;/code&gt; value within the range &lt;code&gt;[-input.dim() - 1, input.dim() + 1)&lt;/code&gt; can be used. Negative &lt;code&gt;dim&lt;/code&gt; will correspond to &lt;a href=&quot;#torch.unsqueeze&quot;&gt;&lt;code&gt;unsqueeze()&lt;/code&gt;&lt;/a&gt; applied at &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;dim + input.dim() + 1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; 範囲内の値は、 &lt;code&gt;[-input.dim() - 1, input.dim() + 1)&lt;/code&gt; を使用することができます。負の &lt;code&gt;dim&lt;/code&gt; は、 &lt;code&gt;dim&lt;/code&gt; = &lt;code&gt;dim + input.dim() + 1&lt;/code&gt; 適用される&lt;a href=&quot;#torch.unsqueeze&quot;&gt; &lt;code&gt;unsqueeze()&lt;/code&gt; に&lt;/a&gt;対応します。</target>
        </trans-unit>
        <trans-unit id="a4042276aa29d077b69d47201952f51420b20aea" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;torch.ByteTensor&lt;/code&gt; which contains all the necessary bits to restore a Generator to a specific point in time.</source>
          <target state="translated">A &lt;code&gt;torch.ByteTensor&lt;/code&gt; 時間内の特定のポイントにジェネレータを復元するために必要なすべてのビットを含みます。</target>
        </trans-unit>
        <trans-unit id="651aaa3c833905f7faa2adf76b8bd668ead8cca6" translate="yes" xml:space="preserve">
          <source>A &lt;code&gt;torch.Storage&lt;/code&gt; is a contiguous, one-dimensional array of a single data type.</source>
          <target state="translated">A &lt;code&gt;torch.Storage&lt;/code&gt; は、単一のデータ・タイプの連続、一次元アレイです。</target>
        </trans-unit>
        <trans-unit id="8d3fcf73542a1b9a5f63963e6df264f067c5be6b" translate="yes" xml:space="preserve">
          <source>A = LL^T</source>
          <target state="translated">A=LL^T</target>
        </trans-unit>
        <trans-unit id="9a98c44769eae9961b395c0bbcfcad7880070dff" translate="yes" xml:space="preserve">
          <source>A = U diag(S) V^T</source>
          <target state="translated">A=U diag(S)V^T</target>
        </trans-unit>
        <trans-unit id="e0c55a36f7072ee8c943df73addbc18e8cc62aa0" translate="yes" xml:space="preserve">
          <source>A = U^TU</source>
          <target state="translated">A=U^TU</target>
        </trans-unit>
        <trans-unit id="4ad39d5878705cc98deef8592636ef6df59eca22" translate="yes" xml:space="preserve">
          <source>A CUDA stream is a linear sequence of execution that belongs to a specific device, independent from other streams. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-semantics&quot;&gt;CUDA semantics&lt;/a&gt; for details.</source>
          <target state="translated">CUDAストリームは、他のストリームから独立した、特定のデバイスに属する実行の線形シーケンスです。詳細については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-semantics&quot;&gt;CUDAセマンティクス&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="1c931baf3955ce6642a1157d462795c45a1e4f6a" translate="yes" xml:space="preserve">
          <source>A Conv2d module attached with FakeQuantize modules for weight, used for quantization aware training.</source>
          <target state="translated">FakeQuantizeモジュールをウェイト用にアタッチしたConv2dモジュールで、量子化を意識した学習に使用します。</target>
        </trans-unit>
        <trans-unit id="72876496e2dc3bd4b4d55b0ee6148f21eda8c0c7" translate="yes" xml:space="preserve">
          <source>A ConvBn2d module is a module fused from Conv2d and BatchNorm2d, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">ConvBn2dモジュールは、Conv2dとBatchNorm2dを融合させたモジュールで、重みのFakeQuantizeモジュールを付加したもので、量子化を意識した学習に使用します。</target>
        </trans-unit>
        <trans-unit id="096a086e744907bafa054ddb3c822576842bca8b" translate="yes" xml:space="preserve">
          <source>A ConvBnReLU2d module is a module fused from Conv2d, BatchNorm2d and ReLU, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">ConvBnReLU2dモジュールは、Conv2d,BatchNorm2d,ReLUを融合させたモジュールで、重みのFakeQuantizeモジュールを付加したもので、量子化を意識した学習に使用します。</target>
        </trans-unit>
        <trans-unit id="6056ceba54b6d5f2f7479fdf0420885d4c9ee2d7" translate="yes" xml:space="preserve">
          <source>A ConvReLU2d module is a fused module of Conv2d and ReLU</source>
          <target state="translated">ConvReLU2dモジュールは、Conv2dとReLUの融合モジュールです。</target>
        </trans-unit>
        <trans-unit id="2680c03e7de7a88804eb33c2fdac5905f71c50af" translate="yes" xml:space="preserve">
          <source>A ConvReLU2d module is a fused module of Conv2d and ReLU, attached with FakeQuantize modules for weight for quantization aware training.</source>
          <target state="translated">ConvReLU2dモジュールは、Conv2dとReLUを融合させたモジュールで、量子化を意識した学習のための重み付けのためのFakeQuantizeモジュールが付属しています。</target>
        </trans-unit>
        <trans-unit id="6f481e2f39df1d5e690d89d168813ffb2098eecf" translate="yes" xml:space="preserve">
          <source>A ConvReLU3d module is a fused module of Conv3d and ReLU</source>
          <target state="translated">ConvReLU3dモジュールはConv3dとReLUの融合モジュールです。</target>
        </trans-unit>
        <trans-unit id="2b27bbd839fbfbe69a98f451005ba9c4f4eacd76" translate="yes" xml:space="preserve">
          <source>A FunctionEventAvg object.</source>
          <target state="translated">FunctionEventAvg オブジェクトです。</target>
        </trans-unit>
        <trans-unit id="c581294889f60e363c7316ff06c75be3343c616d" translate="yes" xml:space="preserve">
          <source>A LinearReLU module fused from Linear and ReLU modules</source>
          <target state="translated">LinearとReLUモジュールを融合させたLinearReLUモジュール</target>
        </trans-unit>
        <trans-unit id="d75cf067e6cff790d10b968c6dfc06b15a74c001" translate="yes" xml:space="preserve">
          <source>A LinearReLU module fused from Linear and ReLU modules, attached with FakeQuantize modules for weight, used in quantization aware training.</source>
          <target state="translated">LinearとReLUモジュールを融合させたLinearReLUモジュールに、重み用のFakeQuantizeモジュールを追加したもので、量子化を意識した学習に使用します。</target>
        </trans-unit>
        <trans-unit id="f014741eaa3c28d99fb30934bea4ac8630cb0954" translate="yes" xml:space="preserve">
          <source>A PyTorch tensor of any dtype, dimension, or backend</source>
          <target state="translated">任意のdtype、次元、バックエンドのPyTorchテンソル</target>
        </trans-unit>
        <trans-unit id="606edcfedaa2aed46ccbb45e395a66931ad76205" translate="yes" xml:space="preserve">
          <source>A TCP-based distributed key-value store implementation. The server store holds the data, while the client stores can connect to the server store over TCP and perform actions such as &lt;code&gt;set()&lt;/code&gt; to insert a key-value pair, &lt;code&gt;get()&lt;/code&gt; to retrieve a key-value pair, etc.</source>
          <target state="translated">TCPベースの分散型Key-Valueストアの実装。サーバーストアはデータを保持しますが、クライアントストアはTCP経由でサーバーストアに接続し、 &lt;code&gt;set()&lt;/code&gt; を使用してキーと値のペアを挿入したり、 &lt;code&gt;get()&lt;/code&gt; を使用してキーと値のペアを取得したりできます。</target>
        </trans-unit>
        <trans-unit id="934bb2f6ce37592fed6983ebae538926df9a870a" translate="yes" xml:space="preserve">
          <source>A Tensor with the same shape as the input, except with &lt;code&gt;dim&lt;/code&gt; removed. Each element of the returned tensor represents the estimated integral</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; 削除されていることを除いて、入力と同じ形状のテンソル。返されたテンソルの各要素は、推定された積分を表します</target>
        </trans-unit>
        <trans-unit id="ba88f3b238bb390167a791ceb442cf7b95e4e5ce" translate="yes" xml:space="preserve">
          <source>A \approx U diag(S) V^T</source>
          <target state="translated">A approx U diag(S)V^T</target>
        </trans-unit>
        <trans-unit id="e1ab8dd0ff33393a1f6a71bc1bf559f59b193357" translate="yes" xml:space="preserve">
          <source>A batch of KL divergences of shape &lt;code&gt;batch_shape&lt;/code&gt;.</source>
          <target state="translated">形状 &lt;code&gt;batch_shape&lt;/code&gt; のKL分岐のバッチ。</target>
        </trans-unit>
        <trans-unit id="4cb845308f633f9bb52d4d2c01f1eae33c0b43f8" translate="yes" xml:space="preserve">
          <source>A boolean indicating if all kernels in this stream are completed.</source>
          <target state="translated">このストリームのすべてのカーネルが完了したかどうかを示すブール値。</target>
        </trans-unit>
        <trans-unit id="b74fae9955917e49531486c1dc48e2490ed86644" translate="yes" xml:space="preserve">
          <source>A boolean indicating if all work currently captured by event has completed.</source>
          <target state="translated">現在イベントによって捕捉されているすべての作業が完了したかどうかを示すブール値。</target>
        </trans-unit>
        <trans-unit id="448d4ffe506866b86729dc826b5e940db7f330bc" translate="yes" xml:space="preserve">
          <source>A boolean output tensor cannot accept a non-boolean tensor.</source>
          <target state="translated">ブーリアン出力テンソルは、非ブーリアンテンソルを受け入れることはできません。</target>
        </trans-unit>
        <trans-unit id="575d060b7c5e05a4efb184af85c6381a6c7e4517" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is NaN and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; がNaNである場合はTrue、それ以外の場合はFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="a32a86eb86fd42f1d26cffcd478d118053b7a4fa" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; 値と等しい場合はTrue、それ以外の場合はFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="158a2b9240f238280e9de635efb432409a1f50cc" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is finite and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が有限である場合はTrue、それ以外の場合はFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="80aa5dd6aaf0df9d8b8247b87a9a03b74284fb4e" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is greater than &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; よりも大きい場合はTrueで、他の場所ではFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="0ab5ab93711aaebbc75e0a5f02857973e9b97aab" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is greater than or equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; 値以上の場合はTrue、それ以外の場合はFalseのブールテンソル</target>
        </trans-unit>
        <trans-unit id="db5355275d060aecda9b99bd049b1fb3bb2b5999" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is infinite and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が無限である場合はTrue、それ以外の場合はFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="d1a62ed7f7827621e58d59ed2687cad0159c8094" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is less than &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; より少ない場合はTrueで、他の場所ではFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="3c0627ce37f19d66b3d1de89c44e210f0dac3318" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is less than or equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; 値以下の場合はTrue、それ以外の場合はFalseのブールテンソル</target>
        </trans-unit>
        <trans-unit id="a1eaf30e5ae09b5f416d4f43e58dcb2543097d23" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is not equal to &lt;code&gt;other&lt;/code&gt; and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が &lt;code&gt;other&lt;/code&gt; 入力と等しくない場合はTrueで、他の場所ではFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="8e7be5071d915aabc81f850d18a45204a8c662e6" translate="yes" xml:space="preserve">
          <source>A boolean tensor that is True where &lt;code&gt;input&lt;/code&gt; is real and False elsewhere</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; が実数である場合はTrue、それ以外の場合はFalseであるブールテンソル</target>
        </trans-unit>
        <trans-unit id="cd05f7a1045f3d5c6441bd51c29203b6005476c5" translate="yes" xml:space="preserve">
          <source>A boolean value</source>
          <target state="translated">ブール値</target>
        </trans-unit>
        <trans-unit id="b8ed5bafa84c3a25c2d663a29827741f80f0b589" translate="yes" xml:space="preserve">
          <source>A circular von Mises distribution.</source>
          <target state="translated">フォン・ミーゼスの円形分布。</target>
        </trans-unit>
        <trans-unit id="aa26eb075c756a3b55b4838f819fe3b9550e2c75" translate="yes" xml:space="preserve">
          <source>A common PyTorch convention is to save tensors using .pt file extension.</source>
          <target state="translated">一般的なPyTorchの規約では、.ptという拡張子を使ってテンソルを保存することになっています。</target>
        </trans-unit>
        <trans-unit id="9c7664a975132aa7b24f7761f786d39644daa8ba" translate="yes" xml:space="preserve">
          <source>A constraint object represents a region over which a variable is valid, e.g. within which a variable can be optimized.</source>
          <target state="translated">制約オブジェクトは、変数が有効な領域(例えば、変数を最適化できる領域)を表します。</target>
        </trans-unit>
        <trans-unit id="476d5990029ab426aac50c8ed35adab4427abf1f" translate="yes" xml:space="preserve">
          <source>A context manager to be used in conjunction with an instance of &lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt;&lt;/a&gt; to be able to train with uneven inputs across participating processes.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt; の&lt;/a&gt;インスタンスと組み合わせて使用​​されるコンテキストマネージャー。参加しているプロセス間で不均一な入力を使用してトレーニングできます。</target>
        </trans-unit>
        <trans-unit id="260ba8ca717d75756a968a13317edb397e545889" translate="yes" xml:space="preserve">
          <source>A context manager to disable gradient synchronizations across DDP processes. Within this context, gradients will be accumulated on module variables, which will later be synchronized in the first forward-backward pass exiting the context.</source>
          <target state="translated">DDP プロセス間のグラデーション同期を無効にするためのコンテキストマネージャです。このコンテキスト内では、グラデーションはモジュール変数に蓄積され、後にコンテキストを抜ける最初のフォワードバックワードパスで同期化されます。</target>
        </trans-unit>
        <trans-unit id="f56526cfd84150a791f8131f272572b491286ff2" translate="yes" xml:space="preserve">
          <source>A context manager to temporarily set the training mode of &amp;lsquo;model&amp;rsquo; to &amp;lsquo;mode&amp;rsquo;, resetting it when we exit the with-block. A no-op if mode is None.</source>
          <target state="translated">'model'のトレーニングモードを 'mode'に一時的に設定し、with-blockを終了するとリセットするコンテキストマネージャー。モードがNoneの場合はno-op。</target>
        </trans-unit>
        <trans-unit id="2285737f700dc7bef014b28bc5b4f7a87acfec42" translate="yes" xml:space="preserve">
          <source>A custom &lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;&lt;code&gt;Sampler&lt;/code&gt;&lt;/a&gt; that yields a list of batch indices at a time can be passed as the &lt;code&gt;batch_sampler&lt;/code&gt; argument. Automatic batching can also be enabled via &lt;code&gt;batch_size&lt;/code&gt; and &lt;code&gt;drop_last&lt;/code&gt; arguments. See &lt;a href=&quot;#loading-batched-and-non-batched-data&quot;&gt;the next section&lt;/a&gt; for more details on this.</source>
          <target state="translated">一度にバッチインデックスのリストを生成するカスタム&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt; &lt;code&gt;Sampler&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;batch_sampler&lt;/code&gt; 引数として渡すことができます。自動バッチ処理は、 &lt;code&gt;batch_size&lt;/code&gt; 引数と &lt;code&gt;drop_last&lt;/code&gt; 引数を使用して有効にすることもできます。詳細について&lt;a href=&quot;#loading-batched-and-non-batched-data&quot;&gt;は、次のセクション&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e3af495f9c511cb3a02634254a4e699d9e76ecf3" translate="yes" xml:space="preserve">
          <source>A custom &lt;code&gt;collate_fn&lt;/code&gt; can be used to customize collation, e.g., padding sequential data to max length of a batch. See &lt;a href=&quot;#dataloader-collate-fn&quot;&gt;this section&lt;/a&gt; on more about &lt;code&gt;collate_fn&lt;/code&gt;.</source>
          <target state="translated">カスタム &lt;code&gt;collate_fn&lt;/code&gt; を使用して、照合をカスタマイズできます。たとえば、バッチの最大長にシーケンシャルデータをパディングします。 &lt;code&gt;collate_fn&lt;/code&gt; 詳細については、&lt;a href=&quot;#dataloader-collate-fn&quot;&gt;このセクション&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e87e0ea4a2441712bbddd88006ff260be6cf01e8" translate="yes" xml:space="preserve">
          <source>A custom &lt;code&gt;setuptools&lt;/code&gt; build extension .</source>
          <target state="translated">カスタム &lt;code&gt;setuptools&lt;/code&gt; ビルド拡張。</target>
        </trans-unit>
        <trans-unit id="4879ed25bb5ad2e7dbdac9f4ce13e07cb540cd8d" translate="yes" xml:space="preserve">
          <source>A decorator for a function indicating that the return value of the function is guaranteed to be a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; object and this function can run asynchronously on the RPC callee. More specifically, the callee extracts the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; returned by the wrapped function and installs subsequent processing steps as a callback to that &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt;. The installed callback will read the value from the &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; when completed and send the value back as the RPC response. That also means the returned &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; only exists on the callee side and is never sent through RPC. This decorator is useful when the wrapped function&amp;rsquo;s (&lt;code&gt;fn&lt;/code&gt;) execution needs to pause and resume due to, e.g., containing &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt; or waiting for other signals.</source>
          <target state="translated">関数の戻り値が&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;オブジェクトであることが保証されており、この関数がRPC呼び出し先で非同期に実行できることを示す関数のデコレーター。より具体的には、呼び出し先は、ラップされた関数によって返される&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; を&lt;/a&gt;抽出し、その&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;へのコールバックとして後続の処理ステップをインストールします。インストールされたコールバックは、完了すると&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;から値を読み取り、RPC応答として値を送り返します。つまり、返される&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;は呼び出し側にのみ存在し、RPCを介して送信されることはありません。このデコレータは、たとえば&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; が&lt;/a&gt;含まれているために、ラップされた関数（ &lt;code&gt;fn&lt;/code&gt; ）の実行を一時停止および再開する必要がある場合に役立ちます。 または他の信号を待っています。</target>
        </trans-unit>
        <trans-unit id="1802e436eb51e9216bfa3579e7b06f1deabcfc67" translate="yes" xml:space="preserve">
          <source>A dict with key type &lt;code&gt;K&lt;/code&gt; and value type &lt;code&gt;V&lt;/code&gt;. Only &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;int&lt;/code&gt;, and &lt;code&gt;float&lt;/code&gt; are allowed as key types.</source>
          <target state="translated">キータイプ &lt;code&gt;K&lt;/code&gt; と値タイプ &lt;code&gt;V&lt;/code&gt; のdict 。キータイプとして使用できるのは、 &lt;code&gt;str&lt;/code&gt; 、 &lt;code&gt;int&lt;/code&gt; 、および &lt;code&gt;float&lt;/code&gt; のみです。</target>
        </trans-unit>
        <trans-unit id="d6b44f652191a0739c60209548e762d3272e171e" translate="yes" xml:space="preserve">
          <source>A dictionary that maps from name or type of submodule to quantization configuration, qconfig applies to all submodules of a given module unless qconfig for the submodules are specified (when the submodule already has qconfig attribute). Entries in the dictionary need to be QConfigDynamic instances.</source>
          <target state="translated">qconfigは、サブモジュールのqconfigが指定されていない限り(サブモジュールが既にqconfig属性を持っている場合)、指定されたモジュールの全てのサブモジュールに適用されます。辞書のエントリはQConfigDynamicインスタンスである必要があります。</target>
        </trans-unit>
        <trans-unit id="7a9fd856e77dfc3abad8cb7687ffa5e312c2b57f" translate="yes" xml:space="preserve">
          <source>A distributed request object. None, if not part of the group</source>
          <target state="translated">分散リクエストオブジェクト。グループに属していない場合は、なし。</target>
        </trans-unit>
        <trans-unit id="250c27944374a4fc6ecb0aa3bd87a6c9fac89495" translate="yes" xml:space="preserve">
          <source>A dynamic quantized GRUCell module with floating point tensor as inputs and outputs. Weights are quantized to 8 bits. We adopt the same interface as &lt;code&gt;torch.nn.GRUCell&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.GRUCell&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.GRUCell&lt;/a&gt; for documentation.</source>
          <target state="translated">入力および出力として浮動小数点テンソルを使用する動的量子化GRUCellモジュール。重みは8ビットに量子化されます。 &lt;code&gt;torch.nn.GRUCell&lt;/code&gt; と同じインターフェースを採用しています。ドキュメントについては、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.GRUCell&quot;&gt;https：&lt;/a&gt;//pytorch.org/docs/stable/nn.html#torch.nn.GRUCellを参照してください。</target>
        </trans-unit>
        <trans-unit id="963ab39ba50a4586010326f40e7fcf681f7e7ed2" translate="yes" xml:space="preserve">
          <source>A dynamic quantized LSTM module with floating point tensor as inputs and outputs. We adopt the same interface as &lt;code&gt;torch.nn.LSTM&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM&lt;/a&gt; for documentation.</source>
          <target state="translated">入力および出力として浮動小数点テンソルを使用する動的量子化LSTMモジュール。 &lt;code&gt;torch.nn.LSTM&lt;/code&gt; と同じインターフェースを採用しています。ドキュメントについては、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM&quot;&gt;https：&lt;/a&gt;//pytorch.org/docs/stable/nn.html#torch.nn.LSTMを参照してください。</target>
        </trans-unit>
        <trans-unit id="2bfcec11b612479566fbcc608de442edef3fec3d" translate="yes" xml:space="preserve">
          <source>A dynamic quantized LSTMCell module with floating point tensor as inputs and outputs. Weights are quantized to 8 bits. We adopt the same interface as &lt;code&gt;torch.nn.LSTMCell&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTMCell&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTMCell&lt;/a&gt; for documentation.</source>
          <target state="translated">入力および出力として浮動小数点テンソルを使用する動的量子化LSTMCellモジュール。重みは8ビットに量子化されます。 &lt;code&gt;torch.nn.LSTMCell&lt;/code&gt; と同じインターフェースを採用しています。ドキュメントについては、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.LSTMCell&quot;&gt;https：&lt;/a&gt;//pytorch.org/docs/stable/nn.html#torch.nn.LSTMCellを参照してください。</target>
        </trans-unit>
        <trans-unit id="5659ac53c7a777e77a4de94c531f76bef16a78a7" translate="yes" xml:space="preserve">
          <source>A dynamic quantized linear module with floating point tensor as inputs and outputs. We adopt the same interface as &lt;code&gt;torch.nn.Linear&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt; for documentation.</source>
          <target state="translated">入力および出力として浮動小数点テンソルを使用する動的量子化線形モジュール。 &lt;code&gt;torch.nn.Linear&lt;/code&gt; と同じインターフェースを採用しています。ドキュメントについては、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https：&lt;/a&gt;//pytorch.org/docs/stable/nn.html#torch.nn.Linearを参照してください。</target>
        </trans-unit>
        <trans-unit id="582df41a91e883c691f7f02b4e1fc90ccc670cb7" translate="yes" xml:space="preserve">
          <source>A float indicating the timeout to use for all RPCs. If an RPC does not complete in this timeframe, it will complete with an exception indicating that it has timed out.</source>
          <target state="translated">すべての RPC で使用するタイムアウトを示す float。このタイムフレーム内にRPCが完了しなかった場合、タイムアウトしたことを示す例外で完了します。</target>
        </trans-unit>
        <trans-unit id="a62b336a0d844d8b369172276cac660873819d03" translate="yes" xml:space="preserve">
          <source>A floating point scalar operand has dtype &lt;code&gt;torch.get_default_dtype()&lt;/code&gt; and an integral non-boolean scalar operand has dtype &lt;code&gt;torch.int64&lt;/code&gt;. Unlike numpy, we do not inspect values when determining the minimum &lt;code&gt;dtypes&lt;/code&gt; of an operand. Quantized and complex types are not yet supported.</source>
          <target state="translated">浮動小数点スカラーオペランドにはdtypetorch.get_default_dtype &lt;code&gt;torch.get_default_dtype()&lt;/code&gt; あり、整数の非ブールスカラーオペランドにはdtypetorch.int64が &lt;code&gt;torch.int64&lt;/code&gt; ます。numpyとは異なり、オペランドの最小 &lt;code&gt;dtypes&lt;/code&gt; を決定するときに値を検査しません。量子化された複雑なタイプはまだサポートされていません。</target>
        </trans-unit>
        <trans-unit id="b9ed960bad6396547e811b3062f43d2d9d84c3b7" translate="yes" xml:space="preserve">
          <source>A gated recurrent unit (GRU) cell</source>
          <target state="translated">ゲート型リカレントユニット(GRU)セル</target>
        </trans-unit>
        <trans-unit id="6500e1e873505e9557317cbc126e48e477677230" translate="yes" xml:space="preserve">
          <source>A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater, unless the environment variable &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; is set. See the CUDA documentation for more details: &lt;a href=&quot;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&quot;&gt;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&lt;/a&gt; If one of these environment variable configurations is not set, a &lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt;&lt;code&gt;RuntimeError&lt;/code&gt;&lt;/a&gt; will be raised from these operations when called with CUDA tensors:</source>
          <target state="translated">環境変数 &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:8&lt;/code&gt; または &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; が設定されていない限り、CUDAバージョンが10.2以上の場合、いくつかのCUDA操作は非決定的です。詳細については、CUDAのドキュメントを参照して&lt;a href=&quot;https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility&quot;&gt;ください。https&lt;/a&gt;：//docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibilityこれらの環境変数構成のいずれかが設定されていない場合、CUDAで呼び出されると&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html#RuntimeError&quot;&gt; &lt;code&gt;RuntimeError&lt;/code&gt; &lt;/a&gt;がこれらの操作から発生します。テンソル：</target>
        </trans-unit>
        <trans-unit id="7749157cec3d641bd4967868e0fa47bf1bc04040" translate="yes" xml:space="preserve">
          <source>A handle of distributed group that can be given to collective calls.</source>
          <target state="translated">コレクティブコールに与えることができる分散グループのハンドル。</target>
        </trans-unit>
        <trans-unit id="206d2d1444ddd6b067f98b835b8bca7ba47b6c99" translate="yes" xml:space="preserve">
          <source>A helper function for checkpointing sequential models.</source>
          <target state="translated">シーケンシャルモデルをチェックポイントするためのヘルパー機能。</target>
        </trans-unit>
        <trans-unit id="3fa20b5ac9b07bb8e81b28cca1e0d1e80ac301dd" translate="yes" xml:space="preserve">
          <source>A kind of Tensor that is to be considered a module parameter.</source>
          <target state="translated">モジュールパラメータとされるテンソルの一種。</target>
        </trans-unit>
        <trans-unit id="f9cebb2a15f669cb89a337fe94399d68f146852b" translate="yes" xml:space="preserve">
          <source>A known limitation that worth mentioning here is user &lt;strong&gt;CANNOT&lt;/strong&gt; load two different branches of the same repo in the &lt;strong&gt;same python process&lt;/strong&gt;. It&amp;rsquo;s just like installing two packages with the same name in Python, which is not good. Cache might join the party and give you surprises if you actually try that. Of course it&amp;rsquo;s totally fine to load them in separate processes.</source>
          <target state="translated">ここで言及する価値のある既知の制限は、ユーザーが&lt;strong&gt;同じPythonプロセス&lt;/strong&gt;で同じリポジトリの2つの異なるブランチをロードでき&lt;strong&gt;ない&lt;/strong&gt;&lt;strong&gt;こと&lt;/strong&gt;です。Pythonに同じ名前の2つのパッケージをインストールするのと同じですが、これは良くありません。キャッシュがパーティーに参加し、実際に試してみると驚きを与えるかもしれません。もちろん、別々のプロセスでそれらをロードすることはまったく問題ありません。</target>
        </trans-unit>
        <trans-unit id="5b6768469e9cca4e490d35bd92c3d9b2169e1d91" translate="yes" xml:space="preserve">
          <source>A linear module attached with FakeQuantize modules for weight, used for quantization aware training.</source>
          <target state="translated">FakeQuantizeモジュールに重み用の線形モジュールを追加したもので、量子化を意識した学習に使用します。</target>
        </trans-unit>
        <trans-unit id="dc7b6582ee399c321872ca72686d97afecec5335" translate="yes" xml:space="preserve">
          <source>A list of include path strings.</source>
          <target state="translated">インクルードパス文字列のリスト。</target>
        </trans-unit>
        <trans-unit id="670f1df273800a76faec2dce35ff3b26f07b45a5" translate="yes" xml:space="preserve">
          <source>A list of the completed &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; results. This method will throw an error if &lt;code&gt;wait&lt;/code&gt; on any &lt;a href=&quot;#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; throws.</source>
          <target state="translated">完了した&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;結果のリスト。場合、このメソッドはエラーをスローします &lt;code&gt;wait&lt;/code&gt; いずれにも&lt;a href=&quot;#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;スローされます。</target>
        </trans-unit>
        <trans-unit id="957409376e9513abfec84a7b922ff172b12a1b20" translate="yes" xml:space="preserve">
          <source>A list of which all members are type &lt;code&gt;T&lt;/code&gt;</source>
          <target state="translated">すべてのメンバーがタイプ &lt;code&gt;T&lt;/code&gt; であるリスト</target>
        </trans-unit>
        <trans-unit id="087cf02c32b2e05acb68308382032450a4a20257" translate="yes" xml:space="preserve">
          <source>A long short-term memory (LSTM) cell.</source>
          <target state="translated">長時間短期記憶(LSTM)細胞。</target>
        </trans-unit>
        <trans-unit id="f18e48f94bce7b9c4d48d2ece0fb5fb7d9efe971" translate="yes" xml:space="preserve">
          <source>A map where the key is the Tensor and the value is the associated gradient for that Tensor.</source>
          <target state="translated">キーがテンソル、値がそのテンソルに関連する勾配であるマップ。</target>
        </trans-unit>
        <trans-unit id="57d19bf168213ea66d938124a89f136c6e9d301e" translate="yes" xml:space="preserve">
          <source>A map-style dataset is one that implements the &lt;code&gt;__getitem__()&lt;/code&gt; and &lt;code&gt;__len__()&lt;/code&gt; protocols, and represents a map from (possibly non-integral) indices/keys to data samples.</source>
          <target state="translated">マップスタイルのデータセットは、 &lt;code&gt;__getitem__()&lt;/code&gt; および &lt;code&gt;__len__()&lt;/code&gt; プロトコルを実装するデータセットであり、（非整数の）インデックス/キーからデータサンプルへのマップを表します。</target>
        </trans-unit>
        <trans-unit id="96c11bff8b88f586e9213a9a4fa4c5da81e27dfc" translate="yes" xml:space="preserve">
          <source>A namedtuple (eigenvalues, eigenvectors) containing</source>
          <target state="translated">を含む名前付きタプル(固有値、固有ベクトル)。</target>
        </trans-unit>
        <trans-unit id="728e8297f47bdf6af1113fc81a7338a6111e3fbb" translate="yes" xml:space="preserve">
          <source>A namedtuple (sign, logabsdet) containing the sign of the determinant, and the log value of the absolute determinant.</source>
          <target state="translated">行列式の符号と絶対行列式の対数値を含む名前付きタプル(sign,logabsdet)。</target>
        </trans-unit>
        <trans-unit id="f051d331990381212770691e09eaebbe9dbf0969" translate="yes" xml:space="preserve">
          <source>A namedtuple (solution, QR) containing:</source>
          <target state="translated">名前付きタプル(溶液、QR)を含む。</target>
        </trans-unit>
        <trans-unit id="1c9b39e663c1fba635b37123383556801e4f83c6" translate="yes" xml:space="preserve">
          <source>A namedtuple &lt;code&gt;(solution, cloned_coefficient)&lt;/code&gt; where &lt;code&gt;cloned_coefficient&lt;/code&gt; is a clone of</source>
          <target state="translated">namedtuple &lt;code&gt;(solution, cloned_coefficient)&lt;/code&gt; &lt;code&gt;cloned_coefficient&lt;/code&gt; でのクローンであります</target>
        </trans-unit>
        <trans-unit id="5a372625038d1c917e3aaa8e230582a3f57787f0" translate="yes" xml:space="preserve">
          <source>A namedtuple of (values, indices) is returned, where the &lt;code&gt;values&lt;/code&gt; are the sorted values and &lt;code&gt;indices&lt;/code&gt; are the indices of the elements in the original &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">ここで、（値、指数）のnamedtupleは、返される &lt;code&gt;values&lt;/code&gt; ソート値とされている &lt;code&gt;indices&lt;/code&gt; 、元の要素のインデックスである &lt;code&gt;input&lt;/code&gt; テンソル。</target>
        </trans-unit>
        <trans-unit id="604316c9ed5b0a04586de06d5b7c827e9c474f1c" translate="yes" xml:space="preserve">
          <source>A namedtuple of &lt;code&gt;(values, indices)&lt;/code&gt; is returned, where the &lt;code&gt;indices&lt;/code&gt; are the indices of the elements in the original &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">&lt;code&gt;(values, indices)&lt;/code&gt; 名前付きタプルが返されます。ここで、 &lt;code&gt;indices&lt;/code&gt; は元の &lt;code&gt;input&lt;/code&gt; テンソルの要素のインデックスです。</target>
        </trans-unit>
        <trans-unit id="2869157b898ed95d4d84e8714207a533d4266c67" translate="yes" xml:space="preserve">
          <source>A new &lt;code&gt;Future&lt;/code&gt; object that holds the return value of the &lt;code&gt;callback&lt;/code&gt; and will be marked as completed when the given &lt;code&gt;callback&lt;/code&gt; finishes.</source>
          <target state="translated">&lt;code&gt;callback&lt;/code&gt; 戻り値を保持し、指定された &lt;code&gt;callback&lt;/code&gt; 終了すると完了としてマークされる新しい &lt;code&gt;Future&lt;/code&gt; オブジェクト。</target>
        </trans-unit>
        <trans-unit id="86f61ab629b1ba7d19f7dcc0bb8025724554b7cc" translate="yes" xml:space="preserve">
          <source>A new optimized torch script module</source>
          <target state="translated">新しい最適化されたトーチスクリプトモジュール</target>
        </trans-unit>
        <trans-unit id="42ae237d21ac89e5671cbfe0c552756ff6818727" translate="yes" xml:space="preserve">
          <source>A newly quantized tensor</source>
          <target state="translated">新たに量子化されたテンソル</target>
        </trans-unit>
        <trans-unit id="0f1ef90ea70757aed597fc7161c74a26091c5cc9" translate="yes" xml:space="preserve">
          <source>A non-complex output tensor cannot accept a complex tensor</source>
          <target state="translated">非複素出力テンソルは複素テンソルを受け入れられない</target>
        </trans-unit>
        <trans-unit id="e7960fd6039dfb2110c74872f4e093bd99c9b78f" translate="yes" xml:space="preserve">
          <source>A number of epochs (epochs) and a number of steps per epoch (steps_per_epoch) are provided. In this case, the number of total steps is inferred by total_steps = epochs * steps_per_epoch</source>
          <target state="translated">エポック数(epochs)とエポックあたりのステップ数(steps_per_epoch)が提供される。この場合、総ステップ数は、total_steps=epochs*steps_per_epochによって推論される。</target>
        </trans-unit>
        <trans-unit id="8860b725134278b328cae593df46234adf438aae" translate="yes" xml:space="preserve">
          <source>A placeholder identity operator that is argument-insensitive.</source>
          <target state="translated">引数を持たないプレースホルダ ID 演算子。</target>
        </trans-unit>
        <trans-unit id="68cb032d3fee685e7e338c671eb8bac87e4a9de4" translate="yes" xml:space="preserve">
          <source>A quantized linear module with quantized tensor as inputs and outputs. We adopt the same interface as &lt;code&gt;torch.nn.Linear&lt;/code&gt;, please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&lt;/a&gt; for documentation.</source>
          <target state="translated">入力および出力として量子化テンソルを備えた量子化線形モジュール。 &lt;code&gt;torch.nn.Linear&lt;/code&gt; と同じインターフェースを採用しています。ドキュメントについては、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.Linear&quot;&gt;https：&lt;/a&gt;//pytorch.org/docs/stable/nn.html#torch.nn.Linearを参照してください。</target>
        </trans-unit>
        <trans-unit id="90e1352af2e81f61b051ad3af1316a3695d6f809" translate="yes" xml:space="preserve">
          <source>A readonly &lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/a&gt; that shows the number of plans currently in the cuFFT plan cache.</source>
          <target state="translated">現在cuFFTプランキャッシュにあるプランの数を示す読み取り専用&lt;a href=&quot;https://docs.python.org/3/library/functions.html#int&quot;&gt; &lt;code&gt;int&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="4fd9c2aa54ec6edcb5667f155a92b1ad827136ed" translate="yes" xml:space="preserve">
          <source>A scalar floating point number</source>
          <target state="translated">スカラー浮動小数点数</target>
        </trans-unit>
        <trans-unit id="ab6a03d7d6d156530f83f56670a446dfe49b0bed" translate="yes" xml:space="preserve">
          <source>A scalar integer</source>
          <target state="translated">スカラー整数</target>
        </trans-unit>
        <trans-unit id="f6cc25f2f216f722bfbd2ae25c5bbc684d2ee1fd" translate="yes" xml:space="preserve">
          <source>A sequential container.</source>
          <target state="translated">シーケンシャルコンテナです。</target>
        </trans-unit>
        <trans-unit id="b8abdf9e14775972dca4bbd0c85df17f123918a1" translate="yes" xml:space="preserve">
          <source>A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.</source>
          <target state="translated">シーケンシャルコンテナです。モジュールはコンストラクタで渡された順に追加されます。あるいは、モジュールの順序付きディクトを渡すこともできます。</target>
        </trans-unit>
        <trans-unit id="d4fc542619d19643a87df58571b1a24f4ec2df18" translate="yes" xml:space="preserve">
          <source>A sequential or shuffled sampler will be automatically constructed based on the &lt;code&gt;shuffle&lt;/code&gt; argument to a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt;. Alternatively, users may use the &lt;code&gt;sampler&lt;/code&gt; argument to specify a custom &lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt;&lt;code&gt;Sampler&lt;/code&gt;&lt;/a&gt; object that at each time yields the next index/key to fetch.</source>
          <target state="translated">シーケンシャルまたはシャッフルされたサンプラーは、&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;への &lt;code&gt;shuffle&lt;/code&gt; 引数に基づいて自動的に構築されます。あるいは、ユーザーは &lt;code&gt;sampler&lt;/code&gt; 引数を使用して、フェッチする次のインデックス/キーを毎回生成するカスタム&lt;a href=&quot;#torch.utils.data.Sampler&quot;&gt; &lt;code&gt;Sampler&lt;/code&gt; &lt;/a&gt;オブジェクトを指定することもできます。</target>
        </trans-unit>
        <trans-unit id="b2ef395639e01521c4ce724db2e4291244bc2c91" translate="yes" xml:space="preserve">
          <source>A set of types and/or submodule names to apply dynamic quantization to, in which case the &lt;code&gt;dtype&lt;/code&gt; argument is used to specify the bit-width</source>
          <target state="translated">動的量子化を適用するタイプおよび/またはサブモジュール名のセット。この場合、 &lt;code&gt;dtype&lt;/code&gt; 引数を使用してビット幅を指定します。</target>
        </trans-unit>
        <trans-unit id="1eb58c4c0d2493633735de8b616a63c6ada9e2fd" translate="yes" xml:space="preserve">
          <source>A simple lookup table that looks up embeddings in a fixed dictionary and size.</source>
          <target state="translated">固定の辞書とサイズでエンベッディングを調べるシンプルなルックアップテーブルです。</target>
        </trans-unit>
        <trans-unit id="28b7624a806a8a7fcea708395f29b1cdc6294a33" translate="yes" xml:space="preserve">
          <source>A simple lookup table that stores embeddings of a fixed dictionary and size.</source>
          <target state="translated">固定の辞書とサイズのエンベッディングを格納するシンプルなルックアップテーブル。</target>
        </trans-unit>
        <trans-unit id="55e7985c56ca03421c43dc04192249c84e14dc6a" translate="yes" xml:space="preserve">
          <source>A single dimension may be -1, in which case it&amp;rsquo;s inferred from the remaining dimensions and the number of elements in &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">単一の次元は-1の場合があります。その場合、残りの次元と &lt;code&gt;input&lt;/code&gt; の要素数から推測されます。</target>
        </trans-unit>
        <trans-unit id="6fd372cb1c5e72e14169cfb741de07d656f9f533" translate="yes" xml:space="preserve">
          <source>A sparse tensor is represented as a pair of dense tensors: a tensor of values and a 2D tensor of indices. A sparse tensor can be constructed by providing these two tensors, as well as the size of the sparse tensor (which cannot be inferred from these tensors!) Suppose we want to define a sparse tensor with the entry 3 at location (0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2). We would then write:</source>
          <target state="translated">疎なテンソルは、密なテンソルのペアとして表現されます:値のテンソルとインデックスの2次元テンソルです。疎なテンソルは、これら2つのテンソルと疎なテンソルのサイズ(これらのテンソルからは推測できません!)を提供することで構築することができます。 例えば、位置(0,2)にエントリ3、位置(1,0)にエントリ4、位置(1,2)にエントリ5を持つ疎なテンソルを定義したいとします。そして,次のように書きます.</target>
        </trans-unit>
        <trans-unit id="25e7a287394a0eef59197bb60e52ac1f6a84a5df" translate="yes" xml:space="preserve">
          <source>A store implementation that uses a file to store the underlying key-value pairs.</source>
          <target state="translated">ファイルを使用してキーと値のペアを保存するストアの実装。</target>
        </trans-unit>
        <trans-unit id="6eb9ae0897420968aee10a2b095c52bec596e05c" translate="yes" xml:space="preserve">
          <source>A string</source>
          <target state="translated">文字列</target>
        </trans-unit>
        <trans-unit id="8f1eb77185d4ddf9f3156ac797aef0e5bc38f488" translate="yes" xml:space="preserve">
          <source>A string containing the table.</source>
          <target state="translated">テーブルを含む文字列。</target>
        </trans-unit>
        <trans-unit id="62ebd3a50dba8122d0758d5d23ce37a93f24ab7e" translate="yes" xml:space="preserve">
          <source>A structure that encapsulates information of a worker in the system. Contains the name and ID of the worker. This class is not meant to be constructed directly, rather, an instance can be retrieved through &lt;a href=&quot;#torch.distributed.rpc.get_worker_info&quot;&gt;&lt;code&gt;get_worker_info()&lt;/code&gt;&lt;/a&gt; and the result can be passed in to functions such as &lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt;&lt;code&gt;rpc_sync()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt;&lt;code&gt;remote()&lt;/code&gt;&lt;/a&gt; to avoid copying a string on every invocation.</source>
          <target state="translated">システム内のワーカーの情報をカプセル化する構造。ワーカーの名前とIDが含まれます。このクラスは直接構築することを意図したものではなく、&lt;a href=&quot;#torch.distributed.rpc.get_worker_info&quot;&gt; &lt;code&gt;get_worker_info()&lt;/code&gt; &lt;/a&gt;を介してインスタンスを取得し、その結果を&lt;a href=&quot;#torch.distributed.rpc.rpc_sync&quot;&gt; &lt;code&gt;rpc_sync()&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributed.rpc.remote&quot;&gt; &lt;code&gt;remote()&lt;/code&gt; &lt;/a&gt;などの関数に渡して、すべての文字列のコピーを回避できます。呼び出し。</target>
        </trans-unit>
        <trans-unit id="eb68c1bf6abfe77fe220468c23dfc4e2ccab3d1b" translate="yes" xml:space="preserve">
          <source>A tensor can be constructed from a Python &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt;&lt;code&gt;list&lt;/code&gt;&lt;/a&gt; or sequence using the &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;torch.tensor()&lt;/code&gt;&lt;/a&gt; constructor:</source>
          <target state="translated">テンソルは、&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;torch.tensor()&lt;/code&gt; &lt;/a&gt;コンストラクターを使用してPython&lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#list&quot;&gt; &lt;code&gt;list&lt;/code&gt; &lt;/a&gt;またはシーケンスから構築できます。</target>
        </trans-unit>
        <trans-unit id="78690c5a267b02f430ea07580ff8566f6ba33315" translate="yes" xml:space="preserve">
          <source>A tensor can be created with &lt;code&gt;requires_grad=True&lt;/code&gt; so that &lt;a href=&quot;autograd#module-torch.autograd&quot;&gt;&lt;code&gt;torch.autograd&lt;/code&gt;&lt;/a&gt; records operations on them for automatic differentiation.</source>
          <target state="translated">テンソルは &lt;code&gt;requires_grad=True&lt;/code&gt; で作成できるため、&lt;a href=&quot;autograd#module-torch.autograd&quot;&gt; &lt;code&gt;torch.autograd&lt;/code&gt; &lt;/a&gt;はそれらの操作を記録して自動微分します。</target>
        </trans-unit>
        <trans-unit id="9f80380a23d77d5e0da6bb3c9300dccfb821b826" translate="yes" xml:space="preserve">
          <source>A tensor containing an elementwise sum of all inputs, placed on the &lt;code&gt;destination&lt;/code&gt; device.</source>
          <target state="translated">&lt;code&gt;destination&lt;/code&gt; デバイスに配置された、すべての入力の要素ごとの合計を含むテンソル。</target>
        </trans-unit>
        <trans-unit id="28d24ca39991219e32d7e5d9431b5638f6178577" translate="yes" xml:space="preserve">
          <source>A tensor containing the STFT result with shape described above</source>
          <target state="translated">前記形状を有するSTFT結果を含むテンソル</target>
        </trans-unit>
        <trans-unit id="4fa2d7d56cae6fbb5c5952f1e0d2ce41103f7c68" translate="yes" xml:space="preserve">
          <source>A tensor containing the complex-to-complex Fourier transform result</source>
          <target state="translated">複素-複素フーリエ変換結果を含むテンソル</target>
        </trans-unit>
        <trans-unit id="f7a71af7c596a286496bba8f33f4ec3e6cafe018" translate="yes" xml:space="preserve">
          <source>A tensor containing the complex-to-complex inverse Fourier transform result</source>
          <target state="translated">複素対複素の逆フーリエ変換結果を含むテンソル</target>
        </trans-unit>
        <trans-unit id="247163b1a472b2aa12f5bee5985796f6dfb72690" translate="yes" xml:space="preserve">
          <source>A tensor containing the complex-to-real inverse Fourier transform result</source>
          <target state="translated">複素対実数逆フーリエ変換結果を含むテンソル</target>
        </trans-unit>
        <trans-unit id="795a9e2ee149db6f297c73b4efe85421d1b43891" translate="yes" xml:space="preserve">
          <source>A tensor containing the real-to-complex Fourier transform result</source>
          <target state="translated">実数-複素フーリエ変換結果を含むテンソル</target>
        </trans-unit>
        <trans-unit id="808c26c158b1b41512b2f49967eb9955a23d3ece" translate="yes" xml:space="preserve">
          <source>A tensor equivalent to converting all the input tensors into lists,</source>
          <target state="translated">すべての入力テンソルをリストに変換することに相当するテンソル。</target>
        </trans-unit>
        <trans-unit id="9f00a5099d29a70d5489d75e795a620e76bd2892" translate="yes" xml:space="preserve">
          <source>A tensor equivalent to converting all the input tensors into lists, do &lt;code&gt;itertools.combinations&lt;/code&gt; or &lt;code&gt;itertools.combinations_with_replacement&lt;/code&gt; on these lists, and finally convert the resulting list into tensor.</source>
          <target state="translated">すべての入力テンソルをリストに変換するのと同等のテンソル。これらのリストで &lt;code&gt;itertools.combinations&lt;/code&gt; または &lt;code&gt;itertools.combinations_with_replacement&lt;/code&gt; を実行し、最後に結果のリストをテンソルに変換します。</target>
        </trans-unit>
        <trans-unit id="ffa7cd4e81e99e52c54f7880515bfb697dd56d45" translate="yes" xml:space="preserve">
          <source>A tensor of shape equal to the broadcasted shape of &lt;code&gt;condition&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;</source>
          <target state="translated">放送された &lt;code&gt;condition&lt;/code&gt; の形状に等しい形状のテンソル、 &lt;code&gt;x&lt;/code&gt; 、 &lt;code&gt;y&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9f636fee4017e68defd8eca1418692d893e6ca2e" translate="yes" xml:space="preserve">
          <source>A tensor of specific data type can be constructed by passing a &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and/or a &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; to a constructor or tensor creation op:</source>
          <target state="translated">特定のデータ型のテンソルは、&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;および/または&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;をコンストラクターまたはテンソル作成操作に渡すことで構築できます。</target>
        </trans-unit>
        <trans-unit id="56a6db01c3a1cc54c7399f9ada8907490b637b87" translate="yes" xml:space="preserve">
          <source>A tensor or a tuple of tensors containing</source>
          <target state="translated">を含むテンソルまたはテンソルのタプル。</target>
        </trans-unit>
        <trans-unit id="7015c602ad96676ce56c48693c2eb3931eef821e" translate="yes" xml:space="preserve">
          <source>A thread-safe store implementation based on an underlying hashmap. This store can be used within the same process (for example, by other threads), but cannot be used across processes.</source>
          <target state="translated">基礎となるハッシュマップに基づいたスレッドセーフストアの実装。このストアは同じプロセス内で (例えば他のスレッドで)使用できますが、プロセス間で使用することはできません。</target>
        </trans-unit>
        <trans-unit id="fc0920364dd37ceba72cafbd19ccdfa555706749" translate="yes" xml:space="preserve">
          <source>A transformer model.</source>
          <target state="translated">トランスフォーマーモデル。</target>
        </trans-unit>
        <trans-unit id="6179bf6b8f65bc90ae5ee40cc1d9226f83588987" translate="yes" xml:space="preserve">
          <source>A transformer model. User is able to modify the attributes as needed. The architecture is based on the paper &amp;ldquo;Attention Is All You Need&amp;rdquo;. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000-6010. Users can build the BERT(&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;) model with corresponding parameters.</source>
          <target state="translated">トランスモデル。ユーザーは必要に応じて属性を変更できます。このアーキテクチャは、「注意が必要なすべて」という論文に基づいています。Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、Aidan N Gomez、Lukasz Kaiser、Illia Polosukhin 2017.必要なのは注意だけです。ニューラル情報処理システムの進歩、6000〜6010ページ。ユーザーは、対応するパラメーターを使用してBERT（&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;https://arxiv.org/abs/1810.04805&lt;/a&gt;）モデルを構築できます。</target>
        </trans-unit>
        <trans-unit id="8d0f75196825a6a65fa8d7281e970ef1150c3424" translate="yes" xml:space="preserve">
          <source>A tuple containing copies of &lt;code&gt;tensor&lt;/code&gt;, placed on &lt;code&gt;devices&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;devices&lt;/code&gt; に配置された &lt;code&gt;tensor&lt;/code&gt; コピーを含むタプル。</target>
        </trans-unit>
        <trans-unit id="8d66b15a6d20ea906de4e959af867fbbfb815b34" translate="yes" xml:space="preserve">
          <source>A tuple containing subtypes &lt;code&gt;T0&lt;/code&gt;, &lt;code&gt;T1&lt;/code&gt;, etc. (e.g. &lt;code&gt;Tuple[Tensor, Tensor]&lt;/code&gt;)</source>
          <target state="translated">サブタイプ &lt;code&gt;T0&lt;/code&gt; 、 &lt;code&gt;T1&lt;/code&gt; などを含むタプル（例： &lt;code&gt;Tuple[Tensor, Tensor]&lt;/code&gt; ）</target>
        </trans-unit>
        <trans-unit id="d1879bf0c8405911e4b464be498b79cafb324a20" translate="yes" xml:space="preserve">
          <source>A tuple of tensors containing</source>
          <target state="translated">を含むテンソルのタプル</target>
        </trans-unit>
        <trans-unit id="a2414a0a13983fc4726a965cde7c58a73e7199ce" translate="yes" xml:space="preserve">
          <source>A user &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; instance to the result value. Use the blocking API &lt;a href=&quot;#torch.distributed.rpc.RRef.to_here&quot;&gt;&lt;code&gt;torch.distributed.rpc.RRef.to_here()&lt;/code&gt;&lt;/a&gt; to retrieve the result value locally.</source>
          <target state="translated">結果値へのユーザー&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;インスタンス。ブロッキング&lt;a href=&quot;#torch.distributed.rpc.RRef.to_here&quot;&gt; &lt;code&gt;torch.distributed.rpc.RRef.to_here()&lt;/code&gt; &lt;/a&gt;を使用して、結果値をローカルで取得します。</target>
        </trans-unit>
        <trans-unit id="e92261305fa4f64f01209063cb7d69a18986cd91" translate="yes" xml:space="preserve">
          <source>A value for total_steps is explicitly provided.</source>
          <target state="translated">total_stepsの値が明示的に指定されています。</target>
        </trans-unit>
        <trans-unit id="327c954237e47bd5486826604abda3addea9acfd" translate="yes" xml:space="preserve">
          <source>A value which is either None or type &lt;code&gt;T&lt;/code&gt;</source>
          <target state="translated">Noneまたはタイプ &lt;code&gt;T&lt;/code&gt; のいずれかの値</target>
        </trans-unit>
        <trans-unit id="50a643ab21488e75a8cc3c466f11fce2f4ad673a" translate="yes" xml:space="preserve">
          <source>A wrapper around Python&amp;rsquo;s assert which is symbolically traceable.</source>
          <target state="translated">シンボリックに追跡可能なPythonのassertのラッパー。</target>
        </trans-unit>
        <trans-unit id="6c4e7377e95c980888bb30d4e414aed707349a68" translate="yes" xml:space="preserve">
          <source>A wrapper around any of the 3 key-value stores (&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt;&lt;code&gt;TCPStore&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributed.FileStore&quot;&gt;&lt;code&gt;FileStore&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;#torch.distributed.HashStore&quot;&gt;&lt;code&gt;HashStore&lt;/code&gt;&lt;/a&gt;) that adds a prefix to each key inserted to the store.</source>
          <target state="translated">ストアに挿入された各キーにプレフィックスを追加する、3つのKey-Valueストア（&lt;a href=&quot;#torch.distributed.TCPStore&quot;&gt; &lt;code&gt;TCPStore&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributed.FileStore&quot;&gt; &lt;code&gt;FileStore&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;#torch.distributed.HashStore&quot;&gt; &lt;code&gt;HashStore&lt;/code&gt; &lt;/a&gt;）のいずれかのラッパー。</target>
        </trans-unit>
        <trans-unit id="cad644a418935c3babf0ae5b058013172734574e" translate="yes" xml:space="preserve">
          <source>A wrapper class that wraps the input module, adds QuantStub and DeQuantStub and surround the call to module with call to quant and dequant modules.</source>
          <target state="translated">入力モジュールをラップし、QuantStub と DeQuantStub を追加し、モジュールへの呼び出しを quant と dequant モジュールへの呼び出しで囲むラッパークラスです。</target>
        </trans-unit>
        <trans-unit id="893fa7187a5a433ff31c6a646ba041165efd5e8a" translate="yes" xml:space="preserve">
          <source>A. Graves et al.: Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks: &lt;a href=&quot;https://www.cs.toronto.edu/~graves/icml_2006.pdf&quot;&gt;https://www.cs.toronto.edu/~graves/icml_2006.pdf&lt;/a&gt;</source>
          <target state="translated">A. Graves et al。：Connectionist Temporal Classification：Labeling Unsegmented Sequence Data with Recurrent Neural Networks：&lt;a href=&quot;https://www.cs.toronto.edu/~graves/icml_2006.pdf&quot;&gt;https&lt;/a&gt;：//www.cs.toronto.edu/~graves/icml_2006.pdf</target>
        </trans-unit>
        <trans-unit id="1eb4168992b5101108db3eeb3c96de61bbb45012" translate="yes" xml:space="preserve">
          <source>APIs in the RPC package are stable. There are multiple ongoing work items to improve performance and error handling, which will ship in future releases.</source>
          <target state="translated">RPC パッケージの API は安定しています。パフォーマンスとエラー処理を改善するための複数の進行中の作業項目があり、これらは将来のリリースで出荷される予定です。</target>
        </trans-unit>
        <trans-unit id="bccb0000d0e87e05464132ae5d1a9fb1c8982b8a" translate="yes" xml:space="preserve">
          <source>ATen operators</source>
          <target state="translated">ATeNオペレータ</target>
        </trans-unit>
        <trans-unit id="4bfc2c1b851857261545e0a7eb83c1db10ae6260" translate="yes" xml:space="preserve">
          <source>AX = B</source>
          <target state="translated">AX=B</target>
        </trans-unit>
        <trans-unit id="afc108ce2cbe35fd87218f8b08145cd05b2342e4" translate="yes" xml:space="preserve">
          <source>AX = b</source>
          <target state="translated">AX=b</target>
        </trans-unit>
        <trans-unit id="0d45206d15c0adf19b111143610d728deb04b811" translate="yes" xml:space="preserve">
          <source>A^T A / (m - 1)</source>
          <target state="translated">A^T A/(m-1)</target>
        </trans-unit>
        <trans-unit id="4c988bad76f6d7f308c6178b6dbc825504d4a7f8" translate="yes" xml:space="preserve">
          <source>Abstract base class for constraints.</source>
          <target state="translated">制約のための抽象的な基底クラス。</target>
        </trans-unit>
        <trans-unit id="086c7a89401b2c5d32553704f5cbdf2377564e0a" translate="yes" xml:space="preserve">
          <source>Abstract base class for creation of new pruning techniques.</source>
          <target state="translated">新しい剪定技術を作成するための抽象的な基底クラス。</target>
        </trans-unit>
        <trans-unit id="b96999daf7913ffe559be13e1a22b45ae0acedc9" translate="yes" xml:space="preserve">
          <source>Abstract class for invertable transformations with computable log det jacobians. They are primarily used in &lt;code&gt;torch.distributions.TransformedDistribution&lt;/code&gt;.</source>
          <target state="translated">計算可能なlogdetヤコビアンを使用した可逆変換の抽象クラス。これらは主に &lt;code&gt;torch.distributions.TransformedDistribution&lt;/code&gt; で使用されます。</target>
        </trans-unit>
        <trans-unit id="ce6150c1e37157c2b0ede38ac1f069f652c4bd27" translate="yes" xml:space="preserve">
          <source>Accepts as argument an instance of a BasePruningMethod or an iterable of them.</source>
          <target state="translated">引数としてBasePruningMethodのインスタンス、またはそれらのイテレート可能な値を受け取ります。</target>
        </trans-unit>
        <trans-unit id="f884a5a94ee360d4b70504f91c5e58e4219b6c1e" translate="yes" xml:space="preserve">
          <source>Accessing Module Parameters</source>
          <target state="translated">モジュールパラメータへのアクセス</target>
        </trans-unit>
        <trans-unit id="f2929dbc213f512c19707fd1ca48c5d74f64d113" translate="yes" xml:space="preserve">
          <source>Accumulate the elements of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; into the &lt;code&gt;self&lt;/code&gt; tensor by adding to the indices in the order given in &lt;code&gt;index&lt;/code&gt;. For example, if &lt;code&gt;dim == 0&lt;/code&gt; and &lt;code&gt;index[i] == j&lt;/code&gt;, then the &lt;code&gt;i&lt;/code&gt;th row of &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; is added to the &lt;code&gt;j&lt;/code&gt;th row of &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">要素蓄積&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;に &lt;code&gt;self&lt;/code&gt; に与えられた順序でインデックスに追加することによってテンソルを &lt;code&gt;index&lt;/code&gt; 。例えば、 &lt;code&gt;dim == 0&lt;/code&gt; と &lt;code&gt;index[i] == j&lt;/code&gt; 、次に &lt;code&gt;i&lt;/code&gt; の行目&lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt;に添加される &lt;code&gt;j&lt;/code&gt; の行目の &lt;code&gt;self&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="af92bf9a55b4e8ebc9cf19933cf41beac97277f2" translate="yes" xml:space="preserve">
          <source>Adaptive softmax is an approximate strategy for training models with large output spaces. It is most effective when the label distribution is highly imbalanced, for example in natural language modelling, where the word frequency distribution approximately follows the &lt;a href=&quot;https://en.wikipedia.org/wiki/Zipf%27s_law&quot;&gt;Zipf&amp;rsquo;s law&lt;/a&gt;.</source>
          <target state="translated">アダプティブソフトマックスは、出力スペースが大きいモデルをトレーニングするための近似戦略です。単語の頻度分布がほぼ&lt;a href=&quot;https://en.wikipedia.org/wiki/Zipf%27s_law&quot;&gt;ジップの法則&lt;/a&gt;に従う自然言語モデリングなど、ラベル分布が非常に不均衡な場合に最も効果的です。</target>
        </trans-unit>
        <trans-unit id="6753d63f427d91531462240c7159228dba9dbe41" translate="yes" xml:space="preserve">
          <source>Adaptive softmax partitions the labels into several clusters, according to their frequency. These clusters may contain different number of targets each. Additionally, clusters containing less frequent labels assign lower dimensional embeddings to those labels, which speeds up the computation. For each minibatch, only clusters for which at least one target is present are evaluated.</source>
          <target state="translated">適応的ソフトマックスは、ラベルを頻度に応じていくつかのクラスタに分割します。これらのクラスターにはそれぞれ異なる数のターゲットが含まれています。さらに、頻度の低いラベルを含むクラスタは、それらのラベルに低次元の埋め込みを割り当て、計算を高速化します。各ミニバッチについて、少なくとも1つのターゲットが存在するクラスタのみが評価されます。</target>
        </trans-unit>
        <trans-unit id="b7d62c155e1ec348bbbea519cad55c85951b3b6e" translate="yes" xml:space="preserve">
          <source>AdaptiveAvgPool1d</source>
          <target state="translated">AdaptiveAvgPool1d</target>
        </trans-unit>
        <trans-unit id="0068238690eed5246c61ee781eb3611fe6751168" translate="yes" xml:space="preserve">
          <source>AdaptiveAvgPool2d</source>
          <target state="translated">AdaptiveAvgPool2d</target>
        </trans-unit>
        <trans-unit id="65992cfd09d95132c3908bd45a21c959a32be4e1" translate="yes" xml:space="preserve">
          <source>AdaptiveAvgPool3d</source>
          <target state="translated">AdaptiveAvgPool3d</target>
        </trans-unit>
        <trans-unit id="a60f272cfc14a259a9716f4818eb79c22d95c973" translate="yes" xml:space="preserve">
          <source>AdaptiveLogSoftmaxWithLoss</source>
          <target state="translated">AdaptiveLogSoftmaxWithLoss</target>
        </trans-unit>
        <trans-unit id="84f10363ff1424545148abb336751c9a84b6497d" translate="yes" xml:space="preserve">
          <source>AdaptiveMaxPool1d</source>
          <target state="translated">AdaptiveMaxPool1d</target>
        </trans-unit>
        <trans-unit id="b001386de556a7b95313a763136a21be6a3d2d16" translate="yes" xml:space="preserve">
          <source>AdaptiveMaxPool2d</source>
          <target state="translated">AdaptiveMaxPool2d</target>
        </trans-unit>
        <trans-unit id="9315f841b98a9cfd3c84766eadb0e1b9b7bcbe32" translate="yes" xml:space="preserve">
          <source>AdaptiveMaxPool3d</source>
          <target state="translated">AdaptiveMaxPool3d</target>
        </trans-unit>
        <trans-unit id="86d178452c7b5ca14e4bbe65a1027bda69043129" translate="yes" xml:space="preserve">
          <source>Add a param group to the &lt;a href=&quot;#torch.optim.Optimizer&quot;&gt;&lt;code&gt;Optimizer&lt;/code&gt;&lt;/a&gt; s &lt;code&gt;param_groups&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.optim.Optimizer&quot;&gt; &lt;code&gt;Optimizer&lt;/code&gt; &lt;/a&gt;の &lt;code&gt;param_groups&lt;/code&gt; にパラメーターグループを追加します。</target>
        </trans-unit>
        <trans-unit id="53b75d7b44ea18bab3550e79b5f19b4d01eb4d3d" translate="yes" xml:space="preserve">
          <source>Add a scalar or tensor to &lt;code&gt;self&lt;/code&gt; tensor. If both &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;other&lt;/code&gt; are specified, each element of &lt;code&gt;other&lt;/code&gt; is scaled by &lt;code&gt;alpha&lt;/code&gt; before being used.</source>
          <target state="translated">スカラーまたはテンソルを &lt;code&gt;self&lt;/code&gt; テンソルに追加します。両方の場合 &lt;code&gt;alpha&lt;/code&gt; および &lt;code&gt;other&lt;/code&gt; 指定され、各要素 &lt;code&gt;other&lt;/code&gt; によってスケーリングされる &lt;code&gt;alpha&lt;/code&gt; 使用される前に。</target>
        </trans-unit>
        <trans-unit id="363f75ca10e654de02076c9e812636b00b9240b1" translate="yes" xml:space="preserve">
          <source>Add a set of hyperparameters to be compared in TensorBoard.</source>
          <target state="translated">TensorBoardで比較するハイパーパラメータのセットを追加します。</target>
        </trans-unit>
        <trans-unit id="2981d9b125bbce3a8357f497272caa27d116b65e" translate="yes" xml:space="preserve">
          <source>Add audio data to summary.</source>
          <target state="translated">サマリーに音声データを追加します。</target>
        </trans-unit>
        <trans-unit id="378dceab0437ac530e9f4b067ecb1268bcc2db27" translate="yes" xml:space="preserve">
          <source>Add batched image data to summary.</source>
          <target state="translated">まとめにバッチ画像データを追加します。</target>
        </trans-unit>
        <trans-unit id="b6c70cf24a9dc9ee0a583b95ed8a5b22e79a979d" translate="yes" xml:space="preserve">
          <source>Add embedding projector data to summary.</source>
          <target state="translated">埋め込みプロジェクターのデータをまとめに追加します。</target>
        </trans-unit>
        <trans-unit id="745fa53d610381d82d054b114f7c40ae6aaa4f61" translate="yes" xml:space="preserve">
          <source>Add graph data to summary.</source>
          <target state="translated">サマリーにグラフデータを追加します。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
