<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="76b27001feb75250d904bb68f5aaa46711a6a0f1" translate="yes" xml:space="preserve">
          <source>Expands the dimension &lt;a href=&quot;tensors#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt; of the &lt;code&gt;self&lt;/code&gt; tensor over multiple dimensions of sizes given by &lt;code&gt;sizes&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの次元&lt;a href=&quot;tensors#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; &lt;/a&gt;を、sizesで指定された &lt;code&gt;sizes&lt;/code&gt; 複数の次元に拡張します。</target>
        </trans-unit>
        <trans-unit id="6e40e001bf1e0b420d657a639d6d67387b6d4923" translate="yes" xml:space="preserve">
          <source>Expected inputs are spatial (4 dimensional). Use &lt;code&gt;upsample_trilinear&lt;/code&gt; fo volumetric (5 dimensional) inputs.</source>
          <target state="translated">予想される入力は空間（4次元）です。体積（5次元）入力の &lt;code&gt;upsample_trilinear&lt;/code&gt; を使用します。</target>
        </trans-unit>
        <trans-unit id="551ccd41342efa881333f0f1e558164218f9345a" translate="yes" xml:space="preserve">
          <source>Expected result:</source>
          <target state="translated">期待される結果。</target>
        </trans-unit>
        <trans-unit id="8439d6715059ee70b74368357e1335f786d20b96" translate="yes" xml:space="preserve">
          <source>Expects &lt;code&gt;input&lt;/code&gt; to be &amp;lt;= 2-D tensor and transposes dimensions 0 and 1.</source>
          <target state="translated">期待 &lt;code&gt;input&lt;/code&gt; &amp;lt;= 2-Dテンソルと転置大きさ0と1とします。</target>
        </trans-unit>
        <trans-unit id="8133389ca86b79f9ac63f2057897dfbe1cda5cc8" translate="yes" xml:space="preserve">
          <source>Explicit alignment by names</source>
          <target state="translated">名前による明示的な整列</target>
        </trans-unit>
        <trans-unit id="34533450ac1f4cb8a131c86d48accad539bed843" translate="yes" xml:space="preserve">
          <source>Exponential</source>
          <target state="translated">Exponential</target>
        </trans-unit>
        <trans-unit id="7d2243304a874bff81f4d326427b9649a3f42d91" translate="yes" xml:space="preserve">
          <source>ExponentialFamily</source>
          <target state="translated">ExponentialFamily</target>
        </trans-unit>
        <trans-unit id="e8c6f63a2d8909014d6aec0ec531f11a54dcd1bb" translate="yes" xml:space="preserve">
          <source>ExponentialFamily is the abstract base class for probability distributions belonging to an exponential family, whose probability mass/density function has the form is defined below</source>
          <target state="translated">ExponentialFamilyは,指数族に属する確率分布の抽象基底クラスであり,その確率の質量/密度関数は以下のように定義されています.</target>
        </trans-unit>
        <trans-unit id="58b807aacff8abe3f97a111c7a1e5f71d192fe91" translate="yes" xml:space="preserve">
          <source>Export a model into ONNX format. This exporter runs your model once in order to get a trace of its execution to be exported; at the moment, it supports a limited set of dynamic models (e.g., RNNs.)</source>
          <target state="translated">モデルをONNX形式にエクスポートします。このエクスポータは、エクスポートされる実行トレースを取得するためにモデルを一度実行します。</target>
        </trans-unit>
        <trans-unit id="69c85a023a54b1f8defe44bdc84c4b1308b399c8" translate="yes" xml:space="preserve">
          <source>Exporting models with unsupported ONNX operators can be achieved using the &lt;code&gt;operator_export_type&lt;/code&gt; flag in export API. This flag is useful when users try to export ATen and non-ATen operators that are not registered and supported in ONNX.</source>
          <target state="translated">サポートされていないONNX演算子を使用したモデルのエクスポートは、エクスポートAPIの &lt;code&gt;operator_export_type&lt;/code&gt; フラグを使用して実行できます。このフラグは、ユーザーがONNXに登録およびサポートされていないATenおよび非ATenオペレーターをエクスポートしようとする場合に役立ちます。</target>
        </trans-unit>
        <trans-unit id="f1d6a87a24293323dbd3502f982e0c3f518eed8d" translate="yes" xml:space="preserve">
          <source>Exports an EventList as a Chrome tracing tools file.</source>
          <target state="translated">EventListをChromeトレースツールのファイルとしてエクスポートします。</target>
        </trans-unit>
        <trans-unit id="ae5fccd8dcd8fc317f8edfc8259af86cd2967a29" translate="yes" xml:space="preserve">
          <source>Expressions</source>
          <target state="translated">Expressions</target>
        </trans-unit>
        <trans-unit id="44bdb40abdeed26ffb35b097c6be620648eb56bc" translate="yes" xml:space="preserve">
          <source>Extending PyTorch</source>
          <target state="translated">PyTorch の拡張</target>
        </trans-unit>
        <trans-unit id="9ff04a6a0866fa949548184e90e852102f7c5167" translate="yes" xml:space="preserve">
          <source>Extension of the Distribution class, which applies a sequence of Transforms to a base distribution. Let f be the composition of transforms applied:</source>
          <target state="translated">基底分布に一連の変換を適用する分布クラスの拡張.fを適用された変形の合成とします.</target>
        </trans-unit>
        <trans-unit id="a505bba828df658cd19ca21d48f6b057b88e1432" translate="yes" xml:space="preserve">
          <source>Extra care needs to be taken when backward through &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; outputs. Such operation is really only stable when &lt;code&gt;input&lt;/code&gt; is full rank with all distinct singular values. Otherwise, &lt;code&gt;NaN&lt;/code&gt; can appear as the gradients are not properly defined. Also, notice that double backward will usually do an additional backward through &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; even if the original backward is only on &lt;code&gt;S&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;U&lt;/code&gt; および &lt;code&gt;V&lt;/code&gt; 出力を逆方向に通過する場合は、特に注意が必要です。このような操作は、 &lt;code&gt;input&lt;/code&gt; がすべての異なる特異値を持つフルランクの場合にのみ実際に安定します。そうしないと、グラデーションが適切に定義されていないため、 &lt;code&gt;NaN&lt;/code&gt; が表示される可能性があります。また、元の後方が &lt;code&gt;S&lt;/code&gt; のみにある場合でも、通常、二重後方は &lt;code&gt;U&lt;/code&gt; と &lt;code&gt;V&lt;/code&gt; を介して追加の後方を実行することに注意してください。</target>
        </trans-unit>
        <trans-unit id="7869f96c8dcb40e05a18db44c02551a0604c8dd8" translate="yes" xml:space="preserve">
          <source>Extra care needs to be taken when backward through outputs. Such operation is really only stable when all eigenvalues are distinct. Otherwise, &lt;code&gt;NaN&lt;/code&gt; can appear as the gradients are not properly defined.</source>
          <target state="translated">出力を逆方向に通過する場合は、特別な注意が必要です。このような操作は、すべての固有値が異なる場合にのみ実際に安定します。そうしないと、グラデーションが適切に定義されていないため、 &lt;code&gt;NaN&lt;/code&gt; が表示される可能性があります。</target>
        </trans-unit>
        <trans-unit id="35e4d02caad3850761be7f0a939f52dc8e6d05c6" translate="yes" xml:space="preserve">
          <source>Extracts sliding local blocks from a batched input tensor.</source>
          <target state="translated">バッチ化された入力テンソルからスライディングローカルブロックを抽出します。</target>
        </trans-unit>
        <trans-unit id="545d81b806ede14bef050d6bbe02b72b7b5279d1" translate="yes" xml:space="preserve">
          <source>Extracts sliding local blocks from an batched input tensor.</source>
          <target state="translated">バッチ化された入力テンソルからスライディングローカルブロックを抽出します。</target>
        </trans-unit>
        <trans-unit id="e69f20e9f683920d3fb4329abd951e878b1f9372" translate="yes" xml:space="preserve">
          <source>F</source>
          <target state="translated">F</target>
        </trans-unit>
        <trans-unit id="bf9ce34c9cacb2121a3faa4bcb13d39153683bf1" translate="yes" xml:space="preserve">
          <source>F(\theta)</source>
          <target state="translated">F(\theta)</target>
        </trans-unit>
        <trans-unit id="d1636ed5d55d52fc51dab6a56c1fdb216178f4c5" translate="yes" xml:space="preserve">
          <source>FAST mode algorithm</source>
          <target state="translated">ファストモードアルゴリズム</target>
        </trans-unit>
        <trans-unit id="5d8a2052196e0929b1ddeff4f9fa793509ac8f6c" translate="yes" xml:space="preserve">
          <source>FCN ResNet101</source>
          <target state="translated">FCN ResNet101</target>
        </trans-unit>
        <trans-unit id="d876bcc45100c189667e02c674ab45db60de2d8b" translate="yes" xml:space="preserve">
          <source>FCN ResNet50</source>
          <target state="translated">FCN ResNet50</target>
        </trans-unit>
        <trans-unit id="70deee53be1d417368b869145a93da9f61814dda" translate="yes" xml:space="preserve">
          <source>FCN ResNet50, ResNet101</source>
          <target state="translated">FCN ResNet50,ResNet101</target>
        </trans-unit>
        <trans-unit id="58296524e883e134fa6cc4840027902c76d7e637" translate="yes" xml:space="preserve">
          <source>Factory functions now take a new &lt;code&gt;names&lt;/code&gt; argument that associates a name with each dimension.</source>
          <target state="translated">ファクトリ関数は、名前を各ディメンションに関連付ける新しい &lt;code&gt;names&lt;/code&gt; 引数を取るようになりました。</target>
        </trans-unit>
        <trans-unit id="97cdbdc7feff827efb082a6b6dd2727237cd49fd" translate="yes" xml:space="preserve">
          <source>False</source>
          <target state="translated">False</target>
        </trans-unit>
        <trans-unit id="6bca42e6cb3531d60196488b0aafe02849dfad8a" translate="yes" xml:space="preserve">
          <source>False if the compiler is (likely) ABI-incompatible with PyTorch, else True.</source>
          <target state="translated">コンパイラがPyTorchとABI互換性がない(可能性が高い)場合はFalse、そうでない場合はTrueです。</target>
        </trans-unit>
        <trans-unit id="f66134050db6d6f1871f0a392769d7d300bffc78" translate="yes" xml:space="preserve">
          <source>Faster R-CNN</source>
          <target state="translated">より速いR-CNN</target>
        </trans-unit>
        <trans-unit id="19fa372bf4511d5897a6678506a36d53384e83c1" translate="yes" xml:space="preserve">
          <source>Faster R-CNN ResNet-50 FPN</source>
          <target state="translated">より高速なR-CNN ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="ceaa939a1707b8201f9f233e5c8d2c8a11872247" translate="yes" xml:space="preserve">
          <source>Faster R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.</source>
          <target state="translated">Faster R-CNNは、一定サイズの入力画像を一定のバッチサイズでONNXに書き出すことができます。</target>
        </trans-unit>
        <trans-unit id="b9a92e1a2a80529a37624caec86105f3856f6680" translate="yes" xml:space="preserve">
          <source>FeatureDropout (training mode not supported)</source>
          <target state="translated">フィーチャードロップアウト(トレーニングモードはサポートされていません</target>
        </trans-unit>
        <trans-unit id="023ddfe2580672ca0eeb5f867eac27e114575b07" translate="yes" xml:space="preserve">
          <source>Features described in this documentation are classified by release status:</source>
          <target state="translated">このドキュメントに記載されている機能は、リリース状況によって分類されています。</target>
        </trans-unit>
        <trans-unit id="4ed223cb662e6eadab1b5774d593969ec64456ed" translate="yes" xml:space="preserve">
          <source>Features for large-scale deployments</source>
          <target state="translated">大規模展開に対応した機能</target>
        </trans-unit>
        <trans-unit id="0e0100beb8ca4fc8e23a8eb611272bb7c779f1f4" translate="yes" xml:space="preserve">
          <source>File descriptor - &lt;code&gt;file_descriptor&lt;/code&gt;</source>
          <target state="translated">ファイル記述子 &lt;code&gt;file_descriptor&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f8affbccfbf014c7f4e4336ada91b93349f5adf6" translate="yes" xml:space="preserve">
          <source>File system - &lt;code&gt;file_system&lt;/code&gt;</source>
          <target state="translated">ファイルシステム &lt;code&gt;file_system&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="29fd83b7db12e4d9231f579c15fdaeb5d71086e4" translate="yes" xml:space="preserve">
          <source>Fill the main diagonal of a tensor that has at least 2-dimensions. When dims&amp;gt;2, all dimensions of input must be of equal length. This function modifies the input tensor in-place, and returns the input tensor.</source>
          <target state="translated">少なくとも2次元のテンソルの主対角線を塗りつぶします。dims&amp;gt; 2の場合、入力のすべての次元は同じ長さでなければなりません。この関数は、入力テンソルをインプレースで変更し、入力テンソルを返します。</target>
        </trans-unit>
        <trans-unit id="46412e89386beda08d3ce994cbdd41f7b9cb6e05" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with elements drawn from the exponential distribution:</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルを指数分布から抽出された要素で埋めます。</target>
        </trans-unit>
        <trans-unit id="1aea402a861ce53378696f47d930c7de8244acde" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with elements drawn from the geometric distribution:</source>
          <target state="translated">幾何分布から引き出された要素で &lt;code&gt;self&lt;/code&gt; テンソルを埋めます。</target>
        </trans-unit>
        <trans-unit id="1abd5eabced3b954f0b9c8f459ed264742cdc1be" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with elements samples from the normal distribution parameterized by &lt;a href=&quot;generated/torch.mean#torch.mean&quot;&gt;&lt;code&gt;mean&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;generated/torch.std#torch.std&quot;&gt;&lt;code&gt;std&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">塗りつぶしの &lt;code&gt;self&lt;/code&gt; によってパラメータ正規分布からの要素をサンプルとテンソル&lt;a href=&quot;generated/torch.mean#torch.mean&quot;&gt; &lt;code&gt;mean&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;generated/torch.std#torch.std&quot;&gt; &lt;code&gt;std&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="be7637b77a168dc9781dec5a6963103f27f1e666" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with numbers sampled from the continuous uniform distribution:</source>
          <target state="translated">連続一様分布からサンプリングされた数値で &lt;code&gt;self&lt;/code&gt; テンソルを埋めます。</target>
        </trans-unit>
        <trans-unit id="963887f4ec9debd27ff138179ec127b4ceb1a324" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with numbers sampled from the discrete uniform distribution over &lt;code&gt;[from, to - 1]&lt;/code&gt;. If not specified, the values are usually only bounded by &lt;code&gt;self&lt;/code&gt; tensor&amp;rsquo;s data type. However, for floating point types, if unspecified, range will be &lt;code&gt;[0, 2^mantissa]&lt;/code&gt; to ensure that every value is representable. For example, &lt;code&gt;torch.tensor(1, dtype=torch.double).random_()&lt;/code&gt; will be uniform in &lt;code&gt;[0, 2^53]&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;[from, to - 1]&lt;/code&gt; の離散一様分布からサンプリングされた数値で、 &lt;code&gt;self&lt;/code&gt; テンソルを埋めます。指定しない場合、値は通常、 &lt;code&gt;self&lt;/code&gt; テンソルのデータ型によってのみ制限されます。ただし、浮動小数点型の場合、指定されていない場合、すべての値が表現可能であることを保証するために、範囲は &lt;code&gt;[0, 2^mantissa]&lt;/code&gt; なります。たとえば、 &lt;code&gt;torch.tensor(1, dtype=torch.double).random_()&lt;/code&gt; は &lt;code&gt;[0, 2^53]&lt;/code&gt; で均一になります。</target>
        </trans-unit>
        <trans-unit id="b7f10ef5f693feaeaa010e2aa027c2e16d3faf27" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with numbers samples from the log-normal distribution parameterized by the given mean</source>
          <target state="translated">与えられた平均によってパラメータ化された対数正規分布からの数値サンプルで &lt;code&gt;self&lt;/code&gt; テンソルを埋めます</target>
        </trans-unit>
        <trans-unit id="a537a70caec95c45887848e05dbf76327e57f2bf" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with the specified value.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルを指定された値で埋めます。</target>
        </trans-unit>
        <trans-unit id="84e59f1fa6c91fd2336c166329083335c07742c5" translate="yes" xml:space="preserve">
          <source>Fills &lt;code&gt;self&lt;/code&gt; tensor with zeros.</source>
          <target state="translated">塗りつぶしの &lt;code&gt;self&lt;/code&gt; ゼロでテンソル。</target>
        </trans-unit>
        <trans-unit id="c357bdf1d8cc36baaa85a26ceaf45fb123516806" translate="yes" xml:space="preserve">
          <source>Fills each location of &lt;code&gt;self&lt;/code&gt; with an independent sample from</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; 各場所をからの独立したサンプルで埋めます</target>
        </trans-unit>
        <trans-unit id="75c253cce2f7953023782f50f2d324ceb99f06ec" translate="yes" xml:space="preserve">
          <source>Fills elements of &lt;code&gt;self&lt;/code&gt; tensor with &lt;code&gt;value&lt;/code&gt; where &lt;code&gt;mask&lt;/code&gt; is True. The shape of &lt;code&gt;mask&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with the shape of the underlying tensor.</source>
          <target state="translated">&lt;code&gt;mask&lt;/code&gt; がTrueの &lt;code&gt;value&lt;/code&gt; 、 &lt;code&gt;self&lt;/code&gt; テンソルの要素を値で埋めます。形状 &lt;code&gt;mask&lt;/code&gt; でなければなりません&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;根本的なテンソルの形状を有します。</target>
        </trans-unit>
        <trans-unit id="7f2c547e676c650b0294e152d6742725981b5e7b" translate="yes" xml:space="preserve">
          <source>Fills the 2-dimensional input &lt;code&gt;Tensor&lt;/code&gt; with the identity matrix. Preserves the identity of the inputs in &lt;code&gt;Linear&lt;/code&gt; layers, where as many inputs are preserved as possible.</source>
          <target state="translated">2次元入力 &lt;code&gt;Tensor&lt;/code&gt; を単位行列で埋めます。可能な限り多くの入力が保持される &lt;code&gt;Linear&lt;/code&gt; レイヤーの入力のIDを保持します。</target>
        </trans-unit>
        <trans-unit id="5e10a9506b95f83d62c2104cb07cd55facde3766" translate="yes" xml:space="preserve">
          <source>Fills the 2D input &lt;code&gt;Tensor&lt;/code&gt; as a sparse matrix, where the non-zero elements will be drawn from the normal distribution</source>
          <target state="translated">2D入力 &lt;code&gt;Tensor&lt;/code&gt; をスパース行列として塗りつぶします。ここで、ゼロ以外の要素は正規分布から描画されます。</target>
        </trans-unit>
        <trans-unit id="5e66c6e2e841f8a8523fead84aa32e52990c1b4b" translate="yes" xml:space="preserve">
          <source>Fills the elements of the &lt;code&gt;self&lt;/code&gt; tensor with value &lt;code&gt;val&lt;/code&gt; by selecting the indices in the order given in &lt;code&gt;index&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;index&lt;/code&gt; で指定された順序でインデックスを選択することにより、 &lt;code&gt;self&lt;/code&gt; テンソルの要素を値 &lt;code&gt;val&lt;/code&gt; で埋めます。</target>
        </trans-unit>
        <trans-unit id="3a21a74e5af8bd75efccfeb2dc749fe2483f779d" translate="yes" xml:space="preserve">
          <source>Fills the input &lt;code&gt;Tensor&lt;/code&gt; with a (semi) orthogonal matrix, as described in &lt;code&gt;Exact solutions to the nonlinear dynamics of learning in deep linear neural networks&lt;/code&gt; - Saxe, A. et al. (2013). The input tensor must have at least 2 dimensions, and for tensors with more than 2 dimensions the trailing dimensions are flattened.</source>
          <target state="translated">&lt;code&gt;Exact solutions to the nonlinear dynamics of learning in deep linear neural networks&lt;/code&gt; 説明されているように、入力 &lt;code&gt;Tensor&lt;/code&gt; を（半）直交行列で埋めます-Saxe、A。etal。（2013）。入力テンソルは少なくとも2次元である必要があり、2次元を超えるテンソルの場合、後続の次元は平坦化されます。</target>
        </trans-unit>
        <trans-unit id="06242c8039ea176e183491ddfbaaf7c2d66c68e8" translate="yes" xml:space="preserve">
          <source>Fills the input &lt;code&gt;Tensor&lt;/code&gt; with values according to the method described in &lt;code&gt;Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification&lt;/code&gt; - He, K. et al. (2015), using a normal distribution. The resulting tensor will have values sampled from</source>
          <target state="translated">&lt;code&gt;Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification&lt;/code&gt; 、K。etal。で説明されている方法に従って入力 &lt;code&gt;Tensor&lt;/code&gt; に値を入力します。（2015）、正規分布を使用。結果のテンソルは、からサンプリングされた値を持ちます</target>
        </trans-unit>
        <trans-unit id="342727420e0d4e4b77efe66611c6eb6db5be0acf" translate="yes" xml:space="preserve">
          <source>Fills the input &lt;code&gt;Tensor&lt;/code&gt; with values according to the method described in &lt;code&gt;Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification&lt;/code&gt; - He, K. et al. (2015), using a uniform distribution. The resulting tensor will have values sampled from</source>
          <target state="translated">&lt;code&gt;Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification&lt;/code&gt; 、K。etal。で説明されている方法に従って入力 &lt;code&gt;Tensor&lt;/code&gt; に値を入力します。（2015）、一様分布を使用。結果のテンソルは、からサンプリングされた値を持ちます</target>
        </trans-unit>
        <trans-unit id="71e3100123b6866d1997e6df9daeefd940ad80de" translate="yes" xml:space="preserve">
          <source>Fills the input &lt;code&gt;Tensor&lt;/code&gt; with values according to the method described in &lt;code&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/code&gt; - Glorot, X. &amp;amp; Bengio, Y. (2010), using a normal distribution. The resulting tensor will have values sampled from</source>
          <target state="translated">正規分布を使用して、 &lt;code&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/code&gt; さを理解する-Glorot、X。＆Bengio、Y。（2010）で説明されている方法に従って、入力 &lt;code&gt;Tensor&lt;/code&gt; に値を入力します。結果のテンソルは、からサンプリングされた値を持ちます</target>
        </trans-unit>
        <trans-unit id="2313477ebbbc49bb7f4bf7d5c39c5ea0206267ac" translate="yes" xml:space="preserve">
          <source>Fills the input &lt;code&gt;Tensor&lt;/code&gt; with values according to the method described in &lt;code&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/code&gt; - Glorot, X. &amp;amp; Bengio, Y. (2010), using a uniform distribution. The resulting tensor will have values sampled from</source>
          <target state="translated">一様分布を使用して、 &lt;code&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/code&gt; さを理解する-Glorot、X。＆Bengio、Y。（2010）で説明されている方法に従って、入力 &lt;code&gt;Tensor&lt;/code&gt; に値を入力します。結果のテンソルは、からサンプリングされた値を持ちます</target>
        </trans-unit>
        <trans-unit id="afacae29047abc8bbea1f5a18cb9f7afddce8004" translate="yes" xml:space="preserve">
          <source>Fills the input Tensor with the scalar value &lt;code&gt;0&lt;/code&gt;.</source>
          <target state="translated">入力テンソルをスカラー値 &lt;code&gt;0&lt;/code&gt; で埋めます。</target>
        </trans-unit>
        <trans-unit id="0749fb4668d1e4b76f3a1ba9aa423e792bc38d58" translate="yes" xml:space="preserve">
          <source>Fills the input Tensor with the scalar value &lt;code&gt;1&lt;/code&gt;.</source>
          <target state="translated">入力テンソルをスカラー値 &lt;code&gt;1&lt;/code&gt; で埋めます。</target>
        </trans-unit>
        <trans-unit id="498455641766cf82c112342c938821f2f05dedf1" translate="yes" xml:space="preserve">
          <source>Fills the input Tensor with the value</source>
          <target state="translated">入力テンソルを値で埋めます。</target>
        </trans-unit>
        <trans-unit id="92513a6a0cb417782fe4aae045c4a1b66c923b2f" translate="yes" xml:space="preserve">
          <source>Fills the input Tensor with values drawn from the normal distribution</source>
          <target state="translated">正規分布から引き出された値で入力テンソルを埋めます.</target>
        </trans-unit>
        <trans-unit id="6b3d75035cf3e14fc34e56b36e9d5379c6dd95d1" translate="yes" xml:space="preserve">
          <source>Fills the input Tensor with values drawn from the uniform distribution</source>
          <target state="translated">入力テンソルを,一様分布から引き出された値で埋めます.</target>
        </trans-unit>
        <trans-unit id="53430dbd9b3ec1b5ed7bd9a57a201a7f2d1a60f2" translate="yes" xml:space="preserve">
          <source>Fills the tensor with numbers drawn from the Cauchy distribution:</source>
          <target state="translated">テンソルをコーシー分布から引き出された数値で埋めます。</target>
        </trans-unit>
        <trans-unit id="c6632aebf9bc7adafe6c2b8a271e6b35dc1107ed" translate="yes" xml:space="preserve">
          <source>Fills the {3, 4, 5}-dimensional input &lt;code&gt;Tensor&lt;/code&gt; with the Dirac delta function. Preserves the identity of the inputs in &lt;code&gt;Convolutional&lt;/code&gt; layers, where as many input channels are preserved as possible. In case of groups&amp;gt;1, each group of channels preserves identity</source>
          <target state="translated">{3、4、5}次元の入力 &lt;code&gt;Tensor&lt;/code&gt; をディラックのデルタ関数で埋めます。可能な限り多くの入力チャネルが保持される &lt;code&gt;Convolutional&lt;/code&gt; 層の入力のアイデンティティを保持します。グループ&amp;gt; 1の場合、チャネルの各グループはIDを保持します</target>
        </trans-unit>
        <trans-unit id="695c574fe765006dd0a54d1a5cdae48d767984bd" translate="yes" xml:space="preserve">
          <source>Find the indices from the &lt;em&gt;innermost&lt;/em&gt; dimension of &lt;code&gt;sorted_sequence&lt;/code&gt; such that, if the corresponding values in &lt;code&gt;values&lt;/code&gt; were inserted before the indices, the order of the corresponding &lt;em&gt;innermost&lt;/em&gt; dimension within &lt;code&gt;sorted_sequence&lt;/code&gt; would be preserved.</source>
          <target state="translated">インデックス検索&lt;em&gt;最も内側&lt;/em&gt;の寸法 &lt;code&gt;sorted_sequence&lt;/code&gt; に対応する値場合は、そのような &lt;code&gt;values&lt;/code&gt; 指数の前に挿入された、対応する順&lt;em&gt;最も内側の&lt;/em&gt;内寸法 &lt;code&gt;sorted_sequence&lt;/code&gt; が保存されるであろうに。</target>
        </trans-unit>
        <trans-unit id="bc20e9bbc443d3b0fd0b14b6ff920327eb09f1d2" translate="yes" xml:space="preserve">
          <source>Find the indices from the &lt;em&gt;innermost&lt;/em&gt; dimension of &lt;code&gt;sorted_sequence&lt;/code&gt; such that, if the corresponding values in &lt;code&gt;values&lt;/code&gt; were inserted before the indices, the order of the corresponding &lt;em&gt;innermost&lt;/em&gt; dimension within &lt;code&gt;sorted_sequence&lt;/code&gt; would be preserved. Return a new tensor with the same size as &lt;code&gt;values&lt;/code&gt;. If &lt;code&gt;right&lt;/code&gt; is False (default), then the left boundary of &lt;code&gt;sorted_sequence&lt;/code&gt; is closed. More formally, the returned index satisfies the following rules:</source>
          <target state="translated">インデックス検索&lt;em&gt;最も内側&lt;/em&gt;の寸法 &lt;code&gt;sorted_sequence&lt;/code&gt; に対応する値場合は、そのような &lt;code&gt;values&lt;/code&gt; 指数の前に挿入された、対応する順&lt;em&gt;最も内側の&lt;/em&gt;内寸法 &lt;code&gt;sorted_sequence&lt;/code&gt; が保存されるであろうに。 &lt;code&gt;values&lt;/code&gt; と同じサイズの新しいテンソルを返します。 &lt;code&gt;right&lt;/code&gt; がFalse（デフォルト）の場合、 &lt;code&gt;sorted_sequence&lt;/code&gt; の左側の境界は閉じられます。より正式には、返されるインデックスは次のルールを満たします。</target>
        </trans-unit>
        <trans-unit id="03215b19f0bffce926c83716ff9399ab447bdf55" translate="yes" xml:space="preserve">
          <source>Find the k largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive defined generalized eigenvalue problem using matrix-free LOBPCG methods.</source>
          <target state="translated">マトリックスフリーのLOBPCG法を用いて、対称性のある正の定義された一般化固有値問題のk個の最大(または最小)固有値と対応する固有ベクトルを求めます。</target>
        </trans-unit>
        <trans-unit id="8cb7b9aabdd31afa308112ad36cdb297f62b4914" translate="yes" xml:space="preserve">
          <source>Fine grained control is possible with &lt;code&gt;qconfig&lt;/code&gt; and &lt;code&gt;mapping&lt;/code&gt; that act similarly to &lt;code&gt;quantize()&lt;/code&gt;. If &lt;code&gt;qconfig&lt;/code&gt; is provided, the &lt;code&gt;dtype&lt;/code&gt; argument is ignored.</source>
          <target state="translated">&lt;code&gt;qconfig&lt;/code&gt; &lt;code&gt;quantize()&lt;/code&gt; と同様に機能するqconfigと &lt;code&gt;mapping&lt;/code&gt; を使用すると、きめ細かい制御が可能です。場合 &lt;code&gt;qconfig&lt;/code&gt; が提供され、 &lt;code&gt;dtype&lt;/code&gt; 引数は無視されます。</target>
        </trans-unit>
        <trans-unit id="d6ca52cc281a8bbbaa3d9b53b49079e29eb878fa" translate="yes" xml:space="preserve">
          <source>First convert your model from GPU to CPU and then save it, like so:</source>
          <target state="translated">まずモデルをGPUからCPUに変換してから、こんな感じで保存します。</target>
        </trans-unit>
        <trans-unit id="ce44c84deade8daed8f8cfb3f091e34fe3a19e21" translate="yes" xml:space="preserve">
          <source>First it will prepare the model for calibration, then it calls &lt;code&gt;run_fn&lt;/code&gt; which will run the calibration step, after that we will convert the model to a quantized model.</source>
          <target state="translated">最初にモデルをキャリブレーション用に準備し、次に &lt;code&gt;run_fn&lt;/code&gt; を呼び出してキャリブレーションステップを実行します。その後、モデルを量子化モデルに変換します。</target>
        </trans-unit>
        <trans-unit id="56b7d451e08bf1ccd9aa8267b497203df559b032" translate="yes" xml:space="preserve">
          <source>First, if you repeatedly perform an operation that can produce duplicate entries (e.g., &lt;a href=&quot;#torch.sparse.FloatTensor.add&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor.add()&lt;/code&gt;&lt;/a&gt;), you should occasionally coalesce your sparse tensors to prevent them from growing too large.</source>
          <target state="translated">まず、重複するエントリを生成する可能性のある操作（&lt;a href=&quot;#torch.sparse.FloatTensor.add&quot;&gt; &lt;code&gt;torch.sparse.FloatTensor.add()&lt;/code&gt; など&lt;/a&gt;）を繰り返し実行する場合は、スパーステンソルが大きくなりすぎないように合体する必要があります。</target>
        </trans-unit>
        <trans-unit id="e3329b7e66ffa5f9cc2ce06f055a9b6ced15b8ee" translate="yes" xml:space="preserve">
          <source>FisherSnedecor</source>
          <target state="translated">FisherSnedecor</target>
        </trans-unit>
        <trans-unit id="0af14ddb20aabbe1bd98f28f2c2f744284ccedb3" translate="yes" xml:space="preserve">
          <source>Flatten</source>
          <target state="translated">Flatten</target>
        </trans-unit>
        <trans-unit id="557473442912b0bbbc1f4c6573c0fe9837b23ef2" translate="yes" xml:space="preserve">
          <source>Flattens &lt;code&gt;dims&lt;/code&gt; into a single dimension with name &lt;code&gt;out_dim&lt;/code&gt;.</source>
          <target state="translated">平らに &lt;code&gt;dims&lt;/code&gt; 名前を持つ単一の次元に &lt;code&gt;out_dim&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="80a931c216b5d2a192745812d7ca953d11d59b70" translate="yes" xml:space="preserve">
          <source>Flattens a contiguous range of dims in a tensor.</source>
          <target state="translated">テンソルの連続するディムの範囲を平坦化します。</target>
        </trans-unit>
        <trans-unit id="e2ed5b97e25777e5a578840b676a3b9e44b41cab" translate="yes" xml:space="preserve">
          <source>Flattens a contiguous range of dims into a tensor.</source>
          <target state="translated">ディムの連続した範囲をテンソルに平坦化します。</target>
        </trans-unit>
        <trans-unit id="bcfce6cdf44c8905f6faca75da235eedd5635aac" translate="yes" xml:space="preserve">
          <source>Flattens a contiguous range of dims into a tensor. For use with &lt;code&gt;Sequential&lt;/code&gt;.</source>
          <target state="translated">連続する範囲の薄暗い値をテンソルに平坦化します。 &lt;code&gt;Sequential&lt;/code&gt; で使用します。</target>
        </trans-unit>
        <trans-unit id="db0a60d5a36fb0f5467808a539ac8c0b01a8dadd" translate="yes" xml:space="preserve">
          <source>Flip array in the left/right direction, returning a new tensor.</source>
          <target state="translated">配列を左右方向に反転させ,新しいテンソルを返します.</target>
        </trans-unit>
        <trans-unit id="e9abeaf079a0d69d0b2ee4704e055dbacab017f3" translate="yes" xml:space="preserve">
          <source>Flip array in the up/down direction, returning a new tensor.</source>
          <target state="translated">配列を上下方向にフリップし、新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="d6b601389a5cfb7f115ef7332083ae3431e4e4e3" translate="yes" xml:space="preserve">
          <source>Flip the entries in each column in the up/down direction. Rows are preserved, but appear in a different order than before.</source>
          <target state="translated">各列のエントリを上下方向に反転させます。行は保存されますが、以前とは異なる順序で表示されます。</target>
        </trans-unit>
        <trans-unit id="f14bb6de935d5a8cea7f1dc6e4323a38f4e11462" translate="yes" xml:space="preserve">
          <source>Flip the entries in each row in the left/right direction. Columns are preserved, but appear in a different order than before.</source>
          <target state="translated">各行のエントリを左右方向に反転させます。列は保存されますが、以前とは異なる順序で表示されます。</target>
        </trans-unit>
        <trans-unit id="23c9f78a2bf71d761dc5a430092962a70ec045f2" translate="yes" xml:space="preserve">
          <source>FloatFunctional</source>
          <target state="translated">FloatFunctional</target>
        </trans-unit>
        <trans-unit id="a2d156b66635ae5fe54c5766d1380c6080564834" translate="yes" xml:space="preserve">
          <source>Floating-point Tensors produced in an autocast-enabled region may be &lt;code&gt;float16&lt;/code&gt;. After returning to an autocast-disabled region, using them with floating-point Tensors of different dtypes may cause type mismatch errors. If so, cast the Tensor(s) produced in the autocast region back to &lt;code&gt;float32&lt;/code&gt; (or other dtype if desired). If a Tensor from the autocast region is already &lt;code&gt;float32&lt;/code&gt;, the cast is a no-op, and incurs no additional overhead. Example:</source>
          <target state="translated">自動キャストが有効な領域で生成される浮動小数点テンソルは、float16である可能性が &lt;code&gt;float16&lt;/code&gt; ます。自動キャストが無効な領域に戻った後、それらを異なるdtypeの浮動小数点テンソルで使用すると、型の不一致エラーが発生する可能性があります。その場合、自動キャスト領域で生成されたTensorを &lt;code&gt;float32&lt;/code&gt; （または必要に応じて他のdtype）にキャストし直します。自動キャスト領域からのTensorがすでに &lt;code&gt;float32&lt;/code&gt; である場合、キャストはノーオペレーションであり、追加のオーバーヘッドは発生しません。例：</target>
        </trans-unit>
        <trans-unit id="0352ecfbeaceff6ef8214a3af42e602c1d2f0c6a" translate="yes" xml:space="preserve">
          <source>Flushes the event file to disk. Call this method to make sure that all pending events have been written to disk.</source>
          <target state="translated">イベントファイルをディスクにフラッシュします。このメソッドを呼び出して、保留中のイベントがすべてディスクに書き込まれたことを確認します。</target>
        </trans-unit>
        <trans-unit id="b6ba0db1f814179114ec82fbf188b2eb5be2596e" translate="yes" xml:space="preserve">
          <source>Fold</source>
          <target state="translated">Fold</target>
        </trans-unit>
        <trans-unit id="ab2123970899470af7c3bcdbf9832cd5ea8344b1" translate="yes" xml:space="preserve">
          <source>Following this tutorial &lt;a href=&quot;https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html&quot;&gt;Extending TorchScript with Custom C++ Operators&lt;/a&gt;, you can create and register your own custom ops implementation in PyTorch. Here&amp;rsquo;s how to export such model to ONNX.:</source>
          <target state="translated">このチュートリアル&lt;a href=&quot;https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html&quot;&gt;に従って、カスタムC ++演算子を使用してTorchScriptを拡張&lt;/a&gt;すると、PyTorchで独自のカスタムops実装を作成して登録できます。このようなモデルをONNXにエクスポートする方法は次のとおりです。</target>
        </trans-unit>
        <trans-unit id="662ac04d8757de24ad35f426f956e3ec58188dcf" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;#iterable-style-datasets&quot;&gt;iterable-style datasets&lt;/a&gt;, data loading order is entirely controlled by the user-defined iterable. This allows easier implementations of chunk-reading and dynamic batch size (e.g., by yielding a batched sample at each time).</source>
          <target state="translated">ための&lt;a href=&quot;#iterable-style-datasets&quot;&gt;反復可能な形式のデータセット&lt;/a&gt;、データのロード順序は、完全にユーザ定義の反復可能にすることによって制御されます。これにより、チャンク読み取りと動的バッチサイズの実装が容易になります（たとえば、毎回バッチサンプルを生成することにより）。</target>
        </trans-unit>
        <trans-unit id="c762389bca1bb2b05603a57f1353b6b58529cac2" translate="yes" xml:space="preserve">
          <source>For &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; objects returned by &lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt;&lt;code&gt;rpc_async()&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;future.wait()&lt;/code&gt; should not be called after &lt;code&gt;shutdown()&lt;/code&gt;.</source>
          <target state="translated">&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;返すオブジェクト&lt;a href=&quot;#torch.distributed.rpc.rpc_async&quot;&gt; &lt;code&gt;rpc_async()&lt;/code&gt; &lt;/a&gt;、 &lt;code&gt;future.wait()&lt;/code&gt; 後に呼び出されるべきではありません &lt;code&gt;shutdown()&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="068880daf2a8a0b7a7463ef0178819889346c85b" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;N&lt;/code&gt;-dimensional padding, use &lt;a href=&quot;../nn.functional#torch.nn.functional.pad&quot;&gt;&lt;code&gt;torch.nn.functional.pad()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">以下のための &lt;code&gt;N&lt;/code&gt; 次元パディング、使用&lt;a href=&quot;../nn.functional#torch.nn.functional.pad&quot;&gt; &lt;code&gt;torch.nn.functional.pad()&lt;/code&gt; &lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="0224a530bfe0946c7afd8a4140361f1cd0dcd86b" translate="yes" xml:space="preserve">
          <source>For &lt;code&gt;torch.nn.functional&lt;/code&gt; operators, we support the following:</source>
          <target state="translated">&lt;code&gt;torch.nn.functional&lt;/code&gt; 演算子、我々は次のことをサポートしています。</target>
        </trans-unit>
        <trans-unit id="e1e6b2fc17a48e201a5b7dbea3ac88cd7be57af5" translate="yes" xml:space="preserve">
          <source>For CPU tensors, this method is currently only available with MKL. Use &lt;a href=&quot;../backends#torch.backends.mkl.is_available&quot;&gt;&lt;code&gt;torch.backends.mkl.is_available()&lt;/code&gt;&lt;/a&gt; to check if MKL is installed.</source>
          <target state="translated">CPUテンソルの場合、この方法は現在MKLでのみ使用できます。使用&lt;a href=&quot;../backends#torch.backends.mkl.is_available&quot;&gt; &lt;code&gt;torch.backends.mkl.is_available()&lt;/code&gt; &lt;/a&gt; MKLがインストールされているかどうかを確認します。</target>
        </trans-unit>
        <trans-unit id="5a9dc733d94431c6a4d80dbab50dc02413b91172" translate="yes" xml:space="preserve">
          <source>For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cufft-plan-cache&quot;&gt;cuFFT plan cache&lt;/a&gt; for more details on how to monitor and control the cache.</source>
          <target state="translated">CUDAテンソルの場合、LRUキャッシュがcuFFTプランに使用され、同じ構成の同じジオメトリのテンソルでFFTメソッドを繰り返し実行する速度を上げます。&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cufft-plan-cache&quot;&gt;キャッシュ&lt;/a&gt;を監視および制御する方法の詳細については、cuFFTプランキャッシュを参照してください。</target>
        </trans-unit>
        <trans-unit id="c3f7242e16cf3e0469ec63da054b257bd101a205" translate="yes" xml:space="preserve">
          <source>For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides. For CPU tensors, an error is thrown.</source>
          <target state="translated">CUDAテンソルの場合、この関数はテンソルが存在するGPUのデバイス序数を返します。CPUテンソルの場合、エラーがスローされます。</target>
        </trans-unit>
        <trans-unit id="0338c8903416c8af92041cbd33c12e566bca8ea7" translate="yes" xml:space="preserve">
          <source>For Tensors that have &lt;a href=&quot;#torch.Tensor.requires_grad&quot;&gt;&lt;code&gt;requires_grad&lt;/code&gt;&lt;/a&gt; which is &lt;code&gt;True&lt;/code&gt;, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so &lt;code&gt;grad_fn&lt;/code&gt; is None.</source>
          <target state="translated">持っているテンソルについて&lt;a href=&quot;#torch.Tensor.requires_grad&quot;&gt; &lt;code&gt;requires_grad&lt;/code&gt; &lt;/a&gt;ある &lt;code&gt;True&lt;/code&gt; それらがユーザーによって作成された場合、彼らは葉のテンソルになります。これは、それらが操作の結果ではないため、 &lt;code&gt;grad_fn&lt;/code&gt; がNoneであることを意味します。</target>
        </trans-unit>
        <trans-unit id="ce3ce048e3708a40dbc3057fc7dbd0788b47316f" translate="yes" xml:space="preserve">
          <source>For Tensors that have &lt;a href=&quot;autograd#torch.Tensor.requires_grad&quot;&gt;&lt;code&gt;requires_grad&lt;/code&gt;&lt;/a&gt; which is &lt;code&gt;True&lt;/code&gt;, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so &lt;code&gt;grad_fn&lt;/code&gt; is None.</source>
          <target state="translated">持っているテンソルについて&lt;a href=&quot;autograd#torch.Tensor.requires_grad&quot;&gt; &lt;code&gt;requires_grad&lt;/code&gt; &lt;/a&gt;ある &lt;code&gt;True&lt;/code&gt; それらがユーザーによって作成された場合、彼らは葉のテンソルになります。これは、それらが操作の結果ではないため、 &lt;code&gt;grad_fn&lt;/code&gt; がNoneであることを意味します。</target>
        </trans-unit>
        <trans-unit id="8d2d3af0bd6ef80615c67c0f72bb823e693063c0" translate="yes" xml:space="preserve">
          <source>For a 3-D tensor the output is specified by:</source>
          <target state="translated">3次元テンソルの場合、出力は次のように指定されます。</target>
        </trans-unit>
        <trans-unit id="3f570fa1da407a7894b9ad9cdc01e54242454c59" translate="yes" xml:space="preserve">
          <source>For a 3-D tensor, &lt;code&gt;self&lt;/code&gt; is updated as:</source>
          <target state="translated">3Dテンソルの場合、 &lt;code&gt;self&lt;/code&gt; は次のように更新されます。</target>
        </trans-unit>
        <trans-unit id="dd4d8e8f7d7355e68f887ffe9f112d1d44ab2731" translate="yes" xml:space="preserve">
          <source>For a comprehensive list of name inference rules, see &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt;. Here are two common operations that may be useful to go over:</source>
          <target state="translated">名前推論規則の包括的なリストについては、&lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;名前付きテンソル演算子のカバレッジを&lt;/a&gt;参照してください。確認するのに役立つ可能性のある2つの一般的な操作を次に示します。</target>
        </trans-unit>
        <trans-unit id="f91f8919582617014f59317b7352c3f1154712ab" translate="yes" xml:space="preserve">
          <source>For a full listing of supported Python features, see &lt;a href=&quot;jit_python_reference#python-language-reference&quot;&gt;Python Language Reference Coverage&lt;/a&gt;.</source>
          <target state="translated">サポートされているPython機能の完全なリストについては、&lt;a href=&quot;jit_python_reference#python-language-reference&quot;&gt;Python言語リファレンスカバレッジを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="4cd19a97e1a392f82662e959d703403f2351a98b" translate="yes" xml:space="preserve">
          <source>For a gentle introduction to TorchScript, see the &lt;a href=&quot;https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html&quot;&gt;Introduction to TorchScript&lt;/a&gt; tutorial.</source>
          <target state="translated">TorchScriptの簡単な紹介については、&lt;a href=&quot;https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html&quot;&gt;TorchScriptの概要&lt;/a&gt;チュートリアルを参照してください。</target>
        </trans-unit>
        <trans-unit id="8e0e8c59f7042dfe9b36d63277e5e7440cb658b4" translate="yes" xml:space="preserve">
          <source>For a tensor &lt;code&gt;input&lt;/code&gt; of sizes</source>
          <target state="translated">サイズのテンソル &lt;code&gt;input&lt;/code&gt; の場合</target>
        </trans-unit>
        <trans-unit id="7afccb9a65464232e6685319e5c664295be01466" translate="yes" xml:space="preserve">
          <source>For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see the &lt;a href=&quot;https://pytorch.org/tutorials/advanced/cpp_export.html&quot;&gt;Loading a PyTorch Model in C++&lt;/a&gt; tutorial.</source>
          <target state="translated">PyTorchモデルをTorchScriptに変換してC ++で実行するエンドツーエンドの例については、「C ++で&lt;a href=&quot;https://pytorch.org/tutorials/advanced/cpp_export.html&quot;&gt;のPyTorchモデル&lt;/a&gt;のロード」チュートリアルを参照してください。</target>
        </trans-unit>
        <trans-unit id="c08a3397ebd78b324e2b03c935d901274f6914be" translate="yes" xml:space="preserve">
          <source>For bags of constant length and no &lt;code&gt;per_sample_weights&lt;/code&gt;, this class</source>
          <target state="translated">一定の長さで &lt;code&gt;per_sample_weights&lt;/code&gt; がないバッグの場合、このクラス</target>
        </trans-unit>
        <trans-unit id="243fa0279fa6c67f52078764a1246089d77121bd" translate="yes" xml:space="preserve">
          <source>For complex functions, no notion of Jacobian exists. Gradcheck verifies if the numerical and analytical values of Wirtinger and Conjugate Wirtinger derivative are consistent. The gradient computation is done under the assumption that the overall function has a real valued output. For functions with complex output, gradcheck compares the numerical and analytical gradients for two values of &lt;code&gt;grad_output&lt;/code&gt;: 1 and 1j. For more details, check out &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#complex-autograd-doc&quot;&gt;Autograd for Complex Numbers&lt;/a&gt;.</source>
          <target state="translated">複雑な関数の場合、ヤコビアンの概念は存在しません。Gradcheckは、WirtingerとConjugateWirtingerの導関数の数値と分析値が一致しているかどうかを確認します。勾配計算は、関数全体が実数値の出力を持っているという仮定の下で行われます。複合出力に機能するため、gradcheckは、二つの値の数値と分析勾配比較 &lt;code&gt;grad_output&lt;/code&gt; 1および1Jを：。詳細については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/autograd.html#complex-autograd-doc&quot;&gt;Autograd for ComplexNumbersを&lt;/a&gt;確認してください。</target>
        </trans-unit>
        <trans-unit id="6f725f3358d3c963d673d4ca7969a99e89c8c101" translate="yes" xml:space="preserve">
          <source>For data loading, passing &lt;code&gt;pin_memory=True&lt;/code&gt; to a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; will automatically put the fetched data Tensors in pinned memory, and thus enables faster data transfer to CUDA-enabled GPUs.</source>
          <target state="translated">データの読み込みの場合、 &lt;code&gt;pin_memory=True&lt;/code&gt; を&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; に渡す&lt;/a&gt;と、フェッチされたデータTensorが自動的に固定メモリに配置されるため、CUDA対応のGPUへのデータ転送が高速になります。</target>
        </trans-unit>
        <trans-unit id="ce5d81031fb4d7e97b33ce443ec1d33497cec1cd" translate="yes" xml:space="preserve">
          <source>For details on input arguments, parameters, and implementation see &lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt;&lt;code&gt;Conv1d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">入力引数、パラメーター、および実装の詳細については、&lt;a href=&quot;generated/torch.nn.conv1d#torch.nn.Conv1d&quot;&gt; &lt;code&gt;Conv1d&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="36b1210fa3359dec217e0f8625012720c3f10bc6" translate="yes" xml:space="preserve">
          <source>For details on input arguments, parameters, and implementation see &lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt;&lt;code&gt;Conv2d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">入力引数、パラメーター、および実装の詳細については、&lt;a href=&quot;generated/torch.nn.conv2d#torch.nn.Conv2d&quot;&gt; &lt;code&gt;Conv2d&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="17fc1bf0dec370ea37946985facbba42ffd22e0f" translate="yes" xml:space="preserve">
          <source>For details on input arguments, parameters, and implementation see &lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt;&lt;code&gt;Conv3d&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">入力引数、パラメーター、および実装の詳細については、&lt;a href=&quot;generated/torch.nn.conv3d#torch.nn.Conv3d&quot;&gt; &lt;code&gt;Conv3d&lt;/code&gt; を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="88fa6dcc55dbef1b20fcb850f35a6375f7b3938c" translate="yes" xml:space="preserve">
          <source>For each element in the input sequence, each layer computes the following function:</source>
          <target state="translated">入力シーケンスの各要素について,各レイヤーは以下の関数を計算します.</target>
        </trans-unit>
        <trans-unit id="d139363266e05a6b552e5defd18e04652bf83d44" translate="yes" xml:space="preserve">
          <source>For each mini-batch sample, the loss in terms of the 1D input</source>
          <target state="translated">各ミニバッチサンプルについて、1D入力の損失は</target>
        </trans-unit>
        <trans-unit id="431645996fbd3fae9490db55c077050efdd9469b" translate="yes" xml:space="preserve">
          <source>For each output location &lt;code&gt;output[n, :, h, w]&lt;/code&gt;, the size-2 vector &lt;code&gt;grid[n, h, w]&lt;/code&gt; specifies &lt;code&gt;input&lt;/code&gt; pixel locations &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, which are used to interpolate the output value &lt;code&gt;output[n, :, h, w]&lt;/code&gt;. In the case of 5D inputs, &lt;code&gt;grid[n, d, h, w]&lt;/code&gt; specifies the &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, &lt;code&gt;z&lt;/code&gt; pixel locations for interpolating &lt;code&gt;output[n, :, d, h, w]&lt;/code&gt;. &lt;code&gt;mode&lt;/code&gt; argument specifies &lt;code&gt;nearest&lt;/code&gt; or &lt;code&gt;bilinear&lt;/code&gt; interpolation method to sample the input pixels.</source>
          <target state="translated">各出力位置 &lt;code&gt;output[n, :, h, w]&lt;/code&gt; について、サイズ2のベクトル &lt;code&gt;grid[n, h, w]&lt;/code&gt; は、出力値 &lt;code&gt;output[n, :, h, w]&lt;/code&gt; を補間するために使用される &lt;code&gt;input&lt;/code&gt; ピクセル位置 &lt;code&gt;x&lt;/code&gt; および &lt;code&gt;y&lt;/code&gt; を指定します。 h、w]。5D入力の場合、 &lt;code&gt;grid[n, d, h, w]&lt;/code&gt; は、 &lt;code&gt;output[n, :, d, h, w]&lt;/code&gt; を補間するための &lt;code&gt;x&lt;/code&gt; 、 &lt;code&gt;y&lt;/code&gt; 、 &lt;code&gt;z&lt;/code&gt; ピクセル位置を指定します。 &lt;code&gt;mode&lt;/code&gt; 引数は、入力ピクセルをサンプリングするための &lt;code&gt;nearest&lt;/code&gt; または &lt;code&gt;bilinear&lt;/code&gt; 内挿法を指定します。</target>
        </trans-unit>
        <trans-unit id="a707b704ee783d908df45582d74fb5eed5208cc2" translate="yes" xml:space="preserve">
          <source>For example, assigning to &lt;code&gt;self&lt;/code&gt; outside of the &lt;code&gt;__init__()&lt;/code&gt; method:</source>
          <target state="translated">たとえば、 &lt;code&gt;__init__()&lt;/code&gt; メソッドの外部で &lt;code&gt;self&lt;/code&gt; に割り当てる：</target>
        </trans-unit>
        <trans-unit id="598cd3a9f173b17b51c024dfc8ec80175fdbbd3c" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;input&lt;/code&gt; is a vector of size N, the result will also be a vector of size N, with elements.</source>
          <target state="translated">たとえば、 &lt;code&gt;input&lt;/code&gt; がサイズNのベクトルである場合、結果は要素を含むサイズNのベクトルにもなります。</target>
        </trans-unit>
        <trans-unit id="c5eb0f2bf9e3391a2f0f43ac5e99b77a4de61cf1" translate="yes" xml:space="preserve">
          <source>For example, if &lt;code&gt;input&lt;/code&gt; is of shape:</source>
          <target state="translated">たとえば、 &lt;code&gt;input&lt;/code&gt; が形状の場合：</target>
        </trans-unit>
        <trans-unit id="cb7354d4a324678f0e4b20e916940e161856f119" translate="yes" xml:space="preserve">
          <source>For example, if a dataset contains 100 positive and 300 negative examples of a single class, then &lt;code&gt;pos_weight&lt;/code&gt; for the class should be equal to</source>
          <target state="translated">たとえば、データセットに1つのクラスの100個の正の例と300個の負の例が含まれている場合、そのクラスの &lt;code&gt;pos_weight&lt;/code&gt; は次のようになります。</target>
        </trans-unit>
        <trans-unit id="ec89e688ce49781ad9518cc67374c388cc79a9c9" translate="yes" xml:space="preserve">
          <source>For example, if the system we use for distributed training has 2 nodes, each of which has 8 GPUs. On each of the 16 GPUs, there is a tensor that we would like to all-reduce. The following code can serve as a reference:</source>
          <target state="translated">例えば、分散訓練に使用するシステムが2つのノードを持ち、それぞれが8つのGPUを持っているとします。16個のGPUのそれぞれに、全還元したいテンソルがあります。以下のコードが参考になります。</target>
        </trans-unit>
        <trans-unit id="b2aafe679a24a7e81a27fcc1b208b172dea562d1" translate="yes" xml:space="preserve">
          <source>For example, such a dataset, when accessed with &lt;code&gt;dataset[idx]&lt;/code&gt;, could read the &lt;code&gt;idx&lt;/code&gt;-th image and its corresponding label from a folder on the disk.</source>
          <target state="translated">たとえば、このようなデータセットは、 &lt;code&gt;dataset[idx]&lt;/code&gt; でアクセスすると、ディスク上のフォルダーから &lt;code&gt;idx&lt;/code&gt; 番目の画像とそれに対応するラベルを読み取ることができます。</target>
        </trans-unit>
        <trans-unit id="734a9ddb49bc44a14f3817f8ab3e399194fe7014" translate="yes" xml:space="preserve">
          <source>For example, such a dataset, when called &lt;code&gt;iter(dataset)&lt;/code&gt;, could return a stream of data reading from a database, a remote server, or even logs generated in real time.</source>
          <target state="translated">たとえば、このようなデータセットは、 &lt;code&gt;iter(dataset)&lt;/code&gt; と呼ばれると、データベース、リモートサーバー、またはリアルタイムで生成されたログから読み取ったデータのストリームを返す可能性があります。</target>
        </trans-unit>
        <trans-unit id="b076a6f19f5c3f95d3197664aa2092f90ac3e4fd" translate="yes" xml:space="preserve">
          <source>For example, suppose that we wanted to implement an operator by operating directly on &lt;a href=&quot;#torch.sparse.FloatTensor._values&quot;&gt;&lt;code&gt;torch.sparse.FloatTensor._values()&lt;/code&gt;&lt;/a&gt;. Multiplication by a scalar can be implemented in the obvious way, as multiplication distributes over addition; however, square root cannot be implemented directly, since &lt;code&gt;sqrt(a + b) != sqrt(a) +
sqrt(b)&lt;/code&gt; (which is what would be computed if you were given an uncoalesced tensor.)</source>
          <target state="translated">たとえば、&lt;a href=&quot;#torch.sparse.FloatTensor._values&quot;&gt; &lt;code&gt;torch.sparse.FloatTensor._values()&lt;/code&gt; を&lt;/a&gt;直接操作して演算子を実装したいとします。スカラーによる乗算は、乗算が加算に分散するため、明白な方法で実装できます。ただし、 &lt;code&gt;sqrt(a + b) != sqrt(a) + sqrt(b)&lt;/code&gt; （非合体テンソルが与えられた場合に計算されるもの）であるため、平方根を直接実装することはできません。</target>
        </trans-unit>
        <trans-unit id="287e119f8bc584b5b1a94e98cf1131a5d81ded2a" translate="yes" xml:space="preserve">
          <source>For example, this is very useful when one wants to specify per-layer learning rates:</source>
          <target state="translated">例えば、レイヤごとの学習率を指定したい場合に非常に便利です。</target>
        </trans-unit>
        <trans-unit id="b3dee60b13728b6faa87ab6d08e758ac130cfdfa" translate="yes" xml:space="preserve">
          <source>For inputs of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; must be a real number, otherwise an integer.</source>
          <target state="translated">タイプ &lt;code&gt;FloatTensor&lt;/code&gt; または &lt;code&gt;DoubleTensor&lt;/code&gt; の入力の場合、 &lt;code&gt;value&lt;/code&gt; は実数である必要があり、そうでない場合は整数である必要があります。</target>
        </trans-unit>
        <trans-unit id="a79d59fd72d10daf74904a50c1c53f2a33467eeb" translate="yes" xml:space="preserve">
          <source>For inputs of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, arguments &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; must be real numbers, otherwise they should be integers</source>
          <target state="translated">タイプ &lt;code&gt;FloatTensor&lt;/code&gt; または &lt;code&gt;DoubleTensor&lt;/code&gt; の入力の場合、引数 &lt;code&gt;beta&lt;/code&gt; および &lt;code&gt;alpha&lt;/code&gt; は実数である必要があり、そうでない場合は整数である必要があります。</target>
        </trans-unit>
        <trans-unit id="c25cdbf09c7b02888e46dd28ab2af0cd145a33a9" translate="yes" xml:space="preserve">
          <source>For inputs of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, arguments &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; must be real numbers, otherwise they should be integers.</source>
          <target state="translated">タイプ &lt;code&gt;FloatTensor&lt;/code&gt; または &lt;code&gt;DoubleTensor&lt;/code&gt; の入力の場合、引数 &lt;code&gt;beta&lt;/code&gt; および &lt;code&gt;alpha&lt;/code&gt; は実数である必要があり、そうでない場合は整数である必要があります。</target>
        </trans-unit>
        <trans-unit id="f2524577d6ea6dbe6d56d704e00d4f3e91229b19" translate="yes" xml:space="preserve">
          <source>For instance, if each data sample consists of a 3-channel image and an integral class label, i.e., each element of the dataset returns a tuple &lt;code&gt;(image, class_index)&lt;/code&gt;, the default &lt;code&gt;collate_fn&lt;/code&gt; collates a list of such tuples into a single tuple of a batched image tensor and a batched class label Tensor. In particular, the default &lt;code&gt;collate_fn&lt;/code&gt; has the following properties:</source>
          <target state="translated">たとえば、各データサンプルが3チャネルの画像と統合クラスラベルで構成されている場合、つまり、データセットの各要素がタプル &lt;code&gt;(image, class_index)&lt;/code&gt; 返す場合、デフォルトの &lt;code&gt;collate_fn&lt;/code&gt; は、そのようなタプルのリストをの単一のタプルに照合します。バッチ処理された画像テンソルとバッチ処理されたクラスラベルTensor。特に、デフォルトの &lt;code&gt;collate_fn&lt;/code&gt; には次のプロパティがあります。</target>
        </trans-unit>
        <trans-unit id="abc897209b2f98b7966665fa36a5eddbbc44f66d" translate="yes" xml:space="preserve">
          <source>For instance:</source>
          <target state="translated">例えば</target>
        </trans-unit>
        <trans-unit id="dc23cb2e2a00ac46f8d5395098475d4070a042d1" translate="yes" xml:space="preserve">
          <source>For iterable-style datasets, since each worker process gets a replica of the &lt;code&gt;dataset&lt;/code&gt; object, naive multi-process loading will often result in duplicated data. Using &lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt;&lt;code&gt;torch.utils.data.get_worker_info()&lt;/code&gt;&lt;/a&gt; and/or &lt;code&gt;worker_init_fn&lt;/code&gt;, users may configure each replica independently. (See &lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt;&lt;code&gt;IterableDataset&lt;/code&gt;&lt;/a&gt; documentations for how to achieve this. ) For similar reasons, in multi-process loading, the &lt;code&gt;drop_last&lt;/code&gt; argument drops the last non-full batch of each worker&amp;rsquo;s iterable-style dataset replica.</source>
          <target state="translated">反復可能なスタイルのデータセットの場合、各ワーカープロセスは &lt;code&gt;dataset&lt;/code&gt; オブジェクトのレプリカを取得するため、単純なマルチプロセスの読み込みではデータが重複することがよくあります。使用&lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt; &lt;code&gt;torch.utils.data.get_worker_info()&lt;/code&gt; &lt;/a&gt;及び/又は &lt;code&gt;worker_init_fn&lt;/code&gt; 、ユーザは、それぞれ独立してレプリカを構成することができます。（これを実現する方法については、&lt;a href=&quot;#torch.utils.data.IterableDataset&quot;&gt; &lt;code&gt;IterableDataset&lt;/code&gt; の&lt;/a&gt;ドキュメントを参照してください。）同様の理由で、マルチプロセスの読み込みでは、 &lt;code&gt;drop_last&lt;/code&gt; 引数は、各ワーカーの反復可能スタイルのデータセットレプリカの最後の非完全バッチを削除します。</target>
        </trans-unit>
        <trans-unit id="22c3fe0b8bd316af1ba2f91851ec2f8f7995ee83" translate="yes" xml:space="preserve">
          <source>For legacy reasons, a device can be constructed via a single device ordinal, which is treated as a cuda device. This matches &lt;a href=&quot;tensors#torch.Tensor.get_device&quot;&gt;&lt;code&gt;Tensor.get_device()&lt;/code&gt;&lt;/a&gt;, which returns an ordinal for cuda tensors and is not supported for cpu tensors.</source>
          <target state="translated">従来の理由により、デバイスは、cudaデバイスとして扱われる単一のデバイス序数を介して構築できます。これは&lt;a href=&quot;tensors#torch.Tensor.get_device&quot;&gt; &lt;code&gt;Tensor.get_device()&lt;/code&gt; &lt;/a&gt;と一致します。これは、cudaテンソルの序数を返し、cpuテンソルではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="0aa3a8773fa895e1e6152468962406770d9b0977" translate="yes" xml:space="preserve">
          <source>For loops over constant nn.ModuleList</source>
          <target state="translated">定数 nn.ModuleList のループの場合</target>
        </trans-unit>
        <trans-unit id="d0ca847043fc995de69359f3596ce96734b521c7" translate="yes" xml:space="preserve">
          <source>For loops over tuples</source>
          <target state="translated">タプルの上のループの場合</target>
        </trans-unit>
        <trans-unit id="5aa0148bf5ef53de46ea15471ea81ef66c0693f4" translate="yes" xml:space="preserve">
          <source>For loops with range</source>
          <target state="translated">範囲のあるループの場合</target>
        </trans-unit>
        <trans-unit id="c492beb9d1c851a0661d50033a687a1b1aab0e7a" translate="yes" xml:space="preserve">
          <source>For map-style datasets, the main process generates the indices using &lt;code&gt;sampler&lt;/code&gt; and sends them to the workers. So any shuffle randomization is done in the main process which guides loading by assigning indices to load.</source>
          <target state="translated">マップスタイルのデータセットの場合、メインプロセスは &lt;code&gt;sampler&lt;/code&gt; を使用してインデックスを生成し、それらをワーカーに送信します。したがって、シャッフルのランダム化は、ロードにインデックスを割り当てることによってロードをガイドするメインプロセスで行われます。</target>
        </trans-unit>
        <trans-unit id="0d65cf1ed6eabecd00c26213c93e0d17f7fcdf45" translate="yes" xml:space="preserve">
          <source>For more complicated uses of the profilers (like in a multi-GPU case), please see &lt;a href=&quot;https://docs.python.org/3/library/profile.html&quot;&gt;https://docs.python.org/3/library/profile.html&lt;/a&gt; or &lt;a href=&quot;autograd#torch.autograd.profiler.profile&quot;&gt;&lt;code&gt;torch.autograd.profiler.profile()&lt;/code&gt;&lt;/a&gt; for more information.</source>
          <target state="translated">プロファイラーのより複雑な使用法（マルチGPUの場合など）については、&lt;a href=&quot;https://docs.python.org/3/library/profile.html&quot;&gt;https&lt;/a&gt;：&lt;a href=&quot;autograd#torch.autograd.profiler.profile&quot;&gt; &lt;code&gt;torch.autograd.profiler.profile()&lt;/code&gt; &lt;/a&gt;またはtorch.autograd.profiler.profile（）を参照してください。</target>
        </trans-unit>
        <trans-unit id="676185286638fbcbfe90f50f9df7e7cdf2648359" translate="yes" xml:space="preserve">
          <source>For more examples, please look at the implementations of &lt;a href=&quot;#torch.distributions.gumbel.Gumbel&quot;&gt;&lt;code&gt;Gumbel&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.half_cauchy.HalfCauchy&quot;&gt;&lt;code&gt;HalfCauchy&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.half_normal.HalfNormal&quot;&gt;&lt;code&gt;HalfNormal&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.log_normal.LogNormal&quot;&gt;&lt;code&gt;LogNormal&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.pareto.Pareto&quot;&gt;&lt;code&gt;Pareto&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.weibull.Weibull&quot;&gt;&lt;code&gt;Weibull&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;#torch.distributions.relaxed_bernoulli.RelaxedBernoulli&quot;&gt;&lt;code&gt;RelaxedBernoulli&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical&quot;&gt;&lt;code&gt;RelaxedOneHotCategorical&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">その他の例については、&lt;a href=&quot;#torch.distributions.gumbel.Gumbel&quot;&gt; &lt;code&gt;Gumbel&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.half_cauchy.HalfCauchy&quot;&gt; &lt;code&gt;HalfCauchy&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.half_normal.HalfNormal&quot;&gt; &lt;code&gt;HalfNormal&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.log_normal.LogNormal&quot;&gt; &lt;code&gt;LogNormal&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.pareto.Pareto&quot;&gt; &lt;code&gt;Pareto&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.weibull.Weibull&quot;&gt; &lt;code&gt;Weibull&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.relaxed_bernoulli.RelaxedBernoulli&quot;&gt; &lt;code&gt;RelaxedBernoulli&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical&quot;&gt; &lt;code&gt;RelaxedOneHotCategorical&lt;/code&gt; の&lt;/a&gt;実装をご覧ください。</target>
        </trans-unit>
        <trans-unit id="7b8781b8ea8a1a7fd16e315cb8caa2f0d8fd81ce" translate="yes" xml:space="preserve">
          <source>For more information on &lt;code&gt;torch.sparse_coo&lt;/code&gt; tensors, see &lt;a href=&quot;sparse#sparse-docs&quot;&gt;torch.sparse&lt;/a&gt;.</source>
          <target state="translated">詳細については &lt;code&gt;torch.sparse_coo&lt;/code&gt; のテンソル、参照&lt;a href=&quot;sparse#sparse-docs&quot;&gt;torch.sparse&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="5a0ad772d1091f121cc7efb6b451798990b8911a" translate="yes" xml:space="preserve">
          <source>For more information on tensor views, see &lt;a href=&quot;tensor_view#tensor-view-doc&quot;&gt;Tensor Views&lt;/a&gt;.</source>
          <target state="translated">テンソルビューの詳細については、&lt;a href=&quot;tensor_view#tensor-view-doc&quot;&gt;テンソルビュー&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="1f3909dab7a0a74dfec923801d50d6afccbbd76f" translate="yes" xml:space="preserve">
          <source>For more information on the &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&quot;tensor_attributes#torch.torch.layout&quot;&gt;&lt;code&gt;torch.layout&lt;/code&gt;&lt;/a&gt; attributes of a &lt;a href=&quot;#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;, see &lt;a href=&quot;tensor_attributes#tensor-attributes-doc&quot;&gt;Tensor Attributes&lt;/a&gt;.</source>
          <target state="translated">詳細については&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;、および&lt;a href=&quot;tensor_attributes#torch.torch.layout&quot;&gt; &lt;code&gt;torch.layout&lt;/code&gt; &lt;/a&gt;の属性&lt;a href=&quot;#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; &lt;/a&gt;、参照&lt;a href=&quot;tensor_attributes#tensor-attributes-doc&quot;&gt;テンソルの属性&lt;/a&gt;。</target>
        </trans-unit>
        <trans-unit id="e6568b8e5f7166a4f6114617787be1538e34997e" translate="yes" xml:space="preserve">
          <source>For now, normalization code can be found in &lt;code&gt;references/video_classification/transforms.py&lt;/code&gt;, see the &lt;code&gt;Normalize&lt;/code&gt; function there. Note that it differs from standard normalization for images because it assumes the video is 4d.</source>
          <target state="translated">今のところ、正規化コードは &lt;code&gt;references/video_classification/transforms.py&lt;/code&gt; あります。そこにある &lt;code&gt;Normalize&lt;/code&gt; 関数を参照してください。ビデオが4Dであると想定しているため、画像の標準的な正規化とは異なることに注意してください。</target>
        </trans-unit>
        <trans-unit id="43d57f5d34139266a152ef339407d7c7bfa3e16a" translate="yes" xml:space="preserve">
          <source>For numerical stability the implementation reverts to the linear function when</source>
          <target state="translated">数値的な安定性を確保するために、実装は</target>
        </trans-unit>
        <trans-unit id="e2c95cbc7cf538a8a02cb4f1bc38de8b5a3ed2b9" translate="yes" xml:space="preserve">
          <source>For object detection and instance segmentation, the pre-trained models return the predictions of the following classes:</source>
          <target state="translated">オブジェクトの検出とインスタンスのセグメンテーションのために、事前学習されたモデルは、以下のクラスの予測値を返します。</target>
        </trans-unit>
        <trans-unit id="0d60fa4ee1b04194485d841887bd2a9720912ce7" translate="yes" xml:space="preserve">
          <source>For one, if either</source>
          <target state="translated">一つには、もしどちらかが</target>
        </trans-unit>
        <trans-unit id="388c4450cdbff00300f1e66a7fe9bdbd7ad63df6" translate="yes" xml:space="preserve">
          <source>For person keypoint detection, the accuracies for the pre-trained models are as follows</source>
          <target state="translated">人物キーポイント検出の場合、事前学習したモデルの精度は以下のようになります。</target>
        </trans-unit>
        <trans-unit id="50930fbd40ff369c0fa47ef8013fdffeda924fcf" translate="yes" xml:space="preserve">
          <source>For person keypoint detection, the pre-trained model return the keypoints in the following order:</source>
          <target state="translated">人物キーポイント検出では、事前学習されたモデルが以下の順序でキーポイントを返す。</target>
        </trans-unit>
        <trans-unit id="1547488bbec68c16b5473f238ae370eab49bdca4" translate="yes" xml:space="preserve">
          <source>For references on how to use it, please refer to &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/imagenet&quot;&gt;PyTorch example - ImageNet implementation&lt;/a&gt;</source>
          <target state="translated">使用方法については、&lt;a href=&quot;https://github.com/pytorch/examples/tree/master/imagenet&quot;&gt;PyTorchの例-ImageNetの実装&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="35c8decc2166af07962152ef6f02d95b39a40bf1" translate="yes" xml:space="preserve">
          <source>For simplest usage provide &lt;code&gt;dtype&lt;/code&gt; argument that can be float16 or qint8. Weight-only quantization by default is performed for layers with large weights size - i.e. Linear and RNN variants.</source>
          <target state="translated">最も簡単な使用法として、float16またはqint8の &lt;code&gt;dtype&lt;/code&gt; 引数を指定します。デフォルトでは、重みのみの量子化は、重みサイズが大きいレイヤー、つまり線形およびRNNバリアントに対して実行されます。</target>
        </trans-unit>
        <trans-unit id="5b0de76315890608ccfec148ffc9eb96ab3d19d0" translate="yes" xml:space="preserve">
          <source>For summation index</source>
          <target state="translated">和算指数の場合</target>
        </trans-unit>
        <trans-unit id="ae21afa5351a91a1f97daa42d064cca4e245e30f" translate="yes" xml:space="preserve">
          <source>For test time, we report the time for the model evaluation and postprocessing (including mask pasting in image), but not the time for computing the precision-recall.</source>
          <target state="translated">テスト時間については、モデルの評価と後処理(画像へのマスク貼り付けを含む)にかかる時間を報告するが、精度-再現性の計算にかかる時間は報告しない。</target>
        </trans-unit>
        <trans-unit id="294fafc65e707c55d30f92f6e6fa7597c4416793" translate="yes" xml:space="preserve">
          <source>For the case of two input spatial dimensions this operation is sometimes called &lt;code&gt;im2col&lt;/code&gt;.</source>
          <target state="translated">2つの入力空間次元の場合、この操作は &lt;code&gt;im2col&lt;/code&gt; と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="4294b91105e53a9501af3f666602dc49b4fae690" translate="yes" xml:space="preserve">
          <source>For the case of two output spatial dimensions this operation is sometimes called &lt;code&gt;col2im&lt;/code&gt;.</source>
          <target state="translated">2つの出力空間次元の場合、この操作は &lt;code&gt;col2im&lt;/code&gt; と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="63464d394b40abaadcd5cd07925b101f22c85d5d" translate="yes" xml:space="preserve">
          <source>For the following examples:</source>
          <target state="translated">以下の例については</target>
        </trans-unit>
        <trans-unit id="250e5319dc4351da49602e421d48ab9ddd21e40e" translate="yes" xml:space="preserve">
          <source>For the full list of NCCL environment variables, please refer to &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html&quot;&gt;NVIDIA NCCL&amp;rsquo;s official documentation&lt;/a&gt;</source>
          <target state="translated">NCCL環境変数の完全なリストについては、&lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html&quot;&gt;NVIDIANCCLの公式ドキュメント&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="fbb3381cc7af3b7907b168edfc7c7438b66cd477" translate="yes" xml:space="preserve">
          <source>For the most part, you shouldn&amp;rsquo;t have to care whether or not a sparse tensor is coalesced or not, as most operations will work identically given a coalesced or uncoalesced sparse tensor. However, there are two cases in which you may need to care.</source>
          <target state="translated">ほとんどの場合、スパーステンソルが合体したかどうかを気にする必要はありません。合体した、または合体していないスパーステンソルが与えられた場合、ほとんどの操作は同じように機能するからです。ただし、注意が必要な場合が2つあります。</target>
        </trans-unit>
        <trans-unit id="b5ee688f7705f701edf82664a012c925ae4f0c34" translate="yes" xml:space="preserve">
          <source>For the unpacked case, the directions can be separated using &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt;, with forward and backward being direction &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; respectively. Similarly, the directions can be separated in the packed case.</source>
          <target state="translated">解凍された場合、方向は &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt; を使用して分離でき、順方向と逆方向はそれぞれ方向 &lt;code&gt;0&lt;/code&gt; と &lt;code&gt;1&lt;/code&gt; です。同様に、パックされたケースでは方向を分けることができます。</target>
        </trans-unit>
        <trans-unit id="c66bf21ad2ff938e858bedebd02eca91c5de881a" translate="yes" xml:space="preserve">
          <source>For these core statistics, values are broken down as follows.</source>
          <target state="translated">これらのコア統計については、値は以下のように分解されています。</target>
        </trans-unit>
        <trans-unit id="0b3352e82009813f0901947623d7383dc915b831" translate="yes" xml:space="preserve">
          <source>For unsorted sequences, use &lt;code&gt;enforce_sorted = False&lt;/code&gt;. If &lt;code&gt;enforce_sorted&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the sequences should be sorted by length in a decreasing order, i.e. &lt;code&gt;input[:,0]&lt;/code&gt; should be the longest sequence, and &lt;code&gt;input[:,B-1]&lt;/code&gt; the shortest one. &lt;code&gt;enforce_sorted = True&lt;/code&gt; is only necessary for ONNX export.</source>
          <target state="translated">ソートされていないシーケンスの場合は、 &lt;code&gt;enforce_sorted = False&lt;/code&gt; 使用します。場合 &lt;code&gt;enforce_sorted&lt;/code&gt; がある &lt;code&gt;True&lt;/code&gt; 、配列は、降順の長さによって、すなわちソートされるべき &lt;code&gt;input[:,0]&lt;/code&gt; 、最長シーケンス、およびなければならない &lt;code&gt;input[:,B-1]&lt;/code&gt; 最短1。 &lt;code&gt;enforce_sorted = True&lt;/code&gt; は、ONNXエクスポートにのみ必要です。</target>
        </trans-unit>
        <trans-unit id="74aa708d44a325bbc3a2350d27d2ddf6e3e6b36a" translate="yes" xml:space="preserve">
          <source>For unsorted sequences, use &lt;code&gt;enforce_sorted = False&lt;/code&gt;. If &lt;code&gt;enforce_sorted&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the sequences should be sorted in the order of decreasing length. &lt;code&gt;enforce_sorted = True&lt;/code&gt; is only necessary for ONNX export.</source>
          <target state="translated">ソートされていないシーケンスの場合は、 &lt;code&gt;enforce_sorted = False&lt;/code&gt; 使用します。場合 &lt;code&gt;enforce_sorted&lt;/code&gt; がある &lt;code&gt;True&lt;/code&gt; 、配列は、長さの降順にソートされなければなりません。 &lt;code&gt;enforce_sorted = True&lt;/code&gt; は、ONNXエクスポートにのみ必要です。</target>
        </trans-unit>
        <trans-unit id="4f7d55db4ef6ba383bbd9077e4ad197526d0bc5b" translate="yes" xml:space="preserve">
          <source>Force collects GPU memory after it has been released by CUDA IPC.</source>
          <target state="translated">Forceは、CUDA IPCで解放された後のGPUメモリを収集します。</target>
        </trans-unit>
        <trans-unit id="65edc3b96f1e2f54f14a87eb92d4dea02b1b6e9b" translate="yes" xml:space="preserve">
          <source>Forces completion of a &lt;code&gt;torch.jit.Future[T]&lt;/code&gt; asynchronous task, returning the result of the task.</source>
          <target state="translated">&lt;code&gt;torch.jit.Future[T]&lt;/code&gt; 非同期タスクの完了を強制し、タスクの結果を返します。</target>
        </trans-unit>
        <trans-unit id="dc619e95fe61cfbb5a61b8e23e153aa71a53f467" translate="yes" xml:space="preserve">
          <source>Forces completion of a &lt;code&gt;torch.jit.Future[T]&lt;/code&gt; asynchronous task, returning the result of the task. See &lt;a href=&quot;torch.jit.fork#torch.jit.fork&quot;&gt;&lt;code&gt;fork()&lt;/code&gt;&lt;/a&gt; for docs and examples. :param func: an asynchronous task reference, created through &lt;code&gt;torch.jit.fork&lt;/code&gt; :type func: torch.jit.Future[T]</source>
          <target state="translated">&lt;code&gt;torch.jit.Future[T]&lt;/code&gt; 非同期タスクの完了を強制し、タスクの結果を返します。ドキュメントと例については、&lt;a href=&quot;torch.jit.fork#torch.jit.fork&quot;&gt; &lt;code&gt;fork()&lt;/code&gt; &lt;/a&gt;を参照してください。 ：param func： &lt;code&gt;torch.jit.fork&lt;/code&gt; を介して作成された非同期タスク参照：type func：torch.jit.Future [T]</target>
        </trans-unit>
        <trans-unit id="7e827f4fab2c732110bd891aca164ea682ff2e51" translate="yes" xml:space="preserve">
          <source>Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in.</source>
          <target state="translated">RNG をフォークすることで、復帰時には RNG がそれまでの状態にリセットされます。</target>
        </trans-unit>
        <trans-unit id="e0b8013b454609aa16cd91b06faebccde13182b1" translate="yes" xml:space="preserve">
          <source>Forward and backward hooks defined on &lt;code&gt;module&lt;/code&gt; and its submodules will be invoked &lt;code&gt;len(device_ids)&lt;/code&gt; times, each with inputs located on a particular device. Particularly, the hooks are only guaranteed to be executed in correct order with respect to operations on corresponding devices. For example, it is not guaranteed that hooks set via &lt;a href=&quot;torch.nn.module#torch.nn.Module.register_forward_pre_hook&quot;&gt;&lt;code&gt;register_forward_pre_hook()&lt;/code&gt;&lt;/a&gt; be executed before &lt;code&gt;all&lt;/code&gt;&lt;code&gt;len(device_ids)&lt;/code&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; calls, but that each such hook be executed before the corresponding &lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; call of that device.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; とそのサブモジュールで定義されたフォワードフックとバックワードフックは &lt;code&gt;len(device_ids)&lt;/code&gt; 回呼び出され、それぞれが特定のデバイスに入力を配置します。特に、フックは、対応するデバイスでの操作に関して正しい順序でのみ実行されることが保証されています。たとえば、&lt;a href=&quot;torch.nn.module#torch.nn.Module.register_forward_pre_hook&quot;&gt; &lt;code&gt;register_forward_pre_hook()&lt;/code&gt; &lt;/a&gt;を介して設定されたフックが、 &lt;code&gt;all&lt;/code&gt; &lt;code&gt;len(device_ids)&lt;/code&gt; &lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;呼び出しの前に実行されることは保証されませんが、そのような各フックは、そのデバイスの対応する&lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;呼び出しの前に実行されます。</target>
        </trans-unit>
        <trans-unit id="6acf90721bbeda5f77e7073663e225cf7715008a" translate="yes" xml:space="preserve">
          <source>Forward and backward hooks defined on &lt;code&gt;module&lt;/code&gt; and its submodules won&amp;rsquo;t be invoked anymore, unless the hooks are initialized in the &lt;code&gt;forward()&lt;/code&gt; method.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; とそのサブモジュールで定義されたフォワードフックとバックワードフックは、フックが &lt;code&gt;forward()&lt;/code&gt; メソッドで初期化されない限り、呼び出されなくなります。</target>
        </trans-unit>
        <trans-unit id="988135b5646708fe12c52e4f90092901a6ed112d" translate="yes" xml:space="preserve">
          <source>Fractional MaxPooling is described in detail in the paper &lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;Fractional MaxPooling&lt;/a&gt; by Ben Graham</source>
          <target state="translated">Fractional MaxPoolingについては、&lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;BenGraham&lt;/a&gt;による論文FractionalMaxPoolingで詳しく説明されています。</target>
        </trans-unit>
        <trans-unit id="2297da08c1909f5dca5e7ab8bf486b563fbe806e" translate="yes" xml:space="preserve">
          <source>FractionalMaxPool2d</source>
          <target state="translated">FractionalMaxPool2d</target>
        </trans-unit>
        <trans-unit id="d790b402d79ac1a723c790313bcd679999474630" translate="yes" xml:space="preserve">
          <source>Frequently Asked Questions</source>
          <target state="translated">よくある質問</target>
        </trans-unit>
        <trans-unit id="8c7beab7a6d84d3a1004bcc75ccd72648a4866a0" translate="yes" xml:space="preserve">
          <source>Frobenius norm</source>
          <target state="translated">フロベニウスノルム</target>
        </trans-unit>
        <trans-unit id="e553dabf708d383e58b9442ad6ace6c5038afc7a" translate="yes" xml:space="preserve">
          <source>From the &lt;code&gt;torch.nn.utils&lt;/code&gt; module</source>
          <target state="translated">&lt;code&gt;torch.nn.utils&lt;/code&gt; モジュールから</target>
        </trans-unit>
        <trans-unit id="f92451195f62b1d7cd9731015aa1fa56d4159f9d" translate="yes" xml:space="preserve">
          <source>Fully Convolutional Networks</source>
          <target state="translated">完全畳み込みネットワーク</target>
        </trans-unit>
        <trans-unit id="f1e410ad1472b42cb42cc98962428637290b6706" translate="yes" xml:space="preserve">
          <source>Function</source>
          <target state="translated">Function</target>
        </trans-unit>
        <trans-unit id="d8cdf10face49f05a0d7bce562c1cbcff9eeec04" translate="yes" xml:space="preserve">
          <source>Function Calls</source>
          <target state="translated">関数呼び出し</target>
        </trans-unit>
        <trans-unit id="7c7552936b2d7609f5d81c59359e027294ef0188" translate="yes" xml:space="preserve">
          <source>Function is called as the entrypoint of the spawned process. This function must be defined at the top level of a module so it can be pickled and spawned. This is a requirement imposed by multiprocessing.</source>
          <target state="translated">関数は、スポーンされたプロセスの入り口として呼び出されます。この関数は、モジュールの最上位レベルで定義されていなければならないので、ピクルスしてスポーンさせることができます。これはマルチプロセッシングによって課せられた要件です。</target>
        </trans-unit>
        <trans-unit id="57608b0f76e1461b0dd084a18f9c93c533b79732" translate="yes" xml:space="preserve">
          <source>Function that computes the Hessian of a given scalar function.</source>
          <target state="translated">与えられたスカラー関数のヘシアンを計算する関数.</target>
        </trans-unit>
        <trans-unit id="de45ff60cbfde5e2d453e6ab4052dd57e579a406" translate="yes" xml:space="preserve">
          <source>Function that computes the Jacobian of a given function.</source>
          <target state="translated">与えられた関数のヤコビアンを計算する関数.</target>
        </trans-unit>
        <trans-unit id="53e89b5d2efea7a989526e66020381aa4e865a00" translate="yes" xml:space="preserve">
          <source>Function that computes the dot product between a vector &lt;code&gt;v&lt;/code&gt; and the Hessian of a given scalar function at the point given by the inputs.</source>
          <target state="translated">入力によって与えられた点で、ベクトル &lt;code&gt;v&lt;/code&gt; と与えられたスカラー関数のヘッセ行列の間の内積を計算する関数。</target>
        </trans-unit>
        <trans-unit id="287af51397c51f28570adbfd1523afcb4677415b" translate="yes" xml:space="preserve">
          <source>Function that computes the dot product between a vector &lt;code&gt;v&lt;/code&gt; and the Jacobian of the given function at the point given by the inputs.</source>
          <target state="translated">入力によって与えられた点で与えられた関数のベクトル &lt;code&gt;v&lt;/code&gt; とヤコビアンの間の内積を計算する関数。</target>
        </trans-unit>
        <trans-unit id="db56d8ae51d7ef133b6d7037c14d1d0f86dcbafc" translate="yes" xml:space="preserve">
          <source>Function that computes the dot product between the Hessian of a given scalar function and a vector &lt;code&gt;v&lt;/code&gt; at the point given by the inputs.</source>
          <target state="translated">与えられたスカラー関数のヘッセ行列と入力によって与えられた点でのベクトル &lt;code&gt;v&lt;/code&gt; の間の内積を計算する関数。</target>
        </trans-unit>
        <trans-unit id="62c588612b56212caded208831fd6675991af83c" translate="yes" xml:space="preserve">
          <source>Function that computes the dot product between the Jacobian of the given function at the point given by the inputs and a vector &lt;code&gt;v&lt;/code&gt;.</source>
          <target state="translated">入力によって与えられた点で与えられた関数のヤコビアンとベクトル &lt;code&gt;v&lt;/code&gt; の間の内積を計算する関数。</target>
        </trans-unit>
        <trans-unit id="6eb78f68900c241e14e0ca55cb63779b55624f2b" translate="yes" xml:space="preserve">
          <source>Function that measures Binary Cross Entropy between target and output logits.</source>
          <target state="translated">目標ロジットと出力ロジット間のバイナリクロスエントロピーを測定する関数です。</target>
        </trans-unit>
        <trans-unit id="7648ef7c5f8c3df8793ee3a78cea755f5210492d" translate="yes" xml:space="preserve">
          <source>Function that measures the Binary Cross Entropy between the target and the output.</source>
          <target state="translated">ターゲットと出力間のバイナリクロスエントロピーを測定する関数です。</target>
        </trans-unit>
        <trans-unit id="9ffd252ff27f5e82a15818c0d16b964ae35b7608" translate="yes" xml:space="preserve">
          <source>Function that returns True when in compilation and False otherwise. This is useful especially with the @unused decorator to leave code in your model that is not yet TorchScript compatible. .. testcode:</source>
          <target state="translated">コンパイル時にTrueを返し、そうでなければFalseを返す関数です。これは特に @unused デコレータを使って、TorchScript と互換性のないコードをモデルに残しておくのに便利です。...testcode。</target>
        </trans-unit>
        <trans-unit id="4f7128796586951f3b8d4c12bad19a0f376bcf68" translate="yes" xml:space="preserve">
          <source>Function that takes the mean element-wise absolute value difference.</source>
          <target state="translated">要素間の平均値絶対値差を取る関数。</target>
        </trans-unit>
        <trans-unit id="092441d339641c913a709b12bd8927bee99f6a19" translate="yes" xml:space="preserve">
          <source>Function that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.</source>
          <target state="translated">要素間誤差の絶対値がベータ値を下回った場合に二乗項を使用し、それ以外の場合にはL1項を使用する関数です。</target>
        </trans-unit>
        <trans-unit id="e285c73ee5b2c775ccf90093dc413f8d49580952" translate="yes" xml:space="preserve">
          <source>Function to draw a sequence of &lt;code&gt;n&lt;/code&gt; points from a Sobol sequence. Note that the samples are dependent on the previous samples. The size of the result is</source>
          <target state="translated">ソボル列から &lt;code&gt;n&lt;/code&gt; 点の列を描く関数。サンプルは前のサンプルに依存していることに注意してください。結果のサイズは</target>
        </trans-unit>
        <trans-unit id="54711e443d02794b60e7868b9b77738a8238e18e" translate="yes" xml:space="preserve">
          <source>Function to fast-forward the state of the &lt;code&gt;SobolEngine&lt;/code&gt; by &lt;code&gt;n&lt;/code&gt; steps. This is equivalent to drawing &lt;code&gt;n&lt;/code&gt; samples without using the samples.</source>
          <target state="translated">早送りする機能の状態 &lt;code&gt;SobolEngine&lt;/code&gt; により、 &lt;code&gt;n&lt;/code&gt; 個のステップ。これは、サンプルを使用せずに &lt;code&gt;n&lt;/code&gt; 個のサンプルを描画することと同じです。</target>
        </trans-unit>
        <trans-unit id="ef0c07b5cc0a1093381723476ea2c34106682639" translate="yes" xml:space="preserve">
          <source>Function to reset the &lt;code&gt;SobolEngine&lt;/code&gt; to base state.</source>
          <target state="translated">&lt;code&gt;SobolEngine&lt;/code&gt; を基本状態にリセットする機能。</target>
        </trans-unit>
        <trans-unit id="27655b57b5b53e117874eb4514d19d44a2fa2f28" translate="yes" xml:space="preserve">
          <source>Functional higher level API</source>
          <target state="translated">機能的に上位レベルのAPI</target>
        </trans-unit>
        <trans-unit id="f4400d33370b62a4424c92ac993690b6bf723355" translate="yes" xml:space="preserve">
          <source>Functional interface</source>
          <target state="translated">機能的なインターフェイス</target>
        </trans-unit>
        <trans-unit id="c75f6c5a3a8ea37a3aa2ef8f8e4a53197661b6a7" translate="yes" xml:space="preserve">
          <source>Functional interface (quantized).</source>
          <target state="translated">機能的なインターフェース(量子化)。</target>
        </trans-unit>
        <trans-unit id="c6f96173e459065a4f35775c868cf69352b58eaa" translate="yes" xml:space="preserve">
          <source>Functionally equivalent to a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, but represents a single function and does not have any attributes or Parameters.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;と機能的に同等ですが、単一の関数を表し、属性やパラメーターはありません。</target>
        </trans-unit>
        <trans-unit id="1f72e9d093d3406e36decddb7c64c8207dc32272" translate="yes" xml:space="preserve">
          <source>Functionally equivalent to a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, but represents a single function and does not have any attributes or Parameters.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;と機能的に同等ですが、単一の関数を表し、属性やパラメーターはありません。</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="5bab26ebb87fa09b2599a41edb42c2be419cbfdb" translate="yes" xml:space="preserve">
          <source>Functions don&amp;rsquo;t change much, they can be decorated with &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;torch.jit.unused&lt;/code&gt;&lt;/a&gt; if needed.</source>
          <target state="translated">関数はあまり変更されません。必要に応じて、&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;torch.jit.unused&lt;/code&gt; で&lt;/a&gt;装飾できます。</target>
        </trans-unit>
        <trans-unit id="f08615c088136953c00202fd041b9b4df5e1dfea" translate="yes" xml:space="preserve">
          <source>Furthermore, if the &lt;code&gt;functions&lt;/code&gt; argument is supplied, bindings will be automatically generated for each function specified. &lt;code&gt;functions&lt;/code&gt; can either be a list of function names, or a dictionary mapping from function names to docstrings. If a list is given, the name of each function is used as its docstring.</source>
          <target state="translated">さらに、 &lt;code&gt;functions&lt;/code&gt; 引数が指定されている場合、指定された関数ごとにバインディングが自動的に生成されます。 &lt;code&gt;functions&lt;/code&gt; は、関数名のリスト、または関数名からdocstringへの辞書マッピングのいずれかです。リストが指定されている場合、各関数の名前がそのdocstringとして使用されます。</target>
        </trans-unit>
        <trans-unit id="5bace8a23b9deebac72cffe4881dc6eed9968755" translate="yes" xml:space="preserve">
          <source>Furthermore, the outputs are scaled by a factor of</source>
          <target state="translated">さらに、出力は</target>
        </trans-unit>
        <trans-unit id="7bd79f69d6d1d8bfef4415bc3f9876396d21f772" translate="yes" xml:space="preserve">
          <source>Fuses a list of modules into a single module</source>
          <target state="translated">モジュールのリストを1つのモジュールに統合します。</target>
        </trans-unit>
        <trans-unit id="936c5a8bd4c7984ab29544b2ca2086d83494e60f" translate="yes" xml:space="preserve">
          <source>Fuses only the following sequence of modules: conv, bn conv, bn, relu conv, relu linear, relu bn, relu All other sequences are left unchanged. For these sequences, replaces the first item in the list with the fused module, replacing the rest of the modules with identity.</source>
          <target state="translated">以下のモジュールのシーケンスのみを融合します:conv,bn conv,bn,relu conv,relu linear,relu bn,relu 他のシーケンスはすべて変更されません。これらのシーケンスについては、リストの最初の項目を融合されたモジュールに置き換え、残りのモジュールを同一性に置き換えます。</target>
        </trans-unit>
        <trans-unit id="5f71e96ba4fcb977ab1e675f428bf9d148fa7baf" translate="yes" xml:space="preserve">
          <source>GELU</source>
          <target state="translated">GELU</target>
        </trans-unit>
        <trans-unit id="1f9ad9bc561d09f2f445363cf93033cdd6037e9c" translate="yes" xml:space="preserve">
          <source>GLU</source>
          <target state="translated">GLU</target>
        </trans-unit>
        <trans-unit id="a6a6318544c9b361fc08c6ed94696c4d207d2748" translate="yes" xml:space="preserve">
          <source>GPU</source>
          <target state="translated">GPU</target>
        </trans-unit>
        <trans-unit id="954c88d52c93dd19e22542fcb20c7d583f7b8447" translate="yes" xml:space="preserve">
          <source>GPU hosts with Ethernet interconnect</source>
          <target state="translated">イーサネット相互接続のGPUホスト</target>
        </trans-unit>
        <trans-unit id="9238bee4212524d967f1550988f8d590152434a1" translate="yes" xml:space="preserve">
          <source>GPU hosts with InfiniBand interconnect</source>
          <target state="translated">InfiniBandインターコネクトを搭載したGPUホスト</target>
        </trans-unit>
        <trans-unit id="2b56fffb35167d283f21ccca2d0bc8fbd0a6fe43" translate="yes" xml:space="preserve">
          <source>GPU tensor</source>
          <target state="translated">GPUテンソル</target>
        </trans-unit>
        <trans-unit id="51c6274e38d61ebd2c2aa1fabf4fb11564b93c03" translate="yes" xml:space="preserve">
          <source>GRU</source>
          <target state="translated">GRU</target>
        </trans-unit>
        <trans-unit id="1e29d48c3333cba171b9e878119cbab38e34e4a1" translate="yes" xml:space="preserve">
          <source>GRUCell</source>
          <target state="translated">GRUCell</target>
        </trans-unit>
        <trans-unit id="cba508b12182b68f501d6af46c4f03f8fc5d2473" translate="yes" xml:space="preserve">
          <source>Gamma</source>
          <target state="translated">Gamma</target>
        </trans-unit>
        <trans-unit id="473631bf9e98f3b45650e597635bf741c36747b6" translate="yes" xml:space="preserve">
          <source>Gathers a list of tensors in a single process.</source>
          <target state="translated">1回の処理でテンソルのリストを収集します。</target>
        </trans-unit>
        <trans-unit id="bd67c5035db82b529f60e273fb31bc01d939b7bc" translate="yes" xml:space="preserve">
          <source>Gathers tensors from multiple GPU devices.</source>
          <target state="translated">複数のGPUデバイスからテンソルを収集します。</target>
        </trans-unit>
        <trans-unit id="dfd7c23593ebd41b22c549217d736ad6cbc14502" translate="yes" xml:space="preserve">
          <source>Gathers tensors from the whole group in a list.</source>
          <target state="translated">グループ全体からテンソルをリストに集めます。</target>
        </trans-unit>
        <trans-unit id="a033b46254c69591de655bd57283ab1b1f241ecf" translate="yes" xml:space="preserve">
          <source>Gathers tensors from the whole group in a list. Each tensor in &lt;code&gt;tensor_list&lt;/code&gt; should reside on a separate GPU</source>
          <target state="translated">グループ全体からテンソルをリストに収集します。 &lt;code&gt;tensor_list&lt;/code&gt; の各テンソルは別々のGPUに存在する必要があります</target>
        </trans-unit>
        <trans-unit id="d1ed345e7cd127b4f17c3621e8381fb806d9f267" translate="yes" xml:space="preserve">
          <source>Gathers values along an axis specified by &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; で指定された軸に沿って値を収集します。</target>
        </trans-unit>
        <trans-unit id="83e2e53da9f325087f4bce1c008f1d1192e058ed" translate="yes" xml:space="preserve">
          <source>Generally speaking, input to this function should contain values following conjugate symmetry. Note that even if &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, often symmetry on some part is still needed. When this requirement is not satisfied, the behavior of &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; is undefined. Since &lt;a href=&quot;../autograd#torch.autograd.gradcheck&quot;&gt;&lt;code&gt;torch.autograd.gradcheck()&lt;/code&gt;&lt;/a&gt; estimates numerical Jacobian with point perturbations, &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; will almost certainly fail the check.</source>
          <target state="translated">一般的に、この関数への入力には、共役対称に従う値が含まれている必要があります。 &lt;code&gt;onesided&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; であっても、一部の対称性が必要になる場合が多いことに注意してください。この要件が満たされない場合、&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; の&lt;/a&gt;動作は未定義です。&lt;a href=&quot;../autograd#torch.autograd.gradcheck&quot;&gt; &lt;code&gt;torch.autograd.gradcheck()&lt;/code&gt; &lt;/a&gt;は点摂動を&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;数値ヤコビアンを推定するため、irfft（）はほぼ確実にチェックに失敗します。</target>
        </trans-unit>
        <trans-unit id="925a95fee15d092ef688c243751df4f4117845d7" translate="yes" xml:space="preserve">
          <source>Generate a square mask for the sequence. The masked positions are filled with float(&amp;lsquo;-inf&amp;rsquo;). Unmasked positions are filled with float(0.0).</source>
          <target state="translated">シーケンスの正方形のマスクを生成します。マスクされた位置はfloat（ '-inf'）で埋められます。マスクされていない位置はfloat（0.0）で埋められます。</target>
        </trans-unit>
        <trans-unit id="05e4b9ca24a152cc1be23c09ff6368077d47b2b3" translate="yes" xml:space="preserve">
          <source>Generates a 2D or 3D flow field (sampling grid), given a batch of affine matrices &lt;code&gt;theta&lt;/code&gt;.</source>
          <target state="translated">アフィン行列 &lt;code&gt;theta&lt;/code&gt; バッチが与えられると、2Dまたは3Dフローフィールド（サンプリンググリッド）を生成します。</target>
        </trans-unit>
        <trans-unit id="535a8bdc4a8b5e249e51bb72f3ff867e269f10d8" translate="yes" xml:space="preserve">
          <source>Generates a Vandermonde matrix.</source>
          <target state="translated">Vandermonde行列を生成します。</target>
        </trans-unit>
        <trans-unit id="a86ef66b9f9c0d2af98ab49a15285f8bd20e1d42" translate="yes" xml:space="preserve">
          <source>Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples if the distribution parameters are batched.</source>
          <target state="translated">分布パラメータがバッチ化されている場合は,sample_shape形状の再パラメータ化されたサンプル,またはsample_shape形状の再パラメータ化されたサンプルのバッチを生成します.</target>
        </trans-unit>
        <trans-unit id="526c10ebcc2b4397308215e12b1bd4ed9189b980" translate="yes" xml:space="preserve">
          <source>Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples if the distribution parameters are batched. Samples first from base distribution and applies &lt;code&gt;transform()&lt;/code&gt; for every transform in the list.</source>
          <target state="translated">分布パラメーターがバッチ処理されている場合は、sample_shape形状の再パラメーター化されたサンプルまたはsample_shape形状の再パラメーター化されたサンプルのバッチを生成します。最初に基本分布からサンプリングし、リスト内のすべての変換に &lt;code&gt;transform()&lt;/code&gt; を適用します。</target>
        </trans-unit>
        <trans-unit id="15364dfe6049d908ff11f7465e040686a232a300" translate="yes" xml:space="preserve">
          <source>Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.</source>
          <target state="translated">分布パラメータがバッチ化されている場合は、sample_shape形状のサンプルまたはsample_shape形状のサンプルのバッチを生成します。</target>
        </trans-unit>
        <trans-unit id="581df05069d7c712c7a78fa21e0f7b76f4e89392" translate="yes" xml:space="preserve">
          <source>Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched. Samples first from base distribution and applies &lt;code&gt;transform()&lt;/code&gt; for every transform in the list.</source>
          <target state="translated">分布パラメーターがバッチ処理されている場合は、sample_shape形状のサンプルまたはsample_shape形状のサンプルのバッチを生成します。最初に基本分布からサンプリングし、リスト内のすべての変換に &lt;code&gt;transform()&lt;/code&gt; を適用します。</target>
        </trans-unit>
        <trans-unit id="b4909d3090c22e034c883a55c3857c6b650fef97" translate="yes" xml:space="preserve">
          <source>Generates n samples or n batches of samples if the distribution parameters are batched.</source>
          <target state="translated">分布パラメータがバッチ化されている場合は、n個のサンプルまたはn個のサンプルのバッチを生成します。</target>
        </trans-unit>
        <trans-unit id="63b4637c6c6f7165bea01744025dd36ab607c841" translate="yes" xml:space="preserve">
          <source>Generates uniformly distributed random samples from the half-open interval &lt;code&gt;[low, high)&lt;/code&gt;.</source>
          <target state="translated">半開区間 &lt;code&gt;[low, high)&lt;/code&gt; から一様分布のランダムサンプルを生成します。</target>
        </trans-unit>
        <trans-unit id="1d20de03126b297e05c13a7d280f33e24c72c537" translate="yes" xml:space="preserve">
          <source>Generator</source>
          <target state="translated">Generator</target>
        </trans-unit>
        <trans-unit id="009c08ccefb98d44d31c65421a4320ecc2bb6f65" translate="yes" xml:space="preserve">
          <source>Generator.device -&amp;gt; device</source>
          <target state="translated">Generator.device-&amp;gt;デバイス</target>
        </trans-unit>
        <trans-unit id="a3e705cc61a19f33d7c9c030f107a70569966485" translate="yes" xml:space="preserve">
          <source>Generators</source>
          <target state="translated">Generators</target>
        </trans-unit>
        <trans-unit id="80dadd86173d0ff3979257793d4e45beb238b6a2" translate="yes" xml:space="preserve">
          <source>Generics</source>
          <target state="translated">Generics</target>
        </trans-unit>
        <trans-unit id="50911697822f06c09ce3f706d64281d2991753b3" translate="yes" xml:space="preserve">
          <source>Geometric</source>
          <target state="translated">Geometric</target>
        </trans-unit>
        <trans-unit id="43ac4a1c9cd4df862c76bc8567278e105813907d" translate="yes" xml:space="preserve">
          <source>Get &lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; of a given worker name. Use this &lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; to avoid passing an expensive string on every invocation.</source>
          <target state="translated">指定されたワーカー名の&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt; &lt;code&gt;WorkerInfo&lt;/code&gt; &lt;/a&gt;を取得します。この&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt; &lt;code&gt;WorkerInfo&lt;/code&gt; &lt;/a&gt;を使用して、すべての呼び出しで高価な文字列を渡さないようにします。</target>
        </trans-unit>
        <trans-unit id="41265238a92192e4ad5f6debaeb489d9d1f1c823" translate="yes" xml:space="preserve">
          <source>Get the Torch Hub cache directory used for storing downloaded models &amp;amp; weights.</source>
          <target state="translated">ダウンロードしたモデルと重みを保存するために使用されるトーチハブキャッシュディレクトリを取得します。</target>
        </trans-unit>
        <trans-unit id="31e03005a5c777fa579a5d2e380424ed9ca0b4c8" translate="yes" xml:space="preserve">
          <source>Get the current default floating point &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">現在のデフォルトの浮動小数点&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; を&lt;/a&gt;取得します。</target>
        </trans-unit>
        <trans-unit id="b8610c06d92827723a75fd0f1cce98077b3a70ce" translate="yes" xml:space="preserve">
          <source>Get the current default floating point &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">現在のデフォルトの浮動小数点&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; を&lt;/a&gt;取得します。</target>
        </trans-unit>
        <trans-unit id="5aca0eb2fa5dfc1cb36d36748698ea752a002636" translate="yes" xml:space="preserve">
          <source>Get the include paths required to build a C++ or CUDA extension.</source>
          <target state="translated">C++または CUDA 拡張モジュールの構築に必要なインクルードパスを取得します。</target>
        </trans-unit>
        <trans-unit id="8c5303d4517efbd9f11eb88c60066d56bc4690f4" translate="yes" xml:space="preserve">
          <source>Get the k-th diagonal of a given matrix:</source>
          <target state="translated">与えられた行列の k 番目の対角線を求めます.</target>
        </trans-unit>
        <trans-unit id="d8e48ff0538ba6cbffe42300fa9158799c05f336" translate="yes" xml:space="preserve">
          <source>Get the square matrix where the input vector is the diagonal:</source>
          <target state="translated">入力ベクトルを対角線とする正方行列を取得します。</target>
        </trans-unit>
        <trans-unit id="c3d9b9988129bd858a97b5e5dca9086f55e31cf1" translate="yes" xml:space="preserve">
          <source>Gets a non-deterministic random number from std::random_device or the current time and uses it to seed a Generator.</source>
          <target state="translated">std::random_device または現在の時刻から非決定論的な乱数を取得し、ジェネレータのシードに使用します。</target>
        </trans-unit>
        <trans-unit id="16cb932f5f31cf2818eda6bf06d30c94768bb98a" translate="yes" xml:space="preserve">
          <source>Gets the cuda capability of a device.</source>
          <target state="translated">デバイスのキューダ能力を取得します。</target>
        </trans-unit>
        <trans-unit id="8c370c58908a07f2882a626fa97d9bcfd7bd61c5" translate="yes" xml:space="preserve">
          <source>Gets the current device of the generator.</source>
          <target state="translated">発電機の電流デバイスを取得します。</target>
        </trans-unit>
        <trans-unit id="b9be3fb15dfe408dead8b567c5693ec335fb2ec0" translate="yes" xml:space="preserve">
          <source>Gets the name of a device.</source>
          <target state="translated">デバイスの名前を取得します。</target>
        </trans-unit>
        <trans-unit id="6a2e241a18985fac466002399c13c581b746dc24" translate="yes" xml:space="preserve">
          <source>Getting started with Distributed RPC Framework</source>
          <target state="translated">分散RPCフレームワークを使い始める</target>
        </trans-unit>
        <trans-unit id="c7e10d3aed3a471005914064e3e561dd9fce7d89" translate="yes" xml:space="preserve">
          <source>Given a 3-D tensor and reduction using the multiplication operation, &lt;code&gt;self&lt;/code&gt; is updated as:</source>
          <target state="translated">3次元テンソルと乗算演算を使用した縮小が与えられると、 &lt;code&gt;self&lt;/code&gt; は次のように更新されます。</target>
        </trans-unit>
        <trans-unit id="cd7589a87267ad50da5e4440a08034e70102a4b2" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer. It has the number of elements that matches the corresponding dimensions (from q_per_channel_axis) of the tensor.</source>
          <target state="translated">線形(アフィン)パーチャンネル量子化によって量子化されたテンソルが与えられた場合,基礎となる量子化器のスケールのテンソルを返します.テンソルの対応する次元(q_per_channel_axisから)に一致する要素数を持ちます。</target>
        </trans-unit>
        <trans-unit id="9a7e24af56b75cfda37479a07ba5602027c1c762" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer. It has the number of elements that matches the corresponding dimensions (from q_per_channel_axis) of the tensor.</source>
          <target state="translated">線形(アフィン)パーチャンネル量子化によって量子化されたテンソルが与えられた場合,基礎となる量子化器のゼロ点のテンソルを返します.テンソルの対応する次元(q_per_channel_axisから)に一致する要素数を持ちます。</target>
        </trans-unit>
        <trans-unit id="2ca023eeaa09e79566843e7d6c6a44e41c5d8038" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied.</source>
          <target state="translated">線形(アフィン)パーチャネル量子化によって量子化されたテンソルが与えられた場合,パーチャネル量子化が適用される次元のインデックスを返します.</target>
        </trans-unit>
        <trans-unit id="488568401d49cd08f3be08869dd3fbd14d9e5113" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer().</source>
          <target state="translated">線形(アフィン)量子化によって量子化されたテンソルが与えられた場合、その下にある量子化器()のスケールを返します。</target>
        </trans-unit>
        <trans-unit id="70ceca1da9acd2d4b46a6674c2ea2f823b1ff770" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer().</source>
          <target state="translated">線形(アフィン)量子化によって量子化されたテンソルが与えられた場合、その下にある量子化器()のゼロ点を返します。</target>
        </trans-unit>
        <trans-unit id="90c7e80a6051c57ef51f03a4a57294f2d936927c" translate="yes" xml:space="preserve">
          <source>Given a list of quantized Tensors, dequantize them and return a list of fp32 Tensors</source>
          <target state="translated">量子化されたテンソルのリストが与えられると,それらを量子化解除して,fp32テンソルのリストを返します.</target>
        </trans-unit>
        <trans-unit id="275d4783ccc8a12c168de20cf782230c04ee1b4f" translate="yes" xml:space="preserve">
          <source>Given a quantized Tensor, &lt;code&gt;self.int_repr()&lt;/code&gt; returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor.</source>
          <target state="translated">量子化されたテンソルが与えられると、 &lt;code&gt;self.int_repr()&lt;/code&gt; は、与えられたテンソルの基礎となるuint8_t値を格納するデータ型としてuint8_tを持つCPUテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a07592b05f2ffe420d78857907dc0a868ad8e9ba" translate="yes" xml:space="preserve">
          <source>Given a quantized Tensor, dequantize it and return the dequantized float Tensor.</source>
          <target state="translated">量子化されたTensorが与えられると、それを量子化解除して、量子化解除されたfloatのTensorを返します。</target>
        </trans-unit>
        <trans-unit id="df67c816ade50221be71f968c55c25fc9c22abad" translate="yes" xml:space="preserve">
          <source>Given an &lt;code&gt;input&lt;/code&gt; and a flow-field &lt;code&gt;grid&lt;/code&gt;, computes the &lt;code&gt;output&lt;/code&gt; using &lt;code&gt;input&lt;/code&gt; values and pixel locations from &lt;code&gt;grid&lt;/code&gt;.</source>
          <target state="translated">与えられた &lt;code&gt;input&lt;/code&gt; フローフィールド &lt;code&gt;grid&lt;/code&gt; 、演算 &lt;code&gt;output&lt;/code&gt; 使用して &lt;code&gt;input&lt;/code&gt; 値とからピクセル位置 &lt;code&gt;grid&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="993de1cd9d3c83efc214190a94f213ab60dcb670" translate="yes" xml:space="preserve">
          <source>Given running min/max as</source>
          <target state="translated">として与えられたランニングの最小値/最大値</target>
        </trans-unit>
        <trans-unit id="1edda6e755754d8aedb4972c3cf98f079bb5938f" translate="yes" xml:space="preserve">
          <source>Given the legs of a right triangle, return its hypotenuse.</source>
          <target state="translated">直角三角形の脚が与えられたとき、その下辺を返します。</target>
        </trans-unit>
        <trans-unit id="2507bf0b60a0a2f4a957fa33007787504bb4d58f" translate="yes" xml:space="preserve">
          <source>Gives us the following diagnostic information:</source>
          <target state="translated">以下の診断情報を提供してくれます。</target>
        </trans-unit>
        <trans-unit id="d4b28b75d3d71965ffab4c160557a8512917b298" translate="yes" xml:space="preserve">
          <source>Globally prunes tensors corresponding to all parameters in &lt;code&gt;parameters&lt;/code&gt; by applying the specified &lt;code&gt;pruning_method&lt;/code&gt;.</source>
          <target state="translated">グローバルのすべてのパラメータに対応するテンソルプルーニング &lt;code&gt;parameters&lt;/code&gt; 指定された適用することにより、 &lt;code&gt;pruning_method&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="5b2d596c770a42eb120b6d78a8d729e895cf8f96" translate="yes" xml:space="preserve">
          <source>Globally prunes tensors corresponding to all parameters in &lt;code&gt;parameters&lt;/code&gt; by applying the specified &lt;code&gt;pruning_method&lt;/code&gt;. Modifies modules in place by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">グローバルのすべてのパラメータに対応するテンソルプルーニング &lt;code&gt;parameters&lt;/code&gt; 指定された適用することにより、 &lt;code&gt;pruning_method&lt;/code&gt; を。次の方法でモジュールを変更します。1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加します。2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="1c964494fd83a4fa2353af497be43d7d3c6b7430" translate="yes" xml:space="preserve">
          <source>Globally unique id to identify the worker.</source>
          <target state="translated">ワーカーを識別するためのグローバルに一意な ID。</target>
        </trans-unit>
        <trans-unit id="2dd8834e4e85debb567290745d3b3e1efdcd0e5d" translate="yes" xml:space="preserve">
          <source>Gloo has been hardened by years of extensive use in PyTorch and is thus very reliable. However, as it was designed to perform collective communication, it may not always be the best fit for RPC. For example, each networking operation is synchronous and blocking, which means that it cannot be run in parallel with others. Moreover, it opens a connection between all pairs of nodes, and brings down all of them when one fails, thus reducing the resiliency and the elasticity of the system.</source>
          <target state="translated">GlooはPyTorchでの長年の使用によって強化されているため、非常に信頼性が高いです。しかし、集団通信を行うために設計されているため、必ずしもRPCに最適とは限りません。例えば、各ネットワーキング操作は同期的でブロッキングされているため、他の操作と並行して実行することができません。さらに、すべてのペアのノード間で接続を開き、1つが故障するとすべてのノードをダウンさせてしまうため、システムの回復力や弾力性が低下してしまいます。</target>
        </trans-unit>
        <trans-unit id="0493f8c5c9a4c1e6227e147f0649196be2a0314a" translate="yes" xml:space="preserve">
          <source>GoogLeNet</source>
          <target state="translated">GoogLeNet</target>
        </trans-unit>
        <trans-unit id="07ad0c4f37a421022704ed36cdcbf7e981dfe5e6" translate="yes" xml:space="preserve">
          <source>GoogLeNet (Inception v1) model architecture from &lt;a href=&quot;http://arxiv.org/abs/1409.4842&quot;&gt;&amp;ldquo;Going Deeper with Convolutions&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://arxiv.org/abs/1409.4842&quot;&gt;「畳み込みでより深くなる」の&lt;/a&gt;GoogLeNet（Inception v1）モデルアーキテクチャ。</target>
        </trans-unit>
        <trans-unit id="a46ca2c8e8067233adba7afe56ba3ef36ef0ac6c" translate="yes" xml:space="preserve">
          <source>GoogleNet</source>
          <target state="translated">GoogleNet</target>
        </trans-unit>
        <trans-unit id="ede11b2557f474a2c7b9c843b53bc7eb91dcac40" translate="yes" xml:space="preserve">
          <source>Gradient Scaling</source>
          <target state="translated">グラデーションのスケーリング</target>
        </trans-unit>
        <trans-unit id="6ff674c26d399b6074c452be450688d5b72da6db" translate="yes" xml:space="preserve">
          <source>Gradients are modified in-place.</source>
          <target state="translated">グラデーションはその場で修正されます。</target>
        </trans-unit>
        <trans-unit id="51f814ea6f476134875113c78aa4479584c4db98" translate="yes" xml:space="preserve">
          <source>Graphs can be inspected as shown to confirm that the computation described by a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; is correct, in both automated and manual fashion, as described below.</source>
          <target state="translated">グラフは、以下に説明するように、自動および手動の両方の方法で、&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;によって記述された計算が正しいことを確認するために示されているように検査できます。</target>
        </trans-unit>
        <trans-unit id="db56247cfffad115bd03a34895c4144a2f602e2a" translate="yes" xml:space="preserve">
          <source>GroupNorm</source>
          <target state="translated">GroupNorm</target>
        </trans-unit>
        <trans-unit id="ae9629f4ebb82c6331c0809fa9a0e54b00e578e6" translate="yes" xml:space="preserve">
          <source>Groups</source>
          <target state="translated">Groups</target>
        </trans-unit>
        <trans-unit id="28391105a9b17b63b7212f323d98a19b7d728841" translate="yes" xml:space="preserve">
          <source>Gumbel</source>
          <target state="translated">Gumbel</target>
        </trans-unit>
        <trans-unit id="7cf184f4c67ad58283ecb19349720b0cae756829" translate="yes" xml:space="preserve">
          <source>H</source>
          <target state="translated">H</target>
        </trans-unit>
        <trans-unit id="e19beadee3375715c817358699b6b6b7c3b1c276" translate="yes" xml:space="preserve">
          <source>H=\text{embedding\_dim}</source>
          <target state="translated">H=\text{embedding\_dim}</target>
        </trans-unit>
        <trans-unit id="0daac27dde551de614ce1f8b22990869e521a767" translate="yes" xml:space="preserve">
          <source>H_{all}=\text{num\_directions} * \text{hidden\_size}</source>
          <target state="translated">H_{all}=Text{num_directions}*\text{hidden_size}.</target>
        </trans-unit>
        <trans-unit id="5af2c1c42a9e7cbeea8d0ef376277c241943a820" translate="yes" xml:space="preserve">
          <source>H_{in1}=\text{in1\_features}</source>
          <target state="translated">H_{in1}=\text{in1\_features}</target>
        </trans-unit>
        <trans-unit id="553b3def323fb898bbf5a634729bc342796f0364" translate="yes" xml:space="preserve">
          <source>H_{in2}=\text{in2\_features}</source>
          <target state="translated">H_{in2}=\text{in2\_features}</target>
        </trans-unit>
        <trans-unit id="3bcb97c0c827228e3e76ce7ff65ced7d17f29099" translate="yes" xml:space="preserve">
          <source>H_{in}</source>
          <target state="translated">H_{in}</target>
        </trans-unit>
        <trans-unit id="208ac84ce5aa93dcc05f3ab66b20dc1d3775c246" translate="yes" xml:space="preserve">
          <source>H_{in} = \text{in\_features}</source>
          <target state="translated">H_{in}=ﾃｷｽﾄ{in_features}</target>
        </trans-unit>
        <trans-unit id="699846905d49c5bcf7b21460adb78513ef80b2fb" translate="yes" xml:space="preserve">
          <source>H_{in}=\text{input\_size}</source>
          <target state="translated">H_{in}=\text{input\_size}</target>
        </trans-unit>
        <trans-unit id="7530e9ad4c2fb5dd91aaec26c4ecbcf1a3a5ae05" translate="yes" xml:space="preserve">
          <source>H_{out}</source>
          <target state="translated">H_{out}</target>
        </trans-unit>
        <trans-unit id="29b7895de890ff23af55e3b18083accf3b3c9504" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}</source>
          <target state="translated">H_{out}=(H_{in}-1)♪ ♪times \times</target>
        </trans-unit>
        <trans-unit id="2ab9363dd5f0a667cae76fffcb24249e4641e2c1" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}</source>
          <target state="translated">H_{out}=(H_{in}-1)♪ ♪times \times</target>
        </trans-unit>
        <trans-unit id="eb1e8745c8404aa0257819793650f55ce47e4a32" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1</source>
          <target state="translated">H_{out}=(H_{in}-1)♪times \times ﾃｷｽﾄ{stride}[0]-2 \times ﾃｷｽﾄ{padding}[0]+\times (text{kernel_size}[0]-1)+\times (text{output\_padding}[0]+1)</target>
        </trans-unit>
        <trans-unit id="18b0ad397dc5e56655f52d98246617aead364a80" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{kernel\_size}[0]</source>
          <target state="translated">H_{out}=(H_{in}-1)♪times \times ﾃｷｽﾄ{stride}[0]-2 \times ﾃｷｽﾄ{padding}[0]+\times ﾃｷｽﾄ{kernel_size}[0]</target>
        </trans-unit>
        <trans-unit id="79c01a18bf062cd324b81ee63feda955b8a67b5e" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="092f027e0b0b6c6ccdb35d8eefd3fbd19f119f52" translate="yes" xml:space="preserve">
          <source>H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}</source>
          <target state="translated">H_{out}=H_{in}+\text{padding_top}+\text{padding_bottom}.</target>
        </trans-unit>
        <trans-unit id="42cf8f4ab52d42aa9e4d4c9b75634fb9ef976615" translate="yes" xml:space="preserve">
          <source>H_{out} = H_{in} \times \text{upscale\_factor}</source>
          <target state="translated">H_{out}=H_{in}\times text{upscale_factor}.</target>
        </trans-unit>
        <trans-unit id="be48d8fe2e8d0b5e7eb05cfe3a720b22ad1fddb5" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor</source>
          <target state="translated">H_{out}=ﾚﾌﾄの\lfloor H_{in}ﾄｲﾒｰｼﾞ</target>
        </trans-unit>
        <trans-unit id="2df9cd2b82eb2979d700977c589d82b892fd325a" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]} \times (\text{kernel\_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+2*\times (Text{kernel_size[0]}-1)-1}{Text{stride[0]}}+1\rightrfloor</target>
        </trans-unit>
        <trans-unit id="475e8a255144af15d34931776b25e492a4505dc7" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+≪H_{in}≫+2 \times ≪Text{padding}[0]-≪Text{dilation}[0]≫ ≫ ≪Times (Text{kernel_size}[0]]-1)-1}{Text{stride}[0]}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="017fc26768fffbdc1fef6a9416fcdd78e1cd6d94" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+2 \times ≪Text{padding}[0]-≪Text{kernel_size}[0]}≪Text{stride}[0]}≫+1 Right\rfloor</target>
        </trans-unit>
        <trans-unit id="d6788aaadc5cc718ef1733396e3d48f7aa8bc1e1" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+≪H_{in}≫+2 \times ≪Text{padding}[1]-≪Text{dilation}[1]≫ ➡ ➡ ≪Text{kernel_size}[1][1]-1)+1}{Text{stride}[1]}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="7eddc94bad71df818c92fb147993424e6e6351b5" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}+2 \times ≪Text{padding}[1]-≪Text{kernel_size}[1]}≪Text{stride}[1]}+1 Right\rfloor</target>
        </trans-unit>
        <trans-unit id="fea56e0b8cb35cbb479b336782329a86326003b9" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} - \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫-≪H_{in}≫-≪H_{in}≫+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="563db076821ec71bea9cecf69cd0383ccd26729e" translate="yes" xml:space="preserve">
          <source>H_{out} = \text{out\_features}</source>
          <target state="translated">H_{out}=ﾃｷｽﾄ{out_features}</target>
        </trans-unit>
        <trans-unit id="4a917c5666fd0c869393621972c028e97e193eb0" translate="yes" xml:space="preserve">
          <source>H_{out}=\text{hidden\_size}</source>
          <target state="translated">H_{out}=\text{hidden\_size}</target>
        </trans-unit>
        <trans-unit id="baeaafcb89405e03dc701698426b69d67220a62d" translate="yes" xml:space="preserve">
          <source>H_{out}=\text{out\_features}</source>
          <target state="translated">H_{out}=\text{out\_features}</target>
        </trans-unit>
        <trans-unit id="e3b87872ef89415e5807523e9374221302af4a0e" translate="yes" xml:space="preserve">
          <source>HalfCauchy</source>
          <target state="translated">HalfCauchy</target>
        </trans-unit>
        <trans-unit id="4fe2e4918ad02d73bac15c6c080f73da0de6891d" translate="yes" xml:space="preserve">
          <source>HalfNormal</source>
          <target state="translated">HalfNormal</target>
        </trans-unit>
        <trans-unit id="593e90ae43cc7b6082dfac4b6d583f5426501c8b" translate="yes" xml:space="preserve">
          <source>Hamming window function.</source>
          <target state="translated">ハミングウィンドウ機能。</target>
        </trans-unit>
        <trans-unit id="69d7b15573065426b9ad5d17655afb90ef85c68f" translate="yes" xml:space="preserve">
          <source>Hann window function.</source>
          <target state="translated">ハン窓機能。</target>
        </trans-unit>
        <trans-unit id="9deb0b051207a937d2c2524ee2d17196f4c7e2ae" translate="yes" xml:space="preserve">
          <source>HardShrink</source>
          <target state="translated">HardShrink</target>
        </trans-unit>
        <trans-unit id="a1d971d31da1fbc25ba44171ebf839ffcca3d2d9" translate="yes" xml:space="preserve">
          <source>HardTanh</source>
          <target state="translated">HardTanh</target>
        </trans-unit>
        <trans-unit id="c9c68b0024efc57340d60b6a9fea397c5c6ea7cf" translate="yes" xml:space="preserve">
          <source>HardTanh is defined as:</source>
          <target state="translated">HardTanhとは、以下のように定義されています。</target>
        </trans-unit>
        <trans-unit id="b2d44614503eb1489dff12f9f7cd6893be6f2de6" translate="yes" xml:space="preserve">
          <source>Hardshrink</source>
          <target state="translated">Hardshrink</target>
        </trans-unit>
        <trans-unit id="6da2cabc8d832449dfd76781dd5cab3e0527d812" translate="yes" xml:space="preserve">
          <source>Hardsigmoid</source>
          <target state="translated">Hardsigmoid</target>
        </trans-unit>
        <trans-unit id="34e8d8510ac49404bdd474758f835c671f823a90" translate="yes" xml:space="preserve">
          <source>Hardswish</source>
          <target state="translated">Hardswish</target>
        </trans-unit>
        <trans-unit id="c5343dec88b0ad5e872efa7466247b124ae44911" translate="yes" xml:space="preserve">
          <source>Hardtanh</source>
          <target state="translated">Hardtanh</target>
        </trans-unit>
        <trans-unit id="0698ac1b047809947767285ae1c3db0b44a90c83" translate="yes" xml:space="preserve">
          <source>Helper decorator for &lt;code&gt;forward&lt;/code&gt; methods of custom autograd functions (subclasses of &lt;a href=&quot;autograd#torch.autograd.Function&quot;&gt;&lt;code&gt;torch.autograd.Function&lt;/code&gt;&lt;/a&gt;). See the &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-custom-examples&quot;&gt;example page&lt;/a&gt; for more detail.</source>
          <target state="translated">カスタムautograd関数（&lt;a href=&quot;autograd#torch.autograd.Function&quot;&gt; &lt;code&gt;torch.autograd.Function&lt;/code&gt; の&lt;/a&gt;サブクラス）の &lt;code&gt;forward&lt;/code&gt; メソッドのヘルパーデコレータ。詳細については&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-custom-examples&quot;&gt;、サンプルページ&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="862f59a03aa723c79d215e788d02145626feeb93" translate="yes" xml:space="preserve">
          <source>Helper decorator for backward methods of custom autograd functions (subclasses of &lt;a href=&quot;autograd#torch.autograd.Function&quot;&gt;&lt;code&gt;torch.autograd.Function&lt;/code&gt;&lt;/a&gt;). Ensures that &lt;code&gt;backward&lt;/code&gt; executes with the same autocast state as &lt;code&gt;forward&lt;/code&gt;. See the &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-custom-examples&quot;&gt;example page&lt;/a&gt; for more detail.</source>
          <target state="translated">カスタムautograd関数（&lt;a href=&quot;autograd#torch.autograd.Function&quot;&gt; &lt;code&gt;torch.autograd.Function&lt;/code&gt; の&lt;/a&gt;サブクラス）の後方メソッドのヘルパーデコレータ。 &lt;code&gt;forward&lt;/code&gt; と同じ自動キャスト状態で &lt;code&gt;backward&lt;/code&gt; 実行されるようにします。詳細については&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/amp_examples.html#amp-custom-examples&quot;&gt;、サンプルページ&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="e2828b0734fec8e5d21a67190b498444f3d1d6ac" translate="yes" xml:space="preserve">
          <source>Helper function to convert all &lt;code&gt;BatchNorm*D&lt;/code&gt; layers in the model to &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt;&lt;/a&gt; layers.</source>
          <target state="translated">モデル内のすべての &lt;code&gt;BatchNorm*D&lt;/code&gt; レイヤーを&lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt; &lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt; &lt;/a&gt;レイヤーに変換するヘルパー関数。</target>
        </trans-unit>
        <trans-unit id="ecbcb0e424c40d9931c2c7c8b44c33c5f4e12465" translate="yes" xml:space="preserve">
          <source>Here</source>
          <target state="translated">Here</target>
        </trans-unit>
        <trans-unit id="2bcc88cec50d653f641638296cdbe26d969f54b5" translate="yes" xml:space="preserve">
          <source>Here are the summary of the accuracies for the models trained on the instances set of COCO train2017 and evaluated on COCO val2017.</source>
          <target state="translated">COCO train2017のインスタンスセットで学習したモデルとCOCO val2017で評価したモデルの精度をまとめてみました。</target>
        </trans-unit>
        <trans-unit id="dab4abc36186b02c3f92677e0eb34f60ea19ee65" translate="yes" xml:space="preserve">
          <source>Here are the ways to call &lt;code&gt;to&lt;/code&gt;:</source>
          <target state="translated">ここでコールする方法があります &lt;code&gt;to&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="445a6f9d83de6be3e9c47cd5d94f26ed51643163" translate="yes" xml:space="preserve">
          <source>Here is a code snippet specifies an entrypoint for &lt;code&gt;resnet18&lt;/code&gt; model if we expand the implementation in &lt;code&gt;pytorch/vision/hubconf.py&lt;/code&gt;. In most case importing the right function in &lt;code&gt;hubconf.py&lt;/code&gt; is sufficient. Here we just want to use the expanded version as an example to show how it works. You can see the full script in &lt;a href=&quot;https://github.com/pytorch/vision/blob/master/hubconf.py&quot;&gt;pytorch/vision repo&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;pytorch/vision/hubconf.py&lt;/code&gt; 実装を拡張した場合の &lt;code&gt;resnet18&lt;/code&gt; モデルのエントリポイントを指定するコードスニペットを次に示します。ほとんどの場合、 &lt;code&gt;hubconf.py&lt;/code&gt; に適切な関数をインポートするだけで十分です。ここでは、拡張バージョンを例として使用して、それがどのように機能するかを示します。完全なスクリプトは&lt;a href=&quot;https://github.com/pytorch/vision/blob/master/hubconf.py&quot;&gt;pytorch / visionリポジトリ&lt;/a&gt;で確認できます</target>
        </trans-unit>
        <trans-unit id="ae7bbf97b180351dca19b9329b791cc507f2b072" translate="yes" xml:space="preserve">
          <source>Here is a simple script which exports a pretrained AlexNet as defined in torchvision into ONNX. It runs a single round of inference and then saves the resulting traced model to &lt;code&gt;alexnet.onnx&lt;/code&gt;:</source>
          <target state="translated">これは、トーチビジョンで定義された事前トレーニング済みのAlexNetをONNXにエクスポートする簡単なスクリプトです。1回の推論を実行し、結果のトレースされたモデルを &lt;code&gt;alexnet.onnx&lt;/code&gt; に保存します。</target>
        </trans-unit>
        <trans-unit id="92287b24e3387d7af034be3a29ae6b7bb430d9be" translate="yes" xml:space="preserve">
          <source>Here is an example of handling missing symbolic function for &lt;code&gt;elu&lt;/code&gt; operator. We try to export the model and see the error message as below:</source>
          <target state="translated">これは、 &lt;code&gt;elu&lt;/code&gt; 演算子の欠落しているシンボリック関数を処理する例です。モデルをエクスポートしようとすると、次のようなエラーメッセージが表示されます。</target>
        </trans-unit>
        <trans-unit id="e2d985f7b3554227167f11444cb5f1733937d03c" translate="yes" xml:space="preserve">
          <source>Here is another &lt;a href=&quot;https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html&quot;&gt;tutorial of exporting the SuperResolution model to ONNX.&lt;/a&gt;.</source>
          <target state="translated">これは&lt;a href=&quot;https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html&quot;&gt;、SuperResolutionモデルをONNXにエクスポートする&lt;/a&gt;別のチュートリアルです。。</target>
        </trans-unit>
        <trans-unit id="3314513abe3b45daef540f3d273944cf3438114e" translate="yes" xml:space="preserve">
          <source>Here the model &lt;code&gt;model&lt;/code&gt; can be an arbitrary &lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt;&lt;code&gt;torch.nn.Module&lt;/code&gt;&lt;/a&gt; object. &lt;code&gt;swa_model&lt;/code&gt; will keep track of the running averages of the parameters of the &lt;code&gt;model&lt;/code&gt;. To update these averages, you can use the &lt;code&gt;update_parameters()&lt;/code&gt; function:</source>
          <target state="translated">ここで、モデル &lt;code&gt;model&lt;/code&gt; は任意の&lt;a href=&quot;generated/torch.nn.module#torch.nn.Module&quot;&gt; &lt;code&gt;torch.nn.Module&lt;/code&gt; &lt;/a&gt;オブジェクトにすることができます。 &lt;code&gt;swa_model&lt;/code&gt; は、 &lt;code&gt;model&lt;/code&gt; パラメーターの移動平均を追跡します。これらの平均を更新するには、 &lt;code&gt;update_parameters()&lt;/code&gt; 関数を使用できます。</target>
        </trans-unit>
        <trans-unit id="fd181c7eb29dc3b0fda6e46bc8cb566ca4c818d9" translate="yes" xml:space="preserve">
          <source>Hessian (Tensor or a tuple of tuple of Tensors) if there are a single input,</source>
          <target state="translated">入力が1つの場合はヘシアン(テンソルまたはテンソルのタプル)。</target>
        </trans-unit>
        <trans-unit id="3d3237992ce2b8eaf6bc76469f46fd9b7ad4ba34" translate="yes" xml:space="preserve">
          <source>HingeEmbeddingLoss</source>
          <target state="translated">HingeEmbeddingLoss</target>
        </trans-unit>
        <trans-unit id="144dc3699fae1cc6bf638916541c8cf0248b5ad0" translate="yes" xml:space="preserve">
          <source>Histogram represented as a tensor</source>
          <target state="translated">テンソルで表されるヒストグラム</target>
        </trans-unit>
        <trans-unit id="6abad81420de9ddfe06289f2d7475110d726e0f7" translate="yes" xml:space="preserve">
          <source>Holds parameters in a dictionary.</source>
          <target state="translated">辞書にパラメータを保持します。</target>
        </trans-unit>
        <trans-unit id="5b433389b7ec9270f0a561a21e07b6fafe96e6b4" translate="yes" xml:space="preserve">
          <source>Holds parameters in a list.</source>
          <target state="translated">パラメータをリストに保持します。</target>
        </trans-unit>
        <trans-unit id="57c99ed1c82d3f1f9d82887040191b4b4abeeaa4" translate="yes" xml:space="preserve">
          <source>Holds submodules in a dictionary.</source>
          <target state="translated">辞書にサブモジュールを保持します。</target>
        </trans-unit>
        <trans-unit id="26eb2ae7fc8977e64bf6bd3cc41f59552193cc67" translate="yes" xml:space="preserve">
          <source>Holds submodules in a list.</source>
          <target state="translated">サブモジュールをリストに保持します。</target>
        </trans-unit>
        <trans-unit id="e7b0c97307f7d5f337291cd7806994ff8fc4ef93" translate="yes" xml:space="preserve">
          <source>Holds the data and list of &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt;&lt;code&gt;batch_sizes&lt;/code&gt;&lt;/a&gt; of a packed sequence.</source>
          <target state="translated">パックされたシーケンスの&lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt; &lt;code&gt;batch_sizes&lt;/code&gt; の&lt;/a&gt;データとリストを保持します。</target>
        </trans-unit>
        <trans-unit id="8419c96872dc0338c3c6bf4230e67b362cd3efd6" translate="yes" xml:space="preserve">
          <source>Holds the data and list of &lt;code&gt;batch_sizes&lt;/code&gt; of a packed sequence.</source>
          <target state="translated">パックされたシーケンスの &lt;code&gt;batch_sizes&lt;/code&gt; のデータとリストを保持します。</target>
        </trans-unit>
        <trans-unit id="0153f88746391d4a3323f9debd32f41ab51f78cf" translate="yes" xml:space="preserve">
          <source>Host to GPU copies are much faster when they originate from pinned (page-locked) memory. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-pinning&quot;&gt;Use pinned memory buffers&lt;/a&gt; for more details on when and how to use pinned memory generally.</source>
          <target state="translated">ホストからGPUへのコピーは、固定された（ページロックされた）メモリから発信された場合、はるかに高速になります。固定メモリを一般的に使用するタイミングと方法の詳細については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-memory-pinning&quot;&gt;固定メモリバッファの使用を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="63507ce15285f9aea8a61982f77258d3225e1e12" translate="yes" xml:space="preserve">
          <source>How to adjust learning rate</source>
          <target state="translated">学習率の調整方法</target>
        </trans-unit>
        <trans-unit id="94d972a8a1e2dd3bfc19dfa88cfbe55c7c0c3689" translate="yes" xml:space="preserve">
          <source>How to implement an entrypoint?</source>
          <target state="translated">エントリポイントを実装するには?</target>
        </trans-unit>
        <trans-unit id="b1304bfd1ec08ee66df1618b8642dc42d805bfa0" translate="yes" xml:space="preserve">
          <source>How to use an optimizer</source>
          <target state="translated">オプティマイザーの使い方</target>
        </trans-unit>
        <trans-unit id="6310012cefe177ccf7e96e77a31017e3653da608" translate="yes" xml:space="preserve">
          <source>However the following will error when caching due to dependency reversal:</source>
          <target state="translated">しかし、以下のような場合は、依存関係の反転によるキャッシュを行うとエラーになります。</target>
        </trans-unit>
        <trans-unit id="25a9b274bc53945b3703ea4d8441695a628a5f50" translate="yes" xml:space="preserve">
          <source>However, &lt;a href=&quot;#torch.nn.EmbeddingBag&quot;&gt;&lt;code&gt;EmbeddingBag&lt;/code&gt;&lt;/a&gt; is much more time and memory efficient than using a chain of these operations.</source>
          <target state="translated">However, &lt;a href=&quot;#torch.nn.EmbeddingBag&quot;&gt; &lt;code&gt;EmbeddingBag&lt;/code&gt; &lt;/a&gt; is much more time and memory efficient than using a chain of these operations.</target>
        </trans-unit>
        <trans-unit id="0911b09b4e58b715dde3450d0531ebe9129437bf" translate="yes" xml:space="preserve">
          <source>However, &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt;&lt;code&gt;batch_sizes&lt;/code&gt;&lt;/a&gt; should always be a CPU &lt;code&gt;torch.int64&lt;/code&gt; tensor.</source>
          <target state="translated">However, &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt; &lt;code&gt;batch_sizes&lt;/code&gt; &lt;/a&gt; should always be a CPU &lt;code&gt;torch.int64&lt;/code&gt; tensor.</target>
        </trans-unit>
        <trans-unit id="8db3600da518c9e30c26a5157e4e57a0a03f2dc3" translate="yes" xml:space="preserve">
          <source>However, if sharding results in multiple workers having incomplete last batches, this estimate can still be inaccurate, because (1) an otherwise complete batch can be broken into multiple ones and (2) more than one batch worth of samples can be dropped when &lt;code&gt;drop_last&lt;/code&gt; is set. Unfortunately, PyTorch can not detect such cases in general.</source>
          <target state="translated">ただし、シャーディングによって複数のワーカーの最後のバッチが不完全になった場合でも、この見積もりは不正確になる可能性があります。これは、（1）そうでなければ完全なバッチが複数のバッチに分割され、（2） &lt;code&gt;drop_last&lt;/code&gt; 時に複数のバッチに相当するサンプルがドロップされる可能性があるためです。が設定されます。残念ながら、PyTorchは一般的にそのようなケースを検出できません。</target>
        </trans-unit>
        <trans-unit id="ca73ab65568cd125c2d27a22bbd9e863c10b675d" translate="yes" xml:space="preserve">
          <source>I</source>
          <target state="translated">I</target>
        </trans-unit>
        <trans-unit id="17be3fac04b9eb29173ba1517552ac97aa85e862" translate="yes" xml:space="preserve">
          <source>I. M. Sobol. The distribution of points in a cube and the accurate evaluation of integrals. Zh. Vychisl. Mat. i Mat. Phys., 7:784-802, 1967.</source>
          <target state="translated">I.M.ソボル 立方体の点の分布と積分の正確な評価。ヴイシズル.Vychisl.因みに,この研究では,このような問題を解決するための方法を検討している。物理学,7:784-802,1967.</target>
        </trans-unit>
        <trans-unit id="c3eeaff2d8f8be416c4b7ba0cc9972581ba73c12" translate="yes" xml:space="preserve">
          <source>INDICES WITH CORRESPONDING NAMES:</source>
          <target state="translated">呼応する名前を持つ指標。</target>
        </trans-unit>
        <trans-unit id="7e5a975b6add84fd53e3710a9ceac15eb06663b7" translate="yes" xml:space="preserve">
          <source>Identity</source>
          <target state="translated">Identity</target>
        </trans-unit>
        <trans-unit id="751c68a3471b1c791efaee0a8e7c24ea0c266efd" translate="yes" xml:space="preserve">
          <source>If</source>
          <target state="translated">If</target>
        </trans-unit>
        <trans-unit id="632018a30643b60c95c40b0734c7a40ff76a740f" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; is 1D with length-&lt;code&gt;K&lt;/code&gt;, each element is the relative probability of sampling the class at that index.</source>
          <target state="translated">場合&lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt; &lt;code&gt;probs&lt;/code&gt; &lt;/a&gt;長さ-と1Dである &lt;code&gt;K&lt;/code&gt; 、各要素は、そのインデックスにクラスをサンプリングする相対的確率です。</target>
        </trans-unit>
        <trans-unit id="0fbd2b7cbc8dbe46ae9eba9716b0dcf6af626a55" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt;&lt;code&gt;probs&lt;/code&gt;&lt;/a&gt; is 2D, it is treated as a batch of relative probability vectors.</source>
          <target state="translated">場合&lt;a href=&quot;#torch.distributions.categorical.Categorical.probs&quot;&gt; &lt;code&gt;probs&lt;/code&gt; &lt;/a&gt;2Dである、それは相対的確率ベクトルのバッチとして処理されます。</target>
        </trans-unit>
        <trans-unit id="e876238e2103f6c99bd92bbd23268dffc89d5e98" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#torch.hub.set_dir&quot;&gt;&lt;code&gt;set_dir()&lt;/code&gt;&lt;/a&gt; is not called, default path is &lt;code&gt;$TORCH_HOME/hub&lt;/code&gt; where environment variable &lt;code&gt;$TORCH_HOME&lt;/code&gt; defaults to &lt;code&gt;$XDG_CACHE_HOME/torch&lt;/code&gt;. &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt; follows the X Design Group specification of the Linux filesystem layout, with a default value &lt;code&gt;~/.cache&lt;/code&gt; if the environment variable is not set.</source>
          <target state="translated">If &lt;a href=&quot;#torch.hub.set_dir&quot;&gt; &lt;code&gt;set_dir()&lt;/code&gt; &lt;/a&gt; is not called, default path is &lt;code&gt;$TORCH_HOME/hub&lt;/code&gt; where environment variable &lt;code&gt;$TORCH_HOME&lt;/code&gt; defaults to &lt;code&gt;$XDG_CACHE_HOME/torch&lt;/code&gt; . &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt; follows the X Design Group specification of the Linux filesystem layout, with a default value &lt;code&gt;~/.cache&lt;/code&gt; if the environment variable is not set.</target>
        </trans-unit>
        <trans-unit id="2365a78f9c70fd188f67372dcb4ead5e46155be1" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; &amp;gt; 0, it is above the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; &amp;gt; 0, it is above the main diagonal.</target>
        </trans-unit>
        <trans-unit id="3b581ac7d1874578962f7ebaf7dd7355265bfcb4" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; &amp;lt; 0, it is below the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; &amp;lt; 0, it is below the main diagonal.</target>
        </trans-unit>
        <trans-unit id="d93aaba0d391e746ad390a6373a6f9bdbe62d27c" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; = 0, it is the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; = 0, it is the main diagonal.</target>
        </trans-unit>
        <trans-unit id="a1496c02b09e4951bc82bcd52564a0a26f1a0976" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;(h_0, c_0)&lt;/code&gt; is not provided, both &lt;strong&gt;h_0&lt;/strong&gt; and &lt;strong&gt;c_0&lt;/strong&gt; default to zero.</source>
          <target state="translated">If &lt;code&gt;(h_0, c_0)&lt;/code&gt; is not provided, both &lt;strong&gt;h_0&lt;/strong&gt; and &lt;strong&gt;c_0&lt;/strong&gt; default to zero.</target>
        </trans-unit>
        <trans-unit id="db361da536d20a314407fbca9d9b4b9534c18d89" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;Model&lt;/code&gt; is instantiated it will result in a compilation error since the compiler doesn&amp;rsquo;t know about &lt;code&gt;x&lt;/code&gt;. There are 4 ways to inform the compiler of attributes on &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">If &lt;code&gt;Model&lt;/code&gt; is instantiated it will result in a compilation error since the compiler doesn&amp;rsquo;t know about &lt;code&gt;x&lt;/code&gt; . There are 4 ways to inform the compiler of attributes on &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="5fde3f46b9d751a46e85953fec7714aa67e2342e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the elements in &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; are added to &lt;code&gt;self&lt;/code&gt;. If accumulate is &lt;code&gt;False&lt;/code&gt;, the behavior is undefined if indices contain duplicate elements.</source>
          <target state="translated">If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the elements in &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; are added to &lt;code&gt;self&lt;/code&gt; . If accumulate is &lt;code&gt;False&lt;/code&gt; , the behavior is undefined if indices contain duplicate elements.</target>
        </trans-unit>
        <trans-unit id="2201c7c6a621b0e5c67fe66d2f987b652400f785" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the elements in &lt;code&gt;value&lt;/code&gt; are added to &lt;code&gt;self&lt;/code&gt;. If accumulate is &lt;code&gt;False&lt;/code&gt;, the behavior is undefined if indices contain duplicate elements.</source>
          <target state="translated">If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the elements in &lt;code&gt;value&lt;/code&gt; are added to &lt;code&gt;self&lt;/code&gt; . If accumulate is &lt;code&gt;False&lt;/code&gt; , the behavior is undefined if indices contain duplicate elements.</target>
        </trans-unit>
        <trans-unit id="989ae399047ba12cf5c5c1ad5cbe5e9842000a8a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the output tensor containing indices. If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, one 1-D tensor for each dimension, containing the indices of each nonzero element along that dimension.</source>
          <target state="translated">If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the output tensor containing indices. If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , one 1-D tensor for each dimension, containing the indices of each nonzero element along that dimension.</target>
        </trans-unit>
        <trans-unit id="42d4ccb0a610720c59f54cf25fbe1940e041af3d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch1&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;batch1&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="f6f5f33da7723c89d0774922372d006d60d5610a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;beta&lt;/code&gt; is 0, then &lt;code&gt;input&lt;/code&gt; will be ignored, and &lt;code&gt;nan&lt;/code&gt; and &lt;code&gt;inf&lt;/code&gt; in it will not be propagated.</source>
          <target state="translated">If &lt;code&gt;beta&lt;/code&gt; is 0, then &lt;code&gt;input&lt;/code&gt; will be ignored, and &lt;code&gt;nan&lt;/code&gt; and &lt;code&gt;inf&lt;/code&gt; in it will not be propagated.</target>
        </trans-unit>
        <trans-unit id="dc51e352774290d1926f402524b258eb4db4275e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), &lt;code&gt;input&lt;/code&gt; will be padded on both sides so that the</source>
          <target state="translated">If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), &lt;code&gt;input&lt;/code&gt; will be padded on both sides so that the</target>
        </trans-unit>
        <trans-unit id="965719376b6d5fe07ada3da22176f7f46b7ed555" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then there will be padding e.g. &lt;code&gt;'constant'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, etc. Left padding can be trimmed off exactly because they can be calculated but right padding cannot be calculated without additional information.</source>
          <target state="translated">If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then there will be padding e.g. &lt;code&gt;'constant'&lt;/code&gt; , &lt;code&gt;'reflect'&lt;/code&gt; , etc. Left padding can be trimmed off exactly because they can be calculated but right padding cannot be calculated without additional information.</target>
        </trans-unit>
        <trans-unit id="fc14ae1693b0f07d578cbfe76b09c86688e0df82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will be zero matrices of shape</source>
          <target state="translated">If &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will be zero matrices of shape</target>
        </trans-unit>
        <trans-unit id="8b121802d7ccc1f4651e3f4251de10bedc8ca4f7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;create_graph=False&lt;/code&gt;, &lt;code&gt;backward()&lt;/code&gt; accumulates into &lt;code&gt;.grad&lt;/code&gt; in-place, which preserves its strides.</source>
          <target state="translated">&lt;code&gt;create_graph=False&lt;/code&gt; の場合、 &lt;code&gt;backward()&lt;/code&gt; はインプレースで &lt;code&gt;.grad&lt;/code&gt; に蓄積され、そのストライドが保持されます。</target>
        </trans-unit>
        <trans-unit id="653e8379ac4a0083fba63e656d38b6380a7d066b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;create_graph=True&lt;/code&gt;, &lt;code&gt;backward()&lt;/code&gt; replaces &lt;code&gt;.grad&lt;/code&gt; with a new tensor &lt;code&gt;.grad + new grad&lt;/code&gt;, which attempts (but does not guarantee) matching the preexisting &lt;code&gt;.grad&lt;/code&gt;&amp;rsquo;s strides.</source>
          <target state="translated">&lt;code&gt;create_graph=True&lt;/code&gt; の場合、 &lt;code&gt;backward()&lt;/code&gt; は &lt;code&gt;.grad&lt;/code&gt; を新しいテンソル &lt;code&gt;.grad + new grad&lt;/code&gt; に置き換えます。これは、既存の &lt;code&gt;.grad&lt;/code&gt; のストライドとの一致を試みます（ただし、保証はしません）。</target>
        </trans-unit>
        <trans-unit id="65b33918f4984ada2bac2f4ee54a2728e16bb872" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;descending&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the elements are sorted in descending order by value.</source>
          <target state="translated">If &lt;code&gt;descending&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the elements are sorted in descending order by value.</target>
        </trans-unit>
        <trans-unit id="f30e67b5addf429de66048f84b97eb2d56624113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dim&lt;/code&gt; is not given, it defaults to the first dimension found with the size 3. Note that this might be unexpected.</source>
          <target state="translated">If &lt;code&gt;dim&lt;/code&gt; is not given, it defaults to the first dimension found with the size 3. Note that this might be unexpected.</target>
        </trans-unit>
        <trans-unit id="e52a79087756b4493bd3fe7986958f5739aaef82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dim&lt;/code&gt; is not given, the last dimension of the &lt;code&gt;input&lt;/code&gt; is chosen.</source>
          <target state="translated">If &lt;code&gt;dim&lt;/code&gt; is not given, the last dimension of the &lt;code&gt;input&lt;/code&gt; is chosen.</target>
        </trans-unit>
        <trans-unit id="ffe3df3fa3b821e3480cebbf887d0692dbdcfbb2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; or &lt;code&gt;forward&lt;/code&gt; of &lt;code&gt;nn.Module&lt;/code&gt;, &lt;code&gt;trace&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. The returned &lt;code&gt;ScriptModule&lt;/code&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt;. If &lt;code&gt;func&lt;/code&gt; is a standalone function, &lt;code&gt;trace&lt;/code&gt; returns &lt;code&gt;ScriptFunction&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; or &lt;code&gt;forward&lt;/code&gt; of &lt;code&gt;nn.Module&lt;/code&gt; , &lt;code&gt;trace&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. The returned &lt;code&gt;ScriptModule&lt;/code&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt; . If &lt;code&gt;func&lt;/code&gt; is a standalone function, &lt;code&gt;trace&lt;/code&gt; returns &lt;code&gt;ScriptFunction&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="12f27a06f15ef646d5a97006314eddc5168ac16a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;function&lt;/code&gt; invocation during backward does anything different than the one during forward, e.g., due to some global variable, the checkpointed version won&amp;rsquo;t be equivalent, and unfortunately it can&amp;rsquo;t be detected.</source>
          <target state="translated">If &lt;code&gt;function&lt;/code&gt; invocation during backward does anything different than the one during forward, e.g., due to some global variable, the checkpointed version won&amp;rsquo;t be equivalent, and unfortunately it can&amp;rsquo;t be detected.</target>
        </trans-unit>
        <trans-unit id="7fc30718c6826ba4f06aa25c6aae50a9ac61ea27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;grid&lt;/code&gt; has values outside the range of &lt;code&gt;[-1, 1]&lt;/code&gt;, the corresponding outputs are handled as defined by &lt;code&gt;padding_mode&lt;/code&gt;. Options are</source>
          <target state="translated">If &lt;code&gt;grid&lt;/code&gt; has values outside the range of &lt;code&gt;[-1, 1]&lt;/code&gt; , the corresponding outputs are handled as defined by &lt;code&gt;padding_mode&lt;/code&gt; . Options are</target>
        </trans-unit>
        <trans-unit id="56cdf52769f875d95bfc8ef6e8310ccf2d0ab6ef" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;hop_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;hop_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a42f5f55bf046653a704f6db77ba0e3241e7e2f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; has</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; has</target>
        </trans-unit>
        <trans-unit id="b713735765f53d252a6982eaad4ca993659b98bf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; has zero determinant, this returns &lt;code&gt;(0, -inf)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; has zero determinant, this returns &lt;code&gt;(0, -inf)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e500b7aaaa41be4614fc8206c1a0e4e07b1a2886" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is 1D of shape &lt;code&gt;(N)&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is 1D of shape &lt;code&gt;(N)&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="06376d4d271f3b9dcf5c2b5b33c61831ac5086a5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is 2D of shape &lt;code&gt;(B, N)&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is 2D of shape &lt;code&gt;(B, N)&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="d721dee0fdf912ec6fe02d3c521f5fb3cf097977" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="333f1219fe75814d72dd2dbd93db4f7d9396ef8a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="63f74a4f9eae20a71d7f307933ef2802201be33d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a matrix with &lt;code&gt;m&lt;/code&gt; rows, &lt;code&gt;out&lt;/code&gt; is an matrix of shape</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a matrix with &lt;code&gt;m&lt;/code&gt; rows, &lt;code&gt;out&lt;/code&gt; is an matrix of shape</target>
        </trans-unit>
        <trans-unit id="27b6ec31f1f65b3c25640d5370bad846221e8b75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a tensor with more than one dimension, then returns a 2-D tensor with diagonal elements equal to a flattened &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a tensor with more than one dimension, then returns a 2-D tensor with diagonal elements equal to a flattened &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="40b5681668244b650aeff8654a98b80d07f3df6a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor</target>
        </trans-unit>
        <trans-unit id="35915a3eb4d935ad3d429e632e78a9274b0c797a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor with the elements of &lt;code&gt;input&lt;/code&gt; as the diagonal.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor with the elements of &lt;code&gt;input&lt;/code&gt; as the diagonal.</target>
        </trans-unit>
        <trans-unit id="ad879c1e17f47008543d08a003ad2cbc09fcfa1b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector, &lt;code&gt;out&lt;/code&gt; is a vector of size &lt;code&gt;num_samples&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector, &lt;code&gt;out&lt;/code&gt; is a vector of size &lt;code&gt;num_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5b37263956a979da36ed328c86d1f8d5bafac1ea" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is an n-dimensional tensor with size</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is an n-dimensional tensor with size</target>
        </trans-unit>
        <trans-unit id="f77fab43f2855d468661a78ecf375280629b91c9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, &lt;code&gt;other&lt;/code&gt; should be a real number, otherwise it should be an integer</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , &lt;code&gt;other&lt;/code&gt; should be a real number, otherwise it should be an integer</target>
        </trans-unit>
        <trans-unit id="59214511303529b73d11d23823eff1c49a8f295c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; should be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , &lt;code&gt;value&lt;/code&gt; should be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="7935f4c92d76a69f5c3018eeffd91bc6bda0cd48" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, args &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt; must be real numbers, otherwise they should be integers.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , args &lt;a href=&quot;torch.min#torch.min&quot;&gt; &lt;code&gt;min&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt; &lt;code&gt;max&lt;/code&gt; &lt;/a&gt; must be real numbers, otherwise they should be integers.</target>
        </trans-unit>
        <trans-unit id="74011e63fd6b8669cda7c1001070f1e13f3cf86f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;other&lt;/code&gt; must be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;other&lt;/code&gt; must be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="fd07eaa51527d175519a582a0f6f85c473a1308f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, returns the loaded PyTorch extension as a Python module. If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; returns nothing (the shared library is loaded into the process as a side effect).</source>
          <target state="translated">If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , returns the loaded PyTorch extension as a Python module. If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; returns nothing (the shared library is loaded into the process as a side effect).</target>
        </trans-unit>
        <trans-unit id="150898b85fa40ffdbf63d6a8c5f8e7d9b416ba17" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim is ``True`&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt;), resulting in the output tensors having fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim is ``True`&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt; ), resulting in the output tensors having fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8dfb26e902cefe829de7730f64927f442131d727" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors are the same size as &lt;code&gt;input&lt;/code&gt;, except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors having 1 fewer dimension than the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors are the same size as &lt;code&gt;input&lt;/code&gt; , except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors having 1 fewer dimension than the &lt;code&gt;input&lt;/code&gt; tensor.</target>
        </trans-unit>
        <trans-unit id="4eef57842bb23530ec99ef24c142564e33a57efb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output dimensions are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimensions being reduced (&lt;code&gt;dim&lt;/code&gt; or all if &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;) where they have size 1. Otherwise, the dimensions being reduced are squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;). If &lt;code&gt;q&lt;/code&gt; is a 1D tensor, an extra dimension is prepended to the output tensor with the same size as &lt;code&gt;q&lt;/code&gt; which represents the quantiles.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output dimensions are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimensions being reduced ( &lt;code&gt;dim&lt;/code&gt; or all if &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; ) where they have size 1. Otherwise, the dimensions being reduced are squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;). If &lt;code&gt;q&lt;/code&gt; is a 1D tensor, an extra dimension is prepended to the output tensor with the same size as &lt;code&gt;q&lt;/code&gt; which represents the quantiles.</target>
        </trans-unit>
        <trans-unit id="8af1f9e4f1fca763580351e3fbd0001f54ae795e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="71fae5aef8701d9d46f893cd636d6b67ec5e6aab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5a9d71d5cbb1ac9891b1a744240b0f98bb2945c1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 (or &lt;code&gt;len(dim)&lt;/code&gt;) fewer dimension(s).</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 (or &lt;code&gt;len(dim)&lt;/code&gt; ) fewer dimension(s).</target>
        </trans-unit>
        <trans-unit id="7c2f11e03ffcd1caa4f43b25af60e0e5bd33899d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensors having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensors having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="21c9748f09f2547a22882ea8c179fcab7d38a94c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the outputs tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the outputs tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fd1cd26edf38a8fdee9967389f0e6dac29ec3c27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt;), resulting in the output tensors having fewer dimensions than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt; ), resulting in the output tensors having fewer dimensions than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a5f40df338bf2f9f730257d36666627ccd6548fc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;dilation&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1, their values will be replicated across all spatial dimensions.</source>
          <target state="translated">If &lt;code&gt;kernel_size&lt;/code&gt; , &lt;code&gt;dilation&lt;/code&gt; , &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1, their values will be replicated across all spatial dimensions.</target>
        </trans-unit>
        <trans-unit id="55b84dbfa8c62b3f0cac777d20c854c0409394ae" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;largest&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the &lt;code&gt;k&lt;/code&gt; smallest elements are returned.</source>
          <target state="translated">If &lt;code&gt;largest&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the &lt;code&gt;k&lt;/code&gt; smallest elements are returned.</target>
        </trans-unit>
        <trans-unit id="fa798f0a6b2f55ce7a633ab807b16e5f24185685" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;map_location&lt;/code&gt; is a &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; object or a string containing a device tag, it indicates the location where all tensors should be loaded.</source>
          <target state="translated">If &lt;code&gt;map_location&lt;/code&gt; is a &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt; object or a string containing a device tag, it indicates the location where all tensors should be loaded.</target>
        </trans-unit>
        <trans-unit id="048f95b6581ac17eb4c969ed9d078d249d78f4f2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;map_location&lt;/code&gt; is a callable, it will be called once for each serialized storage with two arguments: storage and location. The storage argument will be the initial deserialization of the storage, residing on the CPU. Each serialized storage has a location tag associated with it which identifies the device it was saved from, and this tag is the second argument passed to &lt;code&gt;map_location&lt;/code&gt;. The builtin location tags are &lt;code&gt;'cpu'&lt;/code&gt; for CPU tensors and &lt;code&gt;'cuda:device_id'&lt;/code&gt; (e.g. &lt;code&gt;'cuda:2'&lt;/code&gt;) for CUDA tensors. &lt;code&gt;map_location&lt;/code&gt; should return either &lt;code&gt;None&lt;/code&gt; or a storage. If &lt;code&gt;map_location&lt;/code&gt; returns a storage, it will be used as the final deserialized object, already moved to the right device. Otherwise, &lt;a href=&quot;#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt; will fall back to the default behavior, as if &lt;code&gt;map_location&lt;/code&gt; wasn&amp;rsquo;t specified.</source>
          <target state="translated">If &lt;code&gt;map_location&lt;/code&gt; is a callable, it will be called once for each serialized storage with two arguments: storage and location. The storage argument will be the initial deserialization of the storage, residing on the CPU. Each serialized storage has a location tag associated with it which identifies the device it was saved from, and this tag is the second argument passed to &lt;code&gt;map_location&lt;/code&gt; . The builtin location tags are &lt;code&gt;'cpu'&lt;/code&gt; for CPU tensors and &lt;code&gt;'cuda:device_id'&lt;/code&gt; (e.g. &lt;code&gt;'cuda:2'&lt;/code&gt; ) for CUDA tensors. &lt;code&gt;map_location&lt;/code&gt; should return either &lt;code&gt;None&lt;/code&gt; or a storage. If &lt;code&gt;map_location&lt;/code&gt; returns a storage, it will be used as the final deserialized object, already moved to the right device. Otherwise, &lt;a href=&quot;#torch.load&quot;&gt; &lt;code&gt;torch.load()&lt;/code&gt; &lt;/a&gt; will fall back to the default behavior, as if &lt;code&gt;map_location&lt;/code&gt; wasn&amp;rsquo;t specified.</target>
        </trans-unit>
        <trans-unit id="0e6bc544f9847053786078b7293a8d56bcd4734d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;mat1&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;mat1&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="42dc8bdc5d9263d6983656748538a841cde8189e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;mat&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;mat&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="ebf39946f09dcba3bcd6988a72fb252101844e11" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;modules&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt;, a &lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;ModuleDict&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</source>
          <target state="translated">If &lt;code&gt;modules&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt; , a &lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt; &lt;code&gt;ModuleDict&lt;/code&gt; &lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</target>
        </trans-unit>
        <trans-unit id="9da2da81b60822905c169e5c07b984ccee82a21a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n&lt;/code&gt; is negative, then the inverse of the matrix (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt;. For a batch of matrices, the batched inverse (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt;. If &lt;code&gt;n&lt;/code&gt; is 0, then an identity matrix is returned.</source>
          <target state="translated">If &lt;code&gt;n&lt;/code&gt; is negative, then the inverse of the matrix (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt; . For a batch of matrices, the batched inverse (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt; . If &lt;code&gt;n&lt;/code&gt; is 0, then an identity matrix is returned.</target>
        </trans-unit>
        <trans-unit id="7a5b0d2161214cfbfdadaec7bb8185cf215fb328" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n&lt;/code&gt; is the number of dimensions in &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;x.T&lt;/code&gt; is equivalent to &lt;code&gt;x.permute(n-1, n-2, ..., 0)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;n&lt;/code&gt; is the number of dimensions in &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;x.T&lt;/code&gt; is equivalent to &lt;code&gt;x.permute(n-1, n-2, ..., 0)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="64021abf601b2ef80dc11cb82f4cc12a6574725a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;nonlinearity&lt;/code&gt; is &lt;code&gt;&amp;lsquo;relu&amp;rsquo;&lt;/code&gt;, then ReLU is used in place of tanh.</source>
          <target state="translated">If &lt;code&gt;nonlinearity&lt;/code&gt; is &lt;code&gt;&amp;lsquo;relu&amp;rsquo;&lt;/code&gt; , then ReLU is used in place of tanh.</target>
        </trans-unit>
        <trans-unit id="14d766061a3de2fff996b1f5b1787217fd8c9c07" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalized&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default is &lt;code&gt;False&lt;/code&gt;), the function returns the normalized STFT results, i.e., multiplied by</source>
          <target state="translated">If &lt;code&gt;normalized&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default is &lt;code&gt;False&lt;/code&gt; ), the function returns the normalized STFT results, i.e., multiplied by</target>
        </trans-unit>
        <trans-unit id="00b342cfeb1bc29dc26ae492fe4fb871890e749d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;obj&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt;, &lt;code&gt;script&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object. The returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt;. If &lt;code&gt;obj&lt;/code&gt; is a standalone function, a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; will be returned.</source>
          <target state="translated">If &lt;code&gt;obj&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; , &lt;code&gt;script&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; object. The returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt; . If &lt;code&gt;obj&lt;/code&gt; is a standalone function, a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt; will be returned.</target>
        </trans-unit>
        <trans-unit id="a63f6cedcd0f8aaa3b09629c749bc8a65b8e3242" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; &amp;gt; 0, it is above the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; &amp;gt; 0, it is above the main diagonal.</target>
        </trans-unit>
        <trans-unit id="71789ffff3401f164bb9ff6ccd173e3d93708807" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; &amp;lt; 0, it is below the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; &amp;lt; 0, it is below the main diagonal.</target>
        </trans-unit>
        <trans-unit id="68479729055a8e84ce055c5fd8fcdf5fc489269d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; = 0, it is the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; = 0, it is the main diagonal.</target>
        </trans-unit>
        <trans-unit id="4a6e80bcb7f10675f2ca57bde51217a2a4acefff" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default for real input), only values for</source>
          <target state="translated">If &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default for real input), only values for</target>
        </trans-unit>
        <trans-unit id="d02abfd63ad40eea8ad8a0098542cd40d9fd90fd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;only_inputs&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the function will only return a list of gradients w.r.t the specified inputs. If it&amp;rsquo;s &lt;code&gt;False&lt;/code&gt;, then gradient w.r.t. all remaining leaves will still be computed, and will be accumulated into their &lt;code&gt;.grad&lt;/code&gt; attribute.</source>
          <target state="translated">場合 &lt;code&gt;only_inputs&lt;/code&gt; がある &lt;code&gt;True&lt;/code&gt; 、関数は指定された入力をWRT勾配のリストを返します。 &lt;code&gt;False&lt;/code&gt; の場合、残りのすべての葉の勾配は引き続き計算され、 &lt;code&gt;.grad&lt;/code&gt; 属性に累積されます。</target>
        </trans-unit>
        <trans-unit id="d55a2e244595c07c3e007024e25f845d2373549a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;other&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;alpha&lt;/code&gt; must be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;other&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;alpha&lt;/code&gt; must be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="d24ea9f71cf8ff7e189e7b233b073ed7e74bfb09" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;output_size&lt;/code&gt;, &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;dilation&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1 then their values will be replicated across all spatial dimensions.</source>
          <target state="translated">If &lt;code&gt;output_size&lt;/code&gt; , &lt;code&gt;kernel_size&lt;/code&gt; , &lt;code&gt;dilation&lt;/code&gt; , &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1 then their values will be replicated across all spatial dimensions.</target>
        </trans-unit>
        <trans-unit id="bcbbd502f1fedcc0223634c589add98b568f5531" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly padded with negative infinity on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; is the stride between the elements within the sliding window. This &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of the pooling parameters.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly padded with negative infinity on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; is the stride between the elements within the sliding window. This &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of the pooling parameters.</target>
        </trans-unit>
        <trans-unit id="a2d29b6dc8926940187a1fc2a87fbebaeec5e10f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on all three sides for &lt;code&gt;padding&lt;/code&gt; number of points.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on all three sides for &lt;code&gt;padding&lt;/code&gt; number of points.</target>
        </trans-unit>
        <trans-unit id="a34bc02f3af80858de013a28d3f5075d29b733ee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points.</target>
        </trans-unit>
        <trans-unit id="0789404550f41a9218f1f8f6d2d8802206a399d3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; controls the spacing between the kernel points. It is harder to describe, but this &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of what &lt;code&gt;dilation&lt;/code&gt; does.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; controls the spacing between the kernel points. It is harder to describe, but this &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of what &lt;code&gt;dilation&lt;/code&gt; does.</target>
        </trans-unit>
        <trans-unit id="3fe50649c0b4459ddadacb46d032eecac188eedd" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;param.grad&lt;/code&gt; is initially &lt;code&gt;None&lt;/code&gt;:</source>
          <target state="translated">&lt;code&gt;param.grad&lt;/code&gt; が最初に &lt;code&gt;None&lt;/code&gt; の場合：</target>
        </trans-unit>
        <trans-unit id="c202579e5b79a5ca47cce55bf1764d6590abf4d9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;param&lt;/code&gt; already has a non-sparse &lt;code&gt;.grad&lt;/code&gt; attribute:</source>
          <target state="translated">&lt;code&gt;param&lt;/code&gt; にすでにスパースでない &lt;code&gt;.grad&lt;/code&gt; 属性がある場合：</target>
        </trans-unit>
        <trans-unit id="b85948d2056bf712cd0ade9dc5602720a12d6ab2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;param&lt;/code&gt;&amp;rsquo;s memory is non-overlapping and dense, &lt;code&gt;.grad&lt;/code&gt; is created with strides matching &lt;code&gt;param&lt;/code&gt; (thus matching &lt;code&gt;param&lt;/code&gt;&amp;rsquo;s layout).</source>
          <target state="translated">場合 &lt;code&gt;param&lt;/code&gt; のメモリが重複ないと密である、 &lt;code&gt;.grad&lt;/code&gt; が一致ストライドで作成された &lt;code&gt;param&lt;/code&gt; （従ってマッチング &lt;code&gt;param&lt;/code&gt; のレイアウト）」。</target>
        </trans-unit>
        <trans-unit id="5c75f70ae17fab5880e35d5beec80b653312b036" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;parameters&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt;, a &lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt;&lt;code&gt;ParameterDict&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</source>
          <target state="translated">If &lt;code&gt;parameters&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt; , a &lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt; &lt;code&gt;ParameterDict&lt;/code&gt; &lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</target>
        </trans-unit>
        <trans-unit id="fa4de2a8b20f68604caa5fc5c42d01d653f7619e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduction&lt;/code&gt; is not &lt;code&gt;'none'&lt;/code&gt; (default &lt;code&gt;'mean'&lt;/code&gt;), then:</source>
          <target state="translated">If &lt;code&gt;reduction&lt;/code&gt; is not &lt;code&gt;'none'&lt;/code&gt; (default &lt;code&gt;'mean'&lt;/code&gt; ), then:</target>
        </trans-unit>
        <trans-unit id="e3f6cc94ec59a0b57a35c18da0e38bada6245d56" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_complex&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default if input is complex), the return is a &lt;code&gt;input.dim() + 1&lt;/code&gt; dimensional complex tensor. If &lt;code&gt;False&lt;/code&gt;, the output is a &lt;code&gt;input.dim() + 2&lt;/code&gt; dimensional real tensor where the last dimension represents the real and imaginary components.</source>
          <target state="translated">If &lt;code&gt;return_complex&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default if input is complex), the return is a &lt;code&gt;input.dim() + 1&lt;/code&gt; dimensional complex tensor. If &lt;code&gt;False&lt;/code&gt; , the output is a &lt;code&gt;input.dim() + 2&lt;/code&gt; dimensional real tensor where the last dimension represents the real and imaginary components.</target>
        </trans-unit>
        <trans-unit id="f865281b07a3f9b21462c504abaff9fa28e7b147" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self.cycle_momentum&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, this function has a side effect of updating the optimizer&amp;rsquo;s momentum.</source>
          <target state="translated">&lt;code&gt;self.cycle_momentum&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; の場合、この関数にはオプティマイザーの運動量を更新するという副作用があります。</target>
        </trans-unit>
        <trans-unit id="86cbdc2f08a338f85c6f8af902eddf736f286a0f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained indices tensor. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained indices tensor. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="1a38a9c9f965f62380fce875a97d72dc47659bfb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained values tensor. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained values tensor. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="95842db2195edf44c14e3fcd797605bf3a42bb61" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of dense dimensions. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of dense dimensions. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="0bcf04d576bbe19078f6b28ab84fc731b5408840" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of sparse dimensions. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of sparse dimensions. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="ca7f952167ad5a99c7190c4496d9c80f7e0a4624" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then memory is shared between all processes. All changes are written to the file. If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the changes on the storage do not affect the file.</source>
          <target state="translated">If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then memory is shared between all processes. All changes are written to the file. If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the changes on the storage do not affect the file.</target>
        </trans-unit>
        <trans-unit id="015e3e2de9fc9120162aae17d21cac0467229fd9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sizedim&lt;/code&gt; is the size of dimension &lt;code&gt;dimension&lt;/code&gt; for &lt;code&gt;self&lt;/code&gt;, the size of dimension &lt;code&gt;dimension&lt;/code&gt; in the returned tensor will be &lt;code&gt;(sizedim - size) / step + 1&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;sizedim&lt;/code&gt; is the size of dimension &lt;code&gt;dimension&lt;/code&gt; for &lt;code&gt;self&lt;/code&gt; , the size of dimension &lt;code&gt;dimension&lt;/code&gt; in the returned tensor will be &lt;code&gt;(sizedim - size) / step + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e63fb825587df089e2f9c8a5d5a13bc6f9e0bcfa" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), the method returns the reduced singular value decomposition i.e., if the last two dimensions of &lt;code&gt;input&lt;/code&gt; are &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;, then the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will contain only</source>
          <target state="translated">If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), the method returns the reduced singular value decomposition i.e., if the last two dimensions of &lt;code&gt;input&lt;/code&gt; are &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt; , then the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will contain only</target>
        </trans-unit>
        <trans-unit id="7e496e3c20e80698b4576d97cd438ec7eb85163b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then this function returns the thin (reduced) QR factorization. Otherwise, if &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, this function returns the complete QR factorization.</source>
          <target state="translated">If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then this function returns the thin (reduced) QR factorization. Otherwise, if &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , this function returns the complete QR factorization.</target>
        </trans-unit>
        <trans-unit id="1ff1fe08ba98d042300c393b324450ec3743e612" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'github'&lt;/code&gt;, &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be of the form &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; with an optional tag/branch.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'github'&lt;/code&gt; , &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be of the form &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; with an optional tag/branch.</target>
        </trans-unit>
        <trans-unit id="7ddb98294e27497103be69303e2d273125226255" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'local'&lt;/code&gt;, &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be a path to a local directory.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'local'&lt;/code&gt; , &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be a path to a local directory.</target>
        </trans-unit>
        <trans-unit id="8e46fd64e2d63e21f45b5d33db7806f0957cdf7b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is a &lt;code&gt;Storage&lt;/code&gt;, the method sets the underlying storage, offset, size, and stride.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is a &lt;code&gt;Storage&lt;/code&gt; , the method sets the underlying storage, offset, size, and stride.</target>
        </trans-unit>
        <trans-unit id="cde3a8bb0ace5c85908b26369901162f2c89a71e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;split_size_or_sections&lt;/code&gt; is a list, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; will be split into &lt;code&gt;len(split_size_or_sections)&lt;/code&gt; chunks with sizes in &lt;code&gt;dim&lt;/code&gt; according to &lt;code&gt;split_size_or_sections&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;split_size_or_sections&lt;/code&gt; is a list, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; will be split into &lt;code&gt;len(split_size_or_sections)&lt;/code&gt; chunks with sizes in &lt;code&gt;dim&lt;/code&gt; according to &lt;code&gt;split_size_or_sections&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a130a738825270ea8d38803841375a69a70f4847" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;split_size_or_sections&lt;/code&gt; is an integer type, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;split_size&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;split_size_or_sections&lt;/code&gt; is an integer type, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;split_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cfc288bc3d95c2b0c35b45e151245ce8a50c4585" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well.</source>
          <target state="translated">If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; , this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well.</target>
        </trans-unit>
        <trans-unit id="12927d84c9ce948d1b220f95a6bfac95c27d8d68" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default &lt;code&gt;momentum&lt;/code&gt; of 0.1.</source>
          <target state="translated">If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; , during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default &lt;code&gt;momentum&lt;/code&gt; of 0.1.</target>
        </trans-unit>
        <trans-unit id="07322ca8d48ec2924a49a2e5be17cc42cbbed920" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;tracker&lt;/code&gt; sets &lt;code&gt;bvars[&amp;ldquo;force_stop&amp;rdquo;] = True&lt;/code&gt;, the iteration process will be hard-stopped.</source>
          <target state="translated">If &lt;code&gt;tracker&lt;/code&gt; sets &lt;code&gt;bvars[&amp;ldquo;force_stop&amp;rdquo;] = True&lt;/code&gt; , the iteration process will be hard-stopped.</target>
        </trans-unit>
        <trans-unit id="69139fd88bd2f170758129dcebe723655bc85791" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</source>
          <target state="translated">If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</target>
        </trans-unit>
        <trans-unit id="0054a72bc16c599350023586c7a4c1a0ef3cdabb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the variance will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</source>
          <target state="translated">If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the variance will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</target>
        </trans-unit>
        <trans-unit id="64c7abce64d159f698a9f17e0c36ec9abe8f3696" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="ea8581ad2e15c4757c07b341a196b7e3beb08404" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the returned matrix &lt;code&gt;L&lt;/code&gt; is lower-triangular, and the decomposition has the form:</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the returned matrix &lt;code&gt;L&lt;/code&gt; is lower-triangular, and the decomposition has the form:</target>
        </trans-unit>
        <trans-unit id="64a08919bf7ea0ada24f0d42a92ac1bba95e2ff7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then lower triangular portion is used.</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then lower triangular portion is used.</target>
        </trans-unit>
        <trans-unit id="16f312504df9d82f1149f9aeb9d6c3a7744b7863" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; or not provided,</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; or not provided,</target>
        </trans-unit>
        <trans-unit id="0de37aa5dde3c55904d77c2e915431e5555caf52" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, and</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , and</target>
        </trans-unit>
        <trans-unit id="d54780fe04a147f268bb2ed2fa8ab8ca14bbc641" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the returned matrix &lt;code&gt;U&lt;/code&gt; is upper-triangular, and the decomposition has the form:</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the returned matrix &lt;code&gt;U&lt;/code&gt; is upper-triangular, and the decomposition has the form:</target>
        </trans-unit>
        <trans-unit id="f0b760bb14c0f3a83b45512f0cb97f37a555bad1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;vec1&lt;/code&gt; is a vector of size &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; is a vector of size &lt;code&gt;m&lt;/code&gt;, then &lt;code&gt;input&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with a matrix of size</source>
          <target state="translated">場合 &lt;code&gt;vec1&lt;/code&gt; サイズのベクトルであり &lt;code&gt;n&lt;/code&gt; 及び &lt;code&gt;vec2&lt;/code&gt; サイズのベクトルであり &lt;code&gt;m&lt;/code&gt; は、 &lt;code&gt;input&lt;/code&gt; なければならない&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;サイズの行列と</target>
        </trans-unit>
        <trans-unit id="3a620298db8d1a210d3df0072bbfa22f1c6b3dc1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;win_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;n_fft&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;win_length&lt;/code&gt; がある &lt;code&gt;None&lt;/code&gt; （デフォルト）、それがに等しいものとして扱われる &lt;code&gt;n_fft&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e41ff352c71d6d3681ae49796d3eaff91163d87a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;window_length&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;window_length&lt;/code&gt; の場合</target>
        </trans-unit>
        <trans-unit id="5ba4029b8d23bd264ef58b8c6c6f2f2dbcc50773" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;window_length&lt;/code&gt; is one, then the returned window is a single element tensor containing a one.</source>
          <target state="translated">&lt;code&gt;window_length&lt;/code&gt; が1の場合、返されるウィンドウは1を含む単一要素テンソルです。</target>
        </trans-unit>
        <trans-unit id="36700c2c10655c29379465dfe1fd6e89caba46f9" translate="yes" xml:space="preserve">
          <source>If Statements</source>
          <target state="translated">ステートメントの場合</target>
        </trans-unit>
        <trans-unit id="37f71555dd25e508495629f5b40797b269bbe017" translate="yes" xml:space="preserve">
          <source>If True, all the initializers (typically corresponding to parameters) in the exported graph will also be added as inputs to the graph. If False, then initializers are not added as inputs to the graph, and only the non-parameter inputs are added as inputs.</source>
          <target state="translated">True の場合、エクスポートされたグラフ内のすべての初期化子(通常はパラメータに対応)もグラフの入力として追加されます。Falseの場合、初期化子はグラフへの入力として追加されず、パラメータ以外の入力のみが入力として追加されます。</target>
        </trans-unit>
        <trans-unit id="a286c308254a9cdf1bc57c2c79179a955b02516d" translate="yes" xml:space="preserve">
          <source>If a single integer is used, it is treated as a singleton list, and this module will normalize over the last dimension which is expected to be of that specific size.</source>
          <target state="translated">単一の整数が使用されている場合、それはシングルトン・リストとして扱われ、このモジュールは、その特定のサイズであると予想される最後のディメンジョンの上に正規化されます。</target>
        </trans-unit>
        <trans-unit id="6cc6559de482ee416e97f4d6264cba5f02719534" translate="yes" xml:space="preserve">
          <source>If a zero-dimension tensor operand has a higher category than dimensioned operands, we promote to a type with sufficient size and category to hold all zero-dim tensor operands of that category.</source>
          <target state="translated">0次元テンソルオペランドが次元オペランドよりも高いカテゴリを持つ場合、そのカテゴリのすべての0次元テンソルオペランドを保持するのに十分なサイズとカテゴリを持つ型に昇格させます。</target>
        </trans-unit>
        <trans-unit id="4cbc07c033e4f3f50b5cdb0467c64644f527b6f8" translate="yes" xml:space="preserve">
          <source>If an op is unlisted, we assume it&amp;rsquo;s numerically stable in &lt;code&gt;float16&lt;/code&gt;. If you believe an unlisted op is numerically unstable in &lt;code&gt;float16&lt;/code&gt;, please file an issue.</source>
          <target state="translated">opがリストにない場合、 &lt;code&gt;float16&lt;/code&gt; で数値的に安定していると見なされます。リストにないopが &lt;code&gt;float16&lt;/code&gt; で数値的に不安定であると思われる場合は、問題を報告してください。</target>
        </trans-unit>
        <trans-unit id="ad31490b158e1b2eea07f572ad07acc51d64ff3a" translate="yes" xml:space="preserve">
          <source>If any checked tensor in &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;grad_outputs&lt;/code&gt; has overlapping memory, i.e., different indices pointing to the same memory address (e.g., from &lt;code&gt;torch.expand()&lt;/code&gt;), this check will likely fail because the numerical gradients computed by point perturbation at such indices will change values at all other indices that share the same memory address.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;grad_outputs&lt;/code&gt; のチェックされたテンソルに重複するメモリがある場合、つまり、同じメモリアドレスを指す異なるインデックスがある場合（たとえば、 &lt;code&gt;torch.expand()&lt;/code&gt; から）、そのようなインデックスでのポイント摂動によって計算された数値勾配が失敗するため、このチェックは失敗する可能性があります。同じメモリアドレスを共有する他のすべてのインデックスの値を変更します。</target>
        </trans-unit>
        <trans-unit id="cc7adef2433e41254f246b09a9940775c5a1f72e" translate="yes" xml:space="preserve">
          <source>If any checked tensor in &lt;code&gt;input&lt;/code&gt; has overlapping memory, i.e., different indices pointing to the same memory address (e.g., from &lt;code&gt;torch.expand()&lt;/code&gt;), this check will likely fail because the numerical gradients computed by point perturbation at such indices will change values at all other indices that share the same memory address.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; 内のチェックされたテンソルに重複するメモリがある場合、つまり、同じメモリアドレスを指す異なるインデックスがある場合（たとえば、 &lt;code&gt;torch.expand()&lt;/code&gt; から）、そのようなインデックスでの点摂動によって計算された数値勾配が値を変更するため、このチェックは失敗する可能性があります同じメモリアドレスを共有する他のすべてのインデックスで。</target>
        </trans-unit>
        <trans-unit id="3e818bb7352c628c52d3f8d4ba3508811d8bc58f" translate="yes" xml:space="preserve">
          <source>If any of these would help your use case, please &lt;a href=&quot;https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3A%22module%3A+named+tensor%22&quot;&gt;search if an issue has already been filed&lt;/a&gt; and if not, &lt;a href=&quot;https://github.com/pytorch/pytorch/issues/new/choose&quot;&gt;file one&lt;/a&gt;.</source>
          <target state="translated">これらのいずれかがユースケースに役立つ&lt;a href=&quot;https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3A%22module%3A+named+tensor%22&quot;&gt;場合は、問題がすでに提出されているかどうか&lt;/a&gt;を検索し、提出されていない場合は&lt;a href=&quot;https://github.com/pytorch/pytorch/issues/new/choose&quot;&gt;1つ&lt;/a&gt;提出してください。</target>
        </trans-unit>
        <trans-unit id="365d8ae01687e5fc5ba3a3c559e4b1609ec1de03" translate="yes" xml:space="preserve">
          <source>If any optimizer steps were skipped the scale is multiplied by &lt;code&gt;backoff_factor&lt;/code&gt; to reduce it. If &lt;code&gt;growth_interval&lt;/code&gt; unskipped iterations occurred consecutively, the scale is multiplied by &lt;code&gt;growth_factor&lt;/code&gt; to increase it.</source>
          <target state="translated">オプティマイザーの手順がスキップされた場合は、スケールに &lt;code&gt;backoff_factor&lt;/code&gt; を掛けて縮小します。 &lt;code&gt;growth_interval&lt;/code&gt; growth_intervalの反復が連続して発生した場合は、スケールに &lt;code&gt;growth_factor&lt;/code&gt; を掛けて増加させます。</target>
        </trans-unit>
        <trans-unit id="1080160de99f6c4b9ac7827f3fbead61bb81527f" translate="yes" xml:space="preserve">
          <source>If both arguments are 2-dimensional, the matrix-matrix product is returned.</source>
          <target state="translated">両方の引数が2次元の場合、行列-行列積が返されます。</target>
        </trans-unit>
        <trans-unit id="d6fa8132ad71df4e876fdeaeb999a43daf3f4278" translate="yes" xml:space="preserve">
          <source>If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N &amp;gt; 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasted&lt;/a&gt; (and thus must be broadcastable). For example, if &lt;code&gt;input&lt;/code&gt; is a</source>
          <target state="translated">両方の引数が少なくとも1次元で、少なくとも1つの引数がN次元（N&amp;gt; 2）の場合、バッチ行列の乗算が返されます。最初の引数が1次元の場合、バッチ行列を乗算して後で削除するために、その次元の前に1が付加されます。 2番目の引数が1次元の場合、バッチ行列の倍数の目的で1がその次元に追加され、後で削除されます。非マトリックス（つまりバッチ）ディメンションが&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;ブロードキャストされます&lt;/a&gt;（したがって、ブロードキャスト可能である必要があります）。たとえば、 &lt;code&gt;input&lt;/code&gt; が</target>
        </trans-unit>
        <trans-unit id="d89fe56ed688f10e95f166f512f223aa5ad0f1fe" translate="yes" xml:space="preserve">
          <source>If both tensors are 1-dimensional, the dot product (scalar) is returned.</source>
          <target state="translated">両方のテンソルが1次元の場合は、ドット積(スカラー)が返されます。</target>
        </trans-unit>
        <trans-unit id="b74b95d5cdc716438937d19d93c000b85e6ccb8b" translate="yes" xml:space="preserve">
          <source>If checkpointed segment contains tensors detached from the computational graph by &lt;code&gt;detach()&lt;/code&gt; or &lt;code&gt;torch.no_grad()&lt;/code&gt;, the backward pass will raise an error. This is because &lt;code&gt;checkpoint&lt;/code&gt; makes all the outputs require gradients which causes issues when a tensor is defined to have no gradient in the model. To circumvent this, detach the tensors outside of the &lt;code&gt;checkpoint&lt;/code&gt; function.</source>
          <target state="translated">チェックポイントされたセグメントに、 &lt;code&gt;detach()&lt;/code&gt; または &lt;code&gt;torch.no_grad()&lt;/code&gt; によって計算グラフから切り離されたテンソルが含まれている場合、後方パスはエラーを発生させます。これは、 &lt;code&gt;checkpoint&lt;/code&gt; によってすべての出力に勾配が必要になるため、テンソルがモデルに勾配がないと定義されている場合に問題が発生するためです。これを回避するには、 &lt;code&gt;checkpoint&lt;/code&gt; 関数の外側でテンソルを切り離します。</target>
        </trans-unit>
        <trans-unit id="6148ee076450f28f4a8ddad929803f8c02667e14" translate="yes" xml:space="preserve">
          <source>If downloaded file is a zip file, it will be automatically decompressed.</source>
          <target state="translated">ダウンロードしたファイルがZIPファイルの場合は、自動的に解凍されます。</target>
        </trans-unit>
        <trans-unit id="3632499e9221774229ac5b4849f51f9b7ea5baa6" translate="yes" xml:space="preserve">
          <source>If input has shape</source>
          <target state="translated">入力が形状を持っている場合</target>
        </trans-unit>
        <trans-unit id="6054f9e157471bc8a7a27391680f78509c758f80" translate="yes" xml:space="preserve">
          <source>If it is &lt;code&gt;False&lt;/code&gt;, only eigenvalues are computed. If it is &lt;code&gt;True&lt;/code&gt;, both eigenvalues and eigenvectors are computed.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、固有値のみが計算されます。もしそうであれば &lt;code&gt;True&lt;/code&gt; 、固有値と固有ベクトルの両方が計算されます。</target>
        </trans-unit>
        <trans-unit id="c2b14334c440f3e0a03846297c6b858c19d59ebd" translate="yes" xml:space="preserve">
          <source>If neither is specified, &lt;code&gt;init_method&lt;/code&gt; is assumed to be &amp;ldquo;env://&amp;rdquo;.</source>
          <target state="translated">どちらも指定されていない場合、 &lt;code&gt;init_method&lt;/code&gt; は「env：//」であると見なされます。</target>
        </trans-unit>
        <trans-unit id="8af7fa7360ca7c6df177260376e8748ca36e7b2e" translate="yes" xml:space="preserve">
          <source>If new parameters/buffers are added/removed from a module, this number shall be bumped, and the module&amp;rsquo;s &lt;code&gt;_load_from_state_dict&lt;/code&gt; method can compare the version number and do appropriate changes if the state dict is from before the change.</source>
          <target state="translated">新しいパラメータ/バッファがモジュールに追加/削除された場合、この番号はバンプされ、モジュールの &lt;code&gt;_load_from_state_dict&lt;/code&gt; メソッドはバージョン番号を比較し、状態dictが変更前のものである場合は適切な変更を行うことができます。</target>
        </trans-unit>
        <trans-unit id="ab07e4375ba32a4af6a712b8e6818b3c0e5409bd" translate="yes" xml:space="preserve">
          <source>If no inf/NaN gradients are found, invokes &lt;code&gt;optimizer.step()&lt;/code&gt; using the unscaled gradients. Otherwise, &lt;code&gt;optimizer.step()&lt;/code&gt; is skipped to avoid corrupting the params.</source>
          <target state="translated">inf / NaNグラデーションが見つからない場合は、スケーリングされていないグラデーションを使用して &lt;code&gt;optimizer.step()&lt;/code&gt; を呼び出します。それ以外の場合は、paramsの破損を避けるために &lt;code&gt;optimizer.step()&lt;/code&gt; がスキップされます。</target>
        </trans-unit>
        <trans-unit id="35eb8efeed66172f49e69d3035c935e69cd09a9d" translate="yes" xml:space="preserve">
          <source>If not, they are drawn without replacement, which means that when a sample index is drawn for a row, it cannot be drawn again for that row.</source>
          <target state="translated">そうでない場合、それらは置換なしで描画されます。つまり、サンプルインデックスが行に対して描画されたときに、その行に対して再度描画することはできません。</target>
        </trans-unit>
        <trans-unit id="8bad8088b028a7abefb044cb50129322a5504452" translate="yes" xml:space="preserve">
          <source>If one of the elements being compared is a NaN, then that element is returned. &lt;a href=&quot;#torch.maximum&quot;&gt;&lt;code&gt;maximum()&lt;/code&gt;&lt;/a&gt; is not supported for tensors with complex dtypes.</source>
          <target state="translated">比較される要素の1つがNaNである場合、その要素が返されます。&lt;a href=&quot;#torch.maximum&quot;&gt; &lt;code&gt;maximum()&lt;/code&gt; &lt;/a&gt;は、複雑なdtypeを持つテンソルではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="4d2edfb80af8b4c10b0daabd533575291d8f3436" translate="yes" xml:space="preserve">
          <source>If one of the elements being compared is a NaN, then that element is returned. &lt;a href=&quot;#torch.minimum&quot;&gt;&lt;code&gt;minimum()&lt;/code&gt;&lt;/a&gt; is not supported for tensors with complex dtypes.</source>
          <target state="translated">比較される要素の1つがNaNである場合、その要素が返されます。&lt;a href=&quot;#torch.minimum&quot;&gt; &lt;code&gt;minimum()&lt;/code&gt; &lt;/a&gt;は、複雑なdtypeを持つテンソルではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="c998486ad794fdb83e80c2ef35e8c9ca0a076827" translate="yes" xml:space="preserve">
          <source>If one of the processes exits with a non-zero exit status, the remaining processes are killed and an exception is raised with the cause of termination. In the case an exception was caught in the child process, it is forwarded and its traceback is included in the exception raised in the parent process.</source>
          <target state="translated">1つのプロセスが0以外の終了ステータスで終了した場合、残りのプロセスは強制終了され、終了原因が記載された例外が発生します。子プロセスで例外が発生した場合、その例外は転送され、そのトレースバックは親プロセスで発生した例外に含まれます。</target>
        </trans-unit>
        <trans-unit id="7af111fbf2a8bf97e37886e5888c11a588605b8f" translate="yes" xml:space="preserve">
          <source>If provided, the optional argument &lt;code&gt;weight&lt;/code&gt; should be a 1D Tensor assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.</source>
          <target state="translated">指定する場合、オプションの引数の &lt;code&gt;weight&lt;/code&gt; は、各クラスに重みを割り当てる1Dテンソルである必要があります。これは、不均衡なトレーニングセットがある場合に特に役立ちます。</target>
        </trans-unit>
        <trans-unit id="969ca4bbce09cb3097e3db4dcee3ccac4fa12d57" translate="yes" xml:space="preserve">
          <source>If replacement is &lt;code&gt;True&lt;/code&gt;, samples are drawn with replacement.</source>
          <target state="translated">置換が &lt;code&gt;True&lt;/code&gt; の場合、サンプルは置換で抽出されます。</target>
        </trans-unit>
        <trans-unit id="484e62a9e6c54b0aaa3a5007d8a946f20da7704f" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;repeats&lt;/code&gt; is &lt;code&gt;tensor([n1, n2, n3, &amp;hellip;])&lt;/code&gt;, then the output will be &lt;code&gt;tensor([0, 0, &amp;hellip;, 1, 1, &amp;hellip;, 2, 2, &amp;hellip;, &amp;hellip;])&lt;/code&gt; where &lt;code&gt;0&lt;/code&gt; appears &lt;code&gt;n1&lt;/code&gt; times, &lt;code&gt;1&lt;/code&gt; appears &lt;code&gt;n2&lt;/code&gt; times, &lt;code&gt;2&lt;/code&gt; appears &lt;code&gt;n3&lt;/code&gt; times, etc.</source>
          <target state="translated">場合 &lt;code&gt;repeats&lt;/code&gt; ある &lt;code&gt;tensor([n1, n2, n3, &amp;hellip;])&lt;/code&gt; 、出力がされる &lt;code&gt;tensor([0, 0, &amp;hellip;, 1, 1, &amp;hellip;, 2, 2, &amp;hellip;, &amp;hellip;])&lt;/code&gt; &lt;code&gt;0&lt;/code&gt; が現れるの &lt;code&gt;n1&lt;/code&gt; 回、 &lt;code&gt;1&lt;/code&gt; が表示され &lt;code&gt;n2&lt;/code&gt; 回、 &lt;code&gt;2&lt;/code&gt; が表示されます &lt;code&gt;n3&lt;/code&gt; など回、</target>
        </trans-unit>
        <trans-unit id="5a469887feb69df132460464b530071b29b07521" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;self.data&lt;/code&gt; Tensor already has the correct &lt;code&gt;torch.dtype&lt;/code&gt; and &lt;code&gt;torch.device&lt;/code&gt;, then &lt;code&gt;self&lt;/code&gt; is returned. Otherwise, returns a copy with the desired configuration.</source>
          <target state="translated">場合 &lt;code&gt;self.data&lt;/code&gt; のテンソルはすでに正しい持ち &lt;code&gt;torch.dtype&lt;/code&gt; と &lt;code&gt;torch.device&lt;/code&gt; を、その後、 &lt;code&gt;self&lt;/code&gt; 返されます。それ以外の場合は、目的の構成のコピーを返します。</target>
        </trans-unit>
        <trans-unit id="5d823313d98ebbfc4cb390dd8145252b2ceb1eaf" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;self&lt;/code&gt; Tensor already has the correct &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, then &lt;code&gt;self&lt;/code&gt; is returned. Otherwise, the returned tensor is a copy of &lt;code&gt;self&lt;/code&gt; with the desired &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">場合は &lt;code&gt;self&lt;/code&gt; テンソルはすでに正しい持ち&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を&lt;/a&gt;、その後、 &lt;code&gt;self&lt;/code&gt; 返されます。それ以外の場合、返されるテンソルは、目的の&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を&lt;/a&gt;持つ &lt;code&gt;self&lt;/code&gt; のコピーです。</target>
        </trans-unit>
        <trans-unit id="9a55f7772c88fb21a34f619e7cbc1ddc996bd65e" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;spawn&lt;/code&gt; start method is used, &lt;code&gt;worker_init_fn&lt;/code&gt; cannot be an unpicklable object, e.g., a lambda function. See &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/multiprocessing.html#multiprocessing-best-practices&quot;&gt;Multiprocessing best practices&lt;/a&gt; on more details related to multiprocessing in PyTorch.</source>
          <target state="translated">&lt;code&gt;spawn&lt;/code&gt; startメソッドを使用する場合、 &lt;code&gt;worker_init_fn&lt;/code&gt; を選択できないオブジェクト（ラムダ関数など）にすることはできません。PyTorchでのマルチプロセッシングに関連する詳細については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/multiprocessing.html#multiprocessing-best-practices&quot;&gt;マルチプロセッシングのベストプラクティス&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="6b8c8166f7ac4def7f8a41f990435d7b737da1e1" translate="yes" xml:space="preserve">
          <source>If the RNN is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="translated">RNNが双方向性の場合、num_directionsは2でなければならず、そうでなければ1でなければなりません。</target>
        </trans-unit>
        <trans-unit id="b65be36d1abe2727420269313c2df666e233f015" translate="yes" xml:space="preserve">
          <source>If the consumer process dies abnormally to a fatal signal, the shared tensor could be forever kept in memory as long as the sending process is running.</source>
          <target state="translated">コンシューマプロセスが致命的な信号に対して異常終了した場合、送信プロセスが実行されている限り、共有テンソルは永遠にメモリに保持される可能性があります。</target>
        </trans-unit>
        <trans-unit id="191802e65e024d3ca3eb1bca5bd908ca2613d6eb" translate="yes" xml:space="preserve">
          <source>If the current node is the owner, returns a reference to the local value. Otherwise, throws an exception.</source>
          <target state="translated">現在のノードが所有者の場合、ローカル値への参照を返します。そうでない場合は例外をスローします。</target>
        </trans-unit>
        <trans-unit id="c74db6eba0315e50d747303ae70dc492c51af6b7" translate="yes" xml:space="preserve">
          <source>If the decorated &lt;code&gt;forward&lt;/code&gt; is called outside an autocast-enabled region, &lt;a href=&quot;#torch.cuda.amp.custom_fwd&quot;&gt;&lt;code&gt;custom_fwd&lt;/code&gt;&lt;/a&gt; is a no-op and &lt;code&gt;cast_inputs&lt;/code&gt; has no effect.</source>
          <target state="translated">装飾された &lt;code&gt;forward&lt;/code&gt; が自動キャスト対応領域の外部で呼び出された場合、&lt;a href=&quot;#torch.cuda.amp.custom_fwd&quot;&gt; &lt;code&gt;custom_fwd&lt;/code&gt; &lt;/a&gt;はノーオペレーションであり、 &lt;code&gt;cast_inputs&lt;/code&gt; は効果がありません。</target>
        </trans-unit>
        <trans-unit id="9bc28fe59df6be023786ded1b0d7a664101bb1a6" translate="yes" xml:space="preserve">
          <source>If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.</source>
          <target state="translated">第 1 引数が 1 次元、第 2 引数が 2 次元の場合、行列の乗算のためにその次元に 1 が付加されます。行列の乗算の後、前置された次元は削除されます。</target>
        </trans-unit>
        <trans-unit id="805768ae7e7883adbd4eb9cfd347ff7553b939ce" translate="yes" xml:space="preserve">
          <source>If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.</source>
          <target state="translated">第1引数が2次元、第2引数が1次元の場合、行列-ベクトル積が返されます。</target>
        </trans-unit>
        <trans-unit id="603aa447ecbcf1ce44b939cf59f78b72d62d8d4f" translate="yes" xml:space="preserve">
          <source>If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype &lt;code&gt;torch.float16&lt;/code&gt; 4) V100 GPU is used, 5) input data is not in &lt;code&gt;PackedSequence&lt;/code&gt; format persistent algorithm can be selected to improve performance.</source>
          <target state="translated">次の条件が満たされている場合：1）cudnnが有効である、2）入力データがGPU上にある3）入力データがdtype &lt;code&gt;torch.float16&lt;/code&gt; を持っている4）V100 GPUが使用されている、5）入力データが &lt;code&gt;PackedSequence&lt;/code&gt; 形式ではない永続的なアルゴリズムパフォーマンスを向上させるために選択されました。</target>
        </trans-unit>
        <trans-unit id="e2ec6b76ced3aa12445764a71f2f934d55e863cb" translate="yes" xml:space="preserve">
          <source>If the forward pass for a particular op has &lt;code&gt;float16&lt;/code&gt; inputs, the backward pass for that op will produce &lt;code&gt;float16&lt;/code&gt; gradients. Gradient values with small magnitudes may not be representable in &lt;code&gt;float16&lt;/code&gt;. These values will flush to zero (&amp;ldquo;underflow&amp;rdquo;), so the update for the corresponding parameters will be lost.</source>
          <target state="translated">特定のopのフォワードパスに &lt;code&gt;float16&lt;/code&gt; 入力がある場合、そのopのバックワードパスは &lt;code&gt;float16&lt;/code&gt; グラデーションを生成します。大きさが小さいグラデーション値は、 &lt;code&gt;float16&lt;/code&gt; では表現できない場合があります。これらの値はゼロにフラッシュされるため（「アンダーフロー」）、対応するパラメーターの更新は失われます。</target>
        </trans-unit>
        <trans-unit id="787caec1c53ac744f6704113ef9317970b83ba1d" translate="yes" xml:space="preserve">
          <source>If the input argument is a tensor, but ONNX asks for a scalar, we have to explicitly do the conversion. The helper function &lt;code&gt;_scalar&lt;/code&gt; can convert a scalar tensor into a python scalar, and &lt;code&gt;_if_scalar_type_as&lt;/code&gt; can turn a Python scalar into a PyTorch tensor.</source>
          <target state="translated">入力引数がテンソルであるが、ONNXがスカラーを要求する場合、明示的に変換を行う必要があります。ヘルパー関数 &lt;code&gt;_scalar&lt;/code&gt; はスカラーテンソルをPythonスカラーに &lt;code&gt;_if_scalar_type_as&lt;/code&gt; でき、_if_scalar_type_asはPythonスカラーをPyTorchテンソルに変換できます。</target>
        </trans-unit>
        <trans-unit id="9db31a4fe372bf1c4d439edd124d674c08f32005" translate="yes" xml:space="preserve">
          <source>If the main process exits abruptly (e.g. because of an incoming signal), Python&amp;rsquo;s &lt;code&gt;multiprocessing&lt;/code&gt; sometimes fails to clean up its children. It&amp;rsquo;s a known caveat, so if you&amp;rsquo;re seeing any resource leaks after interrupting the interpreter, it probably means that this has just happened to you.</source>
          <target state="translated">メインプロセスが突然終了した場合（たとえば、着信信号のため）、Pythonの &lt;code&gt;multiprocessing&lt;/code&gt; は子のクリーンアップに失敗することがあります。これは既知の警告であるため、インタプリタを中断した後にリソースリークが発生した場合は、おそらくこれが発生したことを意味します。</target>
        </trans-unit>
        <trans-unit id="f988049101ff18d4e7918e66cf5ad5885aec7070" translate="yes" xml:space="preserve">
          <source>If the norm of a row is lower than &lt;code&gt;maxnorm&lt;/code&gt;, the row is unchanged</source>
          <target state="translated">行のノルムが &lt;code&gt;maxnorm&lt;/code&gt; よりも低い場合、行は変更されません</target>
        </trans-unit>
        <trans-unit id="d44fada1fe05f824e96651b70e1c4a292ba8a891" translate="yes" xml:space="preserve">
          <source>If the object is already present in &lt;code&gt;model_dir&lt;/code&gt;, it&amp;rsquo;s deserialized and returned. The default value of &lt;code&gt;model_dir&lt;/code&gt; is &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; where &lt;code&gt;hub_dir&lt;/code&gt; is the directory returned by &lt;a href=&quot;#torch.hub.get_dir&quot;&gt;&lt;code&gt;get_dir()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">オブジェクトがすでに &lt;code&gt;model_dir&lt;/code&gt; に存在する場合は、逆シリアル化されて返されます。 &lt;code&gt;model_dir&lt;/code&gt; のデフォルト値は &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; です。ここで、 &lt;code&gt;hub_dir&lt;/code&gt; は&lt;a href=&quot;#torch.hub.get_dir&quot;&gt; &lt;code&gt;get_dir()&lt;/code&gt; &lt;/a&gt;によって返されるディレクトリです。</target>
        </trans-unit>
        <trans-unit id="572431e231db065e224abcc587fb2e502c2edb94" translate="yes" xml:space="preserve">
          <source>If the object is already present in &lt;code&gt;model_dir&lt;/code&gt;, it&amp;rsquo;s deserialized and returned. The default value of &lt;code&gt;model_dir&lt;/code&gt; is &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; where &lt;code&gt;hub_dir&lt;/code&gt; is the directory returned by &lt;a href=&quot;hub#torch.hub.get_dir&quot;&gt;&lt;code&gt;get_dir()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">オブジェクトがすでに &lt;code&gt;model_dir&lt;/code&gt; に存在する場合は、逆シリアル化されて返されます。 &lt;code&gt;model_dir&lt;/code&gt; のデフォルト値は &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; です。ここで、 &lt;code&gt;hub_dir&lt;/code&gt; は&lt;a href=&quot;hub#torch.hub.get_dir&quot;&gt; &lt;code&gt;get_dir()&lt;/code&gt; &lt;/a&gt;によって返されるディレクトリです。</target>
        </trans-unit>
        <trans-unit id="e07c64dd92353460c82bc7c43c0298ff2498e3ef" translate="yes" xml:space="preserve">
          <source>If the operator is a non-ATen operator, the symbolic function has to be added in the corresponding PyTorch Function class. Please read the following instructions:</source>
          <target state="translated">演算子が非ATen演算子の場合は、対応するPyTorch関数クラスにシンボリック関数を追加する必要があります。以下の説明を読んでください。</target>
        </trans-unit>
        <trans-unit id="8de0216c16416c65797272e400b10794b950ac17" translate="yes" xml:space="preserve">
          <source>If the operator is an ATen operator, which means you can find the declaration of the function in &lt;code&gt;torch/csrc/autograd/generated/VariableType.h&lt;/code&gt; (available in generated code in PyTorch install dir), you should add the symbolic function in &lt;code&gt;torch/onnx/symbolic_opset&amp;lt;version&amp;gt;.py&lt;/code&gt; and follow the instructions listed as below:</source>
          <target state="translated">オペレータはあなたが関数の宣言を見つけることができることを意味しATEN演算子の場合、 &lt;code&gt;torch/csrc/autograd/generated/VariableType.h&lt;/code&gt; （ディレクトリをインストールPyTorchで生成されたコードで入手可能）、あなたはシンボリック機能を追加する必要があり &lt;code&gt;torch/onnx/symbolic_opset&amp;lt;version&amp;gt;.py&lt;/code&gt; を実行し、以下の手順に従います。</target>
        </trans-unit>
        <trans-unit id="3f469a63a2d68271648256ec0018c99f6ecea6e3" translate="yes" xml:space="preserve">
          <source>If the running minimum equals to the running maximum, the scale and zero_point are set to 1.0 and 0.</source>
          <target state="translated">走行最小値が走行最大値に等しい場合、スケールとゼロポイントは1.0と0に設定されます。</target>
        </trans-unit>
        <trans-unit id="f56fe0773d874b4f8f3b816d146b62978698c172" translate="yes" xml:space="preserve">
          <source>If the running minimum equals to the running maximum, the scales and zero_points are set to 1.0 and 0.</source>
          <target state="translated">走行中の最小値が走行中の最大値に等しい場合、スケールとゼロポイントは1.0と0に設定されます。</target>
        </trans-unit>
        <trans-unit id="08987c5581da900d9050fec1b266346dd018ed86" translate="yes" xml:space="preserve">
          <source>If the sum to the power of &lt;code&gt;p&lt;/code&gt; is zero, the gradient of this function is not defined. This implementation will set the gradient to zero in this case.</source>
          <target state="translated">&lt;code&gt;p&lt;/code&gt; の累乗の合計がゼロの場合、この関数の勾配は定義されていません。この場合、この実装は勾配をゼロに設定します。</target>
        </trans-unit>
        <trans-unit id="a6455b98cbf68564852f3d65be9e3d85724ba33b" translate="yes" xml:space="preserve">
          <source>If the targets are given as a 1d tensor that is the concatenation of individual targets, the target_lengths must add up to the total length of the tensor.</source>
          <target state="translated">ターゲットが個々のターゲットを連結した1dテンソルとして与えられた場合、target_lengthsはテンソルの全長に加算されなければなりません。</target>
        </trans-unit>
        <trans-unit id="eb673583185e53bcc86746d0d9978c1392f01670" translate="yes" xml:space="preserve">
          <source>If the tensor has a batch dimension of size 1, then &lt;code&gt;squeeze(input)&lt;/code&gt; will also remove the batch dimension, which can lead to unexpected errors.</source>
          <target state="translated">テンソルのバッチ次元がサイズ1の場合、 &lt;code&gt;squeeze(input)&lt;/code&gt; はバッチ次元も削除するため、予期しないエラーが発生する可能性があります。</target>
        </trans-unit>
        <trans-unit id="67a5ac190ccd238f6283765db614cb7a1d643567" translate="yes" xml:space="preserve">
          <source>If the torch.fft module is imported then &amp;ldquo;torch.fft&amp;rdquo; will refer to the module and not this function. Use &lt;a href=&quot;../tensors#torch.Tensor.fft&quot;&gt;&lt;code&gt;torch.Tensor.fft()&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">torch.fftモジュールがインポートされた場合、「torch.fft」はこの関数ではなくモジュールを参照します。代わりに&lt;a href=&quot;../tensors#torch.Tensor.fft&quot;&gt; &lt;code&gt;torch.Tensor.fft()&lt;/code&gt; を&lt;/a&gt;使用してください。</target>
        </trans-unit>
        <trans-unit id="d413b6561145ebb882d59d64e1d5bb494eb94bfd" translate="yes" xml:space="preserve">
          <source>If the type of a scalar operand is of a higher category than tensor operands (where complex &amp;gt; floating &amp;gt; integral &amp;gt; boolean), we promote to a type with sufficient size to hold all scalar operands of that category.</source>
          <target state="translated">スカラーオペランドの型がテンソルオペランドよりも高いカテゴリ（複素数&amp;gt;浮動&amp;gt;積分&amp;gt;ブール）の場合、そのカテゴリのすべてのスカラーオペランドを保持するのに十分なサイズの型に昇格します。</target>
        </trans-unit>
        <trans-unit id="1fdbc94ec5c6bbfaeab5c1df5a93f67f15cfdc84" translate="yes" xml:space="preserve">
          <source>If there are multiple maximal values in a reduced row then the indices of the first maximal value are returned.</source>
          <target state="translated">縮小された行の中に複数の最大値がある場合は、最初の最大値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="dffbe07ea95c30719f442abdb52cf12ce069da58" translate="yes" xml:space="preserve">
          <source>If there are multiple minimal values in a reduced row then the indices of the first minimal value are returned.</source>
          <target state="translated">縮小された行の中に複数の最小値がある場合は、最初の最小値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="c351680cf4894b25f49425f0d4d516d6d33a16ff" translate="yes" xml:space="preserve">
          <source>If there are multiple minimal values then the indices of the first minimal value are returned.</source>
          <target state="translated">複数の最小値がある場合は、最初の最小値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="7f03b96d2971ec564ed4f31e34caa43003898f1d" translate="yes" xml:space="preserve">
          <source>If there are no higher-category zero-dim operands, we promote to a type with sufficient size and category to hold all dimensioned operands.</source>
          <target state="translated">より高いカテゴリの0-dimオペランドが存在しない場合、すべての次元のオペランドを保持するのに十分なサイズとカテゴリを持つ型に昇格します。</target>
        </trans-unit>
        <trans-unit id="5962a1d4338b99c456d76f53f49888023b22b5fe" translate="yes" xml:space="preserve">
          <source>If this instance is not enabled, returns an empty dict.</source>
          <target state="translated">このインスタンスが有効でない場合は、空の dict を返します。</target>
        </trans-unit>
        <trans-unit id="bc9e3883be4333b3f7486d77ab3655dd30a42ad7" translate="yes" xml:space="preserve">
          <source>If this is already of the correct type, no copy is performed and the original object is returned.</source>
          <target state="translated">これが既に正しい型であれば、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="ce68525cc568e97b080be8925035deeb766a0ee2" translate="yes" xml:space="preserve">
          <source>If this object is already in CPU memory and on the correct device, then no copy is performed and the original object is returned.</source>
          <target state="translated">このオブジェクトが既にCPUメモリ内にあり、正しいデバイス上にある場合、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="6788146c6f952e177f58c27fec835e0c0d256c8a" translate="yes" xml:space="preserve">
          <source>If this object is already in CUDA memory and on the correct device, then no copy is performed and the original object is returned.</source>
          <target state="translated">このオブジェクトが既にCUDAメモリ内にあり、正しいデバイス上にある場合、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="242928789aba900d14b07ac7fbbbd1efba673985" translate="yes" xml:space="preserve">
          <source>If true, undefined output grad tensors will be expanded to tensors full of zeros prior to calling the &lt;code&gt;backward()&lt;/code&gt; method.</source>
          <target state="translated">trueの場合、 &lt;code&gt;backward()&lt;/code&gt; メソッドを呼び出す前に、未定義の出力勾配テンソルがゼロでいっぱいのテンソルに展開されます。</target>
        </trans-unit>
        <trans-unit id="7c50d408ff8252bcf7756ca41661606361f0e20e" translate="yes" xml:space="preserve">
          <source>If x1 has shape</source>
          <target state="translated">x1が形状を持っている場合</target>
        </trans-unit>
        <trans-unit id="c21dcebc3506f3faeef2282027b5db5536bb6293" translate="yes" xml:space="preserve">
          <source>If you are profiling CUDA code, the first profiler that &lt;code&gt;bottleneck&lt;/code&gt; runs (cProfile) will include the CUDA startup time (CUDA buffer allocation cost) in its time reporting. This should not matter if your bottlenecks result in code much slower than the CUDA startup time.</source>
          <target state="translated">CUDAコードをプロファイリングしている場合、 &lt;code&gt;bottleneck&lt;/code&gt; が実行される最初のプロファイラー（cProfile）は、時間レポートにCUDA起動時間（CUDAバッファー割り当てコスト）を含めます。ボトルネックによってコードがCUDAの起動時間よりもはるかに遅くなる場合、これは問題ではありません。</target>
        </trans-unit>
        <trans-unit id="bb09e45c509c395b596fc5d452b50e8440b313fe" translate="yes" xml:space="preserve">
          <source>If you are using DistributedDataParallel in conjunction with the &lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework&lt;/a&gt;, you should always use &lt;a href=&quot;../rpc#torch.distributed.autograd.backward&quot;&gt;&lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt;&lt;/a&gt; to compute gradients and &lt;a href=&quot;../rpc#torch.distributed.optim.DistributedOptimizer&quot;&gt;&lt;code&gt;torch.distributed.optim.DistributedOptimizer&lt;/code&gt;&lt;/a&gt; for optimizing parameters.</source>
          <target state="translated">DistributedDataParallelをDistributedRPC &lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Framework&lt;/a&gt;と組み合わせて使用​​している場合は、常に&lt;a href=&quot;../rpc#torch.distributed.autograd.backward&quot;&gt; &lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt; &lt;/a&gt;を使用して勾配を計算し、&lt;a href=&quot;../rpc#torch.distributed.optim.DistributedOptimizer&quot;&gt; &lt;code&gt;torch.distributed.optim.DistributedOptimizer&lt;/code&gt; &lt;/a&gt;を使用してパラメーターを最適化する必要があります。</target>
        </trans-unit>
        <trans-unit id="f2eaa5f7e49b18ce16b1e20ba98c586a98d8b30c" translate="yes" xml:space="preserve">
          <source>If you are working with a multi-GPU model, this function is insufficient to get determinism. To seed all GPUs, use &lt;a href=&quot;#torch.cuda.manual_seed_all&quot;&gt;&lt;code&gt;manual_seed_all()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">マルチGPUモデルを使用している場合、この関数は決定論を取得するには不十分です。すべてのGPUをシードするには、&lt;a href=&quot;#torch.cuda.manual_seed_all&quot;&gt; &lt;code&gt;manual_seed_all()&lt;/code&gt; を&lt;/a&gt;使用します。</target>
        </trans-unit>
        <trans-unit id="70fa782f705679e7b47a8754281b13145f0bdb95" translate="yes" xml:space="preserve">
          <source>If you are working with a multi-GPU model, this function will only initialize the seed on one GPU. To initialize all GPUs, use &lt;a href=&quot;#torch.cuda.seed_all&quot;&gt;&lt;code&gt;seed_all()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">マルチGPUモデルを使用している場合、この関数は1つのGPUでのみシードを初期化します。すべてのGPUを初期化するには、&lt;a href=&quot;#torch.cuda.seed_all&quot;&gt; &lt;code&gt;seed_all()&lt;/code&gt; を&lt;/a&gt;使用します。</target>
        </trans-unit>
        <trans-unit id="79878b7e0f390005d12ab18a0ff2e5e3bf2df40c" translate="yes" xml:space="preserve">
          <source>If you have more than one GPU on each node, when using the NCCL and Gloo backend, &lt;a href=&quot;#torch.distributed.broadcast_multigpu&quot;&gt;&lt;code&gt;broadcast_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt;&lt;code&gt;all_reduce_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.reduce_multigpu&quot;&gt;&lt;code&gt;reduce_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_gather_multigpu&quot;&gt;&lt;code&gt;all_gather_multigpu()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.reduce_scatter_multigpu&quot;&gt;&lt;code&gt;reduce_scatter_multigpu()&lt;/code&gt;&lt;/a&gt; support distributed collective operations among multiple GPUs within each node. These functions can potentially improve the overall distributed training performance and be easily used by passing a list of tensors. Each Tensor in the passed tensor list needs to be on a separate GPU device of the host where the function is called. Note that the length of the tensor list needs to be identical among all the distributed processes. Also note that currently the multi-GPU collective functions are only supported by the NCCL backend.</source>
          <target state="translated">各ノードに複数のGPUがある場合、NCCLおよびGlooバックエンドを使用すると、&lt;a href=&quot;#torch.distributed.broadcast_multigpu&quot;&gt; &lt;code&gt;broadcast_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt; &lt;code&gt;all_reduce_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.reduce_multigpu&quot;&gt; &lt;code&gt;reduce_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_gather_multigpu&quot;&gt; &lt;code&gt;all_gather_multigpu()&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;#torch.distributed.reduce_scatter_multigpu&quot;&gt; &lt;code&gt;reduce_scatter_multigpu()&lt;/code&gt; &lt;/a&gt;は、各ノード内の複数のGPU間で分散された集合操作をサポートします。これらの関数は、分散トレーニングの全体的なパフォーマンスを向上させる可能性があり、テンソルのリストを渡すことで簡単に使用できます。渡されたテンソルリスト内の各テンソルは、関数が呼び出されるホストの個別のGPUデバイス上にある必要があります。テンソルリストの長さは、すべての分散プロセス間で同一である必要があることに注意してください。また、現在、マルチGPUコレクティブ機能はNCCLバックエンドでのみサポートされていることにも注意してください。</target>
        </trans-unit>
        <trans-unit id="318b82b9810de4a4d14eae5c37c587578c4b554f" translate="yes" xml:space="preserve">
          <source>If you need manual control over &lt;code&gt;.grad&lt;/code&gt;&amp;rsquo;s strides, assign &lt;code&gt;param.grad =&lt;/code&gt; a zeroed tensor with desired strides before the first &lt;code&gt;backward()&lt;/code&gt;, and never reset it to &lt;code&gt;None&lt;/code&gt;. 3 guarantees your layout is preserved as long as &lt;code&gt;create_graph=False&lt;/code&gt;. 4 indicates your layout is &lt;em&gt;likely&lt;/em&gt; preserved even if &lt;code&gt;create_graph=True&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;.grad&lt;/code&gt; のストライドを手動で制御する必要がある場合は、 &lt;code&gt;param.grad =&lt;/code&gt; 最初の &lt;code&gt;backward()&lt;/code&gt; の前に必要なストライドを持つゼロテンソルを割り当て、 &lt;code&gt;None&lt;/code&gt; にリセットしないでください。3は、 &lt;code&gt;create_graph=False&lt;/code&gt; である限りレイアウトが保持されることを保証します。4は、 &lt;code&gt;create_graph=True&lt;/code&gt; であってもレイアウトが保持される&lt;em&gt;可能性&lt;/em&gt;が&lt;em&gt;高い&lt;/em&gt;ことを示します。</target>
        </trans-unit>
        <trans-unit id="67bf24ac1005b3683fde52841b115c0871efc9f7" translate="yes" xml:space="preserve">
          <source>If you need to move a model to GPU via &lt;code&gt;.cuda()&lt;/code&gt;, please do so before constructing optimizers for it. Parameters of a model after &lt;code&gt;.cuda()&lt;/code&gt; will be different objects with those before the call.</source>
          <target state="translated">&lt;code&gt;.cuda()&lt;/code&gt; を介してモデルをGPUに移動する必要がある場合は、そのオプティマイザーを構築する前に移動してください。 &lt;code&gt;.cuda()&lt;/code&gt; の後のモデルのパラメーターは、呼び出し前のパラメーターとは異なるオブジェクトになります。</target>
        </trans-unit>
        <trans-unit id="136147687478e135ab5df6494e85fb08cdedac29" translate="yes" xml:space="preserve">
          <source>If you plan on using this module with a &lt;code&gt;nccl&lt;/code&gt; backend or a &lt;code&gt;gloo&lt;/code&gt; backend (that uses Infiniband), together with a DataLoader that uses multiple workers, please change the multiprocessing start method to &lt;code&gt;forkserver&lt;/code&gt; (Python 3 only) or &lt;code&gt;spawn&lt;/code&gt;. Unfortunately Gloo (that uses Infiniband) and NCCL2 are not fork safe, and you will likely experience deadlocks if you don&amp;rsquo;t change this setting.</source>
          <target state="translated">このモジュールを &lt;code&gt;nccl&lt;/code&gt; バックエンドまたは &lt;code&gt;gloo&lt;/code&gt; バックエンド（Infinibandを使用）と、複数のワーカーを使用するDataLoaderとともに使用する場合は、マルチプロセッシングの開始メソッドを &lt;code&gt;forkserver&lt;/code&gt; （Python 3のみ）または &lt;code&gt;spawn&lt;/code&gt; に変更してください。残念ながら、Gloo（Infinibandを使用）とNCCL2はフォークセーフではないため、この設定を変更しないとデッドロックが発生する可能性があります。</target>
        </trans-unit>
        <trans-unit id="07ab34f8fafef28d79bd246f9789bf5105b86f8b" translate="yes" xml:space="preserve">
          <source>If you plan to backpropagate through QR, note that the current backward implementation is only well-defined when the first</source>
          <target state="translated">QR を使ってバックプロパゲーションを行う予定の場合、現在のバックプロパゲーションの実装は、最初の</target>
        </trans-unit>
        <trans-unit id="1cd7b6977f27c5a4e9182f95ff2f859a518a8917" translate="yes" xml:space="preserve">
          <source>If you use &lt;code&gt;torch.save&lt;/code&gt; on one process to checkpoint the module, and &lt;code&gt;torch.load&lt;/code&gt; on some other processes to recover it, make sure that &lt;code&gt;map_location&lt;/code&gt; is configured properly for every process. Without &lt;code&gt;map_location&lt;/code&gt;, &lt;code&gt;torch.load&lt;/code&gt; would recover the module to devices where the module was saved from.</source>
          <target state="translated">1つのプロセスで &lt;code&gt;torch.save&lt;/code&gt; を使用してモジュールをチェックポイントし、他のいくつかのプロセスで &lt;code&gt;torch.load&lt;/code&gt; を使用してモジュールを回復する場合は、 &lt;code&gt;map_location&lt;/code&gt; がすべてのプロセスに対して適切に構成されていることを確認してください。 &lt;code&gt;torch.load&lt;/code&gt; がない &lt;code&gt;map_location&lt;/code&gt; 、torch.loadは、モジュールが保存されたデバイスにモジュールを回復します。</target>
        </trans-unit>
        <trans-unit id="74c65669b6d4e5ce564cda9931810dc0c170c246" translate="yes" xml:space="preserve">
          <source>If you want downsampling/general resizing, you should use &lt;code&gt;interpolate()&lt;/code&gt;.</source>
          <target state="translated">ダウンサンプリング/一般的なサイズ変更が必要な場合は、 &lt;code&gt;interpolate()&lt;/code&gt; を使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="ace4de17f2e6daea2f622c0b5c24ff868ca712b5" translate="yes" xml:space="preserve">
          <source>If you wish to checkpoint the scaler&amp;rsquo;s state after a particular iteration, &lt;a href=&quot;#torch.cuda.amp.GradScaler.state_dict&quot;&gt;&lt;code&gt;state_dict()&lt;/code&gt;&lt;/a&gt; should be called after &lt;a href=&quot;#torch.cuda.amp.GradScaler.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">特定の反復後にスケーラーの状態をチェックポイントする場合は、&lt;a href=&quot;#torch.cuda.amp.GradScaler.update&quot;&gt; &lt;code&gt;update()&lt;/code&gt; の&lt;/a&gt;後に&lt;a href=&quot;#torch.cuda.amp.GradScaler.state_dict&quot;&gt; &lt;code&gt;state_dict()&lt;/code&gt; &lt;/a&gt;を呼び出す必要があります。</target>
        </trans-unit>
        <trans-unit id="064ec7b53383c8d17c5751c9a34c0ac9daf7e8cd" translate="yes" xml:space="preserve">
          <source>If you&amp;rsquo;re using the Gloo backend, you can specify multiple interfaces by separating them by a comma, like this: &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3&lt;/code&gt;. The backend will dispatch operations in a round-robin fashion across these interfaces. It is imperative that all processes specify the same number of interfaces in this variable.</source>
          <target state="translated">Glooバックエンドを使用している場合は、次のように、複数のインターフェイスをカンマで区切って指定できます： &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3&lt;/code&gt; 。バックエンドは、これらのインターフェイス間でラウンドロビン方式で操作をディスパッチします。すべてのプロセスがこの変数に同じ数のインターフェースを指定することが不可欠です。</target>
        </trans-unit>
        <trans-unit id="40a9a99bd41d3dd35eb2ee9f7f247c013023dc94" translate="yes" xml:space="preserve">
          <source>If your InfiniBand has enabled IP over IB, use Gloo, otherwise, use MPI instead. We are planning on adding InfiniBand support for Gloo in the upcoming releases.</source>
          <target state="translated">InfiniBandでIP over IBを有効にしている場合はGlooを使用し、そうでない場合はMPIを使用してください。今後のリリースでは、GlooのInfiniBandサポートを追加する予定です。</target>
        </trans-unit>
        <trans-unit id="7ea2434c9b9d3a93397a8c29208e88de7aacbec3" translate="yes" xml:space="preserve">
          <source>If your use case is always 1-D sorted sequence, &lt;a href=&quot;torch.bucketize#torch.bucketize&quot;&gt;&lt;code&gt;torch.bucketize()&lt;/code&gt;&lt;/a&gt; is preferred, because it has fewer dimension checks resulting in slightly better performance.</source>
          <target state="translated">ユースケースが常に1次元でソートされたシーケンスである場合は、次元チェックが少なく、パフォーマンスがわずかに向上するため、&lt;a href=&quot;torch.bucketize#torch.bucketize&quot;&gt; &lt;code&gt;torch.bucketize()&lt;/code&gt; &lt;/a&gt;が推奨されます。</target>
        </trans-unit>
        <trans-unit id="52c2c0cd2584a6259a5f73e3f48627e08a00b06c" translate="yes" xml:space="preserve">
          <source>If, on the other hand, a backward pass with &lt;code&gt;create_graph=True&lt;/code&gt; is underway (in other words, if you are setting up for a double-backward), each function&amp;rsquo;s execution during backward is given a nonzero, useful &lt;code&gt;seq=&amp;lt;N&amp;gt;&lt;/code&gt;. Those functions may themselves create Function objects to be executed later during double-backward, just as the original functions in the forward pass did. The relationship between backward and double-backward is conceptually the same as the relationship between forward and backward: The functions still emit current-sequence-number-tagged ranges, the Function objects they create still stash those sequence numbers, and during the eventual double-backward, the Function objects&amp;rsquo; &lt;code&gt;apply()&lt;/code&gt; ranges are still tagged with &lt;code&gt;stashed seq&lt;/code&gt; numbers, which can be compared to &lt;code&gt;seq&lt;/code&gt; numbers from the backward pass.</source>
          <target state="translated">一方、 &lt;code&gt;create_graph=True&lt;/code&gt; の逆方向パスが進行中の場合（つまり、double-backwardを設定している場合）、逆方向での各関数の実行には、ゼロ以外の有用な &lt;code&gt;seq=&amp;lt;N&amp;gt;&lt;/code&gt; が与えられます。これらの関数自体が、フォワードパスの元の関数と同じように、後でダブルバックワード中に実行される関数オブジェクトを作成する場合があります。後方と二重後方の関係は、概念的には前方と後方の関係と同じです。関数は引き続き現在のシーケンス番号のタグ付き範囲を発行し、作成する関数オブジェクトは引き続きそれらのシーケンス番号を隠し、最終的には二重に後方では、関数オブジェクトの &lt;code&gt;apply()&lt;/code&gt; 範囲はまだ &lt;code&gt;stashed seq&lt;/code&gt; タグ付けされています数値。これは、バックワードパスの &lt;code&gt;seq&lt;/code&gt; 番号と比較できます。</target>
        </trans-unit>
        <trans-unit id="eec64bb7b6af56628b6864bb7faf7664a4d5fe90" translate="yes" xml:space="preserve">
          <source>Ignoring the optional batch dimension, this method computes the following expression:</source>
          <target state="translated">オプションのバッチ次元を無視して、このメソッドは以下の式を計算します。</target>
        </trans-unit>
        <trans-unit id="d5e7e82cbad5c6c7282eb3f91a5d122dc9858f8e" translate="yes" xml:space="preserve">
          <source>ImageNet 1-crop error rates (224x224)</source>
          <target state="translated">ImageNet 1クロップエラーレート(224x224</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="7aa6ad27b14b39704b337bb5273a54caf43dd27d" translate="yes" xml:space="preserve">
          <source>Implementation details: &lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https://arxiv.org/pdf/1806.08342.pdf&lt;/a&gt;</source>
          <target state="translated">実装の詳細：&lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https&lt;/a&gt;：//arxiv.org/pdf/1806.08342.pdf</target>
        </trans-unit>
        <trans-unit id="e2301206e5db52d9fb3a1373c4f2d128cbca7b09" translate="yes" xml:space="preserve">
          <source>Implementation details: &lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https://arxiv.org/pdf/1806.08342.pdf&lt;/a&gt; section 3.2.2</source>
          <target state="translated">実装の詳細：&lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https&lt;/a&gt;：//arxiv.org/pdf/1806.08342.pdfセクション3.2.2</target>
        </trans-unit>
        <trans-unit id="123ad8e975b9151926be8910a7ca29c06e0a08b2" translate="yes" xml:space="preserve">
          <source>Implementing a Parameter Server using Distributed RPC Framework</source>
          <target state="translated">分散RPCフレームワークを使用したパラメータサーバの実装</target>
        </trans-unit>
        <trans-unit id="44171a5d0f5320fd21c59c6c6516557d63659e70" translate="yes" xml:space="preserve">
          <source>Implementing batch RPC processing</source>
          <target state="translated">バッチRPC処理の実装</target>
        </trans-unit>
        <trans-unit id="138a4e92d697c7080168dd78d1fdd8142d73db58" translate="yes" xml:space="preserve">
          <source>Implements Adadelta algorithm.</source>
          <target state="translated">Adadelta アルゴリズムをインプリメントします。</target>
        </trans-unit>
        <trans-unit id="3f2f1bb826222edfff8f08a8965769571e6272e0" translate="yes" xml:space="preserve">
          <source>Implements Adagrad algorithm.</source>
          <target state="translated">Adagradアルゴリズムのインプリメント。</target>
        </trans-unit>
        <trans-unit id="f57315b0630de232938139c51a2a3c26106ba982" translate="yes" xml:space="preserve">
          <source>Implements Adam algorithm.</source>
          <target state="translated">アダムアルゴリズムを実装します。</target>
        </trans-unit>
        <trans-unit id="2c77540f43659b4faff14d608e5c738dcda6383c" translate="yes" xml:space="preserve">
          <source>Implements AdamW algorithm.</source>
          <target state="translated">AdamWアルゴリズムを実装しています。</target>
        </trans-unit>
        <trans-unit id="8ee370fe200b91f2533d1c27faf2c64f231383a7" translate="yes" xml:space="preserve">
          <source>Implements Adamax algorithm (a variant of Adam based on infinity norm).</source>
          <target state="translated">Adamaxアルゴリズム(無限大ノルムに基づくAdamの変形)を実装します。</target>
        </trans-unit>
        <trans-unit id="c03be935b69dc866871fdae88659292b8000bbfc" translate="yes" xml:space="preserve">
          <source>Implements Averaged Stochastic Gradient Descent.</source>
          <target state="translated">平均化された確率勾配降下を実装しています。</target>
        </trans-unit>
        <trans-unit id="05307e82588713f6b300d4819c8e92a2878569db" translate="yes" xml:space="preserve">
          <source>Implements L-BFGS algorithm, heavily inspired by &lt;code&gt;minFunc &amp;lt;https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html&amp;gt;&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;minFunc &amp;lt;https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html&amp;gt;&lt;/code&gt; に大きく影響を受けたL-BFGSアルゴリズムを実装します。</target>
        </trans-unit>
        <trans-unit id="bf2d15180174f2200375382c7122c5aecdd4ad8b" translate="yes" xml:space="preserve">
          <source>Implements RMSprop algorithm.</source>
          <target state="translated">RMSpropアルゴリズムをインプリメントします。</target>
        </trans-unit>
        <trans-unit id="9f29957e1ffbfbf9022787fc2c7cfe246141046c" translate="yes" xml:space="preserve">
          <source>Implements data parallelism at the module level.</source>
          <target state="translated">モジュールレベルでのデータ並列処理を実装します。</target>
        </trans-unit>
        <trans-unit id="247ad11e0e8ab7f7233963e6adbe7062bce23a44" translate="yes" xml:space="preserve">
          <source>Implements distributed data parallelism that is based on &lt;code&gt;torch.distributed&lt;/code&gt; package at the module level.</source>
          <target state="translated">モジュールレベルで &lt;code&gt;torch.distributed&lt;/code&gt; パッケージに基づく分散データ並列処理を実装します。</target>
        </trans-unit>
        <trans-unit id="dd0d130d28d26e9f00e5bf88ccace4711a7a11be" translate="yes" xml:space="preserve">
          <source>Implements lazy version of Adam algorithm suitable for sparse tensors.</source>
          <target state="translated">疎なテンソルに適したAdamアルゴリズムの遅延バージョンを実装しています.</target>
        </trans-unit>
        <trans-unit id="a2f16c33652615d2d8893f5da3944e675b6f0334" translate="yes" xml:space="preserve">
          <source>Implements stochastic gradient descent (optionally with momentum).</source>
          <target state="translated">確率的勾配降下を実装します(オプションでモメンタム付き).</target>
        </trans-unit>
        <trans-unit id="83cda66c04c86732b26204a544bebe240466f333" translate="yes" xml:space="preserve">
          <source>Implements the resilient backpropagation algorithm.</source>
          <target state="translated">弾力性のあるバックプロパゲーションアルゴリズムを実装しています。</target>
        </trans-unit>
        <trans-unit id="1ac98376b8dde644a48731cdda5a6c2f0a79cf77" translate="yes" xml:space="preserve">
          <source>Important Notice</source>
          <target state="translated">重要なお知らせ</target>
        </trans-unit>
        <trans-unit id="dbea8ebe841db621fdf156d683ca479b155b0a0f" translate="yes" xml:space="preserve">
          <source>Important consideration in the parameters &lt;code&gt;window&lt;/code&gt; and &lt;code&gt;center&lt;/code&gt; so that the envelop created by the summation of all the windows is never zero at certain point in time. Specifically,</source>
          <target state="translated">すべてのウィンドウの合計によって作成されたエンベロープが特定の時点でゼロにならないように、パラメータ &lt;code&gt;window&lt;/code&gt; と &lt;code&gt;center&lt;/code&gt; で重要な考慮事項。具体的には、</target>
        </trans-unit>
        <trans-unit id="f0e8d11c90c88612b519564a3a4ddc8195dcee1a" translate="yes" xml:space="preserve">
          <source>In &lt;code&gt;worker_init_fn&lt;/code&gt;, you may access the PyTorch seed set for each worker with either &lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt;&lt;code&gt;torch.utils.data.get_worker_info().seed&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.initial_seed#torch.initial_seed&quot;&gt;&lt;code&gt;torch.initial_seed()&lt;/code&gt;&lt;/a&gt;, and use it to seed other libraries before data loading.</source>
          <target state="translated">では &lt;code&gt;worker_init_fn&lt;/code&gt; 、あなたはどちらかと各ワーカーのためのPyTorchシードセットにアクセスすることができ&lt;a href=&quot;#torch.utils.data.get_worker_info&quot;&gt; &lt;code&gt;torch.utils.data.get_worker_info().seed&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;generated/torch.initial_seed#torch.initial_seed&quot;&gt; &lt;code&gt;torch.initial_seed()&lt;/code&gt; &lt;/a&gt;、およびデータのロード前に、他のライブラリをシードするためにそれを使用します。</target>
        </trans-unit>
        <trans-unit id="1546cf194023a313eda4a32e23fe8da2e85133d5" translate="yes" xml:space="preserve">
          <source>In a multilayer GRU, the input</source>
          <target state="translated">多層GRUでは、入力</target>
        </trans-unit>
        <trans-unit id="4ca4b7a5c3d05548dd2f62668a8daeab0e9ec06f" translate="yes" xml:space="preserve">
          <source>In a multilayer LSTM, the input</source>
          <target state="translated">多層LSTMでは、入力</target>
        </trans-unit>
        <trans-unit id="e20dc20835fec339c1d3cc16c346bd578e3d90d9" translate="yes" xml:space="preserve">
          <source>In addition to bools, floats, ints, and Tensors can be used in a conditional and will be implicitly casted to a boolean.</source>
          <target state="translated">bool以外にも、float、int、およびTensorsが条件付きで使用でき、暗黙のうちにbooleanにキャストされます。</target>
        </trans-unit>
        <trans-unit id="3a493aa393d90ed5e727839c89230e8cffd94159" translate="yes" xml:space="preserve">
          <source>In addition to the core statistics, we also provide some simple event counters:</source>
          <target state="translated">コア統計に加えて、いくつかの簡単なイベントカウンタも提供しています。</target>
        </trans-unit>
        <trans-unit id="121bfc6001439fa824c41c891327b9bc48e17ca8" translate="yes" xml:space="preserve">
          <source>In addition, one can now create tensors with &lt;code&gt;requires_grad=True&lt;/code&gt; using factory methods such as &lt;a href=&quot;generated/torch.randn#torch.randn&quot;&gt;&lt;code&gt;torch.randn()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.zeros#torch.zeros&quot;&gt;&lt;code&gt;torch.zeros()&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;generated/torch.ones#torch.ones&quot;&gt;&lt;code&gt;torch.ones()&lt;/code&gt;&lt;/a&gt;, and others like the following:</source>
          <target state="translated">さらに、&lt;a href=&quot;generated/torch.randn#torch.randn&quot;&gt; &lt;code&gt;torch.randn()&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/torch.zeros#torch.zeros&quot;&gt; &lt;code&gt;torch.zeros()&lt;/code&gt; &lt;/a&gt;、&lt;a href=&quot;generated/torch.ones#torch.ones&quot;&gt; &lt;code&gt;torch.ones()&lt;/code&gt; &lt;/a&gt;などのファクトリメソッドを使用して、 &lt;code&gt;requires_grad=True&lt;/code&gt; でテンソルを作成できるようになりました。</target>
        </trans-unit>
        <trans-unit id="14b2f80199ae20e9c340149a30176ab138c9610a" translate="yes" xml:space="preserve">
          <source>In both cases of single-node distributed training or multi-node distributed training, this utility will launch the given number of processes per node (&lt;code&gt;--nproc_per_node&lt;/code&gt;). If used for GPU training, this number needs to be less or equal to the number of GPUs on the current system (&lt;code&gt;nproc_per_node&lt;/code&gt;), and each process will be operating on a single GPU from &lt;em&gt;GPU 0 to GPU (nproc_per_node - 1)&lt;/em&gt;.</source>
          <target state="translated">シングルノード分散トレーニングまたはマルチノード分散トレーニングのどちらの場合も、このユーティリティはノードごとに指定された数のプロセスを起動します（ &lt;code&gt;--nproc_per_node&lt;/code&gt; ）。GPUトレーニングに使用する場合、この数は現在のシステムのGPUの数（ &lt;code&gt;nproc_per_node&lt;/code&gt; ）以下である必要があり、各プロセスは&lt;em&gt;GPU 0からGPU（nproc_per_node -1）&lt;/em&gt;までの単一のGPUで動作します。</target>
        </trans-unit>
        <trans-unit id="0e876cc3bbe05952d2705985bee305b58baf29ac" translate="yes" xml:space="preserve">
          <source>In cases like these, tracing would not be appropriate and &lt;a href=&quot;torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;scripting&lt;/code&gt;&lt;/a&gt; is a better choice. If you trace such models, you may silently get incorrect results on subsequent invocations of the model. The tracer will try to emit warnings when doing something that may cause an incorrect trace to be produced.</source>
          <target state="translated">このような場合、トレースは適切ではなく、&lt;a href=&quot;torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;scripting&lt;/code&gt; &lt;/a&gt;を使用することをお勧めします。このようなモデルをトレースすると、その後のモデルの呼び出しでサイレントに誤った結果が得られる可能性があります。トレーサーは、誤ったトレースが生成される原因となる可能性のある処理を実行すると、警告を発しようとします。</target>
        </trans-unit>
        <trans-unit id="2210461412c5abe9090cdb0e1f87af39668c1506" translate="yes" xml:space="preserve">
          <source>In certain cases, users may want to handle batching manually in dataset code, or simply load individual samples. For example, it could be cheaper to directly load batched data (e.g., bulk reads from a database or reading continuous chunks of memory), or the batch size is data dependent, or the program is designed to work on individual samples. Under these scenarios, it&amp;rsquo;s likely better to not use automatic batching (where &lt;code&gt;collate_fn&lt;/code&gt; is used to collate the samples), but let the data loader directly return each member of the &lt;code&gt;dataset&lt;/code&gt; object.</source>
          <target state="translated">場合によっては、ユーザーはデータセットコードでバッチ処理を手動で処理したり、単に個々のサンプルを読み込んだりすることがあります。たとえば、バッチデータを直接ロードする方が安価な場合（データベースからの一括読み取りやメモリの連続チャンクの読み取りなど）、バッチサイズがデータに依存する場合、プログラムが個々のサンプルで動作するように設計されている場合などです。これらのシナリオでは、自動バッチ処理（ &lt;code&gt;collate_fn&lt;/code&gt; を使用してサンプルを照合する）を使用しない方がよいでしょうが、データローダーが &lt;code&gt;dataset&lt;/code&gt; オブジェクトの各メンバーを直接返すようにします。</target>
        </trans-unit>
        <trans-unit id="86e76c5e72e3158e53103708c732b0ca2fb77314" translate="yes" xml:space="preserve">
          <source>In default &lt;code&gt;reduction&lt;/code&gt; mode &lt;code&gt;'mean'&lt;/code&gt;, the losses are averaged for each minibatch over observations &lt;strong&gt;as well as&lt;/strong&gt; over dimensions. &lt;code&gt;'batchmean'&lt;/code&gt; mode gives the correct KL divergence where losses are averaged over batch dimension only. &lt;code&gt;'mean'&lt;/code&gt; mode&amp;rsquo;s behavior will be changed to the same as &lt;code&gt;'batchmean'&lt;/code&gt; in the next major release.</source>
          <target state="translated">デフォルトの &lt;code&gt;reduction&lt;/code&gt; モード &lt;code&gt;'mean'&lt;/code&gt; では、損失は、観測値&lt;strong&gt;および&lt;/strong&gt;次元全体のミニバッチごとに平均化&lt;strong&gt;さ&lt;/strong&gt;れます。 &lt;code&gt;'batchmean'&lt;/code&gt; モードは、損失がバッチ次元でのみ平均化される正しいKL発散を提供します。 &lt;code&gt;'mean'&lt;/code&gt; モードの動作は、次のメジャーリリースで &lt;code&gt;'batchmean'&lt;/code&gt; と同じに変更されます。</target>
        </trans-unit>
        <trans-unit id="c3aa986e649ca9866807ff9f998ea701984440c5" translate="yes" xml:space="preserve">
          <source>In distributed mode, calling the &lt;code&gt;set_epoch()&lt;/code&gt; method at the beginning of each epoch &lt;strong&gt;before&lt;/strong&gt; creating the &lt;code&gt;DataLoader&lt;/code&gt; iterator is necessary to make shuffling work properly across multiple epochs. Otherwise, the same ordering will be always used.</source>
          <target state="translated">分散モードでは、 &lt;code&gt;DataLoader&lt;/code&gt; イテレータを作成する&lt;strong&gt;前に&lt;/strong&gt;、各エポックの開始時に &lt;code&gt;set_epoch()&lt;/code&gt; メソッドを呼び出す必要があります。これにより、複数のエポック間でシャッフルが適切に機能します。それ以外の場合は、常に同じ順序が使用されます。&lt;strong&gt;&lt;/strong&gt;</target>
        </trans-unit>
        <trans-unit id="d7469a9738cf72345e41f4a9561f6407dd3c1952" translate="yes" xml:space="preserve">
          <source>In each forward, &lt;code&gt;module&lt;/code&gt; is &lt;strong&gt;replicated&lt;/strong&gt; on each device, so any updates to the running module in &lt;code&gt;forward&lt;/code&gt; will be lost. For example, if &lt;code&gt;module&lt;/code&gt; has a counter attribute that is incremented in each &lt;code&gt;forward&lt;/code&gt;, it will always stay at the initial value because the update is done on the replicas which are destroyed after &lt;code&gt;forward&lt;/code&gt;. However, &lt;a href=&quot;#torch.nn.DataParallel&quot;&gt;&lt;code&gt;DataParallel&lt;/code&gt;&lt;/a&gt; guarantees that the replica on &lt;code&gt;device[0]&lt;/code&gt; will have its parameters and buffers sharing storage with the base parallelized &lt;code&gt;module&lt;/code&gt;. So &lt;strong&gt;in-place&lt;/strong&gt; updates to the parameters or buffers on &lt;code&gt;device[0]&lt;/code&gt; will be recorded. E.g., &lt;a href=&quot;torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.utils.spectral_norm#torch.nn.utils.spectral_norm&quot;&gt;&lt;code&gt;spectral_norm()&lt;/code&gt;&lt;/a&gt; rely on this behavior to update the buffers.</source>
          <target state="translated">フォワードごとに、 &lt;code&gt;module&lt;/code&gt; は各デバイスに&lt;strong&gt;複製&lt;/strong&gt;されるため、 &lt;code&gt;forward&lt;/code&gt; 実行中のモジュールへの更新はすべて失われます。たとえば、 &lt;code&gt;module&lt;/code&gt; それぞれにインクリメントされるカウンタの属性があり &lt;code&gt;forward&lt;/code&gt; 更新が後に破壊されたレプリカ上で行われているので、それは常に初期値に滞在する &lt;code&gt;forward&lt;/code&gt; 。ただし、&lt;a href=&quot;#torch.nn.DataParallel&quot;&gt; &lt;code&gt;DataParallel&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;device[0]&lt;/code&gt; 上のレプリカが、ベースの並列化 &lt;code&gt;module&lt;/code&gt; とストレージを共有するパラメーターとバッファーを持つことを保証します。そのため、 &lt;code&gt;device[0]&lt;/code&gt; パラメーターまたはバッファーに対する&lt;strong&gt;インプレース&lt;/strong&gt;更新が記録されます。例えば、&lt;a href=&quot;torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;BatchNorm2d&lt;/code&gt; &lt;/a&gt;とspectrum_norm &lt;a href=&quot;torch.nn.utils.spectral_norm#torch.nn.utils.spectral_norm&quot;&gt; &lt;code&gt;spectral_norm()&lt;/code&gt; &lt;/a&gt;、この動作に依存してバッファーを更新します。</target>
        </trans-unit>
        <trans-unit id="985dc1f8616a9367ef67f7e8fb270d75af2e49e6" translate="yes" xml:space="preserve">
          <source>In fact, resetting all &lt;code&gt;.grad&lt;/code&gt;s to &lt;code&gt;None&lt;/code&gt; before each accumulation phase, e.g.:</source>
          <target state="translated">実際、各蓄積フェーズの前にすべての &lt;code&gt;.grad&lt;/code&gt; を &lt;code&gt;None&lt;/code&gt; にリセットします。例：</target>
        </trans-unit>
        <trans-unit id="c4c7ae6e45efeeb88e3de47cc32025f3afeae3d6" translate="yes" xml:space="preserve">
          <source>In general, folding and unfolding operations are related as follows. Consider &lt;a href=&quot;#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; instances created with the same parameters:</source>
          <target state="translated">一般に、折り畳み操作と展開操作は次のように関連しています。同じパラメーターで作成された&lt;a href=&quot;#torch.nn.Fold&quot;&gt; &lt;code&gt;Fold&lt;/code&gt; &lt;/a&gt;インスタンスと&lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt; &lt;code&gt;Unfold&lt;/code&gt; &lt;/a&gt;インスタンスについて考えてみます。</target>
        </trans-unit>
        <trans-unit id="14a82233b9f46d949d131d9066b4b1e345f4a14b" translate="yes" xml:space="preserve">
          <source>In general, folding and unfolding operations are related as follows. Consider &lt;a href=&quot;torch.nn.fold#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; instances created with the same parameters:</source>
          <target state="translated">一般に、折り畳み操作と展開操作は次のように関連しています。同じパラメーターで作成された&lt;a href=&quot;torch.nn.fold#torch.nn.Fold&quot;&gt; &lt;code&gt;Fold&lt;/code&gt; &lt;/a&gt;インスタンスと&lt;a href=&quot;#torch.nn.Unfold&quot;&gt; &lt;code&gt;Unfold&lt;/code&gt; &lt;/a&gt;インスタンスについて考えてみます。</target>
        </trans-unit>
        <trans-unit id="1855810e3cc280e259c5b815913beac56d322de4" translate="yes" xml:space="preserve">
          <source>In general, the basic method spends least time per iteration. However, the robust methods converge much faster and are more stable. So, the usage of the basic method is generally not recommended but there exist cases where the usage of the basic method may be preferred.</source>
          <target state="translated">一般的に、基本的な方法は、繰り返しあたりの時間が最も短くなります。しかし、ロバスト法はより速く収束し、より安定しています。そのため、基本法の使用は一般的に推奨されませんが、基本法の使用が好ましい場合もあります。</target>
        </trans-unit>
        <trans-unit id="5a8901639688080e9ddf9086d6c38d66aa6d29ff" translate="yes" xml:space="preserve">
          <source>In general, use the full-rank SVD implementation &lt;code&gt;torch.svd&lt;/code&gt; for dense matrices due to its 10-fold higher performance characteristics. The low-rank SVD will be useful for huge sparse matrices that &lt;code&gt;torch.svd&lt;/code&gt; cannot handle.</source>
          <target state="translated">一般に、10倍高いパフォーマンス特性があるため、密行列にはフルランクのSVD実装 &lt;code&gt;torch.svd&lt;/code&gt; を使用します。低ランクのSVDは、 &lt;code&gt;torch.svd&lt;/code&gt; が処理できない巨大なスパース行列に役立ちます。</target>
        </trans-unit>
        <trans-unit id="f1278ae47dd736566667f86259def089c9bd6886" translate="yes" xml:space="preserve">
          <source>In general, you should make sure that optimized parameters live in consistent locations when optimizers are constructed and used.</source>
          <target state="translated">一般的に、オプティマイザを構築して使用する際には、最適化されたパラメータが一貫した場所に存在することを確認する必要があります。</target>
        </trans-unit>
        <trans-unit id="809a8a0c78ca14c8503127d00dd103ee7f6c80b0" translate="yes" xml:space="preserve">
          <source>In many cases either tracing or scripting is an easier approach for converting a model to TorchScript. Tracing and scripting can be composed to suit the particular requirements of a part of a model.</source>
          <target state="translated">多くの場合、モデルをTorchScriptに変換するには、トレースまたはスクリプトのどちらかの方が簡単な方法です。トレースとスクリプトは、モデルの一部の特定の要件に合わせて構成することができます。</target>
        </trans-unit>
        <trans-unit id="6485ce8afe7564cea5c8362029901ba50e16aea8" translate="yes" xml:space="preserve">
          <source>In order to spawn up multiple processes per node, you can use either &lt;code&gt;torch.distributed.launch&lt;/code&gt; or &lt;code&gt;torch.multiprocessing.spawn&lt;/code&gt;.</source>
          <target state="translated">ノードごとに複数のプロセスを生成するには、 &lt;code&gt;torch.distributed.launch&lt;/code&gt; または &lt;code&gt;torch.multiprocessing.spawn&lt;/code&gt; のいずれかを使用できます。</target>
        </trans-unit>
        <trans-unit id="40c808fe1c4d6bdfde7e41f404147333e778923e" translate="yes" xml:space="preserve">
          <source>In order to use CuDNN, the following must be satisfied: &lt;code&gt;targets&lt;/code&gt; must be in concatenated format, all &lt;code&gt;input_lengths&lt;/code&gt; must be &lt;code&gt;T&lt;/code&gt;.</source>
          <target state="translated">CuDNNを使用するには、次の条件を満たす必要があります。 &lt;code&gt;targets&lt;/code&gt; は連結形式である必要があり、すべての &lt;code&gt;input_lengths&lt;/code&gt; は &lt;code&gt;T&lt;/code&gt; である必要があります。</target>
        </trans-unit>
        <trans-unit id="5224913092c4a84680bc86a2c5b52f3a9390a2e0" translate="yes" xml:space="preserve">
          <source>In other words, for an input of size</source>
          <target state="translated">言い換えれば、サイズの入力に対して</target>
        </trans-unit>
        <trans-unit id="6f63e1b44e4587b6cbe87da3c99588530141677e" translate="yes" xml:space="preserve">
          <source>In particular, solves</source>
          <target state="translated">具体的には、以下のような問題を解決します。</target>
        </trans-unit>
        <trans-unit id="43678d1fc6309b5815b7dedc1dd771218daaa610" translate="yes" xml:space="preserve">
          <source>In practice we would sample an action from the output of a network, apply this action in an environment, and then use &lt;code&gt;log_prob&lt;/code&gt; to construct an equivalent loss function. Note that we use a negative because optimizers use gradient descent, whilst the rule above assumes gradient ascent. With a categorical policy, the code for implementing REINFORCE would be as follows:</source>
          <target state="translated">実際には、ネットワークの出力からアクションをサンプリングし、このアクションを環境に適用してから、 &lt;code&gt;log_prob&lt;/code&gt; を使用して同等の損失関数を作成します。オプティマイザーは最急降下法を使用するため、負の値を使用しますが、上記のルールは最急降下法を想定していることに注意してください。カテゴリポリシーを使用すると、REINFORCEを実装するためのコードは次のようになります。</target>
        </trans-unit>
        <trans-unit id="1cb4118455a2bb7d53d0e1417d8853260cb96078" translate="yes" xml:space="preserve">
          <source>In practice, when working with named tensors, one should avoid having unnamed dimensions because their handling can be complicated. It is recommended to lift all unnamed dimensions to be named dimensions by using &lt;a href=&quot;#torch.Tensor.refine_names&quot;&gt;&lt;code&gt;refine_names()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">実際には、名前付きテンソルを使用する場合、処理が複雑になる可能性があるため、名前なしの次元を使用しないようにする必要があります。&lt;a href=&quot;#torch.Tensor.refine_names&quot;&gt; &lt;code&gt;refine_names()&lt;/code&gt; &lt;/a&gt;を使用して、名前のないすべてのディメンションを持ち上げて名前の付いたディメンションにすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="df5ee95eb608e3ef9c532ed1dab9ce8f7003c283" translate="yes" xml:space="preserve">
          <source>In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting &lt;code&gt;torch.backends.cudnn.deterministic =
True&lt;/code&gt;. Please see the notes on &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;Reproducibility&lt;/a&gt; for background.</source>
          <target state="translated">状況によっては、CuDNNでCUDAバックエンドを使用する場合、この演算子はパフォーマンスを向上させるために非決定論的アルゴリズムを選択する場合があります。これが望ましくない場合は、 &lt;code&gt;torch.backends.cudnn.deterministic = True&lt;/code&gt; 設定することで、操作を決定論的にすることができます（パフォーマンスコストがかかる可能性があります）。背景については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;再現性&lt;/a&gt;に関する注記を参照してください。</target>
        </trans-unit>
        <trans-unit id="e14a819b75469318610313772eb13bce47023e07" translate="yes" xml:space="preserve">
          <source>In the above example, aten::triu is not supported in ONNX, hence exporter falls back on this op. OperatorExportTypes.RAW: Export raw ir. OperatorExportTypes.ONNX_FALLTHROUGH: If an op is not supported in ONNX, fall through and export the operator as is, as a custom ONNX op. Using this mode, the op can be exported and implemented by the user for their runtime backend. Example graph:</source>
          <target state="translated">上記の例では、aten::triuはONNXではサポートされていないため、エクスポートはこのオペランドにフォールバックします。OperatorExportTypes.RAW:raw irをエクスポートします。OperatorExportTypes.ONNX_FALLTHROUGH:オペレータがONNXでサポートされていない場合、フォールスルーして、オペレータをそのままカスタムONNXオペレータとしてエクスポートします。このモードを使用すると、ユーザーはランタイムバックエンド用に演算子をエクスポートして実装することができます。グラフの例。</target>
        </trans-unit>
        <trans-unit id="b3a5fd174642790bebe72eca626e159e3e5dfcd8" translate="yes" xml:space="preserve">
          <source>In the above example, prim::ListConstruct is not supported, hence exporter falls through.</source>
          <target state="translated">上記の例では、prim::ListConstruct はサポートされていません。</target>
        </trans-unit>
        <trans-unit id="7c25e2887a622adc243b3c60db24b8cbea2277b3" translate="yes" xml:space="preserve">
          <source>In the case of batches of square matrices with size less or equal to 32 on a CUDA device, the LU factorization is repeated for singular matrices due to the bug in the MAGMA library (see magma issue 13).</source>
          <target state="translated">CUDAデバイス上でサイズが32以下の正方行列のバッチの場合、MAGMAライブラリのバグにより、特異行列に対してLU因数分解が繰り返されます(magma第13号を参照)。</target>
        </trans-unit>
        <trans-unit id="f0075edff8aa44b42fa791f6d655add581639408" translate="yes" xml:space="preserve">
          <source>In the example below, &lt;code&gt;swa_model&lt;/code&gt; is the SWA model that accumulates the averages of the weights. We train the model for a total of 300 epochs and we switch to the SWA learning rate schedule and start to collect SWA averages of the parameters at epoch 160:</source>
          <target state="translated">以下の例では、 &lt;code&gt;swa_model&lt;/code&gt; は重みの平均を累積するSWAモデルです。合計300エポックのモデルをトレーニングし、SWA学習率スケジュールに切り替えて、エポック160でパラメーターのSWA平均の収集を開始します。</target>
        </trans-unit>
        <trans-unit id="7889605442c466f81697836a1b9ec1edd9e39e26" translate="yes" xml:space="preserve">
          <source>In the following table, we use 8 V100 GPUs, with CUDA 10.0 and CUDNN 7.4 to report the results. During training, we use a batch size of 2 per GPU, and during testing a batch size of 1 is used.</source>
          <target state="translated">以下の表では、8台のV100 GPUを使用し、CUDA 10.0とCUDNN 7.4で結果を報告します。トレーニング時にはGPUごとに2のバッチサイズを使用し、テスト時には1のバッチサイズを使用しています。</target>
        </trans-unit>
        <trans-unit id="33fa5776db9b9bbfad4e856c392d72e978768794" translate="yes" xml:space="preserve">
          <source>In the future, &lt;a href=&quot;#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt; may return a non-writeable view for an &lt;code&gt;input&lt;/code&gt; of non-complex dtype. It&amp;rsquo;s recommended that programs not modify the tensor returned by &lt;a href=&quot;#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;input&lt;/code&gt; is of non-complex dtype to be compatible with this change.</source>
          <target state="translated">将来、&lt;a href=&quot;#torch.conj&quot;&gt; &lt;code&gt;torch.conj()&lt;/code&gt; &lt;/a&gt;は、複雑でないdtypeの &lt;code&gt;input&lt;/code&gt; に対して書き込み不可能なビューを返す可能性があります。この変更と互換性があるように、 &lt;code&gt;input&lt;/code&gt; が非複雑なdtypeの場合、プログラムは&lt;a href=&quot;#torch.conj&quot;&gt; &lt;code&gt;torch.conj()&lt;/code&gt; &lt;/a&gt;によって返されるテンソルを変更しないことをお勧めします。</target>
        </trans-unit>
        <trans-unit id="99f1ee81dc5eba42240face3c5c428f4a78edd8a" translate="yes" xml:space="preserve">
          <source>In the future, there will be backends for other frameworks as well.</source>
          <target state="translated">将来的には、他のフレームワークのバックエンドも用意する予定です。</target>
        </trans-unit>
        <trans-unit id="d25cb11f14e2999086551374695bf04a7bfaf842" translate="yes" xml:space="preserve">
          <source>In the past, we were often asked: &amp;ldquo;which backend should I use?&amp;rdquo;.</source>
          <target state="translated">以前は、「どのバックエンドを使用すればよいですか？」とよく聞かれました。</target>
        </trans-unit>
        <trans-unit id="0b0a51e5781bdbc893d9a5aff9fe6d5b37f0885c" translate="yes" xml:space="preserve">
          <source>In the returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, operations that have different behaviors in &lt;code&gt;training&lt;/code&gt; and &lt;code&gt;eval&lt;/code&gt; modes will always behave as if it is in the mode it was in during tracing, no matter which mode the &lt;code&gt;ScriptModule&lt;/code&gt; is in.</source>
          <target state="translated">返された&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;では、 &lt;code&gt;training&lt;/code&gt; モードと &lt;code&gt;eval&lt;/code&gt; モードで動作が異なる操作は、 &lt;code&gt;ScriptModule&lt;/code&gt; がどのモードにあるかに関係なく、トレース中にあったモードにあるかのように常に動作します。</target>
        </trans-unit>
        <trans-unit id="b3daaa94feed4c186e9e9a97512618fa018aae7f" translate="yes" xml:space="preserve">
          <source>In the simplest case, the output value of the layer with input size</source>
          <target state="translated">最も単純なケースでは、入力サイズを持つレイヤの出力値</target>
        </trans-unit>
        <trans-unit id="239b7a59f23d668ac60e6721fee439268e244221" translate="yes" xml:space="preserve">
          <source>In the single-machine synchronous case, &lt;code&gt;torch.distributed&lt;/code&gt; or the &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; wrapper may still have advantages over other approaches to data-parallelism, including &lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel()&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">単一マシンの同期の場合、 &lt;code&gt;torch.distributed&lt;/code&gt; または&lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt; &lt;/a&gt;ラッパーは、&lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt; &lt;code&gt;torch.nn.DataParallel()&lt;/code&gt; &lt;/a&gt;を含むデータ並列処理の他のアプローチよりも優れている場合があります。</target>
        </trans-unit>
        <trans-unit id="1e133f6f146acb51fdcd21b510ff4101dead133b" translate="yes" xml:space="preserve">
          <source>In the spatial (4-D) case, for &lt;code&gt;input&lt;/code&gt; with shape</source>
          <target state="translated">空間（4-D）の場合、形状を使用した &lt;code&gt;input&lt;/code&gt; 場合</target>
        </trans-unit>
        <trans-unit id="51ee81d82611ed15672cbe78ad3be970f77568fa" translate="yes" xml:space="preserve">
          <source>In the symbolic function, if the operator is already standardized in ONNX, we just need to create a node to represent the ONNX operator in the graph.</source>
          <target state="translated">シンボリック関数では、既にONNXで標準化されている演算子であれば、ONNXの演算子をグラフで表現するためのノードを作成するだけでよい。</target>
        </trans-unit>
        <trans-unit id="05f2edf0966166823005056e0975e4e593b57b37" translate="yes" xml:space="preserve">
          <source>In the symbolic function, if the operator is already standardized in ONNX, we only need to create a node to represent the ONNX operator in the graph.</source>
          <target state="translated">シンボリック関数では、ONNXで既に標準化されている演算子であれば、ONNXの演算子をグラフで表現するためのノードを作成するだけでよい。</target>
        </trans-unit>
        <trans-unit id="84a6816bbe45c61bb1b6bef7593d5a6c612e3f5a" translate="yes" xml:space="preserve">
          <source>In these regions, CUDA ops run in an op-specific dtype chosen by autocast to improve performance while maintaining accuracy. See the &lt;a href=&quot;#autocast-op-reference&quot;&gt;Autocast Op Reference&lt;/a&gt; for details.</source>
          <target state="translated">これらのリージョンでは、CUDA opsは、精度を維持しながらパフォーマンスを向上させるために、自動キャストによって選択されたop固有のdtypeで実行されます。詳細については、&lt;a href=&quot;#autocast-op-reference&quot;&gt;Autocast OpReferenceを参照&lt;/a&gt;してください。</target>
        </trans-unit>
        <trans-unit id="c41d2ba36e63a36e43970f33786546314d161009" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;nn.Dropout2d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">In this case, &lt;code&gt;nn.Dropout2d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="df2da228c2bd90611f132d29496ecf7b2c5d7aaa" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;nn.Dropout3d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">In this case, &lt;code&gt;nn.Dropout3d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="f8b3c9fa943c89a945d6617acdfae17b22a6204e" translate="yes" xml:space="preserve">
          <source>In this case, data-dependent control flow like this can be captured using &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;torch.jit.script()&lt;/code&gt;&lt;/a&gt; instead:</source>
          <target state="translated">In this case, data-dependent control flow like this can be captured using &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;torch.jit.script()&lt;/code&gt; &lt;/a&gt; instead:</target>
        </trans-unit>
        <trans-unit id="a5eaf16a960fd80b4157d86a90c080399cfb6b65" translate="yes" xml:space="preserve">
          <source>In this case, loading from a map-style dataset is roughly equivalent with:</source>
          <target state="translated">この場合、マップ形式のデータセットからの読み込みは、大体これと同等のものになります。</target>
        </trans-unit>
        <trans-unit id="0dd020ad3088741e2272795fe9b24fb663481ec2" translate="yes" xml:space="preserve">
          <source>In this mode, data fetching is done in the same process a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; is initialized. Therefore, data loading may block computing. However, this mode may be preferred when resource(s) used for sharing data among processes (e.g., shared memory, file descriptors) is limited, or when the entire dataset is small and can be loaded entirely in memory. Additionally, single-process loading often shows more readable error traces and thus is useful for debugging.</source>
          <target state="translated">このモードでは、データフェッチは&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;が初期化されるのと同じプロセスで実行されます。したがって、データの読み込みによってコンピューティングがブロックされる可能性があります。ただし、このモードは、プロセス間でデータを共有するために使用されるリソース（共有メモリ、ファイル記述子など）が限られている場合、またはデータセット全体が小さく、完全にメモリにロードできる場合に適しています。さらに、単一プロセスのロードでは、多くの場合、より読みやすいエラートレースが表示されるため、デバッグに役立ちます。</target>
        </trans-unit>
        <trans-unit id="37db45d569ba92c31b1894c46ec1eedf759f889f" translate="yes" xml:space="preserve">
          <source>In this mode, each time an iterator of a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; is created (e.g., when you call &lt;code&gt;enumerate(dataloader)&lt;/code&gt;), &lt;code&gt;num_workers&lt;/code&gt; worker processes are created. At this point, the &lt;code&gt;dataset&lt;/code&gt;, &lt;code&gt;collate_fn&lt;/code&gt;, and &lt;code&gt;worker_init_fn&lt;/code&gt; are passed to each worker, where they are used to initialize, and fetch data. This means that dataset access together with its internal IO, transforms (including &lt;code&gt;collate_fn&lt;/code&gt;) runs in the worker process.</source>
          <target state="translated">このモードでは、&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; の&lt;/a&gt;イテレーターが作成されるたびに（たとえば、 &lt;code&gt;enumerate(dataloader)&lt;/code&gt; を呼び出すと）、 &lt;code&gt;num_workers&lt;/code&gt; ワーカープロセスが作成されます。この時点で、 &lt;code&gt;dataset&lt;/code&gt; 、 &lt;code&gt;collate_fn&lt;/code&gt; 、および &lt;code&gt;worker_init_fn&lt;/code&gt; が各ワーカーに渡され、そこでデータの初期化とフェッチに使用されます。これは、データセットアクセスとその内部IO、変換（ &lt;code&gt;collate_fn&lt;/code&gt; を含む）がワーカープロセスで実行されることを意味します。</target>
        </trans-unit>
        <trans-unit id="85295238e8aebda5327b95ca72369c8df3c9eab9" translate="yes" xml:space="preserve">
          <source>In this mode, the result of every computation will have &lt;code&gt;requires_grad=False&lt;/code&gt;, even when the inputs have &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="translated">In this mode, the result of every computation will have &lt;code&gt;requires_grad=False&lt;/code&gt; , even when the inputs have &lt;code&gt;requires_grad=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91c8c0bce1c0356637c4656cf0a0cca8ed0c2a41" translate="yes" xml:space="preserve">
          <source>In this section please find the documentation for named tensor specific APIs. For a comprehensive reference for how names are propagated through other PyTorch operators, see &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt;.</source>
          <target state="translated">In this section please find the documentation for named tensor specific APIs. For a comprehensive reference for how names are propagated through other PyTorch operators, see &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6458e074d9a813cc3dc5f6d0f9ad52155e927d58" translate="yes" xml:space="preserve">
          <source>In this variant, only moments that show up in the gradient get updated, and only those portions of the gradient get applied to the parameters.</source>
          <target state="translated">このバリアントでは、グラデーションに現れるモーメントのみが更新され、グラデーションの部分のみがパラメータに適用されます。</target>
        </trans-unit>
        <trans-unit id="13102db919fdc00f95907c16ae125b4a1f45c313" translate="yes" xml:space="preserve">
          <source>In version 1.6 changed to this from set_training</source>
          <target state="translated">バージョン1.6では、set_trainingからこれに変更されました。</target>
        </trans-unit>
        <trans-unit id="de12c6841ad61e706ed4075c85bb11d26176e1ff" translate="yes" xml:space="preserve">
          <source>In-place correctness checks</source>
          <target state="translated">場面での正しさチェック</target>
        </trans-unit>
        <trans-unit id="16a694343d462dfe3161b9f7e507c3e45c250203" translate="yes" xml:space="preserve">
          <source>In-place operations on Tensors</source>
          <target state="translated">テンソルのインプレース操作</target>
        </trans-unit>
        <trans-unit id="90ef0f5bd340db15b402881b337b9e6fd1b54dd1" translate="yes" xml:space="preserve">
          <source>In-place random sampling</source>
          <target state="translated">インプレイスランダムサンプリング</target>
        </trans-unit>
        <trans-unit id="1723c07101158e28ed701a45820ffb2cbec954ae" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.abs&quot;&gt;&lt;code&gt;abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.abs&quot;&gt; &lt;code&gt;abs()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="24948f16983220b792808971db48b1bcdd5b3fa1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.absolute&quot;&gt;&lt;code&gt;absolute()&lt;/code&gt;&lt;/a&gt; Alias for &lt;a href=&quot;#torch.Tensor.abs_&quot;&gt;&lt;code&gt;abs_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.absolute&quot;&gt; &lt;code&gt;absolute()&lt;/code&gt; &lt;/a&gt; Alias for &lt;a href=&quot;#torch.Tensor.abs_&quot;&gt; &lt;code&gt;abs_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dde70002d7610f16bccc15d518923eec4d107bba" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.acos&quot;&gt;&lt;code&gt;acos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.acos&quot;&gt; &lt;code&gt;acos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f828fea297a593b936b38df78e2d795295f80f1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.acosh&quot;&gt;&lt;code&gt;acosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.acosh&quot;&gt; &lt;code&gt;acosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6e2ef98fa9aa6aca8a1bdb5dad128434e35bceaa" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.add&quot;&gt;&lt;code&gt;add()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.add&quot;&gt; &lt;code&gt;add()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9afdb8ac221f8f75547e87484016d557ba50f247" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addbmm&quot;&gt;&lt;code&gt;addbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addbmm&quot;&gt; &lt;code&gt;addbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dcf43a3561084dec90d7c3a2ecc1b6cc0c26f938" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addcdiv&quot;&gt;&lt;code&gt;addcdiv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addcdiv&quot;&gt; &lt;code&gt;addcdiv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b52599a8d04e379d3f3c9ecc7af347c1222d473b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addcmul&quot;&gt;&lt;code&gt;addcmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addcmul&quot;&gt; &lt;code&gt;addcmul()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="212bb18c46269c9b244d88318432c473793d6225" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addmm&quot;&gt;&lt;code&gt;addmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addmm&quot;&gt; &lt;code&gt;addmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7e04b090badbdcab058cb74254d5f97b547843c5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addmv&quot;&gt;&lt;code&gt;addmv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addmv&quot;&gt; &lt;code&gt;addmv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="714cae5e9e959037c53ed668822d40bf8774aa1b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addr&quot;&gt;&lt;code&gt;addr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addr&quot;&gt; &lt;code&gt;addr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="85808cd790e595c311410030bdf947098dfb3832" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arccos&quot;&gt;&lt;code&gt;arccos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arccos&quot;&gt; &lt;code&gt;arccos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f222472fe1a711c429f88dfa21d735fc20269d70" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arccosh&quot;&gt;&lt;code&gt;arccosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arccosh&quot;&gt; &lt;code&gt;arccosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e5850fc97599dacb252ef7b71a0bc059e90ac832" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arcsin&quot;&gt;&lt;code&gt;arcsin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arcsin&quot;&gt; &lt;code&gt;arcsin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a92421400d2c919bc99b517f289d8339a3ae03e4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arcsinh&quot;&gt;&lt;code&gt;arcsinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arcsinh&quot;&gt; &lt;code&gt;arcsinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ab6c8d62429cad7d186033198296a84d5c952598" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arctan&quot;&gt;&lt;code&gt;arctan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arctan&quot;&gt; &lt;code&gt;arctan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e025d0bea89a2469024775370356f0fa69f44cc9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arctanh&quot;&gt;&lt;code&gt;arctanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arctanh&quot;&gt; &lt;code&gt;arctanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1eda7abb65e5c787ce66fb95749143a3f04888ed" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.asin&quot;&gt;&lt;code&gt;asin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.asin&quot;&gt; &lt;code&gt;asin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0d258dbfd544c95327dd54668d3cb8823507d044" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.asinh&quot;&gt;&lt;code&gt;asinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.asinh&quot;&gt; &lt;code&gt;asinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0e752ea6e17fecf2b883b074dbb3aa938a6f7d1c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atan&quot;&gt;&lt;code&gt;atan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atan&quot;&gt; &lt;code&gt;atan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f00b83a4661950dbba55ca10e0c95538d6e98aaf" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atan2&quot;&gt;&lt;code&gt;atan2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atan2&quot;&gt; &lt;code&gt;atan2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9a9b90fa5b79edeea0ea7f804bf39ca483463ba1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atanh&quot;&gt;&lt;code&gt;atanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atanh&quot;&gt; &lt;code&gt;atanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0cf21533d1ef19709a89c1226676212cc25b35e7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.baddbmm&quot;&gt;&lt;code&gt;baddbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.baddbmm&quot;&gt; &lt;code&gt;baddbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="723c45d84b8a47a2aac768faa389e89dbffdc312" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_and&quot;&gt;&lt;code&gt;bitwise_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_and&quot;&gt; &lt;code&gt;bitwise_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f23ac5a50549f7c4c93c7cc4af1a4a7fb14079c7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_not&quot;&gt;&lt;code&gt;bitwise_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_not&quot;&gt; &lt;code&gt;bitwise_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1643902bef600d4d0d475acf131454814b25dc26" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_or&quot;&gt;&lt;code&gt;bitwise_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_or&quot;&gt; &lt;code&gt;bitwise_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fc90a184109b29c52ddf3915b630a1a54ae9634b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_xor&quot;&gt;&lt;code&gt;bitwise_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_xor&quot;&gt; &lt;code&gt;bitwise_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9b071498cdd10ed979300e38b8823b05d84b4e9a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ceil&quot;&gt;&lt;code&gt;ceil()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ceil&quot;&gt; &lt;code&gt;ceil()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cd0a36194221856cef72e71a8bee0b50682fd547" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.clamp&quot;&gt;&lt;code&gt;clamp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.clamp&quot;&gt; &lt;code&gt;clamp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="70bc593dd1c02b1636bd32a3b21498325eaaa85c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.cos&quot;&gt;&lt;code&gt;cos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.cos&quot;&gt; &lt;code&gt;cos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="30b3045f3354737011026cef07419edca16e51b7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.cosh&quot;&gt;&lt;code&gt;cosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.cosh&quot;&gt; &lt;code&gt;cosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="85698a440de4a886c432db2c8ba93bb04b9783a5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.digamma&quot;&gt;&lt;code&gt;digamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.digamma&quot;&gt; &lt;code&gt;digamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5b9d988d2d91968da3bc8e9addd60ca857a07078" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.div&quot;&gt;&lt;code&gt;div()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.div&quot;&gt; &lt;code&gt;div()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="40f813960ae0cb30555d66235642030e14081a78" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.divide&quot;&gt;&lt;code&gt;divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.divide&quot;&gt; &lt;code&gt;divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3593d29a80b1997092e2a7caab1ae4c89ff665ad" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.eq&quot;&gt;&lt;code&gt;eq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.eq&quot;&gt; &lt;code&gt;eq()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a597279c8f26129b927bac941304ed95baa85e3a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erf&quot;&gt;&lt;code&gt;erf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erf&quot;&gt; &lt;code&gt;erf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cbb6ddfcf060f64c41fb12dadf24c5f4104c8248" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erfc&quot;&gt;&lt;code&gt;erfc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erfc&quot;&gt; &lt;code&gt;erfc()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d3f26f32a7d82b45bafe3bb5a09586684935c0d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erfinv&quot;&gt;&lt;code&gt;erfinv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erfinv&quot;&gt; &lt;code&gt;erfinv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="843b7383da05ed2bdd2c3d50d63831578e83d793" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.exp&quot;&gt;&lt;code&gt;exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.exp&quot;&gt; &lt;code&gt;exp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="592c5733a1bb63ac93435062ef6cf042a3e0764b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.expm1&quot;&gt;&lt;code&gt;expm1()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.expm1&quot;&gt; &lt;code&gt;expm1()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d5d395d973d45d767241ba61182b45ea933b25b3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.fix&quot;&gt;&lt;code&gt;fix()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.fix&quot;&gt; &lt;code&gt;fix()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a0ad235d8de2027be5bcf6998afc520cb85c9fc4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.floor&quot;&gt;&lt;code&gt;floor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.floor&quot;&gt; &lt;code&gt;floor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1298ca9624e848339b14dbd7ac9e1cc72e8426d5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.floor_divide&quot;&gt;&lt;code&gt;floor_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.floor_divide&quot;&gt; &lt;code&gt;floor_divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ba34126e0ac2c59a401a9332bbc39d964a9f1676" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.fmod&quot;&gt;&lt;code&gt;fmod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.fmod&quot;&gt; &lt;code&gt;fmod()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="05577f4319cd8a9afef3327e267c8259cd201bc1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.frac&quot;&gt;&lt;code&gt;frac()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.frac&quot;&gt; &lt;code&gt;frac()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2c9a5d890ffefe6a4582f4b8a23dc1a024530071" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.gcd&quot;&gt;&lt;code&gt;gcd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.gcd&quot;&gt; &lt;code&gt;gcd()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="64f7412f381bbec829d7e064308cdeedbdb4239d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ge&quot;&gt;&lt;code&gt;ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ge&quot;&gt; &lt;code&gt;ge()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="c4e0348ba557fd7f53f8d998e67417ad216e0ca1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.greater&quot;&gt;&lt;code&gt;greater()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.greater&quot;&gt; &lt;code&gt;greater()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="c8558b60a835a6d4d07c498aab1d1c2aee7927ef" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.greater_equal&quot;&gt;&lt;code&gt;greater_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.greater_equal&quot;&gt; &lt;code&gt;greater_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="23ff3a9c46bb69e3bf80c84bd30a30c21ea9397e" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.gt&quot;&gt;&lt;code&gt;gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.gt&quot;&gt; &lt;code&gt;gt()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="0101731065c7560702b5f46c4e91cdc9923c8847" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.hypot&quot;&gt;&lt;code&gt;hypot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.hypot&quot;&gt; &lt;code&gt;hypot()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2ae74e50f4d266279d834bc1480fb185d3f5523f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.i0&quot;&gt;&lt;code&gt;i0()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.i0&quot;&gt; &lt;code&gt;i0()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a9c7375b3919548ed0ffd6165fe0af4e23e758d4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lcm&quot;&gt;&lt;code&gt;lcm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lcm&quot;&gt; &lt;code&gt;lcm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c39b8eebf07573ad5eac2472d11ac00d3ec49609" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.le&quot;&gt;&lt;code&gt;le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.le&quot;&gt; &lt;code&gt;le()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="de77dd1c89036ad69daa80304475b1011fb3301e" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lerp&quot;&gt;&lt;code&gt;lerp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lerp&quot;&gt; &lt;code&gt;lerp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c58f50cdbebdcfb188e2bdfa9fcdc829890f845d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.less&quot;&gt;&lt;code&gt;less()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.less&quot;&gt; &lt;code&gt;less()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="b9423b0d6372fd7e2833e62f8095c74ec7f8c46f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.less_equal&quot;&gt;&lt;code&gt;less_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.less_equal&quot;&gt; &lt;code&gt;less_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6e2671a3a2693a72154fb41d1a6e377bc20e43a8" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lgamma&quot;&gt;&lt;code&gt;lgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lgamma&quot;&gt; &lt;code&gt;lgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9af05e667e56282be6af4fe5b0246f9f857e3a1d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log&quot;&gt;&lt;code&gt;log()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log&quot;&gt; &lt;code&gt;log()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c10939ba9c9c50755fefd56b392ef3407792f705" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log10&quot;&gt;&lt;code&gt;log10()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log10&quot;&gt; &lt;code&gt;log10()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1458e566ebdc0a91bfc06212d913d1e13187212c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log1p&quot;&gt;&lt;code&gt;log1p()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log1p&quot;&gt; &lt;code&gt;log1p()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b4555443ad8a2acf3c819dcdfbbef49a10a2e972" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log2&quot;&gt;&lt;code&gt;log2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log2&quot;&gt; &lt;code&gt;log2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="433b0aeae51de4808da5b68a9beefef42daf02ce" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_and&quot;&gt;&lt;code&gt;logical_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_and&quot;&gt; &lt;code&gt;logical_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c70b5c1f8176e07af5e81b152a7bdfca820fb3f9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_not&quot;&gt;&lt;code&gt;logical_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_not&quot;&gt; &lt;code&gt;logical_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d91ce8af603413f0aefc2d1b8b6eec1f114d044b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_or&quot;&gt;&lt;code&gt;logical_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_or&quot;&gt; &lt;code&gt;logical_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3109d25b88385322d682d606fa91db53903884b9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_xor&quot;&gt;&lt;code&gt;logical_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_xor&quot;&gt; &lt;code&gt;logical_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="343ccb07f42d386eca14f79b12f59de018d60e86" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logit&quot;&gt;&lt;code&gt;logit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logit&quot;&gt; &lt;code&gt;logit()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d856395e389956dab5ecceb9942b3af92fe9ea1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lt&quot;&gt;&lt;code&gt;lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lt&quot;&gt; &lt;code&gt;lt()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="23d64d86cc2e5f1327a6e010cdeb7c115938b177" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.mul&quot;&gt;&lt;code&gt;mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.mul&quot;&gt; &lt;code&gt;mul()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="320ff1f84d1c7cfe2a1624b610ddcce8af66a764" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.multiply&quot;&gt;&lt;code&gt;multiply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.multiply&quot;&gt; &lt;code&gt;multiply()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="d10598fcd6504f5f6bb4b9ddb4d89823cb2a72a4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.mvlgamma&quot;&gt;&lt;code&gt;mvlgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.mvlgamma&quot;&gt; &lt;code&gt;mvlgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b3a59563ae4042d5dfe02b4b4d28142c18b881db" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ne&quot;&gt;&lt;code&gt;ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ne&quot;&gt; &lt;code&gt;ne()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="0933e5f6d727692e6688d039a1e1af9fcbe844b2" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.neg&quot;&gt;&lt;code&gt;neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.neg&quot;&gt; &lt;code&gt;neg()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6b0826ad65145f6f9f94c5d871b782df9fd07711" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.negative&quot;&gt;&lt;code&gt;negative()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.negative&quot;&gt; &lt;code&gt;negative()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9a9845a362319d27c686423e43aadf669c3c68aa" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.nextafter&quot;&gt;&lt;code&gt;nextafter()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.nextafter&quot;&gt; &lt;code&gt;nextafter()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="28a1d8909a6e02b4e7751f03f7b62a7e62637734" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.not_equal&quot;&gt;&lt;code&gt;not_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.not_equal&quot;&gt; &lt;code&gt;not_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="f16d420f4d416e8798bbbadc72fbaac73ed31ae3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.polygamma&quot;&gt;&lt;code&gt;polygamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.polygamma&quot;&gt; &lt;code&gt;polygamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="59d753fe8af8e0e2fdbff27f828f4dc81a011e2f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.pow&quot;&gt;&lt;code&gt;pow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.pow&quot;&gt; &lt;code&gt;pow()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="52dd6f8c275f23765de5ee7462ecb62204684869" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.reciprocal&quot;&gt;&lt;code&gt;reciprocal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.reciprocal&quot;&gt; &lt;code&gt;reciprocal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ca45cdac88c7921f089b79a8f83e20d848c48d4a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.remainder&quot;&gt;&lt;code&gt;remainder()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.remainder&quot;&gt; &lt;code&gt;remainder()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="053eb7c5cd301fdd12904be2836f5fb0ec275646" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.rename&quot;&gt;&lt;code&gt;rename()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.rename&quot;&gt; &lt;code&gt;rename()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="818df20d8449f1acb432a28eac3f0b43768c2197" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.renorm&quot;&gt;&lt;code&gt;renorm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.renorm&quot;&gt; &lt;code&gt;renorm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="53ce6f2d6ab6ae80005a428178e9b77aef382107" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.round&quot;&gt;&lt;code&gt;round()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.round&quot;&gt; &lt;code&gt;round()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b623bd7302eab7378ff509a5b3dd4f0470b21494" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.rsqrt&quot;&gt;&lt;code&gt;rsqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.rsqrt&quot;&gt; &lt;code&gt;rsqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1fe0cf7810c0bc56d540daa9ddb7cec1599e41ee" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sgn&quot;&gt;&lt;code&gt;sgn()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sgn&quot;&gt; &lt;code&gt;sgn()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cdcdd0daf61ad10208f07b04eb0183a9d4d2ab44" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sigmoid&quot;&gt;&lt;code&gt;sigmoid()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sigmoid&quot;&gt; &lt;code&gt;sigmoid()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9e2cd3c0abcebc8ed45bd6570406d8c9d4c33ea1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sign&quot;&gt;&lt;code&gt;sign()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sign&quot;&gt; &lt;code&gt;sign()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="69d6918f4d893ee927f13c625b9f268b4eea1c8b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sin&quot;&gt;&lt;code&gt;sin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sin&quot;&gt; &lt;code&gt;sin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7f906cf7cca8e4f9df35be1db35c6f3f24ecf45b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sinh&quot;&gt;&lt;code&gt;sinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sinh&quot;&gt; &lt;code&gt;sinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cbe8e3f4ea9deb4f23b9e270df8f53c6c9f24e99" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sqrt&quot;&gt;&lt;code&gt;sqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sqrt&quot;&gt; &lt;code&gt;sqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8821b663c3d7115389c6fb460a014cd6f46b31a6" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.square&quot;&gt;&lt;code&gt;square()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.square&quot;&gt; &lt;code&gt;square()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="331d4255e6beb57fd7b54b749ce35473d9c934d2" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.squeeze&quot;&gt;&lt;code&gt;squeeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.squeeze&quot;&gt; &lt;code&gt;squeeze()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c0246ff36c2a3383754e9573043424c772cead3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sub&quot;&gt;&lt;code&gt;sub()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sub&quot;&gt; &lt;code&gt;sub()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="afadc08d16c14a6f3ab63ac2e1777d4a0c639d3d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.subtract&quot;&gt;&lt;code&gt;subtract()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.subtract&quot;&gt; &lt;code&gt;subtract()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="6e9a157c014d95de0d85c9410108016dcf899ffc" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.t&quot;&gt;&lt;code&gt;t()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.t&quot;&gt; &lt;code&gt;t()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="c2bca115f72f0be4030271dbbf4001e5646c23cd" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tan&quot;&gt;&lt;code&gt;tan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tan&quot;&gt; &lt;code&gt;tan()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="abae0cb9439d45a19abc17669152c5675c6b2f91" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tanh&quot;&gt;&lt;code&gt;tanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tanh&quot;&gt; &lt;code&gt;tanh()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="e2861f743f86145802065db61cf1289846a4dadc" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.transpose&quot;&gt;&lt;code&gt;transpose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.transpose&quot;&gt; &lt;code&gt;transpose()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="45499df8d625edfd4a83589eb3c8afa20bd32bb9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tril&quot;&gt;&lt;code&gt;tril()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tril&quot;&gt; &lt;code&gt;tril()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="065bb546251aa96738ef601a77cd6f37ec7d9659" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.triu&quot;&gt;&lt;code&gt;triu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.triu&quot;&gt; &lt;code&gt;triu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="212e370e8fdc9518bb1c8dd81fce7b074d0a6998" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.true_divide_&quot;&gt;&lt;code&gt;true_divide_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.true_divide_&quot;&gt; &lt;code&gt;true_divide_()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="e29d58f0e79f4e7e5e919543670aacaa5b39af55" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.trunc&quot;&gt;&lt;code&gt;trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.trunc&quot;&gt; &lt;code&gt;trunc()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="1e2464f4a6dc92f29b5fe948a1cb58f6a6f8ec52" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.unsqueeze&quot;&gt;&lt;code&gt;unsqueeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.unsqueeze&quot;&gt; &lt;code&gt;unsqueeze()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="40042c187d9c08cff699d8c486b17c8fc8e0f71b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.elu&quot;&gt;&lt;code&gt;elu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.elu&quot;&gt; &lt;code&gt;elu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="fda2e5a23576045d8c887926b8f5f495cbb00502" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.hardtanh&quot;&gt;&lt;code&gt;hardtanh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.hardtanh&quot;&gt; &lt;code&gt;hardtanh()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="4e00c79886a4c5fdfdd4fc0c5274b0108988ba92" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.leaky_relu&quot;&gt;&lt;code&gt;leaky_relu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.leaky_relu&quot;&gt; &lt;code&gt;leaky_relu()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="eda3fb8c00a121092ce0d25f989c8256cb992365" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.relu&quot;&gt;&lt;code&gt;relu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.relu&quot;&gt; &lt;code&gt;relu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="e3a76eb13d927dc0ac3b8f72061ef5fd006d9d68" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.rrelu&quot;&gt;&lt;code&gt;rrelu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.rrelu&quot;&gt; &lt;code&gt;rrelu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="cf12b7cfa392abc73035a860cd7f9148c1c352d9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.threshold&quot;&gt;&lt;code&gt;threshold()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.threshold&quot;&gt; &lt;code&gt;threshold()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="0b7ad9a8774865b3951b77d446d4e908b37c2715" translate="yes" xml:space="preserve">
          <source>Inception (warning: this model is highly sensitive to changes in operator implementation)</source>
          <target state="translated">インセプション(警告:このモデルは演算子の実装の変更に非常に敏感です。</target>
        </trans-unit>
        <trans-unit id="86187099fc5837d4a16585e59250186b1bdbfd39" translate="yes" xml:space="preserve">
          <source>Inception v3</source>
          <target state="translated">インセプション v3</target>
        </trans-unit>
        <trans-unit id="512c1383f2d8169cfead07824d0994b018f42ff3" translate="yes" xml:space="preserve">
          <source>Inception v3 model architecture from &lt;a href=&quot;http://arxiv.org/abs/1512.00567&quot;&gt;&amp;ldquo;Rethinking the Inception Architecture for Computer Vision&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://arxiv.org/abs/1512.00567&quot;&gt;「コンピュータビジョンのインセプションアーキテクチャの再考」の&lt;/a&gt;Inceptionv3モデルアーキテクチャ。</target>
        </trans-unit>
        <trans-unit id="228505f85662d947dfd09fcfb9c5416638b8b2ae" translate="yes" xml:space="preserve">
          <source>Independent</source>
          <target state="translated">Independent</target>
        </trans-unit>
        <trans-unit id="c2df9b932637fe9d32a0f16da1c11873398f873d" translate="yes" xml:space="preserve">
          <source>Index</source>
          <target state="translated">Index</target>
        </trans-unit>
        <trans-unit id="6f4e6ca52449e10a302a5dfc3ebba098cd7e6757" translate="yes" xml:space="preserve">
          <source>Indexing, Slicing, Joining, Mutating Ops</source>
          <target state="translated">インデックス作成、スライス、結合、操作の変更</target>
        </trans-unit>
        <trans-unit id="5e2d7833039dc978e6eb0d1055910e03a86a4609" translate="yes" xml:space="preserve">
          <source>Indices and tables</source>
          <target state="translated">インデックスとテーブル</target>
        </trans-unit>
        <trans-unit id="4eb1cf386795f140ff47153f7333aea4dda421e5" translate="yes" xml:space="preserve">
          <source>Indices are ordered from left to right according to when each was sampled (first samples are placed in first column).</source>
          <target state="translated">指標は左から右へと、それぞれがいつサンプリングされたかに応じて並べられています(最初のサンプルは最初の列に配置されています)。</target>
        </trans-unit>
        <trans-unit id="68fa16ffd48f366e4fa8d57fea78ff03fcab0191" translate="yes" xml:space="preserve">
          <source>Initialization</source>
          <target state="translated">Initialization</target>
        </trans-unit>
        <trans-unit id="8a509cef8fe7210eb4a6fc80831a2072673fceae" translate="yes" xml:space="preserve">
          <source>Initialize PyTorch&amp;rsquo;s CUDA state. You may need to call this explicitly if you are interacting with PyTorch via its C API, as Python bindings for CUDA functionality will not be available until this initialization takes place. Ordinary users should not need this, as all of PyTorch&amp;rsquo;s CUDA methods automatically initialize CUDA state on-demand.</source>
          <target state="translated">PyTorchのCUDA状態を初期化します。C APIを介してPyTorchと対話している場合は、この初期化が行われるまでCUDA機能のPythonバインディングを使用できないため、これを明示的に呼び出す必要がある場合があります。PyTorchのすべてのCUDAメソッドがCUDA状態をオンデマンドで自動的に初期化するため、通常のユーザーはこれを必要としないはずです。</target>
        </trans-unit>
        <trans-unit id="73e5b96b48f418d64840badaa42ca942b71c67be" translate="yes" xml:space="preserve">
          <source>Initializes RPC primitives such as the local RPC agent and distributed autograd, which immediately makes the current process ready to send and receive RPCs.</source>
          <target state="translated">ローカル RPC エージェントや分散 autograd などの RPC プリミティブを初期化し、現在のプロセスを直ちに RPC を送受信できる状態にします。</target>
        </trans-unit>
        <trans-unit id="bd0f315e911df950ab4124032aa329f129570289" translate="yes" xml:space="preserve">
          <source>Initializes the default distributed process group, and this will also initialize the distributed package.</source>
          <target state="translated">デフォルトの分散プロセスグループを初期化し、分散パッケージも初期化します。</target>
        </trans-unit>
        <trans-unit id="252c7bda7950bbedbb2a4bb4550ac0f5ef1aa6a8" translate="yes" xml:space="preserve">
          <source>Input lists. It should contain correctly-sized tensors on each GPU to be used for input of the collective, e.g. &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; contains the reduce_scatter input that resides on the GPU of &lt;code&gt;output_tensor_list[i]&lt;/code&gt;.</source>
          <target state="translated">入力リスト。コレクティブの入力に使用される各GPUに正しいサイズのテンソルが含まれている必要があります。たとえば、 &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; は、 &lt;code&gt;output_tensor_list[i]&lt;/code&gt; GPUにあるreduce_scatter入力が含まれています。</target>
        </trans-unit>
        <trans-unit id="5bba22431efd0a63a04193e3ddac4464b3801e67" translate="yes" xml:space="preserve">
          <source>Input1:</source>
          <target state="translated">Input1:</target>
        </trans-unit>
        <trans-unit id="feac2b2649c90f11d6d855888f274f7a0752b7d9" translate="yes" xml:space="preserve">
          <source>Input2:</source>
          <target state="translated">Input2:</target>
        </trans-unit>
        <trans-unit id="79d70dcb4f9ee8b7d94ed9539586cc73c0d399da" translate="yes" xml:space="preserve">
          <source>Input:</source>
          <target state="translated">Input:</target>
        </trans-unit>
        <trans-unit id="7b180c0fda0377ef1dc31c7cce34da732fc57c9e" translate="yes" xml:space="preserve">
          <source>Input: LongTensor of arbitrary shape containing the indices to extract</source>
          <target state="translated">入力。抽出する指標を含む任意の形状のLongTensor</target>
        </trans-unit>
        <trans-unit id="15c3ba090d23cb0ca95577aa6799755edeefe016" translate="yes" xml:space="preserve">
          <source>Input_lengths: Tuple or tensor of size</source>
          <target state="translated">Input_lengths:サイズのタプルまたはテンソル</target>
        </trans-unit>
        <trans-unit id="fcadc5a2f2ce33e2ebb11bf51a1dd2322a5a729a" translate="yes" xml:space="preserve">
          <source>Inputs:</source>
          <target state="translated">Inputs:</target>
        </trans-unit>
        <trans-unit id="f969dd5ae0f7325be616e39a51b06a49fc60e816" translate="yes" xml:space="preserve">
          <source>Inputs: input, (h_0, c_0)</source>
          <target state="translated">入力:入力、(h_0,c_0)</target>
        </trans-unit>
        <trans-unit id="1be4f879f896bd3dcbeaf30b825be75ca856fcfb" translate="yes" xml:space="preserve">
          <source>Inputs: input, h_0</source>
          <target state="translated">入力:入力、h_0</target>
        </trans-unit>
        <trans-unit id="71bf746d2a9f5ff1025d4c04b2cf1fcfbd657691" translate="yes" xml:space="preserve">
          <source>Inputs: input, hidden</source>
          <target state="translated">入力:入力、非表示</target>
        </trans-unit>
        <trans-unit id="7f3d3cd091d557867390efc2557a3f5b19292265" translate="yes" xml:space="preserve">
          <source>Insert a given module before a given index in the list.</source>
          <target state="translated">指定されたモジュールをリストの指定されたインデックスの前に挿入します。</target>
        </trans-unit>
        <trans-unit id="50d8055b5be81f5be9d6435d07e2a4ac2451cc98" translate="yes" xml:space="preserve">
          <source>Inserts the key-value pair into the store based on the supplied &lt;code&gt;key&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt;. If &lt;code&gt;key&lt;/code&gt; already exists in the store, it will overwrite the old value with the new supplied &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">指定された &lt;code&gt;key&lt;/code&gt; と &lt;code&gt;value&lt;/code&gt; 基づいて、キーと値のペアをストアに挿入します。 &lt;code&gt;key&lt;/code&gt; がストアにすでに存在する場合、古い値が新しく指定された &lt;code&gt;value&lt;/code&gt; で上書きされます。</target>
        </trans-unit>
        <trans-unit id="52616e80a59172caf19bcc15fac4910844e40524" translate="yes" xml:space="preserve">
          <source>Inspecting Code</source>
          <target state="translated">コードの検査</target>
        </trans-unit>
        <trans-unit id="9efecc53883d2ffb75b3f04810dbaac718af41ba" translate="yes" xml:space="preserve">
          <source>InstanceNorm1d</source>
          <target state="translated">InstanceNorm1d</target>
        </trans-unit>
        <trans-unit id="a1ce20a07b568c5cbed5860b3c884130e1c4f948" translate="yes" xml:space="preserve">
          <source>InstanceNorm2d</source>
          <target state="translated">InstanceNorm2d</target>
        </trans-unit>
        <trans-unit id="f8a9e223352c23318d808b3147734411baf32655" translate="yes" xml:space="preserve">
          <source>InstanceNorm3d</source>
          <target state="translated">InstanceNorm3d</target>
        </trans-unit>
        <trans-unit id="c54533fbd7a6f02423b7a436a597e8275c12dc4d" translate="yes" xml:space="preserve">
          <source>Instances of &lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt;&lt;code&gt;autocast&lt;/code&gt;&lt;/a&gt; serve as context managers or decorators that allow regions of your script to run in mixed precision.</source>
          <target state="translated">&lt;a href=&quot;#torch.cuda.amp.autocast&quot;&gt; &lt;code&gt;autocast&lt;/code&gt; &lt;/a&gt;インスタンスは、スクリプトの領域を混合精度で実行できるようにするコンテキストマネージャーまたはデコレーターとして機能します。</target>
        </trans-unit>
        <trans-unit id="8ab3500f668dc459ea6ccd8a8b7456bb53bb532b" translate="yes" xml:space="preserve">
          <source>Instances of this class should never be created manually. They are meant to be instantiated by functions like &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;pack_padded_sequence()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">このクラスのインスタンスを手動で作成しないでください。これらは、&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;pack_padded_sequence()&lt;/code&gt; &lt;/a&gt;などの関数によってインスタンス化されることを目的としています。</target>
        </trans-unit>
        <trans-unit id="5a54ceeb7f75257e5faecf7dac25c3c19332eb52" translate="yes" xml:space="preserve">
          <source>Instancing a pre-trained model will download its weights to a cache directory. This directory can be set using the &lt;code&gt;TORCH_MODEL_ZOO&lt;/code&gt; environment variable. See &lt;a href=&quot;../model_zoo#torch.utils.model_zoo.load_url&quot;&gt;&lt;code&gt;torch.utils.model_zoo.load_url()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">事前にトレーニングされたモデルをインスタンス化すると、その重みがキャッシュディレクトリにダウンロードされます。このディレクトリは、 &lt;code&gt;TORCH_MODEL_ZOO&lt;/code&gt; 環境変数を使用して設定できます。詳細については、&lt;a href=&quot;../model_zoo#torch.utils.model_zoo.load_url&quot;&gt; &lt;code&gt;torch.utils.model_zoo.load_url()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="4156151a1b281cbc4bcd7e0576424486039cddfe" translate="yes" xml:space="preserve">
          <source>Integer division with addcdiv is no longer supported, and in a future release addcdiv will perform a true division of tensor1 and tensor2. The historic addcdiv behavior can be implemented as (input + value * torch.trunc(tensor1 / tensor2)).to(input.dtype) for integer inputs and as (input + value * tensor1 / tensor2) for float inputs. The future addcdiv behavior is just the latter implementation: (input + value * tensor1 / tensor2), for all dtypes.</source>
          <target state="translated">addcdivによる整数除算はサポートされなくなり、将来のリリースでは、addcdivはtensor1とtensor2の真の除算を実行するようになります。これまでのaddcdivの動作は、整数入力の場合は(input+value*torch.trunc(tensor1/tensor2)).to(input.dtype)として、float入力の場合は(input+value*tensor1/tensor2)として実装できます。将来のaddcdivの動作は後者の実装になります。(input+value*tensor1/tensor2)、すべてのdtypeに対して。</target>
        </trans-unit>
        <trans-unit id="2c54682be64b87caa364aa75498c5eaafa212bed" translate="yes" xml:space="preserve">
          <source>Internally invokes &lt;code&gt;unscale_(optimizer)&lt;/code&gt; (unless &lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt; was explicitly called for &lt;code&gt;optimizer&lt;/code&gt; earlier in the iteration). As part of the &lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt;&lt;code&gt;unscale_()&lt;/code&gt;&lt;/a&gt;, gradients are checked for infs/NaNs.</source>
          <target state="translated">&lt;code&gt;unscale_(optimizer)&lt;/code&gt; を内部的に呼び出します（反復の早い段階で&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt; &lt;code&gt;unscale_()&lt;/code&gt; &lt;/a&gt;が &lt;code&gt;optimizer&lt;/code&gt; 明示的に呼び出された場合を除く）。&lt;a href=&quot;#torch.cuda.amp.GradScaler.unscale_&quot;&gt; &lt;code&gt;unscale_()&lt;/code&gt; の&lt;/a&gt;一部として、勾配はinfs / NaNについてチェックされます。</target>
        </trans-unit>
        <trans-unit id="9f650ccc7d0d6be8b0fb7120cf085b2ff78498f0" translate="yes" xml:space="preserve">
          <source>Interpreting Graphs</source>
          <target state="translated">グラフの解釈</target>
        </trans-unit>
        <trans-unit id="ab6b952b1b568a27a27bc4ef9eccfa0e4506f5e1" translate="yes" xml:space="preserve">
          <source>Interpreting the output of this function requires familiarity with the memory allocator internals.</source>
          <target state="translated">この関数の出力を解釈するには、メモリアロケータの内部に精通している必要があります。</target>
        </trans-unit>
        <trans-unit id="e42baee8c04a7fb48aeb23c27863b3e7f99c9a61" translate="yes" xml:space="preserve">
          <source>Inverse short time Fourier Transform.</source>
          <target state="translated">逆短時間フーリエ変換。</target>
        </trans-unit>
        <trans-unit id="f2d2a372360fc80cd1c1832163878137a219bb55" translate="yes" xml:space="preserve">
          <source>Inverse short time Fourier Transform. This is expected to be the inverse of &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt;. It has the same parameters (+ additional optional parameter of &lt;code&gt;length&lt;/code&gt;) and it should return the least squares estimation of the original signal. The algorithm will check using the NOLA condition ( nonzero overlap).</source>
          <target state="translated">逆短時間フーリエ変換。これは、&lt;a href=&quot;torch.stft#torch.stft&quot;&gt; &lt;code&gt;stft()&lt;/code&gt; の&lt;/a&gt;逆であると予想されます。同じパラメーター（+ &lt;code&gt;length&lt;/code&gt; 追加のオプションパラメーター）があり、元の信号の最小二乗推定を返す必要があります。アルゴリズムは、NOLA条件（ゼロ以外のオーバーラップ）を使用してチェックします。</target>
        </trans-unit>
        <trans-unit id="4212bbbb75b521f6e55e2e79c4b2dab9598d7c21" translate="yes" xml:space="preserve">
          <source>Invoking &lt;code&gt;trace&lt;/code&gt; with a module&amp;rsquo;s method captures module parameters (which may require gradients) as &lt;strong&gt;constants&lt;/strong&gt;.</source>
          <target state="translated">モジュールのメソッドを使用して &lt;code&gt;trace&lt;/code&gt; を呼び出すと、モジュールのパラメーター（勾配が必要になる場合があります）が&lt;strong&gt;定数&lt;/strong&gt;としてキャプチャされます。</target>
        </trans-unit>
        <trans-unit id="0b1154e9d45e9b9a76119f9cdf7dd156a3cc44ad" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrices &lt;code&gt;solution&lt;/code&gt; and &lt;code&gt;LU&lt;/code&gt; will be transposed, i.e. with strides like &lt;code&gt;B.contiguous().transpose(-1, -2).stride()&lt;/code&gt; and &lt;code&gt;A.contiguous().transpose(-1, -2).stride()&lt;/code&gt; respectively.</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;solution&lt;/code&gt; と &lt;code&gt;LU&lt;/code&gt; は転置されます。つまり、 &lt;code&gt;B.contiguous().transpose(-1, -2).stride()&lt;/code&gt; や &lt;code&gt;A.contiguous().transpose(-1, -2).stride()&lt;/code&gt; それぞれ。</target>
        </trans-unit>
        <trans-unit id="49986ad18b9e3b5d2fddd594cfccd882001d60e0" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrix &lt;code&gt;U&lt;/code&gt; will be transposed, i.e. with strides &lt;code&gt;U.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;U&lt;/code&gt; は転置されます。つまり、ストライド &lt;code&gt;U.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="82269a6fafdcdbb86e718604476ce9b6c8e7d2a7" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrix &lt;code&gt;V&lt;/code&gt; will be transposed, i.e. with strides &lt;code&gt;V.contiguous().transpose(-1, -2).stride()&lt;/code&gt;.</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;V&lt;/code&gt; は転置されます。つまり、ストライド &lt;code&gt;V.contiguous().transpose(-1, -2).stride()&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="01899cc116f34c67486ee354a88f582f6796cc36" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned tensors will be transposed, i.e. with strides like &lt;code&gt;input.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</source>
          <target state="translated">元のストライドに関係なく、返されるテンソルは転置されます。つまり、 &lt;code&gt;input.contiguous().transpose(-2, -1).stride()&lt;/code&gt; ようなストライドが使用されます。</target>
        </trans-unit>
        <trans-unit id="2310615072fec2b4a5a875a4e0dd6ffebdaf12ad" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if gradients need to be computed for this Tensor, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">このテンソルに対して勾配を計算する必要がある場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="aa669dbfc27ea4c75455d3b2508d4155513b175a" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is a meta tensor, &lt;code&gt;False&lt;/code&gt; otherwise. Meta tensors are like normal tensors, but they carry no data.</source>
          <target state="translated">テンソルがメタテンソルの場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。メタテンソルは通常のテンソルに似ていますが、データはありません。</target>
        </trans-unit>
        <trans-unit id="adff4bd8499f965b85193b88135bc7439c31730a" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is quantized, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">テンソルが量子化されている場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="3a0d8439442e2aedd6e797ff733a51980c711c86" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is stored on the GPU, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">テンソルがGPUに保存されている場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="e91f70a847754923183418ed052bcea694565f54" translate="yes" xml:space="preserve">
          <source>Is the &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; where this Tensor is.</source>
          <target state="translated">このTensorがある&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="4212d08cece9c425b48ec2c1e60e8be1d1e78b6c" translate="yes" xml:space="preserve">
          <source>Is this Tensor with its dimensions reversed.</source>
          <target state="translated">このテンソルは寸法が逆になっているのでしょうか。</target>
        </trans-unit>
        <trans-unit id="6b5b4f414a6eb16cb4afeb48e5665cb815db584b" translate="yes" xml:space="preserve">
          <source>It achieves two things: - makes the output value exactly one-hot (since we add then subtract y_soft value) - makes the gradient equal to y_soft gradient (since we strip all other gradients)</source>
          <target state="translated">これは次の2つのことを実現します:-出力値を正確に1ホットにします(y_soft値を加算してから減算するので)-勾配をy_soft勾配と等しくします(他のすべての勾配を除去するので)-出力値を正確に1ホットにします。</target>
        </trans-unit>
        <trans-unit id="3b6bfab9486b081f92c85bb7d32db79b3eceeba3" translate="yes" xml:space="preserve">
          <source>It always prepends a new dimension as the batch dimension.</source>
          <target state="translated">これは常に新しい寸法をバッチ寸法として前置します。</target>
        </trans-unit>
        <trans-unit id="2f8d2c743873b5a3fbbb90a0d2c5cf8d6a8807aa" translate="yes" xml:space="preserve">
          <source>It automatically converts NumPy arrays and Python numerical values into PyTorch Tensors.</source>
          <target state="translated">NumPy配列やPythonの数値を自動的にPyTorchテンソルに変換してくれます。</target>
        </trans-unit>
        <trans-unit id="49e4e2f8e005da183a111f2acc6be4571ffd2077" translate="yes" xml:space="preserve">
          <source>It contains an entry for every variable in self.__dict__ which is not the optimizer. The learning rate lambda functions will only be saved if they are callable objects and not if they are functions or lambdas.</source>
          <target state="translated">これは、オプティマイザではない self.__dict__のすべての変数のエントリを含んでいます。学習率ラムダ関数は、呼び出し可能なオブジェクトである場合にのみ保存され、関数やラムダである場合には保存されません。</target>
        </trans-unit>
        <trans-unit id="4a7efc8c6cf2fe612e155694f2110de8eb7b9450" translate="yes" xml:space="preserve">
          <source>It contains two entries:</source>
          <target state="translated">2つのエントリが含まれています。</target>
        </trans-unit>
        <trans-unit id="8e6db53c7cd43b88eb003448e0a5df6411ba7a87" translate="yes" xml:space="preserve">
          <source>It currently accepts &lt;code&gt;ndarray&lt;/code&gt; with dtypes of &lt;code&gt;numpy.float64&lt;/code&gt;, &lt;code&gt;numpy.float32&lt;/code&gt;, &lt;code&gt;numpy.float16&lt;/code&gt;, &lt;code&gt;numpy.complex64&lt;/code&gt;, &lt;code&gt;numpy.complex128&lt;/code&gt;, &lt;code&gt;numpy.int64&lt;/code&gt;, &lt;code&gt;numpy.int32&lt;/code&gt;, &lt;code&gt;numpy.int16&lt;/code&gt;, &lt;code&gt;numpy.int8&lt;/code&gt;, &lt;code&gt;numpy.uint8&lt;/code&gt;, and &lt;code&gt;numpy.bool&lt;/code&gt;.</source>
          <target state="translated">これは、現在受け入れ &lt;code&gt;ndarray&lt;/code&gt; のdtypesで &lt;code&gt;numpy.float64&lt;/code&gt; 、 &lt;code&gt;numpy.float32&lt;/code&gt; 、 &lt;code&gt;numpy.float16&lt;/code&gt; 、 &lt;code&gt;numpy.complex64&lt;/code&gt; 、 &lt;code&gt;numpy.complex128&lt;/code&gt; 、 &lt;code&gt;numpy.int64&lt;/code&gt; 、 &lt;code&gt;numpy.int32&lt;/code&gt; 、 &lt;code&gt;numpy.int16&lt;/code&gt; 、 &lt;code&gt;numpy.int8&lt;/code&gt; 、 &lt;code&gt;numpy.uint8&lt;/code&gt; 、および &lt;code&gt;numpy.bool&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="401f208e4a6ef5ef6ad2bc031ef0d0f97b3ebf14" translate="yes" xml:space="preserve">
          <source>It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability &amp;gt;= 3.0</source>
          <target state="translated">CUDAに対応するものがあり、計算機能が3.0以上のNVIDIAGPUでテンソル計算を実行できます。</target>
        </trans-unit>
        <trans-unit id="730337db11f0b320af1c601c156987d99a95f2d4" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;http://jmlr.org/papers/v12/duchi11a.html&quot;&gt;Adaptive Subgradient Methods for Online Learning and Stochastic Optimization&lt;/a&gt;.</source>
          <target state="translated">これは&lt;a href=&quot;http://jmlr.org/papers/v12/duchi11a.html&quot;&gt;、オンライン学習と確率的最適化のための適応劣勾配法で&lt;/a&gt;提案されています。</target>
        </trans-unit>
        <trans-unit id="051e2d9e2a228306c26b3c61549e79ae202aec25" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1212.5701&quot;&gt;ADADELTA: An Adaptive Learning Rate Method&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/abs/1212.5701&quot;&gt;ADADELTA：Adaptive Learning RateMethodで&lt;/a&gt;提案されています。</target>
        </trans-unit>
        <trans-unit id="09050a199eb7d53185c92e9f5b5a66dd6952d42f" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam：A Method for StochasticOptimizationで&lt;/a&gt;提案されています。</target>
        </trans-unit>
        <trans-unit id="333ffdb98cee48515840fbcbba1813b5937b4a78" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;. The implementation of the L2 penalty follows changes proposed in &lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;Decoupled Weight Decay Regularization&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam：A Method for StochasticOptimizationで&lt;/a&gt;提案されています。L2ペナルティの実装は、&lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;Decoupled Weight DecayRegularizationで&lt;/a&gt;提案された変更に従います。</target>
        </trans-unit>
        <trans-unit id="01b731554c5955677b611c13e6a10743e819c4a9" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;SGDR: Stochastic Gradient Descent with Warm Restarts&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;SGDR：ウォームリスタートを伴う確率的勾配降下法で&lt;/a&gt;提案されています。</target>
        </trans-unit>
        <trans-unit id="2ff6bf54974d4bef1fd6f31a4e3985ebfbf18b7e" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;SGDR: Stochastic Gradient Descent with Warm Restarts&lt;/a&gt;. Note that this only implements the cosine annealing part of SGDR, and not the restarts.</source>
          <target state="translated">これは、&lt;a href=&quot;https://arxiv.org/abs/1608.03983&quot;&gt;SGDR：ウォームリスタートを伴う確率的勾配降下法で&lt;/a&gt;提案されています。これはSGDRのコサインアニーリング部分のみを実装し、再起動は実装しないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="459d6918fdc7170b0fc1dc7a88c04a7b59fb13a0" translate="yes" xml:space="preserve">
          <source>It has been proposed in &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=131098&quot;&gt;Acceleration of stochastic approximation by averaging&lt;/a&gt;.</source>
          <target state="translated">これは&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=131098&quot;&gt;、平均化による確率的近似の加速で&lt;/a&gt;提案されています。</target>
        </trans-unit>
        <trans-unit id="6563cef1ae60ef9f0cfc196eb441bdefa9d3c7aa" translate="yes" xml:space="preserve">
          <source>It has similar signature as &lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt;&lt;code&gt;torch.Tensor.to()&lt;/code&gt;&lt;/a&gt;, except optional arguments like &lt;code&gt;non_blocking&lt;/code&gt; and &lt;code&gt;copy&lt;/code&gt; should be passed as kwargs, not args, or they will not apply to the index tensors.</source>
          <target state="translated">&lt;code&gt;non_blocking&lt;/code&gt; や &lt;code&gt;copy&lt;/code&gt; などのオプションの引数をargsではなくkwargsとして渡す必要があることを除いて、&lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt; &lt;code&gt;torch.Tensor.to()&lt;/code&gt; &lt;/a&gt;と同様の署名があります。そうしないと、インデックステンソルには適用されません。</target>
        </trans-unit>
        <trans-unit id="2b37442b8edf941c9b64329b2dd98dad1125f396" translate="yes" xml:space="preserve">
          <source>It is also possible to annotate types with Python 3 type hints from the &lt;code&gt;typing&lt;/code&gt; module.</source>
          <target state="translated">&lt;code&gt;typing&lt;/code&gt; モジュールからPython3タイプヒントでタイプに注釈を付けることもできます。</target>
        </trans-unit>
        <trans-unit id="86993dc3f5b11fb441bb568843f0d884da0db7f4" translate="yes" xml:space="preserve">
          <source>It is an inverse operation to &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;pack_padded_sequence()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;pack_padded_sequence()&lt;/code&gt; の&lt;/a&gt;逆の操作です。</target>
        </trans-unit>
        <trans-unit id="50cbae8d4910e6f042bec5701d96446fe97f36c9" translate="yes" xml:space="preserve">
          <source>It is applied to all slices along dim, and will re-scale them so that the elements lie in the range &lt;code&gt;[0, 1]&lt;/code&gt; and sum to 1.</source>
          <target state="translated">これは、dimに沿ったすべてのスライスに適用され、要素が &lt;code&gt;[0, 1]&lt;/code&gt; 範囲にあり、合計が1になるように再スケーリングします。</target>
        </trans-unit>
        <trans-unit id="79324c046d8fb8ad0505c73e6f4ad6bf30dbe4de" translate="yes" xml:space="preserve">
          <source>It is equivalent to &lt;code&gt;`
ComposeTransform([AffineTransform(0., 2.), SigmoidTransform(), AffineTransform(-1., 2.)])
`&lt;/code&gt; However this might not be numerically stable, thus it is recommended to use &lt;code&gt;TanhTransform&lt;/code&gt; instead.</source>
          <target state="translated">これは、と等価である &lt;code&gt;` ComposeTransform([AffineTransform(0., 2.), SigmoidTransform(), AffineTransform(-1., 2.)]) `&lt;/code&gt; しかし、これは数値的に安定ではないかもしれない、従ってそれは使用することが推奨される &lt;code&gt;TanhTransform&lt;/code&gt; を代わりに。</target>
        </trans-unit>
        <trans-unit id="88fdb36159da698a069b2cd0358110c7f72e3f52" translate="yes" xml:space="preserve">
          <source>It is equivalent to the distribution that &lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt;&lt;code&gt;torch.multinomial()&lt;/code&gt;&lt;/a&gt; samples from.</source>
          <target state="translated">これは、&lt;a href=&quot;generated/torch.multinomial#torch.multinomial&quot;&gt; &lt;code&gt;torch.multinomial()&lt;/code&gt; が&lt;/a&gt;サンプリングする分布と同等です。</target>
        </trans-unit>
        <trans-unit id="b26d4802e99ec71d25e10e9e447cc2865d7a8327" translate="yes" xml:space="preserve">
          <source>It is especially useful in conjunction with &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt;&lt;/a&gt;. In such a case, each process can pass a &lt;code&gt;DistributedSampler&lt;/code&gt; instance as a &lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt;&lt;code&gt;DataLoader&lt;/code&gt;&lt;/a&gt; sampler, and load a subset of the original dataset that is exclusive to it.</source>
          <target state="translated">これは、&lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel&lt;/code&gt; &lt;/a&gt;と組み合わせて使用​​すると特に便利です。このような場合、各プロセスは、 &lt;code&gt;DistributedSampler&lt;/code&gt; インスタンスを&lt;a href=&quot;#torch.utils.data.DataLoader&quot;&gt; &lt;code&gt;DataLoader&lt;/code&gt; &lt;/a&gt;サンプラーとして渡し、それ専用の元のデータセットのサブセットをロードできます。</target>
        </trans-unit>
        <trans-unit id="a9c65d86833900305f35c9e1c934da02bcf964b7" translate="yes" xml:space="preserve">
          <source>It is generally not recommended to return CUDA tensors in multi-process loading because of many subtleties in using CUDA and sharing CUDA tensors in multiprocessing (see &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/multiprocessing.html#multiprocessing-cuda-note&quot;&gt;CUDA in multiprocessing&lt;/a&gt;). Instead, we recommend using &lt;a href=&quot;#memory-pinning&quot;&gt;automatic memory pinning&lt;/a&gt; (i.e., setting &lt;code&gt;pin_memory=True&lt;/code&gt;), which enables fast data transfer to CUDA-enabled GPUs.</source>
          <target state="translated">マルチプロセッシングでCUDAを使用し、CUDAテンソルを共有することには多くの微妙な点があるため、マルチプロセスロードでCUDAテンソルを返すことは一般に推奨されません（&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/multiprocessing.html#multiprocessing-cuda-note&quot;&gt;マルチプロセッシングのCUDAを&lt;/a&gt;参照）。代わりに、&lt;a href=&quot;#memory-pinning&quot;&gt;自動メモリピン留め&lt;/a&gt;を使用することをお勧めします（つまり、 &lt;code&gt;pin_memory=True&lt;/code&gt; を設定します）。これにより、CUDA対応GPUへの高速データ転送が可能になります。</target>
        </trans-unit>
        <trans-unit id="ec0c9b813cf0aa82dc727b897163ee4aef81fc00" translate="yes" xml:space="preserve">
          <source>It is lazily initialized, so you can always import it, and use &lt;a href=&quot;#torch.cuda.is_available&quot;&gt;&lt;code&gt;is_available()&lt;/code&gt;&lt;/a&gt; to determine if your system supports CUDA.</source>
          <target state="translated">遅延初期化されるため、いつでもインポートでき、&lt;a href=&quot;#torch.cuda.is_available&quot;&gt; &lt;code&gt;is_available()&lt;/code&gt; &lt;/a&gt;を使用してシステムがCUDAをサポートしているかどうかを判別できます。</target>
        </trans-unit>
        <trans-unit id="5de635d4ec610b825189efbe466e3cacb9dcacd9" translate="yes" xml:space="preserve">
          <source>It is not possible to directly backpropagate through random samples. However, there are two main methods for creating surrogate functions that can be backpropagated through. These are the score function estimator/likelihood ratio estimator/REINFORCE and the pathwise derivative estimator. REINFORCE is commonly seen as the basis for policy gradient methods in reinforcement learning, and the pathwise derivative estimator is commonly seen in the reparameterization trick in variational autoencoders. Whilst the score function only requires the value of samples</source>
          <target state="translated">ランダムサンプルを介して直接バックプロパゲートすることはできません。しかし、バックプロパゲ ートできるサロゲート関数を作成する方法には、主に2つの方法がある。これらは、スコア関数推定器/尤度比推定器/REINFORCEとパスワイズ微分推定器である。REINFORCEは強化学習における政策勾配法の基礎としてよく知られており、パスワイズ微分推定器は変分オートエンコーダーにおける再パラメータ化のトリックとしてよく知られている。スコア関数はサンプルの値だけを必要とする一方で</target>
        </trans-unit>
        <trans-unit id="7c6829a0a0e941307482f3fc9539e6effef1fbd8" translate="yes" xml:space="preserve">
          <source>It is recommended to use &lt;a href=&quot;torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;DistributedDataParallel&lt;/code&gt;&lt;/a&gt;, instead of this class, to do multi-GPU training, even if there is only a single node. See: &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel&lt;/a&gt; and &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/ddp.html#ddp&quot;&gt;Distributed Data Parallel&lt;/a&gt;.</source>
          <target state="translated">ノードが1つしかない場合でも、マルチGPUトレーニングを実行するには、このクラスの代わりに&lt;a href=&quot;torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;DistributedDataParallel&lt;/code&gt; &lt;/a&gt;を使用することをお勧めします。参照：&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;マルチプロセッシングの代わりにnn.parallel.DistributedDataParallelを使用するか、nn.DataParallel&lt;/a&gt;と&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/ddp.html#ddp&quot;&gt;Distributed &lt;/a&gt;DataParallelを使用してください。</target>
        </trans-unit>
        <trans-unit id="e66b3186074888a018543f3b0fff094946ea09d0" translate="yes" xml:space="preserve">
          <source>It is useful when running the program under nvprof:</source>
          <target state="translated">nvprofの下でプログラムを実行する場合に便利です。</target>
        </trans-unit>
        <trans-unit id="cc50a460e1a231d6b7914ab6f80ce6645cd28d1a" translate="yes" xml:space="preserve">
          <source>It is useful when training a classification problem with &lt;code&gt;C&lt;/code&gt; classes. If provided, the optional argument &lt;code&gt;weight&lt;/code&gt; should be a 1D &lt;code&gt;Tensor&lt;/code&gt; assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.</source>
          <target state="translated">これは、 &lt;code&gt;C&lt;/code&gt; クラスで分類問題をトレーニングするときに役立ちます。指定する場合、オプションの引数の &lt;code&gt;weight&lt;/code&gt; は、各クラスに重みを割り当てる1D &lt;code&gt;Tensor&lt;/code&gt; 必要があります。これは、不均衡なトレーニングセットがある場合に特に役立ちます。</target>
        </trans-unit>
        <trans-unit id="d3dd49ac73db5350741c77e9746cd12b789fc846" translate="yes" xml:space="preserve">
          <source>It must accept a context &lt;code&gt;ctx&lt;/code&gt; as the first argument, followed by as many outputs did &lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; return, and it should return as many tensors, as there were inputs to &lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt;. Each argument is the gradient w.r.t the given output, and each returned value should be the gradient w.r.t. the corresponding input.</source>
          <target state="translated">最初の引数としてコンテキスト &lt;code&gt;ctx&lt;/code&gt; を受け入れ、その後に&lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; が&lt;/a&gt;返した数の出力が続く必要があり、&lt;a href=&quot;#torch.autograd.Function.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;への入力があったのと同じ数のテンソルを返す必要があります。各引数は指定された出力の勾配であり、各戻り値は対応する入力の勾配である必要があります。</target>
        </trans-unit>
        <trans-unit id="252cdfb99fc0852a5d679618d9953abd9399f85f" translate="yes" xml:space="preserve">
          <source>It must accept a context ctx as the first argument, followed by any number of arguments (tensors or other types).</source>
          <target state="translated">最初の引数としてコンテキストctxを受け入れ、その後に任意の数の引数(テンソルや他の型)が続く必要があります。</target>
        </trans-unit>
        <trans-unit id="a5858d55aee32bb1f338ad58158a7863ffaa0e2a" translate="yes" xml:space="preserve">
          <source>It preserves the data structure, e.g., if each sample is a dictionary, it outputs a dictionary with the same set of keys but batched Tensors as values (or lists if the values can not be converted into Tensors). Same for &lt;code&gt;list&lt;/code&gt; s, &lt;code&gt;tuple&lt;/code&gt; s, &lt;code&gt;namedtuple&lt;/code&gt; s, etc.</source>
          <target state="translated">データ構造を保持します。たとえば、各サンプルがディクショナリの場合、同じキーセットを使用してディクショナリを出力しますが、値としてテンソルをバッチ処理します（または値をテンソルに変換できない場合はリストします）。 &lt;code&gt;list&lt;/code&gt; 、 &lt;code&gt;tuple&lt;/code&gt; 、 &lt;code&gt;namedtuple&lt;/code&gt; タプルなどについても同じです。</target>
        </trans-unit>
        <trans-unit id="99a91e5a4c5f62323cf29af98e5d69957ac9245f" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s like QConfig, but for dynamic quantization.</source>
          <target state="translated">QConfigに似ていますが、動的量子化用です。</target>
        </trans-unit>
        <trans-unit id="88103e98293e4d193ade88c8ec2a2e41a9017ce8" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s possible to trade off recall and precision by adding weights to positive examples. In the case of multi-label classification the loss can be described as:</source>
          <target state="translated">肯定的な例に重みを追加することで、再現率と適合率をトレードオフすることができます。マルチラベル分類の場合、損失は次のように説明できます。</target>
        </trans-unit>
        <trans-unit id="ecdda59aea5ee67d7d854c969ccf7f4f4b4a4c54" translate="yes" xml:space="preserve">
          <source>Item</source>
          <target state="translated">Item</target>
        </trans-unit>
        <trans-unit id="6a10d92f43c8da36e2a39d8ec8446f793702e774" translate="yes" xml:space="preserve">
          <source>Iterable-style datasets</source>
          <target state="translated">反復可能なスタイルのデータセット</target>
        </trans-unit>
        <trans-unit id="4dd80eea3f6c51bf5b9c13a8a47609bd55b30e0e" translate="yes" xml:space="preserve">
          <source>Iterables</source>
          <target state="translated">Iterables</target>
        </trans-unit>
        <trans-unit id="069e2ae56a9eacaa6614576bc398f841898b1686" translate="yes" xml:space="preserve">
          <source>Its signature is similar to &lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt;&lt;code&gt;torch.Tensor.to()&lt;/code&gt;&lt;/a&gt;, but only accepts floating point desired &lt;code&gt;dtype&lt;/code&gt; s. In addition, this method will only cast the floating point parameters and buffers to &lt;code&gt;dtype&lt;/code&gt; (if given). The integral parameters and buffers will be moved &lt;code&gt;device&lt;/code&gt;, if that is given, but with dtypes unchanged. When &lt;code&gt;non_blocking&lt;/code&gt; is set, it tries to convert/move asynchronously with respect to the host if possible, e.g., moving CPU Tensors with pinned memory to CUDA devices.</source>
          <target state="translated">その署名は&lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt; &lt;code&gt;torch.Tensor.to()&lt;/code&gt; に&lt;/a&gt;似ていますが、浮動小数点の目的の &lt;code&gt;dtype&lt;/code&gt; のみを受け入れます。さらに、このメソッドは浮動小数点パラメーターとバッファーのみを &lt;code&gt;dtype&lt;/code&gt; にキャストします（指定されている場合）。積分パラメータとバッファは、指定されている場合は &lt;code&gt;device&lt;/code&gt; に移動されますが、dtypeは変更されません。とき &lt;code&gt;non_blocking&lt;/code&gt; がセットされ、可能な場合、それが変換しよう/ CUDAデバイスに固定メモリーとCPUのテンソルを動かし、例えば、ホストに対して非同期に移動。</target>
        </trans-unit>
        <trans-unit id="eb5d2f4a58038c71155ddcf3cea35dc3c6d34501" translate="yes" xml:space="preserve">
          <source>JIT</source>
          <target state="translated">JIT</target>
        </trans-unit>
        <trans-unit id="ba8c07b6e8f75ea0f3fccd63588af034ee568ee6" translate="yes" xml:space="preserve">
          <source>Jacobian (&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;Tensor&lt;/a&gt; or nested tuple of Tensors)</source>
          <target state="translated">ヤコビアン（&lt;a href=&quot;tensors#torch.Tensor&quot;&gt;テンソル&lt;/a&gt;またはテンソルのネストされたタプル）</target>
        </trans-unit>
        <trans-unit id="a26e63e0dd630bf0aa29409ebb2007f8ed0989a9" translate="yes" xml:space="preserve">
          <source>Javadoc</source>
          <target state="translated">Javadoc</target>
        </trans-unit>
        <trans-unit id="a7ee38bb7be4fc44198cb2685d9601dcf2b9f569" translate="yes" xml:space="preserve">
          <source>K</source>
          <target state="translated">K</target>
        </trans-unit>
        <trans-unit id="d1dd1d02265a63fb16a7c02869b20a2ff09b23ec" translate="yes" xml:space="preserve">
          <source>K \geq 1</source>
          <target state="translated">K †††††††††††††††††☆彡</target>
        </trans-unit>
        <trans-unit id="d815c4b766be65370cc630500fbc7534d96810e3" translate="yes" xml:space="preserve">
          <source>KL(p \| q)</source>
          <target state="translated">KL(p \| q)</target>
        </trans-unit>
        <trans-unit id="3789bcc3ea87de653c85546427835735d21460e6" translate="yes" xml:space="preserve">
          <source>KL(p \| q) = \int p(x) \log\frac {p(x)} {q(x)} \,dx</source>
          <target state="translated">KL(p x)=\to p(x)</target>
        </trans-unit>
        <trans-unit id="a0d38167f0e193a1ac968e4ff065116f3dd7d3e2" translate="yes" xml:space="preserve">
          <source>KLDivLoss</source>
          <target state="translated">KLDivLoss</target>
        </trans-unit>
        <trans-unit id="2dff5751295255d47b7ebb571ae0d72fa938cb72" translate="yes" xml:space="preserve">
          <source>Keep in mind that only a limited number of optimizers support sparse gradients: currently it&amp;rsquo;s &lt;code&gt;optim.SGD&lt;/code&gt; (&lt;code&gt;CUDA&lt;/code&gt; and &lt;code&gt;CPU&lt;/code&gt;), &lt;code&gt;optim.SparseAdam&lt;/code&gt; (&lt;code&gt;CUDA&lt;/code&gt; and &lt;code&gt;CPU&lt;/code&gt;) and &lt;code&gt;optim.Adagrad&lt;/code&gt; (&lt;code&gt;CPU&lt;/code&gt;)</source>
          <target state="translated">限られた数のオプティマイザーのみがスパース勾配をサポートしていることに &lt;code&gt;optim.SGD&lt;/code&gt; 。現在、optim.SGD（ &lt;code&gt;CUDA&lt;/code&gt; および &lt;code&gt;CPU&lt;/code&gt; ）、 &lt;code&gt;optim.SparseAdam&lt;/code&gt; （ &lt;code&gt;CUDA&lt;/code&gt; および &lt;code&gt;CPU&lt;/code&gt; ）、および &lt;code&gt;optim.Adagrad&lt;/code&gt; （ &lt;code&gt;CPU&lt;/code&gt; ）です。</target>
        </trans-unit>
        <trans-unit id="61df1ec904a19beceda75adc97e889c2fd5cb69f" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN</source>
          <target state="translated">キーポイント R-CNN</target>
        </trans-unit>
        <trans-unit id="4dbced9709f5236c9b69e641ffff848fd0986a34" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN ResNet-50 FPN</source>
          <target state="translated">キーポイント R-CNN ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="f2815e1786777eee9275fa2f0b31c8b705f9edc6" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.</source>
          <target state="translated">キーポイントR-CNNは、一定サイズの入力画像を一括して一定サイズでONNXに書き出すことができます。</target>
        </trans-unit>
        <trans-unit id="db32172db3cd21ae36313d815fba0dd39bd7127a" translate="yes" xml:space="preserve">
          <source>Keyword Arguments</source>
          <target state="translated">キーワード引数</target>
        </trans-unit>
        <trans-unit id="1c524ac8953f745b9e5b79c69e1b4d39891c5ba1" translate="yes" xml:space="preserve">
          <source>Keyword arguments &lt;code&gt;min_value&lt;/code&gt; and &lt;code&gt;max_value&lt;/code&gt; have been deprecated in favor of &lt;code&gt;min_val&lt;/code&gt; and &lt;code&gt;max_val&lt;/code&gt;.</source>
          <target state="translated">キーワード引数は &lt;code&gt;min_value&lt;/code&gt; と &lt;code&gt;max_value&lt;/code&gt; の賛成で廃止されている &lt;code&gt;min_val&lt;/code&gt; と &lt;code&gt;max_val&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e48bd0570e2bf01526ed152277d5e60977339c96" translate="yes" xml:space="preserve">
          <source>Kicks off the distributed backward pass using the provided roots. This currently implements the &lt;a href=&quot;rpc/distributed_autograd#fast-mode-algorithm&quot;&gt;FAST mode algorithm&lt;/a&gt; which assumes all RPC messages sent in the same distributed autograd context across workers would be part of the autograd graph during the backward pass.</source>
          <target state="translated">提供されたルートを使用して、分散バックワードパスを開始します。これは現在、ワーカー間で同じ分散autogradコンテキストで送信されたすべてのRPCメッセージがバックワードパス中にautogradグラフの一部であると想定する&lt;a href=&quot;rpc/distributed_autograd#fast-mode-algorithm&quot;&gt;FASTモードアルゴリズム&lt;/a&gt;を実装しています。</target>
        </trans-unit>
        <trans-unit id="41bb1570ae7ccc5980e78c5f1c45cc0aed0bdbed" translate="yes" xml:space="preserve">
          <source>Kinetics 1-crop accuracies for clip length 16 (16x112x112)</source>
          <target state="translated">クリップ長さ16(16x112x112)のキネティクス1クリップ精度</target>
        </trans-unit>
        <trans-unit id="a5a5fafee83492d8b176cbbdd5bb0860a6fdbf28" translate="yes" xml:space="preserve">
          <source>Known limitations:</source>
          <target state="translated">既知の制限事項。</target>
        </trans-unit>
        <trans-unit id="d160e0986aca4714714a16f29ec605af90be704d" translate="yes" xml:space="preserve">
          <source>L</source>
          <target state="translated">L</target>
        </trans-unit>
        <trans-unit id="80f4812ca21133a053b1e37ce0b7c69d130f72e6" translate="yes" xml:space="preserve">
          <source>L = \prod_d \left\lfloor\frac{\text{output\_size}[d] + 2 \times \text{padding}[d] % - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c67a32aa874c2b17f9de746130e43c1407789f98" translate="yes" xml:space="preserve">
          <source>L = \prod_d \left\lfloor\frac{\text{spatial\_size}[d] + 2 \times \text{padding}[d] % - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,</source>
          <target state="translated">L=\prod_d ✿︎+2 ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ➡</target>
        </trans-unit>
        <trans-unit id="c775d48eb4f58382ff520cfe8c90ab7190041ada" translate="yes" xml:space="preserve">
          <source>L = \{l_1,\dots,l_N\}^\top</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77bc26a3089aa1a1138008701f4240f1d24f7ec4" translate="yes" xml:space="preserve">
          <source>L(a, p, n) = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}</source>
          <target state="translated">L(a,p,n)=\max \d(i,p_i)-d(a,n_i)+{rrm margin},0}.</target>
        </trans-unit>
        <trans-unit id="38b3e9960c6ed6d7fea333d02fe4a806a8e19d30" translate="yes" xml:space="preserve">
          <source>L1Loss</source>
          <target state="translated">L1Loss</target>
        </trans-unit>
        <trans-unit id="eea818c7023faaf096d89f5dc66b905458038bf3" translate="yes" xml:space="preserve">
          <source>L1Unstructured</source>
          <target state="translated">L1Unstructured</target>
        </trans-unit>
        <trans-unit id="ba6b42d0904cce73f214db608d06bfd30f824246" translate="yes" xml:space="preserve">
          <source>L=C \times \text{upscale\_factor}^2</source>
          <target state="translated">L=C \times text{upscale_factor}^2</target>
        </trans-unit>
        <trans-unit id="e08d4eaec3e70d3b11d0930088b84b2ff38e358f" translate="yes" xml:space="preserve">
          <source>LPPool1d</source>
          <target state="translated">LPPool1d</target>
        </trans-unit>
        <trans-unit id="2ea3c697cd5d5c5710f8ec9f1853900569f0680c" translate="yes" xml:space="preserve">
          <source>LPPool2d</source>
          <target state="translated">LPPool2d</target>
        </trans-unit>
        <trans-unit id="23757b375d1fdee5bda46fff218547176aed63b2" translate="yes" xml:space="preserve">
          <source>LSTM</source>
          <target state="translated">LSTM</target>
        </trans-unit>
        <trans-unit id="2f25bc39b85fe095b000d209878e94802865e367" translate="yes" xml:space="preserve">
          <source>LSTMCell</source>
          <target state="translated">LSTMCell</target>
        </trans-unit>
        <trans-unit id="ecfecac3ee4f2cb5286bbb038509a2e5de7c4c02" translate="yes" xml:space="preserve">
          <source>LU factorization with &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; is not available for CPU, and attempting to do so will throw an error. However, LU factorization with &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; is available for CUDA.</source>
          <target state="translated">&lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; のLU分解はCPUで使用できず、そうしようとするとエラーがスローされます。ただし、 &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; のLU分解はCUDAで使用できます。</target>
        </trans-unit>
        <trans-unit id="0deac72fe13e2e0b87977edeca8e509c0bcfa09e" translate="yes" xml:space="preserve">
          <source>L_p</source>
          <target state="translated">L_p</target>
        </trans-unit>
        <trans-unit id="06c5049b8951b65d33ef4a2ef830eb1114e69b8d" translate="yes" xml:space="preserve">
          <source>L_{out} = (L_{in} - 1) \times \text{stride} - 2 \times \text{padding} + \text{dilation} \times (\text{kernel\_size} - 1) + \text{output\_padding} + 1</source>
          <target state="translated">L_{out}=(L_{in}-1)♪times \times ﾃｷｽﾄ{stride}-2 \times ﾃｷｽﾄ{padding}+ﾃｷｽﾄ{dilation}ﾄｲﾑｽﾞ (\text{kernel_size}-1)+♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ 1</target>
        </trans-unit>
        <trans-unit id="b805a9450351de83336b48fb7172bcc72a263dc2" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceac6a4482e16b31e7e38fe1379ffb2a0580a4c8" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=✿L_{out}+2 ✿L_{in}+2 ✿L_{padding}-✿L_{padding}-✿L_{padding}+1</target>
        </trans-unit>
        <trans-unit id="87439fc8e93caa8a60f8765a05bec347953ce5dc" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=≪Lleft≫ L_{in}+2 \times ≪L_{padding}-≫ ≪Dilation}≫ ≪Times (Text{kernel_size}-1)-1}{Text{stride}}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="9c7d288e1c47c63e7fa88234abfbcbb629553bc4" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor\frac{L_{in} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=≪L_{out}≫-≪L_{in}≫-≪L_{in}≫+1\\rightrfloor</target>
        </trans-unit>
        <trans-unit id="82415f0bf390885258b6da20230789fced78fab6" translate="yes" xml:space="preserve">
          <source>Labels passed as inputs to this module should be sorted according to their frequency. This means that the most frequent label should be represented by the index &lt;code&gt;0&lt;/code&gt;, and the least frequent label should be represented by the index &lt;code&gt;n_classes - 1&lt;/code&gt;.</source>
          <target state="translated">このモジュールへの入力として渡されるラベルは、頻度に従ってソートする必要があります。これは、最も頻度の高いラベルはインデックス &lt;code&gt;0&lt;/code&gt; で表され、最も頻度の低いラベルはインデックス &lt;code&gt;n_classes - 1&lt;/code&gt; で表される必要があることを意味します。</target>
        </trans-unit>
        <trans-unit id="e52f467c6824dfb11f12944d49910287d4e8acf9" translate="yes" xml:space="preserve">
          <source>Language Bindings</source>
          <target state="translated">言語バインディング</target>
        </trans-unit>
        <trans-unit id="f7c1b0b04225275caa328bda30504fd6b8c37f10" translate="yes" xml:space="preserve">
          <source>Laplace</source>
          <target state="translated">Laplace</target>
        </trans-unit>
        <trans-unit id="1a13e309cb6089d8795a4086c303a44f1aa93eb0" translate="yes" xml:space="preserve">
          <source>Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;chunks&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; に沿ったテンソルサイズが &lt;code&gt;chunks&lt;/code&gt; 割り切れない場合、最後のチャンクは小さくなります。</target>
        </trans-unit>
        <trans-unit id="ea4ab66267252a04db528f49cff0f01eeac15249" translate="yes" xml:space="preserve">
          <source>Later, saved tensors can be accessed through the &lt;code&gt;saved_tensors&lt;/code&gt; attribute. Before returning them to the user, a check is made to ensure they weren&amp;rsquo;t used in any in-place operation that modified their content.</source>
          <target state="translated">後で、保存されたテンソルは、 &lt;code&gt;saved_tensors&lt;/code&gt; 属性を介してアクセスできます。それらをユーザーに返す前に、コンテンツを変更するインプレース操作で使用されていないことを確認するためのチェックが行われます。</target>
        </trans-unit>
        <trans-unit id="c11e8b0852264fedca1944abe570a02d58008f36" translate="yes" xml:space="preserve">
          <source>Launch utility</source>
          <target state="translated">ユーティリティの起動</target>
        </trans-unit>
        <trans-unit id="3e7347f29c1c343ae08ddd8deb4a8c8c703257a6" translate="yes" xml:space="preserve">
          <source>LayerNorm</source>
          <target state="translated">LayerNorm</target>
        </trans-unit>
        <trans-unit id="ae8648006d573eefab4fc3a540fa844d3c24c709" translate="yes" xml:space="preserve">
          <source>Leaky Relu</source>
          <target state="translated">漏れたレリュー</target>
        </trans-unit>
        <trans-unit id="f3272736528de0f5cd99ceafd394209cd4f0d9d4" translate="yes" xml:space="preserve">
          <source>LeakyRELU</source>
          <target state="translated">LeakyRELU</target>
        </trans-unit>
        <trans-unit id="fedab85703859b90b0ad1f8cd46b9b7ea93c8647" translate="yes" xml:space="preserve">
          <source>LeakyReLU</source>
          <target state="translated">LeakyReLU</target>
        </trans-unit>
        <trans-unit id="08736899d926026ffd2bed5a1ba2420f2fe34a6d" translate="yes" xml:space="preserve">
          <source>Learning rate scheduling should be applied after optimizer&amp;rsquo;s update; e.g., you should write your code this way:</source>
          <target state="translated">学習率のスケジューリングは、オプティマイザーの更新後に適用する必要があります。たとえば、次のようにコードを記述する必要があります。</target>
        </trans-unit>
        <trans-unit id="7422cede6b29fe51f9334794bb938ed3c22c4e55" translate="yes" xml:space="preserve">
          <source>Least squares estimation of the original signal of size (&amp;hellip;, signal_length)</source>
          <target state="translated">サイズの元の信号の最小二乗推定（&amp;hellip;、signal_length）</target>
        </trans-unit>
        <trans-unit id="81a9dc728fc2ca28b37b2c8b862e702ce61a20d2" translate="yes" xml:space="preserve">
          <source>Legacy Constructors</source>
          <target state="translated">レガシーコンストラクタ</target>
        </trans-unit>
        <trans-unit id="e6252983d84535ed576c200c0613bfb5c53e74f6" translate="yes" xml:space="preserve">
          <source>Let I_0 be the zeroth order modified Bessel function of the first kind (see &lt;a href=&quot;torch.i0#torch.i0&quot;&gt;&lt;code&gt;torch.i0()&lt;/code&gt;&lt;/a&gt;) and &lt;code&gt;N = L - 1&lt;/code&gt; if &lt;code&gt;periodic&lt;/code&gt; is False and &lt;code&gt;L&lt;/code&gt; if &lt;code&gt;periodic&lt;/code&gt; is True, where &lt;code&gt;L&lt;/code&gt; is the &lt;code&gt;window_length&lt;/code&gt;. This function computes:</source>
          <target state="translated">I_0は、ゼロ次は、第一種ベッセル関数を変性とする（参照&lt;a href=&quot;torch.i0#torch.i0&quot;&gt; &lt;code&gt;torch.i0()&lt;/code&gt; &lt;/a&gt;）及び &lt;code&gt;N = L - 1&lt;/code&gt; 場合 &lt;code&gt;periodic&lt;/code&gt; 偽となる &lt;code&gt;L&lt;/code&gt; 場合 &lt;code&gt;periodic&lt;/code&gt; ここで、真である &lt;code&gt;L&lt;/code&gt; がある &lt;code&gt;window_length&lt;/code&gt; 。この関数は以下を計算します：</target>
        </trans-unit>
        <trans-unit id="c0f4fa4a2a001fbe73eaa9b243479e76bce8ec6b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how &lt;code&gt;match&lt;/code&gt; and &lt;code&gt;unify&lt;/code&gt; are used in name inference in the case of adding two one-dim tensors with no broadcasting.</source>
          <target state="translated">ブロードキャストなしで2つの1次元テンソルを追加する場合に、名前の推論で &lt;code&gt;match&lt;/code&gt; と &lt;code&gt;unify&lt;/code&gt; がどのように使用されるかを見てみましょう。</target>
        </trans-unit>
        <trans-unit id="27c968e6692b41bf6e1a241b870dc41ff1a51b17" translate="yes" xml:space="preserve">
          <source>Libraries</source>
          <target state="translated">Libraries</target>
        </trans-unit>
        <trans-unit id="538c09161b8497f998404cafc34964ed3a445575" translate="yes" xml:space="preserve">
          <source>Licensed under the 3-clause BSD License.</source>
          <target state="translated">3句BSDライセンスの下でライセンスされています。</target>
        </trans-unit>
        <trans-unit id="7f5f45ae757c1886e79dc62c9c379591270427af" translate="yes" xml:space="preserve">
          <source>Like &lt;em&gt;output&lt;/em&gt;, the layers can be separated using &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; and similarly for &lt;em&gt;c_n&lt;/em&gt;.</source>
          <target state="translated">&lt;em&gt;出力&lt;/em&gt;と同様に、レイヤーは &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; を使用して、&lt;em&gt;c_n&lt;/em&gt;についても同様に分離できます。</target>
        </trans-unit>
        <trans-unit id="db10501c95280d11842c24308a3aa239dbe03702" translate="yes" xml:space="preserve">
          <source>Like &lt;em&gt;output&lt;/em&gt;, the layers can be separated using &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt;.</source>
          <target state="translated">&lt;em&gt;出力&lt;/em&gt;と同様に、 &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; を使用してレイヤーを分離できます。</target>
        </trans-unit>
        <trans-unit id="e802831cc6f03739c21444458e82e5daba72cf20" translate="yes" xml:space="preserve">
          <source>Like with &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;, the output length must be given in order to recover an even length output:</source>
          <target state="translated">&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;と同様に、偶数の長さの出力を回復するには、出力の長さを指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="a7c04c64ed3f2a9374590c76c50d3b7f1b18e3da" translate="yes" xml:space="preserve">
          <source>Limitations</source>
          <target state="translated">Limitations</target>
        </trans-unit>
        <trans-unit id="af502f2b37eea07ed9083c7daf40f34553f6fccd" translate="yes" xml:space="preserve">
          <source>Linear</source>
          <target state="translated">Linear</target>
        </trans-unit>
        <trans-unit id="52f5fe1a2af4bafc542342604407d9368527a7e4" translate="yes" xml:space="preserve">
          <source>Linear / Identity</source>
          <target state="translated">リニア/アイデンティティ</target>
        </trans-unit>
        <trans-unit id="462229a1c5dbd1fa15040281e0145c1fe6a072c6" translate="yes" xml:space="preserve">
          <source>Linear Layers</source>
          <target state="translated">リニアレイヤー</target>
        </trans-unit>
        <trans-unit id="e0948f7097c1b1ef0dfbf5426722f24d5359dce5" translate="yes" xml:space="preserve">
          <source>Linear functions</source>
          <target state="translated">線形関数</target>
        </trans-unit>
        <trans-unit id="034874347ef77609e931030e8022aaf9f02a5da3" translate="yes" xml:space="preserve">
          <source>LinearReLU</source>
          <target state="translated">LinearReLU</target>
        </trans-unit>
        <trans-unit id="2654ae5325afbc554a0ee441059fbb41cbaf1dbb" translate="yes" xml:space="preserve">
          <source>List Construction</source>
          <target state="translated">工事一覧</target>
        </trans-unit>
        <trans-unit id="92ca3314a6145558197b21fe52556246426b2528" translate="yes" xml:space="preserve">
          <source>List all entrypoints available in &lt;code&gt;github&lt;/code&gt; hubconf.</source>
          <target state="translated">で利用可能なすべてのエントリ・ポイント一覧表示 &lt;code&gt;github&lt;/code&gt; hubconfを。</target>
        </trans-unit>
        <trans-unit id="c7ba7dcf662374aafe652b03d75cb8f6024519d9" translate="yes" xml:space="preserve">
          <source>Literals</source>
          <target state="translated">Literals</target>
        </trans-unit>
        <trans-unit id="bd26911422165279d6cf54be6a2c3601b7d15a43" translate="yes" xml:space="preserve">
          <source>LnStructured</source>
          <target state="translated">LnStructured</target>
        </trans-unit>
        <trans-unit id="b0a48cb5954a9d7f0650f13e3620734ccd2bae05" translate="yes" xml:space="preserve">
          <source>Load a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; previously saved with &lt;a href=&quot;generated/torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">以前に&lt;a href=&quot;generated/torch.jit.save#torch.jit.save&quot;&gt; &lt;code&gt;torch.jit.save&lt;/code&gt; で&lt;/a&gt;保存された&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; を&lt;/a&gt;ロードします</target>
        </trans-unit>
        <trans-unit id="895bd8b16804ae34cfb0e2dc72b19fd2ce1623cf" translate="yes" xml:space="preserve">
          <source>Load a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; previously saved with &lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">以前に&lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt; &lt;code&gt;torch.jit.save&lt;/code&gt; で&lt;/a&gt;保存された&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; を&lt;/a&gt;ロードします</target>
        </trans-unit>
        <trans-unit id="6cb35151312e0bc2bc2c91990968d299f6b351f9" translate="yes" xml:space="preserve">
          <source>Load a model from a github repo or a local directory.</source>
          <target state="translated">githubのレポまたはローカルディレクトリからモデルをロードします。</target>
        </trans-unit>
        <trans-unit id="bbfedf2587224caa5003ffee100938c3cce6187d" translate="yes" xml:space="preserve">
          <source>Loading Batched and Non-Batched Data</source>
          <target state="translated">バッチデータと非バッチデータの読み込み</target>
        </trans-unit>
        <trans-unit id="08eab7f7a8aa4c317badff7188cc2c0bb5835fc2" translate="yes" xml:space="preserve">
          <source>Loading models from Hub</source>
          <target state="translated">ハブからのモデルの読み込み</target>
        </trans-unit>
        <trans-unit id="1df3601943ceea2bf72fecc57231a5842fe092bb" translate="yes" xml:space="preserve">
          <source>Loads a PyTorch C++ extension just-in-time (JIT) from string sources.</source>
          <target state="translated">PyTorch C++拡張機能のジャストインタイム(JIT)を文字列ソースからロードします。</target>
        </trans-unit>
        <trans-unit id="e0c28fcdf2966da4afbb699048a05d25a1e72589" translate="yes" xml:space="preserve">
          <source>Loads a PyTorch C++ extension just-in-time (JIT).</source>
          <target state="translated">PyTorch C++拡張のジャストインタイム(JIT)をロードします。</target>
        </trans-unit>
        <trans-unit id="b8172851e5d518987e24368975b30a3f3621f89a" translate="yes" xml:space="preserve">
          <source>Loads an object saved with &lt;a href=&quot;generated/torch.save#torch.save&quot;&gt;&lt;code&gt;torch.save()&lt;/code&gt;&lt;/a&gt; from a file.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.save#torch.save&quot;&gt; &lt;code&gt;torch.save()&lt;/code&gt; で&lt;/a&gt;保存されたオブジェクトをファイルからロードします。</target>
        </trans-unit>
        <trans-unit id="abae7d5b43752c21e187437593ecfd6e103a310d" translate="yes" xml:space="preserve">
          <source>Loads an object saved with &lt;a href=&quot;torch.save#torch.save&quot;&gt;&lt;code&gt;torch.save()&lt;/code&gt;&lt;/a&gt; from a file.</source>
          <target state="translated">&lt;a href=&quot;torch.save#torch.save&quot;&gt; &lt;code&gt;torch.save()&lt;/code&gt; で&lt;/a&gt;保存されたオブジェクトをファイルからロードします。</target>
        </trans-unit>
        <trans-unit id="f2285e79b168630a8a2e0f5ae0c64959ab5ec6e8" translate="yes" xml:space="preserve">
          <source>Loads the Torch serialized object at the given URL.</source>
          <target state="translated">指定されたURLでTorchのシリアル化オブジェクトを読み込みます。</target>
        </trans-unit>
        <trans-unit id="8e303a8f00a29e8f80582a95270441302240025d" translate="yes" xml:space="preserve">
          <source>Loads the optimizer state.</source>
          <target state="translated">オプティマイザの状態を読み込みます。</target>
        </trans-unit>
        <trans-unit id="7aaab562b127aeeb78317020a69983cd185a2928" translate="yes" xml:space="preserve">
          <source>Loads the scaler state. If this instance is disabled, &lt;a href=&quot;#torch.cuda.amp.GradScaler.load_state_dict&quot;&gt;&lt;code&gt;load_state_dict()&lt;/code&gt;&lt;/a&gt; is a no-op.</source>
          <target state="translated">スケーラーの状態をロードします。このインスタンスが無効になっている場合、&lt;a href=&quot;#torch.cuda.amp.GradScaler.load_state_dict&quot;&gt; &lt;code&gt;load_state_dict()&lt;/code&gt; &lt;/a&gt;は何もしません。</target>
        </trans-unit>
        <trans-unit id="1cfdfc410207837272e43ead5fb1f22980e56511" translate="yes" xml:space="preserve">
          <source>Loads the schedulers state.</source>
          <target state="translated">スケジューラの状態を読み込みます。</target>
        </trans-unit>
        <trans-unit id="bca03b832694245e7d76094e54b41aee61f32b8c" translate="yes" xml:space="preserve">
          <source>Local file system, &lt;code&gt;init_method=&quot;file:///d:/tmp/some_file&quot;&lt;/code&gt;</source>
          <target state="translated">ローカルファイルシステム、 &lt;code&gt;init_method=&quot;file:///d:/tmp/some_file&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9e2a7f51460fa624f29eb4d9345e24061c3314f3" translate="yes" xml:space="preserve">
          <source>LocalResponseNorm</source>
          <target state="translated">LocalResponseNorm</target>
        </trans-unit>
        <trans-unit id="0ca5c78f2cf1102c66c5583023caa00fc87c10db" translate="yes" xml:space="preserve">
          <source>Locally disabling gradient computation</source>
          <target state="translated">勾配計算をローカルで無効にする</target>
        </trans-unit>
        <trans-unit id="4029ee70e71d54ca0962e31cd594321368f86629" translate="yes" xml:space="preserve">
          <source>LogNormal</source>
          <target state="translated">LogNormal</target>
        </trans-unit>
        <trans-unit id="5f6a43bda80ee771a5be7b5a9a5b959803eff8b6" translate="yes" xml:space="preserve">
          <source>LogSigmoid</source>
          <target state="translated">LogSigmoid</target>
        </trans-unit>
        <trans-unit id="9fcfd80b59ec37c0d7c822778e2ede78ad5ef865" translate="yes" xml:space="preserve">
          <source>LogSoftmax</source>
          <target state="translated">LogSoftmax</target>
        </trans-unit>
        <trans-unit id="2be6f5f3dfe34ae207c15144d936b394d3342629" translate="yes" xml:space="preserve">
          <source>Log_probs: Tensor of size</source>
          <target state="translated">Log_probs.サイズのテンソル</target>
        </trans-unit>
        <trans-unit id="3a29b9b1054fef950824734dd96565e57e322c96" translate="yes" xml:space="preserve">
          <source>Logarithm of the sum of exponentiations of the inputs in base-2.</source>
          <target state="translated">ベース2の入力の指数の和の対数。</target>
        </trans-unit>
        <trans-unit id="273c857a62012f5708232560c688d9c8f7c28ba5" translate="yes" xml:space="preserve">
          <source>Logarithm of the sum of exponentiations of the inputs.</source>
          <target state="translated">入力の指数の和の対数。</target>
        </trans-unit>
        <trans-unit id="65eac6118ebdd55aa38b41f70efdf532e567ffd8" translate="yes" xml:space="preserve">
          <source>Logical Operators</source>
          <target state="translated">論理演算子</target>
        </trans-unit>
        <trans-unit id="ca7f4bd6623919e36ffd033c9c80f0e4b3c64f49" translate="yes" xml:space="preserve">
          <source>LogitRelaxedBernoulli</source>
          <target state="translated">LogitRelaxedBernoulli</target>
        </trans-unit>
        <trans-unit id="4e1da61dedde155219f888017b4095799b14e811" translate="yes" xml:space="preserve">
          <source>LongTensor or tuple of LongTensor</source>
          <target state="translated">LongTensorまたはLongTensorのタプル</target>
        </trans-unit>
        <trans-unit id="79894b78077b352e7913286a38c3c0b109363b18" translate="yes" xml:space="preserve">
          <source>LongTensor that has one more dimension with 1 values at the index of last dimension indicated by the input, and 0 everywhere else.</source>
          <target state="translated">入力で示された最後の次元のインデックスに1の値を持ち,それ以外の場所では0の値を持つ,もう1つの次元を持つLongTensor.</target>
        </trans-unit>
        <trans-unit id="5889a83849e7452eb90474433b00a93e8ed08a2f" translate="yes" xml:space="preserve">
          <source>Look at the paper: &lt;a href=&quot;https://arxiv.org/abs/1609.05158&quot;&gt;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network&lt;/a&gt; by Shi et. al (2016) for more details.</source>
          <target state="translated">論文を見てください：Shiらによる&lt;a href=&quot;https://arxiv.org/abs/1609.05158&quot;&gt;効率的なサブピクセル畳み込みニューラルネットワークを使用したリアルタイムの単一画像とビデオの超解像&lt;/a&gt;。詳細については、al（2016）を参照してください。</target>
        </trans-unit>
        <trans-unit id="99663eada4ef450e2ffc9048b04317b33e9db27b" translate="yes" xml:space="preserve">
          <source>Lookup returns the most specific (type,type) match ordered by subclass. If the match is ambiguous, a &lt;code&gt;RuntimeWarning&lt;/code&gt; is raised. For example to resolve the ambiguous situation:</source>
          <target state="translated">ルックアップは、サブクラス順に並べられた最も具体的な（type、type）一致を返します。一致があいまいな場合、 &lt;code&gt;RuntimeWarning&lt;/code&gt; が発生します。たとえば、あいまいな状況を解決するには、次のようにします。</target>
        </trans-unit>
        <trans-unit id="c0224525e6e81a08ff829f4d53c8aff4b15f7024" translate="yes" xml:space="preserve">
          <source>Loss Functions</source>
          <target state="translated">損失機能</target>
        </trans-unit>
        <trans-unit id="bf3496193ce471c7c1c432d246ad87b6a1823e9c" translate="yes" xml:space="preserve">
          <source>Loss functions</source>
          <target state="translated">損失機能</target>
        </trans-unit>
        <trans-unit id="85b9d89a2ed9217bacdf503e6a3c96f95e5750aa" translate="yes" xml:space="preserve">
          <source>Lots of information can be logged for one experiment. To avoid cluttering the UI and have better result clustering, we can group plots by naming them hierarchically. For example, &amp;ldquo;Loss/train&amp;rdquo; and &amp;ldquo;Loss/test&amp;rdquo; will be grouped together, while &amp;ldquo;Accuracy/train&amp;rdquo; and &amp;ldquo;Accuracy/test&amp;rdquo; will be grouped separately in the TensorBoard interface.</source>
          <target state="translated">1回の実験で多くの情報を記録できます。UIの乱雑さを回避し、より良い結果のクラスタリングを実現するために、プロットに階層的な名前を付けてグループ化できます。たとえば、「Loss / train」と「Loss / test」はグループ化され、「Accuracy / train」と「Accuracy / test」はTensorBoardインターフェースで別々にグループ化されます。</target>
        </trans-unit>
        <trans-unit id="a851f6b05f669f852f4c7d2a4117b59cc9a5c4f0" translate="yes" xml:space="preserve">
          <source>LowRankMultivariateNormal</source>
          <target state="translated">LowRankMultivariateNormal</target>
        </trans-unit>
        <trans-unit id="c63ae6dd4fc9f9dda66970e827d13f7c73fe841c" translate="yes" xml:space="preserve">
          <source>M</source>
          <target state="translated">M</target>
        </trans-unit>
        <trans-unit id="a452071172e433a963ff286fe987870a980f2d28" translate="yes" xml:space="preserve">
          <source>M (Tensor, optional): the input tensor&amp;rsquo;s mean of size</source>
          <target state="translated">M（テンソル、オプション）：入力テンソルのサイズの平均</target>
        </trans-unit>
        <trans-unit id="7b186e235f284107df6b4dbe6060d2b6a5d9f1e5" translate="yes" xml:space="preserve">
          <source>MAX</source>
          <target state="translated">MAX</target>
        </trans-unit>
        <trans-unit id="0d96af233d36586b84359d8b5bd0b417787982e1" translate="yes" xml:space="preserve">
          <source>MC3 Network definition</source>
          <target state="translated">MC3 ネットワーク定義</target>
        </trans-unit>
        <trans-unit id="04e66352aa8f9c4c5f26b71bf380973ada994760" translate="yes" xml:space="preserve">
          <source>MIN</source>
          <target state="translated">MIN</target>
        </trans-unit>
        <trans-unit id="351682e4dc04204d75a824bcbf8f8aa6acc15e71" translate="yes" xml:space="preserve">
          <source>MIXED MODE OF (1) and (2):</source>
          <target state="translated">(1)と(2)のミックスモード。</target>
        </trans-unit>
        <trans-unit id="59ce6264cd26f13684de464b9aeb65d1d414e559" translate="yes" xml:space="preserve">
          <source>MNASNet</source>
          <target state="translated">MNASNet</target>
        </trans-unit>
        <trans-unit id="533bea2ee6c045fe09ac0124525af723616f331a" translate="yes" xml:space="preserve">
          <source>MNASNet 1.0</source>
          <target state="translated">MNASNet 1.0</target>
        </trans-unit>
        <trans-unit id="9a7425f07104beddfc0bce0274310b0a2e2ea359" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 0.5 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が0.5のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="98e07c23513158f84ea34588dbe9369dbc7ac20e" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 0.75 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が0.75のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="71754b43c6a0483cdc892a42e6511e7a6757f6a2" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 1.0 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が1.0のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="6f35e9dd2bd116147e38d35cef6e82d4b56bfc05" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 1.3 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：モバイル向けプラットフォーム対応ニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数1.3のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="53880fd71eeaa5e41a5d925ca0243b4befcdb092" translate="yes" xml:space="preserve">
          <source>MSELoss</source>
          <target state="translated">MSELoss</target>
        </trans-unit>
        <trans-unit id="76c7044fa78115fa06a42c399d17d51a9203e830" translate="yes" xml:space="preserve">
          <source>Make a blocking RPC call to run function &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt;. RPC messages are sent and received in parallel to execution of Python code. This method is thread-safe.</source>
          <target state="translated">関数を実行するには、ブロッキングRPCコールしてください &lt;code&gt;func&lt;/code&gt; 作業者 &lt;code&gt;to&lt;/code&gt; 。RPCメッセージは、Pythonコードの実行と並行して送受信されます。このメソッドはスレッドセーフです。</target>
        </trans-unit>
        <trans-unit id="0d7820212a00c819e77e602a3ef50edfe2f50d52" translate="yes" xml:space="preserve">
          <source>Make a non-blocking RPC call to run function &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt;. RPC messages are sent and received in parallel to execution of Python code. This method is thread-safe. This method will immediately return a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; that can be awaited on.</source>
          <target state="translated">ノンブロッキングRPC呼び出しを行って、ワーカーで関数 &lt;code&gt;func&lt;/code&gt; を実行 &lt;code&gt;to&lt;/code&gt; ます。RPCメッセージは、Pythonコードの実行と並行して送受信されます。このメソッドはスレッドセーフです。このメソッドは、&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;可能なFutureをすぐに返します。</target>
        </trans-unit>
        <trans-unit id="f221c8d616e55bc62ec21b79af5d8282f107f2d3" translate="yes" xml:space="preserve">
          <source>Make a remote call to run &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt; and return an &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; to the result value immediately. Worker &lt;code&gt;to&lt;/code&gt; will be the owner of the returned &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt;, and the worker calling &lt;code&gt;remote&lt;/code&gt; is a user. The owner manages the global reference count of its &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt;, and the owner &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; is only destructed when globally there are no living references to it.</source>
          <target state="translated">実行するためのリモート呼び出してください &lt;code&gt;func&lt;/code&gt; を労働者に &lt;code&gt;to&lt;/code&gt; と戻り&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;すぐに結果値にします。労働者 &lt;code&gt;to&lt;/code&gt; 返却の所有者になります&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;、および呼び出し元作業員 &lt;code&gt;remote&lt;/code&gt; ユーザーです。所有者は、その&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; の&lt;/a&gt;グローバル参照カウントを管理し、所有者&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;は、グローバルに参照が存在しない場合にのみ破棄されます。</target>
        </trans-unit>
        <trans-unit id="f909b867fd9b369b49e7c33ae5b4db26cd626b58" translate="yes" xml:space="preserve">
          <source>Make sure that &lt;code&gt;MASTER_ADDR&lt;/code&gt; and &lt;code&gt;MASTER_PORT&lt;/code&gt; are set properly on both workers. Refer to &lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; API for more details. For example,</source>
          <target state="translated">&lt;code&gt;MASTER_ADDR&lt;/code&gt; と &lt;code&gt;MASTER_PORT&lt;/code&gt; が両方のワーカーで正しく設定されていることを確認してください。詳細については、&lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; &lt;/a&gt; APIを参照してください。例えば、</target>
        </trans-unit>
        <trans-unit id="e23b19686007a5b5511fdca9b9d258395bc61451" translate="yes" xml:space="preserve">
          <source>Make sure that any custom &lt;code&gt;collate_fn&lt;/code&gt;, &lt;code&gt;worker_init_fn&lt;/code&gt; or &lt;code&gt;dataset&lt;/code&gt; code is declared as top level definitions, outside of the &lt;code&gt;__main__&lt;/code&gt; check. This ensures that they are available in worker processes. (this is needed since functions are pickled as references only, not &lt;code&gt;bytecode&lt;/code&gt;.)</source>
          <target state="translated">任意のカスタムれていることを確認し &lt;code&gt;collate_fn&lt;/code&gt; 、 &lt;code&gt;worker_init_fn&lt;/code&gt; または &lt;code&gt;dataset&lt;/code&gt; のコードがトップレベルの定義は、外と宣言されている &lt;code&gt;__main__&lt;/code&gt; チェック。これにより、ワーカープロセスで確実に使用できるようになります。（関数は &lt;code&gt;bytecode&lt;/code&gt; ではなく参照としてのみピクルスされるため、これが必要です。）</target>
        </trans-unit>
        <trans-unit id="3140663730440e28711adcbaaf1e5be8f31a832b" translate="yes" xml:space="preserve">
          <source>Makes a &lt;code&gt;cls&lt;/code&gt; instance with the same data pointer as &lt;code&gt;self&lt;/code&gt;. Changes in the output mirror changes in &lt;code&gt;self&lt;/code&gt;, and the output stays attached to the autograd graph. &lt;code&gt;cls&lt;/code&gt; must be a subclass of &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">なる &lt;code&gt;cls&lt;/code&gt; と同じデータポインタを使用してインスタンスを &lt;code&gt;self&lt;/code&gt; 。出力ミラーの変化は &lt;code&gt;self&lt;/code&gt; で変化し、出力はautogradグラフにアタッチされたままになります。 &lt;code&gt;cls&lt;/code&gt; は &lt;code&gt;Tensor&lt;/code&gt; のサブクラスである必要があります。</target>
        </trans-unit>
        <trans-unit id="e810a7ac67a7f7afc66a0a46bf613aab777bf84d" translate="yes" xml:space="preserve">
          <source>Makes all future work submitted to the given stream wait for this event.</source>
          <target state="translated">与えられたストリームに投稿されたすべての将来の作品を、このイベントを待たせます。</target>
        </trans-unit>
        <trans-unit id="8bb52cb02033ef90d627dbaa4c9db7b7d77cc8ad" translate="yes" xml:space="preserve">
          <source>Makes all future work submitted to the stream wait for an event.</source>
          <target state="translated">ストリームに投稿された今後の作品をすべてイベント待ちにします。</target>
        </trans-unit>
        <trans-unit id="49e2977180d59fe62d760df21fb871ec41183f71" translate="yes" xml:space="preserve">
          <source>Manipulating dimensions</source>
          <target state="translated">寸法の操作</target>
        </trans-unit>
        <trans-unit id="1b2e08cb686bf5745b4dbb6986d0dc5c2cab21bf" translate="yes" xml:space="preserve">
          <source>Manual gradient layouts</source>
          <target state="translated">手動グラデーションレイアウト</target>
        </trans-unit>
        <trans-unit id="6d825496aa8e7368b658938db8b142e79e1f39ee" translate="yes" xml:space="preserve">
          <source>Many PyTorch functions, which return a view of a tensor, are internally implemented with this function. Those functions, like &lt;a href=&quot;../tensors#torch.Tensor.expand&quot;&gt;&lt;code&gt;torch.Tensor.expand()&lt;/code&gt;&lt;/a&gt;, are easier to read and are therefore more advisable to use.</source>
          <target state="translated">テンソルのビューを返す多くのPyTorch関数は、この関数で内部的に実装されています。&lt;a href=&quot;../tensors#torch.Tensor.expand&quot;&gt; &lt;code&gt;torch.Tensor.expand()&lt;/code&gt; の&lt;/a&gt;ようなこれらの関数は読みやすいため、使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="181be8aee3d1857e33b8c6d149cff923185af75a" translate="yes" xml:space="preserve">
          <source>Many models use a sigmoid layer right before the binary cross entropy layer. In this case, combine the two layers using &lt;a href=&quot;nn.functional#torch.nn.functional.binary_cross_entropy_with_logits&quot;&gt;&lt;code&gt;torch.nn.functional.binary_cross_entropy_with_logits()&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.nn.bcewithlogitsloss#torch.nn.BCEWithLogitsLoss&quot;&gt;&lt;code&gt;torch.nn.BCEWithLogitsLoss&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;binary_cross_entropy_with_logits&lt;/code&gt; and &lt;code&gt;BCEWithLogits&lt;/code&gt; are safe to autocast.</source>
          <target state="translated">多くのモデルは、バイナリクロスエントロピーレイヤーの直前にシグモイドレイヤーを使用します。この場合、&lt;a href=&quot;nn.functional#torch.nn.functional.binary_cross_entropy_with_logits&quot;&gt; &lt;code&gt;torch.nn.functional.binary_cross_entropy_with_logits()&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/torch.nn.bcewithlogitsloss#torch.nn.BCEWithLogitsLoss&quot;&gt; &lt;code&gt;torch.nn.BCEWithLogitsLoss&lt;/code&gt; &lt;/a&gt;を使用して2つのレイヤーを結合します。 &lt;code&gt;binary_cross_entropy_with_logits&lt;/code&gt; と &lt;code&gt;BCEWithLogits&lt;/code&gt; は安全に自動キャストできます。</target>
        </trans-unit>
        <trans-unit id="877edbec3bdc8c92a89c77b353c1bffa8a6d3f53" translate="yes" xml:space="preserve">
          <source>Many of Python&amp;rsquo;s &lt;a href=&quot;https://docs.python.org/3/library/functions.html&quot;&gt;built-in functions&lt;/a&gt; are supported in TorchScript. The &lt;a href=&quot;https://docs.python.org/3/library/math.html#module-math&quot;&gt;&lt;code&gt;math&lt;/code&gt;&lt;/a&gt; module is also supported (see &lt;a href=&quot;jit_builtin_functions#math-module&quot;&gt;math Module&lt;/a&gt; for details), but no other Python modules (built-in or third party) are supported.</source>
          <target state="translated">Pythonの&lt;a href=&quot;https://docs.python.org/3/library/functions.html&quot;&gt;組み込み関数の&lt;/a&gt;多くは、TorchScriptでサポートされています。&lt;a href=&quot;https://docs.python.org/3/library/math.html#module-math&quot;&gt; &lt;code&gt;math&lt;/code&gt; &lt;/a&gt;モジュールはまた、（参照サポートされている&lt;a href=&quot;jit_builtin_functions#math-module&quot;&gt;数学のモジュールの&lt;/a&gt;詳細については）が、他のPythonモジュール（ビルトインまたは第三者）がサポートされていません。</target>
        </trans-unit>
        <trans-unit id="9a0216a95943fa820f7459f0a77368a7416b7939" translate="yes" xml:space="preserve">
          <source>Map-style datasets</source>
          <target state="translated">マップスタイルのデータセット</target>
        </trans-unit>
        <trans-unit id="8b9cac864fb0630d3e0375c972324ae14f0a7cbf" translate="yes" xml:space="preserve">
          <source>MarginRankingLoss</source>
          <target state="translated">MarginRankingLoss</target>
        </trans-unit>
        <trans-unit id="1373a08f797bf15732fbadb687eff12b2e03c08f" translate="yes" xml:space="preserve">
          <source>Marks given tensors as modified in an in-place operation.</source>
          <target state="translated">与えられたテンソルを、その場の操作で修正したものとしてマークします。</target>
        </trans-unit>
        <trans-unit id="64d7f425f84dfa95b2a3d1450fcc8fbbce25eb01" translate="yes" xml:space="preserve">
          <source>Marks outputs as non-differentiable.</source>
          <target state="translated">出力を区別できないものとしてマークします。</target>
        </trans-unit>
        <trans-unit id="3b3b6161e2be4020ea8045bf777a1b7a9a9ef9d7" translate="yes" xml:space="preserve">
          <source>Mask R-CNN</source>
          <target state="translated">マスク R-CNN</target>
        </trans-unit>
        <trans-unit id="de79ab812f56430c47ab7094aa9e5f95c476c9d5" translate="yes" xml:space="preserve">
          <source>Mask R-CNN ResNet-50 FPN</source>
          <target state="translated">マスク R-CNN ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="e283616925f71932f219908f30d53b3df610dd54" translate="yes" xml:space="preserve">
          <source>Mask R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.</source>
          <target state="translated">マスクR-CNNは、一定サイズの入力画像で一定のバッチサイズでONNXに書き出すことができます。</target>
        </trans-unit>
        <trans-unit id="370101c55e76bb32e62a76c0f757b67a5a083820" translate="yes" xml:space="preserve">
          <source>Math operations</source>
          <target state="translated">数学演算</target>
        </trans-unit>
        <trans-unit id="f266f996d2555bfc5ac129ce470aa82f278b2388" translate="yes" xml:space="preserve">
          <source>Matrix multiplication ops: &lt;a href=&quot;name_inference#contracts-away-dims-doc&quot;&gt;Contracts away dims&lt;/a&gt;</source>
          <target state="translated">行列乗算演算：&lt;a href=&quot;name_inference#contracts-away-dims-doc&quot;&gt;ディムを縮小します&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7a75fc5d78987f3dab3a65065c4b1d4f0692e098" translate="yes" xml:space="preserve">
          <source>Matrix product of two tensors.</source>
          <target state="translated">2つのテンソルの行列積。</target>
        </trans-unit>
        <trans-unit id="eccdf32fe79dd9c576c8118d98c630238fca6bb7" translate="yes" xml:space="preserve">
          <source>MaxPool1d</source>
          <target state="translated">MaxPool1d</target>
        </trans-unit>
        <trans-unit id="3b3d541959fe8a8dd18b510e5a3f48b2498a53b4" translate="yes" xml:space="preserve">
          <source>MaxPool2d</source>
          <target state="translated">MaxPool2d</target>
        </trans-unit>
        <trans-unit id="98908ed042b1a9862ea5e9d4da6ed687e958f368" translate="yes" xml:space="preserve">
          <source>MaxPool3d</source>
          <target state="translated">MaxPool3d</target>
        </trans-unit>
        <trans-unit id="4a5419bdd0aea2636e49e9d7ca08451ce7530629" translate="yes" xml:space="preserve">
          <source>MaxUnpool1d</source>
          <target state="translated">MaxUnpool1d</target>
        </trans-unit>
        <trans-unit id="dde49d17029a94b9195f0444462e31e369394942" translate="yes" xml:space="preserve">
          <source>MaxUnpool2d</source>
          <target state="translated">MaxUnpool2d</target>
        </trans-unit>
        <trans-unit id="cbb9a5d6b569b7fb0a0f22c9d9d9d31e12466046" translate="yes" xml:space="preserve">
          <source>MaxUnpool3d</source>
          <target state="translated">MaxUnpool3d</target>
        </trans-unit>
        <trans-unit id="fe4de202eb4956062e7cfb72ed4b684ffbb5bd30" translate="yes" xml:space="preserve">
          <source>Measures the element-wise mean squared error.</source>
          <target state="translated">要素ごとの平均二乗誤差を測定します。</target>
        </trans-unit>
        <trans-unit id="09b86d975dd6b1f5a73e1c3517013bb23d540761" translate="yes" xml:space="preserve">
          <source>Measures the loss given an input tensor</source>
          <target state="translated">入力テンソルが与えられたときの損失を測定</target>
        </trans-unit>
        <trans-unit id="1d01e0fee07072aec458beb4c034b607f10f63a9" translate="yes" xml:space="preserve">
          <source>Members:</source>
          <target state="translated">Members:</target>
        </trans-unit>
        <trans-unit id="af23da357d652a02423313397c1adbd940726581" translate="yes" xml:space="preserve">
          <source>Memory Pinning</source>
          <target state="translated">メモリピン留め</target>
        </trans-unit>
        <trans-unit id="1c5536b98ab016fe61807564b4a34c80211a7613" translate="yes" xml:space="preserve">
          <source>Memory management</source>
          <target state="translated">メモリ管理</target>
        </trans-unit>
        <trans-unit id="7c5f0da2191ca27795b8631522c1ca879f1716c9" translate="yes" xml:space="preserve">
          <source>Method Calls</source>
          <target state="translated">メソッド呼び出し</target>
        </trans-unit>
        <trans-unit id="fcf32dbe7b3f386bd441fb137d4760dd5708ad54" translate="yes" xml:space="preserve">
          <source>Method to compute the entropy using Bregman divergence of the log normalizer.</source>
          <target state="translated">対数正規化器のブレグマン発散を用いてエントロピーを計算する方法。</target>
        </trans-unit>
        <trans-unit id="b3dfdaa160857d292036f521c9ea3c58c5d52fbd" translate="yes" xml:space="preserve">
          <source>Methods such as &lt;code&gt;var.backward(), var.detach(), var.register_hook()&lt;/code&gt; now work on tensors with the same method names.</source>
          <target state="translated">以下のような方法 &lt;code&gt;var.backward(), var.detach(), var.register_hook()&lt;/code&gt; と同じメソッド名を持つテンソルの今作品。</target>
        </trans-unit>
        <trans-unit id="b69c14783d5324daa62920c742f93c096f643f4f" translate="yes" xml:space="preserve">
          <source>Methods which mutate a tensor are marked with an underscore suffix. For example, &lt;code&gt;torch.FloatTensor.abs_()&lt;/code&gt; computes the absolute value in-place and returns the modified tensor, while &lt;code&gt;torch.FloatTensor.abs()&lt;/code&gt; computes the result in a new tensor.</source>
          <target state="translated">テンソルを変更するメソッドには、アンダースコアの接尾辞が付いています。たとえば、 &lt;code&gt;torch.FloatTensor.abs_()&lt;/code&gt; はインプレースで絶対値を計算し、変更されたテンソルを返しますが、 &lt;code&gt;torch.FloatTensor.abs()&lt;/code&gt; は新しいテンソルで結果を計算します。</target>
        </trans-unit>
        <trans-unit id="9b7c339ea87ccc784ad1deadd85bf646248e9d73" translate="yes" xml:space="preserve">
          <source>Methods which take a device will generally accept a (properly formatted) string or (legacy) integer device ordinal, i.e. the following are all equivalent:</source>
          <target state="translated">デバイスを受け取るメソッドは、一般的に(適切にフォーマットされた)文字列または(レガシーな)整数のデバイス序数を受け入れます。</target>
        </trans-unit>
        <trans-unit id="adfdb53a472af0c4b913a760ea8b9484fe72338d" translate="yes" xml:space="preserve">
          <source>Metric type:</source>
          <target state="translated">メトリックタイプ。</target>
        </trans-unit>
        <trans-unit id="e067f6663a0605e92a7219ee53ccfb43fa76eaf3" translate="yes" xml:space="preserve">
          <source>Migrating to PyTorch 1.2 Recursive Scripting API</source>
          <target state="translated">PyTorch 1.2 Recursive Scripting APIへの移行</target>
        </trans-unit>
        <trans-unit id="ff26bc094b922f3c06f27a4d1e69dcd28d4c0e3c" translate="yes" xml:space="preserve">
          <source>Mixing Tracing and Scripting</source>
          <target state="translated">トレースとスクリプトの混合</target>
        </trans-unit>
        <trans-unit id="6a693905dba81b2e3c99a490b1ec25a2a6253235" translate="yes" xml:space="preserve">
          <source>MixtureSameFamily</source>
          <target state="translated">MixtureSameFamily</target>
        </trans-unit>
        <trans-unit id="9ff690f5176e9e122a08292f5ff8b357a6c354e0" translate="yes" xml:space="preserve">
          <source>MobileNet V2</source>
          <target state="translated">モバイルネットV2</target>
        </trans-unit>
        <trans-unit id="c901047dcc843db7018568e9b72b5dbf5a54540d" translate="yes" xml:space="preserve">
          <source>MobileNet v2</source>
          <target state="translated">モバイルネット v2</target>
        </trans-unit>
        <trans-unit id="b8ff02892916ff59f7fbd4e617fccd01f6bca576" translate="yes" xml:space="preserve">
          <source>Module</source>
          <target state="translated">Module</target>
        </trans-unit>
        <trans-unit id="9c3f2aba6913de8da00faed8e2df2428bb1257b7" translate="yes" xml:space="preserve">
          <source>Module Attributes</source>
          <target state="translated">モジュール属性</target>
        </trans-unit>
        <trans-unit id="3cb22c5e4eabc0e7d3ccf2b60e66f53421b63149" translate="yes" xml:space="preserve">
          <source>Module Index</source>
          <target state="translated">モジュールインデックス</target>
        </trans-unit>
        <trans-unit id="0b2ce983642fdce8da88af1aafe61bc6a6ee4bfb" translate="yes" xml:space="preserve">
          <source>ModuleDict</source>
          <target state="translated">ModuleDict</target>
        </trans-unit>
        <trans-unit id="e12ef0c5e95f31ebc597e0b6fd821d6b604f3f95" translate="yes" xml:space="preserve">
          <source>ModuleList</source>
          <target state="translated">ModuleList</target>
        </trans-unit>
        <trans-unit id="04e9462c0ff02bb9032b92abd45881a3c7e15fb7" translate="yes" xml:space="preserve">
          <source>Modules</source>
          <target state="translated">Modules</target>
        </trans-unit>
        <trans-unit id="9dbae4788d0b2dea68c6e66c9e0ff2aed52f652e" translate="yes" xml:space="preserve">
          <source>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:</source>
          <target state="translated">モジュールは他のモジュールを含むこともでき、ツリー構造の中に入れ子にすることができます。サブモジュールを通常の属性として割り当てることができます。</target>
        </trans-unit>
        <trans-unit id="4a649c7ebd14c451b9eadae1b57b3c6722590226" translate="yes" xml:space="preserve">
          <source>More Information about RPC Autograd</source>
          <target state="translated">RPCオートグラッドの詳細情報</target>
        </trans-unit>
        <trans-unit id="9cb54dedb558ff4177e32b924117d76eb6014c23" translate="yes" xml:space="preserve">
          <source>More Information about RRef</source>
          <target state="translated">RRefの詳細情報</target>
        </trans-unit>
        <trans-unit id="cea97ccd7b3c8bf2304a429a1f4a38f55fbcf7bc" translate="yes" xml:space="preserve">
          <source>More details can be found in the paper &lt;a href=&quot;https://arxiv.org/abs/1704.07483&quot;&gt;Continuously Differentiable Exponential Linear Units&lt;/a&gt; .</source>
          <target state="translated">詳細については、論文「&lt;a href=&quot;https://arxiv.org/abs/1704.07483&quot;&gt;連続微分可能指数線形単位」を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="4458c625976778e29149ea1b97ed51860f9fe8ca" translate="yes" xml:space="preserve">
          <source>More details can be found in the paper &lt;a href=&quot;https://arxiv.org/abs/1706.02515&quot;&gt;Self-Normalizing Neural Networks&lt;/a&gt; .</source>
          <target state="translated">詳細については、論文&lt;a href=&quot;https://arxiv.org/abs/1706.02515&quot;&gt;Self-Normalizing NeuralNetworksを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="8edf225c0a72c5fe13ece57cbf2f54c6b24e17b0" translate="yes" xml:space="preserve">
          <source>More than one element of a broadcasted tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">ブロードキャストされたテンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、場内演算(特にベクトル化されているもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="1d81819b85f2cb3da872c9da3d0ec33cdc7aecdb" translate="yes" xml:space="preserve">
          <source>More than one element of a created tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">作成されたテンソルの1つ以上の要素が1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルに書き込む必要がある場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="304f7ec57645990453077c598f4fe8c37d2314ab" translate="yes" xml:space="preserve">
          <source>More than one element of an expanded tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">展開テンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、場内演算(特にベクトル化されているもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="f38e0558c4bf9056c21ea63c5960cbf11fd1b539" translate="yes" xml:space="preserve">
          <source>More than one element of the created tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">作成されたテンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルに書き込む必要がある場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="599668aa340279a3862bca37e7e4a6db462ba962" translate="yes" xml:space="preserve">
          <source>More than one element of the unfolded tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensor, please clone it first.</source>
          <target state="translated">展開テンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="805667fbfb7f6f1745944861662036a8e58f3c82" translate="yes" xml:space="preserve">
          <source>Moreover, as for &lt;a href=&quot;#torch.Tensor.gather&quot;&gt;&lt;code&gt;gather()&lt;/code&gt;&lt;/a&gt;, the values of &lt;code&gt;index&lt;/code&gt; must be between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;self.size(dim) - 1&lt;/code&gt; inclusive, and all values in a row along the specified dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt; must be unique.</source>
          <target state="translated">また、の場合と同様&lt;a href=&quot;#torch.Tensor.gather&quot;&gt; &lt;code&gt;gather()&lt;/code&gt; &lt;/a&gt;の値 &lt;code&gt;index&lt;/code&gt; の間でなければならない &lt;code&gt;0&lt;/code&gt; と &lt;code&gt;self.size(dim) - 1&lt;/code&gt; 包括的、および指定された次元に沿って一列のすべての値&lt;a href=&quot;#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; &lt;/a&gt;一意でなければなりません。</target>
        </trans-unit>
        <trans-unit id="dbc5f1c387e0131e10dadc48c7f1ed13f16fda56" translate="yes" xml:space="preserve">
          <source>Most attribute types can be inferred, so &lt;code&gt;torch.jit.Attribute&lt;/code&gt; is not necessary. For empty container types, annotate their types using &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526-style&lt;/a&gt; class annotations.</source>
          <target state="translated">ほとんどの属性タイプは推測できるため、 &lt;code&gt;torch.jit.Attribute&lt;/code&gt; は必要ありません。空のコンテナタイプの場合は、PEP526&lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;スタイルの&lt;/a&gt;クラスアノテーションを使用してタイプにアノテーションを付けます。</target>
        </trans-unit>
        <trans-unit id="ed994a7cd5d0a3520430a627f9865ebc68ca6011" translate="yes" xml:space="preserve">
          <source>Moved to &lt;code&gt;torch.hub&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;torch.hub&lt;/code&gt; に移動しました。</target>
        </trans-unit>
        <trans-unit id="2b0f27b71a53a0f7447384ac613f55c4204b1204" translate="yes" xml:space="preserve">
          <source>Moves all model parameters and buffers to the CPU.</source>
          <target state="translated">すべてのモデルパラメータとバッファをCPUに移動します。</target>
        </trans-unit>
        <trans-unit id="e8a79081679af4528b212d87c458a607691d5b3e" translate="yes" xml:space="preserve">
          <source>Moves all model parameters and buffers to the GPU.</source>
          <target state="translated">すべてのモデルパラメータとバッファをGPUに移動します。</target>
        </trans-unit>
        <trans-unit id="e874c62b11df47c2d692fb8935adeff7a382eea3" translate="yes" xml:space="preserve">
          <source>Moves and/or casts the parameters and buffers.</source>
          <target state="translated">パラメータとバッファを移動および/またはキャストします。</target>
        </trans-unit>
        <trans-unit id="7729e2003ebf66fb44071aeaadd11a5376f40f12" translate="yes" xml:space="preserve">
          <source>Moves the dimension(s) of &lt;code&gt;input&lt;/code&gt; at the position(s) in &lt;code&gt;source&lt;/code&gt; to the position(s) in &lt;code&gt;destination&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;source&lt;/code&gt; の位置の &lt;code&gt;input&lt;/code&gt; の次元を &lt;code&gt;destination&lt;/code&gt; の位置に移動します。</target>
        </trans-unit>
        <trans-unit id="35ac3446a4eebf31c31aeb5dad10efd9c64f3049" translate="yes" xml:space="preserve">
          <source>Moves the storage to shared memory.</source>
          <target state="translated">ストレージを共有メモリに移動します。</target>
        </trans-unit>
        <trans-unit id="7b5555e73ea9cfb4e4bc00be9e2f28d1b533e2f3" translate="yes" xml:space="preserve">
          <source>Moves the underlying storage to shared memory.</source>
          <target state="translated">基盤となるストレージを共有メモリに移動します。</target>
        </trans-unit>
        <trans-unit id="8a37b99360165eb79c6362b8c59ca260f24fc9e9" translate="yes" xml:space="preserve">
          <source>Multi-GPU collective functions</source>
          <target state="translated">マルチGPUの集合機能</target>
        </trans-unit>
        <trans-unit id="f8c9042e53df42e885d4b0f01c778b6c31356f24" translate="yes" xml:space="preserve">
          <source>Multi-Node multi-process distributed training: (e.g. two nodes)</source>
          <target state="translated">マルチノード・マルチプロセス分散訓練。(例:2ノード)</target>
        </trans-unit>
        <trans-unit id="cffbb32b31aa84528c7a48bc5418f9c2b5817403" translate="yes" xml:space="preserve">
          <source>Multi-process data loading</source>
          <target state="translated">マルチプロセスデータローディング</target>
        </trans-unit>
        <trans-unit id="e8e85a354a72efff2947c00f8ff7c48fed5f6652" translate="yes" xml:space="preserve">
          <source>MultiHead</source>
          <target state="translated">MultiHead</target>
        </trans-unit>
        <trans-unit id="aaf9b486dc5c2543a40061716ec697ddb8e0fbae" translate="yes" xml:space="preserve">
          <source>MultiLabelMarginLoss</source>
          <target state="translated">MultiLabelMarginLoss</target>
        </trans-unit>
        <trans-unit id="0bd3257d9c850deeb628f346481873a6ea866f39" translate="yes" xml:space="preserve">
          <source>MultiLabelSoftMarginLoss</source>
          <target state="translated">MultiLabelSoftMarginLoss</target>
        </trans-unit>
        <trans-unit id="65baaa8172153705ce14a7161536175046e824b3" translate="yes" xml:space="preserve">
          <source>MultiMarginLoss</source>
          <target state="translated">MultiMarginLoss</target>
        </trans-unit>
        <trans-unit id="d53b7a9617160a0821d5bb5cb1a941ffdfcd6b08" translate="yes" xml:space="preserve">
          <source>MultiheadAttention</source>
          <target state="translated">MultiheadAttention</target>
        </trans-unit>
        <trans-unit id="4319c2711cce37df073896273f25e2e05b39cbdd" translate="yes" xml:space="preserve">
          <source>Multinomial</source>
          <target state="translated">Multinomial</target>
        </trans-unit>
        <trans-unit id="7814aed0b837819b215ee4613ccc9b3a4ba6040e" translate="yes" xml:space="preserve">
          <source>Multiple Assignments</source>
          <target state="translated">複数の課題</target>
        </trans-unit>
        <trans-unit id="2f5facc713a0a585db79dc694e29dcb69110ceb7" translate="yes" xml:space="preserve">
          <source>Multiplies (&amp;lsquo;scales&amp;rsquo;) a tensor or list of tensors by the scale factor.</source>
          <target state="translated">テンソルまたはテンソルのリストにスケール係数を掛けます（「スケール」）。</target>
        </trans-unit>
        <trans-unit id="67620498370f67e43d30e9f331640d50be1f106c" translate="yes" xml:space="preserve">
          <source>Multiplies &lt;code&gt;mat&lt;/code&gt; (given by &lt;code&gt;input3&lt;/code&gt;) by the orthogonal &lt;code&gt;Q&lt;/code&gt; matrix of the QR factorization formed by &lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt; that is represented by &lt;code&gt;(a, tau)&lt;/code&gt; (given by (&lt;code&gt;input&lt;/code&gt;, &lt;code&gt;input2&lt;/code&gt;)).</source>
          <target state="translated">乗算の &lt;code&gt;mat&lt;/code&gt; （によって与え &lt;code&gt;input3&lt;/code&gt; 直交による） &lt;code&gt;Q&lt;/code&gt; により形成されたQR分解の行列&lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;で表される &lt;code&gt;(a, tau)&lt;/code&gt; （で与えられる（ &lt;code&gt;input&lt;/code&gt; 、 &lt;code&gt;input2&lt;/code&gt; ））。</target>
        </trans-unit>
        <trans-unit id="76de5400e24dedf164da206bd33a31ebb079cf8f" translate="yes" xml:space="preserve">
          <source>Multiplies &lt;code&gt;mat&lt;/code&gt; (given by &lt;code&gt;input3&lt;/code&gt;) by the orthogonal &lt;code&gt;Q&lt;/code&gt; matrix of the QR factorization formed by &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt; that is represented by &lt;code&gt;(a, tau)&lt;/code&gt; (given by (&lt;code&gt;input&lt;/code&gt;, &lt;code&gt;input2&lt;/code&gt;)).</source>
          <target state="translated">乗算の &lt;code&gt;mat&lt;/code&gt; （によって与え &lt;code&gt;input3&lt;/code&gt; 直交による） &lt;code&gt;Q&lt;/code&gt; により形成されたQR分解の行列&lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;で表される &lt;code&gt;(a, tau)&lt;/code&gt; （で与えられる（ &lt;code&gt;input&lt;/code&gt; 、 &lt;code&gt;input2&lt;/code&gt; ））。</target>
        </trans-unit>
        <trans-unit id="329fd1dd91c45edaf7c72f188795f5545aaec268" translate="yes" xml:space="preserve">
          <source>Multiplies each element of the input &lt;code&gt;input&lt;/code&gt; with the scalar &lt;code&gt;other&lt;/code&gt; and returns a new resulting tensor.</source>
          <target state="translated">入力 &lt;code&gt;input&lt;/code&gt; 各要素にスカラー &lt;code&gt;other&lt;/code&gt; を乗算し、結果の新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a50721c699d328b377c86aaee9cd7e1759fd60d6" translate="yes" xml:space="preserve">
          <source>Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr.</source>
          <target state="translated">各パラメータ群の学習率に指定された関数で与えられた係数を乗算します。last_epoch=-1の場合、初期値lrをlrに設定する。</target>
        </trans-unit>
        <trans-unit id="4d2004ec3a414cc551a0c27958276999f72ee752" translate="yes" xml:space="preserve">
          <source>Multiprocessing best practices</source>
          <target state="translated">マルチプロセッシングのベストプラクティス</target>
        </trans-unit>
        <trans-unit id="70f967b7b383e533c089648a15d728ac8a059ce8" translate="yes" xml:space="preserve">
          <source>Multiprocessing package - torch.multiprocessing</source>
          <target state="translated">マルチプロセッシングパッケージ-torch.multiprocessing</target>
        </trans-unit>
        <trans-unit id="c1a37b0bcc3effc97da7c8ab9689abbfff92b501" translate="yes" xml:space="preserve">
          <source>MultivariateNormal</source>
          <target state="translated">MultivariateNormal</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="129ca909e4d3ed97aba21ae73582b3bd13e114f8" translate="yes" xml:space="preserve">
          <source>N = \text{batch size}</source>
          <target state="translated">N=ﾃｷｽﾄ{ﾊﾞｯﾁｻｲｽﾞ}の場合</target>
        </trans-unit>
        <trans-unit id="9008c254267c7b8e353b34e82cc9a3ccdffad81e" translate="yes" xml:space="preserve">
          <source>N \times 2 \times 3</source>
          <target state="translated">N 尊い時間 2 尊い時間 3</target>
        </trans-unit>
        <trans-unit id="1b8b351ea25ef1c009076f028a05723a16aa0eb6" translate="yes" xml:space="preserve">
          <source>N \times 3 \times 4</source>
          <target state="translated">♪ N \times 3 ¶times 4</target>
        </trans-unit>
        <trans-unit id="004d23aba5b55baf9486f9aab3e50a94de7147b2" translate="yes" xml:space="preserve">
          <source>N \times C \times D \times H \times W</source>
          <target state="translated">N \times C ″\times D ″\times H ″\times W</target>
        </trans-unit>
        <trans-unit id="14734700ec8d366b9e0bb39033413068e35b488f" translate="yes" xml:space="preserve">
          <source>N \times C \times H \times W</source>
          <target state="translated">N \times C ¶times H \times W.</target>
        </trans-unit>
        <trans-unit id="db16fdaa05353f31c7f5c303d74f40ba9971f144" translate="yes" xml:space="preserve">
          <source>N \times H \times W \times 2</source>
          <target state="translated">N \times H \times W \times 2</target>
        </trans-unit>
        <trans-unit id="7fd20744aa54e5cfb63458f679b6501918e1991e" translate="yes" xml:space="preserve">
          <source>N \times M</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c79a64aa7f7a8e49dfba455783b75f9a68074b19" translate="yes" xml:space="preserve">
          <source>N is the batch size, &lt;code&gt;*&lt;/code&gt; means any number of additional dimensions</source>
          <target state="translated">Nはバッチサイズ、 &lt;code&gt;*&lt;/code&gt; は任意の数の追加ディメンションを意味します</target>
        </trans-unit>
        <trans-unit id="72e211ac7f7abd7ef74bebbff3bdb5e0da1f0db9" translate="yes" xml:space="preserve">
          <source>N-D</source>
          <target state="translated">N-D</target>
        </trans-unit>
        <trans-unit id="7610334d74930225de51e4e4fce7e6de6c627870" translate="yes" xml:space="preserve">
          <source>NCCL has also provided a number of environment variables for fine-tuning purposes.</source>
          <target state="translated">また、NCCLは微調整のために多くの環境変数を提供しています。</target>
        </trans-unit>
        <trans-unit id="165a578116c3590cf83add849da91470c0378dc0" translate="yes" xml:space="preserve">
          <source>NLLLoss</source>
          <target state="translated">NLLLoss</target>
        </trans-unit>
        <trans-unit id="c63922691a03fc61bc5d30e1155494b0495ebce4" translate="yes" xml:space="preserve">
          <source>NN module forward passes have code that don&amp;rsquo;t support named tensors and will error out appropriately.</source>
          <target state="translated">NNモジュールのフォワードパスには、名前付きテンソルをサポートしないコードがあり、適切にエラーが発生します。</target>
        </trans-unit>
        <trans-unit id="fb2adaff54f80ebafd8d75fb8e20d7e6464bee58" translate="yes" xml:space="preserve">
          <source>NN module parameters are unnamed, so outputs may be partially named.</source>
          <target state="translated">NN モジュールのパラメータは名前が付けられていないため、出力は部分的に名前が付けられている場合があります。</target>
        </trans-unit>
        <trans-unit id="fb77d2b5cb211a1bafb61c44a7f17e0c98a57348" translate="yes" xml:space="preserve">
          <source>NN modules are currently unsupported. This can lead to the following when calling modules with named tensor inputs:</source>
          <target state="translated">NN モジュールは現在サポートされていません。これにより、名前付きテンソル入力を持つモジュールを呼び出すと、以下のようになる可能性があります。</target>
        </trans-unit>
        <trans-unit id="0579bfd58f6bcb591b037d0d86676f26b53c86e8" translate="yes" xml:space="preserve">
          <source>NVIDIA Tools Extension (NVTX)</source>
          <target state="translated">NVIDIA Tools Extension (NVTX)</target>
        </trans-unit>
        <trans-unit id="855336587fa59262965cdb9a2a6114933586800b" translate="yes" xml:space="preserve">
          <source>N_i</source>
          <target state="translated">N_i</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
