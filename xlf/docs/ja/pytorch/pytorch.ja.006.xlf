<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file source-language="en" target-language="ja" datatype="htmlbody" original="pytorch">
    <body>
      <group id="pytorch">
        <trans-unit id="0d60fa4ee1b04194485d841887bd2a9720912ce7" translate="yes" xml:space="preserve">
          <source>For one, if either</source>
          <target state="translated">一つには、もしどちらかが</target>
        </trans-unit>
        <trans-unit id="388c4450cdbff00300f1e66a7fe9bdbd7ad63df6" translate="yes" xml:space="preserve">
          <source>For person keypoint detection, the accuracies for the pre-trained models are as follows</source>
          <target state="translated">人物キーポイント検出の場合、事前学習したモデルの精度は以下のようになります。</target>
        </trans-unit>
        <trans-unit id="50930fbd40ff369c0fa47ef8013fdffeda924fcf" translate="yes" xml:space="preserve">
          <source>For person keypoint detection, the pre-trained model return the keypoints in the following order:</source>
          <target state="translated">人物キーポイント検出では、事前学習されたモデルが以下の順序でキーポイントを返す。</target>
        </trans-unit>
        <trans-unit id="1547488bbec68c16b5473f238ae370eab49bdca4" translate="yes" xml:space="preserve">
          <source>For references on how to use it, please refer to &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/imagenet&quot;&gt;PyTorch example - ImageNet implementation&lt;/a&gt;</source>
          <target state="translated">使用方法については、&lt;a href=&quot;https://github.com/pytorch/examples/tree/master/imagenet&quot;&gt;PyTorchの例-ImageNetの実装&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="5b0de76315890608ccfec148ffc9eb96ab3d19d0" translate="yes" xml:space="preserve">
          <source>For summation index</source>
          <target state="translated">和算指数の場合</target>
        </trans-unit>
        <trans-unit id="ae21afa5351a91a1f97daa42d064cca4e245e30f" translate="yes" xml:space="preserve">
          <source>For test time, we report the time for the model evaluation and postprocessing (including mask pasting in image), but not the time for computing the precision-recall.</source>
          <target state="translated">テスト時間については、モデルの評価と後処理(画像へのマスク貼り付けを含む)にかかる時間を報告するが、精度-再現性の計算にかかる時間は報告しない。</target>
        </trans-unit>
        <trans-unit id="294fafc65e707c55d30f92f6e6fa7597c4416793" translate="yes" xml:space="preserve">
          <source>For the case of two input spatial dimensions this operation is sometimes called &lt;code&gt;im2col&lt;/code&gt;.</source>
          <target state="translated">2つの入力空間次元の場合、この操作は &lt;code&gt;im2col&lt;/code&gt; と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="4294b91105e53a9501af3f666602dc49b4fae690" translate="yes" xml:space="preserve">
          <source>For the case of two output spatial dimensions this operation is sometimes called &lt;code&gt;col2im&lt;/code&gt;.</source>
          <target state="translated">2つの出力空間次元の場合、この操作は &lt;code&gt;col2im&lt;/code&gt; と呼ばれることもあります。</target>
        </trans-unit>
        <trans-unit id="63464d394b40abaadcd5cd07925b101f22c85d5d" translate="yes" xml:space="preserve">
          <source>For the following examples:</source>
          <target state="translated">以下の例については</target>
        </trans-unit>
        <trans-unit id="250e5319dc4351da49602e421d48ab9ddd21e40e" translate="yes" xml:space="preserve">
          <source>For the full list of NCCL environment variables, please refer to &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html&quot;&gt;NVIDIA NCCL&amp;rsquo;s official documentation&lt;/a&gt;</source>
          <target state="translated">NCCL環境変数の完全なリストについては、&lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html&quot;&gt;NVIDIANCCLの公式ドキュメント&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="fbb3381cc7af3b7907b168edfc7c7438b66cd477" translate="yes" xml:space="preserve">
          <source>For the most part, you shouldn&amp;rsquo;t have to care whether or not a sparse tensor is coalesced or not, as most operations will work identically given a coalesced or uncoalesced sparse tensor. However, there are two cases in which you may need to care.</source>
          <target state="translated">ほとんどの場合、スパーステンソルが合体したかどうかを気にする必要はありません。合体した、または合体していないスパーステンソルが与えられた場合、ほとんどの操作は同じように機能するからです。ただし、注意が必要な場合が2つあります。</target>
        </trans-unit>
        <trans-unit id="b5ee688f7705f701edf82664a012c925ae4f0c34" translate="yes" xml:space="preserve">
          <source>For the unpacked case, the directions can be separated using &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt;, with forward and backward being direction &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; respectively. Similarly, the directions can be separated in the packed case.</source>
          <target state="translated">解凍された場合、方向は &lt;code&gt;output.view(seq_len, batch, num_directions, hidden_size)&lt;/code&gt; を使用して分離でき、順方向と逆方向はそれぞれ方向 &lt;code&gt;0&lt;/code&gt; と &lt;code&gt;1&lt;/code&gt; です。同様に、パックされたケースでは方向を分けることができます。</target>
        </trans-unit>
        <trans-unit id="0b3352e82009813f0901947623d7383dc915b831" translate="yes" xml:space="preserve">
          <source>For unsorted sequences, use &lt;code&gt;enforce_sorted = False&lt;/code&gt;. If &lt;code&gt;enforce_sorted&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the sequences should be sorted by length in a decreasing order, i.e. &lt;code&gt;input[:,0]&lt;/code&gt; should be the longest sequence, and &lt;code&gt;input[:,B-1]&lt;/code&gt; the shortest one. &lt;code&gt;enforce_sorted = True&lt;/code&gt; is only necessary for ONNX export.</source>
          <target state="translated">ソートされていないシーケンスの場合は、 &lt;code&gt;enforce_sorted = False&lt;/code&gt; 使用します。場合 &lt;code&gt;enforce_sorted&lt;/code&gt; がある &lt;code&gt;True&lt;/code&gt; 、配列は、降順の長さによって、すなわちソートされるべき &lt;code&gt;input[:,0]&lt;/code&gt; 、最長シーケンス、およびなければならない &lt;code&gt;input[:,B-1]&lt;/code&gt; 最短1。 &lt;code&gt;enforce_sorted = True&lt;/code&gt; は、ONNXエクスポートにのみ必要です。</target>
        </trans-unit>
        <trans-unit id="74aa708d44a325bbc3a2350d27d2ddf6e3e6b36a" translate="yes" xml:space="preserve">
          <source>For unsorted sequences, use &lt;code&gt;enforce_sorted = False&lt;/code&gt;. If &lt;code&gt;enforce_sorted&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the sequences should be sorted in the order of decreasing length. &lt;code&gt;enforce_sorted = True&lt;/code&gt; is only necessary for ONNX export.</source>
          <target state="translated">ソートされていないシーケンスの場合は、 &lt;code&gt;enforce_sorted = False&lt;/code&gt; 使用します。場合 &lt;code&gt;enforce_sorted&lt;/code&gt; がある &lt;code&gt;True&lt;/code&gt; 、配列は、長さの降順にソートされなければなりません。 &lt;code&gt;enforce_sorted = True&lt;/code&gt; は、ONNXエクスポートにのみ必要です。</target>
        </trans-unit>
        <trans-unit id="65edc3b96f1e2f54f14a87eb92d4dea02b1b6e9b" translate="yes" xml:space="preserve">
          <source>Forces completion of a &lt;code&gt;torch.jit.Future[T]&lt;/code&gt; asynchronous task, returning the result of the task.</source>
          <target state="translated">&lt;code&gt;torch.jit.Future[T]&lt;/code&gt; 非同期タスクの完了を強制し、タスクの結果を返します。</target>
        </trans-unit>
        <trans-unit id="dc619e95fe61cfbb5a61b8e23e153aa71a53f467" translate="yes" xml:space="preserve">
          <source>Forces completion of a &lt;code&gt;torch.jit.Future[T]&lt;/code&gt; asynchronous task, returning the result of the task. See &lt;a href=&quot;torch.jit.fork#torch.jit.fork&quot;&gt;&lt;code&gt;fork()&lt;/code&gt;&lt;/a&gt; for docs and examples. :param func: an asynchronous task reference, created through &lt;code&gt;torch.jit.fork&lt;/code&gt; :type func: torch.jit.Future[T]</source>
          <target state="translated">&lt;code&gt;torch.jit.Future[T]&lt;/code&gt; 非同期タスクの完了を強制し、タスクの結果を返します。ドキュメントと例については、&lt;a href=&quot;torch.jit.fork#torch.jit.fork&quot;&gt; &lt;code&gt;fork()&lt;/code&gt; &lt;/a&gt;を参照してください。 ：param func： &lt;code&gt;torch.jit.fork&lt;/code&gt; を介して作成された非同期タスク参照：type func：torch.jit.Future [T]</target>
        </trans-unit>
        <trans-unit id="e0b8013b454609aa16cd91b06faebccde13182b1" translate="yes" xml:space="preserve">
          <source>Forward and backward hooks defined on &lt;code&gt;module&lt;/code&gt; and its submodules will be invoked &lt;code&gt;len(device_ids)&lt;/code&gt; times, each with inputs located on a particular device. Particularly, the hooks are only guaranteed to be executed in correct order with respect to operations on corresponding devices. For example, it is not guaranteed that hooks set via &lt;a href=&quot;torch.nn.module#torch.nn.Module.register_forward_pre_hook&quot;&gt;&lt;code&gt;register_forward_pre_hook()&lt;/code&gt;&lt;/a&gt; be executed before &lt;code&gt;all&lt;/code&gt;&lt;code&gt;len(device_ids)&lt;/code&gt;&lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; calls, but that each such hook be executed before the corresponding &lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt;&lt;code&gt;forward()&lt;/code&gt;&lt;/a&gt; call of that device.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; とそのサブモジュールで定義されたフォワードフックとバックワードフックは &lt;code&gt;len(device_ids)&lt;/code&gt; 回呼び出され、それぞれが特定のデバイスに入力を配置します。特に、フックは、対応するデバイスでの操作に関して正しい順序でのみ実行されることが保証されています。たとえば、&lt;a href=&quot;torch.nn.module#torch.nn.Module.register_forward_pre_hook&quot;&gt; &lt;code&gt;register_forward_pre_hook()&lt;/code&gt; &lt;/a&gt;を介して設定されたフックが、 &lt;code&gt;all&lt;/code&gt; &lt;code&gt;len(device_ids)&lt;/code&gt; &lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;呼び出しの前に実行されることは保証されませんが、そのような各フックは、そのデバイスの対応する&lt;a href=&quot;torch.nn.module#torch.nn.Module.forward&quot;&gt; &lt;code&gt;forward()&lt;/code&gt; &lt;/a&gt;呼び出しの前に実行されます。</target>
        </trans-unit>
        <trans-unit id="6acf90721bbeda5f77e7073663e225cf7715008a" translate="yes" xml:space="preserve">
          <source>Forward and backward hooks defined on &lt;code&gt;module&lt;/code&gt; and its submodules won&amp;rsquo;t be invoked anymore, unless the hooks are initialized in the &lt;code&gt;forward()&lt;/code&gt; method.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; とそのサブモジュールで定義されたフォワードフックとバックワードフックは、フックが &lt;code&gt;forward()&lt;/code&gt; メソッドで初期化されない限り、呼び出されなくなります。</target>
        </trans-unit>
        <trans-unit id="988135b5646708fe12c52e4f90092901a6ed112d" translate="yes" xml:space="preserve">
          <source>Fractional MaxPooling is described in detail in the paper &lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;Fractional MaxPooling&lt;/a&gt; by Ben Graham</source>
          <target state="translated">Fractional MaxPoolingについては、&lt;a href=&quot;https://arxiv.org/abs/1412.6071&quot;&gt;BenGraham&lt;/a&gt;による論文FractionalMaxPoolingで詳しく説明されています。</target>
        </trans-unit>
        <trans-unit id="2297da08c1909f5dca5e7ab8bf486b563fbe806e" translate="yes" xml:space="preserve">
          <source>FractionalMaxPool2d</source>
          <target state="translated">FractionalMaxPool2d</target>
        </trans-unit>
        <trans-unit id="d790b402d79ac1a723c790313bcd679999474630" translate="yes" xml:space="preserve">
          <source>Frequently Asked Questions</source>
          <target state="translated">よくある質問</target>
        </trans-unit>
        <trans-unit id="8c7beab7a6d84d3a1004bcc75ccd72648a4866a0" translate="yes" xml:space="preserve">
          <source>Frobenius norm</source>
          <target state="translated">フロベニウスノルム</target>
        </trans-unit>
        <trans-unit id="e553dabf708d383e58b9442ad6ace6c5038afc7a" translate="yes" xml:space="preserve">
          <source>From the &lt;code&gt;torch.nn.utils&lt;/code&gt; module</source>
          <target state="translated">&lt;code&gt;torch.nn.utils&lt;/code&gt; モジュールから</target>
        </trans-unit>
        <trans-unit id="f92451195f62b1d7cd9731015aa1fa56d4159f9d" translate="yes" xml:space="preserve">
          <source>Fully Convolutional Networks</source>
          <target state="translated">完全畳み込みネットワーク</target>
        </trans-unit>
        <trans-unit id="d8cdf10face49f05a0d7bce562c1cbcff9eeec04" translate="yes" xml:space="preserve">
          <source>Function Calls</source>
          <target state="translated">関数呼び出し</target>
        </trans-unit>
        <trans-unit id="6eb78f68900c241e14e0ca55cb63779b55624f2b" translate="yes" xml:space="preserve">
          <source>Function that measures Binary Cross Entropy between target and output logits.</source>
          <target state="translated">目標ロジットと出力ロジット間のバイナリクロスエントロピーを測定する関数です。</target>
        </trans-unit>
        <trans-unit id="7648ef7c5f8c3df8793ee3a78cea755f5210492d" translate="yes" xml:space="preserve">
          <source>Function that measures the Binary Cross Entropy between the target and the output.</source>
          <target state="translated">ターゲットと出力間のバイナリクロスエントロピーを測定する関数です。</target>
        </trans-unit>
        <trans-unit id="9ffd252ff27f5e82a15818c0d16b964ae35b7608" translate="yes" xml:space="preserve">
          <source>Function that returns True when in compilation and False otherwise. This is useful especially with the @unused decorator to leave code in your model that is not yet TorchScript compatible. .. testcode:</source>
          <target state="translated">コンパイル時にTrueを返し、そうでなければFalseを返す関数です。これは特に @unused デコレータを使って、TorchScript と互換性のないコードをモデルに残しておくのに便利です。...testcode。</target>
        </trans-unit>
        <trans-unit id="4f7128796586951f3b8d4c12bad19a0f376bcf68" translate="yes" xml:space="preserve">
          <source>Function that takes the mean element-wise absolute value difference.</source>
          <target state="translated">要素間の平均値絶対値差を取る関数。</target>
        </trans-unit>
        <trans-unit id="092441d339641c913a709b12bd8927bee99f6a19" translate="yes" xml:space="preserve">
          <source>Function that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.</source>
          <target state="translated">要素間誤差の絶対値がベータ値を下回った場合に二乗項を使用し、それ以外の場合にはL1項を使用する関数です。</target>
        </trans-unit>
        <trans-unit id="e285c73ee5b2c775ccf90093dc413f8d49580952" translate="yes" xml:space="preserve">
          <source>Function to draw a sequence of &lt;code&gt;n&lt;/code&gt; points from a Sobol sequence. Note that the samples are dependent on the previous samples. The size of the result is</source>
          <target state="translated">ソボル列から &lt;code&gt;n&lt;/code&gt; 点の列を描く関数。サンプルは前のサンプルに依存していることに注意してください。結果のサイズは</target>
        </trans-unit>
        <trans-unit id="54711e443d02794b60e7868b9b77738a8238e18e" translate="yes" xml:space="preserve">
          <source>Function to fast-forward the state of the &lt;code&gt;SobolEngine&lt;/code&gt; by &lt;code&gt;n&lt;/code&gt; steps. This is equivalent to drawing &lt;code&gt;n&lt;/code&gt; samples without using the samples.</source>
          <target state="translated">早送りする機能の状態 &lt;code&gt;SobolEngine&lt;/code&gt; により、 &lt;code&gt;n&lt;/code&gt; 個のステップ。これは、サンプルを使用せずに &lt;code&gt;n&lt;/code&gt; 個のサンプルを描画することと同じです。</target>
        </trans-unit>
        <trans-unit id="ef0c07b5cc0a1093381723476ea2c34106682639" translate="yes" xml:space="preserve">
          <source>Function to reset the &lt;code&gt;SobolEngine&lt;/code&gt; to base state.</source>
          <target state="translated">&lt;code&gt;SobolEngine&lt;/code&gt; を基本状態にリセットする機能。</target>
        </trans-unit>
        <trans-unit id="f4400d33370b62a4424c92ac993690b6bf723355" translate="yes" xml:space="preserve">
          <source>Functional interface</source>
          <target state="translated">機能的なインターフェイス</target>
        </trans-unit>
        <trans-unit id="c75f6c5a3a8ea37a3aa2ef8f8e4a53197661b6a7" translate="yes" xml:space="preserve">
          <source>Functional interface (quantized).</source>
          <target state="translated">機能的なインターフェース(量子化)。</target>
        </trans-unit>
        <trans-unit id="c6f96173e459065a4f35775c868cf69352b58eaa" translate="yes" xml:space="preserve">
          <source>Functionally equivalent to a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, but represents a single function and does not have any attributes or Parameters.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;と機能的に同等ですが、単一の関数を表し、属性やパラメーターはありません。</target>
        </trans-unit>
        <trans-unit id="1f72e9d093d3406e36decddb7c64c8207dc32272" translate="yes" xml:space="preserve">
          <source>Functionally equivalent to a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, but represents a single function and does not have any attributes or Parameters.</source>
          <target state="translated">&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;と機能的に同等ですが、単一の関数を表し、属性やパラメーターはありません。</target>
        </trans-unit>
        <trans-unit id="2b961dea1dc0c60ddf9a2c8e9d090f6f7d082483" translate="yes" xml:space="preserve">
          <source>Functions</source>
          <target state="translated">Functions</target>
        </trans-unit>
        <trans-unit id="5bab26ebb87fa09b2599a41edb42c2be419cbfdb" translate="yes" xml:space="preserve">
          <source>Functions don&amp;rsquo;t change much, they can be decorated with &lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt;&lt;code&gt;@torch.jit.ignore&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt;&lt;code&gt;torch.jit.unused&lt;/code&gt;&lt;/a&gt; if needed.</source>
          <target state="translated">関数はあまり変更されません。必要に応じて、&lt;a href=&quot;generated/torch.jit.ignore#torch.jit.ignore&quot;&gt; &lt;code&gt;@torch.jit.ignore&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/torch.jit.unused#torch.jit.unused&quot;&gt; &lt;code&gt;torch.jit.unused&lt;/code&gt; で&lt;/a&gt;装飾できます。</target>
        </trans-unit>
        <trans-unit id="f08615c088136953c00202fd041b9b4df5e1dfea" translate="yes" xml:space="preserve">
          <source>Furthermore, if the &lt;code&gt;functions&lt;/code&gt; argument is supplied, bindings will be automatically generated for each function specified. &lt;code&gt;functions&lt;/code&gt; can either be a list of function names, or a dictionary mapping from function names to docstrings. If a list is given, the name of each function is used as its docstring.</source>
          <target state="translated">さらに、 &lt;code&gt;functions&lt;/code&gt; 引数が指定されている場合、指定された関数ごとにバインディングが自動的に生成されます。 &lt;code&gt;functions&lt;/code&gt; は、関数名のリスト、または関数名からdocstringへの辞書マッピングのいずれかです。リストが指定されている場合、各関数の名前がそのdocstringとして使用されます。</target>
        </trans-unit>
        <trans-unit id="5bace8a23b9deebac72cffe4881dc6eed9968755" translate="yes" xml:space="preserve">
          <source>Furthermore, the outputs are scaled by a factor of</source>
          <target state="translated">さらに、出力は</target>
        </trans-unit>
        <trans-unit id="5f71e96ba4fcb977ab1e675f428bf9d148fa7baf" translate="yes" xml:space="preserve">
          <source>GELU</source>
          <target state="translated">GELU</target>
        </trans-unit>
        <trans-unit id="1f9ad9bc561d09f2f445363cf93033cdd6037e9c" translate="yes" xml:space="preserve">
          <source>GLU</source>
          <target state="translated">GLU</target>
        </trans-unit>
        <trans-unit id="a6a6318544c9b361fc08c6ed94696c4d207d2748" translate="yes" xml:space="preserve">
          <source>GPU</source>
          <target state="translated">GPU</target>
        </trans-unit>
        <trans-unit id="954c88d52c93dd19e22542fcb20c7d583f7b8447" translate="yes" xml:space="preserve">
          <source>GPU hosts with Ethernet interconnect</source>
          <target state="translated">イーサネット相互接続のGPUホスト</target>
        </trans-unit>
        <trans-unit id="9238bee4212524d967f1550988f8d590152434a1" translate="yes" xml:space="preserve">
          <source>GPU hosts with InfiniBand interconnect</source>
          <target state="translated">InfiniBandインターコネクトを搭載したGPUホスト</target>
        </trans-unit>
        <trans-unit id="2b56fffb35167d283f21ccca2d0bc8fbd0a6fe43" translate="yes" xml:space="preserve">
          <source>GPU tensor</source>
          <target state="translated">GPUテンソル</target>
        </trans-unit>
        <trans-unit id="51c6274e38d61ebd2c2aa1fabf4fb11564b93c03" translate="yes" xml:space="preserve">
          <source>GRU</source>
          <target state="translated">GRU</target>
        </trans-unit>
        <trans-unit id="1e29d48c3333cba171b9e878119cbab38e34e4a1" translate="yes" xml:space="preserve">
          <source>GRUCell</source>
          <target state="translated">GRUCell</target>
        </trans-unit>
        <trans-unit id="473631bf9e98f3b45650e597635bf741c36747b6" translate="yes" xml:space="preserve">
          <source>Gathers a list of tensors in a single process.</source>
          <target state="translated">1回の処理でテンソルのリストを収集します。</target>
        </trans-unit>
        <trans-unit id="dfd7c23593ebd41b22c549217d736ad6cbc14502" translate="yes" xml:space="preserve">
          <source>Gathers tensors from the whole group in a list.</source>
          <target state="translated">グループ全体からテンソルをリストに集めます。</target>
        </trans-unit>
        <trans-unit id="a033b46254c69591de655bd57283ab1b1f241ecf" translate="yes" xml:space="preserve">
          <source>Gathers tensors from the whole group in a list. Each tensor in &lt;code&gt;tensor_list&lt;/code&gt; should reside on a separate GPU</source>
          <target state="translated">グループ全体からテンソルをリストに収集します。 &lt;code&gt;tensor_list&lt;/code&gt; の各テンソルは別々のGPUに存在する必要があります</target>
        </trans-unit>
        <trans-unit id="d1ed345e7cd127b4f17c3621e8381fb806d9f267" translate="yes" xml:space="preserve">
          <source>Gathers values along an axis specified by &lt;code&gt;dim&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;dim&lt;/code&gt; で指定された軸に沿って値を収集します。</target>
        </trans-unit>
        <trans-unit id="83e2e53da9f325087f4bce1c008f1d1192e058ed" translate="yes" xml:space="preserve">
          <source>Generally speaking, input to this function should contain values following conjugate symmetry. Note that even if &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, often symmetry on some part is still needed. When this requirement is not satisfied, the behavior of &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; is undefined. Since &lt;a href=&quot;../autograd#torch.autograd.gradcheck&quot;&gt;&lt;code&gt;torch.autograd.gradcheck()&lt;/code&gt;&lt;/a&gt; estimates numerical Jacobian with point perturbations, &lt;a href=&quot;#torch.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt; will almost certainly fail the check.</source>
          <target state="translated">一般的に、この関数への入力には、共役対称に従う値が含まれている必要があります。 &lt;code&gt;onesided&lt;/code&gt; が &lt;code&gt;True&lt;/code&gt; であっても、一部の対称性が必要になる場合が多いことに注意してください。この要件が満たされない場合、&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; の&lt;/a&gt;動作は未定義です。&lt;a href=&quot;../autograd#torch.autograd.gradcheck&quot;&gt; &lt;code&gt;torch.autograd.gradcheck()&lt;/code&gt; &lt;/a&gt;は点摂動を&lt;a href=&quot;#torch.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;数値ヤコビアンを推定するため、irfft（）はほぼ確実にチェックに失敗します。</target>
        </trans-unit>
        <trans-unit id="925a95fee15d092ef688c243751df4f4117845d7" translate="yes" xml:space="preserve">
          <source>Generate a square mask for the sequence. The masked positions are filled with float(&amp;lsquo;-inf&amp;rsquo;). Unmasked positions are filled with float(0.0).</source>
          <target state="translated">シーケンスの正方形のマスクを生成します。マスクされた位置はfloat（ '-inf'）で埋められます。マスクされていない位置はfloat（0.0）で埋められます。</target>
        </trans-unit>
        <trans-unit id="05e4b9ca24a152cc1be23c09ff6368077d47b2b3" translate="yes" xml:space="preserve">
          <source>Generates a 2D or 3D flow field (sampling grid), given a batch of affine matrices &lt;code&gt;theta&lt;/code&gt;.</source>
          <target state="translated">アフィン行列 &lt;code&gt;theta&lt;/code&gt; バッチが与えられると、2Dまたは3Dフローフィールド（サンプリンググリッド）を生成します。</target>
        </trans-unit>
        <trans-unit id="535a8bdc4a8b5e249e51bb72f3ff867e269f10d8" translate="yes" xml:space="preserve">
          <source>Generates a Vandermonde matrix.</source>
          <target state="translated">Vandermonde行列を生成します。</target>
        </trans-unit>
        <trans-unit id="1d20de03126b297e05c13a7d280f33e24c72c537" translate="yes" xml:space="preserve">
          <source>Generator</source>
          <target state="translated">Generator</target>
        </trans-unit>
        <trans-unit id="009c08ccefb98d44d31c65421a4320ecc2bb6f65" translate="yes" xml:space="preserve">
          <source>Generator.device -&amp;gt; device</source>
          <target state="translated">Generator.device-&amp;gt;デバイス</target>
        </trans-unit>
        <trans-unit id="a3e705cc61a19f33d7c9c030f107a70569966485" translate="yes" xml:space="preserve">
          <source>Generators</source>
          <target state="translated">Generators</target>
        </trans-unit>
        <trans-unit id="80dadd86173d0ff3979257793d4e45beb238b6a2" translate="yes" xml:space="preserve">
          <source>Generics</source>
          <target state="translated">Generics</target>
        </trans-unit>
        <trans-unit id="43ac4a1c9cd4df862c76bc8567278e105813907d" translate="yes" xml:space="preserve">
          <source>Get &lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; of a given worker name. Use this &lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt;&lt;code&gt;WorkerInfo&lt;/code&gt;&lt;/a&gt; to avoid passing an expensive string on every invocation.</source>
          <target state="translated">指定されたワーカー名の&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt; &lt;code&gt;WorkerInfo&lt;/code&gt; &lt;/a&gt;を取得します。この&lt;a href=&quot;#torch.distributed.rpc.WorkerInfo&quot;&gt; &lt;code&gt;WorkerInfo&lt;/code&gt; &lt;/a&gt;を使用して、すべての呼び出しで高価な文字列を渡さないようにします。</target>
        </trans-unit>
        <trans-unit id="41265238a92192e4ad5f6debaeb489d9d1f1c823" translate="yes" xml:space="preserve">
          <source>Get the Torch Hub cache directory used for storing downloaded models &amp;amp; weights.</source>
          <target state="translated">ダウンロードしたモデルと重みを保存するために使用されるトーチハブキャッシュディレクトリを取得します。</target>
        </trans-unit>
        <trans-unit id="31e03005a5c777fa579a5d2e380424ed9ca0b4c8" translate="yes" xml:space="preserve">
          <source>Get the current default floating point &lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">現在のデフォルトの浮動小数点&lt;a href=&quot;../tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; を&lt;/a&gt;取得します。</target>
        </trans-unit>
        <trans-unit id="b8610c06d92827723a75fd0f1cce98077b3a70ce" translate="yes" xml:space="preserve">
          <source>Get the current default floating point &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">現在のデフォルトの浮動小数点&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; を&lt;/a&gt;取得します。</target>
        </trans-unit>
        <trans-unit id="5aca0eb2fa5dfc1cb36d36748698ea752a002636" translate="yes" xml:space="preserve">
          <source>Get the include paths required to build a C++ or CUDA extension.</source>
          <target state="translated">C++または CUDA 拡張モジュールの構築に必要なインクルードパスを取得します。</target>
        </trans-unit>
        <trans-unit id="8c5303d4517efbd9f11eb88c60066d56bc4690f4" translate="yes" xml:space="preserve">
          <source>Get the k-th diagonal of a given matrix:</source>
          <target state="translated">与えられた行列の k 番目の対角線を求めます.</target>
        </trans-unit>
        <trans-unit id="d8e48ff0538ba6cbffe42300fa9158799c05f336" translate="yes" xml:space="preserve">
          <source>Get the square matrix where the input vector is the diagonal:</source>
          <target state="translated">入力ベクトルを対角線とする正方行列を取得します。</target>
        </trans-unit>
        <trans-unit id="c3d9b9988129bd858a97b5e5dca9086f55e31cf1" translate="yes" xml:space="preserve">
          <source>Gets a non-deterministic random number from std::random_device or the current time and uses it to seed a Generator.</source>
          <target state="translated">std::random_device または現在の時刻から非決定論的な乱数を取得し、ジェネレータのシードに使用します。</target>
        </trans-unit>
        <trans-unit id="8c370c58908a07f2882a626fa97d9bcfd7bd61c5" translate="yes" xml:space="preserve">
          <source>Gets the current device of the generator.</source>
          <target state="translated">発電機の電流デバイスを取得します。</target>
        </trans-unit>
        <trans-unit id="6a2e241a18985fac466002399c13c581b746dc24" translate="yes" xml:space="preserve">
          <source>Getting started with Distributed RPC Framework</source>
          <target state="translated">分散RPCフレームワークを使い始める</target>
        </trans-unit>
        <trans-unit id="c7e10d3aed3a471005914064e3e561dd9fce7d89" translate="yes" xml:space="preserve">
          <source>Given a 3-D tensor and reduction using the multiplication operation, &lt;code&gt;self&lt;/code&gt; is updated as:</source>
          <target state="translated">3次元テンソルと乗算演算を使用した縮小が与えられると、 &lt;code&gt;self&lt;/code&gt; は次のように更新されます。</target>
        </trans-unit>
        <trans-unit id="cd7589a87267ad50da5e4440a08034e70102a4b2" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer. It has the number of elements that matches the corresponding dimensions (from q_per_channel_axis) of the tensor.</source>
          <target state="translated">線形(アフィン)パーチャンネル量子化によって量子化されたテンソルが与えられた場合,基礎となる量子化器のスケールのテンソルを返します.テンソルの対応する次元(q_per_channel_axisから)に一致する要素数を持ちます。</target>
        </trans-unit>
        <trans-unit id="9a7e24af56b75cfda37479a07ba5602027c1c762" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer. It has the number of elements that matches the corresponding dimensions (from q_per_channel_axis) of the tensor.</source>
          <target state="translated">線形(アフィン)パーチャンネル量子化によって量子化されたテンソルが与えられた場合,基礎となる量子化器のゼロ点のテンソルを返します.テンソルの対応する次元(q_per_channel_axisから)に一致する要素数を持ちます。</target>
        </trans-unit>
        <trans-unit id="2ca023eeaa09e79566843e7d6c6a44e41c5d8038" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied.</source>
          <target state="translated">線形(アフィン)パーチャネル量子化によって量子化されたテンソルが与えられた場合,パーチャネル量子化が適用される次元のインデックスを返します.</target>
        </trans-unit>
        <trans-unit id="488568401d49cd08f3be08869dd3fbd14d9e5113" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer().</source>
          <target state="translated">線形(アフィン)量子化によって量子化されたテンソルが与えられた場合、その下にある量子化器()のスケールを返します。</target>
        </trans-unit>
        <trans-unit id="70ceca1da9acd2d4b46a6674c2ea2f823b1ff770" translate="yes" xml:space="preserve">
          <source>Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer().</source>
          <target state="translated">線形(アフィン)量子化によって量子化されたテンソルが与えられた場合、その下にある量子化器()のゼロ点を返します。</target>
        </trans-unit>
        <trans-unit id="90c7e80a6051c57ef51f03a4a57294f2d936927c" translate="yes" xml:space="preserve">
          <source>Given a list of quantized Tensors, dequantize them and return a list of fp32 Tensors</source>
          <target state="translated">量子化されたテンソルのリストが与えられると,それらを量子化解除して,fp32テンソルのリストを返します.</target>
        </trans-unit>
        <trans-unit id="275d4783ccc8a12c168de20cf782230c04ee1b4f" translate="yes" xml:space="preserve">
          <source>Given a quantized Tensor, &lt;code&gt;self.int_repr()&lt;/code&gt; returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor.</source>
          <target state="translated">量子化されたテンソルが与えられると、 &lt;code&gt;self.int_repr()&lt;/code&gt; は、与えられたテンソルの基礎となるuint8_t値を格納するデータ型としてuint8_tを持つCPUテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="a07592b05f2ffe420d78857907dc0a868ad8e9ba" translate="yes" xml:space="preserve">
          <source>Given a quantized Tensor, dequantize it and return the dequantized float Tensor.</source>
          <target state="translated">量子化されたTensorが与えられると、それを量子化解除して、量子化解除されたfloatのTensorを返します。</target>
        </trans-unit>
        <trans-unit id="df67c816ade50221be71f968c55c25fc9c22abad" translate="yes" xml:space="preserve">
          <source>Given an &lt;code&gt;input&lt;/code&gt; and a flow-field &lt;code&gt;grid&lt;/code&gt;, computes the &lt;code&gt;output&lt;/code&gt; using &lt;code&gt;input&lt;/code&gt; values and pixel locations from &lt;code&gt;grid&lt;/code&gt;.</source>
          <target state="translated">与えられた &lt;code&gt;input&lt;/code&gt; フローフィールド &lt;code&gt;grid&lt;/code&gt; 、演算 &lt;code&gt;output&lt;/code&gt; 使用して &lt;code&gt;input&lt;/code&gt; 値とからピクセル位置 &lt;code&gt;grid&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1edda6e755754d8aedb4972c3cf98f079bb5938f" translate="yes" xml:space="preserve">
          <source>Given the legs of a right triangle, return its hypotenuse.</source>
          <target state="translated">直角三角形の脚が与えられたとき、その下辺を返します。</target>
        </trans-unit>
        <trans-unit id="2507bf0b60a0a2f4a957fa33007787504bb4d58f" translate="yes" xml:space="preserve">
          <source>Gives us the following diagnostic information:</source>
          <target state="translated">以下の診断情報を提供してくれます。</target>
        </trans-unit>
        <trans-unit id="d4b28b75d3d71965ffab4c160557a8512917b298" translate="yes" xml:space="preserve">
          <source>Globally prunes tensors corresponding to all parameters in &lt;code&gt;parameters&lt;/code&gt; by applying the specified &lt;code&gt;pruning_method&lt;/code&gt;.</source>
          <target state="translated">グローバルのすべてのパラメータに対応するテンソルプルーニング &lt;code&gt;parameters&lt;/code&gt; 指定された適用することにより、 &lt;code&gt;pruning_method&lt;/code&gt; を。</target>
        </trans-unit>
        <trans-unit id="5b2d596c770a42eb120b6d78a8d729e895cf8f96" translate="yes" xml:space="preserve">
          <source>Globally prunes tensors corresponding to all parameters in &lt;code&gt;parameters&lt;/code&gt; by applying the specified &lt;code&gt;pruning_method&lt;/code&gt;. Modifies modules in place by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">グローバルのすべてのパラメータに対応するテンソルプルーニング &lt;code&gt;parameters&lt;/code&gt; 指定された適用することにより、 &lt;code&gt;pruning_method&lt;/code&gt; を。次の方法でモジュールを変更します。1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加します。2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="1c964494fd83a4fa2353af497be43d7d3c6b7430" translate="yes" xml:space="preserve">
          <source>Globally unique id to identify the worker.</source>
          <target state="translated">ワーカーを識別するためのグローバルに一意な ID。</target>
        </trans-unit>
        <trans-unit id="2dd8834e4e85debb567290745d3b3e1efdcd0e5d" translate="yes" xml:space="preserve">
          <source>Gloo has been hardened by years of extensive use in PyTorch and is thus very reliable. However, as it was designed to perform collective communication, it may not always be the best fit for RPC. For example, each networking operation is synchronous and blocking, which means that it cannot be run in parallel with others. Moreover, it opens a connection between all pairs of nodes, and brings down all of them when one fails, thus reducing the resiliency and the elasticity of the system.</source>
          <target state="translated">GlooはPyTorchでの長年の使用によって強化されているため、非常に信頼性が高いです。しかし、集団通信を行うために設計されているため、必ずしもRPCに最適とは限りません。例えば、各ネットワーキング操作は同期的でブロッキングされているため、他の操作と並行して実行することができません。さらに、すべてのペアのノード間で接続を開き、1つが故障するとすべてのノードをダウンさせてしまうため、システムの回復力や弾力性が低下してしまいます。</target>
        </trans-unit>
        <trans-unit id="0493f8c5c9a4c1e6227e147f0649196be2a0314a" translate="yes" xml:space="preserve">
          <source>GoogLeNet</source>
          <target state="translated">GoogLeNet</target>
        </trans-unit>
        <trans-unit id="07ad0c4f37a421022704ed36cdcbf7e981dfe5e6" translate="yes" xml:space="preserve">
          <source>GoogLeNet (Inception v1) model architecture from &lt;a href=&quot;http://arxiv.org/abs/1409.4842&quot;&gt;&amp;ldquo;Going Deeper with Convolutions&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://arxiv.org/abs/1409.4842&quot;&gt;「畳み込みでより深くなる」の&lt;/a&gt;GoogLeNet（Inception v1）モデルアーキテクチャ。</target>
        </trans-unit>
        <trans-unit id="a46ca2c8e8067233adba7afe56ba3ef36ef0ac6c" translate="yes" xml:space="preserve">
          <source>GoogleNet</source>
          <target state="translated">GoogleNet</target>
        </trans-unit>
        <trans-unit id="6ff674c26d399b6074c452be450688d5b72da6db" translate="yes" xml:space="preserve">
          <source>Gradients are modified in-place.</source>
          <target state="translated">グラデーションはその場で修正されます。</target>
        </trans-unit>
        <trans-unit id="51f814ea6f476134875113c78aa4479584c4db98" translate="yes" xml:space="preserve">
          <source>Graphs can be inspected as shown to confirm that the computation described by a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; is correct, in both automated and manual fashion, as described below.</source>
          <target state="translated">グラフは、以下に説明するように、自動および手動の両方の方法で、&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;によって記述された計算が正しいことを確認するために示されているように検査できます。</target>
        </trans-unit>
        <trans-unit id="db56247cfffad115bd03a34895c4144a2f602e2a" translate="yes" xml:space="preserve">
          <source>GroupNorm</source>
          <target state="translated">GroupNorm</target>
        </trans-unit>
        <trans-unit id="ae9629f4ebb82c6331c0809fa9a0e54b00e578e6" translate="yes" xml:space="preserve">
          <source>Groups</source>
          <target state="translated">Groups</target>
        </trans-unit>
        <trans-unit id="7cf184f4c67ad58283ecb19349720b0cae756829" translate="yes" xml:space="preserve">
          <source>H</source>
          <target state="translated">H</target>
        </trans-unit>
        <trans-unit id="e19beadee3375715c817358699b6b6b7c3b1c276" translate="yes" xml:space="preserve">
          <source>H=\text{embedding\_dim}</source>
          <target state="translated">H=\text{embedding\_dim}</target>
        </trans-unit>
        <trans-unit id="0daac27dde551de614ce1f8b22990869e521a767" translate="yes" xml:space="preserve">
          <source>H_{all}=\text{num\_directions} * \text{hidden\_size}</source>
          <target state="translated">H_{all}=Text{num_directions}*\text{hidden_size}.</target>
        </trans-unit>
        <trans-unit id="5af2c1c42a9e7cbeea8d0ef376277c241943a820" translate="yes" xml:space="preserve">
          <source>H_{in1}=\text{in1\_features}</source>
          <target state="translated">H_{in1}=\text{in1\_features}</target>
        </trans-unit>
        <trans-unit id="553b3def323fb898bbf5a634729bc342796f0364" translate="yes" xml:space="preserve">
          <source>H_{in2}=\text{in2\_features}</source>
          <target state="translated">H_{in2}=\text{in2\_features}</target>
        </trans-unit>
        <trans-unit id="3bcb97c0c827228e3e76ce7ff65ced7d17f29099" translate="yes" xml:space="preserve">
          <source>H_{in}</source>
          <target state="translated">H_{in}</target>
        </trans-unit>
        <trans-unit id="208ac84ce5aa93dcc05f3ab66b20dc1d3775c246" translate="yes" xml:space="preserve">
          <source>H_{in} = \text{in\_features}</source>
          <target state="translated">H_{in}=ﾃｷｽﾄ{in_features}</target>
        </trans-unit>
        <trans-unit id="699846905d49c5bcf7b21460adb78513ef80b2fb" translate="yes" xml:space="preserve">
          <source>H_{in}=\text{input\_size}</source>
          <target state="translated">H_{in}=\text{input\_size}</target>
        </trans-unit>
        <trans-unit id="7530e9ad4c2fb5dd91aaec26c4ecbcf1a3a5ae05" translate="yes" xml:space="preserve">
          <source>H_{out}</source>
          <target state="translated">H_{out}</target>
        </trans-unit>
        <trans-unit id="29b7895de890ff23af55e3b18083accf3b3c9504" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}</source>
          <target state="translated">H_{out}=(H_{in}-1)♪ ♪times \times</target>
        </trans-unit>
        <trans-unit id="2ab9363dd5f0a667cae76fffcb24249e4641e2c1" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}</source>
          <target state="translated">H_{out}=(H_{in}-1)♪ ♪times \times</target>
        </trans-unit>
        <trans-unit id="eb1e8745c8404aa0257819793650f55ce47e4a32" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1</source>
          <target state="translated">H_{out}=(H_{in}-1)♪times \times ﾃｷｽﾄ{stride}[0]-2 \times ﾃｷｽﾄ{padding}[0]+\times (text{kernel_size}[0]-1)+\times (text{output\_padding}[0]+1)</target>
        </trans-unit>
        <trans-unit id="18b0ad397dc5e56655f52d98246617aead364a80" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{kernel\_size}[0]</source>
          <target state="translated">H_{out}=(H_{in}-1)♪times \times ﾃｷｽﾄ{stride}[0]-2 \times ﾃｷｽﾄ{padding}[0]+\times ﾃｷｽﾄ{kernel_size}[0]</target>
        </trans-unit>
        <trans-unit id="79c01a18bf062cd324b81ee63feda955b8a67b5e" translate="yes" xml:space="preserve">
          <source>H_{out} = (H_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="092f027e0b0b6c6ccdb35d8eefd3fbd19f119f52" translate="yes" xml:space="preserve">
          <source>H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}</source>
          <target state="translated">H_{out}=H_{in}+\text{padding_top}+\text{padding_bottom}.</target>
        </trans-unit>
        <trans-unit id="42cf8f4ab52d42aa9e4d4c9b75634fb9ef976615" translate="yes" xml:space="preserve">
          <source>H_{out} = H_{in} \times \text{upscale\_factor}</source>
          <target state="translated">H_{out}=H_{in}\times text{upscale_factor}.</target>
        </trans-unit>
        <trans-unit id="be48d8fe2e8d0b5e7eb05cfe3a720b22ad1fddb5" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor</source>
          <target state="translated">H_{out}=ﾚﾌﾄの\lfloor H_{in}ﾄｲﾒｰｼﾞ</target>
        </trans-unit>
        <trans-unit id="2df9cd2b82eb2979d700977c589d82b892fd325a" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]} \times (\text{kernel\_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+2*\times (Text{kernel_size[0]}-1)-1}{Text{stride[0]}}+1\rightrfloor</target>
        </trans-unit>
        <trans-unit id="475e8a255144af15d34931776b25e492a4505dc7" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+≪H_{in}≫+2 \times ≪Text{padding}[0]-≪Text{dilation}[0]≫ ≫ ≪Times (Text{kernel_size}[0]]-1)-1}{Text{stride}[0]}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="017fc26768fffbdc1fef6a9416fcdd78e1cd6d94" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[0] - \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+2 \times ≪Text{padding}[0]-≪Text{kernel_size}[0]}≪Text{stride}[0]}≫+1 Right\rfloor</target>
        </trans-unit>
        <trans-unit id="d6788aaadc5cc718ef1733396e3d48f7aa8bc1e1" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫+≪H_{in}≫+2 \times ≪Text{padding}[1]-≪Text{dilation}[1]≫ ➡ ➡ ≪Text{kernel_size}[1][1]-1)+1}{Text{stride}[1]}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="7eddc94bad71df818c92fb147993424e6e6351b5" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}+2 \times ≪Text{padding}[1]-≪Text{kernel_size}[1]}≪Text{stride}[1]}+1 Right\rfloor</target>
        </trans-unit>
        <trans-unit id="fea56e0b8cb35cbb479b336782329a86326003b9" translate="yes" xml:space="preserve">
          <source>H_{out} = \left\lfloor\frac{H_{in} - \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor</source>
          <target state="translated">H_{out}=≪H_{out}≫-≪H_{in}≫-≪H_{in}≫+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="563db076821ec71bea9cecf69cd0383ccd26729e" translate="yes" xml:space="preserve">
          <source>H_{out} = \text{out\_features}</source>
          <target state="translated">H_{out}=ﾃｷｽﾄ{out_features}</target>
        </trans-unit>
        <trans-unit id="4a917c5666fd0c869393621972c028e97e193eb0" translate="yes" xml:space="preserve">
          <source>H_{out}=\text{hidden\_size}</source>
          <target state="translated">H_{out}=\text{hidden\_size}</target>
        </trans-unit>
        <trans-unit id="baeaafcb89405e03dc701698426b69d67220a62d" translate="yes" xml:space="preserve">
          <source>H_{out}=\text{out\_features}</source>
          <target state="translated">H_{out}=\text{out\_features}</target>
        </trans-unit>
        <trans-unit id="593e90ae43cc7b6082dfac4b6d583f5426501c8b" translate="yes" xml:space="preserve">
          <source>Hamming window function.</source>
          <target state="translated">ハミングウィンドウ機能。</target>
        </trans-unit>
        <trans-unit id="69d7b15573065426b9ad5d17655afb90ef85c68f" translate="yes" xml:space="preserve">
          <source>Hann window function.</source>
          <target state="translated">ハン窓機能。</target>
        </trans-unit>
        <trans-unit id="9deb0b051207a937d2c2524ee2d17196f4c7e2ae" translate="yes" xml:space="preserve">
          <source>HardShrink</source>
          <target state="translated">HardShrink</target>
        </trans-unit>
        <trans-unit id="a1d971d31da1fbc25ba44171ebf839ffcca3d2d9" translate="yes" xml:space="preserve">
          <source>HardTanh</source>
          <target state="translated">HardTanh</target>
        </trans-unit>
        <trans-unit id="c9c68b0024efc57340d60b6a9fea397c5c6ea7cf" translate="yes" xml:space="preserve">
          <source>HardTanh is defined as:</source>
          <target state="translated">HardTanhとは、以下のように定義されています。</target>
        </trans-unit>
        <trans-unit id="b2d44614503eb1489dff12f9f7cd6893be6f2de6" translate="yes" xml:space="preserve">
          <source>Hardshrink</source>
          <target state="translated">Hardshrink</target>
        </trans-unit>
        <trans-unit id="6da2cabc8d832449dfd76781dd5cab3e0527d812" translate="yes" xml:space="preserve">
          <source>Hardsigmoid</source>
          <target state="translated">Hardsigmoid</target>
        </trans-unit>
        <trans-unit id="34e8d8510ac49404bdd474758f835c671f823a90" translate="yes" xml:space="preserve">
          <source>Hardswish</source>
          <target state="translated">Hardswish</target>
        </trans-unit>
        <trans-unit id="c5343dec88b0ad5e872efa7466247b124ae44911" translate="yes" xml:space="preserve">
          <source>Hardtanh</source>
          <target state="translated">Hardtanh</target>
        </trans-unit>
        <trans-unit id="e2828b0734fec8e5d21a67190b498444f3d1d6ac" translate="yes" xml:space="preserve">
          <source>Helper function to convert all &lt;code&gt;BatchNorm*D&lt;/code&gt; layers in the model to &lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt;&lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt;&lt;/a&gt; layers.</source>
          <target state="translated">モデル内のすべての &lt;code&gt;BatchNorm*D&lt;/code&gt; レイヤーを&lt;a href=&quot;#torch.nn.SyncBatchNorm&quot;&gt; &lt;code&gt;torch.nn.SyncBatchNorm&lt;/code&gt; &lt;/a&gt;レイヤーに変換するヘルパー関数。</target>
        </trans-unit>
        <trans-unit id="ecbcb0e424c40d9931c2c7c8b44c33c5f4e12465" translate="yes" xml:space="preserve">
          <source>Here</source>
          <target state="translated">Here</target>
        </trans-unit>
        <trans-unit id="2bcc88cec50d653f641638296cdbe26d969f54b5" translate="yes" xml:space="preserve">
          <source>Here are the summary of the accuracies for the models trained on the instances set of COCO train2017 and evaluated on COCO val2017.</source>
          <target state="translated">COCO train2017のインスタンスセットで学習したモデルとCOCO val2017で評価したモデルの精度をまとめてみました。</target>
        </trans-unit>
        <trans-unit id="dab4abc36186b02c3f92677e0eb34f60ea19ee65" translate="yes" xml:space="preserve">
          <source>Here are the ways to call &lt;code&gt;to&lt;/code&gt;:</source>
          <target state="translated">ここでコールする方法があります &lt;code&gt;to&lt;/code&gt; ：</target>
        </trans-unit>
        <trans-unit id="445a6f9d83de6be3e9c47cd5d94f26ed51643163" translate="yes" xml:space="preserve">
          <source>Here is a code snippet specifies an entrypoint for &lt;code&gt;resnet18&lt;/code&gt; model if we expand the implementation in &lt;code&gt;pytorch/vision/hubconf.py&lt;/code&gt;. In most case importing the right function in &lt;code&gt;hubconf.py&lt;/code&gt; is sufficient. Here we just want to use the expanded version as an example to show how it works. You can see the full script in &lt;a href=&quot;https://github.com/pytorch/vision/blob/master/hubconf.py&quot;&gt;pytorch/vision repo&lt;/a&gt;</source>
          <target state="translated">&lt;code&gt;pytorch/vision/hubconf.py&lt;/code&gt; 実装を拡張した場合の &lt;code&gt;resnet18&lt;/code&gt; モデルのエントリポイントを指定するコードスニペットを次に示します。ほとんどの場合、 &lt;code&gt;hubconf.py&lt;/code&gt; に適切な関数をインポートするだけで十分です。ここでは、拡張バージョンを例として使用して、それがどのように機能するかを示します。完全なスクリプトは&lt;a href=&quot;https://github.com/pytorch/vision/blob/master/hubconf.py&quot;&gt;pytorch / visionリポジトリ&lt;/a&gt;で確認できます</target>
        </trans-unit>
        <trans-unit id="ae7bbf97b180351dca19b9329b791cc507f2b072" translate="yes" xml:space="preserve">
          <source>Here is a simple script which exports a pretrained AlexNet as defined in torchvision into ONNX. It runs a single round of inference and then saves the resulting traced model to &lt;code&gt;alexnet.onnx&lt;/code&gt;:</source>
          <target state="translated">これは、トーチビジョンで定義された事前トレーニング済みのAlexNetをONNXにエクスポートする簡単なスクリプトです。1回の推論を実行し、結果のトレースされたモデルを &lt;code&gt;alexnet.onnx&lt;/code&gt; に保存します。</target>
        </trans-unit>
        <trans-unit id="92287b24e3387d7af034be3a29ae6b7bb430d9be" translate="yes" xml:space="preserve">
          <source>Here is an example of handling missing symbolic function for &lt;code&gt;elu&lt;/code&gt; operator. We try to export the model and see the error message as below:</source>
          <target state="translated">これは、 &lt;code&gt;elu&lt;/code&gt; 演算子の欠落しているシンボリック関数を処理する例です。モデルをエクスポートしようとすると、次のようなエラーメッセージが表示されます。</target>
        </trans-unit>
        <trans-unit id="e2d985f7b3554227167f11444cb5f1733937d03c" translate="yes" xml:space="preserve">
          <source>Here is another &lt;a href=&quot;https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html&quot;&gt;tutorial of exporting the SuperResolution model to ONNX.&lt;/a&gt;.</source>
          <target state="translated">これは&lt;a href=&quot;https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html&quot;&gt;、SuperResolutionモデルをONNXにエクスポートする&lt;/a&gt;別のチュートリアルです。。</target>
        </trans-unit>
        <trans-unit id="3d3237992ce2b8eaf6bc76469f46fd9b7ad4ba34" translate="yes" xml:space="preserve">
          <source>HingeEmbeddingLoss</source>
          <target state="translated">HingeEmbeddingLoss</target>
        </trans-unit>
        <trans-unit id="144dc3699fae1cc6bf638916541c8cf0248b5ad0" translate="yes" xml:space="preserve">
          <source>Histogram represented as a tensor</source>
          <target state="translated">テンソルで表されるヒストグラム</target>
        </trans-unit>
        <trans-unit id="6abad81420de9ddfe06289f2d7475110d726e0f7" translate="yes" xml:space="preserve">
          <source>Holds parameters in a dictionary.</source>
          <target state="translated">辞書にパラメータを保持します。</target>
        </trans-unit>
        <trans-unit id="5b433389b7ec9270f0a561a21e07b6fafe96e6b4" translate="yes" xml:space="preserve">
          <source>Holds parameters in a list.</source>
          <target state="translated">パラメータをリストに保持します。</target>
        </trans-unit>
        <trans-unit id="57c99ed1c82d3f1f9d82887040191b4b4abeeaa4" translate="yes" xml:space="preserve">
          <source>Holds submodules in a dictionary.</source>
          <target state="translated">辞書にサブモジュールを保持します。</target>
        </trans-unit>
        <trans-unit id="26eb2ae7fc8977e64bf6bd3cc41f59552193cc67" translate="yes" xml:space="preserve">
          <source>Holds submodules in a list.</source>
          <target state="translated">サブモジュールをリストに保持します。</target>
        </trans-unit>
        <trans-unit id="e7b0c97307f7d5f337291cd7806994ff8fc4ef93" translate="yes" xml:space="preserve">
          <source>Holds the data and list of &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt;&lt;code&gt;batch_sizes&lt;/code&gt;&lt;/a&gt; of a packed sequence.</source>
          <target state="translated">パックされたシーケンスの&lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt; &lt;code&gt;batch_sizes&lt;/code&gt; の&lt;/a&gt;データとリストを保持します。</target>
        </trans-unit>
        <trans-unit id="8419c96872dc0338c3c6bf4230e67b362cd3efd6" translate="yes" xml:space="preserve">
          <source>Holds the data and list of &lt;code&gt;batch_sizes&lt;/code&gt; of a packed sequence.</source>
          <target state="translated">パックされたシーケンスの &lt;code&gt;batch_sizes&lt;/code&gt; のデータとリストを保持します。</target>
        </trans-unit>
        <trans-unit id="94d972a8a1e2dd3bfc19dfa88cfbe55c7c0c3689" translate="yes" xml:space="preserve">
          <source>How to implement an entrypoint?</source>
          <target state="translated">エントリポイントを実装するには?</target>
        </trans-unit>
        <trans-unit id="25a9b274bc53945b3703ea4d8441695a628a5f50" translate="yes" xml:space="preserve">
          <source>However, &lt;a href=&quot;#torch.nn.EmbeddingBag&quot;&gt;&lt;code&gt;EmbeddingBag&lt;/code&gt;&lt;/a&gt; is much more time and memory efficient than using a chain of these operations.</source>
          <target state="translated">However, &lt;a href=&quot;#torch.nn.EmbeddingBag&quot;&gt; &lt;code&gt;EmbeddingBag&lt;/code&gt; &lt;/a&gt; is much more time and memory efficient than using a chain of these operations.</target>
        </trans-unit>
        <trans-unit id="0911b09b4e58b715dde3450d0531ebe9129437bf" translate="yes" xml:space="preserve">
          <source>However, &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt;&lt;code&gt;batch_sizes&lt;/code&gt;&lt;/a&gt; should always be a CPU &lt;code&gt;torch.int64&lt;/code&gt; tensor.</source>
          <target state="translated">However, &lt;a href=&quot;#torch.nn.utils.rnn.PackedSequence.batch_sizes&quot;&gt; &lt;code&gt;batch_sizes&lt;/code&gt; &lt;/a&gt; should always be a CPU &lt;code&gt;torch.int64&lt;/code&gt; tensor.</target>
        </trans-unit>
        <trans-unit id="ca73ab65568cd125c2d27a22bbd9e863c10b675d" translate="yes" xml:space="preserve">
          <source>I</source>
          <target state="translated">I</target>
        </trans-unit>
        <trans-unit id="17be3fac04b9eb29173ba1517552ac97aa85e862" translate="yes" xml:space="preserve">
          <source>I. M. Sobol. The distribution of points in a cube and the accurate evaluation of integrals. Zh. Vychisl. Mat. i Mat. Phys., 7:784-802, 1967.</source>
          <target state="translated">I.M.ソボル 立方体の点の分布と積分の正確な評価。ヴイシズル.Vychisl.因みに,この研究では,このような問題を解決するための方法を検討している。物理学,7:784-802,1967.</target>
        </trans-unit>
        <trans-unit id="c3eeaff2d8f8be416c4b7ba0cc9972581ba73c12" translate="yes" xml:space="preserve">
          <source>INDICES WITH CORRESPONDING NAMES:</source>
          <target state="translated">呼応する名前を持つ指標。</target>
        </trans-unit>
        <trans-unit id="7e5a975b6add84fd53e3710a9ceac15eb06663b7" translate="yes" xml:space="preserve">
          <source>Identity</source>
          <target state="translated">Identity</target>
        </trans-unit>
        <trans-unit id="751c68a3471b1c791efaee0a8e7c24ea0c266efd" translate="yes" xml:space="preserve">
          <source>If</source>
          <target state="translated">If</target>
        </trans-unit>
        <trans-unit id="e876238e2103f6c99bd92bbd23268dffc89d5e98" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;#torch.hub.set_dir&quot;&gt;&lt;code&gt;set_dir()&lt;/code&gt;&lt;/a&gt; is not called, default path is &lt;code&gt;$TORCH_HOME/hub&lt;/code&gt; where environment variable &lt;code&gt;$TORCH_HOME&lt;/code&gt; defaults to &lt;code&gt;$XDG_CACHE_HOME/torch&lt;/code&gt;. &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt; follows the X Design Group specification of the Linux filesystem layout, with a default value &lt;code&gt;~/.cache&lt;/code&gt; if the environment variable is not set.</source>
          <target state="translated">If &lt;a href=&quot;#torch.hub.set_dir&quot;&gt; &lt;code&gt;set_dir()&lt;/code&gt; &lt;/a&gt; is not called, default path is &lt;code&gt;$TORCH_HOME/hub&lt;/code&gt; where environment variable &lt;code&gt;$TORCH_HOME&lt;/code&gt; defaults to &lt;code&gt;$XDG_CACHE_HOME/torch&lt;/code&gt; . &lt;code&gt;$XDG_CACHE_HOME&lt;/code&gt; follows the X Design Group specification of the Linux filesystem layout, with a default value &lt;code&gt;~/.cache&lt;/code&gt; if the environment variable is not set.</target>
        </trans-unit>
        <trans-unit id="2365a78f9c70fd188f67372dcb4ead5e46155be1" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; &amp;gt; 0, it is above the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; &amp;gt; 0, it is above the main diagonal.</target>
        </trans-unit>
        <trans-unit id="3b581ac7d1874578962f7ebaf7dd7355265bfcb4" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; &amp;lt; 0, it is below the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; &amp;lt; 0, it is below the main diagonal.</target>
        </trans-unit>
        <trans-unit id="d93aaba0d391e746ad390a6373a6f9bdbe62d27c" translate="yes" xml:space="preserve">
          <source>If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt;&lt;code&gt;diagonal&lt;/code&gt;&lt;/a&gt; = 0, it is the main diagonal.</source>
          <target state="translated">If &lt;a href=&quot;torch.diagonal#torch.diagonal&quot;&gt; &lt;code&gt;diagonal&lt;/code&gt; &lt;/a&gt; = 0, it is the main diagonal.</target>
        </trans-unit>
        <trans-unit id="a1496c02b09e4951bc82bcd52564a0a26f1a0976" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;(h_0, c_0)&lt;/code&gt; is not provided, both &lt;strong&gt;h_0&lt;/strong&gt; and &lt;strong&gt;c_0&lt;/strong&gt; default to zero.</source>
          <target state="translated">If &lt;code&gt;(h_0, c_0)&lt;/code&gt; is not provided, both &lt;strong&gt;h_0&lt;/strong&gt; and &lt;strong&gt;c_0&lt;/strong&gt; default to zero.</target>
        </trans-unit>
        <trans-unit id="db361da536d20a314407fbca9d9b4b9534c18d89" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;Model&lt;/code&gt; is instantiated it will result in a compilation error since the compiler doesn&amp;rsquo;t know about &lt;code&gt;x&lt;/code&gt;. There are 4 ways to inform the compiler of attributes on &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">If &lt;code&gt;Model&lt;/code&gt; is instantiated it will result in a compilation error since the compiler doesn&amp;rsquo;t know about &lt;code&gt;x&lt;/code&gt; . There are 4 ways to inform the compiler of attributes on &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;:</target>
        </trans-unit>
        <trans-unit id="5fde3f46b9d751a46e85953fec7714aa67e2342e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the elements in &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; are added to &lt;code&gt;self&lt;/code&gt;. If accumulate is &lt;code&gt;False&lt;/code&gt;, the behavior is undefined if indices contain duplicate elements.</source>
          <target state="translated">If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the elements in &lt;a href=&quot;generated/torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; are added to &lt;code&gt;self&lt;/code&gt; . If accumulate is &lt;code&gt;False&lt;/code&gt; , the behavior is undefined if indices contain duplicate elements.</target>
        </trans-unit>
        <trans-unit id="2201c7c6a621b0e5c67fe66d2f987b652400f785" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the elements in &lt;code&gt;value&lt;/code&gt; are added to &lt;code&gt;self&lt;/code&gt;. If accumulate is &lt;code&gt;False&lt;/code&gt;, the behavior is undefined if indices contain duplicate elements.</source>
          <target state="translated">If &lt;code&gt;accumulate&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the elements in &lt;code&gt;value&lt;/code&gt; are added to &lt;code&gt;self&lt;/code&gt; . If accumulate is &lt;code&gt;False&lt;/code&gt; , the behavior is undefined if indices contain duplicate elements.</target>
        </trans-unit>
        <trans-unit id="989ae399047ba12cf5c5c1ad5cbe5e9842000a8a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the output tensor containing indices. If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, one 1-D tensor for each dimension, containing the indices of each nonzero element along that dimension.</source>
          <target state="translated">If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the output tensor containing indices. If &lt;code&gt;as_tuple&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , one 1-D tensor for each dimension, containing the indices of each nonzero element along that dimension.</target>
        </trans-unit>
        <trans-unit id="42d4ccb0a610720c59f54cf25fbe1940e041af3d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;batch1&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;batch1&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="f6f5f33da7723c89d0774922372d006d60d5610a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;beta&lt;/code&gt; is 0, then &lt;code&gt;input&lt;/code&gt; will be ignored, and &lt;code&gt;nan&lt;/code&gt; and &lt;code&gt;inf&lt;/code&gt; in it will not be propagated.</source>
          <target state="translated">If &lt;code&gt;beta&lt;/code&gt; is 0, then &lt;code&gt;input&lt;/code&gt; will be ignored, and &lt;code&gt;nan&lt;/code&gt; and &lt;code&gt;inf&lt;/code&gt; in it will not be propagated.</target>
        </trans-unit>
        <trans-unit id="dc51e352774290d1926f402524b258eb4db4275e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), &lt;code&gt;input&lt;/code&gt; will be padded on both sides so that the</source>
          <target state="translated">If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), &lt;code&gt;input&lt;/code&gt; will be padded on both sides so that the</target>
        </trans-unit>
        <trans-unit id="965719376b6d5fe07ada3da22176f7f46b7ed555" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then there will be padding e.g. &lt;code&gt;'constant'&lt;/code&gt;, &lt;code&gt;'reflect'&lt;/code&gt;, etc. Left padding can be trimmed off exactly because they can be calculated but right padding cannot be calculated without additional information.</source>
          <target state="translated">If &lt;code&gt;center&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then there will be padding e.g. &lt;code&gt;'constant'&lt;/code&gt; , &lt;code&gt;'reflect'&lt;/code&gt; , etc. Left padding can be trimmed off exactly because they can be calculated but right padding cannot be calculated without additional information.</target>
        </trans-unit>
        <trans-unit id="fc14ae1693b0f07d578cbfe76b09c86688e0df82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will be zero matrices of shape</source>
          <target state="translated">If &lt;code&gt;compute_uv&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will be zero matrices of shape</target>
        </trans-unit>
        <trans-unit id="65b33918f4984ada2bac2f4ee54a2728e16bb872" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;descending&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the elements are sorted in descending order by value.</source>
          <target state="translated">If &lt;code&gt;descending&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; then the elements are sorted in descending order by value.</target>
        </trans-unit>
        <trans-unit id="f30e67b5addf429de66048f84b97eb2d56624113" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dim&lt;/code&gt; is not given, it defaults to the first dimension found with the size 3. Note that this might be unexpected.</source>
          <target state="translated">If &lt;code&gt;dim&lt;/code&gt; is not given, it defaults to the first dimension found with the size 3. Note that this might be unexpected.</target>
        </trans-unit>
        <trans-unit id="e52a79087756b4493bd3fe7986958f5739aaef82" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;dim&lt;/code&gt; is not given, the last dimension of the &lt;code&gt;input&lt;/code&gt; is chosen.</source>
          <target state="translated">If &lt;code&gt;dim&lt;/code&gt; is not given, the last dimension of the &lt;code&gt;input&lt;/code&gt; is chosen.</target>
        </trans-unit>
        <trans-unit id="ffe3df3fa3b821e3480cebbf887d0692dbdcfbb2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; or &lt;code&gt;forward&lt;/code&gt; of &lt;code&gt;nn.Module&lt;/code&gt;, &lt;code&gt;trace&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. The returned &lt;code&gt;ScriptModule&lt;/code&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt;. If &lt;code&gt;func&lt;/code&gt; is a standalone function, &lt;code&gt;trace&lt;/code&gt; returns &lt;code&gt;ScriptFunction&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;func&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; or &lt;code&gt;forward&lt;/code&gt; of &lt;code&gt;nn.Module&lt;/code&gt; , &lt;code&gt;trace&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; object with a single &lt;code&gt;forward&lt;/code&gt; method containing the traced code. The returned &lt;code&gt;ScriptModule&lt;/code&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt; . If &lt;code&gt;func&lt;/code&gt; is a standalone function, &lt;code&gt;trace&lt;/code&gt; returns &lt;code&gt;ScriptFunction&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="12f27a06f15ef646d5a97006314eddc5168ac16a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;function&lt;/code&gt; invocation during backward does anything different than the one during forward, e.g., due to some global variable, the checkpointed version won&amp;rsquo;t be equivalent, and unfortunately it can&amp;rsquo;t be detected.</source>
          <target state="translated">If &lt;code&gt;function&lt;/code&gt; invocation during backward does anything different than the one during forward, e.g., due to some global variable, the checkpointed version won&amp;rsquo;t be equivalent, and unfortunately it can&amp;rsquo;t be detected.</target>
        </trans-unit>
        <trans-unit id="7fc30718c6826ba4f06aa25c6aae50a9ac61ea27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;grid&lt;/code&gt; has values outside the range of &lt;code&gt;[-1, 1]&lt;/code&gt;, the corresponding outputs are handled as defined by &lt;code&gt;padding_mode&lt;/code&gt;. Options are</source>
          <target state="translated">If &lt;code&gt;grid&lt;/code&gt; has values outside the range of &lt;code&gt;[-1, 1]&lt;/code&gt; , the corresponding outputs are handled as defined by &lt;code&gt;padding_mode&lt;/code&gt; . Options are</target>
        </trans-unit>
        <trans-unit id="56cdf52769f875d95bfc8ef6e8310ccf2d0ab6ef" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;hop_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;hop_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;floor(n_fft / 4)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9a42f5f55bf046653a704f6db77ba0e3241e7e2f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; has</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; has</target>
        </trans-unit>
        <trans-unit id="b713735765f53d252a6982eaad4ca993659b98bf" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; has zero determinant, this returns &lt;code&gt;(0, -inf)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; has zero determinant, this returns &lt;code&gt;(0, -inf)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e500b7aaaa41be4614fc8206c1a0e4e07b1a2886" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is 1D of shape &lt;code&gt;(N)&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is 1D of shape &lt;code&gt;(N)&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="06376d4d271f3b9dcf5c2b5b33c61831ac5086a5" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is 2D of shape &lt;code&gt;(B, N)&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is 2D of shape &lt;code&gt;(B, N)&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="d721dee0fdf912ec6fe02d3c521f5fb3cf097977" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="333f1219fe75814d72dd2dbd93db4f7d9396ef8a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="63f74a4f9eae20a71d7f307933ef2802201be33d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a matrix with &lt;code&gt;m&lt;/code&gt; rows, &lt;code&gt;out&lt;/code&gt; is an matrix of shape</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a matrix with &lt;code&gt;m&lt;/code&gt; rows, &lt;code&gt;out&lt;/code&gt; is an matrix of shape</target>
        </trans-unit>
        <trans-unit id="27b6ec31f1f65b3c25640d5370bad846221e8b75" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a tensor with more than one dimension, then returns a 2-D tensor with diagonal elements equal to a flattened &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a tensor with more than one dimension, then returns a 2-D tensor with diagonal elements equal to a flattened &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="40b5681668244b650aeff8654a98b80d07f3df6a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor</target>
        </trans-unit>
        <trans-unit id="35915a3eb4d935ad3d429e632e78a9274b0c797a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor with the elements of &lt;code&gt;input&lt;/code&gt; as the diagonal.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector (1-D tensor), then returns a 2-D square tensor with the elements of &lt;code&gt;input&lt;/code&gt; as the diagonal.</target>
        </trans-unit>
        <trans-unit id="ad879c1e17f47008543d08a003ad2cbc09fcfa1b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is a vector, &lt;code&gt;out&lt;/code&gt; is a vector of size &lt;code&gt;num_samples&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is a vector, &lt;code&gt;out&lt;/code&gt; is a vector of size &lt;code&gt;num_samples&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5b37263956a979da36ed328c86d1f8d5bafac1ea" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is an n-dimensional tensor with size</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is an n-dimensional tensor with size</target>
        </trans-unit>
        <trans-unit id="f77fab43f2855d468661a78ecf375280629b91c9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, &lt;code&gt;other&lt;/code&gt; should be a real number, otherwise it should be an integer</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , &lt;code&gt;other&lt;/code&gt; should be a real number, otherwise it should be an integer</target>
        </trans-unit>
        <trans-unit id="59214511303529b73d11d23823eff1c49a8f295c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; should be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , &lt;code&gt;value&lt;/code&gt; should be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="7935f4c92d76a69f5c3018eeffd91bc6bda0cd48" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt;, args &lt;a href=&quot;torch.min#torch.min&quot;&gt;&lt;code&gt;min&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt;&lt;code&gt;max&lt;/code&gt;&lt;/a&gt; must be real numbers, otherwise they should be integers.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type &lt;code&gt;FloatTensor&lt;/code&gt; or &lt;code&gt;DoubleTensor&lt;/code&gt; , args &lt;a href=&quot;torch.min#torch.min&quot;&gt; &lt;code&gt;min&lt;/code&gt; &lt;/a&gt; and &lt;a href=&quot;torch.max#torch.max&quot;&gt; &lt;code&gt;max&lt;/code&gt; &lt;/a&gt; must be real numbers, otherwise they should be integers.</target>
        </trans-unit>
        <trans-unit id="74011e63fd6b8669cda7c1001070f1e13f3cf86f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;input&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;other&lt;/code&gt; must be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;input&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;other&lt;/code&gt; must be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="fd07eaa51527d175519a582a0f6f85c473a1308f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, returns the loaded PyTorch extension as a Python module. If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; returns nothing (the shared library is loaded into the process as a side effect).</source>
          <target state="translated">If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , returns the loaded PyTorch extension as a Python module. If &lt;code&gt;is_python_module&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; returns nothing (the shared library is loaded into the process as a side effect).</target>
        </trans-unit>
        <trans-unit id="150898b85fa40ffdbf63d6a8c5f8e7d9b416ba17" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim is ``True`&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt;), resulting in the output tensors having fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim is ``True`&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt; ), resulting in the output tensors having fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="8dfb26e902cefe829de7730f64927f442131d727" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors are the same size as &lt;code&gt;input&lt;/code&gt;, except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors having 1 fewer dimension than the &lt;code&gt;input&lt;/code&gt; tensor.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors are the same size as &lt;code&gt;input&lt;/code&gt; , except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in both the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;indices&lt;/code&gt; tensors having 1 fewer dimension than the &lt;code&gt;input&lt;/code&gt; tensor.</target>
        </trans-unit>
        <trans-unit id="4eef57842bb23530ec99ef24c142564e33a57efb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output dimensions are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimensions being reduced (&lt;code&gt;dim&lt;/code&gt; or all if &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt;) where they have size 1. Otherwise, the dimensions being reduced are squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;). If &lt;code&gt;q&lt;/code&gt; is a 1D tensor, an extra dimension is prepended to the output tensor with the same size as &lt;code&gt;q&lt;/code&gt; which represents the quantiles.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output dimensions are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimensions being reduced ( &lt;code&gt;dim&lt;/code&gt; or all if &lt;code&gt;dim&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; ) where they have size 1. Otherwise, the dimensions being reduced are squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;). If &lt;code&gt;q&lt;/code&gt; is a 1D tensor, an extra dimension is prepended to the output tensor with the same size as &lt;code&gt;q&lt;/code&gt; which represents the quantiles.</target>
        </trans-unit>
        <trans-unit id="8af1f9e4f1fca763580351e3fbd0001f54ae795e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;generated/torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="71fae5aef8701d9d46f893cd636d6b67ec5e6aab" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="5a9d71d5cbb1ac9891b1a744240b0f98bb2945c1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensor having 1 (or &lt;code&gt;len(dim)&lt;/code&gt;) fewer dimension(s).</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensor is of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where it is of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensor having 1 (or &lt;code&gt;len(dim)&lt;/code&gt; ) fewer dimension(s).</target>
        </trans-unit>
        <trans-unit id="7c2f11e03ffcd1caa4f43b25af60e0e5bd33899d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the output tensors having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the output tensors having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="21c9748f09f2547a22882ea8c179fcab7d38a94c" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt;&lt;code&gt;torch.squeeze()&lt;/code&gt;&lt;/a&gt;), resulting in the outputs tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim&lt;/code&gt; is squeezed (see &lt;a href=&quot;torch.squeeze#torch.squeeze&quot;&gt; &lt;code&gt;torch.squeeze()&lt;/code&gt; &lt;/a&gt;), resulting in the outputs tensor having 1 fewer dimension than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="fd1cd26edf38a8fdee9967389f0e6dac29ec3c27" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt;), resulting in the output tensors having fewer dimensions than &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;keepdim&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the output tensors are of the same size as &lt;code&gt;input&lt;/code&gt; except in the dimension(s) &lt;code&gt;dim&lt;/code&gt; where they are of size 1. Otherwise, &lt;code&gt;dim`s are squeezed (see :func:`torch.squeeze&lt;/code&gt; ), resulting in the output tensors having fewer dimensions than &lt;code&gt;input&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a5f40df338bf2f9f730257d36666627ccd6548fc" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;dilation&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1, their values will be replicated across all spatial dimensions.</source>
          <target state="translated">If &lt;code&gt;kernel_size&lt;/code&gt; , &lt;code&gt;dilation&lt;/code&gt; , &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1, their values will be replicated across all spatial dimensions.</target>
        </trans-unit>
        <trans-unit id="55b84dbfa8c62b3f0cac777d20c854c0409394ae" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;largest&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the &lt;code&gt;k&lt;/code&gt; smallest elements are returned.</source>
          <target state="translated">If &lt;code&gt;largest&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; then the &lt;code&gt;k&lt;/code&gt; smallest elements are returned.</target>
        </trans-unit>
        <trans-unit id="fa798f0a6b2f55ce7a633ab807b16e5f24185685" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;map_location&lt;/code&gt; is a &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; object or a string containing a device tag, it indicates the location where all tensors should be loaded.</source>
          <target state="translated">If &lt;code&gt;map_location&lt;/code&gt; is a &lt;a href=&quot;../tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt; object or a string containing a device tag, it indicates the location where all tensors should be loaded.</target>
        </trans-unit>
        <trans-unit id="048f95b6581ac17eb4c969ed9d078d249d78f4f2" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;map_location&lt;/code&gt; is a callable, it will be called once for each serialized storage with two arguments: storage and location. The storage argument will be the initial deserialization of the storage, residing on the CPU. Each serialized storage has a location tag associated with it which identifies the device it was saved from, and this tag is the second argument passed to &lt;code&gt;map_location&lt;/code&gt;. The builtin location tags are &lt;code&gt;'cpu'&lt;/code&gt; for CPU tensors and &lt;code&gt;'cuda:device_id'&lt;/code&gt; (e.g. &lt;code&gt;'cuda:2'&lt;/code&gt;) for CUDA tensors. &lt;code&gt;map_location&lt;/code&gt; should return either &lt;code&gt;None&lt;/code&gt; or a storage. If &lt;code&gt;map_location&lt;/code&gt; returns a storage, it will be used as the final deserialized object, already moved to the right device. Otherwise, &lt;a href=&quot;#torch.load&quot;&gt;&lt;code&gt;torch.load()&lt;/code&gt;&lt;/a&gt; will fall back to the default behavior, as if &lt;code&gt;map_location&lt;/code&gt; wasn&amp;rsquo;t specified.</source>
          <target state="translated">If &lt;code&gt;map_location&lt;/code&gt; is a callable, it will be called once for each serialized storage with two arguments: storage and location. The storage argument will be the initial deserialization of the storage, residing on the CPU. Each serialized storage has a location tag associated with it which identifies the device it was saved from, and this tag is the second argument passed to &lt;code&gt;map_location&lt;/code&gt; . The builtin location tags are &lt;code&gt;'cpu'&lt;/code&gt; for CPU tensors and &lt;code&gt;'cuda:device_id'&lt;/code&gt; (e.g. &lt;code&gt;'cuda:2'&lt;/code&gt; ) for CUDA tensors. &lt;code&gt;map_location&lt;/code&gt; should return either &lt;code&gt;None&lt;/code&gt; or a storage. If &lt;code&gt;map_location&lt;/code&gt; returns a storage, it will be used as the final deserialized object, already moved to the right device. Otherwise, &lt;a href=&quot;#torch.load&quot;&gt; &lt;code&gt;torch.load()&lt;/code&gt; &lt;/a&gt; will fall back to the default behavior, as if &lt;code&gt;map_location&lt;/code&gt; wasn&amp;rsquo;t specified.</target>
        </trans-unit>
        <trans-unit id="0e6bc544f9847053786078b7293a8d56bcd4734d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;mat1&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;mat1&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="42dc8bdc5d9263d6983656748538a841cde8189e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;mat&lt;/code&gt; is a</source>
          <target state="translated">If &lt;code&gt;mat&lt;/code&gt; is a</target>
        </trans-unit>
        <trans-unit id="ebf39946f09dcba3bcd6988a72fb252101844e11" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;modules&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt;, a &lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt;&lt;code&gt;ModuleDict&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</source>
          <target state="translated">If &lt;code&gt;modules&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt; , a &lt;a href=&quot;#torch.nn.ModuleDict&quot;&gt; &lt;code&gt;ModuleDict&lt;/code&gt; &lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</target>
        </trans-unit>
        <trans-unit id="9da2da81b60822905c169e5c07b984ccee82a21a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n&lt;/code&gt; is negative, then the inverse of the matrix (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt;. For a batch of matrices, the batched inverse (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt;. If &lt;code&gt;n&lt;/code&gt; is 0, then an identity matrix is returned.</source>
          <target state="translated">If &lt;code&gt;n&lt;/code&gt; is negative, then the inverse of the matrix (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt; . For a batch of matrices, the batched inverse (if invertible) is raised to the power &lt;code&gt;n&lt;/code&gt; . If &lt;code&gt;n&lt;/code&gt; is 0, then an identity matrix is returned.</target>
        </trans-unit>
        <trans-unit id="7a5b0d2161214cfbfdadaec7bb8185cf215fb328" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;n&lt;/code&gt; is the number of dimensions in &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;x.T&lt;/code&gt; is equivalent to &lt;code&gt;x.permute(n-1, n-2, ..., 0)&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;n&lt;/code&gt; is the number of dimensions in &lt;code&gt;x&lt;/code&gt; , &lt;code&gt;x.T&lt;/code&gt; is equivalent to &lt;code&gt;x.permute(n-1, n-2, ..., 0)&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="64021abf601b2ef80dc11cb82f4cc12a6574725a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;nonlinearity&lt;/code&gt; is &lt;code&gt;&amp;lsquo;relu&amp;rsquo;&lt;/code&gt;, then ReLU is used in place of tanh.</source>
          <target state="translated">If &lt;code&gt;nonlinearity&lt;/code&gt; is &lt;code&gt;&amp;lsquo;relu&amp;rsquo;&lt;/code&gt; , then ReLU is used in place of tanh.</target>
        </trans-unit>
        <trans-unit id="14d766061a3de2fff996b1f5b1787217fd8c9c07" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;normalized&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default is &lt;code&gt;False&lt;/code&gt;), the function returns the normalized STFT results, i.e., multiplied by</source>
          <target state="translated">If &lt;code&gt;normalized&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default is &lt;code&gt;False&lt;/code&gt; ), the function returns the normalized STFT results, i.e., multiplied by</target>
        </trans-unit>
        <trans-unit id="00b342cfeb1bc29dc26ae492fe4fb871890e749d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;obj&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt;, &lt;code&gt;script&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; object. The returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt;. If &lt;code&gt;obj&lt;/code&gt; is a standalone function, a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; will be returned.</source>
          <target state="translated">If &lt;code&gt;obj&lt;/code&gt; is &lt;code&gt;nn.Module&lt;/code&gt; , &lt;code&gt;script&lt;/code&gt; returns a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; object. The returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt; will have the same set of sub-modules and parameters as the original &lt;code&gt;nn.Module&lt;/code&gt; . If &lt;code&gt;obj&lt;/code&gt; is a standalone function, a &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; &lt;/a&gt; will be returned.</target>
        </trans-unit>
        <trans-unit id="a63f6cedcd0f8aaa3b09629c749bc8a65b8e3242" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; &amp;gt; 0, it is above the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; &amp;gt; 0, it is above the main diagonal.</target>
        </trans-unit>
        <trans-unit id="71789ffff3401f164bb9ff6ccd173e3d93708807" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; &amp;lt; 0, it is below the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; &amp;lt; 0, it is below the main diagonal.</target>
        </trans-unit>
        <trans-unit id="68479729055a8e84ce055c5fd8fcdf5fc489269d" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;offset&lt;/code&gt; = 0, it is the main diagonal.</source>
          <target state="translated">If &lt;code&gt;offset&lt;/code&gt; = 0, it is the main diagonal.</target>
        </trans-unit>
        <trans-unit id="4a6e80bcb7f10675f2ca57bde51217a2a4acefff" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default for real input), only values for</source>
          <target state="translated">If &lt;code&gt;onesided&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default for real input), only values for</target>
        </trans-unit>
        <trans-unit id="d55a2e244595c07c3e007024e25f845d2373549a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;other&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;alpha&lt;/code&gt; must be a real number, otherwise it should be an integer.</source>
          <target state="translated">If &lt;code&gt;other&lt;/code&gt; is of type FloatTensor or DoubleTensor, &lt;code&gt;alpha&lt;/code&gt; must be a real number, otherwise it should be an integer.</target>
        </trans-unit>
        <trans-unit id="d24ea9f71cf8ff7e189e7b233b073ed7e74bfb09" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;output_size&lt;/code&gt;, &lt;code&gt;kernel_size&lt;/code&gt;, &lt;code&gt;dilation&lt;/code&gt;, &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1 then their values will be replicated across all spatial dimensions.</source>
          <target state="translated">If &lt;code&gt;output_size&lt;/code&gt; , &lt;code&gt;kernel_size&lt;/code&gt; , &lt;code&gt;dilation&lt;/code&gt; , &lt;code&gt;padding&lt;/code&gt; or &lt;code&gt;stride&lt;/code&gt; is an int or a tuple of length 1 then their values will be replicated across all spatial dimensions.</target>
        </trans-unit>
        <trans-unit id="bcbbd502f1fedcc0223634c589add98b568f5531" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly padded with negative infinity on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; is the stride between the elements within the sliding window. This &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of the pooling parameters.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly padded with negative infinity on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; is the stride between the elements within the sliding window. This &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of the pooling parameters.</target>
        </trans-unit>
        <trans-unit id="a2d29b6dc8926940187a1fc2a87fbebaeec5e10f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on all three sides for &lt;code&gt;padding&lt;/code&gt; number of points.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on all three sides for &lt;code&gt;padding&lt;/code&gt; number of points.</target>
        </trans-unit>
        <trans-unit id="a34bc02f3af80858de013a28d3f5075d29b733ee" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points.</target>
        </trans-unit>
        <trans-unit id="0789404550f41a9218f1f8f6d2d8802206a399d3" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; controls the spacing between the kernel points. It is harder to describe, but this &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of what &lt;code&gt;dilation&lt;/code&gt; does.</source>
          <target state="translated">If &lt;code&gt;padding&lt;/code&gt; is non-zero, then the input is implicitly zero-padded on both sides for &lt;code&gt;padding&lt;/code&gt; number of points. &lt;code&gt;dilation&lt;/code&gt; controls the spacing between the kernel points. It is harder to describe, but this &lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md&quot;&gt;link&lt;/a&gt; has a nice visualization of what &lt;code&gt;dilation&lt;/code&gt; does.</target>
        </trans-unit>
        <trans-unit id="5c75f70ae17fab5880e35d5beec80b653312b036" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;parameters&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt;, a &lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt;&lt;code&gt;ParameterDict&lt;/code&gt;&lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</source>
          <target state="translated">If &lt;code&gt;parameters&lt;/code&gt; is an &lt;code&gt;OrderedDict&lt;/code&gt; , a &lt;a href=&quot;#torch.nn.ParameterDict&quot;&gt; &lt;code&gt;ParameterDict&lt;/code&gt; &lt;/a&gt;, or an iterable of key-value pairs, the order of new elements in it is preserved.</target>
        </trans-unit>
        <trans-unit id="fa4de2a8b20f68604caa5fc5c42d01d653f7619e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;reduction&lt;/code&gt; is not &lt;code&gt;'none'&lt;/code&gt; (default &lt;code&gt;'mean'&lt;/code&gt;), then:</source>
          <target state="translated">If &lt;code&gt;reduction&lt;/code&gt; is not &lt;code&gt;'none'&lt;/code&gt; (default &lt;code&gt;'mean'&lt;/code&gt; ), then:</target>
        </trans-unit>
        <trans-unit id="e3f6cc94ec59a0b57a35c18da0e38bada6245d56" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;return_complex&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default if input is complex), the return is a &lt;code&gt;input.dim() + 1&lt;/code&gt; dimensional complex tensor. If &lt;code&gt;False&lt;/code&gt;, the output is a &lt;code&gt;input.dim() + 2&lt;/code&gt; dimensional real tensor where the last dimension represents the real and imaginary components.</source>
          <target state="translated">If &lt;code&gt;return_complex&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default if input is complex), the return is a &lt;code&gt;input.dim() + 1&lt;/code&gt; dimensional complex tensor. If &lt;code&gt;False&lt;/code&gt; , the output is a &lt;code&gt;input.dim() + 2&lt;/code&gt; dimensional real tensor where the last dimension represents the real and imaginary components.</target>
        </trans-unit>
        <trans-unit id="86cbdc2f08a338f85c6f8af902eddf736f286a0f" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained indices tensor. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained indices tensor. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="1a38a9c9f965f62380fce875a97d72dc47659bfb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained values tensor. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns a view of the contained values tensor. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="95842db2195edf44c14e3fcd797605bf3a42bb61" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of dense dimensions. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of dense dimensions. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="0bcf04d576bbe19078f6b28ab84fc731b5408840" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of sparse dimensions. Otherwise, this throws an error.</source>
          <target state="translated">If &lt;code&gt;self&lt;/code&gt; is a sparse COO tensor (i.e., with &lt;code&gt;torch.sparse_coo&lt;/code&gt; layout), this returns the number of sparse dimensions. Otherwise, this throws an error.</target>
        </trans-unit>
        <trans-unit id="ca7f952167ad5a99c7190c4496d9c80f7e0a4624" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then memory is shared between all processes. All changes are written to the file. If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the changes on the storage do not affect the file.</source>
          <target state="translated">If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then memory is shared between all processes. All changes are written to the file. If &lt;code&gt;shared&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the changes on the storage do not affect the file.</target>
        </trans-unit>
        <trans-unit id="015e3e2de9fc9120162aae17d21cac0467229fd9" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;sizedim&lt;/code&gt; is the size of dimension &lt;code&gt;dimension&lt;/code&gt; for &lt;code&gt;self&lt;/code&gt;, the size of dimension &lt;code&gt;dimension&lt;/code&gt; in the returned tensor will be &lt;code&gt;(sizedim - size) / step + 1&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;sizedim&lt;/code&gt; is the size of dimension &lt;code&gt;dimension&lt;/code&gt; for &lt;code&gt;self&lt;/code&gt; , the size of dimension &lt;code&gt;dimension&lt;/code&gt; in the returned tensor will be &lt;code&gt;(sizedim - size) / step + 1&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="e63fb825587df089e2f9c8a5d5a13bc6f9e0bcfa" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), the method returns the reduced singular value decomposition i.e., if the last two dimensions of &lt;code&gt;input&lt;/code&gt; are &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;, then the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will contain only</source>
          <target state="translated">If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; (default), the method returns the reduced singular value decomposition i.e., if the last two dimensions of &lt;code&gt;input&lt;/code&gt; are &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt; , then the returned &lt;code&gt;U&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; matrices will contain only</target>
        </trans-unit>
        <trans-unit id="7e496e3c20e80698b4576d97cd438ec7eb85163b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, then this function returns the thin (reduced) QR factorization. Otherwise, if &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, this function returns the complete QR factorization.</source>
          <target state="translated">If &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , then this function returns the thin (reduced) QR factorization. Otherwise, if &lt;code&gt;some&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , this function returns the complete QR factorization.</target>
        </trans-unit>
        <trans-unit id="1ff1fe08ba98d042300c393b324450ec3743e612" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'github'&lt;/code&gt;, &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be of the form &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; with an optional tag/branch.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'github'&lt;/code&gt; , &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be of the form &lt;code&gt;repo_owner/repo_name[:tag_name]&lt;/code&gt; with an optional tag/branch.</target>
        </trans-unit>
        <trans-unit id="7ddb98294e27497103be69303e2d273125226255" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'local'&lt;/code&gt;, &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be a path to a local directory.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is &lt;code&gt;'local'&lt;/code&gt; , &lt;code&gt;repo_or_dir&lt;/code&gt; is expected to be a path to a local directory.</target>
        </trans-unit>
        <trans-unit id="8e46fd64e2d63e21f45b5d33db7806f0957cdf7b" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;source&lt;/code&gt; is a &lt;code&gt;Storage&lt;/code&gt;, the method sets the underlying storage, offset, size, and stride.</source>
          <target state="translated">If &lt;code&gt;source&lt;/code&gt; is a &lt;code&gt;Storage&lt;/code&gt; , the method sets the underlying storage, offset, size, and stride.</target>
        </trans-unit>
        <trans-unit id="cde3a8bb0ace5c85908b26369901162f2c89a71e" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;split_size_or_sections&lt;/code&gt; is a list, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; will be split into &lt;code&gt;len(split_size_or_sections)&lt;/code&gt; chunks with sizes in &lt;code&gt;dim&lt;/code&gt; according to &lt;code&gt;split_size_or_sections&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;split_size_or_sections&lt;/code&gt; is a list, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; will be split into &lt;code&gt;len(split_size_or_sections)&lt;/code&gt; chunks with sizes in &lt;code&gt;dim&lt;/code&gt; according to &lt;code&gt;split_size_or_sections&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a130a738825270ea8d38803841375a69a70f4847" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;split_size_or_sections&lt;/code&gt; is an integer type, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt;&lt;code&gt;tensor&lt;/code&gt;&lt;/a&gt; will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;split_size&lt;/code&gt;.</source>
          <target state="translated">If &lt;code&gt;split_size_or_sections&lt;/code&gt; is an integer type, then &lt;a href=&quot;torch.tensor#torch.tensor&quot;&gt; &lt;code&gt;tensor&lt;/code&gt; &lt;/a&gt; will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;split_size&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="cfc288bc3d95c2b0c35b45e151245ce8a50c4585" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well.</source>
          <target state="translated">If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; , this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well.</target>
        </trans-unit>
        <trans-unit id="12927d84c9ce948d1b220f95a6bfac95c27d8d68" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default &lt;code&gt;momentum&lt;/code&gt; of 0.1.</source>
          <target state="translated">If &lt;code&gt;track_running_stats&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt; , during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default &lt;code&gt;momentum&lt;/code&gt; of 0.1.</target>
        </trans-unit>
        <trans-unit id="07322ca8d48ec2924a49a2e5be17cc42cbbed920" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;tracker&lt;/code&gt; sets &lt;code&gt;bvars[&amp;ldquo;force_stop&amp;rdquo;] = True&lt;/code&gt;, the iteration process will be hard-stopped.</source>
          <target state="translated">If &lt;code&gt;tracker&lt;/code&gt; sets &lt;code&gt;bvars[&amp;ldquo;force_stop&amp;rdquo;] = True&lt;/code&gt; , the iteration process will be hard-stopped.</target>
        </trans-unit>
        <trans-unit id="69139fd88bd2f170758129dcebe723655bc85791" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</source>
          <target state="translated">If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</target>
        </trans-unit>
        <trans-unit id="0054a72bc16c599350023586c7a4c1a0ef3cdabb" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then the variance will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</source>
          <target state="translated">If &lt;code&gt;unbiased&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then the variance will be calculated via the biased estimator. Otherwise, Bessel&amp;rsquo;s correction will be used.</target>
        </trans-unit>
        <trans-unit id="64c7abce64d159f698a9f17e0c36ec9abe8f3696" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;,</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; ,</target>
        </trans-unit>
        <trans-unit id="ea8581ad2e15c4757c07b341a196b7e3beb08404" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, the returned matrix &lt;code&gt;L&lt;/code&gt; is lower-triangular, and the decomposition has the form:</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , the returned matrix &lt;code&gt;L&lt;/code&gt; is lower-triangular, and the decomposition has the form:</target>
        </trans-unit>
        <trans-unit id="64a08919bf7ea0ada24f0d42a92ac1bba95e2ff7" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt;, then lower triangular portion is used.</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;False&lt;/code&gt; , then lower triangular portion is used.</target>
        </trans-unit>
        <trans-unit id="16f312504df9d82f1149f9aeb9d6c3a7744b7863" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; or not provided,</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; or not provided,</target>
        </trans-unit>
        <trans-unit id="0de37aa5dde3c55904d77c2e915431e5555caf52" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, and</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , and</target>
        </trans-unit>
        <trans-unit id="d54780fe04a147f268bb2ed2fa8ab8ca14bbc641" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt;, the returned matrix &lt;code&gt;U&lt;/code&gt; is upper-triangular, and the decomposition has the form:</source>
          <target state="translated">If &lt;code&gt;upper&lt;/code&gt; is &lt;code&gt;True&lt;/code&gt; , the returned matrix &lt;code&gt;U&lt;/code&gt; is upper-triangular, and the decomposition has the form:</target>
        </trans-unit>
        <trans-unit id="f0b760bb14c0f3a83b45512f0cb97f37a555bad1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;vec1&lt;/code&gt; is a vector of size &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; is a vector of size &lt;code&gt;m&lt;/code&gt;, then &lt;code&gt;input&lt;/code&gt; must be &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt; with a matrix of size</source>
          <target state="translated">場合 &lt;code&gt;vec1&lt;/code&gt; サイズのベクトルであり &lt;code&gt;n&lt;/code&gt; 及び &lt;code&gt;vec2&lt;/code&gt; サイズのベクトルであり &lt;code&gt;m&lt;/code&gt; は、 &lt;code&gt;input&lt;/code&gt; なければならない&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcastable&lt;/a&gt;サイズの行列と</target>
        </trans-unit>
        <trans-unit id="3a620298db8d1a210d3df0072bbfa22f1c6b3dc1" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;win_length&lt;/code&gt; is &lt;code&gt;None&lt;/code&gt; (default), it is treated as equal to &lt;code&gt;n_fft&lt;/code&gt;.</source>
          <target state="translated">場合 &lt;code&gt;win_length&lt;/code&gt; がある &lt;code&gt;None&lt;/code&gt; （デフォルト）、それがに等しいものとして扱われる &lt;code&gt;n_fft&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e41ff352c71d6d3681ae49796d3eaff91163d87a" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;window_length&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;window_length&lt;/code&gt; の場合</target>
        </trans-unit>
        <trans-unit id="5ba4029b8d23bd264ef58b8c6c6f2f2dbcc50773" translate="yes" xml:space="preserve">
          <source>If &lt;code&gt;window_length&lt;/code&gt; is one, then the returned window is a single element tensor containing a one.</source>
          <target state="translated">&lt;code&gt;window_length&lt;/code&gt; が1の場合、返されるウィンドウは1を含む単一要素テンソルです。</target>
        </trans-unit>
        <trans-unit id="36700c2c10655c29379465dfe1fd6e89caba46f9" translate="yes" xml:space="preserve">
          <source>If Statements</source>
          <target state="translated">ステートメントの場合</target>
        </trans-unit>
        <trans-unit id="37f71555dd25e508495629f5b40797b269bbe017" translate="yes" xml:space="preserve">
          <source>If True, all the initializers (typically corresponding to parameters) in the exported graph will also be added as inputs to the graph. If False, then initializers are not added as inputs to the graph, and only the non-parameter inputs are added as inputs.</source>
          <target state="translated">True の場合、エクスポートされたグラフ内のすべての初期化子(通常はパラメータに対応)もグラフの入力として追加されます。Falseの場合、初期化子はグラフへの入力として追加されず、パラメータ以外の入力のみが入力として追加されます。</target>
        </trans-unit>
        <trans-unit id="a286c308254a9cdf1bc57c2c79179a955b02516d" translate="yes" xml:space="preserve">
          <source>If a single integer is used, it is treated as a singleton list, and this module will normalize over the last dimension which is expected to be of that specific size.</source>
          <target state="translated">単一の整数が使用されている場合、それはシングルトン・リストとして扱われ、このモジュールは、その特定のサイズであると予想される最後のディメンジョンの上に正規化されます。</target>
        </trans-unit>
        <trans-unit id="6cc6559de482ee416e97f4d6264cba5f02719534" translate="yes" xml:space="preserve">
          <source>If a zero-dimension tensor operand has a higher category than dimensioned operands, we promote to a type with sufficient size and category to hold all zero-dim tensor operands of that category.</source>
          <target state="translated">0次元テンソルオペランドが次元オペランドよりも高いカテゴリを持つ場合、そのカテゴリのすべての0次元テンソルオペランドを保持するのに十分なサイズとカテゴリを持つ型に昇格させます。</target>
        </trans-unit>
        <trans-unit id="3e818bb7352c628c52d3f8d4ba3508811d8bc58f" translate="yes" xml:space="preserve">
          <source>If any of these would help your use case, please &lt;a href=&quot;https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3A%22module%3A+named+tensor%22&quot;&gt;search if an issue has already been filed&lt;/a&gt; and if not, &lt;a href=&quot;https://github.com/pytorch/pytorch/issues/new/choose&quot;&gt;file one&lt;/a&gt;.</source>
          <target state="translated">これらのいずれかがユースケースに役立つ&lt;a href=&quot;https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3A%22module%3A+named+tensor%22&quot;&gt;場合は、問題がすでに提出されているかどうか&lt;/a&gt;を検索し、提出されていない場合は&lt;a href=&quot;https://github.com/pytorch/pytorch/issues/new/choose&quot;&gt;1つ&lt;/a&gt;提出してください。</target>
        </trans-unit>
        <trans-unit id="1080160de99f6c4b9ac7827f3fbead61bb81527f" translate="yes" xml:space="preserve">
          <source>If both arguments are 2-dimensional, the matrix-matrix product is returned.</source>
          <target state="translated">両方の引数が2次元の場合、行列-行列積が返されます。</target>
        </trans-unit>
        <trans-unit id="d6fa8132ad71df4e876fdeaeb999a43daf3f4278" translate="yes" xml:space="preserve">
          <source>If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N &amp;gt; 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;broadcasted&lt;/a&gt; (and thus must be broadcastable). For example, if &lt;code&gt;input&lt;/code&gt; is a</source>
          <target state="translated">両方の引数が少なくとも1次元で、少なくとも1つの引数がN次元（N&amp;gt; 2）の場合、バッチ行列の乗算が返されます。最初の引数が1次元の場合、バッチ行列を乗算して後で削除するために、その次元の前に1が付加されます。 2番目の引数が1次元の場合、バッチ行列の倍数の目的で1がその次元に追加され、後で削除されます。非マトリックス（つまりバッチ）ディメンションが&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/broadcasting.html#broadcasting-semantics&quot;&gt;ブロードキャストされます&lt;/a&gt;（したがって、ブロードキャスト可能である必要があります）。たとえば、 &lt;code&gt;input&lt;/code&gt; が</target>
        </trans-unit>
        <trans-unit id="d89fe56ed688f10e95f166f512f223aa5ad0f1fe" translate="yes" xml:space="preserve">
          <source>If both tensors are 1-dimensional, the dot product (scalar) is returned.</source>
          <target state="translated">両方のテンソルが1次元の場合は、ドット積(スカラー)が返されます。</target>
        </trans-unit>
        <trans-unit id="b74b95d5cdc716438937d19d93c000b85e6ccb8b" translate="yes" xml:space="preserve">
          <source>If checkpointed segment contains tensors detached from the computational graph by &lt;code&gt;detach()&lt;/code&gt; or &lt;code&gt;torch.no_grad()&lt;/code&gt;, the backward pass will raise an error. This is because &lt;code&gt;checkpoint&lt;/code&gt; makes all the outputs require gradients which causes issues when a tensor is defined to have no gradient in the model. To circumvent this, detach the tensors outside of the &lt;code&gt;checkpoint&lt;/code&gt; function.</source>
          <target state="translated">チェックポイントされたセグメントに、 &lt;code&gt;detach()&lt;/code&gt; または &lt;code&gt;torch.no_grad()&lt;/code&gt; によって計算グラフから切り離されたテンソルが含まれている場合、後方パスはエラーを発生させます。これは、 &lt;code&gt;checkpoint&lt;/code&gt; によってすべての出力に勾配が必要になるため、テンソルがモデルに勾配がないと定義されている場合に問題が発生するためです。これを回避するには、 &lt;code&gt;checkpoint&lt;/code&gt; 関数の外側でテンソルを切り離します。</target>
        </trans-unit>
        <trans-unit id="6148ee076450f28f4a8ddad929803f8c02667e14" translate="yes" xml:space="preserve">
          <source>If downloaded file is a zip file, it will be automatically decompressed.</source>
          <target state="translated">ダウンロードしたファイルがZIPファイルの場合は、自動的に解凍されます。</target>
        </trans-unit>
        <trans-unit id="3632499e9221774229ac5b4849f51f9b7ea5baa6" translate="yes" xml:space="preserve">
          <source>If input has shape</source>
          <target state="translated">入力が形状を持っている場合</target>
        </trans-unit>
        <trans-unit id="6054f9e157471bc8a7a27391680f78509c758f80" translate="yes" xml:space="preserve">
          <source>If it is &lt;code&gt;False&lt;/code&gt;, only eigenvalues are computed. If it is &lt;code&gt;True&lt;/code&gt;, both eigenvalues and eigenvectors are computed.</source>
          <target state="translated">&lt;code&gt;False&lt;/code&gt; の場合、固有値のみが計算されます。もしそうであれば &lt;code&gt;True&lt;/code&gt; 、固有値と固有ベクトルの両方が計算されます。</target>
        </trans-unit>
        <trans-unit id="c2b14334c440f3e0a03846297c6b858c19d59ebd" translate="yes" xml:space="preserve">
          <source>If neither is specified, &lt;code&gt;init_method&lt;/code&gt; is assumed to be &amp;ldquo;env://&amp;rdquo;.</source>
          <target state="translated">どちらも指定されていない場合、 &lt;code&gt;init_method&lt;/code&gt; は「env：//」であると見なされます。</target>
        </trans-unit>
        <trans-unit id="8af7fa7360ca7c6df177260376e8748ca36e7b2e" translate="yes" xml:space="preserve">
          <source>If new parameters/buffers are added/removed from a module, this number shall be bumped, and the module&amp;rsquo;s &lt;code&gt;_load_from_state_dict&lt;/code&gt; method can compare the version number and do appropriate changes if the state dict is from before the change.</source>
          <target state="translated">新しいパラメータ/バッファがモジュールに追加/削除された場合、この番号はバンプされ、モジュールの &lt;code&gt;_load_from_state_dict&lt;/code&gt; メソッドはバージョン番号を比較し、状態dictが変更前のものである場合は適切な変更を行うことができます。</target>
        </trans-unit>
        <trans-unit id="35eb8efeed66172f49e69d3035c935e69cd09a9d" translate="yes" xml:space="preserve">
          <source>If not, they are drawn without replacement, which means that when a sample index is drawn for a row, it cannot be drawn again for that row.</source>
          <target state="translated">そうでない場合、それらは置換なしで描画されます。つまり、サンプルインデックスが行に対して描画されたときに、その行に対して再度描画することはできません。</target>
        </trans-unit>
        <trans-unit id="8bad8088b028a7abefb044cb50129322a5504452" translate="yes" xml:space="preserve">
          <source>If one of the elements being compared is a NaN, then that element is returned. &lt;a href=&quot;#torch.maximum&quot;&gt;&lt;code&gt;maximum()&lt;/code&gt;&lt;/a&gt; is not supported for tensors with complex dtypes.</source>
          <target state="translated">比較される要素の1つがNaNである場合、その要素が返されます。&lt;a href=&quot;#torch.maximum&quot;&gt; &lt;code&gt;maximum()&lt;/code&gt; &lt;/a&gt;は、複雑なdtypeを持つテンソルではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="4d2edfb80af8b4c10b0daabd533575291d8f3436" translate="yes" xml:space="preserve">
          <source>If one of the elements being compared is a NaN, then that element is returned. &lt;a href=&quot;#torch.minimum&quot;&gt;&lt;code&gt;minimum()&lt;/code&gt;&lt;/a&gt; is not supported for tensors with complex dtypes.</source>
          <target state="translated">比較される要素の1つがNaNである場合、その要素が返されます。&lt;a href=&quot;#torch.minimum&quot;&gt; &lt;code&gt;minimum()&lt;/code&gt; &lt;/a&gt;は、複雑なdtypeを持つテンソルではサポートされていません。</target>
        </trans-unit>
        <trans-unit id="7af111fbf2a8bf97e37886e5888c11a588605b8f" translate="yes" xml:space="preserve">
          <source>If provided, the optional argument &lt;code&gt;weight&lt;/code&gt; should be a 1D Tensor assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.</source>
          <target state="translated">指定する場合、オプションの引数の &lt;code&gt;weight&lt;/code&gt; は、各クラスに重みを割り当てる1Dテンソルである必要があります。これは、不均衡なトレーニングセットがある場合に特に役立ちます。</target>
        </trans-unit>
        <trans-unit id="969ca4bbce09cb3097e3db4dcee3ccac4fa12d57" translate="yes" xml:space="preserve">
          <source>If replacement is &lt;code&gt;True&lt;/code&gt;, samples are drawn with replacement.</source>
          <target state="translated">置換が &lt;code&gt;True&lt;/code&gt; の場合、サンプルは置換で抽出されます。</target>
        </trans-unit>
        <trans-unit id="484e62a9e6c54b0aaa3a5007d8a946f20da7704f" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;repeats&lt;/code&gt; is &lt;code&gt;tensor([n1, n2, n3, &amp;hellip;])&lt;/code&gt;, then the output will be &lt;code&gt;tensor([0, 0, &amp;hellip;, 1, 1, &amp;hellip;, 2, 2, &amp;hellip;, &amp;hellip;])&lt;/code&gt; where &lt;code&gt;0&lt;/code&gt; appears &lt;code&gt;n1&lt;/code&gt; times, &lt;code&gt;1&lt;/code&gt; appears &lt;code&gt;n2&lt;/code&gt; times, &lt;code&gt;2&lt;/code&gt; appears &lt;code&gt;n3&lt;/code&gt; times, etc.</source>
          <target state="translated">場合 &lt;code&gt;repeats&lt;/code&gt; ある &lt;code&gt;tensor([n1, n2, n3, &amp;hellip;])&lt;/code&gt; 、出力がされる &lt;code&gt;tensor([0, 0, &amp;hellip;, 1, 1, &amp;hellip;, 2, 2, &amp;hellip;, &amp;hellip;])&lt;/code&gt; &lt;code&gt;0&lt;/code&gt; が現れるの &lt;code&gt;n1&lt;/code&gt; 回、 &lt;code&gt;1&lt;/code&gt; が表示され &lt;code&gt;n2&lt;/code&gt; 回、 &lt;code&gt;2&lt;/code&gt; が表示されます &lt;code&gt;n3&lt;/code&gt; など回、</target>
        </trans-unit>
        <trans-unit id="5a469887feb69df132460464b530071b29b07521" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;self.data&lt;/code&gt; Tensor already has the correct &lt;code&gt;torch.dtype&lt;/code&gt; and &lt;code&gt;torch.device&lt;/code&gt;, then &lt;code&gt;self&lt;/code&gt; is returned. Otherwise, returns a copy with the desired configuration.</source>
          <target state="translated">場合 &lt;code&gt;self.data&lt;/code&gt; のテンソルはすでに正しい持ち &lt;code&gt;torch.dtype&lt;/code&gt; と &lt;code&gt;torch.device&lt;/code&gt; を、その後、 &lt;code&gt;self&lt;/code&gt; 返されます。それ以外の場合は、目的の構成のコピーを返します。</target>
        </trans-unit>
        <trans-unit id="5d823313d98ebbfc4cb390dd8145252b2ceb1eaf" translate="yes" xml:space="preserve">
          <source>If the &lt;code&gt;self&lt;/code&gt; Tensor already has the correct &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;, then &lt;code&gt;self&lt;/code&gt; is returned. Otherwise, the returned tensor is a copy of &lt;code&gt;self&lt;/code&gt; with the desired &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">場合は &lt;code&gt;self&lt;/code&gt; テンソルはすでに正しい持ち&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を&lt;/a&gt;、その後、 &lt;code&gt;self&lt;/code&gt; 返されます。それ以外の場合、返されるテンソルは、目的の&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; を&lt;/a&gt;持つ &lt;code&gt;self&lt;/code&gt; のコピーです。</target>
        </trans-unit>
        <trans-unit id="6b8c8166f7ac4def7f8a41f990435d7b737da1e1" translate="yes" xml:space="preserve">
          <source>If the RNN is bidirectional, num_directions should be 2, else it should be 1.</source>
          <target state="translated">RNNが双方向性の場合、num_directionsは2でなければならず、そうでなければ1でなければなりません。</target>
        </trans-unit>
        <trans-unit id="191802e65e024d3ca3eb1bca5bd908ca2613d6eb" translate="yes" xml:space="preserve">
          <source>If the current node is the owner, returns a reference to the local value. Otherwise, throws an exception.</source>
          <target state="translated">現在のノードが所有者の場合、ローカル値への参照を返します。そうでない場合は例外をスローします。</target>
        </trans-unit>
        <trans-unit id="9bc28fe59df6be023786ded1b0d7a664101bb1a6" translate="yes" xml:space="preserve">
          <source>If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.</source>
          <target state="translated">第 1 引数が 1 次元、第 2 引数が 2 次元の場合、行列の乗算のためにその次元に 1 が付加されます。行列の乗算の後、前置された次元は削除されます。</target>
        </trans-unit>
        <trans-unit id="805768ae7e7883adbd4eb9cfd347ff7553b939ce" translate="yes" xml:space="preserve">
          <source>If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.</source>
          <target state="translated">第1引数が2次元、第2引数が1次元の場合、行列-ベクトル積が返されます。</target>
        </trans-unit>
        <trans-unit id="603aa447ecbcf1ce44b939cf59f78b72d62d8d4f" translate="yes" xml:space="preserve">
          <source>If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype &lt;code&gt;torch.float16&lt;/code&gt; 4) V100 GPU is used, 5) input data is not in &lt;code&gt;PackedSequence&lt;/code&gt; format persistent algorithm can be selected to improve performance.</source>
          <target state="translated">次の条件が満たされている場合：1）cudnnが有効である、2）入力データがGPU上にある3）入力データがdtype &lt;code&gt;torch.float16&lt;/code&gt; を持っている4）V100 GPUが使用されている、5）入力データが &lt;code&gt;PackedSequence&lt;/code&gt; 形式ではない永続的なアルゴリズムパフォーマンスを向上させるために選択されました。</target>
        </trans-unit>
        <trans-unit id="787caec1c53ac744f6704113ef9317970b83ba1d" translate="yes" xml:space="preserve">
          <source>If the input argument is a tensor, but ONNX asks for a scalar, we have to explicitly do the conversion. The helper function &lt;code&gt;_scalar&lt;/code&gt; can convert a scalar tensor into a python scalar, and &lt;code&gt;_if_scalar_type_as&lt;/code&gt; can turn a Python scalar into a PyTorch tensor.</source>
          <target state="translated">入力引数がテンソルであるが、ONNXがスカラーを要求する場合、明示的に変換を行う必要があります。ヘルパー関数 &lt;code&gt;_scalar&lt;/code&gt; はスカラーテンソルをPythonスカラーに &lt;code&gt;_if_scalar_type_as&lt;/code&gt; でき、_if_scalar_type_asはPythonスカラーをPyTorchテンソルに変換できます。</target>
        </trans-unit>
        <trans-unit id="f988049101ff18d4e7918e66cf5ad5885aec7070" translate="yes" xml:space="preserve">
          <source>If the norm of a row is lower than &lt;code&gt;maxnorm&lt;/code&gt;, the row is unchanged</source>
          <target state="translated">行のノルムが &lt;code&gt;maxnorm&lt;/code&gt; よりも低い場合、行は変更されません</target>
        </trans-unit>
        <trans-unit id="d44fada1fe05f824e96651b70e1c4a292ba8a891" translate="yes" xml:space="preserve">
          <source>If the object is already present in &lt;code&gt;model_dir&lt;/code&gt;, it&amp;rsquo;s deserialized and returned. The default value of &lt;code&gt;model_dir&lt;/code&gt; is &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; where &lt;code&gt;hub_dir&lt;/code&gt; is the directory returned by &lt;a href=&quot;#torch.hub.get_dir&quot;&gt;&lt;code&gt;get_dir()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">オブジェクトがすでに &lt;code&gt;model_dir&lt;/code&gt; に存在する場合は、逆シリアル化されて返されます。 &lt;code&gt;model_dir&lt;/code&gt; のデフォルト値は &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; です。ここで、 &lt;code&gt;hub_dir&lt;/code&gt; は&lt;a href=&quot;#torch.hub.get_dir&quot;&gt; &lt;code&gt;get_dir()&lt;/code&gt; &lt;/a&gt;によって返されるディレクトリです。</target>
        </trans-unit>
        <trans-unit id="572431e231db065e224abcc587fb2e502c2edb94" translate="yes" xml:space="preserve">
          <source>If the object is already present in &lt;code&gt;model_dir&lt;/code&gt;, it&amp;rsquo;s deserialized and returned. The default value of &lt;code&gt;model_dir&lt;/code&gt; is &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; where &lt;code&gt;hub_dir&lt;/code&gt; is the directory returned by &lt;a href=&quot;hub#torch.hub.get_dir&quot;&gt;&lt;code&gt;get_dir()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">オブジェクトがすでに &lt;code&gt;model_dir&lt;/code&gt; に存在する場合は、逆シリアル化されて返されます。 &lt;code&gt;model_dir&lt;/code&gt; のデフォルト値は &lt;code&gt;&amp;lt;hub_dir&amp;gt;/checkpoints&lt;/code&gt; です。ここで、 &lt;code&gt;hub_dir&lt;/code&gt; は&lt;a href=&quot;hub#torch.hub.get_dir&quot;&gt; &lt;code&gt;get_dir()&lt;/code&gt; &lt;/a&gt;によって返されるディレクトリです。</target>
        </trans-unit>
        <trans-unit id="e07c64dd92353460c82bc7c43c0298ff2498e3ef" translate="yes" xml:space="preserve">
          <source>If the operator is a non-ATen operator, the symbolic function has to be added in the corresponding PyTorch Function class. Please read the following instructions:</source>
          <target state="translated">演算子が非ATen演算子の場合は、対応するPyTorch関数クラスにシンボリック関数を追加する必要があります。以下の説明を読んでください。</target>
        </trans-unit>
        <trans-unit id="8de0216c16416c65797272e400b10794b950ac17" translate="yes" xml:space="preserve">
          <source>If the operator is an ATen operator, which means you can find the declaration of the function in &lt;code&gt;torch/csrc/autograd/generated/VariableType.h&lt;/code&gt; (available in generated code in PyTorch install dir), you should add the symbolic function in &lt;code&gt;torch/onnx/symbolic_opset&amp;lt;version&amp;gt;.py&lt;/code&gt; and follow the instructions listed as below:</source>
          <target state="translated">オペレータはあなたが関数の宣言を見つけることができることを意味しATEN演算子の場合、 &lt;code&gt;torch/csrc/autograd/generated/VariableType.h&lt;/code&gt; （ディレクトリをインストールPyTorchで生成されたコードで入手可能）、あなたはシンボリック機能を追加する必要があり &lt;code&gt;torch/onnx/symbolic_opset&amp;lt;version&amp;gt;.py&lt;/code&gt; を実行し、以下の手順に従います。</target>
        </trans-unit>
        <trans-unit id="08987c5581da900d9050fec1b266346dd018ed86" translate="yes" xml:space="preserve">
          <source>If the sum to the power of &lt;code&gt;p&lt;/code&gt; is zero, the gradient of this function is not defined. This implementation will set the gradient to zero in this case.</source>
          <target state="translated">&lt;code&gt;p&lt;/code&gt; の累乗の合計がゼロの場合、この関数の勾配は定義されていません。この場合、この実装は勾配をゼロに設定します。</target>
        </trans-unit>
        <trans-unit id="a6455b98cbf68564852f3d65be9e3d85724ba33b" translate="yes" xml:space="preserve">
          <source>If the targets are given as a 1d tensor that is the concatenation of individual targets, the target_lengths must add up to the total length of the tensor.</source>
          <target state="translated">ターゲットが個々のターゲットを連結した1dテンソルとして与えられた場合、target_lengthsはテンソルの全長に加算されなければなりません。</target>
        </trans-unit>
        <trans-unit id="eb673583185e53bcc86746d0d9978c1392f01670" translate="yes" xml:space="preserve">
          <source>If the tensor has a batch dimension of size 1, then &lt;code&gt;squeeze(input)&lt;/code&gt; will also remove the batch dimension, which can lead to unexpected errors.</source>
          <target state="translated">テンソルのバッチ次元がサイズ1の場合、 &lt;code&gt;squeeze(input)&lt;/code&gt; はバッチ次元も削除するため、予期しないエラーが発生する可能性があります。</target>
        </trans-unit>
        <trans-unit id="67a5ac190ccd238f6283765db614cb7a1d643567" translate="yes" xml:space="preserve">
          <source>If the torch.fft module is imported then &amp;ldquo;torch.fft&amp;rdquo; will refer to the module and not this function. Use &lt;a href=&quot;../tensors#torch.Tensor.fft&quot;&gt;&lt;code&gt;torch.Tensor.fft()&lt;/code&gt;&lt;/a&gt; instead.</source>
          <target state="translated">torch.fftモジュールがインポートされた場合、「torch.fft」はこの関数ではなくモジュールを参照します。代わりに&lt;a href=&quot;../tensors#torch.Tensor.fft&quot;&gt; &lt;code&gt;torch.Tensor.fft()&lt;/code&gt; を&lt;/a&gt;使用してください。</target>
        </trans-unit>
        <trans-unit id="d413b6561145ebb882d59d64e1d5bb494eb94bfd" translate="yes" xml:space="preserve">
          <source>If the type of a scalar operand is of a higher category than tensor operands (where complex &amp;gt; floating &amp;gt; integral &amp;gt; boolean), we promote to a type with sufficient size to hold all scalar operands of that category.</source>
          <target state="translated">スカラーオペランドの型がテンソルオペランドよりも高いカテゴリ（複素数&amp;gt;浮動&amp;gt;積分&amp;gt;ブール）の場合、そのカテゴリのすべてのスカラーオペランドを保持するのに十分なサイズの型に昇格します。</target>
        </trans-unit>
        <trans-unit id="1fdbc94ec5c6bbfaeab5c1df5a93f67f15cfdc84" translate="yes" xml:space="preserve">
          <source>If there are multiple maximal values in a reduced row then the indices of the first maximal value are returned.</source>
          <target state="translated">縮小された行の中に複数の最大値がある場合は、最初の最大値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="dffbe07ea95c30719f442abdb52cf12ce069da58" translate="yes" xml:space="preserve">
          <source>If there are multiple minimal values in a reduced row then the indices of the first minimal value are returned.</source>
          <target state="translated">縮小された行の中に複数の最小値がある場合は、最初の最小値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="c351680cf4894b25f49425f0d4d516d6d33a16ff" translate="yes" xml:space="preserve">
          <source>If there are multiple minimal values then the indices of the first minimal value are returned.</source>
          <target state="translated">複数の最小値がある場合は、最初の最小値のインデックスが返されます。</target>
        </trans-unit>
        <trans-unit id="7f03b96d2971ec564ed4f31e34caa43003898f1d" translate="yes" xml:space="preserve">
          <source>If there are no higher-category zero-dim operands, we promote to a type with sufficient size and category to hold all dimensioned operands.</source>
          <target state="translated">より高いカテゴリの0-dimオペランドが存在しない場合、すべての次元のオペランドを保持するのに十分なサイズとカテゴリを持つ型に昇格します。</target>
        </trans-unit>
        <trans-unit id="bc9e3883be4333b3f7486d77ab3655dd30a42ad7" translate="yes" xml:space="preserve">
          <source>If this is already of the correct type, no copy is performed and the original object is returned.</source>
          <target state="translated">これが既に正しい型であれば、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="ce68525cc568e97b080be8925035deeb766a0ee2" translate="yes" xml:space="preserve">
          <source>If this object is already in CPU memory and on the correct device, then no copy is performed and the original object is returned.</source>
          <target state="translated">このオブジェクトが既にCPUメモリ内にあり、正しいデバイス上にある場合、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="6788146c6f952e177f58c27fec835e0c0d256c8a" translate="yes" xml:space="preserve">
          <source>If this object is already in CUDA memory and on the correct device, then no copy is performed and the original object is returned.</source>
          <target state="translated">このオブジェクトが既にCUDAメモリ内にあり、正しいデバイス上にある場合、コピーは行われず、元のオブジェクトが返されます。</target>
        </trans-unit>
        <trans-unit id="7c50d408ff8252bcf7756ca41661606361f0e20e" translate="yes" xml:space="preserve">
          <source>If x1 has shape</source>
          <target state="translated">x1が形状を持っている場合</target>
        </trans-unit>
        <trans-unit id="c21dcebc3506f3faeef2282027b5db5536bb6293" translate="yes" xml:space="preserve">
          <source>If you are profiling CUDA code, the first profiler that &lt;code&gt;bottleneck&lt;/code&gt; runs (cProfile) will include the CUDA startup time (CUDA buffer allocation cost) in its time reporting. This should not matter if your bottlenecks result in code much slower than the CUDA startup time.</source>
          <target state="translated">CUDAコードをプロファイリングしている場合、 &lt;code&gt;bottleneck&lt;/code&gt; が実行される最初のプロファイラー（cProfile）は、時間レポートにCUDA起動時間（CUDAバッファー割り当てコスト）を含めます。ボトルネックによってコードがCUDAの起動時間よりもはるかに遅くなる場合、これは問題ではありません。</target>
        </trans-unit>
        <trans-unit id="bb09e45c509c395b596fc5d452b50e8440b313fe" translate="yes" xml:space="preserve">
          <source>If you are using DistributedDataParallel in conjunction with the &lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Distributed RPC Framework&lt;/a&gt;, you should always use &lt;a href=&quot;../rpc#torch.distributed.autograd.backward&quot;&gt;&lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt;&lt;/a&gt; to compute gradients and &lt;a href=&quot;../rpc#torch.distributed.optim.DistributedOptimizer&quot;&gt;&lt;code&gt;torch.distributed.optim.DistributedOptimizer&lt;/code&gt;&lt;/a&gt; for optimizing parameters.</source>
          <target state="translated">DistributedDataParallelをDistributedRPC &lt;a href=&quot;../rpc#distributed-rpc-framework&quot;&gt;Framework&lt;/a&gt;と組み合わせて使用​​している場合は、常に&lt;a href=&quot;../rpc#torch.distributed.autograd.backward&quot;&gt; &lt;code&gt;torch.distributed.autograd.backward()&lt;/code&gt; &lt;/a&gt;を使用して勾配を計算し、&lt;a href=&quot;../rpc#torch.distributed.optim.DistributedOptimizer&quot;&gt; &lt;code&gt;torch.distributed.optim.DistributedOptimizer&lt;/code&gt; &lt;/a&gt;を使用してパラメーターを最適化する必要があります。</target>
        </trans-unit>
        <trans-unit id="79878b7e0f390005d12ab18a0ff2e5e3bf2df40c" translate="yes" xml:space="preserve">
          <source>If you have more than one GPU on each node, when using the NCCL and Gloo backend, &lt;a href=&quot;#torch.distributed.broadcast_multigpu&quot;&gt;&lt;code&gt;broadcast_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt;&lt;code&gt;all_reduce_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.reduce_multigpu&quot;&gt;&lt;code&gt;reduce_multigpu()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_gather_multigpu&quot;&gt;&lt;code&gt;all_gather_multigpu()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.distributed.reduce_scatter_multigpu&quot;&gt;&lt;code&gt;reduce_scatter_multigpu()&lt;/code&gt;&lt;/a&gt; support distributed collective operations among multiple GPUs within each node. These functions can potentially improve the overall distributed training performance and be easily used by passing a list of tensors. Each Tensor in the passed tensor list needs to be on a separate GPU device of the host where the function is called. Note that the length of the tensor list needs to be identical among all the distributed processes. Also note that currently the multi-GPU collective functions are only supported by the NCCL backend.</source>
          <target state="translated">各ノードに複数のGPUがある場合、NCCLおよびGlooバックエンドを使用すると、&lt;a href=&quot;#torch.distributed.broadcast_multigpu&quot;&gt; &lt;code&gt;broadcast_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_reduce_multigpu&quot;&gt; &lt;code&gt;all_reduce_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.reduce_multigpu&quot;&gt; &lt;code&gt;reduce_multigpu()&lt;/code&gt; &lt;/a&gt;&lt;a href=&quot;#torch.distributed.all_gather_multigpu&quot;&gt; &lt;code&gt;all_gather_multigpu()&lt;/code&gt; &lt;/a&gt;および&lt;a href=&quot;#torch.distributed.reduce_scatter_multigpu&quot;&gt; &lt;code&gt;reduce_scatter_multigpu()&lt;/code&gt; &lt;/a&gt;は、各ノード内の複数のGPU間で分散された集合操作をサポートします。これらの関数は、分散トレーニングの全体的なパフォーマンスを向上させる可能性があり、テンソルのリストを渡すことで簡単に使用できます。渡されたテンソルリスト内の各テンソルは、関数が呼び出されるホストの個別のGPUデバイス上にある必要があります。テンソルリストの長さは、すべての分散プロセス間で同一である必要があることに注意してください。また、現在、マルチGPUコレクティブ機能はNCCLバックエンドでのみサポートされていることにも注意してください。</target>
        </trans-unit>
        <trans-unit id="136147687478e135ab5df6494e85fb08cdedac29" translate="yes" xml:space="preserve">
          <source>If you plan on using this module with a &lt;code&gt;nccl&lt;/code&gt; backend or a &lt;code&gt;gloo&lt;/code&gt; backend (that uses Infiniband), together with a DataLoader that uses multiple workers, please change the multiprocessing start method to &lt;code&gt;forkserver&lt;/code&gt; (Python 3 only) or &lt;code&gt;spawn&lt;/code&gt;. Unfortunately Gloo (that uses Infiniband) and NCCL2 are not fork safe, and you will likely experience deadlocks if you don&amp;rsquo;t change this setting.</source>
          <target state="translated">このモジュールを &lt;code&gt;nccl&lt;/code&gt; バックエンドまたは &lt;code&gt;gloo&lt;/code&gt; バックエンド（Infinibandを使用）と、複数のワーカーを使用するDataLoaderとともに使用する場合は、マルチプロセッシングの開始メソッドを &lt;code&gt;forkserver&lt;/code&gt; （Python 3のみ）または &lt;code&gt;spawn&lt;/code&gt; に変更してください。残念ながら、Gloo（Infinibandを使用）とNCCL2はフォークセーフではないため、この設定を変更しないとデッドロックが発生する可能性があります。</target>
        </trans-unit>
        <trans-unit id="07ab34f8fafef28d79bd246f9789bf5105b86f8b" translate="yes" xml:space="preserve">
          <source>If you plan to backpropagate through QR, note that the current backward implementation is only well-defined when the first</source>
          <target state="translated">QR を使ってバックプロパゲーションを行う予定の場合、現在のバックプロパゲーションの実装は、最初の</target>
        </trans-unit>
        <trans-unit id="1cd7b6977f27c5a4e9182f95ff2f859a518a8917" translate="yes" xml:space="preserve">
          <source>If you use &lt;code&gt;torch.save&lt;/code&gt; on one process to checkpoint the module, and &lt;code&gt;torch.load&lt;/code&gt; on some other processes to recover it, make sure that &lt;code&gt;map_location&lt;/code&gt; is configured properly for every process. Without &lt;code&gt;map_location&lt;/code&gt;, &lt;code&gt;torch.load&lt;/code&gt; would recover the module to devices where the module was saved from.</source>
          <target state="translated">1つのプロセスで &lt;code&gt;torch.save&lt;/code&gt; を使用してモジュールをチェックポイントし、他のいくつかのプロセスで &lt;code&gt;torch.load&lt;/code&gt; を使用してモジュールを回復する場合は、 &lt;code&gt;map_location&lt;/code&gt; がすべてのプロセスに対して適切に構成されていることを確認してください。 &lt;code&gt;torch.load&lt;/code&gt; がない &lt;code&gt;map_location&lt;/code&gt; 、torch.loadは、モジュールが保存されたデバイスにモジュールを回復します。</target>
        </trans-unit>
        <trans-unit id="74c65669b6d4e5ce564cda9931810dc0c170c246" translate="yes" xml:space="preserve">
          <source>If you want downsampling/general resizing, you should use &lt;code&gt;interpolate()&lt;/code&gt;.</source>
          <target state="translated">ダウンサンプリング/一般的なサイズ変更が必要な場合は、 &lt;code&gt;interpolate()&lt;/code&gt; を使用する必要があります。</target>
        </trans-unit>
        <trans-unit id="064ec7b53383c8d17c5751c9a34c0ac9daf7e8cd" translate="yes" xml:space="preserve">
          <source>If you&amp;rsquo;re using the Gloo backend, you can specify multiple interfaces by separating them by a comma, like this: &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3&lt;/code&gt;. The backend will dispatch operations in a round-robin fashion across these interfaces. It is imperative that all processes specify the same number of interfaces in this variable.</source>
          <target state="translated">Glooバックエンドを使用している場合は、次のように、複数のインターフェイスをカンマで区切って指定できます： &lt;code&gt;export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3&lt;/code&gt; 。バックエンドは、これらのインターフェイス間でラウンドロビン方式で操作をディスパッチします。すべてのプロセスがこの変数に同じ数のインターフェースを指定することが不可欠です。</target>
        </trans-unit>
        <trans-unit id="40a9a99bd41d3dd35eb2ee9f7f247c013023dc94" translate="yes" xml:space="preserve">
          <source>If your InfiniBand has enabled IP over IB, use Gloo, otherwise, use MPI instead. We are planning on adding InfiniBand support for Gloo in the upcoming releases.</source>
          <target state="translated">InfiniBandでIP over IBを有効にしている場合はGlooを使用し、そうでない場合はMPIを使用してください。今後のリリースでは、GlooのInfiniBandサポートを追加する予定です。</target>
        </trans-unit>
        <trans-unit id="7ea2434c9b9d3a93397a8c29208e88de7aacbec3" translate="yes" xml:space="preserve">
          <source>If your use case is always 1-D sorted sequence, &lt;a href=&quot;torch.bucketize#torch.bucketize&quot;&gt;&lt;code&gt;torch.bucketize()&lt;/code&gt;&lt;/a&gt; is preferred, because it has fewer dimension checks resulting in slightly better performance.</source>
          <target state="translated">ユースケースが常に1次元でソートされたシーケンスである場合は、次元チェックが少なく、パフォーマンスがわずかに向上するため、&lt;a href=&quot;torch.bucketize#torch.bucketize&quot;&gt; &lt;code&gt;torch.bucketize()&lt;/code&gt; &lt;/a&gt;が推奨されます。</target>
        </trans-unit>
        <trans-unit id="eec64bb7b6af56628b6864bb7faf7664a4d5fe90" translate="yes" xml:space="preserve">
          <source>Ignoring the optional batch dimension, this method computes the following expression:</source>
          <target state="translated">オプションのバッチ次元を無視して、このメソッドは以下の式を計算します。</target>
        </trans-unit>
        <trans-unit id="d5e7e82cbad5c6c7282eb3f91a5d122dc9858f8e" translate="yes" xml:space="preserve">
          <source>ImageNet 1-crop error rates (224x224)</source>
          <target state="translated">ImageNet 1クロップエラーレート(224x224</target>
        </trans-unit>
        <trans-unit id="8781d615fd77be9578225c40ac67b9471394cced" translate="yes" xml:space="preserve">
          <source>Implementation</source>
          <target state="translated">Implementation</target>
        </trans-unit>
        <trans-unit id="7aa6ad27b14b39704b337bb5273a54caf43dd27d" translate="yes" xml:space="preserve">
          <source>Implementation details: &lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https://arxiv.org/pdf/1806.08342.pdf&lt;/a&gt;</source>
          <target state="translated">実装の詳細：&lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https&lt;/a&gt;：//arxiv.org/pdf/1806.08342.pdf</target>
        </trans-unit>
        <trans-unit id="e2301206e5db52d9fb3a1373c4f2d128cbca7b09" translate="yes" xml:space="preserve">
          <source>Implementation details: &lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https://arxiv.org/pdf/1806.08342.pdf&lt;/a&gt; section 3.2.2</source>
          <target state="translated">実装の詳細：&lt;a href=&quot;https://arxiv.org/pdf/1806.08342.pdf&quot;&gt;https&lt;/a&gt;：//arxiv.org/pdf/1806.08342.pdfセクション3.2.2</target>
        </trans-unit>
        <trans-unit id="123ad8e975b9151926be8910a7ca29c06e0a08b2" translate="yes" xml:space="preserve">
          <source>Implementing a Parameter Server using Distributed RPC Framework</source>
          <target state="translated">分散RPCフレームワークを使用したパラメータサーバの実装</target>
        </trans-unit>
        <trans-unit id="44171a5d0f5320fd21c59c6c6516557d63659e70" translate="yes" xml:space="preserve">
          <source>Implementing batch RPC processing</source>
          <target state="translated">バッチRPC処理の実装</target>
        </trans-unit>
        <trans-unit id="9f29957e1ffbfbf9022787fc2c7cfe246141046c" translate="yes" xml:space="preserve">
          <source>Implements data parallelism at the module level.</source>
          <target state="translated">モジュールレベルでのデータ並列処理を実装します。</target>
        </trans-unit>
        <trans-unit id="247ad11e0e8ab7f7233963e6adbe7062bce23a44" translate="yes" xml:space="preserve">
          <source>Implements distributed data parallelism that is based on &lt;code&gt;torch.distributed&lt;/code&gt; package at the module level.</source>
          <target state="translated">モジュールレベルで &lt;code&gt;torch.distributed&lt;/code&gt; パッケージに基づく分散データ並列処理を実装します。</target>
        </trans-unit>
        <trans-unit id="1ac98376b8dde644a48731cdda5a6c2f0a79cf77" translate="yes" xml:space="preserve">
          <source>Important Notice</source>
          <target state="translated">重要なお知らせ</target>
        </trans-unit>
        <trans-unit id="dbea8ebe841db621fdf156d683ca479b155b0a0f" translate="yes" xml:space="preserve">
          <source>Important consideration in the parameters &lt;code&gt;window&lt;/code&gt; and &lt;code&gt;center&lt;/code&gt; so that the envelop created by the summation of all the windows is never zero at certain point in time. Specifically,</source>
          <target state="translated">すべてのウィンドウの合計によって作成されたエンベロープが特定の時点でゼロにならないように、パラメータ &lt;code&gt;window&lt;/code&gt; と &lt;code&gt;center&lt;/code&gt; で重要な考慮事項。具体的には、</target>
        </trans-unit>
        <trans-unit id="1546cf194023a313eda4a32e23fe8da2e85133d5" translate="yes" xml:space="preserve">
          <source>In a multilayer GRU, the input</source>
          <target state="translated">多層GRUでは、入力</target>
        </trans-unit>
        <trans-unit id="4ca4b7a5c3d05548dd2f62668a8daeab0e9ec06f" translate="yes" xml:space="preserve">
          <source>In a multilayer LSTM, the input</source>
          <target state="translated">多層LSTMでは、入力</target>
        </trans-unit>
        <trans-unit id="e20dc20835fec339c1d3cc16c346bd578e3d90d9" translate="yes" xml:space="preserve">
          <source>In addition to bools, floats, ints, and Tensors can be used in a conditional and will be implicitly casted to a boolean.</source>
          <target state="translated">bool以外にも、float、int、およびTensorsが条件付きで使用でき、暗黙のうちにbooleanにキャストされます。</target>
        </trans-unit>
        <trans-unit id="14b2f80199ae20e9c340149a30176ab138c9610a" translate="yes" xml:space="preserve">
          <source>In both cases of single-node distributed training or multi-node distributed training, this utility will launch the given number of processes per node (&lt;code&gt;--nproc_per_node&lt;/code&gt;). If used for GPU training, this number needs to be less or equal to the number of GPUs on the current system (&lt;code&gt;nproc_per_node&lt;/code&gt;), and each process will be operating on a single GPU from &lt;em&gt;GPU 0 to GPU (nproc_per_node - 1)&lt;/em&gt;.</source>
          <target state="translated">シングルノード分散トレーニングまたはマルチノード分散トレーニングのどちらの場合も、このユーティリティはノードごとに指定された数のプロセスを起動します（ &lt;code&gt;--nproc_per_node&lt;/code&gt; ）。GPUトレーニングに使用する場合、この数は現在のシステムのGPUの数（ &lt;code&gt;nproc_per_node&lt;/code&gt; ）以下である必要があり、各プロセスは&lt;em&gt;GPU 0からGPU（nproc_per_node -1）&lt;/em&gt;までの単一のGPUで動作します。</target>
        </trans-unit>
        <trans-unit id="0e876cc3bbe05952d2705985bee305b58baf29ac" translate="yes" xml:space="preserve">
          <source>In cases like these, tracing would not be appropriate and &lt;a href=&quot;torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;scripting&lt;/code&gt;&lt;/a&gt; is a better choice. If you trace such models, you may silently get incorrect results on subsequent invocations of the model. The tracer will try to emit warnings when doing something that may cause an incorrect trace to be produced.</source>
          <target state="translated">このような場合、トレースは適切ではなく、&lt;a href=&quot;torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;scripting&lt;/code&gt; &lt;/a&gt;を使用することをお勧めします。このようなモデルをトレースすると、その後のモデルの呼び出しでサイレントに誤った結果が得られる可能性があります。トレーサーは、誤ったトレースが生成される原因となる可能性のある処理を実行すると、警告を発しようとします。</target>
        </trans-unit>
        <trans-unit id="86e76c5e72e3158e53103708c732b0ca2fb77314" translate="yes" xml:space="preserve">
          <source>In default &lt;code&gt;reduction&lt;/code&gt; mode &lt;code&gt;'mean'&lt;/code&gt;, the losses are averaged for each minibatch over observations &lt;strong&gt;as well as&lt;/strong&gt; over dimensions. &lt;code&gt;'batchmean'&lt;/code&gt; mode gives the correct KL divergence where losses are averaged over batch dimension only. &lt;code&gt;'mean'&lt;/code&gt; mode&amp;rsquo;s behavior will be changed to the same as &lt;code&gt;'batchmean'&lt;/code&gt; in the next major release.</source>
          <target state="translated">デフォルトの &lt;code&gt;reduction&lt;/code&gt; モード &lt;code&gt;'mean'&lt;/code&gt; では、損失は、観測値&lt;strong&gt;および&lt;/strong&gt;次元全体のミニバッチごとに平均化&lt;strong&gt;さ&lt;/strong&gt;れます。 &lt;code&gt;'batchmean'&lt;/code&gt; モードは、損失がバッチ次元でのみ平均化される正しいKL発散を提供します。 &lt;code&gt;'mean'&lt;/code&gt; モードの動作は、次のメジャーリリースで &lt;code&gt;'batchmean'&lt;/code&gt; と同じに変更されます。</target>
        </trans-unit>
        <trans-unit id="d7469a9738cf72345e41f4a9561f6407dd3c1952" translate="yes" xml:space="preserve">
          <source>In each forward, &lt;code&gt;module&lt;/code&gt; is &lt;strong&gt;replicated&lt;/strong&gt; on each device, so any updates to the running module in &lt;code&gt;forward&lt;/code&gt; will be lost. For example, if &lt;code&gt;module&lt;/code&gt; has a counter attribute that is incremented in each &lt;code&gt;forward&lt;/code&gt;, it will always stay at the initial value because the update is done on the replicas which are destroyed after &lt;code&gt;forward&lt;/code&gt;. However, &lt;a href=&quot;#torch.nn.DataParallel&quot;&gt;&lt;code&gt;DataParallel&lt;/code&gt;&lt;/a&gt; guarantees that the replica on &lt;code&gt;device[0]&lt;/code&gt; will have its parameters and buffers sharing storage with the base parallelized &lt;code&gt;module&lt;/code&gt;. So &lt;strong&gt;in-place&lt;/strong&gt; updates to the parameters or buffers on &lt;code&gt;device[0]&lt;/code&gt; will be recorded. E.g., &lt;a href=&quot;torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt;&lt;code&gt;BatchNorm2d&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.utils.spectral_norm#torch.nn.utils.spectral_norm&quot;&gt;&lt;code&gt;spectral_norm()&lt;/code&gt;&lt;/a&gt; rely on this behavior to update the buffers.</source>
          <target state="translated">フォワードごとに、 &lt;code&gt;module&lt;/code&gt; は各デバイスに&lt;strong&gt;複製&lt;/strong&gt;されるため、 &lt;code&gt;forward&lt;/code&gt; 実行中のモジュールへの更新はすべて失われます。たとえば、 &lt;code&gt;module&lt;/code&gt; それぞれにインクリメントされるカウンタの属性があり &lt;code&gt;forward&lt;/code&gt; 更新が後に破壊されたレプリカ上で行われているので、それは常に初期値に滞在する &lt;code&gt;forward&lt;/code&gt; 。ただし、&lt;a href=&quot;#torch.nn.DataParallel&quot;&gt; &lt;code&gt;DataParallel&lt;/code&gt; &lt;/a&gt;は、 &lt;code&gt;device[0]&lt;/code&gt; 上のレプリカが、ベースの並列化 &lt;code&gt;module&lt;/code&gt; とストレージを共有するパラメーターとバッファーを持つことを保証します。そのため、 &lt;code&gt;device[0]&lt;/code&gt; パラメーターまたはバッファーに対する&lt;strong&gt;インプレース&lt;/strong&gt;更新が記録されます。例えば、&lt;a href=&quot;torch.nn.batchnorm2d#torch.nn.BatchNorm2d&quot;&gt; &lt;code&gt;BatchNorm2d&lt;/code&gt; &lt;/a&gt;とspectrum_norm &lt;a href=&quot;torch.nn.utils.spectral_norm#torch.nn.utils.spectral_norm&quot;&gt; &lt;code&gt;spectral_norm()&lt;/code&gt; &lt;/a&gt;、この動作に依存してバッファーを更新します。</target>
        </trans-unit>
        <trans-unit id="c4c7ae6e45efeeb88e3de47cc32025f3afeae3d6" translate="yes" xml:space="preserve">
          <source>In general, folding and unfolding operations are related as follows. Consider &lt;a href=&quot;#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; instances created with the same parameters:</source>
          <target state="translated">一般に、折り畳み操作と展開操作は次のように関連しています。同じパラメーターで作成された&lt;a href=&quot;#torch.nn.Fold&quot;&gt; &lt;code&gt;Fold&lt;/code&gt; &lt;/a&gt;インスタンスと&lt;a href=&quot;torch.nn.unfold#torch.nn.Unfold&quot;&gt; &lt;code&gt;Unfold&lt;/code&gt; &lt;/a&gt;インスタンスについて考えてみます。</target>
        </trans-unit>
        <trans-unit id="14a82233b9f46d949d131d9066b4b1e345f4a14b" translate="yes" xml:space="preserve">
          <source>In general, folding and unfolding operations are related as follows. Consider &lt;a href=&quot;torch.nn.fold#torch.nn.Fold&quot;&gt;&lt;code&gt;Fold&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.nn.Unfold&quot;&gt;&lt;code&gt;Unfold&lt;/code&gt;&lt;/a&gt; instances created with the same parameters:</source>
          <target state="translated">一般に、折り畳み操作と展開操作は次のように関連しています。同じパラメーターで作成された&lt;a href=&quot;torch.nn.fold#torch.nn.Fold&quot;&gt; &lt;code&gt;Fold&lt;/code&gt; &lt;/a&gt;インスタンスと&lt;a href=&quot;#torch.nn.Unfold&quot;&gt; &lt;code&gt;Unfold&lt;/code&gt; &lt;/a&gt;インスタンスについて考えてみます。</target>
        </trans-unit>
        <trans-unit id="1855810e3cc280e259c5b815913beac56d322de4" translate="yes" xml:space="preserve">
          <source>In general, the basic method spends least time per iteration. However, the robust methods converge much faster and are more stable. So, the usage of the basic method is generally not recommended but there exist cases where the usage of the basic method may be preferred.</source>
          <target state="translated">一般的に、基本的な方法は、繰り返しあたりの時間が最も短くなります。しかし、ロバスト法はより速く収束し、より安定しています。そのため、基本法の使用は一般的に推奨されませんが、基本法の使用が好ましい場合もあります。</target>
        </trans-unit>
        <trans-unit id="5a8901639688080e9ddf9086d6c38d66aa6d29ff" translate="yes" xml:space="preserve">
          <source>In general, use the full-rank SVD implementation &lt;code&gt;torch.svd&lt;/code&gt; for dense matrices due to its 10-fold higher performance characteristics. The low-rank SVD will be useful for huge sparse matrices that &lt;code&gt;torch.svd&lt;/code&gt; cannot handle.</source>
          <target state="translated">一般に、10倍高いパフォーマンス特性があるため、密行列にはフルランクのSVD実装 &lt;code&gt;torch.svd&lt;/code&gt; を使用します。低ランクのSVDは、 &lt;code&gt;torch.svd&lt;/code&gt; が処理できない巨大なスパース行列に役立ちます。</target>
        </trans-unit>
        <trans-unit id="809a8a0c78ca14c8503127d00dd103ee7f6c80b0" translate="yes" xml:space="preserve">
          <source>In many cases either tracing or scripting is an easier approach for converting a model to TorchScript. Tracing and scripting can be composed to suit the particular requirements of a part of a model.</source>
          <target state="translated">多くの場合、モデルをTorchScriptに変換するには、トレースまたはスクリプトのどちらかの方が簡単な方法です。トレースとスクリプトは、モデルの一部の特定の要件に合わせて構成することができます。</target>
        </trans-unit>
        <trans-unit id="6485ce8afe7564cea5c8362029901ba50e16aea8" translate="yes" xml:space="preserve">
          <source>In order to spawn up multiple processes per node, you can use either &lt;code&gt;torch.distributed.launch&lt;/code&gt; or &lt;code&gt;torch.multiprocessing.spawn&lt;/code&gt;.</source>
          <target state="translated">ノードごとに複数のプロセスを生成するには、 &lt;code&gt;torch.distributed.launch&lt;/code&gt; または &lt;code&gt;torch.multiprocessing.spawn&lt;/code&gt; のいずれかを使用できます。</target>
        </trans-unit>
        <trans-unit id="40c808fe1c4d6bdfde7e41f404147333e778923e" translate="yes" xml:space="preserve">
          <source>In order to use CuDNN, the following must be satisfied: &lt;code&gt;targets&lt;/code&gt; must be in concatenated format, all &lt;code&gt;input_lengths&lt;/code&gt; must be &lt;code&gt;T&lt;/code&gt;.</source>
          <target state="translated">CuDNNを使用するには、次の条件を満たす必要があります。 &lt;code&gt;targets&lt;/code&gt; は連結形式である必要があり、すべての &lt;code&gt;input_lengths&lt;/code&gt; は &lt;code&gt;T&lt;/code&gt; である必要があります。</target>
        </trans-unit>
        <trans-unit id="5224913092c4a84680bc86a2c5b52f3a9390a2e0" translate="yes" xml:space="preserve">
          <source>In other words, for an input of size</source>
          <target state="translated">言い換えれば、サイズの入力に対して</target>
        </trans-unit>
        <trans-unit id="6f63e1b44e4587b6cbe87da3c99588530141677e" translate="yes" xml:space="preserve">
          <source>In particular, solves</source>
          <target state="translated">具体的には、以下のような問題を解決します。</target>
        </trans-unit>
        <trans-unit id="1cb4118455a2bb7d53d0e1417d8853260cb96078" translate="yes" xml:space="preserve">
          <source>In practice, when working with named tensors, one should avoid having unnamed dimensions because their handling can be complicated. It is recommended to lift all unnamed dimensions to be named dimensions by using &lt;a href=&quot;#torch.Tensor.refine_names&quot;&gt;&lt;code&gt;refine_names()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">実際には、名前付きテンソルを使用する場合、処理が複雑になる可能性があるため、名前なしの次元を使用しないようにする必要があります。&lt;a href=&quot;#torch.Tensor.refine_names&quot;&gt; &lt;code&gt;refine_names()&lt;/code&gt; &lt;/a&gt;を使用して、名前のないすべてのディメンションを持ち上げて名前の付いたディメンションにすることをお勧めします。</target>
        </trans-unit>
        <trans-unit id="df5ee95eb608e3ef9c532ed1dab9ce8f7003c283" translate="yes" xml:space="preserve">
          <source>In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting &lt;code&gt;torch.backends.cudnn.deterministic =
True&lt;/code&gt;. Please see the notes on &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;Reproducibility&lt;/a&gt; for background.</source>
          <target state="translated">状況によっては、CuDNNでCUDAバックエンドを使用する場合、この演算子はパフォーマンスを向上させるために非決定論的アルゴリズムを選択する場合があります。これが望ましくない場合は、 &lt;code&gt;torch.backends.cudnn.deterministic = True&lt;/code&gt; 設定することで、操作を決定論的にすることができます（パフォーマンスコストがかかる可能性があります）。背景については、&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/randomness.html&quot;&gt;再現性&lt;/a&gt;に関する注記を参照してください。</target>
        </trans-unit>
        <trans-unit id="e14a819b75469318610313772eb13bce47023e07" translate="yes" xml:space="preserve">
          <source>In the above example, aten::triu is not supported in ONNX, hence exporter falls back on this op. OperatorExportTypes.RAW: Export raw ir. OperatorExportTypes.ONNX_FALLTHROUGH: If an op is not supported in ONNX, fall through and export the operator as is, as a custom ONNX op. Using this mode, the op can be exported and implemented by the user for their runtime backend. Example graph:</source>
          <target state="translated">上記の例では、aten::triuはONNXではサポートされていないため、エクスポートはこのオペランドにフォールバックします。OperatorExportTypes.RAW:raw irをエクスポートします。OperatorExportTypes.ONNX_FALLTHROUGH:オペレータがONNXでサポートされていない場合、フォールスルーして、オペレータをそのままカスタムONNXオペレータとしてエクスポートします。このモードを使用すると、ユーザーはランタイムバックエンド用に演算子をエクスポートして実装することができます。グラフの例。</target>
        </trans-unit>
        <trans-unit id="b3a5fd174642790bebe72eca626e159e3e5dfcd8" translate="yes" xml:space="preserve">
          <source>In the above example, prim::ListConstruct is not supported, hence exporter falls through.</source>
          <target state="translated">上記の例では、prim::ListConstruct はサポートされていません。</target>
        </trans-unit>
        <trans-unit id="7c25e2887a622adc243b3c60db24b8cbea2277b3" translate="yes" xml:space="preserve">
          <source>In the case of batches of square matrices with size less or equal to 32 on a CUDA device, the LU factorization is repeated for singular matrices due to the bug in the MAGMA library (see magma issue 13).</source>
          <target state="translated">CUDAデバイス上でサイズが32以下の正方行列のバッチの場合、MAGMAライブラリのバグにより、特異行列に対してLU因数分解が繰り返されます(magma第13号を参照)。</target>
        </trans-unit>
        <trans-unit id="7889605442c466f81697836a1b9ec1edd9e39e26" translate="yes" xml:space="preserve">
          <source>In the following table, we use 8 V100 GPUs, with CUDA 10.0 and CUDNN 7.4 to report the results. During training, we use a batch size of 2 per GPU, and during testing a batch size of 1 is used.</source>
          <target state="translated">以下の表では、8台のV100 GPUを使用し、CUDA 10.0とCUDNN 7.4で結果を報告します。トレーニング時にはGPUごとに2のバッチサイズを使用し、テスト時には1のバッチサイズを使用しています。</target>
        </trans-unit>
        <trans-unit id="33fa5776db9b9bbfad4e856c392d72e978768794" translate="yes" xml:space="preserve">
          <source>In the future, &lt;a href=&quot;#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt; may return a non-writeable view for an &lt;code&gt;input&lt;/code&gt; of non-complex dtype. It&amp;rsquo;s recommended that programs not modify the tensor returned by &lt;a href=&quot;#torch.conj&quot;&gt;&lt;code&gt;torch.conj()&lt;/code&gt;&lt;/a&gt; when &lt;code&gt;input&lt;/code&gt; is of non-complex dtype to be compatible with this change.</source>
          <target state="translated">将来、&lt;a href=&quot;#torch.conj&quot;&gt; &lt;code&gt;torch.conj()&lt;/code&gt; &lt;/a&gt;は、複雑でないdtypeの &lt;code&gt;input&lt;/code&gt; に対して書き込み不可能なビューを返す可能性があります。この変更と互換性があるように、 &lt;code&gt;input&lt;/code&gt; が非複雑なdtypeの場合、プログラムは&lt;a href=&quot;#torch.conj&quot;&gt; &lt;code&gt;torch.conj()&lt;/code&gt; &lt;/a&gt;によって返されるテンソルを変更しないことをお勧めします。</target>
        </trans-unit>
        <trans-unit id="99f1ee81dc5eba42240face3c5c428f4a78edd8a" translate="yes" xml:space="preserve">
          <source>In the future, there will be backends for other frameworks as well.</source>
          <target state="translated">将来的には、他のフレームワークのバックエンドも用意する予定です。</target>
        </trans-unit>
        <trans-unit id="d25cb11f14e2999086551374695bf04a7bfaf842" translate="yes" xml:space="preserve">
          <source>In the past, we were often asked: &amp;ldquo;which backend should I use?&amp;rdquo;.</source>
          <target state="translated">以前は、「どのバックエンドを使用すればよいですか？」とよく聞かれました。</target>
        </trans-unit>
        <trans-unit id="0b0a51e5781bdbc893d9a5aff9fe6d5b37f0885c" translate="yes" xml:space="preserve">
          <source>In the returned &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;, operations that have different behaviors in &lt;code&gt;training&lt;/code&gt; and &lt;code&gt;eval&lt;/code&gt; modes will always behave as if it is in the mode it was in during tracing, no matter which mode the &lt;code&gt;ScriptModule&lt;/code&gt; is in.</source>
          <target state="translated">返された&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;では、 &lt;code&gt;training&lt;/code&gt; モードと &lt;code&gt;eval&lt;/code&gt; モードで動作が異なる操作は、 &lt;code&gt;ScriptModule&lt;/code&gt; がどのモードにあるかに関係なく、トレース中にあったモードにあるかのように常に動作します。</target>
        </trans-unit>
        <trans-unit id="b3daaa94feed4c186e9e9a97512618fa018aae7f" translate="yes" xml:space="preserve">
          <source>In the simplest case, the output value of the layer with input size</source>
          <target state="translated">最も単純なケースでは、入力サイズを持つレイヤの出力値</target>
        </trans-unit>
        <trans-unit id="239b7a59f23d668ac60e6721fee439268e244221" translate="yes" xml:space="preserve">
          <source>In the single-machine synchronous case, &lt;code&gt;torch.distributed&lt;/code&gt; or the &lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt;&lt;/a&gt; wrapper may still have advantages over other approaches to data-parallelism, including &lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt;&lt;code&gt;torch.nn.DataParallel()&lt;/code&gt;&lt;/a&gt;:</source>
          <target state="translated">単一マシンの同期の場合、 &lt;code&gt;torch.distributed&lt;/code&gt; または&lt;a href=&quot;generated/torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;torch.nn.parallel.DistributedDataParallel()&lt;/code&gt; &lt;/a&gt;ラッパーは、&lt;a href=&quot;generated/torch.nn.dataparallel#torch.nn.DataParallel&quot;&gt; &lt;code&gt;torch.nn.DataParallel()&lt;/code&gt; &lt;/a&gt;を含むデータ並列処理の他のアプローチよりも優れている場合があります。</target>
        </trans-unit>
        <trans-unit id="1e133f6f146acb51fdcd21b510ff4101dead133b" translate="yes" xml:space="preserve">
          <source>In the spatial (4-D) case, for &lt;code&gt;input&lt;/code&gt; with shape</source>
          <target state="translated">空間（4-D）の場合、形状を使用した &lt;code&gt;input&lt;/code&gt; 場合</target>
        </trans-unit>
        <trans-unit id="51ee81d82611ed15672cbe78ad3be970f77568fa" translate="yes" xml:space="preserve">
          <source>In the symbolic function, if the operator is already standardized in ONNX, we just need to create a node to represent the ONNX operator in the graph.</source>
          <target state="translated">シンボリック関数では、既にONNXで標準化されている演算子であれば、ONNXの演算子をグラフで表現するためのノードを作成するだけでよい。</target>
        </trans-unit>
        <trans-unit id="05f2edf0966166823005056e0975e4e593b57b37" translate="yes" xml:space="preserve">
          <source>In the symbolic function, if the operator is already standardized in ONNX, we only need to create a node to represent the ONNX operator in the graph.</source>
          <target state="translated">シンボリック関数では、ONNXで既に標準化されている演算子であれば、ONNXの演算子をグラフで表現するためのノードを作成するだけでよい。</target>
        </trans-unit>
        <trans-unit id="c41d2ba36e63a36e43970f33786546314d161009" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;nn.Dropout2d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">In this case, &lt;code&gt;nn.Dropout2d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="df2da228c2bd90611f132d29496ecf7b2c5d7aaa" translate="yes" xml:space="preserve">
          <source>In this case, &lt;code&gt;nn.Dropout3d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</source>
          <target state="translated">In this case, &lt;code&gt;nn.Dropout3d()&lt;/code&gt; will help promote independence between feature maps and should be used instead.</target>
        </trans-unit>
        <trans-unit id="f8b3c9fa943c89a945d6617acdfae17b22a6204e" translate="yes" xml:space="preserve">
          <source>In this case, data-dependent control flow like this can be captured using &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;torch.jit.script()&lt;/code&gt;&lt;/a&gt; instead:</source>
          <target state="translated">In this case, data-dependent control flow like this can be captured using &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;torch.jit.script()&lt;/code&gt; &lt;/a&gt; instead:</target>
        </trans-unit>
        <trans-unit id="85295238e8aebda5327b95ca72369c8df3c9eab9" translate="yes" xml:space="preserve">
          <source>In this mode, the result of every computation will have &lt;code&gt;requires_grad=False&lt;/code&gt;, even when the inputs have &lt;code&gt;requires_grad=True&lt;/code&gt;.</source>
          <target state="translated">In this mode, the result of every computation will have &lt;code&gt;requires_grad=False&lt;/code&gt; , even when the inputs have &lt;code&gt;requires_grad=True&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="91c8c0bce1c0356637c4656cf0a0cca8ed0c2a41" translate="yes" xml:space="preserve">
          <source>In this section please find the documentation for named tensor specific APIs. For a comprehensive reference for how names are propagated through other PyTorch operators, see &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt;.</source>
          <target state="translated">In this section please find the documentation for named tensor specific APIs. For a comprehensive reference for how names are propagated through other PyTorch operators, see &lt;a href=&quot;name_inference#name-inference-reference-doc&quot;&gt;Named Tensors operator coverage&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="13102db919fdc00f95907c16ae125b4a1f45c313" translate="yes" xml:space="preserve">
          <source>In version 1.6 changed to this from set_training</source>
          <target state="translated">バージョン1.6では、set_trainingからこれに変更されました。</target>
        </trans-unit>
        <trans-unit id="90ef0f5bd340db15b402881b337b9e6fd1b54dd1" translate="yes" xml:space="preserve">
          <source>In-place random sampling</source>
          <target state="translated">インプレイスランダムサンプリング</target>
        </trans-unit>
        <trans-unit id="1723c07101158e28ed701a45820ffb2cbec954ae" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.abs&quot;&gt;&lt;code&gt;abs()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.abs&quot;&gt; &lt;code&gt;abs()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="24948f16983220b792808971db48b1bcdd5b3fa1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.absolute&quot;&gt;&lt;code&gt;absolute()&lt;/code&gt;&lt;/a&gt; Alias for &lt;a href=&quot;#torch.Tensor.abs_&quot;&gt;&lt;code&gt;abs_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.absolute&quot;&gt; &lt;code&gt;absolute()&lt;/code&gt; &lt;/a&gt; Alias for &lt;a href=&quot;#torch.Tensor.abs_&quot;&gt; &lt;code&gt;abs_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dde70002d7610f16bccc15d518923eec4d107bba" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.acos&quot;&gt;&lt;code&gt;acos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.acos&quot;&gt; &lt;code&gt;acos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2f828fea297a593b936b38df78e2d795295f80f1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.acosh&quot;&gt;&lt;code&gt;acosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.acosh&quot;&gt; &lt;code&gt;acosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6e2ef98fa9aa6aca8a1bdb5dad128434e35bceaa" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.add&quot;&gt;&lt;code&gt;add()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.add&quot;&gt; &lt;code&gt;add()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9afdb8ac221f8f75547e87484016d557ba50f247" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addbmm&quot;&gt;&lt;code&gt;addbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addbmm&quot;&gt; &lt;code&gt;addbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="dcf43a3561084dec90d7c3a2ecc1b6cc0c26f938" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addcdiv&quot;&gt;&lt;code&gt;addcdiv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addcdiv&quot;&gt; &lt;code&gt;addcdiv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b52599a8d04e379d3f3c9ecc7af347c1222d473b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addcmul&quot;&gt;&lt;code&gt;addcmul()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addcmul&quot;&gt; &lt;code&gt;addcmul()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="212bb18c46269c9b244d88318432c473793d6225" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addmm&quot;&gt;&lt;code&gt;addmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addmm&quot;&gt; &lt;code&gt;addmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7e04b090badbdcab058cb74254d5f97b547843c5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addmv&quot;&gt;&lt;code&gt;addmv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addmv&quot;&gt; &lt;code&gt;addmv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="714cae5e9e959037c53ed668822d40bf8774aa1b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.addr&quot;&gt;&lt;code&gt;addr()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.addr&quot;&gt; &lt;code&gt;addr()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="85808cd790e595c311410030bdf947098dfb3832" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arccos&quot;&gt;&lt;code&gt;arccos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arccos&quot;&gt; &lt;code&gt;arccos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f222472fe1a711c429f88dfa21d735fc20269d70" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arccosh&quot;&gt;&lt;code&gt;arccosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arccosh&quot;&gt; &lt;code&gt;arccosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e5850fc97599dacb252ef7b71a0bc059e90ac832" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arcsin&quot;&gt;&lt;code&gt;arcsin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arcsin&quot;&gt; &lt;code&gt;arcsin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a92421400d2c919bc99b517f289d8339a3ae03e4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arcsinh&quot;&gt;&lt;code&gt;arcsinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arcsinh&quot;&gt; &lt;code&gt;arcsinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ab6c8d62429cad7d186033198296a84d5c952598" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arctan&quot;&gt;&lt;code&gt;arctan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arctan&quot;&gt; &lt;code&gt;arctan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e025d0bea89a2469024775370356f0fa69f44cc9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.arctanh&quot;&gt;&lt;code&gt;arctanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.arctanh&quot;&gt; &lt;code&gt;arctanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1eda7abb65e5c787ce66fb95749143a3f04888ed" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.asin&quot;&gt;&lt;code&gt;asin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.asin&quot;&gt; &lt;code&gt;asin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0d258dbfd544c95327dd54668d3cb8823507d044" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.asinh&quot;&gt;&lt;code&gt;asinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.asinh&quot;&gt; &lt;code&gt;asinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0e752ea6e17fecf2b883b074dbb3aa938a6f7d1c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atan&quot;&gt;&lt;code&gt;atan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atan&quot;&gt; &lt;code&gt;atan()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f00b83a4661950dbba55ca10e0c95538d6e98aaf" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atan2&quot;&gt;&lt;code&gt;atan2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atan2&quot;&gt; &lt;code&gt;atan2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9a9b90fa5b79edeea0ea7f804bf39ca483463ba1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.atanh&quot;&gt;&lt;code&gt;atanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.atanh&quot;&gt; &lt;code&gt;atanh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="0cf21533d1ef19709a89c1226676212cc25b35e7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.baddbmm&quot;&gt;&lt;code&gt;baddbmm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.baddbmm&quot;&gt; &lt;code&gt;baddbmm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="723c45d84b8a47a2aac768faa389e89dbffdc312" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_and&quot;&gt;&lt;code&gt;bitwise_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_and&quot;&gt; &lt;code&gt;bitwise_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="f23ac5a50549f7c4c93c7cc4af1a4a7fb14079c7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_not&quot;&gt;&lt;code&gt;bitwise_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_not&quot;&gt; &lt;code&gt;bitwise_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1643902bef600d4d0d475acf131454814b25dc26" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_or&quot;&gt;&lt;code&gt;bitwise_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_or&quot;&gt; &lt;code&gt;bitwise_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="fc90a184109b29c52ddf3915b630a1a54ae9634b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_xor&quot;&gt;&lt;code&gt;bitwise_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.bitwise_xor&quot;&gt; &lt;code&gt;bitwise_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9b071498cdd10ed979300e38b8823b05d84b4e9a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ceil&quot;&gt;&lt;code&gt;ceil()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ceil&quot;&gt; &lt;code&gt;ceil()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cd0a36194221856cef72e71a8bee0b50682fd547" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.clamp&quot;&gt;&lt;code&gt;clamp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.clamp&quot;&gt; &lt;code&gt;clamp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="70bc593dd1c02b1636bd32a3b21498325eaaa85c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.cos&quot;&gt;&lt;code&gt;cos()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.cos&quot;&gt; &lt;code&gt;cos()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="30b3045f3354737011026cef07419edca16e51b7" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.cosh&quot;&gt;&lt;code&gt;cosh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.cosh&quot;&gt; &lt;code&gt;cosh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="85698a440de4a886c432db2c8ba93bb04b9783a5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.digamma&quot;&gt;&lt;code&gt;digamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.digamma&quot;&gt; &lt;code&gt;digamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="5b9d988d2d91968da3bc8e9addd60ca857a07078" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.div&quot;&gt;&lt;code&gt;div()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.div&quot;&gt; &lt;code&gt;div()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="40f813960ae0cb30555d66235642030e14081a78" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.divide&quot;&gt;&lt;code&gt;divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.divide&quot;&gt; &lt;code&gt;divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3593d29a80b1997092e2a7caab1ae4c89ff665ad" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.eq&quot;&gt;&lt;code&gt;eq()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.eq&quot;&gt; &lt;code&gt;eq()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a597279c8f26129b927bac941304ed95baa85e3a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erf&quot;&gt;&lt;code&gt;erf()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erf&quot;&gt; &lt;code&gt;erf()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cbb6ddfcf060f64c41fb12dadf24c5f4104c8248" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erfc&quot;&gt;&lt;code&gt;erfc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erfc&quot;&gt; &lt;code&gt;erfc()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d3f26f32a7d82b45bafe3bb5a09586684935c0d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.erfinv&quot;&gt;&lt;code&gt;erfinv()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.erfinv&quot;&gt; &lt;code&gt;erfinv()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="843b7383da05ed2bdd2c3d50d63831578e83d793" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.exp&quot;&gt;&lt;code&gt;exp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.exp&quot;&gt; &lt;code&gt;exp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="592c5733a1bb63ac93435062ef6cf042a3e0764b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.expm1&quot;&gt;&lt;code&gt;expm1()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.expm1&quot;&gt; &lt;code&gt;expm1()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d5d395d973d45d767241ba61182b45ea933b25b3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.fix&quot;&gt;&lt;code&gt;fix()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.fix&quot;&gt; &lt;code&gt;fix()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a0ad235d8de2027be5bcf6998afc520cb85c9fc4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.floor&quot;&gt;&lt;code&gt;floor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.floor&quot;&gt; &lt;code&gt;floor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1298ca9624e848339b14dbd7ac9e1cc72e8426d5" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.floor_divide&quot;&gt;&lt;code&gt;floor_divide()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.floor_divide&quot;&gt; &lt;code&gt;floor_divide()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ba34126e0ac2c59a401a9332bbc39d964a9f1676" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.fmod&quot;&gt;&lt;code&gt;fmod()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.fmod&quot;&gt; &lt;code&gt;fmod()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="05577f4319cd8a9afef3327e267c8259cd201bc1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.frac&quot;&gt;&lt;code&gt;frac()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.frac&quot;&gt; &lt;code&gt;frac()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2c9a5d890ffefe6a4582f4b8a23dc1a024530071" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.gcd&quot;&gt;&lt;code&gt;gcd()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.gcd&quot;&gt; &lt;code&gt;gcd()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="64f7412f381bbec829d7e064308cdeedbdb4239d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ge&quot;&gt;&lt;code&gt;ge()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ge&quot;&gt; &lt;code&gt;ge()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="c4e0348ba557fd7f53f8d998e67417ad216e0ca1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.greater&quot;&gt;&lt;code&gt;greater()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.greater&quot;&gt; &lt;code&gt;greater()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="c8558b60a835a6d4d07c498aab1d1c2aee7927ef" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.greater_equal&quot;&gt;&lt;code&gt;greater_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.greater_equal&quot;&gt; &lt;code&gt;greater_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="23ff3a9c46bb69e3bf80c84bd30a30c21ea9397e" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.gt&quot;&gt;&lt;code&gt;gt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.gt&quot;&gt; &lt;code&gt;gt()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="0101731065c7560702b5f46c4e91cdc9923c8847" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.hypot&quot;&gt;&lt;code&gt;hypot()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.hypot&quot;&gt; &lt;code&gt;hypot()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2ae74e50f4d266279d834bc1480fb185d3f5523f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.i0&quot;&gt;&lt;code&gt;i0()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.i0&quot;&gt; &lt;code&gt;i0()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="a9c7375b3919548ed0ffd6165fe0af4e23e758d4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lcm&quot;&gt;&lt;code&gt;lcm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lcm&quot;&gt; &lt;code&gt;lcm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c39b8eebf07573ad5eac2472d11ac00d3ec49609" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.le&quot;&gt;&lt;code&gt;le()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.le&quot;&gt; &lt;code&gt;le()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="de77dd1c89036ad69daa80304475b1011fb3301e" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lerp&quot;&gt;&lt;code&gt;lerp()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lerp&quot;&gt; &lt;code&gt;lerp()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c58f50cdbebdcfb188e2bdfa9fcdc829890f845d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.less&quot;&gt;&lt;code&gt;less()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.less&quot;&gt; &lt;code&gt;less()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="b9423b0d6372fd7e2833e62f8095c74ec7f8c46f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.less_equal&quot;&gt;&lt;code&gt;less_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.less_equal&quot;&gt; &lt;code&gt;less_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6e2671a3a2693a72154fb41d1a6e377bc20e43a8" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lgamma&quot;&gt;&lt;code&gt;lgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lgamma&quot;&gt; &lt;code&gt;lgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9af05e667e56282be6af4fe5b0246f9f857e3a1d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log&quot;&gt;&lt;code&gt;log()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log&quot;&gt; &lt;code&gt;log()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c10939ba9c9c50755fefd56b392ef3407792f705" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log10&quot;&gt;&lt;code&gt;log10()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log10&quot;&gt; &lt;code&gt;log10()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1458e566ebdc0a91bfc06212d913d1e13187212c" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log1p&quot;&gt;&lt;code&gt;log1p()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log1p&quot;&gt; &lt;code&gt;log1p()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b4555443ad8a2acf3c819dcdfbbef49a10a2e972" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.log2&quot;&gt;&lt;code&gt;log2()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.log2&quot;&gt; &lt;code&gt;log2()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="433b0aeae51de4808da5b68a9beefef42daf02ce" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_and&quot;&gt;&lt;code&gt;logical_and()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_and&quot;&gt; &lt;code&gt;logical_and()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="c70b5c1f8176e07af5e81b152a7bdfca820fb3f9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_not&quot;&gt;&lt;code&gt;logical_not()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_not&quot;&gt; &lt;code&gt;logical_not()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="d91ce8af603413f0aefc2d1b8b6eec1f114d044b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_or&quot;&gt;&lt;code&gt;logical_or()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_or&quot;&gt; &lt;code&gt;logical_or()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="3109d25b88385322d682d606fa91db53903884b9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logical_xor&quot;&gt;&lt;code&gt;logical_xor()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logical_xor&quot;&gt; &lt;code&gt;logical_xor()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="343ccb07f42d386eca14f79b12f59de018d60e86" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.logit&quot;&gt;&lt;code&gt;logit()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.logit&quot;&gt; &lt;code&gt;logit()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9d856395e389956dab5ecceb9942b3af92fe9ea1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.lt&quot;&gt;&lt;code&gt;lt()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.lt&quot;&gt; &lt;code&gt;lt()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="23d64d86cc2e5f1327a6e010cdeb7c115938b177" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.mul&quot;&gt;&lt;code&gt;mul()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.mul&quot;&gt; &lt;code&gt;mul()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="320ff1f84d1c7cfe2a1624b610ddcce8af66a764" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.multiply&quot;&gt;&lt;code&gt;multiply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.multiply&quot;&gt; &lt;code&gt;multiply()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="d10598fcd6504f5f6bb4b9ddb4d89823cb2a72a4" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.mvlgamma&quot;&gt;&lt;code&gt;mvlgamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.mvlgamma&quot;&gt; &lt;code&gt;mvlgamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b3a59563ae4042d5dfe02b4b4d28142c18b881db" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.ne&quot;&gt;&lt;code&gt;ne()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.ne&quot;&gt; &lt;code&gt;ne()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="0933e5f6d727692e6688d039a1e1af9fcbe844b2" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.neg&quot;&gt;&lt;code&gt;neg()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.neg&quot;&gt; &lt;code&gt;neg()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6b0826ad65145f6f9f94c5d871b782df9fd07711" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.negative&quot;&gt;&lt;code&gt;negative()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.negative&quot;&gt; &lt;code&gt;negative()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9a9845a362319d27c686423e43aadf669c3c68aa" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.nextafter&quot;&gt;&lt;code&gt;nextafter()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.nextafter&quot;&gt; &lt;code&gt;nextafter()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="28a1d8909a6e02b4e7751f03f7b62a7e62637734" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.not_equal&quot;&gt;&lt;code&gt;not_equal()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.not_equal&quot;&gt; &lt;code&gt;not_equal()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="f16d420f4d416e8798bbbadc72fbaac73ed31ae3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.polygamma&quot;&gt;&lt;code&gt;polygamma()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.polygamma&quot;&gt; &lt;code&gt;polygamma()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="59d753fe8af8e0e2fdbff27f828f4dc81a011e2f" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.pow&quot;&gt;&lt;code&gt;pow()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.pow&quot;&gt; &lt;code&gt;pow()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="52dd6f8c275f23765de5ee7462ecb62204684869" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.reciprocal&quot;&gt;&lt;code&gt;reciprocal()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.reciprocal&quot;&gt; &lt;code&gt;reciprocal()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="ca45cdac88c7921f089b79a8f83e20d848c48d4a" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.remainder&quot;&gt;&lt;code&gt;remainder()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.remainder&quot;&gt; &lt;code&gt;remainder()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="053eb7c5cd301fdd12904be2836f5fb0ec275646" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.rename&quot;&gt;&lt;code&gt;rename()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.rename&quot;&gt; &lt;code&gt;rename()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="818df20d8449f1acb432a28eac3f0b43768c2197" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.renorm&quot;&gt;&lt;code&gt;renorm()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.renorm&quot;&gt; &lt;code&gt;renorm()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="53ce6f2d6ab6ae80005a428178e9b77aef382107" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.round&quot;&gt;&lt;code&gt;round()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.round&quot;&gt; &lt;code&gt;round()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="b623bd7302eab7378ff509a5b3dd4f0470b21494" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.rsqrt&quot;&gt;&lt;code&gt;rsqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.rsqrt&quot;&gt; &lt;code&gt;rsqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="1fe0cf7810c0bc56d540daa9ddb7cec1599e41ee" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sgn&quot;&gt;&lt;code&gt;sgn()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sgn&quot;&gt; &lt;code&gt;sgn()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cdcdd0daf61ad10208f07b04eb0183a9d4d2ab44" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sigmoid&quot;&gt;&lt;code&gt;sigmoid()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sigmoid&quot;&gt; &lt;code&gt;sigmoid()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9e2cd3c0abcebc8ed45bd6570406d8c9d4c33ea1" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sign&quot;&gt;&lt;code&gt;sign()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sign&quot;&gt; &lt;code&gt;sign()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="69d6918f4d893ee927f13c625b9f268b4eea1c8b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sin&quot;&gt;&lt;code&gt;sin()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sin&quot;&gt; &lt;code&gt;sin()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7f906cf7cca8e4f9df35be1db35c6f3f24ecf45b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sinh&quot;&gt;&lt;code&gt;sinh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sinh&quot;&gt; &lt;code&gt;sinh()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="cbe8e3f4ea9deb4f23b9e270df8f53c6c9f24e99" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sqrt&quot;&gt;&lt;code&gt;sqrt()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sqrt&quot;&gt; &lt;code&gt;sqrt()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="8821b663c3d7115389c6fb460a014cd6f46b31a6" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.square&quot;&gt;&lt;code&gt;square()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.square&quot;&gt; &lt;code&gt;square()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="331d4255e6beb57fd7b54b749ce35473d9c934d2" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.squeeze&quot;&gt;&lt;code&gt;squeeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.squeeze&quot;&gt; &lt;code&gt;squeeze()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="9c0246ff36c2a3383754e9573043424c772cead3" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.sub&quot;&gt;&lt;code&gt;sub()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">In-place version of &lt;a href=&quot;#torch.Tensor.sub&quot;&gt; &lt;code&gt;sub()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="afadc08d16c14a6f3ab63ac2e1777d4a0c639d3d" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.subtract&quot;&gt;&lt;code&gt;subtract()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.subtract&quot;&gt; &lt;code&gt;subtract()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="6e9a157c014d95de0d85c9410108016dcf899ffc" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.t&quot;&gt;&lt;code&gt;t()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.t&quot;&gt; &lt;code&gt;t()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="c2bca115f72f0be4030271dbbf4001e5646c23cd" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tan&quot;&gt;&lt;code&gt;tan()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tan&quot;&gt; &lt;code&gt;tan()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="abae0cb9439d45a19abc17669152c5675c6b2f91" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tanh&quot;&gt;&lt;code&gt;tanh()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tanh&quot;&gt; &lt;code&gt;tanh()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="e2861f743f86145802065db61cf1289846a4dadc" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.transpose&quot;&gt;&lt;code&gt;transpose()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.transpose&quot;&gt; &lt;code&gt;transpose()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="45499df8d625edfd4a83589eb3c8afa20bd32bb9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.tril&quot;&gt;&lt;code&gt;tril()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.tril&quot;&gt; &lt;code&gt;tril()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="065bb546251aa96738ef601a77cd6f37ec7d9659" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.triu&quot;&gt;&lt;code&gt;triu()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.triu&quot;&gt; &lt;code&gt;triu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="212e370e8fdc9518bb1c8dd81fce7b074d0a6998" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.true_divide_&quot;&gt;&lt;code&gt;true_divide_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.true_divide_&quot;&gt; &lt;code&gt;true_divide_()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="e29d58f0e79f4e7e5e919543670aacaa5b39af55" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.trunc&quot;&gt;&lt;code&gt;trunc()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.trunc&quot;&gt; &lt;code&gt;trunc()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="1e2464f4a6dc92f29b5fe948a1cb58f6a6f8ec52" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.Tensor.unsqueeze&quot;&gt;&lt;code&gt;unsqueeze()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">&lt;a href=&quot;#torch.Tensor.unsqueeze&quot;&gt; &lt;code&gt;unsqueeze()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン</target>
        </trans-unit>
        <trans-unit id="40042c187d9c08cff699d8c486b17c8fc8e0f71b" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.elu&quot;&gt;&lt;code&gt;elu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.elu&quot;&gt; &lt;code&gt;elu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="fda2e5a23576045d8c887926b8f5f495cbb00502" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.hardtanh&quot;&gt;&lt;code&gt;hardtanh()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.hardtanh&quot;&gt; &lt;code&gt;hardtanh()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="4e00c79886a4c5fdfdd4fc0c5274b0108988ba92" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.leaky_relu&quot;&gt;&lt;code&gt;leaky_relu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.leaky_relu&quot;&gt; &lt;code&gt;leaky_relu()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="eda3fb8c00a121092ce0d25f989c8256cb992365" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.relu&quot;&gt;&lt;code&gt;relu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.relu&quot;&gt; &lt;code&gt;relu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="e3a76eb13d927dc0ac3b8f72061ef5fd006d9d68" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.rrelu&quot;&gt;&lt;code&gt;rrelu()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.rrelu&quot;&gt; &lt;code&gt;rrelu()&lt;/code&gt; の&lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="cf12b7cfa392abc73035a860cd7f9148c1c352d9" translate="yes" xml:space="preserve">
          <source>In-place version of &lt;a href=&quot;#torch.nn.functional.threshold&quot;&gt;&lt;code&gt;threshold()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.functional.threshold&quot;&gt; &lt;code&gt;threshold()&lt;/code&gt; &lt;/a&gt;インプレースバージョン。</target>
        </trans-unit>
        <trans-unit id="0b7ad9a8774865b3951b77d446d4e908b37c2715" translate="yes" xml:space="preserve">
          <source>Inception (warning: this model is highly sensitive to changes in operator implementation)</source>
          <target state="translated">インセプション(警告:このモデルは演算子の実装の変更に非常に敏感です。</target>
        </trans-unit>
        <trans-unit id="86187099fc5837d4a16585e59250186b1bdbfd39" translate="yes" xml:space="preserve">
          <source>Inception v3</source>
          <target state="translated">インセプション v3</target>
        </trans-unit>
        <trans-unit id="512c1383f2d8169cfead07824d0994b018f42ff3" translate="yes" xml:space="preserve">
          <source>Inception v3 model architecture from &lt;a href=&quot;http://arxiv.org/abs/1512.00567&quot;&gt;&amp;ldquo;Rethinking the Inception Architecture for Computer Vision&amp;rdquo;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;http://arxiv.org/abs/1512.00567&quot;&gt;「コンピュータビジョンのインセプションアーキテクチャの再考」の&lt;/a&gt;Inceptionv3モデルアーキテクチャ。</target>
        </trans-unit>
        <trans-unit id="c2df9b932637fe9d32a0f16da1c11873398f873d" translate="yes" xml:space="preserve">
          <source>Index</source>
          <target state="translated">Index</target>
        </trans-unit>
        <trans-unit id="6f4e6ca52449e10a302a5dfc3ebba098cd7e6757" translate="yes" xml:space="preserve">
          <source>Indexing, Slicing, Joining, Mutating Ops</source>
          <target state="translated">インデックス作成、スライス、結合、操作の変更</target>
        </trans-unit>
        <trans-unit id="5e2d7833039dc978e6eb0d1055910e03a86a4609" translate="yes" xml:space="preserve">
          <source>Indices and tables</source>
          <target state="translated">インデックスとテーブル</target>
        </trans-unit>
        <trans-unit id="4eb1cf386795f140ff47153f7333aea4dda421e5" translate="yes" xml:space="preserve">
          <source>Indices are ordered from left to right according to when each was sampled (first samples are placed in first column).</source>
          <target state="translated">指標は左から右へと、それぞれがいつサンプリングされたかに応じて並べられています(最初のサンプルは最初の列に配置されています)。</target>
        </trans-unit>
        <trans-unit id="68fa16ffd48f366e4fa8d57fea78ff03fcab0191" translate="yes" xml:space="preserve">
          <source>Initialization</source>
          <target state="translated">Initialization</target>
        </trans-unit>
        <trans-unit id="73e5b96b48f418d64840badaa42ca942b71c67be" translate="yes" xml:space="preserve">
          <source>Initializes RPC primitives such as the local RPC agent and distributed autograd, which immediately makes the current process ready to send and receive RPCs.</source>
          <target state="translated">ローカル RPC エージェントや分散 autograd などの RPC プリミティブを初期化し、現在のプロセスを直ちに RPC を送受信できる状態にします。</target>
        </trans-unit>
        <trans-unit id="bd0f315e911df950ab4124032aa329f129570289" translate="yes" xml:space="preserve">
          <source>Initializes the default distributed process group, and this will also initialize the distributed package.</source>
          <target state="translated">デフォルトの分散プロセスグループを初期化し、分散パッケージも初期化します。</target>
        </trans-unit>
        <trans-unit id="252c7bda7950bbedbb2a4bb4550ac0f5ef1aa6a8" translate="yes" xml:space="preserve">
          <source>Input lists. It should contain correctly-sized tensors on each GPU to be used for input of the collective, e.g. &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; contains the reduce_scatter input that resides on the GPU of &lt;code&gt;output_tensor_list[i]&lt;/code&gt;.</source>
          <target state="translated">入力リスト。コレクティブの入力に使用される各GPUに正しいサイズのテンソルが含まれている必要があります。たとえば、 &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; は、 &lt;code&gt;output_tensor_list[i]&lt;/code&gt; GPUにあるreduce_scatter入力が含まれています。</target>
        </trans-unit>
        <trans-unit id="5bba22431efd0a63a04193e3ddac4464b3801e67" translate="yes" xml:space="preserve">
          <source>Input1:</source>
          <target state="translated">Input1:</target>
        </trans-unit>
        <trans-unit id="feac2b2649c90f11d6d855888f274f7a0752b7d9" translate="yes" xml:space="preserve">
          <source>Input2:</source>
          <target state="translated">Input2:</target>
        </trans-unit>
        <trans-unit id="79d70dcb4f9ee8b7d94ed9539586cc73c0d399da" translate="yes" xml:space="preserve">
          <source>Input:</source>
          <target state="translated">Input:</target>
        </trans-unit>
        <trans-unit id="7b180c0fda0377ef1dc31c7cce34da732fc57c9e" translate="yes" xml:space="preserve">
          <source>Input: LongTensor of arbitrary shape containing the indices to extract</source>
          <target state="translated">入力。抽出する指標を含む任意の形状のLongTensor</target>
        </trans-unit>
        <trans-unit id="15c3ba090d23cb0ca95577aa6799755edeefe016" translate="yes" xml:space="preserve">
          <source>Input_lengths: Tuple or tensor of size</source>
          <target state="translated">Input_lengths:サイズのタプルまたはテンソル</target>
        </trans-unit>
        <trans-unit id="fcadc5a2f2ce33e2ebb11bf51a1dd2322a5a729a" translate="yes" xml:space="preserve">
          <source>Inputs:</source>
          <target state="translated">Inputs:</target>
        </trans-unit>
        <trans-unit id="f969dd5ae0f7325be616e39a51b06a49fc60e816" translate="yes" xml:space="preserve">
          <source>Inputs: input, (h_0, c_0)</source>
          <target state="translated">入力:入力、(h_0,c_0)</target>
        </trans-unit>
        <trans-unit id="1be4f879f896bd3dcbeaf30b825be75ca856fcfb" translate="yes" xml:space="preserve">
          <source>Inputs: input, h_0</source>
          <target state="translated">入力:入力、h_0</target>
        </trans-unit>
        <trans-unit id="71bf746d2a9f5ff1025d4c04b2cf1fcfbd657691" translate="yes" xml:space="preserve">
          <source>Inputs: input, hidden</source>
          <target state="translated">入力:入力、非表示</target>
        </trans-unit>
        <trans-unit id="7f3d3cd091d557867390efc2557a3f5b19292265" translate="yes" xml:space="preserve">
          <source>Insert a given module before a given index in the list.</source>
          <target state="translated">指定されたモジュールをリストの指定されたインデックスの前に挿入します。</target>
        </trans-unit>
        <trans-unit id="50d8055b5be81f5be9d6435d07e2a4ac2451cc98" translate="yes" xml:space="preserve">
          <source>Inserts the key-value pair into the store based on the supplied &lt;code&gt;key&lt;/code&gt; and &lt;code&gt;value&lt;/code&gt;. If &lt;code&gt;key&lt;/code&gt; already exists in the store, it will overwrite the old value with the new supplied &lt;code&gt;value&lt;/code&gt;.</source>
          <target state="translated">指定された &lt;code&gt;key&lt;/code&gt; と &lt;code&gt;value&lt;/code&gt; 基づいて、キーと値のペアをストアに挿入します。 &lt;code&gt;key&lt;/code&gt; がストアにすでに存在する場合、古い値が新しく指定された &lt;code&gt;value&lt;/code&gt; で上書きされます。</target>
        </trans-unit>
        <trans-unit id="52616e80a59172caf19bcc15fac4910844e40524" translate="yes" xml:space="preserve">
          <source>Inspecting Code</source>
          <target state="translated">コードの検査</target>
        </trans-unit>
        <trans-unit id="9efecc53883d2ffb75b3f04810dbaac718af41ba" translate="yes" xml:space="preserve">
          <source>InstanceNorm1d</source>
          <target state="translated">InstanceNorm1d</target>
        </trans-unit>
        <trans-unit id="a1ce20a07b568c5cbed5860b3c884130e1c4f948" translate="yes" xml:space="preserve">
          <source>InstanceNorm2d</source>
          <target state="translated">InstanceNorm2d</target>
        </trans-unit>
        <trans-unit id="f8a9e223352c23318d808b3147734411baf32655" translate="yes" xml:space="preserve">
          <source>InstanceNorm3d</source>
          <target state="translated">InstanceNorm3d</target>
        </trans-unit>
        <trans-unit id="8ab3500f668dc459ea6ccd8a8b7456bb53bb532b" translate="yes" xml:space="preserve">
          <source>Instances of this class should never be created manually. They are meant to be instantiated by functions like &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;pack_padded_sequence()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">このクラスのインスタンスを手動で作成しないでください。これらは、&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;pack_padded_sequence()&lt;/code&gt; &lt;/a&gt;などの関数によってインスタンス化されることを目的としています。</target>
        </trans-unit>
        <trans-unit id="5a54ceeb7f75257e5faecf7dac25c3c19332eb52" translate="yes" xml:space="preserve">
          <source>Instancing a pre-trained model will download its weights to a cache directory. This directory can be set using the &lt;code&gt;TORCH_MODEL_ZOO&lt;/code&gt; environment variable. See &lt;a href=&quot;../model_zoo#torch.utils.model_zoo.load_url&quot;&gt;&lt;code&gt;torch.utils.model_zoo.load_url()&lt;/code&gt;&lt;/a&gt; for details.</source>
          <target state="translated">事前にトレーニングされたモデルをインスタンス化すると、その重みがキャッシュディレクトリにダウンロードされます。このディレクトリは、 &lt;code&gt;TORCH_MODEL_ZOO&lt;/code&gt; 環境変数を使用して設定できます。詳細については、&lt;a href=&quot;../model_zoo#torch.utils.model_zoo.load_url&quot;&gt; &lt;code&gt;torch.utils.model_zoo.load_url()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="4156151a1b281cbc4bcd7e0576424486039cddfe" translate="yes" xml:space="preserve">
          <source>Integer division with addcdiv is no longer supported, and in a future release addcdiv will perform a true division of tensor1 and tensor2. The historic addcdiv behavior can be implemented as (input + value * torch.trunc(tensor1 / tensor2)).to(input.dtype) for integer inputs and as (input + value * tensor1 / tensor2) for float inputs. The future addcdiv behavior is just the latter implementation: (input + value * tensor1 / tensor2), for all dtypes.</source>
          <target state="translated">addcdivによる整数除算はサポートされなくなり、将来のリリースでは、addcdivはtensor1とtensor2の真の除算を実行するようになります。これまでのaddcdivの動作は、整数入力の場合は(input+value*torch.trunc(tensor1/tensor2)).to(input.dtype)として、float入力の場合は(input+value*tensor1/tensor2)として実装できます。将来のaddcdivの動作は後者の実装になります。(input+value*tensor1/tensor2)、すべてのdtypeに対して。</target>
        </trans-unit>
        <trans-unit id="9f650ccc7d0d6be8b0fb7120cf085b2ff78498f0" translate="yes" xml:space="preserve">
          <source>Interpreting Graphs</source>
          <target state="translated">グラフの解釈</target>
        </trans-unit>
        <trans-unit id="e42baee8c04a7fb48aeb23c27863b3e7f99c9a61" translate="yes" xml:space="preserve">
          <source>Inverse short time Fourier Transform.</source>
          <target state="translated">逆短時間フーリエ変換。</target>
        </trans-unit>
        <trans-unit id="f2d2a372360fc80cd1c1832163878137a219bb55" translate="yes" xml:space="preserve">
          <source>Inverse short time Fourier Transform. This is expected to be the inverse of &lt;a href=&quot;torch.stft#torch.stft&quot;&gt;&lt;code&gt;stft()&lt;/code&gt;&lt;/a&gt;. It has the same parameters (+ additional optional parameter of &lt;code&gt;length&lt;/code&gt;) and it should return the least squares estimation of the original signal. The algorithm will check using the NOLA condition ( nonzero overlap).</source>
          <target state="translated">逆短時間フーリエ変換。これは、&lt;a href=&quot;torch.stft#torch.stft&quot;&gt; &lt;code&gt;stft()&lt;/code&gt; の&lt;/a&gt;逆であると予想されます。同じパラメーター（+ &lt;code&gt;length&lt;/code&gt; 追加のオプションパラメーター）があり、元の信号の最小二乗推定を返す必要があります。アルゴリズムは、NOLA条件（ゼロ以外のオーバーラップ）を使用してチェックします。</target>
        </trans-unit>
        <trans-unit id="4212bbbb75b521f6e55e2e79c4b2dab9598d7c21" translate="yes" xml:space="preserve">
          <source>Invoking &lt;code&gt;trace&lt;/code&gt; with a module&amp;rsquo;s method captures module parameters (which may require gradients) as &lt;strong&gt;constants&lt;/strong&gt;.</source>
          <target state="translated">モジュールのメソッドを使用して &lt;code&gt;trace&lt;/code&gt; を呼び出すと、モジュールのパラメーター（勾配が必要になる場合があります）が&lt;strong&gt;定数&lt;/strong&gt;としてキャプチャされます。</target>
        </trans-unit>
        <trans-unit id="0b1154e9d45e9b9a76119f9cdf7dd156a3cc44ad" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrices &lt;code&gt;solution&lt;/code&gt; and &lt;code&gt;LU&lt;/code&gt; will be transposed, i.e. with strides like &lt;code&gt;B.contiguous().transpose(-1, -2).stride()&lt;/code&gt; and &lt;code&gt;A.contiguous().transpose(-1, -2).stride()&lt;/code&gt; respectively.</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;solution&lt;/code&gt; と &lt;code&gt;LU&lt;/code&gt; は転置されます。つまり、 &lt;code&gt;B.contiguous().transpose(-1, -2).stride()&lt;/code&gt; や &lt;code&gt;A.contiguous().transpose(-1, -2).stride()&lt;/code&gt; それぞれ。</target>
        </trans-unit>
        <trans-unit id="49986ad18b9e3b5d2fddd594cfccd882001d60e0" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrix &lt;code&gt;U&lt;/code&gt; will be transposed, i.e. with strides &lt;code&gt;U.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;U&lt;/code&gt; は転置されます。つまり、ストライド &lt;code&gt;U.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="82269a6fafdcdbb86e718604476ce9b6c8e7d2a7" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned matrix &lt;code&gt;V&lt;/code&gt; will be transposed, i.e. with strides &lt;code&gt;V.contiguous().transpose(-1, -2).stride()&lt;/code&gt;.</source>
          <target state="translated">元のストライドに関係なく、返される行列 &lt;code&gt;V&lt;/code&gt; は転置されます。つまり、ストライド &lt;code&gt;V.contiguous().transpose(-1, -2).stride()&lt;/code&gt; ます。</target>
        </trans-unit>
        <trans-unit id="01899cc116f34c67486ee354a88f582f6796cc36" translate="yes" xml:space="preserve">
          <source>Irrespective of the original strides, the returned tensors will be transposed, i.e. with strides like &lt;code&gt;input.contiguous().transpose(-2, -1).stride()&lt;/code&gt;</source>
          <target state="translated">元のストライドに関係なく、返されるテンソルは転置されます。つまり、 &lt;code&gt;input.contiguous().transpose(-2, -1).stride()&lt;/code&gt; ようなストライドが使用されます。</target>
        </trans-unit>
        <trans-unit id="2310615072fec2b4a5a875a4e0dd6ffebdaf12ad" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if gradients need to be computed for this Tensor, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">このテンソルに対して勾配を計算する必要がある場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="aa669dbfc27ea4c75455d3b2508d4155513b175a" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is a meta tensor, &lt;code&gt;False&lt;/code&gt; otherwise. Meta tensors are like normal tensors, but they carry no data.</source>
          <target state="translated">テンソルがメタテンソルの場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。メタテンソルは通常のテンソルに似ていますが、データはありません。</target>
        </trans-unit>
        <trans-unit id="adff4bd8499f965b85193b88135bc7439c31730a" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is quantized, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">テンソルが量子化されている場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="3a0d8439442e2aedd6e797ff733a51980c711c86" translate="yes" xml:space="preserve">
          <source>Is &lt;code&gt;True&lt;/code&gt; if the Tensor is stored on the GPU, &lt;code&gt;False&lt;/code&gt; otherwise.</source>
          <target state="translated">テンソルがGPUに保存されている場合は &lt;code&gt;True&lt;/code&gt; 、それ以外の場合は &lt;code&gt;False&lt;/code&gt; です。</target>
        </trans-unit>
        <trans-unit id="e91f70a847754923183418ed052bcea694565f54" translate="yes" xml:space="preserve">
          <source>Is the &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; where this Tensor is.</source>
          <target state="translated">このTensorがある&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; &lt;/a&gt;です。</target>
        </trans-unit>
        <trans-unit id="4212d08cece9c425b48ec2c1e60e8be1d1e78b6c" translate="yes" xml:space="preserve">
          <source>Is this Tensor with its dimensions reversed.</source>
          <target state="translated">このテンソルは寸法が逆になっているのでしょうか。</target>
        </trans-unit>
        <trans-unit id="6b5b4f414a6eb16cb4afeb48e5665cb815db584b" translate="yes" xml:space="preserve">
          <source>It achieves two things: - makes the output value exactly one-hot (since we add then subtract y_soft value) - makes the gradient equal to y_soft gradient (since we strip all other gradients)</source>
          <target state="translated">これは次の2つのことを実現します:-出力値を正確に1ホットにします(y_soft値を加算してから減算するので)-勾配をy_soft勾配と等しくします(他のすべての勾配を除去するので)-出力値を正確に1ホットにします。</target>
        </trans-unit>
        <trans-unit id="8e6db53c7cd43b88eb003448e0a5df6411ba7a87" translate="yes" xml:space="preserve">
          <source>It currently accepts &lt;code&gt;ndarray&lt;/code&gt; with dtypes of &lt;code&gt;numpy.float64&lt;/code&gt;, &lt;code&gt;numpy.float32&lt;/code&gt;, &lt;code&gt;numpy.float16&lt;/code&gt;, &lt;code&gt;numpy.complex64&lt;/code&gt;, &lt;code&gt;numpy.complex128&lt;/code&gt;, &lt;code&gt;numpy.int64&lt;/code&gt;, &lt;code&gt;numpy.int32&lt;/code&gt;, &lt;code&gt;numpy.int16&lt;/code&gt;, &lt;code&gt;numpy.int8&lt;/code&gt;, &lt;code&gt;numpy.uint8&lt;/code&gt;, and &lt;code&gt;numpy.bool&lt;/code&gt;.</source>
          <target state="translated">これは、現在受け入れ &lt;code&gt;ndarray&lt;/code&gt; のdtypesで &lt;code&gt;numpy.float64&lt;/code&gt; 、 &lt;code&gt;numpy.float32&lt;/code&gt; 、 &lt;code&gt;numpy.float16&lt;/code&gt; 、 &lt;code&gt;numpy.complex64&lt;/code&gt; 、 &lt;code&gt;numpy.complex128&lt;/code&gt; 、 &lt;code&gt;numpy.int64&lt;/code&gt; 、 &lt;code&gt;numpy.int32&lt;/code&gt; 、 &lt;code&gt;numpy.int16&lt;/code&gt; 、 &lt;code&gt;numpy.int8&lt;/code&gt; 、 &lt;code&gt;numpy.uint8&lt;/code&gt; 、および &lt;code&gt;numpy.bool&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="401f208e4a6ef5ef6ad2bc031ef0d0f97b3ebf14" translate="yes" xml:space="preserve">
          <source>It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability &amp;gt;= 3.0</source>
          <target state="translated">CUDAに対応するものがあり、計算機能が3.0以上のNVIDIAGPUでテンソル計算を実行できます。</target>
        </trans-unit>
        <trans-unit id="6563cef1ae60ef9f0cfc196eb441bdefa9d3c7aa" translate="yes" xml:space="preserve">
          <source>It has similar signature as &lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt;&lt;code&gt;torch.Tensor.to()&lt;/code&gt;&lt;/a&gt;, except optional arguments like &lt;code&gt;non_blocking&lt;/code&gt; and &lt;code&gt;copy&lt;/code&gt; should be passed as kwargs, not args, or they will not apply to the index tensors.</source>
          <target state="translated">&lt;code&gt;non_blocking&lt;/code&gt; や &lt;code&gt;copy&lt;/code&gt; などのオプションの引数をargsではなくkwargsとして渡す必要があることを除いて、&lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt; &lt;code&gt;torch.Tensor.to()&lt;/code&gt; &lt;/a&gt;と同様の署名があります。そうしないと、インデックステンソルには適用されません。</target>
        </trans-unit>
        <trans-unit id="2b37442b8edf941c9b64329b2dd98dad1125f396" translate="yes" xml:space="preserve">
          <source>It is also possible to annotate types with Python 3 type hints from the &lt;code&gt;typing&lt;/code&gt; module.</source>
          <target state="translated">&lt;code&gt;typing&lt;/code&gt; モジュールからPython3タイプヒントでタイプに注釈を付けることもできます。</target>
        </trans-unit>
        <trans-unit id="86993dc3f5b11fb441bb568843f0d884da0db7f4" translate="yes" xml:space="preserve">
          <source>It is an inverse operation to &lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt;&lt;code&gt;pack_padded_sequence()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">これは、&lt;a href=&quot;torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence&quot;&gt; &lt;code&gt;pack_padded_sequence()&lt;/code&gt; の&lt;/a&gt;逆の操作です。</target>
        </trans-unit>
        <trans-unit id="50cbae8d4910e6f042bec5701d96446fe97f36c9" translate="yes" xml:space="preserve">
          <source>It is applied to all slices along dim, and will re-scale them so that the elements lie in the range &lt;code&gt;[0, 1]&lt;/code&gt; and sum to 1.</source>
          <target state="translated">これは、dimに沿ったすべてのスライスに適用され、要素が &lt;code&gt;[0, 1]&lt;/code&gt; 範囲にあり、合計が1になるように再スケーリングします。</target>
        </trans-unit>
        <trans-unit id="7c6829a0a0e941307482f3fc9539e6effef1fbd8" translate="yes" xml:space="preserve">
          <source>It is recommended to use &lt;a href=&quot;torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code&gt;DistributedDataParallel&lt;/code&gt;&lt;/a&gt;, instead of this class, to do multi-GPU training, even if there is only a single node. See: &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel&lt;/a&gt; and &lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/ddp.html#ddp&quot;&gt;Distributed Data Parallel&lt;/a&gt;.</source>
          <target state="translated">ノードが1つしかない場合でも、マルチGPUトレーニングを実行するには、このクラスの代わりに&lt;a href=&quot;torch.nn.parallel.distributeddataparallel#torch.nn.parallel.DistributedDataParallel&quot;&gt; &lt;code&gt;DistributedDataParallel&lt;/code&gt; &lt;/a&gt;を使用することをお勧めします。参照：&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/cuda.html#cuda-nn-ddp-instead&quot;&gt;マルチプロセッシングの代わりにnn.parallel.DistributedDataParallelを使用するか、nn.DataParallel&lt;/a&gt;と&lt;a href=&quot;https://pytorch.org/docs/1.7.0/notes/ddp.html#ddp&quot;&gt;Distributed &lt;/a&gt;DataParallelを使用してください。</target>
        </trans-unit>
        <trans-unit id="cc50a460e1a231d6b7914ab6f80ce6645cd28d1a" translate="yes" xml:space="preserve">
          <source>It is useful when training a classification problem with &lt;code&gt;C&lt;/code&gt; classes. If provided, the optional argument &lt;code&gt;weight&lt;/code&gt; should be a 1D &lt;code&gt;Tensor&lt;/code&gt; assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set.</source>
          <target state="translated">これは、 &lt;code&gt;C&lt;/code&gt; クラスで分類問題をトレーニングするときに役立ちます。指定する場合、オプションの引数の &lt;code&gt;weight&lt;/code&gt; は、各クラスに重みを割り当てる1D &lt;code&gt;Tensor&lt;/code&gt; 必要があります。これは、不均衡なトレーニングセットがある場合に特に役立ちます。</target>
        </trans-unit>
        <trans-unit id="88103e98293e4d193ade88c8ec2a2e41a9017ce8" translate="yes" xml:space="preserve">
          <source>It&amp;rsquo;s possible to trade off recall and precision by adding weights to positive examples. In the case of multi-label classification the loss can be described as:</source>
          <target state="translated">肯定的な例に重みを追加することで、再現率と適合率をトレードオフすることができます。マルチラベル分類の場合、損失は次のように説明できます。</target>
        </trans-unit>
        <trans-unit id="ecdda59aea5ee67d7d854c969ccf7f4f4b4a4c54" translate="yes" xml:space="preserve">
          <source>Item</source>
          <target state="translated">Item</target>
        </trans-unit>
        <trans-unit id="4dd80eea3f6c51bf5b9c13a8a47609bd55b30e0e" translate="yes" xml:space="preserve">
          <source>Iterables</source>
          <target state="translated">Iterables</target>
        </trans-unit>
        <trans-unit id="069e2ae56a9eacaa6614576bc398f841898b1686" translate="yes" xml:space="preserve">
          <source>Its signature is similar to &lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt;&lt;code&gt;torch.Tensor.to()&lt;/code&gt;&lt;/a&gt;, but only accepts floating point desired &lt;code&gt;dtype&lt;/code&gt; s. In addition, this method will only cast the floating point parameters and buffers to &lt;code&gt;dtype&lt;/code&gt; (if given). The integral parameters and buffers will be moved &lt;code&gt;device&lt;/code&gt;, if that is given, but with dtypes unchanged. When &lt;code&gt;non_blocking&lt;/code&gt; is set, it tries to convert/move asynchronously with respect to the host if possible, e.g., moving CPU Tensors with pinned memory to CUDA devices.</source>
          <target state="translated">その署名は&lt;a href=&quot;../tensors#torch.Tensor.to&quot;&gt; &lt;code&gt;torch.Tensor.to()&lt;/code&gt; に&lt;/a&gt;似ていますが、浮動小数点の目的の &lt;code&gt;dtype&lt;/code&gt; のみを受け入れます。さらに、このメソッドは浮動小数点パラメーターとバッファーのみを &lt;code&gt;dtype&lt;/code&gt; にキャストします（指定されている場合）。積分パラメータとバッファは、指定されている場合は &lt;code&gt;device&lt;/code&gt; に移動されますが、dtypeは変更されません。とき &lt;code&gt;non_blocking&lt;/code&gt; がセットされ、可能な場合、それが変換しよう/ CUDAデバイスに固定メモリーとCPUのテンソルを動かし、例えば、ホストに対して非同期に移動。</target>
        </trans-unit>
        <trans-unit id="eb5d2f4a58038c71155ddcf3cea35dc3c6d34501" translate="yes" xml:space="preserve">
          <source>JIT</source>
          <target state="translated">JIT</target>
        </trans-unit>
        <trans-unit id="a26e63e0dd630bf0aa29409ebb2007f8ed0989a9" translate="yes" xml:space="preserve">
          <source>Javadoc</source>
          <target state="translated">Javadoc</target>
        </trans-unit>
        <trans-unit id="a7ee38bb7be4fc44198cb2685d9601dcf2b9f569" translate="yes" xml:space="preserve">
          <source>K</source>
          <target state="translated">K</target>
        </trans-unit>
        <trans-unit id="d1dd1d02265a63fb16a7c02869b20a2ff09b23ec" translate="yes" xml:space="preserve">
          <source>K \geq 1</source>
          <target state="translated">K †††††††††††††††††☆彡</target>
        </trans-unit>
        <trans-unit id="a0d38167f0e193a1ac968e4ff065116f3dd7d3e2" translate="yes" xml:space="preserve">
          <source>KLDivLoss</source>
          <target state="translated">KLDivLoss</target>
        </trans-unit>
        <trans-unit id="2dff5751295255d47b7ebb571ae0d72fa938cb72" translate="yes" xml:space="preserve">
          <source>Keep in mind that only a limited number of optimizers support sparse gradients: currently it&amp;rsquo;s &lt;code&gt;optim.SGD&lt;/code&gt; (&lt;code&gt;CUDA&lt;/code&gt; and &lt;code&gt;CPU&lt;/code&gt;), &lt;code&gt;optim.SparseAdam&lt;/code&gt; (&lt;code&gt;CUDA&lt;/code&gt; and &lt;code&gt;CPU&lt;/code&gt;) and &lt;code&gt;optim.Adagrad&lt;/code&gt; (&lt;code&gt;CPU&lt;/code&gt;)</source>
          <target state="translated">限られた数のオプティマイザーのみがスパース勾配をサポートしていることに &lt;code&gt;optim.SGD&lt;/code&gt; 。現在、optim.SGD（ &lt;code&gt;CUDA&lt;/code&gt; および &lt;code&gt;CPU&lt;/code&gt; ）、 &lt;code&gt;optim.SparseAdam&lt;/code&gt; （ &lt;code&gt;CUDA&lt;/code&gt; および &lt;code&gt;CPU&lt;/code&gt; ）、および &lt;code&gt;optim.Adagrad&lt;/code&gt; （ &lt;code&gt;CPU&lt;/code&gt; ）です。</target>
        </trans-unit>
        <trans-unit id="61df1ec904a19beceda75adc97e889c2fd5cb69f" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN</source>
          <target state="translated">キーポイント R-CNN</target>
        </trans-unit>
        <trans-unit id="4dbced9709f5236c9b69e641ffff848fd0986a34" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN ResNet-50 FPN</source>
          <target state="translated">キーポイント R-CNN ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="f2815e1786777eee9275fa2f0b31c8b705f9edc6" translate="yes" xml:space="preserve">
          <source>Keypoint R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.</source>
          <target state="translated">キーポイントR-CNNは、一定サイズの入力画像を一括して一定サイズでONNXに書き出すことができます。</target>
        </trans-unit>
        <trans-unit id="db32172db3cd21ae36313d815fba0dd39bd7127a" translate="yes" xml:space="preserve">
          <source>Keyword Arguments</source>
          <target state="translated">キーワード引数</target>
        </trans-unit>
        <trans-unit id="1c524ac8953f745b9e5b79c69e1b4d39891c5ba1" translate="yes" xml:space="preserve">
          <source>Keyword arguments &lt;code&gt;min_value&lt;/code&gt; and &lt;code&gt;max_value&lt;/code&gt; have been deprecated in favor of &lt;code&gt;min_val&lt;/code&gt; and &lt;code&gt;max_val&lt;/code&gt;.</source>
          <target state="translated">キーワード引数は &lt;code&gt;min_value&lt;/code&gt; と &lt;code&gt;max_value&lt;/code&gt; の賛成で廃止されている &lt;code&gt;min_val&lt;/code&gt; と &lt;code&gt;max_val&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="e48bd0570e2bf01526ed152277d5e60977339c96" translate="yes" xml:space="preserve">
          <source>Kicks off the distributed backward pass using the provided roots. This currently implements the &lt;a href=&quot;rpc/distributed_autograd#fast-mode-algorithm&quot;&gt;FAST mode algorithm&lt;/a&gt; which assumes all RPC messages sent in the same distributed autograd context across workers would be part of the autograd graph during the backward pass.</source>
          <target state="translated">提供されたルートを使用して、分散バックワードパスを開始します。これは現在、ワーカー間で同じ分散autogradコンテキストで送信されたすべてのRPCメッセージがバックワードパス中にautogradグラフの一部であると想定する&lt;a href=&quot;rpc/distributed_autograd#fast-mode-algorithm&quot;&gt;FASTモードアルゴリズム&lt;/a&gt;を実装しています。</target>
        </trans-unit>
        <trans-unit id="41bb1570ae7ccc5980e78c5f1c45cc0aed0bdbed" translate="yes" xml:space="preserve">
          <source>Kinetics 1-crop accuracies for clip length 16 (16x112x112)</source>
          <target state="translated">クリップ長さ16(16x112x112)のキネティクス1クリップ精度</target>
        </trans-unit>
        <trans-unit id="a5a5fafee83492d8b176cbbdd5bb0860a6fdbf28" translate="yes" xml:space="preserve">
          <source>Known limitations:</source>
          <target state="translated">既知の制限事項。</target>
        </trans-unit>
        <trans-unit id="d160e0986aca4714714a16f29ec605af90be704d" translate="yes" xml:space="preserve">
          <source>L</source>
          <target state="translated">L</target>
        </trans-unit>
        <trans-unit id="80f4812ca21133a053b1e37ce0b7c69d130f72e6" translate="yes" xml:space="preserve">
          <source>L = \prod_d \left\lfloor\frac{\text{output\_size}[d] + 2 \times \text{padding}[d] % - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c67a32aa874c2b17f9de746130e43c1407789f98" translate="yes" xml:space="preserve">
          <source>L = \prod_d \left\lfloor\frac{\text{spatial\_size}[d] + 2 \times \text{padding}[d] % - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,</source>
          <target state="translated">L=\prod_d ✿︎+2 ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ✿︎ ➡</target>
        </trans-unit>
        <trans-unit id="c775d48eb4f58382ff520cfe8c90ab7190041ada" translate="yes" xml:space="preserve">
          <source>L = \{l_1,\dots,l_N\}^\top</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="77bc26a3089aa1a1138008701f4240f1d24f7ec4" translate="yes" xml:space="preserve">
          <source>L(a, p, n) = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}</source>
          <target state="translated">L(a,p,n)=\max \d(i,p_i)-d(a,n_i)+{rrm margin},0}.</target>
        </trans-unit>
        <trans-unit id="38b3e9960c6ed6d7fea333d02fe4a806a8e19d30" translate="yes" xml:space="preserve">
          <source>L1Loss</source>
          <target state="translated">L1Loss</target>
        </trans-unit>
        <trans-unit id="eea818c7023faaf096d89f5dc66b905458038bf3" translate="yes" xml:space="preserve">
          <source>L1Unstructured</source>
          <target state="translated">L1Unstructured</target>
        </trans-unit>
        <trans-unit id="ba6b42d0904cce73f214db608d06bfd30f824246" translate="yes" xml:space="preserve">
          <source>L=C \times \text{upscale\_factor}^2</source>
          <target state="translated">L=C \times text{upscale_factor}^2</target>
        </trans-unit>
        <trans-unit id="e08d4eaec3e70d3b11d0930088b84b2ff38e358f" translate="yes" xml:space="preserve">
          <source>LPPool1d</source>
          <target state="translated">LPPool1d</target>
        </trans-unit>
        <trans-unit id="2ea3c697cd5d5c5710f8ec9f1853900569f0680c" translate="yes" xml:space="preserve">
          <source>LPPool2d</source>
          <target state="translated">LPPool2d</target>
        </trans-unit>
        <trans-unit id="23757b375d1fdee5bda46fff218547176aed63b2" translate="yes" xml:space="preserve">
          <source>LSTM</source>
          <target state="translated">LSTM</target>
        </trans-unit>
        <trans-unit id="2f25bc39b85fe095b000d209878e94802865e367" translate="yes" xml:space="preserve">
          <source>LSTMCell</source>
          <target state="translated">LSTMCell</target>
        </trans-unit>
        <trans-unit id="ecfecac3ee4f2cb5286bbb038509a2e5de7c4c02" translate="yes" xml:space="preserve">
          <source>LU factorization with &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; is not available for CPU, and attempting to do so will throw an error. However, LU factorization with &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; is available for CUDA.</source>
          <target state="translated">&lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; のLU分解はCPUで使用できず、そうしようとするとエラーがスローされます。ただし、 &lt;code&gt;pivot&lt;/code&gt; = &lt;code&gt;False&lt;/code&gt; のLU分解はCUDAで使用できます。</target>
        </trans-unit>
        <trans-unit id="0deac72fe13e2e0b87977edeca8e509c0bcfa09e" translate="yes" xml:space="preserve">
          <source>L_p</source>
          <target state="translated">L_p</target>
        </trans-unit>
        <trans-unit id="06c5049b8951b65d33ef4a2ef830eb1114e69b8d" translate="yes" xml:space="preserve">
          <source>L_{out} = (L_{in} - 1) \times \text{stride} - 2 \times \text{padding} + \text{dilation} \times (\text{kernel\_size} - 1) + \text{output\_padding} + 1</source>
          <target state="translated">L_{out}=(L_{in}-1)♪times \times ﾃｷｽﾄ{stride}-2 \times ﾃｷｽﾄ{padding}+ﾃｷｽﾄ{dilation}ﾄｲﾑｽﾞ (\text{kernel_size}-1)+♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ ♦ 1</target>
        </trans-unit>
        <trans-unit id="b805a9450351de83336b48fb7172bcc72a263dc2" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="ceac6a4482e16b31e7e38fe1379ffb2a0580a4c8" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=✿L_{out}+2 ✿L_{in}+2 ✿L_{padding}-✿L_{padding}-✿L_{padding}+1</target>
        </trans-unit>
        <trans-unit id="87439fc8e93caa8a60f8765a05bec347953ce5dc" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation} \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=≪Lleft≫ L_{in}+2 \times ≪L_{padding}-≫ ≪Dilation}≫ ≪Times (Text{kernel_size}-1)-1}{Text{stride}}+1 right\rfloor</target>
        </trans-unit>
        <trans-unit id="9c7d288e1c47c63e7fa88234abfbcbb629553bc4" translate="yes" xml:space="preserve">
          <source>L_{out} = \left\lfloor\frac{L_{in} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor</source>
          <target state="translated">L_{out}=≪L_{out}≫-≪L_{in}≫-≪L_{in}≫+1\\rightrfloor</target>
        </trans-unit>
        <trans-unit id="82415f0bf390885258b6da20230789fced78fab6" translate="yes" xml:space="preserve">
          <source>Labels passed as inputs to this module should be sorted according to their frequency. This means that the most frequent label should be represented by the index &lt;code&gt;0&lt;/code&gt;, and the least frequent label should be represented by the index &lt;code&gt;n_classes - 1&lt;/code&gt;.</source>
          <target state="translated">このモジュールへの入力として渡されるラベルは、頻度に従ってソートする必要があります。これは、最も頻度の高いラベルはインデックス &lt;code&gt;0&lt;/code&gt; で表され、最も頻度の低いラベルはインデックス &lt;code&gt;n_classes - 1&lt;/code&gt; で表される必要があることを意味します。</target>
        </trans-unit>
        <trans-unit id="e52f467c6824dfb11f12944d49910287d4e8acf9" translate="yes" xml:space="preserve">
          <source>Language Bindings</source>
          <target state="translated">言語バインディング</target>
        </trans-unit>
        <trans-unit id="1a13e309cb6089d8795a4086c303a44f1aa93eb0" translate="yes" xml:space="preserve">
          <source>Last chunk will be smaller if the tensor size along the given dimension &lt;code&gt;dim&lt;/code&gt; is not divisible by &lt;code&gt;chunks&lt;/code&gt;.</source>
          <target state="translated">指定された次元 &lt;code&gt;dim&lt;/code&gt; に沿ったテンソルサイズが &lt;code&gt;chunks&lt;/code&gt; 割り切れない場合、最後のチャンクは小さくなります。</target>
        </trans-unit>
        <trans-unit id="c11e8b0852264fedca1944abe570a02d58008f36" translate="yes" xml:space="preserve">
          <source>Launch utility</source>
          <target state="translated">ユーティリティの起動</target>
        </trans-unit>
        <trans-unit id="3e7347f29c1c343ae08ddd8deb4a8c8c703257a6" translate="yes" xml:space="preserve">
          <source>LayerNorm</source>
          <target state="translated">LayerNorm</target>
        </trans-unit>
        <trans-unit id="ae8648006d573eefab4fc3a540fa844d3c24c709" translate="yes" xml:space="preserve">
          <source>Leaky Relu</source>
          <target state="translated">漏れたレリュー</target>
        </trans-unit>
        <trans-unit id="f3272736528de0f5cd99ceafd394209cd4f0d9d4" translate="yes" xml:space="preserve">
          <source>LeakyRELU</source>
          <target state="translated">LeakyRELU</target>
        </trans-unit>
        <trans-unit id="fedab85703859b90b0ad1f8cd46b9b7ea93c8647" translate="yes" xml:space="preserve">
          <source>LeakyReLU</source>
          <target state="translated">LeakyReLU</target>
        </trans-unit>
        <trans-unit id="7422cede6b29fe51f9334794bb938ed3c22c4e55" translate="yes" xml:space="preserve">
          <source>Least squares estimation of the original signal of size (&amp;hellip;, signal_length)</source>
          <target state="translated">サイズの元の信号の最小二乗推定（&amp;hellip;、signal_length）</target>
        </trans-unit>
        <trans-unit id="81a9dc728fc2ca28b37b2c8b862e702ce61a20d2" translate="yes" xml:space="preserve">
          <source>Legacy Constructors</source>
          <target state="translated">レガシーコンストラクタ</target>
        </trans-unit>
        <trans-unit id="e6252983d84535ed576c200c0613bfb5c53e74f6" translate="yes" xml:space="preserve">
          <source>Let I_0 be the zeroth order modified Bessel function of the first kind (see &lt;a href=&quot;torch.i0#torch.i0&quot;&gt;&lt;code&gt;torch.i0()&lt;/code&gt;&lt;/a&gt;) and &lt;code&gt;N = L - 1&lt;/code&gt; if &lt;code&gt;periodic&lt;/code&gt; is False and &lt;code&gt;L&lt;/code&gt; if &lt;code&gt;periodic&lt;/code&gt; is True, where &lt;code&gt;L&lt;/code&gt; is the &lt;code&gt;window_length&lt;/code&gt;. This function computes:</source>
          <target state="translated">I_0は、ゼロ次は、第一種ベッセル関数を変性とする（参照&lt;a href=&quot;torch.i0#torch.i0&quot;&gt; &lt;code&gt;torch.i0()&lt;/code&gt; &lt;/a&gt;）及び &lt;code&gt;N = L - 1&lt;/code&gt; 場合 &lt;code&gt;periodic&lt;/code&gt; 偽となる &lt;code&gt;L&lt;/code&gt; 場合 &lt;code&gt;periodic&lt;/code&gt; ここで、真である &lt;code&gt;L&lt;/code&gt; がある &lt;code&gt;window_length&lt;/code&gt; 。この関数は以下を計算します：</target>
        </trans-unit>
        <trans-unit id="c0f4fa4a2a001fbe73eaa9b243479e76bce8ec6b" translate="yes" xml:space="preserve">
          <source>Let&amp;rsquo;s see how &lt;code&gt;match&lt;/code&gt; and &lt;code&gt;unify&lt;/code&gt; are used in name inference in the case of adding two one-dim tensors with no broadcasting.</source>
          <target state="translated">ブロードキャストなしで2つの1次元テンソルを追加する場合に、名前の推論で &lt;code&gt;match&lt;/code&gt; と &lt;code&gt;unify&lt;/code&gt; がどのように使用されるかを見てみましょう。</target>
        </trans-unit>
        <trans-unit id="27c968e6692b41bf6e1a241b870dc41ff1a51b17" translate="yes" xml:space="preserve">
          <source>Libraries</source>
          <target state="translated">Libraries</target>
        </trans-unit>
        <trans-unit id="538c09161b8497f998404cafc34964ed3a445575" translate="yes" xml:space="preserve">
          <source>Licensed under the 3-clause BSD License.</source>
          <target state="translated">3句BSDライセンスの下でライセンスされています。</target>
        </trans-unit>
        <trans-unit id="7f5f45ae757c1886e79dc62c9c379591270427af" translate="yes" xml:space="preserve">
          <source>Like &lt;em&gt;output&lt;/em&gt;, the layers can be separated using &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; and similarly for &lt;em&gt;c_n&lt;/em&gt;.</source>
          <target state="translated">&lt;em&gt;出力&lt;/em&gt;と同様に、レイヤーは &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; を使用して、&lt;em&gt;c_n&lt;/em&gt;についても同様に分離できます。</target>
        </trans-unit>
        <trans-unit id="db10501c95280d11842c24308a3aa239dbe03702" translate="yes" xml:space="preserve">
          <source>Like &lt;em&gt;output&lt;/em&gt;, the layers can be separated using &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt;.</source>
          <target state="translated">&lt;em&gt;出力&lt;/em&gt;と同様に、 &lt;code&gt;h_n.view(num_layers, num_directions, batch, hidden_size)&lt;/code&gt; を使用してレイヤーを分離できます。</target>
        </trans-unit>
        <trans-unit id="e802831cc6f03739c21444458e82e5daba72cf20" translate="yes" xml:space="preserve">
          <source>Like with &lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;, the output length must be given in order to recover an even length output:</source>
          <target state="translated">&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;と同様に、偶数の長さの出力を回復するには、出力の長さを指定する必要があります。</target>
        </trans-unit>
        <trans-unit id="a7c04c64ed3f2a9374590c76c50d3b7f1b18e3da" translate="yes" xml:space="preserve">
          <source>Limitations</source>
          <target state="translated">Limitations</target>
        </trans-unit>
        <trans-unit id="af502f2b37eea07ed9083c7daf40f34553f6fccd" translate="yes" xml:space="preserve">
          <source>Linear</source>
          <target state="translated">Linear</target>
        </trans-unit>
        <trans-unit id="52f5fe1a2af4bafc542342604407d9368527a7e4" translate="yes" xml:space="preserve">
          <source>Linear / Identity</source>
          <target state="translated">リニア/アイデンティティ</target>
        </trans-unit>
        <trans-unit id="462229a1c5dbd1fa15040281e0145c1fe6a072c6" translate="yes" xml:space="preserve">
          <source>Linear Layers</source>
          <target state="translated">リニアレイヤー</target>
        </trans-unit>
        <trans-unit id="e0948f7097c1b1ef0dfbf5426722f24d5359dce5" translate="yes" xml:space="preserve">
          <source>Linear functions</source>
          <target state="translated">線形関数</target>
        </trans-unit>
        <trans-unit id="034874347ef77609e931030e8022aaf9f02a5da3" translate="yes" xml:space="preserve">
          <source>LinearReLU</source>
          <target state="translated">LinearReLU</target>
        </trans-unit>
        <trans-unit id="2654ae5325afbc554a0ee441059fbb41cbaf1dbb" translate="yes" xml:space="preserve">
          <source>List Construction</source>
          <target state="translated">工事一覧</target>
        </trans-unit>
        <trans-unit id="92ca3314a6145558197b21fe52556246426b2528" translate="yes" xml:space="preserve">
          <source>List all entrypoints available in &lt;code&gt;github&lt;/code&gt; hubconf.</source>
          <target state="translated">で利用可能なすべてのエントリ・ポイント一覧表示 &lt;code&gt;github&lt;/code&gt; hubconfを。</target>
        </trans-unit>
        <trans-unit id="c7ba7dcf662374aafe652b03d75cb8f6024519d9" translate="yes" xml:space="preserve">
          <source>Literals</source>
          <target state="translated">Literals</target>
        </trans-unit>
        <trans-unit id="bd26911422165279d6cf54be6a2c3601b7d15a43" translate="yes" xml:space="preserve">
          <source>LnStructured</source>
          <target state="translated">LnStructured</target>
        </trans-unit>
        <trans-unit id="b0a48cb5954a9d7f0650f13e3620734ccd2bae05" translate="yes" xml:space="preserve">
          <source>Load a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; previously saved with &lt;a href=&quot;generated/torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">以前に&lt;a href=&quot;generated/torch.jit.save#torch.jit.save&quot;&gt; &lt;code&gt;torch.jit.save&lt;/code&gt; で&lt;/a&gt;保存された&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;generated/torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; を&lt;/a&gt;ロードします</target>
        </trans-unit>
        <trans-unit id="895bd8b16804ae34cfb0e2dc72b19fd2ce1623cf" translate="yes" xml:space="preserve">
          <source>Load a &lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt;&lt;code&gt;ScriptFunction&lt;/code&gt;&lt;/a&gt; previously saved with &lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt;&lt;code&gt;torch.jit.save&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">以前に&lt;a href=&quot;torch.jit.save#torch.jit.save&quot;&gt; &lt;code&gt;torch.jit.save&lt;/code&gt; で&lt;/a&gt;保存された&lt;a href=&quot;torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; &lt;/a&gt;または&lt;a href=&quot;torch.jit.scriptfunction#torch.jit.ScriptFunction&quot;&gt; &lt;code&gt;ScriptFunction&lt;/code&gt; を&lt;/a&gt;ロードします</target>
        </trans-unit>
        <trans-unit id="6cb35151312e0bc2bc2c91990968d299f6b351f9" translate="yes" xml:space="preserve">
          <source>Load a model from a github repo or a local directory.</source>
          <target state="translated">githubのレポまたはローカルディレクトリからモデルをロードします。</target>
        </trans-unit>
        <trans-unit id="08eab7f7a8aa4c317badff7188cc2c0bb5835fc2" translate="yes" xml:space="preserve">
          <source>Loading models from Hub</source>
          <target state="translated">ハブからのモデルの読み込み</target>
        </trans-unit>
        <trans-unit id="1df3601943ceea2bf72fecc57231a5842fe092bb" translate="yes" xml:space="preserve">
          <source>Loads a PyTorch C++ extension just-in-time (JIT) from string sources.</source>
          <target state="translated">PyTorch C++拡張機能のジャストインタイム(JIT)を文字列ソースからロードします。</target>
        </trans-unit>
        <trans-unit id="e0c28fcdf2966da4afbb699048a05d25a1e72589" translate="yes" xml:space="preserve">
          <source>Loads a PyTorch C++ extension just-in-time (JIT).</source>
          <target state="translated">PyTorch C++拡張のジャストインタイム(JIT)をロードします。</target>
        </trans-unit>
        <trans-unit id="b8172851e5d518987e24368975b30a3f3621f89a" translate="yes" xml:space="preserve">
          <source>Loads an object saved with &lt;a href=&quot;generated/torch.save#torch.save&quot;&gt;&lt;code&gt;torch.save()&lt;/code&gt;&lt;/a&gt; from a file.</source>
          <target state="translated">&lt;a href=&quot;generated/torch.save#torch.save&quot;&gt; &lt;code&gt;torch.save()&lt;/code&gt; で&lt;/a&gt;保存されたオブジェクトをファイルからロードします。</target>
        </trans-unit>
        <trans-unit id="abae7d5b43752c21e187437593ecfd6e103a310d" translate="yes" xml:space="preserve">
          <source>Loads an object saved with &lt;a href=&quot;torch.save#torch.save&quot;&gt;&lt;code&gt;torch.save()&lt;/code&gt;&lt;/a&gt; from a file.</source>
          <target state="translated">&lt;a href=&quot;torch.save#torch.save&quot;&gt; &lt;code&gt;torch.save()&lt;/code&gt; で&lt;/a&gt;保存されたオブジェクトをファイルからロードします。</target>
        </trans-unit>
        <trans-unit id="f2285e79b168630a8a2e0f5ae0c64959ab5ec6e8" translate="yes" xml:space="preserve">
          <source>Loads the Torch serialized object at the given URL.</source>
          <target state="translated">指定されたURLでTorchのシリアル化オブジェクトを読み込みます。</target>
        </trans-unit>
        <trans-unit id="bca03b832694245e7d76094e54b41aee61f32b8c" translate="yes" xml:space="preserve">
          <source>Local file system, &lt;code&gt;init_method=&quot;file:///d:/tmp/some_file&quot;&lt;/code&gt;</source>
          <target state="translated">ローカルファイルシステム、 &lt;code&gt;init_method=&quot;file:///d:/tmp/some_file&quot;&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="9e2a7f51460fa624f29eb4d9345e24061c3314f3" translate="yes" xml:space="preserve">
          <source>LocalResponseNorm</source>
          <target state="translated">LocalResponseNorm</target>
        </trans-unit>
        <trans-unit id="0ca5c78f2cf1102c66c5583023caa00fc87c10db" translate="yes" xml:space="preserve">
          <source>Locally disabling gradient computation</source>
          <target state="translated">勾配計算をローカルで無効にする</target>
        </trans-unit>
        <trans-unit id="5f6a43bda80ee771a5be7b5a9a5b959803eff8b6" translate="yes" xml:space="preserve">
          <source>LogSigmoid</source>
          <target state="translated">LogSigmoid</target>
        </trans-unit>
        <trans-unit id="9fcfd80b59ec37c0d7c822778e2ede78ad5ef865" translate="yes" xml:space="preserve">
          <source>LogSoftmax</source>
          <target state="translated">LogSoftmax</target>
        </trans-unit>
        <trans-unit id="2be6f5f3dfe34ae207c15144d936b394d3342629" translate="yes" xml:space="preserve">
          <source>Log_probs: Tensor of size</source>
          <target state="translated">Log_probs.サイズのテンソル</target>
        </trans-unit>
        <trans-unit id="3a29b9b1054fef950824734dd96565e57e322c96" translate="yes" xml:space="preserve">
          <source>Logarithm of the sum of exponentiations of the inputs in base-2.</source>
          <target state="translated">ベース2の入力の指数の和の対数。</target>
        </trans-unit>
        <trans-unit id="273c857a62012f5708232560c688d9c8f7c28ba5" translate="yes" xml:space="preserve">
          <source>Logarithm of the sum of exponentiations of the inputs.</source>
          <target state="translated">入力の指数の和の対数。</target>
        </trans-unit>
        <trans-unit id="65eac6118ebdd55aa38b41f70efdf532e567ffd8" translate="yes" xml:space="preserve">
          <source>Logical Operators</source>
          <target state="translated">論理演算子</target>
        </trans-unit>
        <trans-unit id="4e1da61dedde155219f888017b4095799b14e811" translate="yes" xml:space="preserve">
          <source>LongTensor or tuple of LongTensor</source>
          <target state="translated">LongTensorまたはLongTensorのタプル</target>
        </trans-unit>
        <trans-unit id="79894b78077b352e7913286a38c3c0b109363b18" translate="yes" xml:space="preserve">
          <source>LongTensor that has one more dimension with 1 values at the index of last dimension indicated by the input, and 0 everywhere else.</source>
          <target state="translated">入力で示された最後の次元のインデックスに1の値を持ち,それ以外の場所では0の値を持つ,もう1つの次元を持つLongTensor.</target>
        </trans-unit>
        <trans-unit id="5889a83849e7452eb90474433b00a93e8ed08a2f" translate="yes" xml:space="preserve">
          <source>Look at the paper: &lt;a href=&quot;https://arxiv.org/abs/1609.05158&quot;&gt;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network&lt;/a&gt; by Shi et. al (2016) for more details.</source>
          <target state="translated">論文を見てください：Shiらによる&lt;a href=&quot;https://arxiv.org/abs/1609.05158&quot;&gt;効率的なサブピクセル畳み込みニューラルネットワークを使用したリアルタイムの単一画像とビデオの超解像&lt;/a&gt;。詳細については、al（2016）を参照してください。</target>
        </trans-unit>
        <trans-unit id="c0224525e6e81a08ff829f4d53c8aff4b15f7024" translate="yes" xml:space="preserve">
          <source>Loss Functions</source>
          <target state="translated">損失機能</target>
        </trans-unit>
        <trans-unit id="bf3496193ce471c7c1c432d246ad87b6a1823e9c" translate="yes" xml:space="preserve">
          <source>Loss functions</source>
          <target state="translated">損失機能</target>
        </trans-unit>
        <trans-unit id="85b9d89a2ed9217bacdf503e6a3c96f95e5750aa" translate="yes" xml:space="preserve">
          <source>Lots of information can be logged for one experiment. To avoid cluttering the UI and have better result clustering, we can group plots by naming them hierarchically. For example, &amp;ldquo;Loss/train&amp;rdquo; and &amp;ldquo;Loss/test&amp;rdquo; will be grouped together, while &amp;ldquo;Accuracy/train&amp;rdquo; and &amp;ldquo;Accuracy/test&amp;rdquo; will be grouped separately in the TensorBoard interface.</source>
          <target state="translated">1回の実験で多くの情報を記録できます。UIの乱雑さを回避し、より良い結果のクラスタリングを実現するために、プロットに階層的な名前を付けてグループ化できます。たとえば、「Loss / train」と「Loss / test」はグループ化され、「Accuracy / train」と「Accuracy / test」はTensorBoardインターフェースで別々にグループ化されます。</target>
        </trans-unit>
        <trans-unit id="c63ae6dd4fc9f9dda66970e827d13f7c73fe841c" translate="yes" xml:space="preserve">
          <source>M</source>
          <target state="translated">M</target>
        </trans-unit>
        <trans-unit id="a452071172e433a963ff286fe987870a980f2d28" translate="yes" xml:space="preserve">
          <source>M (Tensor, optional): the input tensor&amp;rsquo;s mean of size</source>
          <target state="translated">M（テンソル、オプション）：入力テンソルのサイズの平均</target>
        </trans-unit>
        <trans-unit id="7b186e235f284107df6b4dbe6060d2b6a5d9f1e5" translate="yes" xml:space="preserve">
          <source>MAX</source>
          <target state="translated">MAX</target>
        </trans-unit>
        <trans-unit id="0d96af233d36586b84359d8b5bd0b417787982e1" translate="yes" xml:space="preserve">
          <source>MC3 Network definition</source>
          <target state="translated">MC3 ネットワーク定義</target>
        </trans-unit>
        <trans-unit id="04e66352aa8f9c4c5f26b71bf380973ada994760" translate="yes" xml:space="preserve">
          <source>MIN</source>
          <target state="translated">MIN</target>
        </trans-unit>
        <trans-unit id="351682e4dc04204d75a824bcbf8f8aa6acc15e71" translate="yes" xml:space="preserve">
          <source>MIXED MODE OF (1) and (2):</source>
          <target state="translated">(1)と(2)のミックスモード。</target>
        </trans-unit>
        <trans-unit id="59ce6264cd26f13684de464b9aeb65d1d414e559" translate="yes" xml:space="preserve">
          <source>MNASNet</source>
          <target state="translated">MNASNet</target>
        </trans-unit>
        <trans-unit id="533bea2ee6c045fe09ac0124525af723616f331a" translate="yes" xml:space="preserve">
          <source>MNASNet 1.0</source>
          <target state="translated">MNASNet 1.0</target>
        </trans-unit>
        <trans-unit id="9a7425f07104beddfc0bce0274310b0a2e2ea359" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 0.5 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が0.5のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="98e07c23513158f84ea34588dbe9369dbc7ac20e" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 0.75 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が0.75のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="71754b43c6a0483cdc892a42e6511e7a6757f6a2" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 1.0 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：プラットフォーム対応のモバイル向けニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数が1.0のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="6f35e9dd2bd116147e38d35cef6e82d4b56bfc05" translate="yes" xml:space="preserve">
          <source>MNASNet with depth multiplier of 1.3 from &lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;&amp;ldquo;MnasNet: Platform-Aware Neural Architecture Search for Mobile&amp;rdquo;&lt;/a&gt;. :param pretrained: If True, returns a model pre-trained on ImageNet :type pretrained: bool :param progress: If True, displays a progress bar of the download to stderr :type progress: bool</source>
          <target state="translated">&lt;a href=&quot;https://arxiv.org/pdf/1807.11626.pdf&quot;&gt;「MnasNet：モバイル向けプラットフォーム対応ニューラルアーキテクチャ検索」の&lt;/a&gt;深度乗数1.3のMNASNet。：param pretrained：Trueの場合、ImageNetで事前トレーニングされたモデルを返します：type pretrained：bool：param progress：Trueの場合、ダウンロードの進行状況バーをstderrに表示します：type progress：bool</target>
        </trans-unit>
        <trans-unit id="53880fd71eeaa5e41a5d925ca0243b4befcdb092" translate="yes" xml:space="preserve">
          <source>MSELoss</source>
          <target state="translated">MSELoss</target>
        </trans-unit>
        <trans-unit id="76c7044fa78115fa06a42c399d17d51a9203e830" translate="yes" xml:space="preserve">
          <source>Make a blocking RPC call to run function &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt;. RPC messages are sent and received in parallel to execution of Python code. This method is thread-safe.</source>
          <target state="translated">関数を実行するには、ブロッキングRPCコールしてください &lt;code&gt;func&lt;/code&gt; 作業者 &lt;code&gt;to&lt;/code&gt; 。RPCメッセージは、Pythonコードの実行と並行して送受信されます。このメソッドはスレッドセーフです。</target>
        </trans-unit>
        <trans-unit id="0d7820212a00c819e77e602a3ef50edfe2f50d52" translate="yes" xml:space="preserve">
          <source>Make a non-blocking RPC call to run function &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt;. RPC messages are sent and received in parallel to execution of Python code. This method is thread-safe. This method will immediately return a &lt;a href=&quot;futures#torch.futures.Future&quot;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; that can be awaited on.</source>
          <target state="translated">ノンブロッキングRPC呼び出しを行って、ワーカーで関数 &lt;code&gt;func&lt;/code&gt; を実行 &lt;code&gt;to&lt;/code&gt; ます。RPCメッセージは、Pythonコードの実行と並行して送受信されます。このメソッドはスレッドセーフです。このメソッドは、&lt;a href=&quot;futures#torch.futures.Future&quot;&gt; &lt;code&gt;Future&lt;/code&gt; &lt;/a&gt;可能なFutureをすぐに返します。</target>
        </trans-unit>
        <trans-unit id="f221c8d616e55bc62ec21b79af5d8282f107f2d3" translate="yes" xml:space="preserve">
          <source>Make a remote call to run &lt;code&gt;func&lt;/code&gt; on worker &lt;code&gt;to&lt;/code&gt; and return an &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; to the result value immediately. Worker &lt;code&gt;to&lt;/code&gt; will be the owner of the returned &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt;, and the worker calling &lt;code&gt;remote&lt;/code&gt; is a user. The owner manages the global reference count of its &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt;, and the owner &lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt;&lt;code&gt;RRef&lt;/code&gt;&lt;/a&gt; is only destructed when globally there are no living references to it.</source>
          <target state="translated">実行するためのリモート呼び出してください &lt;code&gt;func&lt;/code&gt; を労働者に &lt;code&gt;to&lt;/code&gt; と戻り&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;すぐに結果値にします。労働者 &lt;code&gt;to&lt;/code&gt; 返却の所有者になります&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;、および呼び出し元作業員 &lt;code&gt;remote&lt;/code&gt; ユーザーです。所有者は、その&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; の&lt;/a&gt;グローバル参照カウントを管理し、所有者&lt;a href=&quot;#torch.distributed.rpc.RRef&quot;&gt; &lt;code&gt;RRef&lt;/code&gt; &lt;/a&gt;は、グローバルに参照が存在しない場合にのみ破棄されます。</target>
        </trans-unit>
        <trans-unit id="f909b867fd9b369b49e7c33ae5b4db26cd626b58" translate="yes" xml:space="preserve">
          <source>Make sure that &lt;code&gt;MASTER_ADDR&lt;/code&gt; and &lt;code&gt;MASTER_PORT&lt;/code&gt; are set properly on both workers. Refer to &lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt;&lt;code&gt;init_process_group()&lt;/code&gt;&lt;/a&gt; API for more details. For example,</source>
          <target state="translated">&lt;code&gt;MASTER_ADDR&lt;/code&gt; と &lt;code&gt;MASTER_PORT&lt;/code&gt; が両方のワーカーで正しく設定されていることを確認してください。詳細については、&lt;a href=&quot;distributed#torch.distributed.init_process_group&quot;&gt; &lt;code&gt;init_process_group()&lt;/code&gt; &lt;/a&gt; APIを参照してください。例えば、</target>
        </trans-unit>
        <trans-unit id="3140663730440e28711adcbaaf1e5be8f31a832b" translate="yes" xml:space="preserve">
          <source>Makes a &lt;code&gt;cls&lt;/code&gt; instance with the same data pointer as &lt;code&gt;self&lt;/code&gt;. Changes in the output mirror changes in &lt;code&gt;self&lt;/code&gt;, and the output stays attached to the autograd graph. &lt;code&gt;cls&lt;/code&gt; must be a subclass of &lt;code&gt;Tensor&lt;/code&gt;.</source>
          <target state="translated">なる &lt;code&gt;cls&lt;/code&gt; と同じデータポインタを使用してインスタンスを &lt;code&gt;self&lt;/code&gt; 。出力ミラーの変化は &lt;code&gt;self&lt;/code&gt; で変化し、出力はautogradグラフにアタッチされたままになります。 &lt;code&gt;cls&lt;/code&gt; は &lt;code&gt;Tensor&lt;/code&gt; のサブクラスである必要があります。</target>
        </trans-unit>
        <trans-unit id="49e2977180d59fe62d760df21fb871ec41183f71" translate="yes" xml:space="preserve">
          <source>Manipulating dimensions</source>
          <target state="translated">寸法の操作</target>
        </trans-unit>
        <trans-unit id="6d825496aa8e7368b658938db8b142e79e1f39ee" translate="yes" xml:space="preserve">
          <source>Many PyTorch functions, which return a view of a tensor, are internally implemented with this function. Those functions, like &lt;a href=&quot;../tensors#torch.Tensor.expand&quot;&gt;&lt;code&gt;torch.Tensor.expand()&lt;/code&gt;&lt;/a&gt;, are easier to read and are therefore more advisable to use.</source>
          <target state="translated">テンソルのビューを返す多くのPyTorch関数は、この関数で内部的に実装されています。&lt;a href=&quot;../tensors#torch.Tensor.expand&quot;&gt; &lt;code&gt;torch.Tensor.expand()&lt;/code&gt; の&lt;/a&gt;ようなこれらの関数は読みやすいため、使用することをお勧めします。</target>
        </trans-unit>
        <trans-unit id="877edbec3bdc8c92a89c77b353c1bffa8a6d3f53" translate="yes" xml:space="preserve">
          <source>Many of Python&amp;rsquo;s &lt;a href=&quot;https://docs.python.org/3/library/functions.html&quot;&gt;built-in functions&lt;/a&gt; are supported in TorchScript. The &lt;a href=&quot;https://docs.python.org/3/library/math.html#module-math&quot;&gt;&lt;code&gt;math&lt;/code&gt;&lt;/a&gt; module is also supported (see &lt;a href=&quot;jit_builtin_functions#math-module&quot;&gt;math Module&lt;/a&gt; for details), but no other Python modules (built-in or third party) are supported.</source>
          <target state="translated">Pythonの&lt;a href=&quot;https://docs.python.org/3/library/functions.html&quot;&gt;組み込み関数の&lt;/a&gt;多くは、TorchScriptでサポートされています。&lt;a href=&quot;https://docs.python.org/3/library/math.html#module-math&quot;&gt; &lt;code&gt;math&lt;/code&gt; &lt;/a&gt;モジュールはまた、（参照サポートされている&lt;a href=&quot;jit_builtin_functions#math-module&quot;&gt;数学のモジュールの&lt;/a&gt;詳細については）が、他のPythonモジュール（ビルトインまたは第三者）がサポートされていません。</target>
        </trans-unit>
        <trans-unit id="8b9cac864fb0630d3e0375c972324ae14f0a7cbf" translate="yes" xml:space="preserve">
          <source>MarginRankingLoss</source>
          <target state="translated">MarginRankingLoss</target>
        </trans-unit>
        <trans-unit id="3b3b6161e2be4020ea8045bf777a1b7a9a9ef9d7" translate="yes" xml:space="preserve">
          <source>Mask R-CNN</source>
          <target state="translated">マスク R-CNN</target>
        </trans-unit>
        <trans-unit id="de79ab812f56430c47ab7094aa9e5f95c476c9d5" translate="yes" xml:space="preserve">
          <source>Mask R-CNN ResNet-50 FPN</source>
          <target state="translated">マスク R-CNN ResNet-50 FPN</target>
        </trans-unit>
        <trans-unit id="e283616925f71932f219908f30d53b3df610dd54" translate="yes" xml:space="preserve">
          <source>Mask R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.</source>
          <target state="translated">マスクR-CNNは、一定サイズの入力画像で一定のバッチサイズでONNXに書き出すことができます。</target>
        </trans-unit>
        <trans-unit id="370101c55e76bb32e62a76c0f757b67a5a083820" translate="yes" xml:space="preserve">
          <source>Math operations</source>
          <target state="translated">数学演算</target>
        </trans-unit>
        <trans-unit id="f266f996d2555bfc5ac129ce470aa82f278b2388" translate="yes" xml:space="preserve">
          <source>Matrix multiplication ops: &lt;a href=&quot;name_inference#contracts-away-dims-doc&quot;&gt;Contracts away dims&lt;/a&gt;</source>
          <target state="translated">行列乗算演算：&lt;a href=&quot;name_inference#contracts-away-dims-doc&quot;&gt;ディムを縮小します&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="7a75fc5d78987f3dab3a65065c4b1d4f0692e098" translate="yes" xml:space="preserve">
          <source>Matrix product of two tensors.</source>
          <target state="translated">2つのテンソルの行列積。</target>
        </trans-unit>
        <trans-unit id="eccdf32fe79dd9c576c8118d98c630238fca6bb7" translate="yes" xml:space="preserve">
          <source>MaxPool1d</source>
          <target state="translated">MaxPool1d</target>
        </trans-unit>
        <trans-unit id="3b3d541959fe8a8dd18b510e5a3f48b2498a53b4" translate="yes" xml:space="preserve">
          <source>MaxPool2d</source>
          <target state="translated">MaxPool2d</target>
        </trans-unit>
        <trans-unit id="98908ed042b1a9862ea5e9d4da6ed687e958f368" translate="yes" xml:space="preserve">
          <source>MaxPool3d</source>
          <target state="translated">MaxPool3d</target>
        </trans-unit>
        <trans-unit id="4a5419bdd0aea2636e49e9d7ca08451ce7530629" translate="yes" xml:space="preserve">
          <source>MaxUnpool1d</source>
          <target state="translated">MaxUnpool1d</target>
        </trans-unit>
        <trans-unit id="dde49d17029a94b9195f0444462e31e369394942" translate="yes" xml:space="preserve">
          <source>MaxUnpool2d</source>
          <target state="translated">MaxUnpool2d</target>
        </trans-unit>
        <trans-unit id="cbb9a5d6b569b7fb0a0f22c9d9d9d31e12466046" translate="yes" xml:space="preserve">
          <source>MaxUnpool3d</source>
          <target state="translated">MaxUnpool3d</target>
        </trans-unit>
        <trans-unit id="fe4de202eb4956062e7cfb72ed4b684ffbb5bd30" translate="yes" xml:space="preserve">
          <source>Measures the element-wise mean squared error.</source>
          <target state="translated">要素ごとの平均二乗誤差を測定します。</target>
        </trans-unit>
        <trans-unit id="09b86d975dd6b1f5a73e1c3517013bb23d540761" translate="yes" xml:space="preserve">
          <source>Measures the loss given an input tensor</source>
          <target state="translated">入力テンソルが与えられたときの損失を測定</target>
        </trans-unit>
        <trans-unit id="1d01e0fee07072aec458beb4c034b607f10f63a9" translate="yes" xml:space="preserve">
          <source>Members:</source>
          <target state="translated">Members:</target>
        </trans-unit>
        <trans-unit id="7c5f0da2191ca27795b8631522c1ca879f1716c9" translate="yes" xml:space="preserve">
          <source>Method Calls</source>
          <target state="translated">メソッド呼び出し</target>
        </trans-unit>
        <trans-unit id="b69c14783d5324daa62920c742f93c096f643f4f" translate="yes" xml:space="preserve">
          <source>Methods which mutate a tensor are marked with an underscore suffix. For example, &lt;code&gt;torch.FloatTensor.abs_()&lt;/code&gt; computes the absolute value in-place and returns the modified tensor, while &lt;code&gt;torch.FloatTensor.abs()&lt;/code&gt; computes the result in a new tensor.</source>
          <target state="translated">テンソルを変更するメソッドには、アンダースコアの接尾辞が付いています。たとえば、 &lt;code&gt;torch.FloatTensor.abs_()&lt;/code&gt; はインプレースで絶対値を計算し、変更されたテンソルを返しますが、 &lt;code&gt;torch.FloatTensor.abs()&lt;/code&gt; は新しいテンソルで結果を計算します。</target>
        </trans-unit>
        <trans-unit id="9b7c339ea87ccc784ad1deadd85bf646248e9d73" translate="yes" xml:space="preserve">
          <source>Methods which take a device will generally accept a (properly formatted) string or (legacy) integer device ordinal, i.e. the following are all equivalent:</source>
          <target state="translated">デバイスを受け取るメソッドは、一般的に(適切にフォーマットされた)文字列または(レガシーな)整数のデバイス序数を受け入れます。</target>
        </trans-unit>
        <trans-unit id="e067f6663a0605e92a7219ee53ccfb43fa76eaf3" translate="yes" xml:space="preserve">
          <source>Migrating to PyTorch 1.2 Recursive Scripting API</source>
          <target state="translated">PyTorch 1.2 Recursive Scripting APIへの移行</target>
        </trans-unit>
        <trans-unit id="ff26bc094b922f3c06f27a4d1e69dcd28d4c0e3c" translate="yes" xml:space="preserve">
          <source>Mixing Tracing and Scripting</source>
          <target state="translated">トレースとスクリプトの混合</target>
        </trans-unit>
        <trans-unit id="9ff690f5176e9e122a08292f5ff8b357a6c354e0" translate="yes" xml:space="preserve">
          <source>MobileNet V2</source>
          <target state="translated">モバイルネットV2</target>
        </trans-unit>
        <trans-unit id="c901047dcc843db7018568e9b72b5dbf5a54540d" translate="yes" xml:space="preserve">
          <source>MobileNet v2</source>
          <target state="translated">モバイルネット v2</target>
        </trans-unit>
        <trans-unit id="b8ff02892916ff59f7fbd4e617fccd01f6bca576" translate="yes" xml:space="preserve">
          <source>Module</source>
          <target state="translated">Module</target>
        </trans-unit>
        <trans-unit id="9c3f2aba6913de8da00faed8e2df2428bb1257b7" translate="yes" xml:space="preserve">
          <source>Module Attributes</source>
          <target state="translated">モジュール属性</target>
        </trans-unit>
        <trans-unit id="3cb22c5e4eabc0e7d3ccf2b60e66f53421b63149" translate="yes" xml:space="preserve">
          <source>Module Index</source>
          <target state="translated">モジュールインデックス</target>
        </trans-unit>
        <trans-unit id="0b2ce983642fdce8da88af1aafe61bc6a6ee4bfb" translate="yes" xml:space="preserve">
          <source>ModuleDict</source>
          <target state="translated">ModuleDict</target>
        </trans-unit>
        <trans-unit id="e12ef0c5e95f31ebc597e0b6fd821d6b604f3f95" translate="yes" xml:space="preserve">
          <source>ModuleList</source>
          <target state="translated">ModuleList</target>
        </trans-unit>
        <trans-unit id="04e9462c0ff02bb9032b92abd45881a3c7e15fb7" translate="yes" xml:space="preserve">
          <source>Modules</source>
          <target state="translated">Modules</target>
        </trans-unit>
        <trans-unit id="9dbae4788d0b2dea68c6e66c9e0ff2aed52f652e" translate="yes" xml:space="preserve">
          <source>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:</source>
          <target state="translated">モジュールは他のモジュールを含むこともでき、ツリー構造の中に入れ子にすることができます。サブモジュールを通常の属性として割り当てることができます。</target>
        </trans-unit>
        <trans-unit id="4a649c7ebd14c451b9eadae1b57b3c6722590226" translate="yes" xml:space="preserve">
          <source>More Information about RPC Autograd</source>
          <target state="translated">RPCオートグラッドの詳細情報</target>
        </trans-unit>
        <trans-unit id="9cb54dedb558ff4177e32b924117d76eb6014c23" translate="yes" xml:space="preserve">
          <source>More Information about RRef</source>
          <target state="translated">RRefの詳細情報</target>
        </trans-unit>
        <trans-unit id="cea97ccd7b3c8bf2304a429a1f4a38f55fbcf7bc" translate="yes" xml:space="preserve">
          <source>More details can be found in the paper &lt;a href=&quot;https://arxiv.org/abs/1704.07483&quot;&gt;Continuously Differentiable Exponential Linear Units&lt;/a&gt; .</source>
          <target state="translated">詳細については、論文「&lt;a href=&quot;https://arxiv.org/abs/1704.07483&quot;&gt;連続微分可能指数線形単位」を&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="4458c625976778e29149ea1b97ed51860f9fe8ca" translate="yes" xml:space="preserve">
          <source>More details can be found in the paper &lt;a href=&quot;https://arxiv.org/abs/1706.02515&quot;&gt;Self-Normalizing Neural Networks&lt;/a&gt; .</source>
          <target state="translated">詳細については、論文&lt;a href=&quot;https://arxiv.org/abs/1706.02515&quot;&gt;Self-Normalizing NeuralNetworksを&lt;/a&gt;参照してください。</target>
        </trans-unit>
        <trans-unit id="8edf225c0a72c5fe13ece57cbf2f54c6b24e17b0" translate="yes" xml:space="preserve">
          <source>More than one element of a broadcasted tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">ブロードキャストされたテンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、場内演算(特にベクトル化されているもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="1d81819b85f2cb3da872c9da3d0ec33cdc7aecdb" translate="yes" xml:space="preserve">
          <source>More than one element of a created tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">作成されたテンソルの1つ以上の要素が1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルに書き込む必要がある場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="304f7ec57645990453077c598f4fe8c37d2314ab" translate="yes" xml:space="preserve">
          <source>More than one element of an expanded tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">展開テンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、場内演算(特にベクトル化されているもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="f38e0558c4bf9056c21ea63c5960cbf11fd1b539" translate="yes" xml:space="preserve">
          <source>More than one element of the created tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensors, please clone them first.</source>
          <target state="translated">作成されたテンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルに書き込む必要がある場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="599668aa340279a3862bca37e7e4a6db462ba962" translate="yes" xml:space="preserve">
          <source>More than one element of the unfolded tensor may refer to a single memory location. As a result, in-place operations (especially ones that are vectorized) may result in incorrect behavior. If you need to write to the tensor, please clone it first.</source>
          <target state="translated">展開テンソルの1つ以上の要素は、1つのメモリ位置を参照することがあります。その結果、インプレース操作(特にベクトル化されたもの)を行うと、正しくない動作になることがあります。テンソルへの書き込みが必要な場合は、まずテンソルをクローンしてください。</target>
        </trans-unit>
        <trans-unit id="805667fbfb7f6f1745944861662036a8e58f3c82" translate="yes" xml:space="preserve">
          <source>Moreover, as for &lt;a href=&quot;#torch.Tensor.gather&quot;&gt;&lt;code&gt;gather()&lt;/code&gt;&lt;/a&gt;, the values of &lt;code&gt;index&lt;/code&gt; must be between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;self.size(dim) - 1&lt;/code&gt; inclusive, and all values in a row along the specified dimension &lt;a href=&quot;#torch.Tensor.dim&quot;&gt;&lt;code&gt;dim&lt;/code&gt;&lt;/a&gt; must be unique.</source>
          <target state="translated">また、の場合と同様&lt;a href=&quot;#torch.Tensor.gather&quot;&gt; &lt;code&gt;gather()&lt;/code&gt; &lt;/a&gt;の値 &lt;code&gt;index&lt;/code&gt; の間でなければならない &lt;code&gt;0&lt;/code&gt; と &lt;code&gt;self.size(dim) - 1&lt;/code&gt; 包括的、および指定された次元に沿って一列のすべての値&lt;a href=&quot;#torch.Tensor.dim&quot;&gt; &lt;code&gt;dim&lt;/code&gt; &lt;/a&gt;一意でなければなりません。</target>
        </trans-unit>
        <trans-unit id="dbc5f1c387e0131e10dadc48c7f1ed13f16fda56" translate="yes" xml:space="preserve">
          <source>Most attribute types can be inferred, so &lt;code&gt;torch.jit.Attribute&lt;/code&gt; is not necessary. For empty container types, annotate their types using &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;PEP 526-style&lt;/a&gt; class annotations.</source>
          <target state="translated">ほとんどの属性タイプは推測できるため、 &lt;code&gt;torch.jit.Attribute&lt;/code&gt; は必要ありません。空のコンテナタイプの場合は、PEP526&lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/#class-and-instance-variable-annotations&quot;&gt;スタイルの&lt;/a&gt;クラスアノテーションを使用してタイプにアノテーションを付けます。</target>
        </trans-unit>
        <trans-unit id="ed994a7cd5d0a3520430a627f9865ebc68ca6011" translate="yes" xml:space="preserve">
          <source>Moved to &lt;code&gt;torch.hub&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;torch.hub&lt;/code&gt; に移動しました。</target>
        </trans-unit>
        <trans-unit id="2b0f27b71a53a0f7447384ac613f55c4204b1204" translate="yes" xml:space="preserve">
          <source>Moves all model parameters and buffers to the CPU.</source>
          <target state="translated">すべてのモデルパラメータとバッファをCPUに移動します。</target>
        </trans-unit>
        <trans-unit id="e8a79081679af4528b212d87c458a607691d5b3e" translate="yes" xml:space="preserve">
          <source>Moves all model parameters and buffers to the GPU.</source>
          <target state="translated">すべてのモデルパラメータとバッファをGPUに移動します。</target>
        </trans-unit>
        <trans-unit id="e874c62b11df47c2d692fb8935adeff7a382eea3" translate="yes" xml:space="preserve">
          <source>Moves and/or casts the parameters and buffers.</source>
          <target state="translated">パラメータとバッファを移動および/またはキャストします。</target>
        </trans-unit>
        <trans-unit id="7729e2003ebf66fb44071aeaadd11a5376f40f12" translate="yes" xml:space="preserve">
          <source>Moves the dimension(s) of &lt;code&gt;input&lt;/code&gt; at the position(s) in &lt;code&gt;source&lt;/code&gt; to the position(s) in &lt;code&gt;destination&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;source&lt;/code&gt; の位置の &lt;code&gt;input&lt;/code&gt; の次元を &lt;code&gt;destination&lt;/code&gt; の位置に移動します。</target>
        </trans-unit>
        <trans-unit id="35ac3446a4eebf31c31aeb5dad10efd9c64f3049" translate="yes" xml:space="preserve">
          <source>Moves the storage to shared memory.</source>
          <target state="translated">ストレージを共有メモリに移動します。</target>
        </trans-unit>
        <trans-unit id="7b5555e73ea9cfb4e4bc00be9e2f28d1b533e2f3" translate="yes" xml:space="preserve">
          <source>Moves the underlying storage to shared memory.</source>
          <target state="translated">基盤となるストレージを共有メモリに移動します。</target>
        </trans-unit>
        <trans-unit id="8a37b99360165eb79c6362b8c59ca260f24fc9e9" translate="yes" xml:space="preserve">
          <source>Multi-GPU collective functions</source>
          <target state="translated">マルチGPUの集合機能</target>
        </trans-unit>
        <trans-unit id="f8c9042e53df42e885d4b0f01c778b6c31356f24" translate="yes" xml:space="preserve">
          <source>Multi-Node multi-process distributed training: (e.g. two nodes)</source>
          <target state="translated">マルチノード・マルチプロセス分散訓練。(例:2ノード)</target>
        </trans-unit>
        <trans-unit id="e8e85a354a72efff2947c00f8ff7c48fed5f6652" translate="yes" xml:space="preserve">
          <source>MultiHead</source>
          <target state="translated">MultiHead</target>
        </trans-unit>
        <trans-unit id="aaf9b486dc5c2543a40061716ec697ddb8e0fbae" translate="yes" xml:space="preserve">
          <source>MultiLabelMarginLoss</source>
          <target state="translated">MultiLabelMarginLoss</target>
        </trans-unit>
        <trans-unit id="0bd3257d9c850deeb628f346481873a6ea866f39" translate="yes" xml:space="preserve">
          <source>MultiLabelSoftMarginLoss</source>
          <target state="translated">MultiLabelSoftMarginLoss</target>
        </trans-unit>
        <trans-unit id="65baaa8172153705ce14a7161536175046e824b3" translate="yes" xml:space="preserve">
          <source>MultiMarginLoss</source>
          <target state="translated">MultiMarginLoss</target>
        </trans-unit>
        <trans-unit id="d53b7a9617160a0821d5bb5cb1a941ffdfcd6b08" translate="yes" xml:space="preserve">
          <source>MultiheadAttention</source>
          <target state="translated">MultiheadAttention</target>
        </trans-unit>
        <trans-unit id="7814aed0b837819b215ee4613ccc9b3a4ba6040e" translate="yes" xml:space="preserve">
          <source>Multiple Assignments</source>
          <target state="translated">複数の課題</target>
        </trans-unit>
        <trans-unit id="67620498370f67e43d30e9f331640d50be1f106c" translate="yes" xml:space="preserve">
          <source>Multiplies &lt;code&gt;mat&lt;/code&gt; (given by &lt;code&gt;input3&lt;/code&gt;) by the orthogonal &lt;code&gt;Q&lt;/code&gt; matrix of the QR factorization formed by &lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt; that is represented by &lt;code&gt;(a, tau)&lt;/code&gt; (given by (&lt;code&gt;input&lt;/code&gt;, &lt;code&gt;input2&lt;/code&gt;)).</source>
          <target state="translated">乗算の &lt;code&gt;mat&lt;/code&gt; （によって与え &lt;code&gt;input3&lt;/code&gt; 直交による） &lt;code&gt;Q&lt;/code&gt; により形成されたQR分解の行列&lt;a href=&quot;generated/torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;で表される &lt;code&gt;(a, tau)&lt;/code&gt; （で与えられる（ &lt;code&gt;input&lt;/code&gt; 、 &lt;code&gt;input2&lt;/code&gt; ））。</target>
        </trans-unit>
        <trans-unit id="76de5400e24dedf164da206bd33a31ebb079cf8f" translate="yes" xml:space="preserve">
          <source>Multiplies &lt;code&gt;mat&lt;/code&gt; (given by &lt;code&gt;input3&lt;/code&gt;) by the orthogonal &lt;code&gt;Q&lt;/code&gt; matrix of the QR factorization formed by &lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt;&lt;code&gt;torch.geqrf()&lt;/code&gt;&lt;/a&gt; that is represented by &lt;code&gt;(a, tau)&lt;/code&gt; (given by (&lt;code&gt;input&lt;/code&gt;, &lt;code&gt;input2&lt;/code&gt;)).</source>
          <target state="translated">乗算の &lt;code&gt;mat&lt;/code&gt; （によって与え &lt;code&gt;input3&lt;/code&gt; 直交による） &lt;code&gt;Q&lt;/code&gt; により形成されたQR分解の行列&lt;a href=&quot;torch.geqrf#torch.geqrf&quot;&gt; &lt;code&gt;torch.geqrf()&lt;/code&gt; &lt;/a&gt;で表される &lt;code&gt;(a, tau)&lt;/code&gt; （で与えられる（ &lt;code&gt;input&lt;/code&gt; 、 &lt;code&gt;input2&lt;/code&gt; ））。</target>
        </trans-unit>
        <trans-unit id="329fd1dd91c45edaf7c72f188795f5545aaec268" translate="yes" xml:space="preserve">
          <source>Multiplies each element of the input &lt;code&gt;input&lt;/code&gt; with the scalar &lt;code&gt;other&lt;/code&gt; and returns a new resulting tensor.</source>
          <target state="translated">入力 &lt;code&gt;input&lt;/code&gt; 各要素にスカラー &lt;code&gt;other&lt;/code&gt; を乗算し、結果の新しいテンソルを返します。</target>
        </trans-unit>
        <trans-unit id="4d2004ec3a414cc551a0c27958276999f72ee752" translate="yes" xml:space="preserve">
          <source>Multiprocessing best practices</source>
          <target state="translated">マルチプロセッシングのベストプラクティス</target>
        </trans-unit>
        <trans-unit id="b51a60734da64be0e618bacbea2865a8a7dcd669" translate="yes" xml:space="preserve">
          <source>N</source>
          <target state="translated">N</target>
        </trans-unit>
        <trans-unit id="129ca909e4d3ed97aba21ae73582b3bd13e114f8" translate="yes" xml:space="preserve">
          <source>N = \text{batch size}</source>
          <target state="translated">N=ﾃｷｽﾄ{ﾊﾞｯﾁｻｲｽﾞ}の場合</target>
        </trans-unit>
        <trans-unit id="9008c254267c7b8e353b34e82cc9a3ccdffad81e" translate="yes" xml:space="preserve">
          <source>N \times 2 \times 3</source>
          <target state="translated">N 尊い時間 2 尊い時間 3</target>
        </trans-unit>
        <trans-unit id="1b8b351ea25ef1c009076f028a05723a16aa0eb6" translate="yes" xml:space="preserve">
          <source>N \times 3 \times 4</source>
          <target state="translated">♪ N \times 3 ¶times 4</target>
        </trans-unit>
        <trans-unit id="004d23aba5b55baf9486f9aab3e50a94de7147b2" translate="yes" xml:space="preserve">
          <source>N \times C \times D \times H \times W</source>
          <target state="translated">N \times C ″\times D ″\times H ″\times W</target>
        </trans-unit>
        <trans-unit id="14734700ec8d366b9e0bb39033413068e35b488f" translate="yes" xml:space="preserve">
          <source>N \times C \times H \times W</source>
          <target state="translated">N \times C ¶times H \times W.</target>
        </trans-unit>
        <trans-unit id="db16fdaa05353f31c7f5c303d74f40ba9971f144" translate="yes" xml:space="preserve">
          <source>N \times H \times W \times 2</source>
          <target state="translated">N \times H \times W \times 2</target>
        </trans-unit>
        <trans-unit id="7fd20744aa54e5cfb63458f679b6501918e1991e" translate="yes" xml:space="preserve">
          <source>N \times M</source>
          <target state="new"/>
        </trans-unit>
        <trans-unit id="c79a64aa7f7a8e49dfba455783b75f9a68074b19" translate="yes" xml:space="preserve">
          <source>N is the batch size, &lt;code&gt;*&lt;/code&gt; means any number of additional dimensions</source>
          <target state="translated">Nはバッチサイズ、 &lt;code&gt;*&lt;/code&gt; は任意の数の追加ディメンションを意味します</target>
        </trans-unit>
        <trans-unit id="72e211ac7f7abd7ef74bebbff3bdb5e0da1f0db9" translate="yes" xml:space="preserve">
          <source>N-D</source>
          <target state="translated">N-D</target>
        </trans-unit>
        <trans-unit id="7610334d74930225de51e4e4fce7e6de6c627870" translate="yes" xml:space="preserve">
          <source>NCCL has also provided a number of environment variables for fine-tuning purposes.</source>
          <target state="translated">また、NCCLは微調整のために多くの環境変数を提供しています。</target>
        </trans-unit>
        <trans-unit id="165a578116c3590cf83add849da91470c0378dc0" translate="yes" xml:space="preserve">
          <source>NLLLoss</source>
          <target state="translated">NLLLoss</target>
        </trans-unit>
        <trans-unit id="c63922691a03fc61bc5d30e1155494b0495ebce4" translate="yes" xml:space="preserve">
          <source>NN module forward passes have code that don&amp;rsquo;t support named tensors and will error out appropriately.</source>
          <target state="translated">NNモジュールのフォワードパスには、名前付きテンソルをサポートしないコードがあり、適切にエラーが発生します。</target>
        </trans-unit>
        <trans-unit id="fb2adaff54f80ebafd8d75fb8e20d7e6464bee58" translate="yes" xml:space="preserve">
          <source>NN module parameters are unnamed, so outputs may be partially named.</source>
          <target state="translated">NN モジュールのパラメータは名前が付けられていないため、出力は部分的に名前が付けられている場合があります。</target>
        </trans-unit>
        <trans-unit id="fb77d2b5cb211a1bafb61c44a7f17e0c98a57348" translate="yes" xml:space="preserve">
          <source>NN modules are currently unsupported. This can lead to the following when calling modules with named tensor inputs:</source>
          <target state="translated">NN モジュールは現在サポートされていません。これにより、名前付きテンソル入力を持つモジュールを呼び出すと、以下のようになる可能性があります。</target>
        </trans-unit>
        <trans-unit id="855336587fa59262965cdb9a2a6114933586800b" translate="yes" xml:space="preserve">
          <source>N_i</source>
          <target state="translated">N_i</target>
        </trans-unit>
        <trans-unit id="c543b3c390ed1ce750f7a99ce30092a4fe11d2d6" translate="yes" xml:space="preserve">
          <source>NaN values in &lt;code&gt;grid&lt;/code&gt; would be interpreted as &lt;code&gt;-1&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;grid&lt;/code&gt; 内のNaN値は &lt;code&gt;-1&lt;/code&gt; として解釈されます。</target>
        </trans-unit>
        <trans-unit id="709a23220f2c3d64d1e1d6d18c4d5280f8d82fca" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="translated">Name</target>
        </trans-unit>
        <trans-unit id="0585ffb115d09e675d597261b20f2d75a3eb03a7" translate="yes" xml:space="preserve">
          <source>Name propagation semantics</source>
          <target state="translated">名前の伝播のセマンティクス</target>
        </trans-unit>
        <trans-unit id="817cc3c2ad5448f94a4d253bbcac8dd6cc2d1cf9" translate="yes" xml:space="preserve">
          <source>Named Tensors</source>
          <target state="translated">ネームドテンソル</target>
        </trans-unit>
        <trans-unit id="e90e823237a9f4d7fe13c9da511106ba9aee2f03" translate="yes" xml:space="preserve">
          <source>Named Tensors allow users to give explicit names to tensor dimensions. In most cases, operations that take dimension parameters will accept dimension names, avoiding the need to track dimensions by position. In addition, named tensors use names to automatically check that APIs are being used correctly at runtime, providing extra safety. Names can also be used to rearrange dimensions, for example, to support &amp;ldquo;broadcasting by name&amp;rdquo; rather than &amp;ldquo;broadcasting by position&amp;rdquo;.</source>
          <target state="translated">名前付きテンソルを使用すると、ユーザーはテンソル次元に明示的な名前を付けることができます。ほとんどの場合、ディメンションパラメータを受け取る操作はディメンション名を受け入れ、位置ごとにディメンションを追跡する必要がなくなります。さらに、名前付きテンソルは名前を使用して、実行時にAPIが正しく使用されていることを自動的にチェックし、安全性を高めます。名前を使用してディメンションを再配置することもできます。たとえば、「位置によるブロードキャスト」ではなく「名前によるブロードキャスト」をサポートします。</target>
        </trans-unit>
        <trans-unit id="6e3e9a74ab4dd7c6ec7d57c873cd59674e123d29" translate="yes" xml:space="preserve">
          <source>Named Tensors operator coverage</source>
          <target state="translated">ネームドテンソルのオペレータカバレッジ</target>
        </trans-unit>
        <trans-unit id="00f19d99a1a121465f53068cd3e37c47ef1fad72" translate="yes" xml:space="preserve">
          <source>Named Tuples</source>
          <target state="translated">名前付きタプル</target>
        </trans-unit>
        <trans-unit id="d906a9f233a4d60e7ff3266a36abd411378985f0" translate="yes" xml:space="preserve">
          <source>Named dimensions</source>
          <target state="translated">名前付き寸法</target>
        </trans-unit>
        <trans-unit id="d69a85347956dd430a196f336efedfda312c73cf" translate="yes" xml:space="preserve">
          <source>Named dimensions, like regular Tensor dimensions, are ordered. &lt;code&gt;tensor.names[i]&lt;/code&gt; is the name of dimension &lt;code&gt;i&lt;/code&gt; of &lt;code&gt;tensor&lt;/code&gt;.</source>
          <target state="translated">通常のテンソル次元と同様に、名前付き次元が順序付けられます。 &lt;code&gt;tensor.names[i]&lt;/code&gt; は、 &lt;code&gt;tensor&lt;/code&gt; の次元 &lt;code&gt;i&lt;/code&gt; の名前です。</target>
        </trans-unit>
        <trans-unit id="87ade27d950d661d18340b5de9b3d2e0c2886884" translate="yes" xml:space="preserve">
          <source>Named tensor API reference</source>
          <target state="translated">名前付きテンソルAPIリファレンス</target>
        </trans-unit>
        <trans-unit id="554d6e43a251766628f65b287dfa2b6bb568c6f8" translate="yes" xml:space="preserve">
          <source>Named tensors can coexist with unnamed tensors; named tensors are instances of &lt;a href=&quot;tensors#torch.Tensor&quot;&gt;&lt;code&gt;torch.Tensor&lt;/code&gt;&lt;/a&gt;. Unnamed tensors have &lt;code&gt;None&lt;/code&gt;-named dimensions. Named tensors do not require all dimensions to be named.</source>
          <target state="translated">名前付きテンソルは名前なしテンソルと共存できます。名前付きテンソルは&lt;a href=&quot;tensors#torch.Tensor&quot;&gt; &lt;code&gt;torch.Tensor&lt;/code&gt; の&lt;/a&gt;インスタンスです。名前テンソルは持っている &lt;code&gt;None&lt;/code&gt; -named寸法を。名前付きテンソルは、すべての次元に名前を付ける必要はありません。</target>
        </trans-unit>
        <trans-unit id="9babc66ca4089f8e16cccf70d5e5125ac942af22" translate="yes" xml:space="preserve">
          <source>Named tensors use names to automatically check that APIs are being called correctly at runtime. This occurs in a process called &lt;em&gt;name inference&lt;/em&gt;. More formally, name inference consists of the following two steps:</source>
          <target state="translated">名前付きテンソルは、名前を使用して、実行時にAPIが正しく呼び出されていることを自動的に確認します。これは、&lt;em&gt;名前の推論&lt;/em&gt;と呼ばれるプロセスで発生します。より正式には、名前の推論は次の2つのステップで構成されます。</target>
        </trans-unit>
        <trans-unit id="ce14504f9d8c7c9312b2871ff6009782be1ad451" translate="yes" xml:space="preserve">
          <source>Nathan Halko, Per-Gunnar Martinsson, and Joel Tropp, Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions, arXiv:0909.4061 [math.NA; math.PR], 2009 (available at &lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;arXiv&lt;/a&gt;).</source>
          <target state="translated">Nathan Halko、Per-Gunnar Martinsson、およびJoel Tropp、ランダム性のある構造の検索：近似行列分解を構築するための確率的アルゴリズム、arXiv：0909.4061 [math.NA; math.PR]、2009（&lt;a href=&quot;https://arxiv.org/abs/0909.4061&quot;&gt;arXivで&lt;/a&gt;入手可能）。</target>
        </trans-unit>
        <trans-unit id="1589b41367a72480492d7a5904aab37522c48d37" translate="yes" xml:space="preserve">
          <source>Negative log likelihood loss with Poisson distribution of target.</source>
          <target state="translated">目標のポアソン分布を持つ負の対数尤度損失。</target>
        </trans-unit>
        <trans-unit id="53ebc572b4a44802ba114729f07bdaaf5409a9d7" translate="yes" xml:space="preserve">
          <source>Network</source>
          <target state="translated">Network</target>
        </trans-unit>
        <trans-unit id="813b5b686d397a3b63ce050a22e4bcaa735af1e8" translate="yes" xml:space="preserve">
          <source>New API:</source>
          <target state="translated">新しいAPIです。</target>
        </trans-unit>
        <trans-unit id="540f7186c4d530bac579f69bb157fd5e121529cc" translate="yes" xml:space="preserve">
          <source>NewType</source>
          <target state="translated">NewType</target>
        </trans-unit>
        <trans-unit id="0013bf26fef8048809165bc5fc20da2af938e96c" translate="yes" xml:space="preserve">
          <source>No expressions except method definitions are allowed in the body of the class.</source>
          <target state="translated">クラスのボディ内ではメソッド定義以外の表現はできません。</target>
        </trans-unit>
        <trans-unit id="7a05537029cdbc40cf12ae1af3fd5798f2e0fb52" translate="yes" xml:space="preserve">
          <source>No support for inheritance or any other polymorphism strategy, except for inheriting from &lt;code&gt;object&lt;/code&gt; to specify a new-style class.</source>
          <target state="translated">新しいスタイルのクラスを指定するために &lt;code&gt;object&lt;/code&gt; から継承することを除いて、継承またはその他のポリモーフィズム戦略はサポートされていません。</target>
        </trans-unit>
        <trans-unit id="16585665bdbf85c2a46ca04dcdf6f3b3c87a4c04" translate="yes" xml:space="preserve">
          <source>No, but the exporter will try to handle that part. Scalars are converted to constant tensors in ONNX. The exporter will try to figure out the right datatype for scalars. However for cases that it failed to do so, you will need to manually provide the datatype information. This often happens with scripted models, where the datatypes are not recorded. We are trying to improve the datatype propagation in the exporter such that manual changes are not required in the future.</source>
          <target state="translated">いいえ、しかし、エクスポータはその部分を処理しようとします。スカラはONNXでは定数テンソルに変換されます。エクスポータはスカラに適したデータ型を見つけようとします。しかし、それに失敗した場合は、データ型情報を手動で提供する必要があります。これは、データ型が記録されていないスクリプトモデルでよく発生します。将来的に手動での変更が必要ないように、エクスポータでのデータ型の伝播を改善しようとしています。</target>
        </trans-unit>
        <trans-unit id="3a122cf075b0ba371ed052ceb0f012b712c9d692" translate="yes" xml:space="preserve">
          <source>Node 1: &lt;em&gt;(IP: 192.168.1.1, and has a free port: 1234)&lt;/em&gt;</source>
          <target state="translated">ノード1：&lt;em&gt;（IP：192.168.1.1、空きポート：1234）&lt;/em&gt;</target>
        </trans-unit>
        <trans-unit id="d7c20c7d93b71387bce45a0f532f94aceec659b1" translate="yes" xml:space="preserve">
          <source>Node 2:</source>
          <target state="translated">ノード2。</target>
        </trans-unit>
        <trans-unit id="2200871a1ac28c0b5dd797edb44ce5069b3ba408" translate="yes" xml:space="preserve">
          <source>Nominal typing is in development, but structural typing is not</source>
          <target state="translated">名目型付けは開発中ですが、構造型付けは開発中ではありません。</target>
        </trans-unit>
        <trans-unit id="56c04398e9678198426e682b1f9d96427b74b23b" translate="yes" xml:space="preserve">
          <source>Nominal vs structural subtyping</source>
          <target state="translated">名目と構造のサブタイプ</target>
        </trans-unit>
        <trans-unit id="b89eadfaef5d8d82b020885869aa96878170cfaa" translate="yes" xml:space="preserve">
          <source>Non-ATen operators</source>
          <target state="translated">非ATenオペレータ</target>
        </trans-unit>
        <trans-unit id="05ac3d4369dff83cd256460b1c7ab61b3d6873b9" translate="yes" xml:space="preserve">
          <source>Non-linear Activations (other)</source>
          <target state="translated">非線形活性化(その他</target>
        </trans-unit>
        <trans-unit id="37e8f09f37b4ba586b29c8d43264a706f392c534" translate="yes" xml:space="preserve">
          <source>Non-linear Activations (weighted sum, nonlinearity)</source>
          <target state="translated">非線形活性化(加重和、非線形性</target>
        </trans-unit>
        <trans-unit id="90f4c5f6b363fba151454b4dc3811eace77006ea" translate="yes" xml:space="preserve">
          <source>Non-linear activation functions</source>
          <target state="translated">非線形活性化関数</target>
        </trans-unit>
        <trans-unit id="32cfd0f165a52f907e24f0d0d41b54665a307df6" translate="yes" xml:space="preserve">
          <source>Non-local variables are resolved to Python values at compile time when the function is defined. These values are then converted into TorchScript values using the rules described in &lt;a href=&quot;#use-of-python-values&quot;&gt;Use of Python Values&lt;/a&gt;.</source>
          <target state="translated">Non-local variables are resolved to Python values at compile time when the function is defined. These values are then converted into TorchScript values using the rules described in &lt;a href=&quot;#use-of-python-values&quot;&gt;Use of Python Values&lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="6eef6648406c333a4035cd5e60d0bf2ecf2606d7" translate="yes" xml:space="preserve">
          <source>None</source>
          <target state="translated">None</target>
        </trans-unit>
        <trans-unit id="46e38cc5e7e0b2b170857112460a732303fdb5e3" translate="yes" xml:space="preserve">
          <source>Normalization Layers</source>
          <target state="translated">正規化レイヤー</target>
        </trans-unit>
        <trans-unit id="746e3a4c0d98d2df15064221df23fa7793e56038" translate="yes" xml:space="preserve">
          <source>Normalization functions</source>
          <target state="translated">正規化機能</target>
        </trans-unit>
        <trans-unit id="c4639d9330cdd597089734b95310026444f4de7e" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifft&quot;&gt;&lt;code&gt;ifft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifft&quot;&gt; &lt;code&gt;ifft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="fae17255f7a6267cdf6f973a75edad225dcf4d82" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifftn&quot;&gt;&lt;code&gt;ifftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ifftn&quot;&gt; &lt;code&gt;ifftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="37141e0de089638ade05f2fc80c5c6e1a4b3e953" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ihfft&quot;&gt;&lt;code&gt;ihfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.ihfft&quot;&gt; &lt;code&gt;ihfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="d960941bb7a853f66a4f14f14d7f53d0f7022466" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfft&quot;&gt;&lt;code&gt;irfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfft&quot;&gt; &lt;code&gt;irfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="7b81cd890e0116574dbf7776b7567225bd21e39c" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfftn&quot;&gt;&lt;code&gt;irfftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the backward transform (&lt;a href=&quot;#torch.fft.irfftn&quot;&gt; &lt;code&gt;irfftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="e18f2dcd89118b40d295cc2d0f570dae9ee63571" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fft&quot;&gt;&lt;code&gt;fft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fft&quot;&gt; &lt;code&gt;fft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="20885ecc112a0654f2fd1749899c2aade057f18f" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fftn&quot;&gt;&lt;code&gt;fftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.fftn&quot;&gt; &lt;code&gt;fftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="36f2290f1751dd4fd40961edc0b9d58c6d126bef" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.hfft&quot;&gt;&lt;code&gt;hfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.hfft&quot;&gt; &lt;code&gt;hfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="f07c249cb9e5f2751b249e4c52c89f4d38befc44" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfft&quot;&gt;&lt;code&gt;rfft()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfft&quot;&gt; &lt;code&gt;rfft()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="d3864acfcc3775dda73f1b742d452bc185e4b45c" translate="yes" xml:space="preserve">
          <source>Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfftn&quot;&gt;&lt;code&gt;rfftn()&lt;/code&gt;&lt;/a&gt;), these correspond to:</source>
          <target state="translated">Normalization mode. For the forward transform (&lt;a href=&quot;#torch.fft.rfftn&quot;&gt; &lt;code&gt;rfftn()&lt;/code&gt; &lt;/a&gt;), these correspond to:</target>
        </trans-unit>
        <trans-unit id="ac15bca5bbea06cd32f056c8cbf634e4f1faea41" translate="yes" xml:space="preserve">
          <source>Not implemented</source>
          <target state="translated">未実装</target>
        </trans-unit>
        <trans-unit id="df8f8315e0c299c571aa4226e66410f1097a424b" translate="yes" xml:space="preserve">
          <source>Not providing a value for &lt;code&gt;steps&lt;/code&gt; is deprecated. For backwards compatibility, not providing a value for &lt;code&gt;steps&lt;/code&gt; will create a tensor with 100 elements. Note that this behavior is not reflected in the documented function signature and should not be relied on. In a future PyTorch release, failing to provide a value for &lt;code&gt;steps&lt;/code&gt; will throw a runtime error.</source>
          <target state="translated">Not providing a value for &lt;code&gt;steps&lt;/code&gt; is deprecated. For backwards compatibility, not providing a value for &lt;code&gt;steps&lt;/code&gt; will create a tensor with 100 elements. Note that this behavior is not reflected in the documented function signature and should not be relied on. In a future PyTorch release, failing to provide a value for &lt;code&gt;steps&lt;/code&gt; will throw a runtime error.</target>
        </trans-unit>
        <trans-unit id="2c924e3088204ee77ba681f72be3444357932fca" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="translated">Note</target>
        </trans-unit>
        <trans-unit id="da7038b6159ab37164aeb7442907c881108aff7e" translate="yes" xml:space="preserve">
          <source>Note that</source>
          <target state="translated">以下のことに注意してください。</target>
        </trans-unit>
        <trans-unit id="5433b2e634d55f555a9239d7a13b88b55129e9b2" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;#torch.nn.ModuleDict.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; before Python version 3.6) does not preserve the order of the merged mapping.</source>
          <target state="translated">Note that &lt;a href=&quot;#torch.nn.ModuleDict.update&quot;&gt; &lt;code&gt;update()&lt;/code&gt; &lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; before Python version 3.6) does not preserve the order of the merged mapping.</target>
        </trans-unit>
        <trans-unit id="a1dc440ad60db846cad7f7d0a7ce1260c129ea8c" translate="yes" xml:space="preserve">
          <source>Note that &lt;a href=&quot;#torch.nn.ParameterDict.update&quot;&gt;&lt;code&gt;update()&lt;/code&gt;&lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt;) does not preserve the order of the merged mapping.</source>
          <target state="translated">Note that &lt;a href=&quot;#torch.nn.ParameterDict.update&quot;&gt; &lt;code&gt;update()&lt;/code&gt; &lt;/a&gt; with other unordered mapping types (e.g., Python&amp;rsquo;s plain &lt;code&gt;dict&lt;/code&gt; ) does not preserve the order of the merged mapping.</target>
        </trans-unit>
        <trans-unit id="42c994d9673f83cc70c78e02c5d9a230c6566874" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; in &lt;a href=&quot;#torch.hub.load&quot;&gt;&lt;code&gt;torch.hub.load()&lt;/code&gt;&lt;/a&gt; are used to &lt;strong&gt;instantiate&lt;/strong&gt; a model. After you have loaded a model, how can you find out what you can do with the model? A suggested workflow is</source>
          <target state="translated">Note that &lt;code&gt;*args&lt;/code&gt; and &lt;code&gt;**kwargs&lt;/code&gt; in &lt;a href=&quot;#torch.hub.load&quot;&gt; &lt;code&gt;torch.hub.load()&lt;/code&gt; &lt;/a&gt; are used to &lt;strong&gt;instantiate&lt;/strong&gt; a model. After you have loaded a model, how can you find out what you can do with the model? A suggested workflow is</target>
        </trans-unit>
        <trans-unit id="2d1e0d8414eaec791533b2f0922dd4ade580351c" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;BAND&lt;/code&gt;, &lt;code&gt;BOR&lt;/code&gt;, and &lt;code&gt;BXOR&lt;/code&gt; reductions are not available when using the &lt;code&gt;NCCL&lt;/code&gt; backend.</source>
          <target state="translated">Note that &lt;code&gt;BAND&lt;/code&gt; , &lt;code&gt;BOR&lt;/code&gt; , and &lt;code&gt;BXOR&lt;/code&gt; reductions are not available when using the &lt;code&gt;NCCL&lt;/code&gt; backend.</target>
        </trans-unit>
        <trans-unit id="0bd438191e4b3887c615246e19e8361b84bd83a7" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;T[1] == T[-1].conj()&lt;/code&gt; and &lt;code&gt;T[2] == T[-2].conj()&lt;/code&gt; is redundant. We can thus compute the forward transform without considering negative frequencies:</source>
          <target state="translated">Note that &lt;code&gt;T[1] == T[-1].conj()&lt;/code&gt; and &lt;code&gt;T[2] == T[-2].conj()&lt;/code&gt; is redundant. We can thus compute the forward transform without considering negative frequencies:</target>
        </trans-unit>
        <trans-unit id="ee47ccc0fe1d0f9aca7dffbff0fc6bd81769f2e4" translate="yes" xml:space="preserve">
          <source>Note that &lt;code&gt;len(output_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</source>
          <target state="translated">Note that &lt;code&gt;len(output_tensor_list)&lt;/code&gt; needs to be the same for all the distributed processes calling this function.</target>
        </trans-unit>
        <trans-unit id="d9706617db521f3c057495c1501777340ff2c154" translate="yes" xml:space="preserve">
          <source>Note that automatic rank assignment is not supported anymore in the latest distributed package and &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</source>
          <target state="translated">Note that automatic rank assignment is not supported anymore in the latest distributed package and &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</target>
        </trans-unit>
        <trans-unit id="d90621e782b71803aaf8f760cde86adc6ccf606c" translate="yes" xml:space="preserve">
          <source>Note that deterministic operations tend to have worse performance than non-deterministic operations.</source>
          <target state="translated">決定論的な操作は、非決定論的な操作よりもパフォーマンスが悪くなる傾向があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="b7948c066b35cd06338c8b76a0036f57024ca522" translate="yes" xml:space="preserve">
          <source>Note that each element of &lt;code&gt;input_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(output_tensor_list)&lt;/code&gt;, since the function scatters the result from every single GPU in the group. To interpret each element of &lt;code&gt;input_tensor_lists[i]&lt;/code&gt;, note that &lt;code&gt;output_tensor_list[j]&lt;/code&gt; of rank k receives the reduce-scattered result from &lt;code&gt;input_tensor_lists[i][k * world_size + j]&lt;/code&gt;</source>
          <target state="translated">Note that each element of &lt;code&gt;input_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(output_tensor_list)&lt;/code&gt; , since the function scatters the result from every single GPU in the group. To interpret each element of &lt;code&gt;input_tensor_lists[i]&lt;/code&gt; , note that &lt;code&gt;output_tensor_list[j]&lt;/code&gt; of rank k receives the reduce-scattered result from &lt;code&gt;input_tensor_lists[i][k * world_size + j]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f1fa921e9c60fd6eb9bf5d36ace2910b625e1764" translate="yes" xml:space="preserve">
          <source>Note that each element of &lt;code&gt;output_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(input_tensor_list)&lt;/code&gt;, since the function all gathers the result from every single GPU in the group. To interpret each element of &lt;code&gt;output_tensor_lists[i]&lt;/code&gt;, note that &lt;code&gt;input_tensor_list[j]&lt;/code&gt; of rank k will be appear in &lt;code&gt;output_tensor_lists[i][k * world_size + j]&lt;/code&gt;</source>
          <target state="translated">Note that each element of &lt;code&gt;output_tensor_lists&lt;/code&gt; has the size of &lt;code&gt;world_size * len(input_tensor_list)&lt;/code&gt; , since the function all gathers the result from every single GPU in the group. To interpret each element of &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; , note that &lt;code&gt;input_tensor_list[j]&lt;/code&gt; of rank k will be appear in &lt;code&gt;output_tensor_lists[i][k * world_size + j]&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="261fa08253a2249def1244a03fcd9b8841a48f8d" translate="yes" xml:space="preserve">
          <source>Note that multicast address is not supported anymore in the latest distributed package. &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</source>
          <target state="translated">Note that multicast address is not supported anymore in the latest distributed package. &lt;code&gt;group_name&lt;/code&gt; is deprecated as well.</target>
        </trans-unit>
        <trans-unit id="b2830ad219b13cbec38ff7f3f532533bf250586f" translate="yes" xml:space="preserve">
          <source>Note that non-integer &lt;code&gt;step&lt;/code&gt; is subject to floating point rounding errors when comparing against &lt;code&gt;end&lt;/code&gt;; to avoid inconsistency, we advise adding a small epsilon to &lt;code&gt;end&lt;/code&gt; in such cases.</source>
          <target state="translated">Note that non-integer &lt;code&gt;step&lt;/code&gt; is subject to floating point rounding errors when comparing against &lt;code&gt;end&lt;/code&gt; ; to avoid inconsistency, we advise adding a small epsilon to &lt;code&gt;end&lt;/code&gt; in such cases.</target>
        </trans-unit>
        <trans-unit id="fe417e45eca8b56b8a391ee5d65f646c54c00fc4" translate="yes" xml:space="preserve">
          <source>Note that the input to LongTensor is NOT a list of index tuples. If you want to write your indices this way, you should transpose before passing them to the sparse constructor:</source>
          <target state="translated">LongTensor の入力はインデックスタプルのリストではないことに注意してください。インデックスをこのように書きたい場合は、スパースのコンストラクタに渡す前に転置しなければなりません。</target>
        </trans-unit>
        <trans-unit id="7e0f39780c8cac4e285c8ec3c405982d7cafc31f" translate="yes" xml:space="preserve">
          <source>Note that these cases may in fact be traceable in the future.</source>
          <target state="translated">これらのケースは、実際には将来的に追跡可能になる可能性があることに注意してください。</target>
        </trans-unit>
        <trans-unit id="752392a2ff1e2a39cc0db5f6e4585276ad451ffb" translate="yes" xml:space="preserve">
          <source>Note that this function is simply doing &lt;code&gt;isinstance(obj, Tensor)&lt;/code&gt;. Using that &lt;code&gt;isinstance&lt;/code&gt; check is better for typechecking with mypy, and more explicit - so it&amp;rsquo;s recommended to use that instead of &lt;code&gt;is_tensor&lt;/code&gt;.</source>
          <target state="translated">Note that this function is simply doing &lt;code&gt;isinstance(obj, Tensor)&lt;/code&gt; . Using that &lt;code&gt;isinstance&lt;/code&gt; check is better for typechecking with mypy, and more explicit - so it&amp;rsquo;s recommended to use that instead of &lt;code&gt;is_tensor&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="a5b8b84abd5cbd1ff532fd7ae1e19baa9b3b1a28" translate="yes" xml:space="preserve">
          <source>Note that this function requires Python 3.4 or higher.</source>
          <target state="translated">この関数はPython 3.4以上が必要です。</target>
        </trans-unit>
        <trans-unit id="e898adc76bed905448d3327e88134b4893e4bf98" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;matplotlib&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;matplotlib&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="ba4e51216b174df96efb807dbfef6adf290a07f2" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;moviepy&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;moviepy&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="da8c941a1c4dc21607ac70d896e4a7cb648a3554" translate="yes" xml:space="preserve">
          <source>Note that this requires the &lt;code&gt;pillow&lt;/code&gt; package.</source>
          <target state="translated">Note that this requires the &lt;code&gt;pillow&lt;/code&gt; package.</target>
        </trans-unit>
        <trans-unit id="38c3af3645ee3d8c1e85f997b98d93ebdc11ac44" translate="yes" xml:space="preserve">
          <source>Note that when &lt;code&gt;tracker&lt;/code&gt; stores Tensor objects from the LOBPCG instance, it must make copies of these.</source>
          <target state="translated">Note that when &lt;code&gt;tracker&lt;/code&gt; stores Tensor objects from the LOBPCG instance, it must make copies of these.</target>
        </trans-unit>
        <trans-unit id="76d32111f7bcbce3e8104b2ef5376761705e1942" translate="yes" xml:space="preserve">
          <source>Note: A full example to apply nn.Transformer module for the word language model is available in &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/word_language_model&quot;&gt;https://github.com/pytorch/examples/tree/master/word_language_model&lt;/a&gt;</source>
          <target state="translated">Note: A full example to apply nn.Transformer module for the word language model is available in &lt;a href=&quot;https://github.com/pytorch/examples/tree/master/word_language_model&quot;&gt;https://github.com/pytorch/examples/tree/master/word_language_model&lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="2acb81c5ebbb77d4e03260d44dbd15da614d8dba" translate="yes" xml:space="preserve">
          <source>Note: Due to the multi-head attention architecture in the transformer model, the output sequence length of a transformer is same as the input sequence (i.e. target) length of the decode.</source>
          <target state="translated">注:トランスモデルのマルチヘッド注意アーキテクチャのため、トランスの出力シーケンス長は、デコードの入力シーケンス(すなわちターゲット)長と同じです。</target>
        </trans-unit>
        <trans-unit id="ea3f023c9638ee2f77985080cfee0c3149276897" translate="yes" xml:space="preserve">
          <source>Note: Loading a model is the typical use case, but this can also be used to for loading other objects such as tokenizers, loss functions, etc.</source>
          <target state="translated">注:モデルの読み込みが典型的なユースケースですが、トークナイザーや損失関数などの他のオブジェクトの読み込みにも使用できます。</target>
        </trans-unit>
        <trans-unit id="fec631db96f94a854d531dcf201c32e0e5b12fec" translate="yes" xml:space="preserve">
          <source>Note: When beta is set to 0, this is equivalent to &lt;a href=&quot;torch.nn.l1loss#torch.nn.L1Loss&quot;&gt;&lt;code&gt;L1Loss&lt;/code&gt;&lt;/a&gt;. Passing a negative value in for beta will result in an exception.</source>
          <target state="translated">Note: When beta is set to 0, this is equivalent to &lt;a href=&quot;torch.nn.l1loss#torch.nn.L1Loss&quot;&gt; &lt;code&gt;L1Loss&lt;/code&gt; &lt;/a&gt;. Passing a negative value in for beta will result in an exception.</target>
        </trans-unit>
        <trans-unit id="9b7c2d4ed1b493db790041907421b97fbf38eae9" translate="yes" xml:space="preserve">
          <source>Note: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will be unchanged. If a BoolTensor is provided, positions with &lt;code&gt;True&lt;/code&gt; are not allowed to attend while &lt;code&gt;False&lt;/code&gt; values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight. [src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by the attention. If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions will be unchanged. If a BoolTensor is provided, the positions with the value of &lt;code&gt;True&lt;/code&gt; will be ignored while the position with the value of &lt;code&gt;False&lt;/code&gt; will be unchanged.</source>
          <target state="translated">Note: [src/tgt/memory]_mask ensures that position i is allowed to attend the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will be unchanged. If a BoolTensor is provided, positions with &lt;code&gt;True&lt;/code&gt; are not allowed to attend while &lt;code&gt;False&lt;/code&gt; values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight. [src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by the attention. If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions will be unchanged. If a BoolTensor is provided, the positions with the value of &lt;code&gt;True&lt;/code&gt; will be ignored while the position with the value of &lt;code&gt;False&lt;/code&gt; will be unchanged.</target>
        </trans-unit>
        <trans-unit id="70440046a3dc2e079f23ee1c57dfa76669b732aa" translate="yes" xml:space="preserve">
          <source>Notes</source>
          <target state="translated">Notes</target>
        </trans-unit>
        <trans-unit id="4425723195c4a3b16b476f69800fa3cf16abb9b4" translate="yes" xml:space="preserve">
          <source>Notice that if</source>
          <target state="translated">以下のような場合に注意してください。</target>
        </trans-unit>
        <trans-unit id="d1656ebe55b849d2893f4a0cf92db35aea6025bc" translate="yes" xml:space="preserve">
          <source>Notice that operators can also have associated &lt;code&gt;blocks&lt;/code&gt;, namely the &lt;code&gt;prim::Loop&lt;/code&gt; and &lt;code&gt;prim::If&lt;/code&gt; operators. In the graph print-out, these operators are formatted to reflect their equivalent source code forms to facilitate easy debugging.</source>
          <target state="translated">Notice that operators can also have associated &lt;code&gt;blocks&lt;/code&gt; , namely the &lt;code&gt;prim::Loop&lt;/code&gt; and &lt;code&gt;prim::If&lt;/code&gt; operators. In the graph print-out, these operators are formatted to reflect their equivalent source code forms to facilitate easy debugging.</target>
        </trans-unit>
        <trans-unit id="04a5b9046bd473cb428ae07e5d6a160de265bc5d" translate="yes" xml:space="preserve">
          <source>Notice that the symmetric element &lt;code&gt;T[-1] == T[1].conj()&lt;/code&gt; is omitted. At the Nyquist frequency &lt;code&gt;T[-2] == T[2]&lt;/code&gt; is it&amp;rsquo;s own symmetric pair, and therefore must always be real-valued.</source>
          <target state="translated">Notice that the symmetric element &lt;code&gt;T[-1] == T[1].conj()&lt;/code&gt; is omitted. At the Nyquist frequency &lt;code&gt;T[-2] == T[2]&lt;/code&gt; is it&amp;rsquo;s own symmetric pair, and therefore must always be real-valued.</target>
        </trans-unit>
        <trans-unit id="1956334a42d3e178212344356997b21e347fa273" translate="yes" xml:space="preserve">
          <source>Now PyTorch is able to export &lt;code&gt;elu&lt;/code&gt; operator.</source>
          <target state="translated">Now PyTorch is able to export &lt;code&gt;elu&lt;/code&gt; operator.</target>
        </trans-unit>
        <trans-unit id="a30a0ffebbaef4efa26c2a00eda09cf59167dfe6" translate="yes" xml:space="preserve">
          <source>Now the exported ONNX graph becomes:</source>
          <target state="translated">これでエクスポートされたONNXのグラフは以下のようになります。</target>
        </trans-unit>
        <trans-unit id="08a914cde05039694ef0194d9ee79ff9a79dde33" translate="yes" xml:space="preserve">
          <source>O</source>
          <target state="translated">O</target>
        </trans-unit>
        <trans-unit id="58e9484683a456865672c8a4517b530e0f41cd11" translate="yes" xml:space="preserve">
          <source>ONLY INDICES:</source>
          <target state="translated">唯一の指標です。</target>
        </trans-unit>
        <trans-unit id="b335243efa572b5f0beb01acb45b42a02be187b5" translate="yes" xml:space="preserve">
          <source>ONNX</source>
          <target state="translated">ONNX</target>
        </trans-unit>
        <trans-unit id="98099fd5d344320bb061ab40d4f82b1271288a2a" translate="yes" xml:space="preserve">
          <source>ONNX_ATEN</source>
          <target state="translated">ONNX_ATEN</target>
        </trans-unit>
        <trans-unit id="7fd76316b691135ff7ad4e41541a37a2b2ed8c3d" translate="yes" xml:space="preserve">
          <source>ONNX_ATEN_FALLBACK</source>
          <target state="translated">ONNX_ATEN_FALLBACK</target>
        </trans-unit>
        <trans-unit id="0976054bd35910dc334e574eb3e3c16bf4dc9b17" translate="yes" xml:space="preserve">
          <source>ONNX_FALLTHROUGH</source>
          <target state="translated">ONNX_FALLTHROUGH</target>
        </trans-unit>
        <trans-unit id="946938795b376f71c3a327dfe4ec5463d0103fa6" translate="yes" xml:space="preserve">
          <source>Object Detection, Instance Segmentation and Person Keypoint Detection</source>
          <target state="translated">オブジェクト検出、インスタンスセグメンテーション、人物キーポイント検出</target>
        </trans-unit>
        <trans-unit id="8bf3249a3a8cece6d4343af20c9431018c926b24" translate="yes" xml:space="preserve">
          <source>Obtaining log-probabilities in a neural network is easily achieved by adding a &lt;code&gt;LogSoftmax&lt;/code&gt; layer in the last layer of your network. You may use &lt;code&gt;CrossEntropyLoss&lt;/code&gt; instead, if you prefer not to add an extra layer.</source>
          <target state="translated">Obtaining log-probabilities in a neural network is easily achieved by adding a &lt;code&gt;LogSoftmax&lt;/code&gt; layer in the last layer of your network. You may use &lt;code&gt;CrossEntropyLoss&lt;/code&gt; instead, if you prefer not to add an extra layer.</target>
        </trans-unit>
        <trans-unit id="b98c7204267732ffe5bc04ce20cbadbe8642e52b" translate="yes" xml:space="preserve">
          <source>Of course the reality is much more complicated and your script might not be in one of those two extremes depending on the part of the model you&amp;rsquo;re evaluating. If the profiler outputs don&amp;rsquo;t help, you could try looking at the result of &lt;a href=&quot;autograd#torch.autograd.profiler.emit_nvtx&quot;&gt;&lt;code&gt;torch.autograd.profiler.emit_nvtx()&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;nvprof&lt;/code&gt;. However, please take into account that the NVTX overhead is very high and often gives a heavily skewed timeline.</source>
          <target state="translated">Of course the reality is much more complicated and your script might not be in one of those two extremes depending on the part of the model you&amp;rsquo;re evaluating. If the profiler outputs don&amp;rsquo;t help, you could try looking at the result of &lt;a href=&quot;autograd#torch.autograd.profiler.emit_nvtx&quot;&gt; &lt;code&gt;torch.autograd.profiler.emit_nvtx()&lt;/code&gt; &lt;/a&gt; with &lt;code&gt;nvprof&lt;/code&gt; . However, please take into account that the NVTX overhead is very high and often gives a heavily skewed timeline.</target>
        </trans-unit>
        <trans-unit id="c37dc6bfd2614888384f13ab211221f9b141d421" translate="yes" xml:space="preserve">
          <source>Old API:</source>
          <target state="translated">古いAPIです。</target>
        </trans-unit>
        <trans-unit id="fe1a8467f796e691ae75cd019ca47d231225ebf5" translate="yes" xml:space="preserve">
          <source>On CUDA 10.1, set environment variable &lt;code&gt;CUDA_LAUNCH_BLOCKING=1&lt;/code&gt;. This may affect performance.</source>
          <target state="translated">On CUDA 10.1, set environment variable &lt;code&gt;CUDA_LAUNCH_BLOCKING=1&lt;/code&gt; . This may affect performance.</target>
        </trans-unit>
        <trans-unit id="87f5d31208b13882b13d7cef323f2a640539b60a" translate="yes" xml:space="preserve">
          <source>On CUDA 10.2 or later, set environment variable (note the leading colon symbol) &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:2&lt;/code&gt;.</source>
          <target state="translated">On CUDA 10.2 or later, set environment variable (note the leading colon symbol) &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:16:8&lt;/code&gt; or &lt;code&gt;CUBLAS_WORKSPACE_CONFIG=:4096:2&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="b433d4e11b599fd15dbc04960281f9eb287632d1" translate="yes" xml:space="preserve">
          <source>On each window, the function computed is:</source>
          <target state="translated">各ウィンドウ上で、計算された関数は次のようになります。</target>
        </trans-unit>
        <trans-unit id="a84bfeb86e4aa154caeb1f582b53ed62fd133141" translate="yes" xml:space="preserve">
          <source>On modules, methods must be compiled before they can be called. The TorchScript compiler recursively compiles methods it sees when compiling other methods. By default, compilation starts on the &lt;code&gt;forward&lt;/code&gt; method. Any methods called by &lt;code&gt;forward&lt;/code&gt; will be compiled, and any methods called by those methods, and so on. To start compilation at a method other than &lt;code&gt;forward&lt;/code&gt;, use the &lt;a href=&quot;jit#torch.jit.export&quot;&gt;&lt;code&gt;@torch.jit.export&lt;/code&gt;&lt;/a&gt; decorator (&lt;code&gt;forward&lt;/code&gt; implicitly is marked &lt;code&gt;@torch.jit.export&lt;/code&gt;).</source>
          <target state="translated">On modules, methods must be compiled before they can be called. The TorchScript compiler recursively compiles methods it sees when compiling other methods. By default, compilation starts on the &lt;code&gt;forward&lt;/code&gt; method. Any methods called by &lt;code&gt;forward&lt;/code&gt; will be compiled, and any methods called by those methods, and so on. To start compilation at a method other than &lt;code&gt;forward&lt;/code&gt; , use the &lt;a href=&quot;jit#torch.jit.export&quot;&gt; &lt;code&gt;@torch.jit.export&lt;/code&gt; &lt;/a&gt; decorator ( &lt;code&gt;forward&lt;/code&gt; implicitly is marked &lt;code&gt;@torch.jit.export&lt;/code&gt; ).</target>
        </trans-unit>
        <trans-unit id="a488ba8f17e355abbbc16eb50cb56f628e0ef099" translate="yes" xml:space="preserve">
          <source>On the other hand, invoking &lt;code&gt;trace&lt;/code&gt; with module&amp;rsquo;s instance (e.g. &lt;code&gt;my_module&lt;/code&gt;) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required.</source>
          <target state="translated">On the other hand, invoking &lt;code&gt;trace&lt;/code&gt; with module&amp;rsquo;s instance (e.g. &lt;code&gt;my_module&lt;/code&gt; ) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required.</target>
        </trans-unit>
        <trans-unit id="b392f645cfdecae166313100197dfb1e06d02b4b" translate="yes" xml:space="preserve">
          <source>Once all DDP processes have joined, the context manager will broadcast the model corresponding to the last joined process to all processes to ensure the model is the same across all processes (which is guaranteed by DDP).</source>
          <target state="translated">すべてのDDPプロセスが参加すると、コンテキストマネージャは、最後に参加したプロセスに対応するモデルをすべてのプロセスにブロードキャストし、モデルがすべてのプロセスで同じであることを確認します(これはDDPによって保証されています)。</target>
        </trans-unit>
        <trans-unit id="3ebcd2d39bb7401d6e980dad866025a71193ae15" translate="yes" xml:space="preserve">
          <source>Once these are installed, you can use the backend for Caffe2:</source>
          <target state="translated">これらをインストールすると、Caffe2のバックエンドを利用できるようになります。</target>
        </trans-unit>
        <trans-unit id="c7da4cd77b5400566e4f52a1d8995e48e44e2095" translate="yes" xml:space="preserve">
          <source>Once these are installed, you can use the backend for ONNX Runtime:</source>
          <target state="translated">これらをインストールすると、ONNX Runtimeのバックエンドを利用することができます。</target>
        </trans-unit>
        <trans-unit id="181dde386ac4e48b01ea4c9ac2766b9fdca3442c" translate="yes" xml:space="preserve">
          <source>Once you&amp;rsquo;ve installed TensorBoard, these utilities let you log PyTorch models and metrics into a directory for visualization within the TensorBoard UI. Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs.</source>
          <target state="translated">Once you&amp;rsquo;ve installed TensorBoard, these utilities let you log PyTorch models and metrics into a directory for visualization within the TensorBoard UI. Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs.</target>
        </trans-unit>
        <trans-unit id="fa0ae9a8c41213fbda341d9975cb44fc985cb402" translate="yes" xml:space="preserve">
          <source>One can either give a &lt;code&gt;scale_factor&lt;/code&gt; or the target output &lt;code&gt;size&lt;/code&gt; to calculate the output size. (You cannot give both, as it is ambiguous)</source>
          <target state="translated">One can either give a &lt;code&gt;scale_factor&lt;/code&gt; or the target output &lt;code&gt;size&lt;/code&gt; to calculate the output size. (You cannot give both, as it is ambiguous)</target>
        </trans-unit>
        <trans-unit id="f84825776234c0c4615edbbd6631eafc8684c310" translate="yes" xml:space="preserve">
          <source>One cannot specify both positional args &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt; and keyword args &lt;code&gt;rename_map&lt;/code&gt;.</source>
          <target state="translated">One cannot specify both positional args &lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt; and keyword args &lt;code&gt;rename_map&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="f99ff2b17e8a666214d13b388ce8036710cb6b91" translate="yes" xml:space="preserve">
          <source>One way to automatically catch many errors in traces is by using &lt;code&gt;check_inputs&lt;/code&gt; on the &lt;code&gt;torch.jit.trace()&lt;/code&gt; API. &lt;code&gt;check_inputs&lt;/code&gt; takes a list of tuples of inputs that will be used to re-trace the computation and verify the results. For example:</source>
          <target state="translated">One way to automatically catch many errors in traces is by using &lt;code&gt;check_inputs&lt;/code&gt; on the &lt;code&gt;torch.jit.trace()&lt;/code&gt; API. &lt;code&gt;check_inputs&lt;/code&gt; takes a list of tuples of inputs that will be used to re-trace the computation and verify the results. For example:</target>
        </trans-unit>
        <trans-unit id="e9f428e38cd970cf00e186de12fa06466a0c70e3" translate="yes" xml:space="preserve">
          <source>Only 2D input is supported for quantized inputs</source>
          <target state="translated">量子化入力は2D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="e86d4094fa43c487d3762de38c606afefec7936e" translate="yes" xml:space="preserve">
          <source>Only 2D inputs are supported</source>
          <target state="translated">2D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="daede8c2e196c09bd4c265e562b51d50f0840292" translate="yes" xml:space="preserve">
          <source>Only 2D/3D input is supported for quantized inputs</source>
          <target state="translated">量子化入力は2D/3D入力のみサポート</target>
        </trans-unit>
        <trans-unit id="27966aeec004be97d5e6f5f602ef5deb9549007c" translate="yes" xml:space="preserve">
          <source>Only &lt;code&gt;torch.quint8&lt;/code&gt; is supported for the input data type.</source>
          <target state="translated">Only &lt;code&gt;torch.quint8&lt;/code&gt; is supported for the input data type.</target>
        </trans-unit>
        <trans-unit id="04aa0322b01e7ae421d1285e24a5ecee9dd8da63" translate="yes" xml:space="preserve">
          <source>Only &lt;code&gt;zeros&lt;/code&gt; is supported for the &lt;code&gt;padding_mode&lt;/code&gt; argument.</source>
          <target state="translated">Only &lt;code&gt;zeros&lt;/code&gt; is supported for the &lt;code&gt;padding_mode&lt;/code&gt; argument.</target>
        </trans-unit>
        <trans-unit id="4e5b1e16b907585048a530098a587f0e967c17c8" translate="yes" xml:space="preserve">
          <source>Only leaf Tensors will have their &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated during a call to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt;&lt;code&gt;backward()&lt;/code&gt;&lt;/a&gt;. To get &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt;&lt;code&gt;grad&lt;/code&gt;&lt;/a&gt; populated for non-leaf Tensors, you can use &lt;a href=&quot;autograd#torch.Tensor.retain_grad&quot;&gt;&lt;code&gt;retain_grad()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Only leaf Tensors will have their &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt; populated during a call to &lt;a href=&quot;autograd#torch.Tensor.backward&quot;&gt; &lt;code&gt;backward()&lt;/code&gt; &lt;/a&gt;. To get &lt;a href=&quot;autograd#torch.Tensor.grad&quot;&gt; &lt;code&gt;grad&lt;/code&gt; &lt;/a&gt; populated for non-leaf Tensors, you can use &lt;a href=&quot;autograd#torch.Tensor.retain_grad&quot;&gt; &lt;code&gt;retain_grad()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="214baf780986ab4b5685dfad680eb394c92a2724" translate="yes" xml:space="preserve">
          <source>Only nccl and gloo backend are currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl と gloo バックエンドのみです。</target>
        </trans-unit>
        <trans-unit id="db8dc40130a88665cd5bf8f3be6d7ea249aff179" translate="yes" xml:space="preserve">
          <source>Only nccl and gloo backend is currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl と gloo バックエンドのみです。</target>
        </trans-unit>
        <trans-unit id="df8cfb4a9929de36ffa3e1c6452d25a578580d0f" translate="yes" xml:space="preserve">
          <source>Only nccl backend is currently supported tensors should only be GPU tensors</source>
          <target state="translated">現在サポートされているのは nccl バックエンドのみで、テンソルは GPU テンソルのみにする必要があります。</target>
        </trans-unit>
        <trans-unit id="6f7a0a50221e4f4092d5689875e749bacffbc3f1" translate="yes" xml:space="preserve">
          <source>Only the GPU of &lt;code&gt;tensor_list[dst_tensor]&lt;/code&gt; on the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</source>
          <target state="translated">Only the GPU of &lt;code&gt;tensor_list[dst_tensor]&lt;/code&gt; on the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</target>
        </trans-unit>
        <trans-unit id="c024a1c0a5c1c600879124a8ffc9c018f3eeaa1c" translate="yes" xml:space="preserve">
          <source>Only the following modes are supported for the quantized inputs:</source>
          <target state="translated">量子化された入力は、以下のモードのみサポートされています。</target>
        </trans-unit>
        <trans-unit id="4abce74e0ec5249c62cdd843742dc1fcd44cf957" translate="yes" xml:space="preserve">
          <source>Only the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</source>
          <target state="translated">Only the process with rank &lt;code&gt;dst&lt;/code&gt; is going to receive the final result.</target>
        </trans-unit>
        <trans-unit id="465e942c4c87f62f9475a2c554cc5cf2204bbefd" translate="yes" xml:space="preserve">
          <source>Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted but their usage is not recommended. Users need to verify their dict inputs carefully, and keep in mind that dynamic lookups are not available.</source>
          <target state="translated">JITの入出力としては、タプル、リスト、変数のみがサポートされています。辞書や文字列も受け入れられますが、それらの使用は推奨されません。ユーザーはdict入力を慎重に検証する必要があり、動的なルックアップは利用できないことに注意してください。</target>
        </trans-unit>
        <trans-unit id="d0f4a3ec3e4ad0aecc8e89f342dde91d8ebe6688" translate="yes" xml:space="preserve">
          <source>Operator Export Type</source>
          <target state="translated">オペレータ輸出タイプ</target>
        </trans-unit>
        <trans-unit id="bb7373849dc3f047bbc13778dd3b1cb1da43b12b" translate="yes" xml:space="preserve">
          <source>OperatorExportTypes.ONNX: All ops are exported as regular ONNX ops (with ONNX namespace). OperatorExportTypes.ONNX_ATEN: All ops are exported as ATen ops (with aten namespace). OperatorExportTypes.ONNX_ATEN_FALLBACK: If an ATen op is not supported in ONNX or its symbolic is missing, fall back on ATen op. Registered ops are exported to ONNX regularly. Example graph:</source>
          <target state="translated">OperatorExportTypes.ONNX:すべての操作は、通常の ONNX 操作(ONNX 名前空間を持つ)としてエクスポートされます。OperatorExportTypes.ONNX_ATEN:すべてのオペはATenオペとしてエクスポートされます(aten名前空間を持つ)。OperatorExportTypes.ONNX_ATEN_FALLBACK:ATen opがONNXでサポートされていない場合やシンボリックが欠落している場合は、ATen opにフォールバックします。登録されたopは定期的にONNXにエクスポートされます。グラフ例。</target>
        </trans-unit>
        <trans-unit id="e90414358dbfff0a68e4eb5d68a16978cf197d5a" translate="yes" xml:space="preserve">
          <source>Operators</source>
          <target state="translated">Operators</target>
        </trans-unit>
        <trans-unit id="326510735a447ec63da9abec360c7b0441bdd180" translate="yes" xml:space="preserve">
          <source>Optional Type Refinement</source>
          <target state="translated">オプションタイプの絞り込み</target>
        </trans-unit>
        <trans-unit id="21826226f40329aa4cc3679f6cd2d7ad202e0147" translate="yes" xml:space="preserve">
          <source>Optional values &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; are scaling factors on the outer product between &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and the added matrix &lt;code&gt;input&lt;/code&gt; respectively.</source>
          <target state="translated">Optional values &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt; are scaling factors on the outer product between &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and the added matrix &lt;code&gt;input&lt;/code&gt; respectively.</target>
        </trans-unit>
        <trans-unit id="14cf9a30a86cd6abc4768ba63268809b6a642a72" translate="yes" xml:space="preserve">
          <source>Optionally set the Torch Hub directory used to save downloaded models &amp;amp; weights.</source>
          <target state="translated">Optionally set the Torch Hub directory used to save downloaded models &amp;amp; weights.</target>
        </trans-unit>
        <trans-unit id="3cdb2fb789b07586dcdc33ff9c3ec35d1394e04a" translate="yes" xml:space="preserve">
          <source>Optionally, you can give non-equal weighting on the classes by passing a 1D &lt;code&gt;weight&lt;/code&gt; tensor into the constructor.</source>
          <target state="translated">Optionally, you can give non-equal weighting on the classes by passing a 1D &lt;code&gt;weight&lt;/code&gt; tensor into the constructor.</target>
        </trans-unit>
        <trans-unit id="ae88acefda9740ca025e9b1e8d82500694df6312" translate="yes" xml:space="preserve">
          <source>Orphan</source>
          <target state="translated">Orphan</target>
        </trans-unit>
        <trans-unit id="6e6a6f2086bb5fe5dbfd17d8d5f502d48759834b" translate="yes" xml:space="preserve">
          <source>Other</source>
          <target state="translated">Other</target>
        </trans-unit>
        <trans-unit id="d51aeaedae53d1689ff4812f653d88f9f69f9530" translate="yes" xml:space="preserve">
          <source>Other NCCL environment variables</source>
          <target state="translated">その他のNCCL環境変数</target>
        </trans-unit>
        <trans-unit id="b41b4ea22c0549444f4374445d8b5be41ed6c7a3" translate="yes" xml:space="preserve">
          <source>Other Operations</source>
          <target state="translated">その他の事業</target>
        </trans-unit>
        <trans-unit id="b4fb6252944f2406950d09755e09e265942a94cb" translate="yes" xml:space="preserve">
          <source>Other dimensions of &lt;code&gt;input&lt;/code&gt; that are not explicitly moved remain in their original order and appear at the positions not specified in &lt;code&gt;destination&lt;/code&gt;.</source>
          <target state="translated">Other dimensions of &lt;code&gt;input&lt;/code&gt; that are not explicitly moved remain in their original order and appear at the positions not specified in &lt;code&gt;destination&lt;/code&gt; .</target>
        </trans-unit>
        <trans-unit id="9b1d762f3a800a1e6b0f118d4aa509412d043de1" translate="yes" xml:space="preserve">
          <source>Otherwise, if &lt;code&gt;map_location&lt;/code&gt; is a dict, it will be used to remap location tags appearing in the file (keys), to ones that specify where to put the storages (values).</source>
          <target state="translated">Otherwise, if &lt;code&gt;map_location&lt;/code&gt; is a dict, it will be used to remap location tags appearing in the file (keys), to ones that specify where to put the storages (values).</target>
        </trans-unit>
        <trans-unit id="9f6ea88f9397a13956243e283a62e08c4833e59a" translate="yes" xml:space="preserve">
          <source>Otherwise, it will not be possible to view &lt;code&gt;self&lt;/code&gt; tensor as &lt;code&gt;shape&lt;/code&gt; without copying it (e.g., via &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt;&lt;code&gt;contiguous()&lt;/code&gt;&lt;/a&gt;). When it is unclear whether a &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt; can be performed, it is advisable to use &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt;, which returns a view if the shapes are compatible, and copies (equivalent to calling &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt;&lt;code&gt;contiguous()&lt;/code&gt;&lt;/a&gt;) otherwise.</source>
          <target state="translated">Otherwise, it will not be possible to view &lt;code&gt;self&lt;/code&gt; tensor as &lt;code&gt;shape&lt;/code&gt; without copying it (e.g., via &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt; &lt;code&gt;contiguous()&lt;/code&gt; &lt;/a&gt;). When it is unclear whether a &lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt; can be performed, it is advisable to use &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; &lt;/a&gt;, which returns a view if the shapes are compatible, and copies (equivalent to calling &lt;a href=&quot;#torch.Tensor.contiguous&quot;&gt; &lt;code&gt;contiguous()&lt;/code&gt; &lt;/a&gt;) otherwise.</target>
        </trans-unit>
        <trans-unit id="d386f5cc6857d8a2d7baf372e44b4d1117dfed1a" translate="yes" xml:space="preserve">
          <source>Our solution is that BCELoss clamps its log function outputs to be greater than or equal to -100. This way, we can always have a finite loss value and a linear backward method.</source>
          <target state="translated">私たちの解決策は、BCELossがその対数関数の出力を-100以上になるようにクランプすることです。このようにして、我々は常に有限の損失値と線形後方法を持つことができます。</target>
        </trans-unit>
        <trans-unit id="02600672b80ab0a1c4955d9a3e0f68bbce6d3eed" translate="yes" xml:space="preserve">
          <source>Our sparse tensor format permits &lt;em&gt;uncoalesced&lt;/em&gt; sparse tensors, where there may be duplicate coordinates in the indices; in this case, the interpretation is that the value at that index is the sum of all duplicate value entries. Uncoalesced tensors permit us to implement certain operators more efficiently.</source>
          <target state="translated">Our sparse tensor format permits &lt;em&gt;uncoalesced&lt;/em&gt; sparse tensors, where there may be duplicate coordinates in the indices; in this case, the interpretation is that the value at that index is the sum of all duplicate value entries. Uncoalesced tensors permit us to implement certain operators more efficiently.</target>
        </trans-unit>
        <trans-unit id="48c4c6b206793564023af6432f79ea36266139f9" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt;&lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt;&lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt; &lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_add_&quot;&gt; &lt;code&gt;torch.Tensor.index_add_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="99a0b833417509afcf74b89d81969fd3e6454e0f" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt;&lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt;&lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt; &lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_copy_&quot;&gt; &lt;code&gt;torch.Tensor.index_copy_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="f02f9ec70b467240dbc6d49d1fba7b03c1442801" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt;&lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt;&lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt; &lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_fill_&quot;&gt; &lt;code&gt;torch.Tensor.index_fill_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="5a8086fbdf63aa63eb1e982f564377b659f098f0" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_fill_&quot;&gt;&lt;code&gt;torch.Tensor.masked_fill_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_fill_&quot;&gt; &lt;code&gt;torch.Tensor.masked_fill_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="73076ad1c2f9be4b4d38d73b62e6c3e6c045bec2" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_scatter_&quot;&gt;&lt;code&gt;torch.Tensor.masked_scatter_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.masked_scatter_&quot;&gt; &lt;code&gt;torch.Tensor.masked_scatter_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="e013688ad79fc825d3497306dc29bb552d0e34c4" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_&quot;&gt;&lt;code&gt;torch.Tensor.scatter_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_&quot;&gt; &lt;code&gt;torch.Tensor.scatter_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="725700a259ff1b2b017f60b4e74698aa49714d29" translate="yes" xml:space="preserve">
          <source>Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt;&lt;code&gt;torch.Tensor.scatter_add_()&lt;/code&gt;&lt;/a&gt;</source>
          <target state="translated">Out-of-place version of &lt;a href=&quot;#torch.Tensor.scatter_add_&quot;&gt; &lt;code&gt;torch.Tensor.scatter_add_()&lt;/code&gt; &lt;/a&gt;</target>
        </trans-unit>
        <trans-unit id="6398fea054e2780d871397e980d3cf8c7e956e4c" translate="yes" xml:space="preserve">
          <source>Out-place version of &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt;&lt;code&gt;index_put_()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt;&lt;code&gt;torch.Tensor.index_put_()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Out-place version of &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt; &lt;code&gt;index_put_()&lt;/code&gt; &lt;/a&gt;. &lt;code&gt;tensor1&lt;/code&gt; corresponds to &lt;code&gt;self&lt;/code&gt; in &lt;a href=&quot;#torch.Tensor.index_put_&quot;&gt; &lt;code&gt;torch.Tensor.index_put_()&lt;/code&gt; &lt;/a&gt;.</target>
        </trans-unit>
        <trans-unit id="33c36eb13432b5622fd7de9ba502b6b4e6d48ded" translate="yes" xml:space="preserve">
          <source>Outer product of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積。</target>
        </trans-unit>
        <trans-unit id="615e0188218c976163bf2ec4e7c83bb336305665" translate="yes" xml:space="preserve">
          <source>Outer product of &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt;. If &lt;code&gt;input&lt;/code&gt; is a vector of size</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積。場合は &lt;code&gt;input&lt;/code&gt; サイズのベクトルであります</target>
        </trans-unit>
        <trans-unit id="67a0062a0687696c335a2c7d0e459405eba90f74" translate="yes" xml:space="preserve">
          <source>Output lists. It should contain correctly-sized tensors on each GPU to be used for output of the collective, e.g. &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; contains the all_gather result that resides on the GPU of &lt;code&gt;input_tensor_list[i]&lt;/code&gt;.</source>
          <target state="translated">出力リスト。それは例えば、集団の出力に使用する各GPU上の正しくサイズのテンソルを含まなければならない &lt;code&gt;output_tensor_lists[i]&lt;/code&gt; all_gather結果のGPUに存在することを含んで &lt;code&gt;input_tensor_list[i]&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="1b572830da9a955103a98dbcea6dc96cd3c1bf56" translate="yes" xml:space="preserve">
          <source>Output of running &lt;code&gt;function&lt;/code&gt; on &lt;code&gt;*args&lt;/code&gt;</source>
          <target state="translated">実行中の出力 &lt;code&gt;function&lt;/code&gt; 上 &lt;code&gt;*args&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="90de97722219af193315e02c2b185d1c1a5a4186" translate="yes" xml:space="preserve">
          <source>Output of running &lt;code&gt;functions&lt;/code&gt; sequentially on &lt;code&gt;*inputs&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;*inputs&lt;/code&gt; で実行中の &lt;code&gt;functions&lt;/code&gt; 順番に出力</target>
        </trans-unit>
        <trans-unit id="613a57f34002b7db7e7eb40fb879941fd5f0eb57" translate="yes" xml:space="preserve">
          <source>Output shape: &lt;code&gt;(B, embedding_dim)&lt;/code&gt;</source>
          <target state="translated">出力形状： &lt;code&gt;(B, embedding_dim)&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="f6a2e936babf4473798688e71160bef838804c5c" translate="yes" xml:space="preserve">
          <source>Output tensors (on different GPUs) to receive the result of the operation.</source>
          <target state="translated">演算結果を受け取るための出力テンソル(異なるGPU上で)。</target>
        </trans-unit>
        <trans-unit id="be4dd5eb977c617cc4374f35ce4dcfe3424e6c52" translate="yes" xml:space="preserve">
          <source>Output1:</source>
          <target state="translated">Output1:</target>
        </trans-unit>
        <trans-unit id="099f2ae15e5d444369fa820ff7e04ecd1eccb38d" translate="yes" xml:space="preserve">
          <source>Output2:</source>
          <target state="translated">Output2:</target>
        </trans-unit>
        <trans-unit id="f3c8c95c5e534bcd2ea0034a0d83177efa6923f4" translate="yes" xml:space="preserve">
          <source>Output:</source>
          <target state="translated">Output:</target>
        </trans-unit>
        <trans-unit id="8063b576f684099c293104f0277e7a1383d61e53" translate="yes" xml:space="preserve">
          <source>Output: &lt;code&gt;(*, embedding_dim)&lt;/code&gt;, where &lt;code&gt;*&lt;/code&gt; is the input shape</source>
          <target state="translated">出力： &lt;code&gt;(*, embedding_dim)&lt;/code&gt; 、ここで &lt;code&gt;*&lt;/code&gt; は入力形状です</target>
        </trans-unit>
        <trans-unit id="7b14dfe86f44f01989354331a43a653a7f8d7f72" translate="yes" xml:space="preserve">
          <source>Output: A Tensor of shape</source>
          <target state="translated">出力します。形状のテンソル</target>
        </trans-unit>
        <trans-unit id="4a4fbbd55c6c3ccbf6bf7220f45ac1790ff9bb33" translate="yes" xml:space="preserve">
          <source>Output: scalar by default. If :attr:&lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：デフォルトではスカラー。：attr： &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; の場合、</target>
        </trans-unit>
        <trans-unit id="7166320ecb31bd6a3586040c60443c5f16f96651" translate="yes" xml:space="preserve">
          <source>Output: scalar by default. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：デフォルトではスカラー。場合 &lt;code&gt;reduction&lt;/code&gt; ありません &lt;code&gt;'none'&lt;/code&gt; 、そして、</target>
        </trans-unit>
        <trans-unit id="88a34ee124c80fdb97be4c7994066abce0b11c8e" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then</source>
          <target state="translated">出力：スカラー。場合 &lt;code&gt;reduction&lt;/code&gt; ありません &lt;code&gt;'none'&lt;/code&gt; 、そして、</target>
        </trans-unit>
        <trans-unit id="816914c299df40485ecf46a1e795a1eb404d91d8" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then same shape as the input</source>
          <target state="translated">出力：スカラー。 &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; 場合、入力と同じ形状</target>
        </trans-unit>
        <trans-unit id="573c4c1298793f227765c23e85deebaee6066af6" translate="yes" xml:space="preserve">
          <source>Output: scalar. If &lt;code&gt;reduction&lt;/code&gt; is &lt;code&gt;'none'&lt;/code&gt;, then the same size as the target:</source>
          <target state="translated">出力：スカラー。 &lt;code&gt;reduction&lt;/code&gt; が &lt;code&gt;'none'&lt;/code&gt; 場合、ターゲットと同じサイズ：</target>
        </trans-unit>
        <trans-unit id="6ee76fa98a639a0ac269010b7032639b0a171647" translate="yes" xml:space="preserve">
          <source>Outputs:</source>
          <target state="translated">Outputs:</target>
        </trans-unit>
        <trans-unit id="19620445bec40ebeb61b840841c0effef04f34be" translate="yes" xml:space="preserve">
          <source>Outputs: (h_1, c_1)</source>
          <target state="translated">出力。(h_1,c_1)</target>
        </trans-unit>
        <trans-unit id="9b4d142414484eb98f10e629a2f06df85748b811" translate="yes" xml:space="preserve">
          <source>Outputs: h&amp;rsquo;</source>
          <target state="translated">出力：h '</target>
        </trans-unit>
        <trans-unit id="511c97e64880de564b0676893af9fcc8a480a2e2" translate="yes" xml:space="preserve">
          <source>Outputs: output, (h_n, c_n)</source>
          <target state="translated">出力:出力、(h_n,c_n)</target>
        </trans-unit>
        <trans-unit id="a459eb30ab99f3ae5b662cb99c1f4215b146179c" translate="yes" xml:space="preserve">
          <source>Outputs: output, h_n</source>
          <target state="translated">出力:出力、h_n</target>
        </trans-unit>
        <trans-unit id="3454926b31857082d753c8156d0ffd5035b9d6b1" translate="yes" xml:space="preserve">
          <source>Overloaded function.</source>
          <target state="translated">オーバーロードされた機能。</target>
        </trans-unit>
        <trans-unit id="23672df91d237894c7bd8c7afdec0a1cd14fb6f6" translate="yes" xml:space="preserve">
          <source>Owner Share RRef with User</source>
          <target state="translated">オーナー共有RRefをユーザーと共有</target>
        </trans-unit>
        <trans-unit id="511993d3c99719e38a6779073019dacd7178ddb9" translate="yes" xml:space="preserve">
          <source>P</source>
          <target state="translated">P</target>
        </trans-unit>
        <trans-unit id="4a6bac0b7fcbb3ba201bd5676355ccb5034a278a" translate="yes" xml:space="preserve">
          <source>P(x) = \dfrac{1}{\text{to} - \text{from}}</source>
          <target state="translated">P(x)=\dfrac{1}{Text{to}-¶Text{from}}}}。</target>
        </trans-unit>
        <trans-unit id="964bd5656c7a016ef0c9ada7382da7ca1fee27a4" translate="yes" xml:space="preserve">
          <source>PRODUCT</source>
          <target state="translated">PRODUCT</target>
        </trans-unit>
        <trans-unit id="768bfcbbf6df966e333cf0230ff5aeca88678ff9" translate="yes" xml:space="preserve">
          <source>PReLU</source>
          <target state="translated">PReLU</target>
        </trans-unit>
        <trans-unit id="c6672b1c1e9f2629ba013dde01df96129b495f92" translate="yes" xml:space="preserve">
          <source>PackedSequence</source>
          <target state="translated">PackedSequence</target>
        </trans-unit>
        <trans-unit id="c0577f7163ed4ff21523cd27bc5236f92de452c9" translate="yes" xml:space="preserve">
          <source>Packs a Tensor containing padded sequences of variable length.</source>
          <target state="translated">可変長のパッド付きシーケンスを含むテンソルをパックします。</target>
        </trans-unit>
        <trans-unit id="65d415f11a63c4c34ebb5de81f2e889c9328e53e" translate="yes" xml:space="preserve">
          <source>Packs a list of variable length Tensors</source>
          <target state="translated">可変長テンソルのリストをパックします。</target>
        </trans-unit>
        <trans-unit id="019020b0e5b242a0cc1a8528059f3ad86084afa9" translate="yes" xml:space="preserve">
          <source>Pad a list of variable length Tensors with &lt;code&gt;padding_value&lt;/code&gt;</source>
          <target state="translated">パッド付き可変長テンソルのリスト &lt;code&gt;padding_value&lt;/code&gt;</target>
        </trans-unit>
        <trans-unit id="2560c7ddae8fa20bff911361bd8035aef865bce1" translate="yes" xml:space="preserve">
          <source>Padding Layers</source>
          <target state="translated">パディング層</target>
        </trans-unit>
        <trans-unit id="119765b1620180622c6f6bb53002149703be9254" translate="yes" xml:space="preserve">
          <source>Padding mode:</source>
          <target state="translated">パディングモード。</target>
        </trans-unit>
        <trans-unit id="c28c7b4763bce482c5c0e969cee27313a7b7a4b3" translate="yes" xml:space="preserve">
          <source>Padding size:</source>
          <target state="translated">詰め物のサイズ。</target>
        </trans-unit>
        <trans-unit id="01c1aebd02a3849d24632e98070e328ff731c754" translate="yes" xml:space="preserve">
          <source>Pads a packed batch of variable length sequences.</source>
          <target state="translated">可変長のシーケンスをパックしたバッチをパッドします。</target>
        </trans-unit>
        <trans-unit id="5f2ca3b7c48057f8a6249de795ad4677ba74df59" translate="yes" xml:space="preserve">
          <source>Pads tensor.</source>
          <target state="translated">パッドテンソル。</target>
        </trans-unit>
        <trans-unit id="340e6f3d3040c075fcd53240ac5a1540bc713e60" translate="yes" xml:space="preserve">
          <source>Pads the input tensor boundaries with a constant value.</source>
          <target state="translated">入力テンソルの境界を一定の値でパッドします。</target>
        </trans-unit>
        <trans-unit id="66887cd786c809b7e475e385b383407a6d7e005a" translate="yes" xml:space="preserve">
          <source>Pads the input tensor boundaries with zero.</source>
          <target state="translated">入力テンソルの境界をゼロでパッドします。</target>
        </trans-unit>
        <trans-unit id="15f49157ae62175a9c8bfe59b0dd171af5f13c80" translate="yes" xml:space="preserve">
          <source>Pads the input tensor using replication of the input boundary.</source>
          <target state="translated">入力境界の複製を使用して入力テンソルをパッドします。</target>
        </trans-unit>
        <trans-unit id="2095464e9318d466281e389dabe7d857b2607c1d" translate="yes" xml:space="preserve">
          <source>Pads the input tensor using the reflection of the input boundary.</source>
          <target state="translated">入力境界の反射を利用して入力テンソルをパッドします。</target>
        </trans-unit>
        <trans-unit id="9b861161343780fb206bb4b2ff66ca3fba1cab61" translate="yes" xml:space="preserve">
          <source>PairwiseDistance</source>
          <target state="translated">PairwiseDistance</target>
        </trans-unit>
        <trans-unit id="1ad9f67d0f855f646efb3775c7a4778a3cc5a138" translate="yes" xml:space="preserve">
          <source>Parallelism</source>
          <target state="translated">Parallelism</target>
        </trans-unit>
        <trans-unit id="f699f295e5ae4ac633cfa18437fed38d028b3fdb" translate="yes" xml:space="preserve">
          <source>Parameter</source>
          <target state="translated">Parameter</target>
        </trans-unit>
        <trans-unit id="cb5ac90fcc6e04cb5c8cae65265e51f0ab35a0b7" translate="yes" xml:space="preserve">
          <source>Parameter names except the first must EXACTLY match the names in &lt;code&gt;forward&lt;/code&gt;.</source>
          <target state="translated">最初のパラメータ以外のパラメータ名は、 &lt;code&gt;forward&lt;/code&gt; の名前と完全に一致する必要があります。</target>
        </trans-unit>
        <trans-unit id="4891fc0302ab937e6c97e91f093534d4afb88b1e" translate="yes" xml:space="preserve">
          <source>Parameter ordering does NOT necessarily match what is in &lt;code&gt;VariableType.h&lt;/code&gt;, tensors (inputs) are always first, then non-tensor arguments.</source>
          <target state="translated">パラメータの順序は、 &lt;code&gt;VariableType.h&lt;/code&gt; の順序と必ずしも一致しません。テンソル（入力）が常に最初で、次に非テンソル引数です。</target>
        </trans-unit>
        <trans-unit id="88be3e0f29cc772e39dc2a268a55384b430d8f22" translate="yes" xml:space="preserve">
          <source>ParameterDict</source>
          <target state="translated">ParameterDict</target>
        </trans-unit>
        <trans-unit id="63777906465127a1bb8f4e009ca405717880743f" translate="yes" xml:space="preserve">
          <source>ParameterDict can be indexed like a regular Python dictionary, but parameters it contains are properly registered, and will be visible by all Module methods.</source>
          <target state="translated">ParameterDictは通常のPython辞書のようにインデックス化することができますが、それに含まれるパラメータは適切に登録されており、すべてのモジュールメソッドから可視化されます。</target>
        </trans-unit>
        <trans-unit id="acdf35da4c553e1dfc2210109486c37c589cbf86" translate="yes" xml:space="preserve">
          <source>ParameterList</source>
          <target state="translated">ParameterList</target>
        </trans-unit>
        <trans-unit id="a975eea30db9fa05003e3b5097688bd49ec7e01b" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="translated">Parameters</target>
        </trans-unit>
        <trans-unit id="b2ef1af91a76a3fb94590270b4864284563ecce3" translate="yes" xml:space="preserve">
          <source>Parameters are &lt;a href=&quot;../tensors#torch.Tensor&quot;&gt;&lt;code&gt;Tensor&lt;/code&gt;&lt;/a&gt; subclasses, that have a very special property when used with &lt;code&gt;Module&lt;/code&gt; s - when they&amp;rsquo;re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in &lt;code&gt;parameters()&lt;/code&gt; iterator. Assigning a Tensor doesn&amp;rsquo;t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as &lt;a href=&quot;#torch.nn.parameter.Parameter&quot;&gt;&lt;code&gt;Parameter&lt;/code&gt;&lt;/a&gt;, these temporaries would get registered too.</source>
          <target state="translated">パラメータは&lt;a href=&quot;../tensors#torch.Tensor&quot;&gt; &lt;code&gt;Tensor&lt;/code&gt; &lt;/a&gt;サブクラスであり、 &lt;code&gt;Module&lt;/code&gt; で使用すると非常に特殊なプロパティがあります。Module属性として割り当てられると、パラメータのリストに自動的に追加され、たとえば &lt;code&gt;parameters()&lt;/code&gt; イテレータに表示されます。テンソルを割り当てても、そのような効果はありません。これは、RNNの最後の非表示状態など、一時的な状態をモデルにキャッシュしたい場合があるためです。&lt;a href=&quot;#torch.nn.parameter.Parameter&quot;&gt; &lt;code&gt;Parameter&lt;/code&gt; &lt;/a&gt;のようなクラスがなかった場合、これらの一時的なものも登録されます。</target>
        </trans-unit>
        <trans-unit id="3df6923b905b81224f8a63a634516931831a9327" translate="yes" xml:space="preserve">
          <source>Parameters are never broadcast between processes. The module performs an all-reduce step on gradients and assumes that they will be modified by the optimizer in all processes in the same way. Buffers (e.g. BatchNorm stats) are broadcast from the module in process of rank 0, to all other replicas in the system in every iteration.</source>
          <target state="translated">パラメータはプロセス間でブロードキャストされることはありません。モジュールはグラデーションに対して全削減ステップを実行し、すべてのプロセスで同じようにオプティマイザによって変更されることを前提としています。バッファ(例えば、BatchNorm統計値)は、ランク0のプロセスのモジュールから、システム内の他のすべてのレプリカに、反復ごとにブロードキャストされます。</target>
        </trans-unit>
        <trans-unit id="a70edfd33f03d14b9304a9ca1fe474eaf0817702" translate="yes" xml:space="preserve">
          <source>Parsing the local_rank argument</source>
          <target state="translated">local_rank 引数のパース</target>
        </trans-unit>
        <trans-unit id="48a79b6f6f692b43d8485194d95ec3b0c6abe1d9" translate="yes" xml:space="preserve">
          <source>Pass the input through the encoder layer.</source>
          <target state="translated">入力をエンコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="74a6cfbb8f181d4db771aa9745afb6080e4ee4fe" translate="yes" xml:space="preserve">
          <source>Pass the input through the encoder layers in turn.</source>
          <target state="translated">入力を順番にエンコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="4d0cc1f642a2a736b4718ae462ea2ac809ed76b7" translate="yes" xml:space="preserve">
          <source>Pass the inputs (and mask) through the decoder layer in turn.</source>
          <target state="translated">入力(とマスク)を順番にデコーダ層に通します。</target>
        </trans-unit>
        <trans-unit id="8c65d8ab6bdf0e2280cb1ffcf102aefaac492303" translate="yes" xml:space="preserve">
          <source>Pass the inputs (and mask) through the decoder layer.</source>
          <target state="translated">入力(とマスク)をデコーダーレイヤーに通します。</target>
        </trans-unit>
        <trans-unit id="fd97c67f36d1e3c87f8ab45030bd4f215e7035cc" translate="yes" xml:space="preserve">
          <source>Passing -1 as the size for a dimension means not changing the size of that dimension.</source>
          <target state="translated">寸法のサイズとして -1 を渡すと、その寸法のサイズを変更しないことを意味します。</target>
        </trans-unit>
        <trans-unit id="ea3c8179bd96f54267bf75b132502b2bb1730b13" translate="yes" xml:space="preserve">
          <source>Pattern Matching Assignments</source>
          <target state="translated">パターンマッチングの割り当て</target>
        </trans-unit>
        <trans-unit id="bbb4559fe386a24723c5dad9bdcdef77441cfdce" translate="yes" xml:space="preserve">
          <source>Perform a shutdown of the RPC agent, and then destroy the RPC agent. This stops the local agent from accepting outstanding requests, and shuts down the RPC framework by terminating all RPC threads. If &lt;code&gt;graceful=True&lt;/code&gt;, this will block until all local and remote RPC processes reach this method and wait for all outstanding work to complete. Otherwise, if &lt;code&gt;graceful=False&lt;/code&gt;, this is a local shutdown, and it does not wait for other RPC processes to reach this method.</source>
          <target state="translated">RPCエージェントのシャットダウンを実行してから、RPCエージェントを破棄します。これにより、ローカルエージェントが未処理の要求を受け入れるのを停止し、すべてのRPCスレッドを終了してRPCフレームワークをシャットダウンします。 &lt;code&gt;graceful=True&lt;/code&gt; の場合、これはすべてのローカルおよびリモートRPCプロセスがこのメソッドに到達するまでブロックし、すべての未処理の作業が完了するのを待ちます。それ以外の場合、 &lt;code&gt;graceful=False&lt;/code&gt; の場合、これはローカルシャットダウンであり、他のRPCプロセスがこのメソッドに到達するのを待ちません。</target>
        </trans-unit>
        <trans-unit id="000d790b0603ede49c70b8206287b63e59d6ce01" translate="yes" xml:space="preserve">
          <source>Performs</source>
          <target state="translated">Performs</target>
        </trans-unit>
        <trans-unit id="ab6a68d7b5ed065f1d2b1e10ab32e7ca4fa89132" translate="yes" xml:space="preserve">
          <source>Performs Tensor dtype and/or device conversion. A &lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt;&lt;code&gt;torch.dtype&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt;&lt;code&gt;torch.device&lt;/code&gt;&lt;/a&gt; are inferred from the arguments of &lt;code&gt;self.to(*args, **kwargs)&lt;/code&gt;.</source>
          <target state="translated">Tensordtypeおよび/またはデバイス変換を実行します。&lt;a href=&quot;tensor_attributes#torch.torch.dtype&quot;&gt; &lt;code&gt;torch.dtype&lt;/code&gt; &lt;/a&gt;と&lt;a href=&quot;tensor_attributes#torch.torch.device&quot;&gt; &lt;code&gt;torch.device&lt;/code&gt; は&lt;/a&gt;の引数から推論されている &lt;code&gt;self.to(*args, **kwargs)&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="148ba906f736c7be8f3690226a95e0fc3751c601" translate="yes" xml:space="preserve">
          <source>Performs a &amp;ldquo;true&amp;rdquo; division like Python 3. See &lt;a href=&quot;torch.floor_divide#torch.floor_divide&quot;&gt;&lt;code&gt;torch.floor_divide()&lt;/code&gt;&lt;/a&gt; for floor division.</source>
          <target state="translated">Python 3のような「真の」除算を実行します。フロア除算については、&lt;a href=&quot;torch.floor_divide#torch.floor_divide&quot;&gt; &lt;code&gt;torch.floor_divide()&lt;/code&gt; &lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="ca1d45c075edfbcf89b6d16ec3eabd49d65b9ace" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; の行列の行列積。</target>
        </trans-unit>
        <trans-unit id="1d3416bea00d8ee005b5f0e7621baf85cbbbc8e4" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;. &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; の行列の行列積。 &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="6629b05e96ef663c5b3cf02ed167a20014b205ec" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;, with a reduced add step (all matrix multiplications get accumulated along the first dimension).</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; に格納された行列の行列積を、追加ステップを減らして実行します（すべての行列の乗算は最初の次元に沿って累積されます）。</target>
        </trans-unit>
        <trans-unit id="1710424b09b25bd3fe48dce1c221f445326275f1" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;batch1&lt;/code&gt; and &lt;code&gt;batch2&lt;/code&gt;, with a reduced add step (all matrix multiplications get accumulated along the first dimension). &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">バッチ行列を実行します &lt;code&gt;batch1&lt;/code&gt; と &lt;code&gt;batch2&lt;/code&gt; に格納された行列の行列積を、追加ステップを減らして実行します（すべての行列の乗算は最初の次元に沿って累積されます）。 &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="6860592c3b78f43f0a520489d41db750bddd29e5" translate="yes" xml:space="preserve">
          <source>Performs a batch matrix-matrix product of matrices stored in &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;input&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; に格納されている行列のバッチ行列-行列積を実行します。</target>
        </trans-unit>
        <trans-unit id="df9a63e54344ddcdcb571d3c78f6a26c0d733eac" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;input&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。</target>
        </trans-unit>
        <trans-unit id="e06b6aa87fc19869b8dd410c826fba4f794df727" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;mat1&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;mat1&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。</target>
        </trans-unit>
        <trans-unit id="bc47b86c1cbb06be939cda2d15d03119065f2793" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the matrices &lt;code&gt;mat1&lt;/code&gt; and &lt;code&gt;mat2&lt;/code&gt;. The matrix &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">行列 &lt;code&gt;mat1&lt;/code&gt; と &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。マトリックス &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="ec815028dc3febded0f07da8c4424505ed14884e" translate="yes" xml:space="preserve">
          <source>Performs a matrix multiplication of the sparse matrix &lt;code&gt;mat1&lt;/code&gt; and dense matrix &lt;code&gt;mat2&lt;/code&gt;. Similar to &lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt;&lt;code&gt;torch.mm()&lt;/code&gt;&lt;/a&gt;, If &lt;code&gt;mat1&lt;/code&gt; is a</source>
          <target state="translated">スパース行列 &lt;code&gt;mat1&lt;/code&gt; とデンス行列 &lt;code&gt;mat2&lt;/code&gt; の行列乗算を実行します。&lt;a href=&quot;generated/torch.mm#torch.mm&quot;&gt; &lt;code&gt;torch.mm()&lt;/code&gt; &lt;/a&gt;と同様に、 &lt;code&gt;mat1&lt;/code&gt; が</target>
        </trans-unit>
        <trans-unit id="0fcbec8807d0db14810ce48d50247513762338dc" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;input&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;input&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。</target>
        </trans-unit>
        <trans-unit id="fd688cf71edd9657ad9f3dba62a61d9bb7db410e" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;mat&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;.</source>
          <target state="translated">行列 &lt;code&gt;mat&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。</target>
        </trans-unit>
        <trans-unit id="0d3f478da414f374637a9f8efee9102a8950a0aa" translate="yes" xml:space="preserve">
          <source>Performs a matrix-vector product of the matrix &lt;code&gt;mat&lt;/code&gt; and the vector &lt;code&gt;vec&lt;/code&gt;. The vector &lt;code&gt;input&lt;/code&gt; is added to the final result.</source>
          <target state="translated">行列 &lt;code&gt;mat&lt;/code&gt; とベクトル &lt;code&gt;vec&lt;/code&gt; の行列-ベクトル積を実行します。ベクトル &lt;code&gt;input&lt;/code&gt; が最終結果に追加されます。</target>
        </trans-unit>
        <trans-unit id="eb4301873be53ea1f5d5d9d23cf8670a4bf294c6" translate="yes" xml:space="preserve">
          <source>Performs a single optimization step.</source>
          <target state="translated">単一の最適化ステップを実行します。</target>
        </trans-unit>
        <trans-unit id="097227fe1294d426da153667fbb89e50d7a799f6" translate="yes" xml:space="preserve">
          <source>Performs dtype and/or device conversion on &lt;code&gt;self.data&lt;/code&gt;.</source>
          <target state="translated">上の実行DTYPE及び/又はデバイス変換 &lt;code&gt;self.data&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="50008568c0d385fc9c65f3ac3f0c22f33a0fd7e8" translate="yes" xml:space="preserve">
          <source>Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix.</source>
          <target state="translated">低ランク行列,そのような行列のバッチ,または疎な行列に対して線形主成分分析(PCA)を実行します.</target>
        </trans-unit>
        <trans-unit id="20ee59ad32c7c62194b8cc1470dab04b5aeb1063" translate="yes" xml:space="preserve">
          <source>Performs the element-wise division of &lt;code&gt;tensor1&lt;/code&gt; by &lt;code&gt;tensor2&lt;/code&gt;, multiply the result by the scalar &lt;code&gt;value&lt;/code&gt; and add it to &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;tensor1&lt;/code&gt; を &lt;code&gt;tensor2&lt;/code&gt; で要素ごとに除算し、その結果にスカラー &lt;code&gt;value&lt;/code&gt; を掛けて、 &lt;code&gt;input&lt;/code&gt; 追加します。</target>
        </trans-unit>
        <trans-unit id="20dfc56a802418cc6cb883565e29a8149e17cc74" translate="yes" xml:space="preserve">
          <source>Performs the element-wise multiplication of &lt;code&gt;tensor1&lt;/code&gt; by &lt;code&gt;tensor2&lt;/code&gt;, multiply the result by the scalar &lt;code&gt;value&lt;/code&gt; and add it to &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">実行の要素ごとの乗算 &lt;code&gt;tensor1&lt;/code&gt; によって &lt;code&gt;tensor2&lt;/code&gt; 、乗算スカラーによって結果 &lt;code&gt;value&lt;/code&gt; とにそれを追加 &lt;code&gt;input&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="b8d3d151e5b759fb242c35ceb1f1a9e038806294" translate="yes" xml:space="preserve">
          <source>Performs the outer-product of vectors &lt;code&gt;vec1&lt;/code&gt; and &lt;code&gt;vec2&lt;/code&gt; and adds it to the matrix &lt;code&gt;input&lt;/code&gt;.</source>
          <target state="translated">ベクトル &lt;code&gt;vec1&lt;/code&gt; と &lt;code&gt;vec2&lt;/code&gt; の外積を実行し、それを行列 &lt;code&gt;input&lt;/code&gt; 追加します。</target>
        </trans-unit>
        <trans-unit id="7775a934f392a3fd32435cb3afba7f94cd7e9125" translate="yes" xml:space="preserve">
          <source>Permutes the dimensions of the &lt;code&gt;self&lt;/code&gt; tensor to match the dimension order in the &lt;code&gt;other&lt;/code&gt; tensor, adding size-one dims for any new names.</source>
          <target state="translated">並べ替えるの寸法 &lt;code&gt;self&lt;/code&gt; テンソルのディメンションの順序と一致するように、 &lt;code&gt;other&lt;/code&gt; 任意の新しい名前のためにサイズ-1暗くなるの追加、テンソル。</target>
        </trans-unit>
        <trans-unit id="172d57479053b5b2d1caa6f27506a79abfa3d89b" translate="yes" xml:space="preserve">
          <source>Permutes the dimensions of the &lt;code&gt;self&lt;/code&gt; tensor to match the order specified in &lt;a href=&quot;#torch.Tensor.names&quot;&gt;&lt;code&gt;names&lt;/code&gt;&lt;/a&gt;, adding size-one dims for any new names.</source>
          <target state="translated">&lt;code&gt;self&lt;/code&gt; テンソルの次元を&lt;a href=&quot;#torch.Tensor.names&quot;&gt; &lt;code&gt;names&lt;/code&gt; &lt;/a&gt;で指定された順序に一致するように並べ替え、新しい名前にサイズ1の薄暗い値を追加します。</target>
        </trans-unit>
        <trans-unit id="89073f3c192cb17be2601e291aa1534b084f3029" translate="yes" xml:space="preserve">
          <source>PixelShuffle</source>
          <target state="translated">PixelShuffle</target>
        </trans-unit>
        <trans-unit id="46d351806d607c75c00d9e7addd52a82379f8961" translate="yes" xml:space="preserve">
          <source>Please checkout &lt;a href=&quot;#tracing-vs-scripting&quot;&gt;Tracing vs Scripting&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#tracing-vs-scripting&quot;&gt;トレースとスクリプトを確認して&lt;/a&gt;ください。</target>
        </trans-unit>
        <trans-unit id="77243e0c917ac356b20b9bd68dd15bf839ebd531" translate="yes" xml:space="preserve">
          <source>Please ensure that &lt;code&gt;device_ids&lt;/code&gt; argument is set to be the only GPU device id that your code will be operating on. This is generally the local rank of the process. In other words, the &lt;code&gt;device_ids&lt;/code&gt; needs to be &lt;code&gt;[args.local_rank]&lt;/code&gt;, and &lt;code&gt;output_device&lt;/code&gt; needs to be &lt;code&gt;args.local_rank&lt;/code&gt; in order to use this utility</source>
          <target state="translated">&lt;code&gt;device_ids&lt;/code&gt; 引数が、コードが動作する唯一のGPUデバイスIDに設定されていることを確認してください。これは通常、プロセスのローカルランクです。換言すれば、 &lt;code&gt;device_ids&lt;/code&gt; のニーズであると &lt;code&gt;[args.local_rank]&lt;/code&gt; 、及び &lt;code&gt;output_device&lt;/code&gt; する必要が &lt;code&gt;args.local_rank&lt;/code&gt; このユーティリティを使用するために</target>
        </trans-unit>
        <trans-unit id="489042bcd064b62307292513642ef8adc6ce3919" translate="yes" xml:space="preserve">
          <source>Please refer to &lt;a href=&quot;https://pytorch.org/tutorials/beginner/dist_overview.html&quot;&gt;PyTorch Distributed Overview&lt;/a&gt; for a brief introduction to all features related to distributed training.</source>
          <target state="translated">分散トレーニングに関連するすべての機能の簡単な紹介については、&lt;a href=&quot;https://pytorch.org/tutorials/beginner/dist_overview.html&quot;&gt;PyTorch分散概要&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="17832db8653d0843df90a5d67009e3924ef34997" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#torch.Tensor.expand&quot;&gt;&lt;code&gt;expand()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;expand&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;#torch.Tensor.expand&quot;&gt; &lt;code&gt;expand()&lt;/code&gt; &lt;/a&gt;の詳細については、 &lt;code&gt;expand&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="5ec18ad55b74e4a4762c499e962c30b802cc51eb" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;#torch.Tensor.view&quot;&gt;&lt;code&gt;view()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;view&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;#torch.Tensor.view&quot;&gt; &lt;code&gt;view()&lt;/code&gt; &lt;/a&gt;詳細については、 &lt;code&gt;view&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="6ce3ed1431a0c41a218668fa1492f351b3c1863d" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt;&lt;code&gt;reshape()&lt;/code&gt;&lt;/a&gt; for more information about &lt;code&gt;reshape&lt;/code&gt;.</source>
          <target state="translated">参照してください&lt;a href=&quot;generated/torch.reshape#torch.reshape&quot;&gt; &lt;code&gt;reshape()&lt;/code&gt; &lt;/a&gt;詳細については、 &lt;code&gt;reshape&lt;/code&gt; 。</target>
        </trans-unit>
        <trans-unit id="037ad39d2570fc5f7861f69bb41699739bb0d316" translate="yes" xml:space="preserve">
          <source>Please see &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&quot;&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&lt;/a&gt; for more documentation on ReLU.</source>
          <target state="translated">ReLUの詳細については、&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU&quot;&gt;https：//pytorch.org/docs/stable/nn.html#torch.nn.ReLU&lt;/a&gt;を参照してください。</target>
        </trans-unit>
        <trans-unit id="4353aa1de0244f4e4d17336cf0860de21b27bcfd" translate="yes" xml:space="preserve">
          <source>Point-to-point communication</source>
          <target state="translated">ポイントツーポイント通信</target>
        </trans-unit>
        <trans-unit id="f2954403f1437b0d34c50ea2ba4d35acd2ad8ef0" translate="yes" xml:space="preserve">
          <source>Pointwise Ops</source>
          <target state="translated">ポイントワイズオペレーション</target>
        </trans-unit>
        <trans-unit id="7f6c43edfe5b4aaaf229cadb3d90c7f7c42e39d6" translate="yes" xml:space="preserve">
          <source>Poisson</source>
          <target state="translated">Poisson</target>
        </trans-unit>
        <trans-unit id="fa7dfe92888800753b97007c7d56433a35b2c1ff" translate="yes" xml:space="preserve">
          <source>Poisson negative log likelihood loss.</source>
          <target state="translated">ポアソン負の対数尤度損失。</target>
        </trans-unit>
        <trans-unit id="080ef63a7d510bdbbbb0c01b547bfd9466aafda2" translate="yes" xml:space="preserve">
          <source>PoissonNLLLoss</source>
          <target state="translated">PoissonNLLLoss</target>
        </trans-unit>
        <trans-unit id="58ef016bfefe7d0fa87dbd8a9397011926b50b05" translate="yes" xml:space="preserve">
          <source>Pooling functions</source>
          <target state="translated">プーリング機能</target>
        </trans-unit>
        <trans-unit id="4f14f8bf99ac13b99d1b436dd62fcdf8537ddee0" translate="yes" xml:space="preserve">
          <source>Pooling layers</source>
          <target state="translated">層をプールする</target>
        </trans-unit>
        <trans-unit id="7280aa9b126e519bb5acdcab7417841a30bb930a" translate="yes" xml:space="preserve">
          <source>Possible values are:</source>
          <target state="translated">可能な値は以下の通りです。</target>
        </trans-unit>
        <trans-unit id="6175db74ea439762cf31ac47bf2800599471e037" translate="yes" xml:space="preserve">
          <source>Pretrained weights can either be stored locally in the github repo, or loadable by &lt;a href=&quot;#torch.hub.load_state_dict_from_url&quot;&gt;&lt;code&gt;torch.hub.load_state_dict_from_url()&lt;/code&gt;&lt;/a&gt;. If less than 2GB, it&amp;rsquo;s recommended to attach it to a &lt;a href=&quot;https://help.github.com/en/articles/distributing-large-binaries&quot;&gt;project release&lt;/a&gt; and use the url from the release. In the example above &lt;code&gt;torchvision.models.resnet.resnet18&lt;/code&gt; handles &lt;code&gt;pretrained&lt;/code&gt;, alternatively you can put the following logic in the entrypoint definition.</source>
          <target state="translated">事前にトレーニングされたウェイトは、githubリポジトリにローカルに保存するか、&lt;a href=&quot;#torch.hub.load_state_dict_from_url&quot;&gt; &lt;code&gt;torch.hub.load_state_dict_from_url()&lt;/code&gt; で&lt;/a&gt;ロードできます。2GB未満の場合は、&lt;a href=&quot;https://help.github.com/en/articles/distributing-large-binaries&quot;&gt;プロジェクトリリース&lt;/a&gt;に添付して、リリースのURLを使用することをお勧めします。上記の例では、 &lt;code&gt;torchvision.models.resnet.resnet18&lt;/code&gt; が &lt;code&gt;pretrained&lt;/code&gt; トレーニング済みを処理します。または、エントリポイント定義に次のロジックを含めることもできます。</target>
        </trans-unit>
        <trans-unit id="fd6f86c9793df0ba1099fc411b3e7ec52a6a1cfe" translate="yes" xml:space="preserve">
          <source>Print Statements</source>
          <target state="translated">ステートメントの印刷</target>
        </trans-unit>
        <trans-unit id="d36d84ef2381c76d6d53fffa7008829b5eaeb1fc" translate="yes" xml:space="preserve">
          <source>Process Group Backend</source>
          <target state="translated">プロセスグループ バックエンド</target>
        </trans-unit>
        <trans-unit id="40e121339893a371c4a1b2c140642c9b6a34e9bd" translate="yes" xml:space="preserve">
          <source>Produces several warnings and a graph which simply returns the input:</source>
          <target state="translated">複数の警告と,入力を単純に返すグラフを生成します.</target>
        </trans-unit>
        <trans-unit id="a445fe395c6c6d32b8f6c47c9d18f8e8ae1263f5" translate="yes" xml:space="preserve">
          <source>Profiling RPC-based Workloads</source>
          <target state="translated">RPC ベースのワークロードのプロファイリング</target>
        </trans-unit>
        <trans-unit id="6f204147095385ad851c3a0b168d9ac27a7540b0" translate="yes" xml:space="preserve">
          <source>Promotion Examples:</source>
          <target state="translated">プロモーションの例。</target>
        </trans-unit>
        <trans-unit id="17a62537e52031c55b875c513ecbb2c241853032" translate="yes" xml:space="preserve">
          <source>Protocol Scenarios</source>
          <target state="translated">プロトコルのシナリオ</target>
        </trans-unit>
        <trans-unit id="7a477b80f752e81ae51a71148e25e03d00004834" translate="yes" xml:space="preserve">
          <source>Provides a skeleton for customization requiring the overriding of methods such as &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.compute_mask&quot;&gt;&lt;code&gt;compute_mask()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.apply&quot;&gt;&lt;code&gt;apply()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.compute_mask&quot;&gt; &lt;code&gt;compute_mask()&lt;/code&gt; &lt;/a&gt;や&lt;a href=&quot;#torch.nn.utils.prune.BasePruningMethod.apply&quot;&gt; &lt;code&gt;apply()&lt;/code&gt; &lt;/a&gt;などのメソッドのオーバーライドを必要とするカスタマイズ用のスケルトンを提供します。</target>
        </trans-unit>
        <trans-unit id="df76ae939d5d588eb6f5766984f7e5d52eb50216" translate="yes" xml:space="preserve">
          <source>Prune (currently unpruned) units in a tensor at random.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)単位をランダムに剪定します。</target>
        </trans-unit>
        <trans-unit id="368202ce04421132a9166203cfc137eb74e9e21c" translate="yes" xml:space="preserve">
          <source>Prune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.</source>
          <target state="translated">テンソル内の(現在剪定されていない)単位を、L1ノルムが最も低いものをゼロにすることで剪定します。</target>
        </trans-unit>
        <trans-unit id="5b5612215ed58f8a7a594acd4880fde95d901f0f" translate="yes" xml:space="preserve">
          <source>Prune entire (currently unpruned) channels in a tensor at random.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)チャンネル全体をランダムに剪定します。</target>
        </trans-unit>
        <trans-unit id="a802bde3db7f577abbb1b538eee51db0b51ddf30" translate="yes" xml:space="preserve">
          <source>Prune entire (currently unpruned) channels in a tensor based on their Ln-norm.</source>
          <target state="translated">テンソル内の(現在は剪定されていない)チャンネル全体を、そのLn-ノルムに基づいて剪定します。</target>
        </trans-unit>
        <trans-unit id="2306b2b0d296e475c246073f14ea3e13b1639fc6" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by applying the pre-computed mask in &lt;code&gt;mask&lt;/code&gt;.</source>
          <target state="translated">事前に計算されたマスクを &lt;code&gt;mask&lt;/code&gt; 適用することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを削除します。</target>
        </trans-unit>
        <trans-unit id="8222739be42aac5d12f65e68e036f42e19a41197" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by applying the pre-computed mask in &lt;code&gt;mask&lt;/code&gt;. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">事前に計算されたマスクを &lt;code&gt;mask&lt;/code&gt; 適用することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを削除します。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="12f145dd28935b207164778834f46d05e62d324e" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; selected at random.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。</target>
        </trans-unit>
        <trans-unit id="1993775f18835672e6ea2ee6df5cc4b95f07d89b" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; selected at random. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="e4cf8aaa8979161ded3d9362964d7e1da3ab5bd2" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; with the lowest L``n``-norm.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを、最小のL``n``-normで指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）チャネルを削除することによってプルーニングします。</target>
        </trans-unit>
        <trans-unit id="e5e671a44c6d84c3fbfdc3856808100dbb577dde" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) channels along the specified &lt;code&gt;dim&lt;/code&gt; with the lowest L``n``-norm. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">&lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを、指定された &lt;code&gt;dim&lt;/code&gt; に沿って指定された &lt;code&gt;amount&lt;/code&gt; の（現在は削除されていない）チャネルを削除し、L``n``-normを最小にします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="e414308272708bb6595a21b037cefd9b491135bf" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units selected at random.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。</target>
        </trans-unit>
        <trans-unit id="0d1f0e7025ef360a1a8db642ffde843b0c686100" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units selected at random. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">ランダムに選択された指定された &lt;code&gt;amount&lt;/code&gt; の（現在プルーニングされていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルをプルーニングします。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="0e2ae92cb48940de59dcf3dcc3eee3fc2761f74b" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units with the lowest L1-norm.</source>
          <target state="translated">L1ノルムが最も低い指定された &lt;code&gt;amount&lt;/code&gt; の（現在は剪定されていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを剪定します。</target>
        </trans-unit>
        <trans-unit id="3ceb680b02bb9fc923a4db9b23afd99bcf23bd57" translate="yes" xml:space="preserve">
          <source>Prunes tensor corresponding to parameter called &lt;code&gt;name&lt;/code&gt; in &lt;code&gt;module&lt;/code&gt; by removing the specified &lt;code&gt;amount&lt;/code&gt; of (currently unpruned) units with the lowest L1-norm. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called &lt;code&gt;name+'_mask'&lt;/code&gt; corresponding to the binary mask applied to the parameter &lt;code&gt;name&lt;/code&gt; by the pruning method. 2) replacing the parameter &lt;code&gt;name&lt;/code&gt; by its pruned version, while the original (unpruned) parameter is stored in a new parameter named &lt;code&gt;name+'_orig'&lt;/code&gt;.</source>
          <target state="translated">L1ノルムが最も低い指定された &lt;code&gt;amount&lt;/code&gt; の（現在は剪定されていない）ユニットを削除することにより、 &lt;code&gt;module&lt;/code&gt; 内の &lt;code&gt;name&lt;/code&gt; と呼ばれるパラメーターに対応するテンソルを剪定します。 1）プルーニングメソッドによってパラメータ &lt;code&gt;name&lt;/code&gt; 適用されたバイナリマスクに対応する &lt;code&gt;name+'_mask'&lt;/code&gt; という名前のバッファを追加することにより、モジュールをインプレースで変更します（また、変更されたモジュールを返します）。 2）元の（プルーニングされていない）パラメーターが &lt;code&gt;name+'_orig'&lt;/code&gt; という名前の新しいパラメーターに格納されている間に、パラメーター &lt;code&gt;name&lt;/code&gt; をプルーニングされたバージョンに置き換えます。</target>
        </trans-unit>
        <trans-unit id="8ee04a977907bca0b936aebe6227e9be8b0a5084" translate="yes" xml:space="preserve">
          <source>Pruning itself is NOT undone or reversed!</source>
          <target state="translated">剪定自体が元に戻ったり、逆になったりすることはありません!</target>
        </trans-unit>
        <trans-unit id="fae06ff3f9da62952a413ca3bf10b3455201b027" translate="yes" xml:space="preserve">
          <source>PruningContainer</source>
          <target state="translated">PruningContainer</target>
        </trans-unit>
        <trans-unit id="784e725830e98a189da61d3afccea45b6e5a9d0f" translate="yes" xml:space="preserve">
          <source>Publishing models</source>
          <target state="translated">出版モデル</target>
        </trans-unit>
        <trans-unit id="256db3aa08282f6add3cb3226d3554daf2bee937" translate="yes" xml:space="preserve">
          <source>Puts values from the tensor &lt;code&gt;value&lt;/code&gt; into the tensor &lt;code&gt;self&lt;/code&gt; using the indices specified in &lt;a href=&quot;#torch.Tensor.indices&quot;&gt;&lt;code&gt;indices&lt;/code&gt;&lt;/a&gt; (which is a tuple of Tensors). The expression &lt;code&gt;tensor.index_put_(indices, value)&lt;/code&gt; is equivalent to &lt;code&gt;tensor[indices] = value&lt;/code&gt;. Returns &lt;code&gt;self&lt;/code&gt;.</source>
          <target state="translated">インデックスで指定された&lt;a href=&quot;#torch.Tensor.indices&quot;&gt; &lt;code&gt;indices&lt;/code&gt; &lt;/a&gt;（テンソルのタプル）を使用して、テンソル &lt;code&gt;value&lt;/code&gt; をテンソル &lt;code&gt;self&lt;/code&gt; に入れます。式 &lt;code&gt;tensor.index_put_(indices, value)&lt;/code&gt; は、 &lt;code&gt;tensor[indices] = value&lt;/code&gt; と同等です。 &lt;code&gt;self&lt;/code&gt; を返します。</target>
        </trans-unit>
        <trans-unit id="98a2e30eeb85238d061519d74935e170e44c72cb" translate="yes" xml:space="preserve">
          <source>PyTorch</source>
          <target state="translated">PyTorch</target>
        </trans-unit>
        <trans-unit id="2837c35a89ca2ff1375acbd6ae4015154d808597" translate="yes" xml:space="preserve">
          <source>PyTorch Contribution Guide</source>
          <target state="translated">PyTorch 貢献ガイド</target>
        </trans-unit>
        <trans-unit id="0de6ec530c1988d0af9e4ce7eb73eef1189976b6" translate="yes" xml:space="preserve">
          <source>PyTorch Functions and Modules</source>
          <target state="translated">PyTorch の関数とモジュール</target>
        </trans-unit>
        <trans-unit id="6517675a341634e77bfecd3ddf631a647d857475" translate="yes" xml:space="preserve">
          <source>PyTorch Governance</source>
          <target state="translated">PyTorch ガバナンス</target>
        </trans-unit>
        <trans-unit id="d35b21e83a6b1a4ee2adc066dff9672eedab98a1" translate="yes" xml:space="preserve">
          <source>PyTorch Governance | Persons of Interest</source>
          <target state="translated">PyTorch ガバナンス|利害関係者の方へ</target>
        </trans-unit>
        <trans-unit id="3a2bd7a8f704e6cdbe374466d0208d799f0651cc" translate="yes" xml:space="preserve">
          <source>PyTorch and ONNX backends(Caffe2, ONNX Runtime, etc) often have implementations of operators with some numeric differences. Depending on model structure, these differences may be negligible, but they can also cause major divergences in behavior (especially on untrained models.) We allow Caffe2 to call directly to Torch implementations of operators, to help you smooth over these differences when precision is important, and to also document these differences.</source>
          <target state="translated">PyTorchやONNXのバックエンド(Caffe2,ONNX Runtimeなど)では、演算子の実装に数値的な違いがあることがよくあります。モデルの構造にもよりますが、これらの違いは無視できるほどのものではありませんが、動作に大きな違いが生じることもあります(特に非訓練モデルでは)。</target>
        </trans-unit>
        <trans-unit id="6148268ed386643e6b3a594818c58fc07ad9c665" translate="yes" xml:space="preserve">
          <source>PyTorch distributed package supports Linux (stable), MacOS (stable), and Windows (prototype). By default for Linux, the Gloo and NCCL backends are built and included in PyTorch distributed (NCCL only when building with CUDA). MPI is an optional backend that can only be included if you build PyTorch from source. (e.g.building PyTorch on a host that has MPI installed.)</source>
          <target state="translated">PyTorch の配布パッケージは Linux (stable)、MacOS (stable)、Windows (prototype)をサポートしています。Linuxの場合、デフォルトではGlooとNCCLのバックエンドがビルドされ、PyTorchに含まれています(NCCLはCUDAでビルドする場合のみ)。MPIはオプションのバックエンドで、ソースからPyTorchをビルドした場合にのみ含まれます。(例:MPI がインストールされているホストで PyTorch をビルドする場合)</target>
        </trans-unit>
        <trans-unit id="9456a74dbb38bfce73f52a1992187228bd2d00fa" translate="yes" xml:space="preserve">
          <source>PyTorch documentation</source>
          <target state="translated">PyTorch ドキュメント</target>
        </trans-unit>
        <trans-unit id="d19d474346c5b08d13d3339e3bf4feebcd91f549" translate="yes" xml:space="preserve">
          <source>PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.</source>
          <target state="translated">PyTorchはGPUやCPUを使ったディープラーニングのための最適化されたテンソルライブラリです。</target>
        </trans-unit>
        <trans-unit id="899246dc869a567118284070768757e2fc424c84" translate="yes" xml:space="preserve">
          <source>PyTorch on XLA Devices</source>
          <target state="translated">XLAデバイスのPyTorch</target>
        </trans-unit>
        <trans-unit id="c93898f1a89d832ed7049068dfa7cb16c03bf3ed" translate="yes" xml:space="preserve">
          <source>PyTorch preserves storage sharing across serialization. See &lt;code&gt;preserve-storage-sharing&lt;/code&gt; for more details.</source>
          <target state="translated">PyTorchは、シリアル化全体でストレージ共有を維持します。詳細については、 &lt;code&gt;preserve-storage-sharing&lt;/code&gt; を参照してください。</target>
        </trans-unit>
        <trans-unit id="ccb71e60b710059778503566d9b6733540438582" translate="yes" xml:space="preserve">
          <source>PyTorch ships with two builtin backends: &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; and &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt;. Additional ones can be registered using the &lt;code&gt;register_backend()&lt;/code&gt; function.</source>
          <target state="translated">PyTorchには、 &lt;code&gt;BackendType.TENSORPIPE&lt;/code&gt; と &lt;code&gt;BackendType.PROCESS_GROUP&lt;/code&gt; の2つの組み込みバックエンドが付属しています。追加のものは、 &lt;code&gt;register_backend()&lt;/code&gt; 関数を使用して登録できます。</target>
        </trans-unit>
        <trans-unit id="2d5a1e0600b8abe6782e41ec54cae91372de9186" translate="yes" xml:space="preserve">
          <source>Python 2 does not support Ellipsis but one may use a string literal instead (&lt;code&gt;'...'&lt;/code&gt;).</source>
          <target state="translated">Python 2は省略記号をサポートしていませんが、代わりに文字列リテラルを使用できます（ &lt;code&gt;'...'&lt;/code&gt; ）。</target>
        </trans-unit>
        <trans-unit id="b5ec6c002217ad80d40ef02a1f4366196fae59b7" translate="yes" xml:space="preserve">
          <source>Python 3 type hints can be used in place of &lt;code&gt;torch.jit.annotate&lt;/code&gt;</source>
          <target state="translated">&lt;code&gt;torch.jit.annotate&lt;/code&gt; の代わりにPython3タイプのヒントを使用できます</target>
        </trans-unit>
        <trans-unit id="0711b02500c16372db7e037b0db241051fe28013" translate="yes" xml:space="preserve">
          <source>Python API</source>
          <target state="translated">パイソンエーピーアイ</target>
        </trans-unit>
        <trans-unit id="cad6fbd004ed44f2a0389e7ad1a4cfa89ba1d3fc" translate="yes" xml:space="preserve">
          <source>Python Functions and Modules</source>
          <target state="translated">Python の関数とモジュール</target>
        </trans-unit>
        <trans-unit id="c9209054e624163b69a9eb976a32495c0a33865f" translate="yes" xml:space="preserve">
          <source>Python Language Reference Comparison</source>
          <target state="translated">Python言語リファレンス比較</target>
        </trans-unit>
        <trans-unit id="e4ec2cbb65019f4837950da585dfbc7781b88d91" translate="yes" xml:space="preserve">
          <source>Python Language Reference Coverage</source>
          <target state="translated">Pythonの言語リファレンスカバレッジ</target>
        </trans-unit>
        <trans-unit id="fd58a092a5203baf1b73956b039089eaeff86afb" translate="yes" xml:space="preserve">
          <source>Python classes can be used in TorchScript if they are annotated with &lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt;&lt;code&gt;@torch.jit.script&lt;/code&gt;&lt;/a&gt;, similar to how you would declare a TorchScript function:</source>
          <target state="translated">Pythonクラスは、TorchScript関数を宣言する方法と同様に、&lt;a href=&quot;generated/torch.jit.script#torch.jit.script&quot;&gt; &lt;code&gt;@torch.jit.script&lt;/code&gt; &lt;/a&gt;でアノテーションが付けられている場合、TorchScriptで使用できます。</target>
        </trans-unit>
        <trans-unit id="dcb69ff04adf584813a764fcff415e81178eed67" translate="yes" xml:space="preserve">
          <source>Python enums can be used in TorchScript without any extra annotation or code:</source>
          <target state="translated">Pythonのenumは、TorchScriptでは余計なアノテーションやコードを使わずに使用できます。</target>
        </trans-unit>
        <trans-unit id="21aa60d14a5d3bf9941c64223102e72e43cd7db3" translate="yes" xml:space="preserve">
          <source>Python-defined Constants</source>
          <target state="translated">Pythonで定義された定数</target>
        </trans-unit>
        <trans-unit id="bca513fe1a1ac6b508002e4d70e9b04a95755456" translate="yes" xml:space="preserve">
          <source>Pytorch Hub is a pre-trained model repository designed to facilitate research reproducibility.</source>
          <target state="translated">Pytorch Hubは、研究の再現性を高めるために設計された、事前に訓練されたモデルリポジトリです。</target>
        </trans-unit>
        <trans-unit id="4a3b71fd725a5570aa333bd5a258f51e9ad067c8" translate="yes" xml:space="preserve">
          <source>Pytorch Hub provides convenient APIs to explore all available models in hub through &lt;a href=&quot;#torch.hub.list&quot;&gt;&lt;code&gt;torch.hub.list()&lt;/code&gt;&lt;/a&gt;, show docstring and examples through &lt;a href=&quot;#torch.hub.help&quot;&gt;&lt;code&gt;torch.hub.help()&lt;/code&gt;&lt;/a&gt; and load the pre-trained models using &lt;a href=&quot;#torch.hub.load&quot;&gt;&lt;code&gt;torch.hub.load()&lt;/code&gt;&lt;/a&gt;.</source>
          <target state="translated">Pytorch Hubは、&lt;a href=&quot;#torch.hub.list&quot;&gt; &lt;code&gt;torch.hub.list()&lt;/code&gt; &lt;/a&gt;を介してハブで使用可能なすべてのモデルを探索し、&lt;a href=&quot;#torch.hub.help&quot;&gt; &lt;code&gt;torch.hub.help()&lt;/code&gt; &lt;/a&gt;を介してdocstringと例を表示し、&lt;a href=&quot;#torch.hub.load&quot;&gt; &lt;code&gt;torch.hub.load()&lt;/code&gt; &lt;/a&gt;を使用して事前トレーニング済みモデルをロードするための便利なAPIを提供します。</target>
        </trans-unit>
        <trans-unit id="71ea6e31bfc2cea7da3ec5ce3389fe77a6457276" translate="yes" xml:space="preserve">
          <source>Pytorch Hub supports publishing pre-trained models(model definitions and pre-trained weights) to a github repository by adding a simple &lt;code&gt;hubconf.py&lt;/code&gt; file;</source>
          <target state="translated">Pytorch Hubは、単純な &lt;code&gt;hubconf.py&lt;/code&gt; ファイルを追加することで、事前にトレーニングされたモデル（モデル定義と事前にトレーニングされた重み）をgithubリポジトリに公開することをサポートしています。</target>
        </trans-unit>
        <trans-unit id="c3156e00d3c2588c639e0d3cf6821258b05761c7" translate="yes" xml:space="preserve">
          <source>Q</source>
          <target state="translated">Q</target>
        </trans-unit>
        <trans-unit id="817b3643a8c9250c5615063227303b8c5da71cbe" translate="yes" xml:space="preserve">
          <source>Q: Does ONNX support implicit scalar datatype casting?</source>
          <target state="translated">Q:ONNXは暗黙のスカラデータ型キャストをサポートしていますか?</target>
        </trans-unit>
        <trans-unit id="e999540844f438b9780d0892a8883a34284bbec7" translate="yes" xml:space="preserve">
          <source>Q: How do I store attributes on a &lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt;&lt;code&gt;ScriptModule&lt;/code&gt;&lt;/a&gt;?</source>
          <target state="translated">Q：&lt;a href=&quot;generated/torch.jit.scriptmodule#torch.jit.ScriptModule&quot;&gt; &lt;code&gt;ScriptModule&lt;/code&gt; に&lt;/a&gt;属性を保存するにはどうすればよいですか？</target>
        </trans-unit>
        <trans-unit id="71cd3f9caa34814ac682f01c8799e67876c37c7b" translate="yes" xml:space="preserve">
          <source>Q: How to export models with loops in it?</source>
          <target state="translated">Q:ループが入ったモデルをエクスポートするには?</target>
        </trans-unit>
        <trans-unit id="3ab78ce25486eb77e84e3dce117cf425f112dd6c" translate="yes" xml:space="preserve">
          <source>Q: I have exported my lstm model, but its input size seems to be fixed?</source>
          <target state="translated">Q:lstmモデルをエクスポートしたのですが、入力サイズが固定されているようですが?</target>
        </trans-unit>
        <trans-unit id="a12de1b8a4f8718726ec01c0631665899c7a3116" translate="yes" xml:space="preserve">
          <source>Q: I would like to trace module&amp;rsquo;s method but I keep getting this error:</source>
          <target state="translated">Q：モジュールのメソッドをトレースしたいのですが、次のエラーが発生し続けます：</target>
        </trans-unit>
        <trans-unit id="2b00cd8e47e4d783f5be1951f1dd20a7ce719f21" translate="yes" xml:space="preserve">
          <source>Q: I would like to train a model on GPU and do inference on CPU. What are the best practices?</source>
          <target state="translated">Q:GPUでモデルを学習し、CPUで推論をしたい。ベストプラクティスは何ですか?</target>
        </trans-unit>
        <trans-unit id="470067c814eb1ea3d524592caed0d6e62ae92c6f" translate="yes" xml:space="preserve">
          <source>Q: Is tensor in-place indexed assignment like &lt;code&gt;data[index] = new_data&lt;/code&gt; supported?</source>
          <target state="translated">Q： &lt;code&gt;data[index] = new_data&lt;/code&gt; ようなテンソルインプレースインデックス付き代入はサポートされていますか？</target>
        </trans-unit>
        <trans-unit id="e79884b3f980f1ad19cca2c799bbefd52769c3b3" translate="yes" xml:space="preserve">
          <source>Q: Is tensor list exportable to ONNX?</source>
          <target state="translated">Q:テンソルリストはONNXにエクスポートできますか?</target>
        </trans-unit>
        <trans-unit id="892976819297325dacfe2454b5f3511112ebff7a" translate="yes" xml:space="preserve">
          <source>QFunctional</source>
          <target state="translated">QFunctional</target>
        </trans-unit>
        <trans-unit id="97f0eded6b0e44ee7ab93339b4fa67092a5342fa" translate="yes" xml:space="preserve">
          <source>Quantization</source>
          <target state="translated">Quantization</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>
